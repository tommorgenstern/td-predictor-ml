{"custom_id": "scrapy#0c9200094e0764023cd34e72d4012f1c0450d8ad", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 706 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 11 | Methods Changed: 13 | Complexity Δ (Sum/Max): 39/25 | Churn Δ: 709 | Churn Cumulative: 4016 | Contributors (this commit): 33 | Commits (past 90d): 7 | Contributors (cumulative): 63 | DMM Complexity: 0.7530864197530864\n\nDIFF:\n@@ -8,6 +8,7 @@ from pprint import pformat\n from typing import TYPE_CHECKING, Any, Union, cast\n \n from scrapy.settings import default_settings\n+from scrapy.utils.misc import load_object\n \n # The key types are restricted in BaseSettings._get_key() to ones supported by JSON,\n # see https://github.com/scrapy/scrapy/issues/5383.\n@@ -111,6 +112,31 @@ class BaseSettings(MutableMapping[_SettingsKeyT, Any]):\n     def __contains__(self, name: Any) -> bool:\n         return name in self.attributes\n \n+    def add_to_list(self, name: _SettingsKeyT, item: Any) -> None:\n+        \"\"\"Append *item* to the :class:`list` setting with the specified *name*\n+        if *item* is not already in that list.\n+\n+        This change is applied regardless of the priority of the *name*\n+        setting. The setting priority is not affected by this change either.\n+        \"\"\"\n+        value: list[str] = self.getlist(name)\n+        if item not in value:\n+            self.set(name, [*value, item], self.getpriority(name) or 0)\n+\n+    def remove_from_list(self, name: _SettingsKeyT, item: Any) -> None:\n+        \"\"\"Remove *item* from the :class:`list` setting with the specified\n+        *name*.\n+\n+        If *item* is missing, raise :exc:`ValueError`.\n+\n+        This change is applied regardless of the priority of the *name*\n+        setting. The setting priority is not affected by this change either.\n+        \"\"\"\n+        value: list[str] = self.getlist(name)\n+        if item not in value:\n+            raise ValueError(f\"{item!r} not found in the {name} setting ({value!r}).\")\n+        self.set(name, [v for v in value if v != item], self.getpriority(name) or 0)\n+\n     def get(self, name: _SettingsKeyT, default: Any = None) -> Any:\n         \"\"\"\n         Get a setting value without affecting its original type.\n@@ -181,8 +207,9 @@ class BaseSettings(MutableMapping[_SettingsKeyT, Any]):\n         self, name: _SettingsKeyT, default: list[Any] | None = None\n     ) -> list[Any]:\n         \"\"\"\n-        Get a setting value as a list. If the setting original type is a list, a\n-        copy of it will be returned. If it's a string it will be split by \",\".\n+        Get a setting value as a list. If the setting original type is a list,\n+        a copy of it will be returned. If it's a string it will be split by\n+        \",\". If it is an empty string, an empty list will be returned.\n \n         For example, settings populated through environment variables set to\n         ``'one,two'`` will return a list ['one', 'two'] when using this method.\n@@ -194,6 +221,8 @@ class BaseSettings(MutableMapping[_SettingsKeyT, Any]):\n         :type default: object\n         \"\"\"\n         value = self.get(name, default or [])\n+        if not value:\n+            return []\n         if isinstance(value, str):\n             value = value.split(\",\")\n         return list(value)\n@@ -299,6 +328,47 @@ class BaseSettings(MutableMapping[_SettingsKeyT, Any]):\n             return max(cast(int, self.getpriority(name)) for name in self)\n         return get_settings_priority(\"default\")\n \n+    def replace_in_component_priority_dict(\n+        self,\n+        name: _SettingsKeyT,\n+        old_cls: type,\n+        new_cls: type,\n+        priority: int | None = None,\n+    ) -> None:\n+        \"\"\"Replace *old_cls* with *new_cls* in the *name* :ref:`component\n+        priority dictionary <component-priority-dictionaries>`.\n+\n+        If *old_cls* is missing, or has :data:`None` as value, :exc:`KeyError`\n+        is raised.\n+\n+        If *old_cls* was present as an import string, even more than once,\n+        those keys are dropped and replaced by *new_cls*.\n+\n+        If *priority* is specified, that is the value assigned to *new_cls* in\n+        the component priority dictionary. Otherwise, the value of *old_cls* is\n+        used. If *old_cls* was present multiple times (possible with import\n+        strings) with different values, the value assigned to *new_cls* is one\n+        of them, with no guarantee about which one it is.\n+\n+        This change is applied regardless of the priority of the *name*\n+        setting. The setting priority is not affected by this change either.\n+        \"\"\"\n+        component_priority_dict = self.getdict(name)\n+        old_priority = None\n+        for cls_or_path in tuple(component_priority_dict):\n+            if load_object(cls_or_path) != old_cls:\n+                continue\n+            if (old_priority := component_priority_dict.pop(cls_or_path)) is None:\n+                break\n+        if old_priority is None:\n+            raise KeyError(\n+                f\"{old_cls} not found in the {name} setting ({component_priority_dict!r}).\"\n+            )\n+        component_priority_dict[new_cls] = (\n+            old_priority if priority is None else priority\n+        )\n+        self.set(name, component_priority_dict, priority=self.getpriority(name) or 0)\n+\n     def __setitem__(self, name: _SettingsKeyT, value: Any) -> None:\n         self.set(name, value)\n \n@@ -332,6 +402,30 @@ class BaseSettings(MutableMapping[_SettingsKeyT, Any]):\n         else:\n             self.attributes[name].set(value, priority)\n \n+    def set_in_component_priority_dict(\n+        self, name: _SettingsKeyT, cls: type, priority: int | None\n+    ) -> None:\n+        \"\"\"Set the *cls* component in the *name* :ref:`component priority\n+        dictionary <component-priority-dictionaries>` setting with *priority*.\n+\n+        If *cls* already exists, its value is updated.\n+\n+        If *cls* was present as an import string, even more than once, those\n+        keys are dropped and replaced by *cls*.\n+\n+        This change is applied regardless of the priority of the *name*\n+        setting. The setting priority is not affected by this change either.\n+        \"\"\"\n+        component_priority_dict = self.getdict(name)\n+        for cls_or_path in tuple(component_priority_dict):\n+            if not isinstance(cls_or_path, str):\n+                continue\n+            _cls = load_object(cls_or_path)\n+            if _cls == cls:\n+                del component_priority_dict[cls_or_path]\n+        component_priority_dict[cls] = priority\n+        self.set(name, component_priority_dict, self.getpriority(name) or 0)\n+\n     def setdefault(\n         self,\n         name: _SettingsKeyT,\n@@ -344,6 +438,24 @@ class BaseSettings(MutableMapping[_SettingsKeyT, Any]):\n \n         return self.attributes[name].value\n \n+    def setdefault_in_component_priority_dict(\n+        self, name: _SettingsKeyT, cls: type, priority: int | None\n+    ) -> None:\n+        \"\"\"Set the *cls* component in the *name* :ref:`component priority\n+        dictionary <component-priority-dictionaries>` setting with *priority*\n+        if not already defined (even as an import string).\n+\n+        If *cls* is not already defined, it is set regardless of the priority\n+        of the *name* setting. The setting priority is not affected by this\n+        change either.\n+        \"\"\"\n+        component_priority_dict = self.getdict(name)\n+        for cls_or_path in tuple(component_priority_dict):\n+            if load_object(cls_or_path) == cls:\n+                return\n+        component_priority_dict[cls] = priority\n+        self.set(name, component_priority_dict, self.getpriority(name) or 0)\n+\n     def setdict(self, values: _SettingsInputT, priority: int | str = \"project\") -> None:\n         self.update(values, priority)\n \n\n@@ -22,7 +22,8 @@ def build_component_list(\n     *,\n     convert: Callable[[Any], Any] = update_classpath,\n ) -> list[Any]:\n-    \"\"\"Compose a component list from a { class: order } dictionary.\"\"\"\n+    \"\"\"Compose a component list from a :ref:`component priority dictionary\n+    <component-priority-dictionaries>`.\"\"\"\n \n     def _check_components(complist: Collection[Any]) -> None:\n         if len({convert(c) for c in complist}) != len(complist):\n\n@@ -260,6 +260,7 @@ class BaseSettingsTest(unittest.TestCase):\n             \"TEST_FLOAT2\": \"123.45\",\n             \"TEST_LIST1\": [\"one\", \"two\"],\n             \"TEST_LIST2\": \"one,two\",\n+            \"TEST_LIST3\": \"\",\n             \"TEST_STR\": \"value\",\n             \"TEST_DICT1\": {\"key1\": \"val1\", \"ke2\": 3},\n             \"TEST_DICT2\": '{\"key1\": \"val1\", \"ke2\": 3}',\n@@ -292,6 +293,7 @@ class BaseSettingsTest(unittest.TestCase):\n         self.assertEqual(settings.getfloat(\"TEST_FLOATx\", 55.0), 55.0)\n         self.assertEqual(settings.getlist(\"TEST_LIST1\"), [\"one\", \"two\"])\n         self.assertEqual(settings.getlist(\"TEST_LIST2\"), [\"one\", \"two\"])\n+        self.assertEqual(settings.getlist(\"TEST_LIST3\"), [])\n         self.assertEqual(settings.getlist(\"TEST_LISTx\"), [])\n         self.assertEqual(settings.getlist(\"TEST_LISTx\", [\"default\"]), [\"default\"])\n         self.assertEqual(settings[\"TEST_STR\"], \"value\")\n@@ -504,3 +506,591 @@ class SettingsTest(unittest.TestCase):\n             TypeError, match=\"Trying to modify an immutable Settings object\"\n         ):\n             settings.pop(\"OTHER_DUMMY_CONFIG\")\n+\n+\n+@pytest.mark.parametrize(\n+    (\"before\", \"name\", \"item\", \"after\"),\n+    [\n+        ({}, \"FOO\", \"BAR\", {\"FOO\": [\"BAR\"]}),\n+        ({\"FOO\": []}, \"FOO\", \"BAR\", {\"FOO\": [\"BAR\"]}),\n+        ({\"FOO\": [\"BAR\"]}, \"FOO\", \"BAZ\", {\"FOO\": [\"BAR\", \"BAZ\"]}),\n+        ({\"FOO\": [\"BAR\"]}, \"FOO\", \"BAR\", {\"FOO\": [\"BAR\"]}),\n+        ({\"FOO\": \"\"}, \"FOO\", \"BAR\", {\"FOO\": [\"BAR\"]}),\n+        ({\"FOO\": \"BAR\"}, \"FOO\", \"BAR\", {\"FOO\": \"BAR\"}),\n+        ({\"FOO\": \"BAR\"}, \"FOO\", \"BAZ\", {\"FOO\": [\"BAR\", \"BAZ\"]}),\n+        ({\"FOO\": \"BAR,BAZ\"}, \"FOO\", \"BAZ\", {\"FOO\": \"BAR,BAZ\"}),\n+        ({\"FOO\": \"BAR,BAZ\"}, \"FOO\", \"QUX\", {\"FOO\": [\"BAR\", \"BAZ\", \"QUX\"]}),\n+    ],\n+)\n+def test_add_to_list(before, name, item, after):\n+    settings = BaseSettings(before, priority=0)\n+    settings.add_to_list(name, item)\n+    expected_priority = settings.getpriority(name) or 0\n+    expected_settings = BaseSettings(after, priority=expected_priority)\n+    assert settings == expected_settings, (\n+        f\"{settings[name]=} != {expected_settings[name]=}\"\n+    )\n+    assert settings.getpriority(name) == expected_settings.getpriority(name)\n+\n+\n+@pytest.mark.parametrize(\n+    (\"before\", \"name\", \"item\", \"after\"),\n+    [\n+        ({}, \"FOO\", \"BAR\", ValueError),\n+        ({\"FOO\": [\"BAR\"]}, \"FOO\", \"BAR\", {\"FOO\": []}),\n+        ({\"FOO\": [\"BAR\"]}, \"FOO\", \"BAZ\", ValueError),\n+        ({\"FOO\": [\"BAR\", \"BAZ\"]}, \"FOO\", \"BAR\", {\"FOO\": [\"BAZ\"]}),\n+        ({\"FOO\": \"\"}, \"FOO\", \"BAR\", ValueError),\n+        ({\"FOO\": \"[]\"}, \"FOO\", \"BAR\", ValueError),\n+        ({\"FOO\": \"BAR\"}, \"FOO\", \"BAR\", {\"FOO\": []}),\n+        ({\"FOO\": \"BAR\"}, \"FOO\", \"BAZ\", ValueError),\n+        ({\"FOO\": \"BAR,BAZ\"}, \"FOO\", \"BAR\", {\"FOO\": [\"BAZ\"]}),\n+    ],\n+)\n+def test_remove_from_list(before, name, item, after):\n+    settings = BaseSettings(before, priority=0)\n+\n+    if isinstance(after, type) and issubclass(after, Exception):\n+        with pytest.raises(after):\n+            settings.remove_from_list(name, item)\n+        return\n+\n+    settings.remove_from_list(name, item)\n+    expected_priority = settings.getpriority(name) or 0\n+    expected_settings = BaseSettings(after, priority=expected_priority)\n+    assert settings == expected_settings, (\n+        f\"{settings[name]=} != {expected_settings[name]=}\"\n+    )\n+    assert settings.getpriority(name) == expected_settings.getpriority(name)\n+\n+\n+class Component1:\n+    pass\n+\n+\n+Component1Alias = Component1\n+\n+\n+class Component1Subclass(Component1):\n+    pass\n+\n+\n+Component1SubclassAlias = Component1Subclass\n+\n+\n+class Component2:\n+    pass\n+\n+\n+class Component3:\n+    pass\n+\n+\n+class Component4:\n+    pass\n+\n+\n+@pytest.mark.parametrize(\n+    (\"before\", \"name\", \"old_cls\", \"new_cls\", \"priority\", \"after\"),\n+    [\n+        ({}, \"FOO\", Component1, Component2, None, KeyError),\n+        (\n+            {\"FOO\": {Component1: 1}},\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            None,\n+            {\"FOO\": {Component2: 1}},\n+        ),\n+        (\n+            {\"FOO\": {Component1: 1}},\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            2,\n+            {\"FOO\": {Component2: 2}},\n+        ),\n+        (\n+            {\"FOO\": {\"tests.test_settings.Component1\": 1}},\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            None,\n+            {\"FOO\": {Component2: 1}},\n+        ),\n+        (\n+            {\"FOO\": {Component1Alias: 1}},\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            None,\n+            {\"FOO\": {Component2: 1}},\n+        ),\n+        (\n+            {\"FOO\": {Component1Alias: 1}},\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            2,\n+            {\"FOO\": {Component2: 2}},\n+        ),\n+        (\n+            {\"FOO\": {\"tests.test_settings.Component1Alias\": 1}},\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            None,\n+            {\"FOO\": {Component2: 1}},\n+        ),\n+        (\n+            {\"FOO\": {\"tests.test_settings.Component1Alias\": 1}},\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            2,\n+            {\"FOO\": {Component2: 2}},\n+        ),\n+        (\n+            {\n+                \"FOO\": {\n+                    \"tests.test_settings.Component1\": 1,\n+                    \"tests.test_settings.Component1Alias\": 2,\n+                }\n+            },\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            None,\n+            {\"FOO\": {Component2: 2}},\n+        ),\n+        (\n+            {\n+                \"FOO\": {\n+                    \"tests.test_settings.Component1\": 1,\n+                    \"tests.test_settings.Component1Alias\": 2,\n+                }\n+            },\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            3,\n+            {\"FOO\": {Component2: 3}},\n+        ),\n+        (\n+            {\"FOO\": '{\"tests.test_settings.Component1\": 1}'},\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            None,\n+            {\"FOO\": {Component2: 1}},\n+        ),\n+        (\n+            {\"FOO\": '{\"tests.test_settings.Component1\": 1}'},\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            2,\n+            {\"FOO\": {Component2: 2}},\n+        ),\n+        (\n+            {\"FOO\": '{\"tests.test_settings.Component1Alias\": 1}'},\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            None,\n+            {\"FOO\": {Component2: 1}},\n+        ),\n+        (\n+            {\"FOO\": '{\"tests.test_settings.Component1Alias\": 1}'},\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            2,\n+            {\"FOO\": {Component2: 2}},\n+        ),\n+        (\n+            {\n+                \"FOO\": '{\"tests.test_settings.Component1\": 1, \"tests.test_settings.Component1Alias\": 2}'\n+            },\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            None,\n+            {\"FOO\": {Component2: 2}},\n+        ),\n+        (\n+            {\n+                \"FOO\": '{\"tests.test_settings.Component1\": 1, \"tests.test_settings.Component1Alias\": 2}'\n+            },\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            3,\n+            {\"FOO\": {Component2: 3}},\n+        ),\n+        # If old_cls has None as value, raise KeyError.\n+        (\n+            {\"FOO\": {Component1: None}},\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            None,\n+            KeyError,\n+        ),\n+        (\n+            {\"FOO\": '{\"tests.test_settings.Component1\": null}'},\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            None,\n+            KeyError,\n+        ),\n+        (\n+            {\"FOO\": {Component1: None, \"tests.test_settings.Component1\": None}},\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            None,\n+            KeyError,\n+        ),\n+        (\n+            {\"FOO\": {Component1: 1, \"tests.test_settings.Component1\": None}},\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            None,\n+            KeyError,\n+        ),\n+        (\n+            {\"FOO\": {Component1: None, \"tests.test_settings.Component1\": 1}},\n+            \"FOO\",\n+            Component1,\n+            Component2,\n+            None,\n+            KeyError,\n+        ),\n+        # Unrelated components are kept as is, as expected.\n+        (\n+            {\n+                \"FOO\": {\n+                    Component1: 1,\n+                    \"tests.test_settings.Component2\": 2,\n+                    Component3: 3,\n+                }\n+            },\n+            \"FOO\",\n+            Component3,\n+            Component4,\n+            None,\n+            {\n+                \"FOO\": {\n+                    Component1: 1,\n+                    \"tests.test_settings.Component2\": 2,\n+                    Component4: 3,\n+                }\n+            },\n+        ),\n+    ],\n+)\n+def test_replace_in_component_priority_dict(\n+    before, name, old_cls, new_cls, priority, after\n+):\n+    settings = BaseSettings(before, priority=0)\n+\n+    if isinstance(after, type) and issubclass(after, Exception):\n+        with pytest.raises(after):\n+            settings.replace_in_component_priority_dict(\n+                name, old_cls, new_cls, priority\n+            )\n+        return\n+\n+    expected_priority = settings.getpriority(name) or 0\n+    settings.replace_in_component_priority_dict(name, old_cls, new_cls, priority)\n+    expected_settings = BaseSettings(after, priority=expected_priority)\n+    assert settings == expected_settings\n+    assert settings.getpriority(name) == expected_settings.getpriority(name)\n+\n+\n+@pytest.mark.parametrize(\n+    (\"before\", \"name\", \"cls\", \"priority\", \"after\"),\n+    [\n+        # Set\n+        ({}, \"FOO\", Component1, None, {\"FOO\": {Component1: None}}),\n+        ({}, \"FOO\", Component1, 0, {\"FOO\": {Component1: 0}}),\n+        ({}, \"FOO\", Component1, 1, {\"FOO\": {Component1: 1}}),\n+        # Add\n+        (\n+            {\"FOO\": {Component1: 0}},\n+            \"FOO\",\n+            Component2,\n+            None,\n+            {\"FOO\": {Component1: 0, Component2: None}},\n+        ),\n+        (\n+            {\"FOO\": {Component1: 0}},\n+            \"FOO\",\n+            Component2,\n+            0,\n+            {\"FOO\": {Component1: 0, Component2: 0}},\n+        ),\n+        (\n+            {\"FOO\": {Component1: 0}},\n+            \"FOO\",\n+            Component2,\n+            1,\n+            {\"FOO\": {Component1: 0, Component2: 1}},\n+        ),\n+        # Replace\n+        (\n+            {\n+                \"FOO\": {\n+                    Component1: None,\n+                    \"tests.test_settings.Component1\": 0,\n+                    \"tests.test_settings.Component1Alias\": 1,\n+                    Component1Subclass: None,\n+                    \"tests.test_settings.Component1Subclass\": 0,\n+                    \"tests.test_settings.Component1SubclassAlias\": 1,\n+                }\n+            },\n+            \"FOO\",\n+            Component1,\n+            None,\n+            {\n+                \"FOO\": {\n+                    Component1: None,\n+                    Component1Subclass: None,\n+                    \"tests.test_settings.Component1Subclass\": 0,\n+                    \"tests.test_settings.Component1SubclassAlias\": 1,\n+                }\n+            },\n+        ),\n+        (\n+            {\n+                \"FOO\": {\n+                    Component1: 0,\n+                    \"tests.test_settings.Component1\": 1,\n+                    \"tests.test_settings.Component1Alias\": None,\n+                    Component1Subclass: 0,\n+                    \"tests.test_settings.Component1Subclass\": 1,\n+                    \"tests.test_settings.Component1SubclassAlias\": None,\n+                }\n+            },\n+            \"FOO\",\n+            Component1,\n+            0,\n+            {\n+                \"FOO\": {\n+                    Component1: 0,\n+                    Component1Subclass: 0,\n+                    \"tests.test_settings.Component1Subclass\": 1,\n+                    \"tests.test_settings.Component1SubclassAlias\": None,\n+                }\n+            },\n+        ),\n+        (\n+            {\n+                \"FOO\": {\n+                    Component1: 1,\n+                    \"tests.test_settings.Component1\": None,\n+                    \"tests.test_settings.Component1Alias\": 0,\n+                    Component1Subclass: 1,\n+                    \"tests.test_settings.Component1Subclass\": None,\n+                    \"tests.test_settings.Component1SubclassAlias\": 0,\n+                }\n+            },\n+            \"FOO\",\n+            Component1,\n+            1,\n+            {\n+                \"FOO\": {\n+                    Component1: 1,\n+                    Component1Subclass: 1,\n+                    \"tests.test_settings.Component1Subclass\": None,\n+                    \"tests.test_settings.Component1SubclassAlias\": 0,\n+                }\n+            },\n+        ),\n+        # String-based setting values\n+        (\n+            {\"FOO\": '{\"tests.test_settings.Component1\": 0}'},\n+            \"FOO\",\n+            Component2,\n+            None,\n+            {\"FOO\": {\"tests.test_settings.Component1\": 0, Component2: None}},\n+        ),\n+        (\n+            {\n+                \"FOO\": \"\"\"{\n+                    \"tests.test_settings.Component1\": 0,\n+                    \"tests.test_settings.Component1Alias\": 1,\n+                    \"tests.test_settings.Component1Subclass\": 0,\n+                    \"tests.test_settings.Component1SubclassAlias\": 1\n+                }\"\"\"\n+            },\n+            \"FOO\",\n+            Component1,\n+            None,\n+            {\n+                \"FOO\": {\n+                    Component1: None,\n+                    \"tests.test_settings.Component1Subclass\": 0,\n+                    \"tests.test_settings.Component1SubclassAlias\": 1,\n+                }\n+            },\n+        ),\n+    ],\n+)\n+def test_set_in_component_priority_dict(before, name, cls, priority, after):\n+    settings = BaseSettings(before, priority=0)\n+    expected_priority = settings.getpriority(name) or 0\n+    settings.set_in_component_priority_dict(name, cls, priority)\n+    expected_settings = BaseSettings(after, priority=expected_priority)\n+    assert settings == expected_settings\n+    assert settings.getpriority(name) == expected_settings.getpriority(name), (\n+        f\"{settings.getpriority(name)=} != {expected_settings.getpriority(name)=}\"\n+    )\n+\n+\n+@pytest.mark.parametrize(\n+    (\"before\", \"name\", \"cls\", \"priority\", \"after\"),\n+    [\n+        # Set\n+        ({}, \"FOO\", Component1, None, {\"FOO\": {Component1: None}}),\n+        ({}, \"FOO\", Component1, 0, {\"FOO\": {Component1: 0}}),\n+        ({}, \"FOO\", Component1, 1, {\"FOO\": {Component1: 1}}),\n+        # Add\n+        (\n+            {\"FOO\": {Component1: 0}},\n+            \"FOO\",\n+            Component2,\n+            None,\n+            {\"FOO\": {Component1: 0, Component2: None}},\n+        ),\n+        (\n+            {\"FOO\": {Component1: 0}},\n+            \"FOO\",\n+            Component2,\n+            0,\n+            {\"FOO\": {Component1: 0, Component2: 0}},\n+        ),\n+        (\n+            {\"FOO\": {Component1: 0}},\n+            \"FOO\",\n+            Component2,\n+            1,\n+            {\"FOO\": {Component1: 0, Component2: 1}},\n+        ),\n+        # Keep\n+        (\n+            {\n+                \"FOO\": {\n+                    Component1: None,\n+                    \"tests.test_settings.Component1\": 0,\n+                    \"tests.test_settings.Component1Alias\": 1,\n+                    Component1Subclass: None,\n+                    \"tests.test_settings.Component1Subclass\": 0,\n+                    \"tests.test_settings.Component1SubclassAlias\": 1,\n+                }\n+            },\n+            \"FOO\",\n+            Component1,\n+            None,\n+            {\n+                \"FOO\": {\n+                    Component1: None,\n+                    \"tests.test_settings.Component1\": 0,\n+                    \"tests.test_settings.Component1Alias\": 1,\n+                    Component1Subclass: None,\n+                    \"tests.test_settings.Component1Subclass\": 0,\n+                    \"tests.test_settings.Component1SubclassAlias\": 1,\n+                }\n+            },\n+        ),\n+        (\n+            {\n+                \"FOO\": {\n+                    Component1: 0,\n+                    \"tests.test_settings.Component1\": 1,\n+                    \"tests.test_settings.Component1Alias\": None,\n+                    Component1Subclass: 0,\n+                    \"tests.test_settings.Component1Subclass\": 1,\n+                    \"tests.test_settings.Component1SubclassAlias\": None,\n+                }\n+            },\n+            \"FOO\",\n+            Component1,\n+            0,\n+            {\n+                \"FOO\": {\n+                    Component1: 0,\n+                    \"tests.test_settings.Component1\": 1,\n+                    \"tests.test_settings.Component1Alias\": None,\n+                    Component1Subclass: 0,\n+                    \"tests.test_settings.Component1Subclass\": 1,\n+                    \"tests.test_settings.Component1SubclassAlias\": None,\n+                }\n+            },\n+        ),\n+        (\n+            {\n+                \"FOO\": {\n+                    Component1: 1,\n+                    \"tests.test_settings.Component1\": None,\n+                    \"tests.test_settings.Component1Alias\": 0,\n+                    Component1Subclass: 1,\n+                    \"tests.test_settings.Component1Subclass\": None,\n+                    \"tests.test_settings.Component1SubclassAlias\": 0,\n+                }\n+            },\n+            \"FOO\",\n+            Component1,\n+            1,\n+            {\n+                \"FOO\": {\n+                    Component1: 1,\n+                    \"tests.test_settings.Component1\": None,\n+                    \"tests.test_settings.Component1Alias\": 0,\n+                    Component1Subclass: 1,\n+                    \"tests.test_settings.Component1Subclass\": None,\n+                    \"tests.test_settings.Component1SubclassAlias\": 0,\n+                }\n+            },\n+        ),\n+        # String-based setting values\n+        (\n+            {\"FOO\": '{\"tests.test_settings.Component1\": 0}'},\n+            \"FOO\",\n+            Component2,\n+            None,\n+            {\"FOO\": {\"tests.test_settings.Component1\": 0, Component2: None}},\n+        ),\n+        (\n+            {\n+                \"FOO\": \"\"\"{\n+                    \"tests.test_settings.Component1\": 0,\n+                    \"tests.test_settings.Component1Alias\": 1,\n+                    \"tests.test_settings.Component1Subclass\": 0,\n+                    \"tests.test_settings.Component1SubclassAlias\": 1\n+                }\"\"\"\n+            },\n+            \"FOO\",\n+            Component1,\n+            None,\n+            {\n+                \"FOO\": \"\"\"{\n+                    \"tests.test_settings.Component1\": 0,\n+                    \"tests.test_settings.Component1Alias\": 1,\n+                    \"tests.test_settings.Component1Subclass\": 0,\n+                    \"tests.test_settings.Component1SubclassAlias\": 1\n+                }\"\"\"\n+            },\n+        ),\n+    ],\n+)\n+def test_setdefault_in_component_priority_dict(before, name, cls, priority, after):\n+    settings = BaseSettings(before, priority=0)\n+    expected_priority = settings.getpriority(name) or 0\n+    settings.setdefault_in_component_priority_dict(name, cls, priority)\n+    expected_settings = BaseSettings(after, priority=expected_priority)\n+    assert settings == expected_settings\n+    assert settings.getpriority(name) == expected_settings.getpriority(name)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#1843a4f75358a76fe8e4624f8f4dc26084d19b85", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 638 | Lines Deleted: 720 | Files Changed: 14 | Hunks: 335 | Methods Changed: 180 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1358 | Churn Cumulative: 10672 | Contributors (this commit): 54 | Commits (past 90d): 42 | Contributors (cumulative): 174 | DMM Complexity: 0.0\n\nDIFF:\n@@ -16,7 +16,7 @@ from scrapy.utils.python import to_bytes\n from scrapy.utils.test import get_crawler, get_from_asyncio_queue\n \n \n-class ManagerTestCase(TestCase):\n+class TestManagerBase(TestCase):\n     settings_dict = None\n \n     def setUp(self):\n@@ -51,14 +51,14 @@ class ManagerTestCase(TestCase):\n         return ret\n \n \n-class DefaultsTest(ManagerTestCase):\n+class TestDefaults(TestManagerBase):\n     \"\"\"Tests default behavior with default settings\"\"\"\n \n     def test_request_response(self):\n         req = Request(\"http://example.com/index.html\")\n         resp = Response(req.url, status=200)\n         ret = self._download(req, resp)\n-        self.assertTrue(isinstance(ret, Response), \"Non-response returned\")\n+        assert isinstance(ret, Response), \"Non-response returned\"\n \n     def test_3xx_and_invalid_gzipped_body_must_redirect(self):\n         \"\"\"Regression test for a failure when redirecting a compressed\n@@ -86,11 +86,9 @@ class DefaultsTest(ManagerTestCase):\n             },\n         )\n         ret = self._download(request=req, response=resp)\n-        self.assertTrue(isinstance(ret, Request), f\"Not redirected: {ret!r}\")\n-        self.assertEqual(\n-            to_bytes(ret.url),\n-            resp.headers[\"Location\"],\n-            \"Not redirected to location header\",\n+        assert isinstance(ret, Request), f\"Not redirected: {ret!r}\"\n+        assert to_bytes(ret.url) == resp.headers[\"Location\"], (\n+            \"Not redirected to location header\"\n         )\n \n     def test_200_and_invalid_gzipped_body_must_fail(self):\n@@ -111,7 +109,7 @@ class DefaultsTest(ManagerTestCase):\n             self._download(request=req, response=resp)\n \n \n-class ResponseFromProcessRequestTest(ManagerTestCase):\n+class TestResponseFromProcessRequest(TestManagerBase):\n     \"\"\"Tests middleware returning a response from process_request.\"\"\"\n \n     def test_download_func_not_called(self):\n@@ -130,11 +128,11 @@ class ResponseFromProcessRequestTest(ManagerTestCase):\n         dfd.addBoth(results.append)\n         self._wait(dfd)\n \n-        self.assertIs(results[0], resp)\n-        self.assertFalse(download_func.called)\n+        assert results[0] is resp\n+        assert not download_func.called\n \n \n-class ProcessRequestInvalidOutput(ManagerTestCase):\n+class TestProcessRequestInvalidOutput(TestManagerBase):\n     \"\"\"Invalid return value for process_request method should raise an exception\"\"\"\n \n     def test_invalid_process_request(self):\n@@ -149,11 +147,11 @@ class ProcessRequestInvalidOutput(ManagerTestCase):\n         dfd = self.mwman.download(download_func, req, self.spider)\n         results = []\n         dfd.addBoth(results.append)\n-        self.assertIsInstance(results[0], Failure)\n-        self.assertIsInstance(results[0].value, _InvalidOutput)\n+        assert isinstance(results[0], Failure)\n+        assert isinstance(results[0].value, _InvalidOutput)\n \n \n-class ProcessResponseInvalidOutput(ManagerTestCase):\n+class TestProcessResponseInvalidOutput(TestManagerBase):\n     \"\"\"Invalid return value for process_response method should raise an exception\"\"\"\n \n     def test_invalid_process_response(self):\n@@ -168,11 +166,11 @@ class ProcessResponseInvalidOutput(ManagerTestCase):\n         dfd = self.mwman.download(download_func, req, self.spider)\n         results = []\n         dfd.addBoth(results.append)\n-        self.assertIsInstance(results[0], Failure)\n-        self.assertIsInstance(results[0].value, _InvalidOutput)\n+        assert isinstance(results[0], Failure)\n+        assert isinstance(results[0].value, _InvalidOutput)\n \n \n-class ProcessExceptionInvalidOutput(ManagerTestCase):\n+class TestProcessExceptionInvalidOutput(TestManagerBase):\n     \"\"\"Invalid return value for process_exception method should raise an exception\"\"\"\n \n     def test_invalid_process_exception(self):\n@@ -190,11 +188,11 @@ class ProcessExceptionInvalidOutput(ManagerTestCase):\n         dfd = self.mwman.download(download_func, req, self.spider)\n         results = []\n         dfd.addBoth(results.append)\n-        self.assertIsInstance(results[0], Failure)\n-        self.assertIsInstance(results[0].value, _InvalidOutput)\n+        assert isinstance(results[0], Failure)\n+        assert isinstance(results[0].value, _InvalidOutput)\n \n \n-class MiddlewareUsingDeferreds(ManagerTestCase):\n+class TestMiddlewareUsingDeferreds(TestManagerBase):\n     \"\"\"Middlewares using Deferreds should work\"\"\"\n \n     def test_deferred(self):\n@@ -218,12 +216,12 @@ class MiddlewareUsingDeferreds(ManagerTestCase):\n         dfd.addBoth(results.append)\n         self._wait(dfd)\n \n-        self.assertIs(results[0], resp)\n-        self.assertFalse(download_func.called)\n+        assert results[0] is resp\n+        assert not download_func.called\n \n \n @pytest.mark.usefixtures(\"reactor_pytest\")\n-class MiddlewareUsingCoro(ManagerTestCase):\n+class TestMiddlewareUsingCoro(TestManagerBase):\n     \"\"\"Middlewares using asyncio coroutines should work\"\"\"\n \n     def test_asyncdef(self):\n@@ -242,8 +240,8 @@ class MiddlewareUsingCoro(ManagerTestCase):\n         dfd.addBoth(results.append)\n         self._wait(dfd)\n \n-        self.assertIs(results[0], resp)\n-        self.assertFalse(download_func.called)\n+        assert results[0] is resp\n+        assert not download_func.called\n \n     @pytest.mark.only_asyncio\n     def test_asyncdef_asyncio(self):\n@@ -262,5 +260,5 @@ class MiddlewareUsingCoro(ManagerTestCase):\n         dfd.addBoth(results.append)\n         self._wait(dfd)\n \n-        self.assertIs(results[0], resp)\n-        self.assertFalse(download_func.called)\n+        assert results[0] is resp\n+        assert not download_func.called\n\n@@ -1,5 +1,3 @@\n-import unittest\n-\n import pytest\n \n from scrapy.downloadermiddlewares.ajaxcrawl import AjaxCrawlMiddleware\n@@ -9,8 +7,8 @@ from scrapy.utils.test import get_crawler\n \n \n @pytest.mark.filterwarnings(\"ignore::scrapy.exceptions.ScrapyDeprecationWarning\")\n-class AjaxCrawlMiddlewareTest(unittest.TestCase):\n-    def setUp(self):\n+class TestAjaxCrawlMiddleware:\n+    def setup_method(self):\n         crawler = get_crawler(Spider, {\"AJAXCRAWL_ENABLED\": True})\n         self.spider = crawler._create_spider(\"foo\")\n         self.mw = AjaxCrawlMiddleware.from_crawler(crawler)\n@@ -26,13 +24,13 @@ class AjaxCrawlMiddlewareTest(unittest.TestCase):\n     def test_non_get(self):\n         req, resp = self._req_resp(\"http://example.com/\", {\"method\": \"HEAD\"})\n         resp2 = self.mw.process_response(req, resp, self.spider)\n-        self.assertEqual(resp, resp2)\n+        assert resp == resp2\n \n     def test_binary_response(self):\n         req = Request(\"http://example.com/\")\n         resp = Response(\"http://example.com/\", body=b\"foobar\\x00\\x01\\x02\", request=req)\n         resp2 = self.mw.process_response(req, resp, self.spider)\n-        self.assertIs(resp, resp2)\n+        assert resp is resp2\n \n     def test_ajaxcrawl(self):\n         req, resp = self._req_resp(\n@@ -41,8 +39,8 @@ class AjaxCrawlMiddlewareTest(unittest.TestCase):\n             {\"body\": self._ajaxcrawlable_body()},\n         )\n         req2 = self.mw.process_response(req, resp, self.spider)\n-        self.assertEqual(req2.url, \"http://example.com/?_escaped_fragment_=\")\n-        self.assertEqual(req2.meta[\"foo\"], \"bar\")\n+        assert req2.url == \"http://example.com/?_escaped_fragment_=\"\n+        assert req2.meta[\"foo\"] == \"bar\"\n \n     def test_ajaxcrawl_loop(self):\n         req, resp = self._req_resp(\n@@ -53,7 +51,7 @@ class AjaxCrawlMiddlewareTest(unittest.TestCase):\n         resp3 = self.mw.process_response(req2, resp2, self.spider)\n \n         assert isinstance(resp3, HtmlResponse), (resp3.__class__, resp3)\n-        self.assertEqual(resp3.request.url, \"http://example.com/?_escaped_fragment_=\")\n+        assert resp3.request.url == \"http://example.com/?_escaped_fragment_=\"\n         assert resp3 is resp2\n \n     def test_noncrawlable_body(self):\n@@ -61,4 +59,4 @@ class AjaxCrawlMiddlewareTest(unittest.TestCase):\n             \"http://example.com/\", {}, {\"body\": b\"<html></html>\"}\n         )\n         resp2 = self.mw.process_response(req, resp, self.spider)\n-        self.assertIs(resp, resp2)\n+        assert resp is resp2\n\n@@ -1,5 +1,4 @@\n import logging\n-from unittest import TestCase\n \n import pytest\n from testfixtures import LogCapture\n@@ -53,19 +52,19 @@ def _cookies_to_set_cookie_list(cookies):\n     return filter(None, (_cookie_to_set_cookie_value(cookie) for cookie in cookies))\n \n \n-class CookiesMiddlewareTest(TestCase):\n+class TestCookiesMiddleware:\n     def assertCookieValEqual(self, first, second, msg=None):\n         def split_cookies(cookies):\n             return sorted([s.strip() for s in to_bytes(cookies).split(b\";\")])\n \n-        return self.assertEqual(split_cookies(first), split_cookies(second), msg=msg)\n+        assert split_cookies(first) == split_cookies(second), msg\n \n-    def setUp(self):\n+    def setup_method(self):\n         self.spider = Spider(\"foo\")\n         self.mw = CookiesMiddleware()\n         self.redirect_middleware = RedirectMiddleware(settings=Settings())\n \n-    def tearDown(self):\n+    def teardown_method(self):\n         del self.mw\n         del self.redirect_middleware\n \n@@ -80,7 +79,7 @@ class CookiesMiddlewareTest(TestCase):\n \n         req2 = Request(\"http://scrapytest.org/sub1/\")\n         assert self.mw.process_request(req2, self.spider) is None\n-        self.assertEqual(req2.headers.get(\"Cookie\"), b\"C1=value1\")\n+        assert req2.headers.get(\"Cookie\") == b\"C1=value1\"\n \n     def test_setting_false_cookies_enabled(self):\n         with pytest.raises(NotConfigured):\n@@ -89,12 +88,12 @@ class CookiesMiddlewareTest(TestCase):\n             )\n \n     def test_setting_default_cookies_enabled(self):\n-        self.assertIsInstance(\n+        assert isinstance(\n             CookiesMiddleware.from_crawler(get_crawler()), CookiesMiddleware\n         )\n \n     def test_setting_true_cookies_enabled(self):\n-        self.assertIsInstance(\n+        assert isinstance(\n             CookiesMiddleware.from_crawler(\n                 get_crawler(settings_dict={\"COOKIES_ENABLED\": True})\n             ),\n@@ -161,7 +160,7 @@ class CookiesMiddlewareTest(TestCase):\n \n         req2 = Request(\"http://scrapytest.org/sub1/\")\n         assert self.mw.process_request(req2, self.spider) is None\n-        self.assertIn(\"Cookie\", req2.headers)\n+        assert \"Cookie\" in req2.headers\n \n     def test_dont_merge_cookies(self):\n         # merge some cookies into jar\n@@ -185,12 +184,12 @@ class CookiesMiddlewareTest(TestCase):\n         # check that cookies are merged back\n         req = Request(\"http://scrapytest.org/mergeme\")\n         assert self.mw.process_request(req, self.spider) is None\n-        self.assertEqual(req.headers.get(\"Cookie\"), b\"C1=value1\")\n+        assert req.headers.get(\"Cookie\") == b\"C1=value1\"\n \n         # check that cookies are merged when dont_merge_cookies is passed as 0\n         req = Request(\"http://scrapytest.org/mergeme\", meta={\"dont_merge_cookies\": 0})\n         assert self.mw.process_request(req, self.spider) is None\n-        self.assertEqual(req.headers.get(\"Cookie\"), b\"C1=value1\")\n+        assert req.headers.get(\"Cookie\") == b\"C1=value1\"\n \n     def test_complex_cookies(self):\n         # merge some cookies into jar\n@@ -230,7 +229,7 @@ class CookiesMiddlewareTest(TestCase):\n         # embed C2 for scrapytest.org/bar\n         req = Request(\"http://scrapytest.org/bar\")\n         self.mw.process_request(req, self.spider)\n-        self.assertEqual(req.headers.get(\"Cookie\"), b\"C2=value2\")\n+        assert req.headers.get(\"Cookie\") == b\"C2=value2\"\n \n         # embed nothing for scrapytest.org/baz\n         req = Request(\"http://scrapytest.org/baz\")\n@@ -240,7 +239,7 @@ class CookiesMiddlewareTest(TestCase):\n     def test_merge_request_cookies(self):\n         req = Request(\"http://scrapytest.org/\", cookies={\"galleta\": \"salada\"})\n         assert self.mw.process_request(req, self.spider) is None\n-        self.assertEqual(req.headers.get(\"Cookie\"), b\"galleta=salada\")\n+        assert req.headers.get(\"Cookie\") == b\"galleta=salada\"\n \n         headers = {\"Set-Cookie\": \"C1=value1; path=/\"}\n         res = Response(\"http://scrapytest.org/\", headers=headers)\n@@ -260,7 +259,7 @@ class CookiesMiddlewareTest(TestCase):\n             meta={\"cookiejar\": \"store1\"},\n         )\n         assert self.mw.process_request(req, self.spider) is None\n-        self.assertEqual(req.headers.get(\"Cookie\"), b\"galleta=salada\")\n+        assert req.headers.get(\"Cookie\") == b\"galleta=salada\"\n \n         headers = {\"Set-Cookie\": \"C1=value1; path=/\"}\n         res = Response(\"http://scrapytest.org/\", headers=headers, request=req)\n@@ -278,7 +277,7 @@ class CookiesMiddlewareTest(TestCase):\n             meta={\"cookiejar\": \"store2\"},\n         )\n         assert self.mw.process_request(req3, self.spider) is None\n-        self.assertEqual(req3.headers.get(\"Cookie\"), b\"galleta=dulce\")\n+        assert req3.headers.get(\"Cookie\") == b\"galleta=dulce\"\n \n         headers = {\"Set-Cookie\": \"C2=value2; path=/\"}\n         res2 = Response(\"http://scrapytest.org/\", headers=headers, request=req3)\n@@ -302,22 +301,22 @@ class CookiesMiddlewareTest(TestCase):\n \n         req5_2 = Request(\"http://scrapytest.org:1104/some-redirected-path\")\n         assert self.mw.process_request(req5_2, self.spider) is None\n-        self.assertEqual(req5_2.headers.get(\"Cookie\"), b\"C1=value1\")\n+        assert req5_2.headers.get(\"Cookie\") == b\"C1=value1\"\n \n         req5_3 = Request(\"http://scrapytest.org/some-redirected-path\")\n         assert self.mw.process_request(req5_3, self.spider) is None\n-        self.assertEqual(req5_3.headers.get(\"Cookie\"), b\"C1=value1\")\n+        assert req5_3.headers.get(\"Cookie\") == b\"C1=value1\"\n \n         # skip cookie retrieval for not http request\n         req6 = Request(\"file:///scrapy/sometempfile\")\n         assert self.mw.process_request(req6, self.spider) is None\n-        self.assertEqual(req6.headers.get(\"Cookie\"), None)\n+        assert req6.headers.get(\"Cookie\") is None\n \n     def test_local_domain(self):\n         request = Request(\"http://example-host/\", cookies={\"currencyCookie\": \"USD\"})\n         assert self.mw.process_request(request, self.spider) is None\n-        self.assertIn(\"Cookie\", request.headers)\n-        self.assertEqual(b\"currencyCookie=USD\", request.headers[\"Cookie\"])\n+        assert \"Cookie\" in request.headers\n+        assert request.headers[\"Cookie\"] == b\"currencyCookie=USD\"\n \n     @pytest.mark.xfail(reason=\"Cookie header is not currently being processed\")\n     def test_keep_cookie_from_default_request_headers_middleware(self):\n@@ -474,7 +473,7 @@ class CookiesMiddlewareTest(TestCase):\n         request1 = Request(cookies=input_cookies, **source)\n         self.mw.process_request(request1, self.spider)\n         cookies = request1.headers.get(\"Cookie\")\n-        self.assertEqual(cookies, b\"a=b\" if cookies1 else None)\n+        assert cookies == (b\"a=b\" if cookies1 else None)\n \n         response = Response(\n             headers={\n@@ -482,21 +481,18 @@ class CookiesMiddlewareTest(TestCase):\n             },\n             **target,\n         )\n-        self.assertEqual(\n-            self.mw.process_response(request1, response, self.spider),\n-            response,\n-        )\n+        assert self.mw.process_response(request1, response, self.spider) == response\n \n         request2 = self.redirect_middleware.process_response(\n             request1,\n             response,\n             self.spider,\n         )\n-        self.assertIsInstance(request2, Request)\n+        assert isinstance(request2, Request)\n \n         self.mw.process_request(request2, self.spider)\n         cookies = request2.headers.get(\"Cookie\")\n-        self.assertEqual(cookies, b\"a=b\" if cookies2 else None)\n+        assert cookies == (b\"a=b\" if cookies2 else None)\n \n     def test_cookie_redirect_same_domain(self):\n         self._test_cookie_redirect(\n@@ -573,10 +569,10 @@ class CookiesMiddlewareTest(TestCase):\n             response,\n             self.spider,\n         )\n-        self.assertIsInstance(request2, Request)\n+        assert isinstance(request2, Request)\n \n         cookies = request2.headers.get(\"Cookie\")\n-        self.assertEqual(cookies, b\"a=b\" if cookies2 else None)\n+        assert cookies == (b\"a=b\" if cookies2 else None)\n \n     def test_cookie_header_redirect_same_domain(self):\n         self._test_cookie_header_redirect(\n@@ -626,12 +622,12 @@ class CookiesMiddlewareTest(TestCase):\n         request1 = Request(url1, cookies=input_cookies)\n         self.mw.process_request(request1, self.spider)\n         cookies = request1.headers.get(\"Cookie\")\n-        self.assertEqual(cookies, b\"a=b\" if cookies1 else None)\n+        assert cookies == (b\"a=b\" if cookies1 else None)\n \n         request2 = Request(url2)\n         self.mw.process_request(request2, self.spider)\n         cookies = request2.headers.get(\"Cookie\")\n-        self.assertEqual(cookies, b\"a=b\" if cookies2 else None)\n+        assert cookies == (b\"a=b\" if cookies2 else None)\n \n     def test_user_set_cookie_domain_suffix_private(self):\n         self._test_user_set_cookie_domain_followup(\n@@ -692,15 +688,12 @@ class CookiesMiddlewareTest(TestCase):\n             \"Set-Cookie\": _cookies_to_set_cookie_list(input_cookies),\n         }\n         response = Response(url1, status=200, headers=headers)\n-        self.assertEqual(\n-            self.mw.process_response(request1, response, self.spider),\n-            response,\n-        )\n+        assert self.mw.process_response(request1, response, self.spider) == response\n \n         request2 = Request(url2)\n         self.mw.process_request(request2, self.spider)\n         actual_cookies = request2.headers.get(\"Cookie\")\n-        self.assertEqual(actual_cookies, b\"a=b\" if cookies else None)\n+        assert actual_cookies == (b\"a=b\" if cookies else None)\n \n     def test_server_set_cookie_domain_suffix_private(self):\n         self._test_server_set_cookie_domain_followup(\n@@ -752,30 +745,27 @@ class CookiesMiddlewareTest(TestCase):\n         request1 = Request(f\"{from_scheme}://a.example\", cookies=input_cookies)\n         self.mw.process_request(request1, self.spider)\n         cookies = request1.headers.get(\"Cookie\")\n-        self.assertEqual(cookies, b\"a=b\" if cookies1 else None)\n+        assert cookies == (b\"a=b\" if cookies1 else None)\n \n         response = Response(\n             f\"{from_scheme}://a.example\",\n             headers={\"Location\": f\"{to_scheme}://a.example\"},\n             status=301,\n         )\n-        self.assertEqual(\n-            self.mw.process_response(request1, response, self.spider),\n-            response,\n-        )\n+        assert self.mw.process_response(request1, response, self.spider) == response\n \n         request2 = self.redirect_middleware.process_response(\n             request1,\n             response,\n             self.spider,\n         )\n-        self.assertIsInstance(request2, Request)\n+        assert isinstance(request2, Request)\n         cookies = request2.headers.get(\"Cookie\")\n-        self.assertEqual(cookies, b\"a=b\" if cookies2 else None)\n+        assert cookies == (b\"a=b\" if cookies2 else None)\n \n         self.mw.process_request(request2, self.spider)\n         cookies = request2.headers.get(\"Cookie\")\n-        self.assertEqual(cookies, b\"a=b\" if cookies3 else None)\n+        assert cookies == (b\"a=b\" if cookies3 else None)\n \n     def test_cookie_redirect_secure_undefined_downgrade(self):\n         self._test_cookie_redirect_scheme_change(\n\n@@ -1,5 +1,3 @@\n-from unittest import TestCase\n-\n from scrapy.downloadermiddlewares.defaultheaders import DefaultHeadersMiddleware\n from scrapy.http import Request\n from scrapy.spiders import Spider\n@@ -7,7 +5,7 @@ from scrapy.utils.python import to_bytes\n from scrapy.utils.test import get_crawler\n \n \n-class TestDefaultHeadersMiddleware(TestCase):\n+class TestDefaultHeadersMiddleware:\n     def get_defaults_spider_mw(self):\n         crawler = get_crawler(Spider)\n         spider = crawler._create_spider(\"foo\")\n@@ -21,15 +19,15 @@ class TestDefaultHeadersMiddleware(TestCase):\n         defaults, spider, mw = self.get_defaults_spider_mw()\n         req = Request(\"http://www.scrapytest.org\")\n         mw.process_request(req, spider)\n-        self.assertEqual(req.headers, defaults)\n+        assert req.headers == defaults\n \n     def test_update_headers(self):\n         defaults, spider, mw = self.get_defaults_spider_mw()\n         headers = {\"Accept-Language\": [\"es\"], \"Test-Header\": [\"test\"]}\n         bytes_headers = {b\"Accept-Language\": [b\"es\"], b\"Test-Header\": [b\"test\"]}\n         req = Request(\"http://www.scrapytest.org\", headers=headers)\n-        self.assertEqual(req.headers, bytes_headers)\n+        assert req.headers == bytes_headers\n \n         mw.process_request(req, spider)\n         defaults.update(bytes_headers)\n-        self.assertEqual(req.headers, defaults)\n+        assert req.headers == defaults\n\n@@ -1,12 +1,10 @@\n-import unittest\n-\n from scrapy.downloadermiddlewares.downloadtimeout import DownloadTimeoutMiddleware\n from scrapy.http import Request\n from scrapy.spiders import Spider\n from scrapy.utils.test import get_crawler\n \n \n-class DownloadTimeoutMiddlewareTest(unittest.TestCase):\n+class TestDownloadTimeoutMiddleware:\n     def get_request_spider_mw(self, settings=None):\n         crawler = get_crawler(Spider, settings)\n         spider = crawler._create_spider(\"foo\")\n@@ -17,20 +15,20 @@ class DownloadTimeoutMiddlewareTest(unittest.TestCase):\n         req, spider, mw = self.get_request_spider_mw()\n         mw.spider_opened(spider)\n         assert mw.process_request(req, spider) is None\n-        self.assertEqual(req.meta.get(\"download_timeout\"), 180)\n+        assert req.meta.get(\"download_timeout\") == 180\n \n     def test_string_download_timeout(self):\n         req, spider, mw = self.get_request_spider_mw({\"DOWNLOAD_TIMEOUT\": \"20.1\"})\n         mw.spider_opened(spider)\n         assert mw.process_request(req, spider) is None\n-        self.assertEqual(req.meta.get(\"download_timeout\"), 20.1)\n+        assert req.meta.get(\"download_timeout\") == 20.1\n \n     def test_spider_has_download_timeout(self):\n         req, spider, mw = self.get_request_spider_mw()\n         spider.download_timeout = 2\n         mw.spider_opened(spider)\n         assert mw.process_request(req, spider) is None\n-        self.assertEqual(req.meta.get(\"download_timeout\"), 2)\n+        assert req.meta.get(\"download_timeout\") == 2\n \n     def test_request_has_download_timeout(self):\n         req, spider, mw = self.get_request_spider_mw()\n@@ -38,4 +36,4 @@ class DownloadTimeoutMiddlewareTest(unittest.TestCase):\n         mw.spider_opened(spider)\n         req.meta[\"download_timeout\"] = 1\n         assert mw.process_request(req, spider) is None\n-        self.assertEqual(req.meta.get(\"download_timeout\"), 1)\n+        assert req.meta.get(\"download_timeout\") == 1\n\n@@ -1,5 +1,3 @@\n-import unittest\n-\n import pytest\n from w3lib.http import basic_auth_header\n \n@@ -25,8 +23,8 @@ class AnyDomainSpider(Spider):\n     http_auth_domain = None\n \n \n-class HttpAuthMiddlewareLegacyTest(unittest.TestCase):\n-    def setUp(self):\n+class TestHttpAuthMiddlewareLegacy:\n+    def setup_method(self):\n         self.spider = LegacySpider(\"foo\")\n \n     def test_auth(self):\n@@ -35,51 +33,51 @@ class HttpAuthMiddlewareLegacyTest(unittest.TestCase):\n             mw.spider_opened(self.spider)\n \n \n-class HttpAuthMiddlewareTest(unittest.TestCase):\n-    def setUp(self):\n+class TestHttpAuthMiddleware:\n+    def setup_method(self):\n         self.mw = HttpAuthMiddleware()\n         self.spider = DomainSpider(\"foo\")\n         self.mw.spider_opened(self.spider)\n \n-    def tearDown(self):\n+    def teardown_method(self):\n         del self.mw\n \n     def test_no_auth(self):\n         req = Request(\"http://example-noauth.com/\")\n         assert self.mw.process_request(req, self.spider) is None\n-        self.assertNotIn(\"Authorization\", req.headers)\n+        assert \"Authorization\" not in req.headers\n \n     def test_auth_domain(self):\n         req = Request(\"http://example.com/\")\n         assert self.mw.process_request(req, self.spider) is None\n-        self.assertEqual(req.headers[\"Authorization\"], basic_auth_header(\"foo\", \"bar\"))\n+        assert req.headers[\"Authorization\"] == basic_auth_header(\"foo\", \"bar\")\n \n     def test_auth_subdomain(self):\n         req = Request(\"http://foo.example.com/\")\n         assert self.mw.process_request(req, self.spider) is None\n-        self.assertEqual(req.headers[\"Authorization\"], basic_auth_header(\"foo\", \"bar\"))\n+        assert req.headers[\"Authorization\"] == basic_auth_header(\"foo\", \"bar\")\n \n     def test_auth_already_set(self):\n         req = Request(\"http://example.com/\", headers={\"Authorization\": \"Digest 123\"})\n         assert self.mw.process_request(req, self.spider) is None\n-        self.assertEqual(req.headers[\"Authorization\"], b\"Digest 123\")\n+        assert req.headers[\"Authorization\"] == b\"Digest 123\"\n \n \n-class HttpAuthAnyMiddlewareTest(unittest.TestCase):\n-    def setUp(self):\n+class TestHttpAuthAnyMiddleware:\n+    def setup_method(self):\n         self.mw = HttpAuthMiddleware()\n         self.spider = AnyDomainSpider(\"foo\")\n         self.mw.spider_opened(self.spider)\n \n-    def tearDown(self):\n+    def teardown_method(self):\n         del self.mw\n \n     def test_auth(self):\n         req = Request(\"http://example.com/\")\n         assert self.mw.process_request(req, self.spider) is None\n-        self.assertEqual(req.headers[\"Authorization\"], basic_auth_header(\"foo\", \"bar\"))\n+        assert req.headers[\"Authorization\"] == basic_auth_header(\"foo\", \"bar\")\n \n     def test_auth_already_set(self):\n         req = Request(\"http://example.com/\", headers={\"Authorization\": \"Digest 123\"})\n         assert self.mw.process_request(req, self.spider) is None\n-        self.assertEqual(req.headers[\"Authorization\"], b\"Digest 123\")\n+        assert req.headers[\"Authorization\"] == b\"Digest 123\"\n\n@@ -2,7 +2,6 @@ import email.utils\n import shutil\n import tempfile\n import time\n-import unittest\n from contextlib import contextmanager\n \n import pytest\n@@ -15,11 +14,11 @@ from scrapy.spiders import Spider\n from scrapy.utils.test import get_crawler\n \n \n-class _BaseTest(unittest.TestCase):\n+class TestBase:\n     storage_class = \"scrapy.extensions.httpcache.FilesystemCacheStorage\"\n     policy_class = \"scrapy.extensions.httpcache.RFC2616Policy\"\n \n-    def setUp(self):\n+    def setup_method(self):\n         self.yesterday = email.utils.formatdate(time.time() - 86400)\n         self.today = email.utils.formatdate()\n         self.tomorrow = email.utils.formatdate(time.time() + 86400)\n@@ -35,7 +34,7 @@ class _BaseTest(unittest.TestCase):\n         )\n         self.crawler.stats.open_spider(self.spider)\n \n-    def tearDown(self):\n+    def teardown_method(self):\n         self.crawler.stats.close_spider(self.spider, \"\")\n         shutil.rmtree(self.tmpdir)\n \n@@ -72,44 +71,42 @@ class _BaseTest(unittest.TestCase):\n             mw.spider_closed(self.spider)\n \n     def assertEqualResponse(self, response1, response2):\n-        self.assertEqual(response1.url, response2.url)\n-        self.assertEqual(response1.status, response2.status)\n-        self.assertEqual(response1.headers, response2.headers)\n-        self.assertEqual(response1.body, response2.body)\n+        assert response1.url == response2.url\n+        assert response1.status == response2.status\n+        assert response1.headers == response2.headers\n+        assert response1.body == response2.body\n \n     def assertEqualRequest(self, request1, request2):\n-        self.assertEqual(request1.url, request2.url)\n-        self.assertEqual(request1.headers, request2.headers)\n-        self.assertEqual(request1.body, request2.body)\n+        assert request1.url == request2.url\n+        assert request1.headers == request2.headers\n+        assert request1.body == request2.body\n \n     def assertEqualRequestButWithCacheValidators(self, request1, request2):\n-        self.assertEqual(request1.url, request2.url)\n+        assert request1.url == request2.url\n         assert b\"If-None-Match\" not in request1.headers\n         assert b\"If-Modified-Since\" not in request1.headers\n         assert any(\n             h in request2.headers for h in (b\"If-None-Match\", b\"If-Modified-Since\")\n         )\n-        self.assertEqual(request1.body, request2.body)\n+        assert request1.body == request2.body\n \n     def test_dont_cache(self):\n         with self._middleware() as mw:\n             self.request.meta[\"dont_cache\"] = True\n             mw.process_response(self.request, self.response, self.spider)\n-            self.assertEqual(\n-                mw.storage.retrieve_response(self.spider, self.request), None\n-            )\n+            assert mw.storage.retrieve_response(self.spider, self.request) is None\n \n         with self._middleware() as mw:\n             self.request.meta[\"dont_cache\"] = False\n             mw.process_response(self.request, self.response, self.spider)\n             if mw.policy.should_cache_response(self.response, self.request):\n-                self.assertIsInstance(\n+                assert isinstance(\n                     mw.storage.retrieve_response(self.spider, self.request),\n                     self.response.__class__,\n                 )\n \n \n-class DefaultStorageTest(_BaseTest):\n+class TestDefaultStorage(TestBase):\n     def test_storage(self):\n         with self._storage() as storage:\n             request2 = self.request.copy()\n@@ -142,15 +139,15 @@ class DefaultStorageTest(_BaseTest):\n             )\n             storage.store_response(self.spider, self.request, response)\n             cached_response = storage.retrieve_response(self.spider, self.request)\n-            self.assertIsInstance(cached_response, HtmlResponse)\n+            assert isinstance(cached_response, HtmlResponse)\n             self.assertEqualResponse(response, cached_response)\n \n \n-class DbmStorageTest(DefaultStorageTest):\n+class TestDbmStorage(TestDefaultStorage):\n     storage_class = \"scrapy.extensions.httpcache.DbmCacheStorage\"\n \n \n-class DbmStorageWithCustomDbmModuleTest(DbmStorageTest):\n+class TestDbmStorageWithCustomDbmModule(TestDbmStorage):\n     dbm_module = \"tests.mocks.dummydbm\"\n \n     def _get_settings(self, **new_settings):\n@@ -160,16 +157,16 @@ class DbmStorageWithCustomDbmModuleTest(DbmStorageTest):\n     def test_custom_dbm_module_loaded(self):\n         # make sure our dbm module has been loaded\n         with self._storage() as storage:\n-            self.assertEqual(storage.dbmodule.__name__, self.dbm_module)\n+            assert storage.dbmodule.__name__ == self.dbm_module\n \n \n-class FilesystemStorageGzipTest(DefaultStorageTest):\n+class TestFilesystemStorageGzip(TestDefaultStorage):\n     def _get_settings(self, **new_settings):\n         new_settings.setdefault(\"HTTPCACHE_GZIP\", True)\n         return super()._get_settings(**new_settings)\n \n \n-class DummyPolicyTest(_BaseTest):\n+class TestDummyPolicy(TestBase):\n     policy_class = \"scrapy.extensions.httpcache.DummyPolicy\"\n \n     def test_middleware(self):\n@@ -261,7 +258,7 @@ class DummyPolicyTest(_BaseTest):\n             assert \"cached\" in response.flags\n \n \n-class RFC2616PolicyTest(DefaultStorageTest):\n+class TestRFC2616Policy(TestDefaultStorage):\n     policy_class = \"scrapy.extensions.httpcache.RFC2616Policy\"\n \n     def _process_requestresponse(self, mw, request, response):\n@@ -357,7 +354,7 @@ class RFC2616PolicyTest(DefaultStorageTest):\n                     assert \"cached\" in res2.flags\n                     assert res2.status != 304\n                 else:\n-                    self.assertFalse(resc)\n+                    assert not resc\n                     assert \"cached\" not in res2.flags\n \n         # cache unconditionally unless response contains no-store or is a 304\n@@ -381,7 +378,7 @@ class RFC2616PolicyTest(DefaultStorageTest):\n                     assert \"cached\" in res2.flags\n                     assert res2.status != 304\n                 else:\n-                    self.assertFalse(resc)\n+                    assert not resc\n                     assert \"cached\" not in res2.flags\n \n     def test_cached_and_fresh(self):\n\n@@ -2,7 +2,7 @@ from gzip import GzipFile\n from io import BytesIO\n from logging import WARNING\n from pathlib import Path\n-from unittest import SkipTest, TestCase\n+from unittest import SkipTest\n \n import pytest\n from testfixtures import LogCapture\n@@ -51,8 +51,8 @@ FORMAT = {\n }\n \n \n-class HttpCompressionTest(TestCase):\n-    def setUp(self):\n+class TestHttpCompression:\n+    def setup_method(self):\n         self.crawler = get_crawler(Spider)\n         self.spider = self.crawler._create_spider(\"scrapytest.org\")\n         self.mw = HttpCompressionMiddleware.from_crawler(self.crawler)\n@@ -81,10 +81,8 @@ class HttpCompressionTest(TestCase):\n         return response\n \n     def assertStatsEqual(self, key, value):\n-        self.assertEqual(\n-            self.crawler.stats.get_value(key, spider=self.spider),\n-            value,\n-            str(self.crawler.stats.get_stats(self.spider)),\n+        assert self.crawler.stats.get_value(key, spider=self.spider) == value, str(\n+            self.crawler.stats.get_stats(self.spider)\n         )\n \n     def test_setting_false_compression_enabled(self):\n@@ -94,13 +92,13 @@ class HttpCompressionTest(TestCase):\n             )\n \n     def test_setting_default_compression_enabled(self):\n-        self.assertIsInstance(\n+        assert isinstance(\n             HttpCompressionMiddleware.from_crawler(get_crawler()),\n             HttpCompressionMiddleware,\n         )\n \n     def test_setting_true_compression_enabled(self):\n-        self.assertIsInstance(\n+        assert isinstance(\n             HttpCompressionMiddleware.from_crawler(\n                 get_crawler(settings_dict={\"COMPRESSION_ENABLED\": True})\n             ),\n@@ -111,15 +109,13 @@ class HttpCompressionTest(TestCase):\n         request = Request(\"http://scrapytest.org\")\n         assert \"Accept-Encoding\" not in request.headers\n         self.mw.process_request(request, self.spider)\n-        self.assertEqual(\n-            request.headers.get(\"Accept-Encoding\"), b\", \".join(ACCEPTED_ENCODINGS)\n-        )\n+        assert request.headers.get(\"Accept-Encoding\") == b\", \".join(ACCEPTED_ENCODINGS)\n \n     def test_process_response_gzip(self):\n         response = self._getresponse(\"gzip\")\n         request = response.request\n \n-        self.assertEqual(response.headers[\"Content-Encoding\"], b\"gzip\")\n+        assert response.headers[\"Content-Encoding\"] == b\"gzip\"\n         newresponse = self.mw.process_response(request, response, self.spider)\n         assert newresponse is not response\n         assert newresponse.body.startswith(b\"<!DOCTYPE\")\n@@ -137,7 +133,7 @@ class HttpCompressionTest(TestCase):\n             raise SkipTest(\"no brotli\")\n         response = self._getresponse(\"br\")\n         request = response.request\n-        self.assertEqual(response.headers[\"Content-Encoding\"], b\"br\")\n+        assert response.headers[\"Content-Encoding\"] == b\"br\"\n         newresponse = self.mw.process_response(request, response, self.spider)\n         assert newresponse is not response\n         assert newresponse.body.startswith(b\"<!DOCTYPE\")\n@@ -159,7 +155,7 @@ class HttpCompressionTest(TestCase):\n             pass\n         response = self._getresponse(\"br\")\n         request = response.request\n-        self.assertEqual(response.headers[\"Content-Encoding\"], b\"br\")\n+        assert response.headers[\"Content-Encoding\"] == b\"br\"\n         with LogCapture(\n             \"scrapy.downloadermiddlewares.httpcompression\",\n             propagate=False,\n@@ -178,7 +174,7 @@ class HttpCompressionTest(TestCase):\n             ),\n         )\n         assert newresponse is not response\n-        self.assertEqual(newresponse.headers.getlist(\"Content-Encoding\"), [b\"br\"])\n+        assert newresponse.headers.getlist(\"Content-Encoding\") == [b\"br\"]\n \n     def test_process_response_zstd(self):\n         try:\n@@ -191,7 +187,7 @@ class HttpCompressionTest(TestCase):\n                 continue\n             response = self._getresponse(check_key)\n             request = response.request\n-            self.assertEqual(response.headers[\"Content-Encoding\"], b\"zstd\")\n+            assert response.headers[\"Content-Encoding\"] == b\"zstd\"\n             newresponse = self.mw.process_response(request, response, self.spider)\n             if raw_content is None:\n                 raw_content = newresponse.body\n@@ -210,7 +206,7 @@ class HttpCompressionTest(TestCase):\n             pass\n         response = self._getresponse(\"zstd-static-content-size\")\n         request = response.request\n-        self.assertEqual(response.headers[\"Content-Encoding\"], b\"zstd\")\n+        assert response.headers[\"Content-Encoding\"] == b\"zstd\"\n         with LogCapture(\n             \"scrapy.downloadermiddlewares.httpcompression\",\n             propagate=False,\n@@ -229,13 +225,13 @@ class HttpCompressionTest(TestCase):\n             ),\n         )\n         assert newresponse is not response\n-        self.assertEqual(newresponse.headers.getlist(\"Content-Encoding\"), [b\"zstd\"])\n+        assert newresponse.headers.getlist(\"Content-Encoding\") == [b\"zstd\"]\n \n     def test_process_response_rawdeflate(self):\n         response = self._getresponse(\"rawdeflate\")\n         request = response.request\n \n-        self.assertEqual(response.headers[\"Content-Encoding\"], b\"deflate\")\n+        assert response.headers[\"Content-Encoding\"] == b\"deflate\"\n         newresponse = self.mw.process_response(request, response, self.spider)\n         assert newresponse is not response\n         assert newresponse.body.startswith(b\"<!DOCTYPE\")\n@@ -247,7 +243,7 @@ class HttpCompressionTest(TestCase):\n         response = self._getresponse(\"zlibdeflate\")\n         request = response.request\n \n-        self.assertEqual(response.headers[\"Content-Encoding\"], b\"deflate\")\n+        assert response.headers[\"Content-Encoding\"] == b\"deflate\"\n         newresponse = self.mw.process_response(request, response, self.spider)\n         assert newresponse is not response\n         assert newresponse.body.startswith(b\"<!DOCTYPE\")\n@@ -272,7 +268,7 @@ class HttpCompressionTest(TestCase):\n         request = response.request\n         newresponse = self.mw.process_response(request, response, self.spider)\n         assert newresponse is not response\n-        self.assertEqual(newresponse.headers.getlist(\"Content-Encoding\"), [b\"uuencode\"])\n+        assert newresponse.headers.getlist(\"Content-Encoding\") == [b\"uuencode\"]\n \n     def test_multi_compression_single_header(self):\n         response = self._getresponse(\"gzip-deflate\")\n@@ -303,9 +299,7 @@ class HttpCompressionTest(TestCase):\n             ),\n         )\n         assert newresponse is not response\n-        self.assertEqual(\n-            newresponse.headers.getlist(\"Content-Encoding\"), [b\"gzip\", b\"foo\"]\n-        )\n+        assert newresponse.headers.getlist(\"Content-Encoding\") == [b\"gzip\", b\"foo\"]\n \n     def test_multi_compression_multiple_header(self):\n         response = self._getresponse(\"gzip-deflate\")\n@@ -322,9 +316,7 @@ class HttpCompressionTest(TestCase):\n         request = response.request\n         newresponse = self.mw.process_response(request, response, self.spider)\n         assert newresponse is not response\n-        self.assertEqual(\n-            newresponse.headers.getlist(\"Content-Encoding\"), [b\"gzip\", b\"foo\"]\n-        )\n+        assert newresponse.headers.getlist(\"Content-Encoding\") == [b\"gzip\", b\"foo\"]\n \n     def test_multi_compression_single_and_multiple_header(self):\n         response = self._getresponse(\"gzip-deflate-gzip\")\n@@ -341,9 +333,7 @@ class HttpCompressionTest(TestCase):\n         request = response.request\n         newresponse = self.mw.process_response(request, response, self.spider)\n         assert newresponse is not response\n-        self.assertEqual(\n-            newresponse.headers.getlist(\"Content-Encoding\"), [b\"gzip\", b\"foo\"]\n-        )\n+        assert newresponse.headers.getlist(\"Content-Encoding\") == [b\"gzip\", b\"foo\"]\n \n     def test_process_response_encoding_inside_body(self):\n         headers = {\n@@ -365,8 +355,8 @@ class HttpCompressionTest(TestCase):\n \n         newresponse = self.mw.process_response(request, response, self.spider)\n         assert isinstance(newresponse, HtmlResponse)\n-        self.assertEqual(newresponse.body, plainbody)\n-        self.assertEqual(newresponse.encoding, resolve_encoding(\"gb2312\"))\n+        assert newresponse.body == plainbody\n+        assert newresponse.encoding == resolve_encoding(\"gb2312\")\n         self.assertStatsEqual(\"httpcompression/response_count\", 1)\n         self.assertStatsEqual(\"httpcompression/response_bytes\", len(plainbody))\n \n@@ -390,8 +380,8 @@ class HttpCompressionTest(TestCase):\n \n         newresponse = self.mw.process_response(request, response, self.spider)\n         assert isinstance(newresponse, HtmlResponse)\n-        self.assertEqual(newresponse.body, plainbody)\n-        self.assertEqual(newresponse.encoding, resolve_encoding(\"gb2312\"))\n+        assert newresponse.body == plainbody\n+        assert newresponse.encoding == resolve_encoding(\"gb2312\")\n         self.assertStatsEqual(\"httpcompression/response_count\", 1)\n         self.assertStatsEqual(\"httpcompression/response_bytes\", len(plainbody))\n \n@@ -413,8 +403,8 @@ class HttpCompressionTest(TestCase):\n \n         newresponse = self.mw.process_response(request, response, self.spider)\n         assert isinstance(newresponse, respcls)\n-        self.assertEqual(newresponse.body, plainbody)\n-        self.assertEqual(newresponse.encoding, resolve_encoding(\"gb2312\"))\n+        assert newresponse.body == plainbody\n+        assert newresponse.encoding == resolve_encoding(\"gb2312\")\n         self.assertStatsEqual(\"httpcompression/response_count\", 1)\n         self.assertStatsEqual(\"httpcompression/response_bytes\", len(plainbody))\n \n@@ -424,9 +414,9 @@ class HttpCompressionTest(TestCase):\n         request = response.request\n \n         newresponse = self.mw.process_response(request, response, self.spider)\n-        self.assertIsNot(newresponse, response)\n-        self.assertTrue(newresponse.body.startswith(b\"<!DOCTYPE\"))\n-        self.assertNotIn(\"Content-Encoding\", newresponse.headers)\n+        assert newresponse is not response\n+        assert newresponse.body.startswith(b\"<!DOCTYPE\")\n+        assert \"Content-Encoding\" not in newresponse.headers\n         self.assertStatsEqual(\"httpcompression/response_count\", 1)\n         self.assertStatsEqual(\"httpcompression/response_bytes\", 74837)\n \n@@ -436,9 +426,9 @@ class HttpCompressionTest(TestCase):\n         request = response.request\n \n         newresponse = self.mw.process_response(request, response, self.spider)\n-        self.assertIsNot(newresponse, response)\n-        self.assertTrue(newresponse.body.startswith(b\"<!DOCTYPE\"))\n-        self.assertNotIn(\"Content-Encoding\", newresponse.headers)\n+        assert newresponse is not response\n+        assert newresponse.body.startswith(b\"<!DOCTYPE\")\n+        assert \"Content-Encoding\" not in newresponse.headers\n         self.assertStatsEqual(\"httpcompression/response_count\", 1)\n         self.assertStatsEqual(\"httpcompression/response_bytes\", 74837)\n \n@@ -448,9 +438,9 @@ class HttpCompressionTest(TestCase):\n         request = response.request\n \n         newresponse = self.mw.process_response(request, response, self.spider)\n-        self.assertIsNot(newresponse, response)\n-        self.assertTrue(newresponse.body.startswith(b\"<!DOCTYPE\"))\n-        self.assertNotIn(\"Content-Encoding\", newresponse.headers)\n+        assert newresponse is not response\n+        assert newresponse.body.startswith(b\"<!DOCTYPE\")\n+        assert \"Content-Encoding\" not in newresponse.headers\n         self.assertStatsEqual(\"httpcompression/response_count\", 1)\n         self.assertStatsEqual(\"httpcompression/response_bytes\", 74837)\n \n@@ -496,7 +486,7 @@ class HttpCompressionTest(TestCase):\n         request = Request(\"http://www.example.com/\")\n \n         newresponse = self.mw.process_response(request, response, self.spider)\n-        self.assertEqual(gunzip(newresponse.body), plainbody)\n+        assert gunzip(newresponse.body) == plainbody\n         self.assertStatsEqual(\"httpcompression/response_count\", 1)\n         self.assertStatsEqual(\"httpcompression/response_bytes\", 230)\n \n@@ -507,8 +497,8 @@ class HttpCompressionTest(TestCase):\n         request.method = \"HEAD\"\n         response = response.replace(body=None)\n         newresponse = self.mw.process_response(request, response, self.spider)\n-        self.assertIs(newresponse, response)\n-        self.assertEqual(response.body, b\"\")\n+        assert newresponse is response\n+        assert response.body == b\"\"\n         self.assertStatsEqual(\"httpcompression/response_count\", None)\n         self.assertStatsEqual(\"httpcompression/response_bytes\", None)\n \n\n@@ -1,7 +1,6 @@\n import os\n \n import pytest\n-from twisted.trial.unittest import TestCase\n \n from scrapy.downloadermiddlewares.httpproxy import HttpProxyMiddleware\n from scrapy.exceptions import NotConfigured\n@@ -12,13 +11,13 @@ from scrapy.utils.test import get_crawler\n spider = Spider(\"foo\")\n \n \n-class TestHttpProxyMiddleware(TestCase):\n+class TestHttpProxyMiddleware:\n     failureException = AssertionError  # type: ignore[assignment]\n \n-    def setUp(self):\n+    def setup_method(self):\n         self._oldenv = os.environ.copy()\n \n-    def tearDown(self):\n+    def teardown_method(self):\n         os.environ = self._oldenv\n \n     def test_not_enabled(self):\n@@ -33,8 +32,8 @@ class TestHttpProxyMiddleware(TestCase):\n         for url in (\"http://e.com\", \"https://e.com\", \"file:///tmp/a\"):\n             req = Request(url)\n             assert mw.process_request(req, spider) is None\n-            self.assertEqual(req.url, url)\n-            self.assertEqual(req.meta, {})\n+            assert req.url == url\n+            assert req.meta == {}\n \n     def test_environment_proxies(self):\n         os.environ[\"http_proxy\"] = http_proxy = \"https://proxy.for.http:3128\"\n@@ -49,32 +48,32 @@ class TestHttpProxyMiddleware(TestCase):\n         ]:\n             req = Request(url)\n             assert mw.process_request(req, spider) is None\n-            self.assertEqual(req.url, url)\n-            self.assertEqual(req.meta.get(\"proxy\"), proxy)\n+            assert req.url == url\n+            assert req.meta.get(\"proxy\") == proxy\n \n     def test_proxy_precedence_meta(self):\n         os.environ[\"http_proxy\"] = \"https://proxy.com\"\n         mw = HttpProxyMiddleware()\n         req = Request(\"http://scrapytest.org\", meta={\"proxy\": \"https://new.proxy:3128\"})\n         assert mw.process_request(req, spider) is None\n-        self.assertEqual(req.meta, {\"proxy\": \"https://new.proxy:3128\"})\n+        assert req.meta == {\"proxy\": \"https://new.proxy:3128\"}\n \n     def test_proxy_auth(self):\n         os.environ[\"http_proxy\"] = \"https://user:pass@proxy:3128\"\n         mw = HttpProxyMiddleware()\n         req = Request(\"http://scrapytest.org\")\n         assert mw.process_request(req, spider) is None\n-        self.assertEqual(req.meta[\"proxy\"], \"https://proxy:3128\")\n-        self.assertEqual(req.headers.get(\"Proxy-Authorization\"), b\"Basic dXNlcjpwYXNz\")\n+        assert req.meta[\"proxy\"] == \"https://proxy:3128\"\n+        assert req.headers.get(\"Proxy-Authorization\") == b\"Basic dXNlcjpwYXNz\"\n         # proxy from request.meta\n         req = Request(\n             \"http://scrapytest.org\",\n             meta={\"proxy\": \"https://username:password@proxy:3128\"},\n         )\n         assert mw.process_request(req, spider) is None\n-        self.assertEqual(req.meta[\"proxy\"], \"https://proxy:3128\")\n-        self.assertEqual(\n-            req.headers.get(\"Proxy-Authorization\"), b\"Basic dXNlcm5hbWU6cGFzc3dvcmQ=\"\n+        assert req.meta[\"proxy\"] == \"https://proxy:3128\"\n+        assert (\n+            req.headers.get(\"Proxy-Authorization\") == b\"Basic dXNlcm5hbWU6cGFzc3dvcmQ=\"\n         )\n \n     def test_proxy_auth_empty_passwd(self):\n@@ -82,15 +81,15 @@ class TestHttpProxyMiddleware(TestCase):\n         mw = HttpProxyMiddleware()\n         req = Request(\"http://scrapytest.org\")\n         assert mw.process_request(req, spider) is None\n-        self.assertEqual(req.meta[\"proxy\"], \"https://proxy:3128\")\n-        self.assertEqual(req.headers.get(\"Proxy-Authorization\"), b\"Basic dXNlcjo=\")\n+        assert req.meta[\"proxy\"] == \"https://proxy:3128\"\n+        assert req.headers.get(\"Proxy-Authorization\") == b\"Basic dXNlcjo=\"\n         # proxy from request.meta\n         req = Request(\n             \"http://scrapytest.org\", meta={\"proxy\": \"https://username:@proxy:3128\"}\n         )\n         assert mw.process_request(req, spider) is None\n-        self.assertEqual(req.meta[\"proxy\"], \"https://proxy:3128\")\n-        self.assertEqual(req.headers.get(\"Proxy-Authorization\"), b\"Basic dXNlcm5hbWU6\")\n+        assert req.meta[\"proxy\"] == \"https://proxy:3128\"\n+        assert req.headers.get(\"Proxy-Authorization\") == b\"Basic dXNlcm5hbWU6\"\n \n     def test_proxy_auth_encoding(self):\n         # utf-8 encoding\n@@ -98,33 +97,31 @@ class TestHttpProxyMiddleware(TestCase):\n         mw = HttpProxyMiddleware(auth_encoding=\"utf-8\")\n         req = Request(\"http://scrapytest.org\")\n         assert mw.process_request(req, spider) is None\n-        self.assertEqual(req.meta[\"proxy\"], \"https://proxy:3128\")\n-        self.assertEqual(req.headers.get(\"Proxy-Authorization\"), b\"Basic bcOhbjpwYXNz\")\n+        assert req.meta[\"proxy\"] == \"https://proxy:3128\"\n+        assert req.headers.get(\"Proxy-Authorization\") == b\"Basic bcOhbjpwYXNz\"\n \n         # proxy from request.meta\n         req = Request(\n             \"http://scrapytest.org\", meta={\"proxy\": \"https://\\u00fcser:pass@proxy:3128\"}\n         )\n         assert mw.process_request(req, spider) is None\n-        self.assertEqual(req.meta[\"proxy\"], \"https://proxy:3128\")\n-        self.assertEqual(\n-            req.headers.get(\"Proxy-Authorization\"), b\"Basic w7xzZXI6cGFzcw==\"\n-        )\n+        assert req.meta[\"proxy\"] == \"https://proxy:3128\"\n+        assert req.headers.get(\"Proxy-Authorization\") == b\"Basic w7xzZXI6cGFzcw==\"\n \n         # default latin-1 encoding\n         mw = HttpProxyMiddleware(auth_encoding=\"latin-1\")\n         req = Request(\"http://scrapytest.org\")\n         assert mw.process_request(req, spider) is None\n-        self.assertEqual(req.meta[\"proxy\"], \"https://proxy:3128\")\n-        self.assertEqual(req.headers.get(\"Proxy-Authorization\"), b\"Basic beFuOnBhc3M=\")\n+        assert req.meta[\"proxy\"] == \"https://proxy:3128\"\n+        assert req.headers.get(\"Proxy-Authorization\") == b\"Basic beFuOnBhc3M=\"\n \n         # proxy from request.meta, latin-1 encoding\n         req = Request(\n             \"http://scrapytest.org\", meta={\"proxy\": \"https://\\u00fcser:pass@proxy:3128\"}\n         )\n         assert mw.process_request(req, spider) is None\n-        self.assertEqual(req.meta[\"proxy\"], \"https://proxy:3128\")\n-        self.assertEqual(req.headers.get(\"Proxy-Authorization\"), b\"Basic /HNlcjpwYXNz\")\n+        assert req.meta[\"proxy\"] == \"https://proxy:3128\"\n+        assert req.headers.get(\"Proxy-Authorization\") == b\"Basic /HNlcjpwYXNz\"\n \n     def test_proxy_already_seted(self):\n         os.environ[\"http_proxy\"] = \"https://proxy.for.http:3128\"\n@@ -157,7 +154,7 @@ class TestHttpProxyMiddleware(TestCase):\n         os.environ[\"no_proxy\"] = \"*\"\n         req = Request(\"http://noproxy.com\", meta={\"proxy\": \"http://proxy.com\"})\n         assert mw.process_request(req, spider) is None\n-        self.assertEqual(req.meta, {\"proxy\": \"http://proxy.com\"})\n+        assert req.meta == {\"proxy\": \"http://proxy.com\"}\n \n     def test_no_proxy_invalid_values(self):\n         os.environ[\"no_proxy\"] = \"/var/run/docker.sock\"\n@@ -172,8 +169,8 @@ class TestHttpProxyMiddleware(TestCase):\n         assert middleware.process_request(request, spider) is None\n         request.meta[\"proxy\"] = \"https://example.com\"\n         assert middleware.process_request(request, spider) is None\n-        self.assertEqual(request.meta[\"proxy\"], \"https://example.com\")\n-        self.assertNotIn(b\"Proxy-Authorization\", request.headers)\n+        assert request.meta[\"proxy\"] == \"https://example.com\"\n+        assert b\"Proxy-Authorization\" not in request.headers\n \n     def test_add_proxy_with_credentials(self):\n         middleware = HttpProxyMiddleware()\n@@ -181,15 +178,12 @@ class TestHttpProxyMiddleware(TestCase):\n         assert middleware.process_request(request, spider) is None\n         request.meta[\"proxy\"] = \"https://user1:password1@example.com\"\n         assert middleware.process_request(request, spider) is None\n-        self.assertEqual(request.meta[\"proxy\"], \"https://example.com\")\n+        assert request.meta[\"proxy\"] == \"https://example.com\"\n         encoded_credentials = middleware._basic_auth_header(\n             \"user1\",\n             \"password1\",\n         )\n-        self.assertEqual(\n-            request.headers[\"Proxy-Authorization\"],\n-            b\"Basic \" + encoded_credentials,\n-        )\n+        assert request.headers[\"Proxy-Authorization\"] == b\"Basic \" + encoded_credentials\n \n     def test_remove_proxy_without_credentials(self):\n         middleware = HttpProxyMiddleware()\n@@ -200,8 +194,8 @@ class TestHttpProxyMiddleware(TestCase):\n         assert middleware.process_request(request, spider) is None\n         request.meta[\"proxy\"] = None\n         assert middleware.process_request(request, spider) is None\n-        self.assertIsNone(request.meta[\"proxy\"])\n-        self.assertNotIn(b\"Proxy-Authorization\", request.headers)\n+        assert request.meta[\"proxy\"] is None\n+        assert b\"Proxy-Authorization\" not in request.headers\n \n     def test_remove_proxy_with_credentials(self):\n         middleware = HttpProxyMiddleware()\n@@ -212,8 +206,8 @@ class TestHttpProxyMiddleware(TestCase):\n         assert middleware.process_request(request, spider) is None\n         request.meta[\"proxy\"] = None\n         assert middleware.process_request(request, spider) is None\n-        self.assertIsNone(request.meta[\"proxy\"])\n-        self.assertNotIn(b\"Proxy-Authorization\", request.headers)\n+        assert request.meta[\"proxy\"] is None\n+        assert b\"Proxy-Authorization\" not in request.headers\n \n     def test_add_credentials(self):\n         \"\"\"If the proxy request meta switches to a proxy URL with the same\n@@ -228,15 +222,12 @@ class TestHttpProxyMiddleware(TestCase):\n \n         request.meta[\"proxy\"] = \"https://user1:password1@example.com\"\n         assert middleware.process_request(request, spider) is None\n-        self.assertEqual(request.meta[\"proxy\"], \"https://example.com\")\n+        assert request.meta[\"proxy\"] == \"https://example.com\"\n         encoded_credentials = middleware._basic_auth_header(\n             \"user1\",\n             \"password1\",\n         )\n-        self.assertEqual(\n-            request.headers[\"Proxy-Authorization\"],\n-            b\"Basic \" + encoded_credentials,\n-        )\n+        assert request.headers[\"Proxy-Authorization\"] == b\"Basic \" + encoded_credentials\n \n     def test_change_credentials(self):\n         \"\"\"If the proxy request meta switches to a proxy URL with different\n@@ -249,15 +240,12 @@ class TestHttpProxyMiddleware(TestCase):\n         assert middleware.process_request(request, spider) is None\n         request.meta[\"proxy\"] = \"https://user2:password2@example.com\"\n         assert middleware.process_request(request, spider) is None\n-        self.assertEqual(request.meta[\"proxy\"], \"https://example.com\")\n+        assert request.meta[\"proxy\"] == \"https://example.com\"\n         encoded_credentials = middleware._basic_auth_header(\n             \"user2\",\n             \"password2\",\n         )\n-        self.assertEqual(\n-            request.headers[\"Proxy-Authorization\"],\n-            b\"Basic \" + encoded_credentials,\n-        )\n+        assert request.headers[\"Proxy-Authorization\"] == b\"Basic \" + encoded_credentials\n \n     def test_remove_credentials(self):\n         \"\"\"If the proxy request meta switches to a proxy URL with the same\n@@ -276,21 +264,18 @@ class TestHttpProxyMiddleware(TestCase):\n \n         request.meta[\"proxy\"] = \"https://example.com\"\n         assert middleware.process_request(request, spider) is None\n-        self.assertEqual(request.meta[\"proxy\"], \"https://example.com\")\n+        assert request.meta[\"proxy\"] == \"https://example.com\"\n         encoded_credentials = middleware._basic_auth_header(\n             \"user1\",\n             \"password1\",\n         )\n-        self.assertEqual(\n-            request.headers[\"Proxy-Authorization\"],\n-            b\"Basic \" + encoded_credentials,\n-        )\n+        assert request.headers[\"Proxy-Authorization\"] == b\"Basic \" + encoded_credentials\n \n         request.meta[\"proxy\"] = \"https://example.com\"\n         del request.headers[b\"Proxy-Authorization\"]\n         assert middleware.process_request(request, spider) is None\n-        self.assertEqual(request.meta[\"proxy\"], \"https://example.com\")\n-        self.assertNotIn(b\"Proxy-Authorization\", request.headers)\n+        assert request.meta[\"proxy\"] == \"https://example.com\"\n+        assert b\"Proxy-Authorization\" not in request.headers\n \n     def test_change_proxy_add_credentials(self):\n         middleware = HttpProxyMiddleware()\n@@ -302,15 +287,12 @@ class TestHttpProxyMiddleware(TestCase):\n \n         request.meta[\"proxy\"] = \"https://user1:password1@example.org\"\n         assert middleware.process_request(request, spider) is None\n-        self.assertEqual(request.meta[\"proxy\"], \"https://example.org\")\n+        assert request.meta[\"proxy\"] == \"https://example.org\"\n         encoded_credentials = middleware._basic_auth_header(\n             \"user1\",\n             \"password1\",\n         )\n-        self.assertEqual(\n-            request.headers[\"Proxy-Authorization\"],\n-            b\"Basic \" + encoded_credentials,\n-        )\n+        assert request.headers[\"Proxy-Authorization\"] == b\"Basic \" + encoded_credentials\n \n     def test_change_proxy_keep_credentials(self):\n         middleware = HttpProxyMiddleware()\n@@ -322,21 +304,18 @@ class TestHttpProxyMiddleware(TestCase):\n \n         request.meta[\"proxy\"] = \"https://user1:password1@example.org\"\n         assert middleware.process_request(request, spider) is None\n-        self.assertEqual(request.meta[\"proxy\"], \"https://example.org\")\n+        assert request.meta[\"proxy\"] == \"https://example.org\"\n         encoded_credentials = middleware._basic_auth_header(\n             \"user1\",\n             \"password1\",\n         )\n-        self.assertEqual(\n-            request.headers[\"Proxy-Authorization\"],\n-            b\"Basic \" + encoded_credentials,\n-        )\n+        assert request.headers[\"Proxy-Authorization\"] == b\"Basic \" + encoded_credentials\n \n         # Make sure, indirectly, that _auth_proxy is updated.\n         request.meta[\"proxy\"] = \"https://example.com\"\n         assert middleware.process_request(request, spider) is None\n-        self.assertEqual(request.meta[\"proxy\"], \"https://example.com\")\n-        self.assertNotIn(b\"Proxy-Authorization\", request.headers)\n+        assert request.meta[\"proxy\"] == \"https://example.com\"\n+        assert b\"Proxy-Authorization\" not in request.headers\n \n     def test_change_proxy_change_credentials(self):\n         middleware = HttpProxyMiddleware()\n@@ -348,15 +327,12 @@ class TestHttpProxyMiddleware(TestCase):\n \n         request.meta[\"proxy\"] = \"https://user2:password2@example.org\"\n         assert middleware.process_request(request, spider) is None\n-        self.assertEqual(request.meta[\"proxy\"], \"https://example.org\")\n+        assert request.meta[\"proxy\"] == \"https://example.org\"\n         encoded_credentials = middleware._basic_auth_header(\n             \"user2\",\n             \"password2\",\n         )\n-        self.assertEqual(\n-            request.headers[\"Proxy-Authorization\"],\n-            b\"Basic \" + encoded_credentials,\n-        )\n+        assert request.headers[\"Proxy-Authorization\"] == b\"Basic \" + encoded_credentials\n \n     def test_change_proxy_remove_credentials(self):\n         \"\"\"If the proxy request meta switches to a proxy URL with a different\n@@ -369,8 +345,8 @@ class TestHttpProxyMiddleware(TestCase):\n         assert middleware.process_request(request, spider) is None\n         request.meta[\"proxy\"] = \"https://example.org\"\n         assert middleware.process_request(request, spider) is None\n-        self.assertEqual(request.meta, {\"proxy\": \"https://example.org\"})\n-        self.assertNotIn(b\"Proxy-Authorization\", request.headers)\n+        assert request.meta == {\"proxy\": \"https://example.org\"}\n+        assert b\"Proxy-Authorization\" not in request.headers\n \n     def test_change_proxy_remove_credentials_preremoved_header(self):\n         \"\"\"Corner case of proxy switch with credentials removal where the\n@@ -388,8 +364,8 @@ class TestHttpProxyMiddleware(TestCase):\n         request.meta[\"proxy\"] = \"https://example.org\"\n         del request.headers[b\"Proxy-Authorization\"]\n         assert middleware.process_request(request, spider) is None\n-        self.assertEqual(request.meta, {\"proxy\": \"https://example.org\"})\n-        self.assertNotIn(b\"Proxy-Authorization\", request.headers)\n+        assert request.meta == {\"proxy\": \"https://example.org\"}\n+        assert b\"Proxy-Authorization\" not in request.headers\n \n     def test_proxy_authentication_header_undefined_proxy(self):\n         middleware = HttpProxyMiddleware()\n@@ -398,8 +374,8 @@ class TestHttpProxyMiddleware(TestCase):\n             headers={\"Proxy-Authorization\": \"Basic foo\"},\n         )\n         assert middleware.process_request(request, spider) is None\n-        self.assertNotIn(\"proxy\", request.meta)\n-        self.assertNotIn(b\"Proxy-Authorization\", request.headers)\n+        assert \"proxy\" not in request.meta\n+        assert b\"Proxy-Authorization\" not in request.headers\n \n     def test_proxy_authentication_header_disabled_proxy(self):\n         middleware = HttpProxyMiddleware()\n@@ -409,8 +385,8 @@ class TestHttpProxyMiddleware(TestCase):\n             meta={\"proxy\": None},\n         )\n         assert middleware.process_request(request, spider) is None\n-        self.assertIsNone(request.meta[\"proxy\"])\n-        self.assertNotIn(b\"Proxy-Authorization\", request.headers)\n+        assert request.meta[\"proxy\"] is None\n+        assert b\"Proxy-Authorization\" not in request.headers\n \n     def test_proxy_authentication_header_proxy_without_credentials(self):\n         \"\"\"As long as the proxy URL in request metadata remains the same, the\n@@ -423,17 +399,17 @@ class TestHttpProxyMiddleware(TestCase):\n             meta={\"proxy\": \"https://example.com\"},\n         )\n         assert middleware.process_request(request, spider) is None\n-        self.assertEqual(request.meta[\"proxy\"], \"https://example.com\")\n-        self.assertEqual(request.headers[\"Proxy-Authorization\"], b\"Basic foo\")\n+        assert request.meta[\"proxy\"] == \"https://example.com\"\n+        assert request.headers[\"Proxy-Authorization\"] == b\"Basic foo\"\n \n         assert middleware.process_request(request, spider) is None\n-        self.assertEqual(request.meta[\"proxy\"], \"https://example.com\")\n-        self.assertEqual(request.headers[\"Proxy-Authorization\"], b\"Basic foo\")\n+        assert request.meta[\"proxy\"] == \"https://example.com\"\n+        assert request.headers[\"Proxy-Authorization\"] == b\"Basic foo\"\n \n         request.headers[\"Proxy-Authorization\"] = b\"Basic bar\"\n         assert middleware.process_request(request, spider) is None\n-        self.assertEqual(request.meta[\"proxy\"], \"https://example.com\")\n-        self.assertEqual(request.headers[\"Proxy-Authorization\"], b\"Basic bar\")\n+        assert request.meta[\"proxy\"] == \"https://example.com\"\n+        assert request.headers[\"Proxy-Authorization\"] == b\"Basic bar\"\n \n     def test_proxy_authentication_header_proxy_with_same_credentials(self):\n         middleware = HttpProxyMiddleware()\n@@ -447,11 +423,8 @@ class TestHttpProxyMiddleware(TestCase):\n             meta={\"proxy\": \"https://user1:password1@example.com\"},\n         )\n         assert middleware.process_request(request, spider) is None\n-        self.assertEqual(request.meta[\"proxy\"], \"https://example.com\")\n-        self.assertEqual(\n-            request.headers[\"Proxy-Authorization\"],\n-            b\"Basic \" + encoded_credentials,\n-        )\n+        assert request.meta[\"proxy\"] == \"https://example.com\"\n+        assert request.headers[\"Proxy-Authorization\"] == b\"Basic \" + encoded_credentials\n \n     def test_proxy_authentication_header_proxy_with_different_credentials(self):\n         middleware = HttpProxyMiddleware()\n@@ -465,12 +438,11 @@ class TestHttpProxyMiddleware(TestCase):\n             meta={\"proxy\": \"https://user2:password2@example.com\"},\n         )\n         assert middleware.process_request(request, spider) is None\n-        self.assertEqual(request.meta[\"proxy\"], \"https://example.com\")\n+        assert request.meta[\"proxy\"] == \"https://example.com\"\n         encoded_credentials2 = middleware._basic_auth_header(\n             \"user2\",\n             \"password2\",\n         )\n-        self.assertEqual(\n-            request.headers[\"Proxy-Authorization\"],\n-            b\"Basic \" + encoded_credentials2,\n+        assert (\n+            request.headers[\"Proxy-Authorization\"] == b\"Basic \" + encoded_credentials2\n         )\n\n@@ -1,4 +1,3 @@\n-import unittest\n from itertools import chain, product\n \n import pytest\n@@ -16,12 +15,12 @@ from scrapy.utils.test import get_crawler\n \n \n class Base:\n-    class Test(unittest.TestCase):\n+    class Test:\n         def test_priority_adjust(self):\n             req = Request(\"http://a.com\")\n             rsp = self.get_response(req, \"http://a.com/redirected\")\n             req2 = self.mw.process_response(req, rsp, self.spider)\n-            self.assertGreater(req2.priority, req.priority)\n+            assert req2.priority > req.priority\n \n         def test_dont_redirect(self):\n             url = \"http://www.example.com/301\"\n@@ -53,8 +52,8 @@ class Base:\n \n             req2 = self.mw.process_response(req, rsp, self.spider)\n             assert isinstance(req2, Request)\n-            self.assertEqual(req2.url, url2)\n-            self.assertEqual(req2.method, \"GET\")\n+            assert req2.url == url2\n+            assert req2.method == \"GET\"\n             assert \"Content-Type\" not in req2.headers, (\n                 \"Content-Type header must not be present in redirected request\"\n             )\n@@ -71,7 +70,7 @@ class Base:\n             req = self.mw.process_response(req, rsp, self.spider)\n             assert isinstance(req, Request)\n             assert \"redirect_times\" in req.meta\n-            self.assertEqual(req.meta[\"redirect_times\"], 1)\n+            assert req.meta[\"redirect_times\"] == 1\n             with pytest.raises(IgnoreRequest):\n                 self.mw.process_response(req, rsp, self.spider)\n \n@@ -92,15 +91,13 @@ class Base:\n             rsp2 = self.get_response(req1, \"/redirected2\")\n             req3 = self.mw.process_response(req2, rsp2, self.spider)\n \n-            self.assertEqual(req2.url, \"http://scrapytest.org/redirected\")\n-            self.assertEqual(\n-                req2.meta[\"redirect_urls\"], [\"http://scrapytest.org/first\"]\n-            )\n-            self.assertEqual(req3.url, \"http://scrapytest.org/redirected2\")\n-            self.assertEqual(\n-                req3.meta[\"redirect_urls\"],\n-                [\"http://scrapytest.org/first\", \"http://scrapytest.org/redirected\"],\n-            )\n+            assert req2.url == \"http://scrapytest.org/redirected\"\n+            assert req2.meta[\"redirect_urls\"] == [\"http://scrapytest.org/first\"]\n+            assert req3.url == \"http://scrapytest.org/redirected2\"\n+            assert req3.meta[\"redirect_urls\"] == [\n+                \"http://scrapytest.org/first\",\n+                \"http://scrapytest.org/redirected\",\n+            ]\n \n         def test_redirect_reasons(self):\n             req1 = Request(\"http://scrapytest.org/first\")\n@@ -108,8 +105,8 @@ class Base:\n             req2 = self.mw.process_response(req1, rsp1, self.spider)\n             rsp2 = self.get_response(req2, \"/redirected2\")\n             req3 = self.mw.process_response(req2, rsp2, self.spider)\n-            self.assertEqual(req2.meta[\"redirect_reasons\"], [self.reason])\n-            self.assertEqual(req3.meta[\"redirect_reasons\"], [self.reason, self.reason])\n+            assert req2.meta[\"redirect_reasons\"] == [self.reason]\n+            assert req3.meta[\"redirect_reasons\"] == [self.reason, self.reason]\n \n         def test_cross_origin_header_dropping(self):\n             safe_headers = {\"A\": \"B\"}\n@@ -129,10 +126,8 @@ class Base:\n             internal_redirect_request = self.mw.process_response(\n                 original_request, internal_response, self.spider\n             )\n-            self.assertIsInstance(internal_redirect_request, Request)\n-            self.assertEqual(\n-                original_request.headers, internal_redirect_request.headers\n-            )\n+            assert isinstance(internal_redirect_request, Request)\n+            assert original_request.headers == internal_redirect_request.headers\n \n             # Redirects to the same origin (same scheme, same domain, same port)\n             # keep all headers also when the scheme is http.\n@@ -144,8 +139,8 @@ class Base:\n             http_redirect_request = self.mw.process_response(\n                 http_request, http_response, self.spider\n             )\n-            self.assertIsInstance(http_redirect_request, Request)\n-            self.assertEqual(http_request.headers, http_redirect_request.headers)\n+            assert isinstance(http_redirect_request, Request)\n+            assert http_request.headers == http_redirect_request.headers\n \n             # For default ports, whether the port is explicit or implicit does not\n             # affect the outcome, it is still the same origin.\n@@ -155,10 +150,8 @@ class Base:\n             to_explicit_port_redirect_request = self.mw.process_response(\n                 original_request, to_explicit_port_response, self.spider\n             )\n-            self.assertIsInstance(to_explicit_port_redirect_request, Request)\n-            self.assertEqual(\n-                original_request.headers, to_explicit_port_redirect_request.headers\n-            )\n+            assert isinstance(to_explicit_port_redirect_request, Request)\n+            assert original_request.headers == to_explicit_port_redirect_request.headers\n \n             # For default ports, whether the port is explicit or implicit does not\n             # affect the outcome, it is still the same origin.\n@@ -168,10 +161,8 @@ class Base:\n             to_implicit_port_redirect_request = self.mw.process_response(\n                 original_request, to_implicit_port_response, self.spider\n             )\n-            self.assertIsInstance(to_implicit_port_redirect_request, Request)\n-            self.assertEqual(\n-                original_request.headers, to_implicit_port_redirect_request.headers\n-            )\n+            assert isinstance(to_implicit_port_redirect_request, Request)\n+            assert original_request.headers == to_implicit_port_redirect_request.headers\n \n             # A port change drops the Authorization header because the origin\n             # changes, but keeps the Cookie header because the domain remains the\n@@ -182,11 +173,11 @@ class Base:\n             different_port_redirect_request = self.mw.process_response(\n                 original_request, different_port_response, self.spider\n             )\n-            self.assertIsInstance(different_port_redirect_request, Request)\n-            self.assertEqual(\n-                {**safe_headers, **cookie_header},\n-                different_port_redirect_request.headers.to_unicode_dict(),\n-            )\n+            assert isinstance(different_port_redirect_request, Request)\n+            assert {\n+                **safe_headers,\n+                **cookie_header,\n+            } == different_port_redirect_request.headers.to_unicode_dict()\n \n             # A domain change drops both the Authorization and the Cookie header.\n             external_response = self.get_response(\n@@ -195,10 +186,8 @@ class Base:\n             external_redirect_request = self.mw.process_response(\n                 original_request, external_response, self.spider\n             )\n-            self.assertIsInstance(external_redirect_request, Request)\n-            self.assertEqual(\n-                safe_headers, external_redirect_request.headers.to_unicode_dict()\n-            )\n+            assert isinstance(external_redirect_request, Request)\n+            assert safe_headers == external_redirect_request.headers.to_unicode_dict()\n \n             # A scheme upgrade (http → https) drops the Authorization header\n             # because the origin changes, but keeps the Cookie header because the\n@@ -207,11 +196,11 @@ class Base:\n             upgrade_redirect_request = self.mw.process_response(\n                 http_request, upgrade_response, self.spider\n             )\n-            self.assertIsInstance(upgrade_redirect_request, Request)\n-            self.assertEqual(\n-                {**safe_headers, **cookie_header},\n-                upgrade_redirect_request.headers.to_unicode_dict(),\n-            )\n+            assert isinstance(upgrade_redirect_request, Request)\n+            assert {\n+                **safe_headers,\n+                **cookie_header,\n+            } == upgrade_redirect_request.headers.to_unicode_dict()\n \n             # A scheme downgrade (https → http) drops the Authorization header\n             # because the origin changes, and the Cookie header because its value\n@@ -228,11 +217,8 @@ class Base:\n             downgrade_redirect_request = self.mw.process_response(\n                 original_request, downgrade_response, self.spider\n             )\n-            self.assertIsInstance(downgrade_redirect_request, Request)\n-            self.assertEqual(\n-                safe_headers,\n-                downgrade_redirect_request.headers.to_unicode_dict(),\n-            )\n+            assert isinstance(downgrade_redirect_request, Request)\n+            assert safe_headers == downgrade_redirect_request.headers.to_unicode_dict()\n \n         def test_meta_proxy_http_absolute(self):\n             crawler = get_crawler()\n@@ -244,37 +230,37 @@ class Base:\n             spider = None\n             proxy_mw.process_request(request1, spider)\n \n-            self.assertEqual(request1.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request1.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request1.meta[\"proxy\"], \"https://a.example\")\n+            assert request1.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request1.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request1.meta[\"proxy\"] == \"https://a.example\"\n \n             response1 = self.get_response(request1, \"http://example.com\")\n             request2 = redirect_mw.process_response(request1, response1, spider)\n \n-            self.assertIsInstance(request2, Request)\n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request2, Request)\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request2, spider)\n \n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             response2 = self.get_response(request2, \"http://example.com\")\n             request3 = redirect_mw.process_response(request2, response2, spider)\n \n-            self.assertIsInstance(request3, Request)\n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request3, Request)\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request3, spider)\n \n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n         def test_meta_proxy_http_relative(self):\n             crawler = get_crawler()\n@@ -286,37 +272,37 @@ class Base:\n             spider = None\n             proxy_mw.process_request(request1, spider)\n \n-            self.assertEqual(request1.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request1.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request1.meta[\"proxy\"], \"https://a.example\")\n+            assert request1.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request1.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request1.meta[\"proxy\"] == \"https://a.example\"\n \n             response1 = self.get_response(request1, \"/a\")\n             request2 = redirect_mw.process_response(request1, response1, spider)\n \n-            self.assertIsInstance(request2, Request)\n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request2, Request)\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request2, spider)\n \n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             response2 = self.get_response(request2, \"/a\")\n             request3 = redirect_mw.process_response(request2, response2, spider)\n \n-            self.assertIsInstance(request3, Request)\n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request3, Request)\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request3, spider)\n \n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n         def test_meta_proxy_https_absolute(self):\n             crawler = get_crawler()\n@@ -328,37 +314,37 @@ class Base:\n             spider = None\n             proxy_mw.process_request(request1, spider)\n \n-            self.assertEqual(request1.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request1.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request1.meta[\"proxy\"], \"https://a.example\")\n+            assert request1.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request1.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request1.meta[\"proxy\"] == \"https://a.example\"\n \n             response1 = self.get_response(request1, \"https://example.com\")\n             request2 = redirect_mw.process_response(request1, response1, spider)\n \n-            self.assertIsInstance(request2, Request)\n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request2, Request)\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request2, spider)\n \n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             response2 = self.get_response(request2, \"https://example.com\")\n             request3 = redirect_mw.process_response(request2, response2, spider)\n \n-            self.assertIsInstance(request3, Request)\n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request3, Request)\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request3, spider)\n \n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n         def test_meta_proxy_https_relative(self):\n             crawler = get_crawler()\n@@ -370,37 +356,37 @@ class Base:\n             spider = None\n             proxy_mw.process_request(request1, spider)\n \n-            self.assertEqual(request1.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request1.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request1.meta[\"proxy\"], \"https://a.example\")\n+            assert request1.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request1.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request1.meta[\"proxy\"] == \"https://a.example\"\n \n             response1 = self.get_response(request1, \"/a\")\n             request2 = redirect_mw.process_response(request1, response1, spider)\n \n-            self.assertIsInstance(request2, Request)\n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request2, Request)\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request2, spider)\n \n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             response2 = self.get_response(request2, \"/a\")\n             request3 = redirect_mw.process_response(request2, response2, spider)\n \n-            self.assertIsInstance(request3, Request)\n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request3, Request)\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request3, spider)\n \n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n         def test_meta_proxy_http_to_https(self):\n             crawler = get_crawler()\n@@ -412,37 +398,37 @@ class Base:\n             spider = None\n             proxy_mw.process_request(request1, spider)\n \n-            self.assertEqual(request1.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request1.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request1.meta[\"proxy\"], \"https://a.example\")\n+            assert request1.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request1.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request1.meta[\"proxy\"] == \"https://a.example\"\n \n             response1 = self.get_response(request1, \"https://example.com\")\n             request2 = redirect_mw.process_response(request1, response1, spider)\n \n-            self.assertIsInstance(request2, Request)\n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request2, Request)\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request2, spider)\n \n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             response2 = self.get_response(request2, \"http://example.com\")\n             request3 = redirect_mw.process_response(request2, response2, spider)\n \n-            self.assertIsInstance(request3, Request)\n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request3, Request)\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request3, spider)\n \n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n         def test_meta_proxy_https_to_http(self):\n             crawler = get_crawler()\n@@ -454,37 +440,37 @@ class Base:\n             spider = None\n             proxy_mw.process_request(request1, spider)\n \n-            self.assertEqual(request1.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request1.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request1.meta[\"proxy\"], \"https://a.example\")\n+            assert request1.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request1.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request1.meta[\"proxy\"] == \"https://a.example\"\n \n             response1 = self.get_response(request1, \"http://example.com\")\n             request2 = redirect_mw.process_response(request1, response1, spider)\n \n-            self.assertIsInstance(request2, Request)\n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request2, Request)\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request2, spider)\n \n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             response2 = self.get_response(request2, \"https://example.com\")\n             request3 = redirect_mw.process_response(request2, response2, spider)\n \n-            self.assertIsInstance(request3, Request)\n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request3, Request)\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request3, spider)\n \n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n         def test_system_proxy_http_absolute(self):\n             crawler = get_crawler()\n@@ -499,37 +485,37 @@ class Base:\n             spider = None\n             proxy_mw.process_request(request1, spider)\n \n-            self.assertEqual(request1.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request1.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request1.meta[\"proxy\"], \"https://a.example\")\n+            assert request1.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request1.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request1.meta[\"proxy\"] == \"https://a.example\"\n \n             response1 = self.get_response(request1, \"http://example.com\")\n             request2 = redirect_mw.process_response(request1, response1, spider)\n \n-            self.assertIsInstance(request2, Request)\n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request2, Request)\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request2, spider)\n \n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             response2 = self.get_response(request2, \"http://example.com\")\n             request3 = redirect_mw.process_response(request2, response2, spider)\n \n-            self.assertIsInstance(request3, Request)\n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request3, Request)\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request3, spider)\n \n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n         def test_system_proxy_http_relative(self):\n             crawler = get_crawler()\n@@ -544,37 +530,37 @@ class Base:\n             spider = None\n             proxy_mw.process_request(request1, spider)\n \n-            self.assertEqual(request1.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request1.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request1.meta[\"proxy\"], \"https://a.example\")\n+            assert request1.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request1.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request1.meta[\"proxy\"] == \"https://a.example\"\n \n             response1 = self.get_response(request1, \"/a\")\n             request2 = redirect_mw.process_response(request1, response1, spider)\n \n-            self.assertIsInstance(request2, Request)\n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request2, Request)\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request2, spider)\n \n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             response2 = self.get_response(request2, \"/a\")\n             request3 = redirect_mw.process_response(request2, response2, spider)\n \n-            self.assertIsInstance(request3, Request)\n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request3, Request)\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request3, spider)\n \n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n         def test_system_proxy_https_absolute(self):\n             crawler = get_crawler()\n@@ -589,37 +575,37 @@ class Base:\n             spider = None\n             proxy_mw.process_request(request1, spider)\n \n-            self.assertEqual(request1.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request1.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request1.meta[\"proxy\"], \"https://a.example\")\n+            assert request1.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request1.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request1.meta[\"proxy\"] == \"https://a.example\"\n \n             response1 = self.get_response(request1, \"https://example.com\")\n             request2 = redirect_mw.process_response(request1, response1, spider)\n \n-            self.assertIsInstance(request2, Request)\n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request2, Request)\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request2, spider)\n \n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             response2 = self.get_response(request2, \"https://example.com\")\n             request3 = redirect_mw.process_response(request2, response2, spider)\n \n-            self.assertIsInstance(request3, Request)\n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request3, Request)\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request3, spider)\n \n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n         def test_system_proxy_https_relative(self):\n             crawler = get_crawler()\n@@ -634,37 +620,37 @@ class Base:\n             spider = None\n             proxy_mw.process_request(request1, spider)\n \n-            self.assertEqual(request1.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request1.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request1.meta[\"proxy\"], \"https://a.example\")\n+            assert request1.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request1.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request1.meta[\"proxy\"] == \"https://a.example\"\n \n             response1 = self.get_response(request1, \"/a\")\n             request2 = redirect_mw.process_response(request1, response1, spider)\n \n-            self.assertIsInstance(request2, Request)\n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request2, Request)\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request2, spider)\n \n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             response2 = self.get_response(request2, \"/a\")\n             request3 = redirect_mw.process_response(request2, response2, spider)\n \n-            self.assertIsInstance(request3, Request)\n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert isinstance(request3, Request)\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n             proxy_mw.process_request(request3, spider)\n \n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n         def test_system_proxy_proxied_http_to_proxied_https(self):\n             crawler = get_crawler()\n@@ -680,37 +666,37 @@ class Base:\n             spider = None\n             proxy_mw.process_request(request1, spider)\n \n-            self.assertEqual(request1.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request1.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request1.meta[\"proxy\"], \"https://a.example\")\n+            assert request1.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request1.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request1.meta[\"proxy\"] == \"https://a.example\"\n \n             response1 = self.get_response(request1, \"https://example.com\")\n             request2 = redirect_mw.process_response(request1, response1, spider)\n \n-            self.assertIsInstance(request2, Request)\n-            self.assertNotIn(\"Proxy-Authorization\", request2.headers)\n-            self.assertNotIn(\"_auth_proxy\", request2.meta)\n-            self.assertNotIn(\"proxy\", request2.meta)\n+            assert isinstance(request2, Request)\n+            assert \"Proxy-Authorization\" not in request2.headers\n+            assert \"_auth_proxy\" not in request2.meta\n+            assert \"proxy\" not in request2.meta\n \n             proxy_mw.process_request(request2, spider)\n \n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic Yjo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://b.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://b.example\")\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic Yjo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://b.example\"\n+            assert request2.meta[\"proxy\"] == \"https://b.example\"\n \n             response2 = self.get_response(request2, \"http://example.com\")\n             request3 = redirect_mw.process_response(request2, response2, spider)\n \n-            self.assertIsInstance(request3, Request)\n-            self.assertNotIn(\"Proxy-Authorization\", request3.headers)\n-            self.assertNotIn(\"_auth_proxy\", request3.meta)\n-            self.assertNotIn(\"proxy\", request3.meta)\n+            assert isinstance(request3, Request)\n+            assert \"Proxy-Authorization\" not in request3.headers\n+            assert \"_auth_proxy\" not in request3.meta\n+            assert \"proxy\" not in request3.meta\n \n             proxy_mw.process_request(request3, spider)\n \n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n         def test_system_proxy_proxied_http_to_unproxied_https(self):\n             crawler = get_crawler()\n@@ -725,37 +711,37 @@ class Base:\n             spider = None\n             proxy_mw.process_request(request1, spider)\n \n-            self.assertEqual(request1.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request1.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request1.meta[\"proxy\"], \"https://a.example\")\n+            assert request1.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request1.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request1.meta[\"proxy\"] == \"https://a.example\"\n \n             response1 = self.get_response(request1, \"https://example.com\")\n             request2 = redirect_mw.process_response(request1, response1, spider)\n \n-            self.assertIsInstance(request2, Request)\n-            self.assertNotIn(\"Proxy-Authorization\", request2.headers)\n-            self.assertNotIn(\"_auth_proxy\", request2.meta)\n-            self.assertNotIn(\"proxy\", request2.meta)\n+            assert isinstance(request2, Request)\n+            assert \"Proxy-Authorization\" not in request2.headers\n+            assert \"_auth_proxy\" not in request2.meta\n+            assert \"proxy\" not in request2.meta\n \n             proxy_mw.process_request(request2, spider)\n \n-            self.assertNotIn(\"Proxy-Authorization\", request2.headers)\n-            self.assertNotIn(\"_auth_proxy\", request2.meta)\n-            self.assertNotIn(\"proxy\", request2.meta)\n+            assert \"Proxy-Authorization\" not in request2.headers\n+            assert \"_auth_proxy\" not in request2.meta\n+            assert \"proxy\" not in request2.meta\n \n             response2 = self.get_response(request2, \"http://example.com\")\n             request3 = redirect_mw.process_response(request2, response2, spider)\n \n-            self.assertIsInstance(request3, Request)\n-            self.assertNotIn(\"Proxy-Authorization\", request3.headers)\n-            self.assertNotIn(\"_auth_proxy\", request3.meta)\n-            self.assertNotIn(\"proxy\", request3.meta)\n+            assert isinstance(request3, Request)\n+            assert \"Proxy-Authorization\" not in request3.headers\n+            assert \"_auth_proxy\" not in request3.meta\n+            assert \"proxy\" not in request3.meta\n \n             proxy_mw.process_request(request3, spider)\n \n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://a.example\")\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request3.meta[\"proxy\"] == \"https://a.example\"\n \n         def test_system_proxy_unproxied_http_to_proxied_https(self):\n             crawler = get_crawler()\n@@ -770,37 +756,37 @@ class Base:\n             spider = None\n             proxy_mw.process_request(request1, spider)\n \n-            self.assertNotIn(\"Proxy-Authorization\", request1.headers)\n-            self.assertNotIn(\"_auth_proxy\", request1.meta)\n-            self.assertNotIn(\"proxy\", request1.meta)\n+            assert \"Proxy-Authorization\" not in request1.headers\n+            assert \"_auth_proxy\" not in request1.meta\n+            assert \"proxy\" not in request1.meta\n \n             response1 = self.get_response(request1, \"https://example.com\")\n             request2 = redirect_mw.process_response(request1, response1, spider)\n \n-            self.assertIsInstance(request2, Request)\n-            self.assertNotIn(\"Proxy-Authorization\", request2.headers)\n-            self.assertNotIn(\"_auth_proxy\", request2.meta)\n-            self.assertNotIn(\"proxy\", request2.meta)\n+            assert isinstance(request2, Request)\n+            assert \"Proxy-Authorization\" not in request2.headers\n+            assert \"_auth_proxy\" not in request2.meta\n+            assert \"proxy\" not in request2.meta\n \n             proxy_mw.process_request(request2, spider)\n \n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic Yjo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://b.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://b.example\")\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic Yjo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://b.example\"\n+            assert request2.meta[\"proxy\"] == \"https://b.example\"\n \n             response2 = self.get_response(request2, \"http://example.com\")\n             request3 = redirect_mw.process_response(request2, response2, spider)\n \n-            self.assertIsInstance(request3, Request)\n-            self.assertNotIn(\"Proxy-Authorization\", request3.headers)\n-            self.assertNotIn(\"_auth_proxy\", request3.meta)\n-            self.assertNotIn(\"proxy\", request3.meta)\n+            assert isinstance(request3, Request)\n+            assert \"Proxy-Authorization\" not in request3.headers\n+            assert \"_auth_proxy\" not in request3.meta\n+            assert \"proxy\" not in request3.meta\n \n             proxy_mw.process_request(request3, spider)\n \n-            self.assertNotIn(\"Proxy-Authorization\", request3.headers)\n-            self.assertNotIn(\"_auth_proxy\", request3.meta)\n-            self.assertNotIn(\"proxy\", request3.meta)\n+            assert \"Proxy-Authorization\" not in request3.headers\n+            assert \"_auth_proxy\" not in request3.meta\n+            assert \"proxy\" not in request3.meta\n \n         def test_system_proxy_unproxied_http_to_unproxied_https(self):\n             crawler = get_crawler()\n@@ -811,37 +797,37 @@ class Base:\n             spider = None\n             proxy_mw.process_request(request1, spider)\n \n-            self.assertNotIn(\"Proxy-Authorization\", request1.headers)\n-            self.assertNotIn(\"_auth_proxy\", request1.meta)\n-            self.assertNotIn(\"proxy\", request1.meta)\n+            assert \"Proxy-Authorization\" not in request1.headers\n+            assert \"_auth_proxy\" not in request1.meta\n+            assert \"proxy\" not in request1.meta\n \n             response1 = self.get_response(request1, \"https://example.com\")\n             request2 = redirect_mw.process_response(request1, response1, spider)\n \n-            self.assertIsInstance(request2, Request)\n-            self.assertNotIn(\"Proxy-Authorization\", request2.headers)\n-            self.assertNotIn(\"_auth_proxy\", request2.meta)\n-            self.assertNotIn(\"proxy\", request2.meta)\n+            assert isinstance(request2, Request)\n+            assert \"Proxy-Authorization\" not in request2.headers\n+            assert \"_auth_proxy\" not in request2.meta\n+            assert \"proxy\" not in request2.meta\n \n             proxy_mw.process_request(request2, spider)\n \n-            self.assertNotIn(\"Proxy-Authorization\", request2.headers)\n-            self.assertNotIn(\"_auth_proxy\", request2.meta)\n-            self.assertNotIn(\"proxy\", request2.meta)\n+            assert \"Proxy-Authorization\" not in request2.headers\n+            assert \"_auth_proxy\" not in request2.meta\n+            assert \"proxy\" not in request2.meta\n \n             response2 = self.get_response(request2, \"http://example.com\")\n             request3 = redirect_mw.process_response(request2, response2, spider)\n \n-            self.assertIsInstance(request3, Request)\n-            self.assertNotIn(\"Proxy-Authorization\", request3.headers)\n-            self.assertNotIn(\"_auth_proxy\", request3.meta)\n-            self.assertNotIn(\"proxy\", request3.meta)\n+            assert isinstance(request3, Request)\n+            assert \"Proxy-Authorization\" not in request3.headers\n+            assert \"_auth_proxy\" not in request3.meta\n+            assert \"proxy\" not in request3.meta\n \n             proxy_mw.process_request(request3, spider)\n \n-            self.assertNotIn(\"Proxy-Authorization\", request3.headers)\n-            self.assertNotIn(\"_auth_proxy\", request3.meta)\n-            self.assertNotIn(\"proxy\", request3.meta)\n+            assert \"Proxy-Authorization\" not in request3.headers\n+            assert \"_auth_proxy\" not in request3.meta\n+            assert \"proxy\" not in request3.meta\n \n         def test_system_proxy_proxied_https_to_proxied_http(self):\n             crawler = get_crawler()\n@@ -857,37 +843,37 @@ class Base:\n             spider = None\n             proxy_mw.process_request(request1, spider)\n \n-            self.assertEqual(request1.headers[\"Proxy-Authorization\"], b\"Basic Yjo=\")\n-            self.assertEqual(request1.meta[\"_auth_proxy\"], \"https://b.example\")\n-            self.assertEqual(request1.meta[\"proxy\"], \"https://b.example\")\n+            assert request1.headers[\"Proxy-Authorization\"] == b\"Basic Yjo=\"\n+            assert request1.meta[\"_auth_proxy\"] == \"https://b.example\"\n+            assert request1.meta[\"proxy\"] == \"https://b.example\"\n \n             response1 = self.get_response(request1, \"http://example.com\")\n             request2 = redirect_mw.process_response(request1, response1, spider)\n \n-            self.assertIsInstance(request2, Request)\n-            self.assertNotIn(\"Proxy-Authorization\", request2.headers)\n-            self.assertNotIn(\"_auth_proxy\", request2.meta)\n-            self.assertNotIn(\"proxy\", request2.meta)\n+            assert isinstance(request2, Request)\n+            assert \"Proxy-Authorization\" not in request2.headers\n+            assert \"_auth_proxy\" not in request2.meta\n+            assert \"proxy\" not in request2.meta\n \n             proxy_mw.process_request(request2, spider)\n \n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             response2 = self.get_response(request2, \"https://example.com\")\n             request3 = redirect_mw.process_response(request2, response2, spider)\n \n-            self.assertIsInstance(request3, Request)\n-            self.assertNotIn(\"Proxy-Authorization\", request3.headers)\n-            self.assertNotIn(\"_auth_proxy\", request3.meta)\n-            self.assertNotIn(\"proxy\", request3.meta)\n+            assert isinstance(request3, Request)\n+            assert \"Proxy-Authorization\" not in request3.headers\n+            assert \"_auth_proxy\" not in request3.meta\n+            assert \"proxy\" not in request3.meta\n \n             proxy_mw.process_request(request3, spider)\n \n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic Yjo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://b.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://b.example\")\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic Yjo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://b.example\"\n+            assert request3.meta[\"proxy\"] == \"https://b.example\"\n \n         def test_system_proxy_proxied_https_to_unproxied_http(self):\n             crawler = get_crawler()\n@@ -902,37 +888,37 @@ class Base:\n             spider = None\n             proxy_mw.process_request(request1, spider)\n \n-            self.assertEqual(request1.headers[\"Proxy-Authorization\"], b\"Basic Yjo=\")\n-            self.assertEqual(request1.meta[\"_auth_proxy\"], \"https://b.example\")\n-            self.assertEqual(request1.meta[\"proxy\"], \"https://b.example\")\n+            assert request1.headers[\"Proxy-Authorization\"] == b\"Basic Yjo=\"\n+            assert request1.meta[\"_auth_proxy\"] == \"https://b.example\"\n+            assert request1.meta[\"proxy\"] == \"https://b.example\"\n \n             response1 = self.get_response(request1, \"http://example.com\")\n             request2 = redirect_mw.process_response(request1, response1, spider)\n \n-            self.assertIsInstance(request2, Request)\n-            self.assertNotIn(\"Proxy-Authorization\", request2.headers)\n-            self.assertNotIn(\"_auth_proxy\", request2.meta)\n-            self.assertNotIn(\"proxy\", request2.meta)\n+            assert isinstance(request2, Request)\n+            assert \"Proxy-Authorization\" not in request2.headers\n+            assert \"_auth_proxy\" not in request2.meta\n+            assert \"proxy\" not in request2.meta\n \n             proxy_mw.process_request(request2, spider)\n \n-            self.assertNotIn(\"Proxy-Authorization\", request2.headers)\n-            self.assertNotIn(\"_auth_proxy\", request2.meta)\n-            self.assertNotIn(\"proxy\", request2.meta)\n+            assert \"Proxy-Authorization\" not in request2.headers\n+            assert \"_auth_proxy\" not in request2.meta\n+            assert \"proxy\" not in request2.meta\n \n             response2 = self.get_response(request2, \"https://example.com\")\n             request3 = redirect_mw.process_response(request2, response2, spider)\n \n-            self.assertIsInstance(request3, Request)\n-            self.assertNotIn(\"Proxy-Authorization\", request3.headers)\n-            self.assertNotIn(\"_auth_proxy\", request3.meta)\n-            self.assertNotIn(\"proxy\", request3.meta)\n+            assert isinstance(request3, Request)\n+            assert \"Proxy-Authorization\" not in request3.headers\n+            assert \"_auth_proxy\" not in request3.meta\n+            assert \"proxy\" not in request3.meta\n \n             proxy_mw.process_request(request3, spider)\n \n-            self.assertEqual(request3.headers[\"Proxy-Authorization\"], b\"Basic Yjo=\")\n-            self.assertEqual(request3.meta[\"_auth_proxy\"], \"https://b.example\")\n-            self.assertEqual(request3.meta[\"proxy\"], \"https://b.example\")\n+            assert request3.headers[\"Proxy-Authorization\"] == b\"Basic Yjo=\"\n+            assert request3.meta[\"_auth_proxy\"] == \"https://b.example\"\n+            assert request3.meta[\"proxy\"] == \"https://b.example\"\n \n         def test_system_proxy_unproxied_https_to_proxied_http(self):\n             crawler = get_crawler()\n@@ -947,37 +933,37 @@ class Base:\n             spider = None\n             proxy_mw.process_request(request1, spider)\n \n-            self.assertNotIn(\"Proxy-Authorization\", request1.headers)\n-            self.assertNotIn(\"_auth_proxy\", request1.meta)\n-            self.assertNotIn(\"proxy\", request1.meta)\n+            assert \"Proxy-Authorization\" not in request1.headers\n+            assert \"_auth_proxy\" not in request1.meta\n+            assert \"proxy\" not in request1.meta\n \n             response1 = self.get_response(request1, \"http://example.com\")\n             request2 = redirect_mw.process_response(request1, response1, spider)\n \n-            self.assertIsInstance(request2, Request)\n-            self.assertNotIn(\"Proxy-Authorization\", request2.headers)\n-            self.assertNotIn(\"_auth_proxy\", request2.meta)\n-            self.assertNotIn(\"proxy\", request2.meta)\n+            assert isinstance(request2, Request)\n+            assert \"Proxy-Authorization\" not in request2.headers\n+            assert \"_auth_proxy\" not in request2.meta\n+            assert \"proxy\" not in request2.meta\n \n             proxy_mw.process_request(request2, spider)\n \n-            self.assertEqual(request2.headers[\"Proxy-Authorization\"], b\"Basic YTo=\")\n-            self.assertEqual(request2.meta[\"_auth_proxy\"], \"https://a.example\")\n-            self.assertEqual(request2.meta[\"proxy\"], \"https://a.example\")\n+            assert request2.headers[\"Proxy-Authorization\"] == b\"Basic YTo=\"\n+            assert request2.meta[\"_auth_proxy\"] == \"https://a.example\"\n+            assert request2.meta[\"proxy\"] == \"https://a.example\"\n \n             response2 = self.get_response(request2, \"https://example.com\")\n             request3 = redirect_mw.process_response(request2, response2, spider)\n \n-            self.assertIsInstance(request3, Request)\n-            self.assertNotIn(\"Proxy-Authorization\", request3.headers)\n-            self.assertNotIn(\"_auth_proxy\", request3.meta)\n-            self.assertNotIn(\"proxy\", request3.meta)\n+            assert isinstance(request3, Request)\n+            assert \"Proxy-Authorization\" not in request3.headers\n+            assert \"_auth_proxy\" not in request3.meta\n+            assert \"proxy\" not in request3.meta\n \n             proxy_mw.process_request(request3, spider)\n \n-            self.assertNotIn(\"Proxy-Authorization\", request3.headers)\n-            self.assertNotIn(\"_auth_proxy\", request3.meta)\n-            self.assertNotIn(\"proxy\", request3.meta)\n+            assert \"Proxy-Authorization\" not in request3.headers\n+            assert \"_auth_proxy\" not in request3.meta\n+            assert \"proxy\" not in request3.meta\n \n         def test_system_proxy_unproxied_https_to_unproxied_http(self):\n             crawler = get_crawler()\n@@ -988,44 +974,44 @@ class Base:\n             spider = None\n             proxy_mw.process_request(request1, spider)\n \n-            self.assertNotIn(\"Proxy-Authorization\", request1.headers)\n-            self.assertNotIn(\"_auth_proxy\", request1.meta)\n-            self.assertNotIn(\"proxy\", request1.meta)\n+            assert \"Proxy-Authorization\" not in request1.headers\n+            assert \"_auth_proxy\" not in request1.meta\n+            assert \"proxy\" not in request1.meta\n \n             response1 = self.get_response(request1, \"http://example.com\")\n             request2 = redirect_mw.process_response(request1, response1, spider)\n \n-            self.assertIsInstance(request2, Request)\n-            self.assertNotIn(\"Proxy-Authorization\", request2.headers)\n-            self.assertNotIn(\"_auth_proxy\", request2.meta)\n-            self.assertNotIn(\"proxy\", request2.meta)\n+            assert isinstance(request2, Request)\n+            assert \"Proxy-Authorization\" not in request2.headers\n+            assert \"_auth_proxy\" not in request2.meta\n+            assert \"proxy\" not in request2.meta\n \n             proxy_mw.process_request(request2, spider)\n \n-            self.assertNotIn(\"Proxy-Authorization\", request2.headers)\n-            self.assertNotIn(\"_auth_proxy\", request2.meta)\n-            self.assertNotIn(\"proxy\", request2.meta)\n+            assert \"Proxy-Authorization\" not in request2.headers\n+            assert \"_auth_proxy\" not in request2.meta\n+            assert \"proxy\" not in request2.meta\n \n             response2 = self.get_response(request2, \"https://example.com\")\n             request3 = redirect_mw.process_response(request2, response2, spider)\n \n-            self.assertIsInstance(request3, Request)\n-            self.assertNotIn(\"Proxy-Authorization\", request3.headers)\n-            self.assertNotIn(\"_auth_proxy\", request3.meta)\n-            self.assertNotIn(\"proxy\", request3.meta)\n+            assert isinstance(request3, Request)\n+            assert \"Proxy-Authorization\" not in request3.headers\n+            assert \"_auth_proxy\" not in request3.meta\n+            assert \"proxy\" not in request3.meta\n \n             proxy_mw.process_request(request3, spider)\n \n-            self.assertNotIn(\"Proxy-Authorization\", request3.headers)\n-            self.assertNotIn(\"_auth_proxy\", request3.meta)\n-            self.assertNotIn(\"proxy\", request3.meta)\n+            assert \"Proxy-Authorization\" not in request3.headers\n+            assert \"_auth_proxy\" not in request3.meta\n+            assert \"proxy\" not in request3.meta\n \n \n-class RedirectMiddlewareTest(Base.Test):\n+class TestRedirectMiddleware(Base.Test):\n     mwcls = RedirectMiddleware\n     reason = 302\n \n-    def setUp(self):\n+    def setup_method(self):\n         self.crawler = get_crawler(Spider)\n         self.spider = self.crawler._create_spider(\"foo\")\n         self.mw = self.mwcls.from_crawler(self.crawler)\n@@ -1043,8 +1029,8 @@ class RedirectMiddlewareTest(Base.Test):\n \n             req2 = self.mw.process_response(req, rsp, self.spider)\n             assert isinstance(req2, Request)\n-            self.assertEqual(req2.url, url2)\n-            self.assertEqual(req2.method, method)\n+            assert req2.url == url2\n+            assert req2.method == method\n \n             # response without Location header but with status code is 3XX should be ignored\n             del rsp.headers[\"Location\"]\n@@ -1070,8 +1056,8 @@ class RedirectMiddlewareTest(Base.Test):\n \n         req2 = self.mw.process_response(req, rsp, self.spider)\n         assert isinstance(req2, Request)\n-        self.assertEqual(req2.url, url2)\n-        self.assertEqual(req2.method, \"HEAD\")\n+        assert req2.url == url2\n+        assert req2.method == \"HEAD\"\n \n     def test_redirect_302_relative(self):\n         url = \"http://www.example.com/302\"\n@@ -1082,8 +1068,8 @@ class RedirectMiddlewareTest(Base.Test):\n \n         req2 = self.mw.process_response(req, rsp, self.spider)\n         assert isinstance(req2, Request)\n-        self.assertEqual(req2.url, url3)\n-        self.assertEqual(req2.method, \"HEAD\")\n+        assert req2.url == url3\n+        assert req2.method == \"HEAD\"\n \n     def test_spider_handling(self):\n         smartspider = self.crawler._create_spider(\"smarty\")\n@@ -1093,7 +1079,7 @@ class RedirectMiddlewareTest(Base.Test):\n         req = Request(url)\n         rsp = Response(url, headers={\"Location\": url2}, status=301)\n         r = self.mw.process_response(req, rsp, smartspider)\n-        self.assertIs(r, rsp)\n+        assert r is rsp\n \n     def test_request_meta_handling(self):\n         url = \"http://www.example.com/301\"\n@@ -1102,7 +1088,7 @@ class RedirectMiddlewareTest(Base.Test):\n         def _test_passthrough(req):\n             rsp = Response(url, headers={\"Location\": url2}, status=301, request=req)\n             r = self.mw.process_response(req, rsp, self.spider)\n-            self.assertIs(r, rsp)\n+            assert r is rsp\n \n         _test_passthrough(\n             Request(url, meta={\"handle_httpstatus_list\": [404, 301, 302]})\n@@ -1119,7 +1105,7 @@ class RedirectMiddlewareTest(Base.Test):\n         )\n         req_result = self.mw.process_response(req, resp, self.spider)\n         perc_encoded_utf8_url = \"http://scrapytest.org/a%E7%E3o\"\n-        self.assertEqual(perc_encoded_utf8_url, req_result.url)\n+        assert perc_encoded_utf8_url == req_result.url\n \n     def test_utf8_location(self):\n         req = Request(\"http://scrapytest.org/first\")\n@@ -1131,7 +1117,7 @@ class RedirectMiddlewareTest(Base.Test):\n         )\n         req_result = self.mw.process_response(req, resp, self.spider)\n         perc_encoded_utf8_url = \"http://scrapytest.org/a%C3%A7%C3%A3o\"\n-        self.assertEqual(perc_encoded_utf8_url, req_result.url)\n+        assert perc_encoded_utf8_url == req_result.url\n \n     def test_no_location(self):\n         request = Request(\"https://example.com\")\n@@ -1197,11 +1183,11 @@ def meta_refresh_body(url, interval=5):\n     return html.encode(\"utf-8\")\n \n \n-class MetaRefreshMiddlewareTest(Base.Test):\n+class TestMetaRefreshMiddleware(Base.Test):\n     mwcls = MetaRefreshMiddleware\n     reason = \"meta refresh\"\n \n-    def setUp(self):\n+    def setup_method(self):\n         crawler = get_crawler(Spider)\n         self.spider = crawler._create_spider(\"foo\")\n         self.mw = self.mwcls.from_crawler(crawler)\n@@ -1217,7 +1203,7 @@ class MetaRefreshMiddlewareTest(Base.Test):\n         rsp = HtmlResponse(req.url, body=self._body())\n         req2 = self.mw.process_response(req, rsp, self.spider)\n         assert isinstance(req2, Request)\n-        self.assertEqual(req2.url, \"http://example.org/newpage\")\n+        assert req2.url == \"http://example.org/newpage\"\n \n     def test_meta_refresh_with_high_interval(self):\n         # meta-refresh with high intervals don't trigger redirects\n@@ -1239,8 +1225,8 @@ class MetaRefreshMiddlewareTest(Base.Test):\n         req2 = self.mw.process_response(req, rsp, self.spider)\n \n         assert isinstance(req2, Request)\n-        self.assertEqual(req2.url, \"http://example.org/newpage\")\n-        self.assertEqual(req2.method, \"GET\")\n+        assert req2.url == \"http://example.org/newpage\"\n+        assert req2.method == \"GET\"\n         assert \"Content-Type\" not in req2.headers, (\n             \"Content-Type header must not be present in redirected request\"\n         )\n\n@@ -1,5 +1,4 @@\n import logging\n-import unittest\n \n import pytest\n from testfixtures import LogCapture\n@@ -21,8 +20,8 @@ from scrapy.spiders import Spider\n from scrapy.utils.test import get_crawler\n \n \n-class RetryTest(unittest.TestCase):\n-    def setUp(self):\n+class TestRetry:\n+    def setup_method(self):\n         self.crawler = get_crawler(Spider)\n         self.spider = self.crawler._create_spider(\"foo\")\n         self.mw = RetryMiddleware.from_crawler(self.crawler)\n@@ -70,12 +69,12 @@ class RetryTest(unittest.TestCase):\n         # first retry\n         req = self.mw.process_response(req, rsp, self.spider)\n         assert isinstance(req, Request)\n-        self.assertEqual(req.meta[\"retry_times\"], 1)\n+        assert req.meta[\"retry_times\"] == 1\n \n         # second retry\n         req = self.mw.process_response(req, rsp, self.spider)\n         assert isinstance(req, Request)\n-        self.assertEqual(req.meta[\"retry_times\"], 2)\n+        assert req.meta[\"retry_times\"] == 2\n \n         # discard it\n         assert self.mw.process_response(req, rsp, self.spider) is rsp\n@@ -129,19 +128,19 @@ class RetryTest(unittest.TestCase):\n         # first retry\n         req = mw.process_exception(req, exception, self.spider)\n         assert isinstance(req, Request)\n-        self.assertEqual(req.meta[\"retry_times\"], 1)\n+        assert req.meta[\"retry_times\"] == 1\n \n         # second retry\n         req = mw.process_exception(req, exception, self.spider)\n         assert isinstance(req, Request)\n-        self.assertEqual(req.meta[\"retry_times\"], 2)\n+        assert req.meta[\"retry_times\"] == 2\n \n         # discard it\n         req = mw.process_exception(req, exception, self.spider)\n-        self.assertEqual(req, None)\n+        assert req is None\n \n \n-class MaxRetryTimesTest(unittest.TestCase):\n+class TestMaxRetryTimes:\n     invalid_url = \"http://www.scrapytest.org/invalid_url\"\n \n     def get_spider_and_middleware(self, settings=None):\n@@ -272,10 +271,10 @@ class MaxRetryTimesTest(unittest.TestCase):\n \n         # discard it\n         req = middleware.process_exception(req, exception, spider)\n-        self.assertEqual(req, None)\n+        assert req is None\n \n \n-class GetRetryRequestTest(unittest.TestCase):\n+class TestGetRetryRequest:\n     def get_spider(self, settings=None):\n         crawler = get_crawler(Spider, settings or {})\n         return crawler._create_spider(\"foo\")\n@@ -288,15 +287,15 @@ class GetRetryRequestTest(unittest.TestCase):\n                 request,\n                 spider=spider,\n             )\n-        self.assertIsInstance(new_request, Request)\n-        self.assertNotEqual(new_request, request)\n-        self.assertEqual(new_request.dont_filter, True)\n+        assert isinstance(new_request, Request)\n+        assert new_request != request\n+        assert new_request.dont_filter\n         expected_retry_times = 1\n-        self.assertEqual(new_request.meta[\"retry_times\"], expected_retry_times)\n-        self.assertEqual(new_request.priority, -1)\n+        assert new_request.meta[\"retry_times\"] == expected_retry_times\n+        assert new_request.priority == -1\n         expected_reason = \"unspecified\"\n         for stat in (\"retry/count\", f\"retry/reason_count/{expected_reason}\"):\n-            self.assertEqual(spider.crawler.stats.get_value(stat), 1)\n+            assert spider.crawler.stats.get_value(stat) == 1\n         log.check_present(\n             (\n                 \"scrapy.downloadermiddlewares.retry\",\n@@ -316,8 +315,8 @@ class GetRetryRequestTest(unittest.TestCase):\n                 spider=spider,\n                 max_retry_times=max_retry_times,\n             )\n-        self.assertEqual(new_request, None)\n-        self.assertEqual(spider.crawler.stats.get_value(\"retry/max_reached\"), 1)\n+        assert new_request is None\n+        assert spider.crawler.stats.get_value(\"retry/max_reached\") == 1\n         failure_count = max_retry_times + 1\n         expected_reason = \"unspecified\"\n         log.check_present(\n@@ -338,15 +337,15 @@ class GetRetryRequestTest(unittest.TestCase):\n                 spider=spider,\n                 max_retry_times=1,\n             )\n-        self.assertIsInstance(new_request, Request)\n-        self.assertNotEqual(new_request, request)\n-        self.assertEqual(new_request.dont_filter, True)\n+        assert isinstance(new_request, Request)\n+        assert new_request != request\n+        assert new_request.dont_filter\n         expected_retry_times = 1\n-        self.assertEqual(new_request.meta[\"retry_times\"], expected_retry_times)\n-        self.assertEqual(new_request.priority, -1)\n+        assert new_request.meta[\"retry_times\"] == expected_retry_times\n+        assert new_request.priority == -1\n         expected_reason = \"unspecified\"\n         for stat in (\"retry/count\", f\"retry/reason_count/{expected_reason}\"):\n-            self.assertEqual(spider.crawler.stats.get_value(stat), 1)\n+            assert spider.crawler.stats.get_value(stat) == 1\n         log.check_present(\n             (\n                 \"scrapy.downloadermiddlewares.retry\",\n@@ -368,16 +367,16 @@ class GetRetryRequestTest(unittest.TestCase):\n                     spider=spider,\n                     max_retry_times=max_retry_times,\n                 )\n-            self.assertIsInstance(new_request, Request)\n-            self.assertNotEqual(new_request, request)\n-            self.assertEqual(new_request.dont_filter, True)\n+            assert isinstance(new_request, Request)\n+            assert new_request != request\n+            assert new_request.dont_filter\n             expected_retry_times = index + 1\n-            self.assertEqual(new_request.meta[\"retry_times\"], expected_retry_times)\n-            self.assertEqual(new_request.priority, -expected_retry_times)\n+            assert new_request.meta[\"retry_times\"] == expected_retry_times\n+            assert new_request.priority == -expected_retry_times\n             expected_reason = \"unspecified\"\n             for stat in (\"retry/count\", f\"retry/reason_count/{expected_reason}\"):\n                 value = spider.crawler.stats.get_value(stat)\n-                self.assertEqual(value, expected_retry_times)\n+                assert value == expected_retry_times\n             log.check_present(\n                 (\n                     \"scrapy.downloadermiddlewares.retry\",\n@@ -393,8 +392,8 @@ class GetRetryRequestTest(unittest.TestCase):\n                 spider=spider,\n                 max_retry_times=max_retry_times,\n             )\n-        self.assertEqual(new_request, None)\n-        self.assertEqual(spider.crawler.stats.get_value(\"retry/max_reached\"), 1)\n+        assert new_request is None\n+        assert spider.crawler.stats.get_value(\"retry/max_reached\") == 1\n         failure_count = max_retry_times + 1\n         expected_reason = \"unspecified\"\n         log.check_present(\n@@ -419,7 +418,7 @@ class GetRetryRequestTest(unittest.TestCase):\n             request,\n             spider=spider,\n         )\n-        self.assertEqual(new_request, None)\n+        assert new_request is None\n \n     def test_max_retry_times_meta(self):\n         max_retry_times = 0\n@@ -430,7 +429,7 @@ class GetRetryRequestTest(unittest.TestCase):\n             request,\n             spider=spider,\n         )\n-        self.assertEqual(new_request, None)\n+        assert new_request is None\n \n     def test_max_retry_times_argument(self):\n         max_retry_times = 0\n@@ -442,7 +441,7 @@ class GetRetryRequestTest(unittest.TestCase):\n             spider=spider,\n             max_retry_times=max_retry_times,\n         )\n-        self.assertEqual(new_request, None)\n+        assert new_request is None\n \n     def test_priority_adjust_setting(self):\n         priority_adjust = 1\n@@ -452,7 +451,7 @@ class GetRetryRequestTest(unittest.TestCase):\n             request,\n             spider=spider,\n         )\n-        self.assertEqual(new_request.priority, priority_adjust)\n+        assert new_request.priority == priority_adjust\n \n     def test_priority_adjust_argument(self):\n         priority_adjust = 1\n@@ -463,7 +462,7 @@ class GetRetryRequestTest(unittest.TestCase):\n             spider=spider,\n             priority_adjust=priority_adjust,\n         )\n-        self.assertEqual(new_request.priority, priority_adjust)\n+        assert new_request.priority == priority_adjust\n \n     def test_log_extra_retry_success(self):\n         request = Request(\"https://example.com\")\n@@ -498,7 +497,7 @@ class GetRetryRequestTest(unittest.TestCase):\n             )\n         expected_retry_times = 1\n         for stat in (\"retry/count\", f\"retry/reason_count/{expected_reason}\"):\n-            self.assertEqual(spider.crawler.stats.get_value(stat), 1)\n+            assert spider.crawler.stats.get_value(stat) == 1\n         log.check_present(\n             (\n                 \"scrapy.downloadermiddlewares.retry\",\n@@ -523,7 +522,7 @@ class GetRetryRequestTest(unittest.TestCase):\n         stat = spider.crawler.stats.get_value(\n             f\"retry/reason_count/{expected_reason_string}\"\n         )\n-        self.assertEqual(stat, 1)\n+        assert stat == 1\n         log.check_present(\n             (\n                 \"scrapy.downloadermiddlewares.retry\",\n@@ -548,7 +547,7 @@ class GetRetryRequestTest(unittest.TestCase):\n         stat = spider.crawler.stats.get_value(\n             f\"retry/reason_count/{expected_reason_string}\"\n         )\n-        self.assertEqual(stat, 1)\n+        assert stat == 1\n         log.check_present(\n             (\n                 \"scrapy.downloadermiddlewares.retry\",\n@@ -573,7 +572,7 @@ class GetRetryRequestTest(unittest.TestCase):\n         stat = spider.crawler.stats.get_value(\n             f\"retry/reason_count/{expected_reason_string}\"\n         )\n-        self.assertEqual(stat, 1)\n+        assert stat == 1\n         log.check_present(\n             (\n                 \"scrapy.downloadermiddlewares.retry\",\n@@ -598,7 +597,7 @@ class GetRetryRequestTest(unittest.TestCase):\n         stat = spider.crawler.stats.get_value(\n             f\"retry/reason_count/{expected_reason_string}\"\n         )\n-        self.assertEqual(stat, 1)\n+        assert stat == 1\n         log.check_present(\n             (\n                 \"scrapy.downloadermiddlewares.retry\",\n@@ -643,4 +642,4 @@ class GetRetryRequestTest(unittest.TestCase):\n             f\"{stats_key}/count\",\n             f\"{stats_key}/reason_count/{expected_reason}\",\n         ):\n-            self.assertEqual(spider.crawler.stats.get_value(stat), 1)\n+            assert spider.crawler.stats.get_value(stat) == 1\n\n@@ -15,7 +15,7 @@ from scrapy.settings import Settings\n from tests.test_robotstxt_interface import rerp_available\n \n \n-class RobotsTxtMiddlewareTest(unittest.TestCase):\n+class TestRobotsTxtMiddleware(unittest.TestCase):\n     def setUp(self):\n         self.crawler = mock.MagicMock()\n         self.crawler.settings = Settings()\n@@ -242,11 +242,11 @@ Disallow: /some/randome/page.html\n     def assertRobotsTxtRequested(self, base_url):\n         calls = self.crawler.engine.download.call_args_list\n         request = calls[0][0][0]\n-        self.assertEqual(request.url, f\"{base_url}/robots.txt\")\n-        self.assertEqual(request.callback, NO_CALLBACK)\n+        assert request.url == f\"{base_url}/robots.txt\"\n+        assert request.callback == NO_CALLBACK\n \n \n-class RobotsTxtMiddlewareWithRerpTest(RobotsTxtMiddlewareTest):\n+class TestRobotsTxtMiddlewareWithRerp(TestRobotsTxtMiddleware):\n     if not rerp_available():\n         skip = \"Rerp parser is not installed\"\n \n\n@@ -1,5 +1,3 @@\n-from unittest import TestCase\n-\n from scrapy.downloadermiddlewares.stats import DownloaderStats\n from scrapy.http import Request, Response\n from scrapy.spiders import Spider\n@@ -10,8 +8,8 @@ class MyException(Exception):\n     pass\n \n \n-class TestDownloaderStats(TestCase):\n-    def setUp(self):\n+class TestDownloaderStats:\n+    def setup_method(self):\n         self.crawler = get_crawler(Spider)\n         self.spider = self.crawler._create_spider(\"scrapytest.org\")\n         self.mw = DownloaderStats(self.crawler.stats)\n@@ -22,10 +20,8 @@ class TestDownloaderStats(TestCase):\n         self.res = Response(\"scrapytest.org\", status=400)\n \n     def assertStatsEqual(self, key, value):\n-        self.assertEqual(\n-            self.crawler.stats.get_value(key, spider=self.spider),\n-            value,\n-            str(self.crawler.stats.get_stats(self.spider)),\n+        assert self.crawler.stats.get_value(key, spider=self.spider) == value, str(\n+            self.crawler.stats.get_stats(self.spider)\n         )\n \n     def test_process_request(self):\n@@ -44,5 +40,5 @@ class TestDownloaderStats(TestCase):\n             1,\n         )\n \n-    def tearDown(self):\n+    def teardown_method(self):\n         self.crawler.stats.close_spider(self.spider, \"\")\n\n@@ -1,12 +1,10 @@\n-from unittest import TestCase\n-\n from scrapy.downloadermiddlewares.useragent import UserAgentMiddleware\n from scrapy.http import Request\n from scrapy.spiders import Spider\n from scrapy.utils.test import get_crawler\n \n \n-class UserAgentMiddlewareTest(TestCase):\n+class TestUserAgentMiddleware:\n     def get_spider_and_mw(self, default_useragent):\n         crawler = get_crawler(Spider, {\"USER_AGENT\": default_useragent})\n         spider = crawler._create_spider(\"foo\")\n@@ -16,7 +14,7 @@ class UserAgentMiddlewareTest(TestCase):\n         spider, mw = self.get_spider_and_mw(\"default_useragent\")\n         req = Request(\"http://scrapytest.org/\")\n         assert mw.process_request(req, spider) is None\n-        self.assertEqual(req.headers[\"User-Agent\"], b\"default_useragent\")\n+        assert req.headers[\"User-Agent\"] == b\"default_useragent\"\n \n     def test_remove_agent(self):\n         # settings USER_AGENT to None should remove the user agent\n@@ -33,7 +31,7 @@ class UserAgentMiddlewareTest(TestCase):\n         mw.spider_opened(spider)\n         req = Request(\"http://scrapytest.org/\")\n         assert mw.process_request(req, spider) is None\n-        self.assertEqual(req.headers[\"User-Agent\"], b\"spider_useragent\")\n+        assert req.headers[\"User-Agent\"] == b\"spider_useragent\"\n \n     def test_header_agent(self):\n         spider, mw = self.get_spider_and_mw(\"default_useragent\")\n@@ -43,7 +41,7 @@ class UserAgentMiddlewareTest(TestCase):\n             \"http://scrapytest.org/\", headers={\"User-Agent\": \"header_useragent\"}\n         )\n         assert mw.process_request(req, spider) is None\n-        self.assertEqual(req.headers[\"User-Agent\"], b\"header_useragent\")\n+        assert req.headers[\"User-Agent\"] == b\"header_useragent\"\n \n     def test_no_agent(self):\n         spider, mw = self.get_spider_and_mw(None)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
