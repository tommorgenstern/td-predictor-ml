{"custom_id": "keras#1af383120ecea37b2e89549a31278b6519391e13", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 1 | Churn Cumulative: 1902 | Contributors (this commit): 8 | Commits (past 90d): 45 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -176,6 +176,7 @@ class Functional(Function, Model):\n         else:\n             masks = self._flatten_to_reference_inputs(mask)\n             for x, mask in zip(inputs, masks):\n+                if mask is not None:\n                     x._keras_mask = mask\n         outputs = self._run_through_graph(\n             inputs, operation_fn=lambda op: operation_fn(op, training=training)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8a172286ddf2e47e5002db0661d6d928a1f8bc57", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 187 | Lines Deleted: 0 | Files Changed: 5 | Hunks: 5 | Methods Changed: 9 | Complexity Δ (Sum/Max): 13/5 | Churn Δ: 187 | Churn Cumulative: 658 | Contributors (this commit): 6 | Commits (past 90d): 26 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n\n@@ -0,0 +1,24 @@\n+import time\n+\n+import keras_core\n+\n+\n+class BenchmarkMetricsCallback(keras_core.callbacks.Callback):\n+    def __init__(self, start_batch=1, stop_batch=None):\n+        self.start_batch = start_batch\n+        self.stop_batch = stop_batch\n+\n+        # Store the throughput of each epoch.\n+        self.state = {\"throughput\": []}\n+\n+    def on_train_batch_begin(self, batch, logs=None):\n+        if batch == self.start_batch:\n+            self.state[\"epoch_begin_time\"] = time.time()\n+\n+    def on_train_batch_end(self, batch, logs=None):\n+        if batch == self.stop_batch:\n+            epoch_end_time = time.time()\n+            throughput = (self.stop_batch - self.start_batch + 1) / (\n+                epoch_end_time - self.state[\"epoch_begin_time\"]\n+            )\n+            self.state[\"throughput\"].append(throughput)\n\n@@ -0,0 +1,148 @@\n+\"\"\"Image classification benchmark with EfficientNetV2B0.\n+\n+To run the benchmark, make sure you are in model_benchmark/ directory, and run\n+the command below:\n+\n+python3 -m model_benchmark.resnet_image_classification_benchmark \\\n+    --epochs=2 \\\n+    --batch_size=32\n+\"\"\"\n+\n+import time\n+\n+import keras_core as keras\n+import numpy as np\n+import tensorflow as tf\n+import tensorflow_datasets as tfds\n+from absl import app\n+from absl import flags\n+from absl import logging\n+\n+\n+from model_benchmark.benchmark_utils import BenchmarkMetricsCallback\n+from keras_core.applications import EfficientNetV2B0\n+\n+flags.DEFINE_integer(\"epochs\", 1, \"The number of epochs.\")\n+flags.DEFINE_integer(\"batch_size\", 4, \"Batch Size.\")\n+flags.DEFINE_string(\n+    \"mixed_precision_policy\",\n+    \"mixed_float16\",\n+    \"The global precision policy to use, e.g., 'mixed_float16' or 'float32'.\",\n+)\n+\n+FLAGS = flags.FLAGS\n+\n+BATCH_SIZE = 32\n+IMAGE_SIZE = (224, 224)\n+CHANNELS = 3\n+\n+\n+def load_data():\n+    # Load cats vs dogs dataset, and split into train and validation sets.\n+    train_dataset, val_dataset = tfds.load(\n+        \"cats_vs_dogs\", split=[\"train[:90%]\", \"train[90%:]\"], as_supervised=True\n+    )\n+\n+    resizing = keras.layers.Resizing(\n+        IMAGE_SIZE[0], IMAGE_SIZE[1], crop_to_aspect_ratio=True\n+    )\n+\n+    def preprocess_inputs(image, label):\n+        image = tf.cast(image, \"float32\")\n+        return resizing(image), label\n+\n+    train_dataset = (\n+        train_dataset.map(\n+            preprocess_inputs, num_parallel_calls=tf.data.AUTOTUNE\n+        )\n+        .batch(FLAGS.batch_size)\n+        .cache()\n+        .prefetch(tf.data.AUTOTUNE)\n+    )\n+    val_dataset = (\n+        val_dataset.map(preprocess_inputs, num_parallel_calls=tf.data.AUTOTUNE)\n+        .batch(FLAGS.batch_size)\n+        .cache()\n+        .prefetch(tf.data.AUTOTUNE)\n+    )\n+    return train_dataset, val_dataset\n+\n+\n+def load_model():\n+    # Load the EfficientNetV2B0 model and add a classification head.\n+    model = EfficientNetV2B0(include_top=False, weights=\"imagenet\")\n+    classifier = keras.models.Sequential(\n+        [\n+            keras.Input([IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS]),\n+            model,\n+            keras.layers.GlobalAveragePooling2D(),\n+            keras.layers.Dense(2),\n+        ]\n+    )\n+    return classifier\n+\n+\n+def main(_):\n+    keras.mixed_precision.set_dtype_policy(FLAGS.mixed_precision_policy)\n+\n+    logging.info(\n+        \"Benchmarking configs...\\n\"\n+        \"=========================\\n\"\n+        f\"MODEL: EfficientNetV2B0\\n\"\n+        f\"TASK: image classification/dogs-vs-cats \\n\"\n+        f\"BATCH_SIZE: {FLAGS.batch_size}\\n\"\n+        f\"EPOCHS: {FLAGS.epochs}\\n\"\n+        \"=========================\\n\"\n+    )\n+\n+    # Load datasets.\n+    train_ds, validation_ds = load_data()\n+\n+    # Load the model.\n+    classifier = load_model()\n+\n+    lr = keras.optimizers.schedules.PolynomialDecay(\n+        5e-4,\n+        decay_steps=train_ds.cardinality() * FLAGS.epochs,\n+        end_learning_rate=0.0,\n+    )\n+    optimizer = keras.optimizers.Adam(lr)\n+    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n+\n+    benchmark_metrics_callback = BenchmarkMetricsCallback(\n+        start_batch=1,\n+        stop_batch=train_ds.cardinality().numpy()-1,\n+    )\n+\n+    classifier.compile(\n+        optimizer=optimizer,\n+        loss=loss,\n+        metrics=[\"sparse_categorical_accuracy\"],\n+    )\n+    # Start training.\n+    logging.info(\"Starting Training...\")\n+\n+    st = time.time()\n+\n+    history = classifier.fit(\n+        train_ds,\n+        validation_data=validation_ds,\n+        epochs=FLAGS.epochs,\n+        callbacks=[benchmark_metrics_callback],\n+    )\n+\n+    wall_time = time.time() - st\n+    validation_accuracy = history.history[\"val_sparse_categorical_accuracy\"][-1]\n+\n+    examples_per_second = np.mean(\n+        np.array(benchmark_metrics_callback.state[\"throughput\"])\n+    ) * FLAGS.batch_size\n+\n+    logging.info(\"Training Finished!\")\n+    logging.info(f\"Wall Time: {wall_time:.4f} seconds.\")\n+    logging.info(f\"Validation Accuracy: {validation_accuracy:.4f}\")\n+    logging.info(f\"examples_per_second: {examples_per_second:.4f}\")\n+\n+\n+if __name__ == \"__main__\":\n+    app.run(main)\n\n@@ -1,4 +1,5 @@\n from keras_core import activations\n+from keras_core import applications\n from keras_core import backend\n from keras_core import constraints\n from keras_core import datasets\n\n@@ -61,8 +61,22 @@ def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n     )\n \n \n+def _get_concrete_noise_shape(inputs, noise_shape):\n+    if noise_shape is None:\n+        return tf.shape(inputs)\n+\n+    concrete_inputs_shape = tf.shape(inputs)\n+    concrete_noise_shape = []\n+    for i, value in enumerate(noise_shape):\n+        concrete_noise_shape.append(\n+            concrete_inputs_shape[i] if value is None else value\n+        )\n+    return concrete_noise_shape\n+\n+\n def dropout(inputs, rate, noise_shape=None, seed=None):\n     seed = tf_draw_seed(seed)\n+    noise_shape = _get_concrete_noise_shape(inputs, noise_shape)\n     return tf.nn.experimental.stateless_dropout(\n         inputs,\n         rate=rate,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dcf5e7b209795a752f97bcb0fb9fe5ffc21f19c3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 161 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 4 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 161 | Churn Cumulative: 161 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,161 @@\n+\"\"\"Benchmark BERT model on GLUE/MRPC task.\n+\n+To run the script, make sure you are in benchmarks/ directory, abd run the\n+command below:\n+```\n+python3 -m model_benchmark.bert_benchmark \\\n+    --epochs 2 \\\n+    --batch_size 32\n+```\n+\n+\"\"\"\n+\n+import time\n+\n+import keras_core as keras\n+import keras_nlp\n+import numpy as np\n+import tensorflow as tf\n+import tensorflow_datasets as tfds\n+from absl import app\n+from absl import flags\n+from absl import logging\n+\n+from model_benchmark.benchmark_utils import BenchmarkMetricsCallback\n+\n+\n+flags.DEFINE_string(\"model_size\", \"small\", \"The size of model to benchmark.\")\n+flags.DEFINE_string(\n+    \"mixed_precision_policy\",\n+    \"mixed_float16\",\n+    \"The global precision policy to use, e.g., 'mixed_float16' or 'float32'.\",\n+)\n+flags.DEFINE_integer(\"epochs\", 2, \"The number of epochs.\")\n+flags.DEFINE_integer(\"batch_size\", 8, \"Batch Size.\")\n+\n+\n+FLAGS = flags.FLAGS\n+\n+\n+MODEL_SIZE_MAP = {\n+    \"tiny\": \"bert_tiny_en_uncased\",\n+    \"small\": \"bert_small_en_uncased\",\n+    \"base\": \"bert_base_en_uncased\",\n+    \"large\": \"bert_large_en_uncased\",\n+}\n+\n+def load_data():\n+    \"\"\"Load data.\n+\n+    Load GLUE/MRPC dataset, and convert the dictionary format to\n+    (features, label), where `features` is a tuple of all input sentences.\n+    \"\"\"\n+    feature_names = (\"sentence1\", \"sentence2\")\n+\n+    def split_features(x):\n+        # GLUE comes with dictonary data, we convert it to a uniform format\n+        # (features, label), where features is a tuple consisting of all\n+        # features. This format is necessary for using KerasNLP preprocessors.\n+        features = tuple([x[name] for name in feature_names])\n+        label = x[\"label\"]\n+        return (features, label)\n+\n+    train_ds, test_ds, validation_ds = tfds.load(\n+        \"glue/mrpc\",\n+        split=[\"train\", \"test\", \"validation\"],\n+    )\n+\n+    train_ds = (\n+        train_ds.map(split_features, num_parallel_calls=tf.data.AUTOTUNE)\n+        .batch(FLAGS.batch_size)\n+        .prefetch(tf.data.AUTOTUNE)\n+    )\n+    test_ds = (\n+        test_ds.map(split_features, num_parallel_calls=tf.data.AUTOTUNE)\n+        .batch(FLAGS.batch_size)\n+        .prefetch(tf.data.AUTOTUNE)\n+    )\n+    validation_ds = (\n+        validation_ds.map(split_features, num_parallel_calls=tf.data.AUTOTUNE)\n+        .batch(FLAGS.batch_size)\n+        .prefetch(tf.data.AUTOTUNE)\n+    )\n+    return train_ds, test_ds, validation_ds\n+\n+\n+def load_model():\n+    if FLAGS.model_size not in MODEL_SIZE_MAP.keys():\n+        raise KeyError(\n+            f\"`model_size` must be one of {MODEL_SIZE_MAP.keys()}, but \"\n+            f\"received {FLAGS.model_size}.\"\n+        )\n+    return keras_nlp.models.BertClassifier.from_preset(\n+        MODEL_SIZE_MAP[FLAGS.model_size], num_classes=2\n+    )\n+\n+\n+def main(_):\n+    keras.mixed_precision.set_dtype_policy(FLAGS.mixed_precision_policy)\n+\n+    logging.info(\n+        \"Benchmarking configs...\\n\"\n+        \"=========================\\n\"\n+        f\"MODEL: BERT {FLAGS.model_size}\\n\"\n+        f\"TASK: glue/mrpc \\n\"\n+        f\"BATCH_SIZE: {FLAGS.batch_size}\\n\"\n+        f\"EPOCHS: {FLAGS.epochs}\\n\"\n+        \"=========================\\n\"\n+    )\n+\n+    # Load datasets.\n+    train_ds, test_ds, validation_ds = load_data()\n+\n+    # Load the model.\n+    model = load_model()\n+    # Set loss and metrics.\n+    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n+    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n+    # Configure optimizer.\n+    lr = keras.optimizers.schedules.PolynomialDecay(\n+        5e-4,\n+        decay_steps=train_ds.cardinality() * FLAGS.epochs,\n+        end_learning_rate=0.0,\n+    )\n+    optimizer = keras.optimizers.AdamW(lr, weight_decay=0.01)\n+    optimizer.exclude_from_weight_decay(\n+        var_names=[\"LayerNorm\", \"layer_norm\", \"bias\"]\n+    )\n+\n+    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n+\n+    benchmark_metrics_callback = BenchmarkMetricsCallback(\n+        start_batch=1,\n+        stop_batch=train_ds.cardinality().numpy() - 1,\n+    )\n+\n+    # Start training.\n+    logging.info(\"Starting Training...\")\n+\n+    st = time.time()\n+    history = model.fit(\n+        train_ds,\n+        validation_data=validation_ds,\n+        epochs=FLAGS.epochs,\n+        callbacks=[benchmark_metrics_callback],\n+    )\n+\n+    wall_time = time.time() - st\n+    validation_accuracy = history.history[\"val_sparse_categorical_accuracy\"][-1]\n+    examples_per_second = (\n+        np.mean(np.array(benchmark_metrics_callback.state[\"throughput\"]))\n+        * FLAGS.batch_size\n+    )\n+\n+    logging.info(\"Training Finished!\")\n+    logging.info(f\"Wall Time: {wall_time:.4f} seconds.\")\n+    logging.info(f\"Validation Accuracy: {validation_accuracy:.4f}\")\n+    logging.info(f\"examples_per_second: {examples_per_second:.4f}\")\n+\n+\n+if __name__ == \"__main__\":\n+    app.run(main)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#36a4a832209bf804fc569b361208253bfd4dd3e6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 12 | Files Changed: 3 | Hunks: 17 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 33 | Churn Cumulative: 1503 | Contributors (this commit): 5 | Commits (past 90d): 21 | Contributors (cumulative): 9 | DMM Complexity: 0.7777777777777778\n\nDIFF:\n@@ -12,7 +12,6 @@ python3 -m model_benchmark.bert_benchmark \\\n \n import time\n \n-import keras_core as keras\n import keras_nlp\n import numpy as np\n import tensorflow as tf\n@@ -20,9 +19,9 @@ import tensorflow_datasets as tfds\n from absl import app\n from absl import flags\n from absl import logging\n-\n from model_benchmark.benchmark_utils import BenchmarkMetricsCallback\n \n+import keras_core as keras\n \n flags.DEFINE_string(\"model_size\", \"small\", \"The size of model to benchmark.\")\n flags.DEFINE_string(\n@@ -44,6 +43,7 @@ MODEL_SIZE_MAP = {\n     \"large\": \"bert_large_en_uncased\",\n }\n \n+\n def load_data():\n     \"\"\"Load data.\n \n\n@@ -10,16 +10,15 @@ python3 -m model_benchmark.resnet_image_classification_benchmark \\\n \n import time\n \n-import keras_core as keras\n import numpy as np\n import tensorflow as tf\n import tensorflow_datasets as tfds\n from absl import app\n from absl import flags\n from absl import logging\n-\n-\n from model_benchmark.benchmark_utils import BenchmarkMetricsCallback\n+\n+import keras_core as keras\n from keras_core.applications import EfficientNetV2B0\n \n flags.DEFINE_integer(\"epochs\", 1, \"The number of epochs.\")\n@@ -134,9 +133,10 @@ def main(_):\n     wall_time = time.time() - st\n     validation_accuracy = history.history[\"val_sparse_categorical_accuracy\"][-1]\n \n-    examples_per_second = np.mean(\n-        np.array(benchmark_metrics_callback.state[\"throughput\"])\n-    ) * FLAGS.batch_size\n+    examples_per_second = (\n+        np.mean(np.array(benchmark_metrics_callback.state[\"throughput\"]))\n+        * FLAGS.batch_size\n+    )\n \n     logging.info(\"Training Finished!\")\n     logging.info(f\"Wall Time: {wall_time:.4f} seconds.\")\n\n@@ -63,8 +63,10 @@ def highlight_symbol(x):\n     return f\"[color(33)]{x}[/]\"\n \n \n-def bold_text(x):\n+def bold_text(x, color=None):\n     \"\"\"Bolds text using rich markup.\"\"\"\n+    if color:\n+        return f\"[bold][color({color})]{x}[/][/]\"\n     return f\"[bold]{x}[/]\"\n \n \n@@ -172,19 +174,22 @@ def print_summary(\n         positions = positions or [0.45, 0.84, 1.0]\n         # header names for the different log elements\n         header = [\"Layer (type)\", \"Output Shape\", \"Param #\"]\n+        alignment = [\"left\", \"left\", \"right\"]\n     else:\n         line_length = line_length or 108\n         positions = positions or [0.3, 0.56, 0.70, 1.0]\n         # header names for the different log elements\n         header = [\"Layer (type)\", \"Output Shape\", \"Param #\", \"Connected to\"]\n+        alignment = [\"left\", \"left\", \"right\", \"left\"]\n         relevant_nodes = []\n         for v in model._nodes_by_depth.values():\n             relevant_nodes += v\n \n     if show_trainable:\n         line_length += 8\n-        positions = [p * 0.86 for p in positions] + [1.0]\n+        positions = [p * 0.88 for p in positions] + [1.0]\n         header.append(\"Trainable\")\n+        alignment.append(\"center\")\n \n     # Compute columns widths\n     line_length = min(line_length, shutil.get_terminal_size().columns - 4)\n@@ -200,7 +205,6 @@ def print_summary(\n     # Render summary as a rich table.\n     columns = []\n     # Right align parameter counts.\n-    alignment = [\"left\", \"left\", \"right\", \"left\", \"left\"]\n     for i, name in enumerate(header):\n         column = rich.table.Column(\n             name,\n@@ -208,6 +212,7 @@ def print_summary(\n             width=column_widths[i],\n         )\n         columns.append(column)\n+\n     table = rich.table.Table(*columns, width=line_length, show_lines=True)\n \n     def get_layer_fields(layer, prefix=\"\"):\n@@ -226,7 +231,11 @@ def print_summary(\n \n         fields = [name, output_shape, params]\n         if show_trainable:\n-            fields.append(\"Y\" if layer.trainable else \"N\")\n+            fields.append(\n+                bold_text(\"Y\", color=34)\n+                if layer.trainable\n+                else bold_text(\"N\", color=9)\n+            )\n         return fields\n \n     def get_connections(layer):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2523dc7eebcd70232cadfc58b0f0f38cc3651be5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1249 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 6 | Complexity Δ (Sum/Max): 14/14 | Churn Δ: 1249 | Churn Cumulative: 1249 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,879 @@\n+\"\"\"\n+Title: The Functional API\n+Author: [fchollet](https://twitter.com/fchollet)\n+Date created: 2019/03/01\n+Last modified: 2020/04/12\n+Description: Complete guide to the functional API.\n+Accelerator: GPU\n+\"\"\"\n+\"\"\"\n+## Setup\n+\"\"\"\n+\n+import numpy as np\n+import keras_core as keras\n+from keras_core import layers\n+from keras_core import operations as ops\n+\n+\"\"\"\n+## Introduction\n+\n+The Keras *functional API* is a way to create models that are more flexible\n+than the `keras.Sequential` API. The functional API can handle models\n+with non-linear topology, shared layers, and even multiple inputs or outputs.\n+\n+The main idea is that a deep learning model is usually\n+a directed acyclic graph (DAG) of layers.\n+So the functional API is a way to build *graphs of layers*.\n+\n+Consider the following model:\n+\n+<div class=\"k-default-codeblock\">\n+```\n+(input: 784-dimensional vectors)\n+       ↧\n+[Dense (64 units, relu activation)]\n+       ↧\n+[Dense (64 units, relu activation)]\n+       ↧\n+[Dense (10 units, softmax activation)]\n+       ↧\n+(output: logits of a probability distribution over 10 classes)\n+```\n+</div>\n+\n+This is a basic graph with three layers.\n+To build this model using the functional API, start by creating an input node:\n+\"\"\"\n+\n+inputs = keras.Input(shape=(784,))\n+\n+\"\"\"\n+The shape of the data is set as a 784-dimensional vector.\n+The batch size is always omitted since only the shape of each sample is specified.\n+\n+If, for example, you have an image input with a shape of `(32, 32, 3)`,\n+you would use:\n+\"\"\"\n+\n+# Just for demonstration purposes.\n+img_inputs = keras.Input(shape=(32, 32, 3))\n+\n+\"\"\"\n+The `inputs` that is returned contains information about the shape and `dtype`\n+of the input data that you feed to your model.\n+Here's the shape:\n+\"\"\"\n+\n+inputs.shape\n+\n+\"\"\"\n+Here's the dtype:\n+\"\"\"\n+\n+inputs.dtype\n+\n+\"\"\"\n+You create a new node in the graph of layers by calling a layer on this `inputs`\n+object:\n+\"\"\"\n+\n+dense = layers.Dense(64, activation=\"relu\")\n+x = dense(inputs)\n+\n+\"\"\"\n+The \"layer call\" action is like drawing an arrow from \"inputs\" to this layer\n+you created.\n+You're \"passing\" the inputs to the `dense` layer, and you get `x` as the output.\n+\n+Let's add a few more layers to the graph of layers:\n+\"\"\"\n+\n+x = layers.Dense(64, activation=\"relu\")(x)\n+outputs = layers.Dense(10)(x)\n+\n+\"\"\"\n+At this point, you can create a `Model` by specifying its inputs and outputs\n+in the graph of layers:\n+\"\"\"\n+\n+model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")\n+\n+\"\"\"\n+Let's check out what the model summary looks like:\n+\"\"\"\n+\n+model.summary()\n+\n+\"\"\"\n+You can also plot the model as a graph:\n+\"\"\"\n+\n+keras.utils.plot_model(model, \"my_first_model.png\")\n+\n+\"\"\"\n+And, optionally, display the input and output shapes of each layer\n+in the plotted graph:\n+\"\"\"\n+\n+keras.utils.plot_model(\n+    model, \"my_first_model_with_shape_info.png\", show_shapes=True\n+)\n+\n+\"\"\"\n+This figure and the code are almost identical. In the code version,\n+the connection arrows are replaced by the call operation.\n+\n+A \"graph of layers\" is an intuitive mental image for a deep learning model,\n+and the functional API is a way to create models that closely mirrors this.\n+\"\"\"\n+\n+\"\"\"\n+## Training, evaluation, and inference\n+\n+Training, evaluation, and inference work exactly in the same way for models\n+built using the functional API as for `Sequential` models.\n+\n+The `Model` class offers a built-in training loop (the `fit()` method)\n+and a built-in evaluation loop (the `evaluate()` method). Note\n+that you can easily [customize these loops](/guides/customizing_what_happens_in_fit/)\n+to implement training routines beyond supervised learning\n+(e.g. [GANs](https://keras.io/examples/generative/dcgan_overriding_train_step/)).\n+\n+Here, load the MNIST image data, reshape it into vectors,\n+fit the model on the data (while monitoring performance on a validation split),\n+then evaluate the model on the test data:\n+\"\"\"\n+\n+(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n+\n+x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n+x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n+\n+model.compile(\n+    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n+    optimizer=keras.optimizers.RMSprop(),\n+    metrics=[\"accuracy\"],\n+)\n+\n+history = model.fit(\n+    x_train, y_train, batch_size=64, epochs=2, validation_split=0.2\n+)\n+\n+test_scores = model.evaluate(x_test, y_test, verbose=2)\n+print(\"Test loss:\", test_scores[0])\n+print(\"Test accuracy:\", test_scores[1])\n+\n+\"\"\"\n+For further reading, see the [training and evaluation](/guides/training_with_built_in_methods/) guide.\n+\"\"\"\n+\n+\"\"\"\n+## Save and serialize\n+\n+Saving the model and serialization work the same way for models built using\n+the functional API as they do for `Sequential` models. The standard way\n+to save a functional model is to call `model.save()`\n+to save the entire model as a single file. You can later recreate the same model\n+from this file, even if the code that built the model is no longer available.\n+\n+This saved file includes the:\n+- model architecture\n+- model weight values (that were learned during training)\n+- model training config, if any (as passed to `compile()`)\n+- optimizer and its state, if any (to restart training where you left off)\n+\"\"\"\n+\n+model.save(\"my_model.keras\")\n+del model\n+# Recreate the exact same model purely from the file:\n+model = keras.models.load_model(\"my_model.keras\")\n+\n+\"\"\"\n+For details, read the model [serialization & saving](\n+    /guides/serialization_and_saving/) guide.\n+\"\"\"\n+\n+\"\"\"\n+## Use the same graph of layers to define multiple models\n+\n+In the functional API, models are created by specifying their inputs\n+and outputs in a graph of layers. That means that a single\n+graph of layers can be used to generate multiple models.\n+\n+In the example below, you use the same stack of layers to instantiate two models:\n+an `encoder` model that turns image inputs into 16-dimensional vectors,\n+and an end-to-end `autoencoder` model for training.\n+\"\"\"\n+\n+encoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n+x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n+x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n+x = layers.MaxPooling2D(3)(x)\n+x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n+x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n+encoder_output = layers.GlobalMaxPooling2D()(x)\n+\n+encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n+encoder.summary()\n+\n+x = layers.Reshape((4, 4, 1))(encoder_output)\n+x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n+x = layers.Conv2DTranspose(32, 3, activation=\"relu\")(x)\n+x = layers.UpSampling2D(3)(x)\n+x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n+decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(x)\n+\n+autoencoder = keras.Model(encoder_input, decoder_output, name=\"autoencoder\")\n+autoencoder.summary()\n+\n+\"\"\"\n+Here, the decoding architecture is strictly symmetrical\n+to the encoding architecture, so the output shape is the same as\n+the input shape `(28, 28, 1)`.\n+\n+The reverse of a `Conv2D` layer is a `Conv2DTranspose` layer,\n+and the reverse of a `MaxPooling2D` layer is an `UpSampling2D` layer.\n+\"\"\"\n+\n+\"\"\"\n+## All models are callable, just like layers\n+\n+You can treat any model as if it were a layer by invoking it on an `Input` or\n+on the output of another layer. By calling a model you aren't just reusing\n+the architecture of the model, you're also reusing its weights.\n+\n+To see this in action, here's a different take on the autoencoder example that\n+creates an encoder model, a decoder model, and chains them in two calls\n+to obtain the autoencoder model:\n+\"\"\"\n+\n+encoder_input = keras.Input(shape=(28, 28, 1), name=\"original_img\")\n+x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n+x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n+x = layers.MaxPooling2D(3)(x)\n+x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n+x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n+encoder_output = layers.GlobalMaxPooling2D()(x)\n+\n+encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n+encoder.summary()\n+\n+decoder_input = keras.Input(shape=(16,), name=\"encoded_img\")\n+x = layers.Reshape((4, 4, 1))(decoder_input)\n+x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n+x = layers.Conv2DTranspose(32, 3, activation=\"relu\")(x)\n+x = layers.UpSampling2D(3)(x)\n+x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n+decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(x)\n+\n+decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n+decoder.summary()\n+\n+autoencoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n+encoded_img = encoder(autoencoder_input)\n+decoded_img = decoder(encoded_img)\n+autoencoder = keras.Model(autoencoder_input, decoded_img, name=\"autoencoder\")\n+autoencoder.summary()\n+\n+\"\"\"\n+As you can see, the model can be nested: a model can contain sub-models\n+(since a model is just like a layer).\n+A common use case for model nesting is *ensembling*.\n+For example, here's how to ensemble a set of models into a single model\n+that averages their predictions:\n+\"\"\"\n+\n+\n+def get_model():\n+    inputs = keras.Input(shape=(128,))\n+    outputs = layers.Dense(1)(inputs)\n+    return keras.Model(inputs, outputs)\n+\n+\n+model1 = get_model()\n+model2 = get_model()\n+model3 = get_model()\n+\n+inputs = keras.Input(shape=(128,))\n+y1 = model1(inputs)\n+y2 = model2(inputs)\n+y3 = model3(inputs)\n+outputs = layers.average([y1, y2, y3])\n+ensemble_model = keras.Model(inputs=inputs, outputs=outputs)\n+\n+\"\"\"\n+## Manipulate complex graph topologies\n+\n+### Models with multiple inputs and outputs\n+\n+The functional API makes it easy to manipulate multiple inputs and outputs.\n+This cannot be handled with the `Sequential` API.\n+\n+For example, if you're building a system for ranking customer issue tickets by\n+priority and routing them to the correct department,\n+then the model will have three inputs:\n+\n+- the title of the ticket (text input),\n+- the text body of the ticket (text input), and\n+- any tags added by the user (categorical input)\n+\n+This model will have two outputs:\n+\n+- the priority score between 0 and 1 (scalar sigmoid output), and\n+- the department that should handle the ticket (softmax output\n+over the set of departments).\n+\n+You can build this model in a few lines with the functional API:\n+\"\"\"\n+\n+num_tags = 12  # Number of unique issue tags\n+num_words = 10000  # Size of vocabulary obtained when preprocessing text data\n+num_departments = 4  # Number of departments for predictions\n+\n+title_input = keras.Input(\n+    shape=(None,), name=\"title\"\n+)  # Variable-length sequence of ints\n+body_input = keras.Input(\n+    shape=(None,), name=\"body\"\n+)  # Variable-length sequence of ints\n+tags_input = keras.Input(\n+    shape=(num_tags,), name=\"tags\"\n+)  # Binary vectors of size `num_tags`\n+\n+# Embed each word in the title into a 64-dimensional vector\n+title_features = layers.Embedding(num_words, 64)(title_input)\n+# Embed each word in the text into a 64-dimensional vector\n+body_features = layers.Embedding(num_words, 64)(body_input)\n+\n+# Reduce sequence of embedded words in the title into a single 128-dimensional vector\n+title_features = layers.LSTM(128)(title_features)\n+# Reduce sequence of embedded words in the body into a single 32-dimensional vector\n+body_features = layers.LSTM(32)(body_features)\n+\n+# Merge all available features into a single large vector via concatenation\n+x = layers.concatenate([title_features, body_features, tags_input])\n+\n+# Stick a logistic regression for priority prediction on top of the features\n+priority_pred = layers.Dense(1, name=\"priority\")(x)\n+# Stick a department classifier on top of the features\n+department_pred = layers.Dense(num_departments, name=\"department\")(x)\n+\n+# Instantiate an end-to-end model predicting both priority and department\n+model = keras.Model(\n+    inputs=[title_input, body_input, tags_input],\n+    outputs={\"priority\": priority_pred, \"department\": department_pred},\n+)\n+\n+\"\"\"\n+Now plot the model:\n+\"\"\"\n+\n+keras.utils.plot_model(\n+    model, \"multi_input_and_output_model.png\", show_shapes=True\n+)\n+\n+\"\"\"\n+When compiling this model, you can assign different losses to each output.\n+You can even assign different weights to each loss -- to modulate\n+their contribution to the total training loss.\n+\"\"\"\n+\n+model.compile(\n+    optimizer=keras.optimizers.RMSprop(1e-3),\n+    loss=[\n+        keras.losses.BinaryCrossentropy(from_logits=True),\n+        keras.losses.CategoricalCrossentropy(from_logits=True),\n+    ],\n+    loss_weights=[1.0, 0.2],\n+)\n+\n+\"\"\"\n+Since the output layers have different names, you could also specify\n+the losses and loss weights with the corresponding layer names:\n+\"\"\"\n+\n+model.compile(\n+    optimizer=keras.optimizers.RMSprop(1e-3),\n+    loss={\n+        \"priority\": keras.losses.BinaryCrossentropy(from_logits=True),\n+        \"department\": keras.losses.CategoricalCrossentropy(from_logits=True),\n+    },\n+    loss_weights={\"priority\": 1.0, \"department\": 0.2},\n+)\n+\n+\"\"\"\n+Train the model by passing lists of NumPy arrays of inputs and targets:\n+\"\"\"\n+\n+# Dummy input data\n+title_data = np.random.randint(num_words, size=(1280, 10))\n+body_data = np.random.randint(num_words, size=(1280, 100))\n+tags_data = np.random.randint(2, size=(1280, num_tags)).astype(\"float32\")\n+\n+# Dummy target data\n+priority_targets = np.random.random(size=(1280, 1))\n+dept_targets = np.random.randint(2, size=(1280, num_departments))\n+\n+model.fit(\n+    {\"title\": title_data, \"body\": body_data, \"tags\": tags_data},\n+    {\"priority\": priority_targets, \"department\": dept_targets},\n+    epochs=2,\n+    batch_size=32,\n+)\n+\n+\"\"\"\n+When calling fit with a `Dataset` object, it should yield either a\n+tuple of lists like `([title_data, body_data, tags_data], [priority_targets, dept_targets])`\n+or a tuple of dictionaries like\n+`({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets})`.\n+\n+For more detailed explanation, refer to the [training and evaluation](/guides/training_with_built_in_methods/) guide.\n+\"\"\"\n+\n+\"\"\"\n+### A toy ResNet model\n+\n+In addition to models with multiple inputs and outputs,\n+the functional API makes it easy to manipulate non-linear connectivity\n+topologies -- these are models with layers that are not connected sequentially,\n+which the `Sequential` API cannot handle.\n+\n+A common use case for this is residual connections.\n+Let's build a toy ResNet model for CIFAR10 to demonstrate this:\n+\"\"\"\n+\n+inputs = keras.Input(shape=(32, 32, 3), name=\"img\")\n+x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n+x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n+block_1_output = layers.MaxPooling2D(3)(x)\n+\n+x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_1_output)\n+x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n+block_2_output = layers.add([x, block_1_output])\n+\n+x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_2_output)\n+x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n+block_3_output = layers.add([x, block_2_output])\n+\n+x = layers.Conv2D(64, 3, activation=\"relu\")(block_3_output)\n+x = layers.GlobalAveragePooling2D()(x)\n+x = layers.Dense(256, activation=\"relu\")(x)\n+x = layers.Dropout(0.5)(x)\n+outputs = layers.Dense(10)(x)\n+\n+model = keras.Model(inputs, outputs, name=\"toy_resnet\")\n+model.summary()\n+\n+\"\"\"\n+Plot the model:\n+\"\"\"\n+\n+keras.utils.plot_model(model, \"mini_resnet.png\", show_shapes=True)\n+\n+\"\"\"\n+Now train the model:\n+\"\"\"\n+\n+(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n+\n+x_train = x_train.astype(\"float32\") / 255.0\n+x_test = x_test.astype(\"float32\") / 255.0\n+y_train = keras.utils.to_categorical(y_train, 10)\n+y_test = keras.utils.to_categorical(y_test, 10)\n+\n+model.compile(\n+    optimizer=keras.optimizers.RMSprop(1e-3),\n+    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n+    metrics=[\"acc\"],\n+)\n+# We restrict the data to the first 1000 samples so as to limit execution time\n+# on Colab. Try to train on the entire dataset until convergence!\n+model.fit(\n+    x_train[:1000],\n+    y_train[:1000],\n+    batch_size=64,\n+    epochs=1,\n+    validation_split=0.2,\n+)\n+\n+\"\"\"\n+## Shared layers\n+\n+Another good use for the functional API are models that use *shared layers*.\n+Shared layers are layer instances that are reused multiple times in the same model --\n+they learn features that correspond to multiple paths in the graph-of-layers.\n+\n+Shared layers are often used to encode inputs from similar spaces\n+(say, two different pieces of text that feature similar vocabulary).\n+They enable sharing of information across these different inputs,\n+and they make it possible to train such a model on less data.\n+If a given word is seen in one of the inputs,\n+that will benefit the processing of all inputs that pass through the shared layer.\n+\n+To share a layer in the functional API, call the same layer instance multiple times.\n+For instance, here's an `Embedding` layer shared across two different text inputs:\n+\"\"\"\n+\n+# Embedding for 1000 unique words mapped to 128-dimensional vectors\n+shared_embedding = layers.Embedding(1000, 128)\n+\n+# Variable-length sequence of integers\n+text_input_a = keras.Input(shape=(None,), dtype=\"int32\")\n+\n+# Variable-length sequence of integers\n+text_input_b = keras.Input(shape=(None,), dtype=\"int32\")\n+\n+# Reuse the same layer to encode both inputs\n+encoded_input_a = shared_embedding(text_input_a)\n+encoded_input_b = shared_embedding(text_input_b)\n+\n+\"\"\"\n+## Extract and reuse nodes in the graph of layers\n+\n+Because the graph of layers you are manipulating is a static data structure,\n+it can be accessed and inspected. And this is how you are able to plot\n+functional models as images.\n+\n+This also means that you can access the activations of intermediate layers\n+(\"nodes\" in the graph) and reuse them elsewhere --\n+which is very useful for something like feature extraction.\n+\n+Let's look at an example. This is a VGG19 model with weights pretrained on ImageNet:\n+\"\"\"\n+\n+vgg19 = keras.applications.VGG19()\n+\n+\"\"\"\n+And these are the intermediate activations of the model,\n+obtained by querying the graph data structure:\n+\"\"\"\n+\n+features_list = [layer.output for layer in vgg19.layers]\n+\n+\"\"\"\n+Use these features to create a new feature-extraction model that returns\n+the values of the intermediate layer activations:\n+\"\"\"\n+\n+feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list)\n+\n+img = np.random.random((1, 224, 224, 3)).astype(\"float32\")\n+extracted_features = feat_extraction_model(img)\n+\n+\"\"\"\n+This comes in handy for tasks like\n+[neural style transfer](https://keras.io/examples/generative/neural_style_transfer/),\n+among other things.\n+\"\"\"\n+\n+\"\"\"\n+## Extend the API using custom layers\n+\n+`keras` includes a wide range of built-in layers, for example:\n+\n+- Convolutional layers: `Conv1D`, `Conv2D`, `Conv3D`, `Conv2DTranspose`\n+- Pooling layers: `MaxPooling1D`, `MaxPooling2D`, `MaxPooling3D`, `AveragePooling1D`\n+- RNN layers: `GRU`, `LSTM`, `ConvLSTM2D`\n+- `BatchNormalization`, `Dropout`, `Embedding`, etc.\n+\n+But if you don't find what you need, it's easy to extend the API by creating\n+your own layers. All layers subclass the `Layer` class and implement:\n+\n+- `call` method, that specifies the computation done by the layer.\n+- `build` method, that creates the weights of the layer (this is just a style\n+convention since you can create weights in `__init__`, as well).\n+\n+To learn more about creating layers from scratch, read\n+[custom layers and models](/guides/making_new_layers_and_models_via_subclassing) guide.\n+\n+The following is a basic implementation of `keras.layers.Dense`:\n+\"\"\"\n+\n+\n+class CustomDense(layers.Layer):\n+    def __init__(self, units=32):\n+        super().__init__()\n+        self.units = units\n+\n+    def build(self, input_shape):\n+        self.w = self.add_weight(\n+            shape=(input_shape[-1], self.units),\n+            initializer=\"random_normal\",\n+            trainable=True,\n+        )\n+        self.b = self.add_weight(\n+            shape=(self.units,), initializer=\"random_normal\", trainable=True\n+        )\n+\n+    def call(self, inputs):\n+        return ops.matmul(inputs, self.w) + self.b\n+\n+\n+inputs = keras.Input((4,))\n+outputs = CustomDense(10)(inputs)\n+\n+model = keras.Model(inputs, outputs)\n+\n+\"\"\"\n+For serialization support in your custom layer, define a `get_config()`\n+method that returns the constructor arguments of the layer instance:\n+\"\"\"\n+\n+\n+class CustomDense(layers.Layer):\n+    def __init__(self, units=32):\n+        super().__init__()\n+        self.units = units\n+\n+    def build(self, input_shape):\n+        self.w = self.add_weight(\n+            shape=(input_shape[-1], self.units),\n+            initializer=\"random_normal\",\n+            trainable=True,\n+        )\n+        self.b = self.add_weight(\n+            shape=(self.units,), initializer=\"random_normal\", trainable=True\n+        )\n+\n+    def call(self, inputs):\n+        return ops.matmul(inputs, self.w) + self.b\n+\n+    def get_config(self):\n+        return {\"units\": self.units}\n+\n+\n+inputs = keras.Input((4,))\n+outputs = CustomDense(10)(inputs)\n+\n+model = keras.Model(inputs, outputs)\n+config = model.get_config()\n+\n+new_model = keras.Model.from_config(\n+    config, custom_objects={\"CustomDense\": CustomDense}\n+)\n+\n+\"\"\"\n+Optionally, implement the class method `from_config(cls, config)` which is used\n+when recreating a layer instance given its config dictionary.\n+The default implementation of `from_config` is:\n+\n+```python\n+def from_config(cls, config):\n+  return cls(**config)\n+```\n+\"\"\"\n+\n+\"\"\"\n+## When to use the functional API\n+\n+Should you use the Keras functional API to create a new model,\n+or just subclass the `Model` class directly? In general, the functional API\n+is higher-level, easier and safer, and has a number of\n+features that subclassed models do not support.\n+\n+However, model subclassing provides greater flexibility when building models\n+that are not easily expressible as directed acyclic graphs of layers.\n+For example, you could not implement a Tree-RNN with the functional API\n+and would have to subclass `Model` directly.\n+\n+For an in-depth look at the differences between the functional API and\n+model subclassing, read\n+[What are Symbolic and Imperative APIs in TensorFlow 2.0?](https://blog.tensorflow.org/2019/01/what-are-symbolic-and-imperative-apis.html).\n+\n+### Functional API strengths:\n+\n+The following properties are also true for Sequential models\n+(which are also data structures), but are not true for subclassed models\n+(which are Python bytecode, not data structures).\n+\n+#### Less verbose\n+\n+There is no `super().__init__(...)`, no `def call(self, ...):`, etc.\n+\n+Compare:\n+\n+```python\n+inputs = keras.Input(shape=(32,))\n+x = layers.Dense(64, activation='relu')(inputs)\n+outputs = layers.Dense(10)(x)\n+mlp = keras.Model(inputs, outputs)\n+```\n+\n+With the subclassed version:\n+\n+```python\n+class MLP(keras.Model):\n+\n+  def __init__(self, **kwargs):\n+    super().__init__(**kwargs)\n+    self.dense_1 = layers.Dense(64, activation='relu')\n+    self.dense_2 = layers.Dense(10)\n+\n+  def call(self, inputs):\n+    x = self.dense_1(inputs)\n+    return self.dense_2(x)\n+\n+# Instantiate the model.\n+mlp = MLP()\n+# Necessary to create the model's state.\n+# The model doesn't have a state until it's called at least once.\n+_ = mlp(ops.zeros((1, 32)))\n+```\n+\n+#### Model validation while defining its connectivity graph\n+\n+In the functional API, the input specification (shape and dtype) is created\n+in advance (using `Input`). Every time you call a layer,\n+the layer checks that the specification passed to it matches its assumptions,\n+and it will raise a helpful error message if not.\n+\n+This guarantees that any model you can build with the functional API will run.\n+All debugging -- other than convergence-related debugging --\n+happens statically during the model construction and not at execution time.\n+This is similar to type checking in a compiler.\n+\n+#### A functional model is plottable and inspectable\n+\n+You can plot the model as a graph, and you can easily access intermediate nodes\n+in this graph. For example, to extract and reuse the activations of intermediate\n+layers (as seen in a previous example):\n+\n+```python\n+features_list = [layer.output for layer in vgg19.layers]\n+feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list)\n+```\n+\n+#### A functional model can be serialized or cloned\n+\n+Because a functional model is a data structure rather than a piece of code,\n+it is safely serializable and can be saved as a single file\n+that allows you to recreate the exact same model\n+without having access to any of the original code.\n+See the [serialization & saving guide](/guides/serialization_and_saving/).\n+\n+To serialize a subclassed model, it is necessary for the implementer\n+to specify a `get_config()`\n+and `from_config()` method at the model level.\n+\n+\n+### Functional API weakness:\n+\n+#### It does not support dynamic architectures\n+\n+The functional API treats models as DAGs of layers.\n+This is true for most deep learning architectures, but not all -- for example,\n+recursive networks or Tree RNNs do not follow this assumption and cannot\n+be implemented in the functional API.\n+\"\"\"\n+\n+\"\"\"\n+## Mix-and-match API styles\n+\n+Choosing between the functional API or Model subclassing isn't a\n+binary decision that restricts you into one category of models.\n+All models in the `keras` API can interact with each other, whether they're\n+`Sequential` models, functional models, or subclassed models that are written\n+from scratch.\n+\n+You can always use a functional model or `Sequential` model\n+as part of a subclassed model or layer:\n+\"\"\"\n+\n+units = 32\n+timesteps = 10\n+input_dim = 5\n+\n+# Define a Functional model\n+inputs = keras.Input((None, units))\n+x = layers.GlobalAveragePooling1D()(inputs)\n+outputs = layers.Dense(1)(x)\n+model = keras.Model(inputs, outputs)\n+\n+\n+class CustomRNN(layers.Layer):\n+    def __init__(self):\n+        super().__init__()\n+        self.units = units\n+        self.projection_1 = layers.Dense(units=units, activation=\"tanh\")\n+        self.projection_2 = layers.Dense(units=units, activation=\"tanh\")\n+        # Our previously-defined Functional model\n+        self.classifier = model\n+\n+    def call(self, inputs):\n+        outputs = []\n+        state = ops.zeros(shape=(inputs.shape[0], self.units))\n+        for t in range(inputs.shape[1]):\n+            x = inputs[:, t, :]\n+            h = self.projection_1(x)\n+            y = h + self.projection_2(state)\n+            state = y\n+            outputs.append(y)\n+        features = ops.stack(outputs, axis=1)\n+        print(features.shape)\n+        return self.classifier(features)\n+\n+\n+rnn_model = CustomRNN()\n+_ = rnn_model(ops.zeros((1, timesteps, input_dim)))\n+\n+\"\"\"\n+You can use any subclassed layer or model in the functional API\n+as long as it implements a `call` method that follows one of the following patterns:\n+\n+- `call(self, inputs, **kwargs)` --\n+Where `inputs` is a tensor or a nested structure of tensors (e.g. a list of tensors),\n+and where `**kwargs` are non-tensor arguments (non-inputs).\n+- `call(self, inputs, training=None, **kwargs)` --\n+Where `training` is a boolean indicating whether the layer should behave\n+in training mode and inference mode.\n+- `call(self, inputs, mask=None, **kwargs)` --\n+Where `mask` is a boolean mask tensor (useful for RNNs, for instance).\n+- `call(self, inputs, training=None, mask=None, **kwargs)` --\n+Of course, you can have both masking and training-specific behavior at the same time.\n+\n+Additionally, if you implement the `get_config` method on your custom Layer or model,\n+the functional models you create will still be serializable and cloneable.\n+\n+Here's a quick example of a custom RNN, written from scratch,\n+being used in a functional model:\n+\"\"\"\n+\n+units = 32\n+timesteps = 10\n+input_dim = 5\n+batch_size = 16\n+\n+\n+class CustomRNN(layers.Layer):\n+    def __init__(self):\n+        super().__init__()\n+        self.units = units\n+        self.projection_1 = layers.Dense(units=units, activation=\"tanh\")\n+        self.projection_2 = layers.Dense(units=units, activation=\"tanh\")\n+        self.classifier = layers.Dense(1)\n+\n+    def call(self, inputs):\n+        outputs = []\n+        state = ops.zeros(shape=(inputs.shape[0], self.units))\n+        for t in range(inputs.shape[1]):\n+            x = inputs[:, t, :]\n+            h = self.projection_1(x)\n+            y = h + self.projection_2(state)\n+            state = y\n+            outputs.append(y)\n+        features = ops.stack(outputs, axis=1)\n+        return self.classifier(features)\n+\n+\n+# Note that you specify a static batch size for the inputs with the `batch_shape`\n+# arg, because the inner computation of `CustomRNN` requires a static batch size\n+# (when you create the `state` zeros tensor).\n+inputs = keras.Input(batch_shape=(batch_size, timesteps, input_dim))\n+x = layers.Conv1D(32, 3)(inputs)\n+outputs = CustomRNN()(x)\n+\n+model = keras.Model(inputs, outputs)\n+\n+rnn_model = CustomRNN()\n+_ = rnn_model(ops.zeros((1, 10, 5)))\n\n@@ -0,0 +1,370 @@\n+\"\"\"\n+Title: The Sequential model\n+Author: [fchollet](https://twitter.com/fchollet)\n+Date created: 2020/04/12\n+Last modified: 2020/04/12\n+Description: Complete guide to the Sequential model.\n+Accelerator: GPU\n+\"\"\"\n+\"\"\"\n+## Setup\n+\n+\"\"\"\n+\n+import keras_core as keras\n+from keras_core import layers\n+from keras_core import operations as ops\n+\n+\"\"\"\n+## When to use a Sequential model\n+\n+A `Sequential` model is appropriate for **a plain stack of layers**\n+where each layer has **exactly one input tensor and one output tensor**.\n+\n+Schematically, the following `Sequential` model:\n+\"\"\"\n+\n+# Define Sequential model with 3 layers\n+model = keras.Sequential(\n+    [\n+        layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n+        layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n+        layers.Dense(4, name=\"layer3\"),\n+    ]\n+)\n+# Call model on a test input\n+x = ops.ones((3, 3))\n+y = model(x)\n+\n+\"\"\"\n+is equivalent to this function:\n+\"\"\"\n+\n+# Create 3 layers\n+layer1 = layers.Dense(2, activation=\"relu\", name=\"layer1\")\n+layer2 = layers.Dense(3, activation=\"relu\", name=\"layer2\")\n+layer3 = layers.Dense(4, name=\"layer3\")\n+\n+# Call layers on a test input\n+x = ops.ones((3, 3))\n+y = layer3(layer2(layer1(x)))\n+\n+\"\"\"\n+A Sequential model is **not appropriate** when:\n+\n+- Your model has multiple inputs or multiple outputs\n+- Any of your layers has multiple inputs or multiple outputs\n+- You need to do layer sharing\n+- You want non-linear topology (e.g. a residual connection, a multi-branch\n+model)\n+\"\"\"\n+\n+\"\"\"\n+## Creating a Sequential model\n+\n+You can create a Sequential model by passing a list of layers to the Sequential\n+constructor:\n+\"\"\"\n+\n+model = keras.Sequential(\n+    [\n+        layers.Dense(2, activation=\"relu\"),\n+        layers.Dense(3, activation=\"relu\"),\n+        layers.Dense(4),\n+    ]\n+)\n+\n+\"\"\"\n+Its layers are accessible via the `layers` attribute:\n+\"\"\"\n+\n+model.layers\n+\n+\"\"\"\n+You can also create a Sequential model incrementally via the `add()` method:\n+\"\"\"\n+\n+model = keras.Sequential()\n+model.add(layers.Dense(2, activation=\"relu\"))\n+model.add(layers.Dense(3, activation=\"relu\"))\n+model.add(layers.Dense(4))\n+\n+\"\"\"\n+Note that there's also a corresponding `pop()` method to remove layers:\n+a Sequential model behaves very much like a list of layers.\n+\"\"\"\n+\n+model.pop()\n+print(len(model.layers))  # 2\n+\n+\"\"\"\n+Also note that the Sequential constructor accepts a `name` argument, just like\n+any layer or model in Keras. This is useful to annotate TensorBoard graphs\n+with semantically meaningful names.\n+\"\"\"\n+\n+model = keras.Sequential(name=\"my_sequential\")\n+model.add(layers.Dense(2, activation=\"relu\", name=\"layer1\"))\n+model.add(layers.Dense(3, activation=\"relu\", name=\"layer2\"))\n+model.add(layers.Dense(4, name=\"layer3\"))\n+\n+\"\"\"\n+## Specifying the input shape in advance\n+\n+Generally, all layers in Keras need to know the shape of their inputs\n+in order to be able to create their weights. So when you create a layer like\n+this, initially, it has no weights:\n+\"\"\"\n+\n+layer = layers.Dense(3)\n+layer.weights  # Empty\n+\n+\"\"\"\n+It creates its weights the first time it is called on an input, since the shape\n+of the weights depends on the shape of the inputs:\n+\"\"\"\n+\n+# Call layer on a test input\n+x = ops.ones((1, 4))\n+y = layer(x)\n+layer.weights  # Now it has weights, of shape (4, 3) and (3,)\n+\n+\"\"\"\n+Naturally, this also applies to Sequential models. When you instantiate a\n+Sequential model without an input shape, it isn't \"built\": it has no weights\n+(and calling\n+`model.weights` results in an error stating just this). The weights are created\n+when the model first sees some input data:\n+\"\"\"\n+\n+model = keras.Sequential(\n+    [\n+        layers.Dense(2, activation=\"relu\"),\n+        layers.Dense(3, activation=\"relu\"),\n+        layers.Dense(4),\n+    ]\n+)  # No weights at this stage!\n+\n+# At this point, you can't do this:\n+# model.weights\n+\n+# You also can't do this:\n+# model.summary()\n+\n+# Call the model on a test input\n+x = ops.ones((1, 4))\n+y = model(x)\n+print(\"Number of weights after calling the model:\", len(model.weights))  # 6\n+\n+\"\"\"\n+Once a model is \"built\", you can call its `summary()` method to display its\n+contents:\n+\"\"\"\n+\n+model.summary()\n+\n+\"\"\"\n+However, it can be very useful when building a Sequential model incrementally\n+to be able to display the summary of the model so far, including the current\n+output shape. In this case, you should start your model by passing an `Input`\n+object to your model, so that it knows its input shape from the start:\n+\"\"\"\n+\n+model = keras.Sequential()\n+model.add(keras.Input(shape=(4,)))\n+model.add(layers.Dense(2, activation=\"relu\"))\n+\n+model.summary()\n+\n+\"\"\"\n+Note that the `Input` object is not displayed as part of `model.layers`, since\n+it isn't a layer:\n+\"\"\"\n+\n+model.layers\n+\n+\"\"\"\n+Models built with a predefined input shape like this always have weights (even\n+before seeing any data) and always have a defined output shape.\n+\n+In general, it's a recommended best practice to always specify the input shape\n+of a Sequential model in advance if you know what it is.\n+\"\"\"\n+\n+\"\"\"\n+## A common debugging workflow: `add()` + `summary()`\n+\n+When building a new Sequential architecture, it's useful to incrementally stack\n+layers with `add()` and frequently print model summaries. For instance, this\n+enables you to monitor how a stack of `Conv2D` and `MaxPooling2D` layers is\n+downsampling image feature maps:\n+\"\"\"\n+\n+model = keras.Sequential()\n+model.add(keras.Input(shape=(250, 250, 3)))  # 250x250 RGB images\n+model.add(layers.Conv2D(32, 5, strides=2, activation=\"relu\"))\n+model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n+model.add(layers.MaxPooling2D(3))\n+\n+# Can you guess what the current output shape is at this point? Probably not.\n+# Let's just print it:\n+model.summary()\n+\n+# The answer was: (40, 40, 32), so we can keep downsampling...\n+\n+model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n+model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n+model.add(layers.MaxPooling2D(3))\n+model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n+model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n+model.add(layers.MaxPooling2D(2))\n+\n+# And now?\n+model.summary()\n+\n+# Now that we have 4x4 feature maps, time to apply global max pooling.\n+model.add(layers.GlobalMaxPooling2D())\n+\n+# Finally, we add a classification layer.\n+model.add(layers.Dense(10))\n+\n+\"\"\"\n+Very practical, right?\n+\n+\n+\"\"\"\n+\n+\"\"\"\n+## What to do once you have a model\n+\n+Once your model architecture is ready, you will want to:\n+\n+- Train your model, evaluate it, and run inference. See our\n+[guide to training & evaluation with the built-in loops](\n+    /guides/training_with_built_in_methods/)\n+- Save your model to disk and restore it. See our\n+[guide to serialization & saving](/guides/serialization_and_saving/).\n+- Speed up model training by leveraging multiple GPUs. See our\n+[guide to multi-GPU and distributed training](https://keras.io/guides/distributed_training/).\n+\"\"\"\n+\n+\"\"\"\n+## Feature extraction with a Sequential model\n+\n+Once a Sequential model has been built, it behaves like a [Functional API\n+model](/guides/functional_api/). This means that every layer has an `input`\n+and `output` attribute. These attributes can be used to do neat things, like\n+quickly\n+creating a model that extracts the outputs of all intermediate layers in a\n+Sequential model:\n+\"\"\"\n+\n+initial_model = keras.Sequential(\n+    [\n+        keras.Input(shape=(250, 250, 3)),\n+        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n+        layers.Conv2D(32, 3, activation=\"relu\"),\n+        layers.Conv2D(32, 3, activation=\"relu\"),\n+    ]\n+)\n+feature_extractor = keras.Model(\n+    inputs=initial_model.inputs,\n+    outputs=[layer.output for layer in initial_model.layers],\n+)\n+\n+# Call feature extractor on test input.\n+x = ops.ones((1, 250, 250, 3))\n+features = feature_extractor(x)\n+\n+\"\"\"\n+Here's a similar example that only extract features from one layer:\n+\"\"\"\n+\n+initial_model = keras.Sequential(\n+    [\n+        keras.Input(shape=(250, 250, 3)),\n+        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n+        layers.Conv2D(32, 3, activation=\"relu\", name=\"my_intermediate_layer\"),\n+        layers.Conv2D(32, 3, activation=\"relu\"),\n+    ]\n+)\n+feature_extractor = keras.Model(\n+    inputs=initial_model.inputs,\n+    outputs=initial_model.get_layer(name=\"my_intermediate_layer\").output,\n+)\n+# Call feature extractor on test input.\n+x = ops.ones((1, 250, 250, 3))\n+features = feature_extractor(x)\n+\n+\"\"\"\n+## Transfer learning with a Sequential model\n+\n+Transfer learning consists of freezing the bottom layers in a model and only training\n+the top layers. If you aren't familiar with it, make sure to read our [guide\n+to transfer learning](/guides/transfer_learning/).\n+\n+Here are two common transfer learning blueprint involving Sequential models.\n+\n+First, let's say that you have a Sequential model, and you want to freeze all\n+layers except the last one. In this case, you would simply iterate over\n+`model.layers` and set `layer.trainable = False` on each layer, except the\n+last one. Like this:\n+\n+```python\n+model = keras.Sequential([\n+    keras.Input(shape=(784)),\n+    layers.Dense(32, activation='relu'),\n+    layers.Dense(32, activation='relu'),\n+    layers.Dense(32, activation='relu'),\n+    layers.Dense(10),\n+])\n+\n+# Presumably you would want to first load pre-trained weights.\n+model.load_weights(...)\n+\n+# Freeze all layers except the last one.\n+for layer in model.layers[:-1]:\n+  layer.trainable = False\n+\n+# Recompile and train (this will only update the weights of the last layer).\n+model.compile(...)\n+model.fit(...)\n+```\n+\n+Another common blueprint is to use a Sequential model to stack a pre-trained\n+model and some freshly initialized classification layers. Like this:\n+\n+```python\n+# Load a convolutional base with pre-trained weights\n+base_model = keras.applications.Xception(\n+    weights='imagenet',\n+    include_top=False,\n+    pooling='avg')\n+\n+# Freeze the base model\n+base_model.trainable = False\n+\n+# Use a Sequential model to add a trainable classifier on top\n+model = keras.Sequential([\n+    base_model,\n+    layers.Dense(1000),\n+])\n+\n+# Compile & train\n+model.compile(...)\n+model.fit(...)\n+```\n+\n+If you do transfer learning, you will probably find yourself frequently using\n+these two patterns.\n+\"\"\"\n+\n+\"\"\"\n+That's about all you need to know about Sequential models!\n+\n+To find out more about building models in Keras, see:\n+\n+- [Guide to the Functional API](/guides/functional_api/)\n+- [Guide to making new Layers & Models via subclassing](\n+    /guides/making_new_layers_and_models_via_subclassing/)\n+\"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
