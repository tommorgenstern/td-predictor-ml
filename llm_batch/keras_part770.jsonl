{"custom_id": "keras#cd86342448f37410542c9398d09bcb45b16b4899", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 11 | Contributors (this commit): 1 | Commits (past 90d): 4 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -1,7 +1,7 @@\n from keras.api_export import keras_export\n \n # Unique source of truth for the version number.\n-__version__ = \"3.0.0\"\n+__version__ = \"3.0.1\"\n \n \n @keras_export(\"keras.version\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d09e73d203be274b5a3d5aec351f66e92b9b28e9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 23 | Files Changed: 1 | Hunks: 9 | Methods Changed: 3 | Complexity Δ (Sum/Max): -5/0 | Churn Δ: 25 | Churn Cumulative: 42 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: 0.13333333333333333\n\nDIFF:\n@@ -441,7 +441,6 @@ def rnn(\n     return last_output, outputs, new_states\n \n \n-@tf.function\n def gru(\n     inputs,\n     initial_state,\n@@ -457,7 +456,6 @@ def gru(\n     time_major=False,\n     reset_after=True,\n ):\n-    inputs_supported = _do_rnn_inputs_support_cudnn(mask, time_major)\n     cudnn_supported = cudnn_ok(\n         activation,\n         recurrent_activation,\n@@ -465,7 +463,7 @@ def gru(\n         use_bias=bias is not None,\n         reset_after=reset_after,\n     )\n-    if not cudnn_supported or not inputs_supported:\n+    if not cudnn_supported or mask is not None:\n         raise NotImplementedError\n \n     from keras.backend.tensorflow import Variable\n@@ -535,21 +533,6 @@ def _do_lstm_arguments_support_cudnn(\n     )\n \n \n-def _do_rnn_inputs_support_cudnn(mask, time_major):\n-    if tf.sysconfig.get_build_info()[\"is_rocm_build\"]:\n-        if mask is not None:\n-            return tf.reduce_all(mask)\n-        return True\n-    if mask is None:\n-        return True\n-    if time_major:\n-        mask = tf.transpose(mask)\n-    return tf.logical_and(\n-        _is_sequence_right_padded(mask),\n-        tf.logical_not(_has_fully_masked_sequence(mask)),\n-    )\n-\n-\n def _is_sequence_right_padded(mask):\n     \"\"\"Check the mask tensor and see if it right padded.\n \n@@ -655,7 +638,6 @@ def _is_gpu_available():\n     return bool(tf.config.list_logical_devices(\"GPU\"))\n \n \n-@tf.function(autograph=False)\n def _cudnn_gru(\n     inputs,\n     initial_state,\n@@ -802,7 +784,6 @@ def cudnn_ok(\n     return args_supported and _is_gpu_available()\n \n \n-@tf.function\n def lstm(\n     inputs,\n     initial_state_h,\n@@ -818,11 +799,10 @@ def lstm(\n     unroll=False,\n     time_major=False,\n ):\n-    inputs_supported = _do_rnn_inputs_support_cudnn(mask, time_major)\n     cudnn_supported = cudnn_ok(\n         activation, recurrent_activation, unroll, use_bias=bias is not None\n     )\n-    if not cudnn_supported or not inputs_supported:\n+    if not cudnn_supported or mask is not None:\n         raise NotImplementedError\n \n     from keras.backend.tensorflow import Variable\n@@ -855,7 +835,6 @@ def lstm(\n         raise NotImplementedError\n \n \n-@tf.function(autograph=False)\n def _cudnn_lstm(\n     inputs,\n     initial_state_h,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0049b35f1da169e9bbca04c650ecad1eb28c0e53", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 54 | Lines Deleted: 11 | Files Changed: 2 | Hunks: 11 | Methods Changed: 4 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 65 | Churn Cumulative: 3712 | Contributors (this commit): 10 | Commits (past 90d): 4 | Contributors (cumulative): 18 | DMM Complexity: 1.0\n\nDIFF:\n@@ -222,14 +222,15 @@ class Bidirectional(Wrapper):\n         y_rev = self.backward_layer(\n             backward_inputs, initial_state=backward_state, **kwargs\n         )\n-        y = ops.cast(y, self.compute_dtype)\n-        y_rev = ops.cast(y_rev, self.compute_dtype)\n \n         if self.return_state:\n-            states = y[1:] + y_rev[1:]\n+            states = tuple(y[1:] + y_rev[1:])\n             y = y[0]\n             y_rev = y_rev[0]\n \n+        y = ops.cast(y, self.compute_dtype)\n+        y_rev = ops.cast(y_rev, self.compute_dtype)\n+\n         if self.return_sequences:\n             y_rev = ops.flip(y_rev, axis=1)\n         if self.merge_mode == \"concat\":\n@@ -241,7 +242,7 @@ class Bidirectional(Wrapper):\n         elif self.merge_mode == \"mul\":\n             output = y * y_rev\n         elif self.merge_mode is None:\n-            output = [y, y_rev]\n+            output = (y, y_rev)\n         else:\n             raise ValueError(\n                 \"Unrecognized value for `merge_mode`. \"\n@@ -251,7 +252,7 @@ class Bidirectional(Wrapper):\n         if self.return_state:\n             if self.merge_mode is None:\n                 return output + states\n-            return [output] + states\n+            return (output,) + states\n         return output\n \n     def reset_states(self):\n@@ -264,6 +265,12 @@ class Bidirectional(Wrapper):\n         self.forward_layer.reset_state()\n         self.backward_layer.reset_state()\n \n+    @property\n+    def states(self):\n+        if self.forward_layer.states and self.backward_layer.states:\n+            return tuple(self.forward_layer.states + self.backward_layer.states)\n+        return None\n+\n     def build(self, sequences_shape, initial_state_shape=None):\n         self.forward_layer.build(sequences_shape)\n         self.backward_layer.build(sequences_shape)\n@@ -274,18 +281,17 @@ class Bidirectional(Wrapper):\n             mask = mask[0]\n         if self.return_sequences:\n             if not self.merge_mode:\n-                output_mask = [mask, mask]\n+                output_mask = (mask, mask)\n             else:\n                 output_mask = mask\n         else:\n-            output_mask = [None, None] if not self.merge_mode else None\n+            output_mask = (None, None) if not self.merge_mode else None\n \n-        if self.return_state:\n-            states = self.forward_layer.states\n-            state_mask = [None for _ in states]\n+        if self.return_state and self.states is not None:\n+            state_mask = (None for _ in self.states)\n             if isinstance(output_mask, list):\n                 return output_mask + state_mask * 2\n-            return [output_mask] + state_mask * 2\n+            return (output_mask,) + state_mask * 2\n         return output_mask\n \n     def get_config(self):\n\n@@ -197,3 +197,40 @@ class SimpleRNNTest(testing.TestCase):\n             ),\n             output,\n         )\n+\n+    def test_return_state(self):\n+        sequence = np.arange(24).reshape((2, 4, 3)).astype(\"float32\")\n+        forward_layer = layers.LSTM(\n+            2,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+            return_state=True,\n+        )\n+        layer = layers.Bidirectional(layer=forward_layer)\n+        output, h1, c1, h2, c2 = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.1990008, 0.1990008, 0.12659755, 0.12659755],\n+                    [0.52335435, 0.52335435, 0.44717982, 0.44717982],\n+                ]\n+            ),\n+            output,\n+        )\n+        self.assertAllClose(\n+            np.array([[0.1990008, 0.1990008], [0.52335435, 0.52335435]]),\n+            h1,\n+        )\n+        self.assertAllClose(\n+            np.array([[0.35567185, 0.35567185], [1.0492687, 1.0492687]]),\n+            c1,\n+        )\n+        self.assertAllClose(\n+            np.array([[0.12659755, 0.12659755], [0.44717982, 0.44717982]]),\n+            h2,\n+        )\n+        self.assertAllClose(\n+            np.array([[0.2501858, 0.2501858], [0.941473, 0.941473]]),\n+            c2,\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8954e5e3e509c230a0d54679ec7b5e8ea7d5b132", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 110 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -31,8 +31,19 @@ class RegularizersTest(testing.TestCase):\n     def test_orthogonal_regularizer(self):\n         value = np.random.random((4, 4))\n         x = backend.Variable(value)\n-        regularizers.OrthogonalRegularizer(factor=0.1, mode=\"rows\")(x)\n-        # TODO\n+        y = regularizers.OrthogonalRegularizer(factor=0.1, mode=\"rows\")(x)\n+\n+        l2_norm = np.linalg.norm(value, axis=1, keepdims=True)\n+        inputs = value / l2_norm\n+        self.assertAllClose(\n+            y,\n+            0.1\n+            * 0.5\n+            * np.sum(\n+                np.abs(np.dot(inputs, np.transpose(inputs)) * (1.0 - np.eye(4)))\n+            )\n+            / (4.0 * (4.0 - 1.0) / 2.0),\n+        )\n \n     def test_get_method(self):\n         obj = regularizers.get(\"l1l2\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#10252a9e7d68c6818423deee1c4c8549038e4171", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 63 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 67 | Churn Cumulative: 85 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 5 | DMM Complexity: 0.9545454545454546\n\nDIFF:\n@@ -139,6 +139,7 @@ def get_file(\n     extract=False,\n     archive_format=\"auto\",\n     cache_dir=None,\n+    force_download=False,\n ):\n     \"\"\"Downloads a file from a URL if it not already in the cache.\n \n@@ -187,6 +188,8 @@ def get_file(\n         cache_dir: Location to store cached files, when None it\n             defaults ether `$KERAS_HOME` if the `KERAS_HOME` environment\n             variable is set or `~/.keras/`.\n+        force_download: If `True`, the file will always be re-downloaded\n+            regardless of the cache state.\n \n     Returns:\n         Path to the downloaded file.\n@@ -238,17 +241,19 @@ def get_file(\n     else:\n         fpath = os.path.join(datadir, fname)\n \n+    if force_download:\n+        download = True\n+    elif os.path.exists(fpath):\n+        # File found in cache.\n         download = False\n-    if os.path.exists(fpath):\n-        # File found; verify integrity if a hash was provided.\n+        # Verify integrity if a hash was provided.\n         if file_hash is not None:\n             if not validate_file(fpath, file_hash, algorithm=hash_algorithm):\n                 io_utils.print_msg(\n                     \"A local file was found, but it seems to be \"\n                     f\"incomplete or outdated because the {hash_algorithm} \"\n                     \"file hash does not match the original value of \"\n-                    f\"{file_hash} \"\n-                    \"so we will re-download the data.\"\n+                    f\"{file_hash} so we will re-download the data.\"\n                 )\n                 download = True\n     else:\n\n@@ -378,6 +378,60 @@ class GetFileTest(test_case.TestCase):\n         path = file_utils.get_file(\"test.txt\", origin, file_hash=hashval)\n         self.assertTrue(os.path.exists(path))\n \n+    def test_cache_invalidation(self):\n+        \"\"\"Test using a hash to force cache invalidation.\"\"\"\n+        cache_dir = self.get_temp_dir()\n+        src_path = os.path.join(self.get_temp_dir(), \"test.txt\")\n+        with open(src_path, \"w\") as text_file:\n+            text_file.write(\"Float like a butterfly, sting like a bee.\")\n+        orig_hash = file_utils.hash_file(src_path)\n+        origin = urllib.parse.urljoin(\n+            \"file://\", urllib.request.pathname2url(os.path.abspath(src_path))\n+        )\n+        # Download into the cache.\n+        dest_path = file_utils.get_file(\n+            \"test.txt\", origin, file_hash=orig_hash, cache_dir=cache_dir\n+        )\n+        self.assertEqual(orig_hash, file_utils.hash_file(dest_path))\n+\n+        with open(src_path, \"w\") as text_file:\n+            text_file.write(\"Float like a zeppelin, sting like a jellyfish.\")\n+        new_hash = file_utils.hash_file(src_path)\n+        # Without a hash, we should get the cached version.\n+        dest_path = file_utils.get_file(\"test.txt\", origin, cache_dir=cache_dir)\n+        self.assertEqual(orig_hash, file_utils.hash_file(dest_path))\n+        # Without the new hash, we should re-download.\n+        dest_path = file_utils.get_file(\n+            \"test.txt\", origin, file_hash=new_hash, cache_dir=cache_dir\n+        )\n+        self.assertEqual(new_hash, file_utils.hash_file(dest_path))\n+\n+    def test_force_download(self):\n+        \"\"\"Test using a hash to force cache invalidation.\"\"\"\n+        cache_dir = self.get_temp_dir()\n+        src_path = os.path.join(self.get_temp_dir(), \"test.txt\")\n+        with open(src_path, \"w\") as text_file:\n+            text_file.write(\"Float like a butterfly, sting like a bee.\")\n+        orig_hash = file_utils.hash_file(src_path)\n+        origin = urllib.parse.urljoin(\n+            \"file://\", urllib.request.pathname2url(os.path.abspath(src_path))\n+        )\n+        # Download into the cache.\n+        dest_path = file_utils.get_file(\"test.txt\", origin, cache_dir=cache_dir)\n+        self.assertEqual(orig_hash, file_utils.hash_file(dest_path))\n+\n+        with open(src_path, \"w\") as text_file:\n+            text_file.write(\"Float like a zeppelin, sting like a jellyfish.\")\n+        new_hash = file_utils.hash_file(src_path)\n+        # Get cached version.\n+        dest_path = file_utils.get_file(\"test.txt\", origin, cache_dir=cache_dir)\n+        self.assertEqual(orig_hash, file_utils.hash_file(dest_path))\n+        # Force download.\n+        dest_path = file_utils.get_file(\n+            \"test.txt\", origin, force_download=True, cache_dir=cache_dir\n+        )\n+        self.assertEqual(new_hash, file_utils.hash_file(dest_path))\n+\n     def test_get_file_with_failed_integrity_check(self):\n         \"\"\"Test file download with failed integrity check.\"\"\"\n         orig_dir = self.get_temp_dir()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fea907c5f612a827ddbaa2030a40d8c63a8df1f2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 69 | Files Changed: 3 | Hunks: 10 | Methods Changed: 3 | Complexity Δ (Sum/Max): -10/0 | Churn Δ: 89 | Churn Cumulative: 1164 | Contributors (this commit): 7 | Commits (past 90d): 11 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -7,7 +7,6 @@ from keras import backend\n from keras import utils\n from keras.api_export import keras_export\n from keras.layers.layer import Layer\n-from keras.legacy.saving import legacy_h5_format\n from keras.models.variable_mapping import map_trackable_variables\n from keras.saving import saving_api\n from keras.saving import saving_lib\n@@ -269,13 +268,14 @@ class Model(Trainer, Layer):\n         \"\"\"Saves a model as a `.keras` file.\n \n         Args:\n-            filepath: `str` or `pathlib.Path` object.\n-                Path where to save the model. Must end in `.keras`.\n-            overwrite: Whether we should overwrite any existing model\n-                at the target location, or instead ask the user\n-                via an interactive prompt.\n-            save_format: Format to use, as a string. Only the `\"keras\"`\n-                format is supported at this time.\n+            filepath: `str` or `pathlib.Path` object. Path where to save\n+                the model. Must end in `.keras`.\n+            overwrite: Whether we should overwrite any existing model at\n+                the target location, or instead ask the user via\n+                an interactive prompt.\n+            save_format: The `save_format` argument is deprecated in Keras 3.\n+                Format to use, as a string. Only the `\"keras\"` format is\n+                supported at this time.\n \n         Example:\n \n@@ -292,8 +292,7 @@ class Model(Trainer, Layer):\n         assert np.allclose(model.predict(x), loaded_model.predict(x))\n         ```\n \n-        Note that `model.save()` is an alias for\n-        `keras.saving.save_model()`.\n+        Note that `model.save()` is an alias for `keras.saving.save_model()`.\n \n         The saved `.keras` file contains:\n \n@@ -303,60 +302,7 @@ class Model(Trainer, Layer):\n \n         Thus models can be reinstantiated in the exact same state.\n         \"\"\"\n-        include_optimizer = kwargs.pop(\"include_optimizer\", True)\n-        save_format = kwargs.pop(\"save_format\", None)\n-        if kwargs:\n-            raise ValueError(\n-                \"The following argument(s) are not supported: \"\n-                f\"{list(kwargs.keys())}\"\n-            )\n-        if save_format:\n-            if str(filepath).endswith((\".h5\", \".hdf5\")) or str(\n-                filepath\n-            ).endswith(\".keras\"):\n-                warnings.warn(\n-                    \"The `save_format` argument is deprecated in Keras 3. \"\n-                    \"We recommend removing this argument as it can be inferred \"\n-                    \"from the file path. \"\n-                    f\"Received: save_format={save_format}\"\n-                )\n-            else:\n-                raise ValueError(\n-                    \"The `save_format` argument is deprecated in Keras 3. \"\n-                    \"Please remove this argument and pass a file path with \"\n-                    \"either `.keras` or `.h5` extension.\"\n-                    f\"Received: save_format={save_format}\"\n-                )\n-        try:\n-            exists = os.path.exists(filepath)\n-        except TypeError:\n-            exists = False\n-        if exists and not overwrite:\n-            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n-            if not proceed:\n-                return\n-        if str(filepath).endswith(\".keras\"):\n-            saving_lib.save_model(self, filepath)\n-        elif str(filepath).endswith((\".h5\", \".hdf5\")):\n-            # Deprecation warnings\n-            warnings.warn(\n-                \"You are saving your model as an HDF5 file via `model.save()`. \"\n-                \"This file format is considered legacy. \"\n-                \"We recommend using instead the native Keras format, \"\n-                \"e.g. `model.save('my_model.keras')`.\"\n-            )\n-            legacy_h5_format.save_model_to_hdf5(\n-                self, filepath, overwrite, include_optimizer\n-            )\n-        else:\n-            raise ValueError(\n-                \"Invalid filepath extension for saving. \"\n-                \"Please add either a `.keras` extension for the native Keras \"\n-                f\"format (recommended) or a `.h5` extension. \"\n-                \"Use `tf.saved_model.save()` if you want to export a \"\n-                \"SavedModel for use with TFLite/TFServing/etc. \"\n-                f\"Received: filepath={filepath}.\"\n-            )\n+        return saving_api.save_model(self, filepath, overwrite, **kwargs)\n \n     @traceback_utils.filter_traceback\n     def save_weights(self, filepath, overwrite=True):\n\n@@ -78,13 +78,14 @@ def save_model(model, filepath, overwrite=True, **kwargs):\n     # Deprecation warnings\n     if str(filepath).endswith((\".h5\", \".hdf5\")):\n         logging.warning(\n-            \"You are saving your model as an HDF5 file via `model.save()`. \"\n+            \"You are saving your model as an HDF5 file via \"\n+            \"`model.save()` or `keras.saving.save_model(model)`. \"\n             \"This file format is considered legacy. \"\n             \"We recommend using instead the native Keras format, \"\n-            \"e.g. `model.save('my_model.keras')`.\"\n+            \"e.g. `model.save('my_model.keras')` or \"\n+            \"`keras.saving.save_model(model, 'my_model.keras')`. \"\n         )\n \n-    if str(filepath).endswith(\".keras\"):\n     # If file exists and should not be overwritten.\n     try:\n         exists = os.path.exists(filepath)\n@@ -94,6 +95,8 @@ def save_model(model, filepath, overwrite=True, **kwargs):\n         proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n         if not proceed:\n             return\n+\n+    if str(filepath).endswith(\".keras\"):\n         saving_lib.save_model(model, filepath)\n     elif str(filepath).endswith((\".h5\", \".hdf5\")):\n         legacy_h5_format.save_model_to_hdf5(\n\n@@ -171,8 +171,10 @@ class SaveModelTestsWarning(test_case.TestCase):\n         with mock.patch.object(logging, \"warning\") as mock_warn:\n             saving_api.save_model(model, filepath)\n             mock_warn.assert_called_once_with(\n-                \"You are saving your model as an HDF5 file via `model.save()`. \"\n+                \"You are saving your model as an HDF5 file via \"\n+                \"`model.save()` or `keras.saving.save_model(model)`. \"\n                 \"This file format is considered legacy. \"\n                 \"We recommend using instead the native Keras format, \"\n-                \"e.g. `model.save('my_model.keras')`.\"\n+                \"e.g. `model.save('my_model.keras')` or \"\n+                \"`keras.saving.save_model(model, 'my_model.keras')`. \"\n             )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ec49bc1be737cd4170093f44fb7b76251a3a35dd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 14 | Churn Cumulative: 124 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -6,8 +6,20 @@ from keras import testing\n from keras.regularizers.regularizers import validate_float_arg\n \n \n-# TODO: serialization tests\n class RegularizersTest(testing.TestCase):\n+    def test_config(self):\n+        reg = regularizers.L1(0.1)\n+        self.run_class_serialization_test(reg)\n+\n+        reg = regularizers.L2(0.1)\n+        self.run_class_serialization_test(reg)\n+\n+        reg = regularizers.L1L2(l1=0.1, l2=0.2)\n+        self.run_class_serialization_test(reg)\n+\n+        reg = regularizers.OrthogonalRegularizer(factor=0.1, mode=\"rows\")\n+        self.run_class_serialization_test(reg)\n+\n     def test_l1(self):\n         value = np.random.random((4, 4))\n         x = backend.Variable(value)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6ad6f9b0075a252d497005911462ab7a31d6062f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 32 | Churn Cumulative: 48 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -4,6 +4,34 @@ from keras.backend.common import global_state\n \n @keras_export(\"keras.StatelessScope\")\n class StatelessScope:\n+    \"\"\"Scope to prevent any update to Keras Variables.\n+\n+    The values of variables to be used inside the scope\n+    should be passed via the `state_mapping` argument, a\n+    list of tuples `(k, v)` where `k` is a `KerasVariable`\n+    and `v` is the intended value for this variable\n+    (a backend tensor).\n+\n+    Updated values can be collected on scope exit via\n+    `value = scope.get_current_value(variable)`. No updates\n+    will be applied in-place to any variables for the duration\n+    of the scope.\n+\n+    Example:\n+\n+    ```python\n+    state_mapping = [(k, ops.ones(k.shape, k.dtype)) for k in model.weights]\n+    with keras.StatelessScope(state_mapping) as scope:\n+        outputs = model.some_function(inputs)\n+\n+    # All model variables remain unchanged. Their new values can be\n+    # collected via:\n+    for k in model.weights:\n+        new_value = scope.get_current_value(k)\n+        print(f\"New value for {k}: {new_value})\n+    ```\n+    \"\"\"\n+\n     def __init__(\n         self,\n         state_mapping=None,\n@@ -21,14 +49,14 @@ class StatelessScope:\n         for k, v in state_mapping:\n             if not isinstance(k, KerasVariable):\n                 raise ValueError(\n-                    \"Invalid reference variable in VariableSwapScope: \"\n+                    \"Invalid reference variable in StatelessScope: \"\n                     \"all keys in argument `mapping` must be KerasVariable \"\n                     f\"instances. Received instead: {k}\"\n                 )\n             v = backend.convert_to_tensor(v, dtype=k.dtype)\n             if k.shape != v.shape:\n                 raise ValueError(\n-                    \"Invalid variable value in VariableSwapScope: \"\n+                    \"Invalid variable value in StatelessScope: \"\n                     \"all values in argument `mapping` must be tensors with \"\n                     \"a shape that matches the corresponding variable shape. \"\n                     f\"For variable {k}, received invalid value {v} with shape \"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4e89ad4c14dfaef77439116a6c45588de3e8b679", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 63 | Lines Deleted: 1 | Files Changed: 7 | Hunks: 14 | Methods Changed: 7 | Complexity Δ (Sum/Max): 5/1 | Churn Δ: 64 | Churn Cumulative: 4817 | Contributors (this commit): 21 | Commits (past 90d): 33 | Contributors (cumulative): 43 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3,6 +3,7 @@ import pytest\n from absl.testing import parameterized\n from numpy.lib.stride_tricks import as_strided\n \n+from keras import constraints\n from keras import layers\n from keras import testing\n \n@@ -783,3 +784,19 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             groups=groups,\n         )\n         self.assertAllClose(outputs, expected, rtol=5e-4)\n+\n+    def test_conv_constraints(self):\n+        layer = layers.Conv2D(\n+            filters=4,\n+            kernel_size=3,\n+            kernel_constraint=\"non_neg\",\n+        )\n+        layer.build((None, 5, 5, 3))\n+        self.assertIsInstance(layer.kernel.constraint, constraints.NonNeg)\n+        layer = layers.Conv2D(\n+            filters=4,\n+            kernel_size=3,\n+            bias_constraint=\"non_neg\",\n+        )\n+        layer.build((None, 5, 5, 3))\n+        self.assertIsInstance(layer.bias.constraint, constraints.NonNeg)\n\n@@ -91,6 +91,7 @@ class Dense(Layer):\n             shape=(input_dim, self.units),\n             initializer=self.kernel_initializer,\n             regularizer=self.kernel_regularizer,\n+            constraint=self.kernel_constraint,\n         )\n         if self.use_bias:\n             self.bias = self.add_weight(\n@@ -98,6 +99,7 @@ class Dense(Layer):\n                 shape=(self.units,),\n                 initializer=self.bias_initializer,\n                 regularizer=self.bias_regularizer,\n+                constraint=self.bias_constraint,\n             )\n         else:\n             self.bias = None\n\n@@ -2,6 +2,7 @@ import numpy as np\n import pytest\n \n from keras import backend\n+from keras import constraints\n from keras import layers\n from keras import testing\n from keras.backend.common import keras_tensor\n@@ -167,3 +168,11 @@ class DenseTest(testing.TestCase):\n         output = layer(inputs)\n         expected_output = np.array([[5.0, 0.0]])\n         self.assertAllClose(output, expected_output)\n+\n+    def test_dense_constraints(self):\n+        layer = layers.Dense(units=2, kernel_constraint=\"non_neg\")\n+        layer.build((None, 2))\n+        self.assertIsInstance(layer.kernel.constraint, constraints.NonNeg)\n+        layer = layers.Dense(units=2, bias_constraint=\"non_neg\")\n+        layer.build((None, 2))\n+        self.assertIsInstance(layer.bias.constraint, constraints.NonNeg)\n\n@@ -1,6 +1,7 @@\n import pytest\n from absl.testing import parameterized\n \n+from keras import constraints\n from keras import layers\n from keras import testing\n \n@@ -263,3 +264,15 @@ class EinsumDenseTest(testing.TestCase, parameterized.TestCase):\n         self.assertEqual(layer.kernel.shape, expected_kernel_shape)\n         if expected_bias_shape is not None:\n             self.assertEqual(layer.bias.shape, expected_bias_shape)\n+\n+    def test_einsum_dense_constraints(self):\n+        layer = layers.EinsumDense(\n+            \"abc,cde->abde\", (1, 3, 4), kernel_constraint=\"non_neg\"\n+        )\n+        layer.build((2, 1, 2))\n+        self.assertIsInstance(layer.kernel.constraint, constraints.NonNeg)\n+        layer = layers.EinsumDense(\n+            \"ab,b->a\", (1, 3, 4), bias_axes=\"a\", bias_constraint=\"non_neg\"\n+        )\n+        layer.build((2, 1, 2))\n+        self.assertIsInstance(layer.bias.constraint, constraints.NonNeg)\n\n@@ -2,6 +2,7 @@ import numpy as np\n import pytest\n \n from keras import backend\n+from keras import constraints\n from keras import layers\n from keras.testing import test_case\n \n@@ -94,3 +95,8 @@ class EmbeddingTest(test_case.TestCase):\n         input_data = np.array([2, 1, 0])\n         mask = layer.compute_mask(input_data)\n         self.assertIsNone(mask)\n+\n+    def test_embedding_constraints(self):\n+        layer = layers.Embedding(3, 2, embeddings_constraint=\"non_neg\")\n+        layer.build((None, 2))\n+        self.assertIsInstance(layer.embeddings.constraint, constraints.NonNeg)\n\n@@ -23,6 +23,7 @@ from functools import wraps\n import tree\n \n from keras import backend\n+from keras import constraints\n from keras import initializers\n from keras import mixed_precision\n from keras import regularizers\n@@ -503,7 +504,7 @@ class Layer(BackendLayer, Operation):\n             )\n         # Will be added to layer.losses\n         variable.regularizer = regularizer\n-        variable.constraint = constraint\n+        variable.constraint = constraints.get(constraint)\n         self._track_variable(variable)\n         return variable\n \n\n@@ -10,6 +10,7 @@ from keras import initializers\n from keras import layers\n from keras import losses\n from keras import metrics\n+from keras import models\n from keras import ops\n from keras import optimizers\n from keras import testing\n@@ -1139,3 +1140,16 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n             callbacks=[stopper],\n         )\n         self.assertEqual(stopper.counter, stop_count)\n+\n+    @pytest.mark.requires_trainable_backend\n+    def test_constraints_are_applied(self):\n+        model = models.Sequential(\n+            [layers.Dense(2, kernel_constraint=\"non_neg\")]\n+        )\n+        x = np.ones((2, 3))\n+        y = np.ones((2, 2))\n+        model.compile(optimizer=\"rmsprop\", loss=\"mse\")\n+        model.fit(x, y)\n+        self.assertGreaterEqual(\n+            np.min(backend.convert_to_numpy(model.layers[0].kernel)), 0.0\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1ad0b3711d83ebbeef51f66019d4924f9f78f3e9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 29 | Files Changed: 1 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 43 | Churn Cumulative: 1438 | Contributors (this commit): 15 | Commits (past 90d): 2 | Contributors (cumulative): 15 | DMM Complexity: 0.0\n\nDIFF:\n@@ -53,11 +53,6 @@ class MultiHeadAttention(Layer):\n             attention over all axes, but batch, heads, and features.\n         kernel_initializer: Initializer for dense layer kernels.\n         bias_initializer: Initializer for dense layer biases.\n-        kernel_regularizer: Regularizer for dense layer kernels.\n-        bias_regularizer: Regularizer for dense layer biases.\n-        activity_regularizer: Regularizer for dense layer activity.\n-        kernel_constraint: Constraint for dense layer kernels.\n-        bias_constraint: Constraint for dense layer kernels.\n \n     Call arguments:\n         query: Query tensor of shape `(B, T, dim)`, where `B` is the batch size,\n@@ -104,11 +99,6 @@ class MultiHeadAttention(Layer):\n         attention_axes=None,\n         kernel_initializer=\"glorot_uniform\",\n         bias_initializer=\"zeros\",\n-        kernel_regularizer=None,\n-        bias_regularizer=None,\n-        activity_regularizer=None,\n-        kernel_constraint=None,\n-        bias_constraint=None,\n         **kwargs,\n     ):\n         super().__init__(**kwargs)\n@@ -123,11 +113,6 @@ class MultiHeadAttention(Layer):\n         self._output_shape = output_shape\n         self._kernel_initializer = initializers.get(kernel_initializer)\n         self._bias_initializer = initializers.get(bias_initializer)\n-        self._kernel_regularizer = regularizers.get(kernel_regularizer)\n-        self._bias_regularizer = regularizers.get(bias_regularizer)\n-        self._activity_regularizer = regularizers.get(activity_regularizer)\n-        self._kernel_constraint = constraints.get(kernel_constraint)\n-        self._bias_constraint = constraints.get(bias_constraint)\n         if isinstance(attention_axes, int):\n             attention_axes = (attention_axes,)\n         elif attention_axes and not isinstance(attention_axes, (list, tuple)):\n@@ -151,18 +136,23 @@ class MultiHeadAttention(Layer):\n                 self._kernel_initializer\n             ),\n             \"bias_initializer\": initializers.serialize(self._bias_initializer),\n-            \"kernel_regularizer\": regularizers.serialize(\n-                self._kernel_regularizer\n-            ),\n-            \"bias_regularizer\": regularizers.serialize(self._bias_regularizer),\n-            \"activity_regularizer\": regularizers.serialize(\n-                self._activity_regularizer\n-            ),\n-            \"kernel_constraint\": constraints.serialize(self._kernel_constraint),\n-            \"bias_constraint\": constraints.serialize(self._bias_constraint),\n         }\n         return {**base_config, **config}\n \n+    @classmethod\n+    def from_config(cls, config):\n+        unused_legacy_args = {\n+            \"activity_regularizer\",\n+            \"bias_regularizer\",\n+            \"kernel_regularizer\",\n+            \"bias_constraint\",\n+            \"kernel_constraint\",\n+        }\n+        for kwarg in unused_legacy_args:\n+            if kwarg in config:\n+                config.pop(kwarg)\n+        return super().from_config(config)\n+\n     def build(\n         self,\n         query_shape,\n@@ -238,11 +228,6 @@ class MultiHeadAttention(Layer):\n \n     def _get_common_kwargs_for_sublayer(self):\n         common_kwargs = dict(\n-            kernel_regularizer=self._kernel_regularizer,\n-            bias_regularizer=self._bias_regularizer,\n-            activity_regularizer=self._activity_regularizer,\n-            kernel_constraint=self._kernel_constraint,\n-            bias_constraint=self._bias_constraint,\n             dtype=self.dtype_policy,\n         )\n         # Create new clone of kernel/bias initializer, so that we don't reuse\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#947a43b9678d87b120128a4e5f195f1c95a94337", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 29 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 43 | Churn Cumulative: 1481 | Contributors (this commit): 15 | Commits (past 90d): 3 | Contributors (cumulative): 15 | DMM Complexity: 1.0\n\nDIFF:\n@@ -53,6 +53,11 @@ class MultiHeadAttention(Layer):\n             attention over all axes, but batch, heads, and features.\n         kernel_initializer: Initializer for dense layer kernels.\n         bias_initializer: Initializer for dense layer biases.\n+        kernel_regularizer: Regularizer for dense layer kernels.\n+        bias_regularizer: Regularizer for dense layer biases.\n+        activity_regularizer: Regularizer for dense layer activity.\n+        kernel_constraint: Constraint for dense layer kernels.\n+        bias_constraint: Constraint for dense layer kernels.\n \n     Call arguments:\n         query: Query tensor of shape `(B, T, dim)`, where `B` is the batch size,\n@@ -99,6 +104,11 @@ class MultiHeadAttention(Layer):\n         attention_axes=None,\n         kernel_initializer=\"glorot_uniform\",\n         bias_initializer=\"zeros\",\n+        kernel_regularizer=None,\n+        bias_regularizer=None,\n+        activity_regularizer=None,\n+        kernel_constraint=None,\n+        bias_constraint=None,\n         **kwargs,\n     ):\n         super().__init__(**kwargs)\n@@ -113,6 +123,11 @@ class MultiHeadAttention(Layer):\n         self._output_shape = output_shape\n         self._kernel_initializer = initializers.get(kernel_initializer)\n         self._bias_initializer = initializers.get(bias_initializer)\n+        self._kernel_regularizer = regularizers.get(kernel_regularizer)\n+        self._bias_regularizer = regularizers.get(bias_regularizer)\n+        self._activity_regularizer = regularizers.get(activity_regularizer)\n+        self._kernel_constraint = constraints.get(kernel_constraint)\n+        self._bias_constraint = constraints.get(bias_constraint)\n         if isinstance(attention_axes, int):\n             attention_axes = (attention_axes,)\n         elif attention_axes and not isinstance(attention_axes, (list, tuple)):\n@@ -136,23 +151,18 @@ class MultiHeadAttention(Layer):\n                 self._kernel_initializer\n             ),\n             \"bias_initializer\": initializers.serialize(self._bias_initializer),\n+            \"kernel_regularizer\": regularizers.serialize(\n+                self._kernel_regularizer\n+            ),\n+            \"bias_regularizer\": regularizers.serialize(self._bias_regularizer),\n+            \"activity_regularizer\": regularizers.serialize(\n+                self._activity_regularizer\n+            ),\n+            \"kernel_constraint\": constraints.serialize(self._kernel_constraint),\n+            \"bias_constraint\": constraints.serialize(self._bias_constraint),\n         }\n         return {**base_config, **config}\n \n-    @classmethod\n-    def from_config(cls, config):\n-        unused_legacy_args = {\n-            \"activity_regularizer\",\n-            \"bias_regularizer\",\n-            \"kernel_regularizer\",\n-            \"bias_constraint\",\n-            \"kernel_constraint\",\n-        }\n-        for kwarg in unused_legacy_args:\n-            if kwarg in config:\n-                config.pop(kwarg)\n-        return super().from_config(config)\n-\n     def build(\n         self,\n         query_shape,\n@@ -228,6 +238,11 @@ class MultiHeadAttention(Layer):\n \n     def _get_common_kwargs_for_sublayer(self):\n         common_kwargs = dict(\n+            kernel_regularizer=self._kernel_regularizer,\n+            bias_regularizer=self._bias_regularizer,\n+            activity_regularizer=self._activity_regularizer,\n+            kernel_constraint=self._kernel_constraint,\n+            bias_constraint=self._bias_constraint,\n             dtype=self.dtype_policy,\n         )\n         # Create new clone of kernel/bias initializer, so that we don't reuse\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#07fc99f4b739a554da0c0885a3e0c28e9380e0ee", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 38 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 38 | Churn Cumulative: 1470 | Contributors (this commit): 12 | Commits (past 90d): 3 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3,6 +3,7 @@ import pytest\n from absl.testing import parameterized\n \n from keras import backend\n+from keras import constraints\n from keras import initializers\n from keras import layers\n from keras import testing\n@@ -249,3 +250,40 @@ class MultiHeadAttentionTest(testing.TestCase, parameterized.TestCase):\n             [[[[0.33, 0.67], [0.67, 0.33]], [[0.33, 0.67], [0.67, 0.33]]]],\n             atol=1e-3,\n         )\n+\n+    def test_mha_constraints(self):\n+        query = np.array([[[1.0, 0.0], [0.0, 1.0]]])\n+        key = np.array([[[0.0, 1.0], [1.0, 0.0]]])\n+        value = np.array([[[1.0, 2.0], [3.0, 4.0]]])\n+        num_heads = 2\n+        key_dim = 2\n+        layer = layers.MultiHeadAttention(\n+            num_heads=num_heads,\n+            key_dim=key_dim,\n+            kernel_constraint=\"non_neg\",\n+        )\n+        layer.build(query.shape, key.shape, value.shape)\n+        self.assertIsInstance(\n+            layer._query_dense.kernel.constraint, constraints.NonNeg\n+        )\n+        self.assertIsInstance(\n+            layer._value_dense.kernel.constraint, constraints.NonNeg\n+        )\n+        self.assertIsInstance(\n+            layer._key_dense.kernel.constraint, constraints.NonNeg\n+        )\n+        layer = layers.MultiHeadAttention(\n+            num_heads=num_heads,\n+            key_dim=key_dim,\n+            bias_constraint=\"non_neg\",\n+        )\n+        layer.build(query.shape, key.shape, value.shape)\n+        self.assertIsInstance(\n+            layer._query_dense.bias.constraint, constraints.NonNeg\n+        )\n+        self.assertIsInstance(\n+            layer._value_dense.bias.constraint, constraints.NonNeg\n+        )\n+        self.assertIsInstance(\n+            layer._key_dense.bias.constraint, constraints.NonNeg\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#327360e617771d4f34e2b4bf4810ed8b413709bb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 15 | Churn Cumulative: 99 | Contributors (this commit): 3 | Commits (past 90d): 11 | Contributors (cumulative): 4 | DMM Complexity: 0.7777777777777778\n\nDIFF:\n@@ -169,6 +169,7 @@ def compute_output_spec(fn, *args, **kwargs):\n                     idx_sym += 1\n \n                 i += 1\n+            with StatelessScope():\n                 return fn(*rec_args, **kwargs, **static_kwargs)\n \n         jax_out = None\n@@ -208,7 +209,9 @@ def compute_output_spec(fn, *args, **kwargs):\n                     else:\n                         flat_out.append(x1)\n                 jax_out = pack_sequence_as(jax_out_1, flat_out)\n-            except:\n+            except Exception as e:\n+                if \"[JAX RNG]\" in str(e):\n+                    raise e\n                 # Errors can happen when the filled dimensions\n                 # are not compatible with the function\n                 # (or when the function contains a bug).\n\n@@ -93,13 +93,19 @@ class SeedGenerator:\n def global_seed_generator():\n     if jax_utils.is_in_jax_tracing_scope():\n         raise ValueError(\n-            \"When tracing a JAX function, \"\n+            \"[JAX RNG] When tracing a JAX function, \"\n             \"you should only use seeded random ops, e.g. \"\n             \"you should create a `SeedGenerator` instance, attach it \"\n             \"to your layer/model, and pass the instance as the `seed` \"\n             \"argument when calling random ops. Unseeded random ops \"\n             \"would get incorrectly traced by JAX and would become constant \"\n-            \"after tracing.\"\n+            \"after tracing. Example:\\n\\n\"\n+            \"```\\n\"\n+            \"# Make sure to set the seed generator as a layer attribute\\n\"\n+            \"self.seed_generator = keras.random.SeedGenerator(seed=1337)\\n\"\n+            \"...\\n\"\n+            \"out = keras.random.normal(shape=(1,), seed=self.seed_generator)\\n\"\n+            \"```\"\n         )\n     gen = global_state.get_global_attribute(\"global_seed_generator\")\n     if gen is None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d745fa8847eb93ccaa5f4a3c5ebf331f3cb17d9f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 4 | Hunks: 4 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 155 | Contributors (this commit): 3 | Commits (past 90d): 14 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -54,7 +54,7 @@ class ReduceLROnPlateau(Callback):\n         mode=\"auto\",\n         min_delta=1e-4,\n         cooldown=0,\n-        min_lr=0,\n+        min_lr=0.,\n         **kwargs,\n     ):\n         super().__init__()\n\n@@ -412,7 +412,7 @@ class AudioDatasetFromDirectoryTest(testing.TestCase):\n             ValueError, \"`validation_split` must be set\"\n         ):\n             _ = audio_dataset_utils.audio_dataset_from_directory(\n-                directory, validation_split=0, subset=\"training\"\n+                directory, validation_split=0., subset=\"training\"\n             )\n \n         with self.assertRaisesRegex(ValueError, \"must provide a `seed`\"):\n\n@@ -438,7 +438,7 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n             ValueError, \"`validation_split` must be set\"\n         ):\n             _ = image_dataset_utils.image_dataset_from_directory(\n-                directory, validation_split=0, subset=\"training\"\n+                directory, validation_split=0., subset=\"training\"\n             )\n \n         with self.assertRaisesRegex(ValueError, \"must provide a `seed`\"):\n\n@@ -280,7 +280,7 @@ class TextDatasetFromDirectoryTest(testing.TestCase):\n             ValueError, \"`validation_split` must be set\"\n         ):\n             _ = text_dataset_utils.text_dataset_from_directory(\n-                directory, validation_split=0, subset=\"training\"\n+                directory, validation_split=0., subset=\"training\"\n             )\n \n         with self.assertRaisesRegex(ValueError, \"must provide a `seed`\"):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#037ec9f5fc61a53c6e1f4c02b7bf1443429dcd45", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 4 | Hunks: 4 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 163 | Contributors (this commit): 3 | Commits (past 90d): 18 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -54,7 +54,7 @@ class ReduceLROnPlateau(Callback):\n         mode=\"auto\",\n         min_delta=1e-4,\n         cooldown=0,\n-        min_lr=0.,\n+        min_lr=0.0,\n         **kwargs,\n     ):\n         super().__init__()\n\n@@ -412,7 +412,7 @@ class AudioDatasetFromDirectoryTest(testing.TestCase):\n             ValueError, \"`validation_split` must be set\"\n         ):\n             _ = audio_dataset_utils.audio_dataset_from_directory(\n-                directory, validation_split=0., subset=\"training\"\n+                directory, validation_split=0.0, subset=\"training\"\n             )\n \n         with self.assertRaisesRegex(ValueError, \"must provide a `seed`\"):\n\n@@ -438,7 +438,7 @@ class ImageDatasetFromDirectoryTest(testing.TestCase):\n             ValueError, \"`validation_split` must be set\"\n         ):\n             _ = image_dataset_utils.image_dataset_from_directory(\n-                directory, validation_split=0., subset=\"training\"\n+                directory, validation_split=0.0, subset=\"training\"\n             )\n \n         with self.assertRaisesRegex(ValueError, \"must provide a `seed`\"):\n\n@@ -280,7 +280,7 @@ class TextDatasetFromDirectoryTest(testing.TestCase):\n             ValueError, \"`validation_split` must be set\"\n         ):\n             _ = text_dataset_utils.text_dataset_from_directory(\n-                directory, validation_split=0., subset=\"training\"\n+                directory, validation_split=0.0, subset=\"training\"\n             )\n \n         with self.assertRaisesRegex(ValueError, \"must provide a `seed`\"):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
