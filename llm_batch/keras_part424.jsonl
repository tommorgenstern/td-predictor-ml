{"custom_id": "keras#2fc98ba7baf0118a25ff746ceebafe25343fe918", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 18 | Churn Cumulative: 3621 | Contributors (this commit): 6 | Commits (past 90d): 11 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -441,11 +441,21 @@ class RandomCrop(base_layer.BaseRandomLayer):\n \n   def call(self, inputs, training=True):\n     inputs = utils.ensure_tensor(inputs, dtype=self.compute_dtype)\n+    if training:\n       input_shape = tf.shape(inputs)\n       h_diff = input_shape[H_AXIS] - self.height\n       w_diff = input_shape[W_AXIS] - self.width\n+      return tf.cond(\n+          tf.reduce_all((h_diff >= 0, w_diff >= 0)),\n+          lambda: self._random_crop(inputs),\n+          lambda: self._resize(inputs))\n+    else:\n+      return self._resize(inputs)\n \n-    def random_crop():\n+  def _random_crop(self, inputs):\n+    input_shape = tf.shape(inputs)\n+    h_diff = input_shape[H_AXIS] - self.height\n+    w_diff = input_shape[W_AXIS] - self.width\n     dtype = input_shape.dtype\n     rands = self._random_generator.random_uniform([2], 0, dtype.max, dtype)\n     h_start = rands[0] % (h_diff + 1)\n@@ -453,15 +463,11 @@ class RandomCrop(base_layer.BaseRandomLayer):\n     return tf.image.crop_to_bounding_box(inputs, h_start, w_start,\n                                          self.height, self.width)\n \n-    def resize():\n+  def _resize(self, inputs):\n     outputs = smart_resize(inputs, [self.height, self.width])\n     # smart_resize will always output float32, so we need to re-cast.\n     return tf.cast(outputs, self.compute_dtype)\n \n-    return tf.cond(\n-        tf.reduce_all((training, h_diff >= 0, w_diff >= 0)), random_crop,\n-        resize)\n-\n   def compute_output_shape(self, input_shape):\n     input_shape = tf.TensorShape(input_shape).as_list()\n     input_shape[H_AXIS] = self.height\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a70913f1a4682c2b0c950d73afef750295f8f5a5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 1093 | Contributors (this commit): 26 | Commits (past 90d): 3 | Contributors (cumulative): 26 | DMM Complexity: 1.0\n\nDIFF:\n@@ -290,8 +290,7 @@ def model_to_dot(model,\n             [format_shape(ishape) for ishape in layer.input_shapes])\n       else:\n         inputlabels = '?'\n-      label = '{%s}|{input:|output:}|{{%s}|{%s}}' % (label, inputlabels,\n-                                                       outputlabels)\n+      label = '{%s}|{input:|output:}|{{%s}|{%s}}' % (label, inputlabels, outputlabels)\n     if not expand_nested or not isinstance(\n         layer, functional.Functional):\n       node = pydot.Node(layer_id, label=label)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b98819301c20b38d07ed0aeebc425077d7b45da4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 75 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -7,10 +7,12 @@ from keras.utils import tf_utils\n \n import tensorflow.compat.v2 as tf\n \n-from keras.dtensor.python import mesh_util\n-from keras.dtensor.python import tpu_util\n from keras.dtensor.tests import test_util\n-from tensorflow.dtensor import python as dtensor  # pylint: disable=g-direct-tensorflow-import\n+# pylint: disable=g-direct-tensorflow-import\n+from tensorflow.dtensor import python as dtensor\n+from tensorflow.dtensor.python import mesh_util\n+from tensorflow.dtensor.python import tpu_util\n+# pylint: enable=g-direct-tensorflow-import\n \n \n class MnistTest(test_util.DTensorBaseTest):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6825703b55c7f2ec0374095d25f377cd62bac14d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 11 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -17,10 +17,13 @@\n from keras.optimizers.optimizer_experimental import optimizer\n from keras.utils import generic_utils\n import tensorflow.compat.v2 as tf\n+# pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.util.tf_export import keras_export\n \n \n # pylint: disable=g-classes-have-attributes\n @generic_utils.register_keras_serializable()\n+@keras_export('keras.optimizers.experimental.RMSprop', v1=[])\n class RMSprop(optimizer.Optimizer):\n   r\"\"\"Optimizer that implements the RMSprop algorithm.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6a633424ed8f0f9b0c13f025bfb63cf65eaa9a20", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 37 | Files Changed: 2 | Hunks: 6 | Methods Changed: 6 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 48 | Churn Cumulative: 3044 | Contributors (this commit): 9 | Commits (past 90d): 21 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -261,7 +261,10 @@ class CategoricalAccuracy(base_metric.MeanMetricWrapper):\n \n   def __init__(self, name='categorical_accuracy', dtype=None):\n     super(CategoricalAccuracy, self).__init__(\n-        metrics_utils.categorical_matches, name, dtype=dtype)\n+        lambda y_true, y_pred: metrics_utils.sparse_categorical_matches(\n+          tf.math.argmax(y_true, axis=-1),\n+          y_pred),\n+        name, dtype=dtype)\n \n \n @keras_export('keras.metrics.SparseCategoricalAccuracy')\n@@ -377,7 +380,11 @@ class TopKCategoricalAccuracy(base_metric.MeanMetricWrapper):\n \n   def __init__(self, k=5, name='top_k_categorical_accuracy', dtype=None):\n     super(TopKCategoricalAccuracy, self).__init__(\n-        metrics_utils.top_k_categorical_matches, name, dtype=dtype, k=k)\n+        lambda y_true, y_pred, k: metrics_utils.sparse_top_k_categorical_matches(\n+          tf.math.argmax(y_true, axis=-1),\n+          y_pred,\n+          k),\n+        name, dtype=dtype, k=k)\n \n \n @keras_export('keras.metrics.SparseTopKCategoricalAccuracy')\n@@ -3245,7 +3252,7 @@ def categorical_accuracy(y_true, y_pred):\n   # categorical_accuracy behavior from the vital behavior of the \n   # categorical_matches method needed in backend dependencies.\n \n-  return metrics_utils.categorical_matches(y_true, y_pred)\n+  return metrics_utils.sparse_categorical_matches(tf.math.argmax(y_true, axis=-1), y_pred)\n \n \n @keras_export('keras.metrics.sparse_categorical_accuracy')\n@@ -3304,7 +3311,7 @@ def top_k_categorical_accuracy(y_true, y_pred, k=5):\n   # public facing top_k_categorical_accuracy behavior from the vital behavior\n   # of the top_k_categorical_matches method needed in backend dependencies.\n \n-  return metrics_utils.top_k_categorical_matches(y_true, y_pred, k)\n+  return metrics_utils.sparse_top_k_categorical_matches(tf.math.argmax(y_true, axis=-1), y_pred, k)\n \n \n @keras_export('keras.metrics.sparse_top_k_categorical_accuracy')\n\n@@ -889,23 +889,6 @@ def sparse_categorical_matches(y_true, y_pred):\n   return tf.cast(tf.equal(y_true, y_pred), backend.floatx())\n \n \n-def categorical_matches(y_true, y_pred):\n-  \"\"\"Creates float Tensor for how often predictions match one-hot labels.\n-\n-  You can provide logits of classes as `y_pred`, since argmax of\n-  logits and probabilities are same.\n-\n-  Args:\n-    y_true: One-hot ground truth values.\n-    y_pred: The prediction values.\n-\n-  Returns:\n-    Match tensor: 1.0 for label-prediction match, 0.0 for mismatch.\n-  \"\"\"\n-  y_true = tf.math.argmax(y_true, axis=-1)\n-  return sparse_categorical_matches(y_true, y_pred)\n-\n-\n def sparse_top_k_categorical_matches(y_true, y_pred, k=5):\n   \"\"\"Creates float Tensor, 1.0 for label-TopK_prediction match, 0.0 for mismatch.\n \n@@ -943,19 +926,3 @@ def sparse_top_k_categorical_matches(y_true, y_pred, k=5):\n     return tf.reshape(matches, shape=y_true_org_shape)\n \n   return matches\n-\n-\n-def top_k_categorical_matches(y_true, y_pred, k=5):\n-  \"\"\"Creates float Tensor for how often topK_predictions match one-hot labels.\n-\n-  Args:\n-    y_true: The ground truth values.\n-    y_pred: The prediction values.\n-    k: (Optional) Number of top elements to look at for computing accuracy.\n-      Defaults to 5.\n-\n-  Returns:\n-    Match tensor: 1.0 for label-prediction match, 0.0 for mismatch.\n-  \"\"\"\n-  y_true = tf.math.argmax(y_true, axis=-1)\n-  return sparse_top_k_categorical_matches(y_true, y_pred, k=k)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7973ffc933c5f42835e36f6e7ea60d4b9d1c5a56", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 56 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 56 | Churn Cumulative: 366 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -17,6 +17,9 @@\n import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n+import numpy as np\n+\n+from keras import backend\n from keras.testing_infra import test_combinations\n from keras.utils import metrics_utils\n \n@@ -289,6 +292,59 @@ class FilterTopKTest(tf.test.TestCase, parameterized.TestCase):\n         42.\n     ])\n \n+class MatchesMethodsTest(tf.test.TestCase, parameterized.TestCase):\n+\n+  def test_sparse_categorical_matches_int(self):\n+    with self.cached_session():\n+      matches_method = metrics_utils.sparse_categorical_matches\n+      \n+      # Test return tensor is type float\n+      y_true = backend.variable(np.random.randint(0, 7, (6,)))\n+      y_pred = backend.variable(np.random.random((6, 7)))\n+      self.assertEqual(backend.eval(matches_method(y_true, y_pred)).dtype,\n+                        backend.floatx())\n+\n+      # Tests that resulting Tensor always has same shape as y_true. Tests from\n+      # 1 dim to 4 dims\n+      dims = []\n+      for _ in range(4):\n+          dims.append(np.random.randint(1, 7))\n+          y_true = backend.variable(np.random.randint(0, 7, dims))\n+          y_pred = backend.variable(np.random.random(dims+[3]))\n+          self.assertEqual(backend.eval(matches_method(y_true, y_pred)).shape,\n+                            y_true.shape)\n+\n+      # Test correctness if the shape of y_true is (num_samples,)\n+      y_true = backend.variable([1., 0., 0., 0.])\n+      y_pred = backend.variable(\n+          [[0.8, 0.2], [0.6, 0.4], [0.7, 0.3], [0.9, 0.1]])\n+      self.assertAllEqual(\n+          backend.eval(matches_method(y_true, y_pred)), [0., 1., 1., 1.])\n+\n+      # Test correctness if the shape of y_true is (num_samples, 1)\n+      y_true = backend.variable([[1.], [0.], [0.], [0.]])\n+      y_pred = backend.variable(\n+          [[0.8, 0.2], [0.6, 0.4], [0.7, 0.3], [0.9, 0.1]])\n+      self.assertAllEqual(\n+          backend.eval(matches_method(y_true, y_pred)), [0., 1., 1., 1.])\n+\n+      # Test correctness if the shape of y_true is (batch_size, seq_length) and\n+      # y_pred is (batch_size, seq_length, num_classes)\n+      y_pred = backend.variable(\n+          np.array([[[0.2, 0.3, 0.1], [0.1, 0.2, 0.7]],\n+                    [[0.3, 0.2, 0.1], [0.7, 0.2, 0.1]]]))\n+      y_true = backend.variable(np.array([[1, 0], [1, 0]]))\n+      self.assertAllEqual(\n+          backend.eval(matches_method(y_true, y_pred)), [[1., 0.], [0., 1.]])\n+\n+  def test_sparse_categorical_accuracy_float(self):\n+    with self.cached_session():\n+      matches_method = metrics_utils.sparse_categorical_matches\n+      y_true = backend.variable(np.random.random((6,)))\n+      y_pred = backend.variable(np.random.random((6, 7)))\n+      self.assertEqual(backend.eval(matches_method(y_true, y_pred)).shape, (6,))\n+\n+\n \n if __name__ == '__main__':\n   tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#eefd967f49192fb769154e930be8480af369a752", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 1096 | Contributors (this commit): 26 | Commits (past 90d): 4 | Contributors (cumulative): 26 | DMM Complexity: 0.0\n\nDIFF:\n@@ -290,7 +290,8 @@ def model_to_dot(model,\n             [format_shape(ishape) for ishape in layer.input_shapes])\n       else:\n         inputlabels = '?'\n-      label = '{%s}|{input:|output:}|{{%s}|{%s}}' % (label, inputlabels, outputlabels)\n+      label = '{%s}|{input:|output:}|{{%s}|{%s}}' % (\n+          label, inputlabels, outputlabels)\n     if not expand_nested or not isinstance(\n         layer, functional.Functional):\n       node = pydot.Node(layer_id, label=label)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1bddcfe1d026c366f6208c57ca5ddfe8f7428948", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 9 | Files Changed: 9 | Hunks: 9 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 29 | Churn Cumulative: 124 | Contributors (this commit): 3 | Commits (past 90d): 19 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -23,7 +23,8 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export('keras.optimizers.Adadelta')\n+# pylint: disable=g-classes-have-attributes\n+@keras_export('keras.optimizers.Adadelta', 'keras.optimizers.legacy.Adadelta')\n class Adadelta(optimizer_v2.OptimizerV2):\n   r\"\"\"Optimizer that implements the Adadelta algorithm.\n \n\n@@ -23,7 +23,8 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export('keras.optimizers.Adagrad')\n+# pylint: disable=g-classes-have-attributes\n+@keras_export('keras.optimizers.Adagrad', 'keras.optimizers.legacy.Adagrad')\n class Adagrad(optimizer_v2.OptimizerV2):\n   r\"\"\"Optimizer that implements the Adagrad algorithm.\n \n\n@@ -20,7 +20,8 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export('keras.optimizers.Adam')\n+# pylint: disable=g-classes-have-attributes\n+@keras_export('keras.optimizers.Adam', 'keras.optimizers.legacy.Adam')\n class Adam(optimizer_v2.OptimizerV2):\n   r\"\"\"Optimizer that implements the Adam algorithm.\n \n\n@@ -20,7 +20,8 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export('keras.optimizers.Adamax')\n+# pylint: disable=g-classes-have-attributes\n+@keras_export('keras.optimizers.Adamax', 'keras.optimizers.legacy.Adamax')\n class Adamax(optimizer_v2.OptimizerV2):\n   \"\"\"Optimizer that implements the Adamax algorithm.\n \n\n@@ -21,7 +21,8 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export  # pylint: disable=g-direct-tensorflow-import\n \n \n-@keras_export('keras.optimizers.Ftrl')\n+# pylint: disable=g-classes-have-attributes\n+@keras_export('keras.optimizers.Ftrl', 'keras.optimizers.legacy.Ftrl')\n class Ftrl(optimizer_v2.OptimizerV2):\n   r\"\"\"Optimizer that implements the FTRL algorithm.\n \n\n@@ -20,7 +20,8 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export  # pylint: disable=g-direct-tensorflow-import\n \n \n-@keras_export(\"keras.optimizers.SGD\")\n+# pylint: disable=g-classes-have-attributes\n+@keras_export(\"keras.optimizers.SGD\", \"keras.optimizers.legacy.SGD\")\n class SGD(optimizer_v2.OptimizerV2):\n   r\"\"\"Gradient descent (with momentum) optimizer.\n \n\n@@ -21,7 +21,8 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export('keras.optimizers.Nadam')\n+# pylint: disable=g-classes-have-attributes\n+@keras_export('keras.optimizers.Nadam', 'keras.optimizers.legacy.Nadam')\n class Nadam(optimizer_v2.OptimizerV2):\n   r\"\"\"Optimizer that implements the NAdam algorithm.\n   Much like Adam is essentially RMSprop with momentum, Nadam is Adam with\n\n@@ -92,7 +92,10 @@ def name_scope_only_in_function_or_graph(name):\n     return NullContextmanager()\n \n \n-@keras_export(\"keras.optimizers.Optimizer\", metaclass=abc.ABCMeta)\n+@keras_export(\n+    \"keras.optimizers.Optimizer\",\n+    \"keras.optimizers.legacy.Optimizer\",\n+    metaclass=abc.ABCMeta)\n class OptimizerV2(tf.__internal__.tracking.Trackable):\n   \"\"\"Base class for Keras optimizers.\n \n\n@@ -23,7 +23,8 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export(\"keras.optimizers.RMSprop\")\n+# pylint: disable=g-classes-have-attributes\n+@keras_export(\"keras.optimizers.RMSprop\", \"keras.optimizers.legacy.RMSprop\")\n class RMSprop(optimizer_v2.OptimizerV2):\n   r\"\"\"Optimizer that implements the RMSprop algorithm.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#98105b739a163a1911735b9e63c12bebba576349", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 28 | Files Changed: 2 | Hunks: 9 | Methods Changed: 5 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 62 | Churn Cumulative: 6354 | Contributors (this commit): 7 | Commits (past 90d): 20 | Contributors (cumulative): 12 | DMM Complexity: 0.0\n\nDIFF:\n@@ -637,7 +637,7 @@ class RandomFlip(BaseImageAugmentationLayer):\n @keras_export('keras.layers.RandomTranslation',\n               'keras.layers.experimental.preprocessing.RandomTranslation',\n               v1=[])\n-class RandomTranslation(base_layer.BaseRandomLayer):\n+class RandomTranslation(BaseImageAugmentationLayer):\n   \"\"\"A preprocessing layer which randomly translates images during training.\n \n   This layer will apply random translations to each image during training,\n@@ -739,36 +739,26 @@ class RandomTranslation(base_layer.BaseRandomLayer):\n     self.interpolation = interpolation\n     self.seed = seed\n \n-  def call(self, inputs, training=True):\n-    inputs = utils.ensure_tensor(inputs, self.compute_dtype)\n-\n-    def random_translated_inputs(inputs):\n+  @tf.function\n+  def augment_image(self, image, transformation=None):\n     \"\"\"Translated inputs with random ops.\"\"\"\n     # The transform op only accepts rank 4 inputs, so if we have an unbatched\n     # image, we need to temporarily expand dims to a batch.\n-      original_shape = inputs.shape\n-      unbatched = inputs.shape.rank == 3\n-      if unbatched:\n-        inputs = tf.expand_dims(inputs, 0)\n+    original_shape = image.shape\n+    inputs = tf.expand_dims(image, 0)\n \n     inputs_shape = tf.shape(inputs)\n-      batch_size = inputs_shape[0]\n     img_hd = tf.cast(inputs_shape[H_AXIS], tf.float32)\n     img_wd = tf.cast(inputs_shape[W_AXIS], tf.float32)\n-      height_translate = self._random_generator.random_uniform(\n-          shape=[batch_size, 1],\n-          minval=self.height_lower,\n-          maxval=self.height_upper,\n-          dtype=tf.float32)\n-      height_translate = height_translate * img_hd\n-      width_translate = self._random_generator.random_uniform(\n-          shape=[batch_size, 1],\n-          minval=self.width_lower,\n-          maxval=self.width_upper,\n-          dtype=tf.float32)\n-      width_translate = width_translate * img_wd\n+\n+    if transformation is None:\n+      transformation = self.get_random_tranformation()\n+    height_translation = transformation['height_translation']\n+    width_translation = transformation['width_translation']\n+    height_translation = height_translation * img_hd\n+    width_translation = width_translation * img_wd\n     translations = tf.cast(\n-          tf.concat([width_translate, height_translate], axis=1),\n+        tf.concat([width_translation, height_translation], axis=1),\n         dtype=tf.float32)\n     output = transform(\n         inputs,\n@@ -776,15 +766,30 @@ class RandomTranslation(base_layer.BaseRandomLayer):\n         interpolation=self.interpolation,\n         fill_mode=self.fill_mode,\n         fill_value=self.fill_value)\n-      if unbatched:\n+\n     output = tf.squeeze(output, 0)\n     output.set_shape(original_shape)\n     return output\n \n-    if training:\n-      return random_translated_inputs(inputs)\n-    else:\n-      return inputs\n+  def get_random_tranformation(self):\n+    batch_size = 1\n+    height_translation = self._random_generator.random_uniform(\n+        shape=[batch_size, 1],\n+        minval=self.height_lower,\n+        maxval=self.height_upper,\n+        dtype=tf.float32)\n+    width_translation = self._random_generator.random_uniform(\n+        shape=[batch_size, 1],\n+        minval=self.width_lower,\n+        maxval=self.width_upper,\n+        dtype=tf.float32)\n+    return {'height_translation': height_translation,\n+            'width_translation': width_translation}\n+\n+  def _batch_augment(self, inputs):\n+    # Change to vectorized_map for better performance, as well as work around\n+    # issue for different tensorspec between inputs and outputs.\n+    return tf.vectorized_map(self._augment, inputs)\n \n   def compute_output_shape(self, input_shape):\n     return input_shape\n\n@@ -829,6 +829,7 @@ class RandomBrightnessTest(test_combinations.TestCase):\n     self.assertEqual(reconstructed_layer._seed, layer._seed)\n \n \n+@test_utils.run_v2_only\n @test_combinations.run_all_keras_modes(always_skip_v1=True)\n class RandomTranslationTest(test_combinations.TestCase):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4b6798b55cc6e8361a9170fcc68902bebe46c2ff", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 20 | Files Changed: 9 | Hunks: 9 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 29 | Churn Cumulative: 153 | Contributors (this commit): 3 | Commits (past 90d): 28 | Contributors (cumulative): 27 | DMM Complexity: None\n\nDIFF:\n@@ -23,8 +23,7 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n \n-# pylint: disable=g-classes-have-attributes\n-@keras_export('keras.optimizers.Adadelta', 'keras.optimizers.legacy.Adadelta')\n+@keras_export('keras.optimizers.Adadelta')\n class Adadelta(optimizer_v2.OptimizerV2):\n   r\"\"\"Optimizer that implements the Adadelta algorithm.\n \n\n@@ -23,8 +23,7 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n \n-# pylint: disable=g-classes-have-attributes\n-@keras_export('keras.optimizers.Adagrad', 'keras.optimizers.legacy.Adagrad')\n+@keras_export('keras.optimizers.Adagrad')\n class Adagrad(optimizer_v2.OptimizerV2):\n   r\"\"\"Optimizer that implements the Adagrad algorithm.\n \n\n@@ -20,8 +20,7 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n \n-# pylint: disable=g-classes-have-attributes\n-@keras_export('keras.optimizers.Adam', 'keras.optimizers.legacy.Adam')\n+@keras_export('keras.optimizers.Adam')\n class Adam(optimizer_v2.OptimizerV2):\n   r\"\"\"Optimizer that implements the Adam algorithm.\n \n\n@@ -20,8 +20,7 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n \n-# pylint: disable=g-classes-have-attributes\n-@keras_export('keras.optimizers.Adamax', 'keras.optimizers.legacy.Adamax')\n+@keras_export('keras.optimizers.Adamax')\n class Adamax(optimizer_v2.OptimizerV2):\n   \"\"\"Optimizer that implements the Adamax algorithm.\n \n\n@@ -21,8 +21,7 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export  # pylint: disable=g-direct-tensorflow-import\n \n \n-# pylint: disable=g-classes-have-attributes\n-@keras_export('keras.optimizers.Ftrl', 'keras.optimizers.legacy.Ftrl')\n+@keras_export('keras.optimizers.Ftrl')\n class Ftrl(optimizer_v2.OptimizerV2):\n   r\"\"\"Optimizer that implements the FTRL algorithm.\n \n\n@@ -20,8 +20,7 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export  # pylint: disable=g-direct-tensorflow-import\n \n \n-# pylint: disable=g-classes-have-attributes\n-@keras_export(\"keras.optimizers.SGD\", \"keras.optimizers.legacy.SGD\")\n+@keras_export(\"keras.optimizers.SGD\")\n class SGD(optimizer_v2.OptimizerV2):\n   r\"\"\"Gradient descent (with momentum) optimizer.\n \n\n@@ -21,8 +21,7 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n \n-# pylint: disable=g-classes-have-attributes\n-@keras_export('keras.optimizers.Nadam', 'keras.optimizers.legacy.Nadam')\n+@keras_export('keras.optimizers.Nadam')\n class Nadam(optimizer_v2.OptimizerV2):\n   r\"\"\"Optimizer that implements the NAdam algorithm.\n   Much like Adam is essentially RMSprop with momentum, Nadam is Adam with\n\n@@ -92,10 +92,7 @@ def name_scope_only_in_function_or_graph(name):\n     return NullContextmanager()\n \n \n-@keras_export(\n-    \"keras.optimizers.Optimizer\",\n-    \"keras.optimizers.legacy.Optimizer\",\n-    metaclass=abc.ABCMeta)\n+@keras_export(\"keras.optimizers.Optimizer\", metaclass=abc.ABCMeta)\n class OptimizerV2(tf.__internal__.tracking.Trackable):\n   \"\"\"Base class for Keras optimizers.\n \n\n@@ -23,8 +23,7 @@ from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n \n-# pylint: disable=g-classes-have-attributes\n-@keras_export(\"keras.optimizers.RMSprop\", \"keras.optimizers.legacy.RMSprop\")\n+@keras_export(\"keras.optimizers.RMSprop\")\n class RMSprop(optimizer_v2.OptimizerV2):\n   r\"\"\"Optimizer that implements the RMSprop algorithm.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d1f4f2637a40c22ce59920ac16677dc9ec85aaaa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 15 | Files Changed: 3 | Hunks: 11 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 26 | Churn Cumulative: 6384 | Contributors (this commit): 19 | Commits (past 90d): 17 | Contributors (cumulative): 27 | DMM Complexity: None\n\nDIFF:\n@@ -145,7 +145,7 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n   Output shape:\n     Same as input shape.\n \n-  Attributes:\n+  Arguments:\n     bin_boundaries: A list of bin boundaries. The leftmost and rightmost bins\n       will always extend to `-inf` and `inf`, so `bin_boundaries=[0., 1., 2.]`\n       generates bins `(-inf, 0.)`, `[0., 1.)`, `[1., 2.)`, and `[2., +inf)`. If\n\n@@ -571,7 +571,7 @@ class RandomFlip(BaseImageAugmentationLayer):\n     3D (unbatched) or 4D (batched) tensor with shape:\n     `(..., height, width, channels)`, in `\"channels_last\"` format.\n \n-  Attributes:\n+  Arguments:\n     mode: String indicating which flip mode to use. Can be `\"horizontal\"`,\n       `\"vertical\"`, or `\"horizontal_and_vertical\"`. Defaults to\n       `\"horizontal_and_vertical\"`. `\"horizontal\"` is a left-right flip and\n@@ -997,7 +997,7 @@ class RandomRotation(base_layer.BaseRandomLayer):\n     3D (unbatched) or 4D (batched) tensor with shape:\n     `(..., height, width, channels)`, in `\"channels_last\"` format\n \n-  Attributes:\n+  Arguments:\n     factor: a float represented as fraction of 2 Pi, or a tuple of size 2\n       representing lower and upper bound for rotating clockwise and\n       counter-clockwise. A positive values means rotating counter clock-wise,\n@@ -1339,7 +1339,7 @@ class RandomContrast(base_layer.BaseRandomLayer):\n     3D (unbatched) or 4D (batched) tensor with shape:\n     `(..., height, width, channels)`, in `\"channels_last\"` format.\n \n-  Attributes:\n+  Arguments:\n     factor: a positive float represented as fraction of value, or a tuple of\n       size 2 representing lower and upper bound. When represented as a single\n       float, lower = upper. The contrast factor will be randomly picked between\n\n@@ -13,9 +13,10 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Built-in regularizers.\"\"\"\n+# pylint: disable=g-classes-have-attributes\n+# pylint: disable=invalid-name\n \n import tensorflow.compat.v2 as tf\n-# pylint: disable=invalid-name\n \n import math\n \n@@ -150,16 +151,11 @@ class Regularizer:\n   training and executing models, exporting to and from SavedModels, or saving\n   and loading weight checkpoints.\n \n-  Registration is required for Keras `model_to_estimator`, saving and\n-  loading models to HDF5 formats, Keras model cloning, some visualization\n+  Registration is required for saving and\n+  loading models to HDF5 format, Keras model cloning, some visualization\n   utilities, and exporting models to and from JSON. If using this functionality,\n   you must make sure any python process running your model has also defined\n   and registered your custom regularizer.\n-\n-  `tf.keras.utils.register_keras_serializable` is only available in TF 2.1 and\n-  beyond. In earlier versions of TensorFlow you must pass your custom\n-  regularizer to the `custom_objects` argument of methods that expect custom\n-  regularizers to be registered as serializable.\n   \"\"\"\n \n   def __call__(self, x):\n@@ -223,7 +219,7 @@ class L1L2(Regularizer):\n \n   In this case, the default values used are `l1=0.01` and `l2=0.01`.\n \n-  Attributes:\n+  Arguments:\n       l1: Float; L1 regularization factor.\n       l2: Float; L2 regularization factor.\n   \"\"\"\n@@ -265,7 +261,7 @@ class L1(Regularizer):\n \n   In this case, the default value used is `l1=0.01`.\n \n-  Attributes:\n+  Arguments:\n       l1: Float; L1 regularization factor.\n   \"\"\"\n \n@@ -299,7 +295,7 @@ class L2(Regularizer):\n \n   In this case, the default value used is `l2=0.01`.\n \n-  Attributes:\n+  Arguments:\n       l2: Float; L2 regularization factor.\n   \"\"\"\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b3f1f645238c93ec3b283f64f73a02df3aea6b53", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 17 | Churn Cumulative: 312 | Contributors (this commit): 5 | Commits (past 90d): 1 | Contributors (cumulative): 5 | DMM Complexity: 0.6\n\nDIFF:\n@@ -63,8 +63,10 @@ def index_directory(directory,\n     class_names = subdirs\n   else:\n     subdirs = []\n-    for subdir in sorted(os.listdir(directory)):\n-      if os.path.isdir(os.path.join(directory, subdir)):\n+    for subdir in sorted(tf.io.gfile.listdir(directory)):\n+      if tf.io.gfile.isdir(tf.io.gfile.join(directory, subdir)):\n+        if subdir.endswith('/'):\n+          subdir = subdir[:-1]\n         subdirs.append(subdir)\n     if not class_names:\n       class_names = subdirs\n@@ -83,7 +85,7 @@ def index_directory(directory,\n   results = []\n   filenames = []\n \n-  for dirpath in (os.path.join(directory, subdir) for subdir in subdirs):\n+  for dirpath in (tf.io.gfile.join(directory, subdir) for subdir in subdirs):\n     results.append(\n         pool.apply_async(index_subdirectory,\n                          (dirpath, class_indices, follow_links, formats)))\n@@ -112,7 +114,7 @@ def index_directory(directory,\n           (len(filenames), len(class_names)))\n   pool.close()\n   pool.join()\n-  file_paths = [os.path.join(directory, fname) for fname in filenames]\n+  file_paths = [tf.io.gfile.join(directory, fname) for fname in filenames]\n \n   if shuffle:\n     # Shuffle globally to erase macro-structure\n@@ -126,6 +128,9 @@ def index_directory(directory,\n \n \n def iter_valid_files(directory, follow_links, formats):\n+  if not follow_links:\n+    walk = tf.io.gfile.walk(directory)\n+  else:\n     walk = os.walk(directory, followlinks=follow_links)\n   for root, _, files in sorted(walk, key=lambda x: x[0]):\n     for fname in sorted(files):\n@@ -154,8 +159,8 @@ def index_subdirectory(directory, class_indices, follow_links, formats):\n   filenames = []\n   for root, fname in valid_files:\n     labels.append(class_indices[dirname])\n-    absolute_path = os.path.join(root, fname)\n-    relative_path = os.path.join(\n+    absolute_path = tf.io.gfile.join(root, fname)\n+    relative_path = tf.io.gfile.join(\n         dirname, os.path.relpath(absolute_path, directory))\n     filenames.append(relative_path)\n   return filenames, labels\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a63a59407bcd78c6f1dc9df66df002dd219f9706", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 9 | Churn Cumulative: 1219 | Contributors (this commit): 3 | Commits (past 90d): 14 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3282,7 +3282,13 @@ def sparse_categorical_accuracy(y_true, y_pred):\n   # public facing sparse_categorical_accuracy behavior from the vital behavior\n   # of the sparse_categorical_matches method needed in backend dependencies.\n \n-  return metrics_utils.sparse_categorical_matches(y_true, y_pred)\n+  matches = metrics_utils.sparse_categorical_matches(y_true, y_pred)\n+\n+  # if shape is (num_samples, 1) squeeze\n+  if matches.shape.ndims > 1 and matches.shape[-1] == 1:\n+    matches = tf.squeeze(matches, [-1])\n+\n+  return matches\n \n \n @keras_export('keras.metrics.top_k_categorical_accuracy')\n@@ -3342,6 +3348,7 @@ def sparse_top_k_categorical_accuracy(y_true, y_pred, k=5):\n   # behavior of the sparse_top_k_categorical_matches method needed in backend\n   # dependencies.\n \n+\n   return metrics_utils.sparse_top_k_categorical_matches(y_true, y_pred, k)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e03ec387a61a4c7cb51b4badb4a20fe8c39226f4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 10 | Churn Cumulative: 1844 | Contributors (this commit): 9 | Commits (past 90d): 9 | Contributors (cumulative): 9 | DMM Complexity: 0.0\n\nDIFF:\n@@ -874,13 +874,9 @@ def sparse_categorical_matches(y_true, y_pred):\n   \"\"\"\n   y_pred = tf.convert_to_tensor(y_pred)\n   y_true = tf.convert_to_tensor(y_true)\n-  y_pred_rank = y_pred.shape.ndims\n-  y_true_rank = y_true.shape.ndims\n-  # If the shape of y_true is (num_samples, 1), squeeze to (num_samples,)\n-  if (y_true_rank is not None) and (y_pred_rank is not None) and (len(\n-      backend.int_shape(y_true)) == len(backend.int_shape(y_pred))):\n-    y_true = tf.squeeze(y_true, [-1])\n-  y_pred = tf.math.argmax(y_pred, axis=-1)\n+\n+  # Reshape to ensure comparable to y_true in tf.equal\n+  y_pred = tf.reshape(tf.math.argmax(y_pred, axis=-1), shape=tf.shape(y_true))\n \n   # If the predicted output and actual output types don't match, force cast them\n   # to match.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#789468e16d93a25bbc1317a6b8d4206e6a2e104c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 93 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 100 | Churn Cumulative: 466 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -294,7 +294,7 @@ class FilterTopKTest(tf.test.TestCase, parameterized.TestCase):\n \n class MatchesMethodsTest(tf.test.TestCase, parameterized.TestCase):\n \n-  def test_sparse_categorical_matches_int(self):\n+  def test_sparse_categorical_matches(self):\n     with self.cached_session():\n       matches_method = metrics_utils.sparse_categorical_matches\n       \n@@ -326,7 +326,7 @@ class MatchesMethodsTest(tf.test.TestCase, parameterized.TestCase):\n       y_pred = backend.variable(\n           [[0.8, 0.2], [0.6, 0.4], [0.7, 0.3], [0.9, 0.1]])\n       self.assertAllEqual(\n-          backend.eval(matches_method(y_true, y_pred)), [0., 1., 1., 1.])\n+          backend.eval(matches_method(y_true, y_pred)), [[0.], [1.], [1.], [1.]])\n \n       # Test correctness if the shape of y_true is (batch_size, seq_length) and\n       # y_pred is (batch_size, seq_length, num_classes)\n@@ -337,13 +337,99 @@ class MatchesMethodsTest(tf.test.TestCase, parameterized.TestCase):\n       self.assertAllEqual(\n           backend.eval(matches_method(y_true, y_pred)), [[1., 0.], [0., 1.]])\n \n-  def test_sparse_categorical_accuracy_float(self):\n+  def test_sparse_top_k_categorical_matches(self):\n     with self.cached_session():\n-      matches_method = metrics_utils.sparse_categorical_matches\n-      y_true = backend.variable(np.random.random((6,)))\n-      y_pred = backend.variable(np.random.random((6, 7)))\n-      self.assertEqual(backend.eval(matches_method(y_true, y_pred)).shape, (6,))\n+      matches_method = metrics_utils.sparse_top_k_categorical_matches\n       \n+      # Test return tensor is type float\n+      y_true = backend.variable(np.random.randint(0, 7, (6,)))\n+      y_pred = backend.variable(np.random.random((6, 7)))\n+      self.assertEqual(backend.eval(matches_method(y_true, y_pred, 1)).dtype,\n+                        backend.floatx())\n+\n+      # Tests that resulting Tensor always has same shape as y_true. Tests from\n+      # 1 dim to 4 dims\n+      dims = []\n+      for _ in range(4):\n+          dims.append(np.random.randint(1, 7))\n+          y_true = backend.variable(np.random.randint(0, 7, dims))\n+          y_pred = backend.variable(np.random.random(dims+[3]))\n+          self.assertEqual(backend.eval(matches_method(y_true, y_pred, 1)).shape,\n+                            y_true.shape)\n+\n+      # Test correctness if the shape of y_true is (num_samples,) for k = 1,2,3\n+      y_true = backend.variable([1., 0., 0., 0.])\n+      y_pred = backend.variable(\n+          [[0.7, 0.2, 0.1], [0.5, 0.3, 0.2], [0.6, 0.3, 0.1], [0.0, 0.1, 0.9]])\n+      self.assertAllEqual(\n+          backend.eval(matches_method(y_true, y_pred, 1)), [0., 1., 1., 0.])\n+      self.assertAllEqual(\n+          backend.eval(matches_method(y_true, y_pred, 2)), [1., 1., 1., 0.])\n+      self.assertAllEqual(\n+          backend.eval(matches_method(y_true, y_pred, 3)), [1., 1., 1., 1.])\n+    \n+      # Test correctness if the shape of y_true is (num_samples, 1) for k = 1,2,3\n+      y_true = backend.variable([[1.], [0.], [0.], [0.]])\n+      y_pred = backend.variable(\n+          [[0.7, 0.2, 0.1], [0.5, 0.3, 0.2], [0.6, 0.3, 0.1], [0.0, 0.1, 0.9]])\n+      self.assertAllEqual(\n+          backend.eval(matches_method(y_true, y_pred, 1)), [[0.], [1.], [1.], [0.]])\n+      self.assertAllEqual(\n+          backend.eval(matches_method(y_true, y_pred, 2)), [[1.], [1.], [1.], [0.]])\n+      self.assertAllEqual(\n+          backend.eval(matches_method(y_true, y_pred, 3)), [[1.], [1.], [1.], [1.]])\n+\n+      # Test correctness if the shape of y_true is (batch_size, seq_length) and\n+      # y_pred is (batch_size, seq_length, num_classes) for k = 1,2,3\n+      y_pred = backend.variable(\n+          np.array([[[0.2, 0.3, 0.1], [0.1, 0.2, 0.7]],\n+                    [[0.3, 0.2, 0.1], [0.7, 0.2, 0.1]]]))\n+      y_true = backend.variable(np.array([[1, 0], [1, 0]]))\n+      self.assertAllEqual(\n+          backend.eval(matches_method(y_true, y_pred, 1)), [[1., 0.], [0., 1.]])\n+      self.assertAllEqual(\n+          backend.eval(matches_method(y_true, y_pred, 2)), [[1., 0.], [1., 1.]])\n+      self.assertAllEqual(\n+          backend.eval(matches_method(y_true, y_pred, 3)), [[1., 1.], [1., 1.]])\n+  \n+  def test_binary_matches(self):\n+    with self.cached_session():\n+      matches_method = metrics_utils.binary_matches\n+      \n+      # Test return tensor is type float\n+      y_true = backend.variable(np.random.random((6, 7)))\n+      y_pred = backend.variable(np.random.random((6, 7)))\n+      self.assertEqual(backend.eval(matches_method(y_true, y_pred, .5)).dtype,\n+                        backend.floatx())\n+\n+      # Tests that resulting Tensor always has same shape as y_true. Tests from\n+      # 1 dim to 4 dims.\n+      dims = []\n+      for _ in range(4):\n+          dims.append(np.random.randint(1, 7))\n+          y_true = y_pred = backend.variable(np.random.random(dims))\n+          self.assertEqual(backend.eval(matches_method(y_true, y_pred, 0.)).shape,\n+                            y_true.shape)\n+      \n+      # Testing for correctness shape (num_samples, 1)\n+      y_true = backend.variable([[1.], [0.], [1.], [1.]])\n+      y_pred = backend.variable([[.75], [.2], [.2], [.75]])\n+      self.assertAllEqual(\n+          backend.eval(matches_method(y_true, y_pred, .5)), [[1.],[1.],[0.],[1.]])\n+\n+      # Testing for correctness shape (num_samples,)\n+      y_true = backend.variable([1., 0., 1., 1.])\n+      y_pred = backend.variable([.75, .2, .2, .75])\n+      self.assertAllEqual(\n+          backend.eval(matches_method(y_true, y_pred, .5)), [1.,1.,0.,1.])\n+\n+      # Testing for correctness batches of sequences\n+      # shape (num_samples, seq_len)\n+      y_true = backend.variable([[1., 0.], [0., 1.], [1., 0.], [1., 0.]])\n+      y_pred = backend.variable([[.75, .2], [.2, .75], [.2, .75], [.75, .2]])\n+      self.assertAllEqual(\n+          backend.eval(matches_method(y_true, y_pred, .5)),\n+                                    [[1., 1.],[1., 1.],[0., 0.],[1., 1.]])\n \n \n if __name__ == '__main__':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2485cc8e927b0d21c5f4f5543ddb1f54873c75f0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 1222 | Contributors (this commit): 3 | Commits (past 90d): 15 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -3278,7 +3278,8 @@ def sparse_categorical_accuracy(y_true, y_pred):\n   Returns:\n     Sparse categorical accuracy values.\n   \"\"\"\n-  # Note: wraps metrics_utils.sparse_categorical_matches. This seperates\n+  # Note: wraps metrics_utils.sparse_categorical_matches method and checks for \n+  # squeezing to align with expected public facing behavior. This seperates\n   # public facing sparse_categorical_accuracy behavior from the vital behavior\n   # of the sparse_categorical_matches method needed in backend dependencies.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d4480e8525440de6211c57c8df6c85d1aa168085", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 3689 | Contributors (this commit): 7 | Commits (past 90d): 14 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -222,6 +222,7 @@ class CenterCrop(base_layer.Layer):\n     return dict(list(base_config.items()) + list(config.items()))\n \n \n+@keras_export('keras.__internal__.layers.BaseImageAugmentationLayer')\n class BaseImageAugmentationLayer(base_layer.BaseRandomLayer):\n   \"\"\"Abstract base layer for image augmentaion.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f43b1265ee9034d0a467762b32baab634b7e2628", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 125 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): 7/6 | Churn Δ: 129 | Churn Cumulative: 1855 | Contributors (this commit): 15 | Commits (past 90d): 4 | Contributors (cumulative): 18 | DMM Complexity: 1.0\n\nDIFF:\n@@ -30,13 +30,13 @@ def _check_penalty_number(x):\n   \"\"\"check penalty number availability, raise ValueError if failed.\"\"\"\n   if not isinstance(x, (float, int)):\n     raise ValueError(\n-        f'Value: {x} is not a valid regularization penalty number, '\n-        'expected an int or float value')\n+        f'Value {x} is not a valid regularization penalty number, '\n+        'expected an int or float value.')\n \n   if math.isinf(x) or math.isnan(x):\n     raise ValueError(\n-        f'Value: {x} is not a valid regularization penalty number, '\n-        'an infinity number or NaN are not valid value')\n+        f'Value {x} is not a valid regularization penalty number, '\n+        'an infinite number or NaN are not valid values.')\n \n \n def _none_to_default(inputs, default):\n@@ -316,6 +316,64 @@ class L2(Regularizer):\n     return {'l2': float(self.l2)}\n \n \n+@keras_export(\n+    'keras.regularizers.OrthogonalRegularizer',\n+    'keras.regularizers.orthogonal_regularizer',\n+    v1=[])\n+class OrthogonalRegularizer(Regularizer):\n+  \"\"\"A regularizer that encourages input vectors to be orthogonal to each other.\n+\n+  It can be applied to either the rows of a matrix (`mode=\"rows\"`) or its\n+  columns (`mode=\"columns\"`). When applied to a `Dense` kernel of shape\n+  `(input_dim, units)`, rows mode will seek to make the feature vectors\n+  (i.e. the basis of the output space) orthogonal to each other.\n+\n+  Arguments:\n+    factor: Float. The regularization factor. The regularization penalty will\n+      be proportional to `factor` times the mean of the dot products between\n+      the L2-normalized rows (if `mode=\"rows\"`, or columns if `mode=\"columns\"`)\n+      of the inputs, excluding the product of each row/column with itself.\n+      Defaults to 0.01.\n+    mode: String, one of `{\"rows\", \"columns\"}`. Defaults to `\"rows\"`. In rows\n+      mode, the regularization effect seeks to make the rows of the input\n+      orthogonal to each other. In columns mode, it seeks to make the columns\n+      of the input orthogonal to each other.\n+\n+  Example:\n+\n+  >>> regularizer = tf.keras.regularizers.OrthogonalRegularizer(factor=0.01)\n+  >>> layer = tf.keras.layers.Dense(units=4, kernel_regularizer=regularizer)\n+  \"\"\"\n+\n+  def __init__(self, factor=0.01, mode='rows'):\n+    _check_penalty_number(factor)\n+    self.factor = backend.cast_to_floatx(factor)\n+    if mode not in {'rows', 'columns'}:\n+      raise ValueError('Invalid value for argument `mode`. Expected one of '\n+                       f'{{\"rows\", \"columns\"}}. Received: mode={mode}')\n+    self.mode = mode\n+\n+  def __call__(self, inputs):\n+    if inputs.shape.rank != 2:\n+      raise ValueError(\n+          'Inputs to OrthogonalRegularizer must have rank 2. Received: '\n+          f'inputs.shape == {inputs.shape}')\n+    if self.mode == 'rows':\n+      inputs = tf.math.l2_normalize(inputs, axis=1)\n+      product = tf.matmul(inputs, tf.transpose(inputs))\n+      size = inputs.shape[0]\n+    else:\n+      inputs = tf.math.l2_normalize(inputs, axis=0)\n+      product = tf.matmul(tf.transpose(inputs), inputs)\n+      size = inputs.shape[1]\n+    product_no_diagonal = product * (1. - tf.eye(size, dtype=inputs.dtype))\n+    num_pairs = size * (size - 1.) / 2.\n+    return self.factor * 0.5 * tf.reduce_sum(product_no_diagonal) / num_pairs\n+\n+  def get_config(self):\n+    return {'factor': float(self.factor), 'mode': self.mode}\n+\n+\n @keras_export('keras.regularizers.l1_l2')\n def l1_l2(l1=0.01, l2=0.01):  # pylint: disable=redefined-outer-name\n   r\"\"\"Create a regularizer that applies both L1 and L2 penalties.\n@@ -339,6 +397,7 @@ def l1_l2(l1=0.01, l2=0.01):  # pylint: disable=redefined-outer-name\n # Deserialization aliases.\n l1 = L1\n l2 = L2\n+orthogonal_regularizer = OrthogonalRegularizer\n \n \n @keras_export('keras.regularizers.serialize')\n\n@@ -210,6 +210,68 @@ class KerasRegularizersTest(test_combinations.TestCase,\n     if hasattr(regularizer, 'l2'):\n       self.assertAllClose(regularizer.l2, expected_value)\n \n+  @test_utils.run_v2_only\n+  def test_orthogonal_regularizer(self):\n+    # Test correctness.\n+    factor = 0.1\n+    reg_rows = regularizers.OrthogonalRegularizer(factor=factor, mode='rows')\n+    reg_cols = regularizers.OrthogonalRegularizer(factor=factor, mode='columns')\n+\n+    # Test with square matrix\n+    inputs = tf.constant([[1, 1, 1, 1],\n+                          [2, 0, 0, 0],\n+                          [0, 0, 3, 1]], dtype='float32')\n+    normalized_rows = tf.math.l2_normalize(inputs, axis=1)\n+    normalized_cols = tf.math.l2_normalize(inputs, axis=0)\n+    rows_pairs = [\n+        tf.reduce_sum(normalized_rows[0] * normalized_rows[1]),\n+        tf.reduce_sum(normalized_rows[0] * normalized_rows[2]),\n+        tf.reduce_sum(normalized_rows[1] * normalized_rows[2]),\n+    ]\n+    col_pairs = [\n+        tf.reduce_sum(normalized_cols[:, 0] * normalized_cols[:, 1]),\n+        tf.reduce_sum(normalized_cols[:, 0] * normalized_cols[:, 2]),\n+        tf.reduce_sum(normalized_cols[:, 0] * normalized_cols[:, 3]),\n+        tf.reduce_sum(normalized_cols[:, 1] * normalized_cols[:, 2]),\n+        tf.reduce_sum(normalized_cols[:, 1] * normalized_cols[:, 3]),\n+        tf.reduce_sum(normalized_cols[:, 2] * normalized_cols[:, 3]),\n+    ]\n+    num_row_pairs = 3\n+    num_col_pairs = 6\n+    # Expected: factor * sum(pairwise_dot_products_of_rows) / num_row_pairs\n+    self.assertAllClose(reg_rows(inputs),\n+                        factor * sum(rows_pairs) / num_row_pairs)\n+    # Expected: factor * sum(pairwise_dot_products_of_columns) / num_col_pairs\n+    self.assertAllClose(reg_cols(inputs),\n+                        factor * sum(col_pairs) / num_col_pairs)\n+\n+    # Test incorrect usage.\n+    with self.assertRaisesRegex(ValueError, 'must have rank 2'):\n+      reg_rows(tf.constant([1, 1], dtype='float32'))\n+\n+    # Test serialization\n+    self.assertDictEqual(reg_cols.get_config(),\n+                         {'factor': factor, 'mode': 'columns'})\n+\n+    # Test usage in model.\n+    model_inputs = keras.Input((3,))\n+    model_outputs = keras.layers.Dense(\n+        4, kernel_regularizer=reg_rows)(model_inputs)\n+    model = keras.Model(model_inputs, model_outputs)\n+    model.compile(optimizer='rmsprop', loss='mse')\n+    model.fit(np.random.random((16, 3)), np.random.random((16, 4)), epochs=1)\n+\n+    # Test serialization and deserialiation as part of model.\n+    inputs = tf.constant([[1, 1, 1],\n+                          [2, 0, 0],\n+                          [0, 0, 3]], dtype='float32')\n+    outputs = model(inputs)\n+    config = model.get_config()\n+    weights = model.get_weights()\n+    model = keras.Model.from_config(config)\n+    model.set_weights(weights)\n+    self.assertAllClose(model(inputs), outputs, atol=1e-5)\n+\n \n if __name__ == '__main__':\n   tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
