{"custom_id": "keras#cb1d25fddbd575158af655daeae810b54a153ec7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 56 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 5 | Complexity Δ (Sum/Max): 5/3 | Churn Δ: 56 | Churn Cumulative: 1798 | Contributors (this commit): 15 | Commits (past 90d): 71 | Contributors (cumulative): 17 | DMM Complexity: 1.0\n\nDIFF:\n@@ -116,6 +116,33 @@ class MaskedLayer(Layer):\n         return self.get_input_mask(train)\n \n \n+class Masking(MaskedLayer):\n+    \"\"\"Mask an input sequence by using a mask value to identify padding.\n+\n+    This layer copies the input to the output layer, while creating an output mask in the process.\n+    This layer is only available with sequences, so its input should be the in\n+    the shape (nb_samples, timesteps, input_dim) and its output is of the shape\n+    (nb_samples, timesteps).\n+\n+    At each timestep, if the values all equal `mask_value`, then the timestep\n+    mask is zero (skipped), otherwise it is 1.\n+\n+    \"\"\"\n+\n+    def __init__(self, mask_value=0):\n+        super(Masking, self).__init__()\n+        self.mask_value = mask_value\n+        self.input = T.tensor3()\n+\n+    def get_output_mask(self, train=False):\n+        X = self.get_input(train)\n+        return T.any(T.ones_like(X) * (1 - T.eq(X, self.mask_value)), axis=-1)\n+\n+    def get_config(self):\n+        return dict(super(Masking, self).get_config(),\n+                    mask_value=self.mask_value)\n+\n+\n class Merge(object):\n     def __init__(self, layers, mode='sum'):\n         ''' Merge the output of a list of layers or containers into a single tensor.\n\n@@ -116,5 +116,34 @@ class TestConfigParams(unittest.TestCase):\n         self._runner(layer)\n \n \n+class TestMasking(unittest.TestCase):\n+    \"\"\"Test the Masking class\"\"\"\n+\n+    def test_sequences(self):\n+        \"\"\"Test masking sequences with zeroes as padding\"\"\"\n+        # integer inputs, one per timestep, like embeddings\n+        layer = core.Masking()\n+        func = theano.function([layer.input], layer.get_output_mask())\n+        self.assertTrue(np.all(\n+            # get mask for this input\n+            func(np.array(\n+            [[[1], [2], [3], [0]],\n+             [[0], [4], [5], [0]]], dtype=np.int32)) ==\n+            # This is the expected output mask, one dimension less\n+            np.array([[1, 1, 1, 0], [0, 1, 1, 0]])))\n+\n+    def test_non_zero(self):\n+        \"\"\"Test masking with non-zero mask value\"\"\"\n+        layer = core.Masking(5)\n+        func = theano.function([layer.input], layer.get_output_mask())\n+        self.assertTrue(np.all(\n+            # get mask for this input, if not all the values are 5, shouldn't masked\n+            func(np.array(\n+            [[[1, 1], [2, 1], [3, 1], [5, 5]],\n+             [[1, 5], [5, 0], [0, 0], [0, 0]]], dtype=np.int32)) ==\n+            # This is the expected output mask, one dimension less\n+            np.array([[1, 1, 1, 0], [1, 1, 1, 1]])))\n+\n+\n if __name__ == '__main__':\n     unittest.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a06e1936793959ae99103924a962fe450cda4959", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 40 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 3 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 40 | Churn Cumulative: 132 | Contributors (this commit): 4 | Commits (past 90d): 9 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -68,3 +68,43 @@ class ParametricSoftplus(MaskedLayer):\n                 \"input_shape\": self.input_shape,\n                 \"alpha_init\": self.alpha_init,\n                 \"beta_init\": self.beta_init}\n+\n+class ThresholdedLinear(MaskedLayer):\n+    '''\n+        Thresholded Linear Activation\n+\n+        Reference:\n+            Zero-Bias Autoencoders and the Benefits of Co-Adapting Features\n+            http://arxiv.org/pdf/1402.3337.pdf\n+    '''\n+    def __init__(self, theta=1.0):\n+        super(ThresholdedLinear, self).__init__()\n+        self.theta = theta\n+    \n+    def get_output(self, train):\n+        X = self.get_input(train)\n+        return T.switch( abs(X) < self.theta, 0, X )\n+\n+    def get_config(self):\n+        return {\"name\": self.__class__.__name__,\n+            \"theta\": self.theta}\n+\n+class ThresholdedReLu(MaskedLayer):\n+    '''\n+        Thresholded Rectified Activation\n+\n+        Reference:\n+            Zero-Bias Autoencoders and the Benefits of Co-Adapting Features\n+            http://arxiv.org/pdf/1402.3337.pdf\n+    '''\n+    def __init__(self, theta=1.0):\n+        super(ThresholdedReLu, self).__init__()\n+        self.theta = theta\n+    \n+    def get_output(self, train):\n+        X = self.get_input(train)\n+        return T.switch( X > self.theta, X, 0 )\n+\n+    def get_config(self):\n+        return {\"name\": self.__class__.__name__,\n+            \"theta\": self.theta}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#48381f8af59d568ddd1ccaf69439329dcf4bad19", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 11 | Files Changed: 1 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 20 | Churn Cumulative: 1669 | Contributors (this commit): 15 | Commits (past 90d): 66 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -119,28 +119,26 @@ class MaskedLayer(Layer):\n class Masking(MaskedLayer):\n     \"\"\"Mask an input sequence by using a mask value to identify padding.\n \n-    This layer copies the input to the output layer, while creating an output mask in the process.\n-    This layer is only available with sequences, so its input should be the in\n-    the shape (nb_samples, timesteps, input_dim) and its output is of the shape\n-    (nb_samples, timesteps).\n+    This layer copies the input to the output layer,\n+    while creating an output mask in the process.\n \n-    At each timestep, if the values all equal `mask_value`, then the timestep\n-    mask is zero (skipped), otherwise it is 1.\n+    At each timestep, if the values all equal `mask_value`,\n+    then the corresponding mask value for the timestep is 0 (skipped),\n+    otherwise it is 1.\n \n     \"\"\"\n-\n-    def __init__(self, mask_value=0):\n+    def __init__(self, mask_value=0.):\n         super(Masking, self).__init__()\n         self.mask_value = mask_value\n         self.input = T.tensor3()\n \n     def get_output_mask(self, train=False):\n         X = self.get_input(train)\n-        return T.any(T.ones_like(X) * (1 - T.eq(X, self.mask_value)), axis=-1)\n+        return T.any(T.ones_like(X) * (1. - T.eq(X, self.mask_value)), axis=-1)\n \n     def get_config(self):\n-        return dict(super(Masking, self).get_config(),\n-                    mask_value=self.mask_value)\n+        return {\"name\": self.__class__.__name__,\n+                \"mask_value\": self.mask_value}\n \n \n class Merge(object):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cb763aa26bda02929d17608ec6601cfdf334c90a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 21 | Churn Cumulative: 1839 | Contributors (this commit): 16 | Commits (past 90d): 72 | Contributors (cumulative): 19 | DMM Complexity: 1.0\n\nDIFF:\n@@ -119,8 +119,8 @@ class MaskedLayer(Layer):\n class Masking(MaskedLayer):\n     \"\"\"Mask an input sequence by using a mask value to identify padding.\n \n-    This layer copies the input to the output layer,\n-    while creating an output mask in the process.\n+    This layer copies the input to the output layer with identified padding\n+    replaced with 0s and creates an output mask in the process.\n \n     At each timestep, if the values all equal `mask_value`,\n     then the corresponding mask value for the timestep is 0 (skipped),\n@@ -136,6 +136,10 @@ class Masking(MaskedLayer):\n         X = self.get_input(train)\n         return T.any(T.ones_like(X) * (1. - T.eq(X, self.mask_value)), axis=-1)\n \n+    def get_output(self, train=False):\n+        X = self.get_input(train)\n+        return X * T.shape_padright(T.any((1. - T.eq(X, self.mask_value)), axis=-1))\n+\n     def get_config(self):\n         return {\"name\": self.__class__.__name__,\n                 \"mask_value\": self.mask_value}\n\n@@ -144,6 +144,19 @@ class TestMasking(unittest.TestCase):\n             # This is the expected output mask, one dimension less\n             np.array([[1, 1, 1, 0], [1, 1, 1, 1]])))\n \n+    def test_non_zero_output(self):\n+        \"\"\"Test output of masking layer with non-zero mask value\"\"\"\n+        layer = core.Masking(5)\n+        func = theano.function([layer.input], layer.get_output())\n+        self.assertTrue(np.all(\n+            # get output for this input, replace padding with 0\n+            func(np.array(\n+            [[[1, 1], [2, 1], [3, 1], [5, 5]],\n+             [[1, 5], [5, 0], [0, 0], [0, 0]]], dtype=np.int32)) ==\n+            # This is the expected output\n+            np.array([[[1, 1], [2, 1], [3, 1], [0, 0]],\n+             [[1, 5], [5, 0], [0, 0], [0, 0]]])))\n+\n \n if __name__ == '__main__':\n     unittest.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#53aaa66994cd6039e5c15566e98a27aa17f2d1d5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 16 | Churn Cumulative: 2574 | Contributors (this commit): 21 | Commits (past 90d): 91 | Contributors (cumulative): 21 | DMM Complexity: 0.0\n\nDIFF:\n@@ -63,13 +63,16 @@ def slice_X(X, start=None, stop=None):\n \n \n def weighted_objective(fn):\n-    def weighted(y_true, y_pred, weights):\n+    def weighted(y_true, y_pred, weights, mask=None):\n         # it's important that 0 * Inf == 0, not NaN, so I need to mask first\n         masked_y_true = y_true[weights.nonzero()[:-1]]\n         masked_y_pred = y_pred[weights.nonzero()[:-1]]\n         masked_weights = weights[weights.nonzero()]\n         obj_output = fn(masked_y_true, masked_y_pred)\n+        if mask is None:\n             return (masked_weights.flatten() * obj_output.flatten()).mean()\n+        else:\n+            return (masked_weights.flatten() * obj_output.flatten()).sum() / mask.sum()\n     return weighted\n \n \n@@ -338,7 +341,8 @@ class Sequential(Model, containers.Sequential):\n             - set_weights\n     '''\n \n-    def compile(self, optimizer, loss, class_mode=\"categorical\", theano_mode=None):\n+    def compile(self, optimizer, loss, class_mode=\"categorical\", theano_mode=None,\n+                mask_cost=False):\n         self.optimizer = optimizers.get(optimizer)\n \n         self.loss = objectives.get(loss)\n@@ -356,8 +360,12 @@ class Sequential(Model, containers.Sequential):\n \n         self.weights = T.ones_like(self.y_train)\n \n-        train_loss = weighted_loss(self.y, self.y_train, self.weights)\n-        test_loss = weighted_loss(self.y, self.y_test, self.weights)\n+        if mask_cost:\n+            mask = self.layers[-1].get_output_mask()\n+        else:\n+            mask = None\n+        train_loss = weighted_loss(self.y, self.y_train, self.weights, mask)\n+        test_loss = weighted_loss(self.y, self.y_test, self.weights, mask)\n \n         train_loss.name = 'train_loss'\n         test_loss.name = 'test_loss'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a79343f5b03407bba225a40e1383f515faee473d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 25 | Churn Cumulative: 25 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,25 @@\n+import numpy as np\n+from keras.models import Sequential\n+from keras.layers.core import TimeDistributedDense, Masking\n+\n+\n+def test_cost_masking():\n+    X = np.array(\n+        [[[1, 1], [2, 1], [3, 1], [5, 5]],\n+         [[1, 5], [5, 0], [0, 0], [0, 0]]], dtype=np.int32)\n+\n+    model = Sequential()\n+    model.add(Masking(mask_value=0))\n+    model.add(TimeDistributedDense(2, 1, init='one'))\n+    model.compile(loss='mse', optimizer='sgd')\n+    y = model.predict(X)\n+\n+    loss = model.fit(X, 4*y, nb_epoch=1, batch_size=2, verbose=1).history['loss'][0]\n+    assert loss == 213.75\n+\n+    model = Sequential()\n+    model.add(Masking(mask_value=0))\n+    model.add(TimeDistributedDense(2, 1, init='one'))\n+    model.compile(loss='mse', optimizer='sgd', mask_cost=True)\n+    loss = model.fit(X, 4*y, nb_epoch=1, batch_size=2, verbose=1).history['loss'][0]\n+    assert loss == 285.0\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f25f894bd9495fcfb8f15460397d74fe64f87acd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 2607 | Contributors (this commit): 21 | Commits (past 90d): 93 | Contributors (cumulative): 22 | DMM Complexity: 1.0\n\nDIFF:\n@@ -72,7 +72,11 @@ def weighted_objective(fn):\n         if mask is None:\n             return (masked_weights.flatten() * obj_output.flatten()).mean()\n         else:\n-            return (masked_weights.flatten() * obj_output.flatten()).sum() / mask.sum()\n+            # We assume the time index to be masked is axis=1\n+            wc = masked_weights * obj_output\n+            wc = wc.reshape(mask.shape)\n+            wc = wc.sum(axis=1) / mask.sum(axis=1)\n+            return wc.mean()\n     return weighted\n \n \n\n@@ -22,4 +22,4 @@ def test_cost_masking():\n     model.add(TimeDistributedDense(2, 1, init='one'))\n     model.compile(loss='mse', optimizer='sgd', mask_cost=True)\n     loss = model.fit(X, 4*y, nb_epoch=1, batch_size=2, verbose=1).history['loss'][0]\n-    assert loss == 285.0\n+    assert loss == 282.375\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#eeb56b9e228472ef3d19cdb5e6fe43322953e21a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 16 | Files Changed: 1 | Hunks: 7 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 25 | Churn Cumulative: 591 | Contributors (this commit): 8 | Commits (past 90d): 16 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -166,13 +166,11 @@ class Adadelta(Optimizer):\n \n class Adam(Optimizer):\n     '''\n-        Reference: http://arxiv.org/abs/1412.6980\n+        Reference: http://arxiv.org/abs/1412.6980v8\n \n-        Default parameters follow those provided in the original paper\n-\n-        lambda is renamed kappa.\n+        Default parameters follow those provided in the original paper.\n     '''\n-    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, kappa=1-1e-8, *args, **kwargs):\n+    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, *args, **kwargs):\n         super(Adam, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n         self.iterations = shared_scalar(0)\n@@ -181,21 +179,17 @@ class Adam(Optimizer):\n         grads = self.get_gradients(loss, params)\n         self.updates = [(self.iterations, self.iterations+1.)]\n \n-        i = self.iterations\n-        beta_1_t = self.beta_1 * (self.kappa**i)\n-\n-        # the update below seems missing from the paper, but is obviously required\n-        beta_2_t = self.beta_2 * (self.kappa**i)\n+        t = self.iterations\n \n         for p, g, c in zip(params, grads, constraints):\n             m = theano.shared(p.get_value() * 0.)  # zero init of moment\n             v = theano.shared(p.get_value() * 0.)  # zero init of velocity\n \n-            m_t = (beta_1_t * m) + (1 - beta_1_t) * g\n-            v_t = (beta_2_t * v) + (1 - beta_2_t) * (g**2)\n+            m_t = (self.beta_1 * m) + (1 - self.beta_1) * g\n+            v_t = (self.beta_2 * v) + (1 - self.beta_2) * (g**2)\n \n-            m_b_t = m_t / (1 - beta_1_t)\n-            v_b_t = v_t / (1 - beta_2_t)\n+            m_b_t = m_t / (1 - self.beta_1**t)\n+            v_b_t = v_t / (1 - self.beta_2**t)\n \n             p_t = p - self.lr * m_b_t / (T.sqrt(v_b_t) + self.epsilon)\n \n@@ -209,8 +203,7 @@ class Adam(Optimizer):\n                 \"lr\": self.lr,\n                 \"beta_1\": self.beta_1,\n                 \"beta_2\": self.beta_2,\n-                \"epsilon\": self.epsilon,\n-                \"kappa\": self.kappa}\n+                \"epsilon\": self.epsilon}\n \n # aliases\n sgd = SGD\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c68aaa21af3f0b065b6017a008c53e92791ed256", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 593 | Contributors (this commit): 8 | Commits (past 90d): 17 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -179,7 +179,7 @@ class Adam(Optimizer):\n         grads = self.get_gradients(loss, params)\n         self.updates = [(self.iterations, self.iterations+1.)]\n \n-        t = self.iterations\n+        t = self.iterations + 1\n \n         for p, g, c in zip(params, grads, constraints):\n             m = theano.shared(p.get_value() * 0.)  # zero init of moment\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#10b767d17ec0fcd3a965e983dbccde7a080b6585", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 600 | Contributors (this commit): 8 | Commits (past 90d): 18 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -187,11 +187,8 @@ class Adam(Optimizer):\n \n             m_t = (self.beta_1 * m) + (1 - self.beta_1) * g\n             v_t = (self.beta_2 * v) + (1 - self.beta_2) * (g**2)\n-\n-            m_b_t = m_t / (1 - self.beta_1**t)\n-            v_b_t = v_t / (1 - self.beta_2**t)\n-\n-            p_t = p - self.lr * m_b_t / (T.sqrt(v_b_t) + self.epsilon)\n+            lr_t = self.lr * T.sqrt(1-self.beta_2**t)/(1-self.beta_1**t)\n+            p_t = p - lr_t * m_t / (T.sqrt(v_t) + self.epsilon)\n \n             self.updates.append((m, m_t))\n             self.updates.append((v, v_t))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9c7c52d9080246b9b2c6de37497640187c450b23", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 602 | Contributors (this commit): 8 | Commits (past 90d): 19 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -180,6 +180,7 @@ class Adam(Optimizer):\n         self.updates = [(self.iterations, self.iterations+1.)]\n \n         t = self.iterations + 1\n+        lr_t = self.lr * T.sqrt(1-self.beta_2**t)/(1-self.beta_1**t)\n \n         for p, g, c in zip(params, grads, constraints):\n             m = theano.shared(p.get_value() * 0.)  # zero init of moment\n@@ -187,7 +188,6 @@ class Adam(Optimizer):\n \n             m_t = (self.beta_1 * m) + (1 - self.beta_1) * g\n             v_t = (self.beta_2 * v) + (1 - self.beta_2) * (g**2)\n-            lr_t = self.lr * T.sqrt(1-self.beta_2**t)/(1-self.beta_1**t)\n             p_t = p - lr_t * m_t / (T.sqrt(v_t) + self.epsilon)\n \n             self.updates.append((m, m_t))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#15a3a1f1ce2a7babf62c61f73709c074249ed840", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 25 | Files Changed: 5 | Hunks: 21 | Methods Changed: 11 | Complexity Δ (Sum/Max): -5/0 | Churn Δ: 43 | Churn Cumulative: 4678 | Contributors (this commit): 28 | Commits (past 90d): 179 | Contributors (cumulative): 44 | DMM Complexity: 1.0\n\nDIFF:\n@@ -12,7 +12,6 @@ from ..regularizers import ActivityRegularizer, Regularizer\n \n from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n from six.moves import zip\n-srng = RandomStreams(seed=np.random.randint(10e6))\n \n \n class Layer(object):\n@@ -223,13 +222,14 @@ class Dropout(MaskedLayer):\n     def __init__(self, p):\n         super(Dropout, self).__init__()\n         self.p = p\n+        self.srng = RandomStreams(seed=np.random.randint(10e6))\n \n     def get_output(self, train=False):\n         X = self.get_input(train)\n         if self.p > 0.:\n             retain_prob = 1. - self.p\n             if train:\n-                X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n+                X *= self.srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n             else:\n                 X *= retain_prob\n         return X\n@@ -512,11 +512,11 @@ class AutoEncoder(Layer):\n         self.constraints = []\n         for layer in [self.encoder, self.decoder]:\n             params, regularizers, constraints = layer.get_params()\n-            self.constraints += constraints\n-            for p, r in zip(params, regularizers):\n+            self.regularizers += regularizers\n+            for p, c in zip(params, constraints):\n                 if p not in self.params:\n                     self.params.append(p)\n-                    self.regularizers.append(r)\n+                    self.constraints.append(c)\n \n         if weights is not None:\n             self.set_weights(weights)\n\n@@ -1,7 +1,9 @@\n from __future__ import absolute_import\n-from .core import srng, MaskedLayer\n+import numpy as np\n+from .core import MaskedLayer\n import theano\n import theano.tensor as T\n+from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n \n \n class GaussianNoise(MaskedLayer):\n@@ -11,13 +13,14 @@ class GaussianNoise(MaskedLayer):\n     def __init__(self, sigma):\n         super(GaussianNoise, self).__init__()\n         self.sigma = sigma\n+        self.srng = RandomStreams(seed=np.random.randint(10e6))\n \n     def get_output(self, train=False):\n         X = self.get_input(train)\n         if not train or self.sigma == 0:\n             return X\n         else:\n-            return X + srng.normal(size=X.shape, avg=0.0, std=self.sigma,\n+            return X + self.srng.normal(size=X.shape, avg=0.0, std=self.sigma,\n                                         dtype=theano.config.floatX)\n \n     def get_config(self):\n@@ -36,12 +39,13 @@ class GaussianDropout(MaskedLayer):\n     def __init__(self, p):\n         super(GaussianDropout, self).__init__()\n         self.p = p\n+        self.srng = RandomStreams(seed=np.random.randint(10e6))\n \n     def get_output(self, train):\n         X = self.get_input(train)\n         if train:\n             # self.p refers to drop probability rather than retain probability (as in paper) to match Dropout layer syntax\n-            X *= srng.normal(size=X.shape, avg=1.0, std=T.sqrt(self.p / (1.0 - self.p)), dtype=theano.config.floatX)\n+            X *= self.srng.normal(size=X.shape, avg=1.0, std=T.sqrt(self.p / (1.0 - self.p)), dtype=theano.config.floatX)\n         return X\n \n     def get_config(self):\n\n@@ -124,7 +124,7 @@ def model_from_config(config):\n         class_mode = config.get('class_mode')\n         theano_mode = config.get('theano_mode')\n \n-        optimizer_params = config.get('optimizer')\n+        optimizer_params = dict([(k, v) for k, v in config.get('optimizer').items()])\n         optimizer_name = optimizer_params.pop('name')\n         optimizer = optimizers.get(optimizer_name, optimizer_params)\n \n@@ -213,9 +213,9 @@ class Model(object):\n \n                 callbacks.on_batch_end(batch_index, batch_logs)\n \n+                epoch_logs = {}\n                 if batch_index == len(batches) - 1:  # last batch\n                     # validation\n-                    epoch_logs = {}\n                     if do_validation:\n                         # replace with self._evaluate\n                         val_outs = self._test_loop(val_f, val_ins, batch_size=batch_size, verbose=0)\n\n@@ -2,6 +2,7 @@ from __future__ import print_function\n import inspect\n import numpy as np\n import theano\n+import copy\n \n from ..layers.advanced_activations import LeakyReLU, PReLU\n from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer\n@@ -15,9 +16,9 @@ from .. import regularizers\n from .. import constraints\n \n \n-def container_from_config(layer_dict):\n+def container_from_config(original_layer_dict):\n+    layer_dict = copy.deepcopy(original_layer_dict)\n     name = layer_dict.get('name')\n-    hasParams = False\n \n     if name == 'Merge':\n         mode = layer_dict.get('mode')\n@@ -57,12 +58,7 @@ def container_from_config(layer_dict):\n         return graph_layer\n \n     else:\n-        # The case in which layer_dict represents an \"atomic\" layer\n         layer_dict.pop('name')\n-        if 'parameters' in layer_dict:\n-            params = layer_dict.get('parameters')\n-            layer_dict.pop('parameters')\n-            hasParams = True\n \n         for k, v in layer_dict.items():\n             # For now, this can only happen for regularizers and constraints\n@@ -75,13 +71,6 @@ def container_from_config(layer_dict):\n                     layer_dict[k] = regularizers.get(vname, v)\n \n         base_layer = get_layer(name, layer_dict)\n-        if hasParams:\n-            shaped_params = []\n-            for param in params:\n-                data = np.asarray(param.get('data'))\n-                shape = tuple(param.get('shape'))\n-                shaped_params.append(data.reshape(shape))\n-            base_layer.set_weights(shaped_params)\n         return base_layer\n \n \n\n@@ -98,4 +98,4 @@ reloaded_graph.get_config(verbose=1)\n reloaded_graph.compile('rmsprop', {'output1': 'mse'})\n new_pred = reloaded_graph.predict({'input1': X_test})\n \n-assert(new_pred['output1'][3][1] == original_pred['output1'][3][1])\n+assert(np.sum(new_pred['output1'] - original_pred['output1']) == 0)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1e3d9f7be11410a0eaf071b3ca68d4ca7bfad86b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 749 | Contributors (this commit): 5 | Commits (past 90d): 25 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -255,7 +255,7 @@ class RemoteMonitor(Callback):\n \n         for k, v in self.totals.items():\n             send[k] = v / self.seen\n-        for k, v in self.logs:\n+        for k, v in logs:\n             send[k] = v\n \n         r = requests.post(self.root + '/publish/epoch/end/', {'data': json.dumps(send)})\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4ecb5bdd14f664129f26d805e9f78c8dd41bba24", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 754 | Contributors (this commit): 5 | Commits (past 90d): 26 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -255,7 +255,10 @@ class RemoteMonitor(Callback):\n \n         for k, v in self.totals.items():\n             send[k] = v / self.seen\n-        for k, v in logs:\n+        for k, v in logs.items():\n             send[k] = v\n \n+        try:\n             r = requests.post(self.root + '/publish/epoch/end/', {'data': json.dumps(send)})\n+        except:\n+            print('Warning: could not reach RemoteMonitor root server at ' + str(self.root))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#de78ddff9c6c14e606fce8d88d04de0eff77319b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 171 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 4 | Complexity Δ (Sum/Max): 19/19 | Churn Δ: 171 | Churn Cumulative: 171 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 0.45454545454545453\n\nDIFF:\n@@ -0,0 +1,171 @@\n+from __future__ import absolute_import\n+from __future__ import print_function\n+import re\n+import tarfile\n+\n+import numpy as np\n+np.random.seed(1337)  # for reproducibility\n+\n+from keras.datasets.data_utils import get_file\n+from keras.layers.embeddings import Embedding\n+from keras.layers.core import Dense, Merge\n+from keras.layers import recurrent\n+from keras.models import Sequential\n+from keras.preprocessing.sequence import pad_sequences\n+\n+'''\n+Trains two recurrent neural networks based upon a story and a question.\n+The resulting merged vector is then queried to answer a range of bAbI tasks.\n+\n+The results are comparable to those for an LSTM model provided in Weston et al.:\n+\"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\"\n+http://arxiv.org/abs/1502.05698\n+\n+For the resources related to the bAbI project, refer to:\n+https://research.facebook.com/researchers/1543934539189348\n+\n+Notes:\n+\n+- With default word, sentence, and query vector sizes, the GRU model achieves:\n+  - 52.1% test accuracy on QA1 in 20 epochs (2 seconds per epoch on CPU)\n+  - 37.0% test accuracy on QA2 in 20 epochs (16 seconds per epoch on CPU)\n+In comparison, the Facebook paper achieves 50% and 20% for the LSTM baseline.\n+\n+- The task does not traditionally parse the question separately. This likely\n+improves accuracy and is a good example of merging two RNNs.\n+\n+- The word vector embeddings are not shared between the story and question RNNs.\n+\n+- See how the accuracy changes given 10,000 training samples (en-10k) instead\n+of only 1000. 1000 was used in order to be comparable to the original paper.\n+\n+- Experiment with GRU, LSTM, and JZS1-3 as they give subtly different results.\n+\n+- The length and noise (i.e. 'useless' story components) impact the ability for\n+LSTMs / GRUs to provide the correct answer. Given only the supporting facts,\n+these RNNs can achieve 100% accuracy on many tasks. Memory networks and neural\n+networks that use attentional processes can efficiently search through this\n+noise to find the relevant statements, improving performance substantially.\n+This becomes especially obvious on QA2 and QA3, both far longer than QA1.\n+'''\n+\n+def tokenize(sent):\n+    '''Return the tokens of a sentence including punctuation.\n+\n+    >>> tokenize('Bob dropped the apple. Where is the apple?')\n+    ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n+    '''\n+    return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]\n+\n+def parse_stories(lines, only_supporting=False):\n+    '''Parse stories provided in the bAbi tasks format\n+\n+    If only_supporting is true, only the sentences that support the answer are kept.\n+    '''\n+    data = []\n+    story = []\n+    for line in lines:\n+        line = line.strip()\n+        nid, line = line.split(' ', 1)\n+        nid = int(nid)\n+        if nid == 1:\n+            story = []\n+        if '\\t' in line:\n+            q, a, supporting = line.split('\\t')\n+            q = tokenize(q)\n+            substory = None\n+            if only_supporting:\n+                # Only select the related substory\n+                supporting = map(int, supporting.split())\n+                substory = [story[i - 1] for i in supporting]\n+            else:\n+                # Provide all the substories\n+                substory = [x for x in story if x]\n+            data.append((substory, q, a))\n+            story.append('')\n+        else:\n+            sent = tokenize(line)\n+            story.append(sent)\n+    return data\n+\n+def get_stories(f, only_supporting=False, max_length=None):\n+    '''Given a file name, read the file, retrieve the stories, and then convert the sentences into a single story.\n+\n+    If max_length is supplied, any stories longer than max_length tokens will be discarded.\n+    '''\n+    data = parse_stories(f.readlines(), only_supporting=only_supporting)\n+    flatten = lambda data: reduce(lambda x, y: x + y, data)\n+    data = [(flatten(story), q, answer) for story, q, answer in data if not max_length or len(flatten(story)) < max_length]\n+    return data\n+\n+def vectorize_stories(data):\n+    X = []\n+    Xq = []\n+    Y = []\n+    for story, query, answer in data:\n+        x = [word_idx[w] for w in story]\n+        xq = [word_idx[w] for w in query]\n+        y = np.zeros(vocab_size)\n+        y[word_idx[answer]] = 1\n+        X.append(x)\n+        Xq.append(xq)\n+        Y.append(y)\n+    return pad_sequences(X, maxlen=story_maxlen), pad_sequences(Xq, maxlen=query_maxlen), np.array(Y)\n+\n+RNN = recurrent.GRU\n+EMBED_HIDDEN_SIZE = 50\n+SENT_HIDDEN_SIZE = 100\n+QUERY_HIDDEN_SIZE = 100\n+BATCH_SIZE = 32\n+EPOCHS = 20\n+print('RNN / Embed / Sent / Query = {}, {}, {}, {}'.format(RNN, EMBED_HIDDEN_SIZE, SENT_HIDDEN_SIZE, QUERY_HIDDEN_SIZE))\n+\n+path = get_file('babi-tasks-v1-2.tar.gz', origin='http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz')\n+tar = tarfile.open(path)\n+# Default QA1 with 1000 samples\n+#challenge = 'tasks_1-20_v1-2/en/qa1_single-supporting-fact_{}.txt'\n+# QA1 with 10,000 samples\n+#challenge = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt'\n+# QA2 with 1000 samples\n+challenge = 'tasks_1-20_v1-2/en/qa2_two-supporting-facts_{}.txt'\n+# QA2 with 1000 samples\n+#challenge = 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt'\n+train = get_stories(tar.extractfile(challenge.format('train')))\n+test = get_stories(tar.extractfile(challenge.format('test')))\n+\n+vocab = sorted(reduce(lambda x, y: x | y, (set(story + q) for story, q, answer in train + test)))\n+# Reserve 0 for masking via pad_sequences\n+vocab_size = len(vocab) + 1\n+word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n+story_maxlen = max(map(len, (x for x, _, _ in train + test)))\n+query_maxlen = max(map(len, (x for _, x, _ in train + test)))\n+\n+X, Xq, Y = vectorize_stories(train)\n+tX, tXq, tY = vectorize_stories(test)\n+\n+print('vocab = {}'.format(vocab))\n+print('X.shape = {}'.format(X.shape))\n+print('Xq.shape = {}'.format(Xq.shape))\n+print('Y.shape = {}'.format(Y.shape))\n+print('story_maxlen, query_maxlen = {}, {}'.format(story_maxlen, query_maxlen))\n+\n+print('Build model...')\n+\n+sentrnn = Sequential()\n+sentrnn.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE, mask_zero=True))\n+sentrnn.add(RNN(EMBED_HIDDEN_SIZE, SENT_HIDDEN_SIZE, return_sequences=False))\n+\n+qrnn = Sequential()\n+qrnn.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE))\n+qrnn.add(RNN(EMBED_HIDDEN_SIZE, QUERY_HIDDEN_SIZE, return_sequences=False))\n+\n+model = Sequential()\n+model.add(Merge([sentrnn, qrnn], mode='concat'))\n+model.add(Dense(SENT_HIDDEN_SIZE + QUERY_HIDDEN_SIZE, vocab_size, activation='softmax'))\n+\n+model.compile(optimizer='adam', loss='categorical_crossentropy', class_mode='categorical')\n+\n+print('Training')\n+model.fit([X, Xq], Y, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, validation_split=0.05, show_accuracy=True)\n+loss, acc = model.evaluate([tX, tXq], tY, batch_size=BATCH_SIZE, show_accuracy=True)\n+print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#37965cae6b6746f22a00d04e0b963a297c51f940", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 177 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -49,6 +49,7 @@ noise to find the relevant statements, improving performance substantially.\n This becomes especially obvious on QA2 and QA3, both far longer than QA1.\n '''\n \n+\n def tokenize(sent):\n     '''Return the tokens of a sentence including punctuation.\n \n@@ -57,6 +58,7 @@ def tokenize(sent):\n     '''\n     return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]\n \n+\n def parse_stories(lines, only_supporting=False):\n     '''Parse stories provided in the bAbi tasks format\n \n@@ -88,6 +90,7 @@ def parse_stories(lines, only_supporting=False):\n             story.append(sent)\n     return data\n \n+\n def get_stories(f, only_supporting=False, max_length=None):\n     '''Given a file name, read the file, retrieve the stories, and then convert the sentences into a single story.\n \n@@ -98,6 +101,7 @@ def get_stories(f, only_supporting=False, max_length=None):\n     data = [(flatten(story), q, answer) for story, q, answer in data if not max_length or len(flatten(story)) < max_length]\n     return data\n \n+\n def vectorize_stories(data):\n     X = []\n     Xq = []\n@@ -128,7 +132,7 @@ tar = tarfile.open(path)\n # challenge = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt'\n # QA2 with 1000 samples\n challenge = 'tasks_1-20_v1-2/en/qa2_two-supporting-facts_{}.txt'\n-# QA2 with 1000 samples\n+# QA2 with 10,000 samples\n # challenge = 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt'\n train = get_stories(tar.extractfile(challenge.format('train')))\n test = get_stories(tar.extractfile(challenge.format('test')))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#149d0e8d1871a7864fc2d582d6ce650512de371c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 233 | Contributors (this commit): 6 | Commits (past 90d): 25 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -49,6 +49,9 @@ def binary_crossentropy(y_true, y_pred):\n     bce = T.nnet.binary_crossentropy(y_pred, y_true).mean(axis=-1)\n     return bce\n \n+def poisson_loss(y_true, y_pred):\n+    return T.mean(y_pred - y_true * T.log(y_pred), axis=-1)\n+\n # aliases\n mse = MSE = mean_squared_error\n mae = MAE = mean_absolute_error\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6fddf15f1f04487e098bf47f56d7224d2e82e335", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 7 | Churn Cumulative: 43 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2,10 +2,13 @@ from __future__ import absolute_import\n from __future__ import print_function\n \n import tarfile, inspect, os\n-from six.moves.urllib.request import urlretrieve\n+from six.moves.urllib.request import FancyURLopener\n \n from ..utils.generic_utils import Progbar\n \n+class ParanoidURLopener(FancyURLopener):\n+  def http_error_default(self, url, fp, errcode, errmsg, headers):\n+    raise Exception('URL fetch failure on {}: {} -- {}'.format(url, errcode, errmsg))\n \n def get_file(fname, origin, untar=False):\n     datadir = os.path.expanduser(os.path.join('~', '.keras', 'datasets'))\n@@ -33,7 +36,7 @@ def get_file(fname, origin, untar=False):\n             else:\n                 progbar.update(count*block_size)\n \n-        urlretrieve(origin, fpath, dl_progress)\n+        ParanoidURLopener().retrieve(origin, fpath, dl_progress)\n         progbar = None\n \n     if untar:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1d6b60c1ad50ffe88eb5f0f613cf28e2e955a253", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 9 | Churn Cumulative: 2593 | Contributors (this commit): 21 | Commits (past 90d): 89 | Contributors (cumulative): 21 | DMM Complexity: 0.0\n\nDIFF:\n@@ -77,15 +77,18 @@ def standardize_weights(y, sample_weight=None, class_weight=None):\n     if sample_weight is not None:\n         return standardize_y(sample_weight)\n     elif isinstance(class_weight, dict):\n-        if len(y.shape) > 2:\n-            raise Exception('class_weight not supported for 3+ dimensional targets.')\n+        if len(y.shape) > 3:\n+            raise Exception('class_weight not supported for 4+ dimensional targets.')\n+        yshape = y.shape\n+        y = np.reshape(y, (-1,yshape[-1])) # for time-distributed data, collapse time and sample\n         if y.shape[1] > 1:\n             y_classes = y.argmax(axis=1)\n         elif y.shape[1] == 1:\n             y_classes = np.reshape(y, y.shape[0])\n         else:\n             y_classes = y\n-        return np.expand_dims(np.array(list(map(lambda x: class_weight[x], y_classes))), 1)\n+        class_weights = np.asarray([class_weight[cls] for cls in y_classes])\n+        return np.reshape(class_weights, yshape[:-1] + (1,)) # uncollapse initial dimensions\n     else:\n         return np.ones(y.shape[:-1] + (1,))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6d17e9994e082a8f2b31a98a56e9df1ccb37e43c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 489 | Contributors (this commit): 7 | Commits (past 90d): 18 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -89,19 +89,19 @@ class MaxPooling1D(Layer):\n         self.pool_length = pool_length\n         self.stride = stride\n         if self.stride:\n-            self.st = (1, self.stride)\n+            self.st = (self.stride, 1)\n         else:\n             self.st = None\n \n         self.input = T.tensor3()\n-        self.poolsize = (1, pool_length)\n+        self.poolsize = (pool_length, 1)\n         self.ignore_border = ignore_border\n \n     def get_output(self, train):\n         X = self.get_input(train)\n-        X = T.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1)).dimshuffle(0, 1, 3, 2)\n+        X = T.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1)).dimshuffle(0, 2, 1, 3)\n         output = T.signal.downsample.max_pool_2d(X, ds=self.poolsize, st=self.st, ignore_border=self.ignore_border)\n-        output = output.dimshuffle(0, 1, 3, 2)\n+        output = output.dimshuffle(0, 2, 1, 3)\n         return T.reshape(output, (output.shape[0], output.shape[1], output.shape[2]))\n \n     def get_config(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#63284a47ffc83e4855004929daa42621e275a1e8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 179 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -137,7 +137,7 @@ challenge = 'tasks_1-20_v1-2/en/qa2_two-supporting-facts_{}.txt'\n train = get_stories(tar.extractfile(challenge.format('train')))\n test = get_stories(tar.extractfile(challenge.format('test')))\n \n-vocab = sorted(reduce(lambda x, y: x | y, (set(story + q) for story, q, answer in train + test)))\n+vocab = sorted(reduce(lambda x, y: x | y, (set(story + q + [answer]) for story, q, answer in train + test)))\n # Reserve 0 for masking via pad_sequences\n vocab_size = len(vocab) + 1\n word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dbc0c277295dcb49b1c508db614f4e24b7337828", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 182 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -1,5 +1,6 @@\n from __future__ import absolute_import\n from __future__ import print_function\n+from functools import reduce\n import re\n import tarfile\n \n@@ -67,7 +68,7 @@ def parse_stories(lines, only_supporting=False):\n     data = []\n     story = []\n     for line in lines:\n-        line = line.strip()\n+        line = line.decode('utf-8').strip()\n         nid, line = line.split(' ', 1)\n         nid = int(nid)\n         if nid == 1:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#342f2bc271720a22c04e3986df4fc1530624a6cf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 23 | Churn Cumulative: 205 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -22,6 +22,29 @@ The results are comparable to those for an LSTM model provided in Weston et al.:\n \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\"\n http://arxiv.org/abs/1502.05698\n \n+Task Number                  | FB LSTM Baseline | Keras QA\n+---                          | ---              | ---\n+QA1 - Single Supporting Fact | 50               | 52.1\n+QA2 - Two Supporting Facts   | 20               | 37.0\n+QA3 - Three Supporting Facts | 20               | 20.5\n+QA4 - Two Arg. Relations     | 61               | 62.9\n+QA5 - Three Arg. Relations   | 70               | 61.9\n+QA6 - Yes/No Questions       | 48               | 50.7\n+QA7 - Counting               | 49               | 78.9\n+QA8 - Lists/Sets             | 45               | 77.2\n+QA9 - Simple Negation        | 64               | 64.0\n+QA10 - Indefinite Knowledge  | 44               | 47.7\n+QA11 - Basic Coreference     | 72               | 74.9\n+QA12 - Conjunction           | 74               | 76.4\n+QA13 - Compound Coreference  | 94               | 94.4\n+QA14 - Time Reasoning        | 27               | 34.8\n+QA15 - Basic Deduction       | 21               | 32.4\n+QA16 - Basic Induction       | 23               | 50.6\n+QA17 - Positional Reasoning  | 51               | 49.1\n+QA18 - Size Reasoning        | 52               | 90.8\n+QA19 - Path Finding          | 8                | 9.0\n+QA20 - Agent's Motivations   | 91               | 90.7\n+\n For the resources related to the bAbI project, refer to:\n https://research.facebook.com/researchers/1543934539189348\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
