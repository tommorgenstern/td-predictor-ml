{"custom_id": "keras#13402f1d2d55c55087d84d80769cefe8b890c48f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 420 | Contributors (this commit): 18 | Commits (past 90d): 14 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -23,4 +23,4 @@ from .layers import Input\n from .models import Model\r\n from .models import Sequential\r\n \r\n-__version__ = '2.1.2'\r\n+__version__ = '2.1.3'\r\n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='2.1.2',\n+      version='2.1.3',\n       description='Deep Learning for humans',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/keras-team/keras',\n-      download_url='https://github.com/keras-team/keras/tarball/2.1.2',\n+      download_url='https://github.com/keras-team/keras/tarball/2.1.3',\n       license='MIT',\n       install_requires=['numpy>=1.9.1',\n                         'scipy>=0.14',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#53ec990d54130dd0a457dd235c93d39de32d571d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 43 | Lines Deleted: 48 | Files Changed: 1 | Hunks: 12 | Methods Changed: 12 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 91 | Churn Cumulative: 1023 | Contributors (this commit): 8 | Commits (past 90d): 6 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,4 +1,7 @@\n import pytest\n+import numpy as np\n+import time\n+import random\n import os\n from multiprocessing import Process, Queue\n from keras.utils.test_utils import keras_test\n@@ -14,6 +17,13 @@ pytestmark = pytest.mark.skipif(\n     reason='runs only when the relevant files have been modified')\n \n \n+DENSENET_LIST = [(applications.DenseNet121, 1024),\n+                 (applications.DenseNet169, 1664),\n+                 (applications.DenseNet201, 1920)]\n+NASNET_LIST = [(applications.NASNetMobile, 1056),\n+               (applications.NASNetLarge, 4032)]\n+\n+\n def clean_run(model_fn):\n     if K.backend() == 'cntk':\n         # Create model in a subprocess so that the memory consumed by InceptionResNetV2 will be\n@@ -292,12 +302,10 @@ def test_mobilenet_image_size():\n \n \n @keras_test\n-@pytest.mark.parametrize('fun', [\n-    applications.DenseNet121,\n-    applications.DenseNet169,\n-    applications.DenseNet201],\n-    ids=['DenseNet121', 'DenseNet169', 'DenseNet201'])\n-def test_densenet(fun):\n+def test_densenet():\n+    random.seed(time.time())\n+    fun, _ = random.choice(DENSENET_LIST)\n+\n     def model_fn():\n         return fun(weights=None)\n     output_shape = clean_run(model_fn)\n@@ -305,12 +313,10 @@ def test_densenet(fun):\n \n \n @keras_test\n-@pytest.mark.parametrize('fun,dim', [\n-    (applications.DenseNet121, 1024),\n-    (applications.DenseNet169, 1664),\n-    (applications.DenseNet201, 1920)],\n-    ids=['DenseNet121', 'DenseNet169', 'DenseNet201'])\n-def test_densenet_no_top(fun, dim):\n+def test_densenet_no_top():\n+    random.seed(time.time())\n+    fun, dim = random.choice(DENSENET_LIST)\n+\n     def model_fn():\n         return fun(weights=None, include_top=False)\n     output_shape = clean_run(model_fn)\n@@ -318,12 +324,10 @@ def test_densenet_no_top(fun, dim):\n \n \n @keras_test\n-@pytest.mark.parametrize('fun,dim', [\n-    (applications.DenseNet121, 1024),\n-    (applications.DenseNet169, 1664),\n-    (applications.DenseNet201, 1920)],\n-    ids=['DenseNet121', 'DenseNet169', 'DenseNet201'])\n-def test_densenet_pooling(fun, dim):\n+def test_densenet_pooling():\n+    random.seed(time.time())\n+    fun, dim = random.choice(DENSENET_LIST)\n+\n     def model_fn():\n         return fun(weights=None, include_top=False, pooling='avg')\n     output_shape = clean_run(model_fn)\n@@ -331,12 +335,10 @@ def test_densenet_pooling(fun, dim):\n \n \n @keras_test\n-@pytest.mark.parametrize('fun,dim', [\n-    (applications.DenseNet121, 1024),\n-    (applications.DenseNet169, 1664),\n-    (applications.DenseNet201, 1920)],\n-    ids=['DenseNet121', 'DenseNet169', 'DenseNet201'])\n-def test_densenet_variable_input_channels(fun, dim):\n+def test_densenet_variable_input_channels():\n+    random.seed(time.time())\n+    fun, dim = random.choice(DENSENET_LIST)\n+\n     def model_fn(input_shape):\n         return fun(weights=None, include_top=False, input_shape=input_shape)\n     output_shape = clean_run(lambda: model_fn((None, None, 1)))\n@@ -350,10 +352,9 @@ def test_densenet_variable_input_channels(fun, dim):\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n                     reason='NASNets are supported only on TensorFlow')\n def test_nasnet():\n-    model = applications.NASNetMobile(weights=None)\n-    assert model.output_shape == (None, 1000)\n-\n-    model = applications.NASNetLarge(weights=None)\n+    random.seed(time.time())\n+    fun, _ = random.choice(NASNET_LIST)\n+    model = fun(weights=None)\n     assert model.output_shape == (None, 1000)\n \n \n@@ -361,41 +362,35 @@ def test_nasnet():\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n                     reason='NASNets are supported only on TensorFlow')\n def test_nasnet_no_top():\n-    model = applications.NASNetMobile(weights=None, include_top=False)\n-    assert model.output_shape == (None, None, None, 1056)\n-\n-    model = applications.NASNetLarge(weights=None, include_top=False)\n-    assert model.output_shape == (None, None, None, 4032)\n+    random.seed(time.time())\n+    fun, dim = random.choice(NASNET_LIST)\n+    model = fun(weights=None, include_top=False)\n+    assert model.output_shape == (None, None, None, dim)\n \n \n @keras_test\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n                     reason='NASNets are supported only on TensorFlow')\n def test_nasnet_pooling():\n-    model = applications.NASNetMobile(weights=None, include_top=False, pooling='avg')\n-    assert model.output_shape == (None, 1056)\n-\n-    model = applications.NASNetLarge(weights=None, include_top=False, pooling='avg')\n-    assert model.output_shape == (None, 4032)\n+    random.seed(time.time())\n+    fun, dim = random.choice(NASNET_LIST)\n+    model = fun(weights=None, include_top=False, pooling='avg')\n+    assert model.output_shape == (None, dim)\n \n \n @keras_test\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n                     reason='NASNets are supported only on TensorFlow')\n def test_nasnet_variable_input_channels():\n+    random.seed(time.time())\n+    fun, dim = random.choice(NASNET_LIST)\n     input_shape = (1, None, None) if K.image_data_format() == 'channels_first' else (None, None, 1)\n-    model = applications.NASNetMobile(weights=None, include_top=False, input_shape=input_shape)\n-    assert model.output_shape == (None, None, None, 1056)\n-\n-    model = applications.NASNetLarge(weights=None, include_top=False, input_shape=input_shape)\n-    assert model.output_shape == (None, None, None, 4032)\n+    model = fun(weights=None, include_top=False, input_shape=input_shape)\n+    assert model.output_shape == (None, None, None, dim)\n \n     input_shape = (4, None, None) if K.image_data_format() == 'channels_first' else (None, None, 4)\n-    model = applications.NASNetMobile(weights=None, include_top=False, input_shape=input_shape)\n-    assert model.output_shape == (None, None, None, 1056)\n-\n-    model = applications.NASNetLarge(weights=None, include_top=False, input_shape=input_shape)\n-    assert model.output_shape == (None, None, None, 4032)\n+    model = fun(weights=None, include_top=False, input_shape=input_shape)\n+    assert model.output_shape == (None, None, None, dim)\n \n \n @pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TF backend')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#64f80d6077edd5f277a1181df94bf4510ea0517a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 10157 | Contributors (this commit): 52 | Commits (past 90d): 32 | Contributors (cumulative): 61 | DMM Complexity: 1.0\n\nDIFF:\n@@ -106,7 +106,7 @@ class StackedRNNCells(Layer):\n                 output_dim = cell.state_size[0]\n             else:\n                 output_dim = cell.state_size\n-            input_shape = (input_shape[0], input_shape[1], output_dim)\n+            input_shape = (input_shape[0], output_dim)\n         self.built = True\n \n     def get_config(self):\n\n@@ -517,6 +517,9 @@ def test_minimal_rnn_cell_layer():\n             super(MinimalRNNCell, self).__init__(**kwargs)\n \n         def build(self, input_shape):\n+            # no time axis in the input shape passed to RNN cells\n+            assert len(input_shape) == 2\n+\n             self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                           initializer='uniform',\n                                           name='kernel')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7113063a93ef8d77c6d7d21a2756c1ac802d83de", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 70 | Lines Deleted: 56 | Files Changed: 1 | Hunks: 25 | Methods Changed: 4 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 126 | Churn Cumulative: 843 | Contributors (this commit): 4 | Commits (past 90d): 10 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -113,7 +113,7 @@ def lr_schedule(epoch):\n     return lr\n \n \n-def resnet_block(inputs,\n+def resnet_layer(inputs,\n                  num_filters=16,\n                  kernel_size=3,\n                  strides=1,\n@@ -135,29 +135,26 @@ def resnet_block(inputs,\n     # Returns\n         x (tensor): tensor as input to the next layer\n     \"\"\"\n+    conv = Conv2D(num_filters,\n+                  kernel_size=kernel_size,\n+                  strides=strides,\n+                  padding='same',\n+                  kernel_initializer='he_normal',\n+                  kernel_regularizer=l2(1e-4))\n+\n     x = inputs\n     if conv_first:\n-        x = Conv2D(num_filters,\n-                   kernel_size=kernel_size,\n-                   strides=strides,\n-                   padding='same',\n-                   kernel_initializer='he_normal',\n-                   kernel_regularizer=l2(1e-4))(x)\n+        x = conv(x)\n         if batch_normalization:\n             x = BatchNormalization()(x)\n-        if activation:\n+        if activation is not None:\n             x = Activation(activation)(x)\n-        return x\n+    else:\n         if batch_normalization:\n             x = BatchNormalization()(x)\n-    if activation:\n-        x = Activation('relu')(x)\n-    x = Conv2D(num_filters,\n-               kernel_size=kernel_size,\n-               strides=strides,\n-               padding='same',\n-               kernel_initializer='he_normal',\n-               kernel_regularizer=l2(1e-4))(x)\n+        if activation is not None:\n+            x = Activation(activation)(x)\n+        x = conv(x)\n     return x\n \n \n@@ -166,8 +163,14 @@ def resnet_v1(input_shape, depth, num_classes=10):\n \n     Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n     Last ReLU is after the shortcut connection.\n-    The number of filters doubles when the feature maps size\n-    is halved.\n+    At the beginning of each stage, the feature map size is halved (downsampled)\n+    by a convolutional layer with strides=2, while the number of filters is\n+    doubled. Within each stage, the layers have the same number filters and the\n+    same number of filters.\n+    Features maps sizes:\n+    stage 0: 32x32, 16\n+    stage 1: 16x16, 32\n+    stage 2:  8x8,  64\n     The Number of parameters is approx the same as Table 6 of [a]:\n     ResNet20 0.27M\n     ResNet32 0.46M\n@@ -186,26 +189,27 @@ def resnet_v1(input_shape, depth, num_classes=10):\n     if (depth - 2) % 6 != 0:\n         raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n     # Start model definition.\n-    inputs = Input(shape=input_shape)\n     num_filters = 16\n-    num_sub_blocks = int((depth - 2) / 6)\n+    num_res_blocks = int((depth - 2) / 6)\n \n-    x = resnet_block(inputs=inputs)\n-    # Instantiate convolutional base (stack of blocks).\n-    for i in range(3):\n-        for j in range(num_sub_blocks):\n+    inputs = Input(shape=input_shape)\n+    x = resnet_layer(inputs=inputs)\n+    # Instantiate the stack of residual units\n+    for stack in range(3):\n+        for res_block in range(num_res_blocks):\n             strides = 1\n-            is_first_layer_but_not_first_block = j == 0 and i > 0\n-            if is_first_layer_but_not_first_block:\n-                strides = 2\n-            y = resnet_block(inputs=x,\n+            if stack > 0 and res_block == 0:  # first layer but not first stack\n+                strides = 2  # downsample\n+            y = resnet_layer(inputs=x,\n                              num_filters=num_filters,\n                              strides=strides)\n-            y = resnet_block(inputs=y,\n+            y = resnet_layer(inputs=y,\n                              num_filters=num_filters,\n                              activation=None)\n-            if is_first_layer_but_not_first_block:\n-                x = resnet_block(inputs=x,\n+            if stack > 0 and res_block == 0:  # first layer but not first stack\n+                # linear projection residual shortcut connection to match\n+                # changed dims\n+                x = resnet_layer(inputs=x,\n                                  num_filters=num_filters,\n                                  kernel_size=1,\n                                  strides=strides,\n@@ -213,7 +217,7 @@ def resnet_v1(input_shape, depth, num_classes=10):\n                                  batch_normalization=False)\n             x = keras.layers.add([x, y])\n             x = Activation('relu')(x)\n-        num_filters = 2 * num_filters\n+        num_filters *= 2\n \n     # Add classifier on top.\n     # v1 does not use BN after last shortcut connection-ReLU\n@@ -235,7 +239,15 @@ def resnet_v2(input_shape, depth, num_classes=10):\n     bottleneck layer\n     First shortcut connection per layer is 1 x 1 Conv2D.\n     Second and onwards shortcut connection is identity.\n-    Features maps sizes: 16(input), 64(1st sub_block), 128(2nd), 256(3rd)\n+    At the beginning of each stage, the feature map size is halved (downsampled)\n+    by a convolutional layer with strides=2, while the number of filter maps is\n+    doubled. Within each stage, the layers have the same number filters and the\n+    same filter map sizes.\n+    Features maps sizes:\n+    conv1  : 32x32,  16\n+    stage 0: 32x32,  64\n+    stage 1: 16x16, 128\n+    stage 2:  8x8,  256\n \n     # Arguments\n         input_shape (tensor): shape of input image tensor\n@@ -248,48 +260,50 @@ def resnet_v2(input_shape, depth, num_classes=10):\n     if (depth - 2) % 9 != 0:\n         raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n     # Start model definition.\n-    inputs = Input(shape=input_shape)\n     num_filters_in = 16\n-    num_filters_out = 64\n-    filter_multiplier = 4\n-    num_sub_blocks = int((depth - 2) / 9)\n+    num_res_blocks = int((depth - 2) / 9)\n \n+    inputs = Input(shape=input_shape)\n     # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n-    x = resnet_block(inputs=inputs,\n+    x = resnet_layer(inputs=inputs,\n                      num_filters=num_filters_in,\n                      conv_first=True)\n \n-    # Instantiate convolutional base (stack of blocks).\n+    # Instantiate the stack of residual units\n+    for stage in range(3):\n+        for res_block in range(num_res_blocks):\n+            activation = 'relu'\n+            batch_normalization = True\n+            strides = 1\n+            if stage == 0:\n+                num_filters_out = num_filters_in * 4\n+                if res_block == 0:  # first layer and first stage\n                     activation = None\n                     batch_normalization = False\n-    for i in range(3):\n-        if i > 0:\n-            filter_multiplier = 2\n-        num_filters_out = num_filters_in * filter_multiplier\n+            else:\n+                num_filters_out = num_filters_in * 2\n+                if res_block == 0:  # first layer but not first stage\n+                    strides = 2    # downsample\n \n-        for j in range(num_sub_blocks):\n-            strides = 1\n-            is_first_layer_but_not_first_block = j == 0 and i > 0\n-            if is_first_layer_but_not_first_block:\n-                strides = 2\n-            y = resnet_block(inputs=x,\n+            # bottleneck residual unit\n+            y = resnet_layer(inputs=x,\n                              num_filters=num_filters_in,\n                              kernel_size=1,\n                              strides=strides,\n                              activation=activation,\n                              batch_normalization=batch_normalization,\n                              conv_first=False)\n-            activation = 'relu'\n-            batch_normalization = True\n-            y = resnet_block(inputs=y,\n+            y = resnet_layer(inputs=y,\n                              num_filters=num_filters_in,\n                              conv_first=False)\n-            y = resnet_block(inputs=y,\n+            y = resnet_layer(inputs=y,\n                              num_filters=num_filters_out,\n                              kernel_size=1,\n                              conv_first=False)\n-            if j == 0:\n-                x = resnet_block(inputs=x,\n+            if res_block == 0:\n+                # linear projection residual shortcut connection to match\n+                # changed dims\n+                x = resnet_layer(inputs=x,\n                                  num_filters=num_filters_out,\n                                  kernel_size=1,\n                                  strides=strides,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#149272a25af10bda7bb58205a162f6bc590ef488", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 13 | Churn Cumulative: 1360 | Contributors (this commit): 15 | Commits (past 90d): 15 | Contributors (cumulative): 15 | DMM Complexity: 1.0\n\nDIFF:\n@@ -468,16 +468,27 @@ class OrderedEnqueuer(SequenceEnqueuer):\n                  use_multiprocessing=False,\n                  shuffle=False):\n         self.sequence = sequence\n+        self.use_multiprocessing = use_multiprocessing\n \n         global _SEQUENCE_COUNTER\n         if _SEQUENCE_COUNTER is None:\n+            try:\n                 _SEQUENCE_COUNTER = multiprocessing.Value('i', 0)\n+            except OSError:\n+                # In this case the OS does not allow us to use\n+                # multiprocessing. We resort to an int\n+                # for enqueuer indexing.\n+                _SEQUENCE_COUNTER = 0\n \n+        if isinstance(_SEQUENCE_COUNTER, int):\n+            self.uid = _SEQUENCE_COUNTER\n+            _SEQUENCE_COUNTER += 1\n+        else:\n             # Doing Multiprocessing.Value += x is not process-safe.\n             with _SEQUENCE_COUNTER.get_lock():\n                 self.uid = _SEQUENCE_COUNTER.value\n                 _SEQUENCE_COUNTER.value += 1\n-        self.use_multiprocessing = use_multiprocessing\n+\n         self.shuffle = shuffle\n         self.workers = 0\n         self.executor_fn = None\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a6542e845e9af539ba2def25b36e4afdc1162f0a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 8 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 110 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -8,21 +8,19 @@ from keras import regularizers\n \n data_dim = 5\n num_classes = 2\n-epochs = 1\n batch_size = 10\n \n \n def get_data():\n-    (x_train, y_train), (x_test, y_test) = test_utils.get_test_data(\n+    (x_train, y_train), _ = test_utils.get_test_data(\n         num_train=batch_size,\n         num_test=batch_size,\n         input_shape=(data_dim,),\n         classification=True,\n         num_classes=num_classes)\n     y_train = np_utils.to_categorical(y_train, num_classes)\n-    y_test = np_utils.to_categorical(y_test, num_classes)\n \n-    return (x_train, y_train), (x_test, y_test)\n+    return x_train, y_train\n \n \n def create_model(kernel_regularizer=None, activity_regularizer=None):\n@@ -35,25 +33,23 @@ def create_model(kernel_regularizer=None, activity_regularizer=None):\n \n \n def test_kernel_regularization():\n-    (x_train, y_train), (x_test, y_test) = get_data()\n+    x_train, y_train = get_data()\n     for reg in [regularizers.l1(),\n                 regularizers.l2(),\n                 regularizers.l1_l2()]:\n         model = create_model(kernel_regularizer=reg)\n         model.compile(loss='categorical_crossentropy', optimizer='sgd')\n         assert len(model.losses) == 1\n-        model.fit(x_train, y_train, batch_size=batch_size,\n-                  epochs=epochs, verbose=0)\n+        model.train_on_batch(x_train, y_train)\n \n \n def test_activity_regularization():\n-    (x_train, y_train), (x_test, y_test) = get_data()\n+    x_train, y_train = get_data()\n     for reg in [regularizers.l1(), regularizers.l2()]:\n         model = create_model(activity_regularizer=reg)\n         model.compile(loss='categorical_crossentropy', optimizer='sgd')\n         assert len(model.losses) == 1\n-        model.fit(x_train, y_train, batch_size=batch_size,\n-                  epochs=epochs, verbose=0)\n+        model.train_on_batch(x_train, y_train)\n \n \n if __name__ == '__main__':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#950e5d063320a72ca61f2082c154a65a48766239", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 41 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 7 | Methods Changed: 4 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 42 | Churn Cumulative: 10199 | Contributors (this commit): 52 | Commits (past 90d): 34 | Contributors (cumulative): 61 | DMM Complexity: 0.0\n\nDIFF:\n@@ -73,7 +73,7 @@ class StackedRNNCells(Layer):\n                 state_size.append(cell.state_size)\n         return tuple(state_size)\n \n-    def call(self, inputs, states, **kwargs):\n+    def call(self, inputs, states, constants=None, **kwargs):\n         # Recover per-cell states.\n         nested_states = []\n         for cell in self.cells[::-1]:\n@@ -88,6 +88,11 @@ class StackedRNNCells(Layer):\n         # Call the cells in order and store the returned states.\n         new_nested_states = []\n         for cell, states in zip(self.cells, nested_states):\n+            if has_arg(cell.call, 'constants'):\n+                inputs, states = cell.call(inputs, states,\n+                                           constants=constants,\n+                                           **kwargs)\n+            else:\n                 inputs, states = cell.call(inputs, states, **kwargs)\n             new_nested_states.append(states)\n \n@@ -99,8 +104,14 @@ class StackedRNNCells(Layer):\n         return inputs, states\n \n     def build(self, input_shape):\n+        if isinstance(input_shape, list):\n+            constants_shape = input_shape[1:]\n+            input_shape = input_shape[0]\n         for cell in self.cells:\n             if isinstance(cell, Layer):\n+                if has_arg(cell.call, 'constants'):\n+                    cell.build([input_shape] + constants_shape)\n+                else:\n                     cell.build(input_shape)\n             if hasattr(cell.state_size, '__len__'):\n                 output_dim = cell.state_size[0]\n\n@@ -698,6 +698,7 @@ def test_batch_size_equal_one(layer_class):\n     model.train_on_batch(x, y)\n \n \n+@keras_test\n def test_rnn_cell_with_constants_layer():\n \n     class RNNCellWithConstants(keras.layers.Layer):\n@@ -778,7 +779,35 @@ def test_rnn_cell_with_constants_layer():\n     y_np_3 = model.predict([x_np, c_np])\n     assert_allclose(y_np, y_np_3, atol=1e-4)\n \n+    # Test stacking.\n+    cells = [recurrent.GRUCell(8),\n+             RNNCellWithConstants(12),\n+             RNNCellWithConstants(32)]\n+    layer = recurrent.RNN(cells)\n+    y = layer(x, constants=c)\n+    model = keras.models.Model([x, c], y)\n+    model.compile(optimizer='rmsprop', loss='mse')\n+    model.train_on_batch(\n+        [np.zeros((6, 5, 5)), np.zeros((6, 3))],\n+        np.zeros((6, 32))\n+    )\n \n+    # Test stacked RNN serialization.\n+    x_np = np.random.random((6, 5, 5))\n+    c_np = np.random.random((6, 3))\n+    y_np = model.predict([x_np, c_np])\n+    weights = model.get_weights()\n+    config = layer.get_config()\n+    with keras.utils.CustomObjectScope(custom_objects):\n+        layer = recurrent.RNN.from_config(config.copy())\n+    y = layer(x, constants=c)\n+    model = keras.models.Model([x, c], y)\n+    model.set_weights(weights)\n+    y_np_2 = model.predict([x_np, c_np])\n+    assert_allclose(y_np, y_np_2, atol=1e-4)\n+\n+\n+@keras_test\n def test_rnn_cell_with_constants_layer_passing_initial_state():\n \n     class RNNCellWithConstants(keras.layers.Layer):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#58cf55038e4011bc80632f9b5fe271de22ca71f9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 505 | Contributors (this commit): 4 | Commits (past 90d): 5 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -295,7 +295,7 @@ def test_specify_initial_state_keras_tensor():\n             output = layer(inputs, initial_state=initial_state[0])\n         else:\n             output = layer(inputs, initial_state=initial_state)\n-        assert initial_state[0] in layer.inbound_nodes[0].input_tensors\n+        assert initial_state[0] in layer._inbound_nodes[0].input_tensors\n \n         model = keras.models.Model([inputs] + initial_state, output)\n         model.compile(loss='categorical_crossentropy', optimizer='adam')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#97acd91baf198d059628b22d172e9078dcde8831", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 6 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 627 | Contributors (this commit): 9 | Commits (past 90d): 10 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -33,6 +33,7 @@ from six.moves import range\n from keras.datasets import mnist\n from keras import layers\n from keras.layers import Input, Dense, Reshape, Flatten, Embedding, Dropout\n+from keras.layers import BatchNormalization\n from keras.layers.advanced_activations import LeakyReLU\n from keras.layers.convolutional import Conv2DTranspose, Conv2D\n from keras.models import Sequential, Model\n@@ -56,11 +57,13 @@ def build_generator(latent_size):\n     cnn.add(Conv2DTranspose(192, 5, strides=1, padding='valid',\n                             activation='relu',\n                             kernel_initializer='glorot_normal'))\n+    cnn.add(BatchNormalization())\n \n     # upsample to (14, 14, ...)\n     cnn.add(Conv2DTranspose(96, 5, strides=2, padding='same',\n                             activation='relu',\n                             kernel_initializer='glorot_normal'))\n+    cnn.add(BatchNormalization())\n \n     # upsample to (28, 28, ...)\n     cnn.add(Conv2DTranspose(1, 5, strides=2, padding='same',\n@@ -124,7 +127,7 @@ def build_discriminator():\n if __name__ == '__main__':\n \n     # batch and latent size taken from the paper\n-    epochs = 50\n+    epochs = 100\n     batch_size = 100\n     latent_size = 100\n \n@@ -215,8 +218,10 @@ if __name__ == '__main__':\n \n             x = np.concatenate((image_batch, generated_images))\n \n-            # use soft real/fake labels\n-            soft_zero, soft_one = 0.1, 0.9\n+            # use one-sided soft real/fake labels\n+            # Salimans et al., 2016\n+            # https://arxiv.org/pdf/1606.03498.pdf (Section 3.4)\n+            soft_zero, soft_one = 0, 0.95\n             y = np.array([soft_one] * batch_size + [soft_zero] * batch_size)\n             aux_y = np.concatenate((label_batch, sampled_labels), axis=0)\n \n@@ -286,7 +291,7 @@ if __name__ == '__main__':\n             'component', *discriminator.metrics_names))\n         print('-' * 65)\n \n-        ROW_FMT = '{0:<22s} | {1:<4.2f} | {2:<15.2f} | {3:<5.2f}'\n+        ROW_FMT = '{0:<22s} | {1:<4.2f} | {2:<15.4f} | {3:<5.4f}'\n         print(ROW_FMT.format('generator (train)',\n                              *train_history['generator'][-1]))\n         print(ROW_FMT.format('generator (test)',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a0859a4201e6f5700520e127d66ef2c6a7af6251", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 179 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 179 | Churn Cumulative: 179 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 0.0\n\nDIFF:\n@@ -0,0 +1,179 @@\n+'''Train a simple deep CNN on the CIFAR10 small images dataset.\n+\n+Using Tensorflow internal augmentation APIs by replacing ImageGenerator with\n+an embedded AugmentLayer using LambdaLayer, which is faster on GPU.\n+\n+# Benchmark of `ImageGenerator` vs `AugmentLayer` both using augmentation 2D:\n+(backend = Tensorflow-GPU, Nvidia Tesla P100-SXM2)\n+\n+Settings: horizontal_flip = True\n+----------------------------------------------------------------------------\n+Epoch     | ImageGenerator | ImageGenerator | AugmentLayer  | Augment Layer\n+Number    | %Accuracy      | Performance    | %Accuracy     | Performance\n+----------------------------------------------------------------------------\n+1         | 44.84          | 15ms/step      | 45.54         | 358us/step\n+2         | 52.34          |  8ms/step      | 50.55         | 285us/step\n+8         | 65.45          |  8ms/step      | 65.59         | 281us/step\n+25        | 76.74          |  8ms/step      | 76.17         | 280us/step\n+100       | 78.81          |  8ms/step      | 78.70         | 285us/step\n+---------------------------------------------------------------------------\n+\n+Settings: rotation = 30.0\n+----------------------------------------------------------------------------\n+Epoch     | ImageGenerator | ImageGenerator | AugmentLayer  | Augment Layer\n+Number    | %Accuracy      | Performance    | %Accuracy     | Performance\n+----------------------------------------------------------------------------\n+1         | 43.46          | 15ms/step      | 42.21         | 334us/step\n+2         | 48.95          | 11ms/step      | 48.06         | 282us/step\n+8         | 63.59          | 11ms/step      | 61.35         | 290us/step\n+25        | 72.25          | 12ms/step      | 71.08         | 287us/step\n+100       | 76.35          | 11ms/step      | 74.62         | 286us/step\n+---------------------------------------------------------------------------\n+(Corner process and rotation precision by `ImageGenerator` and `AugmentLayer`\n+are slightly different.)\n+'''\n+\n+from __future__ import print_function\n+import keras\n+from keras.datasets import cifar10\n+from keras.models import Sequential\n+from keras.layers import Dense, Dropout, Activation, Flatten\n+from keras.layers import Conv2D, Lambda, MaxPooling2D\n+from keras import backend as K\n+import os\n+\n+if K.backend() != 'tensorflow':\n+    raise RuntimeError('This example can only run with the '\n+                       'TensorFlow backend, '\n+                       'because it requires TF-native augmentation APIs')\n+\n+import tensorflow as tf\n+\n+\n+def augment_2d(inputs, rotation=0, horizontal_flip=False, vertical_flip=False):\n+    \"\"\"Apply additive augmentation on 2D data.\n+\n+    # Arguments\n+      rotation: A float, the degree range for rotation (0 <= rotation < 180),\n+          e.g. 3 for random image rotation between (-3.0, 3.0).\n+      horizontal_flip: A boolean, whether to allow random horizontal flip,\n+          e.g. true for 50% possiblity to flip image horizontally.\n+      vertical_flip: A boolean, whether to allow random vertical flip,\n+          e.g. true for 50% possiblity to flip image vertically.\n+\n+    # Returns\n+      input data after augmentation, whose shape is the same as its original.\n+    \"\"\"\n+    if inputs.dtype != tf.float32:\n+        inputs = tf.image.convert_image_dtype(inputs, dtype=tf.float32)\n+\n+    with tf.name_scope('augmentation'):\n+        shp = tf.shape(inputs)\n+        batch_size, height, width = shp[0], shp[1], shp[2]\n+        width = tf.cast(width, tf.float32)\n+        height = tf.cast(height, tf.float32)\n+\n+        transforms = []\n+        identity = tf.constant([1, 0, 0, 0, 1, 0, 0, 0], dtype=tf.float32)\n+\n+        if rotation > 0:\n+            angle_rad = rotation * 3.141592653589793 / 180.0\n+            angles = tf.random_uniform([batch_size], -angle_rad, angle_rad)\n+            f = tf.contrib.image.angles_to_projective_transforms(angles,\n+                                                                 height, width)\n+            transforms.append(f)\n+\n+        if horizontal_flip:\n+            coin = tf.less(tf.random_uniform([batch_size], 0, 1.0), 0.5)\n+            shape = [-1., 0., width, 0., 1., 0., 0., 0.]\n+            flip_transform = tf.convert_to_tensor(shape, dtype=tf.float32)\n+            flip = tf.tile(tf.expand_dims(flip_transform, 0), [batch_size, 1])\n+            noflip = tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])\n+            transforms.append(tf.where(coin, flip, noflip))\n+\n+        if vertical_flip:\n+            coin = tf.less(tf.random_uniform([batch_size], 0, 1.0), 0.5)\n+            shape = [1., 0., 0., 0., -1., height, 0., 0.]\n+            flip_transform = tf.convert_to_tensor(shape, dtype=tf.float32)\n+            flip = tf.tile(tf.expand_dims(flip_transform, 0), [batch_size, 1])\n+            noflip = tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])\n+            transforms.append(tf.where(coin, flip, noflip))\n+\n+    if transforms:\n+        f = tf.contrib.image.compose_transforms(*transforms)\n+        inputs = tf.contrib.image.transform(inputs, f, interpolation='BILINEAR')\n+    return inputs\n+\n+\n+batch_size = 32\n+num_classes = 10\n+epochs = 100\n+num_predictions = 20\n+save_dir = '/tmp/saved_models'\n+model_name = 'keras_cifar10_trained_model.h5'\n+\n+# The data, shuffled and split between train and test sets:\n+(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n+print('x_train shape:', x_train.shape)\n+print(x_train.shape[0], 'train samples')\n+print(x_test.shape[0], 'test samples')\n+\n+# Convert class vectors to binary class matrices.\n+y_train = keras.utils.to_categorical(y_train, num_classes)\n+y_test = keras.utils.to_categorical(y_test, num_classes)\n+\n+model = Sequential()\n+model.add(Lambda(augment_2d,\n+                 input_shape=x_train.shape[1:],\n+                 arguments={'rotation': 8.0, 'horizontal_flip': True}))\n+model.add(Conv2D(32, (3, 3), padding='same'))\n+model.add(Activation('relu'))\n+model.add(Conv2D(32, (3, 3)))\n+model.add(Activation('relu'))\n+model.add(MaxPooling2D(pool_size=(2, 2)))\n+model.add(Dropout(0.25))\n+\n+model.add(Conv2D(64, (3, 3), padding='same'))\n+model.add(Activation('relu'))\n+model.add(Conv2D(64, (3, 3)))\n+model.add(Activation('relu'))\n+model.add(MaxPooling2D(pool_size=(2, 2)))\n+model.add(Dropout(0.25))\n+\n+model.add(Flatten())\n+model.add(Dense(512))\n+model.add(Activation('relu'))\n+model.add(Dropout(0.5))\n+model.add(Dense(num_classes))\n+model.add(Activation('softmax'))\n+\n+# initiate RMSprop optimizer\n+opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n+\n+# Let's train the model using RMSprop\n+model.compile(loss='categorical_crossentropy',\n+              optimizer=opt,\n+              metrics=['accuracy'])\n+\n+x_train = x_train.astype('float32')\n+x_test = x_test.astype('float32')\n+x_train /= 255\n+x_test /= 255\n+\n+model.fit(x_train, y_train,\n+          batch_size=batch_size,\n+          epochs=epochs,\n+          validation_data=(x_test, y_test),\n+          shuffle=True)\n+\n+# Save model and weights\n+if not os.path.isdir(save_dir):\n+    os.makedirs(save_dir)\n+model_path = os.path.join(save_dir, model_name)\n+model.save(model_path)\n+print('Saved trained model at %s ' % model_path)\n+\n+# Score trained model.\n+scores = model.evaluate(x_test, y_test, verbose=1)\n+print('Test loss:', scores[0])\n+print('Test accuracy:', scores[1])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4c7425fe4d7836f32d123af19c90719dd9fe567a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 1180 | Contributors (this commit): 29 | Commits (past 90d): 22 | Contributors (cumulative): 37 | DMM Complexity: 0.0\n\nDIFF:\n@@ -226,7 +226,8 @@ def func_load(code, defaults=None, closure=None, globs=None):\n         closure = tuple(ensure_value_to_cell(_) for _ in closure)\n     try:\n         raw_code = codecs.decode(code.encode('ascii'), 'base64')\n-    except (UnicodeEncodeError, binascii.Error):\n+        code = marshal.loads(raw_code)\n+    except (UnicodeEncodeError, binascii.Error, ValueError):\n         # backwards compatibility for models serialized prior to 2.1.2\n         raw_code = code.encode('raw_unicode_escape')\n         code = marshal.loads(raw_code)\n\n@@ -121,7 +121,7 @@ def test_func_dump_and_load_closure():\n \n \n @pytest.mark.parametrize(\n-    'test_func', [activations.softmax, np.argmax, lambda x: x**2])\n+    'test_func', [activations.softmax, np.argmax, lambda x: x**2, lambda x: x])\n def test_func_dump_and_load_backwards_compat(test_func):\n     # this test ensures that models serialized prior to version 2.1.2 can still be\n     # deserialized\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2fbac5a775fb846796d53e2aec8af4fe6d95963e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 3060 | Contributors (this commit): 20 | Commits (past 90d): 6 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -440,7 +440,7 @@ class TestBackend(object):\n             grad = k.gradients(loss, [exp])\n             zero_grad = k.gradients(loss + zero_loss, [exp])\n             z_list.append(k.eval(grad[0]))\n-            zero_list.append(k.eval(grad[0]))\n+            zero_list.append(k.eval(zero_grad[0]))\n \n         assert_list_pairwise(z_list)\n         assert_list_pairwise(zero_list)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8350eb80bb37a643b29afc0ab19e99796b475fac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 151 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 153 | Churn Cumulative: 418 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -66,7 +66,7 @@ input_texts = []\n target_texts = []\n input_characters = set()\n target_characters = set()\n-lines = open(data_path).read().split('\\n')\n+lines = open(data_path, 'r', encoding='utf-8').read().split('\\n')\n for line in lines[: min(num_samples, len(lines) - 1)]:\n     input_text, target_text = line.split('\\t')\n     # We use \"tab\" as the \"start sequence\" character\n@@ -220,7 +220,7 @@ def decode_sequence(input_seq):\n \n \n for seq_index in range(100):\n-    # Take one sequence (part of the training test)\n+    # Take one sequence (part of the training set)\n     # for trying out decoding.\n     input_seq = encoder_input_data[seq_index: seq_index + 1]\n     decoded_sentence = decode_sequence(input_seq)\n\n@@ -0,0 +1,149 @@\n+'''Restore a character-level sequence to sequence model from disk and use it\n+to generate predictions.\n+\n+This script loads the s2s.h5 model saved by lstm_seq2seq.py and generates\n+sequences from it.  It assumes that no changes have been made (for example:\n+latent_dim is unchanged, and the input data and model architecture are unchanged).\n+\n+See lstm_seq2seq.py for more details on the model architecture and how\n+it is trained.\n+'''\n+from __future__ import print_function\n+\n+from keras.models import Model, load_model\n+from keras.layers import Input\n+import numpy as np\n+\n+batch_size = 64  # Batch size for training.\n+epochs = 100  # Number of epochs to train for.\n+latent_dim = 256  # Latent dimensionality of the encoding space.\n+num_samples = 10000  # Number of samples to train on.\n+# Path to the data txt file on disk.\n+data_path = 'fra-eng/fra.txt'\n+\n+# Vectorize the data.  We use the same approach as the training script.\n+# NOTE: the data must be identical, in order for the character -> integer\n+# mappings to be consistent.\n+# We omit encoding target_texts since they are not needed.\n+input_texts = []\n+target_texts = []\n+input_characters = set()\n+target_characters = set()\n+lines = open(data_path, 'r', encoding='utf-8').read().split('\\n')\n+for line in lines[: min(num_samples, len(lines) - 1)]:\n+    input_text, target_text = line.split('\\t')\n+    # We use \"tab\" as the \"start sequence\" character\n+    # for the targets, and \"\\n\" as \"end sequence\" character.\n+    target_text = '\\t' + target_text + '\\n'\n+    input_texts.append(input_text)\n+    target_texts.append(target_text)\n+    for char in input_text:\n+        if char not in input_characters:\n+            input_characters.add(char)\n+    for char in target_text:\n+        if char not in target_characters:\n+            target_characters.add(char)\n+\n+input_characters = sorted(list(input_characters))\n+target_characters = sorted(list(target_characters))\n+num_encoder_tokens = len(input_characters)\n+num_decoder_tokens = len(target_characters)\n+max_encoder_seq_length = max([len(txt) for txt in input_texts])\n+max_decoder_seq_length = max([len(txt) for txt in target_texts])\n+\n+print('Number of samples:', len(input_texts))\n+print('Number of unique input tokens:', num_encoder_tokens)\n+print('Number of unique output tokens:', num_decoder_tokens)\n+print('Max sequence length for inputs:', max_encoder_seq_length)\n+print('Max sequence length for outputs:', max_decoder_seq_length)\n+\n+input_token_index = dict(\n+    [(char, i) for i, char in enumerate(input_characters)])\n+target_token_index = dict(\n+    [(char, i) for i, char in enumerate(target_characters)])\n+\n+encoder_input_data = np.zeros(\n+    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n+    dtype='float32')\n+\n+for i, input_text in enumerate(input_texts):\n+    for t, char in enumerate(input_text):\n+        encoder_input_data[i, t, input_token_index[char]] = 1.\n+\n+# Restore the model and construct the encoder and decoder.\n+model = load_model('s2s.h5')\n+\n+encoder_inputs = model.input[0]   # input_1\n+encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output   # lstm_1\n+encoder_states = [state_h_enc, state_c_enc]\n+encoder_model = Model(encoder_inputs, encoder_states)\n+\n+decoder_inputs = model.input[1]   # input_2\n+decoder_state_input_h = Input(shape=(latent_dim,), name='input_3')\n+decoder_state_input_c = Input(shape=(latent_dim,), name='input_4')\n+decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n+decoder_lstm = model.layers[3]\n+decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n+    decoder_inputs, initial_state=decoder_states_inputs)\n+decoder_states = [state_h_dec, state_c_dec]\n+decoder_dense = model.layers[4]\n+decoder_outputs = decoder_dense(decoder_outputs)\n+decoder_model = Model(\n+    [decoder_inputs] + decoder_states_inputs,\n+    [decoder_outputs] + decoder_states)\n+\n+# Reverse-lookup token index to decode sequences back to\n+# something readable.\n+reverse_input_char_index = dict(\n+    (i, char) for char, i in input_token_index.items())\n+reverse_target_char_index = dict(\n+    (i, char) for char, i in target_token_index.items())\n+\n+\n+# Decodes an input sequence.  Future work should support beam search.\n+def decode_sequence(input_seq):\n+    # Encode the input as state vectors.\n+    states_value = encoder_model.predict(input_seq)\n+\n+    # Generate empty target sequence of length 1.\n+    target_seq = np.zeros((1, 1, num_decoder_tokens))\n+    # Populate the first character of target sequence with the start character.\n+    target_seq[0, 0, target_token_index['\\t']] = 1.\n+\n+    # Sampling loop for a batch of sequences\n+    # (to simplify, here we assume a batch of size 1).\n+    stop_condition = False\n+    decoded_sentence = ''\n+    while not stop_condition:\n+        output_tokens, h, c = decoder_model.predict(\n+            [target_seq] + states_value)\n+\n+        # Sample a token\n+        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n+        sampled_char = reverse_target_char_index[sampled_token_index]\n+        decoded_sentence += sampled_char\n+\n+        # Exit condition: either hit max length\n+        # or find stop character.\n+        if (sampled_char == '\\n' or\n+           len(decoded_sentence) > max_decoder_seq_length):\n+            stop_condition = True\n+\n+        # Update the target sequence (of length 1).\n+        target_seq = np.zeros((1, 1, num_decoder_tokens))\n+        target_seq[0, 0, sampled_token_index] = 1.\n+\n+        # Update states\n+        states_value = [h, c]\n+\n+    return decoded_sentence\n+\n+\n+for seq_index in range(100):\n+    # Take one sequence (part of the training set)\n+    # for trying out decoding.\n+    input_seq = encoder_input_data[seq_index: seq_index + 1]\n+    decoded_sentence = decode_sequence(input_seq)\n+    print('-')\n+    print('Input sentence:', input_texts[seq_index])\n+    print('Decoded sentence:', decoded_sentence)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1f2e7a749a6fc67a59debf6fba4bc32fe57f5ad7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 6159 | Contributors (this commit): 79 | Commits (past 90d): 39 | Contributors (cumulative): 79 | DMM Complexity: None\n\nDIFF:\n@@ -244,7 +244,7 @@ def _check_loss_and_target_compatibility(targets, loss_fns, output_shapes):\n                   losses.binary_crossentropy,\n                   losses.categorical_crossentropy}\n     for y, loss, shape in zip(targets, loss_fns, output_shapes):\n-        if loss is None:\n+        if y is None or loss is None:\n             continue\n         if loss is losses.categorical_crossentropy:\n             if y.shape[-1] == 1:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
