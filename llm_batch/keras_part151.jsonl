{"custom_id": "keras#f1a95869ebad98db11aba463e7dab031de6dcba0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 154 | Contributors (this commit): 4 | Commits (past 90d): 1 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -102,9 +102,9 @@ print('Preparing embedding matrix.')\n \n # prepare embedding matrix\n nb_words = min(MAX_NB_WORDS, len(word_index))\n-embedding_matrix = np.zeros((nb_words + 1, EMBEDDING_DIM))\n+embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n for word, i in word_index.items():\n-    if i > MAX_NB_WORDS:\n+    if i >= MAX_NB_WORDS:\n         continue\n     embedding_vector = embeddings_index.get(word)\n     if embedding_vector is not None:\n@@ -113,7 +113,7 @@ for word, i in word_index.items():\n \n # load pre-trained word embeddings into an Embedding layer\n # note that we set trainable = False so as to keep the embeddings fixed\n-embedding_layer = Embedding(nb_words + 1,\n+embedding_layer = Embedding(nb_words,\n                             EMBEDDING_DIM,\n                             weights=[embedding_matrix],\n                             input_length=MAX_SEQUENCE_LENGTH,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ff1f79603296bffc312076afa0589d229145924c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 3064 | Contributors (this commit): 33 | Commits (past 90d): 16 | Contributors (cumulative): 33 | DMM Complexity: 1.0\n\nDIFF:\n@@ -724,7 +724,6 @@ class Model(Container):\n                         append_metric(i, name, tensor)\n \n         # prepare gradient updates and state updates\n-        self.optimizer = optimizers.get(optimizer)\n         self.total_loss = total_loss\n         self.sample_weights = sample_weights\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0f4fec30f00b29aa206e36fe875c83ff6149b618", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 11 | Files Changed: 3 | Hunks: 13 | Methods Changed: 4 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 30 | Churn Cumulative: 8273 | Contributors (this commit): 62 | Commits (past 90d): 56 | Contributors (cumulative): 87 | DMM Complexity: 0.5\n\nDIFF:\n@@ -831,7 +831,6 @@ def batch_dot(x, y, axes=None):\n \n     # Arguments\n         x, y: Keras tensors or variables with `ndim >= 2`\n-            (With TensorFlow backend, `batch_dot()` only supports `ndim >= 3`)\n         axes: list of (or single) int with target dimensions.\n             The lengths of `axes[0]` and `axes[1]` should be the same.\n \n@@ -870,10 +869,14 @@ def batch_dot(x, y, axes=None):\n         (32, 1, 30)\n     ```\n     \"\"\"\n-    if ndim(x) < 3 or ndim(y) < 3:\n-        raise ValueError('Invalid dimensions for batch_dot: ', ndim(x), ndim(y))\n     if isinstance(axes, int):\n         axes = (axes, axes)\n+    if ndim(x) == 2 and ndim(y) == 2:\n+        if axes[0] == axes[1]:\n+            out = tf.reduce_sum(tf.mul(x, y), axes[0])\n+        else:\n+            out = tf.reduce_sum(tf.mul(tf.transpose(x, [1, 0]), y), axes[1])\n+    else:\n         if axes is not None:\n             adj_x = None if axes[0] == ndim(x) - 1 else True\n             adj_y = True if axes[1] == ndim(y) - 1 else None\n\n@@ -77,15 +77,26 @@ class TestBackend(object):\n \n         check_two_tensor_operation('batch_dot', (4, 2, 3), (4, 5, 3),\n                                    axes=(2, 2))\n+        check_two_tensor_operation('batch_dot', (32, 20), (32, 20), axes=1)\n+        check_two_tensor_operation('batch_dot', (32, 20), (32, 20), axes=(1, 1))\n         check_single_tensor_operation('transpose', (4, 2))\n         check_single_tensor_operation('reverse', (4, 3, 2), axes=1)\n         check_single_tensor_operation('reverse', (4, 3, 2), axes=(1, 2))\n \n     def test_batch_dot_shape(self):\n-        with pytest.raises(ValueError):\n         x_batch = KTF.ones(shape=(32, 20))\n         y_batch = KTF.ones(shape=(32, 20))\n         xy_batch_dot = KTF.batch_dot(x_batch, y_batch, axes=1)\n+        assert_allclose(KTF.eval(xy_batch_dot), np.ones((32, 1)) * 20, atol=1e-05)\n+        xy_batch_dot = KTF.batch_dot(x_batch, y_batch, axes=0)\n+        assert_allclose(KTF.eval(xy_batch_dot), np.ones((20, 1)) * 32, atol=1e-05)\n+        # making sure swapping axes when ndim == 2 works\n+        x_batch = KTF.ones(shape=(32, 20))\n+        y_batch = KTF.ones(shape=(20, 32))\n+        xy_batch_dot = KTF.batch_dot(x_batch, y_batch, axes=(0, 1))\n+        assert_allclose(KTF.eval(xy_batch_dot), np.ones((20, 1)) * 32, atol=1e-05)\n+        xy_batch_dot = KTF.batch_dot(x_batch, y_batch, axes=(1, 0))\n+        assert_allclose(KTF.eval(xy_batch_dot), np.ones((32, 1)) * 20, atol=1e-05)\n \n     def test_shape_operations(self):\n         # concatenate\n\n@@ -7,7 +7,7 @@ np.random.seed(1337)\n \n from keras import backend as K\n from keras.models import Sequential\n-from keras.layers.core import Dense, Activation, Merge, Lambda, Reshape\n+from keras.layers.core import Dense, Activation, Merge, Lambda\n from keras.utils import np_utils\n from keras.utils.test_utils import get_test_data, keras_test\n from keras.models import model_from_json, model_from_yaml\n@@ -287,17 +287,14 @@ def test_merge_dot():\n \n     left = Sequential()\n     left.add(Dense(input_dim=input_dim, output_dim=nb_hidden))\n-    left.add(Reshape((nb_hidden, 1)))\n     left.add(Activation('relu'))\n \n     right = Sequential()\n     right.add(Dense(input_dim=input_dim, output_dim=nb_hidden))\n-    right.add(Reshape((nb_hidden, 1)))\n     right.add(Activation('relu'))\n \n     model = Sequential()\n     model.add(Merge([left, right], mode='dot', dot_axes=1))\n-    model.add(Reshape((1,)))\n     model.add(Dense(nb_class))\n     model.add(Activation('softmax'))\n \n@@ -305,17 +302,14 @@ def test_merge_dot():\n \n     left = Sequential()\n     left.add(Dense(input_dim=input_dim, output_dim=nb_hidden))\n-    left.add(Reshape((nb_hidden, 1)))\n     left.add(Activation('relu'))\n \n     right = Sequential()\n     right.add(Dense(input_dim=input_dim, output_dim=nb_hidden))\n-    right.add(Reshape((nb_hidden, 1)))\n     right.add(Activation('relu'))\n \n     model = Sequential()\n     model.add(Merge([left, right], mode='dot', dot_axes=[1, 1]))\n-    model.add(Reshape((1,)))\n     model.add(Dense(nb_class))\n     model.add(Activation('softmax'))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7016e8f1d966a0069d418b806a27583234c9c082", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 8 | Methods Changed: 4 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 28 | Churn Cumulative: 9871 | Contributors (this commit): 78 | Commits (past 90d): 84 | Contributors (cumulative): 114 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2235,8 +2235,14 @@ def in_train_phase(x, alt):\n         Either `x` or `alt` based on `K.learning_phase`.\n     \"\"\"\n     if learning_phase() is 1:\n+        if callable(x):\n+            return x()\n+        else:\n             return x\n     elif learning_phase() is 0:\n+        if callable(alt):\n+            return alt()\n+        else:\n             return alt\n     # else: assume learning phase is a placeholder tensor.\n     x = switch(learning_phase(), x, alt)\n@@ -2252,8 +2258,14 @@ def in_test_phase(x, alt):\n         Either `x` or `alt` based on `K.learning_phase`.\n     \"\"\"\n     if learning_phase() is 1:\n+        if callable(alt):\n+            return alt()\n+        else:\n             return alt\n     elif learning_phase() is 0:\n+        if callable(x):\n+            return x()\n+        else:\n             return x\n     # else: assume learning phase is a placeholder tensor.\n     x = switch(learning_phase(), alt, x)\n\n@@ -1163,28 +1163,28 @@ def switch(condition, then_expression, else_expression):\n \n \n def in_train_phase(x, alt):\n-    if _LEARNING_PHASE is 1:\n-        return x\n-    elif _LEARNING_PHASE is 0:\n-        return alt\n     if callable(x):\n         x = x()\n     if callable(alt):\n         alt = alt()\n+    if _LEARNING_PHASE is 1:\n+        return x\n+    elif _LEARNING_PHASE is 0:\n+        return alt\n     x = theano.ifelse.ifelse(_LEARNING_PHASE, x, alt)\n     x._uses_learning_phase = True\n     return x\n \n \n def in_test_phase(x, alt):\n-    if _LEARNING_PHASE is 1:\n-        return alt\n-    elif _LEARNING_PHASE is 0:\n-        return x\n     if callable(x):\n         x = x()\n     if callable(alt):\n         alt = alt()\n+    if _LEARNING_PHASE is 1:\n+        return alt\n+    elif _LEARNING_PHASE is 0:\n+        return x\n     x = theano.ifelse.ifelse(_LEARNING_PHASE, alt, x)\n     x._uses_learning_phase = True\n     return x\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1de4bf1b5989f76e377f0b8022b41773a354ba99", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 16 | Churn Cumulative: 6093 | Contributors (this commit): 61 | Commits (past 90d): 48 | Contributors (cumulative): 61 | DMM Complexity: 0.0\n\nDIFF:\n@@ -28,6 +28,10 @@ _GRAPH_LEARNING_PHASES = {}\n # Change its value via `manual_variable_initialization(value)`.\n _MANUAL_VAR_INIT = False\n \n+# These two integers contain the tensorflow version for coping with API breaks.\n+tf_major_version = int(tf.__version__.split('.')[0])\n+tf_minor_version = int(tf.__version__.split('.')[1])\n+\n \n def clear_session():\n     \"\"\"Destroys the current TF graph and creates a new one.\n@@ -240,6 +244,11 @@ def variable(value, dtype=None, name=None):\n         sparse_coo = value.tocoo()\n         indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),\n                                   np.expand_dims(sparse_coo.col, 1)), 1)\n+        if tf_major_version >= 1:\n+            v = tf.SparseTensor(indices=indices,\n+                                values=sparse_coo.data,\n+                                dense_shape=sparse_coo.shape)\n+        else:\n             v = tf.SparseTensor(indices=indices,\n                                 values=sparse_coo.data,\n                                 shape=sparse_coo.shape)\n@@ -1429,6 +1438,9 @@ def concatenate(tensors, axis=-1):\n \n     if py_all([is_sparse(x) for x in tensors]):\n         return tf.sparse_concat(axis, tensors)\n+    else:\n+        if tf_major_version >= 1:\n+            return tf.concat([to_dense(x) for x in tensors], axis)\n         else:\n             try:\n                 return tf.concat_v2([to_dense(x) for x in tensors], axis)\n@@ -3061,6 +3073,10 @@ def ctc_decode(y_pred, input_length, greedy=True, beam_width=100,\n             sequence_length=input_length, beam_width=beam_width,\n             top_paths=top_paths)\n \n+    if tf_major_version >= 1:\n+        decoded_dense = [tf.sparse_to_dense(st.indices, st.dense_shape, st.values, default_value=-1)\n+                         for st in decoded]\n+    else:\n         decoded_dense = [tf.sparse_to_dense(st.indices, st.shape, st.values, default_value=-1)\n                          for st in decoded]\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#676e227b47865c296d1731270d5f111e1422d1e2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 6573 | Contributors (this commit): 33 | Commits (past 90d): 19 | Contributors (cumulative): 33 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1169,7 +1169,6 @@ class Convolution3D(Layer):\n \n     def build(self, input_shape):\n         assert len(input_shape) == 5\n-        self.input_spec = [InputSpec(shape=input_shape)]\n \n         if self.dim_ordering == 'th':\n             stack_size = input_shape[1]\n@@ -1229,11 +1228,9 @@ class Convolution3D(Layer):\n             raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n \n     def call(self, x, mask=None):\n-        input_shape = self.input_spec[0].shape\n         output = K.conv3d(x, self.W, strides=self.subsample,\n                           border_mode=self.border_mode,\n                           dim_ordering=self.dim_ordering,\n-                          volume_shape=input_shape,\n                           filter_shape=self.W_shape)\n         if self.bias:\n             if self.dim_ordering == 'th':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5c384a1bca81a525f2d4b89f9ed225c75110c1bf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 11 | Files Changed: 1 | Hunks: 11 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 22 | Churn Cumulative: 1918 | Contributors (this commit): 22 | Commits (past 90d): 12 | Contributors (cumulative): 22 | DMM Complexity: None\n\nDIFF:\n@@ -210,7 +210,7 @@ def array_to_img(x, dim_ordering='default', scale=True):\n     if pil_image is None:\n         raise ImportError('Could not import PIL.Image. '\n                           'The use of `array_to_img` requires PIL.')\n-    x = np.asarray(x)\n+    x = np.asarray(x, dtype=K.floatx())\n     if x.ndim != 3:\n         raise ValueError('Expected image array to have rank 3 (single image). '\n                          'Got array with shape:', x.shape)\n@@ -249,7 +249,7 @@ def img_to_array(img, dim_ordering='default'):\n         dim_ordering: Image data format.\n \n     # Returns\n-        A 3D Numpy array (float32).\n+        A 3D Numpy array.\n \n     # Raises\n         ValueError: if invalid `img` or `dim_ordering` is passed.\n@@ -261,7 +261,7 @@ def img_to_array(img, dim_ordering='default'):\n     # Numpy array x has format (height, width, channel)\n     # or (channel, height, width)\n     # but original PIL image has format (width, height, channel)\n-    x = np.asarray(img, dtype='float32')\n+    x = np.asarray(img, dtype=K.floatx())\n     if len(x.shape) == 3:\n         if dim_ordering == 'th':\n             x = x.transpose(2, 0, 1)\n@@ -572,7 +572,7 @@ class ImageDataGenerator(object):\n         # Raises\n             ValueError: in case of invalid input `x`.\n         \"\"\"\n-        x = np.asarray(x)\n+        x = np.asarray(x, dtype=K.floatx())\n         if x.ndim != 4:\n             raise ValueError('Input to `.fit()` should have rank 4. '\n                              'Got array with shape: ' + str(x.shape))\n@@ -590,7 +590,7 @@ class ImageDataGenerator(object):\n \n         x = np.copy(x)\n         if augment:\n-            ax = np.zeros(tuple([rounds * x.shape[0]] + list(x.shape)[1:]))\n+            ax = np.zeros(tuple([rounds * x.shape[0]] + list(x.shape)[1:]), dtype=K.floatx())\n             for r in range(rounds):\n                 for i in range(x.shape[0]):\n                     ax[i + r * x.shape[0]] = self.random_transform(x[i])\n@@ -675,7 +675,7 @@ class NumpyArrayIterator(Iterator):\n                              (np.asarray(x).shape, np.asarray(y).shape))\n         if dim_ordering == 'default':\n             dim_ordering = K.image_dim_ordering()\n-        self.x = np.asarray(x)\n+        self.x = np.asarray(x, dtype=K.floatx())\n         if self.x.ndim != 4:\n             raise ValueError('Input data in `NumpyArrayIterator` '\n                              'should have rank 4. You passed an array '\n@@ -708,10 +708,10 @@ class NumpyArrayIterator(Iterator):\n             index_array, current_index, current_batch_size = next(self.index_generator)\n         # The transformation of images is not under thread lock\n         # so it can be done in parallel\n-        batch_x = np.zeros(tuple([current_batch_size] + list(self.x.shape)[1:]))\n+        batch_x = np.zeros(tuple([current_batch_size] + list(self.x.shape)[1:]), dtype=K.floatx())\n         for i, j in enumerate(index_array):\n             x = self.x[j]\n-            x = self.image_data_generator.random_transform(x.astype('float32'))\n+            x = self.image_data_generator.random_transform(x.astype(K.floatx()))\n             x = self.image_data_generator.standardize(x)\n             batch_x[i] = x\n         if self.save_to_dir:\n@@ -822,7 +822,7 @@ class DirectoryIterator(Iterator):\n             index_array, current_index, current_batch_size = next(self.index_generator)\n         # The transformation of images is not under thread lock\n         # so it can be done in parallel\n-        batch_x = np.zeros((current_batch_size,) + self.image_shape)\n+        batch_x = np.zeros((current_batch_size,) + self.image_shape, dtype=K.floatx())\n         grayscale = self.color_mode == 'grayscale'\n         # build batch of image data\n         for i, j in enumerate(index_array):\n@@ -847,9 +847,9 @@ class DirectoryIterator(Iterator):\n         if self.class_mode == 'sparse':\n             batch_y = self.classes[index_array]\n         elif self.class_mode == 'binary':\n-            batch_y = self.classes[index_array].astype('float32')\n+            batch_y = self.classes[index_array].astype(K.floatx())\n         elif self.class_mode == 'categorical':\n-            batch_y = np.zeros((len(batch_x), self.nb_class), dtype='float32')\n+            batch_y = np.zeros((len(batch_x), self.nb_class), dtype=K.floatx())\n             for i, label in enumerate(self.classes[index_array]):\n                 batch_y[i, label] = 1.\n         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d009ac8fba0cfdf9f107131721ee24732a5ebc00", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 14 | Churn Cumulative: 680 | Contributors (this commit): 3 | Commits (past 90d): 10 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -1,13 +1,13 @@\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n \n-from keras import backend as K\n-from keras.layers import activations\n-from keras.layers import initializations\n-from keras.layers import regularizers\n-from keras.layers import constraints\n-from keras.engine import Layer\n-from keras.engine import InputSpec\n+from .. import backend as K\n+from .. import activations\n+from .. import initializations\n+from .. import regularizers\n+from .. import constraints\n+from ..engine import Layer\n+from ..engine import InputSpec\n from ..utils.np_utils import conv_output_length\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#99ee2fb09ab33f72dca627dc586ac3884ded337a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 47 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 47 | Churn Cumulative: 302 | Contributors (this commit): 7 | Commits (past 90d): 4 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -91,6 +91,53 @@ class UnitNorm(Constraint):\n                 'axis': self.axis}\n \n \n+class MinMaxNorm(Constraint):\n+    \"\"\"MinMaxNorm weight constraint.\n+\n+    Constrains the weights incident to each hidden unit\n+    to have the norm between a lower bound and an upper bound.\n+\n+    # Arguments\n+        low: the minimum norm for the incoming weights.\n+        high: the maximum norm for the incoming weights.\n+        rate: rate for enforcing the constraint: weights will be\n+            rescaled to yield (1 - rate) * norm + rate * norm.clip(low, high).\n+            Effectively, this means that rate=1.0 stands for strict\n+            enforcement of the constraint, while rate<1.0 means that\n+            weights will be rescaled at each step to slowly move\n+            towards a value inside the desired interval.\n+        axis: integer, axis along which to calculate weight norms.\n+            For instance, in a `Dense` layer the weight matrix\n+            has shape `(input_dim, output_dim)`,\n+            set `axis` to `0` to constrain each weight vector\n+            of length `(input_dim,)`.\n+            In a `Convolution2D` layer with `dim_ordering=\"tf\"`,\n+            the weight tensor has shape\n+            `(rows, cols, input_depth, output_depth)`,\n+            set `axis` to `[0, 1, 2]`\n+            to constrain the weights of each filter tensor of size\n+            `(rows, cols, input_depth)`.\n+    \"\"\"\n+    def __init__(self, low=0.0, high=1.0, rate=1.0, axis=0):\n+        self.low = low\n+        self.high = high\n+        self.rate = rate\n+        self.axis = axis\n+\n+    def __call__(self, p):\n+        norms = K.sqrt(K.sum(K.square(p), axis=self.axis, keepdims=True))\n+        desired = self.rate * K.clip(norms, self.low, self.high) + (1 - self.rate) * norms\n+        p *= (desired / (K.epsilon() + norms))\n+        return p\n+\n+    def get_config(self):\n+        return {'name': self.__class__.__name__,\n+                'low': self.low,\n+                'high': self.high,\n+                'rate': self.rate,\n+                'axis': self.axis}\n+\n+\n # Aliases.\n \n maxnorm = MaxNorm\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#757b3ed1b0dbff7a83c6b3b9dd6edb565af2bf4d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 110 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -13,6 +13,7 @@ from keras.layers import Dense, Dropout, Activation, Flatten\n from keras.layers import Convolution2D, MaxPooling2D\n from keras.utils import np_utils\n from keras.wrappers.scikit_learn import KerasClassifier\n+from keras import backend as K\n from sklearn.grid_search import GridSearchCV\n \n \n@@ -23,8 +24,16 @@ img_rows, img_cols = 28, 28\n \n # load training data and do basic data normalization\n (X_train, y_train), (X_test, y_test) = mnist.load_data()\n+\n+if K.image_dim_ordering() == 'th':\n     X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n     X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n+    input_shape = (1, img_rows, img_cols)\n+else:\n+    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n+    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n+    input_shape = (img_rows, img_cols, 1)\n+\n X_train = X_train.astype('float32')\n X_test = X_test.astype('float32')\n X_train /= 255\n@@ -48,7 +57,7 @@ def make_model(dense_layer_sizes, nb_filters, nb_conv, nb_pool):\n \n     model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n                             border_mode='valid',\n-                            input_shape=(1, img_rows, img_cols)))\n+                            input_shape=input_shape))\n     model.add(Activation('relu'))\n     model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n     model.add(Activation('relu'))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5ea9f5bdd1bc32f419e81904b3daeb4460d25eae", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 635 | Contributors (this commit): 7 | Commits (past 90d): 9 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -1,3 +1,4 @@\n+import copy\n from ..engine import Layer\n from ..engine import InputSpec\n from .. import backend as K\n@@ -163,7 +164,7 @@ class Bidirectional(Wrapper):\n             raise ValueError('Invalid merge mode. '\n                              'Merge mode should be one of '\n                              '{\"sum\", \"mul\", \"ave\", \"concat\", None}')\n-        self.forward_layer = layer\n+        self.forward_layer = copy.copy(layer)\n         config = layer.get_config()\n         config['go_backwards'] = not config['go_backwards']\n         self.backward_layer = layer.__class__.from_config(config)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3ad7463b60e269986697ae692fae93cf6056e56f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 3066 | Contributors (this commit): 34 | Commits (past 90d): 17 | Contributors (cumulative): 34 | DMM Complexity: None\n\nDIFF:\n@@ -49,7 +49,7 @@ def standardize_input_data(data, names, shapes=None,\n             if name not in data:\n                 raise ValueError('No data provided for \"' +\n                                  name + '\". Need data for each key in: ' +\n-                                 str(data.keys()))\n+                                 str(names))\n             arrays.append(data[name])\n     elif isinstance(data, list):\n         if len(data) != len(names):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#793232fe762b7e7c27fd9da88596babb1721500d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 448 | Contributors (this commit): 13 | Commits (past 90d): 7 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -197,7 +197,7 @@ class Progbar(object):\n         interval: Minimum visual progress update interval (in seconds).\n     \"\"\"\n \n-    def __init__(self, target, width=30, verbose=1, interval=0.01):\n+    def __init__(self, target, width=30, verbose=1, interval=0.05):\n         self.width = width\n         self.target = target\n         self.sum_values = {}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#66f2613416787a4746c14243d92672b275d82123", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 16 | Files Changed: 1 | Hunks: 13 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 50 | Churn Cumulative: 3844 | Contributors (this commit): 54 | Commits (past 90d): 38 | Contributors (cumulative): 54 | DMM Complexity: None\n\nDIFF:\n@@ -1444,24 +1444,24 @@ def _preprocess_conv3d_filter_shape(dim_ordering, filter_shape):\n     return filter_shape\n \n \n-def _postprocess_conv2d_output(conv_out, x, border_mode, np_kernel, strides, dim_ordering):\n+def _postprocess_conv2d_output(conv_out, x, border_mode, kernel_shape, strides, dim_ordering):\n     if border_mode == 'same':\n-        if np_kernel.shape[2] % 2 == 0:\n+        if kernel_shape[2] % 2 == 0:\n             conv_out = conv_out[:, :, :(x.shape[2] + strides[0] - 1) // strides[0], :]\n-        if np_kernel.shape[3] % 2 == 0:\n+        if kernel_shape[3] % 2 == 0:\n             conv_out = conv_out[:, :, :, :(x.shape[3] + strides[1] - 1) // strides[1]]\n     if dim_ordering == 'tf':\n         conv_out = conv_out.dimshuffle((0, 2, 3, 1))\n     return conv_out\n \n \n-def _postprocess_conv3d_output(conv_out, x, border_mode, np_kernel, strides, dim_ordering):\n+def _postprocess_conv3d_output(conv_out, x, border_mode, kernel_shape, strides, dim_ordering):\n     if border_mode == 'same':\n-        if np_kernel.shape[2] % 2 == 0:\n+        if kernel_shape[2] % 2 == 0:\n             conv_out = conv_out[:, :, :(x.shape[2] + strides[0] - 1) // strides[0], :, :]\n-        if np_kernel.shape[3] % 2 == 0:\n+        if kernel_shape[3] % 2 == 0:\n             conv_out = conv_out[:, :, :, :(x.shape[3] + strides[1] - 1) // strides[1], :]\n-        if np_kernel.shape[4] % 2 == 0:\n+        if kernel_shape[4] % 2 == 0:\n             conv_out = conv_out[:, :, :, :, :(x.shape[4] + strides[2] - 1) // strides[2]]\n     if dim_ordering == 'tf':\n         conv_out = conv_out.dimshuffle((0, 2, 3, 4, 1))\n@@ -1501,7 +1501,13 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid',\n     x = _preprocess_conv2d_input(x, dim_ordering)\n     kernel = _preprocess_conv2d_kernel(kernel, dim_ordering)\n     th_border_mode = _preprocess_border_mode(border_mode)\n-    np_kernel = kernel.eval()\n+\n+    if hasattr(kernel, '_keras_shape'):\n+        kernel_shape = kernel._keras_shape\n+    else:\n+        # Will only work if `kernel` is a shared variable.\n+        kernel_shape = kernel.eval().shape\n+\n     image_shape = _preprocess_conv2d_image_shape(dim_ordering, image_shape)\n     filter_shape = _preprocess_conv2d_filter_shape(dim_ordering, filter_shape)\n \n@@ -1525,8 +1531,8 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid',\n                                  filter_shape=filter_shape,\n                                  filter_dilation=filter_dilation)\n \n-    conv_out = _postprocess_conv2d_output(conv_out, x, border_mode, np_kernel,\n-                                          strides, dim_ordering)\n+    conv_out = _postprocess_conv2d_output(conv_out, x, border_mode,\n+                                          kernel_shape, strides, dim_ordering)\n     return conv_out\n \n \n@@ -1558,7 +1564,13 @@ def deconv2d(x, kernel, output_shape, strides=(1, 1),\n     kernel = _preprocess_conv2d_kernel(kernel, dim_ordering)\n     kernel = kernel.dimshuffle((1, 0, 2, 3))\n     th_border_mode = _preprocess_border_mode(border_mode)\n-    np_kernel = kernel.eval()\n+\n+    if hasattr(kernel, '_keras_shape'):\n+        kernel_shape = kernel._keras_shape\n+    else:\n+        # Will only work if `kernel` is a shared variable.\n+        kernel_shape = kernel.eval().shape\n+\n     filter_shape = _preprocess_conv2d_filter_shape(dim_ordering, filter_shape)\n     filter_shape = tuple(filter_shape[i] for i in (1, 0, 2, 3))\n \n@@ -1569,8 +1581,8 @@ def deconv2d(x, kernel, output_shape, strides=(1, 1),\n                                                         filter_flip=not flip_filters)\n     conv_out = op(kernel, x, output_shape[2:])\n \n-    conv_out = _postprocess_conv2d_output(conv_out, x, border_mode, np_kernel,\n-                                          strides, dim_ordering)\n+    conv_out = _postprocess_conv2d_output(conv_out, x, border_mode,\n+                                          kernel_shape, strides, dim_ordering)\n     return conv_out\n \n \n@@ -1617,7 +1629,13 @@ def conv3d(x, kernel, strides=(1, 1, 1),\n     x = _preprocess_conv3d_input(x, dim_ordering)\n     kernel = _preprocess_conv3d_kernel(kernel, dim_ordering)\n     th_border_mode = _preprocess_border_mode(border_mode)\n-    np_kernel = kernel.eval()\n+\n+    if hasattr(kernel, '_keras_shape'):\n+        kernel_shape = kernel._keras_shape\n+    else:\n+        # Will only work if `kernel` is a shared variable.\n+        kernel_shape = kernel.eval().shape\n+\n     volume_shape = _preprocess_conv3d_volume_shape(dim_ordering, volume_shape)\n     filter_shape = _preprocess_conv3d_filter_shape(dim_ordering, filter_shape)\n \n@@ -1628,8 +1646,8 @@ def conv3d(x, kernel, strides=(1, 1, 1),\n                              filter_shape=filter_shape,\n                              filter_dilation=filter_dilation)\n \n-    conv_out = _postprocess_conv3d_output(conv_out, x, border_mode, np_kernel,\n-                                          strides, dim_ordering)\n+    conv_out = _postprocess_conv3d_output(conv_out, x, border_mode,\n+                                          kernel_shape, strides, dim_ordering)\n     return conv_out\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e58f0be8f011b04ebff0d82282cdcd1fd4480c56", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 176 | Contributors (this commit): 8 | Commits (past 90d): 4 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -14,5 +14,11 @@ setup(name='Keras',\n       extras_require={\n           'h5py': ['h5py'],\n           'visualize': ['pydot-ng'],\n+          'tests': ['pytest',\n+                    'pytest-cov',\n+                    'pytest-pep8',\n+                    'pytest-xdist',\n+                    'python-coveralls',\n+                    'coverage==3.7.1'],\n       },\n       packages=find_packages())\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#434545a11f10b5e47615dd23116cd8d3e24cf141", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 6 | Churn Cumulative: 6099 | Contributors (this commit): 61 | Commits (past 90d): 49 | Contributors (cumulative): 61 | DMM Complexity: 0.0\n\nDIFF:\n@@ -881,6 +881,12 @@ def batch_dot(x, y, axes=None):\n     if isinstance(axes, int):\n         axes = (axes, axes)\n     if ndim(x) == 2 and ndim(y) == 2:\n+        if tf_major_version >= 1:\n+            if axes[0] == axes[1]:\n+                out = tf.reduce_sum(tf.multiply(x, y), axes[0])\n+            else:\n+                out = tf.reduce_sum(tf.multiply(tf.transpose(x, [1, 0]), y), axes[1])\n+        else:\n             if axes[0] == axes[1]:\n                 out = tf.reduce_sum(tf.mul(x, y), axes[0])\n             else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9777b51ee2f898c176b6e7d2c9412eb7556bb60b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 196 | Contributors (this commit): 6 | Commits (past 90d): 5 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -110,7 +110,7 @@ def save_array(array, name):\n \n def load_array(name):\n     if tables is None:\n-        raise ImportError('The use of `save_array` requires '\n+        raise ImportError('The use of `load_array` requires '\n                           'the tables module.')\n     f = tables.open_file(name)\n     array = f.root.data\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#14f35ab05551ec0b4531489cd4c48a2dd322020e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 194 | Contributors (this commit): 4 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -57,8 +57,8 @@ def preprocess_input(audio_path, dim_ordering='default'):\n     if n_sample < n_sample_wanted:  # if too short\n         src = np.hstack((src, np.zeros((int(duration * sr) - n_sample,))))\n     elif n_sample > n_sample_wanted:  # if too long\n-        src = src[(n_sample - n_sample_wanted) / 2:\n-                  (n_sample + n_sample_wanted) / 2]\n+        src = src[(n_sample - n_sample_wanted) // 2:\n+                  (n_sample + n_sample_wanted) // 2]\n \n     logam = librosa.logamplitude\n     melgram = librosa.feature.melspectrogram\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#023331ec2a7b0086abfc81eca16c84a1692ee653", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2474 | Lines Deleted: 3062 | Files Changed: 29 | Hunks: 520 | Methods Changed: 218 | Complexity Δ (Sum/Max): -49/31 | Churn Δ: 5536 | Churn Cumulative: 65205 | Contributors (this commit): 229 | Commits (past 90d): 316 | Contributors (cumulative): 522 | DMM Complexity: 0.33125\n\nDIFF:\n@@ -25,15 +25,15 @@ maxlen = 80  # cut texts after this number of words (among top max_features most\n batch_size = 32\n \n print('Loading data...')\n-(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n-print(len(X_train), 'train sequences')\n-print(len(X_test), 'test sequences')\n+(x_train, y_train), (x_test, y_test) = imdb.load_data(nb_words=max_features)\n+print(len(x_train), 'train sequences')\n+print(len(x_test), 'test sequences')\n \n print('Pad sequences (samples x time)')\n-X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n-X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n-print('X_train shape:', X_train.shape)\n-print('X_test shape:', X_test.shape)\n+x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n+x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n+print('x_train shape:', x_train.shape)\n+print('x_test shape:', x_test.shape)\n \n print('Build model...')\n model = Sequential()\n@@ -48,9 +48,9 @@ model.compile(loss='binary_crossentropy',\n               metrics=['accuracy'])\n \n print('Train...')\n-model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=15,\n-          validation_data=(X_test, y_test))\n-score, acc = model.evaluate(X_test, y_test,\n+model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=15,\n+          validation_data=(x_test, y_test))\n+score, acc = model.evaluate(x_test, y_test,\n                             batch_size=batch_size)\n print('Test score:', score)\n print('Test accuracy:', acc)\n\n@@ -11,7 +11,7 @@ from . import constraints\n from . import initializers\r\n from . import metrics\r\n from . import models\r\n-from . import objectives\r\n+from . import losses\r\n from . import optimizers\r\n from . import regularizers\r\n \r\n\n@@ -1,6 +1,7 @@\n from __future__ import absolute_import\n+import six\n from . import backend as K\n-from .utils.generic_utils import get_from_module\n+from .utils.generic_utils import deserialize_keras_object\n \n \n def softmax(x):\n@@ -49,7 +50,25 @@ def linear(x):\n     return x\n \n \n+def serialize(activation):\n+    return activation.__name__\n+\n+\n+def deserialize(name, custom_objects=None):\n+    return deserialize_keras_object(name,\n+                                    module_objects=globals(),\n+                                    custom_objects=custom_objects,\n+                                    printable_module_name='activation function')\n+\n+\n def get(identifier):\n     if identifier is None:\n         return linear\n-    return get_from_module(identifier, globals(), 'activation function')\n+    if isinstance(identifier, six.string_types):\n+        identifier = str(identifier)\n+        return deserialize(identifier)\n+    elif callable(identifier):\n+        return identifier\n+    else:\n+        raise ValueError('Could not interpret '\n+                         'activation function identifier:', identifier)\n\n@@ -7,7 +7,6 @@ from .common import epsilon\n from .common import floatx\n from .common import set_epsilon\n from .common import set_floatx\n-from .common import get_uid\n from .common import cast_to_floatx\n from .common import image_data_format\n from .common import set_image_data_format\n\n@@ -1,11 +1,8 @@\n import numpy as np\n \n-from collections import defaultdict\n-\n # the type of float to use throughout the session.\n _FLOATX = 'float32'\n _EPSILON = 10e-8\n-_UID_PREFIXES = defaultdict(int)\n _IMAGE_DATA_FORMAT = 'channels_last'\n _LEGACY_WEIGHT_ORDERING = False\n \n@@ -151,33 +148,6 @@ def set_image_data_format(data_format):\n     _IMAGE_DATA_FORMAT = str(data_format)\n \n \n-def get_uid(prefix=''):\n-    \"\"\"Provides a unique UID given a string prefix.\n-\n-    # Arguments\n-        prefix: string.\n-\n-    # Returns\n-        An integer.\n-\n-    # Example\n-    ```\n-        >>> keras.backend.get_uid('dense')\n-        >>> 1\n-        >>> keras.backend.get_uid('dense')\n-        >>> 2\n-    ```\n-\n-    \"\"\"\n-    _UID_PREFIXES[prefix] += 1\n-    return _UID_PREFIXES[prefix]\n-\n-\n-def reset_uids():\n-    global _UID_PREFIXES\n-    _UID_PREFIXES = defaultdict(int)\n-\n-\n def is_keras_tensor(x):\n     \"\"\"Returns whether `x` is a Keras tensor.\n \n\n@@ -1,3 +1,4 @@\n+from collections import defaultdict\n import tensorflow as tf\n \n from tensorflow.python.training import moving_averages\n@@ -11,7 +12,7 @@ except ImportError:\n import numpy as np\n import os\n import warnings\n-from .common import floatx, _EPSILON, image_data_format, reset_uids\n+from .common import floatx, _EPSILON, image_data_format\n py_all = all\n \n # INTERNAL UTILS\n@@ -19,10 +20,18 @@ py_all = all\n # This is the default internal TF session used by Keras.\n # It can be set manually via `set_session(sess)`.\n _SESSION = None\n+\n # This dictionary holds a mapping {graph: learning_phase}.\n # A learning phase is a bool tensor used to run Keras models in\n # either train mode (learning_phase == 1) or test mode (learning_phase == 0).\n _GRAPH_LEARNING_PHASES = {}\n+\n+# This dictionary holds a mapping {graph: UID_DICT}.\n+# each UID_DICT is a dictionary mapping name prefixes to a current index,\n+# used for generatic graph-specific string UIDs\n+# for various names (e.g. layer names).\n+_GRAPH_UID_DICTS = {}\n+\n # This boolean flag can be set to True to leave variable initialization\n # up to the user.\n # Change its value via `manual_variable_initialization(value)`.\n@@ -33,6 +42,20 @@ tf_major_version = int(tf.__version__.split('.')[0])\n tf_minor_version = int(tf.__version__.split('.')[1])\n \n \n+def get_uid(prefix=''):\n+    global _GRAPH_UID_DICTS\n+    graph = tf.get_default_graph()\n+    if graph not in _GRAPH_UID_DICTS:\n+        _GRAPH_UID_DICTS[graph] = defaultdict(int)\n+    _GRAPH_UID_DICTS[graph][prefix] += 1\n+    return _GRAPH_UID_DICTS[graph][prefix]\n+\n+\n+def reset_uids():\n+    global _GRAPH_UID_DICTS\n+    _GRAPH_UID_DICTS = {}\n+\n+\n def clear_session():\n     \"\"\"Destroys the current TF graph and creates a new one.\n \n@@ -2612,13 +2635,13 @@ def _preprocess_conv3d_kernel(kernel, data_format):\n     return kernel\n \n \n-def _preprocess_border_mode(border_mode):\n-    if border_mode == 'same':\n+def _preprocess_padding(padding):\n+    if padding == 'same':\n         padding = 'SAME'\n-    elif border_mode == 'valid':\n+    elif padding == 'valid':\n         padding = 'VALID'\n     else:\n-        raise ValueError('Invalid border mode:', border_mode)\n+        raise ValueError('Invalid border mode:', padding)\n     return padding\n \n \n@@ -2640,43 +2663,50 @@ def _postprocess_conv3d_output(x, data_format):\n     return x\n \n \n-def conv1d(x, kernel, stride=1, border_mode='valid',\n-           image_shape=None, filter_shape=None):\n+def conv1d(x, kernel, stride=1, padding='valid',\n+           data_format=None, dilation_rate=1):\n     \"\"\"1D convolution.\n \n     # Arguments\n+        x: input tensor.\n         kernel: kernel tensor.\n         strides: stride integer.\n-        border_mode: string, `\"same\"` or `\"valid\"`.\n+        padding: string, `\"same\"` or `\"valid\"`.\n+        data_format: string, one of \"channels_last\", \"channels_first\".\n+        dilation_rate: integer dilate rate.\n \n     # Returns\n         A tensor, result of 1D convolution.\n     \"\"\"\n     # pre-process dtype\n-    x_dtype = dtype(x)\n-    if x_dtype == 'float64':\n-        x = tf.cast(x, 'float32')\n-        kernel = tf.cast(kernel, 'float32')\n-    padding = _preprocess_border_mode(border_mode)\n-    x = tf.nn.conv1d(x, kernel, stride, padding=padding)\n-    # post-process dtype\n-    if x_dtype == 'float64':\n-        x = tf.cast(x, 'float64')\n+    padding = _preprocess_padding(padding)\n+    if data_format == 'channels_last':\n+        tf_data_format = 'NWC'\n+    else:\n+        tf_data_format = 'NCW'\n+    x = tf.nn.convolution(\n+        input=x,\n+        filter=kernel,\n+        dilation_rate=(dilation_rate,),\n+        strides=(stride,),\n+        padding=padding,\n+        data_format=tf_data_format)\n     return x\n \n \n-def conv2d(x, kernel, strides=(1, 1), border_mode='valid',\n-           data_format='default',\n-           image_shape=None, filter_shape=None, filter_dilation=(1, 1)):\n+def conv2d(x, kernel, strides=(1, 1), padding='valid',\n+           data_format=None, dilation_rate=(1, 1)):\n     \"\"\"2D convolution.\n \n     # Arguments\n+        x: input tensor.\n         kernel: kernel tensor.\n         strides: strides tuple.\n-        border_mode: string, `\"same\"` or `\"valid\"`.\n+        padding: string, `\"same\"` or `\"valid\"`.\n         data_format: `\"channels_last\"` or `\"channels_first\"`.\n             Whether to use Theano or TensorFlow data format\n             for inputs/kernels/ouputs.\n+        dilation_rate: tuple of 2 integers.\n \n     # Returns\n         A tensor, result of 2D convolution.\n@@ -2684,28 +2714,28 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid',\n     # Raises\n         ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n     \"\"\"\n-    if data_format == 'default':\n+    if data_format is None:\n         data_format = image_data_format()\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format ' + str(data_format))\n \n-    x = _preprocess_conv2d_input(x, data_format)\n-    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n-    padding = _preprocess_border_mode(border_mode)\n-    if filter_dilation == (1, 1):\n-        strides = (1,) + strides + (1,)\n-        x = tf.nn.conv2d(x, kernel, strides, padding=padding)\n+    padding = _preprocess_padding(padding)\n+    if data_format == 'channels_last':\n+        tf_data_format = 'NHWC'\n     else:\n-        assert filter_dilation[0] == filter_dilation[1]\n-        assert strides == (1, 1), 'Invalid strides for dilated convolution'\n-        x = tf.nn.atrous_conv2d(x, kernel, filter_dilation[0], padding=padding)\n-    return _postprocess_conv2d_output(x, data_format)\n+        tf_data_format = 'NCHW'\n+    x = tf.nn.convolution(\n+        input=x,\n+        filter=kernel,\n+        dilation_rate=dilation_rate,\n+        strides=strides,\n+        padding=padding,\n+        data_format=tf_data_format)\n+    return x\n \n \n-def deconv2d(x, kernel, output_shape, strides=(1, 1),\n-             border_mode='valid',\n-             data_format='default',\n-             image_shape=None, filter_shape=None):\n+def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n+                     padding='valid', data_format=None):\n     \"\"\"2D deconvolution (i.e. transposed convolution).\n \n     # Arguments\n@@ -2713,7 +2743,7 @@ def deconv2d(x, kernel, output_shape, strides=(1, 1),\n         kernel: kernel tensor.\n         output_shape: 1D int tensor for the output shape.\n         strides: strides tuple.\n-        border_mode: string, `\"same\"` or `\"valid\"`.\n+        padding: string, `\"same\"` or `\"valid\"`.\n         data_format: `\"channels_last\"` or `\"channels_first\"`.\n             Whether to use Theano or TensorFlow data format\n             for inputs/kernels/ouputs.\n@@ -2724,7 +2754,7 @@ def deconv2d(x, kernel, output_shape, strides=(1, 1),\n     # Raises\n         ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n     \"\"\"\n-    if data_format == 'default':\n+    if data_format is None:\n         data_format = image_data_format()\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format ' + str(data_format))\n@@ -2733,61 +2763,27 @@ def deconv2d(x, kernel, output_shape, strides=(1, 1),\n     output_shape = _preprocess_deconv_output_shape(x, output_shape, data_format)\n     kernel = _preprocess_conv2d_kernel(kernel, data_format)\n     kernel = tf.transpose(kernel, (0, 1, 3, 2))\n-    padding = _preprocess_border_mode(border_mode)\n+    padding = _preprocess_padding(padding)\n     strides = (1,) + strides + (1,)\n \n     x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,\n                                padding=padding)\n-    return _postprocess_conv2d_output(x, data_format)\n-\n-\n-def atrous_conv2d(x, kernel, rate=1,\n-                  border_mode='valid',\n-                  data_format='default',\n-                  image_shape=None, filter_shape=None):\n-    \"\"\"Atrous 2D convolution. Also as known as dilated convolution.\n-\n-    # Arguments\n-        x: input tensor.\n-        kernel: kernel tensor.\n-        rate: integer > 0, the sample stride.\n-        output_shape: 1D int tensor for the output shape.\n-        strides: strides tuple.\n-        border_mode: string, `\"same\"` or `\"valid\"`.\n-        data_format: `\"channels_last\"` or `\"channels_first\"`.\n-            Whether to use Theano or TensorFlow data format\n-            for inputs/kernels/ouputs.\n-\n-    # Returns\n-        A tensor, result of atrous transposed 2D convolution.\n-\n-    # Raises\n-        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n-    \"\"\"\n-    if data_format == 'default':\n-        data_format = image_data_format()\n-    if data_format not in {'channels_first', 'channels_last'}:\n-        raise ValueError('Unknown data_format ' + str(data_format))\n-    if rate == 1:\n-        return conv2d(x, kernel, strides=(1, 1), border_mode=border_mode,\n-                      data_format=data_format)\n-\n-    x = _preprocess_conv2d_input(x, data_format)\n-    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n-    padding = _preprocess_border_mode(border_mode)\n-\n-    x = tf.nn.atrous_conv2d(x, kernel, rate, padding)\n-    return _postprocess_conv2d_output(x, data_format)\n+    x = _postprocess_conv2d_output(x, data_format)\n+    # TODO: set_shape with static shape\n+    return x\n \n \n def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n-                     border_mode='valid', data_format='default'):\n+                     padding='valid', data_format=None, dilation_rate=(1, 1)):\n     \"\"\"2-D convolution with separable filters.\n \n+    # Arguments\n+        # TODO\n+\n     # Raises\n         ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n     \"\"\"\n-    if data_format == 'default':\n+    if data_format is None:\n         data_format = image_data_format()\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format ' + str(data_format))\n@@ -2797,26 +2793,29 @@ def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n                                                  data_format)\n     pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel,\n                                                  data_format)\n-    padding = _preprocess_border_mode(border_mode)\n+    padding = _preprocess_padding(padding)\n     strides = (1,) + strides + (1,)\n \n     x = tf.nn.separable_conv2d(x, depthwise_kernel, pointwise_kernel,\n-                               strides, padding)\n+                               strides=strides,\n+                               padding=padding,\n+                               rate=dilation_rate)\n     return _postprocess_conv2d_output(x, data_format)\n \n \n-def conv3d(x, kernel, strides=(1, 1, 1),\n-           border_mode='valid', data_format='default',\n-           volume_shape=None, filter_shape=None):\n+def conv3d(x, kernel, strides=(1, 1, 1), padding='valid',\n+           data_format=None, dilation_rate=(1, 1, 1)):\n     \"\"\"3D convolution.\n \n     # Arguments\n+        x: input tensor.\n         kernel: kernel tensor.\n         strides: strides tuple.\n-        border_mode: string, `\"same\"` or `\"valid\"`.\n+        padding: string, `\"same\"` or `\"valid\"`.\n         data_format: `\"channels_last\"` or `\"channels_first\"`.\n             Whether to use Theano or TensorFlow data format\n             for inputs/kernels/ouputs.\n+        dilation_rate: tuple of 3 integers.\n \n     # Returns\n         A tensor, result of 3D convolution.\n@@ -2824,29 +2823,36 @@ def conv3d(x, kernel, strides=(1, 1, 1),\n     # Raises\n         ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n     \"\"\"\n-    if data_format == 'default':\n+    if data_format is None:\n         data_format = image_data_format()\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format ' + str(data_format))\n \n+    # With 5d inputs, tf.nn.convolution only supports\n+    # data_format NCHW, so we transpose the inputs\n+    # in case we are in data_format channels_first.\n     x = _preprocess_conv3d_input(x, data_format)\n-    kernel = _preprocess_conv3d_kernel(kernel, data_format)\n-    padding = _preprocess_border_mode(border_mode)\n-    strides = (1,) + strides + (1,)\n-\n-    x = tf.nn.conv3d(x, kernel, strides, padding)\n+    padding = _preprocess_padding(padding)\n+    x = tf.nn.convolution(\n+        input=x,\n+        filter=kernel,\n+        dilation_rate=dilation_rate,\n+        strides=strides,\n+        padding=padding,\n+        data_format='NDHWC')\n     return _postprocess_conv3d_output(x, data_format)\n \n \n def pool2d(x, pool_size, strides=(1, 1),\n-           border_mode='valid', data_format='default',\n+           padding='valid', data_format=None,\n            pool_mode='max'):\n     \"\"\"2D Pooling.\n \n     # Arguments\n+        x: input tensor.\n         pool_size: tuple of 2 integers.\n         strides: tuple of 2 integers.\n-        border_mode: one of `\"valid\"`, `\"same\"`.\n+        padding: one of `\"valid\"`, `\"same\"`.\n         data_format: one of `\"channels_first\"`, `\"channels_last\"`.\n         pool_mode: one of `\"max\"`, `\"avg\"`.\n \n@@ -2857,12 +2863,12 @@ def pool2d(x, pool_size, strides=(1, 1),\n         ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n         ValueError: if `pool_mode` is neither `max` or `avg`.\n     \"\"\"\n-    if data_format == 'default':\n+    if data_format is None:\n         data_format = image_data_format()\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format ' + str(data_format))\n \n-    padding = _preprocess_border_mode(border_mode)\n+    padding = _preprocess_padding(padding)\n     strides = (1,) + strides + (1,)\n     pool_size = (1,) + pool_size + (1,)\n \n@@ -2878,14 +2884,15 @@ def pool2d(x, pool_size, strides=(1, 1),\n     return _postprocess_conv2d_output(x, data_format)\n \n \n-def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n-           data_format='default', pool_mode='max'):\n+def pool3d(x, pool_size, strides=(1, 1, 1), padding='valid',\n+           data_format=None, pool_mode='max'):\n     \"\"\"3D Pooling.\n \n     # Arguments\n+        x: input tensor.\n         pool_size: tuple of 3 integers.\n         strides: tuple of 3 integers.\n-        border_mode: one of `\"valid\"`, `\"same\"`.\n+        padding: one of `\"valid\"`, `\"same\"`.\n         data_format: one of `\"channels_first\"`, `\"channels_last\"`.\n         pool_mode: one of `\"max\"`, `\"avg\"`.\n \n@@ -2896,12 +2903,12 @@ def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n         ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n         ValueError: if `pool_mode` is neither `max` or `avg`.\n     \"\"\"\n-    if data_format == 'default':\n+    if data_format is None:\n         data_format = image_data_format()\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format ' + str(data_format))\n \n-    padding = _preprocess_border_mode(border_mode)\n+    padding = _preprocess_padding(padding)\n     strides = (1,) + strides + (1,)\n     pool_size = (1,) + pool_size + (1,)\n \n@@ -2917,6 +2924,31 @@ def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n     return _postprocess_conv3d_output(x, data_format)\n \n \n+def bias_add(x, bias, data_format=None):\n+    if data_format is None:\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n+    if ndim(x) == 5:\n+        if data_format == 'channels_first':\n+            x += reshape(bias, (1, int_shape(bias)[0], 1, 1, 1))\n+        elif data_format == 'channels_last':\n+            x += reshape(bias, (1, 1, 1, 1, int_shape(bias)[0]))\n+    elif ndim(x) == 4:\n+        if data_format == 'channels_first':\n+            x += reshape(bias, (1, int_shape(bias)[0], 1, 1))\n+        elif data_format == 'channels_last':\n+            x += reshape(bias, (1, 1, 1, int_shape(bias)[0]))\n+    elif ndim(x) == 3:\n+        if data_format == 'channels_first':\n+            x += reshape(bias, (1, int_shape(bias)[0], 1))\n+        elif data_format == 'channels_last':\n+            x += reshape(bias, (1, 1, int_shape(bias)[0]))\n+    else:\n+        x += bias\n+    return x\n+\n+\n # RANDOMNESS\n \n def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n\n@@ -1,3 +1,4 @@\n+from collections import defaultdict\n import theano\n from theano import tensor as T\n from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n@@ -21,6 +22,7 @@ py_all = all\n # INTERNAL UTILS\n theano.config.floatX = _FLOATX\n _LEARNING_PHASE = T.scalar(dtype='uint8', name='keras_learning_phase')  # 0 = test, 1 = train\n+_UID_PREFIXES = defaultdict(int)\n \n \n def learning_phase():\n@@ -36,6 +38,33 @@ def set_learning_phase(value):\n     _LEARNING_PHASE = value\n \n \n+def get_uid(prefix=''):\n+    \"\"\"Provides a unique UID given a string prefix.\n+\n+    # Arguments\n+        prefix: string.\n+\n+    # Returns\n+        An integer.\n+\n+    # Example\n+    ```\n+        >>> keras.backend.get_uid('dense')\n+        >>> 1\n+        >>> keras.backend.get_uid('dense')\n+        >>> 2\n+    ```\n+\n+    \"\"\"\n+    _UID_PREFIXES[prefix] += 1\n+    return _UID_PREFIXES[prefix]\n+\n+\n+def reset_uids():\n+    global _UID_PREFIXES\n+    _UID_PREFIXES = defaultdict(int)\n+\n+\n # VARIABLE MANIPULATION\n \n \n@@ -1366,35 +1395,33 @@ def _preprocess_conv3d_input(x, data_format):\n \n \n def _preprocess_conv2d_kernel(kernel, data_format):\n-    if data_format == 'channels_last':\n-        # TF uses the last dimension as channel dimension,\n-        # instead of the 2nd one.\n-        # TH kernel shape: (depth, input_depth, rows, cols)\n-        # TF kernel shape: (rows, cols, input_depth, depth)\n+    # As of Keras 2.0.0, all kernels are normalized\n+    # on the format `(rows, cols, input_depth, depth)`,\n+    # independently of `data_format`.\n+    # Theano expects `(depth, input_depth, rows, cols)`.\n     kernel = kernel.dimshuffle((3, 2, 0, 1))\n     return kernel\n \n \n def _preprocess_conv3d_kernel(kernel, data_format):\n-    if data_format == 'channels_last':\n-        # TF uses the last dimension as channel dimension,\n-        # instead of the 2nd one.\n-        # TH kernel shape: (depth, input_depth, rows, cols, slices)\n-        # TF kernel shape: (rows, cols, slices, input_depth, depth)\n+    # As of Keras 2.0.0, all kernels are normalized\n+    # on the format `(space, input_depth, depth)`,\n+    # independently of `data_format`.\n+    # Theano expects `(depth, input_depth, space)`.\n     kernel = kernel.dimshuffle((4, 3, 0, 1, 2))\n     return kernel\n \n \n-def _preprocess_border_mode(border_mode):\n-    if border_mode == 'same':\n-        th_border_mode = 'half'\n-    elif border_mode == 'valid':\n-        th_border_mode = 'valid'\n-    elif border_mode == 'full':\n-        th_border_mode = 'full'\n+def _preprocess_padding(padding):\n+    if padding == 'same':\n+        th_padding = 'half'\n+    elif padding == 'valid':\n+        th_padding = 'valid'\n+    elif padding == 'full':\n+        th_padding = 'full'\n     else:\n-        raise ValueError('Border mode not supported:', str(border_mode))\n-    return th_border_mode\n+        raise ValueError('Border mode not supported:', str(padding))\n+    return th_padding\n \n \n def _preprocess_conv2d_image_shape(data_format, image_shape):\n@@ -1462,9 +1489,9 @@ def _preprocess_conv3d_filter_shape(data_format, filter_shape):\n \n \n def _postprocess_conv2d_output(conv_out, x,\n-                               border_mode, kernel_shape,\n+                               padding, kernel_shape,\n                                strides, data_format):\n-    if border_mode == 'same':\n+    if padding == 'same':\n         if kernel_shape[2] % 2 == 0:\n             conv_out = conv_out[:, :, :(x.shape[2] + strides[0] - 1) // strides[0], :]\n         if kernel_shape[3] % 2 == 0:\n@@ -1475,9 +1502,9 @@ def _postprocess_conv2d_output(conv_out, x,\n \n \n def _postprocess_conv3d_output(conv_out, x,\n-                               border_mode, kernel_shape,\n+                               padding, kernel_shape,\n                                strides, data_format):\n-    if border_mode == 'same':\n+    if padding == 'same':\n         if kernel_shape[2] % 2 == 0:\n             conv_out = conv_out[:, :, :(x.shape[2] + strides[0] - 1) // strides[0], :, :]\n         if kernel_shape[3] % 2 == 0:\n@@ -1489,39 +1516,74 @@ def _postprocess_conv3d_output(conv_out, x,\n     return conv_out\n \n \n-def conv1d(x, kernel, stride=1, border_mode='valid',\n-           image_shape=None, filter_shape=None):\n+def conv1d(x, kernel, stride=1, padding='valid',\n+           data_format=None, dilation_rate=1):\n     \"\"\"1D convolution.\n \n     # Arguments\n         kernel: kernel tensor.\n         strides: stride integer.\n-        border_mode: string, \"same\" or \"valid\".\n+        padding: string, \"same\" or \"valid\".\n+        data_format: string, one of \"channels_last\", \"channels_first\"\n+        dilate_rate: integer.\n     \"\"\"\n-    raise NotImplementedError\n+    if data_format is None:\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ', data_format)\n+    if data_format == 'channels_last':\n+        # original shape: (batch, length, input_dim)\n+        # add dim to x to have (batch, length, 1, input_dim)\n+        x = expand_dims(x, 2)\n+        # update x._keras_shape\n+        if hasattr(x, '_keras_shape'):\n+            shape = x._keras_shape\n+            x._keras_shape = (shape[0], shape[1], 1, shape[2])\n+    else:\n+        # original shape: (batch, input_dim, length)\n+        # add dim to x to have (batch, input_dim, length, 1)\n+        x = expand_dims(x, 3)\n+        # update x._keras_shape\n+        if hasattr(x, '_keras_shape'):\n+            shape = x._keras_shape\n+            x._keras_shape = (shape[0], shape[1], shape[2], 1)\n+    # update dilation rate, strides\n+    dilation_rate = (dilation_rate, 1)\n+    strides = (stride, 1)\n+    # add dim to kernel (always same format independently of data_format)\n+    # i.e. (rows, 1, input_depth, depth)\n+    kernel = expand_dims(x, 1)\n+    output = conv2d(x, kernel,\n+                    strides=strides, padding=padding,\n+                    data_format=data_format, dilation_rate=dilation_rate)\n+    # remove added dim\n+    if data_format == 'channels_last':\n+        output = squeeze(output, 2)\n+    else:\n+        output = squeeze(output, 3)\n+    return output\n \n \n-def conv2d(x, kernel, strides=(1, 1), border_mode='valid',\n-           data_format='default', image_shape=None,\n-           filter_shape=None, filter_dilation=(1, 1)):\n+def conv2d(x, kernel, strides=(1, 1), padding='valid',\n+           data_format=None, dilation_rate=(1, 1)):\n     \"\"\"2D convolution.\n \n     # Arguments\n         kernel: kernel tensor.\n         strides: strides tuple.\n-        border_mode: string, \"same\" or \"valid\".\n+        padding: string, \"same\" or \"valid\".\n         data_format: \"channels_last\" or \"channels_first\".\n             Whether to use Theano or TensorFlow data format\n         in inputs/kernels/ouputs.\n     \"\"\"\n-    if data_format == 'default':\n+    if data_format is None:\n         data_format = image_data_format()\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format ', data_format)\n \n     x = _preprocess_conv2d_input(x, data_format)\n     kernel = _preprocess_conv2d_kernel(kernel, data_format)\n-    th_border_mode = _preprocess_border_mode(border_mode)\n+    th_padding = _preprocess_padding(padding)\n \n     if hasattr(kernel, '_keras_shape'):\n         kernel_shape = kernel._keras_shape\n@@ -1529,50 +1591,36 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid',\n         # Will only work if `kernel` is a shared variable.\n         kernel_shape = kernel.eval().shape\n \n+    image_shape = int_shape(x)\n     image_shape = _preprocess_conv2d_image_shape(data_format, image_shape)\n-    filter_shape = _preprocess_conv2d_filter_shape(data_format, filter_shape)\n+    kernel_shape = _preprocess_conv2d_filter_shape(data_format, kernel_shape)\n \n-    # TODO: remove the if statement when theano with no filter dilation is deprecated.\n-    if filter_dilation == (1, 1):\n     conv_out = T.nnet.conv2d(x, kernel,\n-                                 border_mode=th_border_mode,\n+                             border_mode=th_padding,\n                              subsample=strides,\n                              input_shape=image_shape,\n-                                 filter_shape=filter_shape)\n-    else:\n-        # T.nnet.conv2d uses **kwargs, so the filter_dilation parameter will be\n-        # ignored by versions that do not support it\n-        if 'filter_dilation' not in inspect.getargspec(T.nnet.conv2d).args:\n-            raise ValueError('conv2d with filter dilation requires Theano '\n-                             '0.9.0dev2 or newer.')\n-        conv_out = T.nnet.conv2d(x, kernel,\n-                                 border_mode=th_border_mode,\n-                                 subsample=strides,\n-                                 input_shape=image_shape,\n-                                 filter_shape=filter_shape,\n-                                 filter_dilation=filter_dilation)\n-    conv_out = _postprocess_conv2d_output(conv_out, x, border_mode,\n+                             filter_shape=kernel_shape,\n+                             filter_dilation=dilation_rate)\n+    conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n                                           kernel_shape, strides, data_format)\n     return conv_out\n \n \n-def deconv2d(x, kernel, output_shape, strides=(1, 1),\n-             border_mode='valid',\n-             data_format='default',\n-             image_shape=None, filter_shape=None):\n+def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n+                     padding='valid', data_format=None):\n     \"\"\"2D deconvolution (transposed convolution).\n \n     # Arguments\n         kernel: kernel tensor.\n         output_shape: desired dimensions of output.\n         strides: strides tuple.\n-        border_mode: string, \"same\" or \"valid\".\n+        padding: string, \"same\" or \"valid\".\n         data_format: \"channels_last\" or \"channels_first\".\n             Whether to use Theano or TensorFlow data format\n         in inputs/kernels/ouputs.\n     \"\"\"\n     flip_filters = False\n-    if data_format == 'default':\n+    if data_format is None:\n         data_format = image_data_format()\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format ' + data_format)\n@@ -1587,7 +1635,7 @@ def deconv2d(x, kernel, output_shape, strides=(1, 1),\n     kernel = _preprocess_conv2d_kernel(kernel, data_format)\n \n     kernel = kernel.dimshuffle((1, 0, 2, 3))\n-    th_border_mode = _preprocess_border_mode(border_mode)\n+    th_padding = _preprocess_padding(padding)\n \n     if hasattr(kernel, '_keras_shape'):\n         kernel_shape = kernel._keras_shape\n@@ -1595,64 +1643,46 @@ def deconv2d(x, kernel, output_shape, strides=(1, 1),\n         # Will only work if `kernel` is a shared variable.\n         kernel_shape = kernel.eval().shape\n \n-    filter_shape = _preprocess_conv2d_filter_shape(data_format, filter_shape)\n-\n+    filter_shape = _preprocess_conv2d_filter_shape(data_format, kernel_shape)\n     filter_shape = tuple(filter_shape[i] for i in (1, 0, 2, 3))\n \n     op = T.nnet.abstract_conv.AbstractConv2d_gradInputs(imshp=output_shape,\n-                                                        kshp=filter_shape,\n+                                                        kshp=kernel_shape,\n                                                         subsample=strides,\n-                                                        border_mode=th_border_mode,\n+                                                        border_mode=th_padding,\n                                                         filter_flip=not flip_filters)\n     conv_out = op(kernel, x, output_shape[2:])\n-    conv_out = _postprocess_conv2d_output(conv_out, x, border_mode,\n+    conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n                                           kernel_shape, strides, data_format)\n     return conv_out\n \n \n-def atrous_conv2d(x, kernel, rate=1,\n-                  border_mode='valid',\n-                  data_format='default',\n-                  image_shape=None, filter_shape=None):\n-    raise NotImplementedError\n-\n-\n def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n-                     border_mode='valid', data_format='default'):\n+                     padding='valid', data_format=None, dilation_rate=(1, 1)):\n     raise NotImplementedError\n \n \n def conv3d(x, kernel, strides=(1, 1, 1),\n-           border_mode='valid', data_format='default',\n-           volume_shape=None, filter_shape=None,\n-           filter_dilation=(1, 1, 1)):\n+           padding='valid', data_format=None,\n+           dilation_rate=(1, 1, 1)):\n     \"\"\"3D convolution.\n \n     # Arguments\n         kernel: kernel tensor.\n         strides: strides tuple.\n-        border_mode: string, \"same\" or \"valid\".\n+        padding: string, \"same\" or \"valid\".\n         data_format: \"channels_last\" or \"channels_first\".\n             Whether to use Theano or TensorFlow data format\n         in inputs/kernels/ouputs.\n     \"\"\"\n-    if data_format == 'default':\n+    if data_format is None:\n         data_format = image_data_format()\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format:', data_format)\n \n-    # TODO: remove this if statement when Theano without AbstractConv3d is deprecated\n-    if not hasattr(T.nnet, 'conv3d'):\n-        if filter_dilation != (1, 1, 1):\n-            raise ValueError('conv3d with filter dilation requires Theano '\n-                             '0.9.0dev3 or newer.')\n-\n-        return _old_theano_conv3d(x, kernel, strides, border_mode,\n-                                  data_format, volume_shape, filter_shape)\n-\n     x = _preprocess_conv3d_input(x, data_format)\n     kernel = _preprocess_conv3d_kernel(kernel, data_format)\n-    th_border_mode = _preprocess_border_mode(border_mode)\n+    th_padding = _preprocess_padding(padding)\n \n     if hasattr(kernel, '_keras_shape'):\n         kernel_shape = kernel._keras_shape\n@@ -1660,101 +1690,38 @@ def conv3d(x, kernel, strides=(1, 1, 1),\n         # Will only work if `kernel` is a shared variable.\n         kernel_shape = kernel.eval().shape\n \n+    volume_shape = int_shape(x)\n     volume_shape = _preprocess_conv3d_volume_shape(data_format, volume_shape)\n-    filter_shape = _preprocess_conv3d_filter_shape(data_format, filter_shape)\n+    kernel_shape = _preprocess_conv3d_filter_shape(data_format, kernel_shape)\n \n     conv_out = T.nnet.conv3d(x, kernel,\n-                             border_mode=th_border_mode,\n+                             border_mode=th_padding,\n                              subsample=strides,\n                              input_shape=volume_shape,\n-                             filter_shape=filter_shape,\n-                             filter_dilation=filter_dilation)\n-    conv_out = _postprocess_conv3d_output(conv_out, x, border_mode,\n+                             filter_shape=kernel_shape,\n+                             filter_dilation=dilation_rate)\n+    conv_out = _postprocess_conv3d_output(conv_out, x, padding,\n                                           kernel_shape, strides, data_format)\n     return conv_out\n \n \n-# TODO: remove this function when theano without AbstractConv3d is deprecated\n-def _old_theano_conv3d(x, kernel, strides=(1, 1, 1),\n-                       border_mode='valid', data_format='default',\n-                       volume_shape=None, filter_shape=None):\n-    \"\"\"\n-    Run on cuDNN if available.\n-    border_mode: string, \"same\" or \"valid\".\n-    \"\"\"\n-    if data_format == 'default':\n-        data_format = image_data_format()\n-    if data_format not in {'channels_first', 'channels_last'}:\n-        raise ValueError('Unknown data_format:', data_format)\n-    if border_mode not in {'same', 'valid'}:\n-        raise ValueError('Invalid border mode:', border_mode)\n-\n-    if data_format == 'channels_last':\n-        # TF uses the last dimension as channel dimension,\n-        # instead of the 2nd one.\n-        # TH input shape: (samples, input_depth, conv_dim1, conv_dim2, conv_dim3)\n-        # TF input shape: (samples, conv_dim1, conv_dim2, conv_dim3, input_depth)\n-        # TH kernel shape: (out_depth, input_depth, kernel_dim1, kernel_dim2, kernel_dim3)\n-        # TF kernel shape: (kernel_dim1, kernel_dim2, kernel_dim3, input_depth, out_depth)\n-        x = x.dimshuffle((0, 4, 1, 2, 3))\n-        kernel = kernel.dimshuffle((4, 3, 0, 1, 2))\n-        if volume_shape:\n-            volume_shape = (volume_shape[0], volume_shape[4],\n-                            volume_shape[1], volume_shape[2], volume_shape[3])\n-        if filter_shape:\n-            filter_shape = (filter_shape[4], filter_shape[3],\n-                            filter_shape[0], filter_shape[1], filter_shape[2])\n-\n-    if border_mode == 'same':\n-        assert(strides == (1, 1, 1))\n-        pad_dim1 = (kernel.shape[2] - 1)\n-        pad_dim2 = (kernel.shape[3] - 1)\n-        pad_dim3 = (kernel.shape[4] - 1)\n-        output_shape = (x.shape[0], x.shape[1],\n-                        x.shape[2] + pad_dim1,\n-                        x.shape[3] + pad_dim2,\n-                        x.shape[4] + pad_dim3)\n-        output = T.zeros(output_shape)\n-        indices = (slice(None), slice(None),\n-                   slice(pad_dim1 // 2, x.shape[2] + pad_dim1 // 2),\n-                   slice(pad_dim2 // 2, x.shape[3] + pad_dim2 // 2),\n-                   slice(pad_dim3 // 2, x.shape[4] + pad_dim3 // 2))\n-        x = T.set_subtensor(output[indices], x)\n-        border_mode = 'valid'\n-\n-    border_mode_3d = (border_mode, border_mode, border_mode)\n-    conv_out = conv3d2d.conv3d(signals=x.dimshuffle(0, 2, 1, 3, 4),\n-                               filters=kernel.dimshuffle(0, 2, 1, 3, 4),\n-                               border_mode=border_mode_3d)\n-    conv_out = conv_out.dimshuffle(0, 2, 1, 3, 4)\n-\n-    # support strides by manually slicing the output\n-    if strides != (1, 1, 1):\n-        conv_out = conv_out[:, :, ::strides[0], ::strides[1], ::strides[2]]\n-\n-    if data_format == 'channels_last':\n-        conv_out = conv_out.dimshuffle((0, 2, 3, 4, 1))\n-\n-    return conv_out\n-\n-\n-def pool2d(x, pool_size, strides=(1, 1), border_mode='valid',\n-           data_format='default', pool_mode='max'):\n-    if data_format == 'default':\n+def pool2d(x, pool_size, strides=(1, 1), padding='valid',\n+           data_format=None, pool_mode='max'):\n+    if data_format is None:\n         data_format = image_data_format()\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format:', data_format)\n \n     assert pool_size[0] >= 1 and pool_size[1] >= 1\n \n-    if border_mode == 'same':\n+    if padding == 'same':\n         w_pad = pool_size[0] - 2 if pool_size[0] > 2 and pool_size[0] % 2 == 1 else pool_size[0] - 1\n         h_pad = pool_size[1] - 2 if pool_size[1] > 2 and pool_size[1] % 2 == 1 else pool_size[1] - 1\n         padding = (w_pad, h_pad)\n-    elif border_mode == 'valid':\n+    elif padding == 'valid':\n         padding = (0, 0)\n     else:\n-        raise ValueError('Invalid border mode:', border_mode)\n+        raise ValueError('Invalid border mode:', padding)\n \n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format:', data_format)\n@@ -1763,37 +1730,19 @@ def pool2d(x, pool_size, strides=(1, 1), border_mode='valid',\n         x = x.dimshuffle((0, 3, 1, 2))\n \n     if pool_mode == 'max':\n-        # TODO remove the old call once Theano older than 0.9.0dev4 is deprecated\n-        try:\n-            # new interface (introduced in 0.9.0dev4)\n         pool_out = pool.pool_2d(x, ws=pool_size, stride=strides,\n                                 ignore_border=True,\n                                 pad=padding,\n                                 mode='max')\n-        except TypeError:\n-            # old interface\n-            pool_out = pool.pool_2d(x, ds=pool_size, st=strides,\n-                                    ignore_border=True,\n-                                    padding=padding,\n-                                    mode='max')\n     elif pool_mode == 'avg':\n-        # TODO remove the old call once Theano older than 0.9.0dev4 is deprecated\n-        try:\n-            # new interface (introduced in 0.9.0dev4)\n         pool_out = pool.pool_2d(x, ws=pool_size, stride=strides,\n                                 ignore_border=True,\n                                 pad=padding,\n                                 mode='average_exc_pad')\n-        except TypeError:\n-            # old interface\n-            pool_out = pool.pool_2d(x, ds=pool_size, st=strides,\n-                                    ignore_border=True,\n-                                    padding=padding,\n-                                    mode='average_exc_pad')\n     else:\n         raise ValueError('Invalid pooling mode:', pool_mode)\n \n-    if border_mode == 'same':\n+    if padding == 'same':\n         expected_width = (x.shape[2] + strides[0] - 1) // strides[0]\n         expected_height = (x.shape[3] + strides[1] - 1) // strides[1]\n \n@@ -1806,28 +1755,22 @@ def pool2d(x, pool_size, strides=(1, 1), border_mode='valid',\n     return pool_out\n \n \n-def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n-           data_format='default', pool_mode='max'):\n-    if data_format == 'default':\n+def pool3d(x, pool_size, strides=(1, 1, 1), padding='valid',\n+           data_format=None, pool_mode='max'):\n+    if data_format is None:\n         data_format = image_data_format()\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format:', data_format)\n \n-    # TODO: remove this if statement when Theano without pool_3d is deprecated\n-    #       (pool_3d was introduced after 0.9.0dev3)\n-    if not hasattr(T.signal.pool, 'pool_3d'):\n-        return _old_theano_pool3d(x, pool_size, strides, border_mode,\n-                                  data_format, pool_mode)\n-\n-    if border_mode == 'same':\n+    if padding == 'same':\n         w_pad = pool_size[0] - 2 if pool_size[0] % 2 == 1 else pool_size[0] - 1\n         h_pad = pool_size[1] - 2 if pool_size[1] % 2 == 1 else pool_size[1] - 1\n         d_pad = pool_size[2] - 2 if pool_size[2] % 2 == 1 else pool_size[2] - 1\n         padding = (w_pad, h_pad, d_pad)\n-    elif border_mode == 'valid':\n+    elif padding == 'valid':\n         padding = (0, 0, 0)\n     else:\n-        raise ValueError('Invalid border mode:', border_mode)\n+        raise ValueError('Invalid padding:', padding)\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format:', data_format)\n \n@@ -1835,37 +1778,19 @@ def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n         x = x.dimshuffle((0, 4, 1, 2, 3))\n \n     if pool_mode == 'max':\n-        # TODO remove the old call once Theano older than 0.9.0dev4 is deprecated\n-        try:\n-            # new interface (introduced in 0.9.0dev4)\n         pool_out = pool.pool_3d(x, ws=pool_size, stride=strides,\n                                 ignore_border=True,\n                                 pad=padding,\n                                 mode='max')\n-        except TypeError:\n-            # old interface\n-            pool_out = pool.pool_3d(x, ds=pool_size, st=strides,\n-                                    ignore_border=True,\n-                                    padding=padding,\n-                                    mode='max')\n     elif pool_mode == 'avg':\n-        # TODO remove the old call once Theano older than 0.9.0dev4 is deprecated\n-        try:\n-            # new interface (introduced in 0.9.0dev4)\n         pool_out = pool.pool_3d(x, ws=pool_size, stride=strides,\n                                 ignore_border=True,\n                                 pad=padding,\n                                 mode='average_exc_pad')\n-        except TypeError:\n-            # old interface\n-            pool_out = pool.pool_3d(x, ds=pool_size, st=strides,\n-                                    ignore_border=True,\n-                                    padding=padding,\n-                                    mode='average_exc_pad')\n     else:\n         raise ValueError('Invalid pooling mode:', pool_mode)\n \n-    if border_mode == 'same':\n+    if padding == 'same':\n         expected_width = (x.shape[2] + strides[0] - 1) // strides[0]\n         expected_height = (x.shape[3] + strides[1] - 1) // strides[1]\n         expected_depth = (x.shape[4] + strides[2] - 1) // strides[2]\n@@ -1880,69 +1805,29 @@ def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n     return pool_out\n \n \n-# TODO: remove this function when Theano without pool_3d is deprecated\n-#       (pool_3d was introduced after 0.9.0dev3)\n-def _old_theano_pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n-                       data_format='default', pool_mode='max'):\n-    if data_format == 'default':\n+def bias_add(x, bias, data_format=None):\n+    if data_format is None:\n         data_format = image_data_format()\n     if data_format not in {'channels_first', 'channels_last'}:\n-        raise ValueError('Unknown data_format:', data_format)\n-\n-    if border_mode == 'same':\n-        # TODO: add implementation for border_mode=\"same\"\n-        raise ValueError('border_mode=\"same\" not supported with Theano.')\n-    elif border_mode == 'valid':\n-        ignore_border = True\n-        padding = (0, 0)\n+        raise ValueError('Unknown data_format ' + str(data_format))\n+    if ndim(x) == 5:\n+        if data_format == 'channels_first':\n+            x += reshape(bias, (1, bias.shape[0], 1, 1, 1))\n+        elif data_format == 'channels_last':\n+            x += reshape(bias, (1, 1, 1, 1, bias.shape[0]))\n+    if ndim(x) == 4:\n+        if data_format == 'channels_first':\n+            x += reshape(bias, (1, bias.shape[0], 1, 1))\n+        elif data_format == 'channels_last':\n+            x += reshape(bias, (1, 1, 1, bias.shape[0]))\n+    if ndim(x) == 3:\n+        if data_format == 'channels_first':\n+            x += reshape(bias, (1, bias.shape[0], 1))\n+        elif data_format == 'channels_last':\n+            x += reshape(bias, (1, 1, bias.shape[0]))\n     else:\n-        raise ValueError('Invalid border mode:', border_mode)\n-\n-    if data_format not in {'channels_first', 'channels_last'}:\n-        raise ValueError('Unknown data_format:', data_format)\n-\n-    if data_format == 'channels_last':\n-        x = x.dimshuffle((0, 4, 1, 2, 3))\n-\n-    if pool_mode == 'max':\n-        # pooling over conv_dim2, conv_dim1 (last two channels)\n-        output = pool.pool_2d(input=x.dimshuffle(0, 1, 4, 3, 2),\n-                              ds=(pool_size[1], pool_size[0]),\n-                              st=(strides[1], strides[0]),\n-                              ignore_border=ignore_border,\n-                              padding=padding,\n-                              mode='max')\n-\n-        # pooling over conv_dim3\n-        pool_out = pool.pool_2d(input=output.dimshuffle(0, 1, 4, 3, 2),\n-                                ds=(1, pool_size[2]),\n-                                st=(1, strides[2]),\n-                                ignore_border=ignore_border,\n-                                padding=padding,\n-                                mode='max')\n-\n-    elif pool_mode == 'avg':\n-        # pooling over conv_dim2, conv_dim1 (last two channels)\n-        output = pool.pool_2d(input=x.dimshuffle(0, 1, 4, 3, 2),\n-                              ds=(pool_size[1], pool_size[0]),\n-                              st=(strides[1], strides[0]),\n-                              ignore_border=ignore_border,\n-                              padding=padding,\n-                              mode='average_exc_pad')\n-\n-        # pooling over conv_dim3\n-        pool_out = pool.pool_2d(input=output.dimshuffle(0, 1, 4, 3, 2),\n-                                ds=(1, pool_size[2]),\n-                                st=(1, strides[2]),\n-                                ignore_border=ignore_border,\n-                                padding=padding,\n-                                mode='average_exc_pad')\n-    else:\n-        raise ValueError('Invalid pooling mode:', pool_mode)\n-\n-    if data_format == 'channels_last':\n-        pool_out = pool_out.dimshuffle((0, 2, 3, 4, 1))\n-    return pool_out\n+        x += bias\n+    return x\n \n \n # RANDOMNESS\n\n@@ -1,12 +1,14 @@\n from __future__ import absolute_import\n+import six\n from . import backend as K\n-from .utils.generic_utils import get_from_module\n+from .utils.generic_utils import serialize_keras_object\n+from .utils.generic_utils import deserialize_keras_object\n \n \n class Constraint(object):\n \n-    def __call__(self, p):\n-        return p\n+    def __call__(self, w):\n+        return w\n \n     def get_config(self):\n         return {'name': self.__class__.__name__}\n@@ -40,8 +42,8 @@ class MaxNorm(Constraint):\n         self.m = m\n         self.axis = axis\n \n-    def __call__(self, p):\n-        norms = K.sqrt(K.sum(K.square(p), axis=self.axis, keepdims=True))\n+    def __call__(self, w):\n+        norms = K.sqrt(K.sum(K.square(w), axis=self.axis, keepdims=True))\n         desired = K.clip(norms, 0, self.m)\n         p *= (desired / (K.epsilon() + norms))\n         return p\n@@ -81,8 +83,8 @@ class UnitNorm(Constraint):\n     def __init__(self, axis=0):\n         self.axis = axis\n \n-    def __call__(self, p):\n-        return p / (K.epsilon() + K.sqrt(K.sum(K.square(p),\n+    def __call__(self, w):\n+        return w / (K.epsilon() + K.sqrt(K.sum(K.square(w),\n                                                axis=self.axis,\n                                                keepdims=True)))\n \n@@ -124,11 +126,12 @@ class MinMaxNorm(Constraint):\n         self.rate = rate\n         self.axis = axis\n \n-    def __call__(self, p):\n-        norms = K.sqrt(K.sum(K.square(p), axis=self.axis, keepdims=True))\n-        desired = self.rate * K.clip(norms, self.low, self.high) + (1 - self.rate) * norms\n-        p *= (desired / (K.epsilon() + norms))\n-        return p\n+    def __call__(self, w):\n+        norms = K.sqrt(K.sum(K.square(w), axis=self.axis, keepdims=True))\n+        desired = (self.rate * K.clip(norms, self.low, self.high) +\n+                   (1 - self.rate) * norms)\n+        w *= (desired / (K.epsilon() + norms))\n+        return w\n \n     def get_config(self):\n         return {'name': self.__class__.__name__,\n@@ -140,11 +143,31 @@ class MinMaxNorm(Constraint):\n \n # Aliases.\n \n-maxnorm = MaxNorm\n-nonneg = NonNeg\n-unitnorm = UnitNorm\n+max_norm = MaxNorm\n+non_neg = NonNeg\n+unit_norm = UnitNorm\n \n \n-def get(identifier, kwargs=None):\n-    return get_from_module(identifier, globals(), 'constraint',\n-                           instantiate=True, kwargs=kwargs)\n+def serialize(constraint):\n+    return serialize_keras_object(constraint)\n+\n+\n+def deserialize(config):\n+    return deserialize_keras_object(config,\n+                                    module_objects=globals(),\n+                                    printable_module_name='regularizer')\n+\n+\n+def get(identifier):\n+    if identifier is None:\n+        return None\n+    if isinstance(identifier, dict):\n+        return deserialize(identifier)\n+    elif isinstance(identifier, six.string_types):\n+        config = {'class_name': str(identifier), 'config': {}}\n+        return deserialize(config)\n+    elif callable(identifier):\n+        return identifier\n+    else:\n+        raise ValueError('Could not interpret constraint identifier:',\n+                         identifier)\n\n@@ -9,6 +9,7 @@ import types as python_types\n import warnings\n import copy\n import os\n+import re\n import inspect\n from six.moves import zip\n \n@@ -29,18 +30,81 @@ def to_list(x):\n     return [x]\n \n \n-def object_list_uid(object_list):\n+def _object_list_uid(object_list):\n     object_list = to_list(object_list)\n     return ', '.join([str(abs(id(x))) for x in object_list])\n \n \n+def _is_all_none(iterable_or_element):\n+    if not isinstance(iterable_or_element, (list, tuple)):\n+        iterable = [iterable_or_element]\n+    else:\n+        iterable = iterable_or_element\n+    for element in iterable:\n+        if element is not None:\n+            return False\n+    return True\n+\n+\n+def _collect_previous_mask(input_tensors):\n+    # Return the output mask(s) of the previous node.\n+    input_tensors = to_list(input_tensors)\n+    inbound_layers = []\n+    node_indices = []\n+    tensor_indices = []\n+    for x in input_tensors:\n+        if hasattr(x, '_keras_history'):\n+            inbound_layer, node_index, tensor_index = x._keras_history\n+            inbound_layers.append(inbound_layer)\n+            node_indices.append(node_index)\n+            tensor_indices.append(tensor_index)\n+        else:\n+            raise ValueError('Input tensor is not a Keras tensor:', x)\n+    nodes = [layer.inbound_nodes[i] for layer, i in zip(inbound_layers, node_indices)]\n+    masks = [node.output_masks[i] for node, i in zip(nodes, tensor_indices)]\n+    if len(masks) == 1:\n+        return masks[0]\n+    return masks\n+\n+\n+def _to_snake_case(name):\n+    intermediate = re.sub('(.)([A-Z][a-z0-9]+)', r'\\1_\\2', name)\n+    insecure = re.sub('([a-z])([A-Z])', r'\\1_\\2', intermediate).lower()\n+    # If the class is private the name starts with \"_\" which is not secure\n+    # for creating scopes. We prefix the name with \"private\" in this case.\n+    if insecure[0] != '_':\n+        return insecure\n+    return 'private' + insecure\n+\n+\n+def _collect_input_shape(input_tensors):\n+    # Return the output shape(s) of a list of Keras tensors.\n+    input_tensors = to_list(input_tensors)\n+    shapes = []\n+    for x in input_tensors:\n+        if hasattr(x, '_keras_shape'):\n+            shapes.append(x._keras_shape)\n+        else:\n+            raise ValueError('Input tensor is not a Keras tensor:', x)\n+    if len(shapes) == 1:\n+        return shapes[0]\n+    return shapes\n+\n+\n class InputSpec(object):\n-    \"\"\"This specifies the ndim, dtype and shape of every input to a layer.\n+    \"\"\"Specifies the ndim, dtype and shape of every input to a layer.\n+\n     Every layer should expose (if appropriate) an `input_spec` attribute:\n     a list of instances of InputSpec (one per input tensor).\n \n     A None entry in a shape is compatible with any dimension,\n     a None shape is compatible with any shape.\n+\n+    # Arguments\n+        TODO\n+\n+    # Attributes\n+        TODO\n     \"\"\"\n \n     def __init__(self, dtype=None, shape=None, ndim=None):\n@@ -140,68 +204,6 @@ class Node(object):\n                 layer.outbound_nodes.append(self)\n         outbound_layer.inbound_nodes.append(self)\n \n-    @classmethod\n-    def create_node(cls, outbound_layer,\n-                    inbound_layers, node_indices=None, tensor_indices=None):\n-        if not node_indices:\n-            node_indices = [0 for _ in range(len(inbound_layers))]\n-        else:\n-            assert len(node_indices) == len(inbound_layers)\n-        if not tensor_indices:\n-            tensor_indices = [0 for _ in range(len(inbound_layers))]\n-\n-        input_tensors = []\n-        input_masks = []\n-        input_shapes = []\n-\n-        for inbound_layer, node_index, tensor_index in zip(inbound_layers, node_indices, tensor_indices):\n-            inbound_node = inbound_layer.inbound_nodes[node_index]\n-            input_tensors.append(inbound_node.output_tensors[tensor_index])\n-            input_masks.append(inbound_node.output_masks[tensor_index])\n-            input_shapes.append(inbound_node.output_shapes[tensor_index])\n-\n-        assert len(input_shapes) == len(input_tensors) == len(input_masks)\n-\n-        if len(input_tensors) == 1:\n-            output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n-            output_masks = to_list(outbound_layer.compute_mask(input_tensors[0], input_masks[0]))\n-            # TODO: try to auto-infer shape\n-            # if exception is raised by get_output_shape_for.\n-            output_shapes = to_list(outbound_layer.get_output_shape_for(input_shapes[0]))\n-        else:\n-            output_tensors = to_list(outbound_layer.call(input_tensors, mask=input_masks))\n-            output_masks = to_list(outbound_layer.compute_mask(input_tensors, input_masks))\n-            output_shapes = to_list(outbound_layer.get_output_shape_for(input_shapes))\n-\n-        if not output_tensors or output_tensors[0] is None:\n-            raise TypeError('The `call` method of layer \"' +\n-                            outbound_layer.name +\n-                            '\" should return a tensor. Found: ' +\n-                            str(output_tensors[0]))\n-        if len(output_tensors) != len(output_shapes):\n-            raise ValueError('The `get_output_shape_for` method of layer \"' +\n-                             outbound_layer.name +\n-                             '\"\" should return one shape tuple per '\n-                             'output tensor of the layer. Found: ' +\n-                             str(output_shapes))\n-        if len(output_tensors) != len(output_masks):\n-            raise ValueError('The `compute_mask` method of layer \"' +\n-                             outbound_layer.name +\n-                             '\" should return one mask tensor per '\n-                             'output tensor of the layer. Found: ' +\n-                             str(output_masks))\n-\n-        for i in range(len(output_tensors)):\n-            output_tensors[i]._keras_shape = output_shapes[i]\n-            output_tensors[i]._uses_learning_phase = any([x._uses_learning_phase for x in input_tensors]) or outbound_layer.uses_learning_phase\n-            output_tensors[i]._keras_history = (outbound_layer, len(outbound_layer.inbound_nodes), i)\n-\n-        return cls(outbound_layer,\n-                   inbound_layers, node_indices, tensor_indices,\n-                   input_tensors, output_tensors,\n-                   input_masks, output_masks,\n-                   input_shapes, output_shapes)\n-\n     def get_config(self):\n         inbound_names = []\n         for layer in self.inbound_layers:\n@@ -241,7 +243,6 @@ class Layer(object):\n         output_shape: Shape tuple. See above.\n         inbound_nodes: List of nodes.\n         outbound_nodes: List of nodes.\n-        supports_masking: Boolean.\n         input, output: Input/output tensor(s). Note that if the layer is used\n             more than once (shared layer), this is ill-defined\n             and will raise an exception. In such cases, use\n@@ -258,7 +259,7 @@ class Layer(object):\n         __call__(x, mask=None): Wrapper around the layer logic (`call`).\n             If x is a Keras tensor:\n                 - Connect current layer with last layer from tensor:\n-                    `self.add_inbound_node(last_layer)`\n+                    `self._add_inbound_node(last_layer)`\n                 - Add layer to tensor history\n             If layer is not built:\n                 - Build from x._keras_shape\n@@ -280,44 +281,34 @@ class Layer(object):\n \n     # Internal methods:\n         build(input_shape)\n-        add_inbound_node(layer, index=0)\n+        _add_inbound_node(layer, index=0)\n         create_input_layer()\n         assert_input_compatibility()\n     \"\"\"\n \n     def __init__(self, **kwargs):\n-        # These properties should have been set\n-        # by the child class, as appropriate.\n-        if not hasattr(self, 'input_spec'):\n         self.input_spec = None\n-        if not hasattr(self, 'supports_masking'):\n-            self.supports_masking = False\n-        if not hasattr(self, 'uses_learning_phase'):\n         self.uses_learning_phase = False\n+        self.supports_masking = False\n \n-        # These lists will be filled via successive calls\n-        # to self.add_inbound_node().\n-        self.inbound_nodes = []\n-        self.outbound_nodes = []\n-\n-        # These properties will be set upon call of self.build(),\n-        # which itself will be called upon self.add_inbound_node if necessary.\n-        if not hasattr(self, '_trainable_weights'):\n+        # These properties will be set upon call of self.build()\n         self._trainable_weights = []\n-        if not hasattr(self, '_non_trainable_weights'):\n         self._non_trainable_weights = []\n-        if not hasattr(self, 'losses'):\n-            self.losses = []\n-        if not hasattr(self, 'constraints'):\n         self.constraints = {}  # dict {tensor: constraint instance}\n         self.built = False\n \n+        # These lists will be filled via successive calls\n+        # to self._add_inbound_node().\n+        self.inbound_nodes = []\n+        self.outbound_nodes = []\n+\n         # These properties should be set by the user via keyword arguments.\n         # note that 'input_dtype', 'input_shape' and 'batch_input_shape'\n         # are only applicable to input layers: do not pass these keywords\n         # to non-input layers.\n         allowed_kwargs = {'input_shape',\n                           'batch_input_shape',\n+                          'batch_size',\n                           'input_dtype',\n                           'name',\n                           'trainable'}\n@@ -326,18 +317,22 @@ class Layer(object):\n                 raise TypeError('Keyword argument not understood:', kwarg)\n         name = kwargs.get('name')\n         if not name:\n-            prefix = self.__class__.__name__.lower()\n-            name = prefix + '_' + str(K.get_uid(prefix))\n+            prefix = self.__class__.__name__\n+            name = _to_snake_case(prefix) + '_' + str(K.get_uid(prefix))\n         self.name = name\n \n         self.trainable = kwargs.get('trainable', True)\n-        if 'batch_input_shape' in kwargs or 'input_shape' in kwargs:\n-            # In this case we will create an input layer\n+        if 'input_shape' in kwargs or 'batch_input_shape' in kwargs:\n+            # In this case we will later create an input layer\n             # to insert before the current layer\n             if 'batch_input_shape' in kwargs:\n                 batch_input_shape = tuple(kwargs['batch_input_shape'])\n             elif 'input_shape' in kwargs:\n-                batch_input_shape = (None,) + tuple(kwargs['input_shape'])\n+                if 'batch_size' in kwargs:\n+                    batch_size = kwargs['batch_size']\n+                else:\n+                    batch_size = None\n+                batch_input_shape = (batch_size,) + tuple(kwargs['input_shape'])\n             self.batch_input_shape = batch_input_shape\n             input_dtype = kwargs.get('input_dtype', K.floatx())\n             self.input_dtype = input_dtype\n@@ -366,25 +361,10 @@ class Layer(object):\n     def non_trainable_weights(self, weights):\n         self._non_trainable_weights = weights\n \n-    @property\n-    def regularizers(self):\n-        warnings.warn('The `regularizers` property of '\n-                      'layers/models is deprecated. '\n-                      'Regularization losses are now managed via the `losses` '\n-                      'layer/model property.')\n-        return []\n-\n-    @regularizers.setter\n-    def regularizers(self, _):\n-        warnings.warn('The `regularizers` property of layers/models '\n-                      'is deprecated. '\n-                      'Regularization losses are now managed via the `losses` '\n-                      'layer/model property.')\n-\n     def create_input_layer(self, batch_input_shape,\n                            input_dtype=None, name=None):\n         if not name:\n-            prefix = self.__class__.__name__.lower() + '_input_'\n+            prefix = _to_snake_case(self.__class__.__name__) + '_input_'\n             name = prefix + str(K.get_uid(prefix))\n         if not input_dtype:\n             input_dtype = K.floatx()\n@@ -493,37 +473,37 @@ class Layer(object):\n                                 str(spec.shape) + ', found shape=' +\n                                 str(x_shape))\n \n-    def call(self, x, mask=None):\n+    def call(self, x):\n         \"\"\"This is where the layer's logic lives.\n \n         # Arguments\n             x: input tensor, or list/tuple of input tensors.\n-            mask: a masking tensor (or list of tensors). Used mainly in RNNs.\n \n         # Returns:\n             A tensor or list/tuple of tensors.\n         \"\"\"\n         return x\n \n-    def __call__(self, x, mask=None):\n+    def __call__(self, x, **kwargs):\n         \"\"\"Wrapper around self.call(), for handling\n         internal Keras references.\n \n         If a Keras tensor is passed:\n-            - We call self.add_inbound_node().\n+            - We call self._add_inbound_node().\n             - If necessary, we `build` the layer to match\n                 the _keras_shape of the input(s).\n             - We update the _keras_shape of every input tensor with\n                 its new shape (obtained via self.get_output_shape_for).\n-                This is done as part of add_inbound_node().\n+                This is done as part of _add_inbound_node().\n             - We update the _keras_history of the output tensor(s)\n                 with the current layer.\n-                This is done as part of add_inbound_node().\n+                This is done as part of _add_inbound_node().\n \n         # Arguments\n             x: Can be a tensor or list/tuple of tensors.\n-            mask: Tensor or list/tuple of tensors.\n+            **kwargs: Additional keyword arguments to be passed to `call()`.\n         \"\"\"\n+        # Handle laying building (weight creating, input spec locking).\n         if not self.built:\n             # Raise exceptions in case the input is not compatible\n             # with the input_spec specified in the layer constructor.\n@@ -553,87 +533,89 @@ class Layer(object):\n         # with the input_spec set at build time.\n         self.assert_input_compatibility(x)\n \n-        input_tensors = to_list(x)\n-        inbound_layers = []\n-        node_indices = []\n-        tensor_indices = []\n-        for input_tensor in input_tensors:\n-            if hasattr(input_tensor, '_keras_history') and input_tensor._keras_history:\n-                # This is a Keras tensor.\n-                previous_layer, node_index, tensor_index = input_tensor._keras_history\n-                inbound_layers.append(previous_layer)\n-                node_indices.append(node_index)\n-                tensor_indices.append(tensor_index)\n-            else:\n-                inbound_layers = None\n-                break\n+        # Handle mask propagation.\n+        previous_mask = _collect_previous_mask(x)\n+        if not _is_all_none(previous_mask):\n+            # The previous layer generated a mask.\n+            if 'mask' in inspect.getargspec(self.call).args:\n+                if 'mask' not in kwargs:\n+                    # If mask is explicitly passed to __call__,\n+                    # we should override the default mask.\n+                    kwargs['mask'] = previous_mask\n+        # Handle automatic shape inference (only useful for Theano).\n+        input_shape = _collect_input_shape(x)\n \n-        if inbound_layers:\n-            # This will call layer.build() if necessary.\n-            self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n-            # Outputs were already computed when calling self.add_inbound_node.\n-            outputs = self.inbound_nodes[-1].output_tensors\n-        else:\n-            # This case appears if the input was not a Keras tensor.\n-            outputs = to_list(self.call(x, mask))\n+        # Actually call the layer, collecting output(s), mask(s), and shape(s).\n+        output = self.call(x, **kwargs)\n+        output_mask = self.compute_mask(x, previous_mask)\n+        # Infering the output shape is only relevant for Theano.\n+        output_shape = self.get_output_shape_for(input_shape)\n+\n+        # Add an inbound node to the layer, so that it keeps track\n+        # of the call and of all new variables created during the call.\n+        # This also updates the layer history of the output tensor(s).\n+        # If the input tensor(s) had not previous Keras history,\n+        # this does nothing.\n+        self._add_inbound_node(input_tensors=x, output_tensors=output,\n+                               input_masks=previous_mask, output_masks=output_mask,\n+                               input_shapes=input_shape, output_shapes=output_shape)\n \n         # Apply activity regularizer if any:\n         if hasattr(self, 'activity_regularizer') and self.activity_regularizer is not None:\n-            regularization_losses = [self.activity_regularizer(x) for x in outputs]\n-            self.add_loss(regularization_losses, input_tensors)\n+            regularization_losses = [self.activity_regularizer(x) for x in to_list(output)]\n+            self.add_loss(regularization_losses, to_list(x))\n \n-        # If single output tensor: return it,\n-        # else return a list (at least 2 elements).\n-        if len(outputs) == 1:\n-            return outputs[0]\n-        else:\n-            return outputs\n+        return output\n \n-    def add_inbound_node(self, inbound_layers,\n-                         node_indices=None, tensor_indices=None):\n+    def _add_inbound_node(self, input_tensors, output_tensors,\n+                          input_masks, output_masks,\n+                          input_shapes, output_shapes):\n         \"\"\"\n-        # Arguments\n-            inbound_layers: Can be a layer instance\n-                or a list/tuple of layer instances.\n-            node_indices: Integer (or list of integers).\n-                The input layer might have a number of\n-                parallel output streams;\n-                this is the index of the stream (in the input layer)\n-                where to connect the current layer.\n-            tensor_indices: Integer or list of integers.\n-                The output of the inbound node might be a list/tuple\n-                of tensor, and we might only be interested in\n-                one specific entry.\n-                This index allows you to specify the index of\n-                the entry in the output list\n-                (if applicable). \"None\" means that we take all outputs\n-                (as a list).\n+        TODO\n         \"\"\"\n-        inbound_layers = to_list(inbound_layers)\n-        if not node_indices:\n-            node_indices = [0 for _ in range(len(inbound_layers))]\n-        else:\n-            node_indices = to_list(node_indices)\n-            assert len(node_indices) == len(inbound_layers)\n-        if not tensor_indices:\n-            tensor_indices = [0 for _ in range(len(inbound_layers))]\n-        else:\n-            tensor_indices = to_list(tensor_indices)\n+        input_tensors = to_list(input_tensors)\n+        output_tensors = to_list(output_tensors)\n+        input_masks = to_list(input_masks)\n+        output_masks = to_list(output_masks)\n+        input_shapes = to_list(output_shapes)\n+        output_shapes = to_list(output_shapes)\n \n-        if not self.built:\n-            # collect input_shapes for call to build()\n-            input_shapes = []\n-            for layer, node_index, tensor_index in zip(inbound_layers, node_indices, tensor_indices):\n-                input_shapes.append(layer.inbound_nodes[node_index].output_shapes[tensor_index])\n-            # call build()\n-            if len(input_shapes) == 1:\n-                self.build(input_shape=input_shapes[0])\n+        # Collect input tensor(s) coordinates.\n+        inbound_layers = []\n+        node_indices = []\n+        tensor_indices = []\n+        for x in input_tensors:\n+            if hasattr(x, '_keras_history'):\n+                inbound_layer, node_index, tensor_index = x._keras_history\n+                inbound_layers.append(inbound_layer)\n+                node_indices.append(node_index)\n+                tensor_indices.append(tensor_index)\n             else:\n-                self.build(input_shape=input_shapes)\n-            self.built = True\n-        # creating the node automatically updates self.inbound_nodes\n-        # as well as outbound_nodes on inbound layers.\n-        Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n+                raise ValueError('Input tensor is not a Keras tensor:', x)\n+\n+        # Create node, add it to inbound nodes.\n+        Node(\n+            self,\n+            inbound_layers=inbound_layers,\n+            node_indices=node_indices,\n+            tensor_indices=tensor_indices,\n+            input_tensors=input_tensors,\n+            output_tensors=output_tensors,\n+            input_masks=input_masks,\n+            output_masks=output_masks,\n+            input_shapes=input_shapes,\n+            output_shapes=output_shapes\n+        )\n+\n+        # Update tensor history, _keras_shape and _uses_learning_phase.\n+        for i in range(len(output_tensors)):\n+            output_tensors[i]._keras_shape = output_shapes[i]\n+            uses_lp = (any([x._uses_learning_phase for x in input_tensors]) or\n+                       self.uses_learning_phase)\n+            output_tensors[i]._uses_learning_phase = uses_lp\n+            output_tensors[i]._keras_history = (self,\n+                                                len(self.inbound_nodes) - 1,\n+                                                i)\n \n     def get_output_shape_for(self, input_shape):\n         \"\"\"Computes the output shape of the layer given\n@@ -660,16 +642,16 @@ class Layer(object):\n             None or a tensor (or list of tensors,\n                 one per output tensor of the layer).\n         \"\"\"\n-        if not hasattr(self, 'supports_masking') or not self.supports_masking:\n+        if not self.supports_masking:\n             if input_mask is not None:\n                 if isinstance(input_mask, list):\n                     if any(mask is not None for mask in input_mask):\n-                        raise ValueError('Layer ' + self.name +\n+                        raise TypeError('Layer ' + self.name +\n                                         ' does not support masking, '\n                                         'but was passed an input_mask: ' +\n                                         str(input_mask))\n                 else:\n-                    raise ValueError('Layer ' + self.name +\n+                    raise TypeError('Layer ' + self.name +\n                                     ' does not support masking, '\n                                     'but was passed an input_mask: ' +\n                                     str(input_mask))\n@@ -693,6 +675,12 @@ class Layer(object):\n     def _get_node_attribute_at_index(self, node_index, attr, attr_name):\n         \"\"\"Retrieves an attribute (e.g. input_tensors) from a node.\n \n+        This is used to implement the methods:\n+            - get_input_shape_at\n+            - get_output_shape_at\n+            - get_input_at\n+            etc...\n+\n         # Arguments\n             node_index: Integer index of the node from which\n                 to retrieve the attribute.\n@@ -760,6 +748,9 @@ class Layer(object):\n         \"\"\"Retrieves the input tensor(s) of a layer (only applicable if\n         the layer has exactly one inbound node, i.e. if it is connected\n         to one incoming layer).\n+\n+        # Returns\n+            TODO\n         \"\"\"\n         if len(self.inbound_nodes) > 1:\n             raise AttributeError('Layer ' + self.name +\n@@ -778,6 +769,9 @@ class Layer(object):\n         \"\"\"Retrieves the output tensor(s) of a layer (only applicable if\n         the layer has exactly one inbound node, i.e. if it is connected\n         to one incoming layer).\n+\n+        # Returns\n+            TODO\n         \"\"\"\n         if len(self.inbound_nodes) == 0:\n             raise AttributeError('Layer ' + self.name +\n@@ -796,13 +790,17 @@ class Layer(object):\n         \"\"\"Retrieves the input mask tensor(s) of a layer (only applicable if\n         the layer has exactly one inbound node, i.e. if it is connected\n         to one incoming layer).\n+\n+        # Returns\n+            TODO\n         \"\"\"\n         if len(self.inbound_nodes) != 1:\n             raise AttributeError('Layer ' + self.name +\n                                  ' has multiple inbound nodes, ' +\n                                  'hence the notion of \"layer input mask\" '\n                                  'is ill-defined. '\n-                                 'Use `get_input_mask_at(node_index)` instead.')\n+                                 'Use `get_input_mask_at(node_index)` '\n+                                 'instead.')\n         return self._get_node_attribute_at_index(0, 'input_masks',\n                                                  'input mask')\n \n@@ -811,6 +809,9 @@ class Layer(object):\n         \"\"\"Retrieves the output mask tensor(s) of a layer (only applicable if\n         the layer has exactly one inbound node, i.e. if it is connected\n         to one incoming layer).\n+\n+        # Returns\n+            TODO\n         \"\"\"\n         if len(self.inbound_nodes) != 1:\n             raise AttributeError('Layer ' + self.name +\n@@ -827,6 +828,9 @@ class Layer(object):\n         \"\"\"Retrieves the input shape tuple(s) of a layer. Only applicable\n         if the layer has one inbound node,\n         or if all inbound nodes have the same input shape.\n+\n+        # Returns\n+            TODO\n         \"\"\"\n         if not self.inbound_nodes:\n             raise AttributeError('The layer has never been called '\n@@ -852,6 +856,9 @@ class Layer(object):\n         \"\"\"Retrieves the output shape tuple(s) of a layer. Only applicable\n         if the layer has one inbound node,\n         or if all inbound nodes have the same output shape.\n+\n+        # Returns\n+            TODO\n         \"\"\"\n         if not self.inbound_nodes:\n             raise AttributeError('The layer has never been called '\n@@ -873,6 +880,8 @@ class Layer(object):\n                                  'instead.')\n \n     def add_loss(self, losses, inputs=None):\n+        \"\"\"TODO\n+        \"\"\"\n         if losses is None:\n             return\n         # Update self.losses\n@@ -891,7 +900,7 @@ class Layer(object):\n         if not hasattr(self, '_per_input_losses'):\n             self._per_input_losses = {}\n         if inputs is not None:\n-            inputs_hash = object_list_uid(inputs)\n+            inputs_hash = _object_list_uid(inputs)\n         else:\n             # Updates indexed by None are unconditional\n             # rather than input-dependent\n@@ -901,6 +910,8 @@ class Layer(object):\n         self._per_input_losses[inputs_hash] += losses\n \n     def add_update(self, updates, inputs=None):\n+        \"\"\"TODO\n+        \"\"\"\n         if updates is None:\n             return\n         # Update self.updates\n@@ -919,7 +930,7 @@ class Layer(object):\n         if not hasattr(self, '_per_input_updates'):\n             self._per_input_updates = {}\n         if inputs is not None:\n-            inputs_hash = object_list_uid(inputs)\n+            inputs_hash = _object_list_uid(inputs)\n         else:\n             # Updates indexed by None are unconditional\n             # rather than input-dependent\n@@ -932,7 +943,7 @@ class Layer(object):\n         if not hasattr(self, '_per_input_updates'):\n             return []\n         if inputs is not None:\n-            inputs_hash = object_list_uid(inputs)\n+            inputs_hash = _object_list_uid(inputs)\n         else:\n             inputs_hash = None\n         if inputs_hash in self._per_input_updates:\n@@ -943,7 +954,7 @@ class Layer(object):\n         if not hasattr(self, '_per_input_losses'):\n             return []\n         if inputs is not None:\n-            inputs_hash = object_list_uid(inputs)\n+            inputs_hash = _object_list_uid(inputs)\n         else:\n             inputs_hash = None\n         if inputs_hash in self._per_input_losses:\n@@ -988,21 +999,28 @@ class Layer(object):\n         K.batch_set_value(weight_value_tuples)\n \n     def get_weights(self):\n-        \"\"\"Returns the current weights of the layer,\n-        as a list of numpy arrays.\n+        \"\"\"Returns the current weights of the layer.\n+\n+        # Returns\n+            Weights values as a list of numpy arrays.\n         \"\"\"\n         params = self.weights\n         return K.batch_get_value(params)\n \n     def get_config(self):\n-        \"\"\"Returns a Python dictionary (serializable)\n+        \"\"\"Returns the config of the layer.\n+\n+        A layer config is a Python dictionary (serializable)\n         containing the configuration of a layer.\n         The same layer can be reinstantiated later\n         (without its trained weights) from this configuration.\n \n         The config of a layer does not include connectivity\n         information, nor the layer class name. These are handled\n-        by Container (one layer of abstraction above).\n+        by `Container` (one layer of abstraction above).\n+\n+        # Returns\n+            Python dictionary.\n         \"\"\"\n         config = {'name': self.name,\n                   'trainable': self.trainable}\n@@ -1014,7 +1032,9 @@ class Layer(object):\n \n     @classmethod\n     def from_config(cls, config):\n-        \"\"\"This method is the reverse of get_config,\n+        \"\"\"Creates a layer from its config.\n+\n+        This method is the reverse of `get_config`,\n         capable of instantiating the same layer from the config\n         dictionary. It does not handle layer connectivity\n         (handled by Container), nor weights (handled by `set_weights`).\n@@ -1022,12 +1042,17 @@ class Layer(object):\n         # Arguments\n             config: A Python dictionary, typically the\n                 output of get_config.\n+\n+        # Returns\n+            A layer instance.\n         \"\"\"\n         return cls(**config)\n \n     def count_params(self):\n-        \"\"\"Returns the total number of floats (or ints)\n-        composing the weights of the layer.\n+        \"\"\"Count the total number of scalars composing the weights.\n+\n+        # Returns\n+            An integer count.\n         \"\"\"\n         if not self.built:\n             if self.__class__.__name__ == 'Sequential':\n@@ -1042,6 +1067,7 @@ class Layer(object):\n \n class InputLayer(Layer):\n     \"\"\"Layer to be used as an entry point into a graph.\n+\n     It can either wrap an existing tensor (pass an `input_tensor` argument)\n     or create its a placeholder tensor (pass arguments `input_shape`\n     or `batch_input_shape` as well as `input_dtype`).\n@@ -1059,8 +1085,8 @@ class InputLayer(Layer):\n \n     def __init__(self, input_shape=None, batch_input_shape=None,\n                  input_dtype=None, input_tensor=None, sparse=False, name=None):\n+        # TODO: call parent's __init__ instead.\n         self.input_spec = None\n-        self.supports_masking = False\n         self.uses_learning_phase = False\n         self.trainable = False\n         self.built = True\n@@ -1263,6 +1289,7 @@ class Merge(Layer):\n                  dot_axes=-1, output_shape=None, output_mask=None,\n                  arguments=None, node_indices=None, tensor_indices=None,\n                  name=None):\n+        # TODO: call parent's __init__ instead.\n         self.layers = layers\n         self.mode = mode\n         self.concat_axis = concat_axis\n@@ -1278,7 +1305,6 @@ class Merge(Layer):\n         self.constraints = {}\n         self._trainable_weights = []\n         self._non_trainable_weights = []\n-        self.supports_masking = True\n         self.uses_learning_phase = False\n         self.input_spec = None  # Compatible with anything.\n         if not name:\n@@ -1299,7 +1325,7 @@ class Merge(Layer):\n                                        concat_axis, dot_axes,\n                                        node_indices, tensor_indices)\n             self.built = True\n-            self.add_inbound_node(layers, node_indices, tensor_indices)\n+            self._add_inbound_node(layers, node_indices, tensor_indices)\n         else:\n             self.built = False\n \n@@ -1371,7 +1397,7 @@ class Merge(Layer):\n                                  'output shapes except for the concat axis. '\n                                  'Layer shapes: %s' % (input_shapes))\n \n-    def call(self, inputs, mask=None):\n+    def call(self, inputs):\n         if not isinstance(inputs, list) or len(inputs) <= 1:\n             raise TypeError('Merge must be called on a list of tensors '\n                             '(at least 2). Got: ' + str(inputs))\n@@ -1422,7 +1448,7 @@ class Merge(Layer):\n         else:\n             raise ValueError('Unknown merge mode.')\n \n-    def __call__(self, inputs, mask=None):\n+    def __call__(self, inputs, **kwargs):\n         \"\"\"We disable successive calls to __call__ for Merge layers.\n         Although there is no technical obstacle to\n         making it possible to __call__ a Merge instance many times\n@@ -1456,12 +1482,12 @@ class Merge(Layer):\n                                        self.concat_axis, self.dot_axes,\n                                        node_indices, tensor_indices)\n             self.built = True\n-            self.add_inbound_node(layers, node_indices, tensor_indices)\n+            self._add_inbound_node(layers, node_indices, tensor_indices)\n \n             outputs = self.inbound_nodes[-1].output_tensors\n             return outputs[0]  # Merge only returns a single tensor.\n         else:\n-            return self.call(inputs, mask)\n+            return self.masked_call(inputs, **kwargs)\n \n     def get_output_shape_for(self, input_shape):\n         # Must have multiple input shape tuples.\n@@ -1712,7 +1738,6 @@ class Container(Layer):\n         output_shape\n         inbound_nodes: list of nodes\n         outbound_nodes: list of nodes\n-        supports_masking (boolean)\n         trainable_weights (list of variables)\n         non_trainable_weights (list of variables)\n         constraints (list of tuples (weight, constraint))\n@@ -1730,12 +1755,15 @@ class Container(Layer):\n     \"\"\"\n \n     def __init__(self, input, output, name=None):\n+        # TODO: call parent's __init__ instead.\n         # Handle name argument.\n         if not name:\n             prefix = self.__class__.__name__.lower()\n             name = prefix + '_' + str(K.get_uid(prefix))\n         self.name = name\n \n+        self.supports_masking = False\n+\n         # Whether container weights are trainable.\n         self.trainable = True\n \n@@ -2029,7 +2057,7 @@ class Container(Layer):\n              input_shapes=[x._keras_shape for x in self.inputs],\n              output_shapes=[x._keras_shape for x in self.outputs])\n         self.built = True\n-        self.supports_masking = False\n+\n         # The following are implemented as property functions:\n         # self.constraints\n         # self.trainable_weights\n@@ -2142,16 +2170,6 @@ class Container(Layer):\n                 cons[key] = value\n         return cons\n \n-    @property\n-    def regularizers(self):\n-        warnings.warn('The `regularizers` attribute of layers/models '\n-                      'is deprecated. '\n-                      'Regularization losses are now managed via the `losses` '\n-                      'layer/model property.\\n'\n-                      'The `regularizers` attribute will be removed '\n-                      'after 06/2017.')\n-        return []\n-\n     @property\n     def trainable_weights(self):\n         if not self.trainable:\n@@ -2387,8 +2405,8 @@ class Container(Layer):\n                     # call layer\n                     if len(computed_data) == 1:\n                         computed_tensor, computed_mask = computed_data[0]\n-                        output_tensors = to_list(layer.call(computed_tensor,\n-                                                            computed_mask))\n+                        output_tensors = to_list(layer.masked_call(computed_tensor,\n+                                                                   mask=computed_mask))\n                         output_masks = to_list(layer.compute_mask(computed_tensor,\n                                                                   computed_mask))\n                         computed_tensors = [computed_tensor]\n@@ -2396,8 +2414,8 @@ class Container(Layer):\n                     else:\n                         computed_tensors = [x[0] for x in computed_data]\n                         computed_masks = [x[1] for x in computed_data]\n-                        output_tensors = to_list(layer.call(computed_tensors,\n-                                                            computed_masks))\n+                        output_tensors = to_list(layer.masked_call(computed_tensors,\n+                                                                   mask=computed_masks))\n                         output_masks = to_list(layer.compute_mask(computed_tensors,\n                                                                   computed_masks))\n \n@@ -2780,17 +2798,6 @@ class Container(Layer):\n                                      ' weights, but the saved weights have ' +\n                                      str(len(weight_values)) +\n                                      ' elements.')\n-                if layer.__class__.__name__ == 'Convolution1D':\n-                    # This is for backwards compatibility with\n-                    # the old Conv1D weights format.\n-                    w = weight_values[0]\n-                    shape = w.shape\n-                    if shape[:2] != (layer.filter_length, 1) or shape[3] != layer.nb_filter:\n-                        # Legacy shape:\n-                        # (self.nb_filter, input_dim, self.filter_length, 1)\n-                        assert shape[0] == layer.nb_filter and shape[2:] == (layer.filter_length, 1)\n-                        w = np.transpose(w, (2, 3, 1, 0))\n-                        weight_values[0] = w\n                 weight_value_tuples += zip(symbolic_weights, weight_values)\n             K.batch_set_value(weight_value_tuples)\n \n\n@@ -18,7 +18,7 @@ except ImportError:\n from .topology import Container\n from .. import backend as K\n from .. import optimizers\n-from .. import objectives\n+from .. import losses\n from .. import metrics as metrics_module\n from ..utils.generic_utils import Progbar\n from .. import callbacks as cbks\n@@ -496,9 +496,9 @@ class Model(Container):\n             optimizer: str (name of optimizer) or optimizer object.\n                 See [optimizers](/optimizers).\n             loss: str (name of objective function) or objective function.\n-                See [objectives](/objectives).\n+                See [losses](/losses).\n                 If the model has multiple outputs, you can use a different loss\n-                on each output by passing a dictionary or a list of objectives.\n+                on each output by passing a dictionary or a list of losses.\n             metrics: list of metrics to be evaluated by the model\n                 during training and testing.\n                 Typically you will use `metrics=['accuracy']`.\n@@ -558,7 +558,7 @@ class Model(Container):\n                 if name not in loss:\n                     raise ValueError('Output \"' + name +\n                                      '\" missing from loss dictionary.')\n-                loss_functions.append(objectives.get(loss[name]))\n+                loss_functions.append(losses.get(loss[name]))\n         elif isinstance(loss, list):\n             if len(loss) != len(self.outputs):\n                 raise ValueError('When passing a list as loss, '\n@@ -566,9 +566,9 @@ class Model(Container):\n                                  'The model has ' + str(len(self.outputs)) +\n                                  ' outputs, but you passed loss=' +\n                                  str(loss))\n-            loss_functions = [objectives.get(l) for l in loss]\n+            loss_functions = [losses.get(l) for l in loss]\n         else:\n-            loss_function = objectives.get(loss)\n+            loss_function = losses.get(loss)\n             loss_functions = [loss_function for _ in range(len(self.outputs))]\n         self.loss_functions = loss_functions\n         weighted_losses = [weighted_objective(fn) for fn in loss_functions]\n@@ -701,10 +701,10 @@ class Model(Container):\n                     # (because of class mode duality)\n                     output_shape = self.internal_output_shapes[i]\n                     acc_fn = None\n-                    if output_shape[-1] == 1 or self.loss_functions[i] == objectives.binary_crossentropy:\n+                    if output_shape[-1] == 1 or self.loss_functions[i] == losses.binary_crossentropy:\n                         # case: binary accuracy\n                         acc_fn = metrics_module.binary_accuracy\n-                    elif self.loss_functions[i] == objectives.sparse_categorical_crossentropy:\n+                    elif self.loss_functions[i] == losses.sparse_categorical_crossentropy:\n                         # case: categorical accuracy with sparse targets\n                         acc_fn = metrics_module.sparse_categorical_accuracy\n                     else:\n@@ -1019,7 +1019,7 @@ class Model(Container):\n         for output_shape, loss_fn in zip(self.internal_output_shapes, self.loss_functions):\n             if loss_fn.__name__ == 'sparse_categorical_crossentropy':\n                 output_shapes.append(output_shape[:-1] + (1,))\n-            elif getattr(objectives, loss_fn.__name__, None) is None:\n+            elif getattr(losses, loss_fn.__name__, None) is None:\n                 output_shapes.append(None)\n             else:\n                 output_shapes.append(output_shape)\n\n@@ -1,7 +1,9 @@\n from __future__ import absolute_import\n import numpy as np\n+import six\n from . import backend as K\n-from .utils.generic_utils import get_from_module\n+from .utils.generic_utils import serialize_keras_object\n+from .utils.generic_utils import deserialize_keras_object\n \n \n class Initializer(object):\n@@ -11,6 +13,13 @@ class Initializer(object):\n     def __call__(self, shape, dtype=None):\n         raise NotImplementedError\n \n+    def get_config(self):\n+        return {}\n+\n+    @classmethod\n+    def from_config(cls, config):\n+        return cls(**config)\n+\n \n class Zeros(Initializer):\n     \"\"\"Initializer that generates tensors initialized to 0.\"\"\"\n@@ -39,6 +48,9 @@ class Constant(Initializer):\n     def __call__(self, shape, dtype=None):\n         return K.constant(self.value, shape=shape, dtype=dtype)\n \n+    def get_config(self):\n+        return {'value': self.value}\n+\n \n class RandomNormal(Initializer):\n     \"\"\"Initializer that generates tensors with a normal distribution.\n@@ -60,6 +72,13 @@ class RandomNormal(Initializer):\n         return K.random_normal(shape, self.mean, self.stddev,\n                                dtype=dtype, seed=self.seed)\n \n+    def get_config(self):\n+        return {\n+            'mean': self.mean,\n+            'stddev': self.stddev,\n+            'seed': self.seed\n+        }\n+\n \n class RandomUniform(Initializer):\n     \"\"\"Initializer that generates tensors with a uniform distribution.\n@@ -81,6 +100,13 @@ class RandomUniform(Initializer):\n         return K.random_uniform(shape, self.minval, self.maxval,\n                                 dtype=dtype, seed=self.seed)\n \n+    def get_config(self):\n+        return {\n+            'minval': self.minval,\n+            'maxval': self.maxval,\n+            'seed': self.seed,\n+        }\n+\n \n class TruncatedNormal(Initializer):\n     \"\"\"Initializer that generates a truncated normal distribution.\n@@ -107,6 +133,13 @@ class TruncatedNormal(Initializer):\n         return K.truncated_normal(shape, self.mean, self.stddev,\n                                   dtype=dtype, seed=self.seed)\n \n+    def get_config(self):\n+        return {\n+            'mean': self.mean,\n+            'stddev': self.stddev,\n+            'seed': self.seed\n+        }\n+\n \n class VarianceScaling(Initializer):\n     \"\"\"Initializer capable of adapting its scale to the shape of weights.\n@@ -180,6 +213,15 @@ class VarianceScaling(Initializer):\n             return K.random_uniform(shape, -limit, limit,\n                                     dtype=dtype, seed=self.seed)\n \n+    def get_config(self):\n+        return {\n+            'scale': self.scale,\n+            'mode': self.mode,\n+            'distribution': self.distribution,\n+            'seed': self.seed,\n+            'data_format': self.data_format\n+        }\n+\n \n class Orthogonal(Initializer):\n     \"\"\"Initializer that generates a random orthogonal matrix.\n@@ -207,6 +249,12 @@ class Orthogonal(Initializer):\n         q = q.reshape(shape)\n         return self.gain * q[:shape[0], :shape[1]]\n \n+    def get_config(self):\n+        return {\n+            'gain': self.gain,\n+            'seed': self.seed\n+        }\n+\n \n class Identity(Initializer):\n     \"\"\"Initializer that generates the identity matrix.\n@@ -227,6 +275,11 @@ class Identity(Initializer):\n         else:\n             return self.gain * np.identity(shape[0])\n \n+    def get_config(self):\n+        return {\n+            'gain': self.gain\n+        }\n+\n \n def lecun_uniform(seed=None, data_format=None):\n     \"\"\"LeCun uniform initializer.\n@@ -384,6 +437,25 @@ def _compute_fans(shape, data_format='channels_first'):\n     return fan_in, fan_out\n \n \n-def get(identifier, **kwargs):\n-    return get_from_module(identifier, globals(),\n-                           'initializer', instantiate=True, kwargs=kwargs)\n+def serialize(initializer):\n+    return serialize_keras_object(initializer)\n+\n+\n+def deserialize(config, custom_objects=None):\n+    return deserialize_keras_object(config,\n+                                    module_objects=globals(),\n+                                    custom_objects=None,\n+                                    printable_module_name='initializer')\n+\n+\n+def get(identifier):\n+    if isinstance(identifier, dict):\n+        return deserialize(identifier)\n+    elif isinstance(identifier, six.string_types):\n+        config = {'class_name': str(identifier), 'config': {}}\n+        return deserialize(config)\n+    elif callable(identifier):\n+        return identifier\n+    else:\n+        raise ValueError('Could not interpret initializer identifier:',\n+                         identifier)\n\n@@ -1,5 +1,6 @@\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n+import copy\n \n from .. import backend as K\n from .. import activations\n@@ -8,8 +9,7 @@ from .. import regularizers\n from .. import constraints\n from ..engine import Layer\n from ..engine import InputSpec\n-from ..utils.np_utils import conv_output_length\n-from ..utils.np_utils import conv_input_length\n+from ..utils import conv_utils\n \n # imports for backwards namespace compatibility\n from .pooling import AveragePooling1D\n@@ -20,1098 +20,506 @@ from .pooling import MaxPooling2D\n from .pooling import MaxPooling3D\n \n \n-class Convolution1D(Layer):\n-    \"\"\"Convolution operator for filtering neighborhoods of 1-D inputs.\n+class _Conv(Layer):\n+    \"\"\"Abstract nD convolution layer (private, used as implementation base).\n \n-    When using this layer as the first layer in a model,\n-    either provide the keyword argument `input_dim`\n-    (int, e.g. 128 for sequences of 128-dimensional vectors),\n-    or `input_shape` (tuple of integers, e.g. (10, 128) for sequences\n-    of 10 vectors of 128-dimensional vectors).\n-\n-    # Example\n-\n-    ```python\n-        # apply a convolution 1d of length 3 to a sequence with 10 timesteps,\n-        # with 64 output filters\n-        model = Sequential()\n-        model.add(Convolution1D(64, 3, border_mode='same', input_shape=(10, 32)))\n-        # now model.output_shape == (None, 10, 64)\n-\n-        # add a new conv1d on top\n-        model.add(Convolution1D(32, 3, border_mode='same'))\n-        # now model.output_shape == (None, 10, 32)\n-    ```\n+    This layer creates a convolution kernel that is convolved\n+    with the layer input to produce a tensor of outputs.\n+    If `use_bias` is True, a bias vector is created and added to the outputs.\n+    Finally, if `activation` is not `None`,\n+    it is applied to the outputs as well.\n \n     # Arguments\n-        nb_filter: Number of convolution kernels to use\n-            (dimensionality of the output).\n-        filter_length: The extension (spatial or temporal) of each filter.\n-        init: name of initializer function for the weights of the layer\n-            (see [initializers](../initializers.md)), or alternatively,\n-            Theano function to use for weights initializer.\n-            This parameter is only relevant\n-            if you don't pass a `weights` argument.\n-        activation: name of activation function to use\n-            (see [activations](../activations.md)),\n-            or alternatively, elementwise Theano function.\n+        rank: An integer, the rank of the convolution,\n+            e.g. \"2\" for 2D convolution.\n+        filters: Integer, the dimensionality of the output space\n+            (i.e. the number output of filters in the convolution).\n+        kernel_size: An integer or tuple/list of n integers, specifying the\n+            dimensions of the convolution window.\n+        strides: An integer or tuple/list of n integers,\n+            specifying the strides of the convolution.\n+            Specifying any stride value != 1 is incompatible with specifying\n+            any `dilation_rate` value != 1.\n+        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n+        data_format: A string,\n+            one of `channels_last` (default) or `channels_first`.\n+            The ordering of the dimensions in the inputs.\n+            `channels_last` corresponds to inputs with shape\n+            `(batch, ..., channels)` while `channels_first` corresponds to\n+            inputs with shape `(batch, channels, ...)`.\n+            It defaults to the `image_data_format` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"channels_last\".\n+        dilation_rate: An integer or tuple/list of n integers, specifying\n+            the dilation rate to use for dilated convolution.\n+            Currently, specifying any `dilation_rate` value != 1 is\n+            incompatible with specifying any `strides` value != 1.\n+        activation: Activation function to use\n+            (see [activations](../activations.md)).\n             If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: a(x) = x).\n-        weights: list of numpy arrays to set as initial weights.\n-        border_mode: 'valid', 'same' or 'full'\n-            ('full' requires the Theano backend).\n-        subsample_length: factor by which to subsample output.\n-        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n-            (eg. L1 or L2 regularization), applied to the main weights matrix.\n-        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n-            applied to the bias.\n-        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n-            applied to the network output.\n-        W_constraint: instance of the [constraints](../constraints.md) module\n-            (eg. maxnorm, nonneg), applied to the main weights matrix.\n-        b_constraint: instance of the [constraints](../constraints.md) module,\n-            applied to the bias.\n-        bias: whether to include a bias\n-            (i.e. make the layer affine rather than linear).\n-        input_dim: Number of channels/dimensions in the input.\n-            Either this argument or the keyword argument `input_shape`must be\n-            provided when using this layer as the first layer in a model.\n-        input_length: Length of input sequences, when it is constant.\n-            This argument is required if you are going to connect\n-            `Flatten` then `Dense` layers upstream\n-            (without it, the shape of the dense outputs cannot be computed).\n-\n-    # Input shape\n-        3D tensor with shape: `(samples, steps, input_dim)`.\n-\n-    # Output shape\n-        3D tensor with shape: `(samples, new_steps, nb_filter)`.\n-        `steps` value might have changed due to padding.\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        use_bias: Boolean, whether the layer uses a bias vector.\n+        kernel_initializer: Initializer for the `kernel` weights matrix\n+            (see [initializers](../initializers.md)).\n+        bias_initializer: Initializer for the bias vector\n+            (see [initializers](../initializers.md)).\n+        kernel_regularizer: Regularizer function applied to\n+            the `kernel` weights matrix\n+            (see [regularizer](../regularizers.md)).\n+        bias_regularizer: Regularizer function applied to the bias vector\n+            (see [regularizer](../regularizers.md)).\n+        activity_regularizer: Regularizer function applied to\n+            the output of the layer (its \"activation\").\n+            (see [regularizer](../regularizers.md)).\n+        kernel_constraint: Constraint function applied to the kernel matrix\n+            (see [constraints](../constraints.md)).\n+        bias_constraint: Constraint function applied to the bias vector\n+            (see [constraints](../constraints.md)).\n     \"\"\"\n \n-    def __init__(self, nb_filter, filter_length,\n-                 init='glorot_uniform', activation=None, weights=None,\n-                 border_mode='valid', subsample_length=1,\n-                 W_regularizer=None, b_regularizer=None,\n+    def __init__(self, rank,\n+                 filters,\n+                 kernel_size,\n+                 strides=1,\n+                 padding='valid',\n+                 data_format=None,\n+                 dilation_rate=1,\n+                 activation=None,\n+                 use_bias=True,\n+                 kernel_initializer='glorot_uniform',\n+                 bias_initializer='zeros',\n+                 kernel_regularizer=None,\n+                 bias_regularizer=None,\n                  activity_regularizer=None,\n-                 W_constraint=None, b_constraint=None,\n-                 bias=True, input_dim=None, input_length=None, **kwargs):\n-\n-        if border_mode not in {'valid', 'same', 'full'}:\n-            raise ValueError('Invalid border mode for Convolution1D:', border_mode)\n-        self.nb_filter = nb_filter\n-        self.filter_length = filter_length\n-        self.init = initializers.get(init, data_format='channels_last')\n+                 kernel_constraint=None,\n+                 bias_constraint=None,\n+                 **kwargs):\n+        super(_Conv, self).__init__(**kwargs)\n+        self.rank = rank\n+        self.filters = filters\n+        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n+        self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n+        self.padding = conv_utils.normalize_padding(padding)\n+        self.data_format = conv_utils.normalize_data_format(data_format)\n+        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, rank, 'dilation_rate')\n         self.activation = activations.get(activation)\n-        self.border_mode = border_mode\n-        self.subsample_length = subsample_length\n-\n-        self.subsample = (subsample_length, 1)\n-\n-        self.W_regularizer = regularizers.get(W_regularizer)\n-        self.b_regularizer = regularizers.get(b_regularizer)\n+        self.use_bias = use_bias\n+        self.kernel_initializer = initializers.get(kernel_initializer)\n+        self.bias_initializer = initializers.get(bias_initializer)\n+        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n+        self.bias_regularizer = regularizers.get(bias_regularizer)\n         self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-        self.W_constraint = constraints.get(W_constraint)\n-        self.b_constraint = constraints.get(b_constraint)\n-\n-        self.bias = bias\n-        self.input_spec = [InputSpec(ndim=3)]\n-        self.initial_weights = weights\n-        self.input_dim = input_dim\n-        self.input_length = input_length\n-        if self.input_dim:\n-            kwargs['input_shape'] = (self.input_length, self.input_dim)\n-        super(Convolution1D, self).__init__(**kwargs)\n-\n-    def build(self, input_shape):\n-        input_dim = input_shape[2]\n-        self.W_shape = (self.filter_length, 1, input_dim, self.nb_filter)\n-\n-        self.W = self.add_weight(self.W_shape,\n-                                 initializer=self.init,\n-                                 name='{}_W'.format(self.name),\n-                                 regularizer=self.W_regularizer,\n-                                 constraint=self.W_constraint)\n-        if self.bias:\n-            self.b = self.add_weight((self.nb_filter,),\n-                                     initializer='zero',\n-                                     name='{}_b'.format(self.name),\n-                                     regularizer=self.b_regularizer,\n-                                     constraint=self.b_constraint)\n-        else:\n-            self.b = None\n-\n-        if self.initial_weights is not None:\n-            self.set_weights(self.initial_weights)\n-            del self.initial_weights\n-        self.built = True\n-\n-    def get_output_shape_for(self, input_shape):\n-        length = conv_output_length(input_shape[1],\n-                                    self.filter_length,\n-                                    self.border_mode,\n-                                    self.subsample[0])\n-        return (input_shape[0], length, self.nb_filter)\n-\n-    def call(self, x, mask=None):\n-        x = K.expand_dims(x, 2)  # add a dummy dimension\n-        output = K.conv2d(x, self.W, strides=self.subsample,\n-                          border_mode=self.border_mode,\n-                          data_format='channels_last')\n-        output = K.squeeze(output, 2)  # remove the dummy dimension\n-        if self.bias:\n-            output += K.reshape(self.b, (1, 1, self.nb_filter))\n-        output = self.activation(output)\n-        return output\n-\n-    def get_config(self):\n-        config = {'nb_filter': self.nb_filter,\n-                  'filter_length': self.filter_length,\n-                  'init': self.init.__name__,\n-                  'activation': self.activation.__name__,\n-                  'border_mode': self.border_mode,\n-                  'subsample_length': self.subsample_length,\n-                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n-                  'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n-                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n-                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n-                  'b_constraint': self.b_constraint.get_config() if self.b_constraint else None,\n-                  'bias': self.bias,\n-                  'input_dim': self.input_dim,\n-                  'input_length': self.input_length}\n-        base_config = super(Convolution1D, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class AtrousConvolution1D(Convolution1D):\n-    \"\"\"Atrous Convolution operator for filtering neighborhoods of 1-D inputs.\n-\n-    A.k.a dilated convolution or convolution with holes.\n-    When using this layer as the first layer in a model,\n-    either provide the keyword argument `input_dim`\n-    (int, e.g. 128 for sequences of 128-dimensional vectors),\n-    or `input_shape` (tuples of integers, e.g. (10, 128) for sequences\n-    of 10 vectors of 128-dimensional vectors).\n-\n-    # Example\n-\n-    ```python\n-        # apply an atrous convolution 1d\n-        # with atrous rate 2 of length 3 to a sequence with 10 timesteps,\n-        # with 64 output filters\n-        model = Sequential()\n-        model.add(AtrousConvolution1D(64, 3, atrous_rate=2,\n-                                      border_mode='same',\n-                                      input_shape=(10, 32)))\n-        # now model.output_shape == (None, 10, 64)\n-\n-        # add a new atrous conv1d on top\n-        model.add(AtrousConvolution1D(32, 3, atrous_rate=2,\n-                                      border_mode='same'))\n-        # now model.output_shape == (None, 10, 32)\n-    ```\n-\n-    # Arguments\n-        nb_filter: Number of convolution kernels to use\n-            (dimensionality of the output).\n-        filter_length: The extension (spatial or temporal) of each filter.\n-        init: name of initializer function for the weights of the layer\n-            (see [initializers](../initializers.md)), or alternatively,\n-            Theano function to use for weights initializer.\n-            This parameter is only relevant\n-            if you don't pass a `weights` argument.\n-        activation: name of activation function to use\n-            (see [activations](../activations.md)),\n-            or alternatively, elementwise Theano function.\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: a(x) = x).\n-        weights: list of numpy arrays to set as initial weights.\n-        border_mode: 'valid', 'same' or 'full'\n-            ('full' requires the Theano backend).\n-        subsample_length: factor by which to subsample output.\n-        atrous_rate: Factor for kernel dilation. Also called filter_dilation\n-            elsewhere.\n-        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n-            (eg. L1 or L2 regularization), applied to the main weights matrix.\n-        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n-            applied to the bias.\n-        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n-            applied to the network output.\n-        W_constraint: instance of the [constraints](../constraints.md) module\n-            (eg. maxnorm, nonneg), applied to the main weights matrix.\n-        b_constraint: instance of the [constraints](../constraints.md) module,\n-            applied to the bias.\n-        bias: whether to include a bias\n-            (i.e. make the layer affine rather than linear).\n-        input_dim: Number of channels/dimensions in the input.\n-            Either this argument or the keyword argument `input_shape`must be\n-            provided when using this layer as the first layer in a model.\n-        input_length: Length of input sequences, when it is constant.\n-            This argument is required if you are going to connect\n-            `Flatten` then `Dense` layers upstream\n-            (without it, the shape of the dense outputs cannot be computed).\n-\n-    # Input shape\n-        3D tensor with shape: `(samples, steps, input_dim)`.\n-\n-    # Output shape\n-        3D tensor with shape: `(samples, new_steps, nb_filter)`.\n-        `steps` value might have changed due to padding.\n-    \"\"\"\n-\n-    def __init__(self, nb_filter, filter_length,\n-                 init='glorot_uniform', activation=None, weights=None,\n-                 border_mode='valid', subsample_length=1, atrous_rate=1,\n-                 W_regularizer=None, b_regularizer=None,\n-                 activity_regularizer=None,\n-                 W_constraint=None, b_constraint=None,\n-                 bias=True, **kwargs):\n-\n-        if border_mode not in {'valid', 'same', 'full'}:\n-            raise ValueError('Invalid border mode for AtrousConv1D:', border_mode)\n-\n-        self.atrous_rate = int(atrous_rate)\n-\n-        super(AtrousConvolution1D, self).__init__(\n-            nb_filter, filter_length,\n-            init=init, activation=activation,\n-            weights=weights, border_mode=border_mode,\n-            subsample_length=subsample_length,\n-            W_regularizer=W_regularizer, b_regularizer=b_regularizer,\n-            activity_regularizer=activity_regularizer,\n-            W_constraint=W_constraint, b_constraint=b_constraint,\n-            bias=bias, **kwargs)\n-\n-    def get_output_shape_for(self, input_shape):\n-        length = conv_output_length(input_shape[1],\n-                                    self.filter_length,\n-                                    self.border_mode,\n-                                    self.subsample[0],\n-                                    dilation=self.atrous_rate)\n-        return (input_shape[0], length, self.nb_filter)\n-\n-    def call(self, x, mask=None):\n-        x = K.expand_dims(x, 2)  # add a dummy dimension\n-        output = K.conv2d(x, self.W, strides=self.subsample,\n-                          border_mode=self.border_mode,\n-                          data_format='channels_last',\n-                          filter_dilation=(self.atrous_rate, self.atrous_rate))\n-        output = K.squeeze(output, 2)  # remove the dummy dimension\n-        if self.bias:\n-            output += K.reshape(self.b, (1, 1, self.nb_filter))\n-        output = self.activation(output)\n-        return output\n-\n-    def get_config(self):\n-        config = {'atrous_rate': self.atrous_rate}\n-        base_config = super(AtrousConvolution1D, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class Convolution2D(Layer):\n-    \"\"\"Convolution operator for filtering windows of two-dimensional inputs.\n-\n-    When using this layer as the first layer in a model,\n-    provide the keyword argument `input_shape`\n-    (tuple of integers, does not include the sample axis),\n-    e.g. `input_shape=(3, 128, 128)` for 128x128 RGB pictures.\n-\n-    # Examples\n-\n-    ```python\n-        # apply a 3x3 convolution with 64 output filters on a 256x256 image:\n-        model = Sequential()\n-        model.add(Convolution2D(64, 3, 3,\n-                                border_mode='same',\n-                                input_shape=(3, 256, 256)))\n-        # now model.output_shape == (None, 64, 256, 256)\n-\n-        # add a 3x3 convolution on top, with 32 output filters:\n-        model.add(Convolution2D(32, 3, 3, border_mode='same'))\n-        # now model.output_shape == (None, 32, 256, 256)\n-    ```\n-\n-    # Arguments\n-        nb_filter: Number of convolution filters to use.\n-        nb_row: Number of rows in the convolution kernel.\n-        nb_col: Number of columns in the convolution kernel.\n-        init: name of initializer function for the weights of the layer\n-            (see [initializers](../initializers.md)), or alternatively,\n-            Theano function to use for weights initializer.\n-            This parameter is only relevant if you don't pass\n-            a `weights` argument.\n-        activation: name of activation function to use\n-            (see [activations](../activations.md)),\n-            or alternatively, elementwise Theano function.\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: a(x) = x).\n-        weights: list of numpy arrays to set as initial weights.\n-        border_mode: 'valid', 'same' or 'full'\n-            ('full' requires the Theano backend).\n-        subsample: tuple of length 2. Factor by which to subsample output.\n-            Also called strides elsewhere.\n-        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n-            (eg. L1 or L2 regularization), applied to the main weights matrix.\n-        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n-            applied to the bias.\n-        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n-            applied to the network output.\n-        W_constraint: instance of the [constraints](../constraints.md) module\n-            (eg. maxnorm, nonneg), applied to the main weights matrix.\n-        b_constraint: instance of the [constraints](../constraints.md) module,\n-            applied to the bias.\n-        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n-            (the depth) is at index 1, in 'channels_last' mode is it at index 3.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-        bias: whether to include a bias\n-            (i.e. make the layer affine rather than linear).\n-\n-    # Input shape\n-        4D tensor with shape:\n-        `(samples, channels, rows, cols)` if data_format='channels_first'\n-        or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if data_format='channels_last'.\n-\n-    # Output shape\n-        4D tensor with shape:\n-        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'\n-        or 4D tensor with shape:\n-        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.\n-        `rows` and `cols` values might have changed due to padding.\n-    \"\"\"\n-\n-    def __init__(self, nb_filter, nb_row, nb_col,\n-                 init='glorot_uniform', activation=None, weights=None,\n-                 border_mode='valid', subsample=(1, 1), data_format='default',\n-                 W_regularizer=None, b_regularizer=None,\n-                 activity_regularizer=None,\n-                 W_constraint=None, b_constraint=None,\n-                 bias=True, **kwargs):\n-        if data_format == 'default':\n-            data_format = K.image_data_format()\n-        if border_mode not in {'valid', 'same', 'full'}:\n-            raise ValueError('Invalid border mode for Convolution2D:', border_mode)\n-        self.nb_filter = nb_filter\n-        self.nb_row = nb_row\n-        self.nb_col = nb_col\n-        self.init = initializers.get(init, data_format=data_format)\n-        self.activation = activations.get(activation)\n-        self.border_mode = border_mode\n-        self.subsample = tuple(subsample)\n-        if data_format not in {'channels_last', 'channels_first'}:\n-            raise ValueError('data_format must be in {\"channels_last\", \"channels_first\"}.')\n-        self.data_format = data_format\n-\n-        self.W_regularizer = regularizers.get(W_regularizer)\n-        self.b_regularizer = regularizers.get(b_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-        self.W_constraint = constraints.get(W_constraint)\n-        self.b_constraint = constraints.get(b_constraint)\n-\n-        self.bias = bias\n-        self.input_spec = [InputSpec(ndim=4)]\n-        self.initial_weights = weights\n-        super(Convolution2D, self).__init__(**kwargs)\n+        self.kernel_constraint = constraints.get(kernel_constraint)\n+        self.bias_constraint = constraints.get(bias_constraint)\n \n     def build(self, input_shape):\n+        if len(input_shape) != self.rank + 2:\n+            raise ValueError('Inputs should have rank ' +\n+                             str(self.rank + 2) +\n+                             'Received input shape:', str(input_shape))\n         if self.data_format == 'channels_first':\n-            stack_size = input_shape[1]\n-            self.W_shape = (self.nb_filter, stack_size, self.nb_row, self.nb_col)\n-        elif self.data_format == 'channels_last':\n-            stack_size = input_shape[3]\n-            self.W_shape = (self.nb_row, self.nb_col, stack_size, self.nb_filter)\n+            channel_axis = 1\n         else:\n-            raise ValueError('Invalid data_format:', self.data_format)\n-        self.W = self.add_weight(self.W_shape,\n-                                 initializer=self.init,\n-                                 name='{}_W'.format(self.name),\n-                                 regularizer=self.W_regularizer,\n-                                 constraint=self.W_constraint)\n-        if self.bias:\n-            self.b = self.add_weight((self.nb_filter,),\n-                                     initializer='zero',\n-                                     name='{}_b'.format(self.name),\n-                                     regularizer=self.b_regularizer,\n-                                     constraint=self.b_constraint)\n+            channel_axis = -1\n+        if input_shape[channel_axis] is None:\n+            raise ValueError('The channel dimension of the inputs '\n+                             'should be defined. Found `None`.')\n+            # TODO: set InputSpec\n+        input_dim = input_shape[channel_axis]\n+        kernel_shape = self.kernel_size + (input_dim, self.filters)\n+\n+        self.kernel = self.add_weight(kernel_shape,\n+                                      initializer=self.kernel_initializer,\n+                                      name='kernel',\n+                                      regularizer=self.kernel_regularizer,\n+                                      constraint=self.kernel_constraint)\n+        if self.use_bias:\n+            self.bias = self.add_weight((self.filters,),\n+                                        initializer=self.bias_initializer,\n+                                        name='bias',\n+                                        regularizer=self.bias_regularizer,\n+                                        constraint=self.bias_constraint)\n         else:\n-            self.b = None\n+            self.bias = None\n \n-        if self.initial_weights is not None:\n-            self.set_weights(self.initial_weights)\n-            del self.initial_weights\n-        self.built = True\n-\n-    def get_output_shape_for(self, input_shape):\n-        if self.data_format == 'channels_first':\n-            rows = input_shape[2]\n-            cols = input_shape[3]\n-        elif self.data_format == 'channels_last':\n-            rows = input_shape[1]\n-            cols = input_shape[2]\n-        else:\n-            raise ValueError('Invalid data_format:', self.data_format)\n-\n-        rows = conv_output_length(rows, self.nb_row,\n-                                  self.border_mode, self.subsample[0])\n-        cols = conv_output_length(cols, self.nb_col,\n-                                  self.border_mode, self.subsample[1])\n-\n-        if self.data_format == 'channels_first':\n-            return (input_shape[0], self.nb_filter, rows, cols)\n-        elif self.data_format == 'channels_last':\n-            return (input_shape[0], rows, cols, self.nb_filter)\n-\n-    def call(self, x, mask=None):\n-        output = K.conv2d(x, self.W, strides=self.subsample,\n-                          border_mode=self.border_mode,\n+    def call(self, x):\n+        if self.rank == 1:\n+            outputs = K.conv1d(\n+                x,\n+                self.kernel,\n+                stride=self.strides[0],\n+                padding=self.padding,\n                 data_format=self.data_format,\n-                          filter_shape=self.W_shape)\n-        if self.bias:\n-            if self.data_format == 'channels_first':\n-                output += K.reshape(self.b, (1, self.nb_filter, 1, 1))\n-            elif self.data_format == 'channels_last':\n-                output += K.reshape(self.b, (1, 1, 1, self.nb_filter))\n-            else:\n-                raise ValueError('Invalid data_format:', self.data_format)\n-        output = self.activation(output)\n-        return output\n-\n-    def get_config(self):\n-        config = {'nb_filter': self.nb_filter,\n-                  'nb_row': self.nb_row,\n-                  'nb_col': self.nb_col,\n-                  'init': self.init.__name__,\n-                  'activation': self.activation.__name__,\n-                  'border_mode': self.border_mode,\n-                  'subsample': self.subsample,\n-                  'data_format': self.data_format,\n-                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n-                  'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n-                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n-                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n-                  'b_constraint': self.b_constraint.get_config() if self.b_constraint else None,\n-                  'bias': self.bias}\n-        base_config = super(Convolution2D, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class Deconvolution2D(Convolution2D):\n-    \"\"\"Transposed convolution operator for filtering windows of 2-D inputs.\n-\n-    The need for transposed convolutions generally arises from the desire to\n-    use a transformation going in the opposite direction\n-    of a normal convolution, i.e., from something that has the shape\n-    of the output of some convolution to something that has the shape\n-    of its input while maintaining a connectivity pattern\n-    that is compatible with said convolution.\n-\n-    When using this layer as the first layer in a model,\n-    provide the keyword argument `input_shape`\n-    (tuple of integers, does not include the sample axis),\n-    e.g. `input_shape=(3, 128, 128)` for 128x128 RGB pictures.\n-\n-    To pass the correct `output_shape` to this layer,\n-    one could use a test model to predict and observe the actual output shape.\n-\n-    # Examples\n-\n-    ```python\n-        # apply a 3x3 transposed convolution\n-        # with stride 1x1 and 3 output filters on a 12x12 image:\n-        model = Sequential()\n-        model.add(Deconvolution2D(3, 3, 3, output_shape=(None, 3, 14, 14),\n-                                  border_mode='valid',\n-                                  input_shape=(3, 12, 12)))\n-        # Note that you will have to change\n-        # the output_shape depending on the backend used.\n-\n-        # we can predict with the model and print the shape of the array.\n-        dummy_input = np.ones((32, 3, 12, 12))\n-        # For TensorFlow dummy_input = np.ones((32, 12, 12, 3))\n-        preds = model.predict(dummy_input)\n-        print(preds.shape)\n-        # Theano GPU: (None, 3, 13, 13)\n-        # Theano CPU: (None, 3, 14, 14)\n-        # TensorFlow: (None, 14, 14, 3)\n-\n-        # apply a 3x3 transposed convolution\n-        # with stride 2x2 and 3 output filters on a 12x12 image:\n-        model = Sequential()\n-        model.add(Deconvolution2D(3, 3, 3, output_shape=(None, 3, 25, 25),\n-                                  subsample=(2, 2),\n-                                  border_mode='valid',\n-                                  input_shape=(3, 12, 12)))\n-        model.summary()\n-\n-        # we can predict with the model and print the shape of the array.\n-        dummy_input = np.ones((32, 3, 12, 12))\n-        # For TensorFlow dummy_input = np.ones((32, 12, 12, 3))\n-        preds = model.predict(dummy_input)\n-        print(preds.shape)\n-        # Theano GPU: (None, 3, 25, 25)\n-        # Theano CPU: (None, 3, 25, 25)\n-        # TensorFlow: (None, 25, 25, 3)\n-    ```\n-\n-    # Arguments\n-        nb_filter: Number of transposed convolution filters to use.\n-        nb_row: Number of rows in the transposed convolution kernel.\n-        nb_col: Number of columns in the transposed convolution kernel.\n-        output_shape: Output shape of the transposed convolution operation.\n-            tuple of integers\n-            `(nb_samples, nb_filter, nb_output_rows, nb_output_cols)`.\n-             It is better to use\n-             a dummy input and observe the actual output shape of\n-             a layer, as specified in the examples.\n-        init: name of initializer function for the weights of the layer\n-            (see [initializers](../initializers.md)), or alternatively,\n-            Theano function to use for weights initializer.\n-            This parameter is only relevant if you don't pass\n-            a `weights` argument.\n-        activation: name of activation function to use\n-            (see [activations](../activations.md)),\n-            or alternatively, elementwise Theano/TensorFlow function.\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: a(x) = x).\n-        weights: list of numpy arrays to set as initial weights.\n-        border_mode: 'valid', 'same' or 'full'\n-            ('full' requires the Theano backend).\n-        subsample: tuple of length 2. Factor by which to oversample output.\n-            Also called strides elsewhere.\n-        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n-            (eg. L1 or L2 regularization), applied to the main weights matrix.\n-        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n-            applied to the bias.\n-        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n-            applied to the network output.\n-        W_constraint: instance of the [constraints](../constraints.md) module\n-            (eg. maxnorm, nonneg), applied to the main weights matrix.\n-        b_constraint: instance of the [constraints](../constraints.md) module,\n-            applied to the bias.\n-        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n-            (the depth) is at index 1, in 'channels_last' mode is it at index 3.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-        bias: whether to include a bias\n-            (i.e. make the layer affine rather than linear).\n-\n-    # Input shape\n-        4D tensor with shape:\n-        `(samples, channels, rows, cols)` if data_format='channels_first'\n-        or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if data_format='channels_last'.\n-\n-    # Output shape\n-        4D tensor with shape:\n-        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'\n-        or 4D tensor with shape:\n-        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.\n-        `rows` and `cols` values might have changed due to padding.\n-\n-    # References\n-        - [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285v1)\n-        - [Transposed convolution arithmetic](http://deeplearning.net/software/theano_versions/dev/tutorial/conv_arithmetic.html#transposed-convolution-arithmetic)\n-        - [Deconvolutional Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)\n-    \"\"\"\n-\n-    def __init__(self, nb_filter, nb_row, nb_col, output_shape,\n-                 init='glorot_uniform', activation=None, weights=None,\n-                 border_mode='valid', subsample=(1, 1),\n-                 data_format='default',\n-                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n-                 W_constraint=None, b_constraint=None,\n-                 bias=True, **kwargs):\n-        if data_format == 'default':\n-            data_format = K.image_data_format()\n-        if border_mode not in {'valid', 'same', 'full'}:\n-            raise ValueError('Invalid border mode for Deconvolution2D:', border_mode)\n-\n-        self.output_shape_ = output_shape\n-\n-        super(Deconvolution2D, self).__init__(nb_filter, nb_row, nb_col,\n-                                              init=init,\n-                                              activation=activation,\n-                                              weights=weights,\n-                                              border_mode=border_mode,\n-                                              subsample=subsample,\n-                                              data_format=data_format,\n-                                              W_regularizer=W_regularizer,\n-                                              b_regularizer=b_regularizer,\n-                                              activity_regularizer=activity_regularizer,\n-                                              W_constraint=W_constraint,\n-                                              b_constraint=b_constraint,\n-                                              bias=bias,\n-                                              **kwargs)\n-\n-    def get_output_shape_for(self, input_shape):\n-        if self.data_format == 'channels_first':\n-            rows = self.output_shape_[2]\n-            cols = self.output_shape_[3]\n-        elif self.data_format == 'channels_last':\n-            rows = self.output_shape_[1]\n-            cols = self.output_shape_[2]\n-        else:\n-            raise ValueError('Invalid data_format:', self.data_format)\n-\n-        if self.data_format == 'channels_first':\n-            return (input_shape[0], self.nb_filter, rows, cols)\n-        elif self.data_format == 'channels_last':\n-            return (input_shape[0], rows, cols, self.nb_filter)\n-\n-    def call(self, x, mask=None):\n-        output = K.deconv2d(x, self.W, self.output_shape_,\n-                            strides=self.subsample,\n-                            border_mode=self.border_mode,\n+                dilation_rate=self.dilation_rate[0])\n+        if self.rank == 2:\n+            outputs = K.conv2d(\n+                x,\n+                self.kernel,\n+                strides=self.strides,\n+                padding=self.padding,\n                 data_format=self.data_format,\n-                            filter_shape=self.W_shape)\n-        if self.bias:\n-            if self.data_format == 'channels_first':\n-                output += K.reshape(self.b, (1, self.nb_filter, 1, 1))\n-            elif self.data_format == 'channels_last':\n-                output += K.reshape(self.b, (1, 1, 1, self.nb_filter))\n-            else:\n-                raise ValueError('Invalid data_format:', self.data_format)\n-        output = self.activation(output)\n-        return output\n-\n-    def get_config(self):\n-        config = {'output_shape': self.output_shape_}\n-        base_config = super(Deconvolution2D, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class AtrousConvolution2D(Convolution2D):\n-    \"\"\"Atrous Convolution operator for filtering windows of 2-D inputs.\n-\n-    A.k.a dilated convolution or convolution with holes.\n-    When using this layer as the first layer in a model,\n-    provide the keyword argument `input_shape`\n-    (tuple of integers, does not include the sample axis),\n-    e.g. `input_shape=(3, 128, 128)` for 128x128 RGB pictures.\n-\n-    # Examples\n-\n-    ```python\n-        # apply a 3x3 convolution with atrous rate 2x2\n-        # and 64 output filters on a 256x256 image:\n-        model = Sequential()\n-        model.add(AtrousConvolution2D(64, 3, 3, atrous_rate=(2,2),\n-                                      border_mode='valid',\n-                                      input_shape=(3, 256, 256)))\n-        # now the actual kernel size is dilated\n-        # from 3x3 to 5x5 (3+(3-1)*(2-1)=5)\n-        # thus model.output_shape == (None, 64, 252, 252)\n-    ```\n-\n-    # Arguments\n-        nb_filter: Number of convolution filters to use.\n-        nb_row: Number of rows in the convolution kernel.\n-        nb_col: Number of columns in the convolution kernel.\n-        init: name of initializer function for the weights of the layer\n-            (see [initializers](../initializers.md)), or alternatively,\n-            Theano function to use for weights initializer.\n-            This parameter is only relevant if you don't pass\n-            a `weights` argument.\n-        activation: name of activation function to use\n-            (see [activations](../activations.md)),\n-            or alternatively, elementwise Theano function.\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: a(x) = x).\n-        weights: list of numpy arrays to set as initial weights.\n-        border_mode: 'valid', 'same' or 'full'\n-            ('full' requires the Theano backend).\n-        subsample: tuple of length 2. Factor by which to subsample output.\n-            Also called strides elsewhere.\n-        atrous_rate: tuple of length 2. Factor for kernel dilation.\n-            Also called filter_dilation elsewhere.\n-        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n-            (eg. L1 or L2 regularization), applied to the main weights matrix.\n-        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n-            applied to the bias.\n-        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n-            applied to the network output.\n-        W_constraint: instance of the [constraints](../constraints.md) module\n-            (eg. maxnorm, nonneg), applied to the main weights matrix.\n-        b_constraint: instance of the [constraints](../constraints.md) module,\n-            applied to the bias.\n-        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n-            (the depth) is at index 1, in 'channels_last' mode is it at index 3.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-        bias: whether to include a bias\n-            (i.e. make the layer affine rather than linear).\n-\n-    # Input shape\n-        4D tensor with shape:\n-        `(samples, channels, rows, cols)` if data_format='channels_first'\n-        or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if data_format='channels_last'.\n-\n-    # Output shape\n-        4D tensor with shape:\n-        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'\n-        or 4D tensor with shape:\n-        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.\n-        `rows` and `cols` values might have changed due to padding.\n-\n-    # References\n-        - [Multi-Scale Context Aggregation by Dilated Convolutions](https://arxiv.org/abs/1511.07122)\n-    \"\"\"\n-\n-    def __init__(self, nb_filter, nb_row, nb_col,\n-                 init='glorot_uniform', activation=None, weights=None,\n-                 border_mode='valid', subsample=(1, 1),\n-                 atrous_rate=(1, 1), data_format='default',\n-                 W_regularizer=None, b_regularizer=None,\n-                 activity_regularizer=None,\n-                 W_constraint=None, b_constraint=None,\n-                 bias=True, **kwargs):\n-        if data_format == 'default':\n-            data_format = K.image_data_format()\n-\n-        if border_mode not in {'valid', 'same', 'full'}:\n-            raise ValueError('Invalid border mode for AtrousConv2D:', border_mode)\n-\n-        self.atrous_rate = tuple(atrous_rate)\n-\n-        super(AtrousConvolution2D, self).__init__(nb_filter, nb_row, nb_col,\n-                                                  init=init,\n-                                                  activation=activation,\n-                                                  weights=weights,\n-                                                  border_mode=border_mode,\n-                                                  subsample=subsample,\n-                                                  data_format=data_format,\n-                                                  W_regularizer=W_regularizer,\n-                                                  b_regularizer=b_regularizer,\n-                                                  activity_regularizer=activity_regularizer,\n-                                                  W_constraint=W_constraint,\n-                                                  b_constraint=b_constraint,\n-                                                  bias=bias,\n-                                                  **kwargs)\n-\n-    def get_output_shape_for(self, input_shape):\n-        if self.data_format == 'channels_first':\n-            rows = input_shape[2]\n-            cols = input_shape[3]\n-        elif self.data_format == 'channels_last':\n-            rows = input_shape[1]\n-            cols = input_shape[2]\n-        else:\n-            raise ValueError('Invalid data_format:', self.data_format)\n-\n-        rows = conv_output_length(rows, self.nb_row, self.border_mode,\n-                                  self.subsample[0],\n-                                  dilation=self.atrous_rate[0])\n-        cols = conv_output_length(cols, self.nb_col, self.border_mode,\n-                                  self.subsample[1],\n-                                  dilation=self.atrous_rate[1])\n-\n-        if self.data_format == 'channels_first':\n-            return (input_shape[0], self.nb_filter, rows, cols)\n-        elif self.data_format == 'channels_last':\n-            return (input_shape[0], rows, cols, self.nb_filter)\n-\n-    def call(self, x, mask=None):\n-        output = K.conv2d(x, self.W, strides=self.subsample,\n-                          border_mode=self.border_mode,\n+                dilation_rate=self.dilation_rate)\n+        if self.rank == 3:\n+            outputs = K.conv3d(\n+                x,\n+                self.kernel,\n+                strides=self.strides,\n+                padding=self.padding,\n                 data_format=self.data_format,\n-                          filter_shape=self.W_shape,\n-                          filter_dilation=self.atrous_rate)\n-        if self.bias:\n-            if self.data_format == 'channels_first':\n-                output += K.reshape(self.b, (1, self.nb_filter, 1, 1))\n-            elif self.data_format == 'channels_last':\n-                output += K.reshape(self.b, (1, 1, 1, self.nb_filter))\n-            else:\n-                raise ValueError('Invalid data_format:', self.data_format)\n-        output = self.activation(output)\n-        return output\n+                dilation_rate=self.dilation_rate)\n \n-    def get_config(self):\n-        config = {'atrous_rate': self.atrous_rate}\n-        base_config = super(AtrousConvolution2D, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class SeparableConvolution2D(Layer):\n-    \"\"\"Separable convolution operator for 2D inputs.\n-\n-    Separable convolutions consist in first performing\n-    a depthwise spatial convolution\n-    (which acts on each input channel separately)\n-    followed by a pointwise convolution which mixes together the resulting\n-    output channels. The `depth_multiplier` argument controls how many\n-    output channels are generated per input channel in the depthwise step.\n-\n-    Intuitively, separable convolutions can be understood as\n-    a way to factorize a convolution kernel into two smaller kernels,\n-    or as an extreme version of an Inception block.\n-\n-    When using this layer as the first layer in a model,\n-    provide the keyword argument `input_shape`\n-    (tuple of integers, does not include the sample axis),\n-    e.g. `input_shape=(3, 128, 128)` for 128x128 RGB pictures.\n-\n-    # Theano warning\n-\n-    This layer is only available with the\n-    TensorFlow backend for the time being.\n-\n-    # Arguments\n-        nb_filter: Number of convolution filters to use.\n-        nb_row: Number of rows in the convolution kernel.\n-        nb_col: Number of columns in the convolution kernel.\n-        init: name of initializer function for the weights of the layer\n-            (see [initializers](../initializers.md)), or alternatively,\n-            Theano function to use for weights initializer.\n-            This parameter is only relevant if you don't pass\n-            a `weights` argument.\n-        activation: name of activation function to use\n-            (see [activations](../activations.md)),\n-            or alternatively, elementwise Theano function.\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: a(x) = x).\n-        weights: list of numpy arrays to set as initial weights.\n-        border_mode: 'valid' or 'same'.\n-        subsample: tuple of length 2. Factor by which to subsample output.\n-            Also called strides elsewhere.\n-        depth_multiplier: how many output channel to use per input channel\n-            for the depthwise convolution step.\n-        depthwise_regularizer: instance of [WeightRegularizer](../regularizers.md)\n-            (eg. L1 or L2 regularization), applied to the depthwise weights matrix.\n-        pointwise_regularizer: instance of [WeightRegularizer](../regularizers.md)\n-            (eg. L1 or L2 regularization), applied to the pointwise weights matrix.\n-        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n-            applied to the bias.\n-        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n-            applied to the network output.\n-        depthwise_constraint: instance of the [constraints](../constraints.md) module\n-            (eg. maxnorm, nonneg), applied to the depthwise weights matrix.\n-        pointwise_constraint: instance of the [constraints](../constraints.md) module\n-            (eg. maxnorm, nonneg), applied to the pointwise weights matrix.\n-        b_constraint: instance of the [constraints](../constraints.md) module,\n-            applied to the bias.\n-        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n-            (the depth) is at index 1, in 'channels_last' mode is it at index 3.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-        bias: whether to include a bias\n-            (i.e. make the layer affine rather than linear).\n-\n-    # Input shape\n-        4D tensor with shape:\n-        `(samples, channels, rows, cols)` if data_format='channels_first'\n-        or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if data_format='channels_last'.\n-\n-    # Output shape\n-        4D tensor with shape:\n-        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'\n-        or 4D tensor with shape:\n-        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.\n-        `rows` and `cols` values might have changed due to padding.\n-    \"\"\"\n-\n-    def __init__(self, nb_filter, nb_row, nb_col,\n-                 init='glorot_uniform', activation=None, weights=None,\n-                 border_mode='valid', subsample=(1, 1),\n-                 depth_multiplier=1, data_format='default',\n-                 depthwise_regularizer=None, pointwise_regularizer=None,\n-                 b_regularizer=None, activity_regularizer=None,\n-                 depthwise_constraint=None, pointwise_constraint=None,\n-                 b_constraint=None,\n-                 bias=True, **kwargs):\n-\n-        if K.backend() != 'tensorflow':\n-            raise RuntimeError('SeparableConv2D is only available '\n-                               'with TensorFlow for the time being.')\n-\n-        if data_format == 'default':\n-            data_format = K.image_data_format()\n-\n-        if border_mode not in {'valid', 'same'}:\n-            raise ValueError('Invalid border mode for SeparableConv2D:', border_mode)\n-\n-        if border_mode not in {'valid', 'same'}:\n-            raise ValueError('Invalid border mode for SeparableConv2D:', border_mode)\n-        self.nb_filter = nb_filter\n-        self.nb_row = nb_row\n-        self.nb_col = nb_col\n-        self.init = initializers.get(init, data_format=data_format)\n-        self.activation = activations.get(activation)\n-        if border_mode not in {'valid', 'same'}:\n-            raise ValueError('border_mode must be in {valid, same}.')\n-        self.border_mode = border_mode\n-        self.subsample = tuple(subsample)\n-        self.depth_multiplier = depth_multiplier\n-        if data_format not in {'channels_last', 'channels_first'}:\n-            raise ValueError('data_format must be in {\"channels_last\", \"channels_first\"}.')\n-        self.data_format = data_format\n-\n-        self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\n-        self.pointwise_regularizer = regularizers.get(pointwise_regularizer)\n-        self.b_regularizer = regularizers.get(b_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-        self.depthwise_constraint = constraints.get(depthwise_constraint)\n-        self.pointwise_constraint = constraints.get(pointwise_constraint)\n-        self.b_constraint = constraints.get(b_constraint)\n-\n-        self.bias = bias\n-        self.input_spec = [InputSpec(ndim=4)]\n-        self.initial_weights = weights\n-        super(SeparableConvolution2D, self).__init__(**kwargs)\n-\n-    def build(self, input_shape):\n-        if self.data_format == 'channels_first':\n-            stack_size = input_shape[1]\n-            depthwise_shape = (self.depth_multiplier, stack_size, self.nb_row, self.nb_col)\n-            pointwise_shape = (self.nb_filter, self.depth_multiplier * stack_size, 1, 1)\n-        elif self.data_format == 'channels_last':\n-            stack_size = input_shape[3]\n-            depthwise_shape = (self.nb_row, self.nb_col, stack_size, self.depth_multiplier)\n-            pointwise_shape = (1, 1, self.depth_multiplier * stack_size, self.nb_filter)\n-        else:\n-            raise ValueError('Invalid data_format:', self.data_format)\n-\n-        self.depthwise_kernel = self.add_weight(depthwise_shape,\n-                                                initializer=self.init,\n-                                                regularizer=self.depthwise_regularizer,\n-                                                constraint=self.depthwise_constraint,\n-                                                name='{}_depthwise_kernel'.format(self.name))\n-        self.pointwise_kernel = self.add_weight(pointwise_shape,\n-                                                initializer=self.init,\n-                                                regularizer=self.pointwise_regularizer,\n-                                                constraint=self.pointwise_constraint,\n-                                                name='{}_pointwise_kernel'.format(self.name))\n-        if self.bias:\n-            self.b = self.add_weight((self.nb_filter,),\n-                                     initializer='zero',\n-                                     name='{}_b'.format(self.name),\n-                                     regularizer=self.b_regularizer,\n-                                     constraint=self.b_constraint)\n-        else:\n-            self.b = None\n-\n-        if self.initial_weights is not None:\n-            self.set_weights(self.initial_weights)\n-            del self.initial_weights\n-        self.built = True\n-\n-    def get_output_shape_for(self, input_shape):\n-        if self.data_format == 'channels_first':\n-            rows = input_shape[2]\n-            cols = input_shape[3]\n-        elif self.data_format == 'channels_last':\n-            rows = input_shape[1]\n-            cols = input_shape[2]\n-        else:\n-            raise ValueError('Invalid data_format:', self.data_format)\n-\n-        rows = conv_output_length(rows, self.nb_row,\n-                                  self.border_mode, self.subsample[0])\n-        cols = conv_output_length(cols, self.nb_col,\n-                                  self.border_mode, self.subsample[1])\n-\n-        if self.data_format == 'channels_first':\n-            return (input_shape[0], self.nb_filter, rows, cols)\n-        elif self.data_format == 'channels_last':\n-            return (input_shape[0], rows, cols, self.nb_filter)\n-        else:\n-            raise ValueError('Invalid data_format:', self.data_format)\n-\n-    def call(self, x, mask=None):\n-        output = K.separable_conv2d(x, self.depthwise_kernel,\n-                                    self.pointwise_kernel,\n-                                    strides=self.subsample,\n-                                    border_mode=self.border_mode,\n+        if self.bias is not None:\n+            outputs = K.bias_add(\n+                outputs,\n+                self.bias,\n                 data_format=self.data_format)\n-        if self.bias:\n+\n+        if self.activation is not None:\n+            return self.activation(outputs)\n+        return outputs\n+\n+    def get_output_shape_for(self, input_shape):\n+        if self.data_format == 'channels_last':\n+            space = input_shape[1:-1]\n+            new_space = []\n+            for i in range(len(space)):\n+                new_dim = conv_utils.conv_output_length(\n+                    space[i],\n+                    self.kernel_size[i],\n+                    padding=self.padding,\n+                    stride=self.strides[i],\n+                    dilation=self.dilation_rate[i])\n+                new_space.append(new_dim)\n+            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n         if self.data_format == 'channels_first':\n-                output += K.reshape(self.b, (1, self.nb_filter, 1, 1))\n-            elif self.data_format == 'channels_last':\n-                output += K.reshape(self.b, (1, 1, 1, self.nb_filter))\n-            else:\n-                raise ValueError('Invalid data_format:', self.data_format)\n-        output = self.activation(output)\n-        return output\n+            space = input_shape[2:]\n+            new_space = []\n+            for i in range(len(space)):\n+                new_dim = conv_utils.conv_output_length(\n+                    space[i],\n+                    self.kernel_size[i],\n+                    padding=self.padding,\n+                    stride=self.strides[i],\n+                    dilation=self.dilation_rate[i])\n+                new_space.append(new_dim)\n+            return (input_shape[0], self.filters) + tuple(new_space)\n \n     def get_config(self):\n-        config = {'nb_filter': self.nb_filter,\n-                  'nb_row': self.nb_row,\n-                  'nb_col': self.nb_col,\n-                  'init': self.init.__name__,\n-                  'activation': self.activation.__name__,\n-                  'border_mode': self.border_mode,\n-                  'subsample': self.subsample,\n-                  'depth_multiplier': self.depth_multiplier,\n+        config = {\n+            'rank': self.rank,\n+            'filters': self.filters,\n+            'kernel_size': self.kernel_size,\n+            'strides': self.strides,\n+            'padding': self.padding,\n             'data_format': self.data_format,\n-                  'depthwise_regularizer': self.depthwise_regularizer.get_config() if self.depthwise_regularizer else None,\n-                  'pointwise_regularizer': self.depthwise_regularizer.get_config() if self.depthwise_regularizer else None,\n-                  'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n-                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n-                  'depthwise_constraint': self.depthwise_constraint.get_config() if self.depthwise_constraint else None,\n-                  'pointwise_constraint': self.pointwise_constraint.get_config() if self.pointwise_constraint else None,\n-                  'b_constraint': self.b_constraint.get_config() if self.b_constraint else None,\n-                  'bias': self.bias}\n-        base_config = super(SeparableConvolution2D, self).get_config()\n+            'dilation_rate': self.dilation_rate,\n+            'activation': activations.serialize(self.activation),\n+            'use_bias': self.use_bias,\n+            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n+            'bias_initializer': initializers.serialize(self.kernel_initializer),\n+            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n+            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n+            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n+            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n+            'bias_constraint': constraints.serialize(self.bias_constraint)\n+        }\n+        base_config = super(_Conv, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n \n-class Convolution3D(Layer):\n-    \"\"\"Convolution operator for filtering windows of three-dimensional inputs.\n+class Conv1D(_Conv):\n+    \"\"\"1D convolution layer (e.g. temporal convolution).\n+\n+    This layer creates a convolution kernel that is convolved\n+    with the layer input over a single spatial (or temporal) dimension\n+    to produce a tensor of outputs.\n+    If `use_bias` is True, a bias vector is created and added to the outputs.\n+    Finally, if `activation` is not `None`,\n+    it is applied to the outputs as well.\n+\n+    When using this layer as the first layer in a model,\n+    provide an `input_shape` argument\n+    (tuple of integers or `None`, e.g.\n+    `(10, 128)` for sequences of 10 vectors of 128-dimensional vectors,\n+    or `(None, 128)` for variable-length sequences of 128-dimensional vectors.\n+\n+    # Arguments\n+        filters: Integer, the dimensionality of the output space\n+            (i.e. the number output of filters in the convolution).\n+        kernel_size: An integer or tuple/list of a single integer,\n+            specifying the length of the 1D convolution window.\n+        strides: An integer or tuple/list of a single integer,\n+            specifying the stride length of the convolution.\n+            Specifying any stride value != 1 is incompatible with specifying\n+            any `dilation_rate` value != 1.\n+        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n+        dilation_rate: an integer or tuple/list of a single integer, specifying\n+            the dilation rate to use for dilated convolution.\n+            Currently, specifying any `dilation_rate` value != 1 is\n+            incompatible with specifying any `strides` value != 1.\n+        activation: Activation function to use\n+            (see [activations](../activations.md)).\n+            If you don't specify anything, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        use_bias: Boolean, whether the layer uses a bias vector.\n+        kernel_initializer: Initializer for the `kernel` weights matrix\n+            (see [initializers](../initializers.md)).\n+        bias_initializer: Initializer for the bias vector\n+            (see [initializers](../initializers.md)).\n+        kernel_regularizer: Regularizer function applied to\n+            the `kernel` weights matrix\n+            (see [regularizer](../regularizers.md)).\n+        bias_regularizer: Regularizer function applied to the bias vector\n+            (see [regularizer](../regularizers.md)).\n+        activity_regularizer: Regularizer function applied to\n+            the output of the layer (its \"activation\").\n+            (see [regularizer](../regularizers.md)).\n+        kernel_constraint: Constraint function applied to the kernel matrix\n+            (see [constraints](../constraints.md)).\n+        bias_constraint: Constraint function applied to the bias vector\n+            (see [constraints](../constraints.md)).\n+\n+    # Input shape\n+        3D tensor with shape: `(batch_size, steps, input_dim)`\n+        (if `data_format` is `channels_last`).\n+\n+    # Output shape\n+        3D tensor with shape: `(batch_size, new_steps, nb_filter)`\n+        (if `data_format` is `channels_last`).\n+        `steps` value might have changed due to padding or strides.\n+    \"\"\"\n+\n+    def __init__(self, filters,\n+                 kernel_size,\n+                 strides=1,\n+                 padding='valid',\n+                 dilation_rate=1,\n+                 activation=None,\n+                 use_bias=True,\n+                 kernel_initializer='glorot_uniform',\n+                 bias_initializer='zeros',\n+                 kernel_regularizer=None,\n+                 bias_regularizer=None,\n+                 activity_regularizer=None,\n+                 kernel_constraint=None,\n+                 bias_constraint=None,\n+                 **kwargs):\n+        super(Conv1D, self).__init__(\n+            rank=1,\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format='channels_last',\n+            dilation_rate=dilation_rate,\n+            activation=activation,\n+            use_bias=use_bias,\n+            kernel_initializer=kernel_initializer,\n+            bias_initializer=bias_initializer,\n+            kernel_regularizer=kernel_regularizer,\n+            bias_regularizer=bias_regularizer,\n+            activity_regularizer=activity_regularizer,\n+            kernel_constraint=kernel_constraint,\n+            bias_constraint=bias_constraint,\n+            **kwargs)\n+        self.input_spec = [InputSpec(ndim=3)]\n+\n+    def get_config(self):\n+        config = super(Conv1D, self).get_config()\n+        config.pop('rank')\n+        config.pop('data_format')\n+        return config\n+\n+\n+class Conv2D(_Conv):\n+    \"\"\"2D convolution layer (e.g. spatial convolution over images).\n+\n+    This layer creates a convolution kernel that is convolved\n+    with the layer input to produce a tensor of\n+    outputs. If `use_bias` is True,\n+    a bias vector is created and added to the outputs. Finally, if\n+    `activation` is not `None`, it is applied to the outputs as well.\n \n     When using this layer as the first layer in a model,\n     provide the keyword argument `input_shape`\n     (tuple of integers, does not include the sample axis),\n-    e.g. `input_shape=(3, 10, 128, 128)` for 10 frames of 128x128 RGB pictures.\n+    e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n+    in `data_format=\"channels_last\"`.\n \n     # Arguments\n-        nb_filter: Number of convolution filters to use.\n-        kernel_dim1: Length of the first dimension in the convolution kernel.\n-        kernel_dim2: Length of the second dimension in the convolution kernel.\n-        kernel_dim3: Length of the third dimension in the convolution kernel.\n-        init: name of initializer function for the weights of the layer\n-            (see [initializers](../initializers.md)), or alternatively,\n-            Theano function to use for weights initializer.\n-            This parameter is only relevant if you don't pass\n-            a `weights` argument.\n-        activation: name of activation function to use\n-            (see [activations](../activations.md)),\n-            or alternatively, elementwise Theano function.\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: a(x) = x).\n-        weights: list of Numpy arrays to set as initial weights.\n-        border_mode: 'valid', 'same' or 'full'\n-            ('full' requires the Theano backend).\n-        subsample: tuple of length 3. Factor by which to subsample output.\n-            Also called strides elsewhere.\n-            Note: 'subsample' is implemented by slicing\n-            the output of conv3d with strides=(1,1,1).\n-        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n-            (eg. L1 or L2 regularization), applied to the main weights matrix.\n-        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n-            applied to the bias.\n-        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n-            applied to the network output.\n-        W_constraint: instance of the [constraints](../constraints.md) module\n-            (eg. maxnorm, nonneg), applied to the main weights matrix.\n-        b_constraint: instance of the [constraints](../constraints.md) module,\n-            applied to the bias.\n-        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n-            (the depth) is at index 1, in 'channels_last' mode is it at index 4.\n+        filters: Integer, the dimensionality of the output space\n+            (i.e. the number output of filters in the convolution).\n+        kernel_size: An integer or tuple/list of 2 integers, specifying the\n+            width and height of the 2D convolution window.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+        strides: An integer or tuple/list of 2 integers,\n+            specifying the strides of the convolution along the width and height.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+            Specifying any stride value != 1 is incompatible with specifying\n+            any `dilation_rate` value != 1.\n+        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n+        data_format: A string,\n+            one of `channels_last` (default) or `channels_first`.\n+            The ordering of the dimensions in the inputs.\n+            `channels_last` corresponds to inputs with shape\n+            `(batch, width, height, channels)` while `channels_first`\n+            corresponds to inputs with shape `(batch, channels, width, height)`.\n             It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n             If you never set it, then it will be \"channels_last\".\n-        bias: whether to include a bias\n-            (i.e. make the layer affine rather than linear).\n+        dilation_rate: an integer or tuple/list of 2 integers, specifying\n+            the dilation rate to use for dilated convolution.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+            Currently, specifying any `dilation_rate` value != 1 is\n+            incompatible with specifying any stride value != 1.\n+        activation: Activation function to use\n+            (see [activations](../activations.md)).\n+            If you don't specify anything, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        use_bias: Boolean, whether the layer uses a bias vector.\n+        kernel_initializer: Initializer for the `kernel` weights matrix\n+            (see [initializers](../initializers.md)).\n+        bias_initializer: Initializer for the bias vector\n+            (see [initializers](../initializers.md)).\n+        kernel_regularizer: Regularizer function applied to\n+            the `kernel` weights matrix\n+            (see [regularizer](../regularizers.md)).\n+        bias_regularizer: Regularizer function applied to the bias vector\n+            (see [regularizer](../regularizers.md)).\n+        activity_regularizer: Regularizer function applied to\n+            the output of the layer (its \"activation\").\n+            (see [regularizer](../regularizers.md)).\n+        kernel_constraint: Constraint function applied to the kernel matrix\n+            (see [constraints](../constraints.md)).\n+        bias_constraint: Constraint function applied to the bias vector\n+            (see [constraints](../constraints.md)).\n+\n+    # Input shape\n+        4D tensor with shape:\n+        `(samples, channels, rows, cols)` if data_format='channels_first'\n+        or 4D tensor with shape:\n+        `(samples, rows, cols, channels)` if data_format='channels_last'.\n+\n+    # Output shape\n+        4D tensor with shape:\n+        `(samples, nb_filter, new_rows, new_cols)` if data_format='channels_first'\n+        or 4D tensor with shape:\n+        `(samples, new_rows, new_cols, nb_filter)` if data_format='channels_last'.\n+        `rows` and `cols` values might have changed due to padding.\n+    \"\"\"\n+\n+    def __init__(self, filters,\n+                 kernel_size,\n+                 strides=(1, 1),\n+                 padding='valid',\n+                 data_format=None,\n+                 dilation_rate=(1, 1),\n+                 activation=None,\n+                 use_bias=True,\n+                 kernel_initializer='glorot_uniform',\n+                 bias_initializer='zeros',\n+                 kernel_regularizer=None,\n+                 bias_regularizer=None,\n+                 activity_regularizer=None,\n+                 kernel_constraint=None,\n+                 bias_constraint=None,\n+                 **kwargs):\n+        super(Conv2D, self).__init__(\n+            rank=2,\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+            activation=activation,\n+            use_bias=use_bias,\n+            kernel_initializer=kernel_initializer,\n+            bias_initializer=bias_initializer,\n+            kernel_regularizer=kernel_regularizer,\n+            bias_regularizer=bias_regularizer,\n+            activity_regularizer=activity_regularizer,\n+            kernel_constraint=kernel_constraint,\n+            bias_constraint=bias_constraint,\n+            **kwargs)\n+        self.input_spec = [InputSpec(ndim=4)]\n+\n+    def get_config(self):\n+        config = super(Conv2D, self).get_config()\n+        config.pop('rank')\n+        return config\n+\n+\n+class Conv3D(_Conv):\n+    \"\"\"3D convolution layer (e.g. spatial convolution over volumes).\n+\n+    This layer creates a convolution kernel that is convolved\n+    with the layer input to produce a tensor of\n+    outputs. If `use_bias` is True,\n+    a bias vector is created and added to the outputs. Finally, if\n+    `activation` is not `None`, it is applied to the outputs as well.\n+\n+    When using this layer as the first layer in a model,\n+    provide the keyword argument `input_shape`\n+    (tuple of integers, does not include the sample axis),\n+    e.g. `input_shape=(128, 128, 128, 3)` for 128x128x128 volumes\n+    with a single channel,\n+    in `data_format=\"channels_last\"`.\n+\n+    # Arguments\n+        filters: Integer, the dimensionality of the output space\n+            (i.e. the number output of filters in the convolution).\n+        kernel_size: An integer or tuple/list of 3 integers, specifying the\n+            width and height of the 3D convolution window.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+        strides: An integer or tuple/list of 3 integers,\n+            specifying the strides of the convolution along each spatial dimension.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+            Specifying any stride value != 1 is incompatible with specifying\n+            any `dilation_rate` value != 1.\n+        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n+        data_format: A string,\n+            one of `channels_last` (default) or `channels_first`.\n+            The ordering of the dimensions in the inputs.\n+            `channels_last` corresponds to inputs with shape\n+            `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n+            while `channels_first` corresponds to inputs with shape\n+            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n+            It defaults to the `image_data_format` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"channels_last\".\n+        dilation_rate: an integer or tuple/list of 3 integers, specifying\n+            the dilation rate to use for dilated convolution.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+            Currently, specifying any `dilation_rate` value != 1 is\n+            incompatible with specifying any stride value != 1.\n+        activation: Activation function to use\n+            (see [activations](../activations.md)).\n+            If you don't specify anything, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        use_bias: Boolean, whether the layer uses a bias vector.\n+        kernel_initializer: Initializer for the `kernel` weights matrix\n+            (see [initializers](../initializers.md)).\n+        bias_initializer: Initializer for the bias vector\n+            (see [initializers](../initializers.md)).\n+        kernel_regularizer: Regularizer function applied to\n+            the `kernel` weights matrix\n+            (see [regularizer](../regularizers.md)).\n+        bias_regularizer: Regularizer function applied to the bias vector\n+            (see [regularizer](../regularizers.md)).\n+        activity_regularizer: Regularizer function applied to\n+            the output of the layer (its \"activation\").\n+            (see [regularizer](../regularizers.md)).\n+        kernel_constraint: Constraint function applied to the kernel matrix\n+            (see [constraints](../constraints.md)).\n+        bias_constraint: Constraint function applied to the bias vector\n+            (see [constraints](../constraints.md)).\n \n     # Input shape\n         5D tensor with shape:\n@@ -1127,165 +535,527 @@ class Convolution3D(Layer):\n         `new_conv_dim1`, `new_conv_dim2` and `new_conv_dim3` values might have changed due to padding.\n     \"\"\"\n \n-    def __init__(self, nb_filter, kernel_dim1, kernel_dim2, kernel_dim3,\n-                 init='glorot_uniform', activation=None, weights=None,\n-                 border_mode='valid', subsample=(1, 1, 1), data_format='default',\n-                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n-                 W_constraint=None, b_constraint=None,\n-                 bias=True, **kwargs):\n-        if data_format == 'default':\n-            data_format = K.image_data_format()\n-\n-        if border_mode not in {'valid', 'same', 'full'}:\n-            raise ValueError('Invalid border mode for Convolution3D:', border_mode)\n-        self.nb_filter = nb_filter\n-        self.kernel_dim1 = kernel_dim1\n-        self.kernel_dim2 = kernel_dim2\n-        self.kernel_dim3 = kernel_dim3\n-        self.init = initializers.get(init, data_format=data_format)\n-        self.activation = activations.get(activation)\n-        self.border_mode = border_mode\n-        self.subsample = tuple(subsample)\n-        if data_format not in {'channels_last', 'channels_first'}:\n-            raise ValueError('data_format must be in {\"channels_last\", \"channels_first\"}.')\n-        self.data_format = data_format\n-\n-        self.W_regularizer = regularizers.get(W_regularizer)\n-        self.b_regularizer = regularizers.get(b_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-        self.W_constraint = constraints.get(W_constraint)\n-        self.b_constraint = constraints.get(b_constraint)\n-\n-        self.bias = bias\n+    def __init__(self, filters,\n+                 kernel_size,\n+                 strides=(1, 1, 1),\n+                 padding='valid',\n+                 data_format=None,\n+                 dilation_rate=(1, 1, 1),\n+                 activation=None,\n+                 use_bias=True,\n+                 kernel_initializer='glorot_uniform',\n+                 bias_initializer='zeros',\n+                 kernel_regularizer=None,\n+                 bias_regularizer=None,\n+                 activity_regularizer=None,\n+                 kernel_constraint=None,\n+                 bias_constraint=None,\n+                 **kwargs):\n+        super(Conv3D, self).__init__(\n+            rank=3,\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+            activation=activation,\n+            use_bias=use_bias,\n+            kernel_initializer=kernel_initializer,\n+            bias_initializer=bias_initializer,\n+            kernel_regularizer=kernel_regularizer,\n+            bias_regularizer=bias_regularizer,\n+            activity_regularizer=activity_regularizer,\n+            kernel_constraint=kernel_constraint,\n+            bias_constraint=bias_constraint,\n+            **kwargs)\n         self.input_spec = [InputSpec(ndim=5)]\n-        self.initial_weights = weights\n-        super(Convolution3D, self).__init__(**kwargs)\n+\n+    def get_config(self):\n+        config = super(Conv3D, self).get_config()\n+        config.pop('rank')\n+        return config\n+\n+\n+class Conv2DTranspose(Conv2D):\n+    \"\"\"Transposed convolution layer (sometimes called Deconvolution).\n+\n+    The need for transposed convolutions generally arises\n+    from the desire to use a transformation going in the opposite direction\n+    of a normal convolution, i.e., from something that has the shape of the\n+    output of some convolution to something that has the shape of its input\n+    while maintaining a connectivity pattern that is compatible with\n+    said convolution.\n+\n+    When using this layer as the first layer in a model,\n+    provide the keyword argument `input_shape`\n+    (tuple of integers, does not include the sample axis),\n+    e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n+    in `data_format=\"channels_last\"`.\n+\n+    # Arguments\n+        filters: Integer, the dimensionality of the output space\n+            (i.e. the number output of filters in the convolution).\n+        kernel_size: An integer or tuple/list of 2 integers, specifying the\n+            width and height of the 2D convolution window.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+        strides: An integer or tuple/list of 2 integers,\n+            specifying the strides of the convolution along the width and height.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+            Specifying any stride value != 1 is incompatible with specifying\n+            any `dilation_rate` value != 1.\n+        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n+        data_format: A string,\n+            one of `channels_last` (default) or `channels_first`.\n+            The ordering of the dimensions in the inputs.\n+            `channels_last` corresponds to inputs with shape\n+            `(batch, width, height, channels)` while `channels_first`\n+            corresponds to inputs with shape `(batch, channels, width, height)`.\n+            It defaults to the `image_data_format` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"channels_last\".\n+        dilation_rate: an integer or tuple/list of 2 integers, specifying\n+            the dilation rate to use for dilated convolution.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+            Currently, specifying any `dilation_rate` value != 1 is\n+            incompatible with specifying any stride value != 1.\n+        activation: Activation function to use\n+            (see [activations](../activations.md)).\n+            If you don't specify anything, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        use_bias: Boolean, whether the layer uses a bias vector.\n+        kernel_initializer: Initializer for the `kernel` weights matrix\n+            (see [initializers](../initializers.md)).\n+        bias_initializer: Initializer for the bias vector\n+            (see [initializers](../initializers.md)).\n+        kernel_regularizer: Regularizer function applied to\n+            the `kernel` weights matrix\n+            (see [regularizer](../regularizers.md)).\n+        bias_regularizer: Regularizer function applied to the bias vector\n+            (see [regularizer](../regularizers.md)).\n+        activity_regularizer: Regularizer function applied to\n+            the output of the layer (its \"activation\").\n+            (see [regularizer](../regularizers.md)).\n+        kernel_constraint: Constraint function applied to the kernel matrix\n+            (see [constraints](../constraints.md)).\n+        bias_constraint: Constraint function applied to the bias vector\n+            (see [constraints](../constraints.md)).\n+\n+    # Input shape\n+        4D tensor with shape:\n+        `(batch, channels, rows, cols)` if data_format='channels_first'\n+        or 4D tensor with shape:\n+        `(batch, rows, cols, channels)` if data_format='channels_last'.\n+\n+    # Output shape\n+        4D tensor with shape:\n+        `(batch, nb_filter, new_rows, new_cols)` if data_format='channels_first'\n+        or 4D tensor with shape:\n+        `(batch, new_rows, new_cols, nb_filter)` if data_format='channels_last'.\n+        `rows` and `cols` values might have changed due to padding.\n+\n+    # References\n+        - [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285v1)\n+        - [Deconvolutional Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)\n+    \"\"\"\n+\n+    def __init__(self, filters,\n+                 kernel_size,\n+                 strides=(1, 1),\n+                 padding='valid',\n+                 data_format='channels_last',\n+                 activation=None,\n+                 use_bias=True,\n+                 kernel_initializer='glorot_uniform',\n+                 bias_initializer='zeros',\n+                 kernel_regularizer=None,\n+                 bias_regularizer=None,\n+                 activity_regularizer=None,\n+                 kernel_constraint=None,\n+                 bias_constraint=None,\n+                 **kwargs):\n+        super(Conv2DTranspose, self).__init__(\n+            filters,\n+            kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            activation=activation,\n+            use_bias=use_bias,\n+            kernel_initializer=kernel_initializer,\n+            bias_initializer=bias_initializer,\n+            kernel_regularizer=kernel_regularizer,\n+            bias_regularizer=bias_regularizer,\n+            activity_regularizer=activity_regularizer,\n+            kernel_constraint=kernel_constraint,\n+            bias_constraint=bias_constraint,\n+            **kwargs)\n+        self.input_spec = [InputSpec(ndim=4)]\n \n     def build(self, input_shape):\n-        assert len(input_shape) == 5\n-\n+        if len(input_shape) != 4:\n+            raise ValueError('Inputs should have rank ' +\n+                             str(4) +\n+                             'Received input shape:', str(input_shape))\n         if self.data_format == 'channels_first':\n-            stack_size = input_shape[1]\n-            self.W_shape = (self.nb_filter, stack_size,\n-                            self.kernel_dim1, self.kernel_dim2, self.kernel_dim3)\n-        elif self.data_format == 'channels_last':\n-            stack_size = input_shape[4]\n-            self.W_shape = (self.kernel_dim1, self.kernel_dim2, self.kernel_dim3,\n-                            stack_size, self.nb_filter)\n+            channel_axis = 1\n         else:\n-            raise ValueError('Invalid data_format:', self.data_format)\n+            channel_axis = -1\n+        if input_shape[channel_axis] is None:\n+            raise ValueError('The channel dimension of the inputs '\n+                             'should be defined. Found `None`.')\n+        input_dim = input_shape[channel_axis]\n+        kernel_shape = self.kernel_size + (self.filters, input_dim)\n+\n+        self.kernel = self.add_weight(kernel_shape,\n+                                      initializer=self.kernel_initializer,\n+                                      name='kernel',\n+                                      regularizer=self.kernel_regularizer,\n+                                      constraint=self.kernel_constraint)\n+        if self.use_bias:\n+            self.bias = self.add_weight((self.filters,),\n+                                        initializer=self.bias_initializer,\n+                                        name='bias',\n+                                        regularizer=self.bias_regularizer,\n+                                        constraint=self.bias_constraint)\n+        else:\n+            self.bias = None\n+\n+    def call(self, inputs):\n+        input_shape = K.shape(inputs)\n+        batch_size = input_shape[0]\n+        if self.data_format == 'channels_first':\n+            c_axis, h_axis, w_axis = 1, 2, 3\n+        else:\n+            c_axis, h_axis, w_axis = 3, 1, 2\n+\n+        height, width = input_shape[h_axis], input_shape[w_axis]\n+        kernel_h, kernel_w = self.kernel_size\n+        stride_h, stride_w = self.strides\n+\n+        # Infer the dynamic output shape:\n+        out_height = conv_utils.deconv_length(height,\n+                                              stride_h, kernel_h,\n+                                              self.padding)\n+        out_width = conv_utils.deconv_length(width,\n+                                             stride_w, kernel_w,\n+                                             self.padding)\n+        if self.data_format == 'channels_first':\n+            output_shape = (batch_size, self.filters, out_height, out_width)\n+            strides = (1, 1, stride_h, stride_w)\n+        else:\n+            output_shape = (batch_size, out_height, out_width, self.filters)\n+            strides = (1, stride_h, stride_w, 1)\n+\n+        output_shape_tensor = K.stack(output_shape)\n+        outputs = K.conv2d_transpose(\n+            inputs,\n+            self.kernel,\n+            output_shape_tensor,\n+            strides,\n+            padding=self.padding,\n+            data_format=self.data_format)\n \n-        self.W = self.add_weight(self.W_shape,\n-                                 initializer=self.init,\n-                                 name='{}_W'.format(self.name),\n-                                 regularizer=self.W_regularizer,\n-                                 constraint=self.W_constraint)\n         if self.bias:\n-            self.b = self.add_weight((self.nb_filter,),\n-                                     initializer='zero',\n-                                     name='{}_b'.format(self.name),\n-                                     regularizer=self.b_regularizer,\n-                                     constraint=self.b_constraint)\n-        else:\n-            self.b = None\n+            outputs = K.bias_add(\n+                outputs,\n+                self.bias,\n+                data_format=self.data_format)\n \n-        if self.initial_weights is not None:\n-            self.set_weights(self.initial_weights)\n-            del self.initial_weights\n-        self.built = True\n+        if self.activation is not None:\n+            return self.activation(outputs)\n+        return outputs\n+\n+    def get_output_shape_for(self, input_shape):\n+        output_shape = copy.copy(input_shape)\n+        if self.data_format == 'channels_first':\n+            c_axis, h_axis, w_axis = 1, 2, 3\n+        else:\n+            c_axis, h_axis, w_axis = 3, 1, 2\n+\n+        height, width = input_shape[h_axis], input_shape[w_axis]\n+        kernel_h, kernel_w = self.kernel_size\n+        stride_h, stride_w = self.strides\n+\n+        output_shape[c_axis] = self.filters\n+        output_shape[h_axis] = conv_utils.deconv_length(\n+            output_shape[h_axis], stride_h, kernel_h, self.padding)\n+        output_shape[w_axis] = conv_utils.deconv_length(\n+            output_shape[w_axis], stride_w, kernel_w, self.padding)\n+        return output_shape\n+\n+    def get_config(self):\n+        config = super(Conv2DTranspose, self).get_config()\n+        config.pop('rank')\n+        config.pop('dilate_rate')\n+        return config\n+\n+\n+class SeparableConv2D(Conv2D):\n+    \"\"\"Depthwise separable 2D convolution.\n+\n+    Separable convolutions consist in first performing\n+    a depthwise spatial convolution\n+    (which acts on each input channel separately)\n+    followed by a pointwise convolution which mixes together the resulting\n+    output channels. The `depth_multiplier` argument controls how many\n+    output channels are generated per input channel in the depthwise step.\n+\n+    Intuitively, separable convolutions can be understood as\n+    a way to factorize a convolution kernel into two smaller kernels,\n+    or as an extreme version of an Inception block.\n+\n+    # Arguments\n+        filters: Integer, the dimensionality of the output space\n+            (i.e. the number output of filters in the convolution).\n+        kernel_size: An integer or tuple/list of 2 integers, specifying the\n+            width and height of the 2D convolution window.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+        strides: An integer or tuple/list of 2 integers,\n+            specifying the strides of the convolution along the width and height.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+            Specifying any stride value != 1 is incompatible with specifying\n+            any `dilation_rate` value != 1.\n+        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n+        data_format: A string,\n+            one of `channels_last` (default) or `channels_first`.\n+            The ordering of the dimensions in the inputs.\n+            `channels_last` corresponds to inputs with shape\n+            `(batch, width, height, channels)` while `channels_first`\n+            corresponds to inputs with shape `(batch, channels, width, height)`.\n+            It defaults to the `image_data_format` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"channels_last\".\n+        dilation_rate: an integer or tuple/list of 2 integers, specifying\n+            the dilation rate to use for dilated convolution.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+            Currently, specifying any `dilation_rate` value != 1 is\n+            incompatible with specifying any stride value != 1.\n+        depth_multiplier: The number of depthwise convolution output channels\n+            for each input channel.\n+            The total number of depthwise convolution output\n+            channels will be equal to `num_filters_in * depth_multiplier`.\n+        activation: Activation function to use\n+            (see [activations](../activations.md)).\n+            If you don't specify anything, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        use_bias: Boolean, whether the layer uses a bias vector.\n+        depthwise_initializer: Initializer for the depthwise kernel matrix\n+            (see [initializers](../initializers.md)).\n+        pointwise_initializer: Initializer for the pointwise kernel matrix\n+            (see [initializers](../initializers.md)).\n+        bias_initializer: Initializer for the bias vector\n+            (see [initializers](../initializers.md)).\n+        depthwise_regularizer: Regularizer function applied to\n+            the depthwise kernel matrix\n+            (see [regularizer](../regularizers.md)).\n+        pointwise_regularizer: Regularizer function applied to\n+            the depthwise kernel matrix\n+            (see [regularizer](../regularizers.md)).\n+        bias_regularizer: Regularizer function applied to the bias vector\n+            (see [regularizer](../regularizers.md)).\n+        activity_regularizer: Regularizer function applied to\n+            the output of the layer (its \"activation\").\n+            (see [regularizer](../regularizers.md)).\n+        depthwise_constraint: Constraint function applied to\n+            the depthwise kernel matrix\n+            (see [constraints](../constraints.md)).\n+        pointwise_constraint: Constraint function applied to\n+            the pointwise kernel matrix\n+            (see [constraints](../constraints.md)).\n+        bias_constraint: Constraint function applied to the bias vector\n+            (see [constraints](../constraints.md)).\n+\n+    # Input shape\n+        4D tensor with shape:\n+        `(batch, channels, rows, cols)` if data_format='channels_first'\n+        or 4D tensor with shape:\n+        `(batch, rows, cols, channels)` if data_format='channels_last'.\n+\n+    # Output shape\n+        4D tensor with shape:\n+        `(batch, nb_filter, new_rows, new_cols)` if data_format='channels_first'\n+        or 4D tensor with shape:\n+        `(batch, new_rows, new_cols, nb_filter)` if data_format='channels_last'.\n+        `rows` and `cols` values might have changed due to padding.\n+    \"\"\"\n+\n+    def __init__(self, filters,\n+                 kernel_size,\n+                 strides=(1, 1),\n+                 padding='valid',\n+                 data_format='channels_last',\n+                 dilation_rate=(1, 1),\n+                 depth_multiplier=1,\n+                 activation=None,\n+                 use_bias=True,\n+                 depthwise_initializer='glorot_uniform',\n+                 pointwise_initializer='glorot_uniform',\n+                 bias_initializer='zeros',\n+                 depthwise_regularizer=None,\n+                 pointwise_regularizer=None,\n+                 bias_regularizer=None,\n+                 activity_regularizer=None,\n+                 depthwise_constraint=None,\n+                 pointwise_constraint=None,\n+                 bias_constraint=None,\n+                 **kwargs):\n+        super(SeparableConv2D, self).__init__(\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+            activation=activation,\n+            use_bias=use_bias,\n+            bias_regularizer=bias_regularizer,\n+            activity_regularizer=activity_regularizer,\n+            bias_constraint=bias_constraint,\n+            **kwargs)\n+        self.depth_multiplier = depth_multiplier\n+        self.depthwise_initializer = depthwise_initializer\n+        self.pointwise_initializer = pointwise_initializer\n+        self.depthwise_regularizer = depthwise_regularizer\n+        self.pointwise_constraint = pointwise_constraint\n+        self.depthwise_constraint = depthwise_constraint\n+        self.pointwise_constraint = pointwise_constraint\n+\n+    def build(self, input_shape):\n+        if len(input_shape) < 4:\n+            raise ValueError('Inputs to `SeparableConv2D` should have rank 4. '\n+                             'Received input shape:', str(input_shape))\n+        if self.data_format == 'channels_first':\n+            channel_axis = 1\n+        else:\n+            channel_axis = 3\n+        if input_shape[channel_axis] is None:\n+            raise ValueError('The channel dimension of the inputs to '\n+                             '`SeparableConv2D` '\n+                             'should be defined. Found `None`.')\n+        input_dim = int(input_shape[channel_axis])\n+        depthwise_kernel_shape = (self.kernel_size[0],\n+                                  self.kernel_size[1],\n+                                  input_dim,\n+                                  self.depth_multiplier)\n+        pointwise_kernel_shape = (1, 1,\n+                                  self.depth_multiplier * input_dim,\n+                                  self.filters)\n+\n+        self.depthwise_kernel = self.add_weight(\n+            depthwise_kernel_shape,\n+            initializer=self.depthwise_initializer,\n+            name='depthwise_kernel',\n+            regularizer=self.depthwise_regularizer,\n+            constraint=self.depthwise_constraint)\n+        self.pointwise_kernel = self.add_weight(\n+            pointwise_kernel_shape,\n+            initializer=self.pointwise_initializer,\n+            name='pointwise_kernel',\n+            regularizer=self.pointwise_regularizer,\n+            constraint=self.pointwise_constraint)\n+\n+        if self.use_bias:\n+            self.bias = self.add_weight((self.filters,),\n+                                        initializer=self.bias_initializer,\n+                                        name='bias',\n+                                        regularizer=self.bias_regularizer,\n+                                        constraint=self.bias_constraint)\n+        else:\n+            self.bias = None\n+\n+    def call(self, inputs):\n+        outputs = K.separable_conv2d(\n+            inputs,\n+            self.depthwise_kernel,\n+            self.pointwise_kernel,\n+            data_format=self.data_format,\n+            strides=self.strides,\n+            padding=self.padding,\n+            rate=self.dilation_rate)\n+\n+        if self.bias:\n+            outputs = K.bias_add(\n+                outputs,\n+                self.bias,\n+                data_format=self.data_format)\n+\n+        if self.activation is not None:\n+            return self.activation(outputs)\n+        return outputs\n \n     def get_output_shape_for(self, input_shape):\n         if self.data_format == 'channels_first':\n-            conv_dim1 = input_shape[2]\n-            conv_dim2 = input_shape[3]\n-            conv_dim3 = input_shape[4]\n+            rows = input_shape[2]\n+            cols = input_shape[3]\n         elif self.data_format == 'channels_last':\n-            conv_dim1 = input_shape[1]\n-            conv_dim2 = input_shape[2]\n-            conv_dim3 = input_shape[3]\n-        else:\n-            raise ValueError('Invalid data_format:', self.data_format)\n-\n-        conv_dim1 = conv_output_length(conv_dim1, self.kernel_dim1,\n-                                       self.border_mode, self.subsample[0])\n-        conv_dim2 = conv_output_length(conv_dim2, self.kernel_dim2,\n-                                       self.border_mode, self.subsample[1])\n-        conv_dim3 = conv_output_length(conv_dim3, self.kernel_dim3,\n-                                       self.border_mode, self.subsample[2])\n+            rows = input_shape[1]\n+            cols = input_shape[2]\n \n+        rows = conv_utils.conv_output_length(rows, self.nb_row,\n+                                             self.padding,\n+                                             self.strides[0],\n+                                             dilation=self.dilation_rate[0])\n+        cols = conv_utils.conv_output_length(cols, self.nb_col,\n+                                             self.padding,\n+                                             self.strides[1],\n+                                             dilation=self.dilation_rate[1])\n         if self.data_format == 'channels_first':\n-            return (input_shape[0], self.nb_filter, conv_dim1, conv_dim2, conv_dim3)\n+            return (input_shape[0], self.filters, rows, cols)\n         elif self.data_format == 'channels_last':\n-            return (input_shape[0], conv_dim1, conv_dim2, conv_dim3, self.nb_filter)\n-        else:\n-            raise ValueError('Invalid data_format:', self.data_format)\n-\n-    def call(self, x, mask=None):\n-        output = K.conv3d(x, self.W, strides=self.subsample,\n-                          border_mode=self.border_mode,\n-                          data_format=self.data_format,\n-                          filter_shape=self.W_shape)\n-        if self.bias:\n-            if self.data_format == 'channels_first':\n-                output += K.reshape(self.b, (1, self.nb_filter, 1, 1, 1))\n-            elif self.data_format == 'channels_last':\n-                output += K.reshape(self.b, (1, 1, 1, 1, self.nb_filter))\n-            else:\n-                raise ValueError('Invalid data_format:', self.data_format)\n-        output = self.activation(output)\n-        return output\n+            return (input_shape[0], rows, cols, self.filters)\n \n     def get_config(self):\n-        config = {'nb_filter': self.nb_filter,\n-                  'kernel_dim1': self.kernel_dim1,\n-                  'kernel_dim2': self.kernel_dim2,\n-                  'kernel_dim3': self.kernel_dim3,\n-                  'data_format': self.data_format,\n-                  'init': self.init.__name__,\n-                  'activation': self.activation.__name__,\n-                  'border_mode': self.border_mode,\n-                  'subsample': self.subsample,\n-                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n-                  'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n-                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n-                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n-                  'b_constraint': self.b_constraint.get_config() if self.b_constraint else None,\n-                  'bias': self.bias}\n-        base_config = super(Convolution3D, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n+        config = super(SeparableConv2D, self).get_config()\n+        config.pop('kernel_initializer')\n+        config.pop('kernel_regularizer')\n+        config.pop('kernel_constraint')\n+        config['depth_multiplier'] = self.depth_multiplier\n+        config['depthwise_initializer'] = initializers.serialize(self.depthwise_initializer)\n+        config['pointwise_initializer'] = initializers.serialize(self.pointwise_initializer)\n+        config['depthwise_regularizer'] = regularizers.serialize(self.depthwise_regularizer)\n+        config['pointwise_regularizer'] = regularizers.serialize(self.pointwise_regularizer)\n+        config['depthwise_constraint'] = constraints.serialize(self.depthwise_constraint)\n+        config['pointwise_constraint'] = constraints.serialize(self.pointwise_constraint)\n+        return config\n \n \n class UpSampling1D(Layer):\n     \"\"\"Upsampling layer for 1D inputs.\n \n-    Repeats each temporal step `length` times along the time axis.\n+    Repeats each temporal step `size` times along the time axis.\n \n     # Arguments\n-        length: integer. Upsampling factor.\n+        size: integer. Upsampling factor.\n \n     # Input shape\n-        3D tensor with shape: `(samples, steps, features)`.\n+        3D tensor with shape: `(batch, steps, features)`.\n \n     # Output shape\n-        3D tensor with shape: `(samples, upsampled_steps, features)`.\n+        3D tensor with shape: `(batch, upsampled_steps, features)`.\n     \"\"\"\n \n-    def __init__(self, length=2, **kwargs):\n-        self.length = length\n-        self.input_spec = [InputSpec(ndim=3)]\n+    def __init__(self, size=2, **kwargs):\n         super(UpSampling1D, self).__init__(**kwargs)\n+        self.size = int(size)\n+        self.input_spec = [InputSpec(ndim=3)]\n \n     def get_output_shape_for(self, input_shape):\n-        length = self.length * input_shape[1] if input_shape[1] is not None else None\n-        return (input_shape[0], length, input_shape[2])\n+        size = self.size * input_shape[1] if input_shape[1] is not None else None\n+        return (input_shape[0], size, input_shape[2])\n \n     def call(self, x, mask=None):\n-        output = K.repeat_elements(x, self.length, axis=1)\n+        output = K.repeat_elements(x, self.size, axis=1)\n         return output\n \n     def get_config(self):\n-        config = {'length': self.length}\n+        config = {'size': self.size}\n         base_config = super(UpSampling1D, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -1297,7 +1067,7 @@ class UpSampling2D(Layer):\n     by size[0] and size[1] respectively.\n \n     # Arguments\n-        size: tuple of 2 integers. The upsampling factors for rows and columns.\n+        size: int, or tuple of 2 integers. The upsampling factors for rows and columns.\n         data_format: 'channels_first' or 'channels_last'.\n             In 'channels_first' mode, the channels dimension (the depth)\n             is at index 1, in 'channels_last' mode is it at index 3.\n@@ -1307,26 +1077,24 @@ class UpSampling2D(Layer):\n \n     # Input shape\n         4D tensor with shape:\n-        `(samples, channels, rows, cols)` if data_format='channels_first'\n-        or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if data_format='channels_last'.\n+        - If `data_format` is `\"channels_last\"`:\n+            `(batch, rows, cols, channels)`\n+        - If `data_format` is `\"channels_first\"`:\n+            `(batch, channels, rows, cols)`\n \n     # Output shape\n         4D tensor with shape:\n-        `(samples, channels, upsampled_rows, upsampled_cols)` if data_format='channels_first'\n-        or 4D tensor with shape:\n-        `(samples, upsampled_rows, upsampled_cols, channels)` if data_format='channels_last'.\n+        - If `data_format` is `\"channels_last\"`:\n+            `(batch, upsampled_rows, upsampled_cols, channels)`\n+        - If `data_format` is `\"channels_first\"`:\n+            `(batch, channels, upsampled_rows, upsampled_cols)`\n     \"\"\"\n \n     def __init__(self, size=(2, 2), data_format='default', **kwargs):\n-        if data_format == 'default':\n-            data_format = K.image_data_format()\n-        self.size = tuple(size)\n-        if data_format not in {'channels_last', 'channels_first'}:\n-            raise ValueError('data_format must be in {\"channels_last\", \"channels_first\"}.')\n+        super(UpSampling2D, self).__init__(**kwargs)\n+        self.data_format = conv_utils.normalize_data_format(data_format)\n         self.data_format = data_format\n         self.input_spec = [InputSpec(ndim=4)]\n-        super(UpSampling2D, self).__init__(**kwargs)\n \n     def get_output_shape_for(self, input_shape):\n         if self.data_format == 'channels_first':\n@@ -1343,8 +1111,6 @@ class UpSampling2D(Layer):\n                     width,\n                     height,\n                     input_shape[3])\n-        else:\n-            raise ValueError('Invalid data_format:', self.data_format)\n \n     def call(self, x, mask=None):\n         return K.resize_images(x, self.size[0], self.size[1],\n@@ -1363,7 +1129,8 @@ class UpSampling3D(Layer):\n     of the data by size[0], size[1] and size[2] respectively.\n \n     # Arguments\n-        size: tuple of 3 integers. The upsampling factors for dim1, dim2 and dim3.\n+        size: int, or tuple of 3 integers.\n+            The upsampling factors for dim1, dim2 and dim3.\n         data_format: 'channels_first' or 'channels_last'.\n             In 'channels_first' mode, the channels dimension (the depth)\n             is at index 1, in 'channels_last' mode is it at index 4.\n@@ -1373,24 +1140,21 @@ class UpSampling3D(Layer):\n \n     # Input shape\n         5D tensor with shape:\n-        `(samples, channels, dim1, dim2, dim3)` if data_format='channels_first'\n-        or 5D tensor with shape:\n-        `(samples, dim1, dim2, dim3, channels)` if data_format='channels_last'.\n+        - If `data_format` is `\"channels_last\"`:\n+            `(batch, dim1, dim2, dim3, channels)`\n+        - If `data_format` is `\"channels_first\"`:\n+            `(batch, channels, dim1, dim2, dim3)`\n \n     # Output shape\n         5D tensor with shape:\n-        `(samples, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)` if data_format='channels_first'\n-        or 5D tensor with shape:\n-        `(samples, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)` if data_format='channels_last'.\n+        - If `data_format` is `\"channels_last\"`:\n+            `(batch, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)`\n+        - If `data_format` is `\"channels_first\"`:\n+            `(batch, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)`\n     \"\"\"\n \n-    def __init__(self, size=(2, 2, 2), data_format='default', **kwargs):\n-        if data_format == 'default':\n-            data_format = K.image_data_format()\n-        self.size = tuple(size)\n-        if data_format not in {'channels_last', 'channels_first'}:\n-            raise ValueError('data_format must be in {\"channels_last\", \"channels_first\"}.')\n-        self.data_format = data_format\n+    def __init__(self, size=(2, 2, 2), data_format=None, **kwargs):\n+        self.data_format = conv_utils.normalize_data_format(data_format)\n         self.input_spec = [InputSpec(ndim=5)]\n         super(UpSampling3D, self).__init__(**kwargs)\n \n@@ -1434,44 +1198,22 @@ class ZeroPadding1D(Layer):\n             - If int:\n             How many zeros to add at the beginning and end of\n             the padding dimension (axis 1).\n-            - If tuple of int (length 2)\n+            - If tuple of int (length 2):\n             How many zeros to add at the beginning and at the end of\n-            the padding dimension, in order '(left_pad, right_pad)'.\n-            - If dictionary: should contain the keys\n-            {'left_pad', 'right_pad'}.\n-            If any key is missing, default value of 0 will be used for the missing key.\n+            the padding dimension (`(left_pad, right_pad)`).\n \n     # Input shape\n-        3D tensor with shape `(samples, axis_to_pad, features)`\n+        3D tensor with shape `(batch, axis_to_pad, features)`\n \n     # Output shape\n-        3D tensor with shape `(samples, padded_axis, features)`\n+        3D tensor with shape `(batch, padded_axis, features)`\n     \"\"\"\n \n     def __init__(self, padding=1, **kwargs):\n         super(ZeroPadding1D, self).__init__(**kwargs)\n-        self.padding = padding\n-\n-        if isinstance(padding, int):\n-            self.left_pad = padding\n-            self.right_pad = padding\n-\n-        elif isinstance(padding, dict):\n-            if set(padding.keys()) <= {'left_pad', 'right_pad'}:\n-                self.left_pad = padding.get('left_pad', 0)\n-                self.right_pad = padding.get('right_pad', 0)\n-            else:\n-                raise ValueError('Unexpected key found in `padding` dictionary. '\n-                                 'Keys have to be in {\"left_pad\", \"right_pad\"}. '\n-                                 'Found: ' + str(padding.keys()))\n-        else:\n-            padding = tuple(padding)\n-            if len(padding) != 2:\n-                raise ValueError('`padding` should be int, or dict with keys '\n-                                 '{\"left_pad\", \"right_pad\"}, or tuple of length 2. '\n-                                 'Found: ' + str(padding))\n-            self.left_pad = padding[0]\n-            self.right_pad = padding[1]\n+        self.padding = conv_utils.normalize_tuple(padding, 2, 'padding')\n+        self.left_pad = self.padding[0]\n+        self.right_pad = self.padding[1]\n         self.input_spec = [InputSpec(ndim=3)]\n \n     def get_output_shape_for(self, input_shape):\n@@ -1492,18 +1234,20 @@ class ZeroPadding1D(Layer):\n class ZeroPadding2D(Layer):\n     \"\"\"Zero-padding layer for 2D input (e.g. picture).\n \n+    This layer can add rows and columns or zeros\n+    at the top, bottom, left and right side of an image tensor.\n+\n     # Arguments\n-        padding: tuple of int (length 2), or tuple of int (length 4), or dictionary.\n-            - If tuple of int (length 2):\n-            How many zeros to add at the beginning and end of\n-            the 2 padding dimensions (rows and cols).\n-            - If tuple of int (length 4):\n-            How many zeros to add at the beginning and at the end of\n-            the 2 padding dimensions (rows and cols), in the order\n-            '(top_pad, bottom_pad, left_pad, right_pad)'.\n-            - If dictionary: should contain the keys\n-            {'top_pad', 'bottom_pad', 'left_pad', 'right_pad'}.\n-            If any key is missing, default value of 0 will be used for the missing key.\n+        padding: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n+            - If int: the same symmetric padding\n+                is applied to width and height.\n+            - If tuple of 2 ints:\n+                interpreted as two different\n+                symmetric padding values for height and width:\n+                `(symmetric_height_pad, symmetrc_width_pad)`.\n+            - If tuple of 2 tuples of 2 ints:\n+                interpreted as\n+                `((top_pad, bottom_pad), (left_pad, right_pad))`\n         data_format: 'channels_first' or 'channels_last'.\n             In 'channels_first' mode, the channels dimension (the depth)\n             is at index 1, in 'channels_last' mode is it at index 3.\n@@ -1513,70 +1257,55 @@ class ZeroPadding2D(Layer):\n \n     # Input shape\n         4D tensor with shape:\n-        `(samples, channels, rows, cols)` if data_format='channels_first'\n-        or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if data_format='channels_last'.\n+        - If `data_format` is `\"channels_last\"`:\n+            `(batch, rows, cols, channels)`\n+        - If `data_format` is `\"channels_first\"`:\n+            `(batch, channels, rows, cols)`\n \n     # Output shape\n         4D tensor with shape:\n-        `(samples, channels, padded_rows, padded_cols)` if data_format='channels_first'\n-        or 4D tensor with shape:\n-        `(samples, padded_rows, padded_cols, channels)` if data_format='channels_last'.\n+        - If `data_format` is `\"channels_last\"`:\n+            `(batch, padded_rows, padded_cols, channels)`\n+        - If `data_format` is `\"channels_first\"`:\n+            `(batch, channels, padded_rows, padded_cols)`\n     \"\"\"\n \n     def __init__(self,\n                  padding=(1, 1),\n-                 data_format='default',\n+                 data_format=None,\n                  **kwargs):\n         super(ZeroPadding2D, self).__init__(**kwargs)\n-        if data_format == 'default':\n-            data_format = K.image_data_format()\n-\n-        self.padding = padding\n-        if isinstance(padding, dict):\n-            if set(padding.keys()) <= {'top_pad', 'bottom_pad', 'left_pad', 'right_pad'}:\n-                self.top_pad = padding.get('top_pad', 0)\n-                self.bottom_pad = padding.get('bottom_pad', 0)\n-                self.left_pad = padding.get('left_pad', 0)\n-                self.right_pad = padding.get('right_pad', 0)\n+        self.data_format = conv_utils.normalize_data_format(data_format)\n+        if isinstance(padding, int):\n+            self.padding = ((padding, padding), (padding, padding))\n+        if hasattr(padding, '__len__'):\n+            if len(padding) != 2:\n+                raise ValueError('TODO')\n+            height_padding = conv_utils.normalize_tuple(padding[0], 2,\n+                                                        '1st entry of padding')\n+            width_padding = conv_utils.normalize_tuple(padding[1], 2,\n+                                                       '2nd entry of padding')\n+            self.padding = (height_padding, width_padding)\n         else:\n-                raise ValueError('Unexpected key found in `padding` dictionary. '\n-                                 'Keys have to be in {\"top_pad\", \"bottom_pad\", '\n-                                 '\"left_pad\", \"right_pad\"}.'\n-                                 'Found: ' + str(padding.keys()))\n-        else:\n-            padding = tuple(padding)\n-            if len(padding) == 2:\n-                self.top_pad = padding[0]\n-                self.bottom_pad = padding[0]\n-                self.left_pad = padding[1]\n-                self.right_pad = padding[1]\n-            elif len(padding) == 4:\n-                self.top_pad = padding[0]\n-                self.bottom_pad = padding[1]\n-                self.left_pad = padding[2]\n-                self.right_pad = padding[3]\n-            else:\n-                raise TypeError('`padding` should be tuple of int '\n-                                'of length 2 or 4, or dict. '\n+            raise ValueError('`padding` should be either an int, '\n+                             'a tuple of 2 ints '\n+                             '(symmetric_height_pad, symmetric_width_pad), '\n+                             'or a tuple of 2 tuples of 2 ints '\n+                             '((top_pad, bottom_pad), (left_pad, right_pad)).'\n                              'Found: ' + str(padding))\n-\n-        if data_format not in {'channels_last', 'channels_first'}:\n-            raise ValueError('data_format must be in {\"channels_last\", \"channels_first\"}.')\n-        self.data_format = data_format\n         self.input_spec = [InputSpec(ndim=4)]\n \n     def get_output_shape_for(self, input_shape):\n         if self.data_format == 'channels_first':\n-            rows = input_shape[2] + self.top_pad + self.bottom_pad if input_shape[2] is not None else None\n-            cols = input_shape[3] + self.left_pad + self.right_pad if input_shape[3] is not None else None\n+            rows = input_shape[2] + self.padding[0][0] + self.padding[0][1] if input_shape[2] is not None else None\n+            cols = input_shape[3] + self.padding[1][0] + self.padding[1][1] if input_shape[3] is not None else None\n             return (input_shape[0],\n                     input_shape[1],\n                     rows,\n                     cols)\n         elif self.data_format == 'channels_last':\n-            rows = input_shape[1] + self.top_pad + self.bottom_pad if input_shape[1] is not None else None\n-            cols = input_shape[2] + self.left_pad + self.right_pad if input_shape[2] is not None else None\n+            rows = input_shape[1] + self.padding[0][0] + self.padding[0][1] if input_shape[1] is not None else None\n+            cols = input_shape[2] + self.padding[1][0] + self.padding[1][1] if input_shape[2] is not None else None\n             return (input_shape[0],\n                     rows,\n                     cols,\n@@ -1602,10 +1331,16 @@ class ZeroPadding3D(Layer):\n     \"\"\"Zero-padding layer for 3D data (spatial or spatio-temporal).\n \n     # Arguments\n-        padding: tuple of int (length 3)\n-            How many zeros to add at the beginning and end of\n-            the 3 padding dimensions (axis 3, 4 and 5).\n-            Currently only symmetric padding is supported.\n+        padding: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n+            - If int: the same symmetric padding\n+                is applied to width and height.\n+            - If tuple of 2 ints:\n+                interpreted as two different\n+                symmetric padding values for height and width:\n+                `(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad)`.\n+            - If tuple of 2 tuples of 2 ints:\n+                interpreted as\n+                `((left_dim1_pad, right_dim1_pad), (left_dim2_pad, right_dim2_pad), (left_dim3_pad, right_dim3_pad))`\n         data_format: 'channels_first' or 'channels_last'.\n             In 'channels_first' mode, the channels dimension (the depth)\n             is at index 1, in 'channels_last' mode is it at index 4.\n@@ -1615,37 +1350,59 @@ class ZeroPadding3D(Layer):\n \n     # Input shape\n         5D tensor with shape:\n-        `(samples, depth, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad)`\n+        - If `data_format` is `\"channels_last\"`:\n+            `(batch, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad, depth)`\n+        - If `data_format` is `\"channels_first\"`:\n+            `(batch, depth, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad)`\n \n     # Output shape\n         5D tensor with shape:\n-        `(samples, depth, first_padded_axis, second_padded_axis, third_axis_to_pad)`\n+        - If `data_format` is `\"channels_last\"`:\n+            `(batch, first_padded_axis, second_padded_axis, third_axis_to_pad, depth)`\n+        - If `data_format` is `\"channels_first\"`:\n+            `(batch, depth, first_padded_axis, second_padded_axis, third_axis_to_pad)`\n     \"\"\"\n \n-    def __init__(self, padding=(1, 1, 1), data_format='default', **kwargs):\n+    def __init__(self, padding=(1, 1, 1), data_format=None, **kwargs):\n         super(ZeroPadding3D, self).__init__(**kwargs)\n-        if data_format == 'default':\n-            data_format = K.image_data_format()\n-        self.padding = tuple(padding)\n-        if data_format not in {'channels_last', 'channels_first'}:\n-            raise ValueError('data_format must be in {\"channels_last\", \"channels_first\"}.')\n-        self.data_format = data_format\n+        self.data_format = conv_utils.normalize_data_format(data_format)\n+        if isinstance(padding, int):\n+            self.padding = ((padding, padding), (padding, padding), (padding, padding))\n+        if hasattr(padding, '__len__'):\n+            if len(padding) != 3:\n+                raise ValueError('TODO')\n+            dim1_padding = conv_utils.normalize_tuple(padding[0], 2,\n+                                                      '1st entry of padding')\n+            dim2_padding = conv_utils.normalize_tuple(padding[1], 2,\n+                                                      '2nd entry of padding')\n+            dim3_padding = conv_utils.normalize_tuple(padding[2], 2,\n+                                                      '3rd entry of padding')\n+            self.padding = (dim1_padding, dim2_padding, dim3_padding)\n+        else:\n+            raise ValueError('`padding` should be either an int, '\n+                             'a tuple of 3 ints '\n+                             '(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad), '\n+                             'or a tuple of 3 tuples of 2 ints '\n+                             '((left_dim1_pad, right_dim1_pad),'\n+                             ' (left_dim2_pad, right_dim2_pad),'\n+                             ' (left_dim3_pad, right_dim2_pad)). '\n+                             'Found: ' + str(padding))\n         self.input_spec = [InputSpec(ndim=5)]\n \n     def get_output_shape_for(self, input_shape):\n         if self.data_format == 'channels_first':\n-            dim1 = input_shape[2] + 2 * self.padding[0] if input_shape[2] is not None else None\n-            dim2 = input_shape[3] + 2 * self.padding[1] if input_shape[3] is not None else None\n-            dim3 = input_shape[4] + 2 * self.padding[2] if input_shape[4] is not None else None\n+            dim1 = input_shape[2] + 2 * self.padding[0][0] if input_shape[2] is not None else None\n+            dim2 = input_shape[3] + 2 * self.padding[1][0] if input_shape[3] is not None else None\n+            dim3 = input_shape[4] + 2 * self.padding[2][0] if input_shape[4] is not None else None\n             return (input_shape[0],\n                     input_shape[1],\n                     dim1,\n                     dim2,\n                     dim3)\n         elif self.data_format == 'channels_last':\n-            dim1 = input_shape[1] + 2 * self.padding[0] if input_shape[1] is not None else None\n-            dim2 = input_shape[2] + 2 * self.padding[1] if input_shape[2] is not None else None\n-            dim3 = input_shape[3] + 2 * self.padding[2] if input_shape[3] is not None else None\n+            dim1 = input_shape[1] + 2 * self.padding[0][1] if input_shape[1] is not None else None\n+            dim2 = input_shape[2] + 2 * self.padding[1][1] if input_shape[2] is not None else None\n+            dim3 = input_shape[3] + 2 * self.padding[2][1] if input_shape[3] is not None else None\n             return (input_shape[0],\n                     dim1,\n                     dim2,\n@@ -1670,22 +1427,22 @@ class Cropping1D(Layer):\n     It crops along the time dimension (axis 1).\n \n     # Arguments\n-        cropping: tuple of int (length 2)\n+        cropping: int or tuple of int (length 2)\n             How many units should be trimmed off at the beginning and end of\n             the cropping dimension (axis 1).\n+            If a single int is provided,\n+            the same value will be used for both.\n \n     # Input shape\n-        3D tensor with shape `(samples, axis_to_crop, features)`\n+        3D tensor with shape `(batch, axis_to_crop, features)`\n \n     # Output shape\n-        3D tensor with shape `(samples, cropped_axis, features)`\n+        3D tensor with shape `(batch, cropped_axis, features)`\n     \"\"\"\n \n     def __init__(self, cropping=(1, 1), **kwargs):\n         super(Cropping1D, self).__init__(**kwargs)\n-        self.cropping = tuple(cropping)\n-        if len(self.cropping) != 2:\n-            raise ValueError('`cropping` must be a tuple length of 2.')\n+        self.cropping = conv_utils.normalize_tuple(cropping, 2, 'cropping')\n         self.input_spec = [InputSpec(ndim=3)]\n \n     def build(self, input_shape):\n@@ -1701,7 +1458,7 @@ class Cropping1D(Layer):\n                 length,\n                 input_shape[2])\n \n-    def call(self, x, mask=None):\n+    def call(self, x):\n         if self.cropping[1] == 0:\n             return x[:, self.cropping[0]:, :]\n         else:\n@@ -1719,9 +1476,16 @@ class Cropping2D(Layer):\n     It crops along spatial dimensions, i.e. width and height.\n \n     # Arguments\n-        cropping: tuple of tuple of int (length 2)\n-            How many units should be trimmed off at the beginning and end of\n-            the 2 cropping dimensions (width, height).\n+        cropping: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n+            - If int: the same symmetric cropping\n+                is applied to width and height.\n+            - If tuple of 2 ints:\n+                interpreted as two different\n+                symmetric cropping values for height and width:\n+                `(symmetric_height_crop, symmetrc_width_crop)`.\n+            - If tuple of 2 tuples of 2 ints:\n+                interpreted as\n+                `((top_crop, bottom_crop), (left_crop, right_crop))`\n         data_format: 'channels_first' or 'channels_last'.\n             In 'channels_first' mode, the channels dimension (the depth)\n             is at index 1, in 'channels_last' mode is it at index 3.\n@@ -1731,46 +1495,57 @@ class Cropping2D(Layer):\n \n     # Input shape\n         4D tensor with shape:\n-        `(samples, depth, first_axis_to_crop, second_axis_to_crop)`\n+        - If `data_format` is `\"channels_last\"`:\n+            `(batch, rows, cols, channels)`\n+        - If `data_format` is `\"channels_first\"`:\n+            `(batch, channels, rows, cols)`\n \n     # Output shape\n         4D tensor with shape:\n-        `(samples, depth, first_cropped_axis, second_cropped_axis)`\n+        - If `data_format` is `\"channels_last\"`:\n+            `(batch, cropped_rows, cropped_cols, channels)`\n+        - If `data_format` is `\"channels_first\"`:\n+            `(batch, channels, cropped_rows, cropped_cols)`\n \n     # Examples\n \n     ```python\n         # Crop the input 2D images or feature maps\n         model = Sequential()\n-        model.add(Cropping2D(cropping=((2, 2), (4, 4)), input_shape=(3, 28, 28)))\n-        # now model.output_shape == (None, 3, 24, 20)\n-        model.add(Convolution2D(64, 3, 3, border_mode='same))\n+        model.add(Cropping2D(cropping=((2, 2), (4, 4)),\n+                             input_shape=(28, 28, 3)))\n+        # now model.output_shape == (None, 24, 20, 3)\n+        model.add(Conv2D(64, (3, 3), padding='same))\n         model.add(Cropping2D(cropping=((2, 2), (2, 2))))\n-        # now model.output_shape == (None, 64, 20, 16)\n-\n+        # now model.output_shape == (None, 20, 16. 64)\n     ```\n     \"\"\"\n \n-    def __init__(self, cropping=((0, 0), (0, 0)), data_format='default', **kwargs):\n+    def __init__(self, cropping=((0, 0), (0, 0)),\n+                 data_format=None, **kwargs):\n         super(Cropping2D, self).__init__(**kwargs)\n-        if data_format == 'default':\n-            data_format = K.image_data_format()\n-        self.cropping = tuple(cropping)\n-        if len(self.cropping) != 2:\n-            raise ValueError('`cropping` must be a tuple length of 2.')\n-        if len(self.cropping[0]) != 2:\n-            raise ValueError('`cropping[0]` must be a tuple length of 2.')\n-        if len(self.cropping[1]) != 2:\n-            raise ValueError('`cropping[1]` must be a tuple length of 2.')\n-        if data_format not in {'channels_last', 'channels_first'}:\n-            raise ValueError('data_format must be in {\"channels_last\", \"channels_first\"}.')\n-        self.data_format = data_format\n+        self.data_format = conv_utils.normalize_data_format(data_format)\n+        if isinstance(cropping, int):\n+            self.cropping = ((cropping, cropping), (cropping, cropping))\n+        if hasattr(cropping, '__len__'):\n+            if len(cropping) != 2:\n+                raise ValueError('TODO')\n+            height_cropping = conv_utils.normalize_tuple(\n+                cropping[0], 2,\n+                '1st entry of cropping')\n+            width_cropping = conv_utils.normalize_tuple(\n+                cropping[1], 2,\n+                '2nd entry of cropping')\n+            self.cropping = (height_cropping, width_cropping)\n+        else:\n+            raise ValueError('`cropping` should be either an int, '\n+                             'a tuple of 2 ints '\n+                             '(symmetric_height_crop, symmetric_width_crop), '\n+                             'or a tuple of 2 tuples of 2 ints '\n+                             '((top_crop, bottom_crop), (left_crop, right_crop)).'\n+                             'Found: ' + str(cropping))\n         self.input_spec = [InputSpec(ndim=4)]\n \n-    def build(self, input_shape):\n-        self.input_spec = [InputSpec(shape=input_shape)]\n-        self.built = True\n-\n     def get_output_shape_for(self, input_shape):\n         if self.data_format == 'channels_first':\n             return (input_shape[0],\n@@ -1785,7 +1560,7 @@ class Cropping2D(Layer):\n         else:\n             raise ValueError('Invalid data_format:', self.data_format)\n \n-    def call(self, x, mask=None):\n+    def call(self, x):\n         if self.data_format == 'channels_first':\n             if self.cropping[0][1] == self.cropping[1][1] == 0:\n                 return x[:,\n@@ -1837,9 +1612,16 @@ class Cropping3D(Layer):\n     \"\"\"Cropping layer for 3D data (e.g. spatial or spatio-temporal).\n \n     # Arguments\n-        cropping: tuple of tuple of int (length 3)\n-            How many units should be trimmed off at the beginning and end of\n-            the 3 cropping dimensions (kernel_dim1, kernel_dim2, kernerl_dim3).\n+        cropping: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n+            - If int: the same symmetric cropping\n+                is applied to width and height.\n+            - If tuple of 2 ints:\n+                interpreted as two different\n+                symmetric cropping values for height and width:\n+                `(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)`.\n+            - If tuple of 2 tuples of 2 ints:\n+                interpreted as\n+                `((left_dim1_crop, right_dim1_crop), (left_dim2_crop, right_dim2_crop), (left_dim3_crop, right_dim3_crop))`\n         data_format: 'channels_first' or 'channels_last'.\n             In 'channels_first' mode, the channels dimension (the depth)\n             is at index 1, in 'channels_last' mode is it at index 4.\n@@ -1849,37 +1631,48 @@ class Cropping3D(Layer):\n \n     # Input shape\n         5D tensor with shape:\n-        `(samples, depth, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)`\n+        - If `data_format` is `\"channels_last\"`:\n+            `(batch, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop, depth)`\n+        - If `data_format` is `\"channels_first\"`:\n+            `(batch, depth, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)`\n \n     # Output shape\n         5D tensor with shape:\n-        `(samples, depth, first_cropped_axis, second_cropped_axis, third_cropped_axis)`\n-\n+        - If `data_format` is `\"channels_last\"`:\n+            `(batch, first_cropped_axis, second_cropped_axis, third_cropped_axis, depth)`\n+        - If `data_format` is `\"channels_first\"`:\n+            `(batch, depth, first_cropped_axis, second_cropped_axis, third_cropped_axis)`\n     \"\"\"\n \n     def __init__(self, cropping=((1, 1), (1, 1), (1, 1)),\n-                 data_format='default', **kwargs):\n+                 data_format=None, **kwargs):\n         super(Cropping3D, self).__init__(**kwargs)\n-        if data_format == 'default':\n-            data_format = K.image_data_format()\n-        self.cropping = tuple(cropping)\n-        if len(self.cropping) != 3:\n-            raise ValueError('`cropping` must be a tuple length of 3.')\n-        if len(self.cropping[0]) != 2:\n-            raise ValueError('`cropping[0]` must be a tuple length of 2.')\n-        if len(self.cropping[1]) != 2:\n-            raise ValueError('`cropping[1]` must be a tuple length of 2.')\n-        if len(self.cropping[2]) != 2:\n-            raise ValueError('`cropping[2]` must be a tuple length of 2.')\n-        if data_format not in {'channels_last', 'channels_first'}:\n-            raise ValueError('data_format must be in {\"channels_last\", \"channels_first\"}.')\n-        self.data_format = data_format\n+        self.data_format = conv_utils.normalize_data_format(data_format)\n+        if isinstance(cropping, int):\n+            self.cropping = ((cropping, cropping),\n+                             (cropping, cropping),\n+                             (cropping, cropping))\n+        if hasattr(cropping, '__len__'):\n+            if len(cropping) != 3:\n+                raise ValueError('TODO')\n+            dim1_cropping = conv_utils.normalize_tuple(cropping[0], 2,\n+                                                       '1st entry of cropping')\n+            dim2_cropping = conv_utils.normalize_tuple(cropping[1], 2,\n+                                                       '2nd entry of cropping')\n+            dim3_cropping = conv_utils.normalize_tuple(cropping[2], 2,\n+                                                       '3rd entry of cropping')\n+            self.cropping = (dim1_cropping, dim2_cropping, dim3_cropping)\n+        else:\n+            raise ValueError('`cropping` should be either an int, '\n+                             'a tuple of 3 ints '\n+                             '(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop), '\n+                             'or a tuple of 3 tuples of 2 ints '\n+                             '((left_dim1_crop, right_dim1_crop),'\n+                             ' (left_dim2_crop, right_dim2_crop),'\n+                             ' (left_dim3_crop, right_dim2_crop)). '\n+                             'Found: ' + str(cropping))\n         self.input_spec = [InputSpec(ndim=5)]\n \n-    def build(self, input_shape):\n-        self.input_spec = [InputSpec(shape=input_shape)]\n-        self.built = True\n-\n     def get_output_shape_for(self, input_shape):\n         if self.data_format == 'channels_first':\n             dim1 = input_shape[2] - self.cropping[0][0] - self.cropping[0][1] if input_shape[2] is not None else None\n@@ -1902,7 +1695,7 @@ class Cropping3D(Layer):\n         else:\n             raise ValueError('Invalid data_format:', self.data_format)\n \n-    def call(self, x, mask=None):\n+    def call(self, x):\n         if self.data_format == 'channels_first':\n             if self.cropping[0][1] == self.cropping[1][1] == self.cropping[2][1] == 0:\n                 return x[:,\n@@ -2004,14 +1797,3 @@ class Cropping3D(Layer):\n         config = {'cropping': self.cropping}\n         base_config = super(Cropping3D, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-# Aliases\n-\n-Conv1D = Convolution1D\n-Conv2D = Convolution2D\n-Conv3D = Convolution3D\n-Deconv2D = Deconvolution2D\n-AtrousConv1D = AtrousConvolution1D\n-AtrousConv2D = AtrousConvolution2D\n-SeparableConv2D = SeparableConvolution2D\n\n@@ -6,7 +6,7 @@ from .. import regularizers\n import numpy as np\n from ..engine import Layer\n from ..engine import InputSpec\n-from ..utils.np_utils import conv_output_length\n+from ..utils.conv_utils import conv_output_length\n import warnings\n \n \n@@ -82,6 +82,7 @@ class ConvRecurrent2D(Layer):\n     def __init__(self, weights=None, nb_row=None, nb_col=None, nb_filter=None,\n                  return_sequences=False, go_backwards=False, stateful=False,\n                  data_format=None, **kwargs):\n+        super(ConvRecurrent2D, self).__init__(**kwargs)\n         self.return_sequences = return_sequences\n         self.go_backwards = go_backwards\n         self.stateful = stateful\n@@ -92,8 +93,6 @@ class ConvRecurrent2D(Layer):\n         self.data_format = data_format\n         self.input_spec = [InputSpec(ndim=5)]\n \n-        super(ConvRecurrent2D, self).__init__(**kwargs)\n-\n     def compute_mask(self, input, mask):\n         if self.return_sequences:\n             return mask\n@@ -262,6 +261,11 @@ class ConvLSTM2D(ConvRecurrent2D):\n                  border_mode='valid', subsample=(1, 1),\n                  W_regularizer=None, U_regularizer=None, b_regularizer=None,\n                  dropout_W=0., dropout_U=0., **kwargs):\n+        kwargs['nb_filter'] = nb_filter\n+        kwargs['nb_row'] = nb_row\n+        kwargs['nb_col'] = nb_col\n+        kwargs['data_format'] = data_format\n+        super(ConvLSTM2D, self).__init__(**kwargs)\n \n         if data_format == 'default':\n             data_format = K.image_data_format()\n@@ -288,11 +292,6 @@ class ConvLSTM2D(ConvRecurrent2D):\n                           '(samples, time, channels, rows, cols)')\n         self.data_format = data_format\n \n-        kwargs['nb_filter'] = nb_filter\n-        kwargs['nb_row'] = nb_row\n-        kwargs['nb_col'] = nb_col\n-        kwargs['data_format'] = data_format\n-\n         self.W_regularizer = regularizers.get(W_regularizer)\n         self.U_regularizer = regularizers.get(U_regularizer)\n         self.b_regularizer = regularizers.get(b_regularizer)\n@@ -300,8 +299,6 @@ class ConvLSTM2D(ConvRecurrent2D):\n         if self.dropout_W or self.dropout_U:\n             self.uses_learning_phase = True\n \n-        super(ConvLSTM2D, self).__init__(**kwargs)\n-\n     def build(self, input_shape):\n         self.input_spec = [InputSpec(shape=input_shape)]\n \n@@ -507,9 +504,9 @@ class ConvLSTM2D(ConvRecurrent2D):\n         config = {'nb_filter': self.nb_filter,\n                   'nb_row': self.nb_row,\n                   'nb_col': self.nb_col,\n-                  'init': self.init.__name__,\n-                  'inner_init': self.inner_init.__name__,\n-                  'forget_bias_init': self.forget_bias_init.__name__,\n+                  'init': initializers.get_config(self.init),\n+                  'inner_init': initializers.get_config(self.inner_init),\n+                  'forget_bias_init': initializers.get_config(self.forget_bias_init),\n                   'activation': self.activation.__name__,\n                   'data_format': self.data_format,\n                   'border_mode': self.border_mode,\n\n@@ -16,10 +16,8 @@ from .. import regularizers\n from .. import constraints\n from ..engine import InputSpec\n from ..engine import Layer\n-from ..engine import Merge\n from ..utils.generic_utils import func_dump\n from ..utils.generic_utils import func_load\n-from ..utils.generic_utils import get_from_module\n \n \n class Masking(Layer):\n@@ -51,9 +49,9 @@ class Masking(Layer):\n     \"\"\"\n \n     def __init__(self, mask_value=0., **kwargs):\n+        super(Masking, self).__init__(**kwargs)\n         self.supports_masking = True\n         self.mask_value = mask_value\n-        super(Masking, self).__init__(**kwargs)\n \n     def compute_mask(self, x, input_mask=None):\n         return K.any(K.not_equal(x, self.mask_value), axis=-1)\n@@ -77,10 +75,10 @@ class Dropout(Layer):\n     which helps prevent overfitting.\n \n     # Arguments\n-        p: float between 0 and 1. Fraction of the input units to drop.\n+        rate: float between 0 and 1. Fraction of the input units to drop.\n         noise_shape: 1D integer tensor representing the shape of the\n             binary dropout mask that will be multiplied with the input.\n-            For instance, if your inputs ahve shape\n+            For instance, if your inputs have shape\n             `(batch_size, timesteps, features)` and\n             you want the dropout mask to be the same for all timesteps,\n             you can use `noise_shape=(batch_size, 1, features)`.\n@@ -90,29 +88,29 @@ class Dropout(Layer):\n         - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n     \"\"\"\n \n-    def __init__(self, p, noise_shape=None, seed=None, **kwargs):\n-        self.p = p\n+    def __init__(self, rate, noise_shape=None, seed=None, **kwargs):\n+        super(Dropout, self).__init__(**kwargs)\n+        self.rate = rate\n         self.noise_shape = noise_shape\n         self.seed = seed\n-        if 0. < self.p < 1.:\n+        if 0. < self.rate < 1.:\n             self.uses_learning_phase = True\n         self.supports_masking = True\n-        super(Dropout, self).__init__(**kwargs)\n \n     def _get_noise_shape(self, _):\n         return self.noise_shape\n \n     def call(self, x, mask=None):\n-        if 0. < self.p < 1.:\n+        if 0. < self.rate < 1.:\n             noise_shape = self._get_noise_shape(x)\n \n             def dropped_inputs():\n-                return K.dropout(x, self.p, noise_shape, seed=self.seed)\n+                return K.dropout(x, self.rate, noise_shape, seed=self.seed)\n             x = K.in_train_phase(dropped_inputs, lambda: x)\n         return x\n \n     def get_config(self):\n-        config = {'p': self.p}\n+        config = {'rate': self.rate}\n         base_config = super(Dropout, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -142,8 +140,8 @@ class SpatialDropout1D(Dropout):\n         - [Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)\n     \"\"\"\n \n-    def __init__(self, p, **kwargs):\n-        super(SpatialDropout1D, self).__init__(p, **kwargs)\n+    def __init__(self, rate, **kwargs):\n+        super(SpatialDropout1D, self).__init__(rate, **kwargs)\n \n     def _get_noise_shape(self, x):\n         input_shape = K.shape(x)\n@@ -163,9 +161,11 @@ class SpatialDropout2D(Dropout):\n     between feature maps and should be used instead.\n \n     # Arguments\n-        p: float between 0 and 1. Fraction of the input units to drop.\n-        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n-            (the depth) is at index 1, in 'channels_last' mode is it at index 3.\n+        rate: float between 0 and 1. Fraction of the input units to drop.\n+        data_format: 'channels_first' or 'channels_last'.\n+            In 'channels_first' mode, the channels dimension\n+            (the depth) is at index 1,\n+            in 'channels_last' mode is it at index 3.\n             It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n             If you never set it, then it will be \"channels_last\".\n@@ -183,12 +183,14 @@ class SpatialDropout2D(Dropout):\n         - [Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)\n     \"\"\"\n \n-    def __init__(self, p, data_format='default', **kwargs):\n-        if data_format == 'default':\n+    def __init__(self, rate, data_format=None, **kwargs):\n+        super(SpatialDropout2D, self).__init__(rate, **kwargs)\n+        if data_format is None:\n             data_format = K.image_data_format()\n-        assert data_format in {'channels_last', 'channels_first'}, 'data_format must be in {\"channels_last\", \"channels_first\"}'\n+        if data_format not in {'channels_last', 'channels_first'}:\n+            raise ValueError('data_format must be in '\n+                             '{\"channels_last\", \"channels_first\"}')\n         self.data_format = data_format\n-        super(SpatialDropout2D, self).__init__(p, **kwargs)\n \n     def _get_noise_shape(self, x):\n         input_shape = K.shape(x)\n@@ -213,7 +215,7 @@ class SpatialDropout3D(Dropout):\n     between feature maps and should be used instead.\n \n     # Arguments\n-        p: float between 0 and 1. Fraction of the input units to drop.\n+        rate: float between 0 and 1. Fraction of the input units to drop.\n         data_format: 'channels_first' or 'channels_last'.\n             In 'channels_first' mode, the channels dimension (the depth)\n             is at index 1, in 'channels_last' mode is it at index 4.\n@@ -234,12 +236,14 @@ class SpatialDropout3D(Dropout):\n         - [Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)\n     \"\"\"\n \n-    def __init__(self, p, data_format='default', **kwargs):\n-        if data_format == 'default':\n+    def __init__(self, rate, data_format=None, **kwargs):\n+        super(SpatialDropout3D, self).__init__(rate, **kwargs)\n+        if data_format is None:\n             data_format = K.image_data_format()\n-        assert data_format in {'channels_last', 'channels_first'}, 'data_format must be in {\"channels_last\", \"channels_first\"}'\n+        if data_format not in {'channels_last', 'channels_first'}:\n+            raise ValueError('data_format must be in '\n+                             '{\"channels_last\", \"channels_first\"}')\n         self.data_format = data_format\n-        super(SpatialDropout3D, self).__init__(p, **kwargs)\n \n     def _get_noise_shape(self, x):\n         input_shape = K.shape(x)\n@@ -270,15 +274,15 @@ class Activation(Layer):\n     \"\"\"\n \n     def __init__(self, activation, **kwargs):\n+        super(Activation, self).__init__(**kwargs)\n         self.supports_masking = True\n         self.activation = activations.get(activation)\n-        super(Activation, self).__init__(**kwargs)\n \n     def call(self, x, mask=None):\n         return self.activation(x)\n \n     def get_config(self):\n-        config = {'activation': self.activation.__name__}\n+        config = {'activation': activations.serialize(self.activation)}\n         base_config = super(Activation, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -428,8 +432,8 @@ class Permute(Layer):\n     \"\"\"\n \n     def __init__(self, dims, **kwargs):\n-        self.dims = tuple(dims)\n         super(Permute, self).__init__(**kwargs)\n+        self.dims = tuple(dims)\n \n     def get_output_shape_for(self, input_shape):\n         input_shape = list(input_shape)\n@@ -466,8 +470,8 @@ class Flatten(Layer):\n     \"\"\"\n \n     def __init__(self, **kwargs):\n-        self.input_spec = [InputSpec(ndim='3+')]\n         super(Flatten, self).__init__(**kwargs)\n+        self.input_spec = [InputSpec(ndim='3+')]\n \n     def get_output_shape_for(self, input_shape):\n         if not all(input_shape[1:]):\n@@ -509,9 +513,9 @@ class RepeatVector(Layer):\n     \"\"\"\n \n     def __init__(self, n, **kwargs):\n+        super(RepeatVector, self).__init__(**kwargs)\n         self.n = n\n         self.input_spec = [InputSpec(ndim=2)]\n-        super(RepeatVector, self).__init__(**kwargs)\n \n     def get_output_shape_for(self, input_shape):\n         return (input_shape[0], self.n, input_shape[1])\n@@ -526,7 +530,7 @@ class RepeatVector(Layer):\n \n \n class Lambda(Layer):\n-    \"\"\"Used for evaluating an arbitrary expressions on an input.\n+    \"\"\"Wraps arbitrary expression as a `Layer` object.\n \n     # Examples\n \n@@ -560,6 +564,7 @@ class Lambda(Layer):\n         function: The function to be evaluated.\n             Takes input tensor as first argument.\n         output_shape: Expected output shape from function.\n+            Only relevant when using Theano.\n             Can be a tuple or function.\n             If a tuple, it only specifies the first dimension onward;\n                  sample dimension is assumed either the same as the input:\n@@ -578,10 +583,12 @@ class Lambda(Layer):\n         when using this layer as the first layer in a model.\n \n     # Output shape\n-        Specified by `output_shape` argument.\n+        Specified by `output_shape` argument\n+        (or auto-inferred when using TensorFlow).\n     \"\"\"\n \n     def __init__(self, function, output_shape=None, arguments=None, **kwargs):\n+        super(Lambda, self).__init__(**kwargs)\n         self.function = function\n         self.arguments = arguments if arguments else {}\n         self.supports_masking = False\n@@ -595,7 +602,6 @@ class Lambda(Layer):\n                 raise TypeError('In Lambda, `output_shape` '\n                                 'must be a list, a tuple, or a function.')\n             self._output_shape = output_shape\n-        super(Lambda, self).__init__(**kwargs)\n \n     def get_output_shape_for(self, input_shape):\n         if self._output_shape is None:\n@@ -699,141 +705,141 @@ class Lambda(Layer):\n class Dense(Layer):\n     \"\"\"Just your regular densely-connected NN layer.\n \n+    `Dense` implements the operation:\n+    `output = activation(dot(input, kernel) + bias)`\n+    where `activation` is the element-wise activation function\n+    passed as the `activation` argument, `kernel` is a weights matrix\n+    created by the layer, and `bias` is a bias vector created by the layer\n+    (only applicable if `use_bias` is `True`).\n+\n+    Note: if the input to the layer has a rank greater than 2, then\n+    it is flattened prior to the initial dot product with `kernel`.\n+\n     # Example\n \n     ```python\n         # as first layer in a sequential model:\n         model = Sequential()\n-        model.add(Dense(32, input_dim=16))\n+        model.add(Dense(32, input_shape=(16,)))\n         # now the model will take as input arrays of shape (*, 16)\n         # and output arrays of shape (*, 32)\n \n-        # this is equivalent to the above:\n-        model = Sequential()\n-        model.add(Dense(32, input_shape=(16,)))\n-\n         # after the first layer, you don't need to specify\n         # the size of the input anymore:\n         model.add(Dense(32))\n     ```\n \n     # Arguments\n-        output_dim: int > 0.\n-        init: name of initializer function for the weights of the layer\n-            (see [initializers](../initializers.md)),\n-            or alternatively, Theano function to use for weights\n-            initializer. This parameter is only relevant\n-            if you don't pass a `weights` argument.\n-        activation: name of activation function to use\n-            (see [activations](../activations.md)),\n-            or alternatively, elementwise Theano function.\n+        units: Positive interger, dimensionality of the output space.\n+        activation: Activation function to use\n+            (see [activations](../activations.md)).\n             If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: a(x) = x).\n-        weights: list of Numpy arrays to set as initial weights.\n-            The list should have 2 elements, of shape `(input_dim, output_dim)`\n-            and (output_dim,) for weights and biases respectively.\n-        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n-            (eg. L1 or L2 regularization), applied to the main weights matrix.\n-        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n-            applied to the bias.\n-        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n-            applied to the network output.\n-        W_constraint: instance of the [constraints](../constraints.md) module\n-            (eg. maxnorm, nonneg), applied to the main weights matrix.\n-        b_constraint: instance of the [constraints](../constraints.md) module,\n-            applied to the bias.\n-        bias: whether to include a bias\n-            (i.e. make the layer affine rather than linear).\n-        input_dim: dimensionality of the input (integer). This argument\n-            (or alternatively, the keyword argument `input_shape`)\n-            is required when using this layer as the first layer in a model.\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        use_bias: Boolean, whether the layer uses a bias vector.\n+        kernel_initializer: Initializer for the `kernel` weights matrix\n+            (see [initializers](../initializers.md)).\n+        bias_initializer: Initializer for the bias vector\n+            (see [initializers](../initializers.md)).\n+        kernel_regularizer: Regularizer function applied to\n+            the `kernel` weights matrix\n+            (see [regularizer](../regularizers.md)).\n+        bias_regularizer: Regularizer function applied to the bias vector\n+            (see [regularizer](../regularizers.md)).\n+        activity_regularizer: Regularizer function applied to\n+            the output of the layer (its \"activation\").\n+            (see [regularizer](../regularizers.md)).\n+        kernel_constraint: Constraint function applied to\n+            the `kernel` weights matrix\n+            (see [constraints](../constraints.md)).\n+        bias_constraint: Constraint function applied to the bias vector\n+            (see [constraints](../constraints.md)).\n \n     # Input shape\n-        nD tensor with shape: `(nb_samples, ..., input_dim)`.\n+        nD tensor with shape: `(batch_size, ..., input_dim)`.\n         The most common situation would be\n-        a 2D input with shape `(nb_samples, input_dim)`.\n+        a 2D input with shape `(batch_size, input_dim)`.\n \n     # Output shape\n-        nD tensor with shape: `(nb_samples, ..., output_dim)`.\n-        For instance, for a 2D input with shape `(nb_samples, input_dim)`,\n-        the output would have shape `(nb_samples, output_dim)`.\n+        nD tensor with shape: `(batch_size, ..., units)`.\n+        For instance, for a 2D input with shape `(batch_size, input_dim)`,\n+        the output would have shape `(batch_size, units)`.\n     \"\"\"\n \n-    def __init__(self, output_dim, init='glorot_uniform',\n-                 activation=None, weights=None,\n-                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n-                 W_constraint=None, b_constraint=None,\n-                 bias=True, input_dim=None, **kwargs):\n-        self.init = initializers.get(init)\n-        self.activation = activations.get(activation)\n-        self.output_dim = output_dim\n-        self.input_dim = input_dim\n-\n-        self.W_regularizer = regularizers.get(W_regularizer)\n-        self.b_regularizer = regularizers.get(b_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-        self.W_constraint = constraints.get(W_constraint)\n-        self.b_constraint = constraints.get(b_constraint)\n-\n-        self.bias = bias\n-        self.initial_weights = weights\n-        self.input_spec = [InputSpec(ndim='2+')]\n-\n-        if self.input_dim:\n-            kwargs['input_shape'] = (self.input_dim,)\n+    def __init__(self, units,\n+                 activation=None,\n+                 use_bias=True,\n+                 kernel_initializer='glorot_uniform',\n+                 bias_initializer='zeros',\n+                 kernel_regularizer=None,\n+                 bias_regularizer=None,\n+                 activity_regularizer=None,\n+                 kernel_constraint=None,\n+                 bias_constraint=None,\n+                 **kwargs):\n         super(Dense, self).__init__(**kwargs)\n+        self.units = units\n+        self.activation = activations.get(activation)\n+        self.use_bias = use_bias\n+        self.kernel_initializer = initializers.get(kernel_initializer)\n+        self.bias_initializer = initializers.get(bias_initializer)\n+        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n+        self.bias_regularizer = regularizers.get(bias_regularizer)\n+        self.activity_regularizer = regularizers.get(activity_regularizer)\n+        self.kernel_constraint = constraints.get(kernel_constraint)\n+        self.bias_constraint = constraints.get(bias_constraint)\n+        self.input_spec = [InputSpec(ndim='2+')]\n+        self.supports_masking = True\n \n     def build(self, input_shape):\n         assert len(input_shape) >= 2\n+\n         input_dim = input_shape[-1]\n-        self.input_dim = input_dim\n+        # TODO: check last dim in input_dim\n         self.input_spec = [InputSpec(dtype=K.floatx(),\n                                      ndim='2+')]\n \n-        self.W = self.add_weight((input_dim, self.output_dim),\n-                                 initializer=self.init,\n-                                 name='{}_W'.format(self.name),\n-                                 regularizer=self.W_regularizer,\n-                                 constraint=self.W_constraint)\n-        if self.bias:\n-            self.b = self.add_weight((self.output_dim,),\n-                                     initializer='zero',\n-                                     name='{}_b'.format(self.name),\n-                                     regularizer=self.b_regularizer,\n-                                     constraint=self.b_constraint)\n+        self.kernel = self.add_weight((input_dim, self.units),\n+                                      initializer=self.kernel_initializer,\n+                                      name='kernel',\n+                                      regularizer=self.kernel_regularizer,\n+                                      constraint=self.kernel_constraint)\n+        if self.use_bias:\n+            self.bias = self.add_weight((self.units,),\n+                                        initializer=self.bias_initializer,\n+                                        name='bias',\n+                                        regularizer=self.bias_regularizer,\n+                                        constraint=self.bias_constraint)\n         else:\n-            self.b = None\n+            self.bias = None\n \n-        if self.initial_weights is not None:\n-            self.set_weights(self.initial_weights)\n-            del self.initial_weights\n-        self.built = True\n-\n-    def call(self, x, mask=None):\n-        output = K.dot(x, self.W)\n-        if self.bias:\n-            output += self.b\n-        return self.activation(output)\n+    def call(self, x):\n+        output = K.dot(x, self.kernel)\n+        if self.use_bias:\n+            output += self.bias\n+        if self.activation is not None:\n+            output = self.activation(output)\n+        return output\n \n     def get_output_shape_for(self, input_shape):\n         assert input_shape and len(input_shape) >= 2\n-        assert input_shape[-1] and input_shape[-1] == self.input_dim\n+        assert input_shape[-1]\n         output_shape = list(input_shape)\n-        output_shape[-1] = self.output_dim\n+        output_shape[-1] = self.units\n         return tuple(output_shape)\n \n     def get_config(self):\n-        config = {'output_dim': self.output_dim,\n-                  'init': self.init.__name__,\n-                  'activation': self.activation.__name__,\n-                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n-                  'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n-                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n-                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n-                  'b_constraint': self.b_constraint.get_config() if self.b_constraint else None,\n-                  'bias': self.bias,\n-                  'input_dim': self.input_dim}\n+        config = {\n+            'units': self.units,\n+            'activation': activations.serialize(self.activation),\n+            'use_bias': self.use_bias,\n+            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n+            'bias_initializer': initializers.serialize(self.kernel_initializer),\n+            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n+            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n+            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n+            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n+            'bias_constraint': constraints.serialize(self.bias_constraint)\n+        }\n         base_config = super(Dense, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -855,445 +861,14 @@ class ActivityRegularization(Layer):\n     \"\"\"\n \n     def __init__(self, l1=0., l2=0., **kwargs):\n+        super(ActivityRegularization, self).__init__(**kwargs)\n         self.supports_masking = True\n         self.l1 = l1\n         self.l2 = l2\n-\n-        super(ActivityRegularization, self).__init__(**kwargs)\n         self.activity_regularizer = regularizers.L1L2Regularizer(l1=l1, l2=l2)\n-        self.regularizers = [self.activity_regularizer]\n \n     def get_config(self):\n         config = {'l1': self.l1,\n                   'l2': self.l2}\n         base_config = super(ActivityRegularization, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class MaxoutDense(Layer):\n-    \"\"\"A dense maxout layer.\n-\n-    A `MaxoutDense` layer takes the element-wise maximum of\n-    `nb_feature` `Dense(input_dim, output_dim)` linear layers.\n-    This allows the layer to learn a convex,\n-    piecewise linear activation function over the inputs.\n-\n-    Note that this is a *linear* layer;\n-    if you wish to apply activation function\n-    (you shouldn't need to --they are universal function approximators),\n-    an `Activation` layer must be added after.\n-\n-    # Arguments\n-        output_dim: int > 0.\n-        nb_feature: number of Dense layers to use internally.\n-        init: name of initializer function for the weights of the layer\n-            (see [initializers](../initializers.md)),\n-            or alternatively, Theano function to use for weights\n-            initializer. This parameter is only relevant\n-            if you don't pass a `weights` argument.\n-        weights: list of Numpy arrays to set as initial weights.\n-            The list should have 2 elements, of shape `(input_dim, output_dim)`\n-            and (output_dim,) for weights and biases respectively.\n-        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n-            (eg. L1 or L2 regularization), applied to the main weights matrix.\n-        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n-            applied to the bias.\n-        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n-            applied to the network output.\n-        W_constraint: instance of the [constraints](../constraints.md) module\n-            (eg. maxnorm, nonneg), applied to the main weights matrix.\n-        b_constraint: instance of the [constraints](../constraints.md) module,\n-            applied to the bias.\n-        bias: whether to include a bias\n-            (i.e. make the layer affine rather than linear).\n-        input_dim: dimensionality of the input (integer). This argument\n-            (or alternatively, the keyword argument `input_shape`)\n-            is required when using this layer as the first layer in a model.\n-\n-    # Input shape\n-        2D tensor with shape: `(nb_samples, input_dim)`.\n-\n-    # Output shape\n-        2D tensor with shape: `(nb_samples, output_dim)`.\n-\n-    # References\n-        - [Maxout Networks](http://arxiv.org/abs/1302.4389)\n-    \"\"\"\n-\n-    def __init__(self, output_dim,\n-                 nb_feature=4,\n-                 init='glorot_uniform',\n-                 weights=None,\n-                 W_regularizer=None,\n-                 b_regularizer=None,\n-                 activity_regularizer=None,\n-                 W_constraint=None,\n-                 b_constraint=None,\n-                 bias=True,\n-                 input_dim=None,\n-                 **kwargs):\n-        self.output_dim = output_dim\n-        self.nb_feature = nb_feature\n-        self.init = initializers.get(init)\n-\n-        self.W_regularizer = regularizers.get(W_regularizer)\n-        self.b_regularizer = regularizers.get(b_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-        self.W_constraint = constraints.get(W_constraint)\n-        self.b_constraint = constraints.get(b_constraint)\n-\n-        self.bias = bias\n-        self.initial_weights = weights\n-        self.input_spec = [InputSpec(ndim=2)]\n-\n-        self.input_dim = input_dim\n-        if self.input_dim:\n-            kwargs['input_shape'] = (self.input_dim,)\n-        super(MaxoutDense, self).__init__(**kwargs)\n-\n-    def build(self, input_shape):\n-        input_dim = input_shape[1]\n-        self.input_spec = [InputSpec(dtype=K.floatx(),\n-                                     shape=(None, input_dim))]\n-\n-        self.W = self.add_weight((self.nb_feature, input_dim, self.output_dim),\n-                                 initializer=self.init,\n-                                 name='{}_W'.format(self.name),\n-                                 regularizer=self.W_regularizer,\n-                                 constraint=self.W_constraint)\n-        if self.bias:\n-            self.b = self.add_weight((self.nb_feature, self.output_dim,),\n-                                     initializer='zero',\n-                                     name='{}_b'.format(self.name),\n-                                     regularizer=self.b_regularizer,\n-                                     constraint=self.b_constraint)\n-        else:\n-            self.b = None\n-\n-        if self.initial_weights is not None:\n-            self.set_weights(self.initial_weights)\n-            del self.initial_weights\n-        self.built = True\n-\n-    def get_output_shape_for(self, input_shape):\n-        assert input_shape and len(input_shape) == 2\n-        return (input_shape[0], self.output_dim)\n-\n-    def call(self, x, mask=None):\n-        # no activation, this layer is only linear.\n-        output = K.dot(x, self.W)\n-        if self.bias:\n-            output += self.b\n-        output = K.max(output, axis=1)\n-        return output\n-\n-    def get_config(self):\n-        config = {'output_dim': self.output_dim,\n-                  'init': self.init.__name__,\n-                  'nb_feature': self.nb_feature,\n-                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n-                  'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n-                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n-                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n-                  'b_constraint': self.b_constraint.get_config() if self.b_constraint else None,\n-                  'bias': self.bias,\n-                  'input_dim': self.input_dim}\n-        base_config = super(MaxoutDense, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class Highway(Layer):\n-    \"\"\"Densely connected highway network.\n-\n-    Highway layers are a natural extension of LSTMs to feedforward networks.\n-\n-    # Arguments\n-        init: name of initializer function for the weights of the layer\n-            (see [initializers](../initializers.md)),\n-            or alternatively, Theano function to use for weights\n-            initializer. This parameter is only relevant\n-            if you don't pass a `weights` argument.\n-        activation: name of activation function to use\n-            (see [activations](../activations.md)),\n-            or alternatively, elementwise Theano function.\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: a(x) = x).\n-        weights: list of Numpy arrays to set as initial weights.\n-            The list should have 2 elements, of shape `(input_dim, output_dim)`\n-            and (output_dim,) for weights and biases respectively.\n-        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n-            (eg. L1 or L2 regularization), applied to the main weights matrix.\n-        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n-            applied to the bias.\n-        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n-            applied to the network output.\n-        W_constraint: instance of the [constraints](../constraints.md) module\n-            (eg. maxnorm, nonneg), applied to the main weights matrix.\n-        b_constraint: instance of the [constraints](../constraints.md) module,\n-            applied to the bias.\n-        bias: whether to include a bias\n-            (i.e. make the layer affine rather than linear).\n-        input_dim: dimensionality of the input (integer). This argument\n-            (or alternatively, the keyword argument `input_shape`)\n-            is required when using this layer as the first layer in a model.\n-\n-    # Input shape\n-        2D tensor with shape: `(nb_samples, input_dim)`.\n-\n-    # Output shape\n-        2D tensor with shape: `(nb_samples, input_dim)`.\n-\n-    # References\n-        - [Highway Networks](http://arxiv.org/abs/1505.00387v2)\n-    \"\"\"\n-\n-    def __init__(self,\n-                 init='glorot_uniform',\n-                 activation=None,\n-                 weights=None,\n-                 W_regularizer=None,\n-                 b_regularizer=None,\n-                 activity_regularizer=None,\n-                 W_constraint=None,\n-                 b_constraint=None,\n-                 bias=True,\n-                 input_dim=None,\n-                 **kwargs):\n-        if 'transform_bias' in kwargs:\n-            kwargs.pop('transform_bias')\n-            warnings.warn('`transform_bias` argument is deprecated and '\n-                          'will be removed after 5/2017.')\n-        self.init = initializers.get(init)\n-        self.activation = activations.get(activation)\n-\n-        self.W_regularizer = regularizers.get(W_regularizer)\n-        self.b_regularizer = regularizers.get(b_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-        self.W_constraint = constraints.get(W_constraint)\n-        self.b_constraint = constraints.get(b_constraint)\n-\n-        self.bias = bias\n-        self.initial_weights = weights\n-        self.input_spec = [InputSpec(ndim=2)]\n-\n-        self.input_dim = input_dim\n-        if self.input_dim:\n-            kwargs['input_shape'] = (self.input_dim,)\n-        super(Highway, self).__init__(**kwargs)\n-\n-    def build(self, input_shape):\n-        input_dim = input_shape[1]\n-        self.input_spec = [InputSpec(dtype=K.floatx(),\n-                                     shape=(None, input_dim))]\n-\n-        self.W = self.add_weight((input_dim, input_dim),\n-                                 initializer=self.init,\n-                                 name='{}_W'.format(self.name),\n-                                 regularizer=self.W_regularizer,\n-                                 constraint=self.W_constraint)\n-        self.W_carry = self.add_weight((input_dim, input_dim),\n-                                       initializer=self.init,\n-                                       name='{}_W_carry'.format(self.name))\n-        if self.bias:\n-            self.b = self.add_weight((input_dim,),\n-                                     initializer='zero',\n-                                     name='{}_b'.format(self.name),\n-                                     regularizer=self.b_regularizer,\n-                                     constraint=self.b_constraint)\n-            self.b_carry = self.add_weight((input_dim,),\n-                                           initializer='one',\n-                                           name='{}_b_carry'.format(self.name))\n-        else:\n-            self.b_carry = None\n-\n-        if self.initial_weights is not None:\n-            self.set_weights(self.initial_weights)\n-            del self.initial_weights\n-        self.built = True\n-\n-    def call(self, x, mask=None):\n-        y = K.dot(x, self.W_carry)\n-        if self.bias:\n-            y += self.b_carry\n-        transform_weight = activations.sigmoid(y)\n-        y = K.dot(x, self.W)\n-        if self.bias:\n-            y += self.b\n-        act = self.activation(y)\n-        act *= transform_weight\n-        output = act + (1 - transform_weight) * x\n-        return output\n-\n-    def get_config(self):\n-        config = {'init': self.init.__name__,\n-                  'activation': self.activation.__name__,\n-                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n-                  'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n-                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n-                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n-                  'b_constraint': self.b_constraint.get_config() if self.b_constraint else None,\n-                  'bias': self.bias,\n-                  'input_dim': self.input_dim}\n-        base_config = super(Highway, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class TimeDistributedDense(Layer):\n-    \"\"\"Apply a same Dense layer for each dimension[1] (time_dimension) input.\n-\n-    Especially useful after a recurrent network with 'return_sequence=True'.\n-\n-    Note: this layer is deprecated, prefer using the `TimeDistributed` wrapper:\n-    ```python\n-        model.add(TimeDistributed(Dense(32)))\n-    ```\n-\n-    # Input shape\n-        3D tensor with shape `(nb_sample, time_dimension, input_dim)`.\n-\n-    # Output shape\n-        3D tensor with shape `(nb_sample, time_dimension, output_dim)`.\n-\n-    # Arguments\n-        output_dim: int > 0.\n-        init: name of initializer function for the weights of the layer\n-            (see [initializers](../initializers.md)),\n-            or alternatively, Theano function to use for weights\n-            initializer. This parameter is only relevant\n-            if you don't pass a `weights` argument.\n-        activation: name of activation function to use\n-            (see [activations](../activations.md)),\n-            or alternatively, elementwise Theano function.\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: a(x) = x).\n-        weights: list of Numpy arrays to set as initial weights.\n-            The list should have 2 elements, of shape `(input_dim, output_dim)`\n-            and (output_dim,) for weights and biases respectively.\n-        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n-            (eg. L1 or L2 regularization), applied to the main weights matrix.\n-        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n-            applied to the bias.\n-        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n-            applied to the network output.\n-        W_constraint: instance of the [constraints](../constraints.md) module\n-            (eg. maxnorm, nonneg), applied to the main weights matrix.\n-        b_constraint: instance of the [constraints](../constraints.md) module,\n-            applied to the bias.\n-        bias: whether to include a bias\n-            (i.e. make the layer affine rather than linear).\n-        input_dim: dimensionality of the input (integer). This argument\n-            (or alternatively, the keyword argument `input_shape`)\n-            is required when using this layer as the first layer in a model.\n-        input_length: length of inputs sequences\n-            (integer, or None for variable-length sequences).\n-    \"\"\"\n-\n-    def __init__(self, output_dim,\n-                 init='glorot_uniform',\n-                 activation=None,\n-                 weights=None,\n-                 W_regularizer=None,\n-                 b_regularizer=None,\n-                 activity_regularizer=None,\n-                 W_constraint=None,\n-                 b_constraint=None,\n-                 bias=True,\n-                 input_dim=None,\n-                 input_length=None,\n-                 **kwargs):\n-        warnings.warn('`TimeDistributedDense` is deprecated, '\n-                      'And will be removed on May 1st, 2017. '\n-                      'Please use a `Dense` layer instead.')\n-        self.output_dim = output_dim\n-        self.init = initializers.get(init)\n-        self.activation = activations.get(activation)\n-\n-        self.W_regularizer = regularizers.get(W_regularizer)\n-        self.b_regularizer = regularizers.get(b_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-        self.W_constraint = constraints.get(W_constraint)\n-        self.b_constraint = constraints.get(b_constraint)\n-\n-        self.bias = bias\n-        self.initial_weights = weights\n-        self.input_spec = [InputSpec(ndim=3)]\n-        self.supports_masking = True\n-\n-        self.input_dim = input_dim\n-        self.input_length = input_length\n-        if self.input_dim:\n-            kwargs['input_shape'] = (self.input_length, self.input_dim)\n-        super(TimeDistributedDense, self).__init__(**kwargs)\n-\n-    def build(self, input_shape):\n-        self.input_spec = [InputSpec(dtype=K.floatx(),\n-                                     shape=(None,) + input_shape[1:])]\n-        input_dim = input_shape[2]\n-\n-        self.W = self.add_weight((input_dim, self.output_dim),\n-                                 initializer=self.init,\n-                                 name='{}_W'.format(self.name),\n-                                 regularizer=self.W_regularizer,\n-                                 constraint=self.W_constraint)\n-        if self.bias:\n-            self.b = self.add_weight((self.output_dim,),\n-                                     initializer='zero',\n-                                     name='{}_b'.format(self.name),\n-                                     regularizer=self.b_regularizer,\n-                                     constraint=self.b_constraint)\n-        else:\n-            self.b = None\n-\n-        if self.initial_weights is not None:\n-            self.set_weights(self.initial_weights)\n-            del self.initial_weights\n-        self.built = True\n-\n-    def get_output_shape_for(self, input_shape):\n-        return (input_shape[0], input_shape[1], self.output_dim)\n-\n-    def call(self, x, mask=None):\n-        input_shape = self.input_spec[0].shape\n-        # x has shape (samples, timesteps, input_dim)\n-        input_length = input_shape[1]\n-        if not input_length:\n-            if hasattr(K, 'int_shape'):\n-                input_length = K.int_shape(x)[1]\n-                if not input_length:\n-                    raise ValueError('Layer ' + self.name +\n-                                     ' requires to know the length '\n-                                     'of its input, but it could not '\n-                                     'be inferred automatically. '\n-                                     'Specify it manually by passing '\n-                                     'an input_shape argument to '\n-                                     'the first layer in your model.')\n-            else:\n-                input_length = K.shape(x)[1]\n-\n-        # Squash samples and timesteps into a single axis\n-        x = K.reshape(x, (-1, input_shape[-1]))  # (samples * timesteps, input_dim)\n-        y = K.dot(x, self.W)  # (samples * timesteps, output_dim)\n-        if self.bias:\n-            y += self.b\n-        # We have to reshape Y to (samples, timesteps, output_dim)\n-        y = K.reshape(y, (-1, input_length, self.output_dim))  # (samples, timesteps, output_dim)\n-        y = self.activation(y)\n-        return y\n-\n-    def get_config(self):\n-        config = {'output_dim': self.output_dim,\n-                  'init': self.init.__name__,\n-                  'activation': self.activation.__name__,\n-                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n-                  'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n-                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n-                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n-                  'b_constraint': self.b_constraint.get_config() if self.b_constraint else None,\n-                  'bias': self.bias,\n-                  'input_dim': self.input_dim,\n-                  'input_length': self.input_length}\n-        base_config = super(TimeDistributedDense, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n\n@@ -33,74 +33,64 @@ class Embedding(Layer):\n       input_dim: int > 0. Size of the vocabulary, ie.\n           1 + maximum integer index occurring in the input data.\n       output_dim: int >= 0. Dimension of the dense embedding.\n-      init: name of initializer function for the weights\n-          of the layer (see: [initializers](../initializers.md)),\n-          or alternatively, Theano function to use for weights initializer.\n-          This parameter is only relevant if you don't pass a `weights` argument.\n-      weights: list of Numpy arrays to set as initial weights.\n-          The list should have 1 element, of shape `(input_dim, output_dim)`.\n-      W_regularizer: instance of the [regularizers](../regularizers.md) module\n-        (eg. L1 or L2 regularization), applied to the embedding matrix.\n-      W_constraint: instance of the [constraints](../constraints.md) module\n-          (eg. maxnorm, nonneg), applied to the embedding matrix.\n+      embeddings_initializer: Initializer for the `embeddings` matrix\n+            (see [initializers](../initializers.md)).\n+      embeddings_regularizer: Regularizer function applied to\n+            the `embeddings` matrix\n+            (see [regularizer](../regularizers.md)).\n+      embeddings_constraint: Constraint function applied to\n+            the `embeddings` matrix\n+            (see [constraints](../constraints.md)).\n       mask_zero: Whether or not the input value 0 is a special \"padding\"\n           value that should be masked out.\n-          This is useful for [recurrent layers](recurrent.md) which may take\n-          variable length input. If this is `True` then all subsequent layers\n+          This is useful when using [recurrent layers](recurrent.md)\n+          which may take variable length input.\n+          If this is `True` then all subsequent layers\n           in the model need to support masking or an exception will be raised.\n           If mask_zero is set to True, as a consequence, index 0 cannot be\n-          used in the vocabulary (input_dim should equal |vocabulary| + 2).\n+          used in the vocabulary (input_dim should equal `|vocabulary| + 2`).\n       input_length: Length of input sequences, when it is constant.\n           This argument is required if you are going to connect\n           `Flatten` then `Dense` layers upstream\n           (without it, the shape of the dense outputs cannot be computed).\n-      dropout: float between 0 and 1. Fraction of the embeddings to drop.\n \n     # Input shape\n-        2D tensor with shape: `(nb_samples, sequence_length)`.\n+        2D tensor with shape: `(batch_size, sequence_length)`.\n \n     # Output shape\n-        3D tensor with shape: `(nb_samples, sequence_length, output_dim)`.\n+        3D tensor with shape: `(batch_size, sequence_length, output_dim)`.\n \n     # References\n         - [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)\n     \"\"\"\n \n     def __init__(self, input_dim, output_dim,\n-                 init='uniform', input_length=None,\n-                 W_regularizer=None, activity_regularizer=None,\n-                 W_constraint=None,\n+                 embeddings_initializer='uniform',\n+                 embeddings_regularizer=None,\n+                 activity_regularizer=None,\n+                 embeddings_constraint=None,\n                  mask_zero=False,\n-                 weights=None, dropout=0., **kwargs):\n-        self.input_dim = input_dim\n-        self.output_dim = output_dim\n-        self.init = initializers.get(init)\n-        self.input_length = input_length\n-        self.mask_zero = mask_zero\n-        self.dropout = dropout\n-\n-        self.W_constraint = constraints.get(W_constraint)\n-\n-        self.W_regularizer = regularizers.get(W_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-        if 0. < self.dropout < 1.:\n-            self.uses_learning_phase = True\n-        self.initial_weights = weights\n-        kwargs['input_shape'] = (self.input_length,)\n+                 input_length=None,\n+                 **kwargs):\n         kwargs['input_dtype'] = 'int32'\n         super(Embedding, self).__init__(**kwargs)\n \n-    def build(self, input_shape):\n-        self.W = self.add_weight((self.input_dim, self.output_dim),\n-                                 initializer=self.init,\n-                                 name='{}_W'.format(self.name),\n-                                 regularizer=self.W_regularizer,\n-                                 constraint=self.W_constraint)\n+        self.input_dim = input_dim\n+        self.output_dim = output_dim\n+        self.embeddings_initializer = initializers.get(embeddings_initializer)\n+        self.embeddings_regularizer = regularizers.get(embeddings_regularizer)\n+        self.activity_regularizer = regularizers.get(activity_regularizer)\n+        self.embeddings_constraint = constraints.get(embeddings_constraint)\n+        self.mask_zero = mask_zero\n+        self.input_length = input_length\n \n-        if self.initial_weights is not None:\n-            self.set_weights(self.initial_weights)\n-        self.built = True\n+    def build(self, input_shape):\n+        self.embeddings = self.add_weight(\n+            (self.input_dim, self.output_dim),\n+            initializer=self.embeddings_initializer,\n+            name='embeddings',\n+            regularizer=self.embeddings_regularizer,\n+            constraint=self.embeddings_constraint)\n \n     def compute_mask(self, x, mask=None):\n         if not self.mask_zero:\n@@ -118,25 +108,17 @@ class Embedding(Layer):\n     def call(self, x, mask=None):\n         if K.dtype(x) != 'int32':\n             x = K.cast(x, 'int32')\n-        if 0. < self.dropout < 1.:\n-            retain_p = 1. - self.dropout\n-            B = K.random_binomial((self.input_dim,), p=retain_p) * (1. / retain_p)\n-            B = K.expand_dims(B)\n-            W = K.in_train_phase(self.W * B, self.W)\n-        else:\n-            W = self.W\n-        out = K.gather(W, x)\n+        out = K.gather(self.embeddings, x)\n         return out\n \n     def get_config(self):\n         config = {'input_dim': self.input_dim,\n                   'output_dim': self.output_dim,\n-                  'init': self.init.__name__,\n-                  'input_length': self.input_length,\n+                  'embeddings_initializer': initializers.serialize(self.embeddings_initializer),\n+                  'embeddings_regularizer': regularizers.serialize(self.embeddings_regularizer),\n+                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n+                  'embeddings_constraint': constraints.serialize(self.embeddings_constraint),\n                   'mask_zero': self.mask_zero,\n-                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n-                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n-                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n-                  'dropout': self.dropout}\n+                  'input_length': self.input_length}\n         base_config = super(Embedding, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n\n@@ -8,7 +8,7 @@ from .. import regularizers\n from .. import constraints\n from ..engine import Layer\n from ..engine import InputSpec\n-from ..utils.np_utils import conv_output_length\n+from ..utils.conv_utils import conv_output_length\n \n \n class LocallyConnected1D(Layer):\n@@ -168,7 +168,7 @@ class LocallyConnected1D(Layer):\n     def get_config(self):\n         config = {'nb_filter': self.nb_filter,\n                   'filter_length': self.filter_length,\n-                  'init': self.init.__name__,\n+                  'init': initializers.get_config(self.init),\n                   'activation': self.activation.__name__,\n                   'border_mode': self.border_mode,\n                   'subsample_length': self.subsample_length,\n@@ -407,7 +407,7 @@ class LocallyConnected2D(Layer):\n         config = {'nb_filter': self.nb_filter,\n                   'nb_row': self.nb_row,\n                   'nb_col': self.nb_col,\n-                  'init': self.init.__name__,\n+                  'init': initializers.get_config(self.init),\n                   'activation': self.activation.__name__,\n                   'border_mode': self.border_mode,\n                   'subsample': self.subsample,\n\n@@ -4,7 +4,7 @@ from __future__ import absolute_import\n from .. import backend as K\n from ..engine import Layer\n from ..engine import InputSpec\n-from ..utils.np_utils import conv_output_length\n+from ..utils.conv_utils import conv_output_length\n \n \n class _Pooling1D(Layer):\n\n@@ -166,6 +166,11 @@ class Recurrent(Layer):\n                  return_sequences=False, go_backwards=False, stateful=False,\n                  unroll=False, consume_less='cpu',\n                  input_dim=None, input_length=None, **kwargs):\n+        self.input_dim = input_dim\n+        self.input_length = input_length\n+        if self.input_dim:\n+            kwargs['input_shape'] = (self.input_length, self.input_dim)\n+        super(Recurrent, self).__init__(**kwargs)\n         self.return_sequences = return_sequences\n         self.initial_weights = weights\n         self.go_backwards = go_backwards\n@@ -175,11 +180,6 @@ class Recurrent(Layer):\n \n         self.supports_masking = True\n         self.input_spec = [InputSpec(ndim=3)]\n-        self.input_dim = input_dim\n-        self.input_length = input_length\n-        if self.input_dim:\n-            kwargs['input_shape'] = (self.input_length, self.input_dim)\n-        super(Recurrent, self).__init__(**kwargs)\n \n     def get_output_shape_for(self, input_shape):\n         if self.return_sequences:\n@@ -299,6 +299,7 @@ class SimpleRNN(Recurrent):\n                  activation='tanh',\n                  W_regularizer=None, U_regularizer=None, b_regularizer=None,\n                  dropout_W=0., dropout_U=0., **kwargs):\n+        super(SimpleRNN, self).__init__(**kwargs)\n         self.output_dim = output_dim\n         self.init = initializers.get(init)\n         self.inner_init = initializers.get(inner_init)\n@@ -311,7 +312,6 @@ class SimpleRNN(Recurrent):\n \n         if self.dropout_W or self.dropout_U:\n             self.uses_learning_phase = True\n-        super(SimpleRNN, self).__init__(**kwargs)\n \n     def build(self, input_shape):\n         self.input_spec = [InputSpec(shape=input_shape)]\n@@ -407,8 +407,8 @@ class SimpleRNN(Recurrent):\n \n     def get_config(self):\n         config = {'output_dim': self.output_dim,\n-                  'init': self.init.__name__,\n-                  'inner_init': self.inner_init.__name__,\n+                  'init': initializers.get_config(self.init),\n+                  'inner_init': initializers.get_config(self.inner_init),\n                   'activation': self.activation.__name__,\n                   'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n                   'U_regularizer': self.U_regularizer.get_config() if self.U_regularizer else None,\n@@ -452,6 +452,7 @@ class GRU(Recurrent):\n                  activation='tanh', inner_activation='hard_sigmoid',\n                  W_regularizer=None, U_regularizer=None, b_regularizer=None,\n                  dropout_W=0., dropout_U=0., **kwargs):\n+        super(GRU, self).__init__(**kwargs)\n         self.output_dim = output_dim\n         self.init = initializers.get(init)\n         self.inner_init = initializers.get(inner_init)\n@@ -465,7 +466,6 @@ class GRU(Recurrent):\n \n         if self.dropout_W or self.dropout_U:\n             self.uses_learning_phase = True\n-        super(GRU, self).__init__(**kwargs)\n \n     def build(self, input_shape):\n         self.input_spec = [InputSpec(shape=input_shape)]\n@@ -627,8 +627,8 @@ class GRU(Recurrent):\n \n     def get_config(self):\n         config = {'output_dim': self.output_dim,\n-                  'init': self.init.__name__,\n-                  'inner_init': self.inner_init.__name__,\n+                  'init': initializers.get_config(self.init),\n+                  'inner_init': initializers.get_config(self.inner_init),\n                   'activation': self.activation.__name__,\n                   'inner_activation': self.inner_activation.__name__,\n                   'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n@@ -681,6 +681,7 @@ class LSTM(Recurrent):\n                  inner_activation='hard_sigmoid',\n                  W_regularizer=None, U_regularizer=None, b_regularizer=None,\n                  dropout_W=0., dropout_U=0., **kwargs):\n+        super(LSTM, self).__init__(**kwargs)\n         self.output_dim = output_dim\n         self.init = initializers.get(init)\n         self.inner_init = initializers.get(inner_init)\n@@ -695,7 +696,6 @@ class LSTM(Recurrent):\n \n         if self.dropout_W or self.dropout_U:\n             self.uses_learning_phase = True\n-        super(LSTM, self).__init__(**kwargs)\n \n     def build(self, input_shape):\n         self.input_spec = [InputSpec(shape=input_shape)]\n@@ -890,9 +890,9 @@ class LSTM(Recurrent):\n \n     def get_config(self):\n         config = {'output_dim': self.output_dim,\n-                  'init': self.init.__name__,\n-                  'inner_init': self.inner_init.__name__,\n-                  'forget_bias_init': self.forget_bias_init.__name__,\n+                  'init': initializers.get_config(self.init),\n+                  'inner_init': initializers.get_config(self.inner_init),\n+                  'forget_bias_init': initializers.get_config(self.forget_bias_init),\n                   'activation': self.activation.__name__,\n                   'inner_activation': self.inner_activation.__name__,\n                   'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n\n@@ -1,7 +1,7 @@\n from __future__ import absolute_import\n-\n+import six\n from . import backend as K\n-from .utils.generic_utils import get_from_module\n+from .utils.generic_utils import deserialize_keras_object\n \n \n def mean_squared_error(y_true, y_pred):\n@@ -71,5 +71,23 @@ kld = KLD = kullback_leibler_divergence\n cosine = cosine_proximity\n \n \n+def serialize(loss):\n+    return loss.__name__\n+\n+\n+def deserialize(name, custom_objects=None):\n+    return deserialize_keras_object(name,\n+                                    module_objects=globals(),\n+                                    custom_objects=custom_objects,\n+                                    printable_module_name='loss function')\n+\n+\n def get(identifier):\n-    return get_from_module(identifier, globals(), 'objective')\n+    if isinstance(identifier, six.string_types):\n+        identifier = str(identifier)\n+        return deserialize(identifier)\n+    elif callable(identifier):\n+        return identifier\n+    else:\n+        raise ValueError('Could not interpret '\n+                         'loss function identifier:', identifier)\n\n@@ -1,5 +1,7 @@\n+from __future__ import absolute_import\n+import six\n from . import backend as K\n-from .utils.generic_utils import get_from_module\n+from .utils.generic_utils import deserialize_keras_object\n \n \n def binary_accuracy(y_true, y_pred):\n@@ -86,5 +88,23 @@ msle = MSLE = mean_squared_logarithmic_error\n cosine = cosine_proximity\n \n \n+def serialize(metric):\n+    return metric.__name__\n+\n+\n+def deserialize(name, custom_objects=None):\n+    return deserialize_keras_object(name,\n+                                    module_objects=globals(),\n+                                    custom_objects=custom_objects,\n+                                    printable_module_name='metric function')\n+\n+\n def get(identifier):\n-    return get_from_module(identifier, globals(), 'metric')\n+    if isinstance(identifier, six.string_types):\n+        identifier = str(identifier)\n+        return deserialize(identifier)\n+    elif callable(identifier):\n+        return identifier\n+    else:\n+        raise ValueError('Could not interpret '\n+                         'metric function identifier:', identifier)\n\n@@ -10,7 +10,6 @@ from . import optimizers\n from .utils.io_utils import ask_to_proceed_with_overwrite\n from .engine.training import Model\n from .engine.topology import get_source_inputs, Node, Layer, Merge\n-from .optimizers import optimizer_from_config\n \n \n def save_model(model, filepath, overwrite=True):\n@@ -153,7 +152,7 @@ def load_model(filepath, custom_objects=None):\n         return model\n     training_config = json.loads(training_config.decode('utf-8'))\n     optimizer_config = training_config['optimizer_config']\n-    optimizer = optimizer_from_config(optimizer_config,\n+    optimizer = optimizers.deserialize(optimizer_config,\n                                        custom_objects=custom_objects)\n \n     # recover loss functions and metrics\n\n@@ -1,9 +1,10 @@\n from __future__ import absolute_import\n-\n+import six\n from six.moves import zip\n \n from . import backend as K\n-from .utils.generic_utils import get_from_module, get_custom_objects\n+from .utils.generic_utils import serialize_keras_object\n+from .utils.generic_utils import deserialize_keras_object\n \n if K.backend() == 'tensorflow':\n     import tensorflow as tf\n@@ -15,42 +16,6 @@ def clip_norm(g, c, n):\n     return g\n \n \n-def optimizer_from_config(config, custom_objects=None):\n-    \"\"\"Instantiate an optimizer given a config dictionary.\n-\n-    # Arguments\n-        config: Config dictionary\n-            (e.g. output of `optimizer.get_config()`).\n-        custom_objects: Optional dictionary of custom optimizer classes.\n-\n-    # Returns\n-        An optimizer instance.\n-\n-    # Raises\n-        ValueError: in case of invalid optimizer config.\n-    \"\"\"\n-    all_classes = {\n-        'sgd': SGD,\n-        'rmsprop': RMSprop,\n-        'adagrad': Adagrad,\n-        'adadelta': Adadelta,\n-        'adam': Adam,\n-        'adamax': Adamax,\n-        'nadam': Nadam,\n-        'tfoptimizer': TFOptimizer,\n-    }\n-    class_name = config['class_name']\n-    if custom_objects and class_name in custom_objects:\n-        cls = custom_objects[class_name]\n-    elif class_name in get_custom_objects():\n-        cls = get_custom_objects()[class_name]\n-    else:\n-        if class_name.lower() not in all_classes:\n-            raise ValueError('Optimizer class not found:', class_name)\n-        cls = all_classes[class_name.lower()]\n-    return cls.from_config(config['config'])\n-\n-\n class Optimizer(object):\n     \"\"\"Abstract optimizer base class.\n \n@@ -652,11 +617,39 @@ adamax = Adamax\n nadam = Nadam\n \n \n-def get(identifier, kwargs=None):\n+def serialize(optimizer):\n+    return serialize_keras_object(optimizer)\n+\n+\n+def deserialize(config, custom_objects=None):\n+    all_classes = {\n+        'sgd': SGD,\n+        'rmsprop': RMSprop,\n+        'adagrad': Adagrad,\n+        'adadelta': Adadelta,\n+        'adam': Adam,\n+        'adamax': Adamax,\n+        'nadam': Nadam,\n+        'tfoptimizer': TFOptimizer,\n+    }\n+    deserialize_keras_object(config,\n+                             module_objects=all_classes,\n+                             custom_objects=custom_objects,\n+                             printable_module_name='optimizer')\n+\n+\n+def get(identifier):\n     if K.backend() == 'tensorflow':\n         # Wrap TF optimizer instances\n         if isinstance(identifier, tf.train.Optimizer):\n             return TFOptimizer(identifier)\n-    # Instantiate a Keras optimizer\n-    return get_from_module(identifier, globals(), 'optimizer',\n-                           instantiate=True, kwargs=kwargs)\n+    if isinstance(identifier, dict):\n+        return deserialize(identifier)\n+    elif isinstance(identifier, six.string_types):\n+        config = {'class_name': str(identifier), 'config': {}}\n+        return deserialize(config)\n+    if isinstance(identifier, Optimizer):\n+        return identifier\n+    else:\n+        raise ValueError('Could not interpret optimizer identifier:',\n+                         identifier)\n\n@@ -1,6 +1,8 @@\n from __future__ import absolute_import\n+import six\n from . import backend as K\n-from .utils.generic_utils import get_from_module\n+from .utils.generic_utils import serialize_keras_object\n+from .utils.generic_utils import deserialize_keras_object\n \n \n class Regularizer(object):\n@@ -10,6 +12,10 @@ class Regularizer(object):\n     def __call__(self, x):\n         return 0.\n \n+    @classmethod\n+    def from_config(cls, config):\n+        return cls(**config)\n+\n \n class L1L2(Regularizer):\n     \"\"\"Regularizer for L1 and L2 regularization.\n@@ -32,8 +38,7 @@ class L1L2(Regularizer):\n         return regularization\n \n     def get_config(self):\n-        return {'name': self.__class__.__name__,\n-                'l1': float(self.l1),\n+        return {'l1': float(self.l1),\n                 'l2': float(self.l2)}\n \n \n@@ -48,10 +53,31 @@ def l2(l=0.01):\n     return L1L2(l2=l)\n \n \n-def l1l2(l1=0.01, l2=0.01):\n+def l1_l2(l1=0.01, l2=0.01):\n     return L1L2(l1=l1, l2=l2)\n \n \n-def get(identifier, kwargs=None):\n-    return get_from_module(identifier, globals(), 'regularizer',\n-                           instantiate=True, kwargs=kwargs)\n+def serialize(regularizer):\n+    return serialize_keras_object(regularizer)\n+\n+\n+def deserialize(config, custom_objects=None):\n+    return deserialize_keras_object(config,\n+                                    module_objects=globals(),\n+                                    custom_objects=custom_objects,\n+                                    printable_module_name='regularizer')\n+\n+\n+def get(identifier):\n+    if identifier is None:\n+        return None\n+    if isinstance(identifier, dict):\n+        return deserialize(identifier)\n+    elif isinstance(identifier, six.string_types):\n+        config = {'class_name': str(identifier), 'config': {}}\n+        return deserialize(config)\n+    elif callable(identifier):\n+        return identifier\n+    else:\n+        raise ValueError('Could not interpret regularizer identifier:',\n+                         identifier)\n\n@@ -0,0 +1,152 @@\n+from six.moves import range\n+import numpy as np\n+from .. import backend as K\n+\n+\n+def normalize_tuple(value, n, name):\n+    \"\"\"Transforms a single int or iterable of ints into an int tuple.\n+\n+    # Arguments\n+        value: The value to validate and convert. Could an int, or any iterable\n+          of ints.\n+        n: The size of the tuple to be returned.\n+        name: The name of the argument being validated, e.g. \"strides\" or\n+          \"kernel_size\". This is only used to format error messages.\n+\n+    # Returns\n+        A tuple of n integers.\n+\n+    # Raises\n+        ValueError: If something else than an int/long or iterable thereof was\n+        passed.\n+    \"\"\"\n+    if isinstance(value, int):\n+        return (value,) * n\n+    else:\n+        try:\n+            value_tuple = tuple(value)\n+        except TypeError:\n+            raise ValueError('The `' + name + '` argument must be a tuple of ' +\n+                             str(n) + ' integers. Received: ' + str(value))\n+        if len(value_tuple) != n:\n+            raise ValueError('The `' + name + '` argument must be a tuple of ' +\n+                             str(n) + ' integers. Received: ' + str(value))\n+        for single_value in value_tuple:\n+            try:\n+                int(single_value)\n+            except ValueError:\n+                raise ValueError('The `' + name + '` argument must be a tuple of ' +\n+                                 str(n) + ' integers. Received: ' + str(value) + ' '\n+                                 'including element ' + str(single_value) + ' of type' +\n+                                 ' ' + str(type(single_value)))\n+    return value_tuple\n+\n+\n+def normalize_data_format(value):\n+    if value is None:\n+        value = K.image_data_format()\n+    data_format = value.lower()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('The `data_format` argument must be one of '\n+                         '\"channels_first\", \"channels_last\". Received: ' +\n+                         str(value))\n+    return data_format\n+\n+\n+def normalize_padding(value):\n+    padding = value.lower()\n+    if padding not in {'valid', 'same'}:\n+        raise ValueError('The `padding` argument must be one of \"valid\", \"same\". '\n+                         'Received: ' + str(padding))\n+    return padding\n+\n+\n+def convert_kernel(kernel, data_format=None):\n+    \"\"\"Converts a Numpy kernel matrix from Theano format to TensorFlow format.\n+\n+    Also works reciprocally, since the transformation is its own inverse.\n+\n+    # Arguments\n+        kernel: Numpy array (4D or 5D).\n+        data_format: the data format.\n+\n+    # Returns\n+        The converted kernel.\n+\n+    # Raises\n+        ValueError: in case of invalid kernel shape or invalid data_format.\n+    \"\"\"\n+    if data_format is None:\n+        data_format = K.image_data_format()\n+    if not 4 <= kernel.ndim <= 5:\n+        raise ValueError('Invalid kernel shape:', kernel.shape)\n+\n+    slices = [slice(None, None, -1) for _ in range(kernel.ndim)]\n+    no_flip = (slice(None, None), slice(None, None))\n+    if data_format == 'channels_first':  # (out_depth, input_depth, ...)\n+        slices[:2] = no_flip\n+    elif data_format == 'channels_last':  # (..., input_depth, out_depth)\n+        slices[-2:] = no_flip\n+    else:\n+        raise ValueError('Invalid data_format:', data_format)\n+\n+    return np.copy(kernel[slices])\n+\n+\n+def conv_output_length(input_length, filter_size,\n+                       padding, stride, dilation=1):\n+    \"\"\"Determines output length of a convolution given input length.\n+\n+    # Arguments\n+        input_length: integer.\n+        filter_size: integer.\n+        padding: one of \"same\", \"valid\", \"full\".\n+        stride: integer.\n+        dilation: dilation rate, integer.\n+\n+    # Returns\n+        The output length (integer).\n+    \"\"\"\n+    if input_length is None:\n+        return None\n+    assert padding in {'same', 'valid', 'full'}\n+    dilated_filter_size = filter_size + (filter_size - 1) * (dilation - 1)\n+    if padding == 'same':\n+        output_length = input_length\n+    elif padding == 'valid':\n+        output_length = input_length - dilated_filter_size + 1\n+    elif padding == 'full':\n+        output_length = input_length + dilated_filter_size - 1\n+    return (output_length + stride - 1) // stride\n+\n+\n+def conv_input_length(output_length, filter_size, padding, stride):\n+    \"\"\"Determines input length of a convolution given output length.\n+\n+    # Arguments\n+        output_length: integer.\n+        filter_size: integer.\n+        padding: one of \"same\", \"valid\", \"full\".\n+        stride: integer.\n+\n+    # Returns\n+        The input length (integer).\n+    \"\"\"\n+    if output_length is None:\n+        return None\n+    assert padding in {'same', 'valid', 'full'}\n+    if padding == 'same':\n+        pad = filter_size // 2\n+    elif padding == 'valid':\n+        pad = 0\n+    elif padding == 'full':\n+        pad = filter_size - 1\n+    return (output_length - 1) * stride - 2 * pad + filter_size\n+\n+\n+def deconv_length(dim_size, stride_size, kernel_size, padding):\n+    if dim_size is not None:\n+        dim_size *= stride_size\n+    if padding == 'valid' and dim_size is not None:\n+        dim_size += max(kernel_size - stride_size, 0)\n+    return dim_size\n\n@@ -8,6 +8,7 @@ import sys\n import six\n import marshal\n import types as python_types\n+import inspect\n \n _GLOBAL_CUSTOM_OBJECTS = {}\n \n@@ -89,59 +90,67 @@ def get_custom_objects():\n     return _GLOBAL_CUSTOM_OBJECTS\n \n \n-def get_from_module(identifier, module_params, module_name,\n-                    instantiate=False, kwargs=None):\n-    \"\"\"Retrieves a class or function member of a module.\n-\n-    First checks `_GLOBAL_CUSTOM_OBJECTS` for `module_name`, then checks `module_params`.\n-\n-    # Arguments\n-        identifier: the object to retrieve. It could be specified\n-            by name (as a string), or by dict. In any other case,\n-            `identifier` itself will be returned without any changes.\n-        module_params: the members of a module\n-            (e.g. the output of `globals()`).\n-        module_name: string; the name of the target module. Only used\n-            to format error messages.\n-        instantiate: whether to instantiate the returned object\n-            (if it's a class).\n-        kwargs: a dictionary of keyword arguments to pass to the\n-            class constructor if `instantiate` is `True`.\n-\n-    # Returns\n-        The target object.\n-\n-    # Raises\n-        ValueError: if the identifier cannot be found.\n-    \"\"\"\n-    if isinstance(identifier, six.string_types):\n-        res = None\n-        if identifier in _GLOBAL_CUSTOM_OBJECTS:\n-            res = _GLOBAL_CUSTOM_OBJECTS[identifier]\n-        if not res:\n-            res = module_params.get(identifier)\n-        if not res:\n-            raise ValueError('Invalid ' + str(module_name) + ': ' +\n-                             str(identifier))\n-        if instantiate and not kwargs:\n-            return res()\n-        elif instantiate and kwargs:\n-            return res(**kwargs)\n+def serialize_keras_object(instance):\n+    if instance is None:\n+        return None\n+    if hasattr(instance, 'get_config'):\n+        return {\n+            'class_name': instance.__class__.__name__,\n+            'config': instance.get_config()\n+        }\n+    if hasattr(instance, '__name__'):\n+        return instance.__name__\n     else:\n-            return res\n-    elif isinstance(identifier, dict):\n-        name = identifier.pop('name')\n-        res = None\n-        if name in _GLOBAL_CUSTOM_OBJECTS:\n-            res = _GLOBAL_CUSTOM_OBJECTS[name]\n-        if not res:\n-            res = module_params.get(name)\n-        if res:\n-            return res(**identifier)\n+        raise ValueError('Cannot serialize', instance)\n+\n+\n+def deserialize_keras_object(identifier, module_objects=None,\n+                             custom_objects=None,\n+                             printable_module_name='object'):\n+    if isinstance(identifier, dict):\n+        # In this case we are dealing with a Keras config dictionary.\n+        config = identifier\n+        if 'class_name' not in config or 'config' not in config:\n+            raise ValueError('Improper config format:', config)\n+        class_name = config['class_name']\n+        if custom_objects and class_name in custom_objects:\n+            cls = custom_objects[class_name]\n+        elif class_name in _GLOBAL_CUSTOM_OBJECTS:\n+            cls = _GLOBAL_CUSTOM_OBJECTS[class_name]\n         else:\n-            raise ValueError('Invalid ' + str(module_name) + ': ' +\n-                             str(identifier))\n-    return identifier\n+            module_objects = module_objects or {}\n+            cls = module_objects.get(class_name)\n+            if cls is None:\n+                raise ValueError('Unknown ' + printable_module_name,\n+                                 ':', class_name)\n+        if hasattr(cls, 'from_config'):\n+            arg_spec = inspect.getargspec(cls.from_config)\n+            if 'custom_objects' in arg_spec.args:\n+                custom_objects = custom_objects or {}\n+                return cls.from_config(config['config'],\n+                                       custom_objects=dict(_GLOBAL_CUSTOM_OBJECTS.items() +\n+                                                           custom_objects.items()))\n+            return cls.from_config(config['config'])\n+        else:\n+            # Then `cls` may be a function returning a class.\n+            # in this case by convention `config` holds\n+            # the kwargs of the function.\n+            return cls(**config['config'])\n+    elif isinstance(identifier, six.string_types):\n+        function_name = identifier\n+        if custom_objects and function_name in custom_objects:\n+            fn = custom_objects.get(function_name)\n+        elif function_name in _GLOBAL_CUSTOM_OBJECTS:\n+            fn = _GLOBAL_CUSTOM_OBJECTS[function_name]\n+        else:\n+            fn = module_objects.get(function_name)\n+            if fn is None:\n+                raise ValueError('Unknown ' + printable_module_name,\n+                                 ':', class_name)\n+        return fn\n+    else:\n+        raise ValueError('Could not interpret serialized',\n+                         printable_module_name, ':', identifier)\n \n \n def make_tuple(*args):\n\n@@ -1,8 +1,9 @@\n from __future__ import print_function\n import inspect\n \n-from .generic_utils import get_from_module, get_custom_objects\n-from .np_utils import convert_kernel\n+from .generic_utils import get_custom_objects\n+from .generic_utils import deserialize_keras_object\n+from .conv_utils import convert_kernel\n from ..layers import *\n from ..models import Model, Sequential\n from .. import backend as K\n@@ -18,28 +19,13 @@ def layer_from_config(config, custom_objects=None):\n \n     # Returns\n         Layer instance (may be Model, Sequential, Layer...)\n+\n+    # TODO: rename to \"deserialize\" and move to \"layers.__init__.py\"\n     \"\"\"\n-    # Insert custom layers into globals so they can\n-    # be accessed by `get_from_module`.\n-    if custom_objects:\n-        get_custom_objects().update(custom_objects)\n-\n-    class_name = config['class_name']\n-\n-    if class_name == 'Sequential':\n-        layer_class = Sequential\n-    elif class_name in ['Model', 'Container']:\n-        layer_class = Model\n-    else:\n-        layer_class = get_from_module(class_name, globals(), 'layer',\n-                                      instantiate=False)\n-\n-    arg_spec = inspect.getargspec(layer_class.from_config)\n-    if 'custom_objects' in arg_spec.args:\n-        return layer_class.from_config(config['config'],\n-                                       custom_objects=custom_objects)\n-    else:\n-        return layer_class.from_config(config['config'])\n+    return deserialize_keras_object(config,\n+                                    module_objects=globals(),\n+                                    custom_objects=custom_objects,\n+                                    printable_module_name='layer')\n \n \n def print_summary(layers, relevant_nodes=None,\n@@ -52,6 +38,9 @@ def print_summary(layers, relevant_nodes=None,\n         line_length: total length of printed lines\n         positions: relative or absolute positions of log elements in each line.\n             If not provided, defaults to `[.33, .55, .67, 1.]`.\n+\n+    # TODO: don't print connectivity for sequential models\n+    maybe change API to accept a model instance\n     \"\"\"\n     positions = positions or [.33, .55, .67, 1.]\n     if positions[-1] <= 1:\n\n@@ -2,9 +2,7 @@\n from __future__ import absolute_import\n \n import numpy as np\n-from six.moves import range\n from six.moves import zip\n-from .. import backend as K\n \n \n def to_categorical(y, nb_classes=None):\n@@ -35,21 +33,6 @@ def normalize(a, axis=-1, order=2):\n     return a / np.expand_dims(l2, axis)\n \n \n-def binary_logloss(p, y):\n-    epsilon = 1e-15\n-    p = np.maximum(epsilon, p)\n-    p = np.minimum(1 - epsilon, p)\n-    res = sum(y * np.log(p) + np.subtract(1, y) * np.log(np.subtract(1, p)))\n-    res *= -1.0 / len(y)\n-    return res\n-\n-\n-def multiclass_logloss(p, y):\n-    npreds = [p[i][y[i] - 1] for i in range(len(y))]\n-    score = -(1. / len(y)) * np.sum(np.log(npreds))\n-    return score\n-\n-\n def accuracy(p, y):\n     return np.mean([a == b for a, b in zip(p, y)])\n \n@@ -62,86 +45,3 @@ def probas_to_classes(y_pred):\n \n def categorical_probas_to_classes(p):\n     return np.argmax(p, axis=1)\n-\n-\n-def convert_kernel(kernel, data_format=None):\n-    \"\"\"Converts a Numpy kernel matrix from Theano format to TensorFlow format.\n-\n-    Also works reciprocally, since the transformation is its own inverse.\n-\n-    # Arguments\n-        kernel: Numpy array (4D or 5D).\n-        data_format: the data format.\n-\n-    # Returns\n-        The converted kernel.\n-\n-    # Raises\n-        ValueError: in case of invalid kernel shape or invalid data_format.\n-    \"\"\"\n-    if data_format is None:\n-        data_format = K.image_data_format()\n-    if not 4 <= kernel.ndim <= 5:\n-        raise ValueError('Invalid kernel shape:', kernel.shape)\n-\n-    slices = [slice(None, None, -1) for _ in range(kernel.ndim)]\n-    no_flip = (slice(None, None), slice(None, None))\n-    if data_format == 'channels_first':  # (out_depth, input_depth, ...)\n-        slices[:2] = no_flip\n-    elif data_format == 'channels_last':  # (..., input_depth, out_depth)\n-        slices[-2:] = no_flip\n-    else:\n-        raise ValueError('Invalid data_format:', data_format)\n-\n-    return np.copy(kernel[slices])\n-\n-\n-def conv_output_length(input_length, filter_size,\n-                       border_mode, stride, dilation=1):\n-    \"\"\"Determines output length of a convolution given input length.\n-\n-    # Arguments\n-        input_length: integer.\n-        filter_size: integer.\n-        border_mode: one of \"same\", \"valid\", \"full\".\n-        stride: integer.\n-        dilation: dilation rate, integer.\n-\n-    # Returns\n-        The output length (integer).\n-    \"\"\"\n-    if input_length is None:\n-        return None\n-    assert border_mode in {'same', 'valid', 'full'}\n-    dilated_filter_size = filter_size + (filter_size - 1) * (dilation - 1)\n-    if border_mode == 'same':\n-        output_length = input_length\n-    elif border_mode == 'valid':\n-        output_length = input_length - dilated_filter_size + 1\n-    elif border_mode == 'full':\n-        output_length = input_length + dilated_filter_size - 1\n-    return (output_length + stride - 1) // stride\n-\n-\n-def conv_input_length(output_length, filter_size, border_mode, stride):\n-    \"\"\"Determines input length of a convolution given output length.\n-\n-    # Arguments\n-        output_length: integer.\n-        filter_size: integer.\n-        border_mode: one of \"same\", \"valid\", \"full\".\n-        stride: integer.\n-\n-    # Returns\n-        The input length (integer).\n-    \"\"\"\n-    if output_length is None:\n-        return None\n-    assert border_mode in {'same', 'valid', 'full'}\n-    if border_mode == 'same':\n-        pad = filter_size // 2\n-    elif border_mode == 'valid':\n-        pad = 0\n-    elif border_mode == 'full':\n-        pad = filter_size - 1\n-    return (output_length - 1) * stride - 2 * pad + filter_size\n\n@@ -10,85 +10,48 @@ from keras.layers import convolutional, pooling\n \n # TensorFlow does not support full convolution.\n if K.backend() == 'theano':\n-    _convolution_border_modes = ['valid', 'same', 'full']\n+    _convolution_paddings = ['valid', 'same', 'full']\n else:\n-    _convolution_border_modes = ['valid', 'same']\n+    _convolution_paddings = ['valid', 'same']\n \n \n @keras_test\n-def test_convolution_1d():\n-    nb_samples = 2\n-    nb_steps = 8\n+def test_conv_1d():\n+    batch_size = 2\n+    steps = 8\n     input_dim = 2\n-    filter_length = 3\n-    nb_filter = 3\n+    kernel_size = 3\n+    filters = 3\n \n-    for border_mode in _convolution_border_modes:\n-        for subsample_length in [1, 2]:\n-            if border_mode == 'same' and subsample_length != 1:\n+    for padding in _convolution_paddings:\n+        for strides in [1, 2]:\n+            if padding == 'same' and strides != 1:\n                 continue\n+            layer_test(convolutional.Conv1D,\n+                       kwargs={'filters': filters,\n+                               'kernel_size': kernel_size,\n+                               'padding': padding,\n+                               'strides': strides},\n+                       input_shape=(batch_size, steps, input_dim))\n \n-            layer_test(convolutional.Convolution1D,\n-                       kwargs={'nb_filter': nb_filter,\n-                               'filter_length': filter_length,\n-                               'border_mode': border_mode,\n-                               'subsample_length': subsample_length},\n-                       input_shape=(nb_samples, nb_steps, input_dim))\n-\n-            layer_test(convolutional.Convolution1D,\n-                       kwargs={'nb_filter': nb_filter,\n-                               'filter_length': filter_length,\n-                               'border_mode': border_mode,\n-                               'W_regularizer': 'l2',\n-                               'b_regularizer': 'l2',\n+            layer_test(convolutional.Conv1D,\n+                       kwargs={'filters': filters,\n+                               'size': kernel_size,\n+                               'padding': padding,\n+                               'kernel_regularizer': 'l2',\n+                               'bias_regularizer': 'l2',\n                                'activity_regularizer': 'activity_l2',\n-                               'subsample_length': subsample_length},\n-                       input_shape=(nb_samples, nb_steps, input_dim))\n-\n-\n-@keras_test\n-def test_atrous_conv_1d():\n-    nb_samples = 2\n-    nb_steps = 8\n-    input_dim = 2\n-    filter_length = 3\n-    nb_filter = 3\n-\n-    for border_mode in _convolution_border_modes:\n-        for subsample_length in [1, 2]:\n-            for atrous_rate in [1, 2]:\n-                if border_mode == 'same' and subsample_length != 1:\n-                    continue\n-                if subsample_length != 1 and atrous_rate != 1:\n-                    continue\n-\n-                layer_test(convolutional.AtrousConv1D,\n-                           kwargs={'nb_filter': nb_filter,\n-                                   'filter_length': filter_length,\n-                                   'border_mode': border_mode,\n-                                   'subsample_length': subsample_length,\n-                                   'atrous_rate': atrous_rate},\n-                           input_shape=(nb_samples, nb_steps, input_dim))\n-\n-                layer_test(convolutional.AtrousConv1D,\n-                           kwargs={'nb_filter': nb_filter,\n-                                   'filter_length': filter_length,\n-                                   'border_mode': border_mode,\n-                                   'W_regularizer': 'l2',\n-                                   'b_regularizer': 'l2',\n-                                   'activity_regularizer': 'activity_l2',\n-                                   'subsample_length': subsample_length,\n-                                   'atrous_rate': atrous_rate},\n-                           input_shape=(nb_samples, nb_steps, input_dim))\n+                               'strides': strides},\n+                       input_shape=(batch_size, steps, input_dim))\n \n \n @keras_test\n def test_maxpooling_1d():\n-    for border_mode in ['valid', 'same']:\n+    for padding in ['valid', 'same']:\n         for stride in [1, 2]:\n             layer_test(convolutional.MaxPooling1D,\n                        kwargs={'stride': stride,\n-                               'border_mode': border_mode},\n+                               'padding': padding},\n                        input_shape=(3, 5, 4))\n \n \n@@ -97,36 +60,36 @@ def test_averagepooling_1d():\n     for stride in [1, 2]:\n         layer_test(convolutional.AveragePooling1D,\n                    kwargs={'stride': stride,\n-                           'border_mode': 'valid'},\n+                           'padding': 'valid'},\n                    input_shape=(3, 5, 4))\n \n \n @keras_test\n def test_convolution_2d():\n     nb_samples = 2\n-    nb_filter = 2\n+    filters = 2\n     stack_size = 3\n     nb_row = 10\n     nb_col = 6\n \n-    for border_mode in _convolution_border_modes:\n+    for padding in _convolution_paddings:\n         for subsample in [(1, 1), (2, 2)]:\n-            if border_mode == 'same' and subsample != (1, 1):\n+            if padding == 'same' and subsample != (1, 1):\n                 continue\n \n             layer_test(convolutional.Convolution2D,\n-                       kwargs={'nb_filter': nb_filter,\n+                       kwargs={'filters': filters,\n                                'nb_row': 3,\n                                'nb_col': 3,\n-                               'border_mode': border_mode,\n+                               'padding': padding,\n                                'subsample': subsample},\n                        input_shape=(nb_samples, nb_row, nb_col, stack_size))\n \n             layer_test(convolutional.Convolution2D,\n-                       kwargs={'nb_filter': nb_filter,\n+                       kwargs={'filters': filters,\n                                'nb_row': 3,\n                                'nb_col': 3,\n-                               'border_mode': border_mode,\n+                               'padding': padding,\n                                'W_regularizer': 'l2',\n                                'b_regularizer': 'l2',\n                                'activity_regularizer': 'activity_l2',\n@@ -137,36 +100,36 @@ def test_convolution_2d():\n @keras_test\n def test_deconvolution_2d():\n     nb_samples = 2\n-    nb_filter = 2\n+    filters = 2\n     stack_size = 3\n     nb_row = 10\n     nb_col = 6\n \n     for batch_size in [None, nb_samples]:\n-        for border_mode in _convolution_border_modes:\n+        for padding in _convolution_paddings:\n             for subsample in [(1, 1), (2, 2)]:\n-                if border_mode == 'same' and subsample != (1, 1):\n+                if padding == 'same' and subsample != (1, 1):\n                     continue\n \n-                rows = conv_input_length(nb_row, 3, border_mode, subsample[0])\n-                cols = conv_input_length(nb_col, 3, border_mode, subsample[1])\n+                rows = conv_input_length(nb_row, 3, padding, subsample[0])\n+                cols = conv_input_length(nb_col, 3, padding, subsample[1])\n                 layer_test(convolutional.Deconvolution2D,\n-                           kwargs={'nb_filter': nb_filter,\n+                           kwargs={'filters': filters,\n                                    'nb_row': 3,\n                                    'nb_col': 3,\n-                                   'output_shape': (batch_size, nb_filter, rows, cols),\n-                                   'border_mode': border_mode,\n+                                   'output_shape': (batch_size, filters, rows, cols),\n+                                   'padding': padding,\n                                    'subsample': subsample,\n                                    'data_format': 'channels_first'},\n                            input_shape=(nb_samples, stack_size, nb_row, nb_col),\n                            fixed_batch_size=True)\n \n                 layer_test(convolutional.Deconvolution2D,\n-                           kwargs={'nb_filter': nb_filter,\n+                           kwargs={'filters': filters,\n                                    'nb_row': 3,\n                                    'nb_col': 3,\n-                                   'output_shape': (batch_size, nb_filter, rows, cols),\n-                                   'border_mode': border_mode,\n+                                   'output_shape': (batch_size, filters, rows, cols),\n+                                   'padding': padding,\n                                    'data_format': 'channels_first',\n                                    'W_regularizer': 'l2',\n                                    'b_regularizer': 'l2',\n@@ -179,33 +142,33 @@ def test_deconvolution_2d():\n @keras_test\n def test_atrous_conv_2d():\n     nb_samples = 2\n-    nb_filter = 2\n+    filters = 2\n     stack_size = 3\n     nb_row = 10\n     nb_col = 6\n \n-    for border_mode in _convolution_border_modes:\n+    for padding in _convolution_paddings:\n         for subsample in [(1, 1), (2, 2)]:\n             for atrous_rate in [(1, 1), (2, 2)]:\n-                if border_mode == 'same' and subsample != (1, 1):\n+                if padding == 'same' and subsample != (1, 1):\n                     continue\n                 if subsample != (1, 1) and atrous_rate != (1, 1):\n                     continue\n \n                 layer_test(convolutional.AtrousConv2D,\n-                           kwargs={'nb_filter': nb_filter,\n+                           kwargs={'filters': filters,\n                                    'nb_row': 3,\n                                    'nb_col': 3,\n-                                   'border_mode': border_mode,\n+                                   'padding': padding,\n                                    'subsample': subsample,\n                                    'atrous_rate': atrous_rate},\n                            input_shape=(nb_samples, nb_row, nb_col, stack_size))\n \n                 layer_test(convolutional.AtrousConv2D,\n-                           kwargs={'nb_filter': nb_filter,\n+                           kwargs={'filters': filters,\n                                    'nb_row': 3,\n                                    'nb_col': 3,\n-                                   'border_mode': border_mode,\n+                                   'padding': padding,\n                                    'W_regularizer': 'l2',\n                                    'b_regularizer': 'l2',\n                                    'activity_regularizer': 'activity_l2',\n@@ -218,31 +181,31 @@ def test_atrous_conv_2d():\n @keras_test\n def test_separable_conv_2d():\n     nb_samples = 2\n-    nb_filter = 6\n+    filters = 6\n     stack_size = 3\n     nb_row = 10\n     nb_col = 6\n \n-    for border_mode in _convolution_border_modes:\n+    for padding in _convolution_paddings:\n         for subsample in [(1, 1), (2, 2)]:\n             for multiplier in [1, 2]:\n-                if border_mode == 'same' and subsample != (1, 1):\n+                if padding == 'same' and subsample != (1, 1):\n                     continue\n \n                 layer_test(convolutional.SeparableConv2D,\n-                           kwargs={'nb_filter': nb_filter,\n+                           kwargs={'filters': filters,\n                                    'nb_row': 3,\n                                    'nb_col': 3,\n-                                   'border_mode': border_mode,\n+                                   'padding': padding,\n                                    'subsample': subsample,\n                                    'depth_multiplier': multiplier},\n                            input_shape=(nb_samples, nb_row, nb_col, stack_size))\n \n                 layer_test(convolutional.SeparableConv2D,\n-                           kwargs={'nb_filter': nb_filter,\n+                           kwargs={'filters': filters,\n                                    'nb_row': 3,\n                                    'nb_col': 3,\n-                                   'border_mode': border_mode,\n+                                   'padding': padding,\n                                    'depthwise_regularizer': 'l2',\n                                    'pointwise_regularizer': 'l2',\n                                    'b_regularizer': 'l2',\n@@ -301,19 +264,19 @@ def test_maxpooling_2d():\n     for strides in [(1, 1), (2, 2)]:\n         layer_test(convolutional.MaxPooling2D,\n                    kwargs={'strides': strides,\n-                           'border_mode': 'valid',\n+                           'padding': 'valid',\n                            'pool_size': pool_size},\n                    input_shape=(3, 11, 12, 4))\n \n \n @keras_test\n def test_averagepooling_2d():\n-    for border_mode in ['valid', 'same']:\n+    for padding in ['valid', 'same']:\n         for pool_size in [(2, 2), (3, 3), (4, 4), (5, 5)]:\n             for strides in [(1, 1), (2, 2)]:\n                 layer_test(convolutional.AveragePooling2D,\n                            kwargs={'strides': strides,\n-                                   'border_mode': border_mode,\n+                                   'padding': padding,\n                                    'pool_size': pool_size},\n                            input_shape=(3, 11, 12, 4))\n \n@@ -321,7 +284,7 @@ def test_averagepooling_2d():\n @keras_test\n def test_convolution_3d():\n     nb_samples = 2\n-    nb_filter = 2\n+    filters = 2\n     stack_size = 3\n     kernel_dim1 = 2\n     kernel_dim2 = 3\n@@ -331,28 +294,28 @@ def test_convolution_3d():\n     input_len_dim2 = 11\n     input_len_dim3 = 12\n \n-    for border_mode in _convolution_border_modes:\n+    for padding in _convolution_paddings:\n         for subsample in [(1, 1, 1), (2, 2, 2)]:\n-            if border_mode == 'same' and subsample != (1, 1, 1):\n+            if padding == 'same' and subsample != (1, 1, 1):\n                 continue\n \n             layer_test(convolutional.Convolution3D,\n-                       kwargs={'nb_filter': nb_filter,\n+                       kwargs={'filters': filters,\n                                'kernel_dim1': kernel_dim1,\n                                'kernel_dim2': kernel_dim2,\n                                'kernel_dim3': kernel_dim3,\n-                               'border_mode': border_mode,\n+                               'padding': padding,\n                                'subsample': subsample},\n                        input_shape=(nb_samples,\n                                     input_len_dim1, input_len_dim2, input_len_dim3,\n                                     stack_size))\n \n             layer_test(convolutional.Convolution3D,\n-                       kwargs={'nb_filter': nb_filter,\n+                       kwargs={'filters': filters,\n                                'kernel_dim1': kernel_dim1,\n                                'kernel_dim2': kernel_dim2,\n                                'kernel_dim3': kernel_dim3,\n-                               'border_mode': border_mode,\n+                               'padding': padding,\n                                'W_regularizer': 'l2',\n                                'b_regularizer': 'l2',\n                                'activity_regularizer': 'activity_l2',\n@@ -369,7 +332,7 @@ def test_maxpooling_3d():\n     for strides in [(1, 1, 1), (2, 2, 2)]:\n         layer_test(convolutional.MaxPooling3D,\n                    kwargs={'strides': strides,\n-                           'border_mode': 'valid',\n+                           'padding': 'valid',\n                            'pool_size': pool_size},\n                    input_shape=(3, 4, 11, 12, 10))\n \n@@ -381,7 +344,7 @@ def test_averagepooling_3d():\n     for strides in [(1, 1, 1), (2, 2, 2)]:\n         layer_test(convolutional.AveragePooling3D,\n                    kwargs={'strides': strides,\n-                           'border_mode': 'valid',\n+                           'padding': 'valid',\n                            'pool_size': pool_size},\n                    input_shape=(3, 4, 11, 12, 10))\n \n\n@@ -17,7 +17,7 @@ from keras.models import save_model, load_model\n @keras_test\n def test_sequential_model_saving():\n     model = Sequential()\n-    model.add(Dense(2, input_dim=3))\n+    model.add(Dense(2, input_shape=(3,)))\n     model.add(RepeatVector(3))\n     model.add(TimeDistributed(Dense(3)))\n     model.compile(loss=objectives.MSE,\n@@ -54,7 +54,7 @@ def test_sequential_model_saving_2():\n     custom_opt = optimizers.rmsprop\n     custom_loss = objectives.mse\n     model = Sequential()\n-    model.add(Dense(2, input_dim=3))\n+    model.add(Dense(2, input_shape=(3,)))\n     model.add(Dense(3))\n     model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=['acc'])\n \n@@ -103,7 +103,7 @@ def test_fuctional_model_saving():\n @keras_test\n def test_saving_without_compilation():\n     model = Sequential()\n-    model.add(Dense(2, input_dim=3))\n+    model.add(Dense(2, input_shape=(3,)))\n     model.add(Dense(3))\n     model.compile(loss='mse', optimizer='sgd', metrics=['acc'])\n \n@@ -116,7 +116,7 @@ def test_saving_without_compilation():\n @keras_test\n def test_saving_right_after_compilation():\n     model = Sequential()\n-    model.add(Dense(2, input_dim=3))\n+    model.add(Dense(2, input_shape=(3,)))\n     model.add(Dense(3))\n     model.compile(loss='mse', optimizer='sgd', metrics=['acc'])\n     model.model._make_train_function()\n@@ -140,7 +140,7 @@ def test_loading_weights_by_name():\n \n     # sequential model\n     model = Sequential()\n-    model.add(Dense(2, input_dim=3, name=\"rick\"))\n+    model.add(Dense(2, input_shape=(3,), name=\"rick\"))\n     model.add(Dense(3, name=\"morty\"))\n     model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=['acc'])\n \n@@ -157,7 +157,7 @@ def test_loading_weights_by_name():\n     # delete and recreate model\n     del(model)\n     model = Sequential()\n-    model.add(Dense(2, input_dim=3, name=\"rick\"))\n+    model.add(Dense(2, input_shape=(3,), name=\"rick\"))\n     model.add(Dense(3, name=\"morty\"))\n     model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=['acc'])\n \n@@ -187,7 +187,7 @@ def test_loading_weights_by_name_2():\n \n     # sequential model\n     model = Sequential()\n-    model.add(Dense(2, input_dim=3, name=\"rick\"))\n+    model.add(Dense(2, input_shape=(3,), name=\"rick\"))\n     model.add(Dense(3, name=\"morty\"))\n     model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=['acc'])\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
