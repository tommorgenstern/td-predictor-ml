{"custom_id": "keras#1fc98ab59b4f3f8f237f05591cd428efe25f0d53", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 9 | Files Changed: 5 | Hunks: 9 | Methods Changed: 11 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 32 | Churn Cumulative: 2377 | Contributors (this commit): 3 | Commits (past 90d): 32 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -19,7 +19,7 @@ class InitializersTest(testing.TestCase):\n         self.assertEqual(initializer.stddev, stddev)\n         self.assertEqual(initializer.seed, seed)\n         self.assertEqual(values.shape, shape)\n-        self.test_load_external_config(initializer, external_config)\n+        self.assert_idempotent_config(initializer, external_config)\n \n     def test_random_uniform(self):\n         shape = (5, 5)\n@@ -35,11 +35,11 @@ class InitializersTest(testing.TestCase):\n         self.assertEqual(initializer.maxval, maxval)\n         self.assertEqual(initializer.seed, seed)\n         self.assertEqual(values.shape, shape)\n-        self.test_load_external_config(initializer, external_config)\n+        self.assert_idempotent_config(initializer, external_config)\n         values = values.numpy()\n         self.assertGreaterEqual(np.min(values), minval)\n         self.assertLess(np.max(values), maxval)\n \n-    def test_load_external_config(self, initializer, config):\n+    def assert_idempotent_config(self, initializer, config):\n         initializer = initializer.from_config(config)\n         self.assertEqual(initializer.get_config(), config)\n\n@@ -11,10 +11,10 @@ class ExampleMetric(Metric):\n     def __init__(self, name=\"mean_square_error\", dtype=None):\n         super().__init__(name=name, dtype=dtype)\n         self.sum = self.add_variable(\n-            name=\"sum\", initializer=initializers.Zeros()\n+            name=\"sum\", shape=(), initializer=initializers.Zeros()\n         )\n         self.total = self.add_variable(\n-            name=\"total\", initializer=initializers.Zeros(), dtype=\"int32\"\n+            name=\"total\", shape=(), initializer=initializers.Zeros(), dtype=\"int32\"\n         )\n \n     def update_state(self, y_true, y_pred):\n\n@@ -7,10 +7,10 @@ class MeanSquareError(Metric):\n     def __init__(self, name=\"mean_square_error\", dtype=None):\n         super().__init__(name=name, dtype=dtype)\n         self.sum = self.add_variable(\n-            name=\"sum\", initializer=initializers.Zeros()\n+            name=\"sum\", shape=(), initializer=initializers.Zeros()\n         )\n         self.total = self.add_variable(\n-            name=\"total\", initializer=initializers.Zeros()\n+            name=\"total\", shape=(), initializer=initializers.Zeros()\n         )\n \n     def update_state(self, y_true, y_pred):\n\n@@ -996,6 +996,20 @@ def square(x):\n     return backend.execute(\"square\", x)\n \n \n+class Sqrt(Operation):\n+    def call(self, x):\n+        return backend.execute(\"sqrt\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def sqrt(x):\n+    if any_symbolic_tensors((x,)):\n+        return Sqrt().symbolic_call(x)\n+    return backend.execute(\"sqrt\", x)\n+\n+\n class Squeeze(Operation):\n     def __init__(self, axis=None):\n         super().__init__()\n\n@@ -345,6 +345,6 @@ def validate_float_arg(value, name):\n     return float(value)\n \n \n-def l2_normalize(x):\n-    l2_norm = ops.sqrt(ops.sum(ops.square(x)))\n+def l2_normalize(x, axis=0):\n+    l2_norm = ops.sqrt(ops.sum(ops.square(x), axis=axis))\n     return x / l2_norm\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#af0040d1535866f0dd9949e645ce280a6c02371e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 35 | Files Changed: 7 | Hunks: 29 | Methods Changed: 6 | Complexity Δ (Sum/Max): 8/8 | Churn Δ: 69 | Churn Cumulative: 1594 | Contributors (this commit): 3 | Commits (past 90d): 50 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -29,7 +29,7 @@ class MiniDropout(Layer):\n     def __init__(self, rate, name=None):\n         super().__init__(name=name)\n         self.rate = rate\n-        self.seed_generator = backend.random.RandomSeedGenerator(1337)\n+        self.seed_generator = backend.random.SeedGenerator(1337)\n \n     def call(self, inputs):\n         return backend.random.dropout(\n\n@@ -32,7 +32,7 @@ class MiniDropout(Layer):\n     def __init__(self, rate, name=None):\n         super().__init__(name=name)\n         self.rate = rate\n-        self.seed_generator = backend.random.RandomSeedGenerator(1337)\n+        self.seed_generator = backend.random.SeedGenerator(1337)\n \n     def call(self, inputs):\n         return backend.random.dropout(\n\n@@ -1,7 +1,9 @@\n import random as python_random\n \n+from keras_core.backend import backend\n \n-class RandomSeedGenerator:\n+\n+class SeedGenerator:\n     def __init__(self, seed):\n         from keras_core.backend import Variable\n \n@@ -20,7 +22,7 @@ def make_default_seed():\n def draw_seed(seed):\n     from keras_core.backend import convert_to_tensor\n \n-    if isinstance(seed, RandomSeedGenerator):\n+    if isinstance(seed, SeedGenerator):\n         new_seed_value = seed.state.value\n         seed.state.assign(\n             seed.state + convert_to_tensor([0, 1], dtype=\"uint32\")\n@@ -32,6 +34,12 @@ def draw_seed(seed):\n         return convert_to_tensor([make_default_seed(), 0], dtype=\"uint32\")\n     raise ValueError(\n         \"Argument `seed` must be either an integer \"\n-        \"or an instance of `RandomSeedGenerator`. \"\n+        \"or an instance of `SeedGenerator`. \"\n         f\"Received: seed={seed} (of type {type(seed)})\"\n     )\n+\n+\n+if backend() == \"jax\":\n+    from keras_core.backend.jax.random import *\n+else:\n+    from keras_core.backend.tensorflow.random import *\n\\ No newline at end of file\n\n@@ -1,9 +0,0 @@\n-from keras_core.backend import backend\n-from keras_core.backend.random.random_seed_generator import RandomSeedGenerator\n-from keras_core.backend.random.random_seed_generator import draw_seed\n-from keras_core.backend.random.random_seed_generator import make_default_seed\n-\n-if backend() == \"jax\":\n-    from keras_core.backend.jax.random import *\n-else:\n-    from keras_core.backend.tensorflow.random import *\n\n@@ -35,13 +35,13 @@ class VarianceScaling(Initializer):\n         distribution: Random distribution to use.\n             One of `\"truncated_normal\"`, `\"untruncated_normal\"`, or `\"uniform\"`.\n         seed: A Python integer or instance of\n-            `keras_core.backend.RandomSeedGenerator`.\n+            `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n             or None (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n-            of `keras_core.backend.RandomSeedGenerator`.\n+            of `keras_core.backend.SeedGenerator`.\n     \"\"\"\n \n     def __init__(\n@@ -143,13 +143,13 @@ class GlorotUniform(VarianceScaling):\n \n     Args:\n         seed: A Python integer or instance of\n-            `keras_core.backend.RandomSeedGenerator`.\n+            `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n             or None (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n-            of `keras_core.backend.RandomSeedGenerator`.\n+            of `keras_core.backend.SeedGenerator`.\n \n     References:\n \n@@ -185,13 +185,13 @@ class GlorotNormal(VarianceScaling):\n \n     Args:\n         seed: A Python integer or instance of\n-            `keras_core.backend.RandomSeedGenerator`.\n+            `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n             or None (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n-            of `keras_core.backend.RandomSeedGenerator`.\n+            of `keras_core.backend.SeedGenerator`.\n \n     References:\n     - [Glorot et al., 2010](http://proceedings.mlr.press/v9/glorot10a.html)\n@@ -232,13 +232,13 @@ class LecunNormal(VarianceScaling):\n \n     Args:\n         seed: A Python integer or instance of\n-            `keras_core.backend.RandomSeedGenerator`.\n+            `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n             or None (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n-            of `keras_core.backend.RandomSeedGenerator`.\n+            of `keras_core.backend.SeedGenerator`.\n \n     References:\n     - [Klambauer et al., 2017](https://arxiv.org/abs/1706.02515)\n@@ -272,13 +272,13 @@ class LecunUniform(VarianceScaling):\n \n     Args:\n         seed: A Python integer or instance of\n-            `keras_core.backend.RandomSeedGenerator`.\n+            `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n             or None (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n-            of `keras_core.backend.RandomSeedGenerator`.\n+            of `keras_core.backend.SeedGenerator`.\n \n     References:\n     - [Klambauer et al., 2017](https://arxiv.org/abs/1706.02515)\n@@ -312,13 +312,13 @@ class HeNormal(VarianceScaling):\n \n     Args:\n         seed: A Python integer or instance of\n-            `keras_core.backend.RandomSeedGenerator`.\n+            `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n             or None (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n-            of `keras_core.backend.RandomSeedGenerator`.\n+            of `keras_core.backend.SeedGenerator`.\n \n     Reference:\n     - [He et al., 2015](https://arxiv.org/abs/1502.01852)\n@@ -352,13 +352,13 @@ class HeUniform(VarianceScaling):\n \n     Args:\n         seed: A Python integer or instance of\n-            `keras_core.backend.RandomSeedGenerator`.\n+            `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n             or None (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n-            of `keras_core.backend.RandomSeedGenerator`.\n+            of `keras_core.backend.SeedGenerator`.\n \n     Reference:\n     - [He et al., 2015](https://arxiv.org/abs/1502.01852)\n@@ -422,13 +422,13 @@ class RandomNormal(Initializer):\n         stddev: A python scalar or a scalar keras tensor. Standard deviation of the\n            random values to generate.\n         seed: A Python integer or instance of\n-            `keras_core.backend.RandomSeedGenerator`.\n+            `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n             or None (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n-            of `keras_core.backend.RandomSeedGenerator`.\n+            of `keras_core.backend.SeedGenerator`.\n     \"\"\"\n \n     def __init__(self, mean=0.0, stddev=1.0, seed=None):\n@@ -471,13 +471,13 @@ class RandomUniform(Initializer):\n         maxval: A python scalar or a scalar keras tensor. Upper bound of the range of\n             random values to generate (exclusive).\n         seed: A Python integer or instance of\n-            `keras_core.backend.RandomSeedGenerator`.\n+            `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n             or None (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n-            of `keras_core.backend.RandomSeedGenerator`.\n+            of `keras_core.backend.SeedGenerator`.\n     \"\"\"\n \n     def __init__(self, minval=0.0, maxval=1.0, seed=None):\n\n@@ -71,7 +71,7 @@ class Layer(Operation):\n                     and not isinstance(x, Metric),\n                     self._layers,\n                 ),\n-                # TODO: RandomSeedGenerator tracking\n+                # TODO: SeedGenerator tracking\n             }\n         )\n \n@@ -176,7 +176,7 @@ class Layer(Operation):\n \n     @property\n     def variables(self):\n-        # TODO: include not just weights by any variables (also from metrics, optimizers, RandomSeedGenerators)\n+        # TODO: include not just weights by any variables (also from metrics, optimizers, SeedGenerators)\n         variables = self.weights[:]\n         return variables\n \n\n@@ -29,7 +29,7 @@ class MiniDropout(Layer):\n     def __init__(self, rate, name=None):\n         super().__init__(name=name)\n         self.rate = rate\n-        self.seed_generator = backend.random.RandomSeedGenerator(1337)\n+        self.seed_generator = backend.random.SeedGenerator(1337)\n \n     def call(self, inputs):\n         return backend.random.dropout(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f7de75645a79b33574d7f92ed437d21722846b92", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 19/19 | Churn Δ: 8 | Churn Cumulative: 572 | Contributors (this commit): 8 | Commits (past 90d): 3 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -142,13 +142,13 @@ def measure_performance(\n       ValueError: If `x` is none or if `optimizer` is not provided or\n       if `loss` is not provided or if `num_gpus` is negative.\n     \"\"\"\n-    if \"x\" is None:\n+    if x is None:\n         raise ValueError(\"Input data is required.\")\n-    if \"optimizer\" is None:\n+    elif optimizer is None:\n         raise ValueError(\"Optimizer is required.\")\n-    if \"loss\" is None:\n+    elif loss is None:\n         raise ValueError(\"Loss function is required.\")\n-    if num_gpus < 0:\n+    elif num_gpus < 0:\n         raise ValueError(\"`num_gpus` cannot be negative\")\n \n     # TODO(xingyulong): we will add tfds support later and\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#69da687f28e81ac816574c46c9de686d6159213d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 805/805 | Churn Δ: 12 | Churn Cumulative: 18629 | Contributors (this commit): 26 | Commits (past 90d): 16 | Contributors (cumulative): 26 | DMM Complexity: None\n\nDIFF:\n@@ -6324,13 +6324,13 @@ def separable_conv1d(\n     pointwise_kernel = tf.expand_dims(pointwise_kernel, 0)\n     dilation_rate = (1,) + dilation_rate\n \n-    x = tf.compat.v1.nn.separable_conv2d(\n+    x = tf.nn.separable_conv2d(\n         x,\n         depthwise_kernel,\n         pointwise_kernel,\n         strides=strides,\n         padding=padding,\n-        rate=dilation_rate,\n+        dilations=dilation_rate,\n         data_format=tf_data_format,\n     )\n \n@@ -6390,13 +6390,13 @@ def separable_conv2d(\n     else:\n         strides = (1, 1) + strides\n \n-    x = tf.compat.v1.nn.separable_conv2d(\n+    x = tf.nn.separable_conv2d(\n         x,\n         depthwise_kernel,\n         pointwise_kernel,\n         strides=strides,\n         padding=padding,\n-        rate=dilation_rate,\n+        dilations=dilation_rate,\n         data_format=tf_data_format,\n     )\n     if data_format == \"channels_first\" and tf_data_format == \"NHWC\":\n@@ -6445,12 +6445,12 @@ def depthwise_conv2d(\n     else:\n         strides = (1, 1) + strides\n \n-    x = tf.compat.v1.nn.depthwise_conv2d(\n+    x = tf.nn.depthwise_conv2d(\n         x,\n         depthwise_kernel,\n         strides=strides,\n         padding=padding,\n-        rate=dilation_rate,\n+        dilations=dilation_rate,\n         data_format=tf_data_format,\n     )\n     if data_format == \"channels_first\" and tf_data_format == \"NHWC\":\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d0b5e50e4da1ae59d304d7c2d7cfb77fec7cb76a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 78 | Lines Deleted: 75 | Files Changed: 8 | Hunks: 39 | Methods Changed: 19 | Complexity Δ (Sum/Max): 7/8 | Churn Δ: 153 | Churn Cumulative: 1511 | Contributors (this commit): 3 | Commits (past 90d): 49 | Contributors (cumulative): 17 | DMM Complexity: 1.0\n\nDIFF:\n@@ -14,7 +14,10 @@ class ExampleMetric(Metric):\n             name=\"sum\", shape=(), initializer=initializers.Zeros()\n         )\n         self.total = self.add_variable(\n-            name=\"total\", shape=(), initializer=initializers.Zeros(), dtype=\"int32\"\n+            name=\"total\",\n+            shape=(),\n+            initializer=initializers.Zeros(),\n+            dtype=\"int32\",\n         )\n \n     def update_state(self, y_true, y_pred):\n\n@@ -0,0 +1,3 @@\n+from keras_core.models.functional import Functional\n+from keras_core.models.model import Model\n+from keras_core.models.sequential import Sequential\n\n@@ -15,6 +15,7 @@ class FunctionalTest(testing.TestCase):\n         x = layers.Dense(5)(x)\n         outputs = layers.Dense(4)(x)\n         model = Functional([input_a, input_b], outputs)\n+        model.summary()\n \n         # Eager call\n         in_val = [np.random.random((2, 3)), np.random.random((2, 3))]\n\n@@ -1,6 +1,7 @@\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.trainers.trainer import Trainer\n+from keras_core.utils import summary_utils\n \n \n @keras_core_export([\"keras_core.Model\", \"keras_core.models.Model\"])\n@@ -123,13 +124,7 @@ class Model(Layer, Trainer):\n         Raises:\n             ValueError: if `summary()` is called before the model is built.\n         \"\"\"\n-        if not self.built:\n-            raise ValueError(\n-                \"This model has not yet been built. \"\n-                \"Build the model first by calling `build()` or by calling \"\n-                \"the model on a batch of data.\"\n-            )\n-        layer_utils.print_summary(\n+        summary_utils.print_summary(\n             self,\n             line_length=line_length,\n             positions=positions,\n@@ -148,9 +143,7 @@ class Model(Layer, Trainer):\n \n def functional_init_arguments(args, kwargs):\n     return (\n-        len(args) == 2\n-        or len(args) == 1\n-        and \"outputs\" in kwargs\n-        or \"inputs\" in kwargs\n-        and \"outputs\" in kwargs\n+        (len(args) == 2)\n+        or (len(args) == 1 and \"outputs\" in kwargs)\n+        or (\"inputs\" in kwargs and \"outputs\" in kwargs)\n     )\n\n@@ -14,6 +14,7 @@ class SequentialTest(testing.TestCase):\n         model.add(Input(shape=(2,), batch_size=3))\n         model.add(layers.Dense(4))\n         model.add(layers.Dense(5))\n+        model.summary()\n \n         self.assertEqual(len(model.layers), 2)\n \n@@ -21,6 +22,8 @@ class SequentialTest(testing.TestCase):\n         x = np.random.random((3, 2))\n         y = model(x)\n         self.assertTrue(model.built)\n+        model.summary()\n+\n         self.assertEqual(type(model._functional), Functional)\n         self.assertEqual(y.shape, (3, 5))\n \n@@ -55,6 +58,7 @@ class SequentialTest(testing.TestCase):\n         model = Sequential(name=\"seq\")\n         model.add(layers.Dense(4))\n         model.add(layers.Dense(5))\n+        model.summary()\n \n         self.assertEqual(len(model.layers), 2)\n \n@@ -62,6 +66,8 @@ class SequentialTest(testing.TestCase):\n         x = np.random.random((3, 2))\n         y = model(x)\n         self.assertTrue(model.built)\n+        model.summary()\n+\n         self.assertEqual(type(model._functional), Functional)\n         self.assertEqual(y.shape, (3, 5))\n \n@@ -101,6 +107,7 @@ class SequentialTest(testing.TestCase):\n         x = {\"a\": np.random.random((3, 2)), \"b\": np.random.random((3, 2))}\n         y = model(x)\n         self.assertEqual(type(y), dict)\n+        model.summary()\n \n     def test_errors(self):\n         # Trying to pass 2 Inputs\n\n@@ -53,14 +53,11 @@ class Node:\n                 )\n \n         # If inputs don't have metadata yet, add it.\n-        any_input_has_history = False\n         for tensor in self.arguments.keras_tensors:\n             if not hasattr(tensor, \"_keras_history\"):\n                 tensor._keras_history = KerasHistory(\n                     operation=None, node_index=0, tensor_index=0\n                 )\n-            else:\n-                any_input_has_history = True\n \n         # Wire up Node to Operations.\n         self.operation._inbound_nodes.append(self)\n\n@@ -94,7 +94,7 @@ class Operation:\n             The operation's attribute `attr` at the node of index `node_index`.\n         \"\"\"\n         if not self._inbound_nodes:\n-            raise RuntimeError(\n+            raise ValueError(\n                 f\"The layer {self.name} has never been called \"\n                 f\"and thus has no defined {attr_name}.\"\n             )\n\n@@ -9,13 +9,6 @@ from keras_core.utils import dtype_utils\n from keras_core.utils import io_utils\n from keras_core.utils import text_rendering\n \n-from tensorflow import nest\n-\n-from keras_core import backend\n-from keras_core.utils import dtype_utils\n-from keras_core.utils import io_utils\n-from keras_core.utils import text_rendering\n-\n \n def count_params(weights):\n     shapes = [v.shape for v in weights]\n@@ -31,7 +24,8 @@ def weight_memory_size(weights):\n     Returns:\n         The total memory size (in Bytes) of the weights.\n     \"\"\"\n-    unique_weights = set(weights)\n+    unique_weights_ids = set(id(w) for w in weights)\n+    unique_weights = [w for w in weights if id(w) in unique_weights_ids]\n     total_memory_size = 0\n     for w in unique_weights:\n         weight_shape = math.prod(w.shape)\n@@ -43,7 +37,7 @@ def weight_memory_size(weights):\n \n def readable_memory_size(weight_memory_size):\n     \"\"\"Convert the weight memory size (Bytes) to a readable string.\"\"\"\n-    units = [\"Byte\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\n+    units = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\n     scale = 1024\n     for unit in units:\n         if weight_memory_size / scale < 1:\n@@ -53,6 +47,23 @@ def readable_memory_size(weight_memory_size):\n     return \"{:.2f} {}\".format(weight_memory_size, units[-1])\n \n \n+def format_layer_shape(layer):\n+    if not layer._inbound_nodes:\n+        return \"?\"\n+    output_shapes = None\n+    for i in range(len(layer._inbound_nodes)):\n+        shapes = nest.map_structure(\n+            lambda x: tuple(x.shape), layer._inbound_nodes[i].output_tensors\n+        )\n+        if output_shapes is None:\n+            output_shapes = shapes\n+        elif output_shapes != shapes:\n+            return \"multiple\"\n+    if len(output_shapes) == 1 and isinstance(output_shapes[0], tuple):\n+        output_shapes = output_shapes[0]\n+    return str(output_shapes)\n+\n+\n def print_summary(\n     model,\n     line_length=None,\n@@ -97,17 +108,20 @@ def print_summary(\n \n     if isinstance(model, Sequential):\n         sequential_like = True\n+        layers = model.layers\n     elif not isinstance(model, Functional):\n         # We treat subclassed models as a simple sequence of layers, for logging\n         # purposes.\n         sequential_like = True\n+        layers = model.layers\n     else:\n+        layers = model._operations\n         sequential_like = True\n         nodes_by_depth = model._nodes_by_depth.values()\n         nodes = []\n         for v in nodes_by_depth:\n             if (len(v) > 1) or (\n-                len(v) == 1 and len(nest.flatten(v[0].keras_inputs)) > 1\n+                len(v) == 1 and len(nest.flatten(v[0].input_tensors)) > 1\n             ):\n                 # if the model has multiple nodes\n                 # or if the nodes have multiple inbound_layers\n@@ -148,16 +162,27 @@ def print_summary(\n         positions = [p * 0.86 for p in positions] + [1.0]\n         header.append(\"Trainable\")\n \n-    layer_range = get_layer_index_bound_by_layer_name(model, layer_range)\n+    layer_range = get_layer_index_bound_by_layer_name(layers, layer_range)\n \n     print_fn(text_rendering.highlight_msg(f' Model: \"{model.name}\"'))\n     rows = []\n \n-    def format_shape(shape):\n-        shape = tuple(shape)\n-        if len(shape) == 1 and isinstance(shape[0], tuple):\n-            shape = shape[0]\n-        return str(shape)\n+    def get_layer_fields(layer, prefix=\"\"):\n+        output_shape = format_layer_shape(layer)\n+        name = prefix + layer.name\n+        cls_name = layer.__class__.__name__\n+        if not getattr(layer, \"built\", False):\n+            # If a subclassed model has a layer that is not called in\n+            # Model.call, the layer will not be built and we cannot call\n+            # layer.count_params().\n+            params = \"0 (unused)\"\n+        else:\n+            params = layer.count_params()\n+        fields = [name + \" (\" + cls_name + \")\", output_shape, str(params)]\n+\n+        if show_trainable:\n+            fields.append(\"Y\" if layer.trainable else \"N\")\n+        return fields\n \n     def print_layer_summary(layer, prefix=\"\"):\n         \"\"\"Prints a summary for a single layer.\n@@ -167,23 +192,7 @@ def print_summary(\n             nested_level: level of nesting of the layer inside its parent layer\n               (e.g. 0 for a top-level layer, 1 for a nested layer).\n         \"\"\"\n-        try:\n-            output_shape = format_shape(layer.output_shape)\n-        except AttributeError:\n-            output_shape = \"multiple\"\n-        except RuntimeError:  # output_shape unknown in Eager mode.\n-            output_shape = \"?\"\n-        name = prefix + layer.name\n-        cls_name = layer.__class__.__name__\n-        if not layer.built:\n-            # If a subclassed model has a layer that is not called in\n-            # Model.call, the layer will not be built and we cannot call\n-            # layer.count_params().\n-            params = \"0 (unused)\"\n-        else:\n-            params = layer.count_params()\n-        fields = [name + \" (\" + cls_name + \")\", output_shape, str(params)]\n-\n+        fields = get_layer_fields(layer, prefix=prefix)\n         if show_trainable:\n             fields.append(\"Y\" if layer.trainable else \"N\")\n         rows.append(fields)\n@@ -196,31 +205,23 @@ def print_summary(\n             nested_level: level of nesting of the layer inside its parent layer\n               (e.g. 0 for a top-level layer, 1 for a nested layer).\n         \"\"\"\n-        try:\n-            output_shape = format_shape(layer.output_shape)\n-        except AttributeError:\n-            output_shape = \"multiple\"\n+        fields = get_layer_fields(layer, prefix=prefix)\n         connections = []\n         for node in layer._inbound_nodes:\n             if relevant_nodes and node not in relevant_nodes:\n                 # node is not part of the current network\n                 continue\n-            for kt in node.keras_inputs:\n+            for kt in node.input_tensors:\n                 keras_history = kt._keras_history\n-                inbound_layer = keras_history.layer\n+                inbound_layer = keras_history.operation\n                 node_index = keras_history.node_index\n                 tensor_index = keras_history.tensor_index\n                 connections.append(\n                     f\"{inbound_layer.name}[{node_index}][{tensor_index}]\"\n                 )\n-        name = prefix + layer.name\n-        cls_name = layer.__class__.__name__\n-        fields = [\n-            name + \" (\" + cls_name + \")\",\n-            output_shape,\n-            str(layer.count_params()),\n-            connections,\n-        ]\n+        if not connections:\n+            connections = \"-\"\n+        fields.append(connections)\n         if show_trainable:\n             fields.append(\"Y\" if layer.trainable else \"N\")\n         rows.append(fields)\n@@ -241,7 +242,7 @@ def print_summary(\n             for i in range(len(nested_layers)):\n                 print_layer(nested_layers[i], nested_level=nested_level)\n \n-    for layer in model.layers[layer_range[0] : layer_range[1]]:\n+    for layer in layers[layer_range[0] : layer_range[1]]:\n         print_layer(layer)\n \n     # Render summary as a table.\n@@ -279,24 +280,22 @@ def print_summary(\n     print_fn(\n         text_rendering.highlight_msg(\n             f\" Total params: {trainable_count + non_trainable_count}\"\n-            f\"({readable_memory_size(total_memory_size)})\"\n         )\n+        + f\" ({readable_memory_size(total_memory_size)})\"\n     )\n     print_fn(\n-        text_rendering.highlight_msg(\n-            f\" Trainable params: {trainable_count} \"\n-            f\"({readable_memory_size(trainable_memory_size)})\"\n-        )\n+        text_rendering.highlight_msg(f\" Trainable params: {trainable_count}\")\n+        + f\" ({readable_memory_size(trainable_memory_size)})\"\n     )\n     print_fn(\n         text_rendering.highlight_msg(\n             f\" Non-trainable params: {non_trainable_count}\"\n-            f\"({readable_memory_size(non_trainable_memory_size)})\"\n         )\n+        + f\" ({readable_memory_size(non_trainable_memory_size)})\"\n     )\n \n \n-def get_layer_index_bound_by_layer_name(model, layer_range=None):\n+def get_layer_index_bound_by_layer_name(layers, layer_range=None):\n     \"\"\"Get the layer indexes from the model based on layer names.\n \n     The layer indexes can be used to slice the model into sub models for\n@@ -326,16 +325,16 @@ def get_layer_index_bound_by_layer_name(model, layer_range=None):\n                 f\"Received: {layer_range}\"\n             )\n     else:\n-        return [0, len(model.layers)]\n+        return [0, len(layers)]\n \n     lower_index = [\n         idx\n-        for idx, layer in enumerate(model.layers)\n+        for idx, layer in enumerate(layers)\n         if re.match(layer_range[0], layer.name)\n     ]\n     upper_index = [\n         idx\n-        for idx, layer in enumerate(model.layers)\n+        for idx, layer in enumerate(layers)\n         if re.match(layer_range[1], layer.name)\n     ]\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fe87e2bf05260a80fe6194d74bc9216164f221ee", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 32 | Lines Deleted: 13 | Files Changed: 2 | Hunks: 13 | Methods Changed: 8 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 45 | Churn Cumulative: 353 | Contributors (this commit): 1 | Commits (past 90d): 12 | Contributors (cumulative): 2 | DMM Complexity: 0.8\n\nDIFF:\n@@ -17,9 +17,10 @@ class Sequential(Model):\n         self._layers = []\n         if layers:\n             for layer in layers:\n-                self.add(layer)\n+                self.add(layer, rebuild=False)\n+            self._maybe_rebuild()\n \n-    def add(self, layer):\n+    def add(self, layer, rebuild=True):\n         # If we are passed a Keras tensor created by keras.Input(), we\n         # extract the input layer from its keras history and use that.\n         if hasattr(layer, \"_keras_history\"):\n@@ -45,15 +46,29 @@ class Sequential(Model):\n             )\n \n         self._layers.append(layer)\n+        if rebuild:\n+            self._maybe_rebuild()\n+        else:\n             self.built = False\n             self._functional = None\n \n-    def pop(self):\n+    def pop(self, rebuild=True):\n         layer = self._layers.pop()\n+        if rebuild:\n+            self._maybe_rebuild()\n+        else:\n             self.built = False\n             self._functional = None\n         return layer\n \n+    def _maybe_rebuild(self):\n+        if isinstance(self._layers[0], InputLayer) and len(self._layers) > 1:\n+            input_shape = self._layers[0].batch_shape\n+            self.build(input_shape)\n+        else:\n+            self.built = False\n+            self._functional = None\n+\n     def build(self, input_shape=None):\n         if not isinstance(input_shape, (tuple, list)):\n             # Do not attempt to build if the model does not have a single input tensor.\n\n@@ -17,12 +17,12 @@ class SequentialTest(testing.TestCase):\n         model.summary()\n \n         self.assertEqual(len(model.layers), 2)\n+        self.assertTrue(model.built)\n+        self.assertEqual(len(model.weights), 4)\n \n         # Test eager call\n         x = np.random.random((3, 2))\n         y = model(x)\n-        self.assertTrue(model.built)\n-        model.summary()\n \n         self.assertEqual(type(model._functional), Functional)\n         self.assertEqual(y.shape, (3, 5))\n@@ -40,18 +40,22 @@ class SequentialTest(testing.TestCase):\n                 layers.Dense(5),\n             ]\n         )\n+        self.assertEqual(len(model.layers), 2)\n+        self.assertTrue(model.built)\n+        self.assertEqual(len(model.weights), 4)\n+\n         x = np.random.random((3, 2))\n         y = model(x)\n         self.assertEqual(y.shape, (3, 5))\n \n         # Test pop\n         model.pop()\n-        self.assertFalse(model.built)\n-        self.assertEqual(model._functional, None)\n+        self.assertEqual(len(model.layers), 1)\n+        self.assertTrue(model.built)\n+        self.assertEqual(len(model.weights), 2)\n+\n         x = np.random.random((3, 2))\n         y = model(x)\n-        self.assertTrue(model.built)\n-        self.assertEqual(type(model._functional), Functional)\n         self.assertEqual(y.shape, (3, 4))\n \n     def test_basic_flow_deferred(self):\n@@ -89,12 +93,12 @@ class SequentialTest(testing.TestCase):\n \n         # Test pop\n         model.pop()\n-        self.assertFalse(model.built)\n-        self.assertEqual(model._functional, None)\n+        self.assertEqual(len(model.layers), 1)\n+        self.assertTrue(model.built)\n+        self.assertEqual(len(model.weights), 2)\n+\n         x = np.random.random((3, 2))\n         y = model(x)\n-        self.assertTrue(model.built)\n-        self.assertEqual(type(model._functional), Functional)\n         self.assertEqual(y.shape, (3, 4))\n \n     def test_dict_inputs(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c6bd52ff38945eba2ec408a81e300a845d81f309", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 10 | Churn Cumulative: 25809 | Contributors (this commit): 144 | Commits (past 90d): 18 | Contributors (cumulative): 144 | DMM Complexity: 1.0\n\nDIFF:\n@@ -334,10 +334,18 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     def _init_batch_counters(self):\n         # Untracked Variables, used to keep track of mini-batches seen in `fit`,\n         # `evaluate`, and `predict`.\n+        if not tf.inside_function():\n+            # Creating variables inside tf.function is not allowed, hence\n+            # these would otherwise prevent users from creating Keras layers\n+            # inside tf.function.\n+            # These variables are not connected to outputs so they have no\n+            # effect on graph generation anyway.\n             agg = tf.VariableAggregation.ONLY_FIRST_REPLICA\n             self._train_counter = tf.Variable(0, dtype=\"int64\", aggregation=agg)\n             self._test_counter = tf.Variable(0, dtype=\"int64\", aggregation=agg)\n-        self._predict_counter = tf.Variable(0, dtype=\"int64\", aggregation=agg)\n+            self._predict_counter = tf.Variable(\n+                0, dtype=\"int64\", aggregation=agg\n+            )\n \n     def __setattr__(self, name, value):\n         if not getattr(self, \"_self_setattr_tracking\", True):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#395df51ab7db7db0495d003f61a664c620957efc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 29 | Lines Deleted: 53 | Files Changed: 2 | Hunks: 16 | Methods Changed: 7 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 82 | Churn Cumulative: 1468 | Contributors (this commit): 3 | Commits (past 90d): 17 | Contributors (cumulative): 5 | DMM Complexity: 0.5\n\nDIFF:\n@@ -145,12 +145,12 @@ def print_summary(\n \n     if sequential_like:\n         line_length = line_length or 84\n-        positions = positions or [0.45, 0.85, 1.0]\n+        positions = positions or [0.45, 0.84, 1.0]\n         # header names for the different log elements\n         header = [\"Layer (type)\", \"Output Shape\", \"Param #\"]\n     else:\n-        line_length = line_length or 100\n-        positions = positions or [0.3, 0.6, 0.70, 1.0]\n+        line_length = line_length or 108\n+        positions = positions or [0.3, 0.56, 0.70, 1.0]\n         # header names for the different log elements\n         header = [\"Layer (type)\", \"Output Shape\", \"Param #\", \"Connected to\"]\n         relevant_nodes = []\n@@ -162,20 +162,14 @@ def print_summary(\n         positions = [p * 0.86 for p in positions] + [1.0]\n         header.append(\"Trainable\")\n \n-    layer_range = get_layer_index_bound_by_layer_name(layers, layer_range)\n-\n-    print_fn(text_rendering.highlight_msg(f' Model: \"{model.name}\"'))\n-    rows = []\n-\n     def get_layer_fields(layer, prefix=\"\"):\n         output_shape = format_layer_shape(layer)\n         name = prefix + layer.name\n         cls_name = layer.__class__.__name__\n-        if not getattr(layer, \"built\", False):\n-            # If a subclassed model has a layer that is not called in\n-            # Model.call, the layer will not be built and we cannot call\n-            # layer.count_params().\n-            params = \"0 (unused)\"\n+        if not hasattr(layer, \"built\"):\n+            params = \"0\"\n+        elif not layer.built:\n+            params = \"0 (unbuilt)\"\n         else:\n             params = layer.count_params()\n         fields = [name + \" (\" + cls_name + \")\", output_shape, str(params)]\n@@ -184,29 +178,8 @@ def print_summary(\n             fields.append(\"Y\" if layer.trainable else \"N\")\n         return fields\n \n-    def print_layer_summary(layer, prefix=\"\"):\n-        \"\"\"Prints a summary for a single layer.\n-\n-        Args:\n-            layer: target layer.\n-            nested_level: level of nesting of the layer inside its parent layer\n-              (e.g. 0 for a top-level layer, 1 for a nested layer).\n-        \"\"\"\n-        fields = get_layer_fields(layer, prefix=prefix)\n-        if show_trainable:\n-            fields.append(\"Y\" if layer.trainable else \"N\")\n-        rows.append(fields)\n-\n-    def print_layer_summary_with_connections(layer, prefix=\"\"):\n-        \"\"\"Prints a summary for a single layer (including its connections).\n-\n-        Args:\n-            layer: target layer.\n-            nested_level: level of nesting of the layer inside its parent layer\n-              (e.g. 0 for a top-level layer, 1 for a nested layer).\n-        \"\"\"\n-        fields = get_layer_fields(layer, prefix=prefix)\n-        connections = []\n+    def get_connections(layer):\n+        connections = \"\"\n         for node in layer._inbound_nodes:\n             if relevant_nodes and node not in relevant_nodes:\n                 # node is not part of the current network\n@@ -216,34 +189,42 @@ def print_summary(\n                 inbound_layer = keras_history.operation\n                 node_index = keras_history.node_index\n                 tensor_index = keras_history.tensor_index\n-                connections.append(\n+                if connections:\n+                    connections += \", \"\n+                connections += (\n                     f\"{inbound_layer.name}[{node_index}][{tensor_index}]\"\n                 )\n         if not connections:\n             connections = \"-\"\n-        fields.append(connections)\n-        if show_trainable:\n-            fields.append(\"Y\" if layer.trainable else \"N\")\n-        rows.append(fields)\n+        return connections\n \n     def print_layer(layer, nested_level=0):\n         if nested_level:\n             prefix = \"   \" * nested_level + \"└\" + \" \"\n         else:\n             prefix = \"\"\n-        if sequential_like:\n-            print_layer_summary(layer, prefix=prefix)\n-        else:\n-            print_layer_summary_with_connections(layer, prefix=prefix)\n \n+        fields = get_layer_fields(layer, prefix=prefix)\n+        if not sequential_like:\n+            fields.append(get_connections(layer))\n+        if show_trainable:\n+            fields.append(\"Y\" if layer.trainable else \"N\")\n+\n+        rows = [fields]\n         if expand_nested and hasattr(layer, \"layers\") and layer.layers:\n             nested_layers = layer.layers\n             nested_level += 1\n             for i in range(len(nested_layers)):\n+                rows.extend(\n                     print_layer(nested_layers[i], nested_level=nested_level)\n+                )\n+        return rows\n \n+    layer_range = get_layer_index_bound_by_layer_name(layers, layer_range)\n+    print_fn(text_rendering.highlight_msg(f' Model: \"{model.name}\"'))\n+    rows = []\n     for layer in layers[layer_range[0] : layer_range[1]]:\n-        print_layer(layer)\n+        rows.extend(print_layer(layer))\n \n     # Render summary as a table.\n     table = text_rendering.TextTable(\n@@ -254,13 +235,8 @@ def print_summary(\n         alignments=[\"left\"] + [\"center\" for _ in range(len(header) - 1)],\n         max_line_length=line_length,\n     )\n-    try:\n     table_str = table.make()\n     print_fn(table_str)\n-    except UnicodeEncodeError:\n-        printable = set(string.printable)\n-        table_str = filter(lambda x: x in printable, table_str)\n-        print_fn(table_str)\n \n     # After the table, append information about parameter count and size.\n     if hasattr(model, \"_collected_trainable_weights\"):\n\n@@ -63,8 +63,8 @@ class TextTable:\n     ):\n         alignments = alignments or [\"center\" for _ in fields]\n         lines = []\n-        line_break_chars_post = (\")\", \"}\", \"]\")\n-        line_break_chars_pre = (\"(\", \"{\", \"[\")\n+        line_break_chars_post = (\"),\", \"],\")\n+        line_break_chars_pre = (\"(\", \"[\")\n         for field, width, alignment in zip(\n             fields, self.column_widths, alignments\n         ):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3cf1620ff5716f05b088fc986ca55fa8ea6bfe93", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 2 | Files Changed: 3 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 49/46 | Churn Δ: 19 | Churn Cumulative: 6641 | Contributors (this commit): 20 | Commits (past 90d): 12 | Contributors (cumulative): 31 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1555,8 +1555,11 @@ def get_network_config(network, serialize_layer_fn=None, config=None):\n     \"\"\"\n     config = config or {}\n     serialize_obj_fn = serialization_lib.serialize_keras_object\n-    if \"module\" not in config:\n+    set_layers_legacy = False\n+    # To be removed after full affected g3 user migration to Keras V3 Saving.\n+    if getattr(network, \"use_legacy_config\", False):\n         serialize_obj_fn = serialization.serialize_keras_object\n+        set_layers_legacy = True\n     serialize_layer_fn = serialize_layer_fn or serialize_obj_fn\n     config[\"name\"] = network.name\n     node_conversion_map = {}\n@@ -1582,6 +1585,8 @@ def get_network_config(network, serialize_layer_fn=None, config=None):\n                     )\n                     filtered_inbound_nodes.append(node_data)\n \n+            if isinstance(layer, Functional) and set_layers_legacy:\n+                layer.use_legacy_config = True\n             layer_config = serialize_layer_fn(layer)\n             layer_config[\"name\"] = layer.name\n             layer_config[\"inbound_nodes\"] = filtered_inbound_nodes\n\n@@ -29,6 +29,7 @@ from keras.engine.input_layer import Input\n from keras.engine.input_layer import InputLayer\n from keras.optimizers import optimizer_v1\n from keras.saving.legacy import serialization\n+from keras.saving.legacy.saved_model.utils import keras_option_scope\n from keras.saving.object_registration import CustomObjectScope\n from keras.utils import generic_utils\n from keras.utils import version_utils\n@@ -209,6 +210,15 @@ def _clone_functional_model(model, input_tensors=None, layer_fn=_clone_layer):\n             f\"Received: layer_fn={layer_fn}\"\n         )\n \n+    # For affected g3 users who need to default to old serialization in cloning\n+    if getattr(model, \"use_legacy_config\", False):\n+        with keras_option_scope(\n+            save_traces=False, in_tf_saved_model_scope=True\n+        ):\n+            model_configs, created_layers = _clone_layers_and_model_config(\n+                model, new_input_layers, layer_fn\n+            )\n+    else:\n         model_configs, created_layers = _clone_layers_and_model_config(\n             model, new_input_layers, layer_fn\n         )\n\n@@ -369,7 +369,7 @@ class MyDense(keras.layers.Layer):\n         )\n \n     def build(self, input_shape):\n-        unused_batch_size, input_units = input_shape.as_list()\n+        unused_batch_size, input_units = input_shape\n         self._kernel = self.add_weight(\n             \"kernel\",\n             [input_units, self._units],\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#470141f55b7c53e3b676c642477bcbd15ba4b55a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 261 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 5 | Complexity Δ (Sum/Max): 43/43 | Churn Δ: 261 | Churn Cumulative: 261 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 0.15286624203821655\n\nDIFF:\n@@ -0,0 +1,261 @@\n+from keras_core.utils import io_utils\n+from keras_core.api_export import keras_core_export\n+import sys\n+import os\n+import time\n+import math\n+import numpy as np\n+\n+\n+@keras_core_export(\"keras_core.utils.Progbar\")\n+class Progbar:\n+    \"\"\"Displays a progress bar.\n+\n+    Args:\n+        target: Total number of steps expected, None if unknown.\n+        width: Progress bar width on screen.\n+        verbose: Verbosity mode, 0 (silent), 1 (verbose), 2 (semi-verbose)\n+        stateful_metrics: Iterable of string names of metrics that should *not*\n+            be averaged over time. Metrics in this list will be displayed as-is.\n+            All others will be averaged by the progbar before display.\n+        interval: Minimum visual progress update interval (in seconds).\n+        unit_name: Display name for step counts (usually \"step\" or \"sample\").\n+    \"\"\"\n+    def __init__(\n+        self,\n+        target,\n+        width=20,\n+        verbose=1,\n+        interval=0.05,\n+        stateful_metrics=None,\n+        unit_name=\"step\",\n+    ):\n+        self.target = target\n+        self.width = width\n+        self.verbose = verbose\n+        self.interval = interval\n+        self.unit_name = unit_name\n+        if stateful_metrics:\n+            self.stateful_metrics = set(stateful_metrics)\n+        else:\n+            self.stateful_metrics = set()\n+\n+        self._dynamic_display = (\n+            (hasattr(sys.stdout, \"isatty\") and sys.stdout.isatty())\n+            or \"ipykernel\" in sys.modules\n+            or \"posix\" in sys.modules\n+            or \"PYCHARM_HOSTED\" in os.environ\n+        )\n+        self._total_width = 0\n+        self._seen_so_far = 0\n+        # We use a dict + list to avoid garbage collection\n+        # issues found in OrderedDict\n+        self._values = {}\n+        self._values_order = []\n+        self._start = time.time()\n+        self._last_update = 0\n+        self._time_at_epoch_start = self._start\n+        self._time_after_first_step = None\n+\n+    def update(self, current, values=None, finalize=None):\n+        \"\"\"Updates the progress bar.\n+\n+        Args:\n+            current: Index of current step.\n+            values: List of tuples: `(name, value_for_last_step)`. If `name` is\n+                in `stateful_metrics`, `value_for_last_step` will be displayed\n+                as-is. Else, an average of the metric over time will be\n+                displayed.\n+            finalize: Whether this is the last update for the progress bar. If\n+                `None`, defaults to `current >= self.target`.\n+        \"\"\"\n+        if finalize is None:\n+            if self.target is None:\n+                finalize = False\n+            else:\n+                finalize = current >= self.target\n+\n+        values = values or []\n+        for k, v in values:\n+            if k not in self._values_order:\n+                self._values_order.append(k)\n+            if k not in self.stateful_metrics:\n+                # In the case that progress bar doesn't have a target value in\n+                # the first epoch, both on_batch_end and on_epoch_end will be\n+                # called, which will cause 'current' and 'self._seen_so_far' to\n+                # have the same value. Force the minimal value to 1 here,\n+                # otherwise stateful_metric will be 0s.\n+                value_base = max(current - self._seen_so_far, 1)\n+                if k not in self._values:\n+                    self._values[k] = [v * value_base, value_base]\n+                else:\n+                    self._values[k][0] += v * value_base\n+                    self._values[k][1] += value_base\n+            else:\n+                # Stateful metrics output a numeric value. This representation\n+                # means \"take an average from a single value\" but keeps the\n+                # numeric formatting.\n+                self._values[k] = [v, 1]\n+        self._seen_so_far = current\n+\n+        message = \"\"\n+        now = time.time()\n+        time_per_unit = self._estimate_step_duration(current, now)\n+\n+        if self.verbose == 1:\n+            if now - self._last_update < self.interval and not finalize:\n+                return\n+\n+            prev_total_width = self._total_width\n+            if self._dynamic_display:\n+                message += \"\\b\" * prev_total_width\n+                message += \"\\r\"\n+            else:\n+                message += \"\\n\"\n+\n+            if self.target is not None:\n+                numdigits = int(math.log10(self.target)) + 1\n+                bar = (\"%\" + str(numdigits) + \"d/%d\") % (current, self.target)\n+                bar = f\"\\x1b[1m{bar}\\x1b[0m \"\n+                prog = float(current) / self.target\n+                prog_width = int(self.width * prog)\n+\n+                if prog_width > 0:\n+                    bar += \"\\33[32m\" + \"━\" * prog_width + \"\\x1b[0m\"\n+\n+                bar += \"\\33[37m\" + \"━\" * (self.width - prog_width) + \"\\x1b[0m\"\n+\n+            else:\n+                bar = \"%7d/Unknown\" % current\n+\n+            self._total_width = len(bar)\n+            message += bar\n+\n+            # Add ETA if applicable\n+            if self.target is not None and not finalize:\n+                eta = time_per_unit * (self.target - current)\n+                if eta > 3600:\n+                    eta_format = \"%d:%02d:%02d\" % (\n+                        eta // 3600,\n+                        (eta % 3600) // 60,\n+                        eta % 60,\n+                    )\n+                elif eta > 60:\n+                    eta_format = \"%d:%02d\" % (eta // 60, eta % 60)\n+                else:\n+                    eta_format = \"%ds\" % eta\n+                info = f\" \\x1b[1m{eta_format}\\x1b[0m\"\n+            else:\n+                # Time elapsed since start, in seconds\n+                info = f\" \\x1b[1m{now - self._start:.0f}s\\x1b[0m\"\n+\n+            # Add time/step\n+            info += self._format_time(time_per_unit, self.unit_name)\n+\n+            # Add metrics\n+            for k in self._values_order:\n+                info += f\" - {k}:\"\n+                if isinstance(self._values[k], list):\n+                    avg = np.mean(\n+                        self._values[k][0] / max(1, self._values[k][1])\n+                    )\n+                    if abs(avg) > 1e-3:\n+                        info += f\" {avg:.4f}\"\n+                    else:\n+                        info += f\" {avg:.4e}\"\n+                else:\n+                    info += f\" {self._values[k]}\"\n+\n+            self._total_width += len(info)\n+            if prev_total_width > self._total_width:\n+                info += \" \" * (prev_total_width - self._total_width)\n+\n+            if finalize:\n+                info += \"\\n\"\n+\n+            message += info\n+            io_utils.print_msg(message, line_break=False)\n+            message = \"\"\n+\n+        elif self.verbose == 2:\n+            if finalize:\n+                numdigits = int(math.log10(self.target)) + 1\n+                count = (\"%\" + str(numdigits) + \"d/%d\") % (current, self.target)\n+                info = f\"{count} - {now - self._start:.0f}s\"\n+                info += \" -\" + self._format_time(time_per_unit, self.unit_name)\n+                for k in self._values_order:\n+                    info += f\" - {k}:\"\n+                    avg = np.mean(\n+                        self._values[k][0] / max(1, self._values[k][1])\n+                    )\n+                    if avg > 1e-3:\n+                        info += f\" {avg:.4f}\"\n+                    else:\n+                        info += f\" {avg:.4e}\"\n+                info += \"\\n\"\n+                message += info\n+                io_utils.print_msg(message, line_break=False)\n+                message = \"\"\n+\n+        self._last_update = now\n+\n+    def add(self, n, values=None):\n+        self.update(self._seen_so_far + n, values)\n+\n+    def _format_time(self, time_per_unit, unit_name):\n+        \"\"\"format a given duration to display to the user.\n+\n+        Given the duration, this function formats it in either milliseconds\n+        or seconds and displays the unit (i.e. ms/step or s/epoch).\n+\n+        Args:\n+            time_per_unit: the duration to display\n+            unit_name: the name of the unit to display\n+\n+        Returns:\n+            A string with the correctly formatted duration and units\n+        \"\"\"\n+        formatted = \"\"\n+        if time_per_unit >= 1 or time_per_unit == 0:\n+            formatted += f\" {time_per_unit:.0f}s/{unit_name}\"\n+        elif time_per_unit >= 1e-3:\n+            formatted += f\" {time_per_unit * 1000.0:.0f}ms/{unit_name}\"\n+        else:\n+            formatted += f\" {time_per_unit * 1000000.0:.0f}us/{unit_name}\"\n+        return formatted\n+\n+    def _estimate_step_duration(self, current, now):\n+        \"\"\"Estimate the duration of a single step.\n+\n+        Given the step number `current` and the corresponding time `now` this\n+        function returns an estimate for how long a single step takes. If this\n+        is called before one step has been completed (i.e. `current == 0`) then\n+        zero is given as an estimate. The duration estimate ignores the duration\n+        of the (assumed to be non-representative) first step for estimates when\n+        more steps are available (i.e. `current>1`).\n+\n+        Args:\n+            current: Index of current step.\n+            now: The current time.\n+\n+        Returns: Estimate of the duration of a single step.\n+        \"\"\"\n+        if current:\n+            # there are a few special scenarios here:\n+            # 1) somebody is calling the progress bar without ever supplying\n+            #    step 1\n+            # 2) somebody is calling the progress bar and supplies step one\n+            #    multiple times, e.g. as part of a finalizing call\n+            # in these cases, we just fall back to the simple calculation\n+            if self._time_after_first_step is not None and current > 1:\n+                time_per_unit = (now - self._time_after_first_step) / (\n+                    current - 1\n+                )\n+            else:\n+                time_per_unit = (now - self._start) / current\n+\n+            if current == 1:\n+                self._time_after_first_step = now\n+            return time_per_unit\n+        else:\n+            return 0\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
