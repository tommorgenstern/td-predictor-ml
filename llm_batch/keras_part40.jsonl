{"custom_id": "keras#0354e64521c3081d1b8aadb60845182aeadc17c8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 526 | Contributors (this commit): 4 | Commits (past 90d): 20 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -286,8 +286,8 @@ class TestSequential(unittest.TestCase):\n                 s += X[i]\n             return s\n \n-        def output_shape(layers):\n-            return layers[0].output_shape\n+        def output_shape(input_shapes):\n+            return input_shapes[0]\n \n         left = Sequential()\n         left.add(Dense(nb_hidden, input_shape=(input_dim,)))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#79e702ec53182f6efa9c8195c52dbf55dc7dd173", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 9 | Churn Cumulative: 535 | Contributors (this commit): 4 | Commits (past 90d): 21 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2,6 +2,7 @@ from __future__ import absolute_import\n from __future__ import print_function\n import unittest\n import numpy as np\n+import theano\n np.random.seed(1337)\n \n from keras.models import Sequential, model_from_json, model_from_yaml\n@@ -286,6 +287,9 @@ class TestSequential(unittest.TestCase):\n                 s += X[i]\n             return s\n             \n+        def activation(X):\n+          return theano.tensor.nnet.softmax(X)\n+          \n         def output_shape(input_shapes):\n             return input_shapes[0]\n \n@@ -302,7 +306,7 @@ class TestSequential(unittest.TestCase):\n         model.add(LambdaMerge([left, right], function=func, output_shape=output_shape))\n \n         model.add(Dense(nb_class))\n-        model.add(Activation('softmax'))\n+        model.add(Lambda(activation))\n \n         model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n \n@@ -333,7 +337,7 @@ class TestSequential(unittest.TestCase):\n         model = Sequential()\n         model.add(LambdaMerge([left, right], function=func, output_shape=output_shape))\n         model.add(Dense(nb_class))\n-        model.add(Activation('softmax'))\n+        model.add(Lambda(activation))\n         model.load_weights('temp.h5')\n         model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n \n@@ -343,6 +347,7 @@ class TestSequential(unittest.TestCase):\n         \n         print ('test serializing')\n         func = None # Make sure that the model has the function code, not just the function name.\n+        activation = None\n         model_str = pickle.dumps(model)\n         model = pickle.loads(model_str)\n         nloss = model.evaluate([X_train, X_train], y_train, verbose=0)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fb24dc1904411c80b69e694b707716e61c1c2606", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2709 | Contributors (this commit): 25 | Commits (past 90d): 64 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -932,7 +932,7 @@ class Lambda(Layer):\n         else:\n             self.function = marshal.dumps(function.func_code)\n         if output_shape is None:\n-            output_shape = input_shape\n+            output_shape = self.input_shape\n         elif type(output_shape) in {tuple, list}:\n             self._output_shape = tuple(output_shape)\n         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8ee2ffd7e1116bd15218f51c51a2bec77467b3da", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 12 | Churn Cumulative: 2721 | Contributors (this commit): 25 | Commits (past 90d): 64 | Contributors (cumulative): 25 | DMM Complexity: 1.0\n\nDIFF:\n@@ -932,7 +932,7 @@ class Lambda(Layer):\n         else:\n             self.function = marshal.dumps(function.func_code)\n         if output_shape is None:\n-            output_shape = self.input_shape\n+            self._output_shape = None\n         elif type(output_shape) in {tuple, list} :\n             self._output_shape = tuple(output_shape)\n         else:\n@@ -943,7 +943,9 @@ class Lambda(Layer):\n \n     @property\n     def output_shape(self):\n-        if type(self._output_shape) == tuple:\n+        if self._ouput_shape is None:\n+            return self.input_shape\n+        elif type(self._output_shape) == tuple:\n             return self._output_shape\n         else:\n             output_shape_func = marshal.loads(self._output_shape)\n@@ -1006,7 +1008,7 @@ class LambdaMerge(Lambda):\n         else:\n             self.function = marshal.dumps(function.func_code)\n         if output_shape is None:\n-            output_shape = input_shape\n+            self._output_shape = None\n         elif type(output_shape) in {tuple, list}:\n             self._output_shape = tuple(output_shape)\n         else:\n@@ -1017,7 +1019,9 @@ class LambdaMerge(Lambda):\n \n     @property\n     def output_shape(self):\n-        if type(self._output_shape) == tuple:\n+        if self._output_shape is None:\n+            return self.input_shape\n+        elif type(self._output_shape) == tuple:\n             return self._output_shape\n         else:\n             output_shape_func = marshal.loads(self._output_shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2f8b351c9571dfa0582af7aad0e915d769d8664d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2723 | Contributors (this commit): 25 | Commits (past 90d): 65 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -1020,7 +1020,7 @@ class LambdaMerge(Lambda):\n     @property\n     def output_shape(self):\n         if self._output_shape is None:\n-            return self.input_shape\n+            return self.layers[0].input_shape\n         elif type(self._output_shape) == tuple:\n             return self._output_shape\n         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#469640bd4514fce055f037bfe1155a02f37eb25c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 537 | Contributors (this commit): 4 | Commits (past 90d): 22 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -10,6 +10,7 @@ from keras.layers.core import Dense, Activation, Merge, Lambda, LambdaMerge\n from keras.utils import np_utils\n from keras.utils.test_utils import get_test_data\n import pickle\n+import sys\n \n input_dim = 32\n nb_hidden = 16\n@@ -348,6 +349,7 @@ class TestSequential(unittest.TestCase):\n         print ('test serializing')\n         func = None # Make sure that the model has the function code, not just the function name.\n         activation = None\n+        sys.setrecursionlimit(50000)\n         model_str = pickle.dumps(model)\n         model = pickle.loads(model_str)\n         nloss = model.evaluate([X_train, X_train], y_train, verbose=0)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#66ad0bf736924305aa00d7e60a2aa34e721f294b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 20 | Files Changed: 2 | Hunks: 14 | Methods Changed: 10 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 38 | Churn Cumulative: 3204 | Contributors (this commit): 29 | Commits (past 90d): 28 | Contributors (cumulative): 33 | DMM Complexity: 0.3333333333333333\n\nDIFF:\n@@ -105,29 +105,29 @@ def standardize_weights(y, sample_weight=None, class_weight=None):\n         return np.ones(y.shape[:-1] + (1,))\n \n \n-def model_from_yaml(yaml_string, custom_layers={}):\n+def model_from_yaml(yaml_string, custom_objects={}):\n     '''\n         Returns a model generated from a local yaml file,\n         which is either created by hand or from to_yaml method of Sequential or Graph\n     '''\n     import yaml\n     config = yaml.load(yaml_string)\n-    return model_from_config(config, custom_layers=custom_layers)\n+    return model_from_config(config, custom_objects=custom_objects)\n \n \n-def model_from_json(json_string, custom_layers={}):\n+def model_from_json(json_string, custom_objects={}):\n     import json\n     config = json.loads(json_string)\n-    return model_from_config(config, custom_layers=custom_layers)\n+    return model_from_config(config, custom_objects=custom_objects)\n \n \n-def model_from_config(config, custom_layers={}):\n+def model_from_config(config, custom_objects={}):\n     model_name = config.get('name')\n     if model_name not in {'Graph', 'Sequential'}:\n         raise Exception('Unrecognized model:', model_name)\n \n     # Create a container then set class to appropriate model\n-    model = container_from_config(config, custom_layers=custom_layers)\n+    model = container_from_config(config, custom_objects=custom_objects)\n     if model_name == 'Graph':\n         model.__class__ = Graph\n     elif model_name == 'Sequential':\n\n@@ -17,16 +17,20 @@ from .. import regularizers\n from .. import constraints\n \n \n-def container_from_config(original_layer_dict, custom_layers={}):\n+def container_from_config(original_layer_dict, custom_objects={}):\n     layer_dict = copy.deepcopy(original_layer_dict)\n     name = layer_dict.get('name')\n \n+    # Insert custom layers into globals so they can be accessed by `get_from_module`.\n+    for cls_key in custom_objects:\n+        globals()[cls_key] = custom_objects[cls_key]\n+\n     if name == 'Merge':\n         mode = layer_dict.get('mode')\n         layers = layer_dict.get('layers')\n         layer_list = []\n         for layer in layers:\n-            init_layer = container_from_config(layer, custom_layers=custom_layers)\n+            init_layer = container_from_config(layer)\n             layer_list.append(init_layer)\n         merge_layer = Merge(layer_list, mode)\n         return merge_layer\n@@ -35,7 +39,7 @@ def container_from_config(original_layer_dict, custom_layers={}):\n         layers = layer_dict.get('layers')\n         layer_list = []\n         for layer in layers:\n-            init_layer = container_from_config(layer, custom_layers=custom_layers)\n+            init_layer = container_from_config(layer)\n             layer_list.append(init_layer)\n         seq_layer = containers.Sequential(layer_list)\n         return seq_layer\n@@ -49,8 +53,7 @@ def container_from_config(original_layer_dict, custom_layers={}):\n \n         nodes = layer_dict.get('node_config')\n         for node in nodes:\n-            layer = container_from_config(layer_dict['nodes'].get(node['name']),\n-                                          custom_layers=custom_layers)\n+            layer = container_from_config(layer_dict['nodes'].get(node['name']))\n             node['layer'] = layer\n             graph_layer.add_node(**node)\n \n@@ -60,10 +63,8 @@ def container_from_config(original_layer_dict, custom_layers={}):\n         return graph_layer\n \n     elif name == 'AutoEncoder':\n-        kwargs = {'encoder': container_from_config(layer_dict.get('encoder_config'),\n-                                                   custom_layers=custom_layers),\n-                  'decoder': container_from_config(layer_dict.get('decoder_config'),\n-                                                   custom_layers=custom_layers)}\n+        kwargs = {'encoder': container_from_config(layer_dict.get('encoder_config')),\n+                  'decoder': container_from_config(layer_dict.get('decoder_config'))}\n         for kwarg in ['output_reconstruction', 'weights']:\n             if kwarg in layer_dict:\n                 kwargs[kwarg] = layer_dict[kwarg]\n@@ -82,7 +83,7 @@ def container_from_config(original_layer_dict, custom_layers={}):\n                 else: # not a regularizer of constraint, don't touch it\n                     v['name'] = vname\n \n-        base_layer = get_layer(name, layer_dict, custom_layers=custom_layers)\n+        base_layer = get_layer(name, layer_dict)\n         return base_layer\n \n \n@@ -124,8 +125,5 @@ def print_layer_shapes(model, input_shapes):\n \n \n from .generic_utils import get_from_module\n-def get_layer(identifier, kwargs=None, custom_layers={}):\n-    # Insert custom layers into globals so they can be accessed by `get_from_module`.\n-    for cls_key in custom_layers:\n-        globals()[cls_key] = custom_layers[cls_key]\n+def get_layer(identifier, kwargs=None):\n     return get_from_module(identifier, globals(), 'layer', instantiate=True, kwargs=kwargs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bae645b65e9b4199233f4ab7c1679f3b9430e78c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -28/0 | Churn Δ: 4 | Churn Cumulative: 2727 | Contributors (this commit): 25 | Commits (past 90d): 66 | Contributors (cumulative): 25 | DMM Complexity: 0.0\n\nDIFF:\n@@ -453,9 +453,7 @@ class Dropout(MaskedLayer):\n         if self.p > 0.:\n             retain_prob = 1. - self.p\n             if train:\n-                X *= self.srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n-            else:\n-                X *= retain_prob\n+                X *= self.srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX) / retain_prob\n         return X\n \n     def get_config(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#18f122e1d98458ec60e7ea6473c440dae93ddf6f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 2734 | Contributors (this commit): 25 | Commits (past 90d): 67 | Contributors (cumulative): 25 | DMM Complexity: 0.0\n\nDIFF:\n@@ -295,11 +295,14 @@ class Merge(Layer):\n                 raise Exception(mode + \" merge takes exactly 2 layers\")\n             shape1 = layers[0].output_shape\n             shape2 = layers[1].output_shape\n+            n1 = len(shape1)\n+            n2 = len(shape2)\n             if mode == 'dot':\n                 if type(dot_axes) == int:\n                     if dot_axes < 0:\n-                        dot_axes = dot_axes % len(shape1)\n-                    dot_axes = [range(len(shape1) - dot_axes, len(shape2)), range(1, dot_axes + 1)]\n+                        dot_axes = [range(dot_axes % n1,n1), range(dot_axes % n2,n2)]\n+                    else:\n+                        dot_axes = [range(n1 - dot_axes, n2), range(1, dot_axes + 1)]\n                 for i in range(len(dot_axes[0])):\n                     if shape1[dot_axes[0][i]] != shape2[dot_axes[1][i]]:\n                         raise Exception(\" Dot incompatible layers can not be merged using dot mode\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a2d01238af24c38a84b5eca1a719bc1b69029174", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 222 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -34,7 +34,7 @@ class TestTasks(unittest.TestCase):\n         model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n         history = model.fit(X_train, y_train, nb_epoch=15, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)\n         print(history.history)\n-        self.assertTrue(history.history['val_acc'][-1] > 0.9)\n+        self.assertTrue(history.history['val_acc'][-1] > 0.8)\n \n     def test_vector_reg(self):\n         nb_hidden = 10\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#43bf884b5f76232284e27a9d10ae7f76641db023", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 239 | Contributors (this commit): 7 | Commits (past 90d): 3 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -13,6 +13,8 @@ else:\n def mean_squared_error(y_true, y_pred):\n     return T.sqr(y_pred - y_true).mean(axis=-1)\n     \n+def root_mean_squared_error(y_true, y_pred):\n+    return T.sqrt(T.sqr(y_pred - y_true).mean(axis=-1))\n \n def mean_absolute_error(y_true, y_pred):\n     return T.abs_(y_pred - y_true).mean(axis=-1)\n@@ -55,6 +57,7 @@ def poisson_loss(y_true, y_pred):\n \n # aliases\n mse = MSE = mean_squared_error\n+rmse = RMSE = root_mean_squared_error\n mae = MAE = mean_absolute_error\n mape = MAPE = mean_absolute_percentage_error\n msle = MSLE = mean_squared_logarithmic_error\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#42e582b1baf27f6ab15bea61820aa2b7cb9ecd81", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 291 | Contributors (this commit): 8 | Commits (past 90d): 7 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -88,7 +88,7 @@ class WordContextProduct(Layer):\n     '''\n         This layer turns a pair of words (a pivot word + a context word,\n         ie. a word from the same context, or a random, out-of-context word),\n-        indentified by their index in a vocabulary, into two dense reprensentations\n+        identified by their index in a vocabulary, into two dense representations\n         (word representation and context representation).\n \n         Then it returns activation(dot(pivot_embedding, context_embedding)),\n@@ -105,7 +105,7 @@ class WordContextProduct(Layer):\n         input_dim is the size of the vocabulary.\n \n         For more context, see Mikolov et al.:\n-            Efficient Estimation of Word reprensentations in Vector Space\n+            Efficient Estimation of Word representations in Vector Space\n             http://arxiv.org/pdf/1301.3781v3.pdf\n     '''\n     input_ndim = 2\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8f2810bfeee98c6c01c6a76b481dafa24e142666", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 34 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -34,7 +34,6 @@ def binary_logloss(p, y):\n \n \n def multiclass_logloss(P, Y):\n-    score = 0.\n     npreds = [P[i][Y[i]-1] for i in range(len(Y))]\n     score = -(1. / len(Y)) * np.sum(np.log(npreds))\n     return score\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5590dc7b0dcec920403fcda0e09620d56c925bf5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 252 | Contributors (this commit): 7 | Commits (past 90d): 8 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -74,7 +74,7 @@ class ParametricSoftplus(MaskedLayer):\n         self.alphas = sharedX(self.alpha_init * np.ones(input_shape))\n         self.betas = sharedX(self.beta_init * np.ones(input_shape))\n         self.params = [self.alphas, self.betas]\n-        self.input_shape = input_shape\n+        self._input_shape = input_shape\n \n         if self.initial_weights is not None:\n             self.set_weights(self.initial_weights)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#66edb6aea00e3fc4c3d82967889f297ea0ed5045", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 214 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -4,6 +4,7 @@ from keras.models import Sequential, slice_X\n from keras.layers.core import Activation, TimeDistributedDense, RepeatVector\n from keras.layers import recurrent\n import numpy as np\n+from six.moves import range\n \n \"\"\"\n An implementation of sequence to sequence learning for performing addition\n@@ -89,7 +90,7 @@ expected = []\n seen = set()\n print('Generating data...')\n while len(questions) < TRAINING_SIZE:\n-    f = lambda: int(''.join(np.random.choice(list('0123456789')) for i in xrange(np.random.randint(1, DIGITS + 1))))\n+    f = lambda: int(''.join(np.random.choice(list('0123456789')) for i in range(np.random.randint(1, DIGITS + 1))))\n     a, b = f(), f()\n     # Skip any addition questions we've already seen\n     # Also skip any such that X+Y == Y+X (hence the sorting)\n@@ -139,7 +140,7 @@ model.add(RNN(HIDDEN_SIZE, input_shape=(None, len(chars))))\n # For the decoder's input, we repeat the encoded input for each time step\n model.add(RepeatVector(DIGITS + 1))\n # The decoder RNN could be multiple layers stacked or a single layer\n-for _ in xrange(LAYERS):\n+for _ in range(LAYERS):\n     model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n \n # For each of step of the output sequence, decide which character should be chosen\n@@ -156,7 +157,7 @@ for iteration in range(1, 200):\n     model.fit(X_train, y_train, batch_size=BATCH_SIZE, nb_epoch=1, validation_data=(X_val, y_val), show_accuracy=True)\n     ###\n     # Select 10 samples from the validation set at random so we can visualize errors\n-    for i in xrange(10):\n+    for i in range(10):\n         ind = np.random.randint(0, len(X_val))\n         rowX, rowy = X_val[np.array([ind])], y_val[np.array([ind])]\n         preds = model.predict_classes(rowX, verbose=0)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4a6b03403b339d5a3d5d618c58c56afe11f2e607", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 253 | Contributors (this commit): 7 | Commits (past 90d): 9 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -74,7 +74,6 @@ class ParametricSoftplus(MaskedLayer):\n         self.alphas = sharedX(self.alpha_init * np.ones(input_shape))\n         self.betas = sharedX(self.beta_init * np.ones(input_shape))\n         self.params = [self.alphas, self.betas]\n-        self._input_shape = input_shape\n \n         if self.initial_weights is not None:\n             self.set_weights(self.initial_weights)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#742ccaa2cf186e64a03a7b1fd9076374f67aace1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 155 | Contributors (this commit): 7 | Commits (past 90d): 2 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -24,6 +24,8 @@ def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncati\n \n     x = (np.ones((nb_samples, maxlen)) * value).astype(dtype)\n     for idx, s in enumerate(sequences):\n+        if len(s) == 0:\n+            continue # empty list was found\n         if truncating == 'pre':\n             trunc = s[-maxlen:]\n         elif truncating == 'post':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5352e46e09c1f586cb173f6bb2f0d6a01a9aa0a9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2736 | Contributors (this commit): 25 | Commits (past 90d): 68 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -376,7 +376,7 @@ class Merge(Layer):\n                 if X.name is None:\n                     raise ValueError(\"merge_mode='join' only works with named inputs\")\n                 else:\n-                    inputs[X.name] = self.layers[i].get_output(train)\n+                    inputs[X.name] = X\n             return inputs\n         elif self.mode == 'mul':\n             s = self.layers[0].get_output(train)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#57612707c1434ed3b18f9cad5cf2e6dd8b7b3b7d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 2743 | Contributors (this commit): 26 | Commits (past 90d): 69 | Contributors (cumulative): 26 | DMM Complexity: 0.0\n\nDIFF:\n@@ -307,7 +307,12 @@ class Merge(Layer):\n                     if shape1[dot_axes[0][i]] != shape2[dot_axes[1][i]]:\n                         raise Exception(\" Dot incompatible layers can not be merged using dot mode\")\n         elif mode == 'concat':\n-            input_shapes = set([list(l.output_shape).pop(concat_axis) for l in layers])\n+            input_shapes = set()\n+            for l in layers:\n+                oshape = list(l.output_shape)\n+                oshape.pop(concat_axis)\n+                oshape = tuple(oshape)\n+                input_shapes.add(oshape)\n             if len(input_shapes) > 1:\n                 raise Exception(\"'concat' mode can only merge layers with matching output shapes except for the concat axis\")\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7432034ada203e42b9725086e662789c9b9b0a5d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 263 | Contributors (this commit): 9 | Commits (past 90d): 10 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -6,7 +6,7 @@ import copy\n \n from ..layers.advanced_activations import LeakyReLU, PReLU\n from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder, Masking, Permute\n-from ..layers.core import ActivityRegularization, TimeDistributedDense, AutoEncoder, MaxoutDense\n+from ..layers.core import ActivityRegularization, TimeDistributedDense, TimeDistributedMerge, AutoEncoder, MaxoutDense\n from ..layers.convolutional import Convolution1D, Convolution2D, MaxPooling1D, MaxPooling2D, ZeroPadding2D\n from ..layers.embeddings import Embedding, WordContextProduct\n from ..layers.noise import GaussianNoise, GaussianDropout\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#002a9d5d2b2c26fff63293e3007ede9ab7dee616", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 16 | Files Changed: 1 | Hunks: 9 | Methods Changed: 3 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 50 | Churn Cumulative: 2793 | Contributors (this commit): 26 | Commits (past 90d): 70 | Contributors (cumulative): 26 | DMM Complexity: 0.0\n\nDIFF:\n@@ -289,7 +289,8 @@ class Merge(Layer):\n         if mode in {'sum', 'mul', 'ave', 'cos'}:\n             input_shapes = set([l.output_shape for l in layers])\n             if len(input_shapes) > 1:\n-                raise Exception(\"Only layers of same output shape can be merged using \" + mode + \" mode\")\n+                raise Exception(\"Only layers of same output shape can be merged using \" + mode + \" mode. \" +\n+                                \"Layer shapes: %s\" % ([l.output_shape for l in layers]))\n         if mode in {'cos', 'dot'}:\n             if len(layers) > 2:\n                 raise Exception(mode + \" merge takes exactly 2 layers\")\n@@ -303,13 +304,28 @@ class Merge(Layer):\n                         dot_axes = [range(dot_axes % n1, n1), range(dot_axes % n2, n2)]\n                     else:\n                         dot_axes = [range(n1 - dot_axes, n2), range(1, dot_axes + 1)]\n+                if type(dot_axes) not in [list, tuple]:\n+                    raise Exception(\"Invalid type for dot_axes - should be a list.\")\n+                if len(dot_axes) != 2:\n+                    raise Exception(\"Invalid format for dot_axes - should contain two elements.\")\n+                if type(dot_axes[0]) not in [list, tuple] or type(dot_axes[1]) not in [list, tuple]:\n+                    raise Exception(\"Invalid format for dot_axes - list elements should have type 'list' or 'tuple'.\")\n                 for i in range(len(dot_axes[0])):\n                     if shape1[dot_axes[0][i]] != shape2[dot_axes[1][i]]:\n-                        raise Exception(\" Dot incompatible layers can not be merged using dot mode\")\n+                        raise Exception(\"Dimension incompatibility using dot mode: \" +\n+                                        \"%s != %s. \" % (shape1[dot_axes[0][i]], shape2[dot_axes[1][i]]) +\n+                                        \"Layer shapes: %s, %s\" % (shape1, shape2))\n         elif mode == 'concat':\n-            input_shapes = set([list(l.output_shape).pop(concat_axis) for l in layers])\n+            input_shapes = set()\n+            for l in layers:\n+                oshape = list(l.output_shape)\n+                oshape.pop(concat_axis)\n+                oshape = tuple(oshape)\n+                input_shapes.add(oshape)\n             if len(input_shapes) > 1:\n-                raise Exception(\"'concat' mode can only merge layers with matching output shapes except for the concat axis\")\n+                raise Exception(\"'concat' mode can only merge layers with matching \" +\n+                                \"output shapes except for the concat axis. \" +\n+                                \"Layer shapes: %s\" % ([l.output_shape for l in layers]))\n \n         self.mode = mode\n         self.concat_axis = concat_axis\n@@ -344,14 +360,17 @@ class Merge(Layer):\n         elif self.mode == 'dot':\n             shape1 = list(input_shapes[0])\n             shape2 = list(input_shapes[1])\n-            for i in self.dot_axes[0]:\n-                shape1.pop(i)\n-            for i in self.dot_axes[1]:\n-                shape2.pop(i)\n-            shape = shape1 + shape2[1:]\n-            if len(shape) == 1:\n-                shape.append(1)\n-            return tuple(shape)\n+            dot_axes = []\n+            for axes in self.dot_axes:\n+                dot_axes.append([index-1 for index in axes])\n+            tensordot_output = np.tensordot(np.zeros(tuple(shape1[1:])),\n+                                            np.zeros(tuple(shape2[1:])),\n+                                            axes=dot_axes)\n+            if len(tensordot_output.shape) == 0:\n+                shape = (1,)\n+            else:\n+                shape = tensordot_output.shape\n+            return (shape1[0],) + shape\n         elif self.mode == 'cos':\n             return tuple(input_shapes[0][0], 1)\n \n@@ -387,13 +406,13 @@ class Merge(Layer):\n             l1 = self.layers[0].get_output(train)\n             l2 = self.layers[1].get_output(train)\n             output = T.batched_tensordot(l1, l2, self.dot_axes)\n-            output = output.dimshuffle((0, 'x'))\n             return output\n         elif self.mode == 'cos':\n             l1 = self.layers[0].get_output(train)\n             l2 = self.layers[1].get_output(train)\n-            output, _ = theano.scan(lambda v1, v2: T.dot(v1, v2)/T.sqrt(T.dot(v1, v1) * T.dot(v2, v2)), sequences=[l1, l2], outputs_info=None)\n-            output = output.dimshuffle((0, 'x'))\n+            output, _ = theano.scan(lambda v1, v2: T.dot(v1, v2) / T.sqrt(T.dot(v1, v1) * T.dot(v2, v2)),\n+                                    sequences=[l1, l2],\n+                                    outputs_info=None)\n             return output\n         else:\n             raise Exception('Unknown merge mode')\n@@ -441,7 +460,6 @@ class Merge(Layer):\n         return dict(list(base_config.items()) + list(config.items()))\n \n \n-\n class Dropout(MaskedLayer):\n     '''\n         Hinton's dropout.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5964848bdfb6dd6848148e7c86fda5d2d458e52d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 3 | Churn Cumulative: 3333 | Contributors (this commit): 26 | Commits (past 90d): 94 | Contributors (cumulative): 30 | DMM Complexity: None\n\nDIFF:\n@@ -308,7 +308,7 @@ class Merge(Layer):\n                     raise Exception(\"Invalid type for dot_axes - should be a list.\")\n                 if len(dot_axes) != 2:\n                     raise Exception(\"Invalid format for dot_axes - should contain two elements.\")\n-                if type(dot_axes[0]) not in [list, tuple] or type(dot_axes[1]) not in [list, tuple]:\n+                if type(dot_axes[0]) not in [list, tuple, range] or type(dot_axes[1]) not in [list, tuple, range]:\n                     raise Exception(\"Invalid format for dot_axes - list elements should have type 'list' or 'tuple'.\")\n                 for i in range(len(dot_axes[0])):\n                     if shape1[dot_axes[0][i]] != shape2[dot_axes[1][i]]:\n\n@@ -164,6 +164,7 @@ class TestSequential(unittest.TestCase):\n         model.add(Activation('softmax'))\n \n         model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n+\n     def test_merge_concat(self):\n         print('Test merge: concat')\n         left = Sequential()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cc0108097c7dcd52977066bd9aa754885945088b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2797 | Contributors (this commit): 27 | Commits (past 90d): 72 | Contributors (cumulative): 27 | DMM Complexity: None\n\nDIFF:\n@@ -859,7 +859,7 @@ class AutoEncoder(Layer):\n \n     @property\n     def input_shape(self):\n-        self.encoder.previous.output_shape\n+        return self.encoder.input_shape\n \n     @property\n     def output_shape(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#10852b25294c604add0cc3b2e3cf9986891c8385", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 16 | Files Changed: 1 | Hunks: 21 | Methods Changed: 11 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 47 | Churn Cumulative: 1260 | Contributors (this commit): 10 | Commits (past 90d): 8 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -55,7 +55,8 @@ class SimpleRNN(Recurrent):\n     '''\n     def __init__(self, output_dim,\n                  init='glorot_uniform', inner_init='orthogonal', activation='sigmoid', weights=None,\n-                 truncate_gradient=-1, return_sequences=False, input_dim=None, input_length=None, **kwargs):\n+                 truncate_gradient=-1, return_sequences=False, input_dim=None,\n+                 input_length=None, go_backwards=False, **kwargs):\n         self.output_dim = output_dim\n         self.init = initializations.get(init)\n         self.inner_init = initializations.get(inner_init)\n@@ -63,6 +64,7 @@ class SimpleRNN(Recurrent):\n         self.activation = activations.get(activation)\n         self.return_sequences = return_sequences\n         self.initial_weights = weights\n+        self.go_backwards = go_backwards\n \n         self.input_dim = input_dim\n         self.input_length = input_length\n@@ -107,7 +109,8 @@ class SimpleRNN(Recurrent):\n             # initialization of the output. Input to _step with default tap=-1.\n             outputs_info=T.unbroadcast(alloc_zeros_matrix(X.shape[1], self.output_dim), 1),\n             non_sequences=self.U,  # static inputs to _step\n-            truncate_gradient=self.truncate_gradient)\n+            truncate_gradient=self.truncate_gradient,\n+            go_backwards=self.go_backwards)\n \n         if self.return_sequences:\n             return outputs.dimshuffle((1, 0, 2))\n@@ -141,7 +144,7 @@ class SimpleDeepRNN(Recurrent):\n                  init='glorot_uniform', inner_init='orthogonal',\n                  activation='sigmoid', inner_activation='hard_sigmoid',\n                  weights=None, truncate_gradient=-1, return_sequences=False,\n-                 input_dim=None, input_length=None, **kwargs):\n+                 input_dim=None, input_length=None, go_backwards=False, **kwargs):\n         self.output_dim = output_dim\n         self.init = initializations.get(init)\n         self.inner_init = initializations.get(inner_init)\n@@ -151,6 +154,7 @@ class SimpleDeepRNN(Recurrent):\n         self.depth = depth\n         self.return_sequences = return_sequences\n         self.initial_weights = weights\n+        self.go_backwards = go_backwards\n \n         self.input_dim = input_dim\n         self.input_length = input_length\n@@ -202,8 +206,8 @@ class SimpleDeepRNN(Recurrent):\n                 taps=[(-i-1) for i in range(self.depth)]\n             )],\n             non_sequences=self.Us,\n-            truncate_gradient=self.truncate_gradient\n-        )\n+            truncate_gradient=self.truncate_gradient,\n+            go_backwards=self.go_backwards)\n \n         if self.return_sequences:\n             return outputs.dimshuffle((1, 0, 2))\n@@ -251,7 +255,7 @@ class GRU(Recurrent):\n                  init='glorot_uniform', inner_init='orthogonal',\n                  activation='sigmoid', inner_activation='hard_sigmoid',\n                  weights=None, truncate_gradient=-1, return_sequences=False,\n-                 input_dim=None, input_length=None, **kwargs):\n+                 input_dim=None, input_length=None, go_backwards=False, **kwargs):\n         self.output_dim = output_dim\n         self.init = initializations.get(init)\n         self.inner_init = initializations.get(inner_init)\n@@ -260,6 +264,7 @@ class GRU(Recurrent):\n         self.truncate_gradient = truncate_gradient\n         self.return_sequences = return_sequences\n         self.initial_weights = weights\n+        self.go_backwards = go_backwards\n \n         self.input_dim = input_dim\n         self.input_length = input_length\n@@ -317,7 +322,8 @@ class GRU(Recurrent):\n             sequences=[x_z, x_r, x_h, padded_mask],\n             outputs_info=T.unbroadcast(alloc_zeros_matrix(X.shape[1], self.output_dim), 1),\n             non_sequences=[self.U_z, self.U_r, self.U_h],\n-            truncate_gradient=self.truncate_gradient)\n+            truncate_gradient=self.truncate_gradient,\n+            go_backwards=self.go_backwards)\n \n         if self.return_sequences:\n             return outputs.dimshuffle((1, 0, 2))\n@@ -367,7 +373,7 @@ class LSTM(Recurrent):\n                  init='glorot_uniform', inner_init='orthogonal', forget_bias_init='one',\n                  activation='tanh', inner_activation='hard_sigmoid',\n                  weights=None, truncate_gradient=-1, return_sequences=False,\n-                 input_dim=None, input_length=None, **kwargs):\n+                 input_dim=None, input_length=None, go_backwards=False, **kwargs):\n         self.output_dim = output_dim\n         self.init = initializations.get(init)\n         self.inner_init = initializations.get(inner_init)\n@@ -377,6 +383,7 @@ class LSTM(Recurrent):\n         self.truncate_gradient = truncate_gradient\n         self.return_sequences = return_sequences\n         self.initial_weights = weights\n+        self.go_backwards = go_backwards\n \n         self.input_dim = input_dim\n         self.input_length = input_length\n@@ -447,7 +454,8 @@ class LSTM(Recurrent):\n                 T.unbroadcast(alloc_zeros_matrix(X.shape[1], self.output_dim), 1)\n             ],\n             non_sequences=[self.U_i, self.U_f, self.U_o, self.U_c],\n-            truncate_gradient=self.truncate_gradient)\n+            truncate_gradient=self.truncate_gradient,\n+            go_backwards=self.go_backwards)\n \n         if self.return_sequences:\n             return outputs.dimshuffle((1, 0, 2))\n@@ -493,7 +501,7 @@ class JZS1(Recurrent):\n                  init='glorot_uniform', inner_init='orthogonal',\n                  activation='tanh', inner_activation='sigmoid',\n                  weights=None, truncate_gradient=-1, return_sequences=False,\n-                 input_dim=None, input_length=None, **kwargs):\n+                 input_dim=None, input_length=None, go_backwards=False, **kwargs):\n         self.output_dim = output_dim\n         self.init = initializations.get(init)\n         self.inner_init = initializations.get(inner_init)\n@@ -502,6 +510,7 @@ class JZS1(Recurrent):\n         self.truncate_gradient = truncate_gradient\n         self.return_sequences = return_sequences\n         self.initial_weights = weights\n+        self.go_backwards = go_backwards\n \n         self.input_dim = input_dim\n         self.input_length = input_length\n@@ -566,7 +575,8 @@ class JZS1(Recurrent):\n             sequences=[x_z, x_r, x_h, padded_mask],\n             outputs_info=T.unbroadcast(alloc_zeros_matrix(X.shape[1], self.output_dim), 1),\n             non_sequences=[self.U_r, self.U_h],\n-            truncate_gradient=self.truncate_gradient)\n+            truncate_gradient=self.truncate_gradient,\n+            go_backwards=self.go_backwards)\n         if self.return_sequences:\n             return outputs.dimshuffle((1, 0, 2))\n         return outputs[-1]\n@@ -610,7 +620,7 @@ class JZS2(Recurrent):\n                  init='glorot_uniform', inner_init='orthogonal',\n                  activation='tanh', inner_activation='sigmoid',\n                  weights=None, truncate_gradient=-1, return_sequences=False,\n-                 input_dim=None, input_length=None, **kwargs):\n+                 input_dim=None, input_length=None, go_backwards=False, **kwargs):\n         self.output_dim = output_dim\n         self.init = initializations.get(init)\n         self.inner_init = initializations.get(inner_init)\n@@ -619,6 +629,7 @@ class JZS2(Recurrent):\n         self.truncate_gradient = truncate_gradient\n         self.return_sequences = return_sequences\n         self.initial_weights = weights\n+        self.go_backwards = go_backwards\n \n         self.input_dim = input_dim\n         self.input_length = input_length\n@@ -684,7 +695,9 @@ class JZS2(Recurrent):\n             sequences=[x_z, x_r, x_h, padded_mask],\n             outputs_info=T.unbroadcast(alloc_zeros_matrix(X.shape[1], self.output_dim), 1),\n             non_sequences=[self.U_z, self.U_r, self.U_h],\n-            truncate_gradient=self.truncate_gradient)\n+            truncate_gradient=self.truncate_gradient,\n+            go_backwards=self.go_backwards)\n+\n         if self.return_sequences:\n             return outputs.dimshuffle((1, 0, 2))\n         return outputs[-1]\n@@ -728,7 +741,7 @@ class JZS3(Recurrent):\n                  init='glorot_uniform', inner_init='orthogonal',\n                  activation='tanh', inner_activation='sigmoid',\n                  weights=None, truncate_gradient=-1, return_sequences=False,\n-                 input_dim=None, input_length=None, **kwargs):\n+                 input_dim=None, input_length=None, go_backwards=False, **kwargs):\n         self.output_dim = output_dim\n         self.init = initializations.get(init)\n         self.inner_init = initializations.get(inner_init)\n@@ -737,6 +750,7 @@ class JZS3(Recurrent):\n         self.truncate_gradient = truncate_gradient\n         self.return_sequences = return_sequences\n         self.initial_weights = weights\n+        self.go_backwards = go_backwards\n \n         self.input_dim = input_dim\n         self.input_length = input_length\n@@ -794,8 +808,9 @@ class JZS3(Recurrent):\n             sequences=[x_z, x_r, x_h, padded_mask],\n             outputs_info=T.unbroadcast(alloc_zeros_matrix(X.shape[1], self.output_dim), 1),\n             non_sequences=[self.U_z, self.U_r, self.U_h],\n-            truncate_gradient=self.truncate_gradient\n-        )\n+            truncate_gradient=self.truncate_gradient,\n+            go_backwards=self.go_backwards)\n+        \n         if self.return_sequences:\n             return outputs.dimshuffle((1, 0, 2))\n         return outputs[-1]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ca360b0d15a00b1828382cc645669fd500782bbd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 64 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 64 | Churn Cumulative: 64 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -0,0 +1,64 @@\n+from __future__ import absolute_import\n+from __future__ import print_function\n+import numpy as np\n+np.random.seed(1337)  # for reproducibility\n+\n+from keras.preprocessing import sequence\n+from keras.utils.np_utils import accuracy\n+from keras.models import Graph\n+from keras.layers.core import Dense, Dropout\n+from keras.layers.embeddings import Embedding\n+from keras.layers.recurrent import LSTM\n+from keras.datasets import imdb\n+\n+'''\n+    Train a Bidirectional LSTM on the IMDB sentiment classification task.\n+    The dataset is actually too small for bidirectional LSTM to be of any advantage\n+    compared to simpler, much faster methods such as TF-IDF+LogReg.\n+    Bidirectional LSTM may be not suited for a simple text classification task.\n+    Notes:\n+    - RNNs are tricky. And in particular Bidirectional RNNs you may experiment\n+    with different Recurrent layers and different parameters to find the best configuration\n+    for your task.\n+\n+    GPU command:\n+        THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python imdb_bidirectional_lstm.py\n+\n+    Output after 4 epochs on CPU: ~0.8146 \n+'''\n+\n+max_features = 20000\n+maxlen = 100  # cut texts after this number of words (among top max_features most common words)\n+batch_size = 32\n+\n+print(\"Loading data...\")\n+(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features, test_split=0.2)\n+print(len(X_train), 'train sequences')\n+print(len(X_test), 'test sequences')\n+\n+print(\"Pad sequences (samples x time)\")\n+X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n+X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n+print('X_train shape:', X_train.shape)\n+print('X_test shape:', X_test.shape)\n+y_train = np.array(y_train)\n+y_test = np.array(y_test)\n+\n+print('Build model...')\n+model = Graph()\n+model.add_input(name='input', input_shape=(1,), dtype=int)\n+model.add_node(Embedding(max_features, 128, input_length=maxlen), name='embedding', input='input')\n+model.add_node(LSTM(64), name='forward', input='embedding' )  # You can change these two layers with GRU\n+model.add_node(LSTM(64, go_backwards=True), name='backward', input='embedding' )\n+model.add_node(Dropout(0.5), name='dropout', inputs=['forward', 'backward'])\n+model.add_node(Dense(1, activation='sigmoid'), name='sigmoid', input='dropout')\n+model.add_output(name='output', input='sigmoid')\n+\n+# try using different optimizers and different optimizer configs\n+model.compile('adam',{'output':'binary_crossentropy'})\n+\n+print(\"Train...\")\n+model.fit({'input':X_train, 'output':y_train}, batch_size=batch_size, nb_epoch=4)\n+acc = accuracy(y_test, np.round(np.array(model.predict({'input':X_test}, batch_size=batch_size)['output'])))\n+print('Test accuracy:', acc)\n+\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
