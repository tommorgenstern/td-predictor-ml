{"custom_id": "keras#8f30ef400d39e429eba429ee8fe66f5b87c18449", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 304 | Contributors (this commit): 6 | Commits (past 90d): 14 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -124,7 +124,7 @@ class RandomCrop(Layer):\n         input_shape = tf.TensorShape(input_shape).as_list()\n         input_shape[self.height_axis] = self.height\n         input_shape[self.width_axis] = self.width\n-        return tf.TensorShape(input_shape)\n+        return tuple(input_shape)\n \n     def get_config(self):\n         config = super().get_config()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#de3cf30b0e34eb5b91d51407ab2f57773150bf6f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 322 | Contributors (this commit): 7 | Commits (past 90d): 26 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -7,3 +7,4 @@ from keras_core.backend.common.variables import is_int_dtype\n from keras_core.backend.common.variables import standardize_dtype\n from keras_core.backend.common.variables import standardize_shape\n from keras_core.random import random\n+convert\n\\ No newline at end of file\n\n@@ -85,7 +85,7 @@ class RandomCrop(Layer):\n \n     def call(self, inputs, training=True):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n-            inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n+            inputs = ops.core.convert_to_tensor(backend.convert_to_numpy(inputs))\n \n         input_shape = ops.shape(inputs)\n         h_diff = input_shape[self.height_axis] - self.height\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#133b730c34c8a37257a6b40e1f2109dc657ea7fb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 311 | Contributors (this commit): 6 | Commits (past 90d): 16 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -1,6 +1,7 @@\n import numpy as np\n \n from keras_core import ops\n+from keras_core import random\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n@@ -85,7 +86,7 @@ class RandomCrop(Layer):\n \n     def call(self, inputs, training=True):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n-            inputs = ops.core.convert_to_tensor(backend.convert_to_numpy(inputs))\n+            inputs = backend.convert_to_tensor(backend.convert_to_numpy(inputs))\n \n         input_shape = ops.shape(inputs)\n         h_diff = input_shape[self.height_axis] - self.height\n@@ -93,7 +94,7 @@ class RandomCrop(Layer):\n \n         def random_crop():\n             dtype = input_shape.dtype\n-            rands = tf.random.uniform([2], 0, dtype.max, dtype)\n+            rands = random.uniform([2], 0, dtype.max, dtype)\n             h_start = rands[0] % (h_diff + 1)\n             w_start = rands[1] % (w_diff + 1)\n             return tf.image.crop_to_bounding_box(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#08d328695b0ab3de59acafb7515f6c1525e49066", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 113 | Lines Deleted: 60 | Files Changed: 5 | Hunks: 17 | Methods Changed: 16 | Complexity Δ (Sum/Max): -2/3 | Churn Δ: 173 | Churn Cumulative: 772 | Contributors (this commit): 9 | Commits (past 90d): 43 | Contributors (cumulative): 23 | DMM Complexity: 1.0\n\nDIFF:\n@@ -7,4 +7,3 @@ from keras_core.backend.common.variables import is_int_dtype\n from keras_core.backend.common.variables import standardize_dtype\n from keras_core.backend.common.variables import standardize_shape\n from keras_core.random import random\n-convert\n\\ No newline at end of file\n\n@@ -0,0 +1,43 @@\n+import numpy as np\n+\n+from keras_core import backend\n+from keras_core import initializers\n+from keras_core import testing\n+\n+\n+class ConstantInitializersTest(testing.TestCase):\n+    def test_zeros_initializer(self):\n+        shape = (3, 3)\n+\n+        initializer = initializers.Zeros()\n+        values = initializer(shape=shape)\n+        self.assertEqual(values.shape, shape)\n+        np_values = backend.convert_to_numpy(values).data\n+        self.assertEqual(np_values, np.zeros(shape=shape))\n+\n+        self.run_class_serialization_test(initializer)\n+\n+    def test_ones_initializer(self):\n+        shape = (3, 3)\n+\n+        initializer = initializers.Ones()\n+        values = initializer(shape=shape)\n+        self.assertEqual(values.shape, shape)\n+        np_values = backend.convert_to_numpy(values).data\n+        self.assertEqual(np_values, np.ones(shape=shape))\n+\n+        self.run_class_serialization_test(initializer)\n+\n+    def test_constant_initializer(self):\n+        shape = (3, 3)\n+        constant_value = 6.0\n+\n+        initializer = initializers.Constant(value=constant_value)\n+        values = initializer(shape=shape)\n+        self.assertEqual(values.shape, shape)\n+        np_values = backend.convert_to_numpy(values).data\n+        self.assertEqual(\n+            np_values, np.full(shape=shape, fill_value=constant_value)\n+        )\n+\n+        self.run_class_serialization_test(initializer)\n\n@@ -30,6 +30,7 @@ class Constant(Initializer):\n         self.value = float(value)\n \n     def __call__(self, shape, dtype=None):\n+        dtype = standardize_dtype(dtype)\n         return self.value * ops.ones(shape=shape, dtype=dtype)\n \n     def get_config(self):\n\n@@ -1,12 +1,9 @@\n import numpy as np\n \n-from keras_core import ops\n-from keras_core import random\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.utils import backend_utils\n-from keras_core.utils import image_utils\n from keras_core.utils.module_utils import tensorflow as tf\n \n \n@@ -55,9 +52,7 @@ class RandomCrop(Layer):\n             `name` and `dtype`.\n     \"\"\"\n \n-    def __init__(\n-        self, height, width, seed=None, data_format=None, name=None, **kwargs\n-    ):\n+    def __init__(self, height, width, seed=None, name=None, **kwargs):\n         if not tf.available:\n             raise ImportError(\n                 \"Layer RandomCrop requires TensorFlow. \"\n@@ -65,20 +60,13 @@ class RandomCrop(Layer):\n             )\n \n         super().__init__(name=name, **kwargs)\n-        self.height = height\n-        self.width = width\n         self.seed = seed or backend.random.make_default_seed()\n-        self.data_format = (\n-            \"channels_last\" if data_format is None else \"channels_first\"\n+        self.layer = tf.keras.layers.RandomCrop(\n+            height=height,\n+            width=width,\n+            seed=self.seed,\n+            name=name,\n         )\n-\n-        if self.data_format == \"channels_first\":\n-            self.heigh_axis = -2\n-            self.width_axis = -1\n-        elif self.data_format == \"channels_last\":\n-            self.height_axis = -3\n-            self.width_axis = -2\n-\n         self.supports_masking = False\n         self.supports_jit = False\n         self._convert_input_args = False\n@@ -86,34 +74,8 @@ class RandomCrop(Layer):\n \n     def call(self, inputs, training=True):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n-            inputs = backend.convert_to_tensor(backend.convert_to_numpy(inputs))\n-\n-        input_shape = ops.shape(inputs)\n-        h_diff = input_shape[self.height_axis] - self.height\n-        w_diff = input_shape[self.width_axis] - self.width\n-\n-        def random_crop():\n-            dtype = input_shape.dtype\n-            rands = random.uniform([2], 0, dtype.max, dtype)\n-            h_start = rands[0] % (h_diff + 1)\n-            w_start = rands[1] % (w_diff + 1)\n-            return tf.image.crop_to_bounding_box(\n-                inputs, h_start, w_start, self.height, self.width\n-            )\n-\n-        def resize():\n-            outputs = image_utils.smart_resize(\n-                inputs, [self.height, self.width]\n-            )\n-            # smart_resize will always output float32, so we need to re-cast.\n-            return ops.cast(outputs, self.compute_dtype)\n-\n-        outputs = ops.cond(\n-            tf.reduce_all((training, h_diff >= 0, w_diff >= 0)),\n-            random_crop,\n-            resize,\n-        )\n-\n+            inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n+        outputs = self.layer.call(inputs, training=training)\n         if (\n             backend.backend() != \"tensorflow\"\n             and not backend_utils.in_tf_graph()\n@@ -121,15 +83,10 @@ class RandomCrop(Layer):\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n-    def compute_output_shape(self, input_shape, *args, **kwargs):\n-        input_shape = tf.TensorShape(input_shape).as_list()\n-        input_shape[self.height_axis] = self.height\n-        input_shape[self.width_axis] = self.width\n-        return tuple(input_shape)\n+    def compute_output_shape(self, input_shape):\n+        return tuple(self.layer.compute_output_shape(input_shape))\n \n     def get_config(self):\n-        config = super().get_config()\n-        config.update(\n-            {\"height\": self.height, \"width\": self.width, \"seed\": self.seed}\n-        )\n+        config = self.layer.get_config()\n+        config.update({\"seed\": self.seed})\n         return config\n\n@@ -273,7 +273,23 @@ def stop_gradient(variable):\n \n @keras_core_export(\"keras_core.ops.shape\")\n def shape(x):\n-    \"\"\"Gets the shape of the tensor input.\"\"\"\n+    \"\"\"Gets the shape of the tensor input.\n+\n+    Args:\n+        x: A tensor. This function will try to access the `shape` attribute of\n+            the input tensor.\n+\n+    Returns:\n+        A tuple of integers or None values, indicating the shape of the input\n+            tensor.\n+\n+    Example:\n+    >>> x = keras_core.zeros((8, 12))\n+    >>> keras_core.ops.shape(x)\n+    (8, 12)\n+\n+    \"\"\"\n+\n     if any_symbolic_tensors((x,)):\n         return x.shape\n     return backend.core.shape(x)\n@@ -281,8 +297,22 @@ def shape(x):\n \n @keras_core_export(\"keras_core.ops.cast\")\n def cast(x, dtype):\n-    \"\"\"Cast a tensor to the desired dtype.\"\"\"\n+    \"\"\"Cast a tensor to the desired dtype.\n+\n+    Args:\n+        x: A tensor or variable.\n+        dtype: The target type.\n+\n+    Returns:\n+        A tensor of the specified `dtype`.\n+\n+    Example:\n+    >>> x = keras_core.ops.arange(4)\n+    >>> keras_core.ops.cast(x, \"float32\")\n+\n+    \"\"\"\n     dtype = backend.standardize_dtype(dtype)\n+\n     if any_symbolic_tensors((x,)):\n         return backend.KerasTensor(shape=x.shape, dtype=dtype)\n     return backend.core.cast(x, dtype)\n@@ -290,13 +320,36 @@ def cast(x, dtype):\n \n @keras_core_export(\"keras_core.ops.convert_to_tensor\")\n def convert_to_tensor(x, dtype=None):\n-    \"\"\"Convert a NumPy array to a tensor.\"\"\"\n+    \"\"\"Convert a NumPy array to a tensor.\n+\n+    Args:\n+        x: A NumPy array.\n+        dtype: The target type.\n+\n+    Returns:\n+        A tensor of the specified `dtype`.\n+\n+    Example:\n+    >>> x = np.array([1, 2, 3])\n+    >>> keras_core.ops.convert_to_tensor(x)\n+\n+    \"\"\"\n+\n     return backend.convert_to_tensor(x, dtype=dtype)\n \n \n @keras_core_export(\"keras_core.ops.convert_to_numpy\")\n def convert_to_numpy(x):\n-    \"\"\"Convert a tensor to a NumPy array.\"\"\"\n+    \"\"\"Convert a tensor to a NumPy array.\n+\n+    Args:\n+        x: A tensor.\n+\n+    Returns:\n+        A NumPy array.\n+\n+    \"\"\"\n+\n     if any_symbolic_tensors((x,)):\n         # This will raise a `ValueError` defined in the `KerasTensor` class. We\n         # trigger it rather than duplicate it here.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1e8d9013526cc72853de5bd34da4559e1c4fcd99", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 12 | Files Changed: 1 | Hunks: 13 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 43 | Churn Cumulative: 138 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -30,6 +30,30 @@ class Scatter(Operation):\n \n @keras_core_export(\"keras_core.ops.scatter\")\n def scatter(indices, values, shape):\n+    \"\"\"Returns a tensor of shape `shape` where `indices` are set to `values`.\n+\n+    At a high level, this operation does `zeros[indices] = updates` and\n+    returns the output. It is equivalent to:\n+\n+    ```python\n+    zeros = keras_core.ops.zeros(shape)\n+    output = keras_core.ops.scatter_update(zeros, indices, values)\n+    ```\n+\n+    Args:\n+        indices: A tensor or list/tuple specifying\n+            indices for the values in `values`.\n+        updates: A tensor, the values to be set at `indices`.\n+        shape: Shape of the output tensor.\n+\n+    Example:\n+\n+    >>> indices = [[0, 1], [1, 1]]\n+    >>> values = np.array([1., 1.])\n+    >>> keras_core.ops.scatter(indices, values, shape=(2, 2))\n+    array([[0., 1.],\n+           [0., 1.]])\n+    \"\"\"\n     if any_symbolic_tensors((indices, values, shape)):\n         return Scatter().symbolic_call(indices, values, shape)\n     return backend.core.scatter(indices, values, shape)\n@@ -229,7 +253,6 @@ def while_loop(\n     >>> keras_core.ops.while_loop(cond, body, [i])[0]\n     10\n     \"\"\"\n-\n     return backend.core.while_loop(\n         cond,\n         body,\n@@ -284,12 +307,11 @@ def shape(x):\n             tensor.\n \n     Example:\n+\n     >>> x = keras_core.zeros((8, 12))\n     >>> keras_core.ops.shape(x)\n     (8, 12)\n-\n     \"\"\"\n-\n     if any_symbolic_tensors((x,)):\n         return x.shape\n     return backend.core.shape(x)\n@@ -307,9 +329,9 @@ def cast(x, dtype):\n         A tensor of the specified `dtype`.\n \n     Example:\n-    >>> x = keras_core.ops.arange(4)\n-    >>> keras_core.ops.cast(x, \"float32\")\n \n+    >>> x = keras_core.ops.arange(4)\n+    >>> x = keras_core.ops.cast(x, dtype=\"float16\")\n     \"\"\"\n     dtype = backend.standardize_dtype(dtype)\n \n@@ -330,11 +352,10 @@ def convert_to_tensor(x, dtype=None):\n         A tensor of the specified `dtype`.\n \n     Example:\n+\n     >>> x = np.array([1, 2, 3])\n-    >>> keras_core.ops.convert_to_tensor(x)\n-\n+    >>> y = keras_core.ops.convert_to_tensor(x)\n     \"\"\"\n-\n     return backend.convert_to_tensor(x, dtype=dtype)\n \n \n@@ -347,11 +368,9 @@ def convert_to_numpy(x):\n \n     Returns:\n         A NumPy array.\n-\n     \"\"\"\n-\n     if any_symbolic_tensors((x,)):\n-        # This will raise a `ValueError` defined in the `KerasTensor` class. We\n-        # trigger it rather than duplicate it here.\n+        # This will raise a `ValueError` defined in the `KerasTensor` class.\n+        # We trigger it rather than duplicate it here.\n         return np.array(x)\n     return backend.convert_to_numpy(x)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ebfedc9a7ad14324a53adc8d780510a0cca5ca55", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 3 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 826 | Contributors (this commit): 2 | Commits (past 90d): 19 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -15,5 +15,4 @@ from keras_core.layers import Layer\n from keras_core.models import Functional\n from keras_core.models import Model\n from keras_core.models import Sequential\n-\n-__version__ = \"0.1.0\"\n+from keras_core.version import __version__\n\n@@ -20,8 +20,7 @@ from keras_core.saving.serialization_lib import deserialize_keras_object\n from keras_core.saving.serialization_lib import serialize_keras_object\n from keras_core.utils import file_utils\n from keras_core.utils import naming\n-\n-keras_version = \"0.0.0\"  # TODO\n+from keras_core.version import __version__ as keras_version\n \n try:\n     import h5py\n\n@@ -0,0 +1,2 @@\n+# Unique source of truth for the version number.\n+__version__ = \"0.1.0\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3854a0194597dcec171239e04e57e700969b66b1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 80 | Lines Deleted: 139 | Files Changed: 8 | Hunks: 23 | Methods Changed: 18 | Complexity Δ (Sum/Max): 4/7 | Churn Δ: 219 | Churn Cumulative: 1860 | Contributors (this commit): 9 | Commits (past 90d): 71 | Contributors (cumulative): 31 | DMM Complexity: 0.0\n\nDIFF:\n@@ -15,4 +15,5 @@ from keras_core.layers import Layer\n from keras_core.models import Functional\n from keras_core.models import Model\n from keras_core.models import Sequential\n-from keras_core.version import __version__\n+\n+__version__ = \"0.1.0\"\n\n@@ -7,3 +7,4 @@ from keras_core.backend.common.variables import is_int_dtype\n from keras_core.backend.common.variables import standardize_dtype\n from keras_core.backend.common.variables import standardize_shape\n from keras_core.random import random\n+convert\n\\ No newline at end of file\n\n@@ -1,43 +0,0 @@\n-import numpy as np\n-\n-from keras_core import backend\n-from keras_core import initializers\n-from keras_core import testing\n-\n-\n-class ConstantInitializersTest(testing.TestCase):\n-    def test_zeros_initializer(self):\n-        shape = (3, 3)\n-\n-        initializer = initializers.Zeros()\n-        values = initializer(shape=shape)\n-        self.assertEqual(values.shape, shape)\n-        np_values = backend.convert_to_numpy(values).data\n-        self.assertEqual(np_values, np.zeros(shape=shape))\n-\n-        self.run_class_serialization_test(initializer)\n-\n-    def test_ones_initializer(self):\n-        shape = (3, 3)\n-\n-        initializer = initializers.Ones()\n-        values = initializer(shape=shape)\n-        self.assertEqual(values.shape, shape)\n-        np_values = backend.convert_to_numpy(values).data\n-        self.assertEqual(np_values, np.ones(shape=shape))\n-\n-        self.run_class_serialization_test(initializer)\n-\n-    def test_constant_initializer(self):\n-        shape = (3, 3)\n-        constant_value = 6.0\n-\n-        initializer = initializers.Constant(value=constant_value)\n-        values = initializer(shape=shape)\n-        self.assertEqual(values.shape, shape)\n-        np_values = backend.convert_to_numpy(values).data\n-        self.assertEqual(\n-            np_values, np.full(shape=shape, fill_value=constant_value)\n-        )\n-\n-        self.run_class_serialization_test(initializer)\n\n@@ -30,7 +30,6 @@ class Constant(Initializer):\n         self.value = float(value)\n \n     def __call__(self, shape, dtype=None):\n-        dtype = standardize_dtype(dtype)\n         return self.value * ops.ones(shape=shape, dtype=dtype)\n \n     def get_config(self):\n\n@@ -1,9 +1,12 @@\n import numpy as np\n \n+from keras_core import ops\n+from keras_core import random\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.utils import backend_utils\n+from keras_core.utils import image_utils\n from keras_core.utils.module_utils import tensorflow as tf\n \n \n@@ -52,7 +55,9 @@ class RandomCrop(Layer):\n             `name` and `dtype`.\n     \"\"\"\n \n-    def __init__(self, height, width, seed=None, name=None, **kwargs):\n+    def __init__(\n+        self, height, width, seed=None, data_format=None, name=None, **kwargs\n+    ):\n         if not tf.available:\n             raise ImportError(\n                 \"Layer RandomCrop requires TensorFlow. \"\n@@ -60,13 +65,20 @@ class RandomCrop(Layer):\n             )\n \n         super().__init__(name=name, **kwargs)\n+        self.height = height\n+        self.width = width\n         self.seed = seed or backend.random.make_default_seed()\n-        self.layer = tf.keras.layers.RandomCrop(\n-            height=height,\n-            width=width,\n-            seed=self.seed,\n-            name=name,\n+        self.data_format = (\n+            \"channels_last\" if data_format is None else \"channels_first\"\n         )\n+\n+        if self.data_format == \"channels_first\":\n+            self.heigh_axis = -2\n+            self.width_axis = -1\n+        elif self.data_format == \"channels_last\":\n+            self.height_axis = -3\n+            self.width_axis = -2\n+\n         self.supports_masking = False\n         self.supports_jit = False\n         self._convert_input_args = False\n@@ -74,8 +86,47 @@ class RandomCrop(Layer):\n \n     def call(self, inputs, training=True):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n-            inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n-        outputs = self.layer.call(inputs, training=training)\n+            inputs = backend.convert_to_tensor(backend.convert_to_numpy(inputs))\n+\n+        input_shape = ops.shape(inputs)\n+        is_batched = len(input_shape) > 3\n+        inputs = ops.expand_dims(inputs, axis=0) if not is_batched else inputs\n+\n+        h_diff = input_shape[self.height_axis] - self.height\n+        w_diff = input_shape[self.width_axis] - self.width\n+\n+        def random_crop():\n+            dtype = input_shape.dtype\n+            rands = random.uniform([2], 0, dtype.max, dtype, seed=self.seed)\n+            h_start = rands[0] % (h_diff + 1)\n+            w_start = rands[1] % (w_diff + 1)\n+            if self.data_format == \"channels_last\":\n+                return inputs[\n+                    :,\n+                    h_start : h_start + self.height,\n+                    w_start : w_start + self.width,\n+                ]\n+            else:\n+                return inputs[\n+                    :,\n+                    :,\n+                    h_start : h_start + self.height,\n+                    w_start : w_start + self.width,\n+                ]\n+\n+        def resize():\n+            outputs = image_utils.smart_resize(\n+                inputs, [self.height, self.width]\n+            )\n+            # smart_resize will always output float32, so we need to re-cast.\n+            return ops.cast(outputs, self.compute_dtype)\n+\n+        outputs = ops.cond(\n+            tf.reduce_all((training, h_diff >= 0, w_diff >= 0)),\n+            random_crop,\n+            resize,\n+        )\n+\n         if (\n             backend.backend() != \"tensorflow\"\n             and not backend_utils.in_tf_graph()\n@@ -83,10 +134,15 @@ class RandomCrop(Layer):\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n-    def compute_output_shape(self, input_shape):\n-        return tuple(self.layer.compute_output_shape(input_shape))\n+    def compute_output_shape(self, input_shape, *args, **kwargs):\n+        input_shape = tf.TensorShape(input_shape).as_list()\n+        input_shape[self.height_axis] = self.height\n+        input_shape[self.width_axis] = self.width\n+        return tuple(input_shape)\n \n     def get_config(self):\n-        config = self.layer.get_config()\n-        config.update({\"seed\": self.seed})\n+        config = super().get_config()\n+        config.update(\n+            {\"height\": self.height, \"width\": self.width, \"seed\": self.seed}\n+        )\n         return config\n\n@@ -30,30 +30,6 @@ class Scatter(Operation):\n \n @keras_core_export(\"keras_core.ops.scatter\")\n def scatter(indices, values, shape):\n-    \"\"\"Returns a tensor of shape `shape` where `indices` are set to `values`.\n-\n-    At a high level, this operation does `zeros[indices] = updates` and\n-    returns the output. It is equivalent to:\n-\n-    ```python\n-    zeros = keras_core.ops.zeros(shape)\n-    output = keras_core.ops.scatter_update(zeros, indices, values)\n-    ```\n-\n-    Args:\n-        indices: A tensor or list/tuple specifying\n-            indices for the values in `values`.\n-        updates: A tensor, the values to be set at `indices`.\n-        shape: Shape of the output tensor.\n-\n-    Example:\n-\n-    >>> indices = [[0, 1], [1, 1]]\n-    >>> values = np.array([1., 1.])\n-    >>> keras_core.ops.scatter(indices, values, shape=(2, 2))\n-    array([[0., 1.],\n-           [0., 1.]])\n-    \"\"\"\n     if any_symbolic_tensors((indices, values, shape)):\n         return Scatter().symbolic_call(indices, values, shape)\n     return backend.core.scatter(indices, values, shape)\n@@ -253,6 +229,7 @@ def while_loop(\n     >>> keras_core.ops.while_loop(cond, body, [i])[0]\n     10\n     \"\"\"\n+\n     return backend.core.while_loop(\n         cond,\n         body,\n@@ -296,22 +273,7 @@ def stop_gradient(variable):\n \n @keras_core_export(\"keras_core.ops.shape\")\n def shape(x):\n-    \"\"\"Gets the shape of the tensor input.\n-\n-    Args:\n-        x: A tensor. This function will try to access the `shape` attribute of\n-            the input tensor.\n-\n-    Returns:\n-        A tuple of integers or None values, indicating the shape of the input\n-            tensor.\n-\n-    Example:\n-\n-    >>> x = keras_core.zeros((8, 12))\n-    >>> keras_core.ops.shape(x)\n-    (8, 12)\n-    \"\"\"\n+    \"\"\"Gets the shape of the tensor input.\"\"\"\n     if any_symbolic_tensors((x,)):\n         return x.shape\n     return backend.core.shape(x)\n@@ -319,22 +281,8 @@ def shape(x):\n \n @keras_core_export(\"keras_core.ops.cast\")\n def cast(x, dtype):\n-    \"\"\"Cast a tensor to the desired dtype.\n-\n-    Args:\n-        x: A tensor or variable.\n-        dtype: The target type.\n-\n-    Returns:\n-        A tensor of the specified `dtype`.\n-\n-    Example:\n-\n-    >>> x = keras_core.ops.arange(4)\n-    >>> x = keras_core.ops.cast(x, dtype=\"float16\")\n-    \"\"\"\n+    \"\"\"Cast a tensor to the desired dtype.\"\"\"\n     dtype = backend.standardize_dtype(dtype)\n-\n     if any_symbolic_tensors((x,)):\n         return backend.KerasTensor(shape=x.shape, dtype=dtype)\n     return backend.core.cast(x, dtype)\n@@ -342,35 +290,15 @@ def cast(x, dtype):\n \n @keras_core_export(\"keras_core.ops.convert_to_tensor\")\n def convert_to_tensor(x, dtype=None):\n-    \"\"\"Convert a NumPy array to a tensor.\n-\n-    Args:\n-        x: A NumPy array.\n-        dtype: The target type.\n-\n-    Returns:\n-        A tensor of the specified `dtype`.\n-\n-    Example:\n-\n-    >>> x = np.array([1, 2, 3])\n-    >>> y = keras_core.ops.convert_to_tensor(x)\n-    \"\"\"\n+    \"\"\"Convert a NumPy array to a tensor.\"\"\"\n     return backend.convert_to_tensor(x, dtype=dtype)\n \n \n @keras_core_export(\"keras_core.ops.convert_to_numpy\")\n def convert_to_numpy(x):\n-    \"\"\"Convert a tensor to a NumPy array.\n-\n-    Args:\n-        x: A tensor.\n-\n-    Returns:\n-        A NumPy array.\n-    \"\"\"\n+    \"\"\"Convert a tensor to a NumPy array.\"\"\"\n     if any_symbolic_tensors((x,)):\n-        # This will raise a `ValueError` defined in the `KerasTensor` class.\n-        # We trigger it rather than duplicate it here.\n+        # This will raise a `ValueError` defined in the `KerasTensor` class. We\n+        # trigger it rather than duplicate it here.\n         return np.array(x)\n     return backend.convert_to_numpy(x)\n\n@@ -20,7 +20,8 @@ from keras_core.saving.serialization_lib import deserialize_keras_object\n from keras_core.saving.serialization_lib import serialize_keras_object\n from keras_core.utils import file_utils\n from keras_core.utils import naming\n-from keras_core.version import __version__ as keras_version\n+\n+keras_version = \"0.0.0\"  # TODO\n \n try:\n     import h5py\n\n@@ -1,2 +0,0 @@\n-# Unique source of truth for the version number.\n-__version__ = \"0.1.0\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#15f3f41c4fab61bda898a567aeaa9ecb50d8e6fc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 631 | Lines Deleted: 80 | Files Changed: 9 | Hunks: 24 | Methods Changed: 38 | Complexity Δ (Sum/Max): 20/24 | Churn Δ: 711 | Churn Cumulative: 2571 | Contributors (this commit): 9 | Commits (past 90d): 80 | Contributors (cumulative): 32 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,492 @@\n+\"\"\"\n+Title: Zero-DCE for low-light image enhancement\n+Author: [Soumik Rakshit](http://github.com/soumik12345)\n+Converted to Keras Core by: [Soumik Rakshit](http://github.com/soumik12345)\n+Date created: 2021/09/18\n+Last modified: 2023/07/15\n+Description: Implementing Zero-Reference Deep Curve Estimation for low-light image enhancement.\n+Accelerator: GPU\n+\"\"\"\n+\"\"\"\n+## Introduction\n+\n+**Zero-Reference Deep Curve Estimation** or **Zero-DCE** formulates low-light image\n+enhancement as the task of estimating an image-specific\n+[*tonal curve*](https://en.wikipedia.org/wiki/Curve_(tonality)) with a deep neural network.\n+In this example, we train a lightweight deep network, **DCE-Net**, to estimate\n+pixel-wise and high-order tonal curves for dynamic range adjustment of a given image.\n+\n+Zero-DCE takes a low-light image as input and produces high-order tonal curves as its output.\n+These curves are then used for pixel-wise adjustment on the dynamic range of the input to\n+obtain an enhanced image. The curve estimation process is done in such a way that it maintains\n+the range of the enhanced image and preserves the contrast of neighboring pixels. This\n+curve estimation is inspired by curves adjustment used in photo editing software such as\n+Adobe Photoshop where users can adjust points throughout an image’s tonal range.\n+\n+Zero-DCE is appealing because of its relaxed assumptions with regard to reference images:\n+it does not require any input/output image pairs during training.\n+This is achieved through a set of carefully formulated non-reference loss functions,\n+which implicitly measure the enhancement quality and guide the training of the network.\n+\n+### References\n+\n+- [Zero-Reference Deep Curve Estimation for Low-Light Image Enhancement](https://arxiv.org/pdf/2001.06826.pdf)\n+- [Curves adjustment in Adobe Photoshop](https://helpx.adobe.com/photoshop/using/curves-adjustment.html)\n+\"\"\"\n+\n+\"\"\"\n+## Downloading LOLDataset\n+\n+The **LoL Dataset** has been created for low-light image enhancement. It provides 485\n+images for training and 15 for testing. Each image pair in the dataset consists of a\n+low-light input image and its corresponding well-exposed reference image.\n+\"\"\"\n+\n+import os\n+import random\n+import numpy as np\n+from glob import glob\n+from PIL import Image, ImageOps\n+import matplotlib.pyplot as plt\n+\n+import keras_core as keras\n+from keras_core import layers\n+\n+import tensorflow as tf\n+\n+\"\"\"shell\n+wget https://huggingface.co/datasets/geekyrakshit/LoL-Dataset/resolve/main/lol_dataset.zip\n+unzip -q lol_dataset.zip && rm lol_dataset.zip\n+\"\"\"\n+\n+\"\"\"\n+## Creating a TensorFlow Dataset\n+\n+We use 300 low-light images from the LoL Dataset training set for training, and we use\n+the remaining 185 low-light images for validation. We resize the images to size `256 x\n+256` to be used for both training and validation. Note that in order to train the DCE-Net,\n+we will not require the corresponding enhanced images.\n+\"\"\"\n+\n+IMAGE_SIZE = 256\n+BATCH_SIZE = 16\n+MAX_TRAIN_IMAGES = 400\n+\n+\n+def load_data(image_path):\n+    image = tf.io.read_file(image_path)\n+    image = tf.image.decode_png(image, channels=3)\n+    image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n+    image = image / 255.0\n+    return image\n+\n+\n+def data_generator(low_light_images):\n+    dataset = tf.data.Dataset.from_tensor_slices((low_light_images))\n+    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n+    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n+    return dataset\n+\n+\n+train_low_light_images = sorted(glob(\"./lol_dataset/our485/low/*\"))[:MAX_TRAIN_IMAGES]\n+val_low_light_images = sorted(glob(\"./lol_dataset/our485/low/*\"))[MAX_TRAIN_IMAGES:]\n+test_low_light_images = sorted(glob(\"./lol_dataset/eval15/low/*\"))\n+\n+\n+train_dataset = data_generator(train_low_light_images)\n+val_dataset = data_generator(val_low_light_images)\n+\n+print(\"Train Dataset:\", train_dataset)\n+print(\"Validation Dataset:\", val_dataset)\n+\n+\"\"\"\n+## The Zero-DCE Framework\n+\n+The goal of DCE-Net is to estimate a set of best-fitting light-enhancement curves\n+(LE-curves) given an input image. The framework then maps all pixels of the input’s RGB\n+channels by applying the curves iteratively to obtain the final enhanced image.\n+\n+### Understanding light-enhancement curves\n+\n+A ligh-enhancement curve is a kind of curve that can map a low-light image\n+to its enhanced version automatically,\n+where the self-adaptive curve parameters are solely dependent on the input image.\n+When designing such a curve, three objectives should be taken into account:\n+\n+- Each pixel value of the enhanced image should be in the normalized range `[0,1]`, in order to\n+avoid information loss induced by overflow truncation.\n+- It should be monotonous, to preserve the contrast between neighboring pixels.\n+- The shape of this curve should be as simple as possible,\n+and the curve should be differentiable to allow backpropagation.\n+\n+The light-enhancement curve is separately applied to three RGB channels instead of solely on the\n+illumination channel. The three-channel adjustment can better preserve the inherent color and reduce\n+the risk of over-saturation.\n+\n+![](https://li-chongyi.github.io/Zero-DCE_files/framework.png)\n+\n+### DCE-Net\n+\n+The DCE-Net is a lightweight deep neural network that learns the mapping between an input\n+image and its best-fitting curve parameter maps. The input to the DCE-Net is a low-light\n+image while the outputs are a set of pixel-wise curve parameter maps for corresponding\n+higher-order curves. It is a plain CNN of seven convolutional layers with symmetrical\n+concatenation. Each layer consists of 32 convolutional kernels of size 3×3 and stride 1\n+followed by the ReLU activation function. The last convolutional layer is followed by the\n+Tanh activation function, which produces 24 parameter maps for 8 iterations, where each\n+iteration requires three curve parameter maps for the three channels.\n+\n+![](https://i.imgur.com/HtIg34W.png)\n+\"\"\"\n+\n+\n+def build_dce_net():\n+    input_img = keras.Input(shape=[None, None, 3])\n+    conv1 = layers.Conv2D(\n+        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n+    )(input_img)\n+    conv2 = layers.Conv2D(\n+        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n+    )(conv1)\n+    conv3 = layers.Conv2D(\n+        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n+    )(conv2)\n+    conv4 = layers.Conv2D(\n+        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n+    )(conv3)\n+    int_con1 = layers.Concatenate(axis=-1)([conv4, conv3])\n+    conv5 = layers.Conv2D(\n+        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n+    )(int_con1)\n+    int_con2 = layers.Concatenate(axis=-1)([conv5, conv2])\n+    conv6 = layers.Conv2D(\n+        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n+    )(int_con2)\n+    int_con3 = layers.Concatenate(axis=-1)([conv6, conv1])\n+    x_r = layers.Conv2D(24, (3, 3), strides=(1, 1), activation=\"tanh\", padding=\"same\")(\n+        int_con3\n+    )\n+    return keras.Model(inputs=input_img, outputs=x_r)\n+\n+\n+\"\"\"\n+## Loss functions\n+\n+To enable zero-reference learning in DCE-Net, we use a set of differentiable\n+zero-reference losses that allow us to evaluate the quality of enhanced images.\n+\"\"\"\n+\n+\"\"\"\n+### Color constancy loss\n+\n+The *color constancy loss* is used to correct the potential color deviations in the\n+enhanced image.\n+\"\"\"\n+\n+\n+def color_constancy_loss(x):\n+    mean_rgb = tf.reduce_mean(x, axis=(1, 2), keepdims=True)\n+    mr, mg, mb = mean_rgb[:, :, :, 0], mean_rgb[:, :, :, 1], mean_rgb[:, :, :, 2]\n+    d_rg = tf.square(mr - mg)\n+    d_rb = tf.square(mr - mb)\n+    d_gb = tf.square(mb - mg)\n+    return tf.sqrt(tf.square(d_rg) + tf.square(d_rb) + tf.square(d_gb))\n+\n+\n+\"\"\"\n+### Exposure loss\n+\n+To restrain under-/over-exposed regions, we use the *exposure control loss*.\n+It measures the distance between the average intensity value of a local region\n+and a preset well-exposedness level (set to `0.6`).\n+\"\"\"\n+\n+\n+def exposure_loss(x, mean_val=0.6):\n+    x = tf.reduce_mean(x, axis=3, keepdims=True)\n+    mean = tf.nn.avg_pool2d(x, ksize=16, strides=16, padding=\"VALID\")\n+    return tf.reduce_mean(tf.square(mean - mean_val))\n+\n+\n+\"\"\"\n+### Illumination smoothness loss\n+\n+To preserve the monotonicity relations between neighboring pixels, the\n+*illumination smoothness loss* is added to each curve parameter map.\n+\"\"\"\n+\n+\n+def illumination_smoothness_loss(x):\n+    batch_size = tf.shape(x)[0]\n+    h_x = tf.shape(x)[1]\n+    w_x = tf.shape(x)[2]\n+    count_h = (tf.shape(x)[2] - 1) * tf.shape(x)[3]\n+    count_w = tf.shape(x)[2] * (tf.shape(x)[3] - 1)\n+    h_tv = tf.reduce_sum(tf.square((x[:, 1:, :, :] - x[:, : h_x - 1, :, :])))\n+    w_tv = tf.reduce_sum(tf.square((x[:, :, 1:, :] - x[:, :, : w_x - 1, :])))\n+    batch_size = tf.cast(batch_size, dtype=tf.float32)\n+    count_h = tf.cast(count_h, dtype=tf.float32)\n+    count_w = tf.cast(count_w, dtype=tf.float32)\n+    return 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n+\n+\n+\"\"\"\n+### Spatial consistency loss\n+\n+The *spatial consistency loss* encourages spatial coherence of the enhanced image by\n+preserving the contrast between neighboring regions across the input image and its enhanced version.\n+\"\"\"\n+\n+\n+class SpatialConsistencyLoss(keras.losses.Loss):\n+    def __init__(self, **kwargs):\n+        super().__init__(reduction=\"none\")\n+\n+        self.left_kernel = tf.constant(\n+            [[[[0, 0, 0]], [[-1, 1, 0]], [[0, 0, 0]]]], dtype=tf.float32\n+        )\n+        self.right_kernel = tf.constant(\n+            [[[[0, 0, 0]], [[0, 1, -1]], [[0, 0, 0]]]], dtype=tf.float32\n+        )\n+        self.up_kernel = tf.constant(\n+            [[[[0, -1, 0]], [[0, 1, 0]], [[0, 0, 0]]]], dtype=tf.float32\n+        )\n+        self.down_kernel = tf.constant(\n+            [[[[0, 0, 0]], [[0, 1, 0]], [[0, -1, 0]]]], dtype=tf.float32\n+        )\n+\n+    def call(self, y_true, y_pred):\n+        original_mean = tf.reduce_mean(y_true, 3, keepdims=True)\n+        enhanced_mean = tf.reduce_mean(y_pred, 3, keepdims=True)\n+        original_pool = tf.nn.avg_pool2d(\n+            original_mean, ksize=4, strides=4, padding=\"VALID\"\n+        )\n+        enhanced_pool = tf.nn.avg_pool2d(\n+            enhanced_mean, ksize=4, strides=4, padding=\"VALID\"\n+        )\n+\n+        d_original_left = tf.nn.conv2d(\n+            original_pool, self.left_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n+        )\n+        d_original_right = tf.nn.conv2d(\n+            original_pool, self.right_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n+        )\n+        d_original_up = tf.nn.conv2d(\n+            original_pool, self.up_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n+        )\n+        d_original_down = tf.nn.conv2d(\n+            original_pool, self.down_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n+        )\n+\n+        d_enhanced_left = tf.nn.conv2d(\n+            enhanced_pool, self.left_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n+        )\n+        d_enhanced_right = tf.nn.conv2d(\n+            enhanced_pool, self.right_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n+        )\n+        d_enhanced_up = tf.nn.conv2d(\n+            enhanced_pool, self.up_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n+        )\n+        d_enhanced_down = tf.nn.conv2d(\n+            enhanced_pool, self.down_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n+        )\n+\n+        d_left = tf.square(d_original_left - d_enhanced_left)\n+        d_right = tf.square(d_original_right - d_enhanced_right)\n+        d_up = tf.square(d_original_up - d_enhanced_up)\n+        d_down = tf.square(d_original_down - d_enhanced_down)\n+        return d_left + d_right + d_up + d_down\n+\n+\n+\"\"\"\n+### Deep curve estimation model\n+\n+We implement the Zero-DCE framework as a Keras subclassed model.\n+\"\"\"\n+\n+\n+class ZeroDCE(keras.Model):\n+    def __init__(self, **kwargs):\n+        super().__init__(**kwargs)\n+        self.dce_model = build_dce_net()\n+\n+    def compile(self, learning_rate, **kwargs):\n+        super().compile(**kwargs)\n+        self.optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n+        self.spatial_constancy_loss = SpatialConsistencyLoss(reduction=\"none\")\n+        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n+        self.illumination_smoothness_loss_tracker = keras.metrics.Mean(name=\"illumination_smoothness_loss\")\n+        self.spatial_constancy_loss_tracker = keras.metrics.Mean(name=\"spatial_constancy_loss\")\n+        self.color_constancy_loss_tracker = keras.metrics.Mean(name=\"color_constancy_loss\")\n+        self.exposure_loss_tracker = keras.metrics.Mean(name=\"exposure_loss\")\n+\n+    @property\n+    def metrics(self):\n+        return [\n+            self.total_loss_tracker,\n+            self.illumination_smoothness_loss_tracker,\n+            self.spatial_constancy_loss_tracker,\n+            self.color_constancy_loss_tracker,\n+            self.exposure_loss_tracker,\n+        ]\n+\n+    def get_enhanced_image(self, data, output):\n+        r1 = output[:, :, :, :3]\n+        r2 = output[:, :, :, 3:6]\n+        r3 = output[:, :, :, 6:9]\n+        r4 = output[:, :, :, 9:12]\n+        r5 = output[:, :, :, 12:15]\n+        r6 = output[:, :, :, 15:18]\n+        r7 = output[:, :, :, 18:21]\n+        r8 = output[:, :, :, 21:24]\n+        x = data + r1 * (tf.square(data) - data)\n+        x = x + r2 * (tf.square(x) - x)\n+        x = x + r3 * (tf.square(x) - x)\n+        enhanced_image = x + r4 * (tf.square(x) - x)\n+        x = enhanced_image + r5 * (tf.square(enhanced_image) - enhanced_image)\n+        x = x + r6 * (tf.square(x) - x)\n+        x = x + r7 * (tf.square(x) - x)\n+        enhanced_image = x + r8 * (tf.square(x) - x)\n+        return enhanced_image\n+\n+    def call(self, data):\n+        dce_net_output = self.dce_model(data)\n+        return self.get_enhanced_image(data, dce_net_output)\n+\n+    def compute_losses(self, data, output):\n+        enhanced_image = self.get_enhanced_image(data, output)\n+        loss_illumination = 200 * illumination_smoothness_loss(output)\n+        loss_spatial_constancy = tf.reduce_mean(\n+            self.spatial_constancy_loss(enhanced_image, data)\n+        )\n+        loss_color_constancy = 5 * tf.reduce_mean(color_constancy_loss(enhanced_image))\n+        loss_exposure = 10 * tf.reduce_mean(exposure_loss(enhanced_image))\n+        total_loss = (\n+            loss_illumination\n+            + loss_spatial_constancy\n+            + loss_color_constancy\n+            + loss_exposure\n+        )\n+\n+        return {\n+            \"total_loss\": total_loss,\n+            \"illumination_smoothness_loss\": loss_illumination,\n+            \"spatial_constancy_loss\": loss_spatial_constancy,\n+            \"color_constancy_loss\": loss_color_constancy,\n+            \"exposure_loss\": loss_exposure,\n+        }\n+\n+    def train_step(self, data):\n+        with tf.GradientTape() as tape:\n+            output = self.dce_model(data)\n+            losses = self.compute_losses(data, output)\n+\n+        gradients = tape.gradient(\n+            losses[\"total_loss\"], self.dce_model.trainable_weights\n+        )\n+        self.optimizer.apply_gradients(zip(gradients, self.dce_model.trainable_weights))\n+\n+        self.total_loss_tracker.update_state(losses[\"total_loss\"])\n+        self.illumination_smoothness_loss_tracker.update_state(losses[\"illumination_smoothness_loss\"])\n+        self.spatial_constancy_loss_tracker.update_state(losses[\"spatial_constancy_loss\"])\n+        self.color_constancy_loss_tracker.update_state(losses[\"color_constancy_loss\"])\n+        self.exposure_loss_tracker.update_state(losses[\"exposure_loss\"])\n+\n+        return {metric.name: metric.result() for metric in self.metrics}\n+\n+    def test_step(self, data):\n+        output = self.dce_model(data)\n+        losses = self.compute_losses(data, output)\n+\n+        self.total_loss_tracker.update_state(losses[\"total_loss\"])\n+        self.illumination_smoothness_loss_tracker.update_state(losses[\"illumination_smoothness_loss\"])\n+        self.spatial_constancy_loss_tracker.update_state(losses[\"spatial_constancy_loss\"])\n+        self.color_constancy_loss_tracker.update_state(losses[\"color_constancy_loss\"])\n+        self.exposure_loss_tracker.update_state(losses[\"exposure_loss\"])\n+\n+        return {metric.name: metric.result() for metric in self.metrics}\n+\n+    def save_weights(self, filepath, overwrite=True, save_format=None, options=None):\n+        \"\"\"While saving the weights, we simply save the weights of the DCE-Net\"\"\"\n+        self.dce_model.save_weights(\n+            filepath, overwrite=overwrite, save_format=save_format, options=options\n+        )\n+\n+    def load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None):\n+        \"\"\"While loading the weights, we simply load the weights of the DCE-Net\"\"\"\n+        self.dce_model.load_weights(\n+            filepath=filepath,\n+            by_name=by_name,\n+            skip_mismatch=skip_mismatch,\n+            options=options,\n+        )\n+\n+\n+\"\"\"\n+## Training\n+\"\"\"\n+\n+zero_dce_model = ZeroDCE()\n+zero_dce_model.compile(learning_rate=1e-4)\n+history = zero_dce_model.fit(train_dataset, validation_data=val_dataset, epochs=100)\n+\n+\n+def plot_result(item):\n+    plt.plot(history.history[item], label=item)\n+    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n+    plt.xlabel(\"Epochs\")\n+    plt.ylabel(item)\n+    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n+    plt.legend()\n+    plt.grid()\n+    plt.show()\n+\n+\n+plot_result(\"total_loss\")\n+plot_result(\"illumination_smoothness_loss\")\n+plot_result(\"spatial_constancy_loss\")\n+plot_result(\"color_constancy_loss\")\n+plot_result(\"exposure_loss\")\n+\n+\"\"\"\n+## Inference\n+\"\"\"\n+\n+\n+def plot_results(images, titles, figure_size=(12, 12)):\n+    fig = plt.figure(figsize=figure_size)\n+    for i in range(len(images)):\n+        fig.add_subplot(1, len(images), i + 1).set_title(titles[i])\n+        _ = plt.imshow(images[i])\n+        plt.axis(\"off\")\n+    plt.show()\n+\n+\n+def infer(original_image):\n+    image = keras.utils.img_to_array(original_image)\n+    image = image.astype(\"float32\") / 255.0\n+    image = np.expand_dims(image, axis=0)\n+    output_image = zero_dce_model(image)\n+    output_image = tf.cast((output_image[0, :, :, :] * 255), dtype=np.uint8)\n+    output_image = Image.fromarray(output_image.numpy())\n+    return output_image\n+\n+\n+\"\"\"\n+### Inference on test images\n+\n+We compare the test images from LOLDataset enhanced by MIRNet with images enhanced via\n+the `PIL.ImageOps.autocontrast()` function.\n+\n+You can use the trained model hosted on [Hugging Face Hub](https://huggingface.co/keras-io/low-light-image-enhancement)\n+and try the demo on [Hugging Face Spaces](https://huggingface.co/spaces/keras-io/low-light-image-enhancement).\n+\"\"\"\n+\n+for val_image_file in test_low_light_images:\n+    original_image = Image.open(val_image_file)\n+    enhanced_image = infer(original_image)\n+    plot_results(\n+        [original_image, ImageOps.autocontrast(original_image), enhanced_image],\n+        [\"Original\", \"PIL Autocontrast\", \"Enhanced\"],\n+        (20, 12),\n+    )\n\n@@ -15,5 +15,4 @@ from keras_core.layers import Layer\n from keras_core.models import Functional\n from keras_core.models import Model\n from keras_core.models import Sequential\n-\n-__version__ = \"0.1.0\"\n+from keras_core.version import __version__\n\n@@ -7,4 +7,3 @@ from keras_core.backend.common.variables import is_int_dtype\n from keras_core.backend.common.variables import standardize_dtype\n from keras_core.backend.common.variables import standardize_shape\n from keras_core.random import random\n-convert\n\\ No newline at end of file\n\n@@ -0,0 +1,43 @@\n+import numpy as np\n+\n+from keras_core import backend\n+from keras_core import initializers\n+from keras_core import testing\n+\n+\n+class ConstantInitializersTest(testing.TestCase):\n+    def test_zeros_initializer(self):\n+        shape = (3, 3)\n+\n+        initializer = initializers.Zeros()\n+        values = initializer(shape=shape)\n+        self.assertEqual(values.shape, shape)\n+        np_values = backend.convert_to_numpy(values).data\n+        self.assertEqual(np_values, np.zeros(shape=shape))\n+\n+        self.run_class_serialization_test(initializer)\n+\n+    def test_ones_initializer(self):\n+        shape = (3, 3)\n+\n+        initializer = initializers.Ones()\n+        values = initializer(shape=shape)\n+        self.assertEqual(values.shape, shape)\n+        np_values = backend.convert_to_numpy(values).data\n+        self.assertEqual(np_values, np.ones(shape=shape))\n+\n+        self.run_class_serialization_test(initializer)\n+\n+    def test_constant_initializer(self):\n+        shape = (3, 3)\n+        constant_value = 6.0\n+\n+        initializer = initializers.Constant(value=constant_value)\n+        values = initializer(shape=shape)\n+        self.assertEqual(values.shape, shape)\n+        np_values = backend.convert_to_numpy(values).data\n+        self.assertEqual(\n+            np_values, np.full(shape=shape, fill_value=constant_value)\n+        )\n+\n+        self.run_class_serialization_test(initializer)\n\n@@ -30,6 +30,7 @@ class Constant(Initializer):\n         self.value = float(value)\n \n     def __call__(self, shape, dtype=None):\n+        dtype = standardize_dtype(dtype)\n         return self.value * ops.ones(shape=shape, dtype=dtype)\n \n     def get_config(self):\n\n@@ -1,12 +1,9 @@\n import numpy as np\n \n-from keras_core import ops\n-from keras_core import random\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.utils import backend_utils\n-from keras_core.utils import image_utils\n from keras_core.utils.module_utils import tensorflow as tf\n \n \n@@ -55,9 +52,7 @@ class RandomCrop(Layer):\n             `name` and `dtype`.\n     \"\"\"\n \n-    def __init__(\n-        self, height, width, seed=None, data_format=None, name=None, **kwargs\n-    ):\n+    def __init__(self, height, width, seed=None, name=None, **kwargs):\n         if not tf.available:\n             raise ImportError(\n                 \"Layer RandomCrop requires TensorFlow. \"\n@@ -65,20 +60,13 @@ class RandomCrop(Layer):\n             )\n \n         super().__init__(name=name, **kwargs)\n-        self.height = height\n-        self.width = width\n         self.seed = seed or backend.random.make_default_seed()\n-        self.data_format = (\n-            \"channels_last\" if data_format is None else \"channels_first\"\n+        self.layer = tf.keras.layers.RandomCrop(\n+            height=height,\n+            width=width,\n+            seed=self.seed,\n+            name=name,\n         )\n-\n-        if self.data_format == \"channels_first\":\n-            self.heigh_axis = -2\n-            self.width_axis = -1\n-        elif self.data_format == \"channels_last\":\n-            self.height_axis = -3\n-            self.width_axis = -2\n-\n         self.supports_masking = False\n         self.supports_jit = False\n         self._convert_input_args = False\n@@ -86,47 +74,8 @@ class RandomCrop(Layer):\n \n     def call(self, inputs, training=True):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n-            inputs = backend.convert_to_tensor(backend.convert_to_numpy(inputs))\n-\n-        input_shape = ops.shape(inputs)\n-        is_batched = len(input_shape) > 3\n-        inputs = ops.expand_dims(inputs, axis=0) if not is_batched else inputs\n-\n-        h_diff = input_shape[self.height_axis] - self.height\n-        w_diff = input_shape[self.width_axis] - self.width\n-\n-        def random_crop():\n-            dtype = input_shape.dtype\n-            rands = random.uniform([2], 0, dtype.max, dtype, seed=self.seed)\n-            h_start = rands[0] % (h_diff + 1)\n-            w_start = rands[1] % (w_diff + 1)\n-            if self.data_format == \"channels_last\":\n-                return inputs[\n-                    :,\n-                    h_start : h_start + self.height,\n-                    w_start : w_start + self.width,\n-                ]\n-            else:\n-                return inputs[\n-                    :,\n-                    :,\n-                    h_start : h_start + self.height,\n-                    w_start : w_start + self.width,\n-                ]\n-\n-        def resize():\n-            outputs = image_utils.smart_resize(\n-                inputs, [self.height, self.width]\n-            )\n-            # smart_resize will always output float32, so we need to re-cast.\n-            return ops.cast(outputs, self.compute_dtype)\n-\n-        outputs = ops.cond(\n-            tf.reduce_all((training, h_diff >= 0, w_diff >= 0)),\n-            random_crop,\n-            resize,\n-        )\n-\n+            inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n+        outputs = self.layer.call(inputs, training=training)\n         if (\n             backend.backend() != \"tensorflow\"\n             and not backend_utils.in_tf_graph()\n@@ -134,15 +83,10 @@ class RandomCrop(Layer):\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n-    def compute_output_shape(self, input_shape, *args, **kwargs):\n-        input_shape = tf.TensorShape(input_shape).as_list()\n-        input_shape[self.height_axis] = self.height\n-        input_shape[self.width_axis] = self.width\n-        return tuple(input_shape)\n+    def compute_output_shape(self, input_shape):\n+        return tuple(self.layer.compute_output_shape(input_shape))\n \n     def get_config(self):\n-        config = super().get_config()\n-        config.update(\n-            {\"height\": self.height, \"width\": self.width, \"seed\": self.seed}\n-        )\n+        config = self.layer.get_config()\n+        config.update({\"seed\": self.seed})\n         return config\n\n@@ -30,6 +30,30 @@ class Scatter(Operation):\n \n @keras_core_export(\"keras_core.ops.scatter\")\n def scatter(indices, values, shape):\n+    \"\"\"Returns a tensor of shape `shape` where `indices` are set to `values`.\n+\n+    At a high level, this operation does `zeros[indices] = updates` and\n+    returns the output. It is equivalent to:\n+\n+    ```python\n+    zeros = keras_core.ops.zeros(shape)\n+    output = keras_core.ops.scatter_update(zeros, indices, values)\n+    ```\n+\n+    Args:\n+        indices: A tensor or list/tuple specifying\n+            indices for the values in `values`.\n+        updates: A tensor, the values to be set at `indices`.\n+        shape: Shape of the output tensor.\n+\n+    Example:\n+\n+    >>> indices = [[0, 1], [1, 1]]\n+    >>> values = np.array([1., 1.])\n+    >>> keras_core.ops.scatter(indices, values, shape=(2, 2))\n+    array([[0., 1.],\n+           [0., 1.]])\n+    \"\"\"\n     if any_symbolic_tensors((indices, values, shape)):\n         return Scatter().symbolic_call(indices, values, shape)\n     return backend.core.scatter(indices, values, shape)\n@@ -229,7 +253,6 @@ def while_loop(\n     >>> keras_core.ops.while_loop(cond, body, [i])[0]\n     10\n     \"\"\"\n-\n     return backend.core.while_loop(\n         cond,\n         body,\n@@ -273,7 +296,22 @@ def stop_gradient(variable):\n \n @keras_core_export(\"keras_core.ops.shape\")\n def shape(x):\n-    \"\"\"Gets the shape of the tensor input.\"\"\"\n+    \"\"\"Gets the shape of the tensor input.\n+\n+    Args:\n+        x: A tensor. This function will try to access the `shape` attribute of\n+            the input tensor.\n+\n+    Returns:\n+        A tuple of integers or None values, indicating the shape of the input\n+            tensor.\n+\n+    Example:\n+\n+    >>> x = keras_core.zeros((8, 12))\n+    >>> keras_core.ops.shape(x)\n+    (8, 12)\n+    \"\"\"\n     if any_symbolic_tensors((x,)):\n         return x.shape\n     return backend.core.shape(x)\n@@ -281,8 +319,22 @@ def shape(x):\n \n @keras_core_export(\"keras_core.ops.cast\")\n def cast(x, dtype):\n-    \"\"\"Cast a tensor to the desired dtype.\"\"\"\n+    \"\"\"Cast a tensor to the desired dtype.\n+\n+    Args:\n+        x: A tensor or variable.\n+        dtype: The target type.\n+\n+    Returns:\n+        A tensor of the specified `dtype`.\n+\n+    Example:\n+\n+    >>> x = keras_core.ops.arange(4)\n+    >>> x = keras_core.ops.cast(x, dtype=\"float16\")\n+    \"\"\"\n     dtype = backend.standardize_dtype(dtype)\n+\n     if any_symbolic_tensors((x,)):\n         return backend.KerasTensor(shape=x.shape, dtype=dtype)\n     return backend.core.cast(x, dtype)\n@@ -290,15 +342,35 @@ def cast(x, dtype):\n \n @keras_core_export(\"keras_core.ops.convert_to_tensor\")\n def convert_to_tensor(x, dtype=None):\n-    \"\"\"Convert a NumPy array to a tensor.\"\"\"\n+    \"\"\"Convert a NumPy array to a tensor.\n+\n+    Args:\n+        x: A NumPy array.\n+        dtype: The target type.\n+\n+    Returns:\n+        A tensor of the specified `dtype`.\n+\n+    Example:\n+\n+    >>> x = np.array([1, 2, 3])\n+    >>> y = keras_core.ops.convert_to_tensor(x)\n+    \"\"\"\n     return backend.convert_to_tensor(x, dtype=dtype)\n \n \n @keras_core_export(\"keras_core.ops.convert_to_numpy\")\n def convert_to_numpy(x):\n-    \"\"\"Convert a tensor to a NumPy array.\"\"\"\n+    \"\"\"Convert a tensor to a NumPy array.\n+\n+    Args:\n+        x: A tensor.\n+\n+    Returns:\n+        A NumPy array.\n+    \"\"\"\n     if any_symbolic_tensors((x,)):\n-        # This will raise a `ValueError` defined in the `KerasTensor` class. We\n-        # trigger it rather than duplicate it here.\n+        # This will raise a `ValueError` defined in the `KerasTensor` class.\n+        # We trigger it rather than duplicate it here.\n         return np.array(x)\n     return backend.convert_to_numpy(x)\n\n@@ -20,8 +20,7 @@ from keras_core.saving.serialization_lib import deserialize_keras_object\n from keras_core.saving.serialization_lib import serialize_keras_object\n from keras_core.utils import file_utils\n from keras_core.utils import naming\n-\n-keras_version = \"0.0.0\"  # TODO\n+from keras_core.version import __version__ as keras_version\n \n try:\n     import h5py\n\n@@ -0,0 +1,2 @@\n+# Unique source of truth for the version number.\n+__version__ = \"0.1.0\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
