{"custom_id": "keras#eb8eee8ab8617c0fb4f08d8ee6775f33b547a64a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 861 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: 0.5\n\nDIFF:\n@@ -245,8 +245,12 @@ def _write_to_zip_recursively(zipfile_to_save, system_path, zip_path):\n         zipfile_to_save.write(system_path, zip_path)\n     else:\n         for file_name in file_utils.listdir(system_path):\n-            system_file_path = file_utils.join(system_path, file_name)\n-            zip_file_path = file_utils.join(zip_path, file_name)\n+            system_file_path = file_utils.join(system_path, file_name).replace(\n+                \"\\\\\", \"/\"\n+            )\n+            zip_file_path = file_utils.join(zip_path, file_name).replace(\n+                \"\\\\\", \"/\"\n+            )\n             _write_to_zip_recursively(\n                 zipfile_to_save, system_file_path, zip_file_path\n             )\n@@ -308,7 +312,9 @@ def _save_state(\n                 child_obj,\n                 weights_store,\n                 assets_store,\n-                inner_path=file_utils.join(inner_path, child_attr),\n+                inner_path=file_utils.join(inner_path, child_attr).replace(\n+                    \"\\\\\", \"/\"\n+                ),\n                 visited_trackables=visited_trackables,\n             )\n         elif isinstance(child_obj, (list, dict, tuple, set)):\n@@ -316,7 +322,9 @@ def _save_state(\n                 child_obj,\n                 weights_store,\n                 assets_store,\n-                inner_path=file_utils.join(inner_path, child_attr),\n+                inner_path=file_utils.join(inner_path, child_attr).replace(\n+                    \"\\\\\", \"/\"\n+                ),\n                 visited_trackables=visited_trackables,\n             )\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4d1e8168ea454d6ce739cbafd9a8d9c3e2fa5f03", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 6 | Churn Cumulative: 30 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -311,6 +311,12 @@ class TestCase(unittest.TestCase):\n             if input_sparse:\n                 import tensorflow as tf\n \n+                if backend.backend() == \"torch\":\n+                    # Bring output Torch tensors to CPU before using `tf.data`\n+                    dataset = tf.data.Dataset.from_tensors(\n+                        (input_data, backend.convert_to_numpy(output_data))\n+                    )\n+                else:\n                     dataset = tf.data.Dataset.from_tensors(\n                         (input_data, output_data)\n                     )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6bafb3b099cfb29866f5161fab7758c17d895de2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 8 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 24 | Churn Cumulative: 885 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: 0.5\n\nDIFF:\n@@ -378,7 +378,9 @@ def _load_state(\n                 child_obj,\n                 weights_store,\n                 assets_store,\n-                inner_path=file_utils.join(inner_path, child_attr),\n+                inner_path=file_utils.join(inner_path, child_attr).replace(\n+                    \"\\\\\", \"/\"\n+                ),\n                 skip_mismatch=skip_mismatch,\n                 visited_trackables=visited_trackables,\n             )\n@@ -387,7 +389,9 @@ def _load_state(\n                 child_obj,\n                 weights_store,\n                 assets_store,\n-                inner_path=file_utils.join(inner_path, child_attr),\n+                inner_path=file_utils.join(inner_path, child_attr).replace(\n+                    \"\\\\\", \"/\"\n+                ),\n                 skip_mismatch=skip_mismatch,\n                 visited_trackables=visited_trackables,\n             )\n@@ -415,7 +419,7 @@ def _save_container_state(\n                 trackable,\n                 weights_store,\n                 assets_store,\n-                inner_path=file_utils.join(inner_path, name),\n+                inner_path=file_utils.join(inner_path, name).replace(\"\\\\\", \"/\"),\n                 visited_trackables=visited_trackables,\n             )\n \n@@ -444,7 +448,7 @@ def _load_container_state(\n                 trackable,\n                 weights_store,\n                 assets_store,\n-                inner_path=file_utils.join(inner_path, name),\n+                inner_path=file_utils.join(inner_path, name).replace(\"\\\\\", \"/\"),\n                 skip_mismatch=skip_mismatch,\n                 visited_trackables=visited_trackables,\n             )\n@@ -469,7 +473,9 @@ class DiskIOStore:\n             self.tmp_dir = get_temp_dir()\n             if self.mode == \"r\":\n                 self.archive.extractall(path=self.tmp_dir)\n-            self.working_dir = file_utils.join(self.tmp_dir, self.root_path)\n+            self.working_dir = file_utils.join(\n+                self.tmp_dir, self.root_path\n+            ).replace(\"\\\\\", \"/\")\n             if self.mode == \"w\":\n                 file_utils.makedirs(self.working_dir)\n         else:\n@@ -477,13 +483,15 @@ class DiskIOStore:\n                 self.working_dir = root_path\n             else:\n                 self.tmp_dir = get_temp_dir()\n-                self.working_dir = file_utils.join(self.tmp_dir, self.root_path)\n+                self.working_dir = file_utils.join(\n+                    self.tmp_dir, self.root_path\n+                ).replace(\"\\\\\", \"/\")\n                 file_utils.makedirs(self.working_dir)\n \n     def make(self, path):\n         if not path:\n             return self.working_dir\n-        path = file_utils.join(self.working_dir, path)\n+        path = file_utils.join(self.working_dir, path).replace(\"\\\\\", \"/\")\n         if not file_utils.exists(path):\n             file_utils.makedirs(path)\n         return path\n@@ -491,7 +499,7 @@ class DiskIOStore:\n     def get(self, path):\n         if not path:\n             return self.working_dir\n-        path = file_utils.join(self.working_dir, path)\n+        path = file_utils.join(self.working_dir, path).replace(\"\\\\\", \"/\")\n         if file_utils.exists(path):\n             return path\n         return None\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3d92f71e0dfe70a4f86dfab308b55b3dbcd40111", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 270 | Lines Deleted: 262 | Files Changed: 2 | Hunks: 8 | Methods Changed: 26 | Complexity Δ (Sum/Max): 0/22 | Churn Δ: 532 | Churn Cumulative: 965 | Contributors (this commit): 3 | Commits (past 90d): 10 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -0,0 +1,270 @@\n+\"\"\"Test for distribution_lib.py.\"\"\"\n+\n+import functools\n+import os\n+\n+import jax\n+import numpy as np\n+import pytest\n+\n+from keras import backend\n+from keras import layers\n+from keras import models\n+from keras import testing\n+from keras.backend import distribution_lib as backend_dlib\n+from keras.distribution import distribution_lib\n+\n+if backend.backend() == \"jax\":\n+    # Due to https://github.com/google/jax/issues/17188, we can't\n+    # override the XLA flag after the JAX back init. We have to\n+    # run this at top level to let JAX pick the flag value.\n+    xla_flags = os.getenv(\"XLA_FLAGS\") or \"\"\n+    # Don't override user-specified device count, or other XLA flags.\n+    if \"xla_force_host_platform_device_count\" not in xla_flags:\n+        os.environ[\"XLA_FLAGS\"] = (\n+            xla_flags + \" --xla_force_host_platform_device_count=8\"\n+        )\n+\n+\n+@pytest.mark.skipif(\n+    backend.backend() != \"jax\",\n+    reason=\"Backend specific test\",\n+)\n+class JaxDistributionLibTest(testing.TestCase):\n+    def test_list_devices(self):\n+        self.assertEqual(len(distribution_lib.list_devices()), 8)\n+        self.assertEqual(len(distribution_lib.list_devices(\"cpu\")), 8)\n+        self.assertEqual(len(distribution_lib.list_devices(\"cpu\")), 8)\n+\n+    def test_distribute_tensor(self):\n+        jax_mesh = jax.sharding.Mesh(\n+            np.array(jax.devices()).reshape(2, 4), (\"batch\", \"model\")\n+        )\n+\n+        inputs = jax.numpy.array(np.random.normal(size=(16, 8)))\n+        target_layout = jax.sharding.NamedSharding(\n+            jax_mesh, jax.sharding.PartitionSpec(\"batch\", None)\n+        )\n+\n+        @functools.partial(jax.jit, static_argnames=\"target_layout\")\n+        def test_function(inputs, target_layout):\n+            return distribution_lib.distribute_tensor(inputs, target_layout)\n+\n+        result = test_function(inputs, target_layout)\n+        # Note that the returned tensor has a different sharding implementation\n+        # which is GSPMDSharding, but it should be equivalent as the target\n+        # layout specified.\n+        self.assertTrue(result.sharding.is_equivalent_to(target_layout, ndim=2))\n+\n+        # Test without jit\n+        result = distribution_lib.distribute_tensor(inputs, target_layout)\n+        self.assertTrue(result.sharding.is_equivalent_to(target_layout, ndim=2))\n+\n+    def test_to_jax_mesh(self):\n+        devices = [f\"cpu:{i}\" for i in range(8)]\n+        shape = (4, 2)\n+        axis_names = [\"batch\", \"model\"]\n+\n+        mesh = distribution_lib.DeviceMesh(shape, axis_names, devices)\n+        jax_mesh = backend_dlib._to_jax_mesh(mesh)\n+\n+        self.assertIsInstance(jax_mesh, jax.sharding.Mesh)\n+        self.assertEqual(jax_mesh.devices.shape, shape)\n+        self.assertEqual(jax_mesh.axis_names, (\"batch\", \"model\"))\n+\n+    def test_to_jax_layout(self):\n+        axes = [\"data\", None]\n+        mesh = distribution_lib.DeviceMesh(\n+            (4, 2), [\"data\", \"model\"], [f\"cpu:{i}\" for i in range(8)]\n+        )\n+        layout = distribution_lib.TensorLayout(axes, mesh)\n+        jax_sharding = backend_dlib._to_jax_layout(layout)\n+        jax_mesh = backend_dlib._to_jax_mesh(mesh)\n+        self.assertEqual(\n+            jax_sharding,\n+            jax.sharding.NamedSharding(\n+                jax_mesh, jax.sharding.PartitionSpec(\"data\", None)\n+            ),\n+        )\n+\n+    def test_validation_for_device_mesh(self):\n+        axes = [\"data\", None]\n+        layout = distribution_lib.TensorLayout(axes, device_mesh=None)\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \"Cannot create sharding when device mesh is not set\"\n+        ):\n+            backend_dlib._to_jax_layout(layout)\n+\n+    def test_variable_assignment_reuse_layout(self):\n+        shape = (4, 2)\n+        axis_names = [\"batch\", \"model\"]\n+        device_mesh = distribution_lib.DeviceMesh(\n+            shape, axis_names, backend_dlib.list_devices()\n+        )\n+        layout_map = distribution_lib.LayoutMap(device_mesh)\n+        layout_map[\".*dense.*kernel\"] = distribution_lib.TensorLayout(\n+            [None, \"model\"]\n+        )\n+        layout_map[\".*dense.*bias\"] = distribution_lib.TensorLayout([\"model\"])\n+\n+        distribution = distribution_lib.ModelParallel(\n+            device_mesh, layout_map, batch_dim_name=\"batch\"\n+        )\n+\n+        with distribution.scope():\n+            dense_layer = layers.Dense(8)\n+            dense_layer.build((16, 16))\n+\n+        self.assertEqual(\n+            dense_layer.kernel._value.sharding.spec, (None, \"model\")\n+        )\n+        self.assertEqual(dense_layer.bias._value.sharding.spec, (\"model\",))\n+\n+        # Assign a numpy value to dense layer to mimic the model weight loading\n+        new_kernel = np.random.normal(size=(16, 8))\n+        new_bias = np.random.normal(size=(8))\n+        dense_layer.kernel.assign(new_kernel)\n+        dense_layer.bias.assign(new_bias)\n+\n+        # Make sure the loaded value still use the layout when it is\n+        # initialized, even outside of the distribution scope.\n+        self.assertEqual(\n+            dense_layer.kernel._value.sharding.spec, (None, \"model\")\n+        )\n+        self.assertEqual(dense_layer.bias._value.sharding.spec, (\"model\",))\n+\n+    def test_e2e_data_parallel_model(self):\n+        distribution = distribution_lib.DataParallel(\n+            devices=backend_dlib.list_devices()\n+        )\n+\n+        with distribution.scope():\n+            inputs = layers.Input(shape=[28, 28, 1])\n+            y = layers.Flatten()(inputs)\n+            y = layers.Dense(units=200, use_bias=False, activation=\"relu\")(y)\n+            y = layers.Dropout(0.4)(y)\n+            y = layers.Dense(units=10, activation=\"softmax\")(y)\n+            model = models.Model(inputs=inputs, outputs=y)\n+\n+        # Make sure all the weights are properly sharded.\n+        for weight in model.weights:\n+            self.assertTrue(weight._value.sharding.is_fully_replicated)\n+\n+        inputs = np.random.normal(size=(32, 28, 28, 1))\n+        labels = np.random.normal(size=(32, 10))\n+\n+        with distribution.scope():\n+            model.compile(loss=\"mse\")\n+            model.fit(inputs, labels)\n+\n+    def test_e2e_model_parallel_model(self):\n+        shape = (4, 2)\n+        axis_names = [\"batch\", \"model\"]\n+        device_mesh = distribution_lib.DeviceMesh(\n+            shape, axis_names, backend_dlib.list_devices()\n+        )\n+\n+        layout_map = distribution_lib.LayoutMap(device_mesh)\n+        layout_map[\".*dense.*kernel\"] = distribution_lib.TensorLayout(\n+            [None, \"model\"]\n+        )\n+        layout_map[\".*dense.*bias\"] = distribution_lib.TensorLayout([\"model\"])\n+\n+        distribution = distribution_lib.ModelParallel(\n+            device_mesh, layout_map, batch_dim_name=\"batch\"\n+        )\n+        with distribution.scope():\n+            inputs = layers.Input(shape=[28, 28, 1])\n+            y = layers.Flatten()(inputs)\n+            y = layers.Dense(units=200, use_bias=False, activation=\"relu\")(y)\n+            y = layers.Dropout(0.4)(y)\n+            y = layers.Dense(units=10, activation=\"softmax\")(y)\n+            model = models.Model(inputs=inputs, outputs=y)\n+\n+        for weight in model.weights:\n+            if \"kernel\" in weight.name:\n+                self.assertEqual(weight._value.sharding.spec, (None, \"model\"))\n+            elif \"bias\" in weight.name:\n+                self.assertEqual(weight._value.sharding.spec, (\"model\",))\n+            else:\n+                self.assertTrue(weight._value.sharding.is_fully_replicated)\n+\n+        inputs = np.random.normal(size=(32, 28, 28, 1))\n+        labels = np.random.normal(size=(32, 10))\n+\n+        with distribution.scope():\n+            model.compile(loss=\"mse\")\n+            model.fit(inputs, labels)\n+\n+    def test_e2e_model_parallel_with_output_sharding(self):\n+        shape = (4, 2)\n+        axis_names = [\"batch\", \"model\"]\n+        device_mesh = distribution_lib.DeviceMesh(\n+            shape, axis_names, backend_dlib.list_devices()\n+        )\n+\n+        layout_map = distribution_lib.LayoutMap(device_mesh)\n+        layout_map[\".*dense.*kernel\"] = distribution_lib.TensorLayout(\n+            [None, \"model\"]\n+        )\n+        layout_map[\".*dense.*bias\"] = distribution_lib.TensorLayout([\"model\"])\n+        # Force the dense layer output to be batch parallel only, and not\n+        # sharded on model dimension.\n+        layout_map[\".*dense.*output\"] = (\"batch\", None)\n+\n+        distribution = distribution_lib.ModelParallel(\n+            device_mesh, layout_map, batch_dim_name=\"batch\"\n+        )\n+        sharding_capture = ShardingCaptureLayer()\n+        with distribution.scope():\n+            inputs = layers.Input(shape=[28, 28, 1])\n+            y = layers.Flatten()(inputs)\n+            y = layers.Dense(units=200, use_bias=False, activation=\"relu\")(y)\n+            y = sharding_capture(y)\n+            y = layers.Dropout(0.4)(y)\n+            y = layers.Dense(units=10, activation=\"softmax\")(y)\n+            model = models.Model(inputs=inputs, outputs=y)\n+\n+        for weight in model.weights:\n+            if \"kernel\" in weight.name:\n+                self.assertEqual(weight._value.sharding.spec, (None, \"model\"))\n+            elif \"bias\" in weight.name:\n+                self.assertEqual(weight._value.sharding.spec, (\"model\",))\n+            else:\n+                self.assertTrue(weight._value.sharding.is_fully_replicated)\n+\n+        inputs = np.random.normal(size=(32, 28, 28, 1))\n+        labels = np.random.normal(size=(32, 10))\n+\n+        with distribution.scope():\n+            model.compile(loss=\"mse\")\n+            model.fit(inputs, labels)\n+\n+        # Note that the intermediate_tensor_layout is only captured during the\n+        # actual training, and not at the model building time.\n+        intermediate_tensor_layout = jax.sharding.NamedSharding(\n+            backend_dlib._to_jax_mesh(distribution.device_mesh),\n+            jax.sharding.PartitionSpec(\"batch\", None),\n+        )\n+        self.assertTrue(\n+            sharding_capture.captured_input_sharding.is_equivalent_to(\n+                intermediate_tensor_layout, ndim=2\n+            )\n+        )\n+\n+\n+class ShardingCaptureLayer(layers.Layer):\n+    def __init__(self, **kwargs):\n+        super().__init__(**kwargs)\n+        self.captured_input_sharding = None\n+        self.supports_masking = True\n+\n+    def call(self, inputs):\n+        jax.debug.inspect_array_sharding(\n+            inputs, callback=lambda x: self.capture_input_sharding(x)\n+        )\n+        return inputs\n+\n+    def capture_input_sharding(self, sharding):\n+        self.captured_input_sharding = sharding\n\n@@ -1,31 +1,13 @@\n \"\"\"Test for distribution_lib.py.\"\"\"\n \n-import functools\n-import os\n from unittest import mock\n \n-import jax\n import numpy as np\n-import pytest\n \n from keras import backend\n-from keras import layers\n-from keras import models\n from keras import testing\n-from keras.backend import distribution_lib as backend_dlib\n from keras.distribution import distribution_lib\n \n-if backend.backend() == \"jax\":\n-    # Due to https://github.com/google/jax/issues/17188, we can't\n-    # override the XLA flag after the JAX back init. We have to\n-    # run this at top level to let JAX pick the flag value.\n-    xla_flags = os.getenv(\"XLA_FLAGS\") or \"\"\n-    # Don't override user-specified device count, or other XLA flags.\n-    if \"xla_force_host_platform_device_count\" not in xla_flags:\n-        os.environ[\"XLA_FLAGS\"] = (\n-            xla_flags + \" --xla_force_host_platform_device_count=8\"\n-        )\n-\n \n class DeviceMeshTest(testing.TestCase):\n     def test_mesh_creation(self):\n@@ -381,250 +363,6 @@ class LayoutMapTest(testing.TestCase):\n         self.assertEqual(values, [self.sharded_2d, self.sharded_1d])\n \n \n-@pytest.mark.skipif(\n-    backend.backend() != \"jax\",\n-    reason=\"Backend specific test\",\n-)\n-class JaxDistributionLibTest(testing.TestCase):\n-    def test_list_devices(self):\n-        self.assertEqual(len(distribution_lib.list_devices()), 8)\n-        self.assertEqual(len(distribution_lib.list_devices(\"cpu\")), 8)\n-        self.assertEqual(len(distribution_lib.list_devices(\"cpu\")), 8)\n-\n-    def test_distribute_tensor(self):\n-        jax_mesh = jax.sharding.Mesh(\n-            np.array(jax.devices()).reshape(2, 4), (\"batch\", \"model\")\n-        )\n-\n-        inputs = jax.numpy.array(np.random.normal(size=(16, 8)))\n-        target_layout = jax.sharding.NamedSharding(\n-            jax_mesh, jax.sharding.PartitionSpec(\"batch\", None)\n-        )\n-\n-        @functools.partial(jax.jit, static_argnames=\"target_layout\")\n-        def test_function(inputs, target_layout):\n-            return distribution_lib.distribute_tensor(inputs, target_layout)\n-\n-        result = test_function(inputs, target_layout)\n-        # Note that the returned tensor has a different sharding implementation\n-        # which is GSPMDSharding, but it should be equivalent as the target\n-        # layout specified.\n-        self.assertTrue(result.sharding.is_equivalent_to(target_layout, ndim=2))\n-\n-        # Test without jit\n-        result = distribution_lib.distribute_tensor(inputs, target_layout)\n-        self.assertTrue(result.sharding.is_equivalent_to(target_layout, ndim=2))\n-\n-    def test_to_jax_mesh(self):\n-        devices = [f\"cpu:{i}\" for i in range(8)]\n-        shape = (4, 2)\n-        axis_names = [\"batch\", \"model\"]\n-\n-        mesh = distribution_lib.DeviceMesh(shape, axis_names, devices)\n-        jax_mesh = backend_dlib._to_jax_mesh(mesh)\n-\n-        self.assertIsInstance(jax_mesh, jax.sharding.Mesh)\n-        self.assertEqual(jax_mesh.devices.shape, shape)\n-        self.assertEqual(jax_mesh.axis_names, (\"batch\", \"model\"))\n-\n-    def test_to_jax_layout(self):\n-        axes = [\"data\", None]\n-        mesh = distribution_lib.DeviceMesh(\n-            (4, 2), [\"data\", \"model\"], [f\"cpu:{i}\" for i in range(8)]\n-        )\n-        layout = distribution_lib.TensorLayout(axes, mesh)\n-        jax_sharding = backend_dlib._to_jax_layout(layout)\n-        jax_mesh = backend_dlib._to_jax_mesh(mesh)\n-        self.assertEqual(\n-            jax_sharding,\n-            jax.sharding.NamedSharding(\n-                jax_mesh, jax.sharding.PartitionSpec(\"data\", None)\n-            ),\n-        )\n-\n-    def test_validation_for_device_mesh(self):\n-        axes = [\"data\", None]\n-        layout = distribution_lib.TensorLayout(axes, device_mesh=None)\n-\n-        with self.assertRaisesRegex(\n-            ValueError, \"Cannot create sharding when device mesh is not set\"\n-        ):\n-            backend_dlib._to_jax_layout(layout)\n-\n-    def test_variable_assignment_reuse_layout(self):\n-        shape = (4, 2)\n-        axis_names = [\"batch\", \"model\"]\n-        device_mesh = distribution_lib.DeviceMesh(\n-            shape, axis_names, backend_dlib.list_devices()\n-        )\n-        layout_map = distribution_lib.LayoutMap(device_mesh)\n-        layout_map[\".*dense.*kernel\"] = distribution_lib.TensorLayout(\n-            [None, \"model\"]\n-        )\n-        layout_map[\".*dense.*bias\"] = distribution_lib.TensorLayout([\"model\"])\n-\n-        distribution = distribution_lib.ModelParallel(\n-            device_mesh, layout_map, batch_dim_name=\"batch\"\n-        )\n-\n-        with distribution.scope():\n-            dense_layer = layers.Dense(8)\n-            dense_layer.build((16, 16))\n-\n-        self.assertEqual(\n-            dense_layer.kernel._value.sharding.spec, (None, \"model\")\n-        )\n-        self.assertEqual(dense_layer.bias._value.sharding.spec, (\"model\",))\n-\n-        # Assign a numpy value to dense layer to mimic the model weight loading\n-        new_kernel = np.random.normal(size=(16, 8))\n-        new_bias = np.random.normal(size=(8))\n-        dense_layer.kernel.assign(new_kernel)\n-        dense_layer.bias.assign(new_bias)\n-\n-        # Make sure the loaded value still use the layout when it is\n-        # initialized, even outside of the distribution scope.\n-        self.assertEqual(\n-            dense_layer.kernel._value.sharding.spec, (None, \"model\")\n-        )\n-        self.assertEqual(dense_layer.bias._value.sharding.spec, (\"model\",))\n-\n-    def test_e2e_data_parallel_model(self):\n-        distribution = distribution_lib.DataParallel(\n-            devices=backend_dlib.list_devices()\n-        )\n-\n-        with distribution.scope():\n-            inputs = layers.Input(shape=[28, 28, 1])\n-            y = layers.Flatten()(inputs)\n-            y = layers.Dense(units=200, use_bias=False, activation=\"relu\")(y)\n-            y = layers.Dropout(0.4)(y)\n-            y = layers.Dense(units=10, activation=\"softmax\")(y)\n-            model = models.Model(inputs=inputs, outputs=y)\n-\n-        # Make sure all the weights are properly sharded.\n-        for weight in model.weights:\n-            self.assertTrue(weight._value.sharding.is_fully_replicated)\n-\n-        inputs = np.random.normal(size=(32, 28, 28, 1))\n-        labels = np.random.normal(size=(32, 10))\n-\n-        with distribution.scope():\n-            model.compile(loss=\"mse\")\n-            model.fit(inputs, labels)\n-\n-    def test_e2e_model_parallel_model(self):\n-        shape = (4, 2)\n-        axis_names = [\"batch\", \"model\"]\n-        device_mesh = distribution_lib.DeviceMesh(\n-            shape, axis_names, backend_dlib.list_devices()\n-        )\n-\n-        layout_map = distribution_lib.LayoutMap(device_mesh)\n-        layout_map[\".*dense.*kernel\"] = distribution_lib.TensorLayout(\n-            [None, \"model\"]\n-        )\n-        layout_map[\".*dense.*bias\"] = distribution_lib.TensorLayout([\"model\"])\n-\n-        distribution = distribution_lib.ModelParallel(\n-            device_mesh, layout_map, batch_dim_name=\"batch\"\n-        )\n-        with distribution.scope():\n-            inputs = layers.Input(shape=[28, 28, 1])\n-            y = layers.Flatten()(inputs)\n-            y = layers.Dense(units=200, use_bias=False, activation=\"relu\")(y)\n-            y = layers.Dropout(0.4)(y)\n-            y = layers.Dense(units=10, activation=\"softmax\")(y)\n-            model = models.Model(inputs=inputs, outputs=y)\n-\n-        for weight in model.weights:\n-            if \"kernel\" in weight.name:\n-                self.assertEqual(weight._value.sharding.spec, (None, \"model\"))\n-            elif \"bias\" in weight.name:\n-                self.assertEqual(weight._value.sharding.spec, (\"model\",))\n-            else:\n-                self.assertTrue(weight._value.sharding.is_fully_replicated)\n-\n-        inputs = np.random.normal(size=(32, 28, 28, 1))\n-        labels = np.random.normal(size=(32, 10))\n-\n-        with distribution.scope():\n-            model.compile(loss=\"mse\")\n-            model.fit(inputs, labels)\n-\n-    def test_e2e_model_parallel_with_output_sharding(self):\n-        shape = (4, 2)\n-        axis_names = [\"batch\", \"model\"]\n-        device_mesh = distribution_lib.DeviceMesh(\n-            shape, axis_names, backend_dlib.list_devices()\n-        )\n-\n-        layout_map = distribution_lib.LayoutMap(device_mesh)\n-        layout_map[\".*dense.*kernel\"] = distribution_lib.TensorLayout(\n-            [None, \"model\"]\n-        )\n-        layout_map[\".*dense.*bias\"] = distribution_lib.TensorLayout([\"model\"])\n-        # Force the dense layer output to be batch parallel only, and not\n-        # sharded on model dimension.\n-        layout_map[\".*dense.*output\"] = (\"batch\", None)\n-\n-        distribution = distribution_lib.ModelParallel(\n-            device_mesh, layout_map, batch_dim_name=\"batch\"\n-        )\n-        sharding_capture = ShardingCaptureLayer()\n-        with distribution.scope():\n-            inputs = layers.Input(shape=[28, 28, 1])\n-            y = layers.Flatten()(inputs)\n-            y = layers.Dense(units=200, use_bias=False, activation=\"relu\")(y)\n-            y = sharding_capture(y)\n-            y = layers.Dropout(0.4)(y)\n-            y = layers.Dense(units=10, activation=\"softmax\")(y)\n-            model = models.Model(inputs=inputs, outputs=y)\n-\n-        for weight in model.weights:\n-            if \"kernel\" in weight.name:\n-                self.assertEqual(weight._value.sharding.spec, (None, \"model\"))\n-            elif \"bias\" in weight.name:\n-                self.assertEqual(weight._value.sharding.spec, (\"model\",))\n-            else:\n-                self.assertTrue(weight._value.sharding.is_fully_replicated)\n-\n-        inputs = np.random.normal(size=(32, 28, 28, 1))\n-        labels = np.random.normal(size=(32, 10))\n-\n-        with distribution.scope():\n-            model.compile(loss=\"mse\")\n-            model.fit(inputs, labels)\n-\n-        # Note that the intermediate_tensor_layout is only captured during the\n-        # actual training, and not at the model building time.\n-        intermediate_tensor_layout = jax.sharding.NamedSharding(\n-            backend_dlib._to_jax_mesh(distribution.device_mesh),\n-            jax.sharding.PartitionSpec(\"batch\", None),\n-        )\n-        self.assertTrue(\n-            sharding_capture.captured_input_sharding.is_equivalent_to(\n-                intermediate_tensor_layout, ndim=2\n-            )\n-        )\n-\n-\n-class ShardingCaptureLayer(layers.Layer):\n-    def __init__(self, **kwargs):\n-        super().__init__(**kwargs)\n-        self.captured_input_sharding = None\n-        self.supports_masking = True\n-\n-    def call(self, inputs):\n-        jax.debug.inspect_array_sharding(\n-            inputs, callback=lambda x: self.capture_input_sharding(x)\n-        )\n-        return inputs\n-\n-    def capture_input_sharding(self, sharding):\n-        self.captured_input_sharding = sharding\n-\n-\n # @pytest.mark.skipif(\n #     backend.backend() != \"tensorflow\",\n #     reason=\"Backend specific test\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#33ef6c5273e30b164bc7cda20c962152564488a9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 16 | Churn Cumulative: 140 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -58,7 +58,7 @@ def distribute_tensor(tensor, layout):\n     jitted function.\n \n     Args:\n-        value: `jax.Array` that need to be distributed.\n+        tensor: `jax.Array` that need to be distributed.\n         layout: `TensorLayout` for the distribution information, or a\n             `jax.sharding.Sharding` instance.\n \n@@ -67,12 +67,24 @@ def distribute_tensor(tensor, layout):\n     \"\"\"\n     if not isinstance(layout, jax.sharding.Sharding):\n         layout = _to_jax_layout(layout)\n-\n     # TODO(scottzhu): This might not be a cheap check, we should consider\n     # have some proper JAX API for doing this check.\n     if jax_utils.is_in_jax_tracing_scope():\n         return jax.lax.with_sharding_constraint(tensor, layout)\n+\n+    if layout.is_fully_addressable:\n         return jax.device_put(tensor, layout)\n+    else:\n+        # Need to only distribute the value to local addressible devices, and\n+        # repack them back into global format.\n+        mapping = layout.addressable_devices_indices_map(tensor.shape)\n+        local_values = jax.device_put(\n+            [tensor[i] for i in mapping.values()], list(mapping.keys())\n+        )\n+        global_value = jax.make_array_from_single_device_arrays(\n+            tensor.shape, layout, local_values\n+        )\n+        return global_value\n \n \n def _to_jax_device(device_id):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#94aebac5e789d9e19d914caf53e15e2709b06f10", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 62 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 9 | Complexity Δ (Sum/Max): 9/8 | Churn Δ: 62 | Churn Cumulative: 86 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -233,3 +233,9 @@ class RandomTest(testing.TestCase, parameterized.TestCase):\n         self.assertFalse(np.all(x == ops.convert_to_numpy(y)))\n         self.assertAllClose(np.sum(x, axis=1), ops.sum(y, axis=1))\n         self.assertNotAllClose(np.sum(x, axis=0), ops.sum(y, axis=0))\n+\n+    def test_randint_dtype_validation(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"`keras.random.randint` requires an integer `dtype`.\"\n+        ):\n+            random.randint((3, 4), minval=0, maxval=10, dtype=\"float64\")\n\n@@ -0,0 +1,56 @@\n+import numpy as np\n+\n+from keras import backend\n+from keras import ops\n+from keras import testing\n+from keras.random import seed_generator\n+\n+\n+class SeedGeneratorTest(testing.TestCase):\n+    def test_seed_generator_initialization(self):\n+        gen = seed_generator.SeedGenerator()\n+        self.assertIsNotNone(gen.state)\n+\n+        seed = 12345\n+        gen = seed_generator.SeedGenerator(seed=seed)\n+        self.assertEqual(ops.convert_to_numpy(gen.state)[0], seed)\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \"Argument `seed` must be an integer\"\n+        ):\n+            seed_generator.SeedGenerator(seed=\"invalid_seed\")\n+\n+    def test_seed_generator_next(self):\n+        gen = seed_generator.SeedGenerator(seed=42)\n+        seed1 = ops.convert_to_numpy(gen.next())\n+        seed2 = ops.convert_to_numpy(gen.next())\n+        self.assertFalse(np.array_equal(seed1, seed2))\n+\n+    def test_global_seed_generator(self):\n+        gen1 = seed_generator.global_seed_generator()\n+        gen2 = seed_generator.global_seed_generator()\n+        self.assertEqual(gen1, gen2)\n+\n+    def test_make_default_seed(self):\n+        seed1 = seed_generator.make_default_seed()\n+        seed2 = seed_generator.make_default_seed()\n+        self.assertNotEqual(seed1, seed2)\n+\n+    def test_draw_seed_from_seed_generator(self):\n+        gen = seed_generator.SeedGenerator(seed=42)\n+        seed1 = seed_generator.draw_seed(gen)\n+        self.assertTrue(backend.is_tensor(seed1))\n+\n+    def test_draw_seed_from_integer(self):\n+        seed2 = seed_generator.draw_seed(12345)\n+        self.assertTrue(backend.is_tensor(seed2))\n+\n+    def test_draw_seed_from_none(self):\n+        seed3 = seed_generator.draw_seed(None)\n+        self.assertTrue(backend.is_tensor(seed3))\n+\n+    def test_draw_seed_invalid(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"Argument `seed` must be either an integer\"\n+        ):\n+            seed_generator.draw_seed(\"invalid_seed\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#56762f99f6c1b1d7817a932c049f2885d68f4508", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 8 | Churn Cumulative: 60 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -735,6 +735,8 @@ class FeatureSpace(Layer):\n         if rebatched:\n             if self.output_mode == \"concat\":\n                 assert merged_data.shape[0] == 1\n+                if backend.backend() != \"tensorflow\":\n+                    merged_data = backend.convert_to_numpy(merged_data)\n                 merged_data = tf.squeeze(merged_data, axis=0)\n             else:\n                 for name, x in merged_data.items():\n\n@@ -469,8 +469,12 @@ class FeatureSpaceTest(testing.TestCase):\n         out = fs(data)\n         self.assertEqual(tuple(out.shape), (10, 32))\n \n-    @pytest.mark.skipif(backend.backend() == \"numpy\", reason=\"TODO: debug it\")\n+    @pytest.mark.skipif(\n+        backend.backend() != \"tensorflow\", reason=\"TODO: debug it\"\n+    )\n     def test_saving(self):\n+        # Torch GPU: `model.predict(ds.batch(4))` fails on device placement\n+        # JAX GPU: out[0] and ref_out don't match. May be concat feature order?\n         cls = feature_space.FeatureSpace\n         fs = feature_space.FeatureSpace(\n             features={\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#39e3c42729a2b83ac68b0a245336e69612ff7d4e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 121 | Lines Deleted: 161 | Files Changed: 3 | Hunks: 22 | Methods Changed: 13 | Complexity Δ (Sum/Max): 16/14 | Churn Δ: 282 | Churn Cumulative: 2782 | Contributors (this commit): 5 | Commits (past 90d): 7 | Contributors (cumulative): 11 | DMM Complexity: 0.9047619047619048\n\nDIFF:\n@@ -67,6 +67,9 @@ class Operation:\n         try:\n             return backend.compute_output_spec(self.call, *args, **kwargs)\n         except Exception as e:\n+            if isinstance(e, TypeError):\n+                raise e\n+            else:\n                 new_e = RuntimeError(\n                     \"Could not automatically infer the output shape / dtype of \"\n                     f\"'{self.name}' (of type {self.__class__.__name__}). \"\n\n@@ -587,186 +587,133 @@ class SavingAPITest(testing.TestCase):\n         with self.assertRaisesRegex(ValueError, \"are not supported\"):\n             model.save(temp_filepath, invalid_arg=\"hello\")\n \n+    def test_safe_mode(self):\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"unsafe_model.keras\")\n+        model = keras.Sequential(\n+            [\n+                keras.Input(shape=(3,)),\n+                keras.layers.Lambda(lambda x: x * 2),\n+            ]\n+        )\n+        model.save(temp_filepath)\n+        with self.assertRaisesRegex(ValueError, \"Deserializing it is unsafe\"):\n+            model = saving_lib.load_model(temp_filepath)\n+        model = saving_lib.load_model(temp_filepath, safe_mode=False)\n \n-# def test_safe_mode(self):\n-#     temp_filepath = os.path.join(self.get_temp_dir(), \"unsafe_model.keras\")\n-#     model = keras.Sequential(\n-#         [\n-#             keras.Input(shape=(3,)),\n-#             keras.layers.Dense(2, activation=lambda x: x * 2),\n-#         ]\n-#     )\n-#     model.save(temp_filepath)\n-#     with self.assertRaisesRegex(ValueError, \"arbitrary code execution\"):\n-#         model = saving_lib.load_model(temp_filepath)\n-#     model = saving_lib.load_model(temp_filepath, safe_mode=False)\n+    def test_normalization_kpl(self):\n+        # With adapt\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"norm_model.keras\")\n+        model = keras.Sequential(\n+            [\n+                keras.Input(shape=(3,)),\n+                keras.layers.Normalization(),\n+            ]\n+        )\n+        data = np.random.random((3, 3))\n+        model.layers[0].adapt(data)\n+        ref_out = model(data)\n+        model.save(temp_filepath)\n+        model = saving_lib.load_model(temp_filepath)\n+        out = model(data)\n+        self.assertAllClose(ref_out, out, atol=1e-6)\n \n-#     def test_normalization_kpl(self):\n-#         # With adapt\n-#         temp_filepath = os.path.join(self.get_temp_dir(), \"norm_model.keras\")\n-#         model = keras.Sequential(\n-#             [\n-#                 keras.Input(shape=(3,)),\n-#                 keras.layers.Normalization(),\n-#             ]\n-#         )\n-#         data = np.random.random((3, 3))\n-#         model.layers[0].adapt(data)\n-#         ref_out = model(data)\n-#         model.save(temp_filepath)\n-#         model = saving_lib.load_model(temp_filepath)\n-#         out = model(data)\n-#         self.assertAllClose(ref_out, out, atol=1e-6)\n-\n-#         # Without adapt\n-#         model = keras.Sequential(\n-#             [\n-#                 keras.Input(shape=(3,)),\n-#                 keras.layers.Normalization(\n-#                     mean=np.random.random((3,)),\n-#                     variance=np.random.random((3,)),\n-#                 ),\n-#             ]\n-#         )\n-#         ref_out = model(data)\n-#         model.save(temp_filepath)\n-#         model = saving_lib.load_model(temp_filepath)\n-#         out = model(data)\n-#         self.assertAllClose(ref_out, out, atol=1e-6)\n+        # Without adapt\n+        model = keras.Sequential(\n+            [\n+                keras.Input(shape=(3,)),\n+                keras.layers.Normalization(\n+                    mean=np.random.random((3,)),\n+                    variance=np.random.random((3,)),\n+                ),\n+            ]\n+        )\n+        ref_out = model(data)\n+        model.save(temp_filepath)\n+        model = saving_lib.load_model(temp_filepath)\n+        out = model(data)\n+        self.assertAllClose(ref_out, out, atol=1e-6)\n \n \n-# # This custom class lacks custom object registration.\n-# class CustomRNN(keras.layers.Layer):\n-#     def __init__(self, units):\n-#         super(CustomRNN, self).__init__()\n-#         self.units = units\n-#         self.projection_1 = keras.layers.Dense(\n-#             units=units, activation=\"tanh\"\n-#         )\n-#         self.projection_2 = keras.layers.Dense(\n-#             units=units, activation=\"tanh\"\n-#         )\n-#         self.classifier = keras.layers.Dense(1)\n+# This class is properly registered with a `get_config()` method.\n+# However, since it does not subclass keras.layers.Layer, it lacks\n+# `from_config()` for deserialization.\n+@keras.saving.register_keras_serializable()\n+class GrowthFactor:\n+    def __init__(self, factor):\n+        self.factor = factor\n \n-#     def call(self, inputs):\n-#         outputs = []\n-#         state = ops.zeros(shape=(inputs.shape[0], self.units))\n-#         for t in range(inputs.shape[1]):\n-#             x = inputs[:, t, :]\n-#             h = self.projection_1(x)\n-#             y = h + self.projection_2(state)\n-#             state = y\n-#             outputs.append(y)\n-#         features = ops.stack(outputs, axis=1)\n-#         return self.classifier(features)\n+    def __call__(self, inputs):\n+        return inputs * self.factor\n+\n+    def get_config(self):\n+        return {\"factor\": self.factor}\n \n \n-# # This class is properly registered with a `get_config()` method.\n-# # However, since it does not subclass keras.layers.Layer, it lacks\n-# # `from_config()` for deserialization.\n-# @keras.saving.register_keras_serializable()\n-# class GrowthFactor:\n-#     def __init__(self, factor):\n-#         self.factor = factor\n+@keras.saving.register_keras_serializable(package=\"Complex\")\n+class FactorLayer(keras.layers.Layer):\n+    def __init__(self, factor, **kwargs):\n+        super().__init__(**kwargs)\n+        self.factor = factor\n \n-#     def __call__(self, inputs):\n-#         return inputs * self.factor\n+    def call(self, x):\n+        return x * self.factor\n \n-#     def get_config(self):\n-#         return {\"factor\": self.factor}\n+    def get_config(self):\n+        return {\"factor\": self.factor}\n \n \n-# @keras.saving.register_keras_serializable(package=\"Complex\")\n-# class FactorLayer(keras.layers.Layer):\n-#     def __init__(self, factor):\n-#         super().__init__()\n-#         self.factor = factor\n+# This custom model does not explicitly deserialize the layers it includes\n+# in its `get_config`. Explicit deserialization in a `from_config` override\n+# or `__init__` is needed here, or an error will be thrown at loading time.\n+@keras.saving.register_keras_serializable(package=\"Complex\")\n+class ComplexModel(keras.layers.Layer):\n+    def __init__(self, first_layer, second_layer=None, **kwargs):\n+        super().__init__(**kwargs)\n+        self.first_layer = first_layer\n+        if second_layer is not None:\n+            self.second_layer = second_layer\n+        else:\n+            self.second_layer = keras.layers.Dense(8)\n \n-#     def call(self, x):\n-#         return x * self.factor\n+    def get_config(self):\n+        config = super().get_config()\n+        config.update(\n+            {\n+                \"first_layer\": self.first_layer,\n+                \"second_layer\": self.second_layer,\n+            }\n+        )\n+        return config\n \n-#     def get_config(self):\n-#         return {\"factor\": self.factor}\n+    def call(self, inputs):\n+        return self.first_layer(self.second_layer(inputs))\n \n \n-# # This custom model does not explicitly deserialize the layers it includes\n-# # in its `get_config`. Explicit deserialization in a `from_config` override\n-# # or `__init__` is needed here, or an error will be thrown at loading time.\n-# @keras.saving.register_keras_serializable(package=\"Complex\")\n-# class ComplexModel(keras.layers.Layer):\n-#     def __init__(self, first_layer, second_layer=None, **kwargs):\n-#         super().__init__(**kwargs)\n-#         self.first_layer = first_layer\n-#         if second_layer is not None:\n-#             self.second_layer = second_layer\n-#         else:\n-#             self.second_layer = keras.layers.Dense(8)\n+class SavingBattleTest(testing.TestCase):\n+    def test_custom_object_without_from_config(self):\n+        temp_filepath = os.path.join(\n+            self.get_temp_dir(), \"custom_fn_model.keras\"\n+        )\n \n-#     def get_config(self):\n-#         config = super().get_config()\n-#         config.update(\n-#             {\n-#                 \"first_layer\": self.first_layer,\n-#                 \"second_layer\": self.second_layer,\n-#             }\n-#         )\n-#         return config\n+        inputs = keras.Input(shape=(4, 4))\n+        outputs = keras.layers.Dense(1, activation=GrowthFactor(0.5))(inputs)\n+        model = keras.Model(inputs, outputs)\n \n-#     def call(self, inputs):\n-#         return self.first_layer(self.second_layer(inputs))\n+        model.save(temp_filepath)\n \n+        with self.assertRaisesRegex(\n+            TypeError, \"Unable to reconstruct an instance\"\n+        ):\n+            _ = saving_lib.load_model(temp_filepath)\n \n-# class SavingBattleTest(testing.TestCase):\n-#     def test_custom_model_without_registration_error(self):\n-#         temp_filepath = os.path.join(\n-#             self.get_temp_dir(), \"my_custom_model.keras\"\n-#         )\n-#         timesteps = 10\n-#         input_dim = 5\n-#         batch_size = 16\n+    def test_complex_model_without_explicit_deserialization(self):\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"complex_model.keras\")\n \n-#         inputs = keras.Input(\n-#             batch_shape=(batch_size, timesteps, input_dim)\n-#         )\n-#         x = keras.layers.Conv1D(32, 3)(inputs)\n-#         outputs = CustomRNN(32)(x)\n+        inputs = keras.Input((32,))\n+        outputs = ComplexModel(first_layer=FactorLayer(0.5))(inputs)\n+        model = keras.Model(inputs, outputs)\n \n-#         model = keras.Model(inputs, outputs)\n+        model.save(temp_filepath)\n \n-#         with self.assertRaisesRegex(\n-#             TypeError, \"is a custom class, please register it\"\n-#         ):\n-#             model.save(temp_filepath)\n-#             _ = keras.models.load_model(temp_filepath)\n-\n-#     def test_custom_object_without_from_config(self):\n-#         temp_filepath = os.path.join(\n-#             self.get_temp_dir(), \"custom_fn_model.keras\"\n-#         )\n-\n-#         inputs = keras.Input(shape=(4, 4))\n-#         outputs = keras.layers.Dense(\n-#             1, activation=GrowthFactor(0.5)\n-#         )(inputs)\n-#         model = keras.Model(inputs, outputs)\n-\n-#         model.save(temp_filepath)\n-\n-#         with self.assertRaisesRegex(\n-#             TypeError, \"Unable to reconstruct an instance\"\n-#         ):\n-#             _ = keras.models.load_model(temp_filepath)\n-\n-#     def test_complex_model_without_explicit_deserialization(self):\n-#         temp_filepath = os.path.join(\n-#             self.get_temp_dir(), \"complex_model.keras\"\n-#         )\n-\n-#         inputs = keras.Input((32,))\n-#         outputs = ComplexModel(first_layer=FactorLayer(0.5))(inputs)\n-#         model = keras.Model(inputs, outputs)\n-\n-#         model.save(temp_filepath)\n-\n-#         with self.assertRaisesRegex(TypeError, \"are explicitly deserialized\"):\n-#             _ = keras.models.load_model(temp_filepath)\n+        with self.assertRaisesRegex(TypeError, \"are explicitly deserialized\"):\n+            _ = saving_lib.load_model(temp_filepath)\n\n@@ -703,7 +703,17 @@ def deserialize_keras_object(\n     custom_obj_scope = object_registration.CustomObjectScope(custom_objects)\n     safe_mode_scope = SafeModeScope(safe_mode)\n     with custom_obj_scope, safe_mode_scope:\n+        try:\n             instance = cls.from_config(inner_config)\n+        except TypeError as e:\n+            raise TypeError(\n+                f\"{cls} could not be deserialized properly. Please\"\n+                \" ensure that components that are Python object\"\n+                \" instances (layers, models, etc.) returned by\"\n+                \" `get_config()` are explicitly deserialized in the\"\n+                \" model's `from_config()` method.\"\n+                f\"\\n\\nconfig={config}.\\n\\nException encountered: {e}\"\n+            )\n         build_config = config.get(\"build_config\", None)\n         if build_config and not instance.built:\n             instance.build_from_config(build_config)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
