{"custom_id": "keras#5e1d640e20a74c00a73e23c00bb8040b86aba581", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 26 | Churn Cumulative: 2096 | Contributors (this commit): 5 | Commits (past 90d): 4 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -167,13 +167,13 @@ class Normalization(base_preprocessing_layer.PreprocessingLayer):\n       self.adapt_mean = self.add_weight(\n           name='mean',\n           shape=mean_and_var_shape,\n-          dtype=self.dtype,\n+          dtype=self.compute_dtype,\n           initializer='zeros',\n           trainable=False)\n       self.adapt_variance = self.add_weight(\n           name='variance',\n           shape=mean_and_var_shape,\n-          dtype=self.dtype,\n+          dtype=self.compute_dtype,\n           initializer='ones',\n           trainable=False)\n       self.count = self.add_weight(\n@@ -215,8 +215,8 @@ class Normalization(base_preprocessing_layer.PreprocessingLayer):\n \n     total_count = batch_count + self.count\n     batch_weight = (\n-        tf.cast(batch_count, dtype=self.dtype) /\n-        tf.cast(total_count, dtype=self.dtype))\n+        tf.cast(batch_count, dtype=self.compute_dtype) /\n+        tf.cast(total_count, dtype=self.compute_dtype))\n     existing_weight = 1. - batch_weight\n \n     total_mean = self.adapt_mean * existing_weight + batch_mean * batch_weight\n@@ -274,6 +274,6 @@ class Normalization(base_preprocessing_layer.PreprocessingLayer):\n \n   def _standardize_inputs(self, inputs):\n     inputs = tf.convert_to_tensor(inputs)\n-    if inputs.dtype != self.dtype:\n-      inputs = tf.cast(inputs, self.dtype)\n+    if inputs.dtype != self.compute_dtype:\n+      inputs = tf.cast(inputs, self.compute_dtype)\n     return inputs\n\n@@ -27,6 +27,7 @@ from keras import keras_parameterized\n from keras import testing_utils\n from keras.layers.preprocessing import normalization\n from keras.layers.preprocessing import preprocessing_test_utils\n+from keras.mixed_precision import policy\n \n \n def _get_layer_computation_test_cases():\n@@ -184,6 +185,19 @@ class NormalizationTest(keras_parameterized.TestCase,\n                                 \"axis.*values must be in the range\"):\n       normalization.Normalization()(1)\n \n+  def test_output_dtype(self):\n+    if not tf.__internal__.tf2.enabled():\n+      self.skipTest(\"set_global_policy only supported in TF2.\")\n+    # Output should respect an explicit dtype, and default to the global policy.\n+    policy.set_global_policy(\"float64\")\n+    input_data = keras.Input(batch_size=16, shape=(1,))\n+    layer = normalization.Normalization(mean=1.0, variance=1.0, dtype=\"float16\")\n+    output = layer(input_data)\n+    self.assertAllEqual(output.dtype, tf.float16)\n+    layer = normalization.Normalization(mean=1.0, variance=1.0)\n+    output = layer(input_data)\n+    self.assertAllEqual(output.dtype, tf.float64)\n+\n \n @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class NormalizationAdaptTest(keras_parameterized.TestCase,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#650697f8cdbd7f44842fbca533965ec76c2ec69c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 43 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 9 | Methods Changed: 6 | Complexity Δ (Sum/Max): 15/15 | Churn Δ: 46 | Churn Cumulative: 18410 | Contributors (this commit): 137 | Commits (past 90d): 45 | Contributors (cumulative): 149 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2616,7 +2616,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n               line_length=None,\n               positions=None,\n               print_fn=None,\n-              expand_nested=False):\n+              expand_nested=False,\n+              show_trainable=False):\n     \"\"\"Prints a string summary of the network.\n \n     Args:\n@@ -2632,6 +2633,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n             in order to capture the string summary.\n         expand_nested: Whether to expand the nested models.\n             If not provided, defaults to `False`.\n+        show_trainable: Whether to show if a layer is trainable.\n+            If not provided, defaults to `False`.\n \n     Raises:\n         ValueError: if `summary()` is called before the model is built.\n@@ -2646,7 +2649,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         line_length=line_length,\n         positions=positions,\n         print_fn=print_fn,\n-        expand_nested=expand_nested)\n+        expand_nested=expand_nested,\n+        show_trainable=show_trainable)\n \n   @property\n   def layers(self):\n\n@@ -108,7 +108,8 @@ def print_summary(model,\n                   line_length=None,\n                   positions=None,\n                   print_fn=None,\n-                  expand_nested=False):\n+                  expand_nested=False,\n+                  show_trainable=False):\n   \"\"\"Prints a summary of a model.\n \n   Args:\n@@ -125,6 +126,8 @@ def print_summary(model,\n           It defaults to `print` (prints to stdout).\n       expand_nested: Whether to expand the nested models.\n           If not provided, defaults to `False`.\n+      show_trainable: Whether to show if a layer is trainable.\n+          If not provided, defaults to `False`.\n   \"\"\"\n   if print_fn is None:\n     print_fn = print\n@@ -162,6 +165,26 @@ def print_summary(model,\n         if not sequential_like:\n           break\n \n+  if show_trainable:\n+    # Add trainable column\n+    if sequential_like:\n+      line_length = line_length or 85\n+      positions = positions or [.33, .70, .89, 1.]\n+      if positions[-1] <= 1:\n+        positions = [int(line_length * p) for p in positions]\n+      # header names for the different log elements\n+      to_display = ['Layer (type)', 'Output Shape', 'Param #', 'Trainable']\n+    else:\n+      line_length = line_length or 110\n+      positions = positions or [.33, .40, .55, .67, 1.]\n+      if positions[-1] <= 1:\n+        positions = [int(line_length * p) for p in positions]\n+      # header names for the different log elements\n+      to_display = ['Layer (type)', 'Output Shape', 'Param #', 'Trainable', 'Connected to']\n+      relevant_nodes = []\n+      for v in model._nodes_by_depth.values():\n+        relevant_nodes += v\n+  else:\n     if sequential_like:\n       line_length = line_length or 65\n       positions = positions or [.45, .85, 1.]\n@@ -248,7 +271,12 @@ def print_summary(model,\n       params = '0 (unused)'\n     else:\n       params = layer.count_params()\n+\n+    if show_trainable:\n+      fields = [name + ' (' + cls_name + ')', output_shape, params, \"T\" if layer.trainable else \"F\"]\n+    else:\n       fields = [name + ' (' + cls_name + ')', output_shape, params]\n+\n     print_row(fields, positions, nested_level)\n \n   def print_layer_summary_with_connections(layer, nested_level=0):\n@@ -275,6 +303,14 @@ def print_summary(model,\n \n     name = layer.name\n     cls_name = layer.__class__.__name__\n+    if show_trainable:\n+      fields = [\n+        name + ' (' + cls_name + ')', output_shape,\n+        layer.count_params(), \n+        \"T\" if layer.trainable else \"F\", \n+        connections\n+      ]\n+    else:\n       fields = [\n         name + ' (' + cls_name + ')', output_shape,\n         layer.count_params(), connections\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b26d80151580bf46001e24d38a505741de0c5ac4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 125 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 5 | Complexity Δ (Sum/Max): 9/9 | Churn Δ: 125 | Churn Cumulative: 619 | Contributors (this commit): 4 | Commits (past 90d): 8 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -223,6 +223,131 @@ class LayerUtilsTest(tf.test.TestCase):\n     except ImportError:\n       pass\n \n+  def test_print_summary_show_trainable(self):\n+    model = keras.Sequential(name=\"trainable\")\n+    untrained = keras.layers.Conv2D(filters=2, kernel_size=(2, 3), input_shape=(3, 5, 5), name='conv')\n+    model.add(untrained)\n+    model.add(keras.layers.Flatten(name='flat'))\n+    model.add(keras.layers.Dense(5, name='dense'))\n+\n+    untrained.trainable = False\n+\n+    file_name = 'model_4.txt'\n+    temp_dir = self.get_temp_dir()\n+    self.addCleanup(shutil.rmtree, temp_dir, ignore_errors=True)\n+    fpath = os.path.join(temp_dir, file_name)\n+    writer = open(fpath, 'w')\n+\n+    def print_to_file(text):\n+      print(text, file=writer)\n+\n+    try:\n+      layer_utils.print_summary(model, \n+                                print_fn=print_to_file, \n+                                show_trainable=True)\n+      self.assertTrue(tf.io.gfile.exists(fpath))\n+      writer.close()\n+      reader = open(fpath, 'r')\n+      lines = reader.readlines()\n+      reader.close()\n+      check_str = (\n+        'Model: \"trainable\"\\n'\n+        '_____________________________________________________________________________________\\n'\n+        ' Layer (type)               Output Shape                   Param #         Trainable \\n'\n+        '=====================================================================================\\n'\n+        ' conv (Conv2D)              (None, 2, 3, 2)                62              F         \\n'\n+        '                                                                                     \\n'\n+        ' flat (Flatten)             (None, 12)                     0               T         \\n'\n+        '                                                                                     \\n'\n+        ' dense (Dense)              (None, 5)                      65              T         \\n'\n+        '                                                                                     \\n'\n+        '=====================================================================================\\n'\n+        'Total params: 127\\n'\n+        'Trainable params: 65\\n'\n+        'Non-trainable params: 62\\n'\n+        '_____________________________________________________________________________________\\n')\n+\n+      fin_str = ''\n+      for line in lines:\n+        fin_str += line\n+\n+      self.assertIn(fin_str, check_str)\n+      self.assertEqual(len(lines), 15)\n+    except ImportError:\n+      pass\n+\n+  def test_print_summary_expand_nested_show_trainable(self):\n+    shape = (None, None, 3)\n+\n+    def make_model():\n+      x = inputs = keras.Input(shape, name='input2')\n+      untrainable = keras.layers.Conv2D(3, 1)\n+      untrainable.trainable = False\n+      x = untrainable(x)\n+      x = keras.layers.BatchNormalization()(x)\n+      return keras.Model(inputs, x)\n+\n+    x = inner_inputs = keras.Input(shape, name='input1')\n+    x = make_model()(x)\n+    inner_model = keras.Model(inner_inputs, x)\n+\n+    inputs = keras.Input(shape, name='input3')\n+    model = keras.Model(inputs, inner_model(inputs))\n+    \n+    file_name = 'model_6.txt'\n+    temp_dir = self.get_temp_dir()\n+    self.addCleanup(shutil.rmtree, temp_dir, ignore_errors=True)\n+    fpath = os.path.join(temp_dir, file_name)\n+    writer = open(fpath, 'w')\n+\n+    def print_to_file(text):\n+      print(text, file=writer)\n+\n+    try:\n+      layer_utils.print_summary(\n+          model, print_fn=print_to_file, expand_nested=True, show_trainable=True)\n+      self.assertTrue(tf.io.gfile.exists(fpath))\n+      writer.close()\n+      reader = open(fpath, 'r')\n+      lines = reader.readlines()\n+      reader.close()\n+      check_str = (\n+        'Model: \"model_2\"\\n'\n+        '_____________________________________________________________________________________\\n'\n+        ' Layer (type)               Output Shape                   Param #         Trainable \\n'\n+        '=====================================================================================\\n'\n+        ' input3 (InputLayer)        [(None, None, None, 3)]        0               T         \\n'\n+        '                                                                                     \\n'\n+        ' model_1 (Functional)       (None, None, None, 3)          24              T         \\n'\n+        '|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n'\n+        '| input1 (InputLayer)      [(None, None, None, 3)]        0               T         |\\n'\n+        '|                                                                                   |\\n'\n+        '| model (Functional)       (None, None, None, 3)          24              T         |\\n'\n+        '||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\\n'\n+        '|| input2 (InputLayer)    [(None, None, None, 3)]        0               T         ||\\n'\n+        '||                                                                                 ||\\n'\n+        '|| conv2d (Conv2D)        (None, None, None, 3)          12              F         ||\\n'\n+        '||                                                                                 ||\\n'\n+        '|| batch_normalization (Batch  (None, None, None, 3)     12              T         ||\\n'\n+        '|| Normalization)                                                                  ||\\n'\n+        '|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n'\n+        '¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\\n'\n+        '=====================================================================================\\n'\n+        'Total params: 24\\n'\n+        'Trainable params: 6\\n'\n+        'Non-trainable params: 18\\n'\n+        '_____________________________________________________________________________________\\n'\n+      )\n+\n+      fin_str = ''\n+      for line in lines:\n+        fin_str += line\n+\n+      self.assertIn(fin_str, check_str)\n+      self.assertEqual(len(lines), 25)\n+    except ImportError:\n+      pass\n+\n   def test_property_cache(self):\n     test_counter = collections.Counter()\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#899b5fd3690fdb19afaee15f087cb50ad955134f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 154 | Lines Deleted: 30 | Files Changed: 3 | Hunks: 22 | Methods Changed: 14 | Complexity Δ (Sum/Max): 11/6 | Churn Δ: 184 | Churn Cumulative: 1842 | Contributors (this commit): 5 | Commits (past 90d): 9 | Contributors (cumulative): 9 | DMM Complexity: 0.7297297297297297\n\nDIFF:\n@@ -17,14 +17,21 @@\n # pylint: disable=g-classes-have-attributes\n # pylint: disable=g-direct-tensorflow-import\n \n+from keras import backend\n from keras.engine import base_preprocessing_layer\n from keras.layers.preprocessing import preprocessing_utils as utils\n+from keras.utils import layer_utils\n from keras.utils import tf_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n from tensorflow.python.platform import tf_logging as logging\n from tensorflow.python.util.tf_export import keras_export\n \n+INT = utils.INT\n+MULTI_HOT = utils.MULTI_HOT\n+ONE_HOT = utils.ONE_HOT\n+COUNT = utils.COUNT\n+\n \n def summarize(values, epsilon):\n   \"\"\"Reduce a 1D sequence of values to a summary.\n@@ -149,6 +156,25 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n       0.01). Higher values of epsilon increase the quantile approximation, and\n       hence result in more unequal buckets, but could improve performance\n       and resource consumption.\n+    output_mode: Specification for the output of the layer. Defaults to `\"int\"`.\n+      Values can be `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, or `\"count\"`\n+      configuring the layer as follows:\n+        - `\"int\"`: Return the discritized bin indices directly.\n+        - `\"one_hot\"`: Encodes each individual element in the input into an\n+          array the same size as `num_bins`, containing a 1 at the input's bin\n+          index. If the last dimension is size 1, will encode on that dimension.\n+          If the last dimension is not size 1, will append a new dimension for\n+          the encoded output.\n+        - `\"multi_hot\"`: Encodes each sample in the input into a single array\n+          the same size as `num_bins`, containing a 1 for each bin index\n+          index present in the sample. Treats the last dimension as the sample\n+          dimension, if input shape is `(..., sample_length)`, output shape will\n+          be `(..., num_tokens)`.\n+        - `\"count\"`: As `\"multi_hot\"`, but the int array contains a count of the\n+          number of times the bin index appeared in the sample.\n+    sparse: Boolean. Only applicable to `\"one_hot\"`, `\"multi_hot\"`,\n+      and `\"count\"` output modes. If True, returns a `SparseTensor` instead of\n+      a dense `Tensor`. Defaults to False.\n \n   Examples:\n \n@@ -174,6 +200,8 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n                bin_boundaries=None,\n                num_bins=None,\n                epsilon=0.01,\n+               output_mode=\"int\",\n+               sparse=False,\n                **kwargs):\n     # bins is a deprecated arg for setting bin_boundaries or num_bins that still\n     # has some usage.\n@@ -185,9 +213,34 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n       elif bin_boundaries is None:\n         bin_boundaries = kwargs[\"bins\"]\n       del kwargs[\"bins\"]\n+\n+    # By default, output int64 when output_mode='int' and floats otherwise.\n+    if \"dtype\" not in kwargs:\n+      kwargs[\"dtype\"] = tf.int64 if output_mode == INT else backend.floatx()\n+\n     super().__init__(**kwargs)\n     base_preprocessing_layer.keras_kpl_gauge.get_cell(\"Discretization\").set(\n         True)\n+\n+    # Check dtype only after base layer parses it; dtype parsing is complex.\n+    if output_mode == INT and not tf.as_dtype(self.compute_dtype).is_integer:\n+      input_dtype = kwargs[\"dtype\"]\n+      raise ValueError(\"When `output_mode='int'`, `dtype` should be an integer \"\n+                       f\"type. Received: dtype={input_dtype}\")\n+\n+    # 'output_mode' must be one of (INT, ONE_HOT, MULTI_HOT, COUNT)\n+    layer_utils.validate_string_arg(\n+        output_mode,\n+        allowable_strings=(INT, ONE_HOT, MULTI_HOT, COUNT),\n+        layer_name=self.__class__.__name__,\n+        arg_name=\"output_mode\")\n+\n+    if sparse and output_mode == INT:\n+      raise ValueError(f\"`sparse` may only be true if `output_mode` is \"\n+                       f\"`'one_hot'`, `'multi_hot'`, or `'count'`. \"\n+                       f\"Received: sparse={sparse} and \"\n+                       f\"output_mode={output_mode}\")\n+\n     if num_bins is not None and num_bins < 0:\n       raise ValueError(\"`num_bins` must be greater than or equal to 0. \"\n                        \"You passed `num_bins={}`\".format(num_bins))\n@@ -200,6 +253,8 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n     self.bin_boundaries = bin_boundaries if bin_boundaries is not None else []\n     self.num_bins = num_bins\n     self.epsilon = epsilon\n+    self.output_mode = output_mode\n+    self.sparse = sparse\n \n   def build(self, input_shape):\n     super().build(input_shape)\n@@ -252,6 +307,8 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n         \"bin_boundaries\": self.input_bin_boundaries,\n         \"num_bins\": self.num_bins,\n         \"epsilon\": self.epsilon,\n+        \"output_mode\": self.output_mode,\n+        \"sparse\": self.sparse,\n     })\n     return config\n \n@@ -260,30 +317,28 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n \n   def compute_output_signature(self, input_spec):\n     output_shape = self.compute_output_shape(input_spec.shape.as_list())\n-    output_dtype = tf.int64\n     if isinstance(input_spec, tf.SparseTensorSpec):\n       return tf.SparseTensorSpec(\n-          shape=output_shape, dtype=output_dtype)\n-    return tf.TensorSpec(shape=output_shape, dtype=output_dtype)\n+          shape=output_shape, dtype=self.compute_dtype)\n+    return tf.TensorSpec(shape=output_shape, dtype=self.compute_dtype)\n \n   def call(self, inputs):\n     def bucketize(inputs):\n-      outputs = tf.raw_ops.Bucketize(\n-          input=inputs, boundaries=self.bin_boundaries)\n-      # All other preprocessing layers use int64 for int output, so we conform\n-      # here. Sadly the underlying op only supports int32, so we need to cast.\n-      return tf.cast(outputs, tf.int64)\n+      return tf.raw_ops.Bucketize(input=inputs, boundaries=self.bin_boundaries)\n \n     if tf_utils.is_ragged(inputs):\n-      integer_buckets = tf.ragged.map_flat_values(bucketize, inputs)\n-      # Ragged map_flat_values doesn't touch the non-values tensors in the\n-      # ragged composite tensor. If this op is the only op a Keras model,\n-      # this can cause errors in Graph mode, so wrap the tensor in an identity.\n-      return tf.identity(integer_buckets)\n+      indices = tf.ragged.map_flat_values(bucketize, inputs)\n     elif tf_utils.is_sparse(inputs):\n-      return tf.SparseTensor(\n+      indices = tf.SparseTensor(\n           indices=tf.identity(inputs.indices),\n           values=bucketize(inputs.values),\n           dense_shape=tf.identity(inputs.dense_shape))\n     else:\n-      return bucketize(inputs)\n+      indices = bucketize(inputs)\n+\n+    return utils.encode_categorical_inputs(\n+        indices,\n+        output_mode=self.output_mode,\n+        depth=len(self.bin_boundaries) + 1,\n+        sparse=self.sparse,\n+        dtype=self.compute_dtype)\n\n@@ -14,19 +14,16 @@\n # ==============================================================================\n \"\"\"Tests for Keras discretization preprocessing layer.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n-\n import os\n \n from absl.testing import parameterized\n-\n-import numpy as np\n-\n import keras\n from keras import keras_parameterized\n from keras import testing_utils\n from keras.layers.preprocessing import discretization\n from keras.layers.preprocessing import preprocessing_test_utils\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n \n \n @keras_parameterized.run_all_keras_modes\n@@ -122,17 +119,89 @@ class DiscretizationTest(keras_parameterized.TestCase,\n     self.assertAllEqual(indices, output_dataset.indices)\n     self.assertAllEqual(expected_output, output_dataset.values)\n \n-  def test_output_shape(self):\n-    input_data = keras.Input(batch_size=16, shape=(4,), dtype=tf.int64)\n-    layer = discretization.Discretization(bin_boundaries=[-.5, 0.5, 1.5])\n-    output = layer(input_data)\n-    self.assertAllEqual(output.shape.as_list(), [16, 4])\n+  def test_one_hot_output(self):\n+    input_data = np.array([-1.5, 1.0, 3.4, 3.5])\n \n-  def test_output_dtype(self):\n-    input_data = keras.Input(batch_size=16, shape=(4,), dtype=tf.int64)\n+    expected_output = [[1., 0., 0., 0.],\n+                       [0., 0., 1., 0.],\n+                       [0., 0., 0., 1.],\n+                       [0., 0., 0., 1.]]\n+    expected_output_shape = [None, 4]\n+\n+    inputs = keras.Input(shape=(1,))\n+    layer = discretization.Discretization(bin_boundaries=[0., 1., 2.],\n+                                          output_mode=\"one_hot\")\n+    outputs = layer(inputs)\n+    self.assertAllEqual(expected_output_shape, outputs.shape.as_list())\n+\n+    model = keras.Model(inputs, outputs)\n+    output_data = model(input_data)\n+    self.assertAllEqual(expected_output, output_data)\n+\n+  def test_multi_hot_output(self):\n+    input_data = np.array([-1.5, 1.0, 3.4, 3.5])\n+\n+    expected_output = [1., 0., 1., 1.]\n+    expected_output_shape = [None, 4]\n+\n+    inputs = keras.Input(shape=(4,))\n+    layer = discretization.Discretization(bin_boundaries=[0., 1., 2.],\n+                                          output_mode=\"multi_hot\")\n+    outputs = layer(inputs)\n+    self.assertAllEqual(expected_output_shape, outputs.shape.as_list())\n+\n+    model = keras.Model(inputs, outputs)\n+    output_data = model(input_data)\n+    self.assertAllEqual(expected_output, output_data)\n+\n+  def test_count_output(self):\n+    input_data = np.array([-1.5, 1.0, 3.4, 3.5])\n+\n+    expected_output = [1., 0., 1., 2.]\n+    expected_output_shape = [None, 4]\n+\n+    inputs = keras.Input(shape=(4,))\n+    layer = discretization.Discretization(bin_boundaries=[0., 1., 2.],\n+                                          output_mode=\"count\")\n+    outputs = layer(inputs)\n+    self.assertAllEqual(expected_output_shape, outputs.shape.as_list())\n+\n+    model = keras.Model(inputs, outputs)\n+    output_data = model(input_data)\n+    self.assertAllEqual(expected_output, output_data)\n+\n+  def test_output_shape(self):\n+    inputs = keras.Input(batch_size=16, shape=(4,), dtype=tf.int64)\n     layer = discretization.Discretization(bin_boundaries=[-.5, 0.5, 1.5])\n-    output = layer(input_data)\n-    self.assertAllEqual(output.dtype, tf.int64)\n+    outputs = layer(inputs)\n+    self.assertAllEqual(outputs.shape.as_list(), [16, 4])\n+\n+  @parameterized.named_parameters(\n+      (\"int32\", tf.int32),\n+      (\"int64\", tf.int64),\n+  )\n+  def test_output_dtype(self, dtype):\n+    inputs = keras.Input(batch_size=16, shape=(4,), dtype=\"float32\")\n+    layer = discretization.Discretization(bin_boundaries=[-.5, 0.5, 1.5],\n+                                          dtype=dtype)\n+    outputs = layer(inputs)\n+    self.assertAllEqual(outputs.dtype, dtype)\n+\n+  def test_int_output_float_dtype_fails(self):\n+    with self.assertRaisesRegex(ValueError, \"`dtype` should be an integer\"):\n+      discretization.Discretization(bin_boundaries=[-.5], dtype=\"float32\")\n+\n+  @parameterized.named_parameters(\n+      (\"float32\", tf.float32),\n+      (\"float64\", tf.float64),\n+  )\n+  def test_one_hot_output_dtype(self, dtype):\n+    inputs = keras.Input(batch_size=16, shape=(1,), dtype=\"float32\")\n+    layer = discretization.Discretization(bin_boundaries=[-.5, 0.5, 1.5],\n+                                          output_mode=\"one_hot\",\n+                                          dtype=dtype)\n+    outputs = layer(inputs)\n+    self.assertAllEqual(outputs.dtype, dtype)\n \n   def test_num_bins_negative_fails(self):\n     with self.assertRaisesRegex(ValueError, \"`num_bins` must be.*num_bins=-7\"):\n\n@@ -88,7 +88,7 @@ def encode_categorical_inputs(inputs,\n                               idf_weights=None):\n   \"\"\"Encodes categoical inputs according to output_mode.\"\"\"\n   if output_mode == INT:\n-    return tf.cast(inputs, dtype)\n+    return tf.identity(tf.cast(inputs, dtype))\n \n   original_shape = inputs.shape\n   # In all cases, we should uprank scalar input to a single sample.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b184605ae9a32b088c6b54c631a2b93407eeb2f0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 389 | Contributors (this commit): 7 | Commits (past 90d): 3 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -30,6 +30,6 @@ from keras.engine.training import Model\n \n from tensorflow.python.util.tf_export import keras_export\n \n-__version__ = '2.7.0'\n+__version__ = '2.8.0'\n \n keras_export('keras.__version__').export_constant(__name__, '__version__')\n\n@@ -30,7 +30,7 @@ DOCLINES = __doc__.split('\\n')\n # This version string is semver compatible, but incompatible with pip.\n # For pip, we will remove all '-' characters from this string, and use the\n # result for pip.\n-_VERSION = '2.7.0'\n+_VERSION = '2.8.0'\n \n REQUIRED_PACKAGES = [\n     # We depend on TensorFlow's declared pip dependencies.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#efc3681f405884ec4f25744f6db5ae95efacab4d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 79 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 4 | Methods Changed: 6 | Complexity Δ (Sum/Max): 9/5 | Churn Δ: 82 | Churn Cumulative: 883 | Contributors (this commit): 5 | Commits (past 90d): 13 | Contributors (cumulative): 7 | DMM Complexity: 0.6607142857142857\n\nDIFF:\n@@ -618,6 +618,58 @@ class CoreLayersTest(keras_parameterized.TestCase):\n     self.assertEqual(layer.kernel.constraint, k_constraint)\n     self.assertEqual(layer.bias.constraint, b_constraint)\n \n+  def test_dense_layer_ragged_tensor(self):\n+    layer = keras.layers.Dense(2, kernel_initializer='ones', use_bias=False)\n+\n+    # a.shape = [2, None, 2]; a.ragged_rank=1\n+    a = tf.ragged.constant([[[1., 2], [3, 4], [5, 6]], [[7, 8]]],\n+                           ragged_rank=1)\n+    a_out = layer(a)\n+    keras.backend.get_value(layer.kernel)  # ensures var is built in TF 1.x.\n+    self.assertAllEqual(a_out, [[[3., 3], [7, 7], [11, 11]], [[15, 15]]])\n+\n+    # b.shape = [4, 2]; b.ragged_rank=1\n+    b = tf.RaggedTensor.from_uniform_row_length([1., 2, 3, 4, 5, 6, 7, 8], 2)\n+    self.assertAllEqual(layer(b), [[3., 3], [7, 7], [11, 11], [15, 15]])\n+\n+    # c.shape = [2, 2, 2]; c.ragged_rank=2\n+    c = tf.RaggedTensor.from_uniform_row_length(b, 2)\n+    self.assertAllEqual(layer(c), [[[3., 3], [7, 7]], [[11, 11], [15, 15]]])\n+\n+  def test_dense_layer_ragged_tensor_savedmodel(self):\n+    # Check that we don't get a deadlock when saving a Keras model with\n+    # a dense layer that processes RaggedTensors.  (This happened because\n+    # Dense.call() had a recursive call, which is not currently supported\n+    # by the @tf.function decorator.)\n+\n+    class TestModel(keras.Model):\n+\n+      def __init__(self):\n+        super().__init__()\n+        self._layer = keras.layers.Dense(1, kernel_initializer='ones',\n+                                         use_bias=False)\n+\n+      def call(self, inputs):\n+        return self._layer(inputs)\n+\n+    model = TestModel()\n+    result = model(tf.RaggedTensor.from_row_lengths([[1.], [2], [3]], [1, 2]))\n+    keras.backend.get_value(model._layer.kernel)  # required in TF 1.x.\n+    self.assertAllClose(result, [[[1.0]], [[2.0], [3.0]]])\n+    model.save(os.path.join(self.get_temp_dir(), 'savedmodel'),\n+               save_format='tf')\n+\n+  def test_dense_layer_unsupported_ragged_tensor_error(self):\n+    layer = keras.layers.Dense(2)\n+    with self.assertRaisesRegex(\n+        ValueError, 'The last dimension of the inputs to a Dense layer should '\n+        r'be defined. Found None. Full input shape received: .*'):\n+      layer(tf.ragged.constant([[1., 2], [3, 4, 5]]))\n+    with self.assertRaisesRegex(\n+        ValueError, 'Dense layer only supports RaggedTensors when the '\n+        r'innermost dimension is non-ragged. Received: inputs.shape=.*'):\n+      layer.call(tf.ragged.constant([[1., 2], [3, 4, 5]]))\n+\n   def test_activity_regularization(self):\n     layer = keras.layers.ActivityRegularization(l1=0.1)\n     layer(keras.backend.variable(np.ones((2, 4))))\n\n@@ -165,10 +165,30 @@ class Dense(Layer):\n     if inputs.dtype.base_dtype != self._compute_dtype_object.base_dtype:\n       inputs = tf.cast(inputs, dtype=self._compute_dtype_object)\n \n-    if isinstance(inputs, tf.RaggedTensor) and inputs.shape[-1] is not None:\n+    is_ragged = isinstance(inputs, tf.RaggedTensor)\n+    if is_ragged:\n       # In case we encounter a RaggedTensor with a fixed last dimension (last\n-      # dimension not ragged), we can map the call method to the flat values.\n-      return tf.ragged.map_flat_values(self.call, inputs)\n+      # dimension not ragged), we can flatten the input and restore the ragged\n+      # dimensions at the end.\n+      if tf.compat.dimension_value(inputs.shape[-1]) is None:\n+        raise ValueError('Dense layer only supports RaggedTensors when the '\n+                         'innermost dimension is non-ragged. Received: '\n+                         f'inputs.shape={inputs.shape}.')\n+      original_inputs = inputs\n+      if inputs.flat_values.shape.rank > 1:\n+        inputs = inputs.flat_values\n+      else:\n+        # Innermost partition is encoded using uniform_row_length.\n+        # (This is unusual, but we can handle it.)\n+        if inputs.shape.rank == 2:\n+          inputs = inputs.to_tensor()\n+          is_ragged = False\n+        else:\n+          for _ in range(original_inputs.ragged_rank - 1):\n+            inputs = inputs.values\n+          inputs = inputs.to_tensor()\n+          original_inputs = tf.RaggedTensor.from_nested_row_splits(\n+              inputs, original_inputs.nested_row_splits[:-1])\n \n     rank = inputs.shape.rank\n     if rank == 2 or rank is None:\n@@ -211,6 +231,10 @@ class Dense(Layer):\n \n     if self.activation is not None:\n       outputs = self.activation(outputs)\n+\n+    if is_ragged:\n+      outputs = original_inputs.with_flat_values(outputs)\n+\n     return outputs\n \n   def compute_output_shape(self, input_shape):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#06e99956392c47040b3aaedb7f0ce1ed48183c46", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 159 | Lines Deleted: 25 | Files Changed: 2 | Hunks: 21 | Methods Changed: 13 | Complexity Δ (Sum/Max): 11/6 | Churn Δ: 184 | Churn Cumulative: 1292 | Contributors (this commit): 6 | Commits (past 90d): 4 | Contributors (cumulative): 10 | DMM Complexity: 0.47435897435897434\n\nDIFF:\n@@ -14,15 +14,23 @@\n # ==============================================================================\n \"\"\"Keras hashing preprocessing layer.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n # pylint: disable=g-classes-have-attributes\n+# pylint: disable=g-direct-tensorflow-import\n \n-import functools\n-import numpy as np\n+from keras import backend\n from keras.engine import base_layer\n from keras.engine import base_preprocessing_layer\n+from keras.layers.preprocessing import preprocessing_utils as utils\n+from keras.utils import layer_utils\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n from tensorflow.python.util.tf_export import keras_export\n \n+INT = utils.INT\n+MULTI_HOT = utils.MULTI_HOT\n+ONE_HOT = utils.ONE_HOT\n+COUNT = utils.COUNT\n+\n \n @keras_export('keras.layers.Hashing',\n               'keras.layers.experimental.preprocessing.Hashing')\n@@ -108,6 +116,25 @@ class Hashing(base_layer.Layer):\n       These should be non-zero. Defaults to `None` (in that\n       case, the FarmHash64 hash function is used). It also supports\n       tuple/list of 2 unsigned integer numbers, see reference paper for details.\n+    output_mode: Specification for the output of the layer. Defaults to `\"int\"`.\n+      Values can be `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, or `\"count\"`\n+      configuring the layer as follows:\n+        - `\"int\"`: Return the integer bin indices directly.\n+        - `\"one_hot\"`: Encodes each individual element in the input into an\n+          array the same size as `num_bins`, containing a 1 at the input's bin\n+          index. If the last dimension is size 1, will encode on that dimension.\n+          If the last dimension is not size 1, will append a new dimension for\n+          the encoded output.\n+        - `\"multi_hot\"`: Encodes each sample in the input into a single array\n+          the same size as `num_bins`, containing a 1 for each bin index\n+          index present in the sample. Treats the last dimension as the sample\n+          dimension, if input shape is `(..., sample_length)`, output shape will\n+          be `(..., num_tokens)`.\n+        - `\"count\"`: As `\"multi_hot\"`, but the int array contains a count of the\n+          number of times the bin index appeared in the sample.\n+    sparse: Boolean. Only applicable to `\"one_hot\"`, `\"multi_hot\"`,\n+      and `\"count\"` output modes. If True, returns a `SparseTensor` instead of\n+      a dense `Tensor`. Defaults to False.\n     **kwargs: Keyword arguments to construct a layer.\n \n   Input shape:\n@@ -125,16 +152,49 @@ class Hashing(base_layer.Layer):\n \n   \"\"\"\n \n-  def __init__(self, num_bins, mask_value=None, salt=None, **kwargs):\n+  def __init__(self,\n+               num_bins,\n+               mask_value=None,\n+               salt=None,\n+               output_mode='int',\n+               sparse=False,\n+               **kwargs):\n     if num_bins is None or num_bins <= 0:\n       raise ValueError(\n           f'The `num_bins` for `Hashing` cannot be `None` or non-positive '\n           f'values. Received: num_bins={num_bins}.')\n+\n+    # By default, output int64 when output_mode='int' and floats otherwise.\n+    if 'dtype' not in kwargs:\n+      kwargs['dtype'] = tf.int64 if output_mode == INT else backend.floatx()\n+\n     super().__init__(**kwargs)\n     base_preprocessing_layer.keras_kpl_gauge.get_cell('Hashing').set(True)\n+\n+    # Check dtype only after base layer parses it; dtype parsing is complex.\n+    if output_mode == INT and not tf.as_dtype(self.compute_dtype).is_integer:\n+      input_dtype = kwargs['dtype']\n+      raise ValueError('When `output_mode=\"int\"`, `dtype` should be an integer '\n+                       f'type. Received: dtype={input_dtype}')\n+\n+    # 'output_mode' must be one of (INT, ONE_HOT, MULTI_HOT, COUNT)\n+    layer_utils.validate_string_arg(\n+        output_mode,\n+        allowable_strings=(INT, ONE_HOT, MULTI_HOT, COUNT),\n+        layer_name=self.__class__.__name__,\n+        arg_name='output_mode')\n+\n+    if sparse and output_mode == INT:\n+      raise ValueError(f'`sparse` may only be true if `output_mode` is '\n+                       f'`\"one_hot\"`, `\"multi_hot\"`, or `\"count\"`. '\n+                       f'Received: sparse={sparse} and '\n+                       f'output_mode={output_mode}')\n+\n     self.num_bins = num_bins\n     self.mask_value = mask_value\n     self.strong_hash = True if salt is not None else False\n+    self.output_mode = output_mode\n+    self.sparse = sparse\n     self.salt = None\n     if salt is not None:\n       if isinstance(salt, (tuple, list)) and len(salt) == 2:\n@@ -150,51 +210,50 @@ class Hashing(base_layer.Layer):\n     if isinstance(inputs, (list, tuple, np.ndarray)):\n       inputs = tf.convert_to_tensor(inputs)\n     if isinstance(inputs, tf.SparseTensor):\n-      return tf.SparseTensor(\n+      indices = tf.SparseTensor(\n           indices=inputs.indices,\n           values=self._hash_values_to_bins(inputs.values),\n           dense_shape=inputs.dense_shape)\n-    return self._hash_values_to_bins(inputs)\n+    else:\n+      indices = self._hash_values_to_bins(inputs)\n+    return utils.encode_categorical_inputs(\n+        indices,\n+        output_mode=self.output_mode,\n+        depth=self.num_bins,\n+        sparse=self.sparse,\n+        dtype=self.compute_dtype)\n \n   def _hash_values_to_bins(self, values):\n     \"\"\"Converts a non-sparse tensor of values to bin indices.\"\"\"\n-    str_to_hash_bucket = self._get_string_to_hash_bucket_fn()\n-    num_available_bins = self.num_bins\n+    hash_bins = self.num_bins\n     mask = None\n     # If mask_value is set, the zeroth bin is reserved for it.\n-    if self.mask_value is not None and num_available_bins > 1:\n-      num_available_bins -= 1\n+    if self.mask_value is not None and hash_bins > 1:\n+      hash_bins -= 1\n       mask = tf.equal(values, self.mask_value)\n     # Convert all values to strings before hashing.\n     if values.dtype.is_integer:\n       values = tf.as_string(values)\n-    values = str_to_hash_bucket(values, num_available_bins, name='hash')\n+    # Hash the strings.\n+    if self.strong_hash:\n+      values = tf.strings.to_hash_bucket_strong(\n+          values, hash_bins, name='hash', key=self.salt)\n+    else:\n+      values = tf.strings.to_hash_bucket_fast(values, hash_bins, name='hash')\n     if mask is not None:\n       values = tf.add(values, tf.ones_like(values))\n       values = tf.where(mask, tf.zeros_like(values), values)\n     return values\n \n-  def _get_string_to_hash_bucket_fn(self):\n-    \"\"\"Returns the string_to_hash_bucket op to use based on `hasher_key`.\"\"\"\n-    # string_to_hash_bucket_fast uses FarmHash64 as hash function.\n-    if not self.strong_hash:\n-      return tf.strings.to_hash_bucket_fast\n-    # string_to_hash_bucket_strong uses SipHash64 as hash function.\n-    else:\n-      return functools.partial(\n-          tf.strings.to_hash_bucket_strong, key=self.salt)\n-\n   def compute_output_shape(self, input_shape):\n     return input_shape\n \n   def compute_output_signature(self, input_spec):\n     output_shape = self.compute_output_shape(input_spec.shape)\n-    output_dtype = tf.int64\n     if isinstance(input_spec, tf.SparseTensorSpec):\n-      return tf.SparseTensorSpec(\n-          shape=output_shape, dtype=output_dtype)\n+      return tf.SparseTensorSpec(shape=output_shape, dtype=self.compute_dtype)\n     else:\n-      return tf.TensorSpec(shape=output_shape, dtype=output_dtype)\n+      return tf.TensorSpec(shape=output_shape, dtype=self.compute_dtype)\n \n   def get_config(self):\n     config = super().get_config()\n@@ -202,5 +261,7 @@ class Hashing(base_layer.Layer):\n         'num_bins': self.num_bins,\n         'salt': self.salt,\n         'mask_value': self.mask_value,\n+        'output_mode': self.output_mode,\n+        'sparse': self.sparse,\n     })\n     return config\n\n@@ -254,6 +254,79 @@ class HashingTest(keras_parameterized.TestCase):\n     with self.assertRaisesRegex(ValueError, 'can only be a tuple of size 2'):\n       _ = hashing.Hashing(num_bins=1, salt=tf.constant([133, 137]))\n \n+  def test_one_hot_output(self):\n+    input_array = np.array([0, 1, 2, 3, 4])\n+\n+    expected_output = [[0., 1., 0.],\n+                       [1., 0., 0.],\n+                       [0., 1., 0.],\n+                       [1., 0., 0.],\n+                       [0., 0., 1.]]\n+    expected_output_shape = [None, 3]\n+\n+    inputs = keras.Input(shape=(1,), dtype='int32')\n+    layer = hashing.Hashing(num_bins=3, output_mode='one_hot')\n+    outputs = layer(inputs)\n+    self.assertAllEqual(expected_output_shape, outputs.shape.as_list())\n+\n+    model = keras.Model(inputs, outputs)\n+    output_data = model(input_array)\n+    self.assertAllEqual(expected_output, output_data)\n+\n+  def test_multi_hot_output(self):\n+    input_array = np.array([0, 1, 2, 3, 4])\n+\n+    expected_output = [1., 1., 1.]\n+    expected_output_shape = [None, 3]\n+\n+    inputs = keras.Input(shape=(3,), dtype='int32')\n+    layer = hashing.Hashing(num_bins=3, output_mode='multi_hot')\n+    outputs = layer(inputs)\n+    self.assertAllEqual(expected_output_shape, outputs.shape.as_list())\n+\n+    model = keras.Model(inputs, outputs)\n+    output_data = model(input_array)\n+    self.assertAllEqual(expected_output, output_data)\n+\n+  def test_count_output(self):\n+    input_array = np.array([0, 1, 2, 3, 4])\n+\n+    expected_output = [2., 2., 1.]\n+    expected_output_shape = [None, 3]\n+\n+    inputs = keras.Input(shape=(3,), dtype='int32')\n+    layer = hashing.Hashing(num_bins=3, output_mode='count')\n+    outputs = layer(inputs)\n+    self.assertAllEqual(expected_output_shape, outputs.shape.as_list())\n+\n+    model = keras.Model(inputs, outputs)\n+    output_data = model(input_array)\n+    self.assertAllEqual(expected_output, output_data)\n+\n+  @parameterized.named_parameters(\n+      ('int32', tf.int32),\n+      ('int64', tf.int64),\n+  )\n+  def test_output_dtype(self, dtype):\n+    input_data = keras.Input(batch_size=16, shape=(4,), dtype='string')\n+    layer = hashing.Hashing(num_bins=3, dtype=dtype)\n+    output = layer(input_data)\n+    self.assertAllEqual(output.dtype, dtype)\n+\n+  def test_int_output_float_dtype_fails(self):\n+    with self.assertRaisesRegex(ValueError, '`dtype` should be an integer'):\n+      hashing.Hashing(num_bins=3, dtype='string')\n+\n+  @parameterized.named_parameters(\n+      ('float32', tf.float32),\n+      ('float64', tf.float64),\n+  )\n+  def test_one_hot_output_dtype(self, dtype):\n+    input_data = keras.Input(batch_size=16, shape=(1,), dtype='string')\n+    layer = hashing.Hashing(num_bins=3, output_mode='one_hot', dtype=dtype)\n+    output = layer(input_data)\n+    self.assertAllEqual(output.dtype, dtype)\n+\n   def test_hash_compute_output_signature(self):\n     input_shape = tf.TensorShape([2, 3])\n     input_spec = tf.TensorSpec(input_shape, tf.string)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0fb2f1bc3a5fa8202e3345fb6e2d9cc0336cf7d2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 291 | Files Changed: 1 | Hunks: 1 | Methods Changed: 3 | Complexity Δ (Sum/Max): -43/0 | Churn Δ: 291 | Churn Cumulative: 582 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,291 +0,0 @@\n-# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-# ==============================================================================\n-r\"\"\"Utils for EfficientNet V2 models for Keras.\n-\n-Write weights from  ckpt file as in original repo\n-(https://github.com/google/automl/tree/master/efficientnetv2)\n-to h5 file for keras implementation of the models.\n-\n-Usage:\n-\n-# use checkpoint efficientnet-b0/ (can be downloaded from\n-# https://storage.googleapis.com/cloud-tpu-checkpoints/\n-# efficientnet/v2/efficientnetv2-s.tgz\n-\n-# to update weight without top layers, saving to efficientnetv2_b0_notop.h5\n-python efficientnet_v2_weight_update_util.py --model b0 --notop \\\n-    --ckpt efficientnet-b0/ --o efficientnet_v2_b0_notop.h5\n-\n-# use ImageNet21K pretrained and finetuned models for s/m/l variants:\n-# (can be downloaded from\n-# https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/\n-# v2/efficientnetv2-s-21k-ft1k.tgz)\n-# to update weight with top layers, saving to efficientnet_v2_s_new.h5\n-python efficientnet_v2_weight_update_util.py --model s \\\n-    --ckpt efficientnetv2-s-21k-ft1k/ --o efficientnet_v2_s_new.h5\n-\"\"\"\n-import tensorflow.compat.v2 as tf\n-\n-import argparse\n-import warnings\n-\n-from keras.applications import efficientnet_v2\n-from efficientnet_weight_update_util import (\n-    keras_name_to_tf_name_stem_top,\n-    get_keras_blocks,\n-    get_tf_blocks,\n-    get_variable_names_from_ckpt,\n-)\n-\n-\n-def write_ckpt_to_h5(path_h5, path_ckpt, keras_model, use_ema=True):\n-  \"\"\"Map the weights in checkpoint file (tf) to h5 file (keras).\n-\n-  Args:\n-    path_h5: str, path to output hdf5 file to write weights loaded from ckpt\n-      files.\n-    path_ckpt: str, path to the ckpt files (e.g. 'efficientnetv2-b0/model')\n-      that records efficientnet v2 weights from original repo\n-      https://github.com/google/automl/tree/master/efficientnetv2\n-    keras_model: keras model, built from keras.applications efficientnet_v2\n-      functions (e.g. EfficientNetV2_B0)\n-    use_ema: Bool, whether to use ExponentialMovingAverage result or not\n-  \"\"\"\n-  model_name_keras = keras_model.name\n-  model_name_tf = model_name_keras\n-\n-  keras_weight_names = [w.name for w in keras_model.weights]\n-  tf_weight_names = get_variable_names_from_ckpt(path_ckpt)\n-\n-  keras_blocks = get_keras_blocks(keras_weight_names)\n-  tf_blocks = get_tf_blocks(tf_weight_names)\n-\n-  print('check variables match in each block')\n-  for keras_block, tf_block in zip(keras_blocks, tf_blocks):\n-    check_match(keras_block, tf_block, keras_weight_names, tf_weight_names,\n-                model_name_tf)\n-    print('{} and {} match.'.format(tf_block, keras_block))\n-\n-  block_mapping = {x[0]: x[1] for x in zip(keras_blocks, tf_blocks)}\n-\n-  changed_weights = 0\n-  for w in keras_model.weights:\n-    if 'block' in w.name:\n-      # example: 'block1a_dwconv/depthwise_kernel:0' -> 'block1a'\n-      keras_block = w.name.split('/')[0].split('_')[0]\n-      tf_block = block_mapping[keras_block]\n-      tf_name = keras_name_to_tf_name_block(\n-          w.name,\n-          keras_block=keras_block,\n-          tf_block=tf_block,\n-          use_ema=use_ema,\n-          model_name_tf=model_name_tf)\n-    elif any([x in w.name for x in ['stem', 'top', 'predictions', 'probs']]):\n-      tf_name = keras_name_to_tf_name_stem_top(\n-          w.name, use_ema=use_ema, model_name_tf=model_name_tf)\n-    elif 'normalization' in w.name:\n-      print('skipping variable {}: normalization is a layer'\n-            'in keras implementation, but preprocessing in '\n-            'TF implementation.'.format(w.name))\n-      continue\n-    else:\n-      raise ValueError('{} failed to parse.'.format(w.name))\n-\n-    try:\n-      w_tf = tf.train.load_variable(path_ckpt, tf_name)\n-      if (w.value().numpy() != w_tf).any():\n-        w.assign(w_tf)\n-        changed_weights += 1\n-    except ValueError as e:\n-      if any([x in w.name for x in ['top', 'predictions', 'probs']]):\n-        warnings.warn('Fail to load top layer variable {}'\n-                      'from {} because of {}.'.format(w.name, tf_name, e))\n-      else:\n-        raise ValueError('Fail to load {} from {}'.format(w.name, tf_name))\n-\n-  total_weights = len(keras_model.weights)\n-  print('{}/{} weights updated'.format(changed_weights, total_weights))\n-  keras_model.save_weights(path_h5)\n-\n-\n-def check_match(keras_block, tf_block, keras_weight_names, tf_weight_names,\n-                model_name_tf):\n-  \"\"\"Check if the weights in h5 and ckpt match.\n-\n-  we match each name from keras_weight_names that is in keras_block\n-  and check if there is 1-1 correspondence to names from tf_weight_names\n-  that is in tf_block\n-\n-  Args:\n-    keras_block: str, the block name for keras implementation (e.g. 'block1a')\n-    tf_block: str, the block name for tf implementation (e.g. 'blocks_0')\n-    keras_weight_names: list of str, weight names in keras implementation\n-    tf_weight_names: list of str, weight names in tf implementation\n-    model_name_tf: str, the name of model in ckpt.\n-  \"\"\"\n-  names_from_keras = set()\n-  for x in keras_weight_names:\n-    if keras_block in x:\n-      y = keras_name_to_tf_name_block(\n-          x,\n-          keras_block=keras_block,\n-          tf_block=tf_block,\n-          model_name_tf=model_name_tf)\n-      names_from_keras.add(y)\n-\n-  names_from_tf = set()\n-  for x in tf_weight_names:\n-    if tf_block in x and x.split('/')[1].endswith(tf_block):\n-      names_from_tf.add(x)\n-\n-  names_missing = names_from_keras - names_from_tf\n-  if names_missing:\n-    raise ValueError('{} variables not found in checkpoint file: {}'.format(\n-        len(names_missing), names_missing))\n-\n-  names_unused = names_from_tf - names_from_keras\n-  if names_unused:\n-    warnings.warn('{} variables from checkpoint file are not used: {}'.format(\n-        len(names_unused), names_unused))\n-\n-\n-def keras_name_to_tf_name_block(keras_name,\n-                                keras_block='block1a',\n-                                tf_block='blocks_0',\n-                                use_ema=True,\n-                                model_name_tf='efficientnetv2-b0'):\n-  \"\"\"Mapping name in h5 to ckpt that belongs to a block.\n-\n-  we map name keras_name that points to a weight in h5 file\n-  to a name of weight in ckpt file.\n-\n-  Args:\n-    keras_name: str, the name of weight in the h5 file of keras implementation\n-    keras_block: str, the block name for keras implementation (e.g. 'block1a')\n-    tf_block: str, the block name for tf implementation (e.g. 'blocks_0')\n-    use_ema: Bool, use the ExponentialMovingAverage resuolt in ckpt or not\n-    model_name_tf: str, the name of model in ckpt.\n-\n-  Returns:\n-    String for the name of weight as in ckpt file.\n-\n-  Raises:\n-    ValueError if keras_block does not show up in keras_name\n-  \"\"\"\n-\n-  if keras_block not in keras_name:\n-    raise ValueError('block name {} not found in {}'.format(\n-        keras_block, keras_name))\n-\n-  # all blocks in the first group will not have expand conv and bn\n-  is_first_blocks = (keras_block[5] == '1')\n-\n-  # All blocks after 4th are fused mb conv type\n-  is_fused_mb_block = int(keras_block[5]) >= 4\n-\n-  tf_name = [model_name_tf, tf_block]\n-\n-  # depthwide conv\n-  if 'dwconv' in keras_name:\n-    tf_name.append('depthwise_conv2d')\n-    tf_name.append('depthwise_kernel')\n-\n-  # conv layers\n-  if is_first_blocks:\n-    # first blocks only have one conv2d\n-    if 'project_conv' in keras_name:\n-      tf_name.append('conv2d')\n-      tf_name.append('kernel')\n-  else:\n-    if 'project_conv' in keras_name:\n-      tf_name.append('conv2d_1')\n-      tf_name.append('kernel')\n-    elif 'expand_conv' in keras_name:\n-      tf_name.append('conv2d')\n-      tf_name.append('kernel')\n-\n-  # squeeze expansion layers\n-  if '_se_' in keras_name:\n-    if 'reduce' in keras_name:\n-      tf_name.append('se/conv2d')\n-    elif 'expand' in keras_name:\n-      tf_name.append('se/conv2d_1')\n-\n-    if 'kernel' in keras_name:\n-      tf_name.append('kernel')\n-    elif 'bias' in keras_name:\n-      tf_name.append('bias')\n-\n-  # batch normalization layers\n-  if 'bn' in keras_name:\n-    if is_first_blocks:\n-      if 'project' in keras_name:\n-        tf_name.append('tpu_batch_normalization')\n-      else:\n-        tf_name.append('tpu_batch_normalization_1')\n-    else:\n-      if is_fused_mb_block:\n-        if \"project\" in keras_name:\n-          tf_name.append(\"tpu_batch_normalization_2\")\n-        elif \"expand\" in keras_name:\n-          tf_name.append(\"tpu_batch_normalization\")\n-        else:\n-          tf_name.append(\"tpu_batch_normalization_1\")\n-    \n-      else:\n-        if 'project' in keras_name:\n-          tf_name.append('tpu_batch_normalization_1')\n-        else:\n-          tf_name.append('tpu_batch_normalization')\n-\n-    for x in ['moving_mean', 'moving_variance', 'beta', 'gamma']:\n-      if x in keras_name:\n-        tf_name.append(x)\n-  if use_ema:\n-    tf_name.append('ExponentialMovingAverage')\n-  return '/'.join(tf_name)\n-\n-if __name__ == \"__main__\":\n-  arg_to_model = {\n-    'b0': efficientnet_v2.EfficientNetV2_B0,\n-    'b1': efficientnet_v2.EfficientNetV2_B1,\n-    'b2': efficientnet_v2.EfficientNetV2_B2,\n-    'b3': efficientnet_v2.EfficientNetV2_B3,\n-    's': efficientnet_v2.EfficientNetV2_S,\n-    'm': efficientnet_v2.EfficientNetV2_M,\n-    'l': efficientnet_v2.EfficientNetV2_L,\n-  }\n-\n-  p = argparse.ArgumentParser(description='write weights from checkpoint to h5')\n-  p.add_argument(\n-      '--model',\n-      required=True,\n-      type=str,\n-      help='name of efficient model',\n-      choices=arg_to_model.keys())\n-  p.add_argument(\n-      '--notop',\n-      action='store_true',\n-      help='do not include top layers',\n-      default=False)\n-  p.add_argument('--ckpt', required=True, type=str, help='checkpoint path')\n-  p.add_argument(\n-      '--output', '-o', required=True, type=str, help='output (h5) file path')\n-  args = p.parse_args()\n-\n-  include_top = not args.notop\n-\n-  model = arg_to_model[args.model](include_top=include_top, weights=None)\n-  write_ckpt_to_h5(args.output, args.ckpt, keras_model=model)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
