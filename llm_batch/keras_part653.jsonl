{"custom_id": "keras#363e7ace2e838cb74fa6c3e0f8b93348d01a3b28", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 479 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 11 | Complexity Δ (Sum/Max): 14/14 | Churn Δ: 479 | Churn Cumulative: 479 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,479 @@\n+\"\"\"\n+Title: Image classification with Perceiver\n+Author: [Khalid Salama](https://www.linkedin.com/in/khalid-salama-24403144/)\n+Date created: 2021/04/30\n+Last modified: 2021/01/30\n+Description: Implementing the Perceiver model for image classification.\n+Accelerator: GPU\n+\"\"\"\n+\n+\"\"\"\n+## Introduction\n+\n+This example implements the\n+[Perceiver: General Perception with Iterative Attention](https://arxiv.org/abs/2103.03206)\n+model by Andrew Jaegle et al. for image classification,\n+and demonstrates it on the CIFAR-100 dataset.\n+\n+The Perceiver model leverages an asymmetric attention mechanism to iteratively\n+distill inputs into a tight latent bottleneck,\n+allowing it to scale to handle very large inputs.\n+\n+In other words: let's assume that your input data array (e.g. image) has `M` elements (i.e. patches), where `M` is large.\n+In a standard Transformer model, a self-attention operation is performed for the `M` elements.\n+The complexity of this operation is `O(M^2)`.\n+However, the Perceiver model creates a latent array of size `N` elements, where `N << M`,\n+and performs two operations iteratively:\n+\n+1. Cross-attention Transformer between the latent array and the data array - The complexity of this operation is `O(M.N)`.\n+2. Self-attention Transformer on the latent array -  The complexity of this operation is `O(N^2)`.\n+\n+This example requires TensorFlow 2.4 or higher, as well as\n+[TensorFlow Addons](https://www.tensorflow.org/addons/overview),\n+which can be installed using the following command:\n+\n+```python\n+pip install -U tensorflow-addons\n+```\n+\"\"\"\n+\n+\"\"\"\n+## Setup\n+\"\"\"\n+\n+import numpy as np\n+import tensorflow as tf\n+import keras_core as keras\n+from keras_core import layers\n+import tensorflow_addons as tfa\n+\n+\"\"\"\n+## Prepare the data\n+\"\"\"\n+\n+num_classes = 100\n+input_shape = (32, 32, 3)\n+\n+(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n+\n+print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n+print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n+\n+\"\"\"\n+## Configure the hyperparameters\n+\"\"\"\n+\n+learning_rate = 0.001\n+weight_decay = 0.0001\n+batch_size = 64\n+num_epochs = 50\n+dropout_rate = 0.2\n+image_size = 64  # We'll resize input images to this size.\n+patch_size = 2  # Size of the patches to be extract from the input images.\n+num_patches = (image_size // patch_size) ** 2  # Size of the data array.\n+latent_dim = 256  # Size of the latent array.\n+projection_dim = 256  # Embedding size of each element in the data and latent arrays.\n+num_heads = 8  # Number of Transformer heads.\n+ffn_units = [\n+    projection_dim,\n+    projection_dim,\n+]  # Size of the Transformer Feedforward network.\n+num_transformer_blocks = 4\n+num_iterations = 2  # Repetitions of the cross-attention and Transformer modules.\n+classifier_units = [\n+    projection_dim,\n+    num_classes,\n+]  # Size of the Feedforward network of the final classifier.\n+\n+print(f\"Image size: {image_size} X {image_size} = {image_size ** 2}\")\n+print(f\"Patch size: {patch_size} X {patch_size} = {patch_size ** 2} \")\n+print(f\"Patches per image: {num_patches}\")\n+print(f\"Elements per patch (3 channels): {(patch_size ** 2) * 3}\")\n+print(f\"Latent array shape: {latent_dim} X {projection_dim}\")\n+print(f\"Data array shape: {num_patches} X {projection_dim}\")\n+\n+\"\"\"\n+Note that, in order to use each pixel as an individual input in the data array,\n+set `patch_size` to 1.\n+\"\"\"\n+\n+\"\"\"\n+## Use data augmentation\n+\"\"\"\n+\n+data_augmentation = keras.Sequential(\n+    [\n+        layers.Normalization(),\n+        layers.Resizing(image_size, image_size),\n+        layers.RandomFlip(\"horizontal\"),\n+        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n+    ],\n+    name=\"data_augmentation\",\n+)\n+# Compute the mean and the variance of the training data for normalization.\n+data_augmentation.layers[0].adapt(x_train)\n+\n+\"\"\"\n+## Implement Feedforward network (FFN)\n+\"\"\"\n+\n+\n+def create_ffn(hidden_units, dropout_rate):\n+    ffn_layers = []\n+    for units in hidden_units[:-1]:\n+        ffn_layers.append(layers.Dense(units, activation=tf.nn.gelu))\n+\n+    ffn_layers.append(layers.Dense(units=hidden_units[-1]))\n+    ffn_layers.append(layers.Dropout(dropout_rate))\n+\n+    ffn = keras.Sequential(ffn_layers)\n+    return ffn\n+\n+\n+\"\"\"\n+## Implement patch creation as a layer\n+\"\"\"\n+\n+\n+class Patches(layers.Layer):\n+    def __init__(self, patch_size):\n+        super().__init__()\n+        self.patch_size = patch_size\n+\n+    def call(self, images):\n+        batch_size = tf.shape(images)[0]\n+        patches = tf.image.extract_patches(\n+            images=images,\n+            sizes=[1, self.patch_size, self.patch_size, 1],\n+            strides=[1, self.patch_size, self.patch_size, 1],\n+            rates=[1, 1, 1, 1],\n+            padding=\"VALID\",\n+        )\n+        patch_dims = patches.shape[-1]\n+        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n+        return patches\n+\n+\n+\"\"\"\n+## Implement the patch encoding layer\n+\n+The `PatchEncoder` layer will linearly transform a patch by projecting it into\n+a vector of size `latent_dim`. In addition, it adds a learnable position embedding\n+to the projected vector.\n+\n+Note that the orginal Perceiver paper uses the Fourier feature positional encodings.\n+\"\"\"\n+\n+\n+class PatchEncoder(layers.Layer):\n+    def __init__(self, num_patches, projection_dim):\n+        super().__init__()\n+        self.num_patches = num_patches\n+        self.projection = layers.Dense(units=projection_dim)\n+        self.position_embedding = layers.Embedding(\n+            input_dim=num_patches, output_dim=projection_dim\n+        )\n+\n+    def call(self, patches):\n+        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n+        encoded = self.projection(patches) + self.position_embedding(positions)\n+        return encoded\n+\n+\n+\"\"\"\n+## Build the Perceiver model\n+\n+The Perceiver consists of two modules: a cross-attention\n+module and a standard Transformer with self-attention.\n+\"\"\"\n+\n+\"\"\"\n+### Cross-attention module\n+\n+The cross-attention expects a `(latent_dim, projection_dim)` latent array,\n+and the `(data_dim,  projection_dim)` data array as inputs,\n+to produce a `(latent_dim, projection_dim)` latent array as an output.\n+To apply cross-attention, the `query` vectors are generated from the latent array,\n+while the `key` and `value` vectors are generated from the encoded image.\n+\n+Note that the data array in this example is the image,\n+where the `data_dim` is set to the `num_patches`.\n+\"\"\"\n+\n+\n+def create_cross_attention_module(\n+    latent_dim, data_dim, projection_dim, ffn_units, dropout_rate\n+):\n+    inputs = {\n+        # Recieve the latent array as an input of shape [1, latent_dim, projection_dim].\n+        \"latent_array\": layers.Input(shape=(latent_dim, projection_dim)),\n+        # Recieve the data_array (encoded image) as an input of shape [batch_size, data_dim, projection_dim].\n+        \"data_array\": layers.Input(shape=(data_dim, projection_dim)),\n+    }\n+\n+    # Apply layer norm to the inputs\n+    latent_array = layers.LayerNormalization(epsilon=1e-6)(inputs[\"latent_array\"])\n+    data_array = layers.LayerNormalization(epsilon=1e-6)(inputs[\"data_array\"])\n+\n+    # Create query tensor: [1, latent_dim, projection_dim].\n+    query = layers.Dense(units=projection_dim)(latent_array)\n+    # Create key tensor: [batch_size, data_dim, projection_dim].\n+    key = layers.Dense(units=projection_dim)(data_array)\n+    # Create value tensor: [batch_size, data_dim, projection_dim].\n+    value = layers.Dense(units=projection_dim)(data_array)\n+\n+    # Generate cross-attention outputs: [batch_size, latent_dim, projection_dim].\n+    attention_output = layers.Attention(use_scale=True, dropout=0.1)(\n+        [query, key, value], return_attention_scores=False\n+    )\n+    # Skip connection 1.\n+    attention_output = layers.Add()([attention_output, latent_array])\n+\n+    # Apply layer norm.\n+    attention_output = layers.LayerNormalization(epsilon=1e-6)(attention_output)\n+    # Apply Feedforward network.\n+    ffn = create_ffn(hidden_units=ffn_units, dropout_rate=dropout_rate)\n+    outputs = ffn(attention_output)\n+    # Skip connection 2.\n+    outputs = layers.Add()([outputs, attention_output])\n+\n+    # Create the Keras model.\n+    model = keras.Model(inputs=inputs, outputs=outputs)\n+    return model\n+\n+\n+\"\"\"\n+### Transformer module\n+\n+The Transformer expects the output latent vector from the cross-attention module\n+as an input, applies multi-head self-attention to its `latent_dim` elements,\n+followed by feedforward network, to produce another `(latent_dim, projection_dim)` latent array.\n+\"\"\"\n+\n+\n+def create_transformer_module(\n+    latent_dim,\n+    projection_dim,\n+    num_heads,\n+    num_transformer_blocks,\n+    ffn_units,\n+    dropout_rate,\n+):\n+    # input_shape: [1, latent_dim, projection_dim]\n+    inputs = layers.Input(shape=(latent_dim, projection_dim))\n+\n+    x0 = inputs\n+    # Create multiple layers of the Transformer block.\n+    for _ in range(num_transformer_blocks):\n+        # Apply layer normalization 1.\n+        x1 = layers.LayerNormalization(epsilon=1e-6)(x0)\n+        # Create a multi-head self-attention layer.\n+        attention_output = layers.MultiHeadAttention(\n+            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n+        )(x1, x1)\n+        # Skip connection 1.\n+        x2 = layers.Add()([attention_output, x0])\n+        # Apply layer normalization 2.\n+        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n+        # Apply Feedforward network.\n+        ffn = create_ffn(hidden_units=ffn_units, dropout_rate=dropout_rate)\n+        x3 = ffn(x3)\n+        # Skip connection 2.\n+        x0 = layers.Add()([x3, x2])\n+\n+    # Create the Keras model.\n+    model = keras.Model(inputs=inputs, outputs=x0)\n+    return model\n+\n+\n+\"\"\"\n+### Perceiver model\n+\n+The Perceiver model repeats the cross-attention and Transformer modules\n+`num_iterations` times—with shared weights and skip connections—to allow\n+the latent array to iteratively extract information from the input image as it is needed.\n+\"\"\"\n+\n+\n+class Perceiver(keras.Model):\n+    def __init__(\n+        self,\n+        patch_size,\n+        data_dim,\n+        latent_dim,\n+        projection_dim,\n+        num_heads,\n+        num_transformer_blocks,\n+        ffn_units,\n+        dropout_rate,\n+        num_iterations,\n+        classifier_units,\n+    ):\n+        super().__init__()\n+\n+        self.latent_dim = latent_dim\n+        self.data_dim = data_dim\n+        self.patch_size = patch_size\n+        self.projection_dim = projection_dim\n+        self.num_heads = num_heads\n+        self.num_transformer_blocks = num_transformer_blocks\n+        self.ffn_units = ffn_units\n+        self.dropout_rate = dropout_rate\n+        self.num_iterations = num_iterations\n+        self.classifier_units = classifier_units\n+\n+    def build(self, input_shape):\n+        # Create latent array.\n+        self.latent_array = self.add_weight(\n+            shape=(self.latent_dim, self.projection_dim),\n+            initializer=\"random_normal\",\n+            trainable=True,\n+        )\n+\n+        # Create patching module.\n+        self.patcher = Patches(self.patch_size)\n+\n+        # Create patch encoder.\n+        self.patch_encoder = PatchEncoder(self.data_dim, self.projection_dim)\n+\n+        # Create cross-attenion module.\n+        self.cross_attention = create_cross_attention_module(\n+            self.latent_dim,\n+            self.data_dim,\n+            self.projection_dim,\n+            self.ffn_units,\n+            self.dropout_rate,\n+        )\n+\n+        # Create Transformer module.\n+        self.transformer = create_transformer_module(\n+            self.latent_dim,\n+            self.projection_dim,\n+            self.num_heads,\n+            self.num_transformer_blocks,\n+            self.ffn_units,\n+            self.dropout_rate,\n+        )\n+\n+        # Create global average pooling layer.\n+        self.global_average_pooling = layers.GlobalAveragePooling1D()\n+\n+        # Create a classification head.\n+        self.classification_head = create_ffn(\n+            hidden_units=self.classifier_units, dropout_rate=self.dropout_rate\n+        )\n+\n+        super().build(input_shape)\n+\n+    def call(self, inputs):\n+        # Augment data.\n+        augmented = data_augmentation(inputs)\n+        # Create patches.\n+        patches = self.patcher(augmented)\n+        # Encode patches.\n+        encoded_patches = self.patch_encoder(patches)\n+        # Prepare cross-attention inputs.\n+        cross_attention_inputs = {\n+            \"latent_array\": tf.expand_dims(self.latent_array, 0),\n+            \"data_array\": encoded_patches,\n+        }\n+        # Apply the cross-attention and the Transformer modules iteratively.\n+        for _ in range(self.num_iterations):\n+            # Apply cross-attention from the latent array to the data array.\n+            latent_array = self.cross_attention(cross_attention_inputs)\n+            # Apply self-attention Transformer to the latent array.\n+            latent_array = self.transformer(latent_array)\n+            # Set the latent array of the next iteration.\n+            cross_attention_inputs[\"latent_array\"] = latent_array\n+\n+        # Apply global average pooling to generate a [batch_size, projection_dim] repesentation tensor.\n+        representation = self.global_average_pooling(latent_array)\n+        # Generate logits.\n+        logits = self.classification_head(representation)\n+        return logits\n+\n+\n+\"\"\"\n+## Compile, train, and evaluate the mode\n+\"\"\"\n+\n+\n+def run_experiment(model):\n+    # Create LAMB optimizer with weight decay.\n+    optimizer = tfa.optimizers.LAMB(\n+        learning_rate=learning_rate,\n+        weight_decay_rate=weight_decay,\n+    )\n+\n+    # Compile the model.\n+    model.compile(\n+        optimizer=optimizer,\n+        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n+        metrics=[\n+            keras.metrics.SparseCategoricalAccuracy(name=\"acc\"),\n+            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top5-acc\"),\n+        ],\n+    )\n+\n+    # Create a learning rate scheduler callback.\n+    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n+        monitor=\"val_loss\", factor=0.2, patience=3\n+    )\n+\n+    # Create an early stopping callback.\n+    early_stopping = keras.callbacks.EarlyStopping(\n+        monitor=\"val_loss\", patience=15, restore_best_weights=True\n+    )\n+\n+    # Fit the model.\n+    history = model.fit(\n+        x=x_train,\n+        y=y_train,\n+        batch_size=batch_size,\n+        epochs=num_epochs,\n+        validation_split=0.1,\n+        callbacks=[early_stopping, reduce_lr],\n+    )\n+\n+    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n+    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n+    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n+\n+    # Return history to plot learning curves.\n+    return history\n+\n+\n+\"\"\"\n+Note that training the perceiver model with the current settings on a V100 GPUs takes\n+around 200 seconds.\n+\"\"\"\n+\n+perceiver_classifier = Perceiver(\n+    patch_size,\n+    num_patches,\n+    latent_dim,\n+    projection_dim,\n+    num_heads,\n+    num_transformer_blocks,\n+    ffn_units,\n+    dropout_rate,\n+    num_iterations,\n+    classifier_units,\n+)\n+\n+\n+history = run_experiment(perceiver_classifier)\n+\n+\"\"\"\n+After 40 epochs, the Perceiver model achieves around 53% accuracy and 81% top-5 accuracy on the test data.\n+\n+As mentioned in the ablations of the [Perceiver](https://arxiv.org/abs/2103.03206) paper,\n+you can obtain better results by increasing the latent array size,\n+increasing the (projection) dimensions of the latent array and data array elements,\n+increasing the number of blocks in the Transformer module, and increasing the number of iterations of applying\n+the cross-attention and the latent Transformer modules. You may also try to increase the size the input images\n+and use different patch sizes.\n+\n+The Perceiver benefits from inceasing the model size. However, larger models needs bigger accelerators\n+to fit in and train efficiently. This is why in the Perceiver paper they used 32 TPU cores to run the experiments.\n+\"\"\"\n\\ No newline at end of file\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6b0cb5598abbd1df1b82430d1fc1aabc9ea60d41", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 490 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -45,7 +45,6 @@ import numpy as np\n import tensorflow as tf\n import keras_core as keras\n from keras_core import layers\n-import tensorflow_addons as tfa\n \n \"\"\"\n ## Prepare the data\n@@ -206,9 +205,9 @@ def create_cross_attention_module(\n ):\n     inputs = {\n         # Recieve the latent array as an input of shape [1, latent_dim, projection_dim].\n-        \"latent_array\": layers.Input(shape=(latent_dim, projection_dim)),\n+        \"latent_array\": layers.Input(shape=(latent_dim, projection_dim), name=\"latent_array\"),\n         # Recieve the data_array (encoded image) as an input of shape [batch_size, data_dim, projection_dim].\n-        \"data_array\": layers.Input(shape=(data_dim, projection_dim)),\n+        \"data_array\": layers.Input(shape=(data_dim, projection_dim), name=\"data_array\"),\n     }\n \n     # Apply layer norm to the inputs\n@@ -399,10 +398,10 @@ class Perceiver(keras.Model):\n \n \n def run_experiment(model):\n-    # Create LAMB optimizer with weight decay.\n-    optimizer = tfa.optimizers.LAMB(\n+    # Create Adam optimizer with weight decay.\n+    optimizer = keras.optimizers.Adam(\n         learning_rate=learning_rate,\n-        weight_decay_rate=weight_decay,\n+        weight_decay=weight_decay,\n     )\n \n     # Compile the model.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c6d71e6a68850327bf4e922349fad68c28daff10", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 32 | Churn Cumulative: 1446 | Contributors (this commit): 7 | Commits (past 90d): 38 | Contributors (cumulative): 11 | DMM Complexity: 0.0\n\nDIFF:\n@@ -548,19 +548,35 @@ class CompileLoss(losses_module.Loss):\n         self.flat_loss_weights = flat_loss_weights\n         self.built = True\n \n-    def call(self, y_true, y_pred):\n+    def __call__(self, y_true, y_pred, sample_weight=None):\n+        with ops.name_scope(self.name):\n+            return self.call(y_true, y_pred, sample_weight)\n+\n+    def call(self, y_true, y_pred, sample_weight=None):\n         if not self.built:\n             self.build(y_true, y_pred)\n \n         y_true = nest.flatten(y_true)\n         y_pred = nest.flatten(y_pred)\n+\n+        if sample_weight is not None:\n+            sample_weight = nest.flatten(sample_weight)\n+        else:\n+            sample_weight = [None for _ in y_true]\n+\n         loss_values = []\n \n-        for loss, y_t, y_p, w in zip(\n-            self.flat_losses, y_true, y_pred, self.flat_loss_weights\n+        for loss, y_t, y_p, loss_weight, sample_weight in zip(\n+            self.flat_losses,\n+            y_true,\n+            y_pred,\n+            self.flat_loss_weights,\n+            sample_weight,\n         ):\n             if loss:\n-                value = w * ops.cast(loss(y_t, y_p), dtype=backend.floatx())\n+                value = loss_weight * ops.cast(\n+                    loss(y_t, y_p, sample_weight), dtype=backend.floatx()\n+                )\n                 loss_values.append(value)\n         if loss_values:\n             total_loss = sum(loss_values)\n\n@@ -270,6 +270,10 @@ class TestCompileLoss(testing.TestCase, parameterized.TestCase):\n             \"a\": np.array([[1.2, 1.1], [1.0, 0.9], [0.8, 0.7]]),\n             \"b\": np.array([[0.6, 0.5], [0.4, 0.3], [0.2, 0.1]]),\n         }\n+        sample_weight = {\n+            \"a\": np.array([1.0, 2.0, 3.0]),\n+            \"b\": np.array([3.0, 2.0, 1.0]),\n+        }\n         compile_loss.build(y_true, y_pred)\n-        value = compile_loss(y_true, y_pred)\n-        self.assertAllClose(value, 0.953333, atol=1e-5)\n+        value = compile_loss(y_true, y_pred, sample_weight)\n+        self.assertAllClose(value, 1.266666, atol=1e-5)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#81c4c49c323680ef05b3e1b5cb20b0fec37a984c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 152 | Lines Deleted: 16 | Files Changed: 4 | Hunks: 19 | Methods Changed: 7 | Complexity Δ (Sum/Max): 6/3 | Churn Δ: 168 | Churn Cumulative: 4661 | Contributors (this commit): 10 | Commits (past 90d): 76 | Contributors (cumulative): 19 | DMM Complexity: 0.6818181818181818\n\nDIFF:\n@@ -250,20 +250,51 @@ def average_pool(\n     data_format = standardize_data_format(data_format)\n     if data_format == \"channels_last\":\n         inputs = _transpose_spatial_inputs(inputs)\n-\n+    padding_value = 0\n     if padding == \"same\":\n-        # Torch does not natively support `\"same\"` padding, we need to manually\n-        # apply the right amount of padding to `inputs`.\n-        inputs = _apply_same_padding(\n-            inputs, pool_size, strides, operation_type=\"pooling\"\n+        spatial_shape = inputs.shape[2:]\n+        num_spatial_dims = len(spatial_shape)\n+        padding_value = []\n+        uneven_padding = []\n+\n+        for i in range(num_spatial_dims):\n+            padding_size = _compute_padding_length(\n+                spatial_shape[i], pool_size[i], strides[i]\n             )\n+            # Torch only supports even padding on each dim, to replicate the\n+            # behavior of \"same\" padding of `tf.keras` as much as possible,\n+            # we need to pad evenly using the shorter padding.\n+            padding_value.append(padding_size[0])\n+            if padding_size[0] != padding_size[1]:\n+                # Handle unequal padding.\n+                # `torch.nn.pad` sets padding value in the reverse order.\n+                uneven_padding = [0, 1] + uneven_padding\n+        inputs = tnn.pad(inputs, uneven_padding)\n \n     if num_spatial_dims == 1:\n-        outputs = tnn.avg_pool1d(inputs, kernel_size=pool_size, stride=strides)\n+        outputs = tnn.avg_pool1d(\n+            inputs,\n+            kernel_size=pool_size,\n+            stride=strides,\n+            padding=padding_value,\n+            count_include_pad=False,\n+        )\n     elif num_spatial_dims == 2:\n-        outputs = tnn.avg_pool2d(inputs, kernel_size=pool_size, stride=strides)\n+        outputs = tnn.avg_pool2d(\n+            inputs,\n+            kernel_size=pool_size,\n+            stride=strides,\n+            padding=padding_value,\n+            count_include_pad=False,\n+        )\n     elif num_spatial_dims == 3:\n-        outputs = tnn.avg_pool3d(inputs, kernel_size=pool_size, stride=strides)\n+        outputs = tnn.avg_pool3d(\n+            inputs,\n+            kernel_size=pool_size,\n+            stride=strides,\n+            padding=padding_value,\n+            count_include_pad=False,\n+        )\n     else:\n         raise ValueError(\n             \"Inputs to pooling op must have ndim=3, 4 or 5, \"\n\n@@ -1,4 +1,5 @@\n import numpy as np\n+import pytest\n \n from keras_core import backend\n from keras_core import layers\n@@ -356,6 +357,10 @@ class LayerTest(testing.TestCase):\n         y = layer(x)\n         self.assertEqual(ops.min(y), 1)\n \n+    @pytest.mark.skipIf(\n+        backend.backend() == \"torch\",\n+        reason=\"Torch backend has unimplemtned ops for mixed precision on CPU.\",\n+    )\n     def test_mixed_precision(self):\n         x = np.ones((4, 4))\n \n\n@@ -1,7 +1,9 @@\n import numpy as np\n+import pytest\n import tensorflow as tf\n from absl.testing import parameterized\n \n+from keras_core import backend\n from keras_core import layers\n from keras_core import testing\n \n@@ -108,7 +110,6 @@ class AveragePoolingBasicTest(testing.TestCase, parameterized.TestCase):\n class AveragePoolingCorrectnessTest(testing.TestCase, parameterized.TestCase):\n     @parameterized.parameters(\n         (2, 1, \"valid\", \"channels_last\"),\n-        (2, 1, \"same\", \"channels_first\"),\n         ((2,), (2,), \"valid\", \"channels_last\"),\n     )\n     def test_average_pooling1d(self, pool_size, strides, padding, data_format):\n@@ -131,9 +132,39 @@ class AveragePoolingCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         expected = tf_keras_layer(inputs)\n         self.assertAllClose(outputs, expected)\n \n+    @parameterized.parameters(\n+        (2, 1, \"same\", \"channels_first\"),\n+        ((2,), (2,), \"same\", \"channels_last\"),\n+    )\n+    @pytest.mark.skipif(\n+        backend.backend() == \"torch\",\n+        reason=\"Same padding in Torch backend produces different results.\",\n+    )\n+    def test_average_pooling1d_same_padding(\n+        self, pool_size, strides, padding, data_format\n+    ):\n+        inputs = np.arange(24, dtype=\"float32\").reshape((2, 3, 4))\n+\n+        layer = layers.AveragePooling1D(\n+            pool_size=pool_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+        )\n+        tf_keras_layer = tf.keras.layers.AveragePooling1D(\n+            pool_size=pool_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+        )\n+\n+        outputs = layer(inputs)\n+        expected = tf_keras_layer(inputs)\n+        self.assertAllClose(outputs, expected)\n+\n     @parameterized.parameters(\n         (2, 1, \"valid\", \"channels_last\"),\n-        ((2, 3), (2, 2), \"same\", \"channels_last\"),\n+        ((2, 3), (2, 2), \"valid\", \"channels_last\"),\n     )\n     def test_average_pooling2d(self, pool_size, strides, padding, data_format):\n         inputs = np.arange(16, dtype=\"float32\").reshape((1, 4, 4, 1))\n@@ -154,9 +185,37 @@ class AveragePoolingCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         expected = tf_keras_layer(inputs)\n         self.assertAllClose(outputs, expected)\n \n+    @parameterized.parameters(\n+        (2, (2, 1), \"same\", \"channels_last\"),\n+        ((2, 3), (2, 2), \"same\", \"channels_last\"),\n+    )\n+    @pytest.mark.skipif(\n+        backend.backend() == \"torch\",\n+        reason=\"Same padding in Torch backend produces different results.\",\n+    )\n+    def test_average_pooling2d_same_padding(\n+        self, pool_size, strides, padding, data_format\n+    ):\n+        inputs = np.arange(16, dtype=\"float32\").reshape((1, 4, 4, 1))\n+        layer = layers.AveragePooling2D(\n+            pool_size=pool_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+        )\n+        tf_keras_layer = tf.keras.layers.AveragePooling2D(\n+            pool_size=pool_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+        )\n+\n+        outputs = layer(inputs)\n+        expected = tf_keras_layer(inputs)\n+        self.assertAllClose(outputs, expected)\n+\n     @parameterized.parameters(\n         (2, 1, \"valid\", \"channels_last\"),\n-        (2, 1, \"same\", \"channels_first\"),\n         ((2, 3, 2), (2, 2, 1), \"valid\", \"channels_last\"),\n     )\n     def test_average_pooling3d(self, pool_size, strides, padding, data_format):\n@@ -178,3 +237,33 @@ class AveragePoolingCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         outputs = layer(inputs)\n         expected = tf_keras_layer(inputs)\n         self.assertAllClose(outputs, expected)\n+\n+    @parameterized.parameters(\n+        (2, 1, \"same\", \"channels_first\"),\n+        ((2, 3, 2), (2, 2, 1), \"same\", \"channels_last\"),\n+    )\n+    @pytest.mark.skipif(\n+        backend.backend() == \"torch\",\n+        reason=\"Same padding in Torch backend produces different results.\",\n+    )\n+    def test_average_pooling3d_same_padding(\n+        self, pool_size, strides, padding, data_format\n+    ):\n+        inputs = np.arange(240, dtype=\"float32\").reshape((2, 3, 4, 5, 2))\n+\n+        layer = layers.AveragePooling3D(\n+            pool_size=pool_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+        )\n+        tf_keras_layer = tf.keras.layers.AveragePooling3D(\n+            pool_size=pool_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+        )\n+\n+        outputs = layer(inputs)\n+        expected = tf_keras_layer(inputs)\n+        self.assertAllClose(outputs, expected)\n\n@@ -725,17 +725,13 @@ class NNOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             tf.nn.max_pool2d(x, 2, (2, 1), padding=\"SAME\"),\n         )\n \n-    def test_average_pool(self):\n+    def test_average_pool_valid_padding(self):\n         # Test 1D max pooling.\n         x = np.arange(120, dtype=float).reshape([2, 20, 3])\n         self.assertAllClose(\n             knn.average_pool(x, 2, 1, padding=\"valid\"),\n             tf.nn.avg_pool1d(x, 2, 1, padding=\"VALID\"),\n         )\n-        self.assertAllClose(\n-            knn.average_pool(x, 2, 2, padding=\"same\"),\n-            tf.nn.avg_pool1d(x, 2, 2, padding=\"SAME\"),\n-        )\n \n         # Test 2D max pooling.\n         x = np.arange(540, dtype=float).reshape([2, 10, 9, 3])\n@@ -743,6 +739,21 @@ class NNOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             knn.average_pool(x, 2, 1, padding=\"valid\"),\n             tf.nn.avg_pool2d(x, 2, 1, padding=\"VALID\"),\n         )\n+\n+    @pytest.mark.skipif(\n+        backend.backend() == \"torch\",\n+        reason=\"Torch outputs differently from TF when using `same` padding.\",\n+    )\n+    def test_average_pool_same_padding(self):\n+        # Test 1D max pooling.\n+        x = np.arange(120, dtype=float).reshape([2, 20, 3])\n+        self.assertAllClose(\n+            knn.average_pool(x, 2, 2, padding=\"same\"),\n+            tf.nn.avg_pool1d(x, 2, 2, padding=\"SAME\"),\n+        )\n+\n+        # Test 2D max pooling.\n+        x = np.arange(540, dtype=float).reshape([2, 10, 9, 3])\n         self.assertAllClose(\n             knn.average_pool(x, 2, (2, 1), padding=\"same\"),\n             tf.nn.avg_pool2d(x, 2, (2, 1), padding=\"SAME\"),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e4243535f6d3fd412daebbea2fe4658b8a593bed", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 761 | Contributors (this commit): 5 | Commits (past 90d): 35 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -357,7 +357,7 @@ class LayerTest(testing.TestCase):\n         y = layer(x)\n         self.assertEqual(ops.min(y), 1)\n \n-    @pytest.mark.skipIf(\n+    @pytest.mark.skipif(\n         backend.backend() == \"torch\",\n         reason=\"Torch backend has unimplemtned ops for mixed precision on CPU.\",\n     )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#40f9828a1adf5f234ec3af508804bab3271fe900", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 39 | Lines Deleted: 7 | Files Changed: 4 | Hunks: 13 | Methods Changed: 10 | Complexity Δ (Sum/Max): 14/10 | Churn Δ: 46 | Churn Cumulative: 2354 | Contributors (this commit): 6 | Commits (past 90d): 54 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -110,6 +110,11 @@ def _get_elephant(target_size):\n class ApplicationsTest(testing.TestCase, parameterized.TestCase):\n     @parameterized.named_parameters(MODEL_LIST)\n     def test_application_notop_variable_input_channels(self, app, last_dim, _):\n+        if app == nasnet.NASNetMobile and backend.backend() == \"torch\":\n+            self.skipTest(\n+                \"NASNetMobile pretrained incorrect with torch backend.\"\n+            )\n+\n         # Test compatibility with 1 channel\n         if backend.image_data_format() == \"channels_first\":\n             input_shape = (1, None, None)\n@@ -131,6 +136,11 @@ class ApplicationsTest(testing.TestCase, parameterized.TestCase):\n     @parameterized.named_parameters(MODEL_LIST)\n     @pytest.mark.skipif(PIL is None, reason=\"Requires PIL.\")\n     def test_application_base(self, app, _, app_module):\n+        if app == nasnet.NASNetMobile and backend.backend() == \"torch\":\n+            self.skipTest(\n+                \"NASNetMobile pretrained incorrect with torch backend.\"\n+            )\n+\n         # Can be instantiated with default arguments\n         model = app(weights=\"imagenet\")\n \n@@ -149,18 +159,33 @@ class ApplicationsTest(testing.TestCase, parameterized.TestCase):\n \n     @parameterized.named_parameters(MODEL_LIST)\n     def test_application_notop_custom_input_shape(self, app, last_dim, _):\n+        if app == nasnet.NASNetMobile and backend.backend() == \"torch\":\n+            self.skipTest(\n+                \"NASNetMobile pretrained incorrect with torch backend.\"\n+            )\n+\n         model = app(weights=None, include_top=False, input_shape=(123, 123, 3))\n         output_shape = list(model.outputs[0].shape)\n         self.assertEqual(output_shape[-1], last_dim)\n \n     @parameterized.named_parameters(MODEL_LIST)\n     def test_application_pooling(self, app, last_dim, _):\n+        if app == nasnet.NASNetMobile and backend.backend() == \"torch\":\n+            self.skipTest(\n+                \"NASNetMobile pretrained incorrect with torch backend.\"\n+            )\n+\n         model = app(weights=None, include_top=False, pooling=\"max\")\n         output_shape = list(model.outputs[0].shape)\n         self.assertEqual(output_shape, [None, last_dim])\n \n     @parameterized.named_parameters(MODEL_LIST)\n     def test_application_classifier_activation(self, app, *_):\n+        if app == nasnet.NASNetMobile and backend.backend() == \"torch\":\n+            self.skipTest(\n+                \"NASNetMobile pretrained incorrect with torch backend.\"\n+            )\n+\n         model = app(\n             weights=None, include_top=True, classifier_activation=\"softmax\"\n         )\n\n@@ -103,7 +103,7 @@ def preprocess_input(x, data_format=None, mode=\"caffe\"):\n     if isinstance(x, np.ndarray):\n         return _preprocess_numpy_input(x, data_format=data_format, mode=mode)\n     else:\n-        return _preprocess_symbolic_input(x, data_format=data_format, mode=mode)\n+        return _preprocess_tensor_input(x, data_format=data_format, mode=mode)\n \n \n preprocess_input.__doc__ = PREPROCESS_INPUT_DOC.format(\n@@ -230,7 +230,7 @@ def _preprocess_numpy_input(x, data_format, mode):\n     return x\n \n \n-def _preprocess_symbolic_input(x, data_format, mode):\n+def _preprocess_tensor_input(x, data_format, mode):\n     \"\"\"Preprocesses a tensor encoding a batch of images.\n \n     Args:\n@@ -263,13 +263,13 @@ def _preprocess_symbolic_input(x, data_format, mode):\n     else:\n         if data_format == \"channels_first\":\n             # 'RGB'->'BGR'\n-            if ndim == 3:\n-                x = x[::-1, ...]\n+            if len(x.shape) == 3:\n+                x = ops.stack([x[i, ...] for i in (2, 1, 0)], axis=0)\n             else:\n-                x = x[:, ::-1, ...]\n+                x = ops.stack([x[:, i, :] for i in (2, 1, 0)], axis=1)\n         else:\n             # 'RGB'->'BGR'\n-            x = x[..., ::-1]\n+            x = ops.stack([x[..., i] for i in (2, 1, 0)], axis=-1)\n         mean = [103.939, 116.779, 123.68]\n         std = None\n \n\n@@ -381,6 +381,12 @@ def NASNetMobile(\n     Returns:\n         A Keras model instance.\n     \"\"\"\n+    if backend.backend() == \"torch\":\n+        raise ValueError(\n+            \"NASNetMobile is not available with the torch backend \"\n+            \"at this time due to an outstanding bug. \"\n+            \"If interested, please open a PR.\"\n+        )\n     return NASNet(\n         input_shape,\n         penultimate_filters=1056,\n\n@@ -359,9 +359,10 @@ class LayerTest(testing.TestCase):\n \n     @pytest.mark.skipif(\n         backend.backend() == \"torch\",\n-        reason=\"Torch backend has unimplemtned ops for mixed precision on CPU.\",\n+        reason=\"Some torch ops not implemented for float16 on CPU.\",\n     )\n     def test_mixed_precision(self):\n+        print(\"Run with backend.backend()\", backend.backend())\n         x = np.ones((4, 4))\n \n         layer = layers.Dense(2, dtype=\"float16\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c8d37be159e87c156328b565ccc59c381499947a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 14 | Churn Cumulative: 325 | Contributors (this commit): 7 | Commits (past 90d): 15 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -14,10 +14,8 @@ def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n \n \n def top_k(x, k, sorted=True):\n-    if not sorted:\n-        return ValueError(\n-            \"Jax backend does not support `sorted=False` for `ops.top_k`\"\n-        )\n+    # Jax does not supported `sorted`, but in the case where `sorted=False`,\n+    # order is not guaranteed, so OK to return sorted output.\n     return jax.lax.top_k(x, k)\n \n \n\n@@ -20,7 +20,7 @@ class MathOpsDynamicShapeTest(testing.TestCase):\n         outputs = kmath.segment_sum(data, segment_ids, num_segments=5)\n         self.assertEqual(outputs.shape, (5, 4))\n \n-    def test_topk(self):\n+    def test_top_k(self):\n         x = KerasTensor((None, 2, 3))\n         values, indices = kmath.top_k(x, k=1)\n         self.assertEqual(values.shape, (None, 2, 1))\n@@ -155,6 +155,12 @@ class MathOpsCorrectnessTest(testing.TestCase):\n         self.assertAllClose(values, [4, 3])\n         self.assertAllClose(indices, [1, 4])\n \n+        x = np.array([0, 4, 2, 1, 3, -1], dtype=np.float32)\n+        values, indices = kmath.top_k(x, k=2, sorted=False)\n+        # Any order ok when `sorted=False`.\n+        self.assertEqual(set(backend.convert_to_numpy(values)), set([4, 3]))\n+        self.assertEqual(set(backend.convert_to_numpy(indices)), set([1, 4]))\n+\n         x = np.random.rand(5, 5)\n         outputs = kmath.top_k(x, k=2)\n         expected = tf.math.top_k(x, k=2)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#04fd397bab11071eac0ec423c3550e9db0d65670", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 1 | Files Changed: 3 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 29 | Churn Cumulative: 1413 | Contributors (this commit): 9 | Commits (past 90d): 45 | Contributors (cumulative): 20 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4,7 +4,6 @@\n \n from keras_core.backend import cast\n from keras_core.backend import cond\n-from keras_core.backend import convert_to_tensor\n from keras_core.backend import is_tensor\n from keras_core.backend import name_scope\n from keras_core.backend import random\n\n@@ -279,3 +279,21 @@ def cast(x, dtype):\n     if any_symbolic_tensors((x,)):\n         return backend.KerasTensor(shape=x.shape, dtype=dtype)\n     return backend.core.cast(x, dtype)\n+\n+\n+@keras_core_export(\"keras_core.operations.convert_to_tensor\")\n+def convert_to_tensor(x, dtype=None):\n+    \"\"\"Convert a NumPy array to a tensor.\"\"\"\n+    return backend.convert_to_tensor(x, dtype=dtype)\n+\n+\n+@keras_core_export(\"keras_core.operations.convert_to_numpy\")\n+def convert_to_numpy(x):\n+    \"\"\"Convert a tensor to a NumPy array.\"\"\"\n+    if any_symbolic_tensors((x,)):\n+        raise ValueError(\n+            \"A symbolic tensor (usually the result of applying layers or \"\n+            \"operations to a `keras.Input`), cannot be converted to a numpy \"\n+            \"array. There is no concrete value for the input.\"\n+        )\n+    return backend.convert_to_numpy(x)\n\n@@ -231,3 +231,13 @@ class CoreOpsCorrectnessTest(testing.TestCase):\n \n         x = KerasTensor((None, 3, None, 1))\n         self.assertAllEqual(core.shape(x), (None, 3, None, 1))\n+\n+    def test_convert_to_tensor(self):\n+        x = np.ones((2,))\n+        x = ops.convert_to_tensor(x)\n+        x = ops.convert_to_numpy(x)\n+        self.assertAllEqual(x, (1, 1))\n+        self.assertIsInstance(x, np.ndarray)\n+\n+        with self.assertRaises(ValueError):\n+            ops.convert_to_numpy(KerasTensor((2,)))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e2e7f0d0617e7cf23f1bc62cda87e558241e1582", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 42 | Contributors (this commit): 5 | Commits (past 90d): 11 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -1,3 +1,16 @@\n+\"\"\"Torch backend APIs.\n+\n+Torch has a different logic of device management compared to TF and JAX. In\n+short variables/tensors are not by default created on GPU, and GPU cannot\n+directly communicate with CPU. Therefore, we are doing the following to automate\n+device management for Torch backend, if GPU is available:\n+\n+- Variables are created on GPU.\n+- Input data will be placed on GPU at the first `keras_core.layers.Layer` call.\n+- Tensor creation happens on GPU, e.g., `zeros()` will create a tensor on GPU.\n+- `convert_to_numpy` will bring the tensor to CPU and convert to numpy array.\n+\"\"\"\n+\n from keras_core.backend.torch import core\n from keras_core.backend.torch import image\n from keras_core.backend.torch import math\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#57d8ac26f1b653b55b1c797fea1c251d4c68ee92", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 6 | Files Changed: 3 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 20 | Churn Cumulative: 2451 | Contributors (this commit): 10 | Commits (past 90d): 78 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -1,14 +1,17 @@\n \"\"\"Torch backend APIs.\n \n-Torch has a different logic of device management compared to TF and JAX. In\n-short variables/tensors are not by default created on GPU, and GPU cannot\n-directly communicate with CPU. Therefore, we are doing the following to automate\n-device management for Torch backend, if GPU is available:\n+# Note on device placement\n+\n+Torch has a different device placement style compared to TF and JAX.\n+In short, variables/tensors are not created on GPU by default,\n+and the GPU cannot directly communicate with the CPU.\n+To bring Torch behavior in line with TF and JAX automated device placement,\n+we are doing the following to automate device placement if a GPU is available:\n \n - Variables are created on GPU.\n - Input data will be placed on GPU at the first `keras_core.layers.Layer` call.\n - Tensor creation happens on GPU, e.g., `zeros()` will create a tensor on GPU.\n-- `convert_to_numpy` will bring the tensor to CPU and convert to numpy array.\n+- `convert_to_numpy` will bring the tensor to CPU before converting it to NumPy.\n \"\"\"\n \n from keras_core.backend.torch import core\n\n@@ -4,6 +4,11 @@ scatter_update\n slice\n slice_update\n while_loop\n+stop_gradient\n+shape\n+cast\n+convert_to_tensor\n+convert_to_numpy\n \"\"\"\n \n from keras_core import backend\n\n@@ -43,7 +43,7 @@ class Trainer:\n         else:\n             self._compile_metrics = None\n         if jit_compile == \"auto\":\n-            if model_supports_jit(self):\n+            if not run_eagerly and model_supports_jit(self):\n                 jit_compile = True\n             else:\n                 jit_compile = False\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a97cee173612ca3d00a6fb77fc2ca01037d0f252", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 11500 | Contributors (this commit): 10 | Commits (past 90d): 78 | Contributors (cumulative): 17 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2665,6 +2665,9 @@ class Repeat(Operation):\n         size_on_ax = x_shape[self.axis]\n         output_shape = x_shape\n         if isinstance(self.repeats, int):\n+            if size_on_ax is None:\n+                output_shape[self.axis] = None\n+            else:\n                 output_shape[self.axis] = size_on_ax * self.repeats\n         else:\n             output_shape[self.axis] = int(np.sum(self.repeats))\n\n@@ -1027,6 +1027,7 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n         self.assertEqual(knp.repeat(x, 2).shape, (None,))\n         self.assertEqual(knp.repeat(x, 3, axis=1).shape, (None, 9))\n         self.assertEqual(knp.repeat(x, [1, 2], axis=0).shape, (3, 3))\n+        self.assertEqual(knp.repeat(x, 2, axis=0).shape, (None, 3))\n \n     def test_reshape(self):\n         x = KerasTensor([None, 3])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9a2ee731b870313a9207007d8ae8ac5865b3b004", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 11 | Churn Cumulative: 9777 | Contributors (this commit): 11 | Commits (past 90d): 76 | Contributors (cumulative): 18 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4,6 +4,7 @@ import torch\n from keras_core.backend.torch.core import cast\n from keras_core.backend.torch.core import convert_to_tensor\n from keras_core.backend.torch.core import get_device\n+from keras_core.backend.torch.core import is_tensor\n from keras_core.backend.torch.core import to_torch_dtype\n \n TORCH_INT_TYPES = (\n@@ -187,9 +188,9 @@ def argsort(x, axis=-1):\n \n def array(x, dtype=None):\n     dtype = to_torch_dtype(dtype)\n-    if not isinstance(x, torch.Tensor):\n+    if isinstance(x, torch.Tensor):\n         return x\n-    return x.numpy()\n+    return torch.tensor(x, dtype=dtype)\n \n \n def average(x, axis=None, weights=None):\n@@ -754,6 +755,8 @@ def round(x, decimals=0):\n \n \n def tile(x, repeats):\n+    if is_tensor(repeats):\n+        repeats = tuple(repeats.int().numpy())\n     x = convert_to_tensor(x)\n     return torch.tile(x, dims=repeats)\n \n\n@@ -509,7 +509,7 @@ def update_confusion_matrix_variables(\n         data_tiles = [num_thresholds, 1]\n \n     thresh_tiled = ops.tile(\n-        ops.reshape(thresholds, thresh_pretile_shape), ops.array(thresh_tiles)\n+        ops.reshape(thresholds, thresh_pretile_shape), thresh_tiles\n     )\n \n     # Tile the predictions for every threshold.\n\n@@ -2242,6 +2242,8 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         self.assertAllClose(knp.array(x), np.array(x))\n         self.assertAllClose(knp.Array()(x), np.array(x))\n+        self.assertTrue(backend.is_tensor(knp.array(x)))\n+        self.assertTrue(backend.is_tensor(knp.Array()(x)))\n \n     def test_average(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
