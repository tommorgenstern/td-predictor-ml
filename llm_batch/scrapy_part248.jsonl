{"custom_id": "scrapy#127bf499f1d6b4a924d87e39ff89b528586c78c7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 281 | Contributors (this commit): 11 | Commits (past 90d): 1 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -28,7 +28,8 @@ class Command(ScrapyCommand):\n         return \"Interactive scraping console\"\n \n     def long_desc(self):\n-        return \"Interactive console for scraping the given url\"\n+        return (\"Interactive console for scraping the given url or file. \"\n+                \"Use ./file.html syntax or full path for local file.\")\n \n     def add_options(self, parser):\n         ScrapyCommand.add_options(self, parser)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#a25cf5c82f99f7ae11346a2e565d6255835c3814", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 15 | Churn Cumulative: 15 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,15 @@\n+import uuid\n+import os.path\n+\n+\n+def unique_files_queue(queue_class):\n+\n+    class UniqueFilesQueue(queue_class):\n+        def __init__(self, path):\n+            path = path + \"-\" + uuid.uuid4().hex\n+            while os.path.exists(path):\n+                path = path + \"-\" + uuid.uuid4().hex\n+\n+            super().__init__(path)\n+\n+    return UniqueFilesQueue\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#1ce6662a9d7115348788972afce62a5c45199021", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 83 | Lines Deleted: 1 | Files Changed: 3 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 5/3 | Churn Δ: 84 | Churn Cumulative: 784 | Contributors (this commit): 16 | Commits (past 90d): 3 | Contributors (cumulative): 19 | DMM Complexity: 1.0\n\nDIFF:\n@@ -10,6 +10,7 @@ from scrapy.http.headers import Headers\n from scrapy.http.request import Request\n from scrapy.http.request.form import FormRequest\n from scrapy.http.request.rpc import XmlRpcRequest\n+from scrapy.http.request.json_request import JSONRequest\n \n from scrapy.http.response import Response\n from scrapy.http.response.html import HtmlResponse\n\n@@ -0,0 +1,28 @@\n+\"\"\"\n+This module implements the JSONRequest class which is a more convenient class\n+(than Request) to generate JSON Requests.\n+\n+See documentation in docs/topics/request-response.rst\n+\"\"\"\n+\n+import json\n+\n+from scrapy.http.request import Request\n+\n+\n+class JSONRequest(Request):\n+    def __init__(self, *args, **kwargs):\n+        if 'method' not in kwargs:\n+            kwargs['method'] = 'POST'\n+\n+        data = kwargs.pop('data', {})\n+        kwargs['body'] = json.dumps(data)\n+        super(JSONRequest, self).__init__(*args, **kwargs)\n+        self.headers.setdefault(b'Content-Type', b'application/json')\n+\n+    def replace(self, *args, **kwargs):\n+        \"\"\" Create a new Request with the same attributes except for those\n+            given new values. \"\"\"\n+\n+        kwargs.pop('body', None)\n+        return super(JSONRequest, self).replace(*args, **kwargs)\n\n@@ -2,6 +2,7 @@\n import cgi\n import unittest\n import re\n+import json\n \n import six\n from six.moves import xmlrpc_client as xmlrpclib\n@@ -9,7 +10,7 @@ from six.moves.urllib.parse import urlparse, parse_qs, unquote\n if six.PY3:\n     from urllib.parse import unquote_to_bytes\n \n-from scrapy.http import Request, FormRequest, XmlRpcRequest, Headers, HtmlResponse\n+from scrapy.http import Request, FormRequest, XmlRpcRequest, JSONRequest, Headers, HtmlResponse\n from scrapy.utils.python import to_bytes, to_native_str\n \n \n@@ -1147,5 +1148,57 @@ class XmlRpcRequestTest(RequestTest):\n         self._test_request(params=(u'pas£',), encoding='latin1')\n \n \n+class JSONRequestTest(RequestTest):\n+    request_class = JSONRequest\n+    default_method = 'POST'\n+    default_headers = {b'Content-Type': [b'application/json']}\n+\n+    def test_body(self):\n+        r1 = self.request_class(url=\"http://www.example.com/\")\n+        self.assertEqual(r1.body, '{}')\n+\n+        r2 = self.request_class(url=\"http://www.example.com/\", body=b\"\")\n+        self.assertEqual(r2.body, '{}')\n+\n+        data = {\n+            'name': 'value',\n+        }\n+        r3 = self.request_class(url=\"http://www.example.com/\", data=data)\n+        self.assertEqual(r3.body, json.dumps(data))\n+\n+        r4 = self.request_class(url=\"http://www.example.com/\", body='body1', data=data)\n+        self.assertEqual(r3.body, json.dumps(data))\n+\n+    def test_replace(self):\n+        \"\"\"Test Request.replace() method\"\"\"\n+        r1 = self.request_class(\"http://www.example.com\")\n+        hdrs = Headers(r1.headers)\n+        hdrs[b'key'] = b'value'\n+        r2 = r1.replace(body=\"New body\", headers=hdrs)\n+\n+        # body will not be replaced\n+        self.assertEqual(r1.body, r2.body)\n+        self.assertEqual(r1.url, r2.url)\n+        self.assertEqual((r1.headers, r2.headers), (self.default_headers, hdrs))\n+\n+        # Empty attributes (which may fail if not compared properly)\n+        r3 = self.request_class(\"http://www.example.com\", meta={'a': 1}, dont_filter=True)\n+        r4 = r3.replace(url=\"http://www.example.com/2\", meta={}, dont_filter=False)\n+        self.assertEqual(r4.url, \"http://www.example.com/2\")\n+        self.assertEqual(r4.meta, {})\n+        assert r4.dont_filter is False\n+\n+        data1 = {\n+            'name': 'value1',\n+        }\n+        data2 = {\n+            'name': 'value2',\n+        }\n+        r5 = self.request_class(\"http://www.example.com\", data=data1)\n+        r6 = r5.replace(url=\"http://www.example.com/2\", data=data2)\n+        self.assertNotEqual(r5.body, r6.body)\n+        self.assertEqual((r5.body, r6.body), (json.dumps(data1), json.dumps(data2)))\n+\n+\n if __name__ == \"__main__\":\n     unittest.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#1b2b8b4bf0c73b4ad143f943584545702d66cbb7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 762 | Contributors (this commit): 15 | Commits (past 90d): 2 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -1155,19 +1155,19 @@ class JSONRequestTest(RequestTest):\n \n     def test_body(self):\n         r1 = self.request_class(url=\"http://www.example.com/\")\n-        self.assertEqual(r1.body, '{}')\n+        self.assertEqual(r1.body, b'{}')\n \n         r2 = self.request_class(url=\"http://www.example.com/\", body=b\"\")\n-        self.assertEqual(r2.body, '{}')\n+        self.assertEqual(r2.body, b'{}')\n \n         data = {\n             'name': 'value',\n         }\n         r3 = self.request_class(url=\"http://www.example.com/\", data=data)\n-        self.assertEqual(r3.body, json.dumps(data))\n+        self.assertEqual(r3.body, to_bytes(json.dumps(data)))\n \n         r4 = self.request_class(url=\"http://www.example.com/\", body='body1', data=data)\n-        self.assertEqual(r3.body, json.dumps(data))\n+        self.assertEqual(r3.body, to_bytes(json.dumps(data)))\n \n     def test_replace(self):\n         \"\"\"Test Request.replace() method\"\"\"\n@@ -1197,7 +1197,7 @@ class JSONRequestTest(RequestTest):\n         r5 = self.request_class(\"http://www.example.com\", data=data1)\n         r6 = r5.replace(url=\"http://www.example.com/2\", data=data2)\n         self.assertNotEqual(r5.body, r6.body)\n-        self.assertEqual((r5.body, r6.body), (json.dumps(data1), json.dumps(data2)))\n+        self.assertEqual((r5.body, r6.body), (to_bytes(json.dumps(data1)), to_bytes(json.dumps(data2))))\n \n \n if __name__ == \"__main__\":\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#d7c8eee2fc918d07feb708c41089da21b2b9aea5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 61 | Contributors (this commit): 7 | Commits (past 90d): 1 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -30,7 +30,7 @@ class HttpProxyMiddleware(object):\n         user_pass = to_bytes(\n             '%s:%s' % (unquote(username), unquote(password)),\n             encoding=self.auth_encoding)\n-        return base64.b64encode(user_pass).strip()\n+        return base64.b64encode(user_pass)\n \n     def _get_proxy(self, url, orig_type):\n         proxy_type, user, password, hostport = _parse_proxy(url)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#cd619c1d4f3810c96af0ff5c5735c1856dfac95a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 48 | Files Changed: 2 | Hunks: 9 | Methods Changed: 5 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 67 | Churn Cumulative: 857 | Contributors (this commit): 15 | Commits (past 90d): 5 | Contributors (cumulative): 16 | DMM Complexity: 0.0\n\nDIFF:\n@@ -12,17 +12,13 @@ from scrapy.http.request import Request\n \n class JSONRequest(Request):\n     def __init__(self, *args, **kwargs):\n+        data = kwargs.pop('data', None)\n+        if data:\n+            kwargs['body'] = json.dumps(data)\n+\n             if 'method' not in kwargs:\n                 kwargs['method'] = 'POST'\n \n-        data = kwargs.pop('data', {})\n-        kwargs['body'] = json.dumps(data)\n         super(JSONRequest, self).__init__(*args, **kwargs)\n-        self.headers.setdefault(b'Content-Type', b'application/json')\n-\n-    def replace(self, *args, **kwargs):\n-        \"\"\" Create a new Request with the same attributes except for those\n-            given new values. \"\"\"\n-\n-        kwargs.pop('body', None)\n-        return super(JSONRequest, self).replace(*args, **kwargs)\n+        self.headers.setdefault('Content-Type', 'application/json')\n+        self.headers.setdefault('Accept', 'application/json, text/javascript, */*; q=0.01')\n\n@@ -1150,54 +1150,29 @@ class XmlRpcRequestTest(RequestTest):\n \n class JSONRequestTest(RequestTest):\n     request_class = JSONRequest\n-    default_method = 'POST'\n-    default_headers = {b'Content-Type': [b'application/json']}\n+    default_method = 'GET'\n+    default_headers = {b'Content-Type': [b'application/json'], b'Accept': [b'application/json, text/javascript, */*; q=0.01']}\n \n-    def test_body(self):\n+    def test_data(self):\n         r1 = self.request_class(url=\"http://www.example.com/\")\n-        self.assertEqual(r1.body, b'{}')\n+        self.assertEqual(r1.body, b'')\n+        self.assertEqual(r1.method, 'GET')\n \n-        r2 = self.request_class(url=\"http://www.example.com/\", body=b\"\")\n-        self.assertEqual(r2.body, b'{}')\n+        body = b'body'\n+        r2 = self.request_class(url=\"http://www.example.com/\", body=body)\n+        self.assertEqual(r2.body, body)\n+        self.assertEqual(r2.method, 'GET')\n \n         data = {\n             'name': 'value',\n         }\n         r3 = self.request_class(url=\"http://www.example.com/\", data=data)\n         self.assertEqual(r3.body, to_bytes(json.dumps(data)))\n+        self.assertEqual(r3.method, 'POST')\n \n-        r4 = self.request_class(url=\"http://www.example.com/\", body='body1', data=data)\n-        self.assertEqual(r3.body, to_bytes(json.dumps(data)))\n-\n-    def test_replace(self):\n-        \"\"\"Test Request.replace() method\"\"\"\n-        r1 = self.request_class(\"http://www.example.com\")\n-        hdrs = Headers(r1.headers)\n-        hdrs[b'key'] = b'value'\n-        r2 = r1.replace(body=\"New body\", headers=hdrs)\n-\n-        # body will not be replaced\n-        self.assertEqual(r1.body, r2.body)\n-        self.assertEqual(r1.url, r2.url)\n-        self.assertEqual((r1.headers, r2.headers), (self.default_headers, hdrs))\n-\n-        # Empty attributes (which may fail if not compared properly)\n-        r3 = self.request_class(\"http://www.example.com\", meta={'a': 1}, dont_filter=True)\n-        r4 = r3.replace(url=\"http://www.example.com/2\", meta={}, dont_filter=False)\n-        self.assertEqual(r4.url, \"http://www.example.com/2\")\n-        self.assertEqual(r4.meta, {})\n-        assert r4.dont_filter is False\n-\n-        data1 = {\n-            'name': 'value1',\n-        }\n-        data2 = {\n-            'name': 'value2',\n-        }\n-        r5 = self.request_class(\"http://www.example.com\", data=data1)\n-        r6 = r5.replace(url=\"http://www.example.com/2\", data=data2)\n-        self.assertNotEqual(r5.body, r6.body)\n-        self.assertEqual((r5.body, r6.body), (to_bytes(json.dumps(data1)), to_bytes(json.dumps(data2))))\n+        r4 = self.request_class(url=\"http://www.example.com/\", body=body, data=data)\n+        self.assertEqual(r4.body, to_bytes(json.dumps(data)))\n+        self.assertEqual(r4.method, 'POST')\n \n \n if __name__ == \"__main__\":\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c347acbff6545c428aa2c965cd03f03db6bae1bf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 7 | Methods Changed: 4 | Complexity Δ (Sum/Max): 5/3 | Churn Δ: 30 | Churn Cumulative: 887 | Contributors (this commit): 15 | Commits (past 90d): 7 | Contributors (cumulative): 16 | DMM Complexity: 0.3333333333333333\n\nDIFF:\n@@ -6,14 +6,19 @@ See documentation in docs/topics/request-response.rst\n \"\"\"\n \n import json\n+import warnings\n \n from scrapy.http.request import Request\n \n \n class JSONRequest(Request):\n     def __init__(self, *args, **kwargs):\n+        body_passed = 'body' in kwargs\n         data = kwargs.pop('data', None)\n-        if data:\n+        if body_passed and data:\n+            warnings.warn('Both body and data passed. data will be ignored')\n+\n+        elif not body_passed and data:\n             kwargs['body'] = json.dumps(data)\n \n             if 'method' not in kwargs:\n\n@@ -3,6 +3,7 @@ import cgi\n import unittest\n import re\n import json\n+import warnings\n \n import six\n from six.moves import xmlrpc_client as xmlrpclib\n@@ -1153,6 +1154,10 @@ class JSONRequestTest(RequestTest):\n     default_method = 'GET'\n     default_headers = {b'Content-Type': [b'application/json'], b'Accept': [b'application/json, text/javascript, */*; q=0.01']}\n \n+    def setUp(self):\n+        warnings.simplefilter(\"always\")\n+        super(JSONRequestTest, self).setUp()\n+\n     def test_data(self):\n         r1 = self.request_class(url=\"http://www.example.com/\")\n         self.assertEqual(r1.body, b'')\n@@ -1170,9 +1175,23 @@ class JSONRequestTest(RequestTest):\n         self.assertEqual(r3.body, to_bytes(json.dumps(data)))\n         self.assertEqual(r3.method, 'POST')\n \n+        with warnings.catch_warnings(record=True) as _warnings:\n             r4 = self.request_class(url=\"http://www.example.com/\", body=body, data=data)\n-        self.assertEqual(r4.body, to_bytes(json.dumps(data)))\n-        self.assertEqual(r4.method, 'POST')\n+            self.assertEqual(r4.body, body)\n+            self.assertEqual(r4.method, 'GET')\n+            self.assertEqual(len(_warnings), 1)\n+            self.assertIn('data will be ignored', str(_warnings[0].message))\n+\n+        with warnings.catch_warnings(record=True) as _warnings:\n+            r5 = self.request_class(url=\"http://www.example.com/\", body=b'', data=data)\n+            self.assertEqual(r5.body, b'')\n+            self.assertEqual(r5.method, 'GET')\n+            self.assertEqual(len(_warnings), 1)\n+            self.assertIn('data will be ignored', str(_warnings[0].message))\n+\n+    def tearDown(self):\n+        warnings.resetwarnings()\n+        super(JSONRequestTest, self).tearDown()\n \n \n if __name__ == \"__main__\":\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#ecda69130e97629b15d3b09b1e588cb6777ee94d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 7 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 35 | Churn Cumulative: 922 | Contributors (this commit): 15 | Commits (past 90d): 9 | Contributors (cumulative): 16 | DMM Complexity: 0.9230769230769231\n\nDIFF:\n@@ -13,12 +13,14 @@ from scrapy.http.request import Request\n \n class JSONRequest(Request):\n     def __init__(self, *args, **kwargs):\n-        body_passed = 'body' in kwargs\n+        body_passed = kwargs.get('body', None) is not None\n         data = kwargs.pop('data', None)\n-        if body_passed and data:\n+        data_passed = data is not None\n+\n+        if body_passed and data_passed:\n             warnings.warn('Both body and data passed. data will be ignored')\n \n-        elif not body_passed and data:\n+        elif not body_passed and data_passed:\n             kwargs['body'] = json.dumps(data)\n \n             if 'method' not in kwargs:\n\n@@ -1175,20 +1175,35 @@ class JSONRequestTest(RequestTest):\n         self.assertEqual(r3.body, to_bytes(json.dumps(data)))\n         self.assertEqual(r3.method, 'POST')\n \n+        r4 = self.request_class(url=\"http://www.example.com/\", data=[])\n+        self.assertEqual(r4.body, to_bytes(json.dumps([])))\n+        self.assertEqual(r4.method, 'POST')\n+\n         with warnings.catch_warnings(record=True) as _warnings:\n-            r4 = self.request_class(url=\"http://www.example.com/\", body=body, data=data)\n-            self.assertEqual(r4.body, body)\n-            self.assertEqual(r4.method, 'GET')\n+            r5 = self.request_class(url=\"http://www.example.com/\", body=body, data=data)\n+            self.assertEqual(r5.body, body)\n+            self.assertEqual(r5.method, 'GET')\n             self.assertEqual(len(_warnings), 1)\n             self.assertIn('data will be ignored', str(_warnings[0].message))\n \n         with warnings.catch_warnings(record=True) as _warnings:\n-            r5 = self.request_class(url=\"http://www.example.com/\", body=b'', data=data)\n-            self.assertEqual(r5.body, b'')\n-            self.assertEqual(r5.method, 'GET')\n+            r6 = self.request_class(url=\"http://www.example.com/\", body=b'', data=data)\n+            self.assertEqual(r6.body, b'')\n+            self.assertEqual(r6.method, 'GET')\n             self.assertEqual(len(_warnings), 1)\n             self.assertIn('data will be ignored', str(_warnings[0].message))\n \n+        with warnings.catch_warnings(record=True) as _warnings:\n+            r7 = self.request_class(url=\"http://www.example.com/\", body=None, data=data)\n+            self.assertEqual(r7.body, to_bytes(json.dumps(data)))\n+            self.assertEqual(r7.method, 'POST')\n+            self.assertEqual(len(_warnings), 0)\n+\n+        with warnings.catch_warnings(record=True) as _warnings:\n+            r8 = self.request_class(url=\"http://www.example.com/\", body=None, data=None)\n+            self.assertEqual(r8.method, 'GET')\n+            self.assertEqual(len(_warnings), 0)\n+\n     def tearDown(self):\n         warnings.resetwarnings()\n         super(JSONRequestTest, self).tearDown()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#71ef321b68d2fd202de145d0c580387ee59cd2e2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 61 | Contributors (this commit): 1 | Commits (past 90d): 5 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -21,7 +21,7 @@ class JSONRequest(Request):\n             warnings.warn('Both body and data passed. data will be ignored')\n \n         elif not body_passed and data_passed:\n-            kwargs['body'] = json.dumps(data)\n+            kwargs['body'] = json.dumps(data, sort_keys=True)\n \n             if 'method' not in kwargs:\n                 kwargs['method'] = 'POST'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#8f1507a4a5de2ed55cb0fda198265845a047fedb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 130 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 14 | Methods Changed: 14 | Complexity Δ (Sum/Max): 16/10 | Churn Δ: 135 | Churn Cumulative: 1059 | Contributors (this commit): 15 | Commits (past 90d): 12 | Contributors (cumulative): 16 | DMM Complexity: 0.9795918367346939\n\nDIFF:\n@@ -13,6 +13,7 @@ from scrapy.http.request import Request\n \n class JSONRequest(Request):\n     def __init__(self, *args, **kwargs):\n+        dumps_kwargs = kwargs.pop('dumps_kwargs', {})\n         body_passed = kwargs.get('body', None) is not None\n         data = kwargs.pop('data', None)\n         data_passed = data is not None\n@@ -21,7 +22,7 @@ class JSONRequest(Request):\n             warnings.warn('Both body and data passed. data will be ignored')\n \n         elif not body_passed and data_passed:\n-            kwargs['body'] = json.dumps(data, sort_keys=True)\n+            kwargs['body'] = self.dump(data, **dumps_kwargs)\n \n             if 'method' not in kwargs:\n                 kwargs['method'] = 'POST'\n@@ -29,3 +30,21 @@ class JSONRequest(Request):\n         super(JSONRequest, self).__init__(*args, **kwargs)\n         self.headers.setdefault('Content-Type', 'application/json')\n         self.headers.setdefault('Accept', 'application/json, text/javascript, */*; q=0.01')\n+        self._dumps_kwargs = dumps_kwargs\n+\n+    def replace(self, *args, **kwargs):\n+        body_passed = kwargs.get('body', None) is not None\n+        data = kwargs.pop('data', None)\n+        data_passed = data is not None\n+\n+        if body_passed and data_passed:\n+            warnings.warn('Both body and data passed. data will be ignored')\n+\n+        elif not body_passed and data_passed:\n+            kwargs['body'] = self.dump(data, **self._dumps_kwargs)\n+\n+        return super(JSONRequest, self).replace(*args, **kwargs)\n+\n+    def dump(self, data, **kwargs):\n+        \"\"\"Convert to JSON \"\"\"\n+        return json.dumps(data, sort_keys=True, **kwargs)\n\n@@ -14,6 +14,8 @@ if six.PY3:\n from scrapy.http import Request, FormRequest, XmlRpcRequest, JSONRequest, Headers, HtmlResponse\n from scrapy.utils.python import to_bytes, to_native_str\n \n+from tests import mock\n+\n \n class RequestTest(unittest.TestCase):\n \n@@ -1161,24 +1163,49 @@ class JSONRequestTest(RequestTest):\n     def test_data(self):\n         r1 = self.request_class(url=\"http://www.example.com/\")\n         self.assertEqual(r1.body, b'')\n-        self.assertEqual(r1.method, 'GET')\n \n         body = b'body'\n         r2 = self.request_class(url=\"http://www.example.com/\", body=body)\n         self.assertEqual(r2.body, body)\n-        self.assertEqual(r2.method, 'GET')\n \n         data = {\n             'name': 'value',\n         }\n         r3 = self.request_class(url=\"http://www.example.com/\", data=data)\n         self.assertEqual(r3.body, to_bytes(json.dumps(data)))\n-        self.assertEqual(r3.method, 'POST')\n \n+        # empty data\n         r4 = self.request_class(url=\"http://www.example.com/\", data=[])\n         self.assertEqual(r4.body, to_bytes(json.dumps([])))\n-        self.assertEqual(r4.method, 'POST')\n \n+    def test_data_method(self):\n+        # data is not passed\n+        r1 = self.request_class(url=\"http://www.example.com/\")\n+        self.assertEqual(r1.method, 'GET')\n+\n+        body = b'body'\n+        r2 = self.request_class(url=\"http://www.example.com/\", body=body)\n+        self.assertEqual(r2.method, 'GET')\n+\n+        data = {\n+            'name': 'value',\n+        }\n+        r3 = self.request_class(url=\"http://www.example.com/\", data=data)\n+        self.assertEqual(r3.method, 'POST')\n+\n+        # method passed explicitly\n+        r4 = self.request_class(url=\"http://www.example.com/\", data=data, method='GET')\n+        self.assertEqual(r4.method, 'GET')\n+\n+        r5 = self.request_class(url=\"http://www.example.com/\", data=[])\n+        self.assertEqual(r5.method, 'POST')\n+\n+    def test_body_data(self):\n+        \"\"\" passing both body and data should result a warning \"\"\"\n+        body = b'body'\n+        data = {\n+            'name': 'value',\n+        }\n         with warnings.catch_warnings(record=True) as _warnings:\n             r5 = self.request_class(url=\"http://www.example.com/\", body=body, data=data)\n             self.assertEqual(r5.body, body)\n@@ -1186,6 +1213,11 @@ class JSONRequestTest(RequestTest):\n             self.assertEqual(len(_warnings), 1)\n             self.assertIn('data will be ignored', str(_warnings[0].message))\n \n+    def test_empty_body_data(self):\n+        \"\"\" passing any body value and data should result a warning \"\"\"\n+        data = {\n+            'name': 'value',\n+        }\n         with warnings.catch_warnings(record=True) as _warnings:\n             r6 = self.request_class(url=\"http://www.example.com/\", body=b'', data=data)\n             self.assertEqual(r6.body, b'')\n@@ -1193,17 +1225,91 @@ class JSONRequestTest(RequestTest):\n             self.assertEqual(len(_warnings), 1)\n             self.assertIn('data will be ignored', str(_warnings[0].message))\n \n+    def test_body_none_data(self):\n+        data = {\n+            'name': 'value',\n+        }\n         with warnings.catch_warnings(record=True) as _warnings:\n             r7 = self.request_class(url=\"http://www.example.com/\", body=None, data=data)\n             self.assertEqual(r7.body, to_bytes(json.dumps(data)))\n             self.assertEqual(r7.method, 'POST')\n             self.assertEqual(len(_warnings), 0)\n \n+    def test_body_data_none(self):\n         with warnings.catch_warnings(record=True) as _warnings:\n             r8 = self.request_class(url=\"http://www.example.com/\", body=None, data=None)\n             self.assertEqual(r8.method, 'GET')\n             self.assertEqual(len(_warnings), 0)\n \n+    def test_dumps_sort_keys(self):\n+        \"\"\" Test that sort_keys=True is passed to json.dumps by default \"\"\"\n+        data = {\n+            'name': 'value',\n+        }\n+        with mock.patch('json.dumps', return_value=b'') as mock_dumps:\n+            self.request_class(url=\"http://www.example.com/\", data=data)\n+            kwargs = mock_dumps.call_args[1]\n+            self.assertEqual(kwargs['sort_keys'], True)\n+\n+    def test_dumps_kwargs(self):\n+        \"\"\" Test that dumps_kwargs are passed to json.dumps \"\"\"\n+        data = {\n+            'name': 'value',\n+        }\n+        dumps_kwargs = {\n+            'ensure_ascii': True,\n+            'allow_nan': True,\n+        }\n+        with mock.patch('json.dumps', return_value=b'') as mock_dumps:\n+            self.request_class(url=\"http://www.example.com/\", data=data, dumps_kwargs=dumps_kwargs)\n+            kwargs = mock_dumps.call_args[1]\n+            self.assertEqual(kwargs['ensure_ascii'], True)\n+            self.assertEqual(kwargs['allow_nan'], True)\n+\n+    def test_replace_data(self):\n+        data1 = {\n+            'name1': 'value1',\n+        }\n+        data2 = {\n+            'name2': 'value2',\n+        }\n+        r1 = self.request_class(url=\"http://www.example.com/\", data=data1)\n+        r2 = r1.replace(data=data2)\n+        self.assertEqual(r2.body, to_bytes(json.dumps(data2)))\n+\n+    def test_replace_sort_keys(self):\n+        \"\"\" Test that replace provides sort_keys=True to json.dumps \"\"\"\n+        data1 = {\n+            'name1': 'value1',\n+        }\n+        data2 = {\n+            'name2': 'value2',\n+        }\n+        r1 = self.request_class(url=\"http://www.example.com/\", data=data1)\n+        with mock.patch('json.dumps', return_value=b'') as mock_dumps:\n+            r1.replace(data=data2)\n+            kwargs = mock_dumps.call_args[1]\n+            self.assertEqual(kwargs['sort_keys'], True)\n+\n+    def test_replace_dumps_kwargs(self):\n+        \"\"\" Test that dumps_kwargs are provided json.dumps when replace is called \"\"\"\n+        data1 = {\n+            'name1': 'value1',\n+        }\n+        data2 = {\n+            'name2': 'value2',\n+        }\n+        dumps_kwargs = {\n+            'ensure_ascii': True,\n+            'allow_nan': True,\n+        }\n+        r1 = self.request_class(url=\"http://www.example.com/\", data=data1, dumps_kwargs=dumps_kwargs)\n+        with mock.patch('json.dumps', return_value=b'') as mock_dumps:\n+            r1.replace(data=data2)\n+            kwargs = mock_dumps.call_args[1]\n+            self.assertEqual(kwargs['ensure_ascii'], True)\n+            self.assertEqual(kwargs['allow_nan'], True)\n+\n     def tearDown(self):\n         warnings.resetwarnings()\n         super(JSONRequestTest, self).tearDown()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#cdd04dfb1d9a2e6fd8c188dccae26bbdd3454ebd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 461 | Contributors (this commit): 16 | Commits (past 90d): 1 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -56,6 +56,7 @@ setup(\n         'Programming Language :: Python :: 3.4',\n         'Programming Language :: Python :: 3.5',\n         'Programming Language :: Python :: 3.6',\n+        'Programming Language :: Python :: 3.7',\n         'Programming Language :: Python :: Implementation :: CPython',\n         'Programming Language :: Python :: Implementation :: PyPy',\n         'Topic :: Internet :: WWW/HTTP',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#a5e1b7bb4724bafa26b476a87a9f12b4d6479661", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 10 | Churn Cumulative: 56 | Contributors (this commit): 7 | Commits (past 90d): 1 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -17,6 +17,7 @@ class SitemapSpider(Spider):\n     sitemap_rules = [('', 'parse')]\n     sitemap_follow = ['']\n     sitemap_alternate_links = False\n+    sitemap_filter = None\n \n     def __init__(self, *a, **kw):\n         super(SitemapSpider, self).__init__(*a, **kw)\n@@ -43,12 +44,17 @@ class SitemapSpider(Spider):\n                 return\n \n             s = Sitemap(body)\n+            if callable(self.sitemap_filter):\n+                it = self.sitemap_filter(s)\n+            else:\n+                it = s\n+\n             if s.type == 'sitemapindex':\n-                for loc in iterloc(s, self.sitemap_alternate_links):\n+                for loc in iterloc(it, self.sitemap_alternate_links):\n                     if any(x.search(loc) for x in self._follow):\n                         yield Request(loc, callback=self._parse_sitemap)\n             elif s.type == 'urlset':\n-                for loc in iterloc(s, self.sitemap_alternate_links):\n+                for loc in iterloc(it, self.sitemap_alternate_links):\n                     for r, c in self._cbs:\n                         if r.search(loc):\n                             yield Request(loc, callback=c)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#672385a371453c84faa2f31425e3701b25260629", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 12 | Churn Cumulative: 68 | Contributors (this commit): 7 | Commits (past 90d): 2 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -17,7 +17,6 @@ class SitemapSpider(Spider):\n     sitemap_rules = [('', 'parse')]\n     sitemap_follow = ['']\n     sitemap_alternate_links = False\n-    sitemap_filter = None\n \n     def __init__(self, *a, **kw):\n         super(SitemapSpider, self).__init__(*a, **kw)\n@@ -32,6 +31,14 @@ class SitemapSpider(Spider):\n         for url in self.sitemap_urls:\n             yield Request(url, self._parse_sitemap)\n \n+    def sitemap_filter(self, urls):\n+        \"\"\"This method can be used to filter sitemap entries by their\n+        attributes, for example, you can filter locs with lastmod greater\n+        than a given date (see docs).\n+        \"\"\"\n+        for url in urls:\n+            yield url\n+\n     def _parse_sitemap(self, response):\n         if response.url.endswith('/robots.txt'):\n             for url in sitemap_urls_from_robots(response.text, base_url=response.url):\n@@ -44,10 +51,7 @@ class SitemapSpider(Spider):\n                 return\n \n             s = Sitemap(body)\n-            if callable(self.sitemap_filter):\n             it = self.sitemap_filter(s)\n-            else:\n-                it = s\n \n             if s.type == 'sitemapindex':\n                 for loc in iterloc(it, self.sitemap_alternate_links):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#d7d5917ff12ecb8db7cd04592f7cc18b0ab1a996", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 32 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 32 | Churn Cumulative: 297 | Contributors (this commit): 11 | Commits (past 90d): 1 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -375,6 +375,38 @@ Sitemap: /sitemap-relative-url.xml\n                           'http://www.example.com/schweiz-deutsch/',\n                           'http://www.example.com/italiano/'])\n \n+    def test_sitemap_filter(self):\n+        sitemap = b\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+    <urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\"\n+        xmlns:xhtml=\"http://www.w3.org/1999/xhtml\">\n+        <url>\n+            <loc>http://www.example.com/english/</loc>\n+            <lastmod>2010-01-01</lastmod>\n+        </url>\n+        <url>\n+            <loc>http://www.example.com/portuguese/</loc>\n+            <lastmod>2005-01-01</lastmod>\n+        </url>\n+    </urlset>\"\"\"\n+\n+        class FilteredSitemapSpider(self.spider_class):\n+            def sitemap_filter(self, urls):\n+                from datetime import datetime\n+                for url in urls:\n+                    date_time = datetime.strptime(url['lastmod'], '%Y-%m-%d')\n+                    if date_time.year > 2008:\n+                        yield url\n+\n+        r = TextResponse(url=\"http://www.example.com/sitemap.xml\", body=sitemap)\n+        spider = self.spider_class(\"example.com\")\n+        self.assertEqual([req.url for req in spider._parse_sitemap(r)],\n+                         ['http://www.example.com/english/',\n+                          'http://www.example.com/portuguese/'])\n+\n+        spider = FilteredSitemapSpider(\"example.com\")\n+        self.assertEqual([req.url for req in spider._parse_sitemap(r)],\n+                         ['http://www.example.com/english/'])\n+\n \n class DeprecationTest(unittest.TestCase):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#657f0663b3cb97ca1c1a498c066de444bd30fa82", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 14 | Churn Cumulative: 379 | Contributors (this commit): 12 | Commits (past 90d): 5 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -31,13 +31,13 @@ class SitemapSpider(Spider):\n         for url in self.sitemap_urls:\n             yield Request(url, self._parse_sitemap)\n \n-    def sitemap_filter(self, urls):\n+    def sitemap_filter(self, entries):\n         \"\"\"This method can be used to filter sitemap entries by their\n         attributes, for example, you can filter locs with lastmod greater\n         than a given date (see docs).\n         \"\"\"\n-        for url in urls:\n-            yield url\n+        for entry in entries:\n+            yield entry\n \n     def _parse_sitemap(self, response):\n         if response.url.endswith('/robots.txt'):\n\n@@ -390,12 +390,12 @@ Sitemap: /sitemap-relative-url.xml\n     </urlset>\"\"\"\n \n         class FilteredSitemapSpider(self.spider_class):\n-            def sitemap_filter(self, urls):\n+            def sitemap_filter(self, entries):\n                 from datetime import datetime\n-                for url in urls:\n-                    date_time = datetime.strptime(url['lastmod'], '%Y-%m-%d')\n+                for entry in entries:\n+                    date_time = datetime.strptime(entry['lastmod'], '%Y-%m-%d')\n                     if date_time.year > 2008:\n-                        yield url\n+                        yield entry\n \n         r = TextResponse(url=\"http://www.example.com/sitemap.xml\", body=sitemap)\n         spider = self.spider_class(\"example.com\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#5e7ecf9dc1954060fd0445dce5fb54e020dd3e59", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 31 | Churn Cumulative: 336 | Contributors (this commit): 11 | Commits (past 90d): 3 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -407,6 +407,37 @@ Sitemap: /sitemap-relative-url.xml\n         self.assertEqual([req.url for req in spider._parse_sitemap(r)],\n                          ['http://www.example.com/english/'])\n \n+    def test_sitemapindex_filter(self):\n+        sitemap = b\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+    <sitemapindex xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n+        <sitemap>\n+            <loc>http://www.example.com/sitemap1.xml</loc>\n+            <lastmod>2004-01-01T20:00:00+00:00</lastmod>\n+        </sitemap>\n+        <sitemap>\n+            <loc>http://www.example.com/sitemap2.xml</loc>\n+            <lastmod>2005-01-01</lastmod>\n+        </sitemap>\n+    </sitemapindex>\"\"\"\n+\n+        class FilteredSitemapSpider(self.spider_class):\n+            def sitemap_filter(self, entries):\n+                from datetime import datetime\n+                for entry in entries:\n+                    date_time = datetime.strptime(entry['lastmod'].split('T')[0], '%Y-%m-%d')\n+                    if date_time.year > 2004:\n+                        yield entry\n+\n+        r = TextResponse(url=\"http://www.example.com/sitemap.xml\", body=sitemap)\n+        spider = self.spider_class(\"example.com\")\n+        self.assertEqual([req.url for req in spider._parse_sitemap(r)],\n+                         ['http://www.example.com/sitemap1.xml',\n+                          'http://www.example.com/sitemap2.xml'])\n+\n+        spider = FilteredSitemapSpider(\"example.com\")\n+        self.assertEqual([req.url for req in spider._parse_sitemap(r)],\n+                         ['http://www.example.com/sitemap2.xml'])\n+\n \n class DeprecationTest(unittest.TestCase):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#fe283bcd058734f88977a2033dfa36664e7ee619", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 35 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 35 | Churn Cumulative: 371 | Contributors (this commit): 11 | Commits (past 90d): 4 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -407,6 +407,41 @@ Sitemap: /sitemap-relative-url.xml\n         self.assertEqual([req.url for req in spider._parse_sitemap(r)],\n                          ['http://www.example.com/english/'])\n \n+    def test_sitemap_filter_with_alternate_links(self):\n+        sitemap = b\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+    <urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\"\n+        xmlns:xhtml=\"http://www.w3.org/1999/xhtml\">\n+        <url>\n+            <loc>http://www.example.com/english/article_1/</loc>\n+            <lastmod>2010-01-01</lastmod>\n+            <xhtml:link rel=\"alternate\" hreflang=\"de\"\n+                href=\"http://www.example.com/deutsch/article_1/\"/>\n+        </url>\n+        <url>\n+            <loc>http://www.example.com/english/article_2/</loc>\n+            <lastmod>2015-01-01</lastmod>\n+        </url>\n+    </urlset>\"\"\"\n+\n+        class FilteredSitemapSpider(self.spider_class):\n+            def sitemap_filter(self, entries):\n+                for entry in entries:\n+                    alternate_links = entry.get('alternate', tuple())\n+                    for link in alternate_links:\n+                        if '/deutsch/' in link:\n+                            entry['loc'] = link\n+                            yield entry\n+\n+        r = TextResponse(url=\"http://www.example.com/sitemap.xml\", body=sitemap)\n+        spider = self.spider_class(\"example.com\")\n+        self.assertEqual([req.url for req in spider._parse_sitemap(r)],\n+                         ['http://www.example.com/english/article_1/',\n+                          'http://www.example.com/english/article_2/'])\n+\n+        spider = FilteredSitemapSpider(\"example.com\")\n+        self.assertEqual([req.url for req in spider._parse_sitemap(r)],\n+                         ['http://www.example.com/deutsch/article_1/'])\n+\n     def test_sitemapindex_filter(self):\n         sitemap = b\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n     <sitemapindex xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#6c78b3d5ef94791b11c2ce3dfd5cebd757a68b2a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 10/10 | Churn Δ: 6 | Churn Cumulative: 407 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -3,7 +3,7 @@ Spider Middleware manager\n \n See documentation in docs/topics/spider-middleware.rst\n \"\"\"\n-from itertools import chain\n+from itertools import chain, islice\n \n import six\n from twisted.python.failure import Failure\n@@ -58,7 +58,7 @@ class SpiderMiddlewareManager(MiddlewareManager):\n             # don't handle _InvalidOutput exception\n             if isinstance(exception, _InvalidOutput):\n                 return _failure\n-            method_list = self.methods['process_spider_exception'][start_index:]\n+            method_list = islice(self.methods['process_spider_exception'], start_index, None)\n             for method_index, method in enumerate(method_list, start=start_index):\n                 if method is None:\n                     continue\n@@ -89,7 +89,7 @@ class SpiderMiddlewareManager(MiddlewareManager):\n                         raise\n                     recovered.extend(exception_result)\n \n-            method_list = self.methods['process_spider_output'][start_index:]\n+            method_list = islice(self.methods['process_spider_output'], start_index, None)\n             for method_index, method in enumerate(method_list, start=start_index):\n                 if method is None:\n                     continue\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#50a0d87d1e472fcc514f3dc2b028b653b7826a9c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 1236 | Contributors (this commit): 18 | Commits (past 90d): 2 | Contributors (cumulative): 22 | DMM Complexity: 0.0\n\nDIFF:\n@@ -143,7 +143,7 @@ class Scraper(object):\n     def call_spider(self, result, request, spider):\n         result.request = request\n         dfd = defer_result(result)\n-        dfd.addCallbacks(request.callback or spider.parse, request.errback)\n+        dfd.addCallbacks(request.callback or spider.parse, request.errback, callbackKeywords=request.kwargs)\n         return dfd.addCallback(iterate_spider_output)\n \n     def handle_spider_error(self, _failure, request, response, spider):\n\n@@ -18,7 +18,7 @@ class Request(object_ref):\n \n     def __init__(self, url, callback=None, method='GET', headers=None, body=None,\n                  cookies=None, meta=None, encoding='utf-8', priority=0,\n-                 dont_filter=False, errback=None, flags=None):\n+                 dont_filter=False, errback=None, flags=None, kwargs=None):\n \n         self._encoding = encoding  # this one has to be set first\n         self.method = str(method).upper()\n@@ -41,6 +41,7 @@ class Request(object_ref):\n \n         self._meta = dict(meta) if meta else None\n         self.flags = [] if flags is None else list(flags)\n+        self.kwargs = dict(kwargs) if kwargs else None\n \n     @property\n     def meta(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#a2b509a42266a2ab3389de64b608e616f88f77e5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 775 | Contributors (this commit): 11 | Commits (past 90d): 2 | Contributors (cumulative): 16 | DMM Complexity: 1.0\n\nDIFF:\n@@ -106,7 +106,7 @@ class Response(object_ref):\n \n     def follow(self, url, callback=None, method='GET', headers=None, body=None,\n                cookies=None, meta=None, encoding='utf-8', priority=0,\n-               dont_filter=False, errback=None):\n+               dont_filter=False, errback=None, kwargs=None):\n         # type: (...) -> Request\n         \"\"\"\n         Return a :class:`~.Request` instance to follow a link ``url``.\n@@ -132,4 +132,5 @@ class Response(object_ref):\n                        encoding=encoding,\n                        priority=priority,\n                        dont_filter=dont_filter,\n-                       errback=errback)\n+                       errback=errback,\n+                       kwargs=kwargs)\n\n@@ -123,7 +123,7 @@ class TextResponse(Response):\n \n     def follow(self, url, callback=None, method='GET', headers=None, body=None,\n                cookies=None, meta=None, encoding=None, priority=0,\n-               dont_filter=False, errback=None):\n+               dont_filter=False, errback=None, kwargs=None):\n         # type: (...) -> Request\n         \"\"\"\n         Return a :class:`~.Request` instance to follow a link ``url``.\n@@ -154,7 +154,8 @@ class TextResponse(Response):\n             encoding=encoding,\n             priority=priority,\n             dont_filter=dont_filter,\n-            errback=errback\n+            errback=errback,\n+            kwargs=kwargs,\n         )\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
