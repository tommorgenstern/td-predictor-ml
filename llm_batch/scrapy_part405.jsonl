{"custom_id": "scrapy#380c2279b92f1aa7386e79fc43109499a057e8cf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 502 | Lines Deleted: 559 | Files Changed: 7 | Hunks: 331 | Methods Changed: 223 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 1061 | Churn Cumulative: 15829 | Contributors (this commit): 73 | Commits (past 90d): 38 | Contributors (cumulative): 140 | DMM Complexity: 0.0\n\nDIFF:\n@@ -69,46 +69,46 @@ class OffDH:\n         return cls(crawler)\n \n \n-class LoadTestCase(unittest.TestCase):\n+class TestLoad:\n     def test_enabled_handler(self):\n         handlers = {\"scheme\": DummyDH}\n         crawler = get_crawler(settings_dict={\"DOWNLOAD_HANDLERS\": handlers})\n         dh = DownloadHandlers(crawler)\n-        self.assertIn(\"scheme\", dh._schemes)\n-        self.assertIn(\"scheme\", dh._handlers)\n-        self.assertNotIn(\"scheme\", dh._notconfigured)\n+        assert \"scheme\" in dh._schemes\n+        assert \"scheme\" in dh._handlers\n+        assert \"scheme\" not in dh._notconfigured\n \n     def test_not_configured_handler(self):\n         handlers = {\"scheme\": OffDH}\n         crawler = get_crawler(settings_dict={\"DOWNLOAD_HANDLERS\": handlers})\n         dh = DownloadHandlers(crawler)\n-        self.assertIn(\"scheme\", dh._schemes)\n-        self.assertNotIn(\"scheme\", dh._handlers)\n-        self.assertIn(\"scheme\", dh._notconfigured)\n+        assert \"scheme\" in dh._schemes\n+        assert \"scheme\" not in dh._handlers\n+        assert \"scheme\" in dh._notconfigured\n \n     def test_disabled_handler(self):\n         handlers = {\"scheme\": None}\n         crawler = get_crawler(settings_dict={\"DOWNLOAD_HANDLERS\": handlers})\n         dh = DownloadHandlers(crawler)\n-        self.assertNotIn(\"scheme\", dh._schemes)\n+        assert \"scheme\" not in dh._schemes\n         for scheme in handlers:  # force load handlers\n             dh._get_handler(scheme)\n-        self.assertNotIn(\"scheme\", dh._handlers)\n-        self.assertIn(\"scheme\", dh._notconfigured)\n+        assert \"scheme\" not in dh._handlers\n+        assert \"scheme\" in dh._notconfigured\n \n     def test_lazy_handlers(self):\n         handlers = {\"scheme\": DummyLazyDH}\n         crawler = get_crawler(settings_dict={\"DOWNLOAD_HANDLERS\": handlers})\n         dh = DownloadHandlers(crawler)\n-        self.assertIn(\"scheme\", dh._schemes)\n-        self.assertNotIn(\"scheme\", dh._handlers)\n+        assert \"scheme\" in dh._schemes\n+        assert \"scheme\" not in dh._handlers\n         for scheme in handlers:  # force load lazy handler\n             dh._get_handler(scheme)\n-        self.assertIn(\"scheme\", dh._handlers)\n-        self.assertNotIn(\"scheme\", dh._notconfigured)\n+        assert \"scheme\" in dh._handlers\n+        assert \"scheme\" not in dh._notconfigured\n \n \n-class FileTestCase(unittest.TestCase):\n+class TestFile(unittest.TestCase):\n     def setUp(self):\n         # add a special char to check that they are handled correctly\n         self.fd, self.tmpname = mkstemp(suffix=\"^\")\n@@ -122,10 +122,10 @@ class FileTestCase(unittest.TestCase):\n \n     def test_download(self):\n         def _test(response):\n-            self.assertEqual(response.url, request.url)\n-            self.assertEqual(response.status, 200)\n-            self.assertEqual(response.body, b\"0123456789\")\n-            self.assertEqual(response.protocol, None)\n+            assert response.url == request.url\n+            assert response.status == 200\n+            assert response.body == b\"0123456789\"\n+            assert response.protocol is None\n \n         request = Request(path_to_file_uri(self.tmpname))\n         assert request.url.upper().endswith(\"%5E\")\n@@ -217,7 +217,7 @@ class DuplicateHeaderResource(resource.Resource):\n         return b\"\"\n \n \n-class HttpTestCase(unittest.TestCase, ABC):\n+class TestHttp(unittest.TestCase, ABC):\n     scheme = \"http\"\n \n     # only used for HTTPS tests\n@@ -336,8 +336,8 @@ class HttpTestCase(unittest.TestCase, ABC):\n \n     def test_host_header_not_in_request_headers(self):\n         def _test(response):\n-            self.assertEqual(response.body, to_bytes(f\"{self.host}:{self.portno}\"))\n-            self.assertEqual(request.headers, {})\n+            assert response.body == to_bytes(f\"{self.host}:{self.portno}\")\n+            assert not request.headers\n \n         request = Request(self.getURL(\"host\"))\n         return self.download_request(request, Spider(\"foo\")).addCallback(_test)\n@@ -346,8 +346,8 @@ class HttpTestCase(unittest.TestCase, ABC):\n         host = self.host + \":\" + str(self.portno)\n \n         def _test(response):\n-            self.assertEqual(response.body, host.encode())\n-            self.assertEqual(request.headers.get(\"Host\"), host.encode())\n+            assert response.body == host.encode()\n+            assert request.headers.get(\"Host\") == host.encode()\n \n         request = Request(self.getURL(\"host\"), headers={\"Host\": host})\n         return self.download_request(request, Spider(\"foo\")).addCallback(_test)\n@@ -365,7 +365,7 @@ class HttpTestCase(unittest.TestCase, ABC):\n         \"\"\"\n \n         def _test(response):\n-            self.assertEqual(response.body, b\"0\")\n+            assert response.body == b\"0\"\n \n         request = Request(self.getURL(\"contentlength\"), method=\"POST\")\n         return self.download_request(request, Spider(\"foo\")).addCallback(_test)\n@@ -376,8 +376,8 @@ class HttpTestCase(unittest.TestCase, ABC):\n \n             headers = Headers(json.loads(response.text)[\"headers\"])\n             contentlengths = headers.getlist(\"Content-Length\")\n-            self.assertEqual(len(contentlengths), 1)\n-            self.assertEqual(contentlengths, [b\"0\"])\n+            assert len(contentlengths) == 1\n+            assert contentlengths == [b\"0\"]\n \n         request = Request(self.getURL(\"echo\"), method=\"POST\")\n         return self.download_request(request, Spider(\"foo\")).addCallback(_test)\n@@ -399,7 +399,7 @@ class HttpTestCase(unittest.TestCase, ABC):\n \n     def _test_response_class(self, filename, body, response_class):\n         def _test(response):\n-            self.assertEqual(type(response), response_class)\n+            assert type(response) is response_class  # pylint: disable=unidiomatic-typecheck\n \n         request = Request(self.getURL(filename), body=body)\n         return self.download_request(request, Spider(\"foo\")).addCallback(_test)\n@@ -416,17 +416,14 @@ class HttpTestCase(unittest.TestCase, ABC):\n \n     def test_get_duplicate_header(self):\n         def _test(response):\n-            self.assertEqual(\n-                response.headers.getlist(b\"Set-Cookie\"),\n-                [b\"a=b\", b\"c=d\"],\n-            )\n+            assert response.headers.getlist(b\"Set-Cookie\") == [b\"a=b\", b\"c=d\"]\n \n         request = Request(self.getURL(\"duplicate-header\"))\n         return self.download_request(request, Spider(\"foo\")).addCallback(_test)\n \n \n @pytest.mark.filterwarnings(\"ignore::scrapy.exceptions.ScrapyDeprecationWarning\")\n-class Http10TestCase(HttpTestCase):\n+class TestHttp10(TestHttp):\n     \"\"\"HTTP 1.0 test case\"\"\"\n \n     @property\n@@ -441,11 +438,11 @@ class Http10TestCase(HttpTestCase):\n         return d\n \n \n-class Https10TestCase(Http10TestCase):\n+class TestHttps10(TestHttp10):\n     scheme = \"https\"\n \n \n-class Http11TestCase(HttpTestCase):\n+class TestHttp11(TestHttp):\n     \"\"\"HTTP 1.1 test case\"\"\"\n \n     @property\n@@ -466,7 +463,7 @@ class Http11TestCase(HttpTestCase):\n         body = b\"Some plain text\\ndata with tabs\\t and null bytes\\0\"\n \n         def _test_type(response):\n-            self.assertEqual(type(response), TextResponse)\n+            assert type(response) is TextResponse  # pylint: disable=unidiomatic-typecheck\n \n         request = Request(self.getURL(\"nocontenttype\"), body=body)\n         d = self.download_request(request, Spider(\"foo\"))\n@@ -583,7 +580,7 @@ class Http11TestCase(HttpTestCase):\n         return d\n \n \n-class Https11TestCase(Http11TestCase):\n+class TestHttps11(TestHttp11):\n     scheme = \"https\"\n \n     tls_log_message = (\n@@ -611,7 +608,7 @@ class Https11TestCase(Http11TestCase):\n             yield download_handler.close()\n \n \n-class SimpleHttpsTest(unittest.TestCase):\n+class TestSimpleHttps(unittest.TestCase):\n     \"\"\"Base class for special cases tested with just one simple request\"\"\"\n \n     keyfile = \"keys/localhost.key\"\n@@ -663,7 +660,7 @@ class SimpleHttpsTest(unittest.TestCase):\n         return d\n \n \n-class Https11WrongHostnameTestCase(SimpleHttpsTest):\n+class TestHttps11WrongHostname(TestSimpleHttps):\n     # above tests use a server certificate for \"localhost\",\n     # client connection to \"localhost\" too.\n     # here we test that even if the server certificate is for another domain,\n@@ -673,7 +670,7 @@ class Https11WrongHostnameTestCase(SimpleHttpsTest):\n     certfile = \"keys/example-com.cert.pem\"\n \n \n-class Https11InvalidDNSId(SimpleHttpsTest):\n+class TestHttps11InvalidDNSId(TestSimpleHttps):\n     \"\"\"Connect to HTTPS hosts with IP while certificate uses domain names IDs.\"\"\"\n \n     def setUp(self):\n@@ -681,18 +678,18 @@ class Https11InvalidDNSId(SimpleHttpsTest):\n         self.host = \"127.0.0.1\"\n \n \n-class Https11InvalidDNSPattern(SimpleHttpsTest):\n+class TestHttps11InvalidDNSPattern(TestSimpleHttps):\n     \"\"\"Connect to HTTPS hosts where the certificate are issued to an ip instead of a domain.\"\"\"\n \n     keyfile = \"keys/localhost.ip.key\"\n     certfile = \"keys/localhost.ip.crt\"\n \n \n-class Https11CustomCiphers(SimpleHttpsTest):\n+class TestHttps11CustomCiphers(TestSimpleHttps):\n     cipher_string = \"CAMELLIA256-SHA\"\n \n \n-class Http11MockServerTestCase(unittest.TestCase):\n+class TestHttp11MockServer(unittest.TestCase):\n     \"\"\"HTTP 1.1 test case with MockServer\"\"\"\n \n     settings_dict: dict | None = None\n@@ -719,7 +716,7 @@ class Http11MockServerTestCase(unittest.TestCase):\n             )\n         )\n         failure = crawler.spider.meta[\"failure\"]\n-        self.assertIsInstance(failure.value, defer.CancelledError)\n+        assert isinstance(failure.value, defer.CancelledError)\n \n     @defer.inlineCallbacks\n     def test_download(self):\n@@ -728,9 +725,9 @@ class Http11MockServerTestCase(unittest.TestCase):\n             seed=Request(url=self.mockserver.url(\"\", is_secure=self.is_secure))\n         )\n         failure = crawler.spider.meta.get(\"failure\")\n-        self.assertTrue(failure is None)\n+        assert failure is None\n         reason = crawler.spider.meta[\"close_reason\"]\n-        self.assertTrue(reason, \"finished\")\n+        assert reason == \"finished\"\n \n \n class UriResource(resource.Resource):\n@@ -748,7 +745,7 @@ class UriResource(resource.Resource):\n         return b\"\"\n \n \n-class HttpProxyTestCase(unittest.TestCase, ABC):\n+class TestHttpProxy(unittest.TestCase, ABC):\n     expected_http_proxy_request_body = b\"http://example.com\"\n \n     @property\n@@ -777,9 +774,9 @@ class HttpProxyTestCase(unittest.TestCase, ABC):\n \n     def test_download_with_proxy(self):\n         def _test(response):\n-            self.assertEqual(response.status, 200)\n-            self.assertEqual(response.url, request.url)\n-            self.assertEqual(response.body, self.expected_http_proxy_request_body)\n+            assert response.status == 200\n+            assert response.url == request.url\n+            assert response.body == self.expected_http_proxy_request_body\n \n         http_proxy = self.getURL(\"\")\n         request = Request(\"http://example.com\", meta={\"proxy\": http_proxy})\n@@ -787,22 +784,22 @@ class HttpProxyTestCase(unittest.TestCase, ABC):\n \n     def test_download_without_proxy(self):\n         def _test(response):\n-            self.assertEqual(response.status, 200)\n-            self.assertEqual(response.url, request.url)\n-            self.assertEqual(response.body, b\"/path/to/resource\")\n+            assert response.status == 200\n+            assert response.url == request.url\n+            assert response.body == b\"/path/to/resource\"\n \n         request = Request(self.getURL(\"path/to/resource\"))\n         return self.download_request(request, Spider(\"foo\")).addCallback(_test)\n \n \n @pytest.mark.filterwarnings(\"ignore::scrapy.exceptions.ScrapyDeprecationWarning\")\n-class Http10ProxyTestCase(HttpProxyTestCase):\n+class TestHttp10Proxy(TestHttpProxy):\n     @property\n     def download_handler_cls(self) -> type[DownloadHandlerProtocol]:\n         return HTTP10DownloadHandler\n \n \n-class Http11ProxyTestCase(HttpProxyTestCase):\n+class TestHttp11Proxy(TestHttpProxy):\n     @property\n     def download_handler_cls(self) -> type[DownloadHandlerProtocol]:\n         return HTTP11DownloadHandler\n@@ -817,13 +814,13 @@ class Http11ProxyTestCase(HttpProxyTestCase):\n         request = Request(domain, meta={\"proxy\": http_proxy, \"download_timeout\": 0.2})\n         d = self.download_request(request, Spider(\"foo\"))\n         timeout = yield self.assertFailure(d, error.TimeoutError)\n-        self.assertIn(domain, timeout.osError)\n+        assert domain in timeout.osError\n \n     def test_download_with_proxy_without_http_scheme(self):\n         def _test(response):\n-            self.assertEqual(response.status, 200)\n-            self.assertEqual(response.url, request.url)\n-            self.assertEqual(response.body, self.expected_http_proxy_request_body)\n+            assert response.status == 200\n+            assert response.url == request.url\n+            assert response.body == self.expected_http_proxy_request_body\n \n         http_proxy = self.getURL(\"\").replace(\"http://\", \"\")\n         request = Request(\"http://example.com\", meta={\"proxy\": http_proxy})\n@@ -839,8 +836,8 @@ class HttpDownloadHandlerMock:\n \n \n @pytest.mark.requires_botocore\n-class S3AnonTestCase(unittest.TestCase):\n-    def setUp(self):\n+class TestS3Anon:\n+    def setup_method(self):\n         crawler = get_crawler()\n         self.s3reqh = build_from_crawler(\n             S3DownloadHandler,\n@@ -854,13 +851,13 @@ class S3AnonTestCase(unittest.TestCase):\n     def test_anon_request(self):\n         req = Request(\"s3://aws-publicdatasets/\")\n         httpreq = self.download_request(req, self.spider)\n-        self.assertEqual(hasattr(self.s3reqh, \"anon\"), True)\n-        self.assertEqual(self.s3reqh.anon, True)\n-        self.assertEqual(httpreq.url, \"http://aws-publicdatasets.s3.amazonaws.com/\")\n+        assert hasattr(self.s3reqh, \"anon\")\n+        assert self.s3reqh.anon\n+        assert httpreq.url == \"http://aws-publicdatasets.s3.amazonaws.com/\"\n \n \n @pytest.mark.requires_botocore\n-class S3TestCase(unittest.TestCase):\n+class TestS3:\n     download_handler_cls: type = S3DownloadHandler\n \n     # test use same example keys than amazon developer guide\n@@ -870,7 +867,7 @@ class S3TestCase(unittest.TestCase):\n     AWS_ACCESS_KEY_ID = \"0PN5J17HBGZHT7JJ3X82\"\n     AWS_SECRET_ACCESS_KEY = \"uV3F3YluFJax1cknvbcGwgjvx4QpvB+leU8dUj2o\"\n \n-    def setUp(self):\n+    def setup_method(self):\n         crawler = get_crawler()\n         s3reqh = build_from_crawler(\n             S3DownloadHandler,\n@@ -897,17 +894,13 @@ class S3TestCase(unittest.TestCase):\n                 yield\n \n     def test_extra_kw(self):\n-        try:\n         crawler = get_crawler()\n+        with pytest.raises((TypeError, NotConfigured)):\n             build_from_crawler(\n                 S3DownloadHandler,\n                 crawler,\n                 extra_kw=True,\n             )\n-        except Exception as e:\n-            self.assertIsInstance(e, (TypeError, NotConfigured))\n-        else:\n-            raise AssertionError\n \n     def test_request_signing1(self):\n         # gets an object from the johnsmith bucket.\n@@ -915,9 +908,9 @@ class S3TestCase(unittest.TestCase):\n         req = Request(\"s3://johnsmith/photos/puppy.jpg\", headers={\"Date\": date})\n         with self._mocked_date(date):\n             httpreq = self.download_request(req, self.spider)\n-        self.assertEqual(\n-            httpreq.headers[\"Authorization\"],\n-            b\"AWS 0PN5J17HBGZHT7JJ3X82:xXjDGYUmKxnwqr5KXNPGldn5LbA=\",\n+        assert (\n+            httpreq.headers[\"Authorization\"]\n+            == b\"AWS 0PN5J17HBGZHT7JJ3X82:xXjDGYUmKxnwqr5KXNPGldn5LbA=\"\n         )\n \n     def test_request_signing2(self):\n@@ -934,9 +927,9 @@ class S3TestCase(unittest.TestCase):\n         )\n         with self._mocked_date(date):\n             httpreq = self.download_request(req, self.spider)\n-        self.assertEqual(\n-            httpreq.headers[\"Authorization\"],\n-            b\"AWS 0PN5J17HBGZHT7JJ3X82:hcicpDDvL9SsO6AkvxqmIWkmOuQ=\",\n+        assert (\n+            httpreq.headers[\"Authorization\"]\n+            == b\"AWS 0PN5J17HBGZHT7JJ3X82:hcicpDDvL9SsO6AkvxqmIWkmOuQ=\"\n         )\n \n     def test_request_signing3(self):\n@@ -952,9 +945,9 @@ class S3TestCase(unittest.TestCase):\n         )\n         with self._mocked_date(date):\n             httpreq = self.download_request(req, self.spider)\n-        self.assertEqual(\n-            httpreq.headers[\"Authorization\"],\n-            b\"AWS 0PN5J17HBGZHT7JJ3X82:jsRt/rhG+Vtp88HrYL706QhE4w4=\",\n+        assert (\n+            httpreq.headers[\"Authorization\"]\n+            == b\"AWS 0PN5J17HBGZHT7JJ3X82:jsRt/rhG+Vtp88HrYL706QhE4w4=\"\n         )\n \n     def test_request_signing4(self):\n@@ -963,9 +956,9 @@ class S3TestCase(unittest.TestCase):\n         req = Request(\"s3://johnsmith/?acl\", method=\"GET\", headers={\"Date\": date})\n         with self._mocked_date(date):\n             httpreq = self.download_request(req, self.spider)\n-        self.assertEqual(\n-            httpreq.headers[\"Authorization\"],\n-            b\"AWS 0PN5J17HBGZHT7JJ3X82:thdUi9VAkzhkniLj96JIrOPGi0g=\",\n+        assert (\n+            httpreq.headers[\"Authorization\"]\n+            == b\"AWS 0PN5J17HBGZHT7JJ3X82:thdUi9VAkzhkniLj96JIrOPGi0g=\"\n         )\n \n     def test_request_signing6(self):\n@@ -991,9 +984,9 @@ class S3TestCase(unittest.TestCase):\n         )\n         with self._mocked_date(date):\n             httpreq = self.download_request(req, self.spider)\n-        self.assertEqual(\n-            httpreq.headers[\"Authorization\"],\n-            b\"AWS 0PN5J17HBGZHT7JJ3X82:C0FlOtU8Ylb9KDTpZqYkZPX91iI=\",\n+        assert (\n+            httpreq.headers[\"Authorization\"]\n+            == b\"AWS 0PN5J17HBGZHT7JJ3X82:C0FlOtU8Ylb9KDTpZqYkZPX91iI=\"\n         )\n \n     def test_request_signing7(self):\n@@ -1006,13 +999,13 @@ class S3TestCase(unittest.TestCase):\n         )\n         with self._mocked_date(date):\n             httpreq = self.download_request(req, self.spider)\n-        self.assertEqual(\n-            httpreq.headers[\"Authorization\"],\n-            b\"AWS 0PN5J17HBGZHT7JJ3X82:+CfvG8EZ3YccOrRVMXNaK2eKZmM=\",\n+        assert (\n+            httpreq.headers[\"Authorization\"]\n+            == b\"AWS 0PN5J17HBGZHT7JJ3X82:+CfvG8EZ3YccOrRVMXNaK2eKZmM=\"\n         )\n \n \n-class BaseFTPTestCase(unittest.TestCase):\n+class TestFTPBase(unittest.TestCase):\n     username = \"scrapy\"\n     password = \"passwd\"\n     req_meta = {\"ftp_user\": username, \"ftp_password\": password}\n@@ -1068,10 +1061,10 @@ class BaseFTPTestCase(unittest.TestCase):\n         d = self.download_handler.download_request(request, None)\n \n         def _test(r):\n-            self.assertEqual(r.status, 200)\n-            self.assertEqual(r.body, b\"I have the power!\")\n-            self.assertEqual(r.headers, {b\"Local Filename\": [b\"\"], b\"Size\": [b\"17\"]})\n-            self.assertIsNone(r.protocol)\n+            assert r.status == 200\n+            assert r.body == b\"I have the power!\"\n+            assert r.headers == {b\"Local Filename\": [b\"\"], b\"Size\": [b\"17\"]}\n+            assert r.protocol is None\n \n         return self._add_test_callbacks(d, _test)\n \n@@ -1083,9 +1076,9 @@ class BaseFTPTestCase(unittest.TestCase):\n         d = self.download_handler.download_request(request, None)\n \n         def _test(r):\n-            self.assertEqual(r.status, 200)\n-            self.assertEqual(r.body, b\"Moooooooooo power!\")\n-            self.assertEqual(r.headers, {b\"Local Filename\": [b\"\"], b\"Size\": [b\"18\"]})\n+            assert r.status == 200\n+            assert r.body == b\"Moooooooooo power!\"\n+            assert r.headers == {b\"Local Filename\": [b\"\"], b\"Size\": [b\"18\"]}\n \n         return self._add_test_callbacks(d, _test)\n \n@@ -1096,7 +1089,7 @@ class BaseFTPTestCase(unittest.TestCase):\n         d = self.download_handler.download_request(request, None)\n \n         def _test(r):\n-            self.assertEqual(r.status, 404)\n+            assert r.status == 404\n \n         return self._add_test_callbacks(d, _test)\n \n@@ -1111,12 +1104,10 @@ class BaseFTPTestCase(unittest.TestCase):\n         d = self.download_handler.download_request(request, None)\n \n         def _test(r):\n-            self.assertEqual(r.body, fname_bytes)\n-            self.assertEqual(\n-                r.headers, {b\"Local Filename\": [fname_bytes], b\"Size\": [b\"17\"]}\n-            )\n-            self.assertTrue(local_fname.exists())\n-            self.assertEqual(local_fname.read_bytes(), b\"I have the power!\")\n+            assert r.body == fname_bytes\n+            assert r.headers == {b\"Local Filename\": [fname_bytes], b\"Size\": [b\"17\"]}\n+            assert local_fname.exists()\n+            assert local_fname.read_bytes() == b\"I have the power!\"\n             local_fname.unlink()\n \n         return self._add_test_callbacks(d, _test)\n@@ -1131,7 +1122,7 @@ class BaseFTPTestCase(unittest.TestCase):\n         d = self.download_handler.download_request(request, None)\n \n         def _test(r):\n-            self.assertEqual(type(r), response_class)\n+            assert type(r) is response_class  # pylint: disable=unidiomatic-typecheck\n             local_fname.unlink()\n \n         return self._add_test_callbacks(d, _test)\n@@ -1143,7 +1134,7 @@ class BaseFTPTestCase(unittest.TestCase):\n         return self._test_response_class(\"html-file-without-extension\", HtmlResponse)\n \n \n-class FTPTestCase(BaseFTPTestCase):\n+class TestFTP(TestFTPBase):\n     def test_invalid_credentials(self):\n         if self.reactor_pytest == \"asyncio\" and sys.platform == \"win32\":\n             raise unittest.SkipTest(\n@@ -1157,12 +1148,12 @@ class FTPTestCase(BaseFTPTestCase):\n         d = self.download_handler.download_request(request, None)\n \n         def _test(r):\n-            self.assertEqual(r.type, ConnectionLost)\n+            assert r.type == ConnectionLost\n \n         return self._add_test_callbacks(d, errback=_test)\n \n \n-class AnonymousFTPTestCase(BaseFTPTestCase):\n+class TestAnonymousFTP(TestFTPBase):\n     username = \"anonymous\"\n     req_meta = {}\n \n@@ -1188,7 +1179,7 @@ class AnonymousFTPTestCase(BaseFTPTestCase):\n         shutil.rmtree(self.directory)\n \n \n-class DataURITestCase(unittest.TestCase):\n+class TestDataURI(unittest.TestCase):\n     def setUp(self):\n         crawler = get_crawler()\n         self.download_handler = build_from_crawler(DataURIDownloadHandler, crawler)\n@@ -1199,44 +1190,44 @@ class DataURITestCase(unittest.TestCase):\n         uri = \"data:,A%20brief%20note\"\n \n         def _test(response):\n-            self.assertEqual(response.url, uri)\n-            self.assertFalse(response.headers)\n+            assert response.url == uri\n+            assert not response.headers\n \n         request = Request(uri)\n         return self.download_request(request, self.spider).addCallback(_test)\n \n     def test_default_mediatype_encoding(self):\n         def _test(response):\n-            self.assertEqual(response.text, \"A brief note\")\n-            self.assertEqual(type(response), responsetypes.from_mimetype(\"text/plain\"))\n-            self.assertEqual(response.encoding, \"US-ASCII\")\n+            assert response.text == \"A brief note\"\n+            assert type(response) is responsetypes.from_mimetype(\"text/plain\")  # pylint: disable=unidiomatic-typecheck\n+            assert response.encoding == \"US-ASCII\"\n \n         request = Request(\"data:,A%20brief%20note\")\n         return self.download_request(request, self.spider).addCallback(_test)\n \n     def test_default_mediatype(self):\n         def _test(response):\n-            self.assertEqual(response.text, \"\\u038e\\u03a3\\u038e\")\n-            self.assertEqual(type(response), responsetypes.from_mimetype(\"text/plain\"))\n-            self.assertEqual(response.encoding, \"iso-8859-7\")\n+            assert response.text == \"\\u038e\\u03a3\\u038e\"\n+            assert type(response) is responsetypes.from_mimetype(\"text/plain\")  # pylint: disable=unidiomatic-typecheck\n+            assert response.encoding == \"iso-8859-7\"\n \n         request = Request(\"data:;charset=iso-8859-7,%be%d3%be\")\n         return self.download_request(request, self.spider).addCallback(_test)\n \n     def test_text_charset(self):\n         def _test(response):\n-            self.assertEqual(response.text, \"\\u038e\\u03a3\\u038e\")\n-            self.assertEqual(response.body, b\"\\xbe\\xd3\\xbe\")\n-            self.assertEqual(response.encoding, \"iso-8859-7\")\n+            assert response.text == \"\\u038e\\u03a3\\u038e\"\n+            assert response.body == b\"\\xbe\\xd3\\xbe\"\n+            assert response.encoding == \"iso-8859-7\"\n \n         request = Request(\"data:text/plain;charset=iso-8859-7,%be%d3%be\")\n         return self.download_request(request, self.spider).addCallback(_test)\n \n     def test_mediatype_parameters(self):\n         def _test(response):\n-            self.assertEqual(response.text, \"\\u038e\\u03a3\\u038e\")\n-            self.assertEqual(type(response), responsetypes.from_mimetype(\"text/plain\"))\n-            self.assertEqual(response.encoding, \"utf-8\")\n+            assert response.text == \"\\u038e\\u03a3\\u038e\"\n+            assert type(response) is responsetypes.from_mimetype(\"text/plain\")  # pylint: disable=unidiomatic-typecheck\n+            assert response.encoding == \"utf-8\"\n \n         request = Request(\n             \"data:text/plain;foo=%22foo;bar%5C%22%22;\"\n@@ -1247,14 +1238,14 @@ class DataURITestCase(unittest.TestCase):\n \n     def test_base64(self):\n         def _test(response):\n-            self.assertEqual(response.text, \"Hello, world.\")\n+            assert response.text == \"Hello, world.\"\n \n         request = Request(\"data:text/plain;base64,SGVsbG8sIHdvcmxkLg%3D%3D\")\n         return self.download_request(request, self.spider).addCallback(_test)\n \n     def test_protocol(self):\n         def _test(response):\n-            self.assertIsNone(response.protocol)\n+            assert response.protocol is None\n \n         request = Request(\"data:,\")\n         return self.download_request(request, self.spider).addCallback(_test)\n\n@@ -4,7 +4,6 @@ from unittest import mock\n import pytest\n from testfixtures import LogCapture\n from twisted.internet import defer, error, reactor\n-from twisted.trial import unittest\n from twisted.web import server\n from twisted.web.error import SchemeNotSupported\n from twisted.web.http import H2_ENABLED\n@@ -28,25 +27,25 @@ class BaseTestClasses:\n     # A hack to prevent tests from the imported classes to run here too.\n     # See https://stackoverflow.com/q/1323455/113586 for other ways.\n     from tests.test_downloader_handlers import (\n-        Http11MockServerTestCase as Http11MockServerTestCase,\n+        TestHttp11MockServer as TestHttp11MockServer,\n     )\n     from tests.test_downloader_handlers import (\n-        Http11ProxyTestCase as Http11ProxyTestCase,\n+        TestHttp11Proxy as TestHttp11Proxy,\n     )\n     from tests.test_downloader_handlers import (\n-        Https11CustomCiphers as Https11CustomCiphers,\n+        TestHttps11 as TestHttps11,\n     )\n     from tests.test_downloader_handlers import (\n-        Https11InvalidDNSId as Https11InvalidDNSId,\n+        TestHttps11CustomCiphers as TestHttps11CustomCiphers,\n     )\n     from tests.test_downloader_handlers import (\n-        Https11InvalidDNSPattern as Https11InvalidDNSPattern,\n+        TestHttps11InvalidDNSId as TestHttps11InvalidDNSId,\n     )\n     from tests.test_downloader_handlers import (\n-        Https11TestCase as Https11TestCase,\n+        TestHttps11InvalidDNSPattern as TestHttps11InvalidDNSPattern,\n     )\n     from tests.test_downloader_handlers import (\n-        Https11WrongHostnameTestCase as Https11WrongHostnameTestCase,\n+        TestHttps11WrongHostname as TestHttps11WrongHostname,\n     )\n \n \n@@ -56,7 +55,7 @@ def _get_dh() -> type[DownloadHandlerProtocol]:\n     return H2DownloadHandler\n \n \n-class Https2TestCase(BaseTestClasses.Https11TestCase):\n+class TestHttps2(BaseTestClasses.TestHttps11):\n     scheme = \"https\"\n     HTTP2_DATALOSS_SKIP_REASON = \"Content-Length mismatch raises InvalidBodyLengthError\"\n \n@@ -97,22 +96,22 @@ class Https2TestCase(BaseTestClasses.Https11TestCase):\n         yield self.assertFailure(d, SchemeNotSupported)\n \n     def test_download_broken_content_cause_data_loss(self, url=\"broken\"):\n-        raise unittest.SkipTest(self.HTTP2_DATALOSS_SKIP_REASON)\n+        pytest.skip(self.HTTP2_DATALOSS_SKIP_REASON)\n \n     def test_download_broken_chunked_content_cause_data_loss(self):\n-        raise unittest.SkipTest(self.HTTP2_DATALOSS_SKIP_REASON)\n+        pytest.skip(self.HTTP2_DATALOSS_SKIP_REASON)\n \n     def test_download_broken_content_allow_data_loss(self, url=\"broken\"):\n-        raise unittest.SkipTest(self.HTTP2_DATALOSS_SKIP_REASON)\n+        pytest.skip(self.HTTP2_DATALOSS_SKIP_REASON)\n \n     def test_download_broken_chunked_content_allow_data_loss(self):\n-        raise unittest.SkipTest(self.HTTP2_DATALOSS_SKIP_REASON)\n+        pytest.skip(self.HTTP2_DATALOSS_SKIP_REASON)\n \n     def test_download_broken_content_allow_data_loss_via_setting(self, url=\"broken\"):\n-        raise unittest.SkipTest(self.HTTP2_DATALOSS_SKIP_REASON)\n+        pytest.skip(self.HTTP2_DATALOSS_SKIP_REASON)\n \n     def test_download_broken_chunked_content_allow_data_loss_via_setting(self):\n-        raise unittest.SkipTest(self.HTTP2_DATALOSS_SKIP_REASON)\n+        pytest.skip(self.HTTP2_DATALOSS_SKIP_REASON)\n \n     def test_concurrent_requests_same_domain(self):\n         spider = Spider(\"foo\")\n@@ -180,31 +179,31 @@ class Https2TestCase(BaseTestClasses.Https11TestCase):\n         return d\n \n \n-class Https2WrongHostnameTestCase(BaseTestClasses.Https11WrongHostnameTestCase):\n+class Https2WrongHostnameTestCase(BaseTestClasses.TestHttps11WrongHostname):\n     @property\n     def download_handler_cls(self) -> type[DownloadHandlerProtocol]:\n         return _get_dh()\n \n \n-class Https2InvalidDNSId(BaseTestClasses.Https11InvalidDNSId):\n+class Https2InvalidDNSId(BaseTestClasses.TestHttps11InvalidDNSId):\n     @property\n     def download_handler_cls(self) -> type[DownloadHandlerProtocol]:\n         return _get_dh()\n \n \n-class Https2InvalidDNSPattern(BaseTestClasses.Https11InvalidDNSPattern):\n+class Https2InvalidDNSPattern(BaseTestClasses.TestHttps11InvalidDNSPattern):\n     @property\n     def download_handler_cls(self) -> type[DownloadHandlerProtocol]:\n         return _get_dh()\n \n \n-class Https2CustomCiphers(BaseTestClasses.Https11CustomCiphers):\n+class Https2CustomCiphers(BaseTestClasses.TestHttps11CustomCiphers):\n     @property\n     def download_handler_cls(self) -> type[DownloadHandlerProtocol]:\n         return _get_dh()\n \n \n-class Http2MockServerTestCase(BaseTestClasses.Http11MockServerTestCase):\n+class Http2MockServerTestCase(BaseTestClasses.TestHttp11MockServer):\n     \"\"\"HTTP 2.0 test case with MockServer\"\"\"\n \n     settings_dict = {\n@@ -215,7 +214,7 @@ class Http2MockServerTestCase(BaseTestClasses.Http11MockServerTestCase):\n     is_secure = True\n \n \n-class Https2ProxyTestCase(BaseTestClasses.Http11ProxyTestCase):\n+class Https2ProxyTestCase(BaseTestClasses.TestHttp11Proxy):\n     # only used for HTTPS tests\n     keyfile = \"keys/localhost.key\"\n     certfile = \"keys/localhost.crt\"\n\n@@ -54,11 +54,11 @@ class CustomFieldDataclass:\n     age: int = dataclasses.field(metadata={\"serializer\": custom_serializer})\n \n \n-class BaseItemExporterTest(unittest.TestCase):\n+class TestBaseItemExporter:\n     item_class: type = MyItem\n     custom_field_item_class: type = CustomFieldItem\n \n-    def setUp(self):\n+    def setup_method(self):\n         self.i = self.item_class(name=\"John\\xa3\", age=\"22\")\n         self.output = BytesIO()\n         self.ie = self._get_exporter()\n@@ -72,7 +72,7 @@ class BaseItemExporterTest(unittest.TestCase):\n     def _assert_expected_item(self, exported_dict):\n         for k, v in exported_dict.items():\n             exported_dict[k] = to_unicode(v)\n-        self.assertEqual(self.i, self.item_class(**exported_dict))\n+        assert self.i == self.item_class(**exported_dict)\n \n     def _get_nonstring_types_item(self):\n         return {\n@@ -105,45 +105,40 @@ class BaseItemExporterTest(unittest.TestCase):\n     def test_serialize_field(self):\n         a = ItemAdapter(self.i)\n         res = self.ie.serialize_field(a.get_field_meta(\"name\"), \"name\", a[\"name\"])\n-        self.assertEqual(res, \"John\\xa3\")\n+        assert res == \"John\\xa3\"\n \n         res = self.ie.serialize_field(a.get_field_meta(\"age\"), \"age\", a[\"age\"])\n-        self.assertEqual(res, \"22\")\n+        assert res == \"22\"\n \n     def test_fields_to_export(self):\n         ie = self._get_exporter(fields_to_export=[\"name\"])\n-        self.assertEqual(\n-            list(ie._get_serialized_fields(self.i)), [(\"name\", \"John\\xa3\")]\n-        )\n+        assert list(ie._get_serialized_fields(self.i)) == [(\"name\", \"John\\xa3\")]\n \n         ie = self._get_exporter(fields_to_export=[\"name\"], encoding=\"latin-1\")\n         _, name = next(iter(ie._get_serialized_fields(self.i)))\n         assert isinstance(name, str)\n-        self.assertEqual(name, \"John\\xa3\")\n+        assert name == \"John\\xa3\"\n \n         ie = self._get_exporter(fields_to_export={\"name\": \"名稱\"})\n-        self.assertEqual(\n-            list(ie._get_serialized_fields(self.i)), [(\"名稱\", \"John\\xa3\")]\n-        )\n+        assert list(ie._get_serialized_fields(self.i)) == [(\"名稱\", \"John\\xa3\")]\n \n     def test_field_custom_serializer(self):\n         i = self.custom_field_item_class(name=\"John\\xa3\", age=\"22\")\n         a = ItemAdapter(i)\n         ie = self._get_exporter()\n-        self.assertEqual(\n-            ie.serialize_field(a.get_field_meta(\"name\"), \"name\", a[\"name\"]), \"John\\xa3\"\n-        )\n-        self.assertEqual(\n-            ie.serialize_field(a.get_field_meta(\"age\"), \"age\", a[\"age\"]), \"24\"\n+        assert (\n+            ie.serialize_field(a.get_field_meta(\"name\"), \"name\", a[\"name\"])\n+            == \"John\\xa3\"\n         )\n+        assert ie.serialize_field(a.get_field_meta(\"age\"), \"age\", a[\"age\"]) == \"24\"\n \n \n-class BaseItemExporterDataclassTest(BaseItemExporterTest):\n+class TestBaseItemExporterDataclass(TestBaseItemExporter):\n     item_class = MyDataClass\n     custom_field_item_class = CustomFieldDataclass\n \n \n-class PythonItemExporterTest(BaseItemExporterTest):\n+class TestPythonItemExporter(TestBaseItemExporter):\n     def _get_exporter(self, **kwargs):\n         return PythonItemExporter(**kwargs)\n \n@@ -157,16 +152,13 @@ class PythonItemExporterTest(BaseItemExporterTest):\n         i3 = self.item_class(name=\"Jesus\", age=i2)\n         ie = self._get_exporter()\n         exported = ie.export_item(i3)\n-        self.assertEqual(type(exported), dict)\n-        self.assertEqual(\n-            exported,\n-            {\n+        assert isinstance(exported, dict)\n+        assert exported == {\n             \"age\": {\"age\": {\"age\": \"22\", \"name\": \"Joseph\"}, \"name\": \"Maria\"},\n             \"name\": \"Jesus\",\n-            },\n-        )\n-        self.assertEqual(type(exported[\"age\"]), dict)\n-        self.assertEqual(type(exported[\"age\"][\"age\"]), dict)\n+        }\n+        assert isinstance(exported[\"age\"], dict)\n+        assert isinstance(exported[\"age\"][\"age\"], dict)\n \n     def test_export_list(self):\n         i1 = self.item_class(name=\"Joseph\", age=\"22\")\n@@ -174,15 +166,12 @@ class PythonItemExporterTest(BaseItemExporterTest):\n         i3 = self.item_class(name=\"Jesus\", age=[i2])\n         ie = self._get_exporter()\n         exported = ie.export_item(i3)\n-        self.assertEqual(\n-            exported,\n-            {\n+        assert exported == {\n             \"age\": [{\"age\": [{\"age\": \"22\", \"name\": \"Joseph\"}], \"name\": \"Maria\"}],\n             \"name\": \"Jesus\",\n-            },\n-        )\n-        self.assertEqual(type(exported[\"age\"][0]), dict)\n-        self.assertEqual(type(exported[\"age\"][0][\"age\"][0]), dict)\n+        }\n+        assert isinstance(exported[\"age\"][0], dict)\n+        assert isinstance(exported[\"age\"][0][\"age\"][0], dict)\n \n     def test_export_item_dict_list(self):\n         i1 = self.item_class(name=\"Joseph\", age=\"22\")\n@@ -190,29 +179,26 @@ class PythonItemExporterTest(BaseItemExporterTest):\n         i3 = self.item_class(name=\"Jesus\", age=[i2])\n         ie = self._get_exporter()\n         exported = ie.export_item(i3)\n-        self.assertEqual(\n-            exported,\n-            {\n+        assert exported == {\n             \"age\": [{\"age\": [{\"age\": \"22\", \"name\": \"Joseph\"}], \"name\": \"Maria\"}],\n             \"name\": \"Jesus\",\n-            },\n-        )\n-        self.assertEqual(type(exported[\"age\"][0]), dict)\n-        self.assertEqual(type(exported[\"age\"][0][\"age\"][0]), dict)\n+        }\n+        assert isinstance(exported[\"age\"][0], dict)\n+        assert isinstance(exported[\"age\"][0][\"age\"][0], dict)\n \n     def test_nonstring_types_item(self):\n         item = self._get_nonstring_types_item()\n         ie = self._get_exporter()\n         exported = ie.export_item(item)\n-        self.assertEqual(exported, item)\n+        assert exported == item\n \n \n-class PythonItemExporterDataclassTest(PythonItemExporterTest):\n+class TestPythonItemExporterDataclass(TestPythonItemExporter):\n     item_class = MyDataClass\n     custom_field_item_class = CustomFieldDataclass\n \n \n-class PprintItemExporterTest(BaseItemExporterTest):\n+class TestPprintItemExporter(TestBaseItemExporter):\n     def _get_exporter(self, **kwargs):\n         return PprintItemExporter(self.output, **kwargs)\n \n@@ -222,12 +208,12 @@ class PprintItemExporterTest(BaseItemExporterTest):\n         )\n \n \n-class PprintItemExporterDataclassTest(PprintItemExporterTest):\n+class TestPprintItemExporterDataclass(TestPprintItemExporter):\n     item_class = MyDataClass\n     custom_field_item_class = CustomFieldDataclass\n \n \n-class PickleItemExporterTest(BaseItemExporterTest):\n+class TestPickleItemExporter(TestBaseItemExporter):\n     def _get_exporter(self, **kwargs):\n         return PickleItemExporter(self.output, **kwargs)\n \n@@ -245,8 +231,8 @@ class PickleItemExporterTest(BaseItemExporterTest):\n         ie.finish_exporting()\n         del ie  # See the first “del self.ie” in this file for context.\n         f.seek(0)\n-        self.assertEqual(self.item_class(**pickle.load(f)), i1)\n-        self.assertEqual(self.item_class(**pickle.load(f)), i2)\n+        assert self.item_class(**pickle.load(f)) == i1\n+        assert self.item_class(**pickle.load(f)) == i2\n \n     def test_nonstring_types_item(self):\n         item = self._get_nonstring_types_item()\n@@ -256,15 +242,15 @@ class PickleItemExporterTest(BaseItemExporterTest):\n         ie.export_item(item)\n         ie.finish_exporting()\n         del ie  # See the first “del self.ie” in this file for context.\n-        self.assertEqual(pickle.loads(fp.getvalue()), item)\n+        assert pickle.loads(fp.getvalue()) == item\n \n \n-class PickleItemExporterDataclassTest(PickleItemExporterTest):\n+class TestPickleItemExporterDataclass(TestPickleItemExporter):\n     item_class = MyDataClass\n     custom_field_item_class = CustomFieldDataclass\n \n \n-class MarshalItemExporterTest(BaseItemExporterTest):\n+class TestMarshalItemExporter(TestBaseItemExporter):\n     def _get_exporter(self, **kwargs):\n         self.output = tempfile.TemporaryFile()\n         return MarshalItemExporter(self.output, **kwargs)\n@@ -283,15 +269,15 @@ class MarshalItemExporterTest(BaseItemExporterTest):\n         ie.finish_exporting()\n         del ie  # See the first “del self.ie” in this file for context.\n         fp.seek(0)\n-        self.assertEqual(marshal.load(fp), item)\n+        assert marshal.load(fp) == item\n \n \n-class MarshalItemExporterDataclassTest(MarshalItemExporterTest):\n+class TestMarshalItemExporterDataclass(TestMarshalItemExporter):\n     item_class = MyDataClass\n     custom_field_item_class = CustomFieldDataclass\n \n \n-class CsvItemExporterTest(BaseItemExporterTest):\n+class TestCsvItemExporter(TestBaseItemExporter):\n     def _get_exporter(self, **kwargs):\n         self.output = tempfile.TemporaryFile()\n         return CsvItemExporter(self.output, **kwargs)\n@@ -303,7 +289,7 @@ class CsvItemExporterTest(BaseItemExporterTest):\n                 for line in to_unicode(csv).splitlines(True)\n             ]\n \n-        return self.assertEqual(split_csv(first), split_csv(second), msg=msg)\n+        assert split_csv(first) == split_csv(second), msg\n \n     def _check_output(self):\n         self.output.seek(0)\n@@ -406,12 +392,12 @@ class CsvItemExporterTest(BaseItemExporterTest):\n         )\n \n \n-class CsvItemExporterDataclassTest(CsvItemExporterTest):\n+class TestCsvItemExporterDataclass(TestCsvItemExporter):\n     item_class = MyDataClass\n     custom_field_item_class = CustomFieldDataclass\n \n \n-class XmlItemExporterTest(BaseItemExporterTest):\n+class TestXmlItemExporter(TestBaseItemExporter):\n     def _get_exporter(self, **kwargs):\n         return XmlItemExporter(self.output, **kwargs)\n \n@@ -426,7 +412,7 @@ class XmlItemExporterTest(BaseItemExporterTest):\n             doc = lxml.etree.fromstring(xmlcontent)\n             return xmltuple(doc)\n \n-        return self.assertEqual(xmlsplit(first), xmlsplit(second), msg)\n+        assert xmlsplit(first) == xmlsplit(second), msg\n \n     def assertExportResult(self, item, expected_value):\n         fp = BytesIO()\n@@ -517,12 +503,12 @@ class XmlItemExporterTest(BaseItemExporterTest):\n         )\n \n \n-class XmlItemExporterDataclassTest(XmlItemExporterTest):\n+class TestXmlItemExporterDataclass(TestXmlItemExporter):\n     item_class = MyDataClass\n     custom_field_item_class = CustomFieldDataclass\n \n \n-class JsonLinesItemExporterTest(BaseItemExporterTest):\n+class TestJsonLinesItemExporter(TestBaseItemExporter):\n     _expected_nested: Any = {\n         \"name\": \"Jesus\",\n         \"age\": {\"name\": \"Maria\", \"age\": {\"name\": \"Joseph\", \"age\": \"22\"}},\n@@ -533,7 +519,7 @@ class JsonLinesItemExporterTest(BaseItemExporterTest):\n \n     def _check_output(self):\n         exported = json.loads(to_unicode(self.output.getvalue().strip()))\n-        self.assertEqual(exported, ItemAdapter(self.i).asdict())\n+        assert exported == ItemAdapter(self.i).asdict()\n \n     def test_nested_item(self):\n         i1 = self.item_class(name=\"Joseph\", age=\"22\")\n@@ -544,7 +530,7 @@ class JsonLinesItemExporterTest(BaseItemExporterTest):\n         self.ie.finish_exporting()\n         del self.ie  # See the first “del self.ie” in this file for context.\n         exported = json.loads(to_unicode(self.output.getvalue()))\n-        self.assertEqual(exported, self._expected_nested)\n+        assert exported == self._expected_nested\n \n     def test_extra_keywords(self):\n         self.ie = self._get_exporter(sort_keys=True)\n@@ -561,23 +547,23 @@ class JsonLinesItemExporterTest(BaseItemExporterTest):\n         del self.ie  # See the first “del self.ie” in this file for context.\n         exported = json.loads(to_unicode(self.output.getvalue()))\n         item[\"time\"] = str(item[\"time\"])\n-        self.assertEqual(exported, item)\n+        assert exported == item\n \n \n-class JsonLinesItemExporterDataclassTest(JsonLinesItemExporterTest):\n+class TestJsonLinesItemExporterDataclass(TestJsonLinesItemExporter):\n     item_class = MyDataClass\n     custom_field_item_class = CustomFieldDataclass\n \n \n-class JsonItemExporterTest(JsonLinesItemExporterTest):\n-    _expected_nested = [JsonLinesItemExporterTest._expected_nested]\n+class TestJsonItemExporter(TestJsonLinesItemExporter):\n+    _expected_nested = [TestJsonLinesItemExporter._expected_nested]\n \n     def _get_exporter(self, **kwargs):\n         return JsonItemExporter(self.output, **kwargs)\n \n     def _check_output(self):\n         exported = json.loads(to_unicode(self.output.getvalue().strip()))\n-        self.assertEqual(exported, [ItemAdapter(self.i).asdict()])\n+        assert exported == [ItemAdapter(self.i).asdict()]\n \n     def assertTwoItemsExported(self, item):\n         self.ie.start_exporting()\n@@ -586,9 +572,7 @@ class JsonItemExporterTest(JsonLinesItemExporterTest):\n         self.ie.finish_exporting()\n         del self.ie  # See the first “del self.ie” in this file for context.\n         exported = json.loads(to_unicode(self.output.getvalue()))\n-        self.assertEqual(\n-            exported, [ItemAdapter(item).asdict(), ItemAdapter(item).asdict()]\n-        )\n+        assert exported == [ItemAdapter(item).asdict(), ItemAdapter(item).asdict()]\n \n     def test_two_items(self):\n         self.assertTwoItemsExported(self.i)\n@@ -609,7 +593,7 @@ class JsonItemExporterTest(JsonLinesItemExporterTest):\n         self.ie.export_item(i3)\n         self.ie.finish_exporting()\n         exported = json.loads(to_unicode(self.output.getvalue()))\n-        self.assertEqual(exported, [dict(i1), dict(i3)])\n+        assert exported == [dict(i1), dict(i3)]\n \n     def test_nested_item(self):\n         i1 = self.item_class(name=\"Joseph\\xa3\", age=\"22\")\n@@ -624,7 +608,7 @@ class JsonItemExporterTest(JsonLinesItemExporterTest):\n             \"name\": \"Jesus\",\n             \"age\": {\"name\": \"Maria\", \"age\": ItemAdapter(i1).asdict()},\n         }\n-        self.assertEqual(exported, [expected])\n+        assert exported == [expected]\n \n     def test_nested_dict_item(self):\n         i1 = {\"name\": \"Joseph\\xa3\", \"age\": \"22\"}\n@@ -636,7 +620,7 @@ class JsonItemExporterTest(JsonLinesItemExporterTest):\n         del self.ie  # See the first “del self.ie” in this file for context.\n         exported = json.loads(to_unicode(self.output.getvalue()))\n         expected = {\"name\": \"Jesus\", \"age\": {\"name\": \"Maria\", \"age\": i1}}\n-        self.assertEqual(exported, [expected])\n+        assert exported == [expected]\n \n     def test_nonstring_types_item(self):\n         item = self._get_nonstring_types_item()\n@@ -646,10 +630,10 @@ class JsonItemExporterTest(JsonLinesItemExporterTest):\n         del self.ie  # See the first “del self.ie” in this file for context.\n         exported = json.loads(to_unicode(self.output.getvalue()))\n         item[\"time\"] = str(item[\"time\"])\n-        self.assertEqual(exported, [item])\n+        assert exported == [item]\n \n \n-class JsonItemExporterToBytesTest(BaseItemExporterTest):\n+class TestJsonItemExporterToBytes(TestBaseItemExporter):\n     def _get_exporter(self, **kwargs):\n         kwargs[\"encoding\"] = \"latin\"\n         return JsonItemExporter(self.output, **kwargs)\n@@ -665,18 +649,18 @@ class JsonItemExporterToBytesTest(BaseItemExporterTest):\n         self.ie.export_item(i3)\n         self.ie.finish_exporting()\n         exported = json.loads(to_unicode(self.output.getvalue(), encoding=\"latin\"))\n-        self.assertEqual(exported, [dict(i1), dict(i3)])\n+        assert exported == [dict(i1), dict(i3)]\n \n \n-class JsonItemExporterDataclassTest(JsonItemExporterTest):\n+class TestJsonItemExporterDataclass(TestJsonItemExporter):\n     item_class = MyDataClass\n     custom_field_item_class = CustomFieldDataclass\n \n \n-class CustomExporterItemTest(unittest.TestCase):\n+class TestCustomExporterItem:\n     item_class: type = MyItem\n \n-    def setUp(self):\n+    def setup_method(self):\n         if self.item_class is None:\n             raise unittest.SkipTest(\"item class is None\")\n \n@@ -691,17 +675,13 @@ class CustomExporterItemTest(unittest.TestCase):\n         a = ItemAdapter(i)\n         ie = CustomItemExporter()\n \n-        self.assertEqual(\n-            ie.serialize_field(a.get_field_meta(\"name\"), \"name\", a[\"name\"]), \"John\"\n-        )\n-        self.assertEqual(\n-            ie.serialize_field(a.get_field_meta(\"age\"), \"age\", a[\"age\"]), \"23\"\n-        )\n+        assert ie.serialize_field(a.get_field_meta(\"name\"), \"name\", a[\"name\"]) == \"John\"\n+        assert ie.serialize_field(a.get_field_meta(\"age\"), \"age\", a[\"age\"]) == \"23\"\n \n         i2 = {\"name\": \"John\", \"age\": \"22\"}\n-        self.assertEqual(ie.serialize_field({}, \"name\", i2[\"name\"]), \"John\")\n-        self.assertEqual(ie.serialize_field({}, \"age\", i2[\"age\"]), \"23\")\n+        assert ie.serialize_field({}, \"name\", i2[\"name\"]) == \"John\"\n+        assert ie.serialize_field({}, \"age\", i2[\"age\"]) == \"23\"\n \n \n-class CustomExporterDataclassTest(CustomExporterItemTest):\n+class TestCustomExporterDataclass(TestCustomExporterItem):\n     item_class = MyDataClass\n\n@@ -88,7 +88,7 @@ def mock_google_cloud_storage() -> tuple[Any, Any, Any]:\n     return (client_mock, bucket_mock, blob_mock)\n \n \n-class FileFeedStorageTest(unittest.TestCase):\n+class TestFileFeedStorage(unittest.TestCase):\n     def test_store_file_uri(self):\n         path = Path(self.mktemp()).resolve()\n         uri = path_to_file_uri(str(path))\n@@ -137,14 +137,14 @@ class FileFeedStorageTest(unittest.TestCase):\n         file = storage.open(spider)\n         file.write(b\"content\")\n         yield storage.store(file)\n-        self.assertTrue(path.exists())\n+        assert path.exists()\n         try:\n-            self.assertEqual(path.read_bytes(), expected_content)\n+            assert path.read_bytes() == expected_content\n         finally:\n             path.unlink()\n \n \n-class FTPFeedStorageTest(unittest.TestCase):\n+class TestFTPFeedStorage(unittest.TestCase):\n     def get_test_spider(self, settings=None):\n         class TestSpider(scrapy.Spider):\n             name = \"test_spider\"\n@@ -166,9 +166,9 @@ class FTPFeedStorageTest(unittest.TestCase):\n         return storage.store(file)\n \n     def _assert_stored(self, path: Path, content):\n-        self.assertTrue(path.exists())\n+        assert path.exists()\n         try:\n-            self.assertEqual(path.read_bytes(), content)\n+            assert path.read_bytes() == content\n         finally:\n             path.unlink()\n \n@@ -216,10 +216,10 @@ class FTPFeedStorageTest(unittest.TestCase):\n         # RFC3986: 3.2.1. User Information\n         pw_quoted = quote(string.punctuation, safe=\"\")\n         st = FTPFeedStorage(f\"ftp://foo:{pw_quoted}@example.com/some_path\", {})\n-        self.assertEqual(st.password, string.punctuation)\n+        assert st.password == string.punctuation\n \n \n-class BlockingFeedStorageTest(unittest.TestCase):\n+class TestBlockingFeedStorage:\n     def get_test_spider(self, settings=None):\n         class TestSpider(scrapy.Spider):\n             name = \"test_spider\"\n@@ -232,7 +232,7 @@ class BlockingFeedStorageTest(unittest.TestCase):\n \n         tmp = b.open(self.get_test_spider())\n         tmp_path = Path(tmp.name).parent\n-        self.assertEqual(str(tmp_path), tempfile.gettempdir())\n+        assert str(tmp_path) == tempfile.gettempdir()\n \n     def test_temp_file(self):\n         b = BlockingFeedStorage()\n@@ -241,7 +241,7 @@ class BlockingFeedStorageTest(unittest.TestCase):\n         spider = self.get_test_spider({\"FEED_TEMPDIR\": str(tests_path)})\n         tmp = b.open(spider)\n         tmp_path = Path(tmp.name).parent\n-        self.assertEqual(tmp_path, tests_path)\n+        assert tmp_path == tests_path\n \n     def test_invalid_folder(self):\n         b = BlockingFeedStorage()\n@@ -255,7 +255,7 @@ class BlockingFeedStorageTest(unittest.TestCase):\n \n \n @pytest.mark.requires_boto3\n-class S3FeedStorageTest(unittest.TestCase):\n+class TestS3FeedStorage(unittest.TestCase):\n     def test_parse_credentials(self):\n         aws_credentials = {\n             \"AWS_ACCESS_KEY_ID\": \"settings_key\",\n@@ -268,9 +268,9 @@ class S3FeedStorageTest(unittest.TestCase):\n             crawler,\n             \"s3://mybucket/export.csv\",\n         )\n-        self.assertEqual(storage.access_key, \"settings_key\")\n-        self.assertEqual(storage.secret_key, \"settings_secret\")\n-        self.assertEqual(storage.session_token, \"settings_token\")\n+        assert storage.access_key == \"settings_key\"\n+        assert storage.secret_key == \"settings_secret\"\n+        assert storage.session_token == \"settings_token\"\n         # Instantiate directly\n         storage = S3FeedStorage(\n             \"s3://mybucket/export.csv\",\n@@ -278,17 +278,17 @@ class S3FeedStorageTest(unittest.TestCase):\n             aws_credentials[\"AWS_SECRET_ACCESS_KEY\"],\n             session_token=aws_credentials[\"AWS_SESSION_TOKEN\"],\n         )\n-        self.assertEqual(storage.access_key, \"settings_key\")\n-        self.assertEqual(storage.secret_key, \"settings_secret\")\n-        self.assertEqual(storage.session_token, \"settings_token\")\n+        assert storage.access_key == \"settings_key\"\n+        assert storage.secret_key == \"settings_secret\"\n+        assert storage.session_token == \"settings_token\"\n         # URI priority > settings priority\n         storage = S3FeedStorage(\n             \"s3://uri_key:uri_secret@mybucket/export.csv\",\n             aws_credentials[\"AWS_ACCESS_KEY_ID\"],\n             aws_credentials[\"AWS_SECRET_ACCESS_KEY\"],\n         )\n-        self.assertEqual(storage.access_key, \"uri_key\")\n-        self.assertEqual(storage.secret_key, \"uri_secret\")\n+        assert storage.access_key == \"uri_key\"\n+        assert storage.secret_key == \"uri_secret\"\n \n     @defer.inlineCallbacks\n     def test_store(self):\n@@ -306,24 +306,23 @@ class S3FeedStorageTest(unittest.TestCase):\n \n         storage.s3_client = mock.MagicMock()\n         yield storage.store(file)\n-        self.assertEqual(\n-            storage.s3_client.upload_fileobj.call_args,\n-            mock.call(Bucket=bucket, Key=key, Fileobj=file),\n+        assert storage.s3_client.upload_fileobj.call_args == mock.call(\n+            Bucket=bucket, Key=key, Fileobj=file\n         )\n \n     def test_init_without_acl(self):\n         storage = S3FeedStorage(\"s3://mybucket/export.csv\", \"access_key\", \"secret_key\")\n-        self.assertEqual(storage.access_key, \"access_key\")\n-        self.assertEqual(storage.secret_key, \"secret_key\")\n-        self.assertEqual(storage.acl, None)\n+        assert storage.access_key == \"access_key\"\n+        assert storage.secret_key == \"secret_key\"\n+        assert storage.acl is None\n \n     def test_init_with_acl(self):\n         storage = S3FeedStorage(\n             \"s3://mybucket/export.csv\", \"access_key\", \"secret_key\", \"custom-acl\"\n         )\n-        self.assertEqual(storage.access_key, \"access_key\")\n-        self.assertEqual(storage.secret_key, \"secret_key\")\n-        self.assertEqual(storage.acl, \"custom-acl\")\n+        assert storage.access_key == \"access_key\"\n+        assert storage.secret_key == \"secret_key\"\n+        assert storage.acl == \"custom-acl\"\n \n     def test_init_with_endpoint_url(self):\n         storage = S3FeedStorage(\n@@ -332,9 +331,9 @@ class S3FeedStorageTest(unittest.TestCase):\n             \"secret_key\",\n             endpoint_url=\"https://example.com\",\n         )\n-        self.assertEqual(storage.access_key, \"access_key\")\n-        self.assertEqual(storage.secret_key, \"secret_key\")\n-        self.assertEqual(storage.endpoint_url, \"https://example.com\")\n+        assert storage.access_key == \"access_key\"\n+        assert storage.secret_key == \"secret_key\"\n+        assert storage.endpoint_url == \"https://example.com\"\n \n     def test_init_with_region_name(self):\n         region_name = \"ap-east-1\"\n@@ -344,10 +343,10 @@ class S3FeedStorageTest(unittest.TestCase):\n             \"secret_key\",\n             region_name=region_name,\n         )\n-        self.assertEqual(storage.access_key, \"access_key\")\n-        self.assertEqual(storage.secret_key, \"secret_key\")\n-        self.assertEqual(storage.region_name, region_name)\n-        self.assertEqual(storage.s3_client._client_config.region_name, region_name)\n+        assert storage.access_key == \"access_key\"\n+        assert storage.secret_key == \"secret_key\"\n+        assert storage.region_name == region_name\n+        assert storage.s3_client._client_config.region_name == region_name\n \n     def test_from_crawler_without_acl(self):\n         settings = {\n@@ -359,9 +358,9 @@ class S3FeedStorageTest(unittest.TestCase):\n             crawler,\n             \"s3://mybucket/export.csv\",\n         )\n-        self.assertEqual(storage.access_key, \"access_key\")\n-        self.assertEqual(storage.secret_key, \"secret_key\")\n-        self.assertEqual(storage.acl, None)\n+        assert storage.access_key == \"access_key\"\n+        assert storage.secret_key == \"secret_key\"\n+        assert storage.acl is None\n \n     def test_without_endpoint_url(self):\n         settings = {\n@@ -373,9 +372,9 @@ class S3FeedStorageTest(unittest.TestCase):\n             crawler,\n             \"s3://mybucket/export.csv\",\n         )\n-        self.assertEqual(storage.access_key, \"access_key\")\n-        self.assertEqual(storage.secret_key, \"secret_key\")\n-        self.assertEqual(storage.endpoint_url, None)\n+        assert storage.access_key == \"access_key\"\n+        assert storage.secret_key == \"secret_key\"\n+        assert storage.endpoint_url is None\n \n     def test_without_region_name(self):\n         settings = {\n@@ -387,9 +386,9 @@ class S3FeedStorageTest(unittest.TestCase):\n             crawler,\n             \"s3://mybucket/export.csv\",\n         )\n-        self.assertEqual(storage.access_key, \"access_key\")\n-        self.assertEqual(storage.secret_key, \"secret_key\")\n-        self.assertEqual(storage.s3_client._client_config.region_name, \"us-east-1\")\n+        assert storage.access_key == \"access_key\"\n+        assert storage.secret_key == \"secret_key\"\n+        assert storage.s3_client._client_config.region_name == \"us-east-1\"\n \n     def test_from_crawler_with_acl(self):\n         settings = {\n@@ -402,9 +401,9 @@ class S3FeedStorageTest(unittest.TestCase):\n             crawler,\n             \"s3://mybucket/export.csv\",\n         )\n-        self.assertEqual(storage.access_key, \"access_key\")\n-        self.assertEqual(storage.secret_key, \"secret_key\")\n-        self.assertEqual(storage.acl, \"custom-acl\")\n+        assert storage.access_key == \"access_key\"\n+        assert storage.secret_key == \"secret_key\"\n+        assert storage.acl == \"custom-acl\"\n \n     def test_from_crawler_with_endpoint_url(self):\n         settings = {\n@@ -414,9 +413,9 @@ class S3FeedStorageTest(unittest.TestCase):\n         }\n         crawler = get_crawler(settings_dict=settings)\n         storage = S3FeedStorage.from_crawler(crawler, \"s3://mybucket/export.csv\")\n-        self.assertEqual(storage.access_key, \"access_key\")\n-        self.assertEqual(storage.secret_key, \"secret_key\")\n-        self.assertEqual(storage.endpoint_url, \"https://example.com\")\n+        assert storage.access_key == \"access_key\"\n+        assert storage.secret_key == \"secret_key\"\n+        assert storage.endpoint_url == \"https://example.com\"\n \n     def test_from_crawler_with_region_name(self):\n         region_name = \"ap-east-1\"\n@@ -427,10 +426,10 @@ class S3FeedStorageTest(unittest.TestCase):\n         }\n         crawler = get_crawler(settings_dict=settings)\n         storage = S3FeedStorage.from_crawler(crawler, \"s3://mybucket/export.csv\")\n-        self.assertEqual(storage.access_key, \"access_key\")\n-        self.assertEqual(storage.secret_key, \"secret_key\")\n-        self.assertEqual(storage.region_name, region_name)\n-        self.assertEqual(storage.s3_client._client_config.region_name, region_name)\n+        assert storage.access_key == \"access_key\"\n+        assert storage.secret_key == \"secret_key\"\n+        assert storage.region_name == region_name\n+        assert storage.s3_client._client_config.region_name == region_name\n \n     @defer.inlineCallbacks\n     def test_store_without_acl(self):\n@@ -439,9 +438,9 @@ class S3FeedStorageTest(unittest.TestCase):\n             \"access_key\",\n             \"secret_key\",\n         )\n-        self.assertEqual(storage.access_key, \"access_key\")\n-        self.assertEqual(storage.secret_key, \"secret_key\")\n-        self.assertEqual(storage.acl, None)\n+        assert storage.access_key == \"access_key\"\n+        assert storage.secret_key == \"secret_key\"\n+        assert storage.acl is None\n \n         storage.s3_client = mock.MagicMock()\n         yield storage.store(BytesIO(b\"test file\"))\n@@ -450,28 +449,28 @@ class S3FeedStorageTest(unittest.TestCase):\n             .get(\"ExtraArgs\", {})\n             .get(\"ACL\")\n         )\n-        self.assertIsNone(acl)\n+        assert acl is None\n \n     @defer.inlineCallbacks\n     def test_store_with_acl(self):\n         storage = S3FeedStorage(\n             \"s3://mybucket/export.csv\", \"access_key\", \"secret_key\", \"custom-acl\"\n         )\n-        self.assertEqual(storage.access_key, \"access_key\")\n-        self.assertEqual(storage.secret_key, \"secret_key\")\n-        self.assertEqual(storage.acl, \"custom-acl\")\n+        assert storage.access_key == \"access_key\"\n+        assert storage.secret_key == \"secret_key\"\n+        assert storage.acl == \"custom-acl\"\n \n         storage.s3_client = mock.MagicMock()\n         yield storage.store(BytesIO(b\"test file\"))\n         acl = storage.s3_client.upload_fileobj.call_args[1][\"ExtraArgs\"][\"ACL\"]\n-        self.assertEqual(acl, \"custom-acl\")\n+        assert acl == \"custom-acl\"\n \n     def test_overwrite_default(self):\n         with LogCapture() as log:\n             S3FeedStorage(\n                 \"s3://mybucket/export.csv\", \"access_key\", \"secret_key\", \"custom-acl\"\n             )\n-        self.assertNotIn(\"S3 does not support appending to files\", str(log))\n+        assert \"S3 does not support appending to files\" not in str(log)\n \n     def test_overwrite_false(self):\n         with LogCapture() as log:\n@@ -482,10 +481,10 @@ class S3FeedStorageTest(unittest.TestCase):\n                 \"custom-acl\",\n                 feed_options={\"overwrite\": False},\n             )\n-        self.assertIn(\"S3 does not support appending to files\", str(log))\n+        assert \"S3 does not support appending to files\" in str(log)\n \n \n-class GCSFeedStorageTest(unittest.TestCase):\n+class TestGCSFeedStorage(unittest.TestCase):\n     def test_parse_settings(self):\n         try:\n             from google.cloud.storage import Client  # noqa: F401\n@@ -543,7 +542,7 @@ class GCSFeedStorageTest(unittest.TestCase):\n     def test_overwrite_default(self):\n         with LogCapture() as log:\n             GCSFeedStorage(\"gs://mybucket/export.csv\", \"myproject-123\", \"custom-acl\")\n-        self.assertNotIn(\"GCS does not support appending to files\", str(log))\n+        assert \"GCS does not support appending to files\" not in str(log)\n \n     def test_overwrite_false(self):\n         with LogCapture() as log:\n@@ -553,10 +552,10 @@ class GCSFeedStorageTest(unittest.TestCase):\n                 \"custom-acl\",\n                 feed_options={\"overwrite\": False},\n             )\n-        self.assertIn(\"GCS does not support appending to files\", str(log))\n+        assert \"GCS does not support appending to files\" in str(log)\n \n \n-class StdoutFeedStorageTest(unittest.TestCase):\n+class TestStdoutFeedStorage(unittest.TestCase):\n     @defer.inlineCallbacks\n     def test_store(self):\n         out = BytesIO()\n@@ -564,20 +563,21 @@ class StdoutFeedStorageTest(unittest.TestCase):\n         file = storage.open(scrapy.Spider(\"default\"))\n         file.write(b\"content\")\n         yield storage.store(file)\n-        self.assertEqual(out.getvalue(), b\"content\")\n+        assert out.getvalue() == b\"content\"\n \n     def test_overwrite_default(self):\n         with LogCapture() as log:\n             StdoutFeedStorage(\"stdout:\")\n-        self.assertNotIn(\n-            \"Standard output (stdout) storage does not support overwriting\", str(log)\n+        assert (\n+            \"Standard output (stdout) storage does not support overwriting\"\n+            not in str(log)\n         )\n \n     def test_overwrite_true(self):\n         with LogCapture() as log:\n             StdoutFeedStorage(\"stdout:\", feed_options={\"overwrite\": True})\n-        self.assertIn(\n-            \"Standard output (stdout) storage does not support overwriting\", str(log)\n+        assert \"Standard output (stdout) storage does not support overwriting\" in str(\n+            log\n         )\n \n \n@@ -639,7 +639,7 @@ class LogOnStoreFileStorage:\n         file.close()\n \n \n-class FeedExportTestBase(ABC, unittest.TestCase):\n+class TestFeedExportBase(ABC, unittest.TestCase):\n     class MyItem(scrapy.Item):\n         foo = scrapy.Field()\n         egg = scrapy.Field()\n@@ -769,7 +769,7 @@ class ExceptionJsonItemExporter(JsonItemExporter):\n         raise RuntimeError(\"foo\")\n \n \n-class FeedExportTest(FeedExportTestBase):\n+class TestFeedExport(TestFeedExportBase):\n     @defer.inlineCallbacks\n     def run_and_export(self, spider_cls, settings):\n         \"\"\"Run spider with specified settings; return exported data.\"\"\"\n@@ -812,8 +812,8 @@ class FeedExportTest(FeedExportTestBase):\n         )\n         data = yield self.exported_data(items, settings)\n         reader = csv.DictReader(to_unicode(data[\"csv\"]).splitlines())\n-        self.assertEqual(reader.fieldnames, list(header))\n-        self.assertEqual(rows, list(reader))\n+        assert reader.fieldnames == list(header)\n+        assert rows == list(reader)\n \n     @defer.inlineCallbacks\n     def assertExportedJsonLines(self, items, rows, settings=None):\n@@ -828,7 +828,7 @@ class FeedExportTest(FeedExportTestBase):\n         data = yield self.exported_data(items, settings)\n         parsed = [json.loads(to_unicode(line)) for line in data[\"jl\"].splitlines()]\n         rows = [{k: v for k, v in row.items() if v} for row in rows]\n-        self.assertEqual(rows, parsed)\n+        assert rows == parsed\n \n     @defer.inlineCallbacks\n     def assertExportedXml(self, items, rows, settings=None):\n@@ -844,7 +844,7 @@ class FeedExportTest(FeedExportTestBase):\n         rows = [{k: v for k, v in row.items() if v} for row in rows]\n         root = lxml.etree.fromstring(data[\"xml\"])\n         got_rows = [{e.tag: e.text for e in it} for it in root.findall(\"item\")]\n-        self.assertEqual(rows, got_rows)\n+        assert rows == got_rows\n \n     @defer.inlineCallbacks\n     def assertExportedMultiple(self, items, rows, settings=None):\n@@ -862,10 +862,10 @@ class FeedExportTest(FeedExportTestBase):\n         # XML\n         root = lxml.etree.fromstring(data[\"xml\"])\n         xml_rows = [{e.tag: e.text for e in it} for it in root.findall(\"item\")]\n-        self.assertEqual(rows, xml_rows)\n+        assert rows == xml_rows\n         # JSON\n         json_rows = json.loads(to_unicode(data[\"json\"]))\n-        self.assertEqual(rows, json_rows)\n+        assert rows == json_rows\n \n     @defer.inlineCallbacks\n     def assertExportedPickle(self, items, rows, settings=None):\n@@ -882,7 +882,7 @@ class FeedExportTest(FeedExportTestBase):\n         import pickle\n \n         result = self._load_until_eof(data[\"pickle\"], load_func=pickle.load)\n-        self.assertEqual(expected, result)\n+        assert result == expected\n \n     @defer.inlineCallbacks\n     def assertExportedMarshal(self, items, rows, settings=None):\n@@ -899,7 +899,7 @@ class FeedExportTest(FeedExportTestBase):\n         import marshal\n \n         result = self._load_until_eof(data[\"marshal\"], load_func=marshal.load)\n-        self.assertEqual(expected, result)\n+        assert result == expected\n \n     @defer.inlineCallbacks\n     def test_stats_file_success(self):\n@@ -912,12 +912,8 @@ class FeedExportTest(FeedExportTestBase):\n         }\n         crawler = get_crawler(ItemSpider, settings)\n         yield crawler.crawl(mockserver=self.mockserver)\n-        self.assertIn(\n-            \"feedexport/success_count/FileFeedStorage\", crawler.stats.get_stats()\n-        )\n-        self.assertEqual(\n-            crawler.stats.get_value(\"feedexport/success_count/FileFeedStorage\"), 1\n-        )\n+        assert \"feedexport/success_count/FileFeedStorage\" in crawler.stats.get_stats()\n+        assert crawler.stats.get_value(\"feedexport/success_count/FileFeedStorage\") == 1\n \n     @defer.inlineCallbacks\n     def test_stats_file_failed(self):\n@@ -934,12 +930,8 @@ class FeedExportTest(FeedExportTestBase):\n             side_effect=KeyError(\"foo\"),\n         ):\n             yield crawler.crawl(mockserver=self.mockserver)\n-        self.assertIn(\n-            \"feedexport/failed_count/FileFeedStorage\", crawler.stats.get_stats()\n-        )\n-        self.assertEqual(\n-            crawler.stats.get_value(\"feedexport/failed_count/FileFeedStorage\"), 1\n-        )\n+        assert \"feedexport/failed_count/FileFeedStorage\" in crawler.stats.get_stats()\n+        assert crawler.stats.get_value(\"feedexport/failed_count/FileFeedStorage\") == 1\n \n     @defer.inlineCallbacks\n     def test_stats_multiple_file(self):\n@@ -956,17 +948,11 @@ class FeedExportTest(FeedExportTestBase):\n         crawler = get_crawler(ItemSpider, settings)\n         with mock.patch.object(S3FeedStorage, \"store\"):\n             yield crawler.crawl(mockserver=self.mockserver)\n-        self.assertIn(\n-            \"feedexport/success_count/FileFeedStorage\", crawler.stats.get_stats()\n-        )\n-        self.assertIn(\n-            \"feedexport/success_count/StdoutFeedStorage\", crawler.stats.get_stats()\n-        )\n-        self.assertEqual(\n-            crawler.stats.get_value(\"feedexport/success_count/FileFeedStorage\"), 1\n-        )\n-        self.assertEqual(\n-            crawler.stats.get_value(\"feedexport/success_count/StdoutFeedStorage\"), 1\n+        assert \"feedexport/success_count/FileFeedStorage\" in crawler.stats.get_stats()\n+        assert \"feedexport/success_count/StdoutFeedStorage\" in crawler.stats.get_stats()\n+        assert crawler.stats.get_value(\"feedexport/success_count/FileFeedStorage\") == 1\n+        assert (\n+            crawler.stats.get_value(\"feedexport/success_count/StdoutFeedStorage\") == 1\n         )\n \n     @defer.inlineCallbacks\n@@ -993,7 +979,7 @@ class FeedExportTest(FeedExportTestBase):\n                 \"FEED_STORE_EMPTY\": False,\n             }\n             data = yield self.exported_no_data(settings)\n-            self.assertEqual(None, data[fmt])\n+            assert data[fmt] is None\n \n     @defer.inlineCallbacks\n     def test_start_finish_exporting_items(self):\n@@ -1012,8 +998,8 @@ class FeedExportTest(FeedExportTestBase):\n \n         with mock.patch(\"scrapy.extensions.feedexport.FeedSlot\", InstrumentedFeedSlot):\n             _ = yield self.exported_data(items, settings)\n-            self.assertFalse(listener.start_without_finish)\n-            self.assertFalse(listener.finish_without_start)\n+            assert not listener.start_without_finish\n+            assert not listener.finish_without_start\n \n     @defer.inlineCallbacks\n     def test_start_finish_exporting_no_items(self):\n@@ -1030,8 +1016,8 @@ class FeedExportTest(FeedExportTestBase):\n \n         with mock.patch(\"scrapy.extensions.feedexport.FeedSlot\", InstrumentedFeedSlot):\n             _ = yield self.exported_data(items, settings)\n-            self.assertFalse(listener.start_without_finish)\n-            self.assertFalse(listener.finish_without_start)\n+            assert not listener.start_without_finish\n+            assert not listener.finish_without_start\n \n     @defer.inlineCallbacks\n     def test_start_finish_exporting_items_exception(self):\n@@ -1051,8 +1037,8 @@ class FeedExportTest(FeedExportTestBase):\n \n         with mock.patch(\"scrapy.extensions.feedexport.FeedSlot\", InstrumentedFeedSlot):\n             _ = yield self.exported_data(items, settings)\n-            self.assertFalse(listener.start_without_finish)\n-            self.assertFalse(listener.finish_without_start)\n+            assert not listener.start_without_finish\n+            assert not listener.finish_without_start\n \n     @defer.inlineCallbacks\n     def test_start_finish_exporting_no_items_exception(self):\n@@ -1070,8 +1056,8 @@ class FeedExportTest(FeedExportTestBase):\n \n         with mock.patch(\"scrapy.extensions.feedexport.FeedSlot\", InstrumentedFeedSlot):\n             _ = yield self.exported_data(items, settings)\n-            self.assertFalse(listener.start_without_finish)\n-            self.assertFalse(listener.finish_without_start)\n+            assert not listener.start_without_finish\n+            assert not listener.finish_without_start\n \n     @defer.inlineCallbacks\n     def test_export_no_items_store_empty(self):\n@@ -1091,7 +1077,7 @@ class FeedExportTest(FeedExportTestBase):\n                 \"FEED_EXPORT_INDENT\": None,\n             }\n             data = yield self.exported_no_data(settings)\n-            self.assertEqual(expctd, data[fmt])\n+            assert expctd == data[fmt]\n \n     @defer.inlineCallbacks\n     def test_export_no_items_multiple_feeds(self):\n@@ -1109,7 +1095,7 @@ class FeedExportTest(FeedExportTestBase):\n         with LogCapture() as log:\n             yield self.exported_no_data(settings)\n \n-        self.assertEqual(str(log).count(\"Storage.store is called\"), 0)\n+        assert str(log).count(\"Storage.store is called\") == 0\n \n     @defer.inlineCallbacks\n     def test_export_multiple_item_classes(self):\n@@ -1238,7 +1224,7 @@ class FeedExportTest(FeedExportTestBase):\n \n         data = yield self.exported_data(items, settings)\n         for fmt, expected in formats.items():\n-            self.assertEqual(expected, data[fmt])\n+            assert data[fmt] == expected\n \n     @defer.inlineCallbacks\n     def test_export_based_on_custom_filters(self):\n@@ -1297,7 +1283,7 @@ class FeedExportTest(FeedExportTestBase):\n \n         data = yield self.exported_data(items, settings)\n         for fmt, expected in formats.items():\n-            self.assertEqual(expected, data[fmt])\n+            assert data[fmt] == expected\n \n     @defer.inlineCallbacks\n     def test_export_dicts(self):\n@@ -1371,7 +1357,7 @@ class FeedExportTest(FeedExportTestBase):\n                 \"FEED_EXPORT_INDENT\": None,\n             }\n             data = yield self.exported_data(items, settings)\n-            self.assertEqual(expected, data[fmt])\n+            assert data[fmt] == expected\n \n         formats = {\n             \"json\": b'[{\"foo\": \"Test\\xd6\"}]',\n@@ -1392,7 +1378,7 @@ class FeedExportTest(FeedExportTestBase):\n                 \"FEED_EXPORT_ENCODING\": \"latin-1\",\n             }\n             data = yield self.exported_data(items, settings)\n-            self.assertEqual(expected, data[fmt])\n+            assert data[fmt] == expected\n \n     @defer.inlineCallbacks\n     def test_export_multiple_configs(self):\n@@ -1432,7 +1418,7 @@ class FeedExportTest(FeedExportTestBase):\n \n         data = yield self.exported_data(items, settings)\n         for fmt, expected in formats.items():\n-            self.assertEqual(expected, data[fmt])\n+            assert data[fmt] == expected\n \n     @defer.inlineCallbacks\n     def test_export_indentation(self):\n@@ -1588,7 +1574,7 @@ class FeedExportTest(FeedExportTestBase):\n                 },\n             }\n             data = yield self.exported_data(items, settings)\n-            self.assertEqual(row[\"expected\"], data[row[\"format\"]])\n+            assert data[row[\"format\"]] == row[\"expected\"]\n \n     @defer.inlineCallbacks\n     def test_init_exporters_storages_with_crawler(self):\n@@ -1600,8 +1586,8 @@ class FeedExportTest(FeedExportTestBase):\n             },\n         }\n         yield self.exported_data(items=[], settings=settings)\n-        self.assertTrue(FromCrawlerCsvItemExporter.init_with_crawler)\n-        self.assertTrue(FromCrawlerFileFeedStorage.init_with_crawler)\n+        assert FromCrawlerCsvItemExporter.init_with_crawler\n+        assert FromCrawlerFileFeedStorage.init_with_crawler\n \n     @defer.inlineCallbacks\n     def test_str_uri(self):\n@@ -1610,7 +1596,7 @@ class FeedExportTest(FeedExportTestBase):\n             \"FEEDS\": {str(self._random_temp_filename()): {\"format\": \"csv\"}},\n         }\n         data = yield self.exported_no_data(settings)\n-        self.assertEqual(data[\"csv\"], b\"\")\n+        assert data[\"csv\"] == b\"\"\n \n     @defer.inlineCallbacks\n     def test_multiple_feeds_success_logs_blocking_feed_storage(self):\n@@ -1631,7 +1617,7 @@ class FeedExportTest(FeedExportTestBase):\n \n         print(log)\n         for fmt in [\"json\", \"xml\", \"csv\"]:\n-            self.assertIn(f\"Stored {fmt} feed (2 items)\", str(log))\n+            assert f\"Stored {fmt} feed (2 items)\" in str(log)\n \n     @defer.inlineCallbacks\n     def test_multiple_feeds_failing_logs_blocking_feed_storage(self):\n@@ -1652,7 +1638,7 @@ class FeedExportTest(FeedExportTestBase):\n \n         print(log)\n         for fmt in [\"json\", \"xml\", \"csv\"]:\n-            self.assertIn(f\"Error storing {fmt} feed (2 items)\", str(log))\n+            assert f\"Error storing {fmt} feed (2 items)\" in str(log)\n \n     @defer.inlineCallbacks\n     def test_extend_kwargs(self):\n@@ -1689,7 +1675,7 @@ class FeedExportTest(FeedExportTestBase):\n             }\n \n             data = yield self.exported_data(items, settings)\n-            self.assertEqual(row[\"expected\"], data[feed_options[\"format\"]])\n+            assert data[feed_options[\"format\"]] == row[\"expected\"]\n \n     @defer.inlineCallbacks\n     def test_storage_file_no_postprocessing(self):\n@@ -1711,7 +1697,7 @@ class FeedExportTest(FeedExportTestBase):\n             \"FEED_STORAGES\": {\"file\": Storage},\n         }\n         yield self.exported_no_data(settings)\n-        self.assertIs(Storage.open_file, Storage.store_file)\n+        assert Storage.open_file is Storage.store_file\n \n     @defer.inlineCallbacks\n     def test_storage_file_postprocessing(self):\n@@ -1741,11 +1727,11 @@ class FeedExportTest(FeedExportTestBase):\n             \"FEED_STORAGES\": {\"file\": Storage},\n         }\n         yield self.exported_no_data(settings)\n-        self.assertIs(Storage.open_file, Storage.store_file)\n-        self.assertFalse(Storage.file_was_closed)\n+        assert Storage.open_file is Storage.store_file\n+        assert not Storage.file_was_closed\n \n \n-class FeedPostProcessedExportsTest(FeedExportTestBase):\n+class TestFeedPostProcessedExports(TestFeedExportBase):\n     items = [{\"foo\": \"bar\"}]\n     expected = b\"foo\\r\\nbar\\r\\n\"\n \n@@ -1827,7 +1813,7 @@ class FeedPostProcessedExportsTest(FeedExportTestBase):\n         try:\n             gzip.decompress(data[filename])\n         except OSError:\n-            self.fail(\"Received invalid gzip data.\")\n+            pytest.fail(\"Received invalid gzip data.\")\n \n     @defer.inlineCallbacks\n     def test_gzip_plugin_compresslevel(self):\n@@ -1863,8 +1849,8 @@ class FeedPostProcessedExportsTest(FeedExportTestBase):\n \n         for filename, compressed in filename_to_compressed.items():\n             result = gzip.decompress(data[filename])\n-            self.assertEqual(compressed, data[filename])\n-            self.assertEqual(self.expected, result)\n+            assert compressed == data[filename]\n+            assert result == self.expected\n \n     @defer.inlineCallbacks\n     def test_gzip_plugin_mtime(self):\n@@ -1898,8 +1884,8 @@ class FeedPostProcessedExportsTest(FeedExportTestBase):\n \n         for filename, compressed in filename_to_compressed.items():\n             result = gzip.decompress(data[filename])\n-            self.assertEqual(compressed, data[filename])\n-            self.assertEqual(self.expected, result)\n+            assert compressed == data[filename]\n+            assert result == self.expected\n \n     @defer.inlineCallbacks\n     def test_gzip_plugin_filename(self):\n@@ -1933,8 +1919,8 @@ class FeedPostProcessedExportsTest(FeedExportTestBase):\n \n         for filename, compressed in filename_to_compressed.items():\n             result = gzip.decompress(data[filename])\n-            self.assertEqual(compressed, data[filename])\n-            self.assertEqual(self.expected, result)\n+            assert compressed == data[filename]\n+            assert result == self.expected\n \n     @defer.inlineCallbacks\n     def test_lzma_plugin(self):\n@@ -1953,7 +1939,7 @@ class FeedPostProcessedExportsTest(FeedExportTestBase):\n         try:\n             lzma.decompress(data[filename])\n         except lzma.LZMAError:\n-            self.fail(\"Received invalid lzma data.\")\n+            pytest.fail(\"Received invalid lzma data.\")\n \n     @defer.inlineCallbacks\n     def test_lzma_plugin_format(self):\n@@ -1985,8 +1971,8 @@ class FeedPostProcessedExportsTest(FeedExportTestBase):\n \n         for filename, compressed in filename_to_compressed.items():\n             result = lzma.decompress(data[filename])\n-            self.assertEqual(compressed, data[filename])\n-            self.assertEqual(self.expected, result)\n+            assert compressed == data[filename]\n+            assert result == self.expected\n \n     @defer.inlineCallbacks\n     def test_lzma_plugin_check(self):\n@@ -2018,8 +2004,8 @@ class FeedPostProcessedExportsTest(FeedExportTestBase):\n \n         for filename, compressed in filename_to_compressed.items():\n             result = lzma.decompress(data[filename])\n-            self.assertEqual(compressed, data[filename])\n-            self.assertEqual(self.expected, result)\n+            assert compressed == data[filename]\n+            assert result == self.expected\n \n     @defer.inlineCallbacks\n     def test_lzma_plugin_preset(self):\n@@ -2051,8 +2037,8 @@ class FeedPostProcessedExportsTest(FeedExportTestBase):\n \n         for filename, compressed in filename_to_compressed.items():\n             result = lzma.decompress(data[filename])\n-            self.assertEqual(compressed, data[filename])\n-            self.assertEqual(self.expected, result)\n+            assert compressed == data[filename]\n+            assert result == self.expected\n \n     @defer.inlineCallbacks\n     def test_lzma_plugin_filters(self):\n@@ -2075,9 +2061,9 @@ class FeedPostProcessedExportsTest(FeedExportTestBase):\n         }\n \n         data = yield self.exported_data(self.items, settings)\n-        self.assertEqual(compressed, data[filename])\n+        assert compressed == data[filename]\n         result = lzma.decompress(data[filename])\n-        self.assertEqual(self.expected, result)\n+        assert result == self.expected\n \n     @defer.inlineCallbacks\n     def test_bz2_plugin(self):\n@@ -2096,7 +2082,7 @@ class FeedPostProcessedExportsTest(FeedExportTestBase):\n         try:\n             bz2.decompress(data[filename])\n         except OSError:\n-            self.fail(\"Received invalid bz2 data.\")\n+            pytest.fail(\"Received invalid bz2 data.\")\n \n     @defer.inlineCallbacks\n     def test_bz2_plugin_compresslevel(self):\n@@ -2128,8 +2114,8 @@ class FeedPostProcessedExportsTest(FeedExportTestBase):\n \n         for filename, compressed in filename_to_compressed.items():\n             result = bz2.decompress(data[filename])\n-            self.assertEqual(compressed, data[filename])\n-            self.assertEqual(self.expected, result)\n+            assert compressed == data[filename]\n+            assert result == self.expected\n \n     @defer.inlineCallbacks\n     def test_custom_plugin(self):\n@@ -2145,7 +2131,7 @@ class FeedPostProcessedExportsTest(FeedExportTestBase):\n         }\n \n         data = yield self.exported_data(self.items, settings)\n-        self.assertEqual(self.expected, data[filename])\n+        assert data[filename] == self.expected\n \n     @defer.inlineCallbacks\n     def test_custom_plugin_with_parameter(self):\n@@ -2163,7 +2149,7 @@ class FeedPostProcessedExportsTest(FeedExportTestBase):\n         }\n \n         data = yield self.exported_data(self.items, settings)\n-        self.assertEqual(expected, data[filename])\n+        assert data[filename] == expected\n \n     @defer.inlineCallbacks\n     def test_custom_plugin_with_compression(self):\n@@ -2208,7 +2194,7 @@ class FeedPostProcessedExportsTest(FeedExportTestBase):\n \n         for filename, decompressor in filename_to_decompressor.items():\n             result = decompressor(data[filename])\n-            self.assertEqual(expected, result)\n+            assert result == expected\n \n     @defer.inlineCallbacks\n     def test_exports_compatibility_with_postproc(self):\n@@ -2262,10 +2248,10 @@ class FeedPostProcessedExportsTest(FeedExportTestBase):\n                 expected, result = self.items[0], marshal.loads(result)\n             else:\n                 expected = filename_to_expected[filename]\n-            self.assertEqual(expected, result)\n+            assert result == expected\n \n \n-class BatchDeliveriesTest(FeedExportTestBase):\n+class TestBatchDeliveries(TestFeedExportBase):\n     _file_mark = \"_%(batch_time)s_#%(batch_id)02d_\"\n \n     @defer.inlineCallbacks\n@@ -2310,7 +2296,7 @@ class BatchDeliveriesTest(FeedExportTestBase):\n                 json.loads(to_unicode(batch_item)) for batch_item in batch.splitlines()\n             ]\n             expected_batch, rows = rows[:batch_size], rows[batch_size:]\n-            self.assertEqual(expected_batch, got_batch)\n+            assert got_batch == expected_batch\n \n     @defer.inlineCallbacks\n     def assertExportedCsv(self, items, header, rows, settings=None):\n@@ -2328,9 +2314,9 @@ class BatchDeliveriesTest(FeedExportTestBase):\n         data = yield self.exported_data(items, settings)\n         for batch in data[\"csv\"]:\n             got_batch = csv.DictReader(to_unicode(batch).splitlines())\n-            self.assertEqual(list(header), got_batch.fieldnames)\n+            assert list(header) == got_batch.fieldnames\n             expected_batch, rows = rows[:batch_size], rows[batch_size:]\n-            self.assertEqual(expected_batch, list(got_batch))\n+            assert list(got_batch) == expected_batch\n \n     @defer.inlineCallbacks\n     def assertExportedXml(self, items, rows, settings=None):\n@@ -2351,7 +2337,7 @@ class BatchDeliveriesTest(FeedExportTestBase):\n             root = lxml.etree.fromstring(batch)\n             got_batch = [{e.tag: e.text for e in it} for it in root.findall(\"item\")]\n             expected_batch, rows = rows[:batch_size], rows[batch_size:]\n-            self.assertEqual(expected_batch, got_batch)\n+            assert got_batch == expected_batch\n \n     @defer.inlineCallbacks\n     def assertExportedMultiple(self, items, rows, settings=None):\n@@ -2377,13 +2363,13 @@ class BatchDeliveriesTest(FeedExportTestBase):\n             root = lxml.etree.fromstring(batch)\n             got_batch = [{e.tag: e.text for e in it} for it in root.findall(\"item\")]\n             expected_batch, xml_rows = xml_rows[:batch_size], xml_rows[batch_size:]\n-            self.assertEqual(expected_batch, got_batch)\n+            assert got_batch == expected_batch\n         # JSON\n         json_rows = rows.copy()\n         for batch in data[\"json\"]:\n             got_batch = json.loads(batch.decode(\"utf-8\"))\n             expected_batch, json_rows = json_rows[:batch_size], json_rows[batch_size:]\n-            self.assertEqual(expected_batch, got_batch)\n+            assert got_batch == expected_batch\n \n     @defer.inlineCallbacks\n     def assertExportedPickle(self, items, rows, settings=None):\n@@ -2405,7 +2391,7 @@ class BatchDeliveriesTest(FeedExportTestBase):\n         for batch in data[\"pickle\"]:\n             got_batch = self._load_until_eof(batch, load_func=pickle.load)\n             expected_batch, rows = rows[:batch_size], rows[batch_size:]\n-            self.assertEqual(expected_batch, got_batch)\n+            assert got_batch == expected_batch\n \n     @defer.inlineCallbacks\n     def assertExportedMarshal(self, items, rows, settings=None):\n@@ -2427,7 +2413,7 @@ class BatchDeliveriesTest(FeedExportTestBase):\n         for batch in data[\"marshal\"]:\n             got_batch = self._load_until_eof(batch, load_func=marshal.load)\n             expected_batch, rows = rows[:batch_size], rows[batch_size:]\n-            self.assertEqual(expected_batch, got_batch)\n+            assert got_batch == expected_batch\n \n     @defer.inlineCallbacks\n     def test_export_items(self):\n@@ -2472,7 +2458,7 @@ class BatchDeliveriesTest(FeedExportTestBase):\n             }\n             data = yield self.exported_no_data(settings)\n             data = dict(data)\n-            self.assertEqual(0, len(data[fmt]))\n+            assert len(data[fmt]) == 0\n \n     @defer.inlineCallbacks\n     def test_export_no_items_store_empty(self):\n@@ -2496,7 +2482,7 @@ class BatchDeliveriesTest(FeedExportTestBase):\n             }\n             data = yield self.exported_no_data(settings)\n             data = dict(data)\n-            self.assertEqual(expctd, data[fmt][0])\n+            assert data[fmt][0] == expctd\n \n     @defer.inlineCallbacks\n     def test_export_multiple_configs(self):\n@@ -2552,7 +2538,7 @@ class BatchDeliveriesTest(FeedExportTestBase):\n         data = yield self.exported_data(items, settings)\n         for fmt, expected in formats.items():\n             for expected_batch, got_batch in zip(expected, data[fmt]):\n-                self.assertEqual(expected_batch, got_batch)\n+                assert got_batch == expected_batch\n \n     @defer.inlineCallbacks\n     def test_batch_item_count_feeds_setting(self):\n@@ -2576,7 +2562,7 @@ class BatchDeliveriesTest(FeedExportTestBase):\n         data = yield self.exported_data(items, settings)\n         for fmt, expected in formats.items():\n             for expected_batch, got_batch in zip(expected, data[fmt]):\n-                self.assertEqual(expected_batch, got_batch)\n+                assert got_batch == expected_batch\n \n     @defer.inlineCallbacks\n     def test_batch_path_differ(self):\n@@ -2598,7 +2584,7 @@ class BatchDeliveriesTest(FeedExportTestBase):\n             \"FEED_EXPORT_BATCH_ITEM_COUNT\": 1,\n         }\n         data = yield self.exported_data(items, settings)\n-        self.assertEqual(len(items), len(data[\"json\"]))\n+        assert len(items) == len(data[\"json\"])\n \n     @defer.inlineCallbacks\n     def test_stats_batch_file_success(self):\n@@ -2614,12 +2600,8 @@ class BatchDeliveriesTest(FeedExportTestBase):\n         }\n         crawler = get_crawler(ItemSpider, settings)\n         yield crawler.crawl(total=2, mockserver=self.mockserver)\n-        self.assertIn(\n-            \"feedexport/success_count/FileFeedStorage\", crawler.stats.get_stats()\n-        )\n-        self.assertEqual(\n-            crawler.stats.get_value(\"feedexport/success_count/FileFeedStorage\"), 12\n-        )\n+        assert \"feedexport/success_count/FileFeedStorage\" in crawler.stats.get_stats()\n+        assert crawler.stats.get_value(\"feedexport/success_count/FileFeedStorage\") == 12\n \n     @pytest.mark.requires_boto3\n     @defer.inlineCallbacks\n@@ -2687,13 +2669,13 @@ class BatchDeliveriesTest(FeedExportTestBase):\n         crawler = get_crawler(TestSpider, settings)\n         yield crawler.crawl()\n \n-        self.assertEqual(len(CustomS3FeedStorage.stubs), len(items))\n+        assert len(CustomS3FeedStorage.stubs) == len(items)\n         for stub in CustomS3FeedStorage.stubs[:-1]:\n             stub.assert_no_pending_responses()\n \n \n # Test that the FeedExporer sends the feed_exporter_closed and feed_slot_closed signals\n-class FeedExporterSignalsTest(unittest.TestCase):\n+class TestFeedExporterSignals:\n     items = [\n         {\"foo\": \"bar1\", \"egg\": \"spam1\"},\n         {\"foo\": \"bar2\", \"egg\": \"spam2\", \"baz\": \"quux2\"},\n@@ -2754,8 +2736,8 @@ class FeedExporterSignalsTest(unittest.TestCase):\n             self.feed_exporter_closed_signal_handler,\n             self.feed_slot_closed_signal_handler,\n         )\n-        self.assertTrue(self.feed_slot_closed_received)\n-        self.assertTrue(self.feed_exporter_closed_received)\n+        assert self.feed_slot_closed_received\n+        assert self.feed_exporter_closed_received\n \n     def test_feed_exporter_signals_sent_deferred(self):\n         self.feed_exporter_closed_received = False\n@@ -2765,11 +2747,11 @@ class FeedExporterSignalsTest(unittest.TestCase):\n             self.feed_exporter_closed_signal_handler_deferred,\n             self.feed_slot_closed_signal_handler_deferred,\n         )\n-        self.assertTrue(self.feed_slot_closed_received)\n-        self.assertTrue(self.feed_exporter_closed_received)\n+        assert self.feed_slot_closed_received\n+        assert self.feed_exporter_closed_received\n \n \n-class FeedExportInitTest(unittest.TestCase):\n+class TestFeedExportInit:\n     def test_unsupported_storage(self):\n         settings = {\n             \"FEEDS\": {\n@@ -2803,7 +2785,7 @@ class FeedExportInitTest(unittest.TestCase):\n             }\n             crawler = get_crawler(settings_dict=settings)\n             exporter = FeedExporter.from_crawler(crawler)\n-            self.assertIsInstance(exporter, FeedExporter)\n+            assert isinstance(exporter, FeedExporter)\n \n     def test_relative_pathlib_as_uri(self):\n         settings = {\n@@ -2815,13 +2797,14 @@ class FeedExportInitTest(unittest.TestCase):\n         }\n         crawler = get_crawler(settings_dict=settings)\n         exporter = FeedExporter.from_crawler(crawler)\n-        self.assertIsInstance(exporter, FeedExporter)\n+        assert isinstance(exporter, FeedExporter)\n \n \n-class URIParamsTest:\n+class TestURIParams(ABC):\n     spider_name = \"uri_params_spider\"\n     deprecated_options = False\n \n+    @abstractmethod\n     def build_settings(self, uri=\"file:///tmp/foobar\", uri_params=None):\n         raise NotImplementedError\n \n@@ -2850,7 +2833,7 @@ class URIParamsTest:\n             warnings.simplefilter(\"error\", ScrapyDeprecationWarning)\n             feed_exporter.open_spider(spider)\n \n-        self.assertEqual(feed_exporter.slots[0].uri, f\"file:///tmp/{self.spider_name}\")\n+        assert feed_exporter.slots[0].uri == f\"file:///tmp/{self.spider_name}\"\n \n     def test_none(self):\n         def uri_params(params, spider):\n@@ -2866,7 +2849,7 @@ class URIParamsTest:\n \n         feed_exporter.open_spider(spider)\n \n-        self.assertEqual(feed_exporter.slots[0].uri, f\"file:///tmp/{self.spider_name}\")\n+        assert feed_exporter.slots[0].uri == f\"file:///tmp/{self.spider_name}\"\n \n     def test_empty_dict(self):\n         def uri_params(params, spider):\n@@ -2900,7 +2883,7 @@ class URIParamsTest:\n             warnings.simplefilter(\"error\", ScrapyDeprecationWarning)\n             feed_exporter.open_spider(spider)\n \n-        self.assertEqual(feed_exporter.slots[0].uri, f\"file:///tmp/{self.spider_name}\")\n+        assert feed_exporter.slots[0].uri == f\"file:///tmp/{self.spider_name}\"\n \n     def test_custom_param(self):\n         def uri_params(params, spider):\n@@ -2917,10 +2900,10 @@ class URIParamsTest:\n             warnings.simplefilter(\"error\", ScrapyDeprecationWarning)\n             feed_exporter.open_spider(spider)\n \n-        self.assertEqual(feed_exporter.slots[0].uri, f\"file:///tmp/{self.spider_name}\")\n+        assert feed_exporter.slots[0].uri == f\"file:///tmp/{self.spider_name}\"\n \n \n-class URIParamsSettingTest(URIParamsTest, unittest.TestCase):\n+class TestURIParamsSetting(TestURIParams):\n     deprecated_options = True\n \n     def build_settings(self, uri=\"file:///tmp/foobar\", uri_params=None):\n@@ -2933,7 +2916,7 @@ class URIParamsSettingTest(URIParamsTest, unittest.TestCase):\n         }\n \n \n-class URIParamsFeedOptionTest(URIParamsTest, unittest.TestCase):\n+class TestURIParamsFeedOption(TestURIParams):\n     deprecated_options = False\n \n     def build_settings(self, uri=\"file:///tmp/foobar\", uri_params=None):\n\n@@ -185,7 +185,7 @@ def get_client_certificate(\n \n \n @skipIf(not H2_ENABLED, \"HTTP/2 support in Twisted is not enabled\")\n-class Https2ClientProtocolTestCase(TestCase):\n+class TestHttps2ClientProtocol(TestCase):\n     scheme = \"https\"\n     key_file = Path(__file__).parent / \"keys\" / \"localhost.key\"\n     certificate_file = Path(__file__).parent / \"keys\" / \"localhost.crt\"\n@@ -277,14 +277,14 @@ class Https2ClientProtocolTestCase(TestCase):\n \n     def _check_GET(self, request: Request, expected_body, expected_status):\n         def check_response(response: Response):\n-            self.assertEqual(response.status, expected_status)\n-            self.assertEqual(response.body, expected_body)\n-            self.assertEqual(response.request, request)\n+            assert response.status == expected_status\n+            assert response.body == expected_body\n+            assert response.request == request\n \n             content_length_header = response.headers.get(\"Content-Length\")\n             assert content_length_header is not None\n             content_length = int(content_length_header)\n-            self.assertEqual(len(response.body), content_length)\n+            assert len(response.body) == content_length\n \n         d = self.make_request(request)\n         d.addCallback(check_response)\n@@ -325,35 +325,35 @@ class Https2ClientProtocolTestCase(TestCase):\n         d = self.make_request(request)\n \n         def assert_response(response: Response):\n-            self.assertEqual(response.status, expected_status)\n-            self.assertEqual(response.request, request)\n+            assert response.status == expected_status\n+            assert response.request == request\n \n             content_length_header = response.headers.get(\"Content-Length\")\n             assert content_length_header is not None\n             content_length = int(content_length_header)\n-            self.assertEqual(len(response.body), content_length)\n+            assert len(response.body) == content_length\n \n             # Parse the body\n             content_encoding_header = response.headers[b\"Content-Encoding\"]\n             assert content_encoding_header is not None\n             content_encoding = str(content_encoding_header, \"utf-8\")\n             body = json.loads(str(response.body, content_encoding))\n-            self.assertIn(\"request-body\", body)\n-            self.assertIn(\"extra-data\", body)\n-            self.assertIn(\"request-headers\", body)\n+            assert \"request-body\" in body\n+            assert \"extra-data\" in body\n+            assert \"request-headers\" in body\n \n             request_body = body[\"request-body\"]\n-            self.assertEqual(request_body, expected_request_body)\n+            assert request_body == expected_request_body\n \n             extra_data = body[\"extra-data\"]\n-            self.assertEqual(extra_data, expected_extra_data)\n+            assert extra_data == expected_extra_data\n \n             # Check if headers were sent successfully\n             request_headers = body[\"request-headers\"]\n             for k, v in request.headers.items():\n                 k_str = str(k, \"utf-8\")\n-                self.assertIn(k_str, request_headers)\n-                self.assertEqual(request_headers[k_str], str(v[0], \"utf-8\"))\n+                assert k_str in request_headers\n+                assert request_headers[k_str] == str(v[0], \"utf-8\")\n \n         d.addCallback(assert_response)\n         d.addErrback(self.fail)\n@@ -414,8 +414,8 @@ class Https2ClientProtocolTestCase(TestCase):\n         request = Request(url=self.get_url(\"/get-data-html-large\"))\n \n         def assert_response(response: Response):\n-            self.assertEqual(response.status, 499)\n-            self.assertEqual(response.request, request)\n+            assert response.status == 499\n+            assert response.request == request\n \n         d = self.make_request(request)\n         d.addCallback(assert_response)\n@@ -430,12 +430,12 @@ class Https2ClientProtocolTestCase(TestCase):\n         )\n \n         def assert_cancelled_error(failure):\n-            self.assertIsInstance(failure.value, CancelledError)\n+            assert isinstance(failure.value, CancelledError)\n             error_pattern = re.compile(\n                 rf\"Cancelling download of {request.url}: received response \"\n                 rf\"size \\(\\d*\\) larger than download max size \\(1000\\)\"\n             )\n-            self.assertEqual(len(re.findall(error_pattern, str(failure.value))), 1)\n+            assert len(re.findall(error_pattern, str(failure.value))) == 1\n \n         d = self.make_request(request)\n         d.addCallback(self.fail)\n@@ -448,15 +448,13 @@ class Https2ClientProtocolTestCase(TestCase):\n         request = Request(url=self.get_url(\"/dataloss\"))\n \n         def assert_failure(failure: Failure):\n-            self.assertTrue(len(failure.value.reasons) > 0)\n+            assert len(failure.value.reasons) > 0\n             from h2.exceptions import InvalidBodyLengthError\n \n-            self.assertTrue(\n-                any(\n+            assert any(\n                 isinstance(error, InvalidBodyLengthError)\n                 for error in failure.value.reasons\n             )\n-            )\n \n         d = self.make_request(request)\n         d.addCallback(self.fail)\n@@ -467,10 +465,10 @@ class Https2ClientProtocolTestCase(TestCase):\n         request = Request(url=self.get_url(\"/no-content-length-header\"))\n \n         def assert_content_length(response: Response):\n-            self.assertEqual(response.status, 200)\n-            self.assertEqual(response.body, Data.NO_CONTENT_LENGTH)\n-            self.assertEqual(response.request, request)\n-            self.assertNotIn(\"Content-Length\", response.headers)\n+            assert response.status == 200\n+            assert response.body == Data.NO_CONTENT_LENGTH\n+            assert response.request == request\n+            assert \"Content-Length\" not in response.headers\n \n         d = self.make_request(request)\n         d.addCallback(assert_content_length)\n@@ -481,14 +479,12 @@ class Https2ClientProtocolTestCase(TestCase):\n     def _check_log_warnsize(self, request, warn_pattern, expected_body):\n         with self.assertLogs(\"scrapy.core.http2.stream\", level=\"WARNING\") as cm:\n             response = yield self.make_request(request)\n-            self.assertEqual(response.status, 200)\n-            self.assertEqual(response.request, request)\n-            self.assertEqual(response.body, expected_body)\n+            assert response.status == 200\n+            assert response.request == request\n+            assert response.body == expected_body\n \n             # Check the warning is raised only once for this request\n-            self.assertEqual(\n-                sum(len(re.findall(warn_pattern, log)) for log in cm.output), 1\n-            )\n+            assert sum(len(re.findall(warn_pattern, log)) for log in cm.output) == 1\n \n     @inlineCallbacks\n     def test_log_expected_warnsize(self):\n@@ -534,11 +530,11 @@ class Https2ClientProtocolTestCase(TestCase):\n         d_list = []\n \n         def assert_inactive_stream(failure):\n-            self.assertIsNotNone(failure.check(ResponseFailed))\n+            assert failure.check(ResponseFailed) is not None\n             from scrapy.core.http2.stream import InactiveStreamClosed\n \n-            self.assertTrue(\n-                any(isinstance(e, InactiveStreamClosed) for e in failure.value.reasons)\n+            assert any(\n+                isinstance(e, InactiveStreamClosed) for e in failure.value.reasons\n             )\n \n         # Send 100 request (we do not check the result)\n@@ -578,7 +574,7 @@ class Https2ClientProtocolTestCase(TestCase):\n             assert content_encoding_header is not None\n             content_encoding = str(content_encoding_header, \"utf-8\")\n             data = json.loads(str(response.body, content_encoding))\n-            self.assertEqual(data, params)\n+            assert data == params\n \n         d = self.make_request(request)\n         d.addCallback(assert_query_params)\n@@ -588,7 +584,7 @@ class Https2ClientProtocolTestCase(TestCase):\n \n     def test_status_codes(self):\n         def assert_response_status(response: Response, expected_status: int):\n-            self.assertEqual(response.status, expected_status)\n+            assert response.status == expected_status\n \n         d_list = []\n         for status in [200, 404]:\n@@ -604,21 +600,18 @@ class Https2ClientProtocolTestCase(TestCase):\n         request = Request(self.get_url(\"/status?n=200\"))\n \n         def assert_metadata(response: Response):\n-            self.assertEqual(response.request, request)\n-            self.assertIsInstance(response.certificate, Certificate)\n-            assert response.certificate  # typing\n-            self.assertIsNotNone(response.certificate.original)\n-            self.assertEqual(\n-                response.certificate.getIssuer(), self.client_certificate.getIssuer()\n+            assert response.request == request\n+            assert isinstance(response.certificate, Certificate)\n+            assert response.certificate.original is not None\n+            assert (\n+                response.certificate.getIssuer() == self.client_certificate.getIssuer()\n             )\n-            self.assertTrue(\n-                response.certificate.getPublicKey().matches(\n+            assert response.certificate.getPublicKey().matches(\n                 self.client_certificate.getPublicKey()\n             )\n-            )\n \n-            self.assertIsInstance(response.ip_address, IPv4Address)\n-            self.assertEqual(str(response.ip_address), \"127.0.0.1\")\n+            assert isinstance(response.ip_address, IPv4Address)\n+            assert str(response.ip_address) == \"127.0.0.1\"\n \n         d = self.make_request(request)\n         d.addCallback(assert_metadata)\n@@ -632,11 +625,11 @@ class Https2ClientProtocolTestCase(TestCase):\n         def assert_invalid_hostname(failure: Failure):\n             from scrapy.core.http2.stream import InvalidHostname\n \n-            self.assertIsNotNone(failure.check(InvalidHostname))\n+            assert failure.check(InvalidHostname) is not None\n             error_msg = str(failure.value)\n-            self.assertIn(\"localhost\", error_msg)\n-            self.assertIn(\"127.0.0.1\", error_msg)\n-            self.assertIn(str(request), error_msg)\n+            assert \"localhost\" in error_msg\n+            assert \"127.0.0.1\" in error_msg\n+            assert str(request) in error_msg\n \n         d = self.make_request(request)\n         d.addCallback(self.fail)\n@@ -672,13 +665,13 @@ class Https2ClientProtocolTestCase(TestCase):\n                 from scrapy.core.http2.protocol import H2ClientProtocol\n \n                 if isinstance(err, TimeoutError):\n-                    self.assertIn(\n-                        f\"Connection was IDLE for more than {H2ClientProtocol.IDLE_TIMEOUT}s\",\n-                        str(err),\n+                    assert (\n+                        f\"Connection was IDLE for more than {H2ClientProtocol.IDLE_TIMEOUT}s\"\n+                        in str(err)\n                     )\n                     break\n             else:\n-                self.fail()\n+                pytest.fail(\"No TimeoutError raised.\")\n \n         d.addCallback(self.fail)\n         d.addErrback(assert_timeout_error)\n@@ -692,15 +685,15 @@ class Https2ClientProtocolTestCase(TestCase):\n         d = self.make_request(request)\n \n         def assert_request_headers(response: Response):\n-            self.assertEqual(response.status, 200)\n-            self.assertEqual(response.request, request)\n+            assert response.status == 200\n+            assert response.request == request\n \n             response_headers = json.loads(str(response.body, \"utf-8\"))\n-            self.assertIsInstance(response_headers, dict)\n+            assert isinstance(response_headers, dict)\n             for k, v in request.headers.items():\n                 k, v = str(k, \"utf-8\"), str(v[0], \"utf-8\")\n-                self.assertIn(k, response_headers)\n-                self.assertEqual(v, response_headers[k])\n+                assert k in response_headers\n+                assert v == response_headers[k]\n \n         d.addErrback(self.fail)\n         d.addCallback(assert_request_headers)\n\n@@ -1,74 +1,72 @@\n-from unittest import TestCase\n-\n from scrapy.http import Request, Response\n from scrapy.http.cookies import WrappedRequest, WrappedResponse\n from scrapy.utils.httpobj import urlparse_cached\n \n \n-class WrappedRequestTest(TestCase):\n-    def setUp(self):\n+class TestWrappedRequest:\n+    def setup_method(self):\n         self.request = Request(\n             \"http://www.example.com/page.html\", headers={\"Content-Type\": \"text/html\"}\n         )\n         self.wrapped = WrappedRequest(self.request)\n \n     def test_get_full_url(self):\n-        self.assertEqual(self.wrapped.get_full_url(), self.request.url)\n-        self.assertEqual(self.wrapped.full_url, self.request.url)\n+        assert self.wrapped.get_full_url() == self.request.url\n+        assert self.wrapped.full_url == self.request.url\n \n     def test_get_host(self):\n-        self.assertEqual(self.wrapped.get_host(), urlparse_cached(self.request).netloc)\n-        self.assertEqual(self.wrapped.host, urlparse_cached(self.request).netloc)\n+        assert self.wrapped.get_host() == urlparse_cached(self.request).netloc\n+        assert self.wrapped.host == urlparse_cached(self.request).netloc\n \n     def test_get_type(self):\n-        self.assertEqual(self.wrapped.get_type(), urlparse_cached(self.request).scheme)\n-        self.assertEqual(self.wrapped.type, urlparse_cached(self.request).scheme)\n+        assert self.wrapped.get_type() == urlparse_cached(self.request).scheme\n+        assert self.wrapped.type == urlparse_cached(self.request).scheme\n \n     def test_is_unverifiable(self):\n-        self.assertFalse(self.wrapped.is_unverifiable())\n-        self.assertFalse(self.wrapped.unverifiable)\n+        assert not self.wrapped.is_unverifiable()\n+        assert not self.wrapped.unverifiable\n \n     def test_is_unverifiable2(self):\n         self.request.meta[\"is_unverifiable\"] = True\n-        self.assertTrue(self.wrapped.is_unverifiable())\n-        self.assertTrue(self.wrapped.unverifiable)\n+        assert self.wrapped.is_unverifiable()\n+        assert self.wrapped.unverifiable\n \n     def test_get_origin_req_host(self):\n-        self.assertEqual(self.wrapped.origin_req_host, \"www.example.com\")\n+        assert self.wrapped.origin_req_host == \"www.example.com\"\n \n     def test_has_header(self):\n-        self.assertTrue(self.wrapped.has_header(\"content-type\"))\n-        self.assertFalse(self.wrapped.has_header(\"xxxxx\"))\n+        assert self.wrapped.has_header(\"content-type\")\n+        assert not self.wrapped.has_header(\"xxxxx\")\n \n     def test_get_header(self):\n-        self.assertEqual(self.wrapped.get_header(\"content-type\"), \"text/html\")\n-        self.assertEqual(self.wrapped.get_header(\"xxxxx\", \"def\"), \"def\")\n-        self.assertEqual(self.wrapped.get_header(\"xxxxx\"), None)\n+        assert self.wrapped.get_header(\"content-type\") == \"text/html\"\n+        assert self.wrapped.get_header(\"xxxxx\", \"def\") == \"def\"\n+        assert self.wrapped.get_header(\"xxxxx\") is None\n         wrapped = WrappedRequest(\n             Request(\n                 \"http://www.example.com/page.html\", headers={\"empty-binary-header\": b\"\"}\n             )\n         )\n-        self.assertEqual(wrapped.get_header(\"empty-binary-header\"), \"\")\n+        assert wrapped.get_header(\"empty-binary-header\") == \"\"\n \n     def test_header_items(self):\n-        self.assertEqual(self.wrapped.header_items(), [(\"Content-Type\", [\"text/html\"])])\n+        assert self.wrapped.header_items() == [(\"Content-Type\", [\"text/html\"])]\n \n     def test_add_unredirected_header(self):\n         self.wrapped.add_unredirected_header(\"hello\", \"world\")\n-        self.assertEqual(self.request.headers[\"hello\"], b\"world\")\n+        assert self.request.headers[\"hello\"] == b\"world\"\n \n \n-class WrappedResponseTest(TestCase):\n-    def setUp(self):\n+class TestWrappedResponse:\n+    def setup_method(self):\n         self.response = Response(\n             \"http://www.example.com/page.html\", headers={\"Content-TYpe\": \"text/html\"}\n         )\n         self.wrapped = WrappedResponse(self.response)\n \n     def test_info(self):\n-        self.assertIs(self.wrapped.info(), self.wrapped)\n+        assert self.wrapped.info() is self.wrapped\n \n     def test_get_all(self):\n         # get_all result must be native string\n-        self.assertEqual(self.wrapped.get_all(\"content-type\"), [\"text/html\"])\n+        assert self.wrapped.get_all(\"content-type\") == [\"text/html\"]\n\n@@ -1,14 +1,13 @@\n import copy\n-import unittest\n \n import pytest\n \n from scrapy.http import Headers\n \n \n-class HeadersTest(unittest.TestCase):\n+class TestHeaders:\n     def assertSortedEqual(self, first, second, msg=None):\n-        return self.assertEqual(sorted(first), sorted(second), msg)\n+        assert sorted(first) == sorted(second), msg\n \n     def test_basics(self):\n         h = Headers({\"Content-Type\": \"text/html\", \"Content-Length\": 1234})\n@@ -17,53 +16,53 @@ class HeadersTest(unittest.TestCase):\n \n         with pytest.raises(KeyError):\n             h[\"Accept\"]\n-        self.assertEqual(h.get(\"Accept\"), None)\n-        self.assertEqual(h.getlist(\"Accept\"), [])\n+        assert h.get(\"Accept\") is None\n+        assert h.getlist(\"Accept\") == []\n \n-        self.assertEqual(h.get(\"Accept\", \"*/*\"), b\"*/*\")\n-        self.assertEqual(h.getlist(\"Accept\", \"*/*\"), [b\"*/*\"])\n-        self.assertEqual(\n-            h.getlist(\"Accept\", [\"text/html\", \"images/jpeg\"]),\n-            [b\"text/html\", b\"images/jpeg\"],\n-        )\n+        assert h.get(\"Accept\", \"*/*\") == b\"*/*\"\n+        assert h.getlist(\"Accept\", \"*/*\") == [b\"*/*\"]\n+        assert h.getlist(\"Accept\", [\"text/html\", \"images/jpeg\"]) == [\n+            b\"text/html\",\n+            b\"images/jpeg\",\n+        ]\n \n     def test_single_value(self):\n         h = Headers()\n         h[\"Content-Type\"] = \"text/html\"\n-        self.assertEqual(h[\"Content-Type\"], b\"text/html\")\n-        self.assertEqual(h.get(\"Content-Type\"), b\"text/html\")\n-        self.assertEqual(h.getlist(\"Content-Type\"), [b\"text/html\"])\n+        assert h[\"Content-Type\"] == b\"text/html\"\n+        assert h.get(\"Content-Type\") == b\"text/html\"\n+        assert h.getlist(\"Content-Type\") == [b\"text/html\"]\n \n     def test_multivalue(self):\n         h = Headers()\n         h[\"X-Forwarded-For\"] = hlist = [\"ip1\", \"ip2\"]\n-        self.assertEqual(h[\"X-Forwarded-For\"], b\"ip2\")\n-        self.assertEqual(h.get(\"X-Forwarded-For\"), b\"ip2\")\n-        self.assertEqual(h.getlist(\"X-Forwarded-For\"), [b\"ip1\", b\"ip2\"])\n+        assert h[\"X-Forwarded-For\"] == b\"ip2\"\n+        assert h.get(\"X-Forwarded-For\") == b\"ip2\"\n+        assert h.getlist(\"X-Forwarded-For\") == [b\"ip1\", b\"ip2\"]\n         assert h.getlist(\"X-Forwarded-For\") is not hlist\n \n     def test_multivalue_for_one_header(self):\n         h = Headers(((\"a\", \"b\"), (\"a\", \"c\")))\n-        self.assertEqual(h[\"a\"], b\"c\")\n-        self.assertEqual(h.get(\"a\"), b\"c\")\n-        self.assertEqual(h.getlist(\"a\"), [b\"b\", b\"c\"])\n+        assert h[\"a\"] == b\"c\"\n+        assert h.get(\"a\") == b\"c\"\n+        assert h.getlist(\"a\") == [b\"b\", b\"c\"]\n \n     def test_encode_utf8(self):\n         h = Headers({\"key\": \"\\xa3\"}, encoding=\"utf-8\")\n         key, val = dict(h).popitem()\n         assert isinstance(key, bytes), key\n         assert isinstance(val[0], bytes), val[0]\n-        self.assertEqual(val[0], b\"\\xc2\\xa3\")\n+        assert val[0] == b\"\\xc2\\xa3\"\n \n     def test_encode_latin1(self):\n         h = Headers({\"key\": \"\\xa3\"}, encoding=\"latin1\")\n         key, val = dict(h).popitem()\n-        self.assertEqual(val[0], b\"\\xa3\")\n+        assert val[0] == b\"\\xa3\"\n \n     def test_encode_multiple(self):\n         h = Headers({\"key\": [\"\\xa3\"]}, encoding=\"utf-8\")\n         key, val = dict(h).popitem()\n-        self.assertEqual(val[0], b\"\\xc2\\xa3\")\n+        assert val[0] == b\"\\xc2\\xa3\"\n \n     def test_delete_and_contains(self):\n         h = Headers()\n@@ -81,17 +80,17 @@ class HeadersTest(unittest.TestCase):\n \n         h = Headers()\n         olist = h.setdefault(\"X-Forwarded-For\", \"ip1\")\n-        self.assertEqual(h.getlist(\"X-Forwarded-For\"), [b\"ip1\"])\n+        assert h.getlist(\"X-Forwarded-For\") == [b\"ip1\"]\n         assert h.getlist(\"X-Forwarded-For\") is olist\n \n     def test_iterables(self):\n         idict = {\"Content-Type\": \"text/html\", \"X-Forwarded-For\": [\"ip1\", \"ip2\"]}\n \n         h = Headers(idict)\n-        self.assertDictEqual(\n-            dict(h),\n-            {b\"Content-Type\": [b\"text/html\"], b\"X-Forwarded-For\": [b\"ip1\", b\"ip2\"]},\n-        )\n+        assert dict(h) == {\n+            b\"Content-Type\": [b\"text/html\"],\n+            b\"X-Forwarded-For\": [b\"ip1\", b\"ip2\"],\n+        }\n         self.assertSortedEqual(h.keys(), [b\"X-Forwarded-For\", b\"Content-Type\"])\n         self.assertSortedEqual(\n             h.items(),\n@@ -102,57 +101,57 @@ class HeadersTest(unittest.TestCase):\n     def test_update(self):\n         h = Headers()\n         h.update({\"Content-Type\": \"text/html\", \"X-Forwarded-For\": [\"ip1\", \"ip2\"]})\n-        self.assertEqual(h.getlist(\"Content-Type\"), [b\"text/html\"])\n-        self.assertEqual(h.getlist(\"X-Forwarded-For\"), [b\"ip1\", b\"ip2\"])\n+        assert h.getlist(\"Content-Type\") == [b\"text/html\"]\n+        assert h.getlist(\"X-Forwarded-For\") == [b\"ip1\", b\"ip2\"]\n \n     def test_copy(self):\n         h1 = Headers({\"header1\": [\"value1\", \"value2\"]})\n         h2 = copy.copy(h1)\n-        self.assertEqual(h1, h2)\n-        self.assertEqual(h1.getlist(\"header1\"), h2.getlist(\"header1\"))\n+        assert h1 == h2\n+        assert h1.getlist(\"header1\") == h2.getlist(\"header1\")\n         assert h1.getlist(\"header1\") is not h2.getlist(\"header1\")\n         assert isinstance(h2, Headers)\n \n     def test_appendlist(self):\n         h1 = Headers({\"header1\": \"value1\"})\n         h1.appendlist(\"header1\", \"value3\")\n-        self.assertEqual(h1.getlist(\"header1\"), [b\"value1\", b\"value3\"])\n+        assert h1.getlist(\"header1\") == [b\"value1\", b\"value3\"]\n \n         h1 = Headers()\n         h1.appendlist(\"header1\", \"value1\")\n         h1.appendlist(\"header1\", \"value3\")\n-        self.assertEqual(h1.getlist(\"header1\"), [b\"value1\", b\"value3\"])\n+        assert h1.getlist(\"header1\") == [b\"value1\", b\"value3\"]\n \n     def test_setlist(self):\n         h1 = Headers({\"header1\": \"value1\"})\n-        self.assertEqual(h1.getlist(\"header1\"), [b\"value1\"])\n+        assert h1.getlist(\"header1\") == [b\"value1\"]\n         h1.setlist(\"header1\", [b\"value2\", b\"value3\"])\n-        self.assertEqual(h1.getlist(\"header1\"), [b\"value2\", b\"value3\"])\n+        assert h1.getlist(\"header1\") == [b\"value2\", b\"value3\"]\n \n     def test_setlistdefault(self):\n         h1 = Headers({\"header1\": \"value1\"})\n         h1.setlistdefault(\"header1\", [\"value2\", \"value3\"])\n         h1.setlistdefault(\"header2\", [\"value2\", \"value3\"])\n-        self.assertEqual(h1.getlist(\"header1\"), [b\"value1\"])\n-        self.assertEqual(h1.getlist(\"header2\"), [b\"value2\", b\"value3\"])\n+        assert h1.getlist(\"header1\") == [b\"value1\"]\n+        assert h1.getlist(\"header2\") == [b\"value2\", b\"value3\"]\n \n     def test_none_value(self):\n         h1 = Headers()\n         h1[\"foo\"] = \"bar\"\n         h1[\"foo\"] = None\n         h1.setdefault(\"foo\", \"bar\")\n-        self.assertEqual(h1.get(\"foo\"), None)\n-        self.assertEqual(h1.getlist(\"foo\"), [])\n+        assert h1.get(\"foo\") is None\n+        assert h1.getlist(\"foo\") == []\n \n     def test_int_value(self):\n         h1 = Headers({\"hey\": 5})\n         h1[\"foo\"] = 1\n         h1.setdefault(\"bar\", 2)\n         h1.setlist(\"buz\", [1, \"dos\", 3])\n-        self.assertEqual(h1.getlist(\"foo\"), [b\"1\"])\n-        self.assertEqual(h1.getlist(\"bar\"), [b\"2\"])\n-        self.assertEqual(h1.getlist(\"buz\"), [b\"1\", b\"dos\", b\"3\"])\n-        self.assertEqual(h1.getlist(\"hey\"), [b\"5\"])\n+        assert h1.getlist(\"foo\") == [b\"1\"]\n+        assert h1.getlist(\"bar\") == [b\"2\"]\n+        assert h1.getlist(\"buz\") == [b\"1\", b\"dos\", b\"3\"]\n+        assert h1.getlist(\"hey\") == [b\"5\"]\n \n     def test_invalid_value(self):\n         with pytest.raises(TypeError, match=\"Unsupported value type\"):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
