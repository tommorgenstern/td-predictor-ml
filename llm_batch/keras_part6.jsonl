{"custom_id": "keras#6fc8660a5148c1693e2c02874ffdb6a7d8f1a2c8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 12 | Files Changed: 1 | Hunks: 20 | Methods Changed: 8 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 27 | Churn Cumulative: 378 | Contributors (this commit): 3 | Commits (past 90d): 13 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -11,12 +11,14 @@ def clip_norm(g, c, n):\n         g = T.switch(T.ge(n, c), g*c/n, g)\n     return g\n \n+def kl_divergence(p, p_hat):\n+    return p_hat - p + p*T.log(p/p_hat)\n+\n class Optimizer(object):\n     def get_updates(self, params, grads):\n         raise NotImplementedError\n \n     def get_gradients(self, cost, params, regularizers):\n-\n         grads = T.grad(cost, params)\n \n         if hasattr(self, 'clipnorm') and self.clipnorm > 0:\n@@ -34,16 +36,16 @@ class Optimizer(object):\n class SGD(Optimizer):\n \n     def __init__(self, lr=0.01, momentum=0., decay=0., nesterov=False, *args, **kwargs):\n+        self.__dict__.update(kwargs)\n         self.__dict__.update(locals())\n         self.iterations = shared_scalar(0)\n \n     def get_updates(self, params, regularizers, constraints, cost):\n         grads = self.get_gradients(cost, params, regularizers)\n-\n         lr = self.lr * (1.0 / (1.0 + self.decay * self.iterations))\n         updates = [(self.iterations, self.iterations+1.)]\n \n-        for p, g in zip(params, grads):\n+        for p, g, c in zip(params, grads, constraints):\n             m = shared_zeros(p.get_value().shape) # momentum\n             v = self.momentum * m - lr * g # velocity\n             updates.append((m, v)) \n@@ -60,20 +62,19 @@ class SGD(Optimizer):\n class RMSprop(Optimizer):\n \n     def __init__(self, lr=0.001, rho=0.9, epsilon=1e-6, *args, **kwargs):\n+        self.__dict__.update(kwargs)\n         self.__dict__.update(locals())\n \n     def get_updates(self, params, regularizers, constraints, cost):\n         grads = self.get_gradients(cost, params, regularizers)\n-\n         accumulators = [shared_zeros(p.get_value().shape) for p in params]\n         updates = []\n \n-        for p, g, a in zip(params, grads, accumulators):\n+        for p, g, a, c in zip(params, grads, accumulators, constraints):\n             new_a = self.rho * a + (1 - self.rho) * g ** 2 # update accumulator\n             updates.append((a, new_a))\n \n             new_p = p - self.lr * g / T.sqrt(new_a + self.epsilon)\n-\n             updates.append((p, c(new_p))) # apply constraints\n             \n         return updates\n@@ -82,15 +83,15 @@ class RMSprop(Optimizer):\n class Adagrad(Optimizer):\n \n     def __init__(self, lr=0.01, epsilon=1e-6, *args, **kwargs):\n+        self.__dict__.update(kwargs)\n         self.__dict__.update(locals())\n \n     def get_updates(self, params, regularizers, constraints, cost):\n         grads = self.get_gradients(cost, params, regularizers)\n-\n         accumulators = [shared_zeros(p.get_value().shape) for p in params]\n         updates = []\n \n-        for p, g, a in zip(params, grads, accumulators):\n+        for p, g, a, c in zip(params, grads, accumulators, constraints):\n             new_a = a + g ** 2 # update accumulator\n             updates.append((a, new_a))\n \n@@ -104,16 +105,16 @@ class Adadelta(Optimizer):\n         Reference: http://arxiv.org/abs/1212.5701\n     '''\n     def __init__(self, lr=1.0, rho=0.95, epsilon=1e-6, *args, **kwargs):\n+        self.__dict__.update(kwargs)\n         self.__dict__.update(locals())\n \n     def get_updates(self, params, regularizers, constraints, cost):\n         grads = self.get_gradients(cost, params, regularizers)\n-\n         accumulators = [shared_zeros(p.get_value().shape) for p in params]\n         delta_accumulators = [shared_zeros(p.get_value().shape) for p in params]\n         updates = []\n \n-        for p, g, a, d_a in zip(params, grads, accumulators, delta_accumulators):\n+        for p, g, a, d_a, c in zip(params, grads, accumulators, delta_accumulators, constraints):\n             new_a = self.rho * a + (1 - self.rho) * g ** 2 # update accumulator\n             updates.append((a, new_a))\n \n@@ -132,10 +133,13 @@ class Adadelta(Optimizer):\n class Adam(Optimizer):\n     '''\n         Reference: http://arxiv.org/abs/1412.6980\n+\n         Default parameters follow those provided in the original paper\n+\n         lambda is renamed kappa.\n     '''\n     def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, kappa=1-1e-8, *args, **kwargs):\n+        self.__dict__.update(kwargs)\n         self.__dict__.update(locals())\n         self.iterations = shared_scalar(0)\n \n@@ -149,7 +153,7 @@ class Adam(Optimizer):\n         # the update below seems missing from the paper, but is obviously required\n         beta_2_t = self.beta_2 * (self.kappa**i) \n \n-        for p, g in zip(params, grads):\n+        for p, g, c in zip(params, grads, constraints):\n             m = theano.shared(p.get_value() * 0.) # zero init of moment\n             v = theano.shared(p.get_value() * 0.) # zero init of velocity\n \n@@ -163,7 +167,6 @@ class Adam(Optimizer):\n             \n             updates.append((m, m_t))\n             updates.append((v, v_t))\n-\n             updates.append((p, c(p_t))) # apply constraints\n         return updates\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ea92046a19cc4e1446d141a34e260c4a878bd98b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 4 | Churn Cumulative: 478 | Contributors (this commit): 9 | Commits (past 90d): 24 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -36,7 +36,7 @@ class Sequential(object):\n             self.layers[-1].connect(self.layers[-2])\n         self.params += [p for p in layer.params]\n         \n-        if hasattr(layer, 'regularizers'):\n+        if hasattr(layer, 'regularizers') and len(layer.regularizers) == len(layer.params):\n             for r in layer.regularizers:\n                 if r:\n                     self.regularizers.append(r)\n@@ -47,7 +47,7 @@ class Sequential(object):\n         else:\n             self.regularizers += [regularizers.identity for _ in range(len(layer.params))]\n \n-        if hasattr(layer, 'constraints'):\n+        if hasattr(layer, 'constraints') and len(layer.constraints) == len(layer.params):\n             for c in layer.constraints:\n                 if c:\n                     self.constraints.append(c)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d788b8e9194f8125af7059bcc1b730dcc10f196e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 10 | Churn Cumulative: 18 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -87,12 +87,18 @@ def array_to_img(x, scale=True):\n         return Image.fromarray(x.astype(\"uint8\"), \"RGB\")\n     else:\n         # grayscale\n-        return Image.fromarray(x.astype(\"uint8\"), \"L\")\n+        return Image.fromarray(x[:,:,0].astype(\"uint8\"), \"L\")\n \n \n def img_to_array(img):\n     x = np.asarray(img, dtype='float32')\n-    return x.transpose(2, 0, 1)\n+    if len(x.shape)==3:\n+        # RGB: height, width, channel -> channel, height, width\n+        x = x.transpose(2, 0, 1)\n+    else:\n+        # grayscale: height, width -> channel, height, width\n+        x = x.reshape((1, x.shape[0], x.shape[1]))\n+    return x\n \n \n def load_img(path, grayscale=False):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6e5769a8ef2a2e01b75828d5c3bc9343af3882b9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 20 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -106,6 +106,8 @@ def load_img(path, grayscale=False):\n     img = Image.open(open(path))\n     if grayscale:\n         img = img.convert('L')\n+    else: # Assure 3 channel even when loaded image is grayscale\n+        img = img.convert('RGB')\n     return img\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#31ea01865609427c8e940e19a61095a50a44da36", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 24 | Churn Cumulative: 502 | Contributors (this commit): 9 | Commits (past 90d): 25 | Contributors (cumulative): 9 | DMM Complexity: 0.0\n\nDIFF:\n@@ -23,6 +23,15 @@ def make_batches(size, batch_size):\n     nb_batch = int(np.ceil(size/float(batch_size)))\n     return [(i*batch_size, min(size, (i+1)*batch_size)) for i in range(0, nb_batch)]\n \n+def ndim_tensor(ndim):\n+    if ndim == 2:\n+        return T.matrix()\n+    elif ndim == 3:\n+        return T.tensor3()\n+    elif ndim == 4:\n+        return T.tensor4()\n+    return T.matrix()\n+\n class Sequential(object):\n     def __init__(self):\n         self.layers = []\n@@ -59,17 +68,24 @@ class Sequential(object):\n             self.constraints += [constraints.identity for _ in range(len(layer.params))]\n         \n \n-    def compile(self, optimizer, loss, class_mode=\"categorical\"):\n+    def compile(self, optimizer, loss, class_mode=\"categorical\", y_dim_components=1):\n         self.optimizer = optimizers.get(optimizer)\n         self.loss = objectives.get(loss)\n \n-        self.X = self.layers[0].input # input of model \n-        # (first layer must have an \"input\" attribute!)\n+        # input of model \n+        if not hasattr(self.layers[0], 'input'):\n+            for l in self.layers:\n+                if hasattr(l, 'input'):\n+                    break\n+            ndim = l.input.ndim \n+            self.layers[0].input = ndim_tensor(ndim)\n+        self.X = self.layers[0].input\n+\n         self.y_train = self.layers[-1].output(train=True)\n         self.y_test = self.layers[-1].output(train=False)\n \n         # output of model\n-        self.y = T.matrix() # TODO: support for custom output shapes\n+        self.y = ndim_tensor(y_dim_components+1)\n \n         train_loss = self.loss(self.y, self.y_train)\n         test_score = self.loss(self.y, self.y_test)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#18374589571a45be98f1ba107946dbdf01858084", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 379 | Contributors (this commit): 3 | Commits (past 90d): 14 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -15,6 +15,7 @@ def kl_divergence(p, p_hat):\n     return p_hat - p + p*T.log(p/p_hat)\n \n class Optimizer(object):\n+    \n     def get_updates(self, params, grads):\n         raise NotImplementedError\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#03fa41801a464311607ddb2afc8760fafbd3d9c9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 299 | Contributors (this commit): 1 | Commits (past 90d): 6 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -105,8 +105,8 @@ if train_model:\n     else:\n         print('Build model...')\n         model = Sequential()\n-        model.add(WordContextProduct(max_features, proj_dim=dim_proj, init=\"normal\"))\n-        model.compile(loss='hinge', optimizer='adam')\n+        model.add(WordContextProduct(max_features, proj_dim=dim_proj, init=\"uniform\"))\n+        model.compile(loss='mse', optimizer='rmsprop')\n \n     sampling_table = sequence.make_sampling_table(max_features)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#269c46fcdcc7e7f734fcf4876021b49aea64e6ae", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 111 | Contributors (this commit): 2 | Commits (past 90d): 7 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -6,8 +6,8 @@ from six.moves import range\n \n def pad_sequences(sequences, maxlen=None, dtype='int32'):\n     \"\"\"\n-        Pad each sequence to the same lenght: \n-        the lenght of the longuest sequence.\n+        Pad each sequence to the same length: \n+        the length of the longuest sequence.\n \n         If maxlen is provided, any sequence longer\n         than maxlen is truncated to maxlen.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#be1ec8aeccccbe6c5f3c2ef1047256016b607395", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 25 | Files Changed: 7 | Hunks: 24 | Methods Changed: 17 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 53 | Churn Cumulative: 1166 | Contributors (this commit): 11 | Commits (past 90d): 76 | Contributors (cumulative): 25 | DMM Complexity: 1.0\n\nDIFF:\n@@ -6,7 +6,7 @@ class LeakyReLU(Layer):\n         super(LeakyReLU,self).__init__()\n         self.alpha = alpha\n \n-    def output(self, train):\n+    def get_output(self, train):\n         X = self.get_input(train)\n         return ((X + abs(X)) / 2.0) + self.alpha * ((X - abs(X)) / 2.0)\n \n@@ -27,7 +27,7 @@ class PReLU(Layer):\n         self.params = [self.alphas]\n         self.input_shape = input_shape\n \n-    def output(self, train):\n+    def get_output(self, train):\n         X = self.get_input(train)\n         pos = ((X + abs(X)) / 2.0)\n         neg = self.alphas * ((X - abs(X)) / 2.0)\n\n@@ -41,7 +41,7 @@ class Convolution2D(Layer):\n         if weights is not None:\n             self.set_weights(weights)\n \n-    def output(self, train):\n+    def get_output(self, train):\n         X = self.get_input(train)\n \n         conv_out = theano.tensor.nnet.conv.conv2d(X, self.W, \n@@ -69,7 +69,7 @@ class MaxPooling2D(Layer):\n         self.poolsize = poolsize\n         self.ignore_border = ignore_border\n \n-    def output(self, train):\n+    def get_output(self, train):\n         X = self.get_input(train)\n         output = downsample.max_pool_2d(X, self.poolsize, ignore_border=self.ignore_border)\n         return output\n\n@@ -16,15 +16,15 @@ class Layer(object):\n     def __init__(self):\n         self.params = []\n \n-    def connect(self, previous_layer):\n-        self.previous_layer = previous_layer\n+    def connect(self, node):\n+        self.previous = node\n \n-    def output(self, train):\n+    def get_output(self, train):\n         raise NotImplementedError\n \n     def get_input(self, train):\n-        if hasattr(self, 'previous_layer'):\n-            return self.previous_layer.output(train=train)\n+        if hasattr(self, 'previous'):\n+            return self.previous.get_output(train=train)\n         else:\n             return self.input\n \n@@ -50,7 +50,7 @@ class Dropout(Layer):\n         super(Dropout,self).__init__()\n         self.p = p\n \n-    def output(self, train):\n+    def get_output(self, train):\n         X = self.get_input(train)\n         if self.p > 0.:\n             retain_prob = 1. - self.p\n@@ -75,7 +75,7 @@ class Activation(Layer):\n         self.target = target\n         self.beta = beta\n \n-    def output(self, train):\n+    def get_output(self, train):\n         X = self.get_input(train)\n         return self.activation(X)\n \n@@ -96,7 +96,7 @@ class Reshape(Layer):\n         super(Reshape,self).__init__()\n         self.dims = dims\n \n-    def output(self, train):\n+    def get_output(self, train):\n         X = self.get_input(train)\n         nshape = make_tuple(X.shape[0], *self.dims)\n         return theano.tensor.reshape(X, nshape)\n@@ -114,7 +114,7 @@ class Flatten(Layer):\n     def __init__(self):\n         super(Flatten,self).__init__()\n \n-    def output(self, train):\n+    def get_output(self, train):\n         X = self.get_input(train)\n         size = theano.tensor.prod(X.shape) // X.shape[0]\n         nshape = (X.shape[0], size)\n@@ -132,7 +132,7 @@ class RepeatVector(Layer):\n         super(RepeatVector,self).__init__()\n         self.n = n\n \n-    def output(self, train):\n+    def get_output(self, train):\n         X = self.get_input(train)\n         tensors = [X]*self.n\n         stacked = theano.tensor.stack(*tensors)\n@@ -168,7 +168,7 @@ class Dense(Layer):\n         if weights is not None:\n             self.set_weights(weights)\n \n-    def output(self, train):\n+    def get_output(self, train):\n         X = self.get_input(train)\n         output = self.activation(T.dot(X, self.W) + self.b)\n         return output\n@@ -210,7 +210,7 @@ class TimeDistributedDense(Layer):\n         if weights is not None:\n             self.set_weights(weights)\n \n-    def output(self, train):\n+    def get_output(self, train):\n         X = self.get_input(train)\n \n         def act_func(X):\n\n@@ -27,7 +27,7 @@ class Embedding(Layer):\n         if weights is not None:\n             self.set_weights(weights)\n \n-    def output(self, train=False):\n+    def get_output(self, train=False):\n         X = self.get_input(train)\n         out = self.W[X]\n         return out\n@@ -83,7 +83,7 @@ class WordContextProduct(Layer):\n             self.set_weights(weights)\n \n \n-    def output(self, train=False):\n+    def get_output(self, train=False):\n         X = self.get_input(train)\n         w = self.W_w[X[:, 0]] # nb_samples, proj_dim\n         c = self.W_c[X[:, 1]] # nb_samples, proj_dim\n\n@@ -27,7 +27,7 @@ class BatchNormalization(Layer):\n         if weights is not None:\n             self.set_weights(weights)\n \n-    def output(self, train):\n+    def get_output(self, train):\n         X = self.get_input(train)\n \n         if self.mode == 0:\n\n@@ -46,7 +46,7 @@ class SimpleRNN(Layer):\n         '''\n         return self.activation(x_t + T.dot(h_tm1, u))\n \n-    def output(self, train):\n+    def get_output(self, train):\n         X = self.get_input(train) # shape: (nb_samples, time (padded with zeros at the end), input_dim)\n         # new shape: (time, nb_samples, input_dim) -> because theano.scan iterates over main dimension\n         X = X.dimshuffle((1,0,2)) \n@@ -119,7 +119,7 @@ class SimpleDeepRNN(Layer):\n             o += self.inner_activation(T.dot(args[i], args[i+self.depth]))\n         return self.activation(o)\n \n-    def output(self, train):\n+    def get_output(self, train):\n         X = self.get_input(train)\n         X = X.dimshuffle((1,0,2)) \n \n@@ -222,7 +222,7 @@ class GRU(Layer):\n         h_t = z * h_tm1 + (1 - z) * hh_t\n         return h_t\n \n-    def output(self, train):\n+    def get_output(self, train):\n         X = self.get_input(train) \n         X = X.dimshuffle((1,0,2)) \n \n@@ -331,7 +331,7 @@ class LSTM(Layer):\n         h_t = o_t * self.activation(c_t)\n         return h_t, c_t\n \n-    def output(self, train):\n+    def get_output(self, train):\n         X = self.get_input(train) \n         X = X.dimshuffle((1,0,2))\n \n\n@@ -67,6 +67,8 @@ class Sequential(object):\n         else:\n             self.constraints += [constraints.identity for _ in range(len(layer.params))]\n \n+    def get_output(self, train):\n+        return self.layers[-1].get_output(train)\n \n     def compile(self, optimizer, loss, class_mode=\"categorical\", y_dim_components=1):\n         self.optimizer = optimizers.get(optimizer)\n@@ -81,8 +83,8 @@ class Sequential(object):\n             self.layers[0].input = ndim_tensor(ndim)\n         self.X = self.layers[0].input\n \n-        self.y_train = self.layers[-1].output(train=True)\n-        self.y_test = self.layers[-1].output(train=False)\n+        self.y_train = self.get_output(train=True)\n+        self.y_test = self.get_output(train=False)\n \n         # output of model\n         self.y = ndim_tensor(y_dim_components+1)\n@@ -114,6 +116,7 @@ class Sequential(object):\n         self._test_with_acc = theano.function([self.X, self.y], [test_score, test_accuracy], \n             allow_input_downcast=True)\n \n+\n     def train(self, X, y, accuracy=False):\n         y = standardize_y(y)\n         if accuracy:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9390d63056e9e787a1942bb74b582d3224c75892", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 9 | Methods Changed: 2 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 30 | Churn Cumulative: 559 | Contributors (this commit): 10 | Commits (past 90d): 34 | Contributors (cumulative): 11 | DMM Complexity: 0.0\n\nDIFF:\n@@ -159,6 +159,14 @@ class Sequential(object):\n                 if verbose:\n                     print(\"Train on %d samples, validate on %d samples\" % (len(y), len(y_val)))\n         \n+        history = {'epoch':[], 'loss':[]}\n+        if show_accuracy:\n+            history['acc'] = []\n+        if do_validation:\n+            history['val_loss'] = []\n+            if show_accuracy:\n+                history['val_acc'] = []\n+\n         index_array = np.arange(len(X))\n         for epoch in range(nb_epoch):\n             if verbose:\n@@ -167,21 +175,29 @@ class Sequential(object):\n             if shuffle:\n                 np.random.shuffle(index_array)\n \n+            av_loss = 0.\n+            av_acc = 0.\n+            seen = 0\n+\n             batches = make_batches(len(X), batch_size)\n             for batch_index, (batch_start, batch_end) in enumerate(batches):\n                 if shuffle:\n                     batch_ids = index_array[batch_start:batch_end]\n                 else:\n                     batch_ids = slice(batch_start, batch_end)\n+                seen += len(batch_ids)\n                 X_batch = X[batch_ids]\n                 y_batch = y[batch_ids]\n \n                 if show_accuracy:\n                     loss, acc = self._train_with_acc(X_batch, y_batch)\n                     log_values = [('loss', loss), ('acc.', acc)]\n+                    av_loss += loss * len(batch_ids)\n+                    av_acc += acc * len(batch_ids)\n                 else:\n                     loss = self._train(X_batch, y_batch)\n                     log_values = [('loss', loss)]\n+                    av_loss += loss * len(batch_ids)\n \n                 # validation\n                 if do_validation and (batch_index == len(batches) - 1):\n@@ -196,6 +212,16 @@ class Sequential(object):\n                 if verbose:\n                     progbar.update(batch_end, log_values)\n \n+            history['epoch'].append(epoch)\n+            history['loss'].append(av_loss/seen)\n+            if do_validation:\n+                history['val_loss'].append(float(val_loss))\n+            if show_accuracy:\n+                history['acc'].append(av_acc/seen)\n+                if do_validation:\n+                    history['val_acc'].append(float(val_acc))\n+        return history\n+\n             \n     def predict_proba(self, X, batch_size=128, verbose=1):\n         batches = make_batches(len(X), batch_size)\n\n@@ -39,11 +39,12 @@ class Progbar(object):\n         '''\n         for k, v in values:\n             if k not in self.sum_values:\n-                self.sum_values[k] = [v, 1]\n+                self.sum_values[k] = [v * (current-self.seen_so_far), current-self.seen_so_far]\n                 self.unique_values.append(k)\n             else:\n                 self.sum_values[k][0] += v * (current-self.seen_so_far)\n                 self.sum_values[k][1] += (current-self.seen_so_far)\n+        self.seen_so_far = current\n \n         now = time.time()\n         if self.verbose == 1:\n@@ -84,7 +85,6 @@ class Progbar(object):\n \n             sys.stdout.write(info)\n             sys.stdout.flush()\n-            self.seen_so_far = current\n \n             if current >= self.target:\n                 sys.stdout.write(\"\\n\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c0691dfad9a8faff83764929caecefd0ffc6efc2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 130 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -53,7 +53,7 @@ def preprocess_data(X, scaler=None):\n     X = scaler.transform(X)\n     return X, scaler\n \n-def preprocess_labels(y, encoder=None, categorical=True):\n+def preprocess_labels(labels, encoder=None, categorical=True):\n     if not encoder:\n         encoder = LabelEncoder()\n         encoder.fit(labels)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9a083903207f9199003e1b75143f0415925a8783", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 7 | Churn Cumulative: 38 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -15,5 +15,12 @@ def l2(l=.01):\n         return g\n     return l2wrap\n \n+def l1l2(l1=.01, l2=.01):\n+    def l1l2wrap(g, p):\n+        g += T.sgn(p) * l1\n+        g += p * l2\n+        return g\n+    return l1l2wrap\n+\n def identity(g, p):\n     return g\n\\ No newline at end of file\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9a45500de99dd22361aa992db5ad8e0904d1dbc2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 85 | Contributors (this commit): 2 | Commits (past 90d): 9 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -106,7 +106,7 @@ class SimpleDeepRNN(Layer):\n         self.input = T.tensor3()\n \n         self.W = self.init((self.input_dim, self.output_dim))\n-        self.Us = [self.init((self.output_dim, self.output_dim)) for _ in range(self.depth)]\n+        self.Us = [self.inner_init((self.output_dim, self.output_dim)) for _ in range(self.depth)]\n         self.b = shared_zeros((self.output_dim))\n         self.params = [self.W] + self.Us + [self.b]\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ca3e6846e73fee7dc06ecceddde3320ae46d871f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 10 | Churn Cumulative: 545 | Contributors (this commit): 10 | Commits (past 90d): 28 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3,6 +3,7 @@ from __future__ import print_function\n import theano\n import theano.tensor as T\n import numpy as np\n+import warnings\n \n from . import optimizers\n from . import objectives\n@@ -222,8 +223,7 @@ class Sequential(object):\n                     history['val_acc'].append(float(val_acc))\n         return history\n \n-            \n-    def predict_proba(self, X, batch_size=128, verbose=1):\n+    def predict(self, X, batch_size=128, verbose=1):\n         batches = make_batches(len(X), batch_size)\n         if verbose==1:\n             progbar = Progbar(target=len(X))\n@@ -241,6 +241,12 @@ class Sequential(object):\n \n         return preds\n \n+    def predict_proba(self, X, batch_size=128, verbose=1):\n+        preds = self.predict(X, batch_size, verbose)\n+        if preds.min()<0 or preds.max()>1:\n+            warnings.warn(\"Network returning invalid probability values.\")\n+        return preds\n+\n \n     def predict_classes(self, X, batch_size=128, verbose=1):\n         proba = self.predict_proba(X, batch_size=batch_size, verbose=verbose)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1a3f984abd788a87ad3b34d64446d97c1c3864ef", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 550 | Contributors (this commit): 11 | Commits (past 90d): 29 | Contributors (cumulative): 11 | DMM Complexity: 0.0\n\nDIFF:\n@@ -169,6 +169,9 @@ class Sequential(object):\n                 history['val_acc'] = []\n \n         index_array = np.arange(len(X))\n+\n+        # -- allow user to terminate training\n+        try:\n             for epoch in range(nb_epoch):\n                 if verbose:\n                     print('Epoch', epoch)\n@@ -221,6 +224,8 @@ class Sequential(object):\n                     history['acc'].append(av_acc/seen)\n                     if do_validation:\n                         history['val_acc'].append(float(val_acc))\n+        except KeyboardInterrupt:\n+            print('Terminating on KeyboardInterrupt at Epoch', epoch)\n         return history\n \n     def predict(self, X, batch_size=128, verbose=1):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b763f8964f60a12df64f373546bf3d884e26ea8b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 134 | Contributors (this commit): 3 | Commits (past 90d): 6 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -31,6 +31,8 @@ from sklearn.preprocessing import StandardScaler\n         - with smaller layers, largers layers\n         - with more layers, less layers\n         - with different optimizers (SGD+momentum+decay is probably better than Adam!)\n+\n+    Get the data from Kaggle: https://www.kaggle.com/c/otto-group-product-classification-challenge/data\n '''\n \n np.random.seed(1337) # for reproducibility\n@@ -113,7 +115,7 @@ model.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n \n print(\"Training model...\")\n \n-model.fit(X, y, nb_epoch=20, batch_size=16, validation_split=0.15)\n+model.fit(X, y, nb_epoch=20, batch_size=128, validation_split=0.15)\n \n print(\"Generating submission...\")\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3108e9194c9243e7062a81d412399adf6463c1e0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 20 | Churn Cumulative: 58 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -12,17 +12,23 @@ class BatchNormalization(Layer):\n \n             mode: 0 -> featurewise normalization\n                   1 -> samplewise normalization (may sometimes outperform featurewise mode)\n+\n+            momentum: momentum term in the computation of a running estimate of the mean and std of the data\n     '''\n-    def __init__(self, input_shape, epsilon=1e-6, mode=0, weights=None):\n+    def __init__(self, input_shape, epsilon=1e-6, mode=0, momentum=0.9, weights=None):\n         super(BatchNormalization,self).__init__()\n         self.init = initializations.get(\"uniform\")\n         self.input_shape = input_shape\n         self.epsilon = epsilon\n         self.mode = mode\n+        self.momentum = momentum\n \n         self.gamma = self.init((self.input_shape))\n         self.beta = shared_zeros(self.input_shape)\n \n+        self.running_mean = None\n+        self.running_std = None\n+\n         self.params = [self.gamma, self.beta]\n         if weights is not None:\n             self.set_weights(weights)\n@@ -31,11 +37,23 @@ class BatchNormalization(Layer):\n         X = self.get_input(train)\n \n         if self.mode == 0:\n+            if train:\n                 m = X.mean(axis=0)\n                 # manual computation of std to prevent NaNs\n                 std = T.mean((X-m)**2 + self.epsilon, axis=0) ** 0.5\n                 X_normed = (X - m) / (std + self.epsilon)\n \n+                if self.running_mean is None:\n+                    self.running_mean = m\n+                    self.running_std = std\n+                else:\n+                    self.running_mean *= self.momentum\n+                    self.running_mean += (1-self.momentum) * m\n+                    self.running_std *= self.momentum\n+                    self.running_std += (1-self.momentum) * std\n+            else:\n+                X_normed = (X - self.running_mean) / (self.running_std + self.epsilon)\n+\n         elif self.mode == 1:\n             m = X.mean(axis=-1, keepdims=True)\n             std = X.std(axis=-1, keepdims=True)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6873b38acdfa5ae1be639146c01076d24a8ac7a0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 12 | Churn Cumulative: 562 | Contributors (this commit): 12 | Commits (past 90d): 30 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -71,7 +71,7 @@ class Sequential(object):\n     def get_output(self, train):\n         return self.layers[-1].get_output(train)\n \n-    def compile(self, optimizer, loss, class_mode=\"categorical\", y_dim_components=1):\n+    def compile(self, optimizer, loss, class_mode=\"categorical\", y_dim_components=1, theano_mode=None):\n         self.optimizer = optimizers.get(optimizer)\n         self.loss = objectives.get(loss)\n \n@@ -107,15 +107,15 @@ class Sequential(object):\n         updates = self.optimizer.get_updates(self.params, self.regularizers, self.constraints, train_loss)\n \n         self._train = theano.function([self.X, self.y], train_loss, \n-            updates=updates, allow_input_downcast=True)\n+            updates=updates, allow_input_downcast=True, mode=theano_mode)\n         self._train_with_acc = theano.function([self.X, self.y], [train_loss, train_accuracy], \n-            updates=updates, allow_input_downcast=True)\n+            updates=updates, allow_input_downcast=True, mode=theano_mode)\n         self._predict = theano.function([self.X], self.y_test, \n-            allow_input_downcast=True)\n+            allow_input_downcast=True, mode=theano_mode)\n         self._test = theano.function([self.X, self.y], test_score, \n-            allow_input_downcast=True)\n+            allow_input_downcast=True, mode=theano_mode)\n         self._test_with_acc = theano.function([self.X, self.y], [test_score, test_accuracy], \n-            allow_input_downcast=True)\n+            allow_input_downcast=True, mode=theano_mode)\n \n \n     def train(self, X, y, accuracy=False):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#094acd9319664c27caa5a87e68fcb1b48c7129c1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 88 | Contributors (this commit): 3 | Commits (past 90d): 10 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -147,6 +147,7 @@ class SimpleDeepRNN(Layer):\n             \"init\":self.init.__name__,\n             \"inner_init\":self.inner_init.__name__,\n             \"activation\":self.activation.__name__,\n+            \"inner_activation\":self.inner_activation.__name__,\n             \"truncate_gradient\":self.truncate_gradient,\n             \"return_sequences\":self.return_sequences}\n \n@@ -247,6 +248,7 @@ class GRU(Layer):\n             \"init\":self.init.__name__,\n             \"inner_init\":self.inner_init.__name__,\n             \"activation\":self.activation.__name__,\n+            \"inner_activation\":self.inner_activation.__name__,\n             \"truncate_gradient\":self.truncate_gradient,\n             \"return_sequences\":self.return_sequences}\n \n@@ -361,6 +363,7 @@ class LSTM(Layer):\n             \"init\":self.init.__name__,\n             \"inner_init\":self.inner_init.__name__,\n             \"activation\":self.activation.__name__,\n+            \"inner_activation\":self.inner_activation.__name__,\n             \"truncate_gradient\":self.truncate_gradient,\n             \"return_sequences\":self.return_sequences}\n         \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c8a104b8faa3f5ced2c50a5c3ece3627b0af1542", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 5 | Churn Cumulative: 567 | Contributors (this commit): 12 | Commits (past 90d): 31 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -182,10 +182,7 @@ class Sequential(object):\n \n             batches = make_batches(len(X), batch_size)\n             for batch_index, (batch_start, batch_end) in enumerate(batches):\n-                if shuffle:\n                 batch_ids = index_array[batch_start:batch_end]\n-                else:\n-                    batch_ids = slice(batch_start, batch_end)\n                 seen += len(batch_ids)\n                 X_batch = X[batch_ids]\n                 y_batch = y[batch_ids]\n@@ -329,3 +326,5 @@ class Sequential(object):\n             weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n             self.layers[k].set_weights(weights)\n         f.close()\n+\n+\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e82ab0ca50ec5230718e97d0affb2a8573ca52c9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 404 | Lines Deleted: 78 | Files Changed: 4 | Hunks: 47 | Methods Changed: 27 | Complexity Δ (Sum/Max): 36/17 | Churn Δ: 482 | Churn Cumulative: 1369 | Contributors (this commit): 13 | Commits (past 90d): 59 | Contributors (cumulative): 19 | DMM Complexity: 0.9824561403508771\n\nDIFF:\n@@ -42,6 +42,63 @@ class Layer(object):\n         return {\"name\":self.__class__.__name__}\n \n \n+class Merge(object): \n+    def __init__(self, models, mode='sum'):\n+        ''' Merge the output of a list of models into a single tensor.\n+            mode: {'sum', 'concat'}\n+        '''\n+        if len(models) < 2:\n+            raise Exception(\"Please specify two or more input models to merge\")\n+        self.mode = mode\n+        self.models = models\n+        self.params = []\n+        self.regularizers = []\n+        self.constraints = []\n+        for m in self.models:\n+            self.params += m.params\n+            self.regularizers += m.regularizers\n+            self.constraints += m.constraints\n+\n+    def get_output(self, train=False):\n+        if self.mode == 'sum':\n+            s = self.models[0].get_output(train)\n+            for i in range(1, len(self.models)):\n+                s += self.models[i].get_output(train)\n+            return s\n+        elif self.mode == 'concat':\n+            inputs = [self.models[i].get_output(train) for i in range(len(self.models))]\n+            return T.concatenate(inputs, axis=-1)\n+        else:\n+            raise Exception('Unknown merge mode')\n+\n+    def get_input(self, train=False):\n+        res = []\n+        for i in range(len(self.models)):\n+            o = self.models[i].get_input(train)\n+            if type(o) == list:\n+                res += o\n+            else:\n+                res.append(o)\n+        return res\n+\n+    def get_weights(self):\n+        weights = []\n+        for m in self.models:\n+            weights += m.get_weights()\n+        return weights\n+\n+    def set_weights(self, weights):\n+        for i in range(len(self.models)):\n+            nb_param = len(self.models[i].params)\n+            self.models[i].set_weights(weights[:nb_param])\n+            weights = weights[nb_param:]\n+\n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+            \"models\":[m.get_config() for m in self.models],\n+            \"mode\":self.mode}\n+\n+\n class Dropout(Layer):\n     '''\n         Hinton's dropout.\n\n@@ -10,7 +10,7 @@ from . import objectives\n from . import regularizers\n from . import constraints\n import time, copy\n-from .utils.generic_utils import Progbar\n+from .utils.generic_utils import Progbar, printv\n from six.moves import range\n \n def standardize_y(y):\n@@ -33,12 +33,94 @@ def ndim_tensor(ndim):\n         return T.tensor4()\n     return T.matrix()\n \n-class Sequential(object):\n+def standardize_X(X):\n+    if type(X) == list:\n+        return X\n+    else:\n+        return [X]\n+\n+def slice_X(X, start=None, stop=None):\n+    if type(X) == list:\n+        if hasattr(start, '__len__'):\n+            return [x[start] for x in X]\n+        else:\n+            return [x[start:stop] for x in X]\n+    else:\n+        if hasattr(start, '__len__'):\n+            return X[start]\n+        else:\n+            return X[start:stop]\n+\n+\n+class Model(object):\n+\n+    def get_output(self, train):\n+        raise NotImplementedError\n+\n+    def get_input(self, train):\n+        raise NotImplementedError\n+\n+    def compile(self, optimizer, loss, class_mode=\"categorical\", theano_mode=None):\n+        self.optimizer = optimizers.get(optimizer)\n+        self.loss = objectives.get(loss)\n+\n+        # input of model \n+        self.X_train = self.get_input(train=True)\n+        self.X_test = self.get_input(train=False)\n+\n+        self.y_train = self.get_output(train=True)\n+        self.y_test = self.get_output(train=False)\n+\n+        self.y_train = self.get_output(train=True)\n+        self.y_test = self.get_output(train=False)\n+\n+        # target of model\n+        self.y = T.zeros_like(self.y_train)\n+\n+        train_loss = self.loss(self.y, self.y_train)\n+        test_score = self.loss(self.y, self.y_test)\n+\n+        if class_mode == \"categorical\":\n+            train_accuracy = T.mean(T.eq(T.argmax(self.y, axis=-1), T.argmax(self.y_train, axis=-1)))\n+            test_accuracy = T.mean(T.eq(T.argmax(self.y, axis=-1), T.argmax(self.y_test, axis=-1)))\n+\n+        elif class_mode == \"binary\":\n+            train_accuracy = T.mean(T.eq(self.y, T.round(self.y_train)))\n+            test_accuracy = T.mean(T.eq(self.y, T.round(self.y_test)))\n+        else:\n+            raise Exception(\"Invalid class mode:\" + str(class_mode))\n+        self.class_mode = class_mode\n+\n+        updates = self.optimizer.get_updates(self.params, self.regularizers, self.constraints, train_loss)\n+\n+        if type(self.X_train) == list:\n+            train_ins = self.X_train + [self.y]\n+            test_ins = self.X_test + [self.y]\n+            predict_ins = self.X_test\n+        else:\n+            train_ins = [self.X_train, self.y]\n+            test_ins = [self.X_test, self.y]\n+            predict_ins = [self.X_test]\n+\n+        self._train = theano.function(train_ins, train_loss, \n+            updates=updates, allow_input_downcast=True, mode=theano_mode)\n+        self._train_with_acc = theano.function(train_ins, [train_loss, train_accuracy], \n+            updates=updates, allow_input_downcast=True, mode=theano_mode)\n+        self._predict = theano.function(predict_ins, self.y_test, \n+            allow_input_downcast=True, mode=theano_mode)\n+        self._test = theano.function(test_ins, test_score, \n+            allow_input_downcast=True, mode=theano_mode)\n+        self._test_with_acc = theano.function(test_ins, [test_score, test_accuracy], \n+            allow_input_downcast=True, mode=theano_mode)\n+\n+\n+class Sequential(Model):\n     def __init__(self):\n         self.layers = []\n-        self.params = []\n-        self.regularizers = []\n-        self.constraints = []\n+        self.params = [] # learnable\n+        self.regularizers = [] # same size as params\n+        self.constraints = [] # same size as params\n+\n \n     def add(self, layer):\n         self.layers.append(layer)\n@@ -68,74 +150,45 @@ class Sequential(object):\n         else:\n             self.constraints += [constraints.identity for _ in range(len(layer.params))]\n \n-    def get_output(self, train):\n+\n+    def get_output(self, train=False):\n         return self.layers[-1].get_output(train)\n \n-    def compile(self, optimizer, loss, class_mode=\"categorical\", y_dim_components=1, theano_mode=None):\n-        self.optimizer = optimizers.get(optimizer)\n-        self.loss = objectives.get(loss)\n \n-        # input of model \n+    def get_input(self, train=False):\n         if not hasattr(self.layers[0], 'input'):\n             for l in self.layers:\n                 if hasattr(l, 'input'):\n                     break\n             ndim = l.input.ndim \n             self.layers[0].input = ndim_tensor(ndim)\n-        self.X = self.layers[0].input\n-\n-        self.y_train = self.get_output(train=True)\n-        self.y_test = self.get_output(train=False)\n-\n-        # output of model\n-        self.y = ndim_tensor(y_dim_components+1)\n-\n-        train_loss = self.loss(self.y, self.y_train)\n-        test_score = self.loss(self.y, self.y_test)\n-\n-        if class_mode == \"categorical\":\n-            train_accuracy = T.mean(T.eq(T.argmax(self.y, axis=-1), T.argmax(self.y_train, axis=-1)))\n-            test_accuracy = T.mean(T.eq(T.argmax(self.y, axis=-1), T.argmax(self.y_test, axis=-1)))\n-\n-        elif class_mode == \"binary\":\n-            train_accuracy = T.mean(T.eq(self.y, T.round(self.y_train)))\n-            test_accuracy = T.mean(T.eq(self.y, T.round(self.y_test)))\n-        else:\n-            raise Exception(\"Invalid class mode:\" + str(class_mode))\n-        self.class_mode = class_mode\n-\n-        updates = self.optimizer.get_updates(self.params, self.regularizers, self.constraints, train_loss)\n-\n-        self._train = theano.function([self.X, self.y], train_loss, \n-            updates=updates, allow_input_downcast=True, mode=theano_mode)\n-        self._train_with_acc = theano.function([self.X, self.y], [train_loss, train_accuracy], \n-            updates=updates, allow_input_downcast=True, mode=theano_mode)\n-        self._predict = theano.function([self.X], self.y_test, \n-            allow_input_downcast=True, mode=theano_mode)\n-        self._test = theano.function([self.X, self.y], test_score, \n-            allow_input_downcast=True, mode=theano_mode)\n-        self._test_with_acc = theano.function([self.X, self.y], [test_score, test_accuracy], \n-            allow_input_downcast=True, mode=theano_mode)\n+        return self.layers[0].get_input(train)\n \n \n     def train(self, X, y, accuracy=False):\n+        X = standardize_X(X)\n         y = standardize_y(y)\n+        ins = X + [y]\n         if accuracy:\n-            return self._train_with_acc(X, y)\n+            return self._train_with_acc(*ins)\n         else:\n-            return self._train(X, y)\n+            return self._train(*ins)\n         \n \n     def test(self, X, y, accuracy=False):\n+        X = standardize_X(X)\n         y = standardize_y(y)\n+        ins = X + [y]\n         if accuracy:\n-            return self._test_with_acc(X, y)\n+            return self._test_with_acc(*ins)\n         else:\n-            return self._test(X, y)\n+            return self._test(*ins)\n \n \n     def fit(self, X, y, batch_size=128, nb_epoch=100, verbose=1,\n             validation_split=0., validation_data=None, shuffle=True, show_accuracy=False):\n+        \n+        X = standardize_X(X)\n         y = standardize_y(y)\n \n         do_validation = False\n@@ -143,8 +196,10 @@ class Sequential(object):\n             try:\n                 X_val, y_val = validation_data\n             except:\n-                raise Exception(\"Invalid format for validation data; provide a tuple (X_val, y_val).\")\n+                raise Exception(\"Invalid format for validation data; provide a tuple (X_val, y_val). \\\n+                    X_val may be a numpy array or a list of numpy arrays depending on your model input.\")\n             do_validation = True\n+            X_val = standardize_X(X_val)\n             y_val = standardize_y(y_val)\n             if verbose:\n                 print(\"Train on %d samples, validate on %d samples\" % (len(y), len(y_val)))\n@@ -154,8 +209,8 @@ class Sequential(object):\n                 # then split X into smaller X and X_val,\n                 # and split y into smaller y and y_val.\n                 do_validation = True\n-                split_at = int(len(X) * (1 - validation_split))\n-                (X, X_val) = (X[0:split_at], X[split_at:])\n+                split_at = int(len(y) * (1 - validation_split))\n+                (X, X_val) = (slice_X(X, 0, split_at), slice_X(X, split_at))\n                 (y, y_val) = (y[0:split_at], y[split_at:])\n                 if verbose:\n                     print(\"Train on %d samples, validate on %d samples\" % (len(y), len(y_val)))\n@@ -168,11 +223,11 @@ class Sequential(object):\n             if show_accuracy:\n                 history['val_acc'] = []\n \n-        index_array = np.arange(len(X))\n+        index_array = np.arange(len(y))\n         for epoch in range(nb_epoch):\n             if verbose:\n                 print('Epoch', epoch)\n-                progbar = Progbar(target=len(X), verbose=verbose)\n+                progbar = Progbar(target=len(y), verbose=verbose)\n             if shuffle:\n                 np.random.shuffle(index_array)\n \n@@ -180,20 +235,21 @@ class Sequential(object):\n             av_acc = 0.\n             seen = 0\n \n-            batches = make_batches(len(X), batch_size)\n+            batches = make_batches(len(y), batch_size)\n             for batch_index, (batch_start, batch_end) in enumerate(batches):\n                 batch_ids = index_array[batch_start:batch_end]\n                 seen += len(batch_ids)\n-                X_batch = X[batch_ids]\n+                X_batch = slice_X(X, batch_ids)\n                 y_batch = y[batch_ids]\n \n+                ins = X_batch + [y_batch]\n                 if show_accuracy:\n-                    loss, acc = self._train_with_acc(X_batch, y_batch)\n+                    loss, acc = self._train_with_acc(*ins)\n                     log_values = [('loss', loss), ('acc.', acc)]\n                     av_loss += loss * len(batch_ids)\n                     av_acc += acc * len(batch_ids)\n                 else:\n-                    loss = self._train(X_batch, y_batch)\n+                    loss = self._train(*ins)\n                     log_values = [('loss', loss)]\n                     av_loss += loss * len(batch_ids)\n \n@@ -221,15 +277,16 @@ class Sequential(object):\n         return history\n \n     def predict(self, X, batch_size=128, verbose=1):\n-        batches = make_batches(len(X), batch_size)\n+        X = standardize_X(X)\n+        batches = make_batches(len(X[0]), batch_size)\n         if verbose==1:\n-            progbar = Progbar(target=len(X))\n+            progbar = Progbar(target=len(X[0]))\n         for batch_index, (batch_start, batch_end) in enumerate(batches):\n-            X_batch = X[batch_start:batch_end]\n-            batch_preds = self._predict(X_batch)\n+            X_batch = slice_X(X, batch_start, batch_end)\n+            batch_preds = self._predict(*X_batch)\n \n             if batch_index == 0:\n-                shape = (len(X),) + batch_preds.shape[1:]\n+                shape = (len(X[0]),) + batch_preds.shape[1:]\n                 preds = np.zeros(shape)\n             preds[batch_start:batch_end] = batch_preds\n \n@@ -246,7 +303,7 @@ class Sequential(object):\n \n \n     def predict_classes(self, X, batch_size=128, verbose=1):\n-        proba = self.predict_proba(X, batch_size=batch_size, verbose=verbose)\n+        proba = self.predict(X, batch_size=batch_size, verbose=verbose)\n         if self.class_mode == \"categorical\":\n             return proba.argmax(axis=-1)\n         else:\n@@ -254,25 +311,27 @@ class Sequential(object):\n \n \n     def evaluate(self, X, y, batch_size=128, show_accuracy=False, verbose=1):\n+        X = standardize_X(X)\n         y = standardize_y(y)\n \n         if show_accuracy:\n             tot_acc = 0.\n         tot_score = 0.\n \n-        batches = make_batches(len(X), batch_size)\n+        batches = make_batches(len(y), batch_size)\n         if verbose:\n-            progbar = Progbar(target=len(X), verbose=verbose)\n+            progbar = Progbar(target=len(y), verbose=verbose)\n         for batch_index, (batch_start, batch_end) in enumerate(batches):\n-            X_batch = X[batch_start:batch_end]\n+            X_batch = slice_X(X, batch_start, batch_end)\n             y_batch = y[batch_start:batch_end]\n \n+            ins = X_batch + [y_batch]\n             if show_accuracy:\n-                loss, acc = self._test_with_acc(X_batch, y_batch)\n+                loss, acc = self._test_with_acc(*ins)\n                 tot_acc += acc\n                 log_values = [('loss', loss), ('acc.', acc)]\n             else:\n-                loss = self._test(X_batch, y_batch)\n+                loss = self._test(*ins)\n                 log_values = [('loss', loss)]\n             tot_score += loss\n \n@@ -285,18 +344,27 @@ class Sequential(object):\n         else:\n             return tot_score/len(batches)\n \n-    def describe(self, verbose=1):\n+    def get_config(self, verbose=0):\n         layers = []\n         for i, l in enumerate(self.layers):\n             config = l.get_config()\n             layers.append(config)\n         if verbose:\n-                print('Layer %d: %s' % (i, config.get('name', '?')))\n-                for k, v in config.items():\n-                    if k != 'name':\n-                        print('... ' + k + ' = ' + str(v))\n+            printv(layers)\n         return layers\n \n+    def get_weights(self):\n+        res = []\n+        for l in self.layers:\n+            res += l.get_weights()\n+        return res\n+\n+    def set_weights(self, weights):\n+        for i in range(len(self.layers)):\n+            nb_param = len(self.layers[i].params)\n+            self.layers[i].set_weights(weights[:nb_param])\n+            weights = weights[nb_param:]\n+\n     def save_weights(self, filepath):\n         # Save weights from all layers to HDF5\n         import h5py\n@@ -309,11 +377,8 @@ class Sequential(object):\n             g.attrs['nb_params'] = len(weights)\n             for n, param in enumerate(weights):\n                 param_name = 'param_{}'.format(n)\n-                param_dset = g.create_dataset(param_name, param.shape, dtype='float64')\n+                param_dset = g.create_dataset(param_name, param.shape, dtype=param.dtype)\n                 param_dset[:] = param\n-            for k, v in l.get_config().items():\n-                if v is not None:\n-                    g.attrs[k] = v\n         f.flush()\n         f.close()\n \n@@ -327,4 +392,3 @@ class Sequential(object):\n             self.layers[k].set_weights(weights)\n         f.close()\n         \n\\ No newline at end of file\n-\n\n@@ -17,6 +17,27 @@ def get_from_module(identifier, module_params, module_name, instantiate=False):\n def make_tuple(*args):\n     return args\n \n+def printv(v, prefix=''):\n+    if type(v) == dict:\n+        if 'name' in v:\n+            print(prefix + '#' + v['name'])\n+            del v['name']\n+        prefix += '...'\n+        for nk, nv in v.items():\n+            if type(nv) in [dict, list]:\n+                print(prefix + nk + ':')\n+                printv(nv, prefix)\n+            else:\n+                print(prefix + nk + ':' + str(nv))\n+    elif type(v) == list:\n+        prefix += '...'\n+        for i, nv in enumerate(v):\n+            print(prefix + '#' + str(i))\n+            printv(nv, prefix) \n+    else:\n+        prefix += '...'\n+        print(prefix + str(v))\n+\n class Progbar(object):\n     def __init__(self, target, width=30, verbose=1):\n         '''\n\n@@ -0,0 +1,184 @@\n+from __future__ import absolute_import\n+from __future__ import print_function\n+from keras.datasets import mnist\n+from keras.models import Sequential\n+from keras.layers.core import Dense, Activation, Merge\n+from keras.utils import np_utils\n+import numpy as np\n+\n+nb_classes = 10\n+batch_size = 128\n+nb_epoch = 1\n+\n+max_train_samples = 5000\n+max_test_samples = 1000\n+\n+np.random.seed(1337) # for reproducibility\n+\n+# the data, shuffled and split between tran and test sets\n+(X_train, y_train), (X_test, y_test) = mnist.load_data()\n+\n+X_train = X_train.reshape(60000,784)[:max_train_samples]\n+X_test = X_test.reshape(10000,784)[:max_test_samples]\n+X_train = X_train.astype(\"float32\")\n+X_test = X_test.astype(\"float32\")\n+X_train /= 255\n+X_test /= 255\n+\n+# convert class vectors to binary class matrices\n+Y_train = np_utils.to_categorical(y_train, nb_classes)[:max_train_samples]\n+Y_test = np_utils.to_categorical(y_test, nb_classes)[:max_test_samples]\n+\n+#########################\n+# sequential model test #\n+#########################\n+print('Test sequential')\n+model = Sequential()\n+model.add(Dense(784, 50))\n+model.add(Activation('relu'))\n+model.add(Dense(50, 10))\n+model.add(Activation('softmax'))\n+\n+model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n+model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=0, validation_data=(X_test, Y_test))\n+model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=0, validation_data=(X_test, Y_test))\n+model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=0, validation_split=0.1)\n+model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=0, validation_split=0.1)\n+model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0)\n+model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0, shuffle=False)\n+\n+score = model.evaluate(X_train, Y_train, verbose=0)\n+print('score:', score)\n+if score < 0.25:\n+    raise Exception('Score too low, learning issue.')\n+preds = model.predict(X_test, verbose=0)\n+classes = model.predict_classes(X_test, verbose=0)\n+\n+model.get_config(verbose=1)\n+\n+###################\n+# merge test: sum #\n+###################\n+print('Test merge: sum')\n+left = Sequential()\n+left.add(Dense(784, 50))\n+left.add(Activation('relu'))\n+\n+right = Sequential()\n+right.add(Dense(784, 50))\n+right.add(Activation('relu'))\n+\n+model = Sequential()\n+model.add(Merge([left, right], mode='sum'))\n+\n+model.add(Dense(50, 10))\n+model.add(Activation('softmax'))\n+\n+model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n+\n+model.fit([X_train, X_train], Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=0, validation_data=([X_test, X_test], Y_test))\n+model.fit([X_train, X_train], Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=0, validation_data=([X_test, X_test], Y_test))\n+model.fit([X_train, X_train], Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=0, validation_split=0.1)\n+model.fit([X_train, X_train], Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=0, validation_split=0.1)\n+model.fit([X_train, X_train], Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0)\n+model.fit([X_train, X_train], Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0, shuffle=False)\n+\n+score = model.evaluate([X_train, X_train], Y_train, verbose=0)\n+print('score:', score)\n+if score < 0.22:\n+    raise Exception('Score too low, learning issue.')\n+preds = model.predict([X_test, X_test], verbose=0)\n+classes = model.predict_classes([X_test, X_test], verbose=0)\n+\n+model.get_config(verbose=1)\n+\n+###################\n+# merge test: concat #\n+###################\n+print('Test merge: concat')\n+left = Sequential()\n+left.add(Dense(784, 50))\n+left.add(Activation('relu'))\n+\n+right = Sequential()\n+right.add(Dense(784, 50))\n+right.add(Activation('relu'))\n+\n+model = Sequential()\n+model.add(Merge([left, right], mode='concat'))\n+\n+model.add(Dense(50*2, 10))\n+model.add(Activation('softmax'))\n+\n+model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n+\n+model.fit([X_train, X_train], Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=0, validation_data=([X_test, X_test], Y_test))\n+model.fit([X_train, X_train], Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=0, validation_data=([X_test, X_test], Y_test))\n+model.fit([X_train, X_train], Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=0, validation_split=0.1)\n+model.fit([X_train, X_train], Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=0, validation_split=0.1)\n+model.fit([X_train, X_train], Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0)\n+model.fit([X_train, X_train], Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0, shuffle=False)\n+\n+score = model.evaluate([X_train, X_train], Y_train, verbose=0)\n+print('score:', score)\n+if score < 0.22:\n+    raise Exception('Score too low, learning issue.')\n+preds = model.predict([X_test, X_test], verbose=0)\n+classes = model.predict_classes([X_test, X_test], verbose=0)\n+\n+model.get_config(verbose=1)\n+\n+##########################\n+# test merge recursivity #\n+##########################\n+print('Test merge recursivity')\n+\n+left = Sequential()\n+left.add(Dense(784, 50))\n+left.add(Activation('relu'))\n+\n+right = Sequential()\n+right.add(Dense(784, 50))\n+right.add(Activation('relu'))\n+\n+righter = Sequential()\n+righter.add(Dense(784, 50))\n+righter.add(Activation('relu'))\n+\n+intermediate = Sequential()\n+intermediate.add(Merge([left, right], mode='sum'))\n+intermediate.add(Dense(50, 50))\n+intermediate.add(Activation('relu'))\n+\n+model = Sequential()\n+model.add(Merge([intermediate, righter], mode='sum'))\n+\n+model.add(Dense(50, 10))\n+model.add(Activation('softmax'))\n+\n+model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n+\n+model.fit([X_train, X_train, X_train], Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=0, validation_data=([X_test, X_test, X_test], Y_test))\n+model.fit([X_train, X_train, X_train], Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=0, validation_data=([X_test, X_test, X_test], Y_test))\n+model.fit([X_train, X_train, X_train], Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=0, validation_split=0.1)\n+model.fit([X_train, X_train, X_train], Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=0, validation_split=0.1)\n+model.fit([X_train, X_train, X_train], Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0)\n+model.fit([X_train, X_train, X_train], Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0, shuffle=False)\n+\n+score = model.evaluate([X_train, X_train, X_train], Y_train, verbose=0)\n+print('score:', score)\n+if score < 0.19:\n+    raise Exception('Score too low, learning issue.')\n+preds = model.predict([X_test, X_test, X_test], verbose=0)\n+classes = model.predict_classes([X_test, X_test, X_test], verbose=0)\n+\n+model.get_config(verbose=1)\n+\n+model.save_weights('temp.h5')\n+model.load_weights('temp.h5')\n+\n+score = model.evaluate([X_train, X_train, X_train], Y_train, verbose=0)\n+print('score:', score)\n+\n+\n+\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
