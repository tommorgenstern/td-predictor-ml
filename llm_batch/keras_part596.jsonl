{"custom_id": "keras#6f2d44e3ef6dde2584a6b5c6b6f3ec5b0ee1e6f8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 100 | Lines Deleted: 0 | Files Changed: 6 | Hunks: 6 | Methods Changed: 6 | Complexity Δ (Sum/Max): 8/4 | Churn Δ: 100 | Churn Cumulative: 1481 | Contributors (this commit): 7 | Commits (past 90d): 68 | Contributors (cumulative): 16 | DMM Complexity: 1.0\n\nDIFF:\n@@ -11,6 +11,7 @@ from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.backend.common.stateless_scope import StatelessScope\n from keras_core.backend.common.stateless_scope import get_stateless_scope\n from keras_core.backend.common.stateless_scope import in_stateless_scope\n+from keras_core.backend.jax import core\n from keras_core.backend.jax import image\n from keras_core.backend.jax import math\n from keras_core.backend.jax import nn\n\n@@ -0,0 +1,7 @@\n+import jax.numpy as jnp\n+\n+\n+def scatter(indices, values, shape):\n+    zeros = jnp.zeros(shape, values.dtype)\n+    key = tuple(jnp.moveaxis(indices, -1, 0))\n+    return zeros.at[key].set(values)\n\n@@ -8,6 +8,7 @@ from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.backend.common.stateless_scope import StatelessScope\n from keras_core.backend.common.stateless_scope import get_stateless_scope\n from keras_core.backend.common.stateless_scope import in_stateless_scope\n+from keras_core.backend.tensorflow import core\n from keras_core.backend.tensorflow import image\n from keras_core.backend.tensorflow import math\n from keras_core.backend.tensorflow import nn\n\n@@ -0,0 +1,5 @@\n+import tensorflow as tf\n+\n+\n+def scatter(indices, values, shape):\n+    return tf.scatter_nd(indices, values, shape)\n\n@@ -0,0 +1,22 @@\n+\"\"\"\n+scatter\n+\"\"\"\n+\n+from keras_core import backend\n+from keras_core.backend import KerasTensor\n+from keras_core.backend import any_symbolic_tensors\n+from keras_core.operations.operation import Operation\n+\n+\n+class Scatter(Operation):\n+    def call(self, indices, values, shape):\n+        return backend.core.scatter(indices, values, shape)\n+\n+    def compute_output_spec(self, indices, values, shape):\n+        return KerasTensor(shape, dtype=values.dtype)\n+\n+\n+def scatter(indices, values, shape):\n+    if any_symbolic_tensors((indices, values, shape)):\n+        return Scatter().symbolic_call(indices, values, shape)\n+    return backend.core.scatter(indices, values, shape)\n\n@@ -0,0 +1,64 @@\n+import numpy as np\n+import pytest\n+\n+from keras_core import backend\n+from keras_core import testing\n+from keras_core.operations import core\n+\n+\n+@pytest.mark.skipif(\n+    not backend.DYNAMIC_SHAPES_OK,\n+    reason=\"Backend does not support dynamic shapes\",\n+)\n+class CoreOpsDynamicShapeTest(testing.TestCase):\n+    pass\n+\n+\n+class CoreOpsStaticShapeTest(testing.TestCase):\n+    def test_scatter(self):\n+        # Requires dtype\n+        indices = np.array([[0]], dtype=\"int32\")\n+        values = np.array([0], dtype=\"int32\")\n+        shape = (8,)\n+        self.assertEqual(core.scatter(indices, values, shape).shape, (8,))\n+\n+\n+class CoreOpsCorrectnessTest(testing.TestCase):\n+    def test_scatter(self):\n+        # Test 1D\n+        indices = np.array([[1], [3], [4], [7]])\n+        values = np.array([9, 10, 11, 12])\n+        self.assertAllClose(\n+            core.scatter(indices, values, (8,)),\n+            [0, 9, 0, 10, 11, 0, 0, 12],\n+        )\n+        # Test 2D\n+        indices = np.array([[0, 1], [2, 0]])\n+        values = np.array([5, 10])\n+        self.assertAllClose(\n+            core.scatter(indices, values, (3, 2)), [[0, 5], [0, 0], [10, 0]]\n+        )\n+        # Test 3D\n+        indices = np.array([[1], [3]])\n+        values = np.array(\n+            [\n+                [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n+                [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n+            ]\n+        )\n+        self.assertAllClose(\n+            core.scatter(indices, values, (4, 4, 4)),\n+            [\n+                [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],\n+                [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n+                [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],\n+                [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n+            ],\n+        )\n+        # Test slices\n+        indices = np.array([[2], [4]])\n+        values = np.array([[1, 2, 3], [4, 5, 6]])\n+        self.assertAllClose(\n+            core.scatter(indices, values, (6, 3)),\n+            [[0, 0, 0], [0, 0, 0], [1, 2, 3], [0, 0, 0], [4, 5, 6], [0, 0, 0]],\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#42236e5d4e038a6d709d1bec5ac535c6834893f6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1706 | Lines Deleted: 722 | Files Changed: 36 | Hunks: 80 | Methods Changed: 88 | Complexity Δ (Sum/Max): 82/109 | Churn Δ: 2428 | Churn Cumulative: 18203 | Contributors (this commit): 16 | Commits (past 90d): 366 | Contributors (cumulative): 104 | DMM Complexity: 0.7052980132450332\n\nDIFF:\n@@ -11,7 +11,6 @@ from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.backend.common.stateless_scope import StatelessScope\n from keras_core.backend.common.stateless_scope import get_stateless_scope\n from keras_core.backend.common.stateless_scope import in_stateless_scope\n-from keras_core.backend.jax import core\n from keras_core.backend.jax import image\n from keras_core.backend.jax import math\n from keras_core.backend.jax import nn\n\n@@ -1,7 +0,0 @@\n-import jax.numpy as jnp\n-\n-\n-def scatter(indices, values, shape):\n-    zeros = jnp.zeros(shape, values.dtype)\n-    key = tuple(jnp.moveaxis(indices, -1, 0))\n-    return zeros.at[key].set(values)\n\n@@ -8,12 +8,14 @@ from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.backend.common.stateless_scope import StatelessScope\n from keras_core.backend.common.stateless_scope import get_stateless_scope\n from keras_core.backend.common.stateless_scope import in_stateless_scope\n-from keras_core.backend.tensorflow import core\n from keras_core.backend.tensorflow import image\n from keras_core.backend.tensorflow import math\n from keras_core.backend.tensorflow import nn\n from keras_core.backend.tensorflow import numpy\n from keras_core.backend.tensorflow import random\n+from keras_core.backend.tensorflow.rnn import gru\n+from keras_core.backend.tensorflow.rnn import lstm\n+from keras_core.backend.tensorflow.rnn import rnn\n from keras_core.utils.naming import auto_name\n \n DYNAMIC_SHAPES_OK = True\n\n@@ -1,5 +0,0 @@\n-import tensorflow as tf\n-\n-\n-def scatter(indices, values, shape):\n-    return tf.scatter_nd(indices, values, shape)\n\n@@ -602,458 +602,3 @@ def binary_crossentropy(target, output, from_logits=False):\n     bce = target * tf.math.log(output)\n     bce += (1 - target) * tf.math.log(1 - output)\n     return -bce\n-\n-\n-def rnn(\n-    step_function,\n-    inputs,\n-    initial_states,\n-    go_backwards=False,\n-    mask=None,\n-    constants=None,\n-    unroll=False,\n-    input_length=None,\n-    time_major=False,\n-    zero_output_for_mask=False,\n-    return_all_outputs=True,\n-):\n-    \"\"\"Iterates over the time dimension of a tensor.\n-\n-    Args:\n-        step_function: RNN step function.\n-            Args;\n-                `input`; Tensor with shape `(samples, ...)` (no time dimension),\n-                    representing input for the batch of samples at a certain\n-                    time step.\n-                `states`; List of tensors.\n-            Returns;\n-                `output`; Tensor with shape `(samples, output_dim)`\n-                    (no time dimension).\n-                `new_states`; List of tensors, same length and shapes\n-                    as 'states'. The first state in the list must be the\n-                    output tensor at the previous timestep.\n-        inputs: Tensor of temporal data of shape `(samples, time, ...)`\n-            (at least 3D), or nested tensors, and each of which has shape\n-            `(samples, time, ...)`.\n-        initial_states: Tensor with shape `(samples, state_size)`\n-            (no time dimension), containing the initial values for the states\n-            used in the step function. In the case that state_size is in a\n-            nested shape, the shape of initial_states will also follow the\n-            nested structure.\n-        go_backwards: Boolean. If `True`, do the iteration over the time\n-            dimension in reverse order and return the reversed sequence.\n-        mask: Binary tensor with shape `(samples, time, 1)`,\n-            with a zero for every element that is masked.\n-        constants: List of constant values passed at each step.\n-        unroll: Whether to unroll the RNN or to use a symbolic `while_loop`.\n-        input_length: An integer or a 1-D Tensor, depending on whether\n-            the time dimension is fixed-length or not. In case of variable\n-            length input, it is used for masking in case there's no mask\n-            specified.\n-        time_major: Boolean. If `True`, the inputs and outputs will be in shape\n-            `(timesteps, batch, ...)`, whereas in the False case, it will be\n-            `(batch, timesteps, ...)`. Using `time_major = True` is a bit more\n-            efficient because it avoids transposes at the beginning and end of\n-            the RNN calculation. However, most TensorFlow data is batch-major,\n-            so by default this function accepts input and emits output in\n-            batch-major form.\n-        zero_output_for_mask: Boolean. If `True`, the output for masked timestep\n-            will be zeros, whereas in the `False` case, output from previous\n-            timestep is returned.\n-        return_all_outputs: Boolean. If `True`, return the recurrent outputs for\n-            all timesteps in the sequence. If `False`, only return the output\n-            for the last timestep (which consumes less memory).\n-\n-    Returns:\n-        A tuple, `(last_output, outputs, new_states)`.\n-            - `last_output`: the latest output of the rnn,\n-                with shape `(samples, ...)`.\n-            - `outputs`:\n-                - If `return_all_outputs=True`: a tensor with shape\n-                  `(samples, time, ...)` where each entry `outputs[s, t]` is the\n-                  output of the step function at time `t` for sample `s`\n-                - Else, a tensor equal to `last_output` with shape\n-                  `(samples, 1, ...)`\n-            - `new_states`: list of tensors, latest states returned by\n-                the step function, of shape `(samples, ...)`.\n-    \"\"\"\n-\n-    def swap_batch_timestep(input_t):\n-        # Swap the batch and timestep dim for the incoming tensor.\n-        axes = list(range(len(input_t.shape)))\n-        axes[0], axes[1] = 1, 0\n-        return tf.transpose(input_t, axes)\n-\n-    if not time_major:\n-        inputs = tf.nest.map_structure(swap_batch_timestep, inputs)\n-\n-    flatted_inputs = tf.nest.flatten(inputs)\n-    time_steps = flatted_inputs[0].shape[0]\n-    batch = flatted_inputs[0].shape[1]\n-    time_steps_t = tf.shape(flatted_inputs[0])[0]\n-\n-    for input_ in flatted_inputs:\n-        input_.shape.with_rank_at_least(3)\n-\n-    if mask is not None:\n-        if mask.dtype != tf.bool:\n-            mask = tf.cast(mask, tf.bool)\n-        if len(mask.shape) == 2:\n-            mask = tf.expand_dims(mask, axis=-1)\n-        if not time_major:\n-            mask = swap_batch_timestep(mask)\n-\n-    if constants is None:\n-        constants = []\n-\n-    # tf.where needs its condition tensor to be the same shape as its two\n-    # result tensors, but in our case the condition (mask) tensor is\n-    # (nsamples, 1), and inputs are (nsamples, ndimensions) or even more.\n-    # So we need to broadcast the mask to match the shape of inputs.\n-    # That's what the tile call does, it just repeats the mask along its\n-    # second dimension n times.\n-    def _expand_mask(mask_t, input_t, fixed_dim=1):\n-        if tf.nest.is_nested(mask_t):\n-            raise ValueError(\n-                f\"mask_t is expected to be tensor, but got {mask_t}\"\n-            )\n-        if tf.nest.is_nested(input_t):\n-            raise ValueError(\n-                f\"input_t is expected to be tensor, but got {input_t}\"\n-            )\n-        rank_diff = len(input_t.shape) - len(mask_t.shape)\n-        for _ in range(rank_diff):\n-            mask_t = tf.expand_dims(mask_t, -1)\n-        multiples = [1] * fixed_dim + input_t.shape.as_list()[fixed_dim:]\n-        return tf.tile(mask_t, multiples)\n-\n-    if unroll:\n-        if not time_steps:\n-            raise ValueError(\"Unrolling requires a fixed number of timesteps.\")\n-        states = tuple(initial_states)\n-        successive_states = []\n-        successive_outputs = []\n-\n-        # Process the input tensors. The input tensor need to be split on the\n-        # time_step dim, and reverse if go_backwards is True. In the case of\n-        # nested input, the input is flattened and then transformed\n-        # individually.  The result of this will be a tuple of lists, each of\n-        # the item in tuple is list of the tensor with shape (batch, feature)\n-        def _process_single_input_t(input_t):\n-            input_t = tf.unstack(input_t)  # unstack for time_step dim\n-            if go_backwards:\n-                input_t.reverse()\n-            return input_t\n-\n-        if tf.nest.is_nested(inputs):\n-            processed_input = tf.nest.map_structure(\n-                _process_single_input_t, inputs\n-            )\n-        else:\n-            processed_input = (_process_single_input_t(inputs),)\n-\n-        def _get_input_tensor(time):\n-            inp = [t_[time] for t_ in processed_input]\n-            return tf.nest.pack_sequence_as(inputs, inp)\n-\n-        if mask is not None:\n-            mask_list = tf.unstack(mask)\n-            if go_backwards:\n-                mask_list.reverse()\n-\n-            for i in range(time_steps):\n-                inp = _get_input_tensor(i)\n-                mask_t = mask_list[i]\n-                output, new_states = step_function(\n-                    inp, tuple(states) + tuple(constants)\n-                )\n-                tiled_mask_t = _expand_mask(mask_t, output)\n-\n-                if not successive_outputs:\n-                    prev_output = tf.zeros_like(output)\n-                else:\n-                    prev_output = successive_outputs[-1]\n-\n-                output = tf.where(tiled_mask_t, output, prev_output)\n-\n-                flat_states = tf.nest.flatten(states)\n-                flat_new_states = tf.nest.flatten(new_states)\n-                tiled_mask_t = tuple(\n-                    _expand_mask(mask_t, s) for s in flat_states\n-                )\n-                flat_final_states = tuple(\n-                    tf.where(m, s, ps)\n-                    for m, s, ps in zip(\n-                        tiled_mask_t, flat_new_states, flat_states\n-                    )\n-                )\n-                states = tf.nest.pack_sequence_as(states, flat_final_states)\n-\n-                if return_all_outputs:\n-                    successive_outputs.append(output)\n-                    successive_states.append(states)\n-                else:\n-                    successive_outputs = [output]\n-                    successive_states = [states]\n-            last_output = successive_outputs[-1]\n-            new_states = successive_states[-1]\n-            outputs = tf.stack(successive_outputs)\n-\n-            if zero_output_for_mask:\n-                last_output = tf.where(\n-                    _expand_mask(mask_list[-1], last_output),\n-                    last_output,\n-                    tf.zeros_like(last_output),\n-                )\n-                outputs = tf.where(\n-                    _expand_mask(mask, outputs, fixed_dim=2),\n-                    outputs,\n-                    tf.zeros_like(outputs),\n-                )\n-\n-        else:  # mask is None\n-            for i in range(time_steps):\n-                inp = _get_input_tensor(i)\n-                output, states = step_function(\n-                    inp, tuple(states) + tuple(constants)\n-                )\n-                if return_all_outputs:\n-                    successive_outputs.append(output)\n-                    successive_states.append(states)\n-                else:\n-                    successive_outputs = [output]\n-                    successive_states = [states]\n-            last_output = successive_outputs[-1]\n-            new_states = successive_states[-1]\n-            outputs = tf.stack(successive_outputs)\n-\n-    else:  # Unroll == False\n-        states = tuple(initial_states)\n-\n-        # Create input tensor array, if the inputs is nested tensors, then it\n-        # will be flattened first, and tensor array will be created one per\n-        # flattened tensor.\n-        input_ta = tuple(\n-            tf.TensorArray(\n-                dtype=inp.dtype,\n-                size=time_steps_t,\n-                tensor_array_name=f\"input_ta_{i}\",\n-            )\n-            for i, inp in enumerate(flatted_inputs)\n-        )\n-        input_ta = tuple(\n-            ta.unstack(input_)\n-            if not go_backwards\n-            else ta.unstack(tf.reverse(input_, [0]))\n-            for ta, input_ in zip(input_ta, flatted_inputs)\n-        )\n-\n-        # Get the time(0) input and compute the output for that, the output will\n-        # be used to determine the dtype of output tensor array. Don't read from\n-        # input_ta due to TensorArray clear_after_read default to True.\n-        input_time_zero = tf.nest.pack_sequence_as(\n-            inputs, [inp[0] for inp in flatted_inputs]\n-        )\n-        # output_time_zero is used to determine the cell output shape and its\n-        # dtype.  the value is discarded.\n-        output_time_zero, _ = step_function(\n-            input_time_zero, tuple(initial_states) + tuple(constants)\n-        )\n-\n-        output_ta_size = time_steps_t if return_all_outputs else 1\n-        output_ta = tuple(\n-            tf.TensorArray(\n-                dtype=out.dtype,\n-                size=output_ta_size,\n-                element_shape=out.shape,\n-                tensor_array_name=f\"output_ta_{i}\",\n-            )\n-            for i, out in enumerate(tf.nest.flatten(output_time_zero))\n-        )\n-\n-        time = tf.constant(0, dtype=\"int32\", name=\"time\")\n-\n-        if input_length is None:\n-            max_iterations = time_steps_t\n-        else:\n-            max_iterations = tf.reduce_max(input_length)\n-\n-        while_loop_kwargs = {\n-            \"cond\": lambda time, *_: time < time_steps_t,\n-            \"maximum_iterations\": max_iterations,\n-            \"parallel_iterations\": 32,\n-            \"swap_memory\": True,\n-        }\n-        if mask is not None:\n-            if go_backwards:\n-                mask = tf.reverse(mask, [0])\n-\n-            mask_ta = tf.TensorArray(\n-                dtype=tf.bool, size=time_steps_t, tensor_array_name=\"mask_ta\"\n-            )\n-            mask_ta = mask_ta.unstack(mask)\n-\n-            def masking_fn(time):\n-                return mask_ta.read(time)\n-\n-            def compute_masked_output(mask_t, flat_out, flat_mask):\n-                tiled_mask_t = tuple(\n-                    _expand_mask(mask_t, o, fixed_dim=len(mask_t.shape))\n-                    for o in flat_out\n-                )\n-                return tuple(\n-                    tf.where(m, o, fm)\n-                    for m, o, fm in zip(tiled_mask_t, flat_out, flat_mask)\n-                )\n-\n-        elif isinstance(input_length, tf.Tensor):\n-            if go_backwards:\n-                max_len = tf.reduce_max(input_length, axis=0)\n-                rev_input_length = tf.subtract(max_len - 1, input_length)\n-\n-                def masking_fn(time):\n-                    return tf.less(rev_input_length, time)\n-\n-            else:\n-\n-                def masking_fn(time):\n-                    return tf.greater(input_length, time)\n-\n-            def compute_masked_output(mask_t, flat_out, flat_mask):\n-                return tuple(\n-                    tf.where(mask_t, o, zo)\n-                    for (o, zo) in zip(flat_out, flat_mask)\n-                )\n-\n-        else:\n-            masking_fn = None\n-\n-        if masking_fn is not None:\n-            # Mask for the T output will be base on the output of T - 1. In the\n-            # case T = 0, a zero filled tensor will be used.\n-            flat_zero_output = tuple(\n-                tf.zeros_like(o) for o in tf.nest.flatten(output_time_zero)\n-            )\n-\n-            def _step(time, output_ta_t, prev_output, *states):\n-                \"\"\"RNN step function.\n-\n-                Args:\n-                    time: Current timestep value.\n-                    output_ta_t: TensorArray.\n-                    prev_output: tuple of outputs from time - 1.\n-                    *states: List of states.\n-\n-                Returns:\n-                    Tuple: `(time + 1, output_ta_t, output) + tuple(new_states)`\n-                \"\"\"\n-                current_input = tuple(ta.read(time) for ta in input_ta)\n-                # maybe set shape.\n-                current_input = tf.nest.pack_sequence_as(inputs, current_input)\n-                mask_t = masking_fn(time)\n-                output, new_states = step_function(\n-                    current_input, tuple(states) + tuple(constants)\n-                )\n-                # mask output\n-                flat_output = tf.nest.flatten(output)\n-                flat_mask_output = (\n-                    flat_zero_output\n-                    if zero_output_for_mask\n-                    else tf.nest.flatten(prev_output)\n-                )\n-                flat_new_output = compute_masked_output(\n-                    mask_t, flat_output, flat_mask_output\n-                )\n-\n-                # mask states\n-                flat_state = tf.nest.flatten(states)\n-                flat_new_state = tf.nest.flatten(new_states)\n-                flat_final_state = compute_masked_output(\n-                    mask_t, flat_new_state, flat_state\n-                )\n-                new_states = tf.nest.pack_sequence_as(\n-                    new_states, flat_final_state\n-                )\n-\n-                ta_index_to_write = time if return_all_outputs else 0\n-                output_ta_t = tuple(\n-                    ta.write(ta_index_to_write, out)\n-                    for ta, out in zip(output_ta_t, flat_new_output)\n-                )\n-\n-                return (time + 1, output_ta_t, tuple(flat_new_output)) + tuple(\n-                    new_states\n-                )\n-\n-            final_outputs = tf.while_loop(\n-                body=_step,\n-                loop_vars=(time, output_ta, flat_zero_output) + states,\n-                **while_loop_kwargs,\n-            )\n-            # Skip final_outputs[2] which is the output for final timestep.\n-            new_states = final_outputs[3:]\n-        else:\n-\n-            def _step(time, output_ta_t, *states):\n-                \"\"\"RNN step function.\n-\n-                Args:\n-                    time: Current timestep value.\n-                    output_ta_t: TensorArray.\n-                    *states: List of states.\n-\n-                Returns:\n-                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n-                \"\"\"\n-                current_input = tuple(ta.read(time) for ta in input_ta)\n-                current_input = tf.nest.pack_sequence_as(inputs, current_input)\n-                output, new_states = step_function(\n-                    current_input, tuple(states) + tuple(constants)\n-                )\n-                flat_new_state = tf.nest.flatten(new_states)\n-\n-                flat_output = tf.nest.flatten(output)\n-                ta_index_to_write = time if return_all_outputs else 0\n-                output_ta_t = tuple(\n-                    ta.write(ta_index_to_write, out)\n-                    for ta, out in zip(output_ta_t, flat_output)\n-                )\n-\n-                new_states = tf.nest.pack_sequence_as(\n-                    initial_states, flat_new_state\n-                )\n-                return (time + 1, output_ta_t) + tuple(new_states)\n-\n-            final_outputs = tf.while_loop(\n-                body=_step,\n-                loop_vars=(time, output_ta) + states,\n-                **while_loop_kwargs,\n-            )\n-            new_states = final_outputs[2:]\n-\n-        output_ta = final_outputs[1]\n-\n-        outputs = tuple(o.stack() for o in output_ta)\n-        last_output = tuple(o[-1] for o in outputs)\n-\n-        outputs = tf.nest.pack_sequence_as(output_time_zero, outputs)\n-        last_output = tf.nest.pack_sequence_as(output_time_zero, last_output)\n-\n-    # static shape inference\n-    def set_shape(output_):\n-        if isinstance(output_, tf.Tensor):\n-            shape = output_.shape.as_list()\n-            if return_all_outputs:\n-                shape[0] = time_steps\n-            else:\n-                shape[0] = 1\n-            shape[1] = batch\n-            output_.set_shape(shape)\n-        return output_\n-\n-    outputs = tf.nest.map_structure(set_shape, outputs)\n-\n-    if not time_major:\n-        outputs = tf.nest.map_structure(swap_batch_timestep, outputs)\n-\n-    return last_output, outputs, new_states\n\n@@ -0,0 +1,763 @@\n+import tensorflow as tf\n+\n+\n+def rnn(\n+    step_function,\n+    inputs,\n+    initial_states,\n+    go_backwards=False,\n+    mask=None,\n+    constants=None,\n+    unroll=False,\n+    input_length=None,\n+    time_major=False,\n+    zero_output_for_mask=False,\n+    return_all_outputs=True,\n+):\n+    \"\"\"Iterates over the time dimension of a tensor.\n+\n+    Args:\n+        step_function: RNN step function.\n+            Args;\n+                `input`; Tensor with shape `(samples, ...)` (no time dimension),\n+                    representing input for the batch of samples at a certain\n+                    time step.\n+                `states`; List of tensors.\n+            Returns;\n+                `output`; Tensor with shape `(samples, output_dim)`\n+                    (no time dimension).\n+                `new_states`; List of tensors, same length and shapes\n+                    as 'states'. The first state in the list must be the\n+                    output tensor at the previous timestep.\n+        inputs: Tensor of temporal data of shape `(samples, time, ...)`\n+            (at least 3D), or nested tensors, and each of which has shape\n+            `(samples, time, ...)`.\n+        initial_states: Tensor with shape `(samples, state_size)`\n+            (no time dimension), containing the initial values for the states\n+            used in the step function. In the case that state_size is in a\n+            nested shape, the shape of initial_states will also follow the\n+            nested structure.\n+        go_backwards: Boolean. If `True`, do the iteration over the time\n+            dimension in reverse order and return the reversed sequence.\n+        mask: Binary tensor with shape `(samples, time, 1)`,\n+            with a zero for every element that is masked.\n+        constants: List of constant values passed at each step.\n+        unroll: Whether to unroll the RNN or to use a symbolic `while_loop`.\n+        input_length: An integer or a 1-D Tensor, depending on whether\n+            the time dimension is fixed-length or not. In case of variable\n+            length input, it is used for masking in case there's no mask\n+            specified.\n+        time_major: Boolean. If `True`, the inputs and outputs will be in shape\n+            `(timesteps, batch, ...)`, whereas in the False case, it will be\n+            `(batch, timesteps, ...)`. Using `time_major = True` is a bit more\n+            efficient because it avoids transposes at the beginning and end of\n+            the RNN calculation. However, most TensorFlow data is batch-major,\n+            so by default this function accepts input and emits output in\n+            batch-major form.\n+        zero_output_for_mask: Boolean. If `True`, the output for masked timestep\n+            will be zeros, whereas in the `False` case, output from previous\n+            timestep is returned.\n+        return_all_outputs: Boolean. If `True`, return the recurrent outputs for\n+            all timesteps in the sequence. If `False`, only return the output\n+            for the last timestep (which consumes less memory).\n+\n+    Returns:\n+        A tuple, `(last_output, outputs, new_states)`.\n+            - `last_output`: the latest output of the rnn,\n+                with shape `(samples, ...)`.\n+            - `outputs`:\n+                - If `return_all_outputs=True`: a tensor with shape\n+                  `(samples, time, ...)` where each entry `outputs[s, t]` is the\n+                  output of the step function at time `t` for sample `s`\n+                - Else, a tensor equal to `last_output` with shape\n+                  `(samples, 1, ...)`\n+            - `new_states`: list of tensors, latest states returned by\n+                the step function, of shape `(samples, ...)`.\n+    \"\"\"\n+\n+    def swap_batch_timestep(input_t):\n+        # Swap the batch and timestep dim for the incoming tensor.\n+        axes = list(range(len(input_t.shape)))\n+        axes[0], axes[1] = 1, 0\n+        return tf.transpose(input_t, axes)\n+\n+    if not time_major:\n+        inputs = tf.nest.map_structure(swap_batch_timestep, inputs)\n+\n+    flatted_inputs = tf.nest.flatten(inputs)\n+    time_steps = flatted_inputs[0].shape[0]\n+    batch = flatted_inputs[0].shape[1]\n+    time_steps_t = tf.shape(flatted_inputs[0])[0]\n+\n+    for input_ in flatted_inputs:\n+        input_.shape.with_rank_at_least(3)\n+\n+    if mask is not None:\n+        if mask.dtype != tf.bool:\n+            mask = tf.cast(mask, tf.bool)\n+        if len(mask.shape) == 2:\n+            mask = tf.expand_dims(mask, axis=-1)\n+        if not time_major:\n+            mask = swap_batch_timestep(mask)\n+\n+    if constants is None:\n+        constants = []\n+\n+    # tf.where needs its condition tensor to be the same shape as its two\n+    # result tensors, but in our case the condition (mask) tensor is\n+    # (nsamples, 1), and inputs are (nsamples, ndimensions) or even more.\n+    # So we need to broadcast the mask to match the shape of inputs.\n+    # That's what the tile call does, it just repeats the mask along its\n+    # second dimension n times.\n+    def _expand_mask(mask_t, input_t, fixed_dim=1):\n+        if tf.nest.is_nested(mask_t):\n+            raise ValueError(\n+                f\"mask_t is expected to be tensor, but got {mask_t}\"\n+            )\n+        if tf.nest.is_nested(input_t):\n+            raise ValueError(\n+                f\"input_t is expected to be tensor, but got {input_t}\"\n+            )\n+        rank_diff = len(input_t.shape) - len(mask_t.shape)\n+        for _ in range(rank_diff):\n+            mask_t = tf.expand_dims(mask_t, -1)\n+        multiples = [1] * fixed_dim + input_t.shape.as_list()[fixed_dim:]\n+        return tf.tile(mask_t, multiples)\n+\n+    if unroll:\n+        if not time_steps:\n+            raise ValueError(\"Unrolling requires a fixed number of timesteps.\")\n+        states = tuple(initial_states)\n+        successive_states = []\n+        successive_outputs = []\n+\n+        # Process the input tensors. The input tensor need to be split on the\n+        # time_step dim, and reverse if go_backwards is True. In the case of\n+        # nested input, the input is flattened and then transformed\n+        # individually.  The result of this will be a tuple of lists, each of\n+        # the item in tuple is list of the tensor with shape (batch, feature)\n+        def _process_single_input_t(input_t):\n+            input_t = tf.unstack(input_t)  # unstack for time_step dim\n+            if go_backwards:\n+                input_t.reverse()\n+            return input_t\n+\n+        if tf.nest.is_nested(inputs):\n+            processed_input = tf.nest.map_structure(\n+                _process_single_input_t, inputs\n+            )\n+        else:\n+            processed_input = (_process_single_input_t(inputs),)\n+\n+        def _get_input_tensor(time):\n+            inp = [t_[time] for t_ in processed_input]\n+            return tf.nest.pack_sequence_as(inputs, inp)\n+\n+        if mask is not None:\n+            mask_list = tf.unstack(mask)\n+            if go_backwards:\n+                mask_list.reverse()\n+\n+            for i in range(time_steps):\n+                inp = _get_input_tensor(i)\n+                mask_t = mask_list[i]\n+                output, new_states = step_function(\n+                    inp, tuple(states) + tuple(constants)\n+                )\n+                tiled_mask_t = _expand_mask(mask_t, output)\n+\n+                if not successive_outputs:\n+                    prev_output = tf.zeros_like(output)\n+                else:\n+                    prev_output = successive_outputs[-1]\n+\n+                output = tf.where(tiled_mask_t, output, prev_output)\n+\n+                flat_states = tf.nest.flatten(states)\n+                flat_new_states = tf.nest.flatten(new_states)\n+                tiled_mask_t = tuple(\n+                    _expand_mask(mask_t, s) for s in flat_states\n+                )\n+                flat_final_states = tuple(\n+                    tf.where(m, s, ps)\n+                    for m, s, ps in zip(\n+                        tiled_mask_t, flat_new_states, flat_states\n+                    )\n+                )\n+                states = tf.nest.pack_sequence_as(states, flat_final_states)\n+\n+                if return_all_outputs:\n+                    successive_outputs.append(output)\n+                    successive_states.append(states)\n+                else:\n+                    successive_outputs = [output]\n+                    successive_states = [states]\n+            last_output = successive_outputs[-1]\n+            new_states = successive_states[-1]\n+            outputs = tf.stack(successive_outputs)\n+\n+            if zero_output_for_mask:\n+                last_output = tf.where(\n+                    _expand_mask(mask_list[-1], last_output),\n+                    last_output,\n+                    tf.zeros_like(last_output),\n+                )\n+                outputs = tf.where(\n+                    _expand_mask(mask, outputs, fixed_dim=2),\n+                    outputs,\n+                    tf.zeros_like(outputs),\n+                )\n+\n+        else:  # mask is None\n+            for i in range(time_steps):\n+                inp = _get_input_tensor(i)\n+                output, states = step_function(\n+                    inp, tuple(states) + tuple(constants)\n+                )\n+                if return_all_outputs:\n+                    successive_outputs.append(output)\n+                    successive_states.append(states)\n+                else:\n+                    successive_outputs = [output]\n+                    successive_states = [states]\n+            last_output = successive_outputs[-1]\n+            new_states = successive_states[-1]\n+            outputs = tf.stack(successive_outputs)\n+\n+    else:  # Unroll == False\n+        states = tuple(initial_states)\n+\n+        # Create input tensor array, if the inputs is nested tensors, then it\n+        # will be flattened first, and tensor array will be created one per\n+        # flattened tensor.\n+        input_ta = tuple(\n+            tf.TensorArray(\n+                dtype=inp.dtype,\n+                size=time_steps_t,\n+                tensor_array_name=f\"input_ta_{i}\",\n+            )\n+            for i, inp in enumerate(flatted_inputs)\n+        )\n+        input_ta = tuple(\n+            ta.unstack(input_)\n+            if not go_backwards\n+            else ta.unstack(tf.reverse(input_, [0]))\n+            for ta, input_ in zip(input_ta, flatted_inputs)\n+        )\n+\n+        # Get the time(0) input and compute the output for that, the output will\n+        # be used to determine the dtype of output tensor array. Don't read from\n+        # input_ta due to TensorArray clear_after_read default to True.\n+        input_time_zero = tf.nest.pack_sequence_as(\n+            inputs, [inp[0] for inp in flatted_inputs]\n+        )\n+        # output_time_zero is used to determine the cell output shape and its\n+        # dtype.  the value is discarded.\n+        output_time_zero, _ = step_function(\n+            input_time_zero, tuple(initial_states) + tuple(constants)\n+        )\n+\n+        output_ta_size = time_steps_t if return_all_outputs else 1\n+        output_ta = tuple(\n+            tf.TensorArray(\n+                dtype=out.dtype,\n+                size=output_ta_size,\n+                element_shape=out.shape,\n+                tensor_array_name=f\"output_ta_{i}\",\n+            )\n+            for i, out in enumerate(tf.nest.flatten(output_time_zero))\n+        )\n+\n+        time = tf.constant(0, dtype=\"int32\", name=\"time\")\n+\n+        if input_length is None:\n+            max_iterations = time_steps_t\n+        else:\n+            max_iterations = tf.reduce_max(input_length)\n+\n+        while_loop_kwargs = {\n+            \"cond\": lambda time, *_: time < time_steps_t,\n+            \"maximum_iterations\": max_iterations,\n+            \"parallel_iterations\": 32,\n+            \"swap_memory\": True,\n+        }\n+        if mask is not None:\n+            if go_backwards:\n+                mask = tf.reverse(mask, [0])\n+\n+            mask_ta = tf.TensorArray(\n+                dtype=tf.bool, size=time_steps_t, tensor_array_name=\"mask_ta\"\n+            )\n+            mask_ta = mask_ta.unstack(mask)\n+\n+            def masking_fn(time):\n+                return mask_ta.read(time)\n+\n+            def compute_masked_output(mask_t, flat_out, flat_mask):\n+                tiled_mask_t = tuple(\n+                    _expand_mask(mask_t, o, fixed_dim=len(mask_t.shape))\n+                    for o in flat_out\n+                )\n+                return tuple(\n+                    tf.where(m, o, fm)\n+                    for m, o, fm in zip(tiled_mask_t, flat_out, flat_mask)\n+                )\n+\n+        elif isinstance(input_length, tf.Tensor):\n+            if go_backwards:\n+                max_len = tf.reduce_max(input_length, axis=0)\n+                rev_input_length = tf.subtract(max_len - 1, input_length)\n+\n+                def masking_fn(time):\n+                    return tf.less(rev_input_length, time)\n+\n+            else:\n+\n+                def masking_fn(time):\n+                    return tf.greater(input_length, time)\n+\n+            def compute_masked_output(mask_t, flat_out, flat_mask):\n+                return tuple(\n+                    tf.where(mask_t, o, zo)\n+                    for (o, zo) in zip(flat_out, flat_mask)\n+                )\n+\n+        else:\n+            masking_fn = None\n+\n+        if masking_fn is not None:\n+            # Mask for the T output will be base on the output of T - 1. In the\n+            # case T = 0, a zero filled tensor will be used.\n+            flat_zero_output = tuple(\n+                tf.zeros_like(o) for o in tf.nest.flatten(output_time_zero)\n+            )\n+\n+            def _step(time, output_ta_t, prev_output, *states):\n+                \"\"\"RNN step function.\n+\n+                Args:\n+                    time: Current timestep value.\n+                    output_ta_t: TensorArray.\n+                    prev_output: tuple of outputs from time - 1.\n+                    *states: List of states.\n+\n+                Returns:\n+                    Tuple: `(time + 1, output_ta_t, output) + tuple(new_states)`\n+                \"\"\"\n+                current_input = tuple(ta.read(time) for ta in input_ta)\n+                # maybe set shape.\n+                current_input = tf.nest.pack_sequence_as(inputs, current_input)\n+                mask_t = masking_fn(time)\n+                output, new_states = step_function(\n+                    current_input, tuple(states) + tuple(constants)\n+                )\n+                # mask output\n+                flat_output = tf.nest.flatten(output)\n+                flat_mask_output = (\n+                    flat_zero_output\n+                    if zero_output_for_mask\n+                    else tf.nest.flatten(prev_output)\n+                )\n+                flat_new_output = compute_masked_output(\n+                    mask_t, flat_output, flat_mask_output\n+                )\n+\n+                # mask states\n+                flat_state = tf.nest.flatten(states)\n+                flat_new_state = tf.nest.flatten(new_states)\n+                flat_final_state = compute_masked_output(\n+                    mask_t, flat_new_state, flat_state\n+                )\n+                new_states = tf.nest.pack_sequence_as(\n+                    new_states, flat_final_state\n+                )\n+\n+                ta_index_to_write = time if return_all_outputs else 0\n+                output_ta_t = tuple(\n+                    ta.write(ta_index_to_write, out)\n+                    for ta, out in zip(output_ta_t, flat_new_output)\n+                )\n+\n+                return (time + 1, output_ta_t, tuple(flat_new_output)) + tuple(\n+                    new_states\n+                )\n+\n+            final_outputs = tf.while_loop(\n+                body=_step,\n+                loop_vars=(time, output_ta, flat_zero_output) + states,\n+                **while_loop_kwargs,\n+            )\n+            # Skip final_outputs[2] which is the output for final timestep.\n+            new_states = final_outputs[3:]\n+        else:\n+\n+            def _step(time, output_ta_t, *states):\n+                \"\"\"RNN step function.\n+\n+                Args:\n+                    time: Current timestep value.\n+                    output_ta_t: TensorArray.\n+                    *states: List of states.\n+\n+                Returns:\n+                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n+                \"\"\"\n+                current_input = tuple(ta.read(time) for ta in input_ta)\n+                current_input = tf.nest.pack_sequence_as(inputs, current_input)\n+                output, new_states = step_function(\n+                    current_input, tuple(states) + tuple(constants)\n+                )\n+                flat_new_state = tf.nest.flatten(new_states)\n+\n+                flat_output = tf.nest.flatten(output)\n+                ta_index_to_write = time if return_all_outputs else 0\n+                output_ta_t = tuple(\n+                    ta.write(ta_index_to_write, out)\n+                    for ta, out in zip(output_ta_t, flat_output)\n+                )\n+\n+                new_states = tf.nest.pack_sequence_as(\n+                    initial_states, flat_new_state\n+                )\n+                return (time + 1, output_ta_t) + tuple(new_states)\n+\n+            final_outputs = tf.while_loop(\n+                body=_step,\n+                loop_vars=(time, output_ta) + states,\n+                **while_loop_kwargs,\n+            )\n+            new_states = final_outputs[2:]\n+\n+        output_ta = final_outputs[1]\n+\n+        outputs = tuple(o.stack() for o in output_ta)\n+        last_output = tuple(o[-1] for o in outputs)\n+\n+        outputs = tf.nest.pack_sequence_as(output_time_zero, outputs)\n+        last_output = tf.nest.pack_sequence_as(output_time_zero, last_output)\n+\n+    # static shape inference\n+    def set_shape(output_):\n+        if isinstance(output_, tf.Tensor):\n+            shape = output_.shape.as_list()\n+            if return_all_outputs:\n+                shape[0] = time_steps\n+            else:\n+                shape[0] = 1\n+            shape[1] = batch\n+            output_.set_shape(shape)\n+        return output_\n+\n+    outputs = tf.nest.map_structure(set_shape, outputs)\n+\n+    if not time_major:\n+        outputs = tf.nest.map_structure(swap_batch_timestep, outputs)\n+\n+    return last_output, outputs, new_states\n+\n+\n+def gru(\n+    inputs,\n+    initial_state,\n+    mask,\n+    kernel,\n+    recurrent_kernel,\n+    bias,\n+    activation,\n+    recurrent_activation,\n+    return_sequences=False,\n+    go_backwards=False,\n+    unroll=False,\n+    time_major=False,\n+    reset_after=True,\n+):\n+    args_supported = _do_gru_arguments_support_cudnn(\n+        activation=activation,\n+        recurrent_activation=recurrent_activation,\n+        unroll=unroll,\n+        bias=bias,\n+        reset_after=reset_after,\n+    )\n+    inputs_supported = _do_rnn_inputs_support_cudnn(mask, time_major)\n+    if not args_supported or not inputs_supported:\n+        raise NotImplementedError\n+\n+    from keras_core.backend.tensorflow import Variable\n+\n+    if isinstance(kernel, Variable):\n+        kernel = kernel.value\n+    if isinstance(recurrent_kernel, Variable):\n+        recurrent_kernel = recurrent_kernel.value\n+    if isinstance(bias, Variable):\n+        bias = bias.value\n+\n+    try:\n+        return _cudnn_gru(\n+            inputs,\n+            initial_state,\n+            kernel,\n+            recurrent_kernel,\n+            bias,\n+            mask,\n+            time_major,\n+            go_backwards,\n+            return_sequences,\n+        )\n+    except tf.errors.InvalidArgumentError:\n+        # cuDNN op not found.\n+        raise NotImplementedError\n+\n+\n+def _do_gru_arguments_support_cudnn(\n+    activation,\n+    recurrent_activation,\n+    unroll,\n+    bias,\n+    reset_after,\n+):\n+    from keras_core import activations\n+    from keras_core import operations as ops\n+\n+    return (\n+        activation in (activations.tanh, tf.tanh, ops.tanh)\n+        and recurrent_activation\n+        in (activations.sigmoid, tf.sigmoid, ops.sigmoid)\n+        and not unroll\n+        and bias is not None\n+        and reset_after\n+    )\n+\n+\n+def _do_rnn_inputs_support_cudnn(mask, time_major):\n+    if tf.sysconfig.get_build_info()[\"is_rocm_build\"]:\n+        if mask is not None:\n+            return tf.reduce_all(mask)\n+        return True\n+    if mask is None:\n+        return True\n+    if time_major:\n+        mask = tf.transpose(mask)\n+    return tf.logical_and(\n+        _is_sequence_right_padded(mask),\n+        tf.logical_not(_has_fully_masked_sequence(mask)),\n+    )\n+\n+\n+def _is_sequence_right_padded(mask):\n+    \"\"\"Check the mask tensor and see if it right padded.\n+\n+    For cuDNN kernel, it uses the sequence length param to skip the tailing\n+    timestep. If the data is left padded, or not a strict right padding (has\n+    masked value in the middle of the sequence), then cuDNN kernel won't be work\n+    properly in those cases.\n+\n+    Left padded data: [[False, False, True, True, True]].\n+    Right padded data: [[True, True, True, False, False]].\n+    Mixture of mask/unmasked data: [[True, False, True, False, False]].\n+\n+    Note that for the mixed data example above, the actually data RNN should see\n+    are those 2 Trues (index 0 and 2), the index 1 False should be ignored and\n+    not pollute the internal states.\n+\n+    Args:\n+      mask: the Boolean tensor with shape [batch, timestep]\n+\n+    Returns:\n+      boolean scalar tensor, whether the mask is strictly right padded.\n+    \"\"\"\n+    max_seq_length = tf.shape(mask)[1]\n+    count_of_true = tf.reduce_sum(tf.cast(mask, tf.int32), axis=1)\n+    right_padded_mask = tf.sequence_mask(count_of_true, maxlen=max_seq_length)\n+    return tf.reduce_all(tf.equal(mask, right_padded_mask))\n+\n+\n+def _has_fully_masked_sequence(mask):\n+    # Cudnn kernel will error out if the input sequence contains any\n+    # fully masked data. We walk around this issue by rerouting the computation\n+    # to standard kernel, until the issue on cudnn side has been fixed.  For a\n+    # fully masked sequence, it will contain all Falses. To make it easy to\n+    # check, we inverse the boolean, check if any of the sequence has all True.\n+    return tf.reduce_any(tf.reduce_all(tf.logical_not(mask), axis=1))\n+\n+\n+def _standardize_cudnn_weights(weights, biases, shape, transpose_weights=False):\n+    \"\"\"Utility function convert variable to cuDNN compatible parameter.\n+\n+    Note that Keras weights for kernels are different from the cuDNN format.\n+    Eg.:\n+\n+    ```\n+      Keras                 cuDNN\n+      [[0, 1, 2],  <--->  [[0, 2, 4],\n+       [3, 4, 5]]          [1, 3, 5]]\n+    ```\n+\n+    If the input weights need to be in a unified format, then set\n+    `transpose_weights=True` to convert the weights.\n+\n+    Args:\n+        weights: list of weights for the kernels and recurrent kernels.\n+        biases: list of biases for individual gate.\n+        shape: the shape for the converted variables that will be feed to cuDNN.\n+        transpose_weights: boolean, whether to transpose the weights.\n+\n+    Returns:\n+        The converted weights that can be feed to cuDNN ops as param.\n+    \"\"\"\n+\n+    def convert(w):\n+        return tf.transpose(w) if transpose_weights else w\n+\n+    weights = [tf.reshape(convert(x), shape) for x in weights]\n+    biases = [tf.reshape(x, shape) for x in biases]\n+    return tf.concat(weights + biases, axis=0)\n+\n+\n+def _compute_sequence_length_from_mask(mask, time_major):\n+    \"\"\"Calculate the sequence length tensor (1-D) based on the masking tensor.\n+\n+    The masking tensor is a 2D boolean tensor with shape [batch, timestep]. For\n+    any timestep that should be masked, the corresponding field will be False.\n+    Consider the following example:\n+      a = [[True, True, False, False],\n+           [True, True, True, False]]\n+    It is a (2, 4) tensor, and the corresponding sequence length result should\n+    be 1D tensor with value [2, 3]. Note that the masking tensor must be right\n+    padded that could be checked by, e.g., `is_sequence_right_padded()`.\n+\n+    Args:\n+      mask: Boolean tensor with shape [batch, timestep] or [timestep, batch] if\n+        time_major=True.\n+      time_major: Boolean, which indicates whether the mask is time major or\n+        batch major.\n+    Returns:\n+      sequence_length: 1D int32 tensor.\n+    \"\"\"\n+    timestep_index = 0 if time_major else 1\n+    return tf.reduce_sum(tf.cast(mask, tf.int32), axis=timestep_index)\n+\n+\n+@tf.function(autograph=False)\n+def _cudnn_gru(\n+    inputs,\n+    initial_state,\n+    kernel,\n+    recurrent_kernel,\n+    bias,\n+    mask,\n+    time_major,\n+    go_backwards,\n+    return_sequences,\n+):\n+    \"\"\"GRU with cuDNN implementation which is only available for GPU.\"\"\"\n+    if mask is not None:\n+        sequence_lengths = _compute_sequence_length_from_mask(mask, time_major)\n+    else:\n+        sequence_lengths = None\n+\n+    if not time_major and sequence_lengths is None:\n+        inputs = tf.transpose(inputs, perm=(1, 0, 2))\n+        seq_axis, batch_axis = (0, 1)\n+    else:\n+        seq_axis, batch_axis = (0, 1) if time_major else (1, 0)\n+    # For init_h, cuDNN expects one more dim of num_layers before or after batch\n+    # dim for time major or batch major inputs respectively\n+    init_h = tf.expand_dims(initial_state, axis=seq_axis)\n+\n+    weights = tf.split(kernel, 3, axis=1)\n+    weights += tf.split(recurrent_kernel, 3, axis=1)\n+    # Note that the bias was initialized as shape (2, 3 * units), flatten it to\n+    # (6 * units)\n+    bias = tf.split(tf.reshape(bias, [-1]), 6)\n+\n+    if tf.sysconfig.get_build_info()[\"is_cuda_build\"]:\n+        # Note that the gate order for cuDNN is different from the canonical\n+        # format.  canonical format is [z, r, h], whereas cuDNN is [r, z, h].\n+        # The swap need to be done for kernel, recurrent_kernel, input_bias,\n+        # recurrent_bias.\n+        # z is update gate weights.\n+        # r is reset gate weights.\n+        # h is output gate weights.\n+        weights[0], weights[1] = weights[1], weights[0]\n+        weights[3], weights[4] = weights[4], weights[3]\n+        bias[0], bias[1] = bias[1], bias[0]\n+        bias[3], bias[4] = bias[4], bias[3]\n+\n+    params = _standardize_cudnn_weights(\n+        weights=weights,\n+        biases=bias,\n+        shape=tf.constant([-1]),\n+        transpose_weights=True,\n+    )\n+\n+    if sequence_lengths is not None:\n+        if go_backwards:\n+            # Three reversals are required. E.g.,\n+            # normal input = [1, 2, 3, 0, 0]  # where 0 need to be masked\n+            # reversed_input_to_cudnn = [3, 2, 1, 0, 0]\n+            # output_from_cudnn = [6, 5, 4, 0, 0]\n+            # expected_output = [0, 0, 6, 5 ,4]\n+            inputs = tf.reverse_sequence(\n+                inputs,\n+                sequence_lengths,\n+                seq_axis=seq_axis,\n+                batch_axis=batch_axis,\n+            )\n+        outputs, h, _, _, _ = tf.raw_ops.CudnnRNNV3(\n+            input=inputs,\n+            input_h=init_h,\n+            input_c=0,\n+            params=params,\n+            is_training=True,\n+            rnn_mode=\"gru\",\n+            sequence_lengths=sequence_lengths,\n+            time_major=time_major,\n+        )\n+        if go_backwards:\n+            outputs = tf.reverse_sequence(\n+                outputs,\n+                sequence_lengths,\n+                seq_axis=seq_axis,\n+                batch_axis=batch_axis,\n+            )\n+            outputs = tf.reverse(outputs, axis=[seq_axis])\n+    else:\n+        if go_backwards:\n+            # Reverse axis 0 since the input is already convert to time major.\n+            inputs = tf.reverse(inputs, axis=[0])\n+        outputs, h, _, _ = tf.raw_ops.CudnnRNN(\n+            input=inputs,\n+            input_h=init_h,\n+            input_c=0,\n+            params=params,\n+            is_training=True,\n+            rnn_mode=\"gru\",\n+        )\n+\n+    last_output = outputs[-1]\n+    if not time_major and sequence_lengths is None and return_sequences:\n+        outputs = tf.transpose(outputs, perm=[1, 0, 2])\n+    state = tf.squeeze(h, axis=seq_axis)\n+\n+    # In the case of variable length input, the cudnn kernel will fill zeros for\n+    # the output, whereas the default keras behavior is to bring over the\n+    # previous output for t-1, so that in the return_sequence=False case, user\n+    # can quickly get the final effect output instead just 0s at the last\n+    # timestep.  In order to mimic the default keras behavior, we copy the final\n+    # h state as the last_output, since it is numerically same as the output.\n+    if sequence_lengths is not None:\n+        last_output = state\n+\n+    # Match CPU return format\n+    if not return_sequences:\n+        outputs = tf.expand_dims(last_output, axis=0 if time_major else 1)\n+\n+    return (\n+        last_output,\n+        outputs,\n+        state,\n+    )\n+\n+\n+def lstm():\n+    pass\n\n@@ -114,15 +114,12 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             )\n             return outputs\n \n-        def train_function(iterator):\n-            \"\"\"Runs a training execution with multiple steps.\"\"\"\n-            for _ in tf.range(self.steps_per_execution):\n-                outputs = one_step_on_iterator(iterator)\n-            return outputs\n-\n         if not self.run_eagerly:\n-            train_function = tf.function(train_function, reduce_retracing=True)\n-\n+            train_function = tf.function(\n+                one_step_on_iterator, reduce_retracing=True\n+            )\n+        else:\n+            train_function = one_step_on_iterator\n         self.train_function = train_function\n \n     def make_test_function(self, force=False):\n@@ -247,7 +244,6 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             shuffle=shuffle,\n             class_weight=class_weight,\n             distribute_strategy=self.distribute_strategy,\n-            steps_per_execution=self.steps_per_execution,\n         )\n \n         # Container that configures and calls callbacks.\n@@ -449,9 +445,7 @@ class TFEpochIterator(EpochIterator):\n                         self.data_adapter.get_tf_dataset()\n                     )\n                 )\n-            for step in range(\n-                0, self.steps_per_epoch, self.steps_per_execution\n-            ):\n+            for step in range(self.steps_per_epoch):\n                 yield step, self._current_iterator\n         else:\n             iterator = iter(\n@@ -460,14 +454,12 @@ class TFEpochIterator(EpochIterator):\n                 )\n             )\n             if self.num_batches:\n-                for step in range(\n-                    0, self.num_batches, self.steps_per_execution\n-                ):\n+                for step in range(self.num_batches):\n                     yield step, iterator\n             else:\n                 step = -1\n                 while True:\n-                    step += self.steps_per_execution\n+                    step += 1\n                     self._steps_seen = step + 1\n                     yield step, iterator\n         self.data_adapter.on_epoch_end()\n\n@@ -99,6 +99,7 @@ from keras_core.layers.reshaping.permute import Permute\n from keras_core.layers.reshaping.repeat_vector import RepeatVector\n from keras_core.layers.reshaping.reshape import Reshape\n from keras_core.layers.reshaping.up_sampling1d import UpSampling1D\n+from keras_core.layers.rnn.gru import GRU\n from keras_core.layers.rnn.rnn import RNN\n from keras_core.layers.rnn.simple_rnn import SimpleRNN\n from keras_core.layers.rnn.stacked_rnn_cells import StackedRNNCells\n\n@@ -14,11 +14,11 @@ from keras_core.operations.operation_utils import compute_conv_output_shape\n class BaseConv(Layer):\n     \"\"\"Abstract N-D convolution layer (private, used as implementation base).\n \n-    This layer creates a convolution kernel that is convolved (actually\n-    cross-correlated) with the layer input to produce a tensor of outputs. If\n-    `use_bias` is True (and a `bias_initializer` is provided), a bias vector is\n-    created and added to the outputs. Finally, if `activation` is not `None`, it\n-    is applied to the outputs as well.\n+    This layer creates a convolution kernel that is convolved\n+    (actually cross-correlated) with the layer input to produce a tensor of\n+    outputs. If `use_bias` is True (and a `bias_initializer` is provided),\n+    a bias vector is created and added to the outputs. Finally, if\n+    `activation` is not `None`, it is applied to the outputs as well.\n \n     Note: layer attributes cannot be modified after the layer has been called\n     once (except the `trainable` attribute).\n@@ -27,12 +27,12 @@ class BaseConv(Layer):\n         rank: int, the rank of the convolution, e.g. 2 for 2D convolution.\n         filters: int, the dimension of the output space (the number of filters\n             in the convolution).\n-        kernel_size: int or tuple/list of `rank` integers, specifying the size\n-            of the convolution window.\n-        strides: int or tuple/list of `rank` integers, specifying the stride\n-            length of the convolution. If only one int is specified, the same\n-            stride size will be used for all dimensions. `strides > 1` is\n-            incompatible with `dilation_rate > 1`.\n+        kernel_size: int or tuple/list of N integers (N=`rank`), specifying the\n+            size of the convolution window.\n+        strides: int or tuple/list of N integers, specifying the stride length\n+            of the convolution. If only one int is specified, the same stride\n+            size will be used for all dimensions. `stride value != 1` is\n+            incompatible with `dilation_rate != 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n@@ -44,9 +44,9 @@ class BaseConv(Layer):\n             `(batch, features, steps)`. It defaults to the `image_data_format`\n             value found in your Keras config file at `~/.keras/keras.json`.\n             If you never set it, then it will be `\"channels_last\"`.\n-        dilation_rate: int or tuple/list of `rank` integers, specifying the\n-            dilation rate to use for dilated convolution. If only one int is\n-            specified, the same dilation rate will be used for all dimensions.\n+        dilation_rate: int or tuple/list of N integers, specifying the dilation\n+            rate to use for dilated convolution. If only one int is specified,\n+            the same dilation rate will be used for all dimensions.\n         groups: A positive int specifying the number of groups in which the\n             input is split along the channel axis. Each group is convolved\n             separately with `filters // groups` filters. The output is the\n@@ -97,7 +97,7 @@ class BaseConv(Layer):\n         super().__init__(\n             trainable=trainable,\n             name=name,\n-            activity_regularizer=activity_regularizer,\n+            activity_regularizer=regularizers.get(activity_regularizer),\n             **kwargs,\n         )\n         self.rank = rank\n@@ -144,14 +144,14 @@ class BaseConv(Layer):\n \n         if not all(self.kernel_size):\n             raise ValueError(\n-                \"The argument `kernel_size` cannot contain 0. Received \"\n-                f\"kernel_size={self.kernel_size}.\"\n+                \"The argument `kernel_size` cannot contain 0(s). Received: \"\n+                f\"{self.kernel_size}\"\n             )\n \n         if not all(self.strides):\n             raise ValueError(\n-                \"The argument `strides` cannot contains 0. Received \"\n-                f\"strides={self.strides}\"\n+                \"The argument `strides` cannot contains 0(s). Received: \"\n+                f\"{self.strides}\"\n             )\n \n         if max(self.strides) > 1 and max(self.dilation_rate) > 1:\n\n@@ -14,25 +14,26 @@ from keras_core.layers.layer import Layer\n \n \n class BaseConvTranspose(Layer):\n-    \"\"\"Abstract N-D transposed convolution layer.\n+    \"\"\"Abstract N-D transpose convolution layer.\n \n-    The need for transposed convolutions generally arises from the desire to use\n-    a transformation going in the opposite direction of a normal convolution,\n-    i.e., from something that has the shape of the output of some convolution to\n-    something that has the shape of its input while maintaining a connectivity\n-    pattern that is compatible with said convolution.\n+    The need for transposed convolutions generally arises\n+    from the desire to use a transformation going in the opposite direction\n+    of a normal convolution, i.e., from something that has the shape of the\n+    output of some convolution to something that has the shape of its input\n+    while maintaining a connectivity pattern that is compatible with\n+    said convolution.\n \n     Args:\n         rank: int, the rank of the transposed convolution, e.g. 2 for 2D\n             transposed convolution.\n         filters: int, the dimension of the output space (the number of filters\n             in the transposed convolution).\n-        kernel_size: int or tuple/list of `rank` integers, specifying the size\n-            of the transposed convolution window.\n-        strides: int or tuple/list of `rank` integers, specifying the stride\n-            length of the transposed convolution. If only one int is specified,\n-            the same stride size will be used for all dimensions.\n-            `strides > 1` is incompatible with `dilation_rate > 1`.\n+        kernel_size: int or tuple/list of N integers (N=`rank`), specifying the\n+            size of the transposed convolution window.\n+        strides: int or tuple/list of N integers, specifying the stride length\n+            of the transposed convolution. If only one int is specified, the\n+            same stride size will be used for all dimensions.\n+            `stride value != 1` is incompatible with `dilation_rate != 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n@@ -44,9 +45,9 @@ class BaseConvTranspose(Layer):\n             `(batch, features, steps)`. It defaults to the `image_data_format`\n             value found in your Keras config file at `~/.keras/keras.json`.\n             If you never set it, then it will be `\"channels_last\"`.\n-        dilation_rate: int or tuple/list of `rank` integers, specifying the\n-            dilation rate to use for dilated convolution. If only one int is\n-            specified, the same dilation rate will be used for all dimensions.\n+        dilation_rate: int or tuple/list of N integers, specifying the dilation\n+            rate to use for dilated convolution. If only one int is specified,\n+            the same dilation rate will be used for all dimensions.\n         activation: Activation function. If `None`, no activation is applied.\n         use_bias: bool, if `True`, bias will be added to the output.\n         kernel_initializer: Initializer for the convolution kernel. If `None`,\n@@ -130,14 +131,14 @@ class BaseConvTranspose(Layer):\n \n         if not all(self.kernel_size):\n             raise ValueError(\n-                \"The argument `kernel_size` cannot contain 0. Received \"\n-                f\"kernel_size={self.kernel_size}.\"\n+                \"The argument `kernel_size` cannot contain 0. Received: \"\n+                f\"{self.kernel_size}\"\n             )\n \n         if not all(self.strides):\n             raise ValueError(\n-                \"The argument `strides` cannot contains 0. Received \"\n-                f\"strides={self.strides}.\"\n+                \"The argument `strides` cannot contains 0. Received: \"\n+                f\"{self.strides}\"\n             )\n \n         if max(self.strides) > 1 and max(self.dilation_rate) > 1:\n\n@@ -39,12 +39,12 @@ class BaseDepthwiseConv(Layer):\n         depth_multiplier: The number of depthwise convolution output channels\n             for each input channel. The total number of depthwise convolution\n             output channels will be equal to `input_channel * depth_multiplier`.\n-        kernel_size: int or tuple/list of `rank` integers, specifying the size\n-            of the depthwise convolution window.\n-        strides: int or tuple/list of `rank` integers, specifying the stride\n-            length of the depthwise convolution. If only one int is specified,\n-            the same stride size will be used for all dimensions.\n-            `strides > 1` is incompatible with `dilation_rate > 1`.\n+        kernel_size: int or tuple/list of N integers (N=`rank`), specifying the\n+            size of the depthwise convolution window.\n+        strides: int or tuple/list of N integers, specifying the stride length\n+            of the depthwise convolution. If only one int is specified, the same\n+            stride size will be used for all dimensions. `stride value != 1` is\n+            incompatible with `dilation_rate != 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n@@ -56,9 +56,9 @@ class BaseDepthwiseConv(Layer):\n             `(batch, features, steps)`. It defaults to the `image_data_format`\n             value found in your Keras config file at `~/.keras/keras.json`.\n             If you never set it, then it will be `\"channels_last\"`.\n-        dilation_rate: int or tuple/list of `rank` integers, specifying the\n-            dilation rate to use for dilated convolution. If only one int is\n-            specified, the same dilation rate will be used for all dimensions.\n+        dilation_rate: int or tuple/list of N integers, specifying the dilation\n+            rate to use for dilated convolution. If only one int is specified,\n+            the same dilation rate will be used for all dimensions.\n         activation: Activation function. If `None`, no activation is applied.\n         use_bias: bool, if `True`, bias will be added to the output.\n         kernel_initializer: Initializer for the convolution kernel. If `None`,\n@@ -143,14 +143,14 @@ class BaseDepthwiseConv(Layer):\n \n         if not all(self.kernel_size):\n             raise ValueError(\n-                \"The argument `kernel_size` cannot contain 0. Received \"\n-                f\"kernel_size={self.kernel_size}.\"\n+                \"The argument `kernel_size` cannot contain 0(s). Received: \"\n+                f\"{self.kernel_size}\"\n             )\n \n         if not all(self.strides):\n             raise ValueError(\n-                \"The argument `strides` cannot contains 0. Received \"\n-                f\"strides={self.strides}\"\n+                \"The argument `strides` cannot contains 0(s). Received: \"\n+                f\"{self.strides}\"\n             )\n \n         if max(self.strides) > 1 and max(self.dilation_rate) > 1:\n\n@@ -21,8 +21,8 @@ class Conv1D(BaseConv):\n         kernel_size: int or tuple/list of 1 integer, specifying the size of the\n             convolution window.\n         strides: int or tuple/list of 1 integer, specifying the stride length\n-            of the convolution. `strides > 1` is incompatible with\n-            `dilation_rate > 1`.\n+            of the convolution. `stride value != 1` is incompatible with\n+            `dilation_rate != 1`.\n         padding: string, `\"valid\"`, `\"same\"` or `\"causal\"`(case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n@@ -72,9 +72,9 @@ class Conv1D(BaseConv):\n \n     Output shape:\n     - If `data_format=\"channels_last\"`:\n-        A 3D tensor with shape: `(batch_shape, new_steps, filters)`\n+        A 3D tensor with shape: `(batch_shape, new_steps, channels)`\n     - If `data_format=\"channels_first\"`:\n-        A 3D tensor with shape: `(batch_shape, filters, new_steps)`\n+        A 3D tensor with shape: `(batch_shape, channels, new_steps)`\n \n     Returns:\n         A 3D tensor representing `activation(conv1d(inputs, kernel) + bias)`.\n\n@@ -25,8 +25,8 @@ class Conv1DTranspose(BaseConvTranspose):\n         kernel_size: int or tuple/list of 1 integer, specifying the size of the\n             transposed convolution window.\n         strides: int or tuple/list of 1 integer, specifying the stride length\n-            of the transposed convolution. `strides > 1` is incompatible with\n-            `dilation_rate > 1`.\n+            of the transposed convolution. `stride value != 1` is incompatible\n+            with `dilation_rate != 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n@@ -40,6 +40,11 @@ class Conv1DTranspose(BaseConvTranspose):\n             If you never set it, then it will be `\"channels_last\"`.\n         dilation_rate: int or tuple/list of 1 integers, specifying the dilation\n             rate to use for dilated transposed convolution.\n+        groups: A positive int specifying the number of groups in which the\n+            input is split along the channel axis. Each group is convolved\n+            separately with `filters // groups` filters. The output is the\n+            concatenation of all the `groups` results along the channel axis.\n+            Input channels and `filters` must both be divisible by `groups`.\n         activation: Activation function. If `None`, no activation is applied.\n         use_bias: bool, if `True`, bias will be added to the output.\n         kernel_initializer: Initializer for the convolution kernel. If `None`,\n@@ -66,9 +71,9 @@ class Conv1DTranspose(BaseConvTranspose):\n \n     Output shape:\n     - If `data_format=\"channels_last\"`:\n-        A 3D tensor with shape: `(batch_shape, new_steps, filters)`\n+        A 3D tensor with shape: `(batch_shape, new_steps, channels)`\n     - If `data_format=\"channels_first\"`:\n-        A 3D tensor with shape: `(batch_shape, filters, new_steps)`\n+        A 3D tensor with shape: `(batch_shape, channels, new_steps)`\n \n     Returns:\n         A 3D tensor representing\n\n@@ -20,8 +20,8 @@ class Conv2D(BaseConv):\n         kernel_size: int or tuple/list of 2 integer, specifying the size of the\n             convolution window.\n         strides: int or tuple/list of 2 integer, specifying the stride length\n-            of the convolution. `strides > 1` is incompatible with\n-            `dilation_rate > 1`.\n+            of the convolution. `stride value != 1` is incompatible with\n+            `dilation_rate != 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n@@ -68,7 +68,7 @@ class Conv2D(BaseConv):\n \n     Output shape:\n     - If `data_format=\"channels_last\"`:\n-        A 4D tensor with shape: `(batch_size, new_height, new_width, filters)`\n+        A 4D tensor with shape: `(batch_size, new_height, new_width filters)`\n     - If `data_format=\"channels_first\"`:\n         A 4D tensor with shape: `(batch_size, filters, new_height, new_width)`\n \n\n@@ -25,8 +25,8 @@ class Conv2DTranspose(BaseConvTranspose):\n         kernel_size: int or tuple/list of 1 integer, specifying the size of the\n             transposed convolution window.\n         strides: int or tuple/list of 1 integer, specifying the stride length\n-            of the transposed convolution. `strides > 1` is incompatible with\n-            `dilation_rate > 1`.\n+            of the transposed convolution. `stride value != 1` is incompatible\n+            with `dilation_rate != 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n@@ -68,7 +68,7 @@ class Conv2DTranspose(BaseConvTranspose):\n \n     Output shape:\n     - If `data_format=\"channels_last\"`:\n-        A 4D tensor with shape: `(batch_size, new_height, new_width, filters)`\n+        A 4D tensor with shape: `(batch_size, new_height, new_width filters)`\n     - If `data_format=\"channels_first\"`:\n         A 4D tensor with shape: `(batch_size, filters, new_height, new_width)`\n \n\n@@ -20,8 +20,8 @@ class Conv3D(BaseConv):\n         kernel_size: int or tuple/list of 3 integer, specifying the size of the\n             convolution window.\n         strides: int or tuple/list of 3 integer, specifying the stride length\n-            of the convolution. `strides > 1` is incompatible with\n-            `dilation_rate > 1`.\n+            of the convolution. `stride value != 1` is incompatible with\n+            `dilation_rate != 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n@@ -72,10 +72,10 @@ class Conv3D(BaseConv):\n     - If `data_format=\"channels_last\"`:\n         5D tensor with shape:\n         `(batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3,\n-        filters)`\n+        channels)`\n     - If `data_format=\"channels_first\"`:\n         5D tensor with shape:\n-        `(batch_size, filters, new_spatial_dim1, new_spatial_dim2,\n+        `(batch_size, channels, new_spatial_dim1, new_spatial_dim2,\n         new_spatial_dim3)`\n \n     Returns:\n\n@@ -25,8 +25,8 @@ class Conv3DTranspose(BaseConvTranspose):\n         kernel_size: int or tuple/list of 1 integer, specifying the size of the\n             transposed convolution window.\n         strides: int or tuple/list of 1 integer, specifying the stride length\n-            of the transposed convolution. `strides > 1` is incompatible with\n-            `dilation_rate > 1`.\n+            of the transposed convolution. `stride value != 1` is incompatible\n+            with `dilation_rate != 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n@@ -72,10 +72,10 @@ class Conv3DTranspose(BaseConvTranspose):\n     - If `data_format=\"channels_last\"`:\n         5D tensor with shape:\n         `(batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3,\n-        filters)`\n+        channels)`\n     - If `data_format=\"channels_first\"`:\n         5D tensor with shape:\n-        `(batch_size, filters, new_spatial_dim1, new_spatial_dim2,\n+        `(batch_size, channels, new_spatial_dim1, new_spatial_dim2,\n         new_spatial_dim3)`\n \n     Returns:\n\n@@ -417,4 +417,4 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         tf_keras_layer.bias.assign(bias_weights)\n         outputs = layer(inputs)\n         expected = tf_keras_layer(inputs)\n-        self.assertAllClose(outputs, expected)\n+        self.assertAllClose(outputs, expected, atol=1e-5)\n\n@@ -34,8 +34,8 @@ class DepthwiseConv1D(BaseDepthwiseConv):\n         kernel_size: int or tuple/list of 1 integer, specifying the size of the\n             depthwise convolution window.\n         strides: int or tuple/list of 1 integer, specifying the stride length\n-            of the convolution. `strides > 1` is incompatible with\n-            `dilation_rate > 1`.\n+            of the convolution. `stride value != 1` is incompatible\n+            with `dilation_rate != 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n\n@@ -34,8 +34,8 @@ class DepthwiseConv2D(BaseDepthwiseConv):\n         kernel_size: int or tuple/list of 2 integer, specifying the size of the\n             depthwise convolution window.\n         strides: int or tuple/list of 2 integer, specifying the stride length\n-            of the depthwise convolution. `strides > 1` is incompatible with\n-            `dilation_rate > 1`.\n+            of the depthwise convolution. `stride value != 1` is incompatible\n+            with `dilation_rate != 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n\n@@ -29,8 +29,8 @@ class SeparableConv1D(BaseSeparableConv):\n             depthwise convolution window.\n         strides: int or tuple/list of 1 integers, specifying the stride length\n             of the depthwise convolution. If only one int is specified, the same\n-            stride size will be used for all dimensions. `strides > 1` is\n-            incompatible with `dilation_rate > 1`.\n+            stride size will be used for all dimensions. `stride value != 1` is\n+            incompatible with `dilation_rate != 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n\n@@ -29,8 +29,8 @@ class SeparableConv2D(BaseSeparableConv):\n             depthwise convolution window.\n         strides: int or tuple/list of 2 integers, specifying the stride length\n             of the depthwise convolution. If only one int is specified, the same\n-            stride size will be used for all dimensions. `strides > 1` is\n-            incompatible with `dilation_rate > 1`.\n+            stride size will be used for all dimensions. `stride value != 1` is\n+            incompatible with `dilation_rate != 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n\n@@ -0,0 +1,607 @@\n+from tensorflow import nest\n+\n+from keras_core import activations\n+from keras_core import backend\n+from keras_core import constraints\n+from keras_core import initializers\n+from keras_core import operations as ops\n+from keras_core import regularizers\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.input_spec import InputSpec\n+from keras_core.layers.layer import Layer\n+from keras_core.layers.rnn.dropout_rnn_cell import DropoutRNNCell\n+from keras_core.layers.rnn.rnn import RNN\n+\n+\n+@keras_core_export(\"keras_core.layers.GRUCell\")\n+class GRUCell(Layer, DropoutRNNCell):\n+    \"\"\"Cell class for the GRU layer.\n+\n+    This class processes one step within the whole time sequence input, whereas\n+    `keras_core.layer.GRU` processes the whole sequence.\n+\n+    Args:\n+        units: Positive integer, dimensionality of the output space.\n+        activation: Activation function to use. Default: hyperbolic tangent\n+            (`tanh`). If you pass None, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        recurrent_activation: Activation function to use for the recurrent step.\n+            Default: sigmoid (`sigmoid`). If you pass `None`, no activation is\n+            applied (ie. \"linear\" activation: `a(x) = x`).\n+        use_bias: Boolean, (default `True`), whether the layer\n+            should use a bias vector.\n+        kernel_initializer: Initializer for the `kernel` weights matrix,\n+            used for the linear transformation of the inputs. Default:\n+            `\"glorot_uniform\"`.\n+        recurrent_initializer: Initializer for the `recurrent_kernel`\n+            weights matrix, used for the linear transformation\n+            of the recurrent state. Default: `\"orthogonal\"`.\n+        bias_initializer: Initializer for the bias vector. Default: `\"zeros\"`.\n+        kernel_regularizer: Regularizer function applied to the `kernel` weights\n+            matrix. Default: `None`.\n+        recurrent_regularizer: Regularizer function applied to the\n+            `recurrent_kernel` weights matrix. Default: `None`.\n+        bias_regularizer: Regularizer function applied to the bias vector.\n+            Default: `None`.\n+        kernel_constraint: Constraint function applied to the `kernel` weights\n+            matrix. Default: `None`.\n+        recurrent_constraint: Constraint function applied to the\n+            `recurrent_kernel` weights matrix. Default: `None`.\n+        bias_constraint: Constraint function applied to the bias vector.\n+            Default: `None`.\n+        dropout: Float between 0 and 1. Fraction of the units to drop for the\n+            linear transformation of the inputs. Default: 0.\n+        recurrent_dropout: Float between 0 and 1. Fraction of the units to drop\n+            for the linear transformation of the recurrent state. Default: 0.\n+        reset_after: GRU convention (whether to apply reset gate after or\n+            before matrix multiplication). False = \"before\",\n+            True = \"after\" (default and cuDNN compatible).\n+\n+    Call arguments:\n+        inputs: A 2D tensor, with shape `(batch, features)`.\n+        states: A 2D tensor with shape `(batch, units)`, which is the state\n+            from the previous time step.\n+        training: Python boolean indicating whether the layer should behave in\n+            training mode or in inference mode. Only relevant when `dropout` or\n+            `recurrent_dropout` is used.\n+\n+    Example:\n+\n+    >>> inputs = np.random.random((32, 10, 8))\n+    >>> rnn = keras_core.layers.RNN(keras_core.layers.GRUCell(4))\n+    >>> output = rnn(inputs)\n+    >>> output.shape\n+    (32, 4)\n+    >>> rnn = keras_core.layers.RNN(\n+    ...    keras_core.layers.GRUCell(4),\n+    ...    return_sequences=True,\n+    ...    return_state=True)\n+    >>> whole_sequence_output, final_state = rnn(inputs)\n+    >>> whole_sequence_output.shape\n+    (32, 10, 4)\n+    >>> final_state.shape\n+    (32, 4)\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        units,\n+        activation=\"tanh\",\n+        recurrent_activation=\"sigmoid\",\n+        use_bias=True,\n+        kernel_initializer=\"glorot_uniform\",\n+        recurrent_initializer=\"orthogonal\",\n+        bias_initializer=\"zeros\",\n+        kernel_regularizer=None,\n+        recurrent_regularizer=None,\n+        bias_regularizer=None,\n+        kernel_constraint=None,\n+        recurrent_constraint=None,\n+        bias_constraint=None,\n+        dropout=0.0,\n+        recurrent_dropout=0.0,\n+        reset_after=True,\n+        seed=None,\n+        **kwargs,\n+    ):\n+        if units <= 0:\n+            raise ValueError(\n+                \"Received an invalid value for argument `units`, \"\n+                f\"expected a positive integer, got {units}.\"\n+            )\n+        super().__init__(**kwargs)\n+        self.units = units\n+        self.activation = activations.get(activation)\n+        self.recurrent_activation = activations.get(recurrent_activation)\n+        self.use_bias = use_bias\n+\n+        self.kernel_initializer = initializers.get(kernel_initializer)\n+        self.recurrent_initializer = initializers.get(recurrent_initializer)\n+        self.bias_initializer = initializers.get(bias_initializer)\n+\n+        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n+        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n+        self.bias_regularizer = regularizers.get(bias_regularizer)\n+\n+        self.kernel_constraint = constraints.get(kernel_constraint)\n+        self.recurrent_constraint = constraints.get(recurrent_constraint)\n+        self.bias_constraint = constraints.get(bias_constraint)\n+\n+        self.dropout = min(1.0, max(0.0, dropout))\n+        self.recurrent_dropout = min(1.0, max(0.0, recurrent_dropout))\n+        self.seed = seed\n+        self.seed_generator = backend.random.SeedGenerator(seed=seed)\n+\n+        self.reset_after = reset_after\n+        self.state_size = self.units\n+        self.output_size = self.units\n+\n+    def build(self, input_shape):\n+        super().build(input_shape)\n+        input_dim = input_shape[-1]\n+        self.kernel = self.add_weight(\n+            shape=(input_dim, self.units * 3),\n+            name=\"kernel\",\n+            initializer=self.kernel_initializer,\n+            regularizer=self.kernel_regularizer,\n+            constraint=self.kernel_constraint,\n+        )\n+        self.recurrent_kernel = self.add_weight(\n+            shape=(self.units, self.units * 3),\n+            name=\"recurrent_kernel\",\n+            initializer=self.recurrent_initializer,\n+            regularizer=self.recurrent_regularizer,\n+            constraint=self.recurrent_constraint,\n+        )\n+\n+        if self.use_bias:\n+            if not self.reset_after:\n+                bias_shape = (3 * self.units,)\n+            else:\n+                # separate biases for input and recurrent kernels\n+                # Note: the shape is intentionally different from CuDNNGRU\n+                # biases `(2 * 3 * self.units,)`, so that we can distinguish the\n+                # classes when loading and converting saved weights.\n+                bias_shape = (2, 3 * self.units)\n+            self.bias = self.add_weight(\n+                shape=bias_shape,\n+                name=\"bias\",\n+                initializer=self.bias_initializer,\n+                regularizer=self.bias_regularizer,\n+                constraint=self.bias_constraint,\n+            )\n+        else:\n+            self.bias = None\n+        self.built = True\n+\n+    def call(self, inputs, states, training=None):\n+        h_tm1 = (\n+            states[0] if nest.is_nested(states) else states\n+        )  # previous state\n+\n+        dp_mask = self.get_dropout_mask(inputs)\n+        rec_dp_mask = self.get_recurrent_dropout_mask(h_tm1)\n+\n+        if self.use_bias:\n+            if not self.reset_after:\n+                input_bias, recurrent_bias = self.bias, None\n+            else:\n+                input_bias, recurrent_bias = (\n+                    ops.squeeze(e, axis=0)\n+                    for e in ops.split(self.bias, self.bias.shape[0], axis=0)\n+                )\n+\n+        if training and 0.0 < self.dropout < 1.0:\n+            inputs *= dp_mask\n+        inputs_z = inputs\n+        inputs_r = inputs\n+        inputs_h = inputs\n+\n+        x_z = ops.matmul(inputs_z, self.kernel[:, : self.units])\n+        x_r = ops.matmul(inputs_r, self.kernel[:, self.units : self.units * 2])\n+        x_h = ops.matmul(inputs_h, self.kernel[:, self.units * 2 :])\n+\n+        if self.use_bias:\n+            x_z += input_bias[: self.units]\n+            x_r += input_bias[self.units : self.units * 2]\n+            x_h += input_bias[self.units * 2 :]\n+\n+        if training and 0.0 < self.recurrent_dropout < 1.0:\n+            h_tm1 *= rec_dp_mask\n+        h_tm1_z = h_tm1\n+        h_tm1_r = h_tm1\n+        h_tm1_h = h_tm1\n+\n+        recurrent_z = ops.matmul(\n+            h_tm1_z, self.recurrent_kernel[:, : self.units]\n+        )\n+        recurrent_r = ops.matmul(\n+            h_tm1_r, self.recurrent_kernel[:, self.units : self.units * 2]\n+        )\n+        if self.reset_after and self.use_bias:\n+            recurrent_z += recurrent_bias[: self.units]\n+            recurrent_r += recurrent_bias[self.units : self.units * 2]\n+\n+        z = self.recurrent_activation(x_z + recurrent_z)\n+        r = self.recurrent_activation(x_r + recurrent_r)\n+\n+        # reset gate applied after/before matrix multiplication\n+        if self.reset_after:\n+            recurrent_h = ops.matmul(\n+                h_tm1_h, self.recurrent_kernel[:, self.units * 2 :]\n+            )\n+            if self.use_bias:\n+                recurrent_h += recurrent_bias[self.units * 2 :]\n+            recurrent_h = r * recurrent_h\n+        else:\n+            recurrent_h = ops.matmul(\n+                r * h_tm1_h, self.recurrent_kernel[:, self.units * 2 :]\n+            )\n+\n+        hh = self.activation(x_h + recurrent_h)\n+\n+        # previous and candidate state mixed by update gate\n+        h = z * h_tm1 + (1 - z) * hh\n+        new_state = [h] if nest.is_nested(states) else h\n+        return h, new_state\n+\n+    def get_config(self):\n+        config = {\n+            \"units\": self.units,\n+            \"activation\": activations.serialize(self.activation),\n+            \"recurrent_activation\": activations.serialize(\n+                self.recurrent_activation\n+            ),\n+            \"use_bias\": self.use_bias,\n+            \"kernel_initializer\": initializers.serialize(\n+                self.kernel_initializer\n+            ),\n+            \"recurrent_initializer\": initializers.serialize(\n+                self.recurrent_initializer\n+            ),\n+            \"bias_initializer\": initializers.serialize(self.bias_initializer),\n+            \"kernel_regularizer\": regularizers.serialize(\n+                self.kernel_regularizer\n+            ),\n+            \"recurrent_regularizer\": regularizers.serialize(\n+                self.recurrent_regularizer\n+            ),\n+            \"bias_regularizer\": regularizers.serialize(self.bias_regularizer),\n+            \"kernel_constraint\": constraints.serialize(self.kernel_constraint),\n+            \"recurrent_constraint\": constraints.serialize(\n+                self.recurrent_constraint\n+            ),\n+            \"bias_constraint\": constraints.serialize(self.bias_constraint),\n+            \"dropout\": self.dropout,\n+            \"recurrent_dropout\": self.recurrent_dropout,\n+            \"reset_after\": self.reset_after,\n+        }\n+        base_config = super().get_config()\n+        return {**base_config, **config}\n+\n+    def get_initial_state(self, batch_size=None):\n+        return [\n+            ops.zeros((batch_size, self.state_size), dtype=self.compute_dtype)\n+        ]\n+\n+\n+class GRU(RNN):\n+    \"\"\"Gated Recurrent Unit - Cho et al. 2014.\n+\n+    Based on available runtime hardware and constraints, this layer\n+    will choose different implementations (cuDNN-based or backend-native)\n+    to maximize the performance. If a GPU is available and all\n+    the arguments to the layer meet the requirement of the cuDNN kernel\n+    (see below for details), the layer will use a fast cuDNN implementation\n+    when using the TensorFlow backend.\n+\n+    The requirements to use the cuDNN implementation are:\n+\n+    1. `activation` == `tanh`\n+    2. `recurrent_activation` == `sigmoid`\n+    3. `recurrent_dropout` == 0\n+    4. `unroll` is `False`\n+    5. `use_bias` is `True`\n+    6. `reset_after` is `True`\n+    7. Inputs, if use masking, are strictly right-padded.\n+    8. Eager execution is enabled in the outermost context.\n+\n+    There are two variants of the GRU implementation. The default one is based\n+    on [v3](https://arxiv.org/abs/1406.1078v3) and has reset gate applied to\n+    hidden state before matrix multiplication. The other one is based on\n+    [original](https://arxiv.org/abs/1406.1078v1) and has the order reversed.\n+\n+    The second variant is compatible with CuDNNGRU (GPU-only) and allows\n+    inference on CPU. Thus it has separate biases for `kernel` and\n+    `recurrent_kernel`. To use this variant, set `reset_after=True` and\n+    `recurrent_activation='sigmoid'`.\n+\n+    For example:\n+\n+    >>> inputs = np.random.random((32, 10, 8))\n+    >>> gru = keras_core.layers.GRU(4)\n+    >>> output = gru(inputs)\n+    >>> output.shape\n+    (32, 4)\n+    >>> gru = keras_core.layers.GRU(4, return_sequences=True, return_state=True)\n+    >>> whole_sequence_output, final_state = gru(inputs)\n+    >>> whole_sequence_output.shape\n+    (32, 10, 4)\n+    >>> final_state.shape\n+    (32, 4)\n+\n+    Args:\n+        units: Positive integer, dimensionality of the output space.\n+        activation: Activation function to use.\n+            Default: hyperbolic tangent (`tanh`).\n+            If you pass `None`, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        recurrent_activation: Activation function to use\n+            for the recurrent step.\n+            Default: sigmoid (`sigmoid`).\n+            If you pass `None`, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        use_bias: Boolean, (default `True`), whether the layer\n+            should use a bias vector.\n+        kernel_initializer: Initializer for the `kernel` weights matrix,\n+            used for the linear transformation of the inputs. Default:\n+            `\"glorot_uniform\"`.\n+        recurrent_initializer: Initializer for the `recurrent_kernel`\n+            weights matrix, used for the linear transformation of the recurrent\n+            state. Default: `\"orthogonal\"`.\n+        bias_initializer: Initializer for the bias vector. Default: `\"zeros\"`.\n+        kernel_regularizer: Regularizer function applied to the `kernel` weights\n+            matrix. Default: `None`.\n+        recurrent_regularizer: Regularizer function applied to the\n+            `recurrent_kernel` weights matrix. Default: `None`.\n+        bias_regularizer: Regularizer function applied to the bias vector.\n+            Default: `None`.\n+        activity_regularizer: Regularizer function applied to the output of the\n+            layer (its \"activation\"). Default: `None`.\n+        kernel_constraint: Constraint function applied to the `kernel` weights\n+            matrix. Default: `None`.\n+        recurrent_constraint: Constraint function applied to the\n+            `recurrent_kernel` weights matrix. Default: `None`.\n+        bias_constraint: Constraint function applied to the bias vector.\n+            Default: `None`.\n+        dropout: Float between 0 and 1. Fraction of the units to drop for the\n+            linear transformation of the inputs. Default: 0.\n+        recurrent_dropout: Float between 0 and 1. Fraction of the units to drop\n+            for the linear transformation of the recurrent state. Default: 0.\n+        return_sequences: Boolean. Whether to return the last output\n+            in the output sequence, or the full sequence. Default: `False`.\n+        return_state: Boolean. Whether to return the last state in addition\n+            to the output. Default: `False`.\n+        go_backwards: Boolean (default `False`).\n+            If `True`, process the input sequence backwards and return the\n+            reversed sequence.\n+        stateful: Boolean (default False). If `True`, the last state\n+            for each sample at index i in a batch will be used as initial\n+            state for the sample of index i in the following batch.\n+        unroll: Boolean (default False).\n+            If `True`, the network will be unrolled,\n+            else a symbolic loop will be used.\n+            Unrolling can speed-up a RNN,\n+            although it tends to be more memory-intensive.\n+            Unrolling is only suitable for short sequences.\n+        reset_after: GRU convention (whether to apply reset gate after or\n+            before matrix multiplication). `False` is `\"before\"`,\n+            `True` is `\"after\"` (default and cuDNN compatible).\n+\n+    Call arguments:\n+        inputs: A 3D tensor, with shape `(batch, timesteps, feature)`.\n+        mask: Binary tensor of shape `(samples, timesteps)` indicating whether\n+            a given timestep should be masked  (optional).\n+            An individual `True` entry indicates that the corresponding timestep\n+            should be utilized, while a `False` entry indicates that the\n+            corresponding timestep should be ignored. Defaults to `None`.\n+        training: Python boolean indicating whether the layer should behave in\n+            training mode or in inference mode. This argument is passed to the\n+            cell when calling it. This is only relevant if `dropout` or\n+            `recurrent_dropout` is used  (optional). Defaults to `None`.\n+        initial_state: List of initial state tensors to be passed to the first\n+            call of the cell (optional, `None` causes creation\n+            of zero-filled initial state tensors). Defaults to `None`.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        units,\n+        activation=\"tanh\",\n+        recurrent_activation=\"sigmoid\",\n+        use_bias=True,\n+        kernel_initializer=\"glorot_uniform\",\n+        recurrent_initializer=\"orthogonal\",\n+        bias_initializer=\"zeros\",\n+        kernel_regularizer=None,\n+        recurrent_regularizer=None,\n+        bias_regularizer=None,\n+        activity_regularizer=None,\n+        kernel_constraint=None,\n+        recurrent_constraint=None,\n+        bias_constraint=None,\n+        dropout=0.0,\n+        recurrent_dropout=0.0,\n+        return_sequences=False,\n+        return_state=False,\n+        go_backwards=False,\n+        stateful=False,\n+        unroll=False,\n+        reset_after=True,\n+        seed=None,\n+        **kwargs,\n+    ):\n+        cell = GRUCell(\n+            units,\n+            activation=activation,\n+            recurrent_activation=recurrent_activation,\n+            use_bias=use_bias,\n+            kernel_initializer=kernel_initializer,\n+            recurrent_initializer=recurrent_initializer,\n+            bias_initializer=bias_initializer,\n+            kernel_regularizer=kernel_regularizer,\n+            recurrent_regularizer=recurrent_regularizer,\n+            bias_regularizer=bias_regularizer,\n+            kernel_constraint=kernel_constraint,\n+            recurrent_constraint=recurrent_constraint,\n+            bias_constraint=bias_constraint,\n+            dropout=dropout,\n+            recurrent_dropout=recurrent_dropout,\n+            reset_after=reset_after,\n+            dtype=kwargs.get(\"dtype\", None),\n+            trainable=kwargs.get(\"trainable\", True),\n+            name=\"gru_cell\",\n+            seed=seed,\n+        )\n+        super().__init__(\n+            cell,\n+            return_sequences=return_sequences,\n+            return_state=return_state,\n+            go_backwards=go_backwards,\n+            stateful=stateful,\n+            unroll=unroll,\n+            activity_regularizer=activity_regularizer,\n+            **kwargs,\n+        )\n+        self.input_spec = InputSpec(ndim=3)\n+\n+    def inner_loop(self, sequence, initial_state, mask, training=False):\n+        if nest.is_nested(initial_state):\n+            initial_state = initial_state[0]\n+        if nest.is_nested(mask):\n+            mask = mask[0]\n+\n+        try:\n+            # Backends are allowed to specify (optionally) optimized\n+            # implementation of the inner GRU loop. In the case of\n+            # TF for instance, it will leverage cuDNN when feasible, and\n+            # it will raise NotImplementedError otherwise.\n+            return backend.gru(\n+                sequence,\n+                initial_state,\n+                mask,\n+                kernel=self.cell.kernel,\n+                recurrent_kernel=self.cell.recurrent_kernel,\n+                bias=self.cell.bias,\n+                activation=self.cell.activation,\n+                recurrent_activation=self.cell.recurrent_activation,\n+                return_sequences=self.return_sequences,\n+                go_backwards=self.go_backwards,\n+                unroll=self.unroll,\n+                reset_after=self.cell.reset_after,\n+            )\n+        except NotImplementedError:\n+            return super().inner_loop(\n+                sequence, initial_state, mask=mask, training=training\n+            )\n+\n+    def call(self, sequence, initial_state=None, mask=None, training=None):\n+        return super().call(\n+            sequence, mask=mask, training=training, initial_state=initial_state\n+        )\n+\n+    @property\n+    def units(self):\n+        return self.cell.units\n+\n+    @property\n+    def activation(self):\n+        return self.cell.activation\n+\n+    @property\n+    def recurrent_activation(self):\n+        return self.cell.recurrent_activation\n+\n+    @property\n+    def use_bias(self):\n+        return self.cell.use_bias\n+\n+    @property\n+    def kernel_initializer(self):\n+        return self.cell.kernel_initializer\n+\n+    @property\n+    def recurrent_initializer(self):\n+        return self.cell.recurrent_initializer\n+\n+    @property\n+    def bias_initializer(self):\n+        return self.cell.bias_initializer\n+\n+    @property\n+    def kernel_regularizer(self):\n+        return self.cell.kernel_regularizer\n+\n+    @property\n+    def recurrent_regularizer(self):\n+        return self.cell.recurrent_regularizer\n+\n+    @property\n+    def bias_regularizer(self):\n+        return self.cell.bias_regularizer\n+\n+    @property\n+    def kernel_constraint(self):\n+        return self.cell.kernel_constraint\n+\n+    @property\n+    def recurrent_constraint(self):\n+        return self.cell.recurrent_constraint\n+\n+    @property\n+    def bias_constraint(self):\n+        return self.cell.bias_constraint\n+\n+    @property\n+    def dropout(self):\n+        return self.cell.dropout\n+\n+    @property\n+    def recurrent_dropout(self):\n+        return self.cell.recurrent_dropout\n+\n+    @property\n+    def reset_after(self):\n+        return self.cell.reset_after\n+\n+    def get_config(self):\n+        config = {\n+            \"units\": self.units,\n+            \"activation\": activations.serialize(self.activation),\n+            \"recurrent_activation\": activations.serialize(\n+                self.recurrent_activation\n+            ),\n+            \"use_bias\": self.use_bias,\n+            \"kernel_initializer\": initializers.serialize(\n+                self.kernel_initializer\n+            ),\n+            \"recurrent_initializer\": initializers.serialize(\n+                self.recurrent_initializer\n+            ),\n+            \"bias_initializer\": initializers.serialize(self.bias_initializer),\n+            \"kernel_regularizer\": regularizers.serialize(\n+                self.kernel_regularizer\n+            ),\n+            \"recurrent_regularizer\": regularizers.serialize(\n+                self.recurrent_regularizer\n+            ),\n+            \"bias_regularizer\": regularizers.serialize(self.bias_regularizer),\n+            \"activity_regularizer\": regularizers.serialize(\n+                self.activity_regularizer\n+            ),\n+            \"kernel_constraint\": constraints.serialize(self.kernel_constraint),\n+            \"recurrent_constraint\": constraints.serialize(\n+                self.recurrent_constraint\n+            ),\n+            \"bias_constraint\": constraints.serialize(self.bias_constraint),\n+            \"dropout\": self.dropout,\n+            \"recurrent_dropout\": self.recurrent_dropout,\n+            \"reset_after\": self.reset_after,\n+        }\n+        base_config = super().get_config()\n+        del base_config[\"cell\"]\n+        return {**base_config, **config}\n+\n+    @classmethod\n+    def from_config(cls, config):\n+        return cls(**config)\n\n@@ -0,0 +1,172 @@\n+import numpy as np\n+import pytest\n+\n+from keras_core import backend\n+from keras_core import initializers\n+from keras_core import layers\n+from keras_core import testing\n+\n+\n+@pytest.mark.skipif(\n+    backend.backend() != \"tensorflow\",\n+    reason=\"Only implemented for TF for now.\",\n+)\n+class GRUTest(testing.TestCase):\n+    def test_basics(self):\n+        self.run_layer_test(\n+            layers.GRU,\n+            init_kwargs={\"units\": 3, \"dropout\": 0.5, \"recurrent_dropout\": 0.5},\n+            input_shape=(3, 2, 4),\n+            call_kwargs={\"training\": True},\n+            expected_output_shape=(3, 3),\n+            expected_num_trainable_weights=3,\n+            expected_num_non_trainable_weights=0,\n+            supports_masking=True,\n+        )\n+        self.run_layer_test(\n+            layers.GRU,\n+            init_kwargs={\n+                \"units\": 3,\n+                \"return_sequences\": True,\n+                \"bias_regularizer\": \"l1\",\n+                \"kernel_regularizer\": \"l2\",\n+                \"recurrent_regularizer\": \"l2\",\n+            },\n+            input_shape=(3, 2, 4),\n+            expected_output_shape=(3, 2, 3),\n+            expected_num_losses=3,\n+            expected_num_trainable_weights=3,\n+            expected_num_non_trainable_weights=0,\n+            supports_masking=True,\n+        )\n+\n+    def test_correctness(self):\n+        sequence = np.arange(72).reshape((3, 6, 4)).astype(\"float32\")\n+        layer = layers.GRU(\n+            3,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+        )\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.5217289, 0.5217289, 0.5217289],\n+                    [0.6371659, 0.6371659, 0.6371659],\n+                    [0.39384964, 0.39384964, 0.3938496],\n+                ]\n+            ),\n+            output,\n+        )\n+\n+        layer = layers.GRU(\n+            3,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+            go_backwards=True,\n+        )\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.24406259, 0.24406259, 0.24406259],\n+                    [0.611516, 0.611516, 0.611516],\n+                    [0.3928808, 0.3928808, 0.3928808],\n+                ]\n+            ),\n+            output,\n+        )\n+\n+        layer = layers.GRU(\n+            3,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+            unroll=True,\n+        )\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.5217289, 0.5217289, 0.5217289],\n+                    [0.6371659, 0.6371659, 0.6371659],\n+                    [0.39384964, 0.39384964, 0.3938496],\n+                ]\n+            ),\n+            output,\n+        )\n+\n+        layer = layers.GRU(\n+            3,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+            reset_after=False,\n+        )\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.51447755, 0.51447755, 0.51447755],\n+                    [0.6426879, 0.6426879, 0.6426879],\n+                    [0.40208298, 0.40208298, 0.40208298],\n+                ]\n+            ),\n+            output,\n+        )\n+\n+        layer = layers.GRU(\n+            3,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+            use_bias=False,\n+        )\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.49988455, 0.49988455, 0.49988455],\n+                    [0.64701194, 0.64701194, 0.64701194],\n+                    [0.4103359, 0.4103359, 0.4103359],\n+                ]\n+            ),\n+            output,\n+        )\n+\n+    def test_statefulness(self):\n+        sequence = np.arange(24).reshape((2, 3, 4)).astype(\"float32\")\n+        layer = layers.GRU(\n+            4,\n+            stateful=True,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+        )\n+        layer(sequence)\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.29542392, 0.29542392, 0.29542392, 0.29542392],\n+                    [0.5885018, 0.5885018, 0.5885018, 0.5885018],\n+                ]\n+            ),\n+            output,\n+        )\n+        layer.reset_state()\n+        layer(sequence)\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.29542392, 0.29542392, 0.29542392, 0.29542392],\n+                    [0.5885018, 0.5885018, 0.5885018, 0.5885018],\n+                ]\n+            ),\n+            output,\n+        )\n+\n+    # TODO: test masking\n\n\n\n@@ -321,6 +321,32 @@ class RNN(Layer):\n             for v in self.states:\n                 v.assign(ops.zeros_like(v))\n \n+    def inner_loop(self, sequence, initial_state, mask, training=False):\n+        cell_kwargs = {}\n+        if isinstance(self.cell, Layer) and self.cell._call_has_training_arg():\n+            cell_kwargs[\"training\"] = training\n+\n+        def step(inputs, states):\n+            output, new_states = self.cell(inputs, states, **cell_kwargs)\n+            if not nest.is_nested(new_states):\n+                new_states = [new_states]\n+            return output, new_states\n+\n+        if not nest.is_nested(initial_state):\n+            initial_state = [initial_state]\n+\n+        return backend.rnn(\n+            step,\n+            sequence,\n+            initial_state,\n+            go_backwards=self.go_backwards,\n+            mask=mask,\n+            unroll=self.unroll,\n+            input_length=sequence.shape[1],\n+            zero_output_for_mask=self.zero_output_for_mask,\n+            return_all_outputs=self.return_sequences,\n+        )\n+\n     def call(\n         self,\n         sequence,\n@@ -335,18 +361,12 @@ class RNN(Layer):\n                 \"time dimension is undefined. \\n\"\n                 \"- If using a Sequential model, \"\n                 \"specify the time dimension by passing \"\n-                \"an `input_shape` or `batch_input_shape` \"\n-                \"argument to your first layer. If your \"\n-                \"first layer is an Embedding, you can \"\n-                \"also use the `input_length` argument.\\n\"\n+                \"an `Input()` as your first layer.\\n\"\n                 \"- If using the functional API, specify \"\n                 \"the time dimension by passing a `shape` \"\n-                \"or `batch_shape` argument to your Input layer.\"\n+                \"or `batch_shape` argument to your `Input()`.\"\n             )\n \n-        cell_kwargs = {}\n-        if isinstance(self.cell, Layer) and self.cell._call_has_training_arg():\n-            cell_kwargs[\"training\"] = training\n         if initial_state is None:\n             if self.stateful:\n                 initial_state = self.states\n@@ -366,22 +386,11 @@ class RNN(Layer):\n             lambda x: ops.cast(x, dtype=self.compute_dtype), initial_state\n         )\n \n-        def step(inputs, states):\n-            output, new_states = self.cell(inputs, states, **cell_kwargs)\n-            if not nest.is_nested(new_states):\n-                new_states = [new_states]\n-            return output, new_states\n-\n-        last_output, outputs, states = backend.nn.rnn(\n-            step,\n-            sequence,\n-            initial_state,\n-            go_backwards=self.go_backwards,\n+        last_output, outputs, states = self.inner_loop(\n+            sequence=sequence,\n+            initial_state=initial_state,\n             mask=mask,\n-            unroll=self.unroll,\n-            input_length=timesteps,\n-            zero_output_for_mask=self.zero_output_for_mask,\n-            return_all_outputs=self.return_sequences,\n+            training=training,\n         )\n         self._maybe_reset_dropout_masks(self.cell)\n \n\n@@ -51,7 +51,7 @@ class SimpleRNNCell(Layer, DropoutRNNCell):\n             for the linear transformation of the recurrent state. Default: 0.\n \n     Call arguments:\n-        inputs: A 2D tensor, with shape `(batch, feature)`.\n+        inputs: A 2D tensor, with shape `(batch, features)`.\n         states: A 2D tensor with shape `(batch, units)`, which is the state\n             from the previous time step.\n         training: Python boolean indicating whether the layer should behave in\n@@ -334,7 +334,7 @@ class SimpleRNN(RNN):\n             dropout=dropout,\n             recurrent_dropout=recurrent_dropout,\n             seed=seed,\n-            dtype=kwargs.get(\"dtype\"),\n+            dtype=kwargs.get(\"dtype\", None),\n             trainable=kwargs.get(\"trainable\", True),\n             name=\"simple_rnn_cell\",\n         )\n@@ -347,10 +347,9 @@ class SimpleRNN(RNN):\n             unroll=unroll,\n             **kwargs,\n         )\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n         self.input_spec = [InputSpec(ndim=3)]\n \n-    def call(self, inputs, mask=None, training=None, initial_state=None):\n+    def call(self, inputs, initial_state=None, mask=None, training=None):\n         return super().call(\n             inputs, mask=mask, training=training, initial_state=initial_state\n         )\n\n@@ -102,5 +102,7 @@ class MetricTest(testing.TestCase):\n         self.assertEqual(len(metric.variables), 6)\n \n     def test_serialization(self):\n-        # TODO\n-        pass\n+        self.run_class_serialization_test(\n+            ExampleMetric(name=\"mse\"),\n+            custom_objects={\"ExampleMetric\": ExampleMetric},\n+        )\n\n@@ -1,22 +0,0 @@\n-\"\"\"\n-scatter\n-\"\"\"\n-\n-from keras_core import backend\n-from keras_core.backend import KerasTensor\n-from keras_core.backend import any_symbolic_tensors\n-from keras_core.operations.operation import Operation\n-\n-\n-class Scatter(Operation):\n-    def call(self, indices, values, shape):\n-        return backend.core.scatter(indices, values, shape)\n-\n-    def compute_output_spec(self, indices, values, shape):\n-        return KerasTensor(shape, dtype=values.dtype)\n-\n-\n-def scatter(indices, values, shape):\n-    if any_symbolic_tensors((indices, values, shape)):\n-        return Scatter().symbolic_call(indices, values, shape)\n-    return backend.core.scatter(indices, values, shape)\n\n@@ -1,64 +0,0 @@\n-import numpy as np\n-import pytest\n-\n-from keras_core import backend\n-from keras_core import testing\n-from keras_core.operations import core\n-\n-\n-@pytest.mark.skipif(\n-    not backend.DYNAMIC_SHAPES_OK,\n-    reason=\"Backend does not support dynamic shapes\",\n-)\n-class CoreOpsDynamicShapeTest(testing.TestCase):\n-    pass\n-\n-\n-class CoreOpsStaticShapeTest(testing.TestCase):\n-    def test_scatter(self):\n-        # Requires dtype\n-        indices = np.array([[0]], dtype=\"int32\")\n-        values = np.array([0], dtype=\"int32\")\n-        shape = (8,)\n-        self.assertEqual(core.scatter(indices, values, shape).shape, (8,))\n-\n-\n-class CoreOpsCorrectnessTest(testing.TestCase):\n-    def test_scatter(self):\n-        # Test 1D\n-        indices = np.array([[1], [3], [4], [7]])\n-        values = np.array([9, 10, 11, 12])\n-        self.assertAllClose(\n-            core.scatter(indices, values, (8,)),\n-            [0, 9, 0, 10, 11, 0, 0, 12],\n-        )\n-        # Test 2D\n-        indices = np.array([[0, 1], [2, 0]])\n-        values = np.array([5, 10])\n-        self.assertAllClose(\n-            core.scatter(indices, values, (3, 2)), [[0, 5], [0, 0], [10, 0]]\n-        )\n-        # Test 3D\n-        indices = np.array([[1], [3]])\n-        values = np.array(\n-            [\n-                [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n-                [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n-            ]\n-        )\n-        self.assertAllClose(\n-            core.scatter(indices, values, (4, 4, 4)),\n-            [\n-                [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],\n-                [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n-                [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],\n-                [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n-            ],\n-        )\n-        # Test slices\n-        indices = np.array([[2], [4]])\n-        values = np.array([[1, 2, 3], [4, 5, 6]])\n-        self.assertAllClose(\n-            core.scatter(indices, values, (6, 3)),\n-            [[0, 0, 0], [0, 0, 0], [1, 2, 3], [0, 0, 0], [4, 5, 6], [0, 0, 0]],\n-        )\n\n@@ -67,11 +67,15 @@ def get_metric(identifier, y_true, y_pred):\n             y_true, y_pred\n         )\n         if is_binary:\n-            metric_obj = metrics_module.binary_accuracy\n+            metric_obj = metrics_module.BinaryAccuracy(name=str(identifier))\n         elif is_sparse_categorical:\n-            metric_obj = metrics_module.sparse_categorical_accuracy\n+            metric_obj = metrics_module.SparseCategoricalAccuracy(\n+                name=str(identifier)\n+            )\n         else:\n-            metric_obj = metrics_module.categorical_accuracy\n+            metric_obj = metrics_module.CategoricalAccuracy(\n+                name=str(identifier)\n+            )\n \n     if not isinstance(metric_obj, metrics_module.Metric):\n         if isinstance(identifier, str):\n\n@@ -178,6 +178,21 @@ class TestCompileMetrics(testing.TestCase):\n         self.assertAllClose(result[\"mean_squared_error\"], 0.0)\n         self.assertAllClose(result[\"weighted_mean_squared_error\"], 0.0)\n \n+    def test_name_conversions(self):\n+        compile_metrics = CompileMetrics(\n+            metrics=[\"acc\", \"accuracy\"],\n+            weighted_metrics=[],\n+        )\n+        y_true = np.array([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])\n+        y_pred = np.array([[0.4, 0.1], [0.2, 0.6], [0.6, 0.1]])\n+        compile_metrics.build(y_true, y_pred)\n+        compile_metrics.update_state(y_true, y_pred, sample_weight=None)\n+        result = compile_metrics.result()\n+        self.assertTrue(isinstance(result, dict))\n+        self.assertEqual(len(result), 2)\n+        self.assertAllClose(result[\"acc\"], 0.333333)\n+        self.assertAllClose(result[\"accuracy\"], 0.333333)\n+\n \n class TestCompileLoss(testing.TestCase):\n     def test_single_output_case(self):\n\n@@ -60,10 +60,8 @@ class EpochIterator:\n         steps_per_epoch=None,\n         shuffle=False,\n         class_weight=None,\n-        steps_per_execution=1,\n     ):\n         self.steps_per_epoch = steps_per_epoch\n-        self.steps_per_execution = steps_per_execution\n         if steps_per_epoch:\n             self._current_iterator = None\n             self._insufficient_data = False\n@@ -106,7 +104,9 @@ class EpochIterator:\n                     \"sample_weights\", \"the sample weights\", \"PyDataset\"\n                 )\n         elif isinstance(x, types.GeneratorType):\n-            self.data_adapter = generator_data_adapter.GeneratorDataAdapter(x)\n+            self.data_adapter = generator_data_adapter.GeneratorDataAdapter(\n+                x, shuffle=shuffle\n+            )\n             if y is not None:\n                 raise_unsupported_arg(\"y\", \"the targets\", \"PyDataset\")\n             if sample_weight is not None:\n\n@@ -26,7 +26,6 @@ class Trainer:\n         metrics=None,\n         weighted_metrics=None,\n         run_eagerly=False,\n-        steps_per_execution=1,\n         jit_compile=True,\n     ):\n         self.optimizer = optimizers.get(optimizer)\n@@ -50,7 +49,6 @@ class Trainer:\n         self.stop_training = False\n         self.compiled = True\n         self._loss_tracker = metrics_module.Mean(name=\"loss\")\n-        self.steps_per_execution = steps_per_execution\n \n         self._compile_config = serialization_lib.SerializableDict(\n             optimizer=optimizer,\n@@ -59,7 +57,6 @@ class Trainer:\n             metrics=metrics,\n             weighted_metrics=weighted_metrics,\n             run_eagerly=run_eagerly,\n-            steps_per_execution=steps_per_execution,\n             jit_compile=jit_compile,\n         )\n \n\n@@ -1,5 +1,4 @@\n import numpy as np\n-import pytest\n \n from keras_core import backend\n from keras_core import initializers\n@@ -8,7 +7,6 @@ from keras_core import losses\n from keras_core import metrics\n from keras_core import optimizers\n from keras_core import testing\n-from keras_core.callbacks.callback import Callback\n \n if backend.backend() == \"jax\":\n     from keras_core.backend.jax.trainer import JAXTrainer as Trainer\n@@ -215,32 +213,3 @@ class TestTrainer(testing.TestCase):\n \n     def test_predict_flow_jit(self):\n         self._test_predict_flow(run_eagerly=False, jit_compile=True)\n-\n-    # TODO: Remove the skipif when implemented steps_per_execution for JAX.\n-    @pytest.mark.skipif(\n-        backend.backend() != \"tensorflow\",\n-        reason=\"JAX does not support steps_per_execution yet\",\n-    )\n-    def test_steps_per_execution_steps_count(self):\n-        class StepCount(Callback):\n-            def __init__(self):\n-                super().__init__()\n-                self.count = 0\n-                self.batches = [0, 3, 6]\n-\n-            def on_batch_begin(self, batch, logs=None):\n-                assert batch == self.batches[self.count]\n-                self.count += 1\n-\n-        x = np.ones((100, 4))\n-        y = np.ones((100, 1))\n-        model = ExampleModel(units=1)\n-        model.compile(loss=\"mse\", optimizer=\"adam\", steps_per_execution=3)\n-        step_count = StepCount()\n-        model.fit(x=x, y=y, batch_size=16, callbacks=[step_count])\n-        self.assertEqual(step_count.count, 3)\n-\n-        model_2 = ExampleModel(units=1)\n-        model_2.compile(loss=\"mse\", optimizer=\"adam\", steps_per_execution=1)\n-        model_2.fit(x=x, y=y, batch_size=16)\n-        self.assertAllClose(model.get_weights(), model_2.get_weights())\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
