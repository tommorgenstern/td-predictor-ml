{"custom_id": "keras#48f7bebf804455c211153e561061f3e94fe55409", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 11 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 32 | Churn Cumulative: 4221 | Contributors (this commit): 8 | Commits (past 90d): 31 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -33,6 +33,10 @@ from tensorflow.tools.docs import doc_controls\n H_AXIS = -3\n W_AXIS = -2\n \n+IMAGES = 'images'\n+LABELS = 'labels'\n+BOUNDING_BOXES = 'bounding_boxes'\n+\n \n def check_fill_mode_and_interpolation(fill_mode, interpolation):\n   if fill_mode not in {'reflect', 'wrap', 'constant', 'nearest'}:\n@@ -383,7 +387,7 @@ class BaseImageAugmentationLayer(base_layer.BaseRandomLayer):\n     inputs = self._ensure_inputs_are_compute_dtype(inputs)\n     if training:\n       inputs, is_dict = self._format_inputs(inputs)\n-      images = inputs['images']\n+      images = inputs[IMAGES]\n       if images.shape.rank == 3:\n         return self._format_output(self._augment(inputs), is_dict)\n       elif images.shape.rank == 4:\n@@ -396,20 +400,20 @@ class BaseImageAugmentationLayer(base_layer.BaseRandomLayer):\n       return inputs\n \n   def _augment(self, inputs):\n-    image = inputs.get('images', None)\n-    label = inputs.get('labels', None)\n-    bounding_box = inputs.get('bounding_boxes', None)\n+    image = inputs.get(IMAGES, None)\n+    label = inputs.get(LABELS, None)\n+    bounding_box = inputs.get(BOUNDING_BOXES, None)\n     transformation = self.get_random_transformation(\n         image=image, label=label, bounding_box=bounding_box)  # pylint: disable=assignment-from-none\n     image = self.augment_image(image, transformation=transformation)\n-    result = {'images': image}\n+    result = {IMAGES: image}\n     if label is not None:\n       label = self.augment_label(label, transformation=transformation)\n-      result['labels'] = label\n+      result[LABELS] = label\n     if bounding_box is not None:\n       bounding_box = self.augment_bounding_box(\n           bounding_box, transformation=transformation)\n-      result['bounding_boxes'] = bounding_box\n+      result[BOUNDING_BOXES] = bounding_box\n     return result\n \n   def _batch_augment(self, inputs):\n@@ -418,7 +422,7 @@ class BaseImageAugmentationLayer(base_layer.BaseRandomLayer):\n   def _format_inputs(self, inputs):\n     if tf.is_tensor(inputs):\n       # single image input tensor\n-      return {'images': inputs}, False\n+      return {IMAGES: inputs}, False\n     elif isinstance(inputs, dict):\n       # TODO(scottzhu): Check if it only contains the valid keys\n       return inputs, True\n@@ -428,13 +432,13 @@ class BaseImageAugmentationLayer(base_layer.BaseRandomLayer):\n \n   def _format_output(self, output, is_dict):\n     if not is_dict:\n-      return output['images']\n+      return output[IMAGES]\n     else:\n       return output\n \n   def _ensure_inputs_are_compute_dtype(self, inputs):\n     if isinstance(inputs, dict):\n-      inputs['images'] = utils.ensure_tensor(inputs['images'],\n+      inputs[IMAGES] = utils.ensure_tensor(inputs[IMAGES],\n                                              self.compute_dtype)\n     else:\n       inputs = utils.ensure_tensor(inputs, self.compute_dtype)\n@@ -1701,8 +1705,8 @@ class RandomHeight(BaseImageAugmentationLayer):\n     return {'height': adjusted_height}\n \n   def _batch_augment(self, inputs):\n-    images = self.augment_image(inputs['images'], transformation=None)\n-    result = {'images': images}\n+    images = self.augment_image(inputs[IMAGES], transformation=None)\n+    result = {IMAGES: images}\n     # to-do augment bbox to clip bbox to resized height value\n     return result\n \n@@ -1805,8 +1809,8 @@ class RandomWidth(BaseImageAugmentationLayer):\n     self.auto_vectorize = False\n \n   def _batch_augment(self, inputs):\n-    images = self.augment_image(inputs['images'])\n-    result = {'images': images}\n+    images = self.augment_image(inputs[IMAGES])\n+    result = {IMAGES: images}\n     # to-do augment bbox to clip bbox to resized width value\n     return result\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dc3018ddadb519e767151e1bc6057a4bd994dd2e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 103 | Lines Deleted: 73 | Files Changed: 4 | Hunks: 23 | Methods Changed: 9 | Complexity Δ (Sum/Max): 3/13 | Churn Δ: 176 | Churn Cumulative: 4905 | Contributors (this commit): 57 | Commits (past 90d): 15 | Contributors (cumulative): 78 | DMM Complexity: 0.9615384615384616\n\nDIFF:\n@@ -18,10 +18,10 @@\n import copy\n import functools\n import weakref\n+import re\n \n from keras.utils import io_utils\n from keras.utils import tf_inspect\n-from keras.utils.vis_utils import get_layer_index_bound_by_layer_name\n import numpy as np\n \n import tensorflow.compat.v2 as tf\n@@ -117,6 +117,32 @@ def count_params(weights):\n   return int(sum(np.prod(p) for p in standardized_weight_shapes))\n \n \n+def get_layer_index_bound_by_layer_name(model, layer_names):\n+  \"\"\"Return specific range of layers to plot, mainly for sub-graph plot models.\n+\n+  Args:\n+    model: tf.keras.Model\n+    layer_names: unique name of layer of the model, type(str)\n+\n+  Returns:\n+    return the index value of layer based on its unique name (layer_names)\n+  \"\"\"\n+  lower_index = []\n+  upper_index = []\n+  for idx, layer in enumerate(model.layers):\n+    if re.match(layer_names[0], layer.name):\n+      lower_index.append(idx)\n+    if re.match(layer_names[1], layer.name):\n+      upper_index.append(idx)\n+  if not lower_index or not upper_index:\n+    raise ValueError(\n+        'Passed layer_names does not match to layers in the model. '\n+        f'Recieved: {layer_names}')\n+  if min(lower_index) > max(upper_index):\n+    return [min(upper_index), max(lower_index)]\n+  return [min(lower_index), max(upper_index)]\n+\n+\n def print_summary(model,\n                   line_length=None,\n                   positions=None,\n@@ -220,7 +246,8 @@ def print_summary(model,\n       raise ValueError(\n           'layer_range should contain string type only. '\n           f'Received: {layer_range}')\n-    layer_range = get_layer_index_bound_by_layer_name(model, layer_range)\n+    layer_range = get_layer_index_bound_by_layer_name(\n+    \tmodel, layer_range)\n     if layer_range[0] < 0 or layer_range[1] > len(model.layers):\n       raise ValueError('Both values in layer_range should be in range (0, '\n                        f'{len(model.layers)}. Received: {layer_range}')\n@@ -360,7 +387,7 @@ def print_summary(model,\n \n   layers = model.layers\n   for i, layer in enumerate(layers):\n-    if (layer_range) and (i < layer_range[0] or i > layer_range[1]):\n+    if layer_range and (i < layer_range[0] or i > layer_range[1]):\n       continue\n     print_layer(layer)\n   print_fn('=' * line_length)\n\n@@ -262,23 +262,32 @@ class LayerUtilsTest(tf.test.TestCase):\n       reader.close()\n       check_str = (\n           'Model: '\n-          '\"trainable\"\\n____________________________________________________________________________\\n'\n+          '\"trainable\"\\n'\n+          '___________________________________________________________________'\n+          '_________\\n'\n           ' Layer (type)                Output Shape              Param #   '\n-          'Trainable  '\n-          '\\n============================================================================\\n'\n+          'Trainable  \\n'\n+          '==================================================================='\n+          '=========\\n'\n           ' conv (Conv2D)               (None, 2, 3, 2)           62        N '\n           '         \\n'\n           '                                                                   '\n+          '         '\n           '\\n flat (Flatten)              (None, 12)                0         '\n           'Y          \\n'\n           '                                                                   '\n-          '\\n dense (Dense)               (None, 5)                 65        '\n-          'Y          \\n'\n+          '         \\n'\n+          ' dense (Dense)               (None, 5)                 65        Y '\n+          '         \\n'\n           '                                                                   '\n-          '\\n============================================================================\\nTotal'\n-          ' params: 127\\nTrainable params: 65\\nNon-trainable params: '\n-          '62\\n____________________________________________________________________________\\n'\n-          '____________________________________________________________________________\\n'\n+          '         \\n'\n+          '================================================================='\n+          '===========\\n'\n+          'Total params: 127\\nTrainable params: 65\\nNon-trainable params: 62\\n'\n+          '___________________________________________________________________'\n+          '_________\\n'\n+          '___________________________________________________________________'\n+          '_________\\n'\n       )\n \n       fin_str = ''\n@@ -330,35 +339,52 @@ class LayerUtilsTest(tf.test.TestCase):\n       reader.close()\n       check_str = (\n           'Model: '\n-          '\"model_2\"\\n____________________________________________________________________________\\n'\n+          '\"model_2\"\\n'\n+          '___________________________________________________________________'\n+          '_________\\n'\n           ' Layer (type)                Output Shape              Param #   '\n-          'Trainable  '\n-          '\\n============================================================================\\n'\n+          'Trainable  \\n'\n+          '==================================================================='\n+          '=========\\n'\n           ' input3 (InputLayer)         [(None, None, None, 3)]   0         Y '\n           '         \\n'\n           '                                                                   '\n-          '\\n model_1 (Functional)        (None, None, None, 3)     24        '\n-          'Y          '\n-          '\\n|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n|'\n-          ' input1 (InputLayer)       [(None, None, None, 3)]   0         Y'\n-          '          |\\n|'\n-          '                                                                          '\n-          '|\\n| model (Functional)        (None, None, None, 3)     24        '\n-          'Y          '\n-          '|\\n||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\\n||'\n-          ' input2 (InputLayer)     [(None, None, None, 3)]   0         Y'\n-          '          ||\\n||'\n-          '                                                                        '\n-          '||\\n|| conv2d (Conv2D)         (None, None, None, 3)     12        '\n-          'N          ||\\n||'\n-          '                                                                        '\n-          '||\\n|| batch_normalization (BatchN  (None, None, None, 3)  12      '\n-          'Y          ||\\n|| ormalization)'\n-          '                                                          '\n-          '||\\n|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\\n============================================================================\\nTotal'\n-          ' params: 24\\nTrainable params: 6\\nNon-trainable params: '\n-          '18\\n____________________________________________________________________________\\n'\n-          '____________________________________________________________________________\\n'\n+          '         \\n'\n+          ' model_1 (Functional)        (None, None, None, 3)     24        Y '\n+          '         \\n'\n+          '|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯'\n+          '¯¯¯¯¯¯¯¯|\\n'\n+          '| input1 (InputLayer)       [(None, None, None, 3)]   0         Y  '\n+          '        |\\n'\n+          '|                                                                  '\n+          '        |\\n'\n+          '| model (Functional)        (None, None, None, 3)     24        Y  '\n+          '        |\\n'\n+          '||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯'\n+          '¯¯¯¯¯¯¯||\\n'\n+          '|| input2 (InputLayer)     [(None, None, None, 3)]   0         Y   '\n+          '       ||\\n'\n+          '||                                                                 '\n+          '       ||\\n'\n+          '|| conv2d (Conv2D)         (None, None, None, 3)     12        N   '\n+          '       ||\\n'\n+          '||                                                                 '\n+          '       ||\\n'\n+          '|| batch_normalization (BatchN  (None, None, None, 3)  12      Y   '\n+          '       ||\\n'\n+          '|| ormalization)                                                   '\n+          '       ||\\n'\n+          '|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯'\n+          '¯¯¯¯¯¯¯¯|\\n'\n+          '¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯'\n+          '¯¯¯¯¯¯¯¯¯\\n'\n+          '==================================================================='\n+          '=========\\n'\n+          'Total params: 24\\nTrainable params: 6\\nNon-trainable params: 18\\n'\n+          '___________________________________________________________________'\n+          '_________\\n'\n+          '___________________________________________________________________'\n+          '_________\\n'\n       )\n \n       fin_str = ''\n@@ -388,13 +414,16 @@ class LayerUtilsTest(tf.test.TestCase):\n       print(text, file=writer)\n \n     try:\n-      layer_utils.print_summary(model, print_fn=print_to_file, layer_range=[\"conv\", \"flat\"])\n+      layer_utils.print_summary(\n+          model, print_fn=print_to_file, layer_range=[\"conv\", \"flat\"])\n       self.assertTrue(tf.io.gfile.exists(fpath))\n       writer.close()\n       reader = open(fpath, 'r')\n       lines = reader.readlines()\n       reader.close()\n-      self.assertEqual(len(lines), 13)\n+      #The expected lenght with no layer filter is 15\n+      #we filtered out 2 lines by excluding the layer 'dense'\n+      self.assertEqual(len(lines), 15-2)\n     except ImportError:\n       pass\n \n@@ -459,12 +488,11 @@ class LayerUtilsTest(tf.test.TestCase):\n           'Non-trainable params: 6\\n'\n           '_________________________________________________________________\\n')\n       \n-      fin_str = ''\n-      for line in lines:\n-        fin_str += line\n-      print(fin_str)\n+      check_lines = check_str.split(\"\\n\")[:-1] #Removing final empty string which is not a line\n+\n+      fin_str = ''.join(lines)\n       self.assertIn(fin_str, check_str)\n-      self.assertEqual(len(lines), 23)\n+      self.assertEqual(len(lines), len(check_lines))\n     except ImportError:\n       pass\n \n\n@@ -20,9 +20,9 @@ import tensorflow.compat.v2 as tf\n \n import os\n import sys\n-import re\n \n from keras.utils import io_utils\n+from keras.utils import layer_utils\n from tensorflow.python.util.tf_export import keras_export\n \n \n@@ -66,32 +66,6 @@ def add_edge(dot, src, dst):\n     dot.add_edge(pydot.Edge(src, dst))\n \n \n-def get_layer_index_bound_by_layer_name(model, layer_names):\n-  \"\"\"Return specific range of layers to plot, mainly for sub-graph plot models.\n-\n-  Args:\n-    model: tf.keras.Model\n-    layer_names: unique name of layer of the model, type(str)\n-\n-  Returns:\n-    return the index value of layer based on its unique name (layer_names)\n-  \"\"\"\n-  lower_index = []\n-  upper_index = []\n-  for idx, layer in enumerate(model.layers):\n-    if re.match(layer_names[0], layer.name):\n-      lower_index.append(idx)\n-    if re.match(layer_names[1], layer.name):\n-      upper_index.append(idx)\n-  if not lower_index or not upper_index:\n-    raise ValueError(\n-        'Passed layer_names does not match to layers in the model. '\n-        f'Recieved: {layer_names}')\n-  if min(lower_index) > max(upper_index):\n-    return [min(upper_index), max(lower_index)]\n-  return [min(lower_index), max(upper_index)]\n-\n-\n @keras_export('keras.utils.model_to_dot')\n def model_to_dot(model,\n                  show_shapes=False,\n@@ -183,7 +157,7 @@ def model_to_dot(model,\n       raise ValueError(\n           'layer_range should contain string type only. '\n           f'Received: {layer_range}')\n-    layer_range = get_layer_index_bound_by_layer_name(model, layer_range)\n+    layer_range = layer_utils.get_layer_index_bound_by_layer_name(model, layer_range)\n     if layer_range[0] < 0 or layer_range[1] > len(model.layers):\n       raise ValueError('Both values in layer_range should be in range (0, '\n                        f'{len(model.layers)}. Received: {layer_range}')\n\n@@ -21,6 +21,7 @@ from absl.testing import parameterized\n import keras\n from keras.applications import efficientnet\n from keras.utils import vis_utils\n+from keras.utils import layer_utils\n \n \n class ModelToDotFormatTest(tf.test.TestCase, parameterized.TestCase):\n@@ -220,7 +221,7 @@ class ModelToDotFormatTest(tf.test.TestCase, parameterized.TestCase):\n \n \n def get_layer_ids_from_model(model, layer_range):\n-  layer_range = vis_utils.get_layer_index_bound_by_layer_name(\n+  layer_range = layer_utils.get_layer_index_bound_by_layer_name(\n       model, layer_range)\n   layer_ids_from_model = []\n   for i, layer in enumerate(model.layers):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#176fef665fb4a51303e76a1e4295020ddcc52b5f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 33 | Lines Deleted: 13 | Files Changed: 2 | Hunks: 7 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 46 | Churn Cumulative: 181 | Contributors (this commit): 5 | Commits (past 90d): 10 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -328,14 +328,6 @@ class MultiHeadAttention(Layer):\n     else:\n       self._key_shape = tf.TensorShape(key)\n \n-    common_kwargs = dict(\n-        kernel_initializer=self._kernel_initializer,\n-        bias_initializer=self._bias_initializer,\n-        kernel_regularizer=self._kernel_regularizer,\n-        bias_regularizer=self._bias_regularizer,\n-        activity_regularizer=self._activity_regularizer,\n-        kernel_constraint=self._kernel_constraint,\n-        bias_constraint=self._bias_constraint)\n     # Any setup work performed only once should happen in an `init_scope`\n     # to avoid creating symbolic Tensors that will later pollute any eager\n     # operations.\n@@ -349,7 +341,7 @@ class MultiHeadAttention(Layer):\n                                          [self._num_heads, self._key_dim]),\n           bias_axes=bias_axes if self._use_bias else None,\n           name=\"query\",\n-          **common_kwargs)\n+          **self._get_common_kwargs_for_sublayer())\n       einsum_equation, bias_axes, output_rank = _build_proj_equation(\n           self._key_shape.rank - 1, bound_dims=1, output_dims=2)\n       self._key_dense = core.EinsumDense(\n@@ -358,7 +350,7 @@ class MultiHeadAttention(Layer):\n                                          [self._num_heads, self._key_dim]),\n           bias_axes=bias_axes if self._use_bias else None,\n           name=\"key\",\n-          **common_kwargs)\n+          **self._get_common_kwargs_for_sublayer())\n       einsum_equation, bias_axes, output_rank = _build_proj_equation(\n           self._value_shape.rank - 1, bound_dims=1, output_dims=2)\n       self._value_dense = core.EinsumDense(\n@@ -367,14 +359,33 @@ class MultiHeadAttention(Layer):\n                                          [self._num_heads, self._value_dim]),\n           bias_axes=bias_axes if self._use_bias else None,\n           name=\"value\",\n-          **common_kwargs)\n+          **self._get_common_kwargs_for_sublayer())\n \n       # Builds the attention computations for multi-head dot product attention.\n       # These computations could be wrapped into the keras attention layer once\n-      # it support mult-head einsum computations.\n+      # it supports mult-head einsum computations.\n       self._build_attention(output_rank)\n       self._output_dense = self._make_output_dense(\n-          free_dims, common_kwargs, \"attention_output\")\n+          free_dims, self._get_common_kwargs_for_sublayer(),\n+          \"attention_output\")\n+\n+  def _get_common_kwargs_for_sublayer(self):\n+    common_kwargs = dict(\n+        kernel_regularizer=self._kernel_regularizer,\n+        bias_regularizer=self._bias_regularizer,\n+        activity_regularizer=self._activity_regularizer,\n+        kernel_constraint=self._kernel_constraint,\n+        bias_constraint=self._bias_constraint)\n+    # Create new clone of kernel/bias initializer, so that we don't reuse the\n+    # initializer instance, which could lead to same init value since\n+    # initializer is stateless.\n+    kernel_initializer = self._kernel_initializer.__class__.from_config(\n+        self._kernel_initializer.get_config())\n+    bias_initializer = self._bias_initializer.__class__.from_config(\n+        self._bias_initializer.get_config())\n+    common_kwargs['kernel_initializer'] = kernel_initializer\n+    common_kwargs['bias_initializer'] = bias_initializer\n+    return common_kwargs\n \n   def _make_output_dense(self, free_dims, common_kwargs, name=None):\n     \"\"\"Builds the output projection matrix.\n\n@@ -135,6 +135,15 @@ class MultiHeadAttentionTest(test_combinations.TestCase):\n     output = test_layer(query, query)\n     self.assertEqual(output.shape.as_list(), [None, 40, 80])\n \n+    # Make sure the sub layers have different kernel init value, and not reusing\n+    # the initializers.\n+    self.assertNotAllClose(keras.backend.eval(test_layer._query_dense.kernel),\n+                           keras.backend.eval(test_layer._key_dense.kernel))\n+    self.assertNotAllClose(keras.backend.eval(test_layer._query_dense.kernel),\n+                           keras.backend.eval(test_layer._value_dense.kernel))\n+    self.assertNotAllClose(keras.backend.eval(test_layer._query_dense.kernel),\n+                           keras.backend.eval(test_layer._output_dense.kernel))\n+\n   def test_masked_attention_with_scores(self):\n     \"\"\"Test with a mask tensor.\"\"\"\n     test_layer = keras.layers.MultiHeadAttention(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1132da66c8852093901201822320ff3aba754b43", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 11 | Files Changed: 2 | Hunks: 7 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 26 | Churn Cumulative: 11157 | Contributors (this commit): 109 | Commits (past 90d): 12 | Contributors (cumulative): 120 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2573,9 +2573,13 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n         for layer in self.model.layers:\n           for weight in layer.weights:\n             weight_name = weight.name.replace(':', '_')\n-            tf.summary.histogram(weight_name, weight, step=epoch)\n+            # Add a suffix to prevent summary tag name collision.\n+            histogram_weight_name = weight_name + '/histogram'\n+            tf.summary.histogram(histogram_weight_name, weight, step=epoch)\n             if self.write_images:\n-              self._log_weight_as_image(weight, weight_name, epoch)\n+              # Add a suffix to prevent summary tag name collision.\n+              image_weight_name = weight_name + '/image'\n+              self._log_weight_as_image(weight, image_weight_name, epoch)\n         self._train_writer.flush()\n \n   def _log_weight_as_image(self, weight, weight_name, epoch):\n\n@@ -2552,8 +2552,8 @@ class TestTensorBoardV2(test_combinations.TestCase):\n     self.assertEqual(\n         self._strip_layer_names(summary_file.histograms, model_type),\n         {\n-            _ObservedSummary(logdir=self.train_dir, tag='bias_0'),\n-            _ObservedSummary(logdir=self.train_dir, tag='kernel_0'),\n+            _ObservedSummary(logdir=self.train_dir, tag='bias_0/histogram'),\n+            _ObservedSummary(logdir=self.train_dir, tag='kernel_0/histogram'),\n         },\n     )\n \n@@ -2586,17 +2586,17 @@ class TestTensorBoardV2(test_combinations.TestCase):\n     self.assertEqual(\n         self._strip_layer_names(summary_file.histograms, model_type),\n         {\n-            _ObservedSummary(logdir=self.train_dir, tag='bias_0'),\n-            _ObservedSummary(logdir=self.train_dir, tag='kernel_0'),\n+            _ObservedSummary(logdir=self.train_dir, tag='bias_0/histogram'),\n+            _ObservedSummary(logdir=self.train_dir, tag='kernel_0/histogram'),\n         },\n     )\n     if summary_file.convert_from_v2_summary_proto:\n-      expected = {\n-          _ObservedSummary(logdir=self.train_dir, tag='bias_0'),\n-          _ObservedSummary(logdir=self.train_dir, tag='kernel_0'),\n+      expected_image_summaries = {\n+          _ObservedSummary(logdir=self.train_dir, tag='bias_0/image'),\n+          _ObservedSummary(logdir=self.train_dir, tag='kernel_0/image'),\n       }\n     else:\n-      expected = {\n+      expected_image_summaries = {\n           _ObservedSummary(logdir=self.train_dir, tag='bias_0/image/0'),\n           _ObservedSummary(logdir=self.train_dir, tag='kernel_0/image/0'),\n           _ObservedSummary(logdir=self.train_dir, tag='kernel_0/image/1'),\n@@ -2604,7 +2604,7 @@ class TestTensorBoardV2(test_combinations.TestCase):\n       }\n     self.assertEqual(\n         self._strip_layer_names(summary_file.images, model_type),\n-        expected\n+        expected_image_summaries\n     )\n \n   def test_TensorBoard_projector_callback(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#574c7a20b90cf5a1012db504e19877148a3145a9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 17 | Files Changed: 4 | Hunks: 9 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/3 | Churn Δ: 51 | Churn Cumulative: 11913 | Contributors (this commit): 32 | Commits (past 90d): 27 | Contributors (cumulative): 50 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3013,23 +3013,12 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     \"\"\"\n     if self._saved_model_inputs_spec is not None:\n       return  # Already set.\n-    args = args or []\n-    kwargs = kwargs or {}\n \n     inputs_spec = tf.nest.map_structure(tf_utils.get_tensor_spec, inputs)\n-\n-    # Filter out non-tensor arguments from args and kwargs.\n-    args_spec = []\n-    for arg in args:\n-      flat_arg = tf.nest.flatten(arg)\n-      flat_specs = [tf_utils.get_tensor_spec(x) for x in flat_arg]\n-      if any(s is None for s in flat_specs):\n-        break  # Stop recording positional args once a non-tensor has been found\n-      args_spec.append(tf.nest.pack_sequence_as(arg, flat_specs))\n+    args_spec  = tf.nest.map_structure(tf_utils.get_tensor_spec, args or [])\n     kwargs_spec = {}\n+    # Filter out non-tensor arguments from kwargs.\n     for key, kwarg in kwargs.items():\n-      if key == 'training':\n-        continue\n       flat_kwarg = tf.nest.flatten(kwarg)\n       flat_specs = [tf_utils.get_tensor_spec(x) for x in flat_kwarg]\n       if any(s is None for s in flat_specs):\n@@ -3037,7 +3026,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n       kwargs_spec[key] = tf.nest.pack_sequence_as(kwarg, flat_specs)\n \n     self._saved_model_inputs_spec = inputs_spec\n-    self._saved_model_arg_spec = ([inputs_spec] + args_spec, kwargs_spec)\n+    self._saved_model_arg_spec = ([inputs_spec] + list(args_spec), kwargs_spec)\n \n   def _get_save_spec(self, dynamic_batch=True, inputs_only=True):\n     if self._saved_model_inputs_spec is None:\n\n@@ -554,10 +554,16 @@ class LayerCallCollection:\n \n   def trace_with_input_signature(self):\n     \"\"\"Trace with the layer/models inferred input signature if possible.\"\"\"\n-    if None not in tf.nest.flatten(self._layer_inputs):\n+    if self._layer_inputs[0] is None:\n+      return\n+\n+    args, kwargs = self._layer_inputs\n+    if self._expects_training_arg:\n+      args, kwargs = self._call_spec.set_arg_value('training', False, args,\n+                                                   kwargs, inputs_in_args=True)\n+    if None not in tf.nest.flatten([args, kwargs]):\n       # Manually add traces for layers that have keyword arguments and have\n       # a fully defined input signature.\n-      args, kwargs = self._layer_inputs\n       self.add_trace(*args, **kwargs)\n \n \n\n@@ -941,6 +941,28 @@ class TestSavedModelFormatAllModes(test_combinations.TestCase):\n     self.assertAllEqual(self.evaluate(expected),\n                         self.evaluate(actual))\n \n+  def testSaveMultipleInputsWithTraining(self):\n+\n+    class CustomModel(keras.Model):\n+      def call(self, input_1, training, input_2):\n+        if training:\n+          return input_1\n+        else:\n+          return input_2\n+\n+    inp1 = tf.constant(1., shape=[1])\n+    inp2 = tf.constant(2., shape=[1])\n+\n+    model = CustomModel()\n+    self.assertEqual(self.evaluate(model(inp1, True, inp2)), 1.)\n+    self.assertEqual(self.evaluate(model(inp1, False, inp2)), 2.)\n+\n+    saved_model_dir = self._save_model_dir()\n+    model.save(saved_model_dir, save_format='tf')\n+    loaded = keras_load.load(saved_model_dir)\n+    self.assertEqual(self.evaluate(loaded(inp1, True, inp2)), 1.)\n+    self.assertEqual(self.evaluate(loaded(inp1, False, inp2)), 2.)\n+\n   def test_wrapped_layer_training(self):\n     class Custom(keras.models.Model):\n \n\n@@ -299,7 +299,7 @@ def _enforce_names_consistency(specs):\n   \"\"\"Enforces that either all specs have names or none do.\"\"\"\n \n   def _has_name(spec):\n-    return hasattr(spec, 'name') and spec.name is not None\n+    return spec is None or (hasattr(spec, 'name') and spec.name is not None)\n \n   def _clear_name(spec):\n     spec = copy.deepcopy(spec)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#158fee33a100767ab1d2c3b69a49bdac8a277e69", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 12 | Files Changed: 1 | Hunks: 6 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 7478 | Contributors (this commit): 105 | Commits (past 90d): 7 | Contributors (cumulative): 105 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2917,25 +2917,13 @@ class LambdaCallback(Callback):\n     self.__dict__.update(kwargs)\n     if on_epoch_begin is not None:\n       self.on_epoch_begin = on_epoch_begin\n-    else:\n-      self.on_epoch_begin = lambda epoch, logs: None\n     if on_epoch_end is not None:\n       self.on_epoch_end = on_epoch_end\n-    else:\n-      self.on_epoch_end = lambda epoch, logs: None\n     if on_batch_begin is not None:\n       self.on_batch_begin = on_batch_begin\n-    else:\n-      self.on_batch_begin = lambda batch, logs: None\n     if on_batch_end is not None:\n       self.on_batch_end = on_batch_end\n-    else:\n-      self.on_batch_end = lambda batch, logs: None\n     if on_train_begin is not None:\n       self.on_train_begin = on_train_begin\n-    else:\n-      self.on_train_begin = lambda logs: None\n     if on_train_end is not None:\n       self.on_train_end = on_train_end\n-    else:\n-      self.on_train_end = lambda logs: None\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#eaf9cd283fb3f076beebb2cb0652df9aa8ee87be", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 4236 | Contributors (this commit): 8 | Commits (past 90d): 32 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -231,14 +231,14 @@ class BaseImageAugmentationLayer(base_layer.BaseRandomLayer):\n   `augment_label()`, which handles label augmentation if the layer supports\n   that.\n \n-  `augment_bounding_box()`, which handles the bounding box augmentation, if the\n+  `augment_bounding_boxes()`, which handles the bounding box augmentation, if the\n   layer supports that.\n \n   `get_random_transformation()`, which should produce a random transformation\n   setting. The tranformation object, which could be any type, will be passed to\n-  `augment_image`, `augment_label` and `augment_bounding_box`, to coodinate\n+  `augment_image`, `augment_label` and `augment_bounding_boxes`, to coodinate\n   the randomness behavior, eg, in the RandomFlip layer, the image and\n-  bounding_box should be changed in the same way.\n+  bounding_boxes should be changed in the same way.\n \n   The `call()` method support two formats of inputs:\n   1. Single image tensor with 3D (HWC) or 4D (NHWC) format.\n@@ -350,11 +350,12 @@ class BaseImageAugmentationLayer(base_layer.BaseRandomLayer):\n     raise NotImplementedError()\n \n   @doc_controls.for_subclass_implementers\n-  def augment_bounding_box(self, bounding_box, transformation=None):\n+  def augment_bounding_boxes(self, image, bounding_boxes, transformation=None):\n     \"\"\"Augment bounding boxes for one image during training.\n \n     Args:\n-      bounding_box: 2D bounding boxes to the layer. Forwarded from `call()`.\n+      image: 3D image input tensor to the layer. Forwarded from `layer.call()`.\n+      bounding_boxes: 2D bounding boxes to the layer. Forwarded from `call()`.\n       transformation: The transformation object produced by\n         `get_random_transformation`. Used to coordinate the randomness between\n         image, label and bounding box.\n@@ -411,8 +412,8 @@ class BaseImageAugmentationLayer(base_layer.BaseRandomLayer):\n       label = self.augment_label(label, transformation=transformation)\n       result[LABELS] = label\n     if bounding_box is not None:\n-      bounding_box = self.augment_bounding_box(\n-          bounding_box, transformation=transformation)\n+      bounding_box = self.augment_bounding_boxes(\n+          image, bounding_box, transformation=transformation)\n       result[BOUNDING_BOXES] = bounding_box\n     return result\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bfe318c89b900cfdf3e4267e2e77e12e187cbf36", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 42 | Lines Deleted: 47 | Files Changed: 2 | Hunks: 32 | Methods Changed: 10 | Complexity Δ (Sum/Max): -8/0 | Churn Δ: 89 | Churn Cumulative: 7214 | Contributors (this commit): 9 | Commits (past 90d): 51 | Contributors (cumulative): 17 | DMM Complexity: 0.0\n\nDIFF:\n@@ -274,7 +274,7 @@ class BaseImageAugmentationLayer(base_layer.BaseRandomLayer):\n       super().__init__(**kwargs)\n       self._factor = factor\n \n-    def augment_image(self, image, transformation=None):\n+    def augment_image(self, image, transformation):\n       random_factor = tf.random.uniform([], self._factor[0], self._factor[1])\n       mean = tf.math.reduced_mean(inputs, axis=-1, keep_dim=True)\n       return (inputs - mean) * random_factor + mean\n@@ -320,7 +320,7 @@ class BaseImageAugmentationLayer(base_layer.BaseRandomLayer):\n       return tf.map_fn\n \n   @doc_controls.for_subclass_implementers\n-  def augment_image(self, image, transformation=None):\n+  def augment_image(self, image, transformation):\n     \"\"\"Augment a single image during training.\n \n     Args:\n@@ -335,7 +335,7 @@ class BaseImageAugmentationLayer(base_layer.BaseRandomLayer):\n     raise NotImplementedError()\n \n   @doc_controls.for_subclass_implementers\n-  def augment_label(self, label, transformation=None):\n+  def augment_label(self, label, transformation):\n     \"\"\"Augment a single label during training.\n \n     Args:\n@@ -523,9 +523,7 @@ class RandomCrop(BaseImageAugmentationLayer):\n     w_start = rands[1] % (w_diff + 1)\n     return {'top': h_start, 'left': w_start}\n \n-  def augment_image(self, image, transformation=None):\n-    if transformation is None:\n-      transformation = self.get_random_transformation(image)\n+  def augment_image(self, image, transformation):\n     input_shape = tf.shape(image)\n     h_diff = input_shape[H_AXIS] - self.height\n     w_diff = input_shape[W_AXIS] - self.width\n@@ -677,10 +675,10 @@ class RandomFlip(BaseImageAugmentationLayer):\n     self.seed = seed\n     self.auto_vectorize = False\n \n-  def augment_label(self, label, transformation=None):\n+  def augment_label(self, label, transformation):\n     return label\n \n-  def augment_image(self, image, transformation=None):\n+  def augment_image(self, image, transformation):\n     flipped_outputs = image\n     if self.horizontal:\n       seed = self._random_generator.make_seed_for_stateless_op()\n@@ -820,7 +818,7 @@ class RandomTranslation(BaseImageAugmentationLayer):\n     self.seed = seed\n \n   @tf.function\n-  def augment_image(self, image, transformation=None):\n+  def augment_image(self, image, transformation):\n     \"\"\"Translated inputs with random ops.\"\"\"\n     # The transform op only accepts rank 4 inputs, so if we have an unbatched\n     # image, we need to temporarily expand dims to a batch.\n@@ -830,9 +828,6 @@ class RandomTranslation(BaseImageAugmentationLayer):\n     inputs_shape = tf.shape(inputs)\n     img_hd = tf.cast(inputs_shape[H_AXIS], tf.float32)\n     img_wd = tf.cast(inputs_shape[W_AXIS], tf.float32)\n-\n-    if transformation is None:\n-      transformation = self.get_random_transformation(image=image)\n     height_translation = transformation['height_translation']\n     width_translation = transformation['width_translation']\n     height_translation = height_translation * img_hd\n@@ -873,7 +868,7 @@ class RandomTranslation(BaseImageAugmentationLayer):\n     # issue for different tensorspec between inputs and outputs.\n     return tf.vectorized_map(self._augment, inputs)\n \n-  def augment_label(self, label, transformation=None):\n+  def augment_label(self, label, transformation):\n     return label\n \n   def compute_output_shape(self, input_shape):\n@@ -1145,9 +1140,7 @@ class RandomRotation(BaseImageAugmentationLayer):\n         shape=[1], minval=min_angle, maxval=max_angle)\n     return {'angle': angle}\n \n-  def augment_image(self, image, transformation=None):\n-    if transformation is None:\n-      transformation = self.get_random_transformation()\n+  def augment_image(self, image, transformation):\n     image = utils.ensure_tensor(image, self.compute_dtype)\n     original_shape = image.shape\n     image = tf.expand_dims(image, 0)\n@@ -1165,7 +1158,7 @@ class RandomRotation(BaseImageAugmentationLayer):\n     output.set_shape(original_shape)\n     return output\n \n-  def augment_label(self, label, transformation=None):\n+  def augment_label(self, label, transformation):\n     return label\n \n   def compute_output_shape(self, input_shape):\n@@ -1307,10 +1300,8 @@ class RandomZoom(BaseImageAugmentationLayer):\n \n     return {'height_zoom': height_zoom, 'width_zoom': width_zoom}\n \n-  def augment_image(self, image, transformation=None):\n+  def augment_image(self, image, transformation):\n     image = utils.ensure_tensor(image, self.compute_dtype)\n-    if transformation is None:\n-      transformation = self.get_random_transformation()\n     original_shape = image.shape\n     image = tf.expand_dims(image, 0)\n     image_shape = tf.shape(image)\n@@ -1331,7 +1322,7 @@ class RandomZoom(BaseImageAugmentationLayer):\n     output.set_shape(original_shape)\n     return output\n \n-  def augment_label(self, label, transformation=None):\n+  def augment_label(self, label, transformation):\n     return label\n \n   def compute_output_shape(self, input_shape):\n@@ -1459,16 +1450,14 @@ class RandomContrast(BaseImageAugmentationLayer):\n         shape=[], minval=lower, maxval=upper, seed=random_seed)\n     return {'contrast_factor': contrast_factor}\n \n-  def augment_image(self, image, transformation=None):\n-    if transformation is None:\n-      transformation = self.get_random_transformation()\n+  def augment_image(self, image, transformation):\n     contrast_factor = transformation['contrast_factor']\n     output = tf.image.adjust_contrast(image, contrast_factor=contrast_factor)\n     output = tf.clip_by_value(output, 0, 255)\n     output.set_shape(image.shape)\n     return output\n \n-  def augment_label(self, label, transformation=None):\n+  def augment_label(self, label, transformation):\n     return label\n \n   def compute_output_shape(self, input_shape):\n@@ -1554,12 +1543,10 @@ class RandomBrightness(BaseImageAugmentationLayer):\n     self._set_value_range(value_range)\n     self._seed = seed\n \n-  def augment_image(self, image, transformation=None):\n-    if transformation is None:\n-      transformation = self.get_random_transformation()\n+  def augment_image(self, image, transformation):\n     return self._brightness_adjust(image, transformation['rgb_delta'])\n \n-  def augment_label(self, label, transformation=None):\n+  def augment_label(self, label, transformation):\n     return label\n \n   def get_random_transformation(self,\n@@ -1706,14 +1693,14 @@ class RandomHeight(BaseImageAugmentationLayer):\n     return {'height': adjusted_height}\n \n   def _batch_augment(self, inputs):\n-    images = self.augment_image(inputs[IMAGES], transformation=None)\n+    images = self.augment_image(\n+        inputs[IMAGES],\n+        transformation=self.get_random_transformation(image=inputs[IMAGES]))\n     result = {IMAGES: images}\n     # to-do augment bbox to clip bbox to resized height value\n     return result\n \n-  def augment_image(self, image, transformation=None):\n-    if transformation is None:\n-      transformation = self.get_random_transformation(image)\n+  def augment_image(self, image, transformation):\n     # The batch dimension of the input=image is not modified. The output would\n     # be accurate for both unbatched and batched input\n     inputs_shape = tf.shape(image)\n@@ -1810,14 +1797,14 @@ class RandomWidth(BaseImageAugmentationLayer):\n     self.auto_vectorize = False\n \n   def _batch_augment(self, inputs):\n-    images = self.augment_image(inputs[IMAGES])\n+    images = self.augment_image(\n+        inputs[IMAGES],\n+        transformation=self.get_random_transformation(image=inputs[IMAGES]))\n     result = {IMAGES: images}\n     # to-do augment bbox to clip bbox to resized width value\n     return result\n \n-  def augment_image(self, image, transformation=None):\n-    if transformation is None:\n-      transformation = self.get_random_transformation(image)\n+  def augment_image(self, image, transformation):\n     # The batch dimension of the input=image is not modified. The output would\n     # be accurate for both unbatched and batched input\n     inputs = utils.ensure_tensor(image)\n\n@@ -442,7 +442,8 @@ class RandomCropTest(test_combinations.TestCase):\n       layer = image_preprocessing.RandomCrop(8, 8)\n       with tf.compat.v1.test.mock.patch.object(\n           layer._random_generator, 'random_uniform', return_value=mock_offset):\n-        actual_output = layer.augment_image(inp)\n+        actual_output = layer.augment_image(\n+            inp, transformation=layer.get_random_transformation(image=inp))\n         self.assertAllClose(inp[2:10, 2:10, :], actual_output)\n \n   def test_training_false(self):\n@@ -744,7 +745,8 @@ class RandomContrastTest(test_combinations.TestCase):\n     ):\n       with test_utils.use_gpu():\n         layer = image_preprocessing.RandomContrast((0.2, 0.5))\n-        actual_output = layer.augment_image(inp)\n+        actual_output = layer.augment_image(\n+            inp, transformation=layer.get_random_transformation())\n         self.assertAllClose(expected_output, actual_output)\n \n   @test_utils.run_v2_only\n@@ -820,7 +822,8 @@ class RandomBrightnessTest(test_combinations.TestCase):\n     # Always scale up, but randomly between 0 ~ 255\n     layer = image_preprocessing.RandomBrightness([0, 1.0])\n     image = np.random.randint(0, 255, size=(224, 224, 3))\n-    output = layer.augment_image(image, transformation=None)\n+    output = layer.augment_image(\n+        image, transformation=layer.get_random_transformation())\n     diff = output - image\n     self.assertGreaterEqual(tf.math.reduce_min(diff), 0)\n     self.assertGreater(tf.math.reduce_mean(diff), 0)\n@@ -828,7 +831,8 @@ class RandomBrightnessTest(test_combinations.TestCase):\n     # Always scale down, but randomly between 0 ~ 255\n     layer = image_preprocessing.RandomBrightness([-1.0, 0.0])\n     image = np.random.randint(0, 255, size=(224, 224, 3))\n-    output = layer.augment_image(image)\n+    output = layer.augment_image(\n+        image, transformation=layer.get_random_transformation())\n     diff = output - image\n     self.assertLessEqual(tf.math.reduce_max(diff), 0)\n     self.assertLess(tf.math.reduce_mean(diff), 0)\n@@ -1533,7 +1537,8 @@ class RandomRotationTest(test_combinations.TestCase):\n       input_image = np.reshape(np.arange(0, 25), (5, 5, 1)).astype(np.float32)\n       # 180 rotation.\n       layer = image_preprocessing.RandomRotation(factor=(0.5, 0.5))\n-      output_image = layer.augment_image(input_image, transformation=None)\n+      output_image = layer.augment_image(\n+          input_image, transformation=layer.get_random_transformation())\n       expected_output = np.asarray([\n           [24, 23, 22, 21, 20],\n           [19, 18, 17, 16, 15],\n@@ -1671,7 +1676,8 @@ class RandomZoomTest(test_combinations.TestCase):\n       input_image = np.reshape(np.arange(0, 25), (5, 5, 1)).astype(np.int64)\n       layer = image_preprocessing.RandomZoom((-.5, -.5), (-.5, -.5),\n                                              interpolation='nearest')\n-      output_image = layer.augment_image(input_image)\n+      output_image = layer.augment_image(\n+          input_image, transformation=layer.get_random_transformation())\n       expected_output = np.asarray([\n           [6, 7, 7, 8, 8],\n           [11, 12, 12, 13, 13],\n@@ -1812,7 +1818,8 @@ class RandomHeightTest(test_combinations.TestCase):\n       layer = image_preprocessing.RandomHeight(.4)\n       with tf.compat.v1.test.mock.patch.object(\n           layer._random_generator, 'random_uniform', return_value=mock_factor):\n-        img_out = layer.augment_image(img, transformation=None)\n+        img_out = layer.augment_image(\n+            img, transformation=layer.get_random_transformation(image=img))\n         self.assertEqual(img_out.shape[0], 3)\n \n   @test_utils.run_v2_only\n@@ -1944,7 +1951,8 @@ class RandomWidthTest(test_combinations.TestCase):\n       layer = image_preprocessing.RandomWidth(.4)\n       with tf.compat.v1.test.mock.patch.object(\n           layer._random_generator, 'random_uniform', return_value=mock_factor):\n-        img_out = layer.augment_image(img, transformation=None)\n+        img_out = layer.augment_image(\n+            img, transformation=layer.get_random_transformation(image=img))\n         self.assertEqual(img_out.shape[1], 3)\n \n   @test_utils.run_v2_only\n@@ -2062,10 +2070,10 @@ class RandomAddLayer(image_preprocessing.BaseImageAugmentationLayer):\n     return self._random_generator.random_uniform(\n         [], minval=self.value_range[0], maxval=self.value_range[1])\n \n-  def augment_image(self, image, transformation=None):\n+  def augment_image(self, image, transformation):\n     return image + transformation\n \n-  def augment_label(self, label, transformation=None):\n+  def augment_label(self, label, transformation):\n     return label + transformation\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
