{"custom_id": "keras#9bd7a380de9d7f2fe8eca2b6198936735ba6db95", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 109 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -2,7 +2,7 @@ import collections\n import csv\n \n import numpy as np\n-import tensorflow as tf\n+from tensorflow.io import gfile\n \n from keras_core.api_export import keras_core_export\n from keras_core.callbacks.callback import Callback\n@@ -41,13 +41,13 @@ class CSVLogger(Callback):\n \n     def on_train_begin(self, logs=None):\n         if self.append:\n-            if tf.io.gfile.exists(self.filename):\n-                with tf.io.gfile.GFile(self.filename, \"r\") as f:\n+            if gfile.exists(self.filename):\n+                with gfile.GFile(self.filename, \"r\") as f:\n                     self.append_header = not bool(len(f.readline()))\n             mode = \"a\"\n         else:\n             mode = \"w\"\n-        self.csv_file = tf.io.gfile.GFile(self.filename, mode)\n+        self.csv_file = gfile.GFile(self.filename, mode)\n \n     def on_epoch_end(self, epoch, logs=None):\n         logs = logs or {}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#aaa13fd9c6022544ce27cf3b8efbf22f90129b18", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 309 | Lines Deleted: 39 | Files Changed: 5 | Hunks: 40 | Methods Changed: 21 | Complexity Δ (Sum/Max): 36/34 | Churn Δ: 348 | Churn Cumulative: 1876 | Contributors (this commit): 7 | Commits (past 90d): 80 | Contributors (cumulative): 18 | DMM Complexity: 0.5344827586206896\n\nDIFF:\n@@ -1,6 +1,8 @@\n import json\n import os\n \n+from keras_core.api_export import keras_core_export\n+\n # The type of float to use throughout a session.\n _FLOATX = \"float32\"\n \n@@ -14,6 +16,7 @@ _IMAGE_DATA_FORMAT = \"channels_last\"\n _BACKEND = \"tensorflow\"\n \n \n+@keras_core_export([\"keras_core.config.floatx\", \"keras_core.backend.floatx\"])\n def floatx():\n     \"\"\"Return the default float type, as a string.\n \n@@ -23,32 +26,34 @@ def floatx():\n         String, the current default float type.\n \n     Example:\n-    >>> keras_core.backend.floatx()\n+    >>> keras_core.config.floatx()\n     'float32'\n     \"\"\"\n     return _FLOATX\n \n \n+@keras_core_export(\n+    [\"keras_core.config.set_floatx\", \"keras_core.backend.set_floatx\"]\n+)\n def set_floatx(value):\n-    \"\"\"Set the default float type.\n+    \"\"\"Set the default float dtype.\n \n-    Note: It is not recommended to set this to float16 for training, as this\n-    will likely cause numeric stability issues. Instead, mixed precision, which\n-    is using a mix of float16 and float32, can be used by calling\n-    `keras_core.mixed_precision.set_global_policy('mixed_float16')`. See the\n-    [mixed precision guide](\n-      https://www.tensorflow.org/guide/keras/mixed_precision) for details.\n+    Note: It is not recommended to set this to `\"float16\"` for training,\n+    as this will likely cause numeric stability issues.\n+    Instead, mixed precision, which leverages\n+    a mix of `float16` and `float32`. It can be configured by calling\n+    `keras_core.mixed_precision.set_global_policy('mixed_float16')`.\n \n     Args:\n         value: String; `'float16'`, `'float32'`, or `'float64'`.\n \n     Example:\n-    >>> keras_core.backend.floatx()\n+    >>> keras_core.config.floatx()\n     'float32'\n-    >>> keras_core.backend.set_floatx('float64')\n-    >>> keras_core.backend.floatx()\n+    >>> keras_core.config.set_floatx('float64')\n+    >>> keras_core.config.floatx()\n     'float64'\n-    >>> keras_core.backend.set_floatx('float32')\n+    >>> keras_core.config.set_floatx('float32')\n \n     Raises:\n         ValueError: In case of invalid value.\n@@ -63,6 +68,7 @@ def set_floatx(value):\n     _FLOATX = str(value)\n \n \n+@keras_core_export([\"keras_core.config.epsilon\", \"keras_core.backend.epsilon\"])\n def epsilon():\n     \"\"\"Return the value of the fuzz factor used in numeric expressions.\n \n@@ -70,12 +76,15 @@ def epsilon():\n         A float.\n \n     Example:\n-    >>> keras_core.backend.epsilon()\n+    >>> keras_core.config.epsilon()\n     1e-07\n     \"\"\"\n     return _EPSILON\n \n \n+@keras_core_export(\n+    [\"keras_core.config.set_epsilon\", \"keras_core.backend.set_epsilon\"]\n+)\n def set_epsilon(value):\n     \"\"\"Set the value of the fuzz factor used in numeric expressions.\n \n@@ -83,30 +92,42 @@ def set_epsilon(value):\n         value: float. New value of epsilon.\n \n     Example:\n-    >>> keras_core.backend.epsilon()\n+    >>> keras_core.config.epsilon()\n     1e-07\n-    >>> keras_core.backend.set_epsilon(1e-5)\n-    >>> keras_core.backend.epsilon()\n+    >>> keras_core.config.set_epsilon(1e-5)\n+    >>> keras_core.config.epsilon()\n     1e-05\n-     >>> keras_core.backend.set_epsilon(1e-7)\n+     >>> keras_core.config.set_epsilon(1e-7)\n     \"\"\"\n     global _EPSILON\n     _EPSILON = value\n \n \n+@keras_core_export(\n+    [\n+        \"keras_core.config.image_data_format\",\n+        \"keras_core.backend.image_data_format\",\n+    ]\n+)\n def image_data_format():\n     \"\"\"Return the default image data format convention.\n \n     Returns:\n-        A string, either `'channels_first'` or `'channels_last'`\n+        A string, either `'channels_first'` or `'channels_last'`.\n \n     Example:\n-    >>> keras_core.backend.image_data_format()\n+    >>> keras_core.config.image_data_format()\n     'channels_last'\n     \"\"\"\n     return _IMAGE_DATA_FORMAT\n \n \n+@keras_core_export(\n+    [\n+        \"keras_core.config.set_image_data_format\",\n+        \"keras_core.backend.set_image_data_format\",\n+    ]\n+)\n def set_image_data_format(data_format):\n     \"\"\"Set the value of the image data format convention.\n \n@@ -114,15 +135,12 @@ def set_image_data_format(data_format):\n         data_format: string. `'channels_first'` or `'channels_last'`.\n \n     Example:\n-    >>> keras_core.backend.image_data_format()\n+    >>> keras_core.config.image_data_format()\n     'channels_last'\n-    >>> keras_core.backend.set_image_data_format('channels_first')\n-    >>> keras_core.backend.image_data_format()\n+    >>> keras_core.config.set_image_data_format('channels_first')\n+    >>> keras_core.config.image_data_format()\n     'channels_first'\n-    >>> keras_core.backend.set_image_data_format('channels_last')\n-\n-    Raises:\n-        ValueError: In case of invalid `data_format` value.\n+    >>> keras_core.config.set_image_data_format('channels_last')\n     \"\"\"\n     global _IMAGE_DATA_FORMAT\n     accepted_formats = {\"channels_last\", \"channels_first\"}\n@@ -196,6 +214,7 @@ if \"KERAS_BACKEND\" in os.environ:\n         _BACKEND = _backend\n \n \n+@keras_core_export(\"keras_core.backend.backend\")\n def backend():\n     \"\"\"Publicly accessible method for determining the current backend.\n \n\n@@ -34,6 +34,7 @@ from keras_core.layers import input_spec\n from keras_core.metrics.metric import Metric\n from keras_core.operations.operation import Operation\n from keras_core.utils import summary_utils\n+from keras_core.utils import traceback_utils\n from keras_core.utils.tracking import Tracker\n \n \n@@ -277,6 +278,7 @@ class Layer(Operation):\n     def compute_mask(self, inputs, previous_mask):\n         return previous_mask\n \n+    @traceback_utils.filter_traceback\n     def __call__(self, *args, **kwargs):\n         self._check_super_called()\n \n@@ -414,6 +416,7 @@ class Layer(Operation):\n     def call(self, *args, **kwargs):\n         raise NotImplementedError\n \n+    @traceback_utils.filter_traceback\n     def stateless_call(\n         self,\n         trainable_variables,\n@@ -659,8 +662,8 @@ class Layer(Operation):\n         if not self.built:\n             raise ValueError(\n                 \"You tried to call `count_params` \"\n-                f\"on layer '{self.name}'\"\n-                \", but the layer isn't built. \"\n+                f\"on layer '{self.name}', \"\n+                \"but the layer isn't built. \"\n                 \"You can build it manually via: \"\n                 f\"`layer.build(input_shape)`.\"\n             )\n@@ -715,6 +718,8 @@ class Layer(Operation):\n                                 \"`def build(self, x1_shape, x2_shape)`. \"\n                                 \"Keras will not build this layer automatically \"\n                                 \"since it does not conform to this. \"\n+                                \"Expected the following build keys: \"\n+                                f\"{list(shapes_dict.keys())}\"\n                             )\n             if failure:\n                 raise ValueError(\n\n@@ -8,6 +8,7 @@ from keras_core.backend.common.keras_tensor import any_symbolic_tensors\n from keras_core.operations.node import Node\n from keras_core.saving import serialization_lib\n from keras_core.utils import python_utils\n+from keras_core.utils import traceback_utils\n from keras_core.utils.naming import auto_name\n \n \n@@ -24,7 +25,21 @@ class Operation:\n         self._inbound_nodes = []\n         self._outbound_nodes = []\n \n+    @traceback_utils.filter_traceback\n     def __call__(self, *args, **kwargs):\n+        if traceback_utils.is_traceback_filtering_enabled():\n+            # Wrap self.call to provide helpful info in case of exception\n+            if any_symbolic_tensors(args, kwargs):\n+                call_fn = self.symbolic_call\n+            else:\n+                call_fn = self.call\n+            call_fn = traceback_utils.inject_argument_info_in_traceback(\n+                call_fn,\n+                object_name=(f\"{self.__class__.__name__}.call()\"),\n+            )\n+            return call_fn(*args, **kwargs)\n+\n+        # Plain flow.\n         if any_symbolic_tensors(args, kwargs):\n             return self.symbolic_call(*args, **kwargs)\n         return self.call(*args, **kwargs)\n@@ -50,13 +65,15 @@ class Operation:\n         try:\n             return backend.compute_output_spec(self.call, *args, **kwargs)\n         except Exception as e:\n-            raise RuntimeError(\n+            new_e = RuntimeError(\n                 \"Could not automatically infer the output shape / dtype of \"\n-                f\"operation '{self.name}'. \"\n-                \"Please implement the `compute_output_spec()` method \"\n-                f\"on your object ({self.__class__.__name__}). \"\n-                f\"Error encountered: {e}\"\n+                f\"'{self.name}' (of type {self.__class__.__name__}). \"\n+                f\"Either the `{self.__class__.__name__}.call()` method \"\n+                f\"is incorrect, or you need to implement the \"\n+                f\"`{self.__class__.__name__}.compute_output_spec()` method. \"\n+                f\"Error encountered:\\n\\n{e}\"\n             )\n+            raise new_e.with_traceback(e.__traceback__) from None\n \n     def __new__(cls, *args, **kwargs):\n         \"\"\"We override __new__ to saving serializable constructor arguments.\n\n@@ -6,7 +6,7 @@ from keras_core.api_export import keras_core_export\n from keras_core.backend.common import global_state\n \n \n-@keras_core_export(\"keras_core.utils.enable_interactive_logging\")\n+@keras_core_export(\"keras_core.config.enable_interactive_logging\")\n def enable_interactive_logging():\n     \"\"\"Turn on interactive logging.\n \n@@ -17,7 +17,7 @@ def enable_interactive_logging():\n     global_state.set_global_setting(\"interactive_logging\", True)\n \n \n-@keras_core_export(\"keras_core.utils.disable_interactive_logging\")\n+@keras_core_export(\"keras_core.config.disable_interactive_logging\")\n def disable_interactive_logging():\n     \"\"\"Turn off interactive logging.\n \n@@ -28,16 +28,17 @@ def disable_interactive_logging():\n     global_state.set_global_setting(\"interactive_logging\", False)\n \n \n-@keras_core_export(\"keras_core.utils.is_interactive_logging_enabled\")\n+@keras_core_export(\"keras_core.config.is_interactive_logging_enabled\")\n def is_interactive_logging_enabled():\n     \"\"\"Check if interactive logging is enabled.\n \n     To switch between writing logs to stdout and `absl.logging`, you may use\n-    `keras.utils.enable_interactive_logging()` and\n-    `keras.utils.disable_interactie_logging()`.\n+    `keras.config.enable_interactive_logging()` and\n+    `keras.config.disable_interactie_logging()`.\n \n     Returns:\n-        Boolean (True if interactive logging is enabled and False otherwise).\n+        Boolean, `True` if interactive logging is enabled,\n+        and `False` otherwise.\n     \"\"\"\n     return global_state.get_global_setting(\"interactive_logging\", True)\n \n\n@@ -0,0 +1,228 @@\n+import inspect\n+import os\n+import traceback\n+import types\n+\n+from tensorflow import errors as tf_errors\n+from tensorflow import nest\n+\n+from keras_core import backend\n+from keras_core.api_export import keras_core_export\n+from keras_core.backend.common import global_state\n+\n+_EXCLUDED_PATHS = (\n+    os.path.abspath(os.path.join(__file__, \"..\", \"..\")),\n+    os.path.join(\"tensorflow\", \"python\"),\n+)\n+\n+\n+@keras_core_export(\"keras_core.config.enable_traceback_filtering\")\n+def enable_traceback_filtering():\n+    \"\"\"Turn on traceback filtering.\n+\n+    Raw Keras tracebacks (also known as stack traces)\n+    involve many internal frames, which can be\n+    challenging to read through, while not being actionable for end users.\n+    By default, Keras filters internal frames in most exceptions that it\n+    raises, to keep traceback short, readable, and focused on what's\n+    actionable for you (your own code).\n+\n+    See also `keras_core.config.disable_traceback_filtering()` and\n+    `keras_core.config.is_traceback_filtering_enabled()`.\n+\n+    If you have previously disabled traceback filtering via\n+    `keras_core.config.disable_traceback_filtering()`, you can re-enable it via\n+    `keras_core.config.enable_traceback_filtering()`.\n+    \"\"\"\n+    global_state.set_global_setting(\"traceback_filtering\", True)\n+\n+\n+@keras_core_export(\"keras_core.config.disable_traceback_filtering\")\n+def disable_traceback_filtering():\n+    \"\"\"Turn off traceback filtering.\n+\n+    Raw Keras tracebacks (also known as stack traces)\n+    involve many internal frames, which can be\n+    challenging to read through, while not being actionable for end users.\n+    By default, Keras filters internal frames in most exceptions that it\n+    raises, to keep traceback short, readable, and focused on what's\n+    actionable for you (your own code).\n+\n+    See also `keras_core.config.enable_traceback_filtering()` and\n+    `keras_core.config.is_traceback_filtering_enabled()`.\n+\n+    If you have previously disabled traceback filtering via\n+    `keras_core.config.disable_traceback_filtering()`, you can re-enable it via\n+    `keras_core.config.enable_traceback_filtering()`.\n+    \"\"\"\n+    global_state.set_global_setting(\"traceback_filtering\", False)\n+\n+\n+@keras_core_export(\"keras_core.config.is_traceback_filtering_enabled\")\n+def is_traceback_filtering_enabled():\n+    \"\"\"Check if traceback filtering is enabled.\n+\n+    Raw Keras tracebacks (also known as stack traces)\n+    involve many internal frames, which can be\n+    challenging to read through, while not being actionable for end users.\n+    By default, Keras filters internal frames in most exceptions that it\n+    raises, to keep traceback short, readable, and focused on what's\n+    actionable for you (your own code).\n+\n+    See also `keras_core.config.enable_traceback_filtering()` and\n+    `keras_core.config.disable_traceback_filtering()`.\n+\n+    If you have previously disabled traceback filtering via\n+    `keras_core.config.disable_traceback_filtering()`, you can re-enable it via\n+    `keras_core.config.enable_traceback_filtering()`.\n+\n+    Returns:\n+        Boolean, `True` if traceback filtering is enabled,\n+        and `False` otherwise.\n+    \"\"\"\n+    return global_state.get_global_setting(\"traceback_filtering\", True)\n+\n+\n+def include_frame(fname):\n+    for exclusion in _EXCLUDED_PATHS:\n+        if exclusion in fname:\n+            return False\n+    return True\n+\n+\n+def _process_traceback_frames(tb):\n+    \"\"\"Iterate through traceback frames and return a new, filtered traceback.\"\"\"\n+    last_tb = None\n+    tb_list = list(traceback.walk_tb(tb))\n+    for f, line_no in reversed(tb_list):\n+        if include_frame(f.f_code.co_filename):\n+            last_tb = types.TracebackType(last_tb, f, f.f_lasti, line_no)\n+    if last_tb is None and tb_list:\n+        # If no frames were kept during filtering, create a new traceback\n+        # from the outermost function.\n+        f, line_no = tb_list[-1]\n+        last_tb = types.TracebackType(last_tb, f, f.f_lasti, line_no)\n+    return last_tb\n+\n+\n+def filter_traceback(fn):\n+    \"\"\"Filter out Keras-internal traceback frames in exceptions raised by fn.\"\"\"\n+\n+    def error_handler(*args, **kwargs):\n+        if not is_traceback_filtering_enabled():\n+            return fn(*args, **kwargs)\n+\n+        filtered_tb = None\n+        try:\n+            return fn(*args, **kwargs)\n+        except Exception as e:\n+            filtered_tb = _process_traceback_frames(e.__traceback__)\n+            # To get the full stack trace, call:\n+            # `keras_core.config.disable_traceback_filtering()`\n+            raise e.with_traceback(filtered_tb) from None\n+        finally:\n+            del filtered_tb\n+\n+    return error_handler\n+\n+\n+def inject_argument_info_in_traceback(fn, object_name=None):\n+    \"\"\"Add information about call argument values to an error message.\n+\n+    Arguments:\n+        fn: Function to wrap. Exceptions raised by the this function will be\n+            re-raised with additional information added to the error message,\n+            displaying the values of the different arguments that the function\n+            was called with.\n+        object_name: String, display name of the class/function being called,\n+            e.g. `'layer \"layer_name\" (LayerClass)'`.\n+\n+    Returns:\n+        A wrapped version of `fn`.\n+    \"\"\"\n+\n+    def error_handler(*args, **kwargs):\n+        signature = None\n+        bound_signature = None\n+        try:\n+            return fn(*args, **kwargs)\n+        except Exception as e:\n+            if hasattr(e, \"_keras_call_info_injected\"):\n+                # Only inject info for the innermost failing call\n+                raise e\n+            signature = inspect.signature(fn)\n+            try:\n+                # The first argument is `self`, so filter it out\n+                bound_signature = signature.bind(*args, **kwargs)\n+            except TypeError:\n+                # Likely unbindable arguments\n+                raise e\n+\n+            # Add argument context\n+            arguments_context = []\n+            for arg in list(signature.parameters.values()):\n+                if arg.name in bound_signature.arguments:\n+                    value = nest.map_structure(\n+                        format_argument_value,\n+                        bound_signature.arguments[arg.name],\n+                    )\n+                else:\n+                    value = arg.default\n+                arguments_context.append(f\"  • {arg.name}={value}\")\n+\n+            if arguments_context:\n+                arguments_context = \"\\n\".join(arguments_context)\n+                # Get original error message and append information to it.\n+                if isinstance(e, tf_errors.OpError):\n+                    message = e.message\n+                elif e.args:\n+                    # Canonically, the 1st argument in an exception is the error\n+                    # message.  This works for all built-in Python exceptions.\n+                    message = e.args[0]\n+                else:\n+                    message = \"\"\n+                display_name = f\"{object_name if object_name else fn.__name__}\"\n+                message = (\n+                    f\"Exception encountered when calling {display_name}.\\n\\n\"\n+                    f\"\\x1b[1m{message}\\x1b[0m\\n\\n\"\n+                    f\"Arguments received by {display_name}:\\n\"\n+                    f\"{arguments_context}\"\n+                )\n+\n+                # Reraise exception, with added context\n+                if isinstance(e, tf_errors.OpError):\n+                    new_e = e.__class__(e.node_def, e.op, message, e.error_code)\n+                else:\n+                    try:\n+                        # For standard exceptions such as ValueError, TypeError,\n+                        # etc.\n+                        new_e = e.__class__(message)\n+                    except TypeError:\n+                        # For any custom error that doesn't have a standard\n+                        # signature.\n+                        new_e = RuntimeError(message)\n+                new_e._keras_call_info_injected = True\n+            else:\n+                new_e = e\n+            raise new_e.with_traceback(e.__traceback__) from None\n+        finally:\n+            del signature\n+            del bound_signature\n+\n+    return error_handler\n+\n+\n+def format_argument_value(value):\n+    if backend.is_tensor(value):\n+        # Simplified representation for eager / graph tensors\n+        # to keep messages readable\n+        if backend.backend() == \"tensorflow\":\n+            tensor_cls = \"tf.Tensor\"\n+        elif backend.backend() == \"jax\":\n+            tensor_cls = \"jnp.ndarray\"\n+        elif backend.backend() == \"pytorch\":\n+            tensor_cls = \"torch.Tensor\"\n+        else:\n+            tensor_cls = \"array\"\n+        return f\"{tensor_cls}(shape={value.shape}, dtype={value.dtype.name})\"\n+    return repr(value)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9f94a985bb82e56e108f66f65005c72c2ad255a2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 6 | Churn Cumulative: 429 | Contributors (this commit): 7 | Commits (past 90d): 24 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -7,11 +7,17 @@ import numpy as np\n from tensorflow import nest\n \n from keras_core import operations as ops\n+from keras_core.utils import traceback_utils\n \n \n class TestCase(unittest.TestCase):\n     maxDiff = None\n \n+    def __init__(self, *args, **kwargs):\n+        super().__init__(*args, **kwargs)\n+        if traceback_utils.is_traceback_filtering_enabled():\n+            traceback_utils.disable_traceback_filtering()\n+\n     def get_temp_dir(self):\n         temp_dir = tempfile.mkdtemp()\n         self.addCleanup(lambda: shutil.rmtree(temp_dir))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#414f931a91c2c01693308bda52dc9bbfee53313c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 0 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 0 | Churn Cumulative: 0 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#64932dcf24991c878b8dc645ad5d2a163a38b76a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 469 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -189,12 +189,11 @@ def model_to_dot(\n         show_dtype: whether to display layer dtypes.\n         show_layer_names: whether to display layer names.\n         rankdir: `rankdir` argument passed to PyDot,\n-            a string specifying the format of the plot:\n-            `\"TB\"` creates a vertical plot;\n-            `\"LR\"` creates a horizontal plot.\n+            a string specifying the format of the plot: `\"TB\"`\n+            creates a vertical plot; `\"LR\"` creates a horizontal plot.\n         expand_nested: whether to expand nested Functional models\n             into clusters.\n-        dpi: Dots per inch.\n+        dpi: Image resolution in dots per inch.\n         subgraph: whether to return a `pydot.Cluster` instance.\n         show_layer_activations: Display layer activations (only for layers that\n             have an `activation` property).\n@@ -372,11 +371,11 @@ def plot_model(\n         show_dtype: whether to display layer dtypes.\n         show_layer_names: whether to display layer names.\n         rankdir: `rankdir` argument passed to PyDot,\n-            a string specifying the format of the plot: 'TB' creates a vertical\n-                plot; 'LR' creates a horizontal plot.\n+            a string specifying the format of the plot: `\"TB\"`\n+            creates a vertical plot; `\"LR\"` creates a horizontal plot.\n         expand_nested: whether to expand nested Functional models\n             into clusters.\n-        dpi: Dots per inch.\n+        dpi: Image resolution in dots per inch.\n         show_layer_activations: Display layer activations (only for layers that\n             have an `activation` property).\n         show_trainable: whether to display if a layer is trainable.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c8cc9b272062def40f5d15824cf051371c7bf80c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 0 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 0 | Churn Cumulative: 0 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7a76cea04face8cf64c22bdd5b3c958cab3441aa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 771 | Contributors (this commit): 1 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: 0.5\n\nDIFF:\n@@ -68,6 +68,7 @@ def plot_functional_model():\n     x = keras_core.layers.Dense(4, activation=\"relu\")(x)\n     x = keras_core.layers.Dense(4, activation=\"relu\")(x)\n     x += residual\n+    residual = x\n     x = keras_core.layers.Dense(4, activation=\"relu\")(x)\n     x = keras_core.layers.Dense(4, activation=\"relu\")(x)\n     x = keras_core.layers.Dense(4, activation=\"relu\")(x)\n\n@@ -232,6 +232,7 @@ def model_to_dot(\n         dot.set(\"rankdir\", rankdir)\n         dot.set(\"concentrate\", True)\n         dot.set(\"dpi\", dpi)\n+        dot.set(\"splines\", \"ortho\")\n         dot.set_node_defaults(shape=\"record\")\n \n     if kwargs.pop(\"layer_range\", None) is not None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#08a99a75666d22f7df616fe89f9ac1e9750d6b9a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 472 | Contributors (this commit): 1 | Commits (past 90d): 4 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -121,7 +121,7 @@ def make_layer_label(layer, **kwargs):\n     if show_dtype:\n         dtype = None\n         try:\n-            shape = layer.output.dtype\n+            dtype = layer.output.dtype\n         except ValueError:\n             pass\n         cols.append(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f64f5ad8e3005ea81ed81ca72ed011c8fc852643", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 474 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -58,9 +58,7 @@ def get_layer_activation_name(layer):\n \n \n def make_layer_label(layer, **kwargs):\n-    layer_name = layer.name\n     class_name = layer.__class__.__name__\n-    label = class_name\n \n     show_layer_names = kwargs.pop(\"show_layer_names\")\n     show_layer_activations = kwargs.pop(\"show_layer_activations\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d909858268f7bd179652f408f9fea70200f8faf1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 65 | Lines Deleted: 60 | Files Changed: 4 | Hunks: 11 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/11 | Churn Δ: 125 | Churn Cumulative: 9187 | Contributors (this commit): 6 | Commits (past 90d): 52 | Contributors (cumulative): 12 | DMM Complexity: 0.3\n\nDIFF:\n@@ -1,7 +1,6 @@\n-import math\n-\n from keras_core import operations as ops\n from keras_core.layers.layer import Layer\n+from keras_core.operations import operation_utils\n \n \n class Reshape(Layer):\n@@ -44,65 +43,13 @@ class Reshape(Layer):\n         super().__init__(name=name, dtype=dtype)\n         self.target_shape = tuple(target_shape)\n \n-    def _fix_unknown_dimension(self, input_shape, output_shape):\n-        \"\"\"Find and replace a missing dimension in an output shape.\n-\n-        Args:\n-            input_shape: Shape of tensor being reshaped as a tuple of ints.\n-            output_shape: Desired shape of the tensor as a tuple of ints. It\n-                contains at most a single `-1` which indicates a dimension that\n-                should be derived from the input shape.\n-\n-        Returns:\n-            The new output shape as a tuple of ints with a -1 replaced with its\n-            computed value.\n-\n-        Raises:\n-            ValueError: If the total tensor size of the output_shape is\n-                different than the input_shape, or more than one unknown\n-                dimension is specified.\n-        \"\"\"\n-        msg = (\n-            \"total size of new tensor must be unchanged, \"\n-            f\"input_shape={input_shape},output_shape={output_shape}\"\n-        )\n-\n-        known_output_size, unknown_dim_index = 1, None\n-        for index, dim in enumerate(output_shape):\n-            if dim == -1:\n-                if unknown_dim_index is None:\n-                    unknown_dim_index = index\n-                else:\n-                    raise ValueError(\n-                        \"There must be at most one unknown dimension in \"\n-                        f\"output_shape. Received: output_shape={output_shape}.\"\n-                    )\n-            else:\n-                known_output_size *= dim\n-\n-        input_size = math.prod(input_shape)\n-        if unknown_dim_index is not None:\n-            if known_output_size == 0 or input_size % known_output_size != 0:\n-                raise ValueError(msg)\n-            result = list(output_shape)\n-            result[unknown_dim_index] = input_size // known_output_size\n-            return tuple(result)\n-        elif input_size != known_output_size:\n-            raise ValueError(msg)\n-        return output_shape\n-\n     def compute_output_shape(self, input_shape):\n-        output_shape = (input_shape[0],)\n-        if None in input_shape[1:]:\n-            # input shape (partially) unknown? replace -1's with None's\n-            output_shape += tuple(\n-                s if s != -1 else None for s in self.target_shape\n+        return (\n+            input_shape[0],\n+            *operation_utils.compute_reshape_output_shape(\n+                input_shape[1:], self.target_shape, \"target_shape\"\n+            ),\n         )\n-        else:\n-            output_shape += self._fix_unknown_dimension(\n-                input_shape[1:], self.target_shape\n-            )\n-        return output_shape\n \n     def call(self, inputs):\n         return ops.reshape(inputs, (inputs.shape[0],) + self.target_shape)\n\n@@ -138,6 +138,7 @@ import numpy as np\n from keras_core import backend\n from keras_core.backend import KerasTensor\n from keras_core.backend import any_symbolic_tensors\n+from keras_core.operations import operation_utils\n from keras_core.operations.operation import Operation\n \n \n@@ -2346,7 +2347,10 @@ class Reshape(Operation):\n         return backend.numpy.reshape(x, self.new_shape)\n \n     def compute_output_spec(self, x):\n-        return KerasTensor(self.new_shape, dtype=x.dtype)\n+        output_shape = operation_utils.compute_reshape_output_shape(\n+            x.shape, self.new_shape, \"new_shape\"\n+        )\n+        return KerasTensor(output_shape, dtype=x.dtype)\n \n \n def reshape(x, new_shape):\n\n@@ -1016,6 +1016,7 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n     def test_reshape(self):\n         x = KerasTensor([None, 3])\n         self.assertEqual(knp.reshape(x, (3, 2)).shape, (3, 2))\n+        self.assertEqual(knp.reshape(x, (3, -1)).shape, (3, None))\n \n     def test_roll(self):\n         x = KerasTensor([None, 3])\n@@ -1444,6 +1445,9 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n     def test_reshape(self):\n         x = KerasTensor([2, 3])\n         self.assertEqual(knp.reshape(x, (3, 2)).shape, (3, 2))\n+        self.assertEqual(knp.reshape(x, (3, -1)).shape, (3, 2))\n+        self.assertEqual(knp.reshape(x, (6,)).shape, (6,))\n+        self.assertEqual(knp.reshape(x, (-1,)).shape, (6,))\n \n     def test_roll(self):\n         x = KerasTensor([2, 3])\n\n@@ -1,3 +1,5 @@\n+import math\n+\n import numpy as np\n \n \n@@ -111,3 +113,51 @@ def compute_conv_output_shape(\n     else:\n         output_shape = (input_shape[0], kernel_shape[-1]) + output_spatial_shape\n     return output_shape\n+\n+\n+def compute_reshape_output_shape(input_shape, new_shape, new_shape_arg_name):\n+    \"\"\"Converts `-1` in `new_shape` to either an actual dimension or `None`.\n+\n+    This utility does not special case the 0th dimension (batch size).\n+    \"\"\"\n+    unknown_dim_count = new_shape.count(-1)\n+    if unknown_dim_count > 1:\n+        raise ValueError(\n+            \"There must be at most one unknown dimension (-1) in \"\n+            f\"{new_shape_arg_name}. Received: {new_shape_arg_name}={new_shape}.\"\n+        )\n+\n+    # If there is a None in input_shape, we can't infer what the -1 is\n+    if None in input_shape:\n+        return tuple(dim if dim != -1 else None for dim in new_shape)\n+\n+    input_size = math.prod(input_shape)\n+    # If the new_shape fully defined, return it\n+    if unknown_dim_count == 0:\n+        if input_size != math.prod(new_shape):\n+            raise ValueError(\n+                \"The total size of the tensor must be unchanged. Received: \"\n+                f\"input_shape={input_shape}, {new_shape_arg_name}={new_shape}\"\n+            )\n+        return new_shape\n+\n+    # We have one -1 in new_shape, compute the actual value\n+    known_output_size = 1\n+    unknown_dim_index = None\n+    for index, dim in enumerate(new_shape):\n+        if dim == -1:\n+            unknown_dim_index = index\n+        else:\n+            known_output_size *= dim\n+\n+    if known_output_size == 0 or input_size % known_output_size != 0:\n+        raise ValueError(\n+            \"The total size of the tensor must be unchanged, however, the \"\n+            \"input size cannot by divided by the specified dimensions in \"\n+            f\"{new_shape_arg_name}. Received: input_shape={input_shape}, \"\n+            f\"{new_shape_arg_name}={new_shape}\"\n+        )\n+\n+    output_shape = list(new_shape)\n+    output_shape[unknown_dim_index] = input_size // known_output_size\n+    return tuple(output_shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c99de04feb3f914753e8c3ba186b8659d226df6b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 62 | Lines Deleted: 67 | Files Changed: 5 | Hunks: 11 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/11 | Churn Δ: 129 | Churn Cumulative: 9410 | Contributors (this commit): 6 | Commits (past 90d): 58 | Contributors (cumulative): 15 | DMM Complexity: 0.7\n\nDIFF:\n@@ -1,6 +1,7 @@\n+import math\n+\n from keras_core import operations as ops\n from keras_core.layers.layer import Layer\n-from keras_core.operations import operation_utils\n \n \n class Reshape(Layer):\n@@ -43,14 +44,66 @@ class Reshape(Layer):\n         super().__init__(name=name, dtype=dtype)\n         self.target_shape = tuple(target_shape)\n \n-    def compute_output_shape(self, input_shape):\n-        return (\n-            input_shape[0],\n-            *operation_utils.compute_reshape_output_shape(\n-                input_shape[1:], self.target_shape, \"target_shape\"\n-            ),\n+    def _fix_unknown_dimension(self, input_shape, output_shape):\n+        \"\"\"Find and replace a missing dimension in an output shape.\n+\n+        Args:\n+            input_shape: Shape of tensor being reshaped as a tuple of ints.\n+            output_shape: Desired shape of the tensor as a tuple of ints. It\n+                contains at most a single `-1` which indicates a dimension that\n+                should be derived from the input shape.\n+\n+        Returns:\n+            The new output shape as a tuple of ints with a -1 replaced with its\n+            computed value.\n+\n+        Raises:\n+            ValueError: If the total tensor size of the output_shape is\n+                different than the input_shape, or more than one unknown\n+                dimension is specified.\n+        \"\"\"\n+        msg = (\n+            \"total size of new tensor must be unchanged, \"\n+            f\"input_shape={input_shape},output_shape={output_shape}\"\n         )\n \n+        known_output_size, unknown_dim_index = 1, None\n+        for index, dim in enumerate(output_shape):\n+            if dim == -1:\n+                if unknown_dim_index is None:\n+                    unknown_dim_index = index\n+                else:\n+                    raise ValueError(\n+                        \"There must be at most one unknown dimension in \"\n+                        f\"output_shape. Received: output_shape={output_shape}.\"\n+                    )\n+            else:\n+                known_output_size *= dim\n+\n+        input_size = math.prod(input_shape)\n+        if unknown_dim_index is not None:\n+            if known_output_size == 0 or input_size % known_output_size != 0:\n+                raise ValueError(msg)\n+            result = list(output_shape)\n+            result[unknown_dim_index] = input_size // known_output_size\n+            return tuple(result)\n+        elif input_size != known_output_size:\n+            raise ValueError(msg)\n+        return output_shape\n+\n+    def compute_output_shape(self, input_shape):\n+        output_shape = (input_shape[0],)\n+        if None in input_shape[1:]:\n+            # input shape (partially) unknown? replace -1's with None's\n+            output_shape += tuple(\n+                s if s != -1 else None for s in self.target_shape\n+            )\n+        else:\n+            output_shape += self._fix_unknown_dimension(\n+                input_shape[1:], self.target_shape\n+            )\n+        return output_shape\n+\n     def call(self, inputs):\n         return ops.reshape(inputs, (inputs.shape[0],) + self.target_shape)\n \n\n@@ -138,7 +138,6 @@ import numpy as np\n from keras_core import backend\n from keras_core.backend import KerasTensor\n from keras_core.backend import any_symbolic_tensors\n-from keras_core.operations import operation_utils\n from keras_core.operations.operation import Operation\n \n \n@@ -2347,10 +2346,7 @@ class Reshape(Operation):\n         return backend.numpy.reshape(x, self.new_shape)\n \n     def compute_output_spec(self, x):\n-        output_shape = operation_utils.compute_reshape_output_shape(\n-            x.shape, self.new_shape, \"new_shape\"\n-        )\n-        return KerasTensor(output_shape, dtype=x.dtype)\n+        return KerasTensor(self.new_shape, dtype=x.dtype)\n \n \n def reshape(x, new_shape):\n\n@@ -1016,7 +1016,6 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n     def test_reshape(self):\n         x = KerasTensor([None, 3])\n         self.assertEqual(knp.reshape(x, (3, 2)).shape, (3, 2))\n-        self.assertEqual(knp.reshape(x, (3, -1)).shape, (3, None))\n \n     def test_roll(self):\n         x = KerasTensor([None, 3])\n@@ -1445,9 +1444,6 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n     def test_reshape(self):\n         x = KerasTensor([2, 3])\n         self.assertEqual(knp.reshape(x, (3, 2)).shape, (3, 2))\n-        self.assertEqual(knp.reshape(x, (3, -1)).shape, (3, 2))\n-        self.assertEqual(knp.reshape(x, (6,)).shape, (6,))\n-        self.assertEqual(knp.reshape(x, (-1,)).shape, (6,))\n \n     def test_roll(self):\n         x = KerasTensor([2, 3])\n\n@@ -1,5 +1,3 @@\n-import math\n-\n import numpy as np\n \n \n@@ -113,51 +111,3 @@ def compute_conv_output_shape(\n     else:\n         output_shape = (input_shape[0], kernel_shape[-1]) + output_spatial_shape\n     return output_shape\n-\n-\n-def compute_reshape_output_shape(input_shape, new_shape, new_shape_arg_name):\n-    \"\"\"Converts `-1` in `new_shape` to either an actual dimension or `None`.\n-\n-    This utility does not special case the 0th dimension (batch size).\n-    \"\"\"\n-    unknown_dim_count = new_shape.count(-1)\n-    if unknown_dim_count > 1:\n-        raise ValueError(\n-            \"There must be at most one unknown dimension (-1) in \"\n-            f\"{new_shape_arg_name}. Received: {new_shape_arg_name}={new_shape}.\"\n-        )\n-\n-    # If there is a None in input_shape, we can't infer what the -1 is\n-    if None in input_shape:\n-        return tuple(dim if dim != -1 else None for dim in new_shape)\n-\n-    input_size = math.prod(input_shape)\n-    # If the new_shape fully defined, return it\n-    if unknown_dim_count == 0:\n-        if input_size != math.prod(new_shape):\n-            raise ValueError(\n-                \"The total size of the tensor must be unchanged. Received: \"\n-                f\"input_shape={input_shape}, {new_shape_arg_name}={new_shape}\"\n-            )\n-        return new_shape\n-\n-    # We have one -1 in new_shape, compute the actual value\n-    known_output_size = 1\n-    unknown_dim_index = None\n-    for index, dim in enumerate(new_shape):\n-        if dim == -1:\n-            unknown_dim_index = index\n-        else:\n-            known_output_size *= dim\n-\n-    if known_output_size == 0 or input_size % known_output_size != 0:\n-        raise ValueError(\n-            \"The total size of the tensor must be unchanged, however, the \"\n-            \"input size cannot by divided by the specified dimensions in \"\n-            f\"{new_shape_arg_name}. Received: input_shape={input_shape}, \"\n-            f\"{new_shape_arg_name}={new_shape}\"\n-        )\n-\n-    output_shape = list(new_shape)\n-    output_shape[unknown_dim_index] = input_size // known_output_size\n-    return tuple(output_shape)\n\n@@ -32,7 +32,7 @@ def get_functional_model(keras):\n         moving_mean_initializer=\"uniform\", gamma_initializer=\"uniform\"\n     )(x)\n     x = keras.layers.Dense(4, activation=\"relu\")(x)\n-    x += residual\n+    x = keras.layers.add([x, residual])\n     outputs = keras.layers.Dense(5, activation=\"softmax\")(x)\n     return keras.Model(inputs, outputs)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6afc9debeced598878d4edb570045c0d42e37fa2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 240 | Lines Deleted: 62 | Files Changed: 9 | Hunks: 16 | Methods Changed: 16 | Complexity Δ (Sum/Max): 15/11 | Churn Δ: 302 | Churn Cumulative: 10145 | Contributors (this commit): 8 | Commits (past 90d): 72 | Contributors (cumulative): 26 | DMM Complexity: 0.751937984496124\n\nDIFF:\n@@ -86,7 +86,9 @@ class ReLU(ops.Operation):\n         clip_max = max_value is not None\n         if threshold != 0:\n             # computes x for x > threshold else 0\n-            x = x * backend.cast(backend.greater(x, threshold), dtype=x.dtype)\n+            x = x * backend.cast(\n+                backend.numpy.greater(x, threshold), dtype=x.dtype\n+            )\n         elif max_value == 6:\n             # if no threshold, then can use nn.relu6 native op for performance\n             x = backend.nn.relu6(x)\n\n@@ -1 +1,2 @@\n from keras_core.layers.activations.elu import ELU\n+from keras_core.layers.activations.relu import ReLU\n\n@@ -0,0 +1,82 @@\n+from keras_core import activations\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.layer import Layer\n+\n+\n+@keras_core_export(\"keras_core.layers.ReLU\")\n+class ReLU(Layer):\n+    \"\"\"Rectified Linear Unit activation function layer.\n+\n+    Formula:\n+    ``` python\n+    f(x) = max(x,0)\n+    f(x) = max_value if x >= max_value\n+    f(x) = x if threshold <= x < max_value\n+    f(x) = negative_slope * (x - threshold) otherwise\n+    ```\n+\n+    Example:\n+    ``` python\n+    relu_layer = relu.ReLU(max_value=10, negative_slope=0.5, threshold=0)\n+    input = np.array([-10, -5, 0.0, 5, 10])\n+    result = relu_layer(input)\n+    # result = [-5. , -2.5,  0. ,  5. , 10.]\n+    ```\n+\n+    Args:\n+        max_value: Float >= 0. Maximum activation value. None means unlimited.\n+            Defaults to `None`.\n+        negative_slope: Float >= 0. Negative slope coefficient.\n+            Defaults to 0.0.\n+        threshold: Float >= 0. Threshold value for thresholded activation.\n+            Defaults to 0.0.\n+        **kwargs: Base layer keyword arguments, such as\n+            `name` and `dtype`.\n+    \"\"\"\n+\n+    def __init__(\n+        self, max_value=None, negative_slope=0.0, threshold=0.0, **kwargs\n+    ):\n+        super().__init__(**kwargs)\n+        if max_value is not None and max_value < 0.0:\n+            raise ValueError(\n+                \"max_value of a ReLU layer cannot be a negative \"\n+                f\"value. Received max_value: {max_value}\"\n+            )\n+        if negative_slope is None or negative_slope < 0.0:\n+            raise ValueError(\n+                \"negative_slope of a ReLU layer cannot be a negative \"\n+                f\"value. Received negative_slope: {negative_slope}\"\n+            )\n+        if threshold is None or threshold < 0.0:\n+            raise ValueError(\n+                \"threshold of a ReLU layer cannot be a negative \"\n+                f\"value. Received threshold: {threshold}\"\n+            )\n+\n+        self.supports_masking = True\n+        self.max_value = max_value\n+        self.negative_slope = negative_slope\n+        self.threshold = threshold\n+\n+    def call(self, inputs):\n+        return activations.relu(\n+            inputs,\n+            negative_slope=self.negative_slope,\n+            max_value=self.max_value,\n+            threshold=self.threshold,\n+        )\n+\n+    def get_config(self):\n+        config = super().get_config()\n+        config.update(\n+            {\n+                \"max_value\": self.max_value,\n+                \"negative_slope\": self.negative_slope,\n+                \"threshold\": self.threshold,\n+            }\n+        )\n+        return config\n+\n+    def compute_output_shape(self, input_shape):\n+        return input_shape\n\n@@ -0,0 +1,88 @@\n+import numpy as np\n+\n+from keras_core import testing\n+from keras_core.layers.activations import relu\n+\n+\n+class ReLUTest(testing.TestCase):\n+    def test_relu(self):\n+        self.run_layer_test(\n+            relu.ReLU,\n+            init_kwargs={\n+                \"max_value\": 10,\n+                \"negative_slope\": 1,\n+                \"threshold\": 0.5,\n+            },\n+            input_shape=(2, 3, 4),\n+            supports_masking=True,\n+        )\n+\n+    def test_normal_relu_correctness(self):\n+        relu_layer = relu.ReLU(max_value=10, negative_slope=0.0, threshold=0)\n+        input = np.array([-10, -5, 0.0, 5, 10])\n+        expected_output = np.array([0.0, 0.0, 0.0, 5.0, 10.0])\n+        result = relu_layer(input)\n+        self.assertAllClose(result, expected_output)\n+\n+    def test_leaky_relu_correctness(self):\n+        relu_layer = relu.ReLU(max_value=10, negative_slope=0.5, threshold=0)\n+        input = np.array([-10, -5, 0.0, 5, 10])\n+        expected_output = np.array([-5.0, -2.5, 0.0, 5.0, 10.0])\n+        result = relu_layer(input)\n+        self.assertAllClose(result, expected_output)\n+\n+    def test_threshold_relu_correctness(self):\n+        relu_layer = relu.ReLU(max_value=8, negative_slope=0.0, threshold=5)\n+        input = np.array([6.0, 7.0, 0.0, 5, 10])\n+        expected_output = np.array([6.0, 7.0, 0.0, 0.0, 8.0])\n+        result = relu_layer(input)\n+        self.assertAllClose(result, expected_output)\n+\n+    def test_invalid_usage(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"max_value of a ReLU layer cannot be a negative \"\n+            \"value. Received max_value: -10\",\n+        ):\n+            self.run_layer_test(\n+                relu.ReLU,\n+                init_kwargs={\n+                    \"max_value\": -10,\n+                    \"negative_slope\": 1,\n+                    \"threshold\": 0.5,\n+                },\n+                input_shape=(2, 3, 4),\n+                supports_masking=True,\n+            )\n+\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"negative_slope of a ReLU layer cannot be a negative \"\n+            \"value. Received negative_slope: -10\",\n+        ):\n+            self.run_layer_test(\n+                relu.ReLU,\n+                init_kwargs={\n+                    \"max_value\": 10,\n+                    \"negative_slope\": -10,\n+                    \"threshold\": 0.5,\n+                },\n+                input_shape=(2, 3, 4),\n+                supports_masking=True,\n+            )\n+\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"threshold of a ReLU layer cannot be a negative \"\n+            \"value. Received threshold: -10\",\n+        ):\n+            self.run_layer_test(\n+                relu.ReLU,\n+                init_kwargs={\n+                    \"max_value\": 10,\n+                    \"negative_slope\": 1,\n+                    \"threshold\": -10,\n+                },\n+                input_shape=(2, 3, 4),\n+                supports_masking=True,\n+            )\n\n@@ -1,7 +1,6 @@\n-import math\n-\n from keras_core import operations as ops\n from keras_core.layers.layer import Layer\n+from keras_core.operations import operation_utils\n \n \n class Reshape(Layer):\n@@ -44,65 +43,13 @@ class Reshape(Layer):\n         super().__init__(name=name, dtype=dtype)\n         self.target_shape = tuple(target_shape)\n \n-    def _fix_unknown_dimension(self, input_shape, output_shape):\n-        \"\"\"Find and replace a missing dimension in an output shape.\n-\n-        Args:\n-            input_shape: Shape of tensor being reshaped as a tuple of ints.\n-            output_shape: Desired shape of the tensor as a tuple of ints. It\n-                contains at most a single `-1` which indicates a dimension that\n-                should be derived from the input shape.\n-\n-        Returns:\n-            The new output shape as a tuple of ints with a -1 replaced with its\n-            computed value.\n-\n-        Raises:\n-            ValueError: If the total tensor size of the output_shape is\n-                different than the input_shape, or more than one unknown\n-                dimension is specified.\n-        \"\"\"\n-        msg = (\n-            \"total size of new tensor must be unchanged, \"\n-            f\"input_shape={input_shape},output_shape={output_shape}\"\n-        )\n-\n-        known_output_size, unknown_dim_index = 1, None\n-        for index, dim in enumerate(output_shape):\n-            if dim == -1:\n-                if unknown_dim_index is None:\n-                    unknown_dim_index = index\n-                else:\n-                    raise ValueError(\n-                        \"There must be at most one unknown dimension in \"\n-                        f\"output_shape. Received: output_shape={output_shape}.\"\n-                    )\n-            else:\n-                known_output_size *= dim\n-\n-        input_size = math.prod(input_shape)\n-        if unknown_dim_index is not None:\n-            if known_output_size == 0 or input_size % known_output_size != 0:\n-                raise ValueError(msg)\n-            result = list(output_shape)\n-            result[unknown_dim_index] = input_size // known_output_size\n-            return tuple(result)\n-        elif input_size != known_output_size:\n-            raise ValueError(msg)\n-        return output_shape\n-\n     def compute_output_shape(self, input_shape):\n-        output_shape = (input_shape[0],)\n-        if None in input_shape[1:]:\n-            # input shape (partially) unknown? replace -1's with None's\n-            output_shape += tuple(\n-                s if s != -1 else None for s in self.target_shape\n+        return (\n+            input_shape[0],\n+            *operation_utils.compute_reshape_output_shape(\n+                input_shape[1:], self.target_shape, \"target_shape\"\n+            ),\n         )\n-        else:\n-            output_shape += self._fix_unknown_dimension(\n-                input_shape[1:], self.target_shape\n-            )\n-        return output_shape\n \n     def call(self, inputs):\n         return ops.reshape(inputs, (inputs.shape[0],) + self.target_shape)\n\n@@ -138,6 +138,7 @@ import numpy as np\n from keras_core import backend\n from keras_core.backend import KerasTensor\n from keras_core.backend import any_symbolic_tensors\n+from keras_core.operations import operation_utils\n from keras_core.operations.operation import Operation\n \n \n@@ -2346,7 +2347,10 @@ class Reshape(Operation):\n         return backend.numpy.reshape(x, self.new_shape)\n \n     def compute_output_spec(self, x):\n-        return KerasTensor(self.new_shape, dtype=x.dtype)\n+        output_shape = operation_utils.compute_reshape_output_shape(\n+            x.shape, self.new_shape, \"new_shape\"\n+        )\n+        return KerasTensor(output_shape, dtype=x.dtype)\n \n \n def reshape(x, new_shape):\n\n@@ -1016,6 +1016,7 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n     def test_reshape(self):\n         x = KerasTensor([None, 3])\n         self.assertEqual(knp.reshape(x, (3, 2)).shape, (3, 2))\n+        self.assertEqual(knp.reshape(x, (3, -1)).shape, (3, None))\n \n     def test_roll(self):\n         x = KerasTensor([None, 3])\n@@ -1444,6 +1445,9 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n     def test_reshape(self):\n         x = KerasTensor([2, 3])\n         self.assertEqual(knp.reshape(x, (3, 2)).shape, (3, 2))\n+        self.assertEqual(knp.reshape(x, (3, -1)).shape, (3, 2))\n+        self.assertEqual(knp.reshape(x, (6,)).shape, (6,))\n+        self.assertEqual(knp.reshape(x, (-1,)).shape, (6,))\n \n     def test_roll(self):\n         x = KerasTensor([2, 3])\n\n@@ -1,3 +1,5 @@\n+import math\n+\n import numpy as np\n \n \n@@ -111,3 +113,51 @@ def compute_conv_output_shape(\n     else:\n         output_shape = (input_shape[0], kernel_shape[-1]) + output_spatial_shape\n     return output_shape\n+\n+\n+def compute_reshape_output_shape(input_shape, new_shape, new_shape_arg_name):\n+    \"\"\"Converts `-1` in `new_shape` to either an actual dimension or `None`.\n+\n+    This utility does not special case the 0th dimension (batch size).\n+    \"\"\"\n+    unknown_dim_count = new_shape.count(-1)\n+    if unknown_dim_count > 1:\n+        raise ValueError(\n+            \"There must be at most one unknown dimension (-1) in \"\n+            f\"{new_shape_arg_name}. Received: {new_shape_arg_name}={new_shape}.\"\n+        )\n+\n+    # If there is a None in input_shape, we can't infer what the -1 is\n+    if None in input_shape:\n+        return tuple(dim if dim != -1 else None for dim in new_shape)\n+\n+    input_size = math.prod(input_shape)\n+    # If the new_shape fully defined, return it\n+    if unknown_dim_count == 0:\n+        if input_size != math.prod(new_shape):\n+            raise ValueError(\n+                \"The total size of the tensor must be unchanged. Received: \"\n+                f\"input_shape={input_shape}, {new_shape_arg_name}={new_shape}\"\n+            )\n+        return new_shape\n+\n+    # We have one -1 in new_shape, compute the actual value\n+    known_output_size = 1\n+    unknown_dim_index = None\n+    for index, dim in enumerate(new_shape):\n+        if dim == -1:\n+            unknown_dim_index = index\n+        else:\n+            known_output_size *= dim\n+\n+    if known_output_size == 0 or input_size % known_output_size != 0:\n+        raise ValueError(\n+            \"The total size of the tensor must be unchanged, however, the \"\n+            \"input size cannot by divided by the specified dimensions in \"\n+            f\"{new_shape_arg_name}. Received: input_shape={input_shape}, \"\n+            f\"{new_shape_arg_name}={new_shape}\"\n+        )\n+\n+    output_shape = list(new_shape)\n+    output_shape[unknown_dim_index] = input_size // known_output_size\n+    return tuple(output_shape)\n\n@@ -32,7 +32,7 @@ def get_functional_model(keras):\n         moving_mean_initializer=\"uniform\", gamma_initializer=\"uniform\"\n     )(x)\n     x = keras.layers.Dense(4, activation=\"relu\")(x)\n-    x = keras.layers.add([x, residual])\n+    x += residual\n     outputs = keras.layers.Dense(5, activation=\"softmax\")(x)\n     return keras.Model(inputs, outputs)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
