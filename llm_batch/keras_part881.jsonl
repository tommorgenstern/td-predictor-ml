{"custom_id": "keras#3e52ce9cd7ca212e3ba3ce4ec25d77b2e2ad4526", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 355 | Lines Deleted: 0 | Files Changed: 5 | Hunks: 5 | Methods Changed: 18 | Complexity Δ (Sum/Max): 43/35 | Churn Δ: 355 | Churn Cumulative: 1244 | Contributors (this commit): 7 | Commits (past 90d): 53 | Contributors (cumulative): 23 | DMM Complexity: 0.6313725490196078\n\nDIFF:\n@@ -178,6 +178,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_erasing import (\n from keras.src.layers.preprocessing.image_preprocessing.random_flip import (\n     RandomFlip,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_gaussian_blur import (\n+    RandomGaussianBlur,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_grayscale import (\n     RandomGrayscale,\n )\n\n@@ -178,6 +178,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_erasing import (\n from keras.src.layers.preprocessing.image_preprocessing.random_flip import (\n     RandomFlip,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_gaussian_blur import (\n+    RandomGaussianBlur,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_grayscale import (\n     RandomGrayscale,\n )\n\n@@ -122,6 +122,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_erasing import (\n from keras.src.layers.preprocessing.image_preprocessing.random_flip import (\n     RandomFlip,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_gaussian_blur import (\n+    RandomGaussianBlur,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_grayscale import (\n     RandomGrayscale,\n )\n\n@@ -0,0 +1,255 @@\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n+    BaseImagePreprocessingLayer,\n+)\n+from keras.src.random import SeedGenerator\n+\n+\n+@keras_export(\"keras.layers.RandomGaussianBlur\")\n+class RandomGaussianBlur(BaseImagePreprocessingLayer):\n+    \"\"\"Applies random Gaussian blur to images for data augmentation.\n+\n+    This layer performs a Gaussian blur operation on input images with a\n+    randomly selected degree of blurring, controlled by the `factor` and\n+    `sigma` arguments.\n+\n+    Args:\n+        factor: A single float or a tuple of two floats.\n+            `factor` controls the extent to which the image hue is impacted.\n+            `factor=0.0` makes this layer perform a no-op operation,\n+            while a value of `1.0` performs the most aggressive\n+            blurring available. If a tuple is used, a `factor` is\n+            sampled between the two values for every image augmented. If a\n+            single float is used, a value between `0.0` and the passed float is\n+            sampled. Default is 1.0.\n+        kernel_size: Integer. Size of the Gaussian kernel used for blurring.\n+            Must be an odd integer. Default is 3.\n+        sigma: Float or tuple of two floats. Standard deviation of the Gaussian\n+            kernel. Controls the intensity of the blur. If a tuple is provided,\n+            a value is sampled between the two for each image. Default is 1.0.\n+        value_range: the range of values the incoming images will have.\n+            Represented as a two-number tuple written `[low, high]`. This is\n+            typically either `[0, 1]` or `[0, 255]` depending on how your\n+            preprocessing pipeline is set up.\n+        seed: Integer. Used to create a random seed.\n+    \"\"\"\n+\n+    _USE_BASE_FACTOR = False\n+    _FACTOR_BOUNDS = (0, 1)\n+\n+    def __init__(\n+        self,\n+        factor=1.0,\n+        kernel_size=3,\n+        sigma=1.0,\n+        value_range=(0, 255),\n+        data_format=None,\n+        seed=None,\n+        **kwargs,\n+    ):\n+        super().__init__(data_format=data_format, **kwargs)\n+        self._set_factor(factor)\n+        self.kernel_size = self._set_kernel_size(kernel_size, \"kernel_size\")\n+        self.sigma = self._set_factor_by_name(sigma, \"sigma\")\n+        self.value_range = value_range\n+        self.seed = seed\n+        self.generator = SeedGenerator(seed)\n+\n+    def _set_kernel_size(self, factor, name):\n+        error_msg = f\"{name} must be an odd number. Received: {name}={factor}\"\n+        if isinstance(factor, (tuple, list)):\n+            if len(factor) != 2:\n+                error_msg = (\n+                    f\"The `{name}` argument should be a number \"\n+                    \"(or a list of two numbers) \"\n+                    f\"Received: {name}={factor}\"\n+                )\n+                raise ValueError(error_msg)\n+            if (factor[0] % 2 == 0) or (factor[1] % 2 == 0):\n+                raise ValueError(error_msg)\n+            lower, upper = factor\n+        elif isinstance(factor, (int, float)):\n+            if factor % 2 == 0:\n+                raise ValueError(error_msg)\n+            lower, upper = factor, factor\n+        else:\n+            raise ValueError(error_msg)\n+\n+        return lower, upper\n+\n+    def _set_factor_by_name(self, factor, name):\n+        error_msg = (\n+            f\"The `{name}` argument should be a number \"\n+            \"(or a list of two numbers) \"\n+            \"in the range \"\n+            f\"[{self._FACTOR_BOUNDS[0]}, {self._FACTOR_BOUNDS[1]}]. \"\n+            f\"Received: factor={factor}\"\n+        )\n+        if isinstance(factor, (tuple, list)):\n+            if len(factor) != 2:\n+                raise ValueError(error_msg)\n+            if (\n+                factor[0] > self._FACTOR_BOUNDS[1]\n+                or factor[1] < self._FACTOR_BOUNDS[0]\n+            ):\n+                raise ValueError(error_msg)\n+            lower, upper = sorted(factor)\n+        elif isinstance(factor, (int, float)):\n+            if (\n+                factor < self._FACTOR_BOUNDS[0]\n+                or factor > self._FACTOR_BOUNDS[1]\n+            ):\n+                raise ValueError(error_msg)\n+            factor = abs(factor)\n+            lower, upper = [max(-factor, self._FACTOR_BOUNDS[0]), factor]\n+        else:\n+            raise ValueError(error_msg)\n+        return lower, upper\n+\n+    def create_gaussian_kernel(self, kernel_size, sigma, num_channels):\n+        def get_gaussian_kernel1d(size, sigma):\n+            x = (\n+                self.backend.numpy.arange(size, dtype=self.compute_dtype)\n+                - (size - 1) / 2\n+            )\n+            kernel1d = self.backend.numpy.exp(-0.5 * (x / sigma) ** 2)\n+            return kernel1d / self.backend.numpy.sum(kernel1d)\n+\n+        def get_gaussian_kernel2d(size, sigma):\n+            kernel1d_x = get_gaussian_kernel1d(size[0], sigma[0])\n+            kernel1d_y = get_gaussian_kernel1d(size[1], sigma[1])\n+            return self.backend.numpy.tensordot(kernel1d_y, kernel1d_x, axes=0)\n+\n+        kernel = get_gaussian_kernel2d(kernel_size, sigma)\n+\n+        kernel = self.backend.numpy.reshape(\n+            kernel, (kernel_size[0], kernel_size[1], 1, 1)\n+        )\n+        kernel = self.backend.numpy.tile(kernel, [1, 1, num_channels, 1])\n+\n+        kernel = self.backend.cast(kernel, self.compute_dtype)\n+\n+        return kernel\n+\n+    def get_random_transformation(self, data, training=True, seed=None):\n+        if not training:\n+            return None\n+\n+        if isinstance(data, dict):\n+            images = data[\"images\"]\n+        else:\n+            images = data\n+\n+        images_shape = self.backend.shape(images)\n+        rank = len(images_shape)\n+        if rank == 3:\n+            batch_size = 1\n+        elif rank == 4:\n+            batch_size = images_shape[0]\n+        else:\n+            raise ValueError(\n+                \"Expected the input image to be rank 3 or 4. Received \"\n+                f\"inputs.shape={images_shape}\"\n+            )\n+\n+        seed = seed or self._get_seed_generator(self.backend._backend)\n+\n+        blur_probability = self.backend.random.uniform(\n+            shape=(batch_size,),\n+            minval=self.factor[0],\n+            maxval=self.factor[1],\n+            seed=seed,\n+        )\n+\n+        random_threshold = self.backend.random.uniform(\n+            shape=(batch_size,),\n+            minval=0.0,\n+            maxval=1.0,\n+            seed=seed,\n+        )\n+        should_apply_blur = random_threshold < blur_probability\n+\n+        blur_factor = (\n+            self.backend.random.uniform(\n+                shape=(2,),\n+                minval=self.sigma[0],\n+                maxval=self.sigma[1],\n+                seed=seed,\n+                dtype=self.compute_dtype,\n+            )\n+            + 1e-6\n+        )\n+\n+        return {\n+            \"should_apply_blur\": should_apply_blur,\n+            \"blur_factor\": blur_factor,\n+        }\n+\n+    def transform_images(self, images, transformation=None, training=True):\n+        images = self.backend.cast(images, self.compute_dtype)\n+        if training and transformation is not None:\n+            if self.data_format == \"channels_first\":\n+                images = self.backend.numpy.swapaxes(images, -3, -1)\n+\n+            blur_factor = transformation[\"blur_factor\"]\n+            should_apply_blur = transformation[\"should_apply_blur\"]\n+\n+            kernel = self.create_gaussian_kernel(\n+                self.kernel_size,\n+                blur_factor,\n+                self.backend.shape(images)[-1],\n+            )\n+\n+            blur_images = self.backend.nn.depthwise_conv(\n+                images,\n+                kernel,\n+                strides=1,\n+                padding=\"same\",\n+                data_format=\"channels_last\",\n+            )\n+\n+            images = self.backend.numpy.where(\n+                should_apply_blur[:, None, None, None],\n+                blur_images,\n+                images,\n+            )\n+\n+            images = self.backend.numpy.clip(\n+                images, self.value_range[0], self.value_range[1]\n+            )\n+\n+            if self.data_format == \"channels_first\":\n+                images = self.backend.numpy.swapaxes(images, -3, -1)\n+\n+            images = self.backend.cast(images, dtype=self.compute_dtype)\n+\n+        return images\n+\n+    def transform_labels(self, labels, transformation, training=True):\n+        return labels\n+\n+    def transform_segmentation_masks(\n+        self, segmentation_masks, transformation, training=True\n+    ):\n+        return segmentation_masks\n+\n+    def transform_bounding_boxes(\n+        self, bounding_boxes, transformation, training=True\n+    ):\n+        return bounding_boxes\n+\n+    def compute_output_shape(self, input_shape):\n+        return input_shape\n+\n+    def get_config(self):\n+        config = super().get_config()\n+        config.update(\n+            {\n+                \"factor\": self.factor,\n+                \"kernel_size\": self.kernel_size,\n+                \"sigma\": self.sigma,\n+                \"value_range\": self.value_range,\n+                \"seed\": self.seed,\n+            }\n+        )\n+        return config\n\n@@ -0,0 +1,91 @@\n+import numpy as np\n+import pytest\n+from tensorflow import data as tf_data\n+\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n+from keras.src.backend import convert_to_tensor\n+\n+\n+class RandomGaussianBlurTest(testing.TestCase):\n+    @pytest.mark.requires_trainable_backend\n+    def test_layer(self):\n+        self.run_layer_test(\n+            layers.RandomGaussianBlur,\n+            init_kwargs={\n+                \"factor\": 1.0,\n+                \"kernel_size\": 3,\n+                \"sigma\": 0,\n+                \"value_range\": (0, 255),\n+                \"seed\": 1,\n+            },\n+            input_shape=(8, 3, 4, 3),\n+            supports_masking=False,\n+            expected_output_shape=(8, 3, 4, 3),\n+        )\n+\n+    def test_random_erasing_inference(self):\n+        seed = 3481\n+        layer = layers.RandomGaussianBlur()\n+\n+        np.random.seed(seed)\n+        inputs = np.random.randint(0, 255, size=(224, 224, 3))\n+        output = layer(inputs, training=False)\n+        self.assertAllClose(inputs, output)\n+\n+    def test_random_erasing_no_op(self):\n+        seed = 3481\n+        layer = layers.RandomGaussianBlur(factor=0)\n+\n+        np.random.seed(seed)\n+        inputs = np.random.randint(0, 255, size=(224, 224, 3))\n+        output = layer(inputs)\n+        self.assertAllClose(inputs, output)\n+\n+    def test_random_erasing_basic(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            inputs = np.ones((1, 2, 2, 3))\n+            expected_output = np.asarray(\n+                [\n+                    [\n+                        [[0.7273, 0.7273, 0.7273], [0.7273, 0.7273, 0.7273]],\n+                        [[0.7273, 0.7273, 0.7273], [0.7273, 0.7273, 0.7273]],\n+                    ]\n+                ]\n+            )\n+\n+        else:\n+            inputs = np.ones((1, 3, 2, 2))\n+            expected_output = np.asarray(\n+                [\n+                    [\n+                        [[0.7273, 0.7273], [0.7273, 0.7273]],\n+                        [[0.7273, 0.7273], [0.7273, 0.7273]],\n+                        [[0.7273, 0.7273], [0.7273, 0.7273]],\n+                    ]\n+                ]\n+            )\n+\n+        layer = layers.RandomGaussianBlur(data_format=data_format)\n+\n+        transformation = {\n+            \"blur_factor\": convert_to_tensor([0.3732, 0.8654]),\n+            \"should_apply_blur\": convert_to_tensor([True]),\n+        }\n+        output = layer.transform_images(inputs, transformation)\n+\n+        self.assertAllClose(expected_output, output, atol=1e-4, rtol=1e-4)\n+\n+    def test_tf_data_compatibility(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            input_data = np.random.random((2, 8, 8, 3))\n+        else:\n+            input_data = np.random.random((2, 3, 8, 8))\n+        layer = layers.RandomGaussianBlur(data_format=data_format)\n+\n+        ds = tf_data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            output.numpy()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#871ad7a869583d57bf429d1e5146bca96a667b82", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 12 | Files Changed: 2 | Hunks: 7 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 39 | Churn Cumulative: 127 | Contributors (this commit): 7 | Commits (past 90d): 2 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -318,15 +318,12 @@ class BatchNormalization(Layer):\n                 synchronized=self.synchronized,\n             )\n \n-        mask_weights = ops.cast(\n-            mask,\n-            inputs.dtype,\n+        mask_weights = ops.cast(mask, inputs.dtype)\n+        mask_weights_broadcasted = ops.expand_dims(mask_weights, axis=-1)\n+        broadcasted_mask = ops.broadcast_to(\n+            mask_weights_broadcasted, ops.shape(inputs)\n         )\n-        mask_weights_broadcasted = ops.expand_dims(\n-            mask_weights,\n-            axis=-1,\n-        )\n-        weighted_inputs = mask_weights_broadcasted * inputs\n+        weighted_inputs = broadcasted_mask * inputs\n \n         weighted_input_sum = ops.sum(\n             weighted_inputs,\n@@ -334,19 +331,19 @@ class BatchNormalization(Layer):\n             keepdims=True,\n         )\n         sum_of_weights = ops.sum(\n-            mask_weights_broadcasted,\n+            broadcasted_mask,\n             self._reduction_axes,\n             keepdims=True,\n         )\n-        mean = weighted_input_sum / (sum_of_weights + backend.config.epsilon())\n+        mean = weighted_input_sum / (sum_of_weights + backend.epsilon())\n \n         difference = weighted_inputs - mean\n         squared_difference = ops.square(difference)\n         weighted_distsq = ops.sum(\n-            mask_weights_broadcasted * squared_difference,\n+            broadcasted_mask * squared_difference,\n             self._reduction_axes,\n             keepdims=True,\n         )\n-        variance = weighted_distsq / (sum_of_weights + backend.config.epsilon())\n+        variance = weighted_distsq / (sum_of_weights + backend.epsilon())\n \n         return ops.squeeze(mean), ops.squeeze(variance)\n\n@@ -221,3 +221,21 @@ class BatchNormalizationTest(testing.TestCase):\n         with backend.AutocastScope(\"float16\"):\n             layer.moving_variance.assign(large_value)\n             self.assertAllClose(layer.moving_variance.value, large_value)\n+\n+    def test_masked_broadcast_normalization(self):\n+        input_shape = (1, 2, 3, 4)\n+        mask_shape = (1, 2, 1)\n+        x = ops.ones(input_shape)\n+        mask = ops.ones(mask_shape)\n+\n+        layer = layers.BatchNormalization(axis=-1, momentum=0.0, epsilon=1e-3)\n+\n+        y = layer(x, training=True, mask=mask)\n+\n+        mean_y = ops.mean(y, axis=[0, 1, 2])\n+\n+        self.assertAllClose(mean_y, ops.zeros((4,)), atol=1e-6)\n+        self.assertAllClose(y, ops.zeros_like(y), atol=1e-6)\n+\n+        self.assertAllClose(layer.moving_mean, ops.ones((4,)), atol=1e-6)\n+        self.assertAllClose(layer.moving_variance, ops.zeros((4,)), atol=1e-6)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fc1b26de28f07536aa5ecdfdd8672dfd31e77dac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 66 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 4 | Methods Changed: 5 | Complexity Δ (Sum/Max): 9/9 | Churn Δ: 66 | Churn Cumulative: 136 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 9 | DMM Complexity: 0.43636363636363634\n\nDIFF:\n@@ -139,6 +139,7 @@ def is_tf_dataset(x):\n             if parent.__name__ in (\n                 \"DatasetV2\",\n                 \"DistributedDataset\",\n+                \"DistributedDatasetsFromFunction\",\n             ) and \"tensorflow.python.\" in str(parent.__module__):\n                 return True\n     return False\n\n@@ -6,7 +6,9 @@ import pytest\n import tensorflow as tf\n import torch\n \n+from keras.src import Sequential\n from keras.src import backend\n+from keras.src import layers\n from keras.src import testing\n from keras.src.trainers.data_adapters import tf_dataset_adapter\n \n@@ -286,3 +288,66 @@ class TestTFDatasetAdapter(testing.TestCase):\n             self.assertIsInstance(by, expected_class)\n             self.assertEqual(bx.shape, (2, 4))\n             self.assertEqual(by.shape, (2, 2))\n+\n+    def test_distributed_datasets_from_function_adapter_properties(self):\n+        strategy = tf.distribute.MirroredStrategy()\n+\n+        def dataset_fn(input_context):\n+            batch_size = input_context.get_per_replica_batch_size(\n+                global_batch_size=2\n+            )\n+            x = tf.random.uniform((32, 4))\n+            y = tf.random.uniform((32, 2))\n+            return tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size)\n+\n+        dist_dataset = strategy.distribute_datasets_from_function(dataset_fn)\n+        adapter = tf_dataset_adapter.TFDatasetAdapter(dist_dataset)\n+        self.assertEqual(adapter.num_batches, 16)\n+        self.assertIsNone(adapter.batch_size)\n+        self.assertIsNone(adapter.has_partial_batch)\n+        self.assertIsNone(adapter.partial_batch_size)\n+\n+        if backend.backend() == \"numpy\":\n+            it = adapter.get_numpy_iterator()\n+            expected_class = np.ndarray\n+        elif backend.backend() == \"tensorflow\":\n+            it = adapter.get_tf_dataset()\n+            expected_class = tf.Tensor\n+        elif backend.backend() == \"jax\":\n+            it = adapter.get_jax_iterator()\n+            expected_class = np.ndarray\n+        elif backend.backend() == \"torch\":\n+            it = adapter.get_torch_dataloader()\n+            expected_class = torch.Tensor\n+\n+        batch_count = 0\n+        for batch in it:\n+            batch_count += 1\n+            self.assertEqual(len(batch), 2)\n+            data, labels = batch\n+            self.assertIsInstance(data, expected_class)\n+            self.assertIsInstance(labels, expected_class)\n+            self.assertEqual(data.shape, (2, 4))\n+            self.assertEqual(labels.shape, (2, 2))\n+\n+        self.assertEqual(batch_count, 16)\n+\n+    @pytest.mark.requires_trainable_backend\n+    def test_distributed_datasets_from_function_model_integration(self):\n+        strategy = tf.distribute.MirroredStrategy()\n+\n+        def dataset_fn(input_context):\n+            batch_size = input_context.get_per_replica_batch_size(\n+                global_batch_size=2\n+            )\n+            x = tf.random.uniform((4, 1))\n+            y = tf.random.uniform((4, 2))\n+            return tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size)\n+\n+        dist_dataset = strategy.distribute_datasets_from_function(dataset_fn)\n+\n+        model = Sequential([layers.Dense(2, input_shape=(1,))])\n+        model.compile(optimizer=\"adam\", loss=\"mse\")\n+        model.fit(dist_dataset, epochs=1)\n+        history = model.fit(dist_dataset, epochs=1)\n+        self.assertIn(\"loss\", history.history)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#06fb0aed69c5eacd813c84a9a20c9ce5aa2f7428", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 339 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -15,13 +15,14 @@ class RandomErasing(BaseImagePreprocessingLayer):\n \n     Args:\n         factor: A single float or a tuple of two floats.\n-            `factor` controls the extent to which the image hue is impacted.\n-            `factor=0.0` makes this layer perform a no-op operation,\n-            while a value of `1.0` performs the most aggressive\n-            erasing available. If a tuple is used, a `factor` is\n-            sampled between the two values for every image augmented. If a\n-            single float is used, a value between `0.0` and the passed float is\n-            sampled. Default is 1.0.\n+            `factor` controls the probability of applying the transformation.\n+            - `factor=0.0` ensures no erasing is applied.\n+            - `factor=1.0` means erasing is always applied.\n+            - If a tuple `(min, max)` is provided, a probability value\n+              is sampled between `min` and `max` for each image.\n+            - If a single float is provided, a probability is sampled\n+              between `0.0` and the given float.\n+            Default is 1.0.\n         scale: A tuple of two floats representing the aspect ratio range of\n             the erased patch. This defines the width-to-height ratio of\n             the patch to be erased. It can help control the rw shape of\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#00aeab327e945b01f11a28aa7091731646a7d90c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 21 | Churn Cumulative: 85 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -25,6 +25,16 @@ def pytest_configure(config):\n \n \n def pytest_collection_modifyitems(config, items):\n+    with open(\n+        \"keras/src/backend/openvino/excluded_concrete_tests.txt\", \"r\"\n+    ) as file:\n+        openvino_skipped_tests = file.readlines()\n+        # it is necessary to check if stripped line is not empty\n+        # and exclude such lines\n+        openvino_skipped_tests = [\n+            line.strip() for line in openvino_skipped_tests if line.strip()\n+        ]\n+\n     requires_trainable_backend = pytest.mark.skipif(\n         backend() == \"numpy\" or backend() == \"openvino\",\n         reason=\"Trainer not implemented for NumPy and OpenVINO backend.\",\n@@ -32,6 +42,17 @@ def pytest_collection_modifyitems(config, items):\n     for item in items:\n         if \"requires_trainable_backend\" in item.keywords:\n             item.add_marker(requires_trainable_backend)\n+        # also, skip concrete tests for openvino, listed in the special file\n+        # this is more granular mechanism to exclude tests rather\n+        # than using --ignore option\n+        for skipped_test in openvino_skipped_tests:\n+            if skipped_test in item.nodeid:\n+                item.add_marker(\n+                    skip_if_backend(\n+                        \"openvino\",\n+                        \"Not supported operation by openvino backend\",\n+                    )\n+                )\n \n \n def skip_if_backend(given_backend, reason):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b0fc0a3a013a862b6783453b8d710e19594935c8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 112 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -290,7 +290,7 @@ class TestTFDatasetAdapter(testing.TestCase):\n             self.assertEqual(by.shape, (2, 2))\n \n     def test_distributed_datasets_from_function_adapter_properties(self):\n-        strategy = tf.distribute.MirroredStrategy()\n+        strategy = tf.distribute.MirroredStrategy([\"CPU:0\"])\n \n         def dataset_fn(input_context):\n             batch_size = input_context.get_per_replica_batch_size(\n@@ -334,7 +334,7 @@ class TestTFDatasetAdapter(testing.TestCase):\n \n     @pytest.mark.requires_trainable_backend\n     def test_distributed_datasets_from_function_model_integration(self):\n-        strategy = tf.distribute.MirroredStrategy()\n+        strategy = tf.distribute.MirroredStrategy([\"CPU:0\"])\n \n         def dataset_fn(input_context):\n             batch_size = input_context.get_per_replica_batch_size(\n@@ -348,6 +348,5 @@ class TestTFDatasetAdapter(testing.TestCase):\n \n         model = Sequential([layers.Dense(2, input_shape=(1,))])\n         model.compile(optimizer=\"adam\", loss=\"mse\")\n-        model.fit(dist_dataset, epochs=1)\n         history = model.fit(dist_dataset, epochs=1)\n         self.assertIn(\"loss\", history.history)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3b0d4de0e5d2304436a2b2b138927de157b5884a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 17 | Files Changed: 1 | Hunks: 9 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 35 | Churn Cumulative: 411 | Contributors (this commit): 12 | Commits (past 90d): 5 | Contributors (cumulative): 12 | DMM Complexity: 0.0\n\nDIFF:\n@@ -308,7 +308,7 @@ class JAXTrainer(base_trainer.Trainer):\n             return outputs, (state[0], non_trainable_variables)\n \n         if not self.run_eagerly and self.jit_compile:\n-            predict_step = jax.jit(predict_step)\n+            predict_step = jax.jit(predict_step, donate_argnums=0)\n \n         _step_function = self._make_function(\n             predict_step, concatenate_outputs=True\n@@ -316,7 +316,7 @@ class JAXTrainer(base_trainer.Trainer):\n \n         def step_function(state, iterator):\n             outputs, state = _step_function(state, iterator)\n-            return outputs, state[1]\n+            return outputs, state\n \n         self.predict_function = step_function\n \n@@ -671,14 +671,20 @@ class JAXTrainer(base_trainer.Trainer):\n                     state = self._get_jax_state(\n                         trainable_variables=True,\n                         non_trainable_variables=True,\n+                        purge_model_variables=True,\n                     )\n-                    self._purge_model_variables(non_trainable_variables=True)\n                     self._jax_state_synced = False\n-                else:\n-                    state = (state[0], non_trainable_variables)\n-                batch_outputs, non_trainable_variables = self.predict_function(\n-                    state, iterator\n-                )\n+                batch_outputs, state = self.predict_function(state, iterator)\n+                (\n+                    trainable_variables,\n+                    non_trainable_variables,\n+                ) = state\n+                self._jax_state = {\n+                    \"trainable_variables\": trainable_variables,\n+                    # I wouldn't recommend modifying non-trainable model state\n+                    # during predict(), but it's allowed.\n+                    \"non_trainable_variables\": non_trainable_variables,\n+                }\n                 outputs = append_to_outputs(batch_outputs, outputs)\n \n                 # Dispatch callbacks. This takes care of async dispatch.\n@@ -687,11 +693,6 @@ class JAXTrainer(base_trainer.Trainer):\n                 if self.stop_predicting:\n                     break\n \n-        self._jax_state = {\n-            # I wouldn't recommend modifying non-trainable model state\n-            # during predict(), but it's allowed.\n-            \"non_trainable_variables\": non_trainable_variables,\n-        }\n         self.jax_state_sync()\n         callbacks.on_predict_end()\n         self._jax_state = None\n@@ -819,10 +820,10 @@ class JAXTrainer(base_trainer.Trainer):\n         def data():\n             yield (x,)\n \n-        batch_outputs, non_trainable_variables = self.predict_function(\n-            state, data()\n-        )\n+        batch_outputs, state = self.predict_function(state, data())\n+        trainable_variables, non_trainable_variables = state\n         self._jax_state = {\n+            \"trainable_variables\": trainable_variables,\n             \"non_trainable_variables\": non_trainable_variables,\n         }\n         self.jax_state_sync()\n@@ -929,7 +930,7 @@ class JAXTrainer(base_trainer.Trainer):\n     ):\n         \"\"\"Remove all the model variable for memory saving.\n \n-        During JAX training, since the training function are stateless, we have\n+        During JAX training, since the training function is stateless, we have\n         to pass in and get the model weights over and over, during which the\n         copy of the weights that attached to the Variable are still and\n         occupying extra memory. We remove those variable to save memory (for\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c5c2768ddb19947cf92591b2fd87298f3fe1d6b4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 38 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 8 | Methods Changed: 2 | Complexity Δ (Sum/Max): 10/10 | Churn Δ: 41 | Churn Cumulative: 206 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 0.0\n\nDIFF:\n@@ -44,6 +44,9 @@ def _extract_image_batch(images, num_images, batch_size):\n @keras_export(\"keras.visualization.plot_image_gallery\")\n def plot_image_gallery(\n     images,\n+    y_true=None,\n+    y_pred=None,\n+    label_map=None,\n     rows=None,\n     cols=None,\n     value_range=(0, 255),\n@@ -55,11 +58,18 @@ def plot_image_gallery(\n     legend_handles=None,\n     data_format=None,\n ):\n-    \"\"\"Displays a gallery of images.\n+    \"\"\"Displays a gallery of images with optional labels and predictions.\n \n     Args:\n         images: A 4D tensor or NumPy array of images. Shape should be\n            `(batch_size, height, width, channels)`.\n+        y_true: A 1D tensor or NumPy array of true labels (class indices).\n+           Defaults to `None`.\n+        y_pred: A 1D tensor or NumPy array of predicted labels (class indices).\n+           Defaults to `None`.\n+        label_map: A dictionary mapping class indices to class names.\n+            Required if `y_true` or `y_pred` are provided.\n+           Defaults to `None`.\n         value_range: A tuple specifying the value range of the images\n             (e.g., `(0, 255)` or `(0, 1)`). Defaults to `(0, 255)`.\n         rows: The number of rows in the gallery. If `None`, it's calculated\n@@ -83,8 +93,9 @@ def plot_image_gallery(\n             `\"channels_first\"`. Defaults to the Keras backend data format.\n \n     Raises:\n-        ValueError: If both `path` and `show` are set to non-`None` values or if\n-            `images` is not a 4D tensor or array.\n+        ValueError: If both `path` and `show` are set to non-`None` values,\n+            if `images` is not a 4D tensor or array, or if `y_true` or `y_pred`\n+            are provided without a `label_map`.\n         ImportError: if matplotlib is not installed.\n     \"\"\"\n     if plt is None:\n@@ -99,6 +110,12 @@ def plot_image_gallery(\n             \"to be true.\"\n         )\n \n+    if (y_true is not None or y_pred is not None) and label_map is None:\n+        raise ValueError(\n+            \"If `y_true` or `y_pred` are provided, a `label_map` must also be\"\n+            \" provided.\"\n+        )\n+\n     show = show if show is not None else (path is None)\n     data_format = data_format or backend.image_data_format()\n \n@@ -113,6 +130,7 @@ def plot_image_gallery(\n         data_format == \"channels_first\"\n     ):  # Ensure correct data format for plotting\n         images = ops.transpose(images, (0, 2, 3, 1))\n+\n     # Generate subplots\n     fig, axes = plt.subplots(\n         nrows=rows,\n@@ -141,6 +159,11 @@ def plot_image_gallery(\n     if data_format == \"channels_first\":\n         images = images.transpose(0, 2, 3, 1)\n \n+    if y_true is not None:\n+        y_true = ops.convert_to_numpy(y_true)\n+    if y_pred is not None:\n+        y_pred = ops.convert_to_numpy(y_pred)\n+\n     for row in range(rows):\n         for col in range(cols):\n             index = row * cols + col\n@@ -150,6 +173,18 @@ def plot_image_gallery(\n             current_axis.imshow(images[index].astype(\"uint8\"))\n             current_axis.margins(x=0, y=0)\n             current_axis.axis(\"off\")\n+            title_parts = []\n+            if y_true is not None and index < len(y_true):\n+                title_parts.append(\n+                    f\"Label: {label_map.get(y_true[index], 'Unknown')}\"\n+                )\n+            if y_pred is not None and index < len(y_pred):\n+                title_parts.append(\n+                    f\"Pred: {label_map.get(y_pred[index], 'Unknown')}\"\n+                )\n+\n+            if title_parts:\n+                current_axis.set_title(\"  \".join(title_parts), fontsize=8)\n \n     if path is not None:\n         plt.savefig(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c49f48788723d7d264f97396a8569a0b02ed1cf3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 31 | Churn Cumulative: 180 | Contributors (this commit): 5 | Commits (past 90d): 3 | Contributors (cumulative): 8 | DMM Complexity: 0.9565217391304348\n\nDIFF:\n@@ -21,6 +21,8 @@ from keras.src.applications import resnet_v2\n from keras.src.applications import vgg16\n from keras.src.applications import vgg19\n from keras.src.applications import xception\n+from keras.src.layers import Conv2D\n+from keras.src.layers import Input\n from keras.src.saving import serialization_lib\n from keras.src.utils import file_utils\n from keras.src.utils import image_utils\n@@ -239,6 +241,32 @@ class ApplicationsTest(testing.TestCase):\n         output_shape = list(model.outputs[0].shape)\n         self.assertEqual(output_shape[last_dim_axis], last_dim)\n \n+    @parameterized.named_parameters(test_parameters)\n+    def test_application_notop_custom_input_tensor(\n+        self, app, last_dim, _, image_data_format\n+    ):\n+        if app == nasnet.NASNetMobile and backend.backend() == \"torch\":\n+            self.skipTest(\n+                \"NASNetMobile pretrained incorrect with torch backend.\"\n+            )\n+        self.skip_if_invalid_image_data_format_for_model(app, image_data_format)\n+        backend.set_image_data_format(image_data_format)\n+\n+        if image_data_format == \"channels_first\":\n+            input_shape = (4, 123, 123)\n+            last_dim_axis = 1\n+        else:\n+            input_shape = (123, 123, 4)\n+            last_dim_axis = -1\n+\n+        inputs_custom = Input(shape=input_shape, name=\"custom_input\")\n+        inputs_custom = Conv2D(3, (2, 2), padding=\"valid\", strides=(2, 2))(\n+            inputs_custom\n+        )\n+        model = app(weights=None, include_top=False, input_tensor=inputs_custom)\n+        output_shape = list(model.outputs[0].shape)\n+        self.assertEqual(output_shape[last_dim_axis], last_dim)\n+\n     @parameterized.named_parameters(test_parameters)\n     def test_application_pooling(self, app, last_dim, _, image_data_format):\n         if app == nasnet.NASNetMobile and backend.backend() == \"torch\":\n\n@@ -432,10 +432,11 @@ def ConvNeXt(\n \n     if input_tensor is not None:\n         inputs = operation_utils.get_source_inputs(input_tensor)[0]\n+        x = input_tensor\n     else:\n         inputs = img_input\n-\n         x = inputs\n+\n     if include_preprocessing:\n         channel_axis = (\n             3 if backend.image_data_format() == \"channels_last\" else 1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e106d2314e77df8a2f69a900e0b5cf07b8411ca9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 68 | Lines Deleted: 11 | Files Changed: 4 | Hunks: 15 | Methods Changed: 8 | Complexity Δ (Sum/Max): 8/6 | Churn Δ: 79 | Churn Cumulative: 1099 | Contributors (this commit): 15 | Commits (past 90d): 13 | Contributors (cumulative): 21 | DMM Complexity: 0.047619047619047616\n\nDIFF:\n@@ -1,3 +1,5 @@\n+import warnings\n+\n from keras.src import backend\n from keras.src import tree\n from keras.src.export.export_utils import convert_spec_to_tensor\n@@ -6,9 +8,10 @@ from keras.src.export.export_utils import make_tf_tensor_spec\n from keras.src.export.saved_model import DEFAULT_ENDPOINT_NAME\n from keras.src.export.saved_model import ExportArchive\n from keras.src.export.tf2onnx_lib import patch_tf2onnx\n+from keras.src.utils import io_utils\n \n \n-def export_onnx(model, filepath, verbose=True, input_signature=None, **kwargs):\n+def export_onnx(model, filepath, verbose=None, input_signature=None, **kwargs):\n     \"\"\"Export the model as a ONNX artifact for inference.\n \n     This method lets you export a model to a lightweight ONNX artifact\n@@ -22,7 +25,8 @@ def export_onnx(model, filepath, verbose=True, input_signature=None, **kwargs):\n     Args:\n         filepath: `str` or `pathlib.Path` object. The path to save the artifact.\n         verbose: `bool`. Whether to print a message during export. Defaults to\n-            True`.\n+            `None`, which uses the default value set by different backends and\n+            formats.\n         input_signature: Optional. Specifies the shape and dtype of the model\n             inputs. Can be a structure of `keras.InputSpec`, `tf.TensorSpec`,\n             `backend.KerasTensor`, or backend tensor. If not provided, it will\n@@ -55,6 +59,10 @@ def export_onnx(model, filepath, verbose=True, input_signature=None, **kwargs):\n     predictions = ort_session.run(None, ort_inputs)\n     ```\n     \"\"\"\n+    actual_verbose = verbose\n+    if actual_verbose is None:\n+        actual_verbose = True  # Defaults to `True` for all backends.\n+\n     if input_signature is None:\n         input_signature = get_input_signature(model)\n         if not input_signature or not model._called:\n@@ -92,16 +100,56 @@ def export_onnx(model, filepath, verbose=True, input_signature=None, **kwargs):\n                 \"dictionaries as inputs.\"\n             )\n \n-        # Convert to ONNX using TorchScript-based ONNX Exporter.\n-        # TODO: Use TorchDynamo-based ONNX Exporter once\n-        # `torch.onnx.dynamo_export()` supports Keras models.\n-        torch.onnx.export(model, sample_inputs, filepath, verbose=verbose)\n+        if hasattr(model, \"eval\"):\n+            model.eval()\n+        with warnings.catch_warnings():\n+            # Suppress some unuseful warnings.\n+            warnings.filterwarnings(\n+                \"ignore\",\n+                message=r\".*\\n.*\\n*.*\\n*.*export will treat it as a constant.*\",\n+            )\n+            warnings.filterwarnings(\n+                \"ignore\",\n+                message=r\".*not properly registered as a submodule,.*\",\n+            )\n+            warnings.filterwarnings(\n+                \"ignore\",\n+                message=r\".*which is what 'get_attr' Nodes typically target.*\",\n+            )\n+            warnings.filterwarnings(\n+                \"ignore\",\n+                message=r\".*underlying reference in the owning GraphModule.*\",\n+            )\n+            warnings.filterwarnings(\n+                \"ignore\", message=r\".*suppressed about get_attr references.*\"\n+            )\n+            try:\n+                # Try the TorchDynamo-based ONNX exporter first.\n+                onnx_program = torch.onnx.export(\n+                    model, sample_inputs, verbose=actual_verbose, dynamo=True\n+                )\n+                if hasattr(onnx_program, \"optimize\"):\n+                    onnx_program.optimize()  # Only supported by torch>=2.6.0.\n+                onnx_program.save(filepath)\n+            except:\n+                if verbose is None:\n+                    # Set to `False` due to file system leakage issue:\n+                    # https://github.com/keras-team/keras/issues/20826\n+                    actual_verbose = False\n+\n+                # Fall back to the TorchScript-based ONNX exporter.\n+                torch.onnx.export(\n+                    model, sample_inputs, filepath, verbose=actual_verbose\n+                )\n     else:\n         raise NotImplementedError(\n             \"`export_onnx` is only compatible with TensorFlow, JAX and \"\n             \"Torch backends.\"\n         )\n \n+    if actual_verbose:\n+        io_utils.print_msg(f\"Saved artifact at '{filepath}'.\")\n+\n \n def _check_jax_kwargs(kwargs):\n     kwargs = kwargs.copy()\n\n@@ -500,6 +500,7 @@ class ExportArchive(BackendExportArchive):\n         )\n \n         # Print out available endpoints\n+        if verbose:\n             endpoints = \"\\n\\n\".join(\n                 _print_signature(\n                     getattr(self._tf_trackable, name), name, verbose=verbose\n@@ -561,7 +562,7 @@ class ExportArchive(BackendExportArchive):\n \n \n def export_saved_model(\n-    model, filepath, verbose=True, input_signature=None, **kwargs\n+    model, filepath, verbose=None, input_signature=None, **kwargs\n ):\n     \"\"\"Export the model as a TensorFlow SavedModel artifact for inference.\n \n@@ -577,7 +578,8 @@ def export_saved_model(\n     Args:\n         filepath: `str` or `pathlib.Path` object. The path to save the artifact.\n         verbose: `bool`. Whether to print a message during export. Defaults to\n-            True`.\n+            `None`, which uses the default value set by different backends and\n+            formats.\n         input_signature: Optional. Specifies the shape and dtype of the model\n             inputs. Can be a structure of `keras.InputSpec`, `tf.TensorSpec`,\n             `backend.KerasTensor`, or backend tensor. If not provided, it will\n@@ -616,6 +618,8 @@ def export_saved_model(\n     use the lower-level `keras.export.ExportArchive` class. The\n     `export()` method relies on `ExportArchive` internally.\n     \"\"\"\n+    if verbose is None:\n+        verbose = True  # Defaults to `True` for all backends.\n     export_archive = ExportArchive()\n     if input_signature is None:\n         input_signature = get_input_signature(model)\n\n@@ -464,7 +464,7 @@ class Model(Trainer, base_trainer.Trainer, Layer):\n         self,\n         filepath,\n         format=\"tf_saved_model\",\n-        verbose=True,\n+        verbose=None,\n         input_signature=None,\n         **kwargs,\n     ):\n@@ -477,7 +477,8 @@ class Model(Trainer, base_trainer.Trainer, Layer):\n                 `\"tf_saved_model\"` and `\"onnx\"`.  Defaults to\n                 `\"tf_saved_model\"`.\n             verbose: `bool`. Whether to print a message during export. Defaults\n-                to `True`.\n+                to `None`, which uses the default value set by different\n+                backends and formats.\n             input_signature: Optional. Specifies the shape and dtype of the\n                 model inputs. Can be a structure of `keras.InputSpec`,\n                 `tf.TensorSpec`, `backend.KerasTensor`, or backend tensor. If\n@@ -498,6 +499,10 @@ class Model(Trainer, base_trainer.Trainer, Layer):\n         **Note:** This feature is currently supported only with TensorFlow, JAX\n         and Torch backends.\n \n+        **Note:** Be aware that the exported artifact may contain information\n+        from the local file system when using `format=\"onnx\"`, `verbose=True`\n+        and Torch backend.\n+\n         Examples:\n \n         Here's how to export a TensorFlow SavedModel for inference.\n\n@@ -153,7 +153,7 @@ class TorchModuleWrapper(Layer):\n \n         if \"module\" in config:\n             buffer = io.BytesIO(config[\"module\"])\n-            config[\"module\"] = torch.load(buffer)\n+            config[\"module\"] = torch.load(buffer, weights_only=False)\n         return cls(**config)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4447add8f0bcfa673e3f266e37bddc5cd4af4009", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 615 | Lines Deleted: 2 | Files Changed: 13 | Hunks: 27 | Methods Changed: 36 | Complexity Δ (Sum/Max): 60/19 | Churn Δ: 617 | Churn Cumulative: 4152 | Contributors (this commit): 31 | Commits (past 90d): 41 | Contributors (cumulative): 102 | DMM Complexity: 0.8401253918495298\n\nDIFF:\n@@ -14,6 +14,7 @@ from keras.api import Operation\n from keras.api import Optimizer\n from keras.api import Quantizer\n from keras.api import Regularizer\n+from keras.api import RematScope\n from keras.api import Sequential\n from keras.api import StatelessScope\n from keras.api import SymbolicScope\n@@ -44,6 +45,7 @@ from keras.api import preprocessing\n from keras.api import quantizers\n from keras.api import random\n from keras.api import regularizers\n+from keras.api import remat\n from keras.api import saving\n from keras.api import tree\n from keras.api import utils\n\n@@ -37,6 +37,8 @@ from keras.src.backend import Variable\n from keras.src.backend import device\n from keras.src.backend import name_scope\n from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.backend.common.remat import RematScope\n+from keras.src.backend.common.remat import remat\n from keras.src.backend.common.stateless_scope import StatelessScope\n from keras.src.backend.common.symbolic_scope import SymbolicScope\n from keras.src.dtype_policies.dtype_policy import DTypePolicy\n\n@@ -35,6 +35,8 @@ from keras.src.backend import Variable\n from keras.src.backend import device\n from keras.src.backend import name_scope\n from keras.src.backend.common.keras_tensor import KerasTensor\n+from keras.src.backend.common.remat import RematScope\n+from keras.src.backend.common.remat import remat\n from keras.src.backend.common.stateless_scope import StatelessScope\n from keras.src.backend.common.symbolic_scope import SymbolicScope\n from keras.src.dtype_policies.dtype_policy import DTypePolicy\n\n@@ -0,0 +1,185 @@\n+from collections import namedtuple\n+\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.backend.common import global_state\n+\n+\n+@keras_export(\"keras.RematScope\")\n+class RematScope:\n+    \"\"\"A context manager for enabling rematerialization in Keras.\n+\n+    Rematerialization (gradient checkpointing) trades memory for computation by\n+    recomputing intermediate activations during the backward pass. This is\n+    particularly useful for training large models or large batch sizes within\n+    limited memory constraints.\n+\n+    This should be used when initializing the layer (e.g., `layer(input)`).\n+    Rematerialization applies at execution time, not at creation time.\n+\n+    Args:\n+        mode: Rematerialization mode to apply.\n+            Options:\n+            - \"full\": Apply rematerialization globally to all supported\n+              operations.\n+            - \"activations\": Apply rematerialization to activations on any\n+              layers that contain `keras.activations` (e.g., `Dense(...,\n+              activation=relu)`).\n+            - \"larger_than\": Apply rematerialization to layers with output sizes\n+              larger than `output_size_threshold`.\n+            - \"list_of_layers\": Apply rematerialization to a specific list of\n+              layer names.\n+            - None: Disable rematerialization.\n+        output_size_threshold: Output size threshold for the\n+            `\"larger_than\"` mode. Layers producing outputs larger than this\n+            threshold will be rematerialized. Default is `1024`.\n+        layer_names: List of layer names for the\n+            `\"list_of_layers\"` mode. Default is an empty list.\n+\n+    Examples:\n+    Using \"list_of_layers\" mode:\n+\n+    ```python\n+    from keras import RematScope\n+    input_tensor = tf.random.normal((1, 32, 32, 3))\n+    with RematScope(mode=\"list_of_layers\", layer_names=[\"dense_1\",\n+    \"conv2d_1\"]):\n+        layer1 = keras.layers.Dense(128, name=\"dense_1\")\n+        layer2 = keras.layers.Conv2D(64, (3, 3), name=\"conv2d_1\")\n+        layer3 = keras.layers.Dense(64, name=\"dense_2\")\n+        # Only layer1 and layer2 will apply rematerialization\n+        output1 = layer1(input_tensor)\n+        output2 = layer2(output1)\n+        output3 = layer3(output2)\n+    ```\n+\n+    Using \"larger_than\" mode with a specific output size threshold:\n+\n+    ```python\n+    with RematScope(mode=\"larger_than\", output_size_threshold=2048):\n+        layer = keras.layers.Conv2D(64, (3, 3))\n+        output = layer(input_tensor)  # Conv2D outputs larger than 2048\n+    ```\n+\n+    Nested scopes for fine-grained control:\n+\n+    ```python\n+    with RematScope(mode=\"full\"):\n+        # Create layers\n+        layer1 = keras.layers.Dense(128, activation='relu')\n+        output1 = layer1(input_tensor)  # layer1 is fully rematerialized\n+        with RematScope(mode=\"larger_than\", output_size_threshold=512):\n+            layer2 = keras.layers.Conv2D(32, (3, 3))\n+            output2 = layer2(output1) # layer2 is conditionally rematerialized\n+            # if output > 512\n+    ```\n+    \"\"\"\n+\n+    def __init__(\n+        self, mode=\"full\", output_size_threshold=1024, layer_names=None\n+    ):\n+        if mode not in {\n+            \"full\",\n+            \"activations\",\n+            \"larger_than\",\n+            \"list_of_layers\",\n+            None,\n+        }:\n+            raise ValueError(\n+                f\"Invalid mode '{mode}'. Supported modes are: \"\n+                \"'full', 'activations', 'larger_than', 'list_of_layers', or \"\n+                \" None.\"\n+            )\n+        self.mode = mode\n+        self.output_size_threshold = output_size_threshold\n+        self.layer_names = layer_names or []\n+        self._pop_on_exit = False\n+\n+    def __enter__(self):\n+        remat_scope_stack = global_state.get_global_attribute(\n+            \"remat_scope_stack\", default=[], set_to_default=True\n+        )\n+        remat_scope_stack.append(self)\n+        self._pop_on_exit = True\n+        return self\n+\n+    def __exit__(self, *args, **kwargs):\n+        if self._pop_on_exit:\n+            remat_scope_stack = global_state.get_global_attribute(\n+                \"remat_scope_stack\"\n+            )\n+            remat_scope_stack.pop()\n+\n+\n+RematMode = namedtuple(\n+    \"RematMode\", [\"mode\", \"output_size_threshold\", \"layer_names\"]\n+)\n+\n+\n+def get_current_remat_mode():\n+    \"\"\"Get the current rematerialization mode and associated settings.\n+\n+    Returns:\n+        RematMode or None: The current rematerialization mode, or None if not\n+        set.\n+    \"\"\"\n+    remat_scope_stack = global_state.get_global_attribute(\"remat_scope_stack\")\n+    if not remat_scope_stack:\n+        return None\n+    active_scope = remat_scope_stack[-1]\n+    return RematMode(\n+        active_scope.mode,\n+        active_scope.output_size_threshold,\n+        active_scope.layer_names,\n+    )\n+\n+\n+@keras_export(\"keras.remat\")\n+def remat(f):\n+    \"\"\"Applies rematerialization to a function or layer for memory optimization.\n+\n+    Rematerialization is a memory optimization technique that trades off\n+    computation for memory. Instead of storing intermediate results\n+    (e.g. activations) for backpropagation, they are recomputed during the\n+    backward pass. This reduces peak memory usage at the cost of increased\n+    computation time, allowing the training of larger models or using larger\n+    batch sizes within the same memory constraints.\n+\n+    Args:\n+        f: A callable function, to which rematerialization is\n+           applied. This is typically a computationally expensive operation\n+           where intermediate states can be recomputed instead of stored.\n+\n+    Returns:\n+        A wrapped function that applies rematerialization. The returned\n+        function defines a custom gradient, ensuring that during the backward\n+        pass, the forward computation is recomputed as needed.\n+\n+    Example:\n+        ```python\n+        from keras import Model\n+        class CustomRematLayer(layers.Layer):\n+            def __init__(self, **kwargs):\n+                super().__init__(**kwargs)\n+                self.remat_function = remat(self.intermediate_function)\n+\n+            def intermediate_function(self, x):\n+                for _ in range(2):\n+                    x = x + x * 0.1  # Simple scaled transformation\n+                return x\n+\n+            def call(self, inputs):\n+                return self.remat_function(inputs)\n+\n+        # Define a simple model using the custom layer\n+        inputs = layers.Input(shape=(4,))\n+        x = layers.Dense(4, activation=\"relu\")(inputs)\n+        x = CustomRematLayer()(x)  # Custom layer with rematerialization\n+        outputs = layers.Dense(1)(x)\n+\n+        # Create and compile the model\n+        model = Model(inputs=inputs, outputs=outputs)\n+        model.compile(optimizer=\"sgd\", loss=\"mse\")\n+        ```\n+    \"\"\"\n+    return backend.core.remat(f)\n\n@@ -0,0 +1,118 @@\n+import numpy as np\n+\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import models\n+from keras.src import testing\n+from keras.src.backend.common import global_state\n+from keras.src.backend.common.remat import RematScope\n+from keras.src.backend.common.remat import get_current_remat_mode\n+from keras.src.layers import activations\n+\n+\n+class TestRematScope(testing.TestCase):\n+    def setUp(self):\n+        \"\"\"Reset global state before each test.\"\"\"\n+        global_state.clear_session()\n+\n+    def test_remat_scope_activation(self):\n+        self.assertIsNone(\n+            get_current_remat_mode()\n+        )  # Initially, no mode is active\n+\n+        with RematScope(mode=\"full\"):\n+            self.assertEqual(\n+                get_current_remat_mode().mode, \"full\"\n+            )  # Mode is set to \"full\"\n+\n+        self.assertIsNone(\n+            get_current_remat_mode()\n+        )  # Mode is restored to None after scope ends\n+\n+    def test_remat_scope_nested(self):\n+        \"\"\"Test nested scopes with different rematerialization modes.\"\"\"\n+        with RematScope(mode=\"full\"):\n+            self.assertEqual(\n+                get_current_remat_mode().mode, \"full\"\n+            )  # Outer scope is \"full\"\n+\n+            with RematScope(mode=\"activations\"):\n+                self.assertEqual(\n+                    get_current_remat_mode().mode, \"activations\"\n+                )  # Inner scope is \"activations\"\n+\n+            self.assertEqual(\n+                get_current_remat_mode().mode, \"full\"\n+            )  # Back to outer scope\n+\n+        self.assertIsNone(\n+            get_current_remat_mode()\n+        )  # Mode is restored to None after all scopes\n+\n+    def test_remat_scope_stack_management(self):\n+        \"\"\"Test that the remat_scope_stack is managed correctly.\"\"\"\n+        self.assertIsNone(\n+            global_state.get_global_attribute(\"remat_scope_stack\")\n+        )  # No stack initially\n+\n+        with RematScope(mode=\"full\"):\n+            remat_stack = global_state.get_global_attribute(\"remat_scope_stack\")\n+            self.assertIsNotNone(remat_stack)  # Stack is initialized\n+            self.assertEqual(len(remat_stack), 1)  # Stack contains one entry\n+\n+            with RematScope(mode=\"activations\"):\n+                remat_stack = global_state.get_global_attribute(\n+                    \"remat_scope_stack\"\n+                )\n+                self.assertEqual(\n+                    len(remat_stack), 2\n+                )  # Stack contains two entries\n+\n+            remat_stack = global_state.get_global_attribute(\"remat_scope_stack\")\n+            self.assertEqual(len(remat_stack), 1)  # Back to one entry\n+\n+        self.assertEqual(\n+            global_state.get_global_attribute(\"remat_scope_stack\"), []\n+        )  # Stack is cleared\n+\n+    def test_invalid_mode(self):\n+        \"\"\"Test that invalid rematerialization modes raise an error.\"\"\"\n+        with self.assertRaises(ValueError):\n+            RematScope(mode=\"invalid\")  # Invalid mode should raise ValueError\n+\n+\n+class RematTest(testing.TestCase):\n+    def test_remat_basic_call(self):\n+        if backend.backend() in (\"openvino\", \"numpy\"):\n+            self.skipTest(\n+                \"remat is not supported in openvino and numpy backends.\"\n+            )\n+        # Generate dummy data\n+        data_size = 10**5\n+        x_train = np.random.normal(size=(data_size, 4))\n+        y_train = np.random.normal(size=(data_size, 1))\n+\n+        epochs = 5\n+        batch_size = 512\n+        # test applying remat\n+        output_with_remat = backend.core.remat(activations.ReLU())(x_train)\n+        output_without_remat = activations.ReLU()(x_train)\n+        self.assertAllClose(output_with_remat, output_without_remat)\n+        # test remat in a model\n+        intermediate_function = backend.core.remat(activations.ReLU())\n+        inputs = layers.Input(shape=(4,))\n+        x = layers.Dense(4)(inputs)\n+        x = layers.Lambda(intermediate_function)(x)\n+        outputs = layers.Dense(1)(x)\n+        model = models.Model(inputs=inputs, outputs=outputs)\n+        model.predict(x_train)\n+        model.compile(optimizer=\"sgd\", loss=\"mse\")\n+\n+        # Train model\n+        model.fit(\n+            x_train,\n+            y_train,\n+            epochs=epochs,\n+            batch_size=batch_size,\n+            verbose=0,\n+        )\n\n@@ -365,6 +365,18 @@ def custom_gradient(fun):\n     return jax.custom_gradient(fun=fun)\n \n \n+def remat(f):\n+    \"\"\"Implementation of rematerialization.\n+\n+    Args:\n+        f: The function or operation to rematerialize.\n+    Returns:\n+        A function wrapping f that defines a custom gradient, which\n+        recomputes f on the backwards pass of a gradient call.\n+    \"\"\"\n+    return jax.checkpoint(f)\n+\n+\n class name_scope(base_name_scope):\n     def __init__(self, name, **kwargs):\n         super().__init__(name, **kwargs)\n\n@@ -443,3 +443,12 @@ class custom_gradient:\n @contextlib.contextmanager\n def device_scope(device_name):\n     yield\n+\n+\n+def remat(f):\n+    warnings.warn(\n+        \"Rematerialization memory optimization is not supported by the \"\n+        \"Numpy backend. Please switch to JAX, TensorFlow, or PyTorch to \"\n+        \"utilize this feature.\"\n+    )\n+    return f\n\n@@ -615,3 +615,12 @@ def custom_gradient(fun):\n     def __call__(self, *args, **kwargs):\n         outputs, _ = self.fun(*args, **kwargs)\n         return outputs\n+\n+\n+def remat(f):\n+    warnings.warn(\n+        \"Rematerialization memory optimization is not supported by the \"\n+        \"OpenVino backend. Please switch to JAX, TensorFlow, or PyTorch to \"\n+        \"utilize this feature.\"\n+    )\n+    return f\n\n@@ -640,6 +640,18 @@ def custom_gradient(fun):\n     return tf.custom_gradient(f=fun)\n \n \n+def remat(f):\n+    \"\"\"Implementation of rematerialization.\n+\n+    Args:\n+        f: The function or operation to rematerialize.\n+    Returns:\n+        A function wrapping f that defines a custom gradient, which\n+        recomputes f on the backwards pass of a gradient call.\n+    \"\"\"\n+    return tf.recompute_grad(f)\n+\n+\n class name_scope(base_name_scope):\n     def __init__(self, name, **kwargs):\n         super().__init__(name, **kwargs)\n\n@@ -661,6 +661,22 @@ def random_seed_dtype():\n     return \"int32\"\n \n \n+def remat(f):\n+    \"\"\"Implementation of rematerialization.\n+\n+    Args:\n+        f: The function or operation to rematerialize.\n+    Returns:\n+        A function wrapping f that defines a custom gradient, which\n+        recomputes f on the backwards pass of a gradient call.\n+    \"\"\"\n+\n+    def wrapped(*args, **kwargs):\n+        return torch.utils.checkpoint.checkpoint(f, *args, use_reentrant=False)\n+\n+    return wrapped\n+\n+\n class custom_gradient:\n     \"\"\"Decorator for custom gradients.\n \n\n@@ -18,6 +18,7 @@ And some more magic:\n \n import collections\n import inspect\n+import math\n import warnings\n from functools import wraps\n \n@@ -31,7 +32,9 @@ from keras.src import utils\n from keras.src.api_export import keras_export\n from keras.src.backend import KerasTensor\n from keras.src.backend.common import global_state\n+from keras.src.backend.common import remat\n from keras.src.backend.common.name_scope import current_path\n+from keras.src.backend.common.remat import get_current_remat_mode\n from keras.src.backend.common.symbolic_scope import in_symbolic_scope\n from keras.src.distribution import distribution_lib\n from keras.src.dtype_policies import DTypePolicyMap\n@@ -315,6 +318,7 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n         self._build_shapes_dict = None\n         # Parent path\n         self._parent_path = None\n+        self._remat_mode = get_current_remat_mode()\n         self._initialize_tracker()\n \n     @tracking.no_automatic_dependency_tracking\n@@ -898,7 +902,6 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n                 elif self.compute_dtype != self.variable_dtype:\n                     # Enter a new scope if our dtypes are \"mixed\".\n                     new_scope = backend.AutocastScope(self.compute_dtype)\n-\n                 if new_scope is not None:\n                     with new_scope:\n                         outputs = super().__call__(*args, **kwargs)\n@@ -1001,7 +1004,6 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n         ```\n         \"\"\"\n         self._check_super_called()\n-\n         if not self.built:\n             raise ValueError(\n                 f\"To call stateless_call, {self.__class__.__name__} must be \"\n@@ -1038,7 +1040,14 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n             state_mapping=mapping, collect_losses=return_losses\n         ) as scope:\n             if self.dtype_policy.quantization_mode is not None:\n+                if self._remat_mode is not None:\n+                    outputs = self.rematerialized_call(\n+                        self.quantized_call, *args, **kwargs\n+                    )\n+                else:\n                     outputs = self.quantized_call(*args, **kwargs)\n+            elif self._remat_mode is not None:\n+                outputs = self.rematerialized_call(self.call, *args, **kwargs)\n             else:\n                 outputs = self.call(*args, **kwargs)\n             if return_losses:\n@@ -1221,6 +1230,19 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n             )\n \n     def quantized_call(self, *args, **kwargs):\n+        current_remat_mode = get_current_remat_mode()\n+\n+        if (\n+            current_remat_mode != self._remat_mode\n+            and current_remat_mode is not None\n+        ):\n+            warnings.warn(\n+                f\"The RematScope at call time ({current_remat_mode}) differs \"\n+                f\"the one set during layer initialization \"\n+                f\"({self._remat_mode}). \"\n+                f\"Restoring the correct rematerialization mode \"\n+                f\"{self._remat_mode} for this layer.\"\n+            )\n         if self.quantization_mode == \"int8\":\n             return self._int8_call(*args, **kwargs)\n         elif self.quantization_mode == \"float8\":\n@@ -1560,6 +1582,58 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n             self._parent_path = current_path()\n         return backend.name_scope(self.name, caller=self)\n \n+    def rematerialized_call(self, layer_call, *args, **kwargs):\n+        \"\"\"Enable rematerialization dynamically for layer's call method.\n+\n+        Args:\n+            layer_call: The original `call` method of a layer.\n+\n+        Returns:\n+            Rematerialized layer's `call` method.\n+        \"\"\"\n+\n+        def compute_size(x):\n+            return (\n+                math.prod([d or 1 for d in x.shape])\n+                if isinstance(x, KerasTensor)\n+                else 0\n+            )\n+\n+        # Full rematerialization\n+        if self._remat_mode.mode == \"full\":\n+            return remat.remat(layer_call)(*args, **kwargs)\n+\n+        # Apply rematerialization to specific layers\n+        elif self._remat_mode.mode == \"list_of_layers\" and (\n+            self.name in self._remat_mode.layer_names\n+        ):\n+            return remat.remat(layer_call)(*args, **kwargs)\n+\n+        # Apply rematerialization based on output size threshold\n+        elif self._remat_mode.mode == \"larger_than\":\n+            output_spec = self.compute_output_spec(*args, **kwargs)\n+            output_size = sum(\n+                tree.flatten(tree.map_structure(compute_size, output_spec))\n+            )\n+            if (\n+                output_size\n+                and output_size > self._remat_mode.output_size_threshold\n+            ):\n+                return remat.remat(layer_call)(*args, **kwargs)\n+        elif self._remat_mode.mode == \"activations\":\n+            has_activation = (\n+                hasattr(self, \"activation\") and self.activation is not None\n+            )\n+            if has_activation:\n+                not_rematted_activation = self.activation\n+                try:\n+                    self.activation = remat.remat(not_rematted_activation)\n+                    return layer_call(*args, **kwargs)\n+                finally:\n+                    self.activation = not_rematted_activation\n+\n+        return layer_call(*args, **kwargs)\n+\n \n def is_backend_tensor_or_symbolic(x, allow_none=False):\n     if allow_none and x is None:\n\n@@ -1,9 +1,11 @@\n import pickle\n+from unittest.mock import patch\n \n import numpy as np\n import pytest\n from absl.testing import parameterized\n \n+from keras.src import Input\n from keras.src import backend\n from keras.src import dtype_policies\n from keras.src import layers\n@@ -12,6 +14,9 @@ from keras.src import models\n from keras.src import ops\n from keras.src import testing\n from keras.src.backend.common import global_state\n+from keras.src.backend.common import remat\n+from keras.src.backend.common.remat import RematScope\n+from keras.src.models import Model\n \n \n class LayerTest(testing.TestCase):\n@@ -165,6 +170,159 @@ class LayerTest(testing.TestCase):\n             else:\n                 getattr(layer, method)(args)\n \n+    def test_layer_with_remat(self):\n+        \"\"\"Test rematerialization on a simple layer.\"\"\"\n+        # Create a mock to track calls to remat\n+        with patch(\n+            \"keras.src.backend.common.remat.remat\", wraps=remat.remat\n+        ) as mock_remat:\n+\n+            class SomeLayer(layers.Layer):\n+                def call(self, x):\n+                    return x + 1\n+\n+            input_tensor = backend.random.uniform((2, 4))\n+            layer = SomeLayer()\n+            # Case 1: Without rematerialization\n+            output_no_remat = layer(input_tensor)\n+\n+            # Case 2: With rematerialization\n+            with RematScope(mode=\"full\"):\n+                layer = SomeLayer()\n+                output_with_remat = layer(input_tensor)\n+\n+            # Assert outputs are the same\n+            self.assertAllClose(output_no_remat, output_with_remat)\n+\n+            # Ensure remat was applied in the second case\n+            mock_remat.assert_called()\n+\n+    def test_quantized_layer_with_remat(self):\n+        \"\"\"Test rematerialization on a quantized layer.\"\"\"\n+        with patch(\n+            \"keras.src.backend.common.remat.remat\", wraps=remat.remat\n+        ) as mock_remat:\n+            input_tensor = backend.random.uniform((2, 4))\n+\n+            # Case 2: With rematerialization\n+            with RematScope(mode=\"full\"):\n+                layer = layers.Dense(3)\n+                layer.build((2, 4))\n+                layer.quantize(\"float8\")\n+                layer(input_tensor)\n+\n+            # Ensure remat was applied\n+            mock_remat.assert_called()\n+\n+    def test_functional_model_with_remat(self):\n+        if backend.backend() in (\"openvino\", \"numpy\") or testing.jax_uses_gpu():\n+            self.skipTest(\n+                \"remat is not supported in openvino and numpy backends.\"\n+            )\n+        with patch(\n+            \"keras.src.backend.common.remat.remat\", wraps=remat.remat\n+        ) as mock_remat:\n+            # Define model inputs\n+            inputs = Input(shape=(32, 32, 3))\n+\n+            # just one layer in remat scope\n+            with RematScope(mode=\"full\"):\n+                layer = layers.Conv2D(\n+                    64, (3, 3), activation=\"relu\", data_format=\"channels_last\"\n+                )\n+                output = layer(inputs)\n+\n+            # Build the functional model\n+            model = Model(inputs=inputs, outputs=output)\n+\n+            # Compile the model\n+            model.compile(optimizer=\"adam\", loss=\"mse\")\n+\n+            # Generate dummy data for testing\n+            x_train = np.random.random((10, 32, 32, 3)).astype(np.float32)\n+            y_train = np.random.random((10, 30, 30, 64)).astype(np.float32)\n+\n+            # Run training to ensure `RematScope` is applied correctly\n+            model.fit(x_train, y_train, epochs=1, batch_size=2)\n+            self.assertGreater(mock_remat.call_count, 1)\n+\n+    def test_remat_wrapper_list_of_layers(self):\n+        \"\"\"Test rematerialization using list_of_layers mode.\"\"\"\n+        with patch(\n+            \"keras.src.backend.common.remat.remat\", wraps=remat.remat\n+        ) as mock_remat:\n+\n+            class TestLayer(layers.Layer):\n+                def call(self, x):\n+                    return x + 1\n+\n+            class OtherLayer(layers.Layer):\n+                def call(self, x):\n+                    return x * 2\n+\n+            remat_layers = [\"test_layer\"]\n+            input_tensor = backend.random.uniform((4, 4))\n+\n+            with RematScope(mode=\"list_of_layers\", layer_names=remat_layers):\n+                test_layer = TestLayer(name=\"test_layer\")\n+                other_layer = OtherLayer(name=\"other_layer\")\n+                output_test = test_layer(input_tensor)\n+                output_other = other_layer(input_tensor)\n+\n+            self.assertAllClose(output_test, input_tensor + 1)\n+            self.assertAllClose(output_other, input_tensor * 2)\n+\n+            # Ensure remat was applied to the correct layer\n+            mock_remat.assert_called_once()\n+\n+    def test_remat_larger_than_mode(self):\n+        \"\"\"Test rematerialization using larger_than mode.\"\"\"\n+        with patch(\n+            \"keras.src.backend.common.remat.remat\", wraps=remat.remat\n+        ) as mock_remat:\n+\n+            class TestLayer(layers.Layer):\n+                def compute_output_shape(self, input_shape):\n+                    return input_shape\n+\n+                def call(self, x):\n+                    return x + 1\n+\n+            input_tensor = backend.random.uniform((100, 100))  # Large tensor\n+\n+            with RematScope(mode=\"larger_than\", output_size_threshold=5000):\n+                layer = TestLayer()\n+                output = layer(input_tensor)\n+\n+            self.assertAllClose(output, input_tensor + 1)\n+\n+            # Ensure remat was applied\n+            mock_remat.assert_called()\n+\n+    def test_remat_larger_than_mode_high_threshold(self):\n+        \"\"\"Test rematerialization using larger_than mode.\"\"\"\n+        with patch(\n+            \"keras.src.backend.common.remat.remat\", wraps=remat.remat\n+        ) as mock_remat:\n+\n+            class TestLayer(layers.Layer):\n+                def compute_output_shape(self, input_shape):\n+                    return input_shape\n+\n+                def call(self, x):\n+                    return x + 1\n+\n+            input_tensor = backend.random.uniform((100, 100))  # Large tensor\n+\n+            with RematScope(mode=\"larger_than\", output_size_threshold=50000):\n+                layer = TestLayer()\n+                output = layer(input_tensor)\n+\n+            self.assertAllClose(output, input_tensor + 1)\n+\n+            # Ensure remat was applied\n+            mock_remat.assert_not_called()\n+\n     def test_rng_seed_tracking(self):\n         class RNGLayer(layers.Layer):\n             def __init__(self):\n\n@@ -34,6 +34,12 @@ class Operation:\n             # Wrap self.call to provide helpful info in case of exception\n             if any_symbolic_tensors(args, kwargs):\n                 call_fn = self.symbolic_call\n+            else:\n+                if getattr(self, \"_remat_mode\", None) is not None:\n+                    if getattr(self, \"quantization_mode\", None) is not None:\n+                        call_fn = self.rematerialized_call(self.quantized_call)\n+                    else:\n+                        call_fn = self.rematerialized_call(self.call)\n                 else:\n                     if getattr(self, \"quantization_mode\", None) is not None:\n                         call_fn = self.quantized_call\n@@ -48,6 +54,14 @@ class Operation:\n         # Plain flow.\n         if any_symbolic_tensors(args, kwargs):\n             return self.symbolic_call(*args, **kwargs)\n+        elif getattr(self, \"_remat_mode\", None) is not None:\n+            if getattr(self, \"quantization_mode\", None) is not None:\n+                return self.rematerialized_call(\n+                    self.quantized_call, *args, **kwargs\n+                )\n+            else:\n+                return self.rematerialized_call(self.call, *args, **kwargs)\n+        else:\n             if getattr(self, \"quantization_mode\", None) is not None:\n                 return self.quantized_call(*args, **kwargs)\n             else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
