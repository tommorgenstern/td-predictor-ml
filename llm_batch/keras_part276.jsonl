{"custom_id": "keras#09d721abf489cf20d9055e7163cf1762b7763bea", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 10549 | Contributors (this commit): 122 | Commits (past 90d): 25 | Contributors (cumulative): 123 | DMM Complexity: 1.0\n\nDIFF:\n@@ -257,11 +257,12 @@ def in_test_phase(x, alt, training=None):\n \n \n def relu(x, alpha=0., max_value=None, threshold=0.):\n-    y = x * (x >= threshold)\n-    if max_value is not None:\n-        y = np.clip(y, 0.0, max_value)\n-    y += alpha * (x - threshold) * (x < threshold)\n-    return y\n+    if max_value is None:\n+        max_value = np.inf\n+    above_threshold = x * (x >= threshold)\n+    above_threshold = np.clip(above_threshold, 0.0, max_value)\n+    below_threshold = alpha * (x - threshold) * (x < threshold)\n+    return below_threshold + above_threshold\n \n \n def switch(condition, then_expression, else_expression):\n\n@@ -3281,6 +3281,8 @@ def relu(x, alpha=0., max_value=None, threshold=0.):\n \n     # Returns\n         A tensor.\n+\n+    {{np_implementation}}\n     \"\"\"\n \n     if alpha != 0.:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fcf2ed7831185a282895dda193217c2a97e1e41d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 665 | Contributors (this commit): 11 | Commits (past 90d): 2 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -137,7 +137,7 @@ input_tensor = K.concatenate([base_image,\n                               style_reference_image,\n                               combination_image], axis=0)\n \n-# build the VGG16 network with our 3 images as input\n+# build the VGG19 network with our 3 images as input\n # the model will be loaded with pre-trained ImageNet weights\n model = vgg19.VGG19(input_tensor=input_tensor,\n                     weights='imagenet', include_top=False)\n@@ -175,7 +175,7 @@ def style_loss(style, combination):\n     C = gram_matrix(combination)\n     channels = 3\n     size = img_nrows * img_ncols\n-    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n+    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))\n \n # an auxiliary loss function\n # designed to maintain the \"content\" of the\n@@ -204,7 +204,7 @@ def total_variation_loss(x):\n     return K.sum(K.pow(a + b, 1.25))\n \n # combine these loss functions into a single scalar\n-loss = K.variable(0.)\n+loss = K.variable(0.0)\n layer_features = outputs_dict['block5_conv2']\n base_image_features = layer_features[0, :, :, :]\n combination_features = layer_features[2, :, :, :]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1df40521857697867922425db7a708a6c6c78289", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 10 | Methods Changed: 10 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 20 | Churn Cumulative: 10546 | Contributors (this commit): 122 | Commits (past 90d): 19 | Contributors (cumulative): 122 | DMM Complexity: None\n\nDIFF:\n@@ -1321,6 +1321,8 @@ def max(x, axis=None, keepdims=False):\n \n     # Returns\n         A tensor with maximum values of `x`.\n+\n+    {{np_implementation}}\n     \"\"\"\n     return tf.reduce_max(x, axis, keepdims)\n \n@@ -1340,6 +1342,8 @@ def min(x, axis=None, keepdims=False):\n \n     # Returns\n         A tensor with miminum values of `x`.\n+\n+    {{np_implementation}}\n     \"\"\"\n     return tf.reduce_min(x, axis, keepdims)\n \n@@ -1359,6 +1363,8 @@ def sum(x, axis=None, keepdims=False):\n \n     # Returns\n         A tensor with sum of `x`.\n+\n+    {{np_implementation}}\n     \"\"\"\n     return tf.reduce_sum(x, axis, keepdims)\n \n@@ -1378,6 +1384,8 @@ def prod(x, axis=None, keepdims=False):\n \n     # Returns\n         A tensor with the product of elements of `x`.\n+\n+    {{np_implementation}}\n     \"\"\"\n     return tf.reduce_prod(x, axis, keepdims)\n \n@@ -3326,6 +3334,8 @@ def elu(x, alpha=1.):\n \n     # Returns\n         A tensor.\n+\n+    {{np_implementation}}\n     \"\"\"\n     res = tf.nn.elu(x)\n     if alpha == 1:\n@@ -3344,6 +3354,8 @@ def softmax(x, axis=-1):\n \n     # Returns\n         A tensor.\n+\n+    {{np_implementation}}\n     \"\"\"\n     return tf.nn.softmax(x, axis=axis)\n \n@@ -3356,6 +3368,8 @@ def softplus(x):\n \n     # Returns\n         A tensor.\n+\n+    {{np_implementation}}\n     \"\"\"\n     return tf.nn.softplus(x)\n \n@@ -3504,6 +3518,8 @@ def sigmoid(x):\n \n     # Returns\n         A tensor.\n+\n+    {{np_implementation}}\n     \"\"\"\n     return tf.nn.sigmoid(x)\n \n@@ -3538,6 +3554,8 @@ def tanh(x):\n \n     # Returns\n         A tensor.\n+\n+    {{np_implementation}}\n     \"\"\"\n     return tf.nn.tanh(x)\n \n@@ -3573,6 +3591,8 @@ def l2_normalize(x, axis=None):\n \n     # Returns\n         A tensor.\n+\n+    {{np_implementation}}\n     \"\"\"\n     return tf.nn.l2_normalize(x, axis=axis)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8b59e31d2b1d854a1eae585db7bd1582ef95c978", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1708 | Contributors (this commit): 15 | Commits (past 90d): 10 | Contributors (cumulative): 21 | DMM Complexity: None\n\nDIFF:\n@@ -23,7 +23,7 @@ from keras.utils.data_utils import validate_file\n from keras import backend as K\n \n pytestmark = pytest.mark.skipif(\n-    K.backend() == 'tensorflow' and 'TRAVIS_PYTHON_VERSION' in os.environ,\n+    K.backend() in {'tensorflow', 'cntk'} and 'TRAVIS_PYTHON_VERSION' in os.environ,\n     reason='Temporarily disabled until the use_multiprocessing problem is solved')\n \n if sys.version_info < (3,):\n\n@@ -9,7 +9,7 @@ from keras.utils import Sequence\n from keras import backend as K\n \n pytestmark = pytest.mark.skipif(\n-    K.backend() == 'tensorflow' and 'TRAVIS_PYTHON_VERSION' in os.environ,\n+    K.backend() in {'tensorflow', 'cntk'} and 'TRAVIS_PYTHON_VERSION' in os.environ,\n     reason='Temporarily disabled until the use_multiprocessing problem is solved')\n \n STEPS_PER_EPOCH = 100\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#63543a7e35639e8b0b8bce6bb3f80406bb925cf3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 3232 | Contributors (this commit): 82 | Commits (past 90d): 14 | Contributors (cumulative): 82 | DMM Complexity: None\n\nDIFF:\n@@ -669,7 +669,7 @@ class LearningRateScheduler(Callback):\n class TensorBoard(Callback):\n     \"\"\"TensorBoard basic visualizations.\n \n-    [TensorBoard](https://www.tensorflow.org/get_started/summaries_and_tensorboard)\n+    [TensorBoard](https://www.tensorflow.org/guide/summaries_and_tensorboard)\n     is a visualization tool provided with TensorFlow.\n \n     This callback writes a log for TensorBoard, which allows\n@@ -711,14 +711,14 @@ class TensorBoard(Callback):\n             None or empty list all the embedding layer will be watched.\n         embeddings_metadata: a dictionary which maps layer name to a file name\n             in which metadata for this embedding layer is saved. See the\n-            [details](https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional)\n+            [details](https://www.tensorflow.org/guide/embedding#metadata)\n             about metadata files format. In case if the same metadata file is\n             used for all embedding layers, string can be passed.\n         embeddings_data: data to be embedded at layers specified in\n             `embeddings_layer_names`. Numpy array (if the model has a single\n             input) or list of Numpy arrays (if the model has multiple inputs).\n             Learn [more about embeddings](\n-            https://www.tensorflow.org/programmers_guide/embedding).\n+            https://www.tensorflow.org/guide/embedding).\n         update_freq: `'batch'` or `'epoch'` or integer. When using `'batch'`, writes\n             the losses and metrics to TensorBoard after each batch. The same\n             applies for `'epoch'`. If using an integer, let's say `10000`,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#75a35032e194a2d065b0071a9e786adf6cee83ea", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 10550 | Contributors (this commit): 123 | Commits (past 90d): 20 | Contributors (cumulative): 123 | DMM Complexity: None\n\nDIFF:\n@@ -1110,7 +1110,7 @@ def batch_dot(x, y, axes=None):\n     # Arguments\n         x: Keras tensor or variable with `ndim >= 2`.\n         y: Keras tensor or variable with `ndim >= 2`.\n-        axes: int or tupe(int, int). Target dimensions to be reduced.\n+        axes: int or tuple(int, int). Target dimensions to be reduced.\n \n     # Returns\n         A tensor with shape equal to the concatenation of `x`'s shape\n@@ -1129,7 +1129,7 @@ def batch_dot(x, y, axes=None):\n         inner_products = []\n         for xi, yi in zip(x, y):\n             inner_products.append(xi.dot(yi))\n-        result = stack(inner_prodcuts)\n+        result = stack(inner_products)\n         ```\n \n         Shape inference:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e6994347f214ee8a4c2917b88a89f24f889aefcf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1702 | Contributors (this commit): 13 | Commits (past 90d): 8 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -249,7 +249,7 @@ def _deserialize_model(h5dict, custom_objects=None, compile=True):\n     for name in layer_names:\n         layer_weights = model_weights_group[name]\n         weight_names = layer_weights['weight_names']\n-        if weight_names:\n+        if len(weight_names) > 0:\n             filtered_layer_names.append(name)\n \n     layer_names = filtered_layer_names\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bd2968348c330dcb497d114f4b9f9783552113cb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 93 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -71,8 +71,8 @@ def test_min_max_norm():\n         normed = norm_instance(K.variable(array))\n         value = K.eval(normed)\n         l2 = np.sqrt(np.sum(np.square(value), axis=0))\n-        assert not l2[l2 < m]\n-        assert not l2[l2 > m * 2 + 1e-5]\n+        assert l2[l2 < m].size == 0\n+        assert l2[l2 > m * 2 + 1e-5].size == 0\n \n \n if __name__ == '__main__':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dcb5e3cf152977209c7122f6b07d6c86fb4cf1e6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 682 | Contributors (this commit): 12 | Commits (past 90d): 4 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -76,8 +76,8 @@ def build_generator(latent_size):\n     # this will be our label\n     image_class = Input(shape=(1,), dtype='int32')\n \n-    cls = Flatten()(Embedding(num_classes, latent_size,\n-                              embeddings_initializer='glorot_normal')(image_class))\n+    cls = Embedding(num_classes, latent_size,\n+                    embeddings_initializer='glorot_normal')(image_class)\n \n     # hadamard product between z-space and a class conditional embedding\n     h = layers.multiply([latent, cls])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9eaa40b22ec3b10e22bf561cd3f5a9b4b7aa0745", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1854 | Contributors (this commit): 31 | Commits (past 90d): 9 | Contributors (cumulative): 31 | DMM Complexity: None\n\nDIFF:\n@@ -175,6 +175,7 @@ PAGES = [\n             layers.Conv2D,\n             layers.SeparableConv1D,\n             layers.SeparableConv2D,\n+            layers.DepthwiseConv2D,\n             layers.Conv2DTranspose,\n             layers.Conv3D,\n             layers.Conv3DTranspose,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#65cea92a66211e1116fe9faea774ca66b09461e7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 983 | Contributors (this commit): 17 | Commits (past 90d): 1 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -10,3 +10,4 @@ text_to_word_sequence = text.text_to_word_sequence\n one_hot = text.one_hot\n hashing_trick = text.hashing_trick\n Tokenizer = text.Tokenizer\n+tokenizer_from_json = text.tokenizer_from_json\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#edd0c0a4bd4cea027842bc8925048976d65b1ae9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 129 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): 24/22 | Churn Δ: 138 | Churn Cumulative: 16827 | Contributors (this commit): 131 | Commits (past 90d): 64 | Contributors (cumulative): 157 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1221,26 +1221,131 @@ def batch_dot(x, y, axes=None):\n                          ' with axes=' + str(axes) + '. x.shape[%d] != '\n                          'y.shape[%d] (%d != %d).' % (axes[0], axes[1], d1, d2))\n \n-    # bring the dimensions to be reduced to axis 1\n-    if a0 != 1:\n+    # There are 2 ways to perform theano's batched_tensordot in tensorflow:\n+    # 1) Elementwise multiplication followed by tf.reduce_sum. This requires\n+    # more memory but works with partial shape information.\n+    # 2) Using tf.matmul. This is more efficient but all dimensions except\n+    # batch size should be known for input with rank > 3.\n+\n+    if x_ndim > 3:\n+        if None in x_shape[1:]:\n+            x_matmullabe = False\n+        else:\n+            x_matmullabe = True\n+    else:\n+        x_matmullabe = True\n+\n+    if y_ndim > 3:\n+        if None in y_shape[1:]:\n+            y_matmullabe = False\n+        else:\n+            y_matmullabe = True\n+    else:\n+        y_matmullabe = True\n+\n+    use_matmul = x_matmullabe and y_matmullabe\n+\n+    if use_matmul:\n+        # backup ndims. Need them later.\n+        orig_x_ndim = x_ndim\n+        orig_y_ndim = y_ndim\n+\n+        # if rank is 2, expand to 3.\n+        if x_ndim == 2:\n+            x = tf.expand_dims(x, 1)\n+            a0 += 1\n+            x_ndim += 1\n+        if y_ndim == 2:\n+            y = tf.expand_dims(y, 2)\n+            y_ndim += 1\n+\n+        # bring x's dimension to be reduced to last axis.\n+        if a0 != x_ndim - 1:\n             pattern = list(range(x_ndim))\n-        for i in range(a0, 1, -1):\n-            pattern[i] = pattern[i - 1]\n-        pattern[1] = a0\n-        x = permute_dimensions(x, pattern)\n+            for i in range(a0, x_ndim - 1):\n+                pattern[i] = pattern[i + 1]\n+            pattern[-1] = a0\n+            x = tf.transpose(x, pattern)\n+\n+        # bring y's dimension to be reduced to axis 1.\n         if a1 != 1:\n             pattern = list(range(y_ndim))\n             for i in range(a1, 1, -1):\n                 pattern[i] = pattern[i - 1]\n             pattern[1] = a1\n-        y = permute_dimensions(y, pattern)\n+            y = tf.transpose(y, pattern)\n \n-    # reshape to closest broadcastable shape\n+        # normalize both inputs to rank 3.\n+        if x_ndim > 3:\n+            # squash middle dimensions of x.\n+            x_shape = list(int_shape(x))\n+            x_mid_dims = x_shape[1:-1]\n+            x_squashed_dim = np.prod(x_mid_dims)\n+            if x_batch_size is None:\n+                x_batch_size = -1\n+            x = tf.reshape(x, [x_batch_size, x_squashed_dim, x_shape[-1]])\n+            x_squashed = True\n+        else:\n+            x_squashed = False\n+        if y_ndim > 3:\n+            # squash trailing dimensions of y\n+            y_shape = list(int_shape(y))\n+            y_trail_dims = y_shape[2:]\n+            y_squashed_dim = np.prod(y_trail_dims)\n+            if y_batch_size is None:\n+                y_batch_size = -1\n+            y = tf.reshape(y, [y_batch_size, y_shape[1], y_squashed_dim])\n+            y_squashed = True\n+        else:\n+            y_squashed = False\n+\n+        result = tf.matmul(x, y)\n+\n+        # if inputs were squashed, we have to reshape the matmul output.\n+        output_shape = list(int_shape(result))\n+        do_reshape = False\n+        if x_squashed:\n+            output_shape = [output_shape[0]] + x_mid_dims + [output_shape[-1]]\n+            do_reshape = True\n+        if y_squashed:\n+            output_shape = output_shape[:-1] + y_trail_dims\n+            do_reshape = True\n+\n+        if do_reshape:\n+            if output_shape[0] is None:\n+                output_shape[0] = -1\n+            result = tf.reshape(result, output_shape)\n+\n+        # if the inputs were originally rank 2, we remove the added 1 dim.\n+        if orig_x_ndim == 2:\n+            result = tf.squeeze(result, 1)\n+        elif orig_y_ndim == 2:\n+            result = tf.squeeze(result, -1)\n+    else:\n+\n+        # bring the dimension to be reduced to axis 1.\n+        if a0 != 1:\n+            pattern = list(range(x_ndim))\n+            for i in range(a0, 1, -1):\n+                pattern[i] = pattern[i - 1]\n+            pattern[1] = a0\n+            x = tf.transpose(x, pattern)\n+\n+        if a1 != 1:\n+            pattern = list(range(y_ndim))\n+            for i in range(a1, 1, -1):\n+                pattern[i] = pattern[i - 1]\n+            pattern[1] = a1\n+            y = tf.transpose(y, pattern)\n+\n+        # reshape to closest broadcastable shape.\n         x_shape = tf.shape(x)\n         y_shape = tf.shape(y)\n \n         new_x_shape = tf.concat([x_shape, tf.ones_like(y_shape[2:])], 0)\n-    new_y_shape = tf.concat([y_shape[:2], tf.ones_like(x_shape[2:]), y_shape[2:]], 0)\n+        new_y_shape = tf.concat([y_shape[:2],\n+                                tf.ones_like(x_shape[2:]),\n+                                y_shape[2:]], 0)\n \n         x = reshape(x, new_x_shape)\n         y = reshape(y, new_y_shape)\n\n@@ -291,6 +291,21 @@ class TestBackend(object):\n \n             assert_allclose(f([x_np, y_np])[0], z_np, atol=1e-05)\n \n+            # test with placeholders (no shape info)\n+            if K.backend() != 'cntk':\n+                x = K.placeholder(ndim=len(x_shape))\n+                y = K.placeholder(ndim=len(y_shape))\n+                z = K.batch_dot(x, y, axes)\n+\n+                z_shape = K.int_shape(z)\n+                if z_shape is not None:\n+                    assert len(z_shape) == z_np.ndim\n+                    assert set(z_shape) <= set((None, 1))\n+\n+                f = K.function([x, y], [z])\n+\n+                assert_allclose(f([x_np, y_np])[0], z_np, atol=1e-05)\n+\n             # test with variables\n             x = K.variable(x_np)\n             y = K.variable(y_np)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cd44c6e0aaff4bb52a060d778025b32dbde09b44", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 12 | Churn Cumulative: 12 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,12 @@\n+import warnings\r\n+import pytest\r\n+\r\n+\r\n+@pytest.fixture(autouse=True)\r\n+def clear_session_after_test():\r\n+    \"\"\"This wrapper runs for all the tests in the legacy directory (recursively).\r\n+    \"\"\"\r\n+    with warnings.catch_warnings():\r\n+        warnings.filterwarnings('ignore', message=r'(.+) Keras 2 ',\r\n+                                category=UserWarning)\r\n+        yield\r\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1c221934aaeab20ed5b6fa245b33b00a8b557533", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 189 | Lines Deleted: 155 | Files Changed: 3 | Hunks: 34 | Methods Changed: 20 | Complexity Δ (Sum/Max): 16/13 | Churn Δ: 344 | Churn Cumulative: 17194 | Contributors (this commit): 131 | Commits (past 90d): 63 | Contributors (cumulative): 159 | DMM Complexity: 0.0\n\nDIFF:\n@@ -185,43 +185,52 @@ def bias_add(x, y, data_format):\n     return x + y\n \n \n-def rnn(x, w, init, go_backwards=False, mask=None, unroll=False, input_length=None):\n-    w_i, w_h, w_o = w\n-    h = []\n-    o = []\n+def rnn(step_function, inputs, initial_states,\n+        go_backwards=False, mask=None, constants=None,\n+        unroll=False, input_length=None):\n \n-    if go_backwards:\n-        t_list = range(x.shape[1] - 1, -1, -1)\n-    else:\n-        t_list = range(x.shape[1])\n+    if constants is None:\n+        constants = []\n \n+    output_sample, _ = step_function(inputs[:, 0], initial_states + constants)\n     if mask is not None:\n-        from keras import backend as K\n-        np_mask = K.eval(mask)\n-    else:\n-        np_mask = None\n+        if mask.dtype != np.bool:\n+            mask = mask.astype(np.bool)\n+        if mask.shape != inputs.shape[:2]:\n+            raise ValueError(\n+                'mask should have `shape=(samples, time)`, '\n+                'got {}'.format(mask.shape))\n \n-    for (i, t) in enumerate(t_list):\n-        h_t = np.dot(x[:, t], w_i)\n+        def expand_mask(mask_, x):\n+            # expand mask so that `mask[:, t].ndim == x.ndim`\n+            while mask_.ndim < x.ndim + 1:\n+                mask_ = np.expand_dims(mask_, axis=-1)\n+            return mask_\n+        output_mask = expand_mask(mask, output_sample)\n+        states_masks = [expand_mask(mask, state) for state in initial_states]\n \n-        if w_h is not None:\n-            prev = h[i - 1] if i > 0 else init\n-            h_t1 = np.dot(prev, w_h)\n-            if np_mask is not None:\n-                h_t1[np_mask[:, t] == 0] = prev[np_mask[:, t] == 0]\n-        else:\n-            h_t1 = 0\n+    if input_length is None:\n+        input_length = inputs.shape[1]\n+    assert input_length == inputs.shape[1]\n+    time_index = range(input_length)\n+    if go_backwards:\n+        time_index = time_index[::-1]\n \n-        o_t = h_t + h_t1\n-        if w_o is not None:\n-            o_t = np.dot(o_t, w_o)\n-        o.append(o_t)\n+    outputs = []\n+    states_tm1 = initial_states  # tm1 means \"t minus one\" as in \"previous timestep\"\n+    output_tm1 = np.zeros(output_sample.shape)\n+    for t in time_index:\n+        output_t, states_t = step_function(inputs[:, t], states_tm1 + constants)\n+        if mask is not None:\n+            output_t = np.where(output_mask[:, t], output_t, output_tm1)\n+            states_t = [np.where(state_mask[:, t], state_t, state_tm1)\n+                        for state_mask, state_t, state_tm1\n+                        in zip(states_masks, states_t, states_tm1)]\n+        outputs.append(output_t)\n+        states_tm1 = states_t\n+        output_tm1 = output_t\n \n-        if np_mask is not None:\n-            h_t = h_t * np_mask[:, t].reshape(-1, 1)\n-        h.append(h_t + h_t1)\n-\n-    return o[-1], np.stack(o, axis=1), np.stack(h, axis=1)\n+    return outputs[-1], np.stack(outputs, axis=1), states_tm1\n \n \n _LEARNING_PHASE = True\n\n@@ -3042,6 +3042,8 @@ def rnn(step_function, inputs, initial_states,\n             but input timestep is not a fixed number.\n         ValueError: If `mask` is provided (not `None`)\n             but states is not provided (`len(states)` == 0).\n+\n+    {{np_implementation}}\n     \"\"\"\n     ndim = len(inputs.shape)\n     if ndim < 3:\n@@ -3157,10 +3159,6 @@ def rnn(step_function, inputs, initial_states,\n             'maximum_iterations': input_length}\n \n         if mask is not None:\n-            if not states:\n-                raise ValueError('No initial states provided! '\n-                                 'When using masking in an RNN, you should '\n-                                 'provide initial states')\n             if go_backwards:\n                 mask = reverse(mask, 0)\n \n\n@@ -177,6 +177,55 @@ def check_composed_tensor_operations(first_function_name,\n     assert_list_pairwise(z_list)\n \n \n+def check_rnn_operation(step_function_k,\n+                        step_function_np,\n+                        inputs_np,\n+                        initial_states_np,\n+                        mask_np=None,\n+                        constants_np=None,\n+                        **kwargs):\n+    inputs_k = K.variable(inputs_np)\n+    initial_states_k = [K.variable(s) for s in initial_states_np]\n+    if mask_np is not None:\n+        mask_k = K.variable(mask_np)\n+    else:\n+        mask_k = None\n+    if constants_np is not None:\n+        constants_k = [K.variable(c) for c in constants_np]\n+    else:\n+        constants_k = None\n+\n+    last_output_np, output_np, last_states_np = KNP.rnn(\n+        step_function_np,\n+        inputs_np,\n+        initial_states_np,\n+        mask=mask_np,\n+        constants=constants_np,\n+        **kwargs)\n+    # note that numpy reference implementation is independent of `unroll` argument\n+\n+    for unroll in [True, False]:\n+        last_output_k, output_k, last_states_k = K.rnn(\n+            step_function_k,\n+            inputs_k,\n+            initial_states_k,\n+            mask=mask_k,\n+            constants=constants_k,\n+            unroll=unroll,\n+            input_length=inputs_np.shape[1] if unroll else None,\n+            **kwargs)\n+\n+        last_states_k = [K.eval(s) for s in last_states_k]\n+        last_output_k = K.eval(last_output_k)\n+        output_k = K.eval(output_k)\n+\n+        assert_allclose(last_output_k, last_output_np, atol=1e-05)\n+        assert_allclose(output_k, output_np, atol=1e-05)\n+        assert len(last_states_k) == len(last_states_np)\n+        for s_k, s_np in zip(last_states_k, last_states_np):\n+            assert_allclose(s_k, s_np, atol=1e-05)\n+\n+\n class TestBackend(object):\n \n     def test_is_keras_tensor(self):\n@@ -672,65 +721,32 @@ class TestBackend(object):\n         _, wh = parse_shape_or_val((output_dim, output_dim))\n         mask = np.random.randint(2, size=(num_samples, timesteps))\n \n-        x_k = K.variable(x)\n-        h0_k = [K.variable(h0)]\n         wi_k = K.variable(wi)\n         wh_k = K.variable(wh)\n-        mask_k = K.variable(mask)\n \n-        def rnn_fn(x_k, h_k):\n-            assert len(h_k) == 1\n-            y_k = K.dot(x_k, wi_k) + K.dot(h_k[0], wh_k)\n-            return y_k, [y_k]\n+        def get_step_function(backend, w_i, w_h):\n \n-        # test default setup\n-        last_output_list = []\n-        outputs_list = []\n-        state_list = []\n+            def simple_rnn(inputs, states):\n+                assert len(states) == 1\n+                h = states[0]\n+                y = backend.dot(inputs, w_i) + backend.dot(h, w_h)\n+                return y, [y]\n+\n+            return simple_rnn\n \n         kwargs_list = [\n             {'go_backwards': False, 'mask': None},\n-            {'go_backwards': False, 'mask': None, 'unroll': True,\n-             'input_length': timesteps},\n             {'go_backwards': True, 'mask': None},\n-            {'go_backwards': True, 'mask': None, 'unroll': True,\n-             'input_length': timesteps},\n-            {'go_backwards': False, 'mask': mask_k},\n-            {'go_backwards': False, 'mask': mask_k, 'unroll': True,\n-             'input_length': timesteps},\n+            {'go_backwards': False, 'mask': mask},\n+            {'go_backwards': True, 'mask': mask},\n         ]\n-\n-        for (i, kwargs) in enumerate(kwargs_list):\n-            last_y1, y1, h1 = KNP.rnn(x, [wi, wh, None], h0, **kwargs)\n-            last_y2, y2, h2 = K.rnn(rnn_fn, x_k, h0_k, **kwargs)\n-\n-            assert len(h2) == 1\n-            last_y2 = K.eval(last_y2)\n-            y2 = K.eval(y2)\n-            h1 = h1[:, -1]\n-            h2 = K.eval(h2[0])\n-\n-            if kwargs['mask'] is not None:\n-                last_y1 = last_y1 * np.expand_dims(mask[:, -1], -1)\n-                last_y2 = last_y2 * np.expand_dims(mask[:, -1], -1)\n-                y1 = y1 * np.expand_dims(mask, -1)\n-                y2 = y2 * np.expand_dims(mask, -1)\n-                h1 = h1 * np.expand_dims(mask[:, -1], -1)\n-                h2 = h2 * np.expand_dims(mask[:, -1], -1)\n-\n-            last_output_list.append(last_y2)\n-            outputs_list.append(y2)\n-            state_list.append(h2)\n-\n-            if i % 2 == 0:\n-                assert_allclose(last_y1, last_y2, atol=1e-05)\n-                assert_allclose(y1, y2, atol=1e-05)\n-                assert_allclose(h1, h2, atol=1e-05)\n-            else:\n-                assert_allclose(last_output_list[i - 1], last_output_list[i],\n-                                atol=1e-05)\n-                assert_allclose(outputs_list[i - 1], outputs_list[i], atol=1e-05)\n-                assert_allclose(state_list[i - 1], state_list[i], atol=1e-05)\n+        for kwargs in kwargs_list:\n+            check_rnn_operation(step_function_k=get_step_function(K, wi_k, wh_k),\n+                                step_function_np=get_step_function(KNP, wi, wh),\n+                                inputs_np=x,\n+                                initial_states_np=[h0],\n+                                mask_np=kwargs.pop('mask', None),\n+                                **kwargs)\n \n     def test_rnn_additional_states(self):\n         # implement a simple RNN with an additional state\n@@ -742,104 +758,115 @@ class TestBackend(object):\n \n         _, x = parse_shape_or_val((num_samples, timesteps, input_dim))\n         _, h0 = parse_shape_or_val((num_samples, output_dim))\n+        h1 = np.concatenate([h0, h0], axis=-1)\n         _, wi = parse_shape_or_val((input_dim, output_dim))\n         _, wh = parse_shape_or_val((output_dim, output_dim))\n         mask = np.random.randint(2, size=(num_samples, timesteps))\n \n-        x_k = K.variable(x)\n-        h0_k = [K.variable(h0), K.variable(np.concatenate([h0, h0], axis=-1))]\n         wi_k = K.variable(wi)\n         wh_k = K.variable(wh)\n-        mask_k = K.variable(mask)\n \n-        def rnn_fn(x_k, h_k):\n-            assert len(h_k) == 2\n-            y_k = K.dot(x_k, wi_k) + K.dot(h_k[0], wh_k)\n-            return y_k, [y_k, K.concatenate([y_k, y_k], axis=-1)]\n+        def get_step_function(backend, w_i, w_h):\n \n-        # test default setup\n-        last_output_list = []\n-        outputs_list = []\n-        state_list = []\n+            def simple_rnn_with_extra_mock_state(inputs, states):\n+                assert len(states) == 2\n+                h = states[0]\n+                y = backend.dot(inputs, w_i) + backend.dot(h, w_h)\n+                return y, [y, backend.concatenate([y, y], axis=-1)]\n+\n+            return simple_rnn_with_extra_mock_state\n \n         kwargs_list = [\n             {'go_backwards': False, 'mask': None},\n-            {'go_backwards': False, 'mask': None, 'unroll': True,\n-             'input_length': timesteps},\n             {'go_backwards': True, 'mask': None},\n-            {'go_backwards': True, 'mask': None, 'unroll': True,\n-             'input_length': timesteps},\n-            {'go_backwards': False, 'mask': mask_k},\n-            {'go_backwards': False, 'mask': mask_k, 'unroll': True,\n-             'input_length': timesteps},\n+            {'go_backwards': False, 'mask': mask},\n+            {'go_backwards': True, 'mask': mask},\n         ]\n-\n-        for (i, kwargs) in enumerate(kwargs_list):\n-            last_y1, y1, h1 = KNP.rnn(x, [wi, wh, None], h0, **kwargs)\n-            last_y2, y2, h2 = K.rnn(rnn_fn, x_k, h0_k, **kwargs)\n-\n-            assert len(h2) == 2\n-            last_y2 = K.eval(last_y2)\n-            y2 = K.eval(y2)\n-            h11 = h1[:, -1]\n-            h12 = np.concatenate([h1[:, -1], h1[:, -1]], axis=-1)\n-            h21 = K.eval(h2[0])\n-            h22 = K.eval(h2[1])\n-\n-            if kwargs['mask'] is not None:\n-                last_y1 = last_y1 * np.expand_dims(mask[:, -1], -1)\n-                last_y2 = last_y2 * np.expand_dims(mask[:, -1], -1)\n-                y1 = y1 * np.expand_dims(mask, -1)\n-                y2 = y2 * np.expand_dims(mask, -1)\n-                h11 = h11 * np.expand_dims(mask[:, -1], -1)\n-                h21 = h21 * np.expand_dims(mask[:, -1], -1)\n-                h12 = h12 * np.expand_dims(mask[:, -1], -1)\n-                h22 = h22 * np.expand_dims(mask[:, -1], -1)\n-\n-            last_output_list.append(last_y2)\n-            outputs_list.append(y2)\n-            state_list.append((h21, h22))\n-\n-            if i % 2 == 0:\n-                assert_allclose(last_y1, last_y2, atol=1e-05)\n-                assert_allclose(y1, y2, atol=1e-05)\n-                assert_allclose(h11, h21, atol=1e-05)\n-                assert_allclose(h12, h22, atol=1e-05)\n-            else:\n-                assert_allclose(last_output_list[i - 1], last_output_list[i],\n-                                atol=1e-05)\n-                assert_allclose(outputs_list[i - 1], outputs_list[i], atol=1e-05)\n-                assert_allclose(state_list[i - 1][0], state_list[i][0], atol=1e-05)\n-                assert_allclose(state_list[i - 1][1], state_list[i][1], atol=1e-05)\n+        for kwargs in kwargs_list:\n+            check_rnn_operation(step_function_k=get_step_function(K, wi_k, wh_k),\n+                                step_function_np=get_step_function(KNP, wi, wh),\n+                                inputs_np=x,\n+                                initial_states_np=[h0, h1],\n+                                mask_np=kwargs.pop('mask', None),\n+                                **kwargs)\n \n     def test_rnn_no_states(self):\n         # implement a simple RNN without states\n+        num_samples = 3\n         input_dim = 8\n         output_dim = 4\n         timesteps = 5\n \n-        _, x = parse_shape_or_val((32, timesteps, input_dim))\n+        _, x = parse_shape_or_val((num_samples, timesteps, input_dim))\n         _, wi = parse_shape_or_val((input_dim, output_dim))\n+        mask = np.random.randint(2, size=(num_samples, timesteps))\n \n-        x_k = K.variable(x)\n         wi_k = K.variable(wi)\n \n-        def rnn_fn(x_k, h_k):\n-            assert len(h_k) == 0\n-            y_k = K.dot(x_k, wi_k)\n-            return y_k, []\n+        def get_step_function(backend, w_i):\n \n-        last_y1, y1, h1 = KNP.rnn(x, [wi, None, None], None,\n-                                  go_backwards=False, mask=None)\n-        last_y2, y2, h2 = K.rnn(rnn_fn, x_k, [],\n-                                go_backwards=False, mask=None)\n+            def simple_no_states(inputs, states):\n+                assert len(states) == 0\n+                y = backend.dot(inputs, w_i)\n+                return y, []\n \n-        assert len(h2) == 0\n-        last_y2 = K.eval(last_y2)\n-        y2 = K.eval(y2)\n+            return simple_no_states\n \n-        assert_allclose(last_y1, last_y2, atol=1e-05)\n-        assert_allclose(y1, y2, atol=1e-05)\n+        kwargs_list = [\n+            {'go_backwards': False, 'mask': None},\n+            {'go_backwards': True, 'mask': None},\n+            {'go_backwards': False, 'mask': mask},\n+            {'go_backwards': True, 'mask': mask},\n+        ]\n+        for kwargs in kwargs_list:\n+            check_rnn_operation(step_function_k=get_step_function(K, wi_k),\n+                                step_function_np=get_step_function(KNP, wi),\n+                                inputs_np=x,\n+                                initial_states_np=[],\n+                                mask_np=kwargs.pop('mask', None),\n+                                **kwargs)\n+\n+    def test_rnn_constants(self):\n+        # implement a simple RNN\n+        num_samples = 4\n+        input_dim = 5\n+        output_dim = 3\n+        timesteps = 6\n+\n+        _, x = parse_shape_or_val((num_samples, timesteps, input_dim))\n+        _, h0 = parse_shape_or_val((num_samples, output_dim))\n+        _, c = parse_shape_or_val((num_samples, output_dim))\n+        _, wi = parse_shape_or_val((input_dim, output_dim))\n+        _, wh = parse_shape_or_val((output_dim, output_dim))\n+        mask = np.random.randint(2, size=(num_samples, timesteps))\n+\n+        wi_k = K.variable(wi)\n+        wh_k = K.variable(wh)\n+\n+        def get_step_function(backend, w_i, w_h):\n+\n+            def simple_rnn_add_constant(inputs, states_and_constants):\n+                # constants are appended to states in K.rnn\n+                [h, c] = states_and_constants\n+                y = backend.dot(inputs, w_i) + backend.dot(h, w_h) + c\n+                return y, [y]\n+\n+            return simple_rnn_add_constant\n+\n+        kwargs_list = [\n+            {'go_backwards': False, 'mask': None},\n+            {'go_backwards': True, 'mask': None},\n+            {'go_backwards': False, 'mask': mask},\n+            {'go_backwards': True, 'mask': mask},\n+        ]\n+        for kwargs in kwargs_list:\n+            check_rnn_operation(step_function_k=get_step_function(K, wi_k, wh_k),\n+                                step_function_np=get_step_function(KNP, wi, wh),\n+                                inputs_np=x,\n+                                initial_states_np=[h0],\n+                                mask_np=kwargs.pop('mask', None),\n+                                constants_np=[c],\n+                                **kwargs)\n \n     def test_rnn_output_and_state_masking_independent(self):\n         num_samples = 2\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8a73aec637a853f0fccb544dcb61dfe170db1277", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 345 | Contributors (this commit): 19 | Commits (past 90d): 5 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -101,7 +101,7 @@ def softsign(x):\n         x: Input tensor.\n \n     # Returns\n-        The softplus activation: `x / (abs(x) + 1)`.\n+        The softsign activation: `x / (abs(x) + 1)`.\n     \"\"\"\n     return K.softsign(x)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#43b5e9993ab025bd07851d70de5de7fdfe461d24", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 9/7 | Churn Δ: 19 | Churn Cumulative: 11921 | Contributors (this commit): 138 | Commits (past 90d): 21 | Contributors (cumulative): 148 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1021,6 +1021,8 @@ def moving_average_update(x, value, momentum):\n     # Returns\n         An operation to update the variable.\n     \"\"\"\n+    if value.dtype != x.dtype:\n+        value = tf.cast(value, x.dtype)\n     return moving_averages.assign_moving_average(\n         x, value, momentum, zero_debias=True)\n \n@@ -2037,6 +2039,11 @@ def _fused_normalize_batch_in_training(x, gamma, beta, reduction_axes,\n                            dtype=x.dtype,\n                            shape=[x.get_shape()[normalization_axis]])\n \n+    if gamma.dtype != tf.float32:\n+        gamma = tf.cast(gamma, tf.float32)\n+    if beta.dtype != tf.float32:\n+        beta = tf.cast(beta, tf.float32)\n+\n     return tf.nn.fused_batch_norm(\n         x,\n         gamma,\n@@ -2125,6 +2132,16 @@ def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n                 gamma = ones_like(mean)\n             elif ndim(gamma) > 1:\n                 gamma = tf.reshape(gamma, [-1])\n+\n+            if gamma.dtype != tf.float32:\n+                gamma = tf.cast(gamma, tf.float32)\n+            if beta.dtype != tf.float32:\n+                beta = tf.cast(beta, tf.float32)\n+            if mean.dtype != tf.float32:\n+                mean = tf.cast(mean, tf.float32)\n+            if var.dtype != tf.float32:\n+                var = tf.cast(var, tf.float32)\n+\n             y, _, _ = tf.nn.fused_batch_norm(\n                 x,\n                 gamma,\n\n@@ -188,6 +188,8 @@ class BatchNormalization(Layer):\n             sample_size = K.prod([K.shape(inputs)[axis]\n                                   for axis in reduction_axes])\n             sample_size = K.cast(sample_size, dtype=K.dtype(inputs))\n+            if K.backend() == 'tensorflow' and sample_size.dtype != 'float32':\n+                sample_size = K.cast(sample_size, dtype='float32')\n \n             # sample variance - unbiased estimator of population variance\n             variance *= sample_size / (sample_size - (1.0 + self.epsilon))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#29cf97dcb96218ed5435ccee4464aecc891d50d9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 3 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 3098 | Contributors (this commit): 39 | Commits (past 90d): 16 | Contributors (cumulative): 50 | DMM Complexity: None\n\nDIFF:\n@@ -125,7 +125,7 @@ def test_weighted_masked_objective():\n \n \n # TODO: resolve flakyness issue. Tracked with #11560\n-@flaky(rerun_filter=lambda err, *args: not issubclass(err[0], AssertionError))\n+@flaky(rerun_filter=lambda err, *args: issubclass(err[0], AssertionError))\n def test_model_methods():\n     a = Input(shape=(3,), name='input_a')\n     b = Input(shape=(3,), name='input_b')\n\n@@ -123,7 +123,7 @@ def test_sparse_top_k_categorical_accuracy(y_pred, y_true):\n \n # TODO: resolve flakyness issue. Tracked with #11064\n @pytest.mark.parametrize('metrics_mode', ['list', 'dict'])\n-@flaky(rerun_filter=lambda err, *args: not issubclass(err[0], AssertionError))\n+@flaky(rerun_filter=lambda err, *args: issubclass(err[0], AssertionError))\n def test_stateful_metrics(metrics_mode):\n     np.random.seed(1334)\n \n\n@@ -213,7 +213,7 @@ def test_generator_enqueuer_threadsafe():\n \n \n # TODO: resolve flakyness issue. Tracked with #11587\n-@flaky(rerun_filter=lambda err, *args: not issubclass(err[0], StopIteration))\n+@flaky(rerun_filter=lambda err, *args: issubclass(err[0], StopIteration))\n def test_generator_enqueuer_fail_threads():\n     enqueuer = GeneratorEnqueuer(create_generator_from_sequence_threads(\n         FaultSequence()), use_multiprocessing=False)\n@@ -365,7 +365,7 @@ def create_finite_generator_from_sequence_pcs(ds):\n \n \n # TODO: resolve flakyness issue. Tracked with #11586\n-@flaky(rerun_filter=lambda err, *args: not issubclass(err[0], AssertionError))\n+@flaky(rerun_filter=lambda err, *args: issubclass(err[0], AssertionError))\n def test_finite_generator_enqueuer_threads():\n     enqueuer = GeneratorEnqueuer(create_finite_generator_from_sequence_threads(\n         DummySequence([3, 10, 10, 3])), use_multiprocessing=False)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#13b255dfd832dd78bca90fac142325df534d51be", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 13 | Files Changed: 1 | Hunks: 8 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 24 | Churn Cumulative: 465 | Contributors (this commit): 9 | Commits (past 90d): 2 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -8,8 +8,8 @@ http://arxiv.org/abs/1502.05698\n \n Task Number                  | FB LSTM Baseline | Keras QA\n ---                          | ---              | ---\n-QA1 - Single Supporting Fact | 50               | 100.0\n-QA2 - Two Supporting Facts   | 20               | 50.0\n+QA1 - Single Supporting Fact | 50               | 52.1\n+QA2 - Two Supporting Facts   | 20               | 37.0\n QA3 - Three Supporting Facts | 20               | 20.5\n QA4 - Two Arg. Relations     | 61               | 62.9\n QA5 - Three Arg. Relations   | 70               | 61.9\n@@ -35,8 +35,8 @@ https://research.facebook.com/researchers/1543934539189348\n # Notes\n \n - With default word, sentence, and query vector sizes, the GRU model achieves:\n-  - 100% test accuracy on QA1 in 20 epochs (2 seconds per epoch on CPU)\n-  - 50% test accuracy on QA2 in 20 epochs (16 seconds per epoch on CPU)\n+  - 52.1% test accuracy on QA1 in 20 epochs (2 seconds per epoch on CPU)\n+  - 37.0% test accuracy on QA2 in 20 epochs (16 seconds per epoch on CPU)\n In comparison, the Facebook paper achieves 50% and 20% for the LSTM baseline.\n \n - The task does not traditionally parse the question separately. This likely\n@@ -49,7 +49,7 @@ of only 1000. 1000 was used in order to be comparable to the original paper.\n \n - Experiment with GRU, LSTM, and JZS1-3 as they give subtly different results.\n \n-- The length and noise (i.e. 'useless' story components) impact the ability for\n+- The length and noise (i.e. 'useless' story components) impact the ability of\n LSTMs / GRUs to provide the correct answer. Given only the supporting facts,\n these RNNs can achieve 100% accuracy on many tasks. Memory networks and neural\n networks that use attentional processes can efficiently search through this\n@@ -148,7 +148,7 @@ EMBED_HIDDEN_SIZE = 50\n SENT_HIDDEN_SIZE = 100\n QUERY_HIDDEN_SIZE = 100\n BATCH_SIZE = 32\n-EPOCHS = 40\n+EPOCHS = 20\n print('RNN / Embed / Sent / Query = {}, {}, {}, {}'.format(RNN,\n                                                            EMBED_HIDDEN_SIZE,\n                                                            SENT_HIDDEN_SIZE,\n@@ -201,17 +201,13 @@ print('Build model...')\n \n sentence = layers.Input(shape=(story_maxlen,), dtype='int32')\n encoded_sentence = layers.Embedding(vocab_size, EMBED_HIDDEN_SIZE)(sentence)\n-encoded_sentence = layers.Dropout(0.3)(encoded_sentence)\n+encoded_sentence = RNN(SENT_HIDDEN_SIZE)(encoded_sentence)\n \n question = layers.Input(shape=(query_maxlen,), dtype='int32')\n encoded_question = layers.Embedding(vocab_size, EMBED_HIDDEN_SIZE)(question)\n-encoded_question = layers.Dropout(0.3)(encoded_question)\n-encoded_question = RNN(EMBED_HIDDEN_SIZE)(encoded_question)\n-encoded_question = layers.RepeatVector(story_maxlen)(encoded_question)\n+encoded_question = RNN(QUERY_HIDDEN_SIZE)(encoded_question)\n \n-merged = layers.add([encoded_sentence, encoded_question])\n-merged = RNN(EMBED_HIDDEN_SIZE)(merged)\n-merged = layers.Dropout(0.3)(merged)\n+merged = layers.concatenate([encoded_sentence, encoded_question])\n preds = layers.Dense(vocab_size, activation='softmax')(merged)\n \n model = Model([sentence, question], preds)\n@@ -224,6 +220,8 @@ model.fit([x, xq], y,\n           batch_size=BATCH_SIZE,\n           epochs=EPOCHS,\n           validation_split=0.05)\n+\n+print('Evaluation')\n loss, acc = model.evaluate([tx, txq], ty,\n                            batch_size=BATCH_SIZE)\n print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))\n\\ No newline at end of file\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
