{"custom_id": "keras#2f90dab483745168e8049da9d0ae8b912e5da715", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 194 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -877,20 +877,7 @@ def _cudnn_lstm(\n     return_sequences,\n ):\n     if mask is not None:\n-        is_valid_mask = _is_sequence_right_padded(mask, time_major)\n-        tf.Assert(\n-            is_valid_mask,\n-            message=(\n-                \"You are passing a RNN mask that does not correspond to \"\n-                \"right-padded sequences, while using cuDNN, which is not \"\n-                \"supported. With cuDNN, RNN masks can only be used for \"\n-                \"right-padding, e.g. `[[True, True, False, False]]` would \"\n-                \"be a valid mask, but any mask that isn't just contiguous \"\n-                \"`True`'s on the left and contiguous `False`'s on the right \"\n-                \"would be invalid. You can pass `use_cudnn=False` to your \"\n-                \"RNN layer to stop using cuDNN (this may be slower).\"\n-            ),\n-        )\n+        _assert_valid_mask(mask)\n         sequence_lengths = _compute_sequence_length_from_mask(mask, time_major)\n     else:\n         sequence_lengths = None\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#26b908fc98e6b5d66e538c020d7faa26a30e8f2f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 8 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 91 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -1,7 +1,9 @@\n from keras.api_export import keras_export\n from keras.losses.loss import Loss\n from keras.losses.losses import BinaryCrossentropy\n+from keras.losses.losses import BinaryFocalCrossentropy\n from keras.losses.losses import CategoricalCrossentropy\n+from keras.losses.losses import CategoricalFocalCrossentropy\n from keras.losses.losses import CategoricalHinge\n from keras.losses.losses import CosineSimilarity\n from keras.losses.losses import Dice\n@@ -18,7 +20,9 @@ from keras.losses.losses import Poisson\n from keras.losses.losses import SparseCategoricalCrossentropy\n from keras.losses.losses import SquaredHinge\n from keras.losses.losses import binary_crossentropy\n+from keras.losses.losses import binary_focal_crossentropy\n from keras.losses.losses import categorical_crossentropy\n+from keras.losses.losses import categorical_focal_crossentropy\n from keras.losses.losses import categorical_hinge\n from keras.losses.losses import cosine_similarity\n from keras.losses.losses import ctc\n@@ -44,7 +48,9 @@ ALL_OBJECTS = {\n     KLDivergence,\n     Poisson,\n     BinaryCrossentropy,\n+    BinaryFocalCrossentropy,\n     CategoricalCrossentropy,\n+    CategoricalFocalCrossentropy,\n     SparseCategoricalCrossentropy,\n     # Regression\n     MeanSquaredError,\n@@ -64,7 +70,9 @@ ALL_OBJECTS = {\n     kl_divergence,\n     poisson,\n     binary_crossentropy,\n+    binary_focal_crossentropy,\n     categorical_crossentropy,\n+    categorical_focal_crossentropy,\n     sparse_categorical_crossentropy,\n     # Regression\n     mean_squared_error,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#471edf24d9aa769797efdcdc112de9a3e260032d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 17 | Churn Cumulative: 507 | Contributors (this commit): 8 | Commits (past 90d): 23 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1197,6 +1197,8 @@ class Layer(BackendLayer, Operation):\n             self._tracker.add_to_store(\"trainable_variables\", variable)\n         else:\n             self._tracker.add_to_store(\"non_trainable_variables\", variable)\n+        if not self.trainable:\n+            variable.trainable = False\n \n     def _untrack_variable(self, variable):\n         previous_lock_state = self._tracker.locked\n\n@@ -904,3 +904,18 @@ class LayerTest(testing.TestCase):\n         layer.custom_change_dtype()\n         self.assertEqual(layer.w.dtype, \"int8\")\n         self.assertEqual(layer.w.trainable, False)\n+\n+    def test_trainable_init_arg(self):\n+        inputs = layers.Input(shape=(1,))\n+        layer = layers.Dense(2, trainable=False)\n+        outputs = layer(inputs)\n+        model = models.Model(inputs, outputs)\n+\n+        self.assertFalse(layer.trainable)\n+        self.assertLen(layer.trainable_variables, 0)\n+        self.assertLen(model.trainable_variables, 0)\n+\n+        layer.trainable = True\n+        self.assertTrue(layer.trainable)\n+        self.assertLen(layer.trainable_variables, 2)\n+        self.assertLen(model.trainable_variables, 2)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ac44e4b09244d44a7246a68fd0d23b41b41450e8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 77 | Lines Deleted: 36 | Files Changed: 3 | Hunks: 8 | Methods Changed: 10 | Complexity Δ (Sum/Max): 3/1 | Churn Δ: 113 | Churn Cumulative: 139 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -28,10 +28,25 @@ class ZeroPadding1DTest(testing.TestCase, parameterized.TestCase):\n         padded = layers.ZeroPadding1D((1, 2))(input_layer)\n         self.assertEqual(padded.shape, (1, None, 3))\n \n-    def test_zero_padding_1d_errors_if_padding_argument_invalid(self):\n+        input_layer = layers.Input(batch_shape=(1, 2, 3))\n+        padded = layers.ZeroPadding1D((1, 2))(input_layer)\n+        self.assertEqual(padded.shape, (1, 5, 3))\n+\n+    @parameterized.parameters(\n+        {\"padding\": (1,)},\n+        {\"padding\": (1, 2, 3)},\n+        {\"padding\": \"1\"},\n+    )\n+    def test_zero_padding_1d_errors_if_padding_argument_invalid(self, padding):\n         with self.assertRaises(ValueError):\n-            layers.ZeroPadding1D(padding=(1,))\n-        with self.assertRaises(ValueError):\n-            layers.ZeroPadding1D(padding=(1, 2, 3))\n-        with self.assertRaises(ValueError):\n-            layers.ZeroPadding1D(padding=\"1\")\n+            layers.ZeroPadding1D(padding)\n+\n+    def test_zero_padding_1d_get_config(self):\n+        layer = layers.ZeroPadding1D(padding=(1, 2))\n+        expected_config = {\n+            \"dtype\": layer.dtype_policy.name,\n+            \"name\": layer.name,\n+            \"padding\": (1, 2),\n+            \"trainable\": layer.trainable,\n+        }\n+        self.assertEqual(layer.get_config(), expected_config)\n\n@@ -7,8 +7,9 @@ from keras import testing\n \n \n class ZeroPadding2DTest(testing.TestCase, parameterized.TestCase):\n-    @parameterized.named_parameters(\n-        (\"channels_first\", \"channels_first\"), (\"channels_last\", \"channels_last\")\n+    @parameterized.parameters(\n+        {\"data_format\": \"channels_first\"},\n+        {\"data_format\": \"channels_last\"},\n     )\n     def test_zero_padding_2d(self, data_format):\n         inputs = np.random.rand(1, 2, 3, 4)\n@@ -68,16 +69,29 @@ class ZeroPadding2DTest(testing.TestCase, parameterized.TestCase):\n         else:\n             self.assertEqual(padded.shape, (1, 4, 5, None))\n \n-    def test_zero_padding_2d_errors_if_padding_argument_invalid(self):\n+    @parameterized.parameters(\n+        {\"padding\": (1,)},\n+        {\"padding\": (1, 2, 3)},\n+        {\"padding\": \"1\"},\n+        {\"padding\": ((1, 2), (3, 4, 5))},\n+        {\"padding\": ((1, 2), (3, -4))},\n+        {\"padding\": ((1, 2), \"3\")},\n+    )\n+    def test_zero_padding_2d_errors_if_padding_argument_invalid(self, padding):\n         with self.assertRaises(ValueError):\n-            layers.ZeroPadding2D(padding=(1,))\n-        with self.assertRaises(ValueError):\n-            layers.ZeroPadding2D(padding=(1, 2, 3))\n-        with self.assertRaises(ValueError):\n-            layers.ZeroPadding2D(padding=\"1\")\n-        with self.assertRaises(ValueError):\n-            layers.ZeroPadding2D(padding=((1, 2), (3, 4, 5)))\n-        with self.assertRaises(ValueError):\n-            layers.ZeroPadding2D(padding=((1, 2), (3, -4)))\n-        with self.assertRaises(ValueError):\n-            layers.ZeroPadding2D(padding=((1, 2), \"3\"))\n+            layers.ZeroPadding2D(padding)\n+\n+    @parameterized.parameters(\n+        {\"data_format\": \"channels_first\"},\n+        {\"data_format\": \"channels_last\"},\n+    )\n+    def test_zero_padding_2d_get_config(self, data_format):\n+        layer = layers.ZeroPadding2D(padding=(1, 2), data_format=data_format)\n+        expected_config = {\n+            \"data_format\": data_format,\n+            \"dtype\": layer.dtype_policy.name,\n+            \"name\": layer.name,\n+            \"padding\": ((1, 1), (2, 2)),\n+            \"trainable\": layer.trainable,\n+        }\n+        self.assertEqual(layer.get_config(), expected_config)\n\n@@ -7,8 +7,8 @@ from keras import testing\n \n \n class ZeroPadding3DTest(testing.TestCase, parameterized.TestCase):\n-    @parameterized.named_parameters(\n-        (\"channels_first\", \"channels_first\"), (\"channels_last\", \"channels_last\")\n+    @parameterized.parameters(\n+        {\"data_format\": \"channels_first\"}, {\"data_format\": \"channels_last\"}\n     )\n     def test_zero_padding_3d(self, data_format):\n         inputs = np.random.rand(1, 2, 3, 4, 5)\n@@ -74,18 +74,30 @@ class ZeroPadding3DTest(testing.TestCase, parameterized.TestCase):\n         else:\n             self.assertEqual(padded.shape, (1, 5, 5, None, 15))\n \n-    def test_zero_padding_3d_errors_if_padding_argument_invalid(self):\n+    @parameterized.parameters(\n+        {\"padding\": (1,)},\n+        {\"padding\": (1, 2)},\n+        {\"padding\": (1, 2, 3, 4)},\n+        {\"padding\": \"1\"},\n+        {\"padding\": ((1, 2), (3, 4), (5, 6, 7))},\n+        {\"padding\": ((1, 2), (3, 4), (5, -6))},\n+        {\"padding\": ((1, 2), (3, 4), \"5\")},\n+    )\n+    def test_zero_padding_3d_errors_if_padding_argument_invalid(self, padding):\n         with self.assertRaises(ValueError):\n-            layers.ZeroPadding3D(padding=(1,))\n-        with self.assertRaises(ValueError):\n-            layers.ZeroPadding3D(padding=(1, 2))\n-        with self.assertRaises(ValueError):\n-            layers.ZeroPadding3D(padding=(1, 2, 3, 4))\n-        with self.assertRaises(ValueError):\n-            layers.ZeroPadding3D(padding=\"1\")\n-        with self.assertRaises(ValueError):\n-            layers.ZeroPadding3D(padding=((1, 2), (3, 4), (5, 6, 7)))\n-        with self.assertRaises(ValueError):\n-            layers.ZeroPadding3D(padding=((1, 2), (3, 4), (5, -6)))\n-        with self.assertRaises(ValueError):\n-            layers.ZeroPadding3D(padding=((1, 2), (3, 4), \"5\"))\n+            layers.ZeroPadding3D(padding=padding)\n+\n+    @parameterized.parameters(\n+        {\"data_format\": \"channels_first\"},\n+        {\"data_format\": \"channels_last\"},\n+    )\n+    def test_zero_padding_3d_get_config(self, data_format):\n+        layer = layers.ZeroPadding3D(padding=(1, 2, 3), data_format=data_format)\n+        expected_config = {\n+            \"data_format\": data_format,\n+            \"dtype\": layer.dtype_policy.name,\n+            \"name\": layer.name,\n+            \"padding\": ((1, 1), (2, 2), (3, 3)),\n+            \"trainable\": layer.trainable,\n+        }\n+        self.assertEqual(layer.get_config(), expected_config)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#996ccb2d0df669bce875a75bcc0442668fdbfce8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 4 | Churn Cumulative: 198 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -468,7 +468,7 @@ def gru(\n         use_bias=bias is not None,\n         reset_after=reset_after,\n     )\n-    if not cudnn_supported or mask is not None:\n+    if not cudnn_supported:\n         raise NotImplementedError\n \n     from keras.backend.tensorflow import Variable\n@@ -831,7 +831,7 @@ def lstm(\n     cudnn_supported = cudnn_ok(\n         activation, recurrent_activation, unroll, use_bias=bias is not None\n     )\n-    if not cudnn_supported or mask is not None:\n+    if not cudnn_supported:\n         raise NotImplementedError\n \n     from keras.backend.tensorflow import Variable\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4f76442bb4572fb701d08ea46c2f81cb3da3706a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 275 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -445,10 +445,10 @@ class Model(Trainer, Layer):\n         return json.dumps(model_config, **kwargs)\n \n     def export(self, filepath, format=\"tf_saved_model\"):\n-        \"\"\"[TF backend only]* Create a TF SavedModel artifact for inference\n-        (e.g. via TF-Serving).\n+        \"\"\"Create a TF SavedModel artifact for inference.\n \n-        **Note:** This can currently only be used with the TF backend.\n+        **Note:** This can currently only be used with\n+        the TensorFlow or JAX backends.\n \n         This method lets you export a model to a lightweight SavedModel artifact\n         that contains the model's forward pass only (its `call()` method)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d2dfed5dd0c2773ea0a9bd227d2c82f6c41e7423", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 64 | Contributors (this commit): 4 | Commits (past 90d): 5 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -10,7 +10,7 @@ def reduce_to_samplewise_values(values, sample_weight, reduce_fn, dtype):\n     mask = getattr(values, \"_keras_mask\", None)\n     values = ops.cast(values, dtype=dtype)\n     if sample_weight is not None:\n-        sample_weight = ops.cast(sample_weight, dtype=dtype)\n+        sample_weight = ops.convert_to_tensor(sample_weight, dtype=dtype)\n         if mask is not None:\n             sample_weight = losses.loss.apply_mask(\n                 sample_weight, mask, dtype=dtype, reduction=\"sum\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b3ea9e17e93972654d575e73619de21b3fbe0a95", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 835 | Contributors (this commit): 9 | Commits (past 90d): 7 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -20,7 +20,7 @@ class Embedding(Layer):\n     Example:\n \n     >>> model = keras.Sequential()\n-    >>> model.add(keras.layers.Embedding(1000, 64, input_length=10))\n+    >>> model.add(keras.layers.Embedding(1000, 64))\n     >>> # The model will take as input an integer matrix of size (batch,\n     >>> # input_length), and the largest integer (i.e. word index) in the input\n     >>> # should be no larger than 999 (vocabulary size).\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4ed99584cc3f5267180351fb4f1dfe743a041ebc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 7 | Churn Cumulative: 842 | Contributors (this commit): 9 | Commits (past 90d): 8 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,3 +1,5 @@\n+import warnings\n+\n from keras import backend\n from keras import constraints\n from keras import dtype_policies\n@@ -79,6 +81,11 @@ class Embedding(Layer):\n         lora_rank=None,\n         **kwargs,\n     ):\n+        input_length = kwargs.pop(\"input_length\", None)\n+        if input_length is not None:\n+            warnings.warn(\n+                \"Argument `input_length` is deprecated. Just remove it.\"\n+            )\n         super().__init__(**kwargs)\n         self.input_dim = input_dim\n         self.output_dim = output_dim\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#748197cce4852a5638317aa9dcf54a740893d8aa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 3 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 6 | Churn Cumulative: 264 | Contributors (this commit): 10 | Commits (past 90d): 24 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -119,7 +119,6 @@ def convert_to_tensor(x, dtype=None, sparse=None):\n             x.set_shape(x_shape)\n             return x\n         return tf.cast(x, dtype=dtype)\n-    else:\n     return x\n \n \n\n@@ -85,7 +85,7 @@ class Metric:\n \n     def __init__(self, dtype=None, name=None):\n         self.name = name or auto_name(self.__class__.__name__)\n-        self._dtype = dtype\n+        self._dtype = dtype or backend.floatx()\n         self._metrics = []\n         self._variables = []\n         self._tracker = Tracker(\n\n@@ -1,16 +1,19 @@\n from keras import initializers\n from keras import losses\n from keras import ops\n+from keras import backend\n from keras.api_export import keras_export\n from keras.metrics.metric import Metric\n from keras.saving import serialization_lib\n \n \n def reduce_to_samplewise_values(values, sample_weight, reduce_fn, dtype):\n+    dtype = dtype or backend.floatx()\n     mask = getattr(values, \"_keras_mask\", None)\n     values = ops.cast(values, dtype=dtype)\n     if sample_weight is not None:\n         sample_weight = ops.convert_to_tensor(sample_weight, dtype=dtype)\n+\n         if mask is not None:\n             sample_weight = losses.loss.apply_mask(\n                 sample_weight, mask, dtype=dtype, reduction=\"sum\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#963f04773ebabfd3c8b0c9683c63dfd0e0090408", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1161 | Contributors (this commit): 6 | Commits (past 90d): 5 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -255,7 +255,6 @@ def load_weights_only(\n         )\n \n     failed_trackables = set()\n-    print(\"objects_to_skip\", objects_to_skip)\n     if objects_to_skip is not None:\n         visited_trackables = set(id(o) for o in objects_to_skip)\n     else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#92211f95a12c844558d11fb7fadcfc5b5b0402a5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 69 | Contributors (this commit): 4 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -1,7 +1,7 @@\n+from keras import backend\n from keras import initializers\n from keras import losses\n from keras import ops\n-from keras import backend\n from keras.api_export import keras_export\n from keras.metrics.metric import Metric\n from keras.saving import serialization_lib\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a2419dde3f213846d05a0a77c2714b1d188a2b6e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 561 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -63,7 +63,7 @@ class LinalgOpsDynamicShapeTest(testing.TestCase):\n         with self.assertRaises(ValueError):\n             linalg.inv(x)\n \n-    def test_lu_factor(self):\n+    def DISABLED_test_lu_factor(self):\n         x = KerasTensor([None, 4, 3])\n         lu, p = linalg.lu_factor(x)\n         self.assertEqual(lu.shape, (None, 4, 3))\n@@ -126,7 +126,7 @@ class LinalgOpsDynamicShapeTest(testing.TestCase):\n         with self.assertRaises(ValueError):\n             linalg.solve(a, b)\n \n-    def test_solve_triangular(self):\n+    def DISABLED_test_solve_triangular(self):\n         a = KerasTensor([None, 20, 20])\n         b = KerasTensor([None, 20, 5])\n         out = linalg.solve_triangular(a, b)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6f185286ad4757ecbe5718d9287feb5b74877806", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 2 | Files Changed: 3 | Hunks: 7 | Methods Changed: 9 | Complexity Δ (Sum/Max): 14/9 | Churn Δ: 36 | Churn Cumulative: 7408 | Contributors (this commit): 13 | Commits (past 90d): 29 | Contributors (cumulative): 19 | DMM Complexity: 1.0\n\nDIFF:\n@@ -63,7 +63,10 @@ class LinalgOpsDynamicShapeTest(testing.TestCase):\n         with self.assertRaises(ValueError):\n             linalg.inv(x)\n \n-    def DISABLED_test_lu_factor(self):\n+    def test_lu_factor(self):\n+        if self._jax_uses_gpu():\n+            self.skipTest(\"Skipping test with JAX + GPU due to temporary error\")\n+\n         x = KerasTensor([None, 4, 3])\n         lu, p = linalg.lu_factor(x)\n         self.assertEqual(lu.shape, (None, 4, 3))\n@@ -126,7 +129,10 @@ class LinalgOpsDynamicShapeTest(testing.TestCase):\n         with self.assertRaises(ValueError):\n             linalg.solve(a, b)\n \n-    def DISABLED_test_solve_triangular(self):\n+    def test_solve_triangular(self):\n+        if self._jax_uses_gpu():\n+            self.skipTest(\"Skipping test with JAX + GPU due to temporary error\")\n+\n         a = KerasTensor([None, 20, 20])\n         b = KerasTensor([None, 20, 5])\n         out = linalg.solve_triangular(a, b)\n@@ -212,6 +218,9 @@ class LinalgOpsStaticShapeTest(testing.TestCase):\n             linalg.inv(x)\n \n     def test_lu_factor(self):\n+        if self._jax_uses_gpu():\n+            self.skipTest(\"Skipping test with JAX + GPU due to temporary error\")\n+\n         x = KerasTensor([10, 4, 3])\n         lu, p = linalg.lu_factor(x)\n         self.assertEqual(lu.shape, (10, 4, 3))\n@@ -269,6 +278,9 @@ class LinalgOpsStaticShapeTest(testing.TestCase):\n             linalg.solve(a, b)\n \n     def test_solve_triangular(self):\n+        if self._jax_uses_gpu():\n+            self.skipTest(\"Skipping test with JAX + GPU due to temporary error\")\n+\n         a = KerasTensor([4, 3, 3])\n         b = KerasTensor([4, 3, 5])\n         out = linalg.solve_triangular(a, b)\n\n@@ -4562,6 +4562,9 @@ class SparseTest(testing.TestCase, parameterized.TestCase):\n     def test_other_unary_symbolic_sparse_correctness(\n         self, op_function, op_class, np_op, op_kwargs, input_shape\n     ):\n+        if self._tensorflow_uses_gpu():\n+            self.skipTest(\"Skipping test with TF + GPU due to XLA error\")\n+\n         x = np.random.random(input_shape)\n         if op_function is knp.mean:\n             x = create_indexed_slices(x)\n\n@@ -6,6 +6,7 @@ import unittest\n import numpy as np\n \n from keras import backend\n+from keras import distribution\n from keras import ops\n from keras import utils\n from keras.backend.common import is_float_dtype\n@@ -548,6 +549,22 @@ class TestCase(unittest.TestCase):\n                     if is_float_dtype(dtype):\n                         self.assertEqual(dtype, \"float32\")\n \n+    def _uses_gpu(self):\n+        # Condition used to skip tests when using the GPU\n+        devices = distribution.list_devices()\n+        if any(d.startswith(\"gpu\") for d in devices):\n+            return True\n+        return False\n+\n+    def _tensorflow_uses_gpu(self):\n+        return backend.backend() == \"tensorflow\" and self._uses_gpu()\n+\n+    def _jax_uses_gpu(self):\n+        return backend.backend() == \"jax\" and self._uses_gpu()\n+\n+    def _torch_uses_gpu(self):\n+        return backend.backend() == \"torch\" and self._uses_gpu()\n+\n \n def create_keras_tensors(input_shape, dtype, sparse):\n     if isinstance(input_shape, dict):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#142ff5879054a4b0cbdf3f6e508d62a07edd1d90", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 11 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -0,0 +1,11 @@\n+from keras.distribution.distribution_lib import DataParallel\n+from keras.distribution.distribution_lib import DeviceMesh\n+from keras.distribution.distribution_lib import Distribution\n+from keras.distribution.distribution_lib import LayoutMap\n+from keras.distribution.distribution_lib import ModelParallel\n+from keras.distribution.distribution_lib import TensorLayout\n+from keras.distribution.distribution_lib import distribute_tensor\n+from keras.distribution.distribution_lib import distribution\n+from keras.distribution.distribution_lib import initialize\n+from keras.distribution.distribution_lib import list_devices\n+from keras.distribution.distribution_lib import set_distribution\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#121055f73830854b65a77fef0e782ff7ee5759f4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/2 | Churn Δ: 8 | Churn Cumulative: 6982 | Contributors (this commit): 10 | Commits (past 90d): 22 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -356,6 +356,9 @@ class LinalgOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         )\n \n     def test_lu_factor(self):\n+        if self._jax_uses_gpu():\n+            self.skipTest(\"Skipping test with JAX + GPU due to temporary error\")\n+\n         def _pivot_matrix(pivots, n):\n             p_matrix = np.eye(n)\n             for i, p in enumerate(pivots):\n@@ -477,6 +480,8 @@ class LinalgOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(output, expected_result)\n \n     def test_solve_triangular(self):\n+        if self._jax_uses_gpu():\n+            self.skipTest(\"Skipping test with JAX + GPU due to temporary error\")\n \n         # 2d-case\n         x1 = np.array([[1, 2], [0, 5]], dtype=\"float32\")\n\n@@ -4562,9 +4562,6 @@ class SparseTest(testing.TestCase, parameterized.TestCase):\n     def test_other_unary_symbolic_sparse_correctness(\n         self, op_function, op_class, np_op, op_kwargs, input_shape\n     ):\n-        if self._tensorflow_uses_gpu():\n-            self.skipTest(\"Skipping test with TF + GPU due to XLA error\")\n-\n         x = np.random.random(input_shape)\n         if op_function is knp.mean:\n             x = create_indexed_slices(x)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#afeec72797be38e4fbeb53e96b0842bfd8af1452", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 6403 | Contributors (this commit): 9 | Commits (past 90d): 18 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4562,6 +4562,9 @@ class SparseTest(testing.TestCase, parameterized.TestCase):\n     def test_other_unary_symbolic_sparse_correctness(\n         self, op_function, op_class, np_op, op_kwargs, input_shape\n     ):\n+        if self._tensorflow_uses_gpu():\n+            self.skipTest(\"Skipping test with TF + GPU due to XLA error\")\n+\n         x = np.random.random(input_shape)\n         if op_function is knp.mean:\n             x = create_indexed_slices(x)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4dd458bf45ff53e2c02935ea89a9525b2892173d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 304 | Lines Deleted: 0 | Files Changed: 8 | Hunks: 8 | Methods Changed: 46 | Complexity Δ (Sum/Max): 52/9 | Churn Δ: 304 | Churn Cumulative: 304 | Contributors (this commit): 1 | Commits (past 90d): 8 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,23 @@\n+from keras import testing\n+from keras.datasets import boston_housing\n+\n+\n+class BostonHousingTest(testing.TestCase):\n+\n+    def test_load_data(self):\n+        (x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n+        self.assertEqual(x_train.shape[1], 13)\n+        self.assertEqual(x_train.shape[0] + x_test.shape[0], 506)\n+\n+    def test_seed_reproducibility(self):\n+        seed = 123\n+        first_load = boston_housing.load_data(seed=seed)\n+        second_load = boston_housing.load_data(seed=seed)\n+        self.assertAllClose(first_load[0][0], second_load[0][0])\n+        self.assertAllClose(first_load[1][0], second_load[1][0])\n+\n+    def test_invalid_test_split(self):\n+        with self.assertRaises(AssertionError):\n+            boston_housing.load_data(test_split=-0.1)\n+        with self.assertRaises(AssertionError):\n+            boston_housing.load_data(test_split=1.0)\n\n@@ -0,0 +1,33 @@\n+from keras import testing\n+from keras.datasets import california_housing\n+\n+\n+class CaliforniaHousingTest(testing.TestCase):\n+\n+    def test_load_data_large(self):\n+        (x_train, y_train), (x_test, y_test) = california_housing.load_data(\n+            version=\"large\"\n+        )\n+        self.assertEqual(x_train.shape[1], 8)\n+        # Ensure the dataset contains 20,640 samples as documented\n+        self.assertEqual(x_train.shape[0] + x_test.shape[0], 20640)\n+\n+    def test_load_data_small(self):\n+        (x_train, y_train), (x_test, y_test) = california_housing.load_data(\n+            version=\"small\"\n+        )\n+        self.assertEqual(x_train.shape[1], 8)\n+        # Ensure the small dataset contains 600 samples as documented\n+        self.assertEqual(x_train.shape[0] + x_test.shape[0], 600)\n+\n+    def test_invalid_version(self):\n+        with self.assertRaises(ValueError):\n+            california_housing.load_data(version=\"invalid_version\")\n+\n+    def test_seed_reproducibility(self):\n+        # Ensure the data is reproducible with the same seed\n+        seed = 123\n+        first_load = california_housing.load_data(version=\"large\", seed=seed)\n+        second_load = california_housing.load_data(version=\"large\", seed=seed)\n+        self.assertAllClose(first_load[0][0], second_load[0][0])\n+        self.assertAllClose(first_load[1][0], second_load[1][0])\n\n@@ -0,0 +1,35 @@\n+import numpy as np\n+\n+from keras import testing\n+from keras.datasets import cifar100\n+\n+\n+class Cifar100LoadDataTest(testing.TestCase):\n+    def test_shapes_fine_label_mode(self):\n+        (x_train, y_train), (x_test, y_test) = cifar100.load_data(\n+            label_mode=\"fine\"\n+        )\n+        self.assertEqual(x_train.shape, (50000, 32, 32, 3))\n+        self.assertEqual(y_train.shape, (50000, 1))\n+        self.assertEqual(x_test.shape, (10000, 32, 32, 3))\n+        self.assertEqual(y_test.shape, (10000, 1))\n+\n+    def test_shapes_coarse_label_mode(self):\n+        (x_train, y_train), (x_test, y_test) = cifar100.load_data(\n+            label_mode=\"coarse\"\n+        )\n+        self.assertEqual(x_train.shape, (50000, 32, 32, 3))\n+        self.assertEqual(y_train.shape, (50000, 1))\n+        self.assertEqual(x_test.shape, (10000, 32, 32, 3))\n+        self.assertEqual(y_test.shape, (10000, 1))\n+\n+    def test_dtypes(self):\n+        (x_train, y_train), (x_test, y_test) = cifar100.load_data()\n+        self.assertEqual(x_train.dtype, np.uint8)\n+        self.assertEqual(y_train.dtype, np.uint8)\n+        self.assertEqual(x_test.dtype, np.uint8)\n+        self.assertEqual(y_test.dtype, np.uint8)\n+\n+    def test_invalid_label_mode(self):\n+        with self.assertRaises(ValueError):\n+            cifar100.load_data(label_mode=\"invalid\")\n\n@@ -0,0 +1,38 @@\n+import numpy as np\n+\n+from keras import testing\n+from keras.datasets import cifar10\n+\n+\n+class Cifar10LoadDataTest(testing.TestCase):\n+    def test_x_train_shape(self):\n+        (x_train, _), _ = cifar10.load_data()\n+        self.assertEqual(x_train.shape, (50000, 32, 32, 3))\n+\n+    def test_y_train_shape(self):\n+        (_, y_train), _ = cifar10.load_data()\n+        self.assertEqual(y_train.shape, (50000, 1))\n+\n+    def test_x_test_shape(self):\n+        _, (x_test, _) = cifar10.load_data()\n+        self.assertEqual(x_test.shape, (10000, 32, 32, 3))\n+\n+    def test_y_test_shape(self):\n+        _, (_, y_test) = cifar10.load_data()\n+        self.assertEqual(y_test.shape, (10000, 1))\n+\n+    def test_x_train_dtype(self):\n+        (x_train, _), _ = cifar10.load_data()\n+        self.assertEqual(x_train.dtype, np.uint8)\n+\n+    def test_y_train_dtype(self):\n+        (_, y_train), _ = cifar10.load_data()\n+        self.assertEqual(y_train.dtype, np.uint8)\n+\n+    def test_x_test_dtype(self):\n+        _, (x_test, _) = cifar10.load_data()\n+        self.assertEqual(x_test.dtype, np.uint8)\n+\n+    def test_y_test_dtype(self):\n+        _, (_, y_test) = cifar10.load_data()\n+        self.assertEqual(y_test.dtype, np.uint8)\n\n@@ -0,0 +1,38 @@\n+import numpy as np\n+\n+from keras import testing\n+from keras.datasets import fashion_mnist\n+\n+\n+class FashionMnistLoadDataTest(testing.TestCase):\n+    def test_x_train_shape(self):\n+        (x_train, _), _ = fashion_mnist.load_data()\n+        self.assertEqual(x_train.shape, (60000, 28, 28))\n+\n+    def test_y_train_shape(self):\n+        (_, y_train), _ = fashion_mnist.load_data()\n+        self.assertEqual(y_train.shape, (60000,))\n+\n+    def test_x_test_shape(self):\n+        _, (x_test, _) = fashion_mnist.load_data()\n+        self.assertEqual(x_test.shape, (10000, 28, 28))\n+\n+    def test_y_test_shape(self):\n+        _, (_, y_test) = fashion_mnist.load_data()\n+        self.assertEqual(y_test.shape, (10000,))\n+\n+    def test_x_train_dtype(self):\n+        (x_train, _), _ = fashion_mnist.load_data()\n+        self.assertEqual(x_train.dtype, np.uint8)\n+\n+    def test_y_train_dtype(self):\n+        (_, y_train), _ = fashion_mnist.load_data()\n+        self.assertEqual(y_train.dtype, np.uint8)\n+\n+    def test_x_test_dtype(self):\n+        _, (x_test, _) = fashion_mnist.load_data()\n+        self.assertEqual(x_test.dtype, np.uint8)\n+\n+    def test_y_test_dtype(self):\n+        _, (_, y_test) = fashion_mnist.load_data()\n+        self.assertEqual(y_test.dtype, np.uint8)\n\n@@ -0,0 +1,48 @@\n+import numpy as np\n+\n+from keras import testing\n+from keras.datasets import imdb\n+\n+\n+class ImdbLoadDataTest(testing.TestCase):\n+    def test_load_data_default(self):\n+        (x_train, y_train), (x_test, y_test) = imdb.load_data()\n+        self.assertIsInstance(x_train, list)\n+        self.assertIsInstance(y_train, np.ndarray)\n+        self.assertIsInstance(x_test, list)\n+        self.assertIsInstance(y_test, np.ndarray)\n+\n+        # Check lengths\n+        self.assertEqual(len(x_train), 25000)\n+        self.assertEqual(len(y_train), 25000)\n+        self.assertEqual(len(x_test), 25000)\n+        self.assertEqual(len(y_test), 25000)\n+\n+        # Check types within lists for x\n+        self.assertIsInstance(x_train[0], list)\n+        self.assertIsInstance(x_test[0], list)\n+\n+    def test_num_words(self):\n+        # Only consider the top 1000 words\n+        (x_train, _), _ = imdb.load_data(num_words=1000)\n+        # Ensure that no word index exceeds 999 (0-based indexing)\n+        max_index = max(max(sequence) for sequence in x_train if sequence)\n+        self.assertLessEqual(max_index, 999)\n+\n+    def test_skip_top(self):\n+        # Skip the top 10 most frequent words\n+        (x_train, _), _ = imdb.load_data(skip_top=10, num_words=1000)\n+        # Check if top 10 words are skipped properly\n+        self.assertNotIn(1, x_train[0])  # Assuming 1 is among top 10\n+\n+    def test_maxlen(self):\n+        # Only consider sequences shorter than 100\n+        (x_train, _), _ = imdb.load_data(maxlen=100)\n+        self.assertTrue(all(len(seq) <= 100 for seq in x_train))\n+\n+    def test_get_word_index(self):\n+        word_index = imdb.get_word_index()\n+        self.assertIsInstance(word_index, dict)\n+        # Check if word_index contains specific known words\n+        self.assertIn(\"the\", word_index)\n+        self.assertIn(\"and\", word_index)\n\n@@ -0,0 +1,38 @@\n+import numpy as np\n+\n+from keras import testing\n+from keras.datasets import mnist\n+\n+\n+class MnistLoadDataTest(testing.TestCase):\n+    def test_x_train_shape(self):\n+        (x_train, _), _ = mnist.load_data()\n+        self.assertEqual(x_train.shape, (60000, 28, 28))\n+\n+    def test_y_train_shape(self):\n+        (_, y_train), _ = mnist.load_data()\n+        self.assertEqual(y_train.shape, (60000,))\n+\n+    def test_x_test_shape(self):\n+        _, (x_test, _) = mnist.load_data()\n+        self.assertEqual(x_test.shape, (10000, 28, 28))\n+\n+    def test_y_test_shape(self):\n+        _, (_, y_test) = mnist.load_data()\n+        self.assertEqual(y_test.shape, (10000,))\n+\n+    def test_x_train_dtype(self):\n+        (x_train, _), _ = mnist.load_data()\n+        self.assertEqual(x_train.dtype, np.uint8)\n+\n+    def test_y_train_dtype(self):\n+        (_, y_train), _ = mnist.load_data()\n+        self.assertEqual(y_train.dtype, np.uint8)\n+\n+    def test_x_test_dtype(self):\n+        _, (x_test, _) = mnist.load_data()\n+        self.assertEqual(x_test.dtype, np.uint8)\n+\n+    def test_y_test_dtype(self):\n+        _, (_, y_test) = mnist.load_data()\n+        self.assertEqual(y_test.dtype, np.uint8)\n\n@@ -0,0 +1,51 @@\n+import numpy as np\n+\n+from keras import testing\n+from keras.datasets import reuters\n+\n+\n+class ReutersLoadDataTest(testing.TestCase):\n+    def test_load_data_default(self):\n+        (x_train, y_train), (x_test, y_test) = reuters.load_data()\n+        # Check types\n+        self.assertIsInstance(x_train, np.ndarray)\n+        self.assertIsInstance(y_train, np.ndarray)\n+        self.assertIsInstance(x_test, np.ndarray)\n+        self.assertIsInstance(y_test, np.ndarray)\n+\n+        # Check shapes\n+        self.assertGreater(len(x_train), 0)\n+        self.assertEqual(len(x_train), len(y_train))\n+        self.assertGreater(len(x_test), 0)\n+        self.assertEqual(len(x_test), len(y_test))\n+\n+    def test_num_words(self):\n+        # Only consider the top 1000 words\n+        (x_train, _), _ = reuters.load_data(num_words=1000)\n+        # Ensure no word index exceeds 999 (0-based indexing)\n+        max_index = max(max(sequence) for sequence in x_train if sequence)\n+        self.assertLessEqual(max_index, 999)\n+\n+    def test_skip_top(self):\n+        # Skip the top 10 most frequent words\n+        (x_train, _), _ = reuters.load_data(skip_top=10, num_words=1000)\n+        # Assuming 1 is among top 10, check if it's skipped\n+        self.assertNotIn(1, x_train[0])\n+\n+    def test_maxlen(self):\n+        # Only consider sequences shorter than 50\n+        (x_train, _), _ = reuters.load_data(maxlen=50)\n+        self.assertTrue(all(len(seq) <= 50 for seq in x_train))\n+\n+    def test_get_word_index(self):\n+        word_index = reuters.get_word_index()\n+        self.assertIsInstance(word_index, dict)\n+        # Check if word_index contains specific known words\n+        self.assertIn(\"the\", word_index)\n+\n+    def test_get_label_names(self):\n+        label_names = reuters.get_label_names()\n+        self.assertIsInstance(label_names, tuple)\n+        # Check if the tuple contains specific known labels\n+        self.assertIn(\"earn\", label_names)\n+        self.assertIn(\"acq\", label_names)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a48c46182a6a01efc660d65d3e0606053fc96097", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 4 | Churn Cumulative: 6407 | Contributors (this commit): 9 | Commits (past 90d): 19 | Contributors (cumulative): 9 | DMM Complexity: 0.0\n\nDIFF:\n@@ -4559,12 +4559,10 @@ class SparseTest(testing.TestCase, parameterized.TestCase):\n         self.assertSameSparseness(op_class()(x), x)\n \n     @parameterized.named_parameters(OTHER_UNARY_OPS_TESTS)\n+    @pytest.mark.skipif(backend.backend() == \"tensorflow\", reason=\"temporary\")\n     def test_other_unary_symbolic_sparse_correctness(\n         self, op_function, op_class, np_op, op_kwargs, input_shape\n     ):\n-        if self._tensorflow_uses_gpu():\n-            self.skipTest(\"Skipping test with TF + GPU due to XLA error\")\n-\n         x = np.random.random(input_shape)\n         if op_function is knp.mean:\n             x = create_indexed_slices(x)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c2733bfa96bc2666f9f214a2e7eed6cb8a5576f4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 17 | Files Changed: 4 | Hunks: 10 | Methods Changed: 10 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 44 | Churn Cumulative: 7468 | Contributors (this commit): 13 | Commits (past 90d): 37 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -64,7 +64,7 @@ class LinalgOpsDynamicShapeTest(testing.TestCase):\n             linalg.inv(x)\n \n     def test_lu_factor(self):\n-        if self._jax_uses_gpu():\n+        if testing.jax_uses_gpu():\n             self.skipTest(\"Skipping test with JAX + GPU due to temporary error\")\n \n         x = KerasTensor([None, 4, 3])\n@@ -130,7 +130,7 @@ class LinalgOpsDynamicShapeTest(testing.TestCase):\n             linalg.solve(a, b)\n \n     def test_solve_triangular(self):\n-        if self._jax_uses_gpu():\n+        if testing.jax_uses_gpu():\n             self.skipTest(\"Skipping test with JAX + GPU due to temporary error\")\n \n         a = KerasTensor([None, 20, 20])\n@@ -218,7 +218,7 @@ class LinalgOpsStaticShapeTest(testing.TestCase):\n             linalg.inv(x)\n \n     def test_lu_factor(self):\n-        if self._jax_uses_gpu():\n+        if testing.jax_uses_gpu():\n             self.skipTest(\"Skipping test with JAX + GPU due to temporary error\")\n \n         x = KerasTensor([10, 4, 3])\n@@ -278,7 +278,7 @@ class LinalgOpsStaticShapeTest(testing.TestCase):\n             linalg.solve(a, b)\n \n     def test_solve_triangular(self):\n-        if self._jax_uses_gpu():\n+        if testing.jax_uses_gpu():\n             self.skipTest(\"Skipping test with JAX + GPU due to temporary error\")\n \n         a = KerasTensor([4, 3, 3])\n@@ -356,7 +356,7 @@ class LinalgOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         )\n \n     def test_lu_factor(self):\n-        if self._jax_uses_gpu():\n+        if testing.jax_uses_gpu():\n             self.skipTest(\"Skipping test with JAX + GPU due to temporary error\")\n \n         def _pivot_matrix(pivots, n):\n@@ -480,7 +480,7 @@ class LinalgOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(output, expected_result)\n \n     def test_solve_triangular(self):\n-        if self._jax_uses_gpu():\n+        if testing.jax_uses_gpu():\n             self.skipTest(\"Skipping test with JAX + GPU due to temporary error\")\n \n         # 2d-case\n\n@@ -4559,7 +4559,9 @@ class SparseTest(testing.TestCase, parameterized.TestCase):\n         self.assertSameSparseness(op_class()(x), x)\n \n     @parameterized.named_parameters(OTHER_UNARY_OPS_TESTS)\n-    @pytest.mark.skipif(backend.backend() == \"tensorflow\", reason=\"temporary\")\n+    @pytest.mark.skipif(\n+        testing.tensorflow_uses_gpu(), reason=\"Temporary, XLA error\"\n+    )\n     def test_other_unary_symbolic_sparse_correctness(\n         self, op_function, op_class, np_op, op_kwargs, input_shape\n     ):\n\n@@ -1 +1,5 @@\n from keras.testing.test_case import TestCase\n+from keras.testing.test_case import jax_uses_gpu\n+from keras.testing.test_case import tensorflow_uses_gpu\n+from keras.testing.test_case import torch_uses_gpu\n+from keras.testing.test_case import uses_gpu\n\n@@ -549,22 +549,26 @@ class TestCase(unittest.TestCase):\n                     if is_float_dtype(dtype):\n                         self.assertEqual(dtype, \"float32\")\n \n-    def _uses_gpu(self):\n+\n+def tensorflow_uses_gpu():\n+    return backend.backend() == \"tensorflow\" and uses_gpu()\n+\n+\n+def jax_uses_gpu():\n+    return backend.backend() == \"jax\" and uses_gpu()\n+\n+\n+def torch_uses_gpu():\n+    return backend.backend() == \"torch\" and uses_gpu()\n+\n+\n+def uses_gpu():\n     # Condition used to skip tests when using the GPU\n     devices = distribution.list_devices()\n     if any(d.startswith(\"gpu\") for d in devices):\n         return True\n     return False\n \n-    def _tensorflow_uses_gpu(self):\n-        return backend.backend() == \"tensorflow\" and self._uses_gpu()\n-\n-    def _jax_uses_gpu(self):\n-        return backend.backend() == \"jax\" and self._uses_gpu()\n-\n-    def _torch_uses_gpu(self):\n-        return backend.backend() == \"torch\" and self._uses_gpu()\n-\n \n def create_keras_tensors(input_shape, dtype, sparse):\n     if isinstance(input_shape, dict):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5dd801a1577919a6457a376c04b4183410a751fb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 6413 | Contributors (this commit): 9 | Commits (past 90d): 21 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -4560,7 +4560,7 @@ class SparseTest(testing.TestCase, parameterized.TestCase):\n \n     @parameterized.named_parameters(OTHER_UNARY_OPS_TESTS)\n     @pytest.mark.skipif(\n-        testing.tensorflow_uses_gpu(), reason=\"Temporary, XLA error\"\n+        backend.backend() == \"tensorflow\", reason=\"Temporary, XLA error\"\n     )\n     def test_other_unary_symbolic_sparse_correctness(\n         self, op_function, op_class, np_op, op_kwargs, input_shape\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
