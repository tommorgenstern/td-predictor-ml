{"custom_id": "keras#355568a25e1bcb917bd7a2a2f99da7e902f7df2e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 10 | Files Changed: 4 | Hunks: 13 | Methods Changed: 6 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 31 | Churn Cumulative: 12861 | Contributors (this commit): 107 | Commits (past 90d): 24 | Contributors (cumulative): 125 | DMM Complexity: 0.5\n\nDIFF:\n@@ -143,9 +143,11 @@ def set_callback_parameters(\n         mode: String. One of ModeKeys.TRAIN, ModeKeys.TEST, or ModeKeys.PREDICT.\n           Which loop mode to configure callbacks for.\n     \"\"\"\n-    metric_names = model.metrics_names\n+    metric_names = None\n     for cbk in callback_list:\n         if isinstance(cbk, (BaseLogger, ProgbarLogger)):\n+            if not metric_names:\n+                metric_names = model.metrics_names\n             cbk.stateful_metrics = metric_names[1:]  # Exclude `loss`\n \n     # Set callback parameters\n@@ -153,6 +155,8 @@ def set_callback_parameters(\n     # When we have deferred build scenario with iterator input, we will compile\n     # when we standardize first batch of data.\n     if mode != ModeKeys.PREDICT:\n+        if not metric_names:\n+            metric_names = model.metrics_names\n         callback_metrics = copy.copy(metric_names)\n         if do_validation:\n             callback_metrics += [\"val_\" + n for n in metric_names]\n@@ -900,6 +904,13 @@ class Callback:\n               method but that may change in the future.\n         \"\"\"\n \n+    def make_logs(self, model, logs, outputs, mode, prefix=''):\n+        \"\"\"Computes logs for sending to `on_batch_end` methods.\"\"\"\n+        if not self.callbacks:\n+            return logs\n+\n+        return make_logs(model, logs, outputs, mode, prefix=prefix)\n+\n     def _implements_train_batch_hooks(self):\n         \"\"\"Determines if this Callback should be called for each train batch.\"\"\"\n         return (\n\n@@ -363,7 +363,7 @@ def model_iteration(\n                 aggregator.aggregate(batch_outs)\n \n                 # Callbacks batch end.\n-                batch_logs = cbks.make_logs(model, batch_logs, batch_outs, mode)\n+                batch_logs = callbacks.make_logs(model, batch_logs, batch_outs, mode)\n                 callbacks._call_batch_hook(mode, \"end\", step, batch_logs)\n                 step += 1\n \n@@ -426,7 +426,7 @@ def model_iteration(\n                 aggregator.aggregate(batch_outs, batch_start, batch_end)\n \n                 # Callbacks batch end.\n-                batch_logs = cbks.make_logs(model, batch_logs, batch_outs, mode)\n+                batch_logs = callbacks.make_logs(model, batch_logs, batch_outs, mode)\n                 callbacks._call_batch_hook(mode, \"end\", batch_index, batch_logs)\n \n                 if callbacks.model.stop_training:\n@@ -434,7 +434,7 @@ def model_iteration(\n \n         aggregator.finalize()\n         results = aggregator.results\n-        epoch_logs = cbks.make_logs(model, epoch_logs, results, mode)\n+        epoch_logs = callbacks.make_logs(model, epoch_logs, results, mode)\n         if len(results) == 1:\n             results = results[0]\n \n@@ -469,7 +469,7 @@ def model_iteration(\n             )\n             if not isinstance(val_results, list):\n                 val_results = [val_results]\n-            epoch_logs = cbks.make_logs(\n+            epoch_logs = callbacks.make_logs(\n                 model, epoch_logs, val_results, mode, prefix=\"val_\"\n             )\n             if val_iterator and epoch < epochs - 1:\n\n@@ -448,7 +448,7 @@ def experimental_tpu_test_loop(\n                 # mirrored vars.\n                 outs[i] = batch_outs[label]\n \n-        batch_logs = cbks.make_logs(model, batch_logs, outs, mode)\n+        batch_logs = callbacks.make_logs(model, batch_logs, outs, mode)\n         callbacks._call_batch_hook(mode, \"end\", current_step, batch_logs)\n         if verbose == 1:\n             progbar.update(current_step + 1)\n@@ -617,7 +617,7 @@ def experimental_tpu_predict_loop(\n             ]\n             unconcatenated_outs[i].extend(single_model_output)\n \n-        batch_logs = cbks.make_logs(model, batch_logs, batch_outs, mode)\n+        batch_logs = callbacks.make_logs(model, batch_logs, batch_outs, mode)\n         callbacks._call_batch_hook(mode, \"end\", current_step, batch_logs)\n         if verbose == 1:\n             progbar.update(current_step + 1)\n\n@@ -306,7 +306,7 @@ def model_iteration(\n             aggregator.aggregate(batch_outs)\n \n             # Callbacks batch end.\n-            batch_logs = cbks.make_logs(model, batch_logs, batch_outs, mode)\n+            batch_logs = callbacks.make_logs(model, batch_logs, batch_outs, mode)\n             callbacks._call_batch_hook(mode, \"end\", step, batch_logs)\n             step += 1\n \n@@ -315,7 +315,7 @@ def model_iteration(\n \n         aggregator.finalize()\n         results = aggregator.results\n-        epoch_logs = cbks.make_logs(model, epoch_logs, results, mode)\n+        epoch_logs = callbacks.make_logs(model, epoch_logs, results, mode)\n         if len(results) == 1:\n             results = results[0]\n \n@@ -342,7 +342,7 @@ def model_iteration(\n \n             if not isinstance(val_results, list):\n                 val_results = [val_results]\n-            epoch_logs = cbks.make_logs(\n+            epoch_logs = callbacks.make_logs(\n                 model, epoch_logs, val_results, mode, prefix=\"val_\"\n             )\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#84639bdd8722ec1687cf03e3fea081212a822669", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 2829 | Contributors (this commit): 18 | Commits (past 90d): 18 | Contributors (cumulative): 18 | DMM Complexity: 0.0\n\nDIFF:\n@@ -353,6 +353,12 @@ class TensorLikeDataAdapter(DataAdapter):\n \n             dataset = dataset.map(shuffle_batch)\n \n+        options = tf.data.Options()\n+        options.experimental_distribute.auto_shard_policy = (\n+            tf.data.experimental.AutoShardPolicy.DATA\n+        )\n+        dataset = dataset.with_options(options)\n+\n         self._dataset = dataset\n \n     def slice_inputs(self, indices_dataset, inputs):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ebb5e0e3f5e0b02cad2b54144022084301588ac5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 510 | Lines Deleted: 449 | Files Changed: 13 | Hunks: 188 | Methods Changed: 98 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 959 | Churn Cumulative: 14674 | Contributors (this commit): 19 | Commits (past 90d): 54 | Contributors (cumulative): 102 | DMM Complexity: 0.5333333333333333\n\nDIFF:\n@@ -42,9 +42,9 @@ class AutoCastVariable(tf.Variable, tf.__internal__.types.Tensor):\n     \"\"\"Variable that will cast itself to a different dtype in applicable contexts.\n \n     This class wraps a floating-point `tf.Variable`. It emulates the variable\n-    interface and delegates to the wrapped variable, but it additionally will cast\n-    the wrapped variable under an `enable_auto_cast_variables(dtype)` context\n-    manager.\n+    interface and delegates to the wrapped variable, but it additionally will\n+    cast the wrapped variable under an `enable_auto_cast_variables(dtype)`\n+    context manager.\n \n     For example:\n \n@@ -57,8 +57,8 @@ class AutoCastVariable(tf.Variable, tf.__internal__.types.Tensor):\n     tf.float16\n \n     The purpose of this class is to allow Keras layers to create variables in\n-    float32, and automatically cast them to float16 or bfloat16 when the layer is\n-    called.\n+    float32, and automatically cast them to float16 or bfloat16 when the layer\n+    is called.\n     \"\"\"\n \n     def __init__(self, variable):\n@@ -81,10 +81,10 @@ class AutoCastVariable(tf.Variable, tf.__internal__.types.Tensor):\n                 \"type: %s\" % variable.dtype.name\n             )\n         self._variable = variable\n-        # 'delegate' means AutoCastVariable.op return self._variable.op, which will\n-        # raise an AttributeError in Eager (as intended). If set to any other value,\n-        # AutoCastVariable.op returns that value instead, which is used to set the\n-        # op attribute in AutoCastVariable.assign().\n+        # 'delegate' means AutoCastVariable.op return self._variable.op, which\n+        # will raise an AttributeError in Eager (as intended). If set to any\n+        # other value, AutoCastVariable.op returns that value instead, which is\n+        # used to set the op attribute in AutoCastVariable.assign().\n         self._op = \"delegate\"\n \n     def _should_cast(self):\n@@ -133,8 +133,8 @@ class AutoCastVariable(tf.Variable, tf.__internal__.types.Tensor):\n     def _dense_var_to_tensor(self, dtype=None, name=None, as_ref=False):\n         \"\"\"Converts this variable to a tensor.\"\"\"\n         if as_ref:\n-            # This ValueError should not occur in practice since it is impossible to\n-            # pass as_ref=True using public APIs.\n+            # This ValueError should not occur in practice since it is\n+            # impossible to pass as_ref=True using public APIs.\n             raise ValueError(\n                 \"Cannot convert AutoCastVariable to a tensor if \"\n                 \"as_ref=True is passed to convert_to_tensor\"\n@@ -184,9 +184,9 @@ class AutoCastVariable(tf.Variable, tf.__internal__.types.Tensor):\n     #   * 'count_up_to': This method only applies to int variables, which cannot\n     #     be wrapped with an AutoCastVariable.\n     #   * 'ref': Instead we inherit the definition from Variable.\n-    #     If we defined and delegated to Variable, the ref of an AutoCastVariable\n-    #     would be the same as the ref of the underlying variable, which would be\n-    #     strange as they are different Python objects.\n+    #     If we defined and delegated to Variable, the ref of an\n+    #     AutoCastVariable would be the same as the ref of the underlying\n+    #     variable, which would be strange as they are different Python objects.\n \n     def set_shape(self, shape):\n         return self._variable.set_shape(self, shape)\n@@ -221,14 +221,15 @@ class AutoCastVariable(tf.Variable, tf.__internal__.types.Tensor):\n         self, update_fn, value, use_locking=None, name=None, read_value=True\n     ):\n         # TODO(b/146181571): This logic can be simplified once\n-        # DistributedVariable.assign returns a DistributedVariable. Currently for\n-        # MirroredStrategy, it returns a Mirrored value.\n+        # DistributedVariable.assign returns a DistributedVariable. Currently\n+        # for MirroredStrategy, it returns a Mirrored value.\n         if tf.compat.v1.executing_eagerly_outside_functions():\n             assign_op = update_fn(value, use_locking, name, False)\n             if read_value:\n-                # We create a new AutoCastVariable with the same underlying tf.Variable.\n-                # The new AutoCastVariable is identical except the 'op' attribute is\n-                # defined. This matches the behavior of tf.Variable.assign.\n+                # We create a new AutoCastVariable with the same underlying\n+                # tf.Variable.  The new AutoCastVariable is identical except the\n+                # 'op' attribute is defined. This matches the behavior of\n+                # tf.Variable.assign.\n                 var = create_autocast_variable(self._variable)\n                 var._op = assign_op  # pylint:disable=protected-access\n                 return var\n@@ -367,8 +368,8 @@ class AutoCastVariable(tf.Variable, tf.__internal__.types.Tensor):\n     def _gather_saveables_for_checkpoint(self):\n         # By delegating this method to the wrapped variable, checkpoints with\n         # AutoCastVariables are identical to checkpoints with normal variables.\n-        # Therefore models checkpointed with AutoCastVariables can be restored on\n-        # models with normal variables, and vice versa.\n+        # Therefore models checkpointed with AutoCastVariables can be restored\n+        # on models with normal variables, and vice versa.\n         return (\n             self._variable._gather_saveables_for_checkpoint()\n         )  # pylint:disable=protected-access\n@@ -493,28 +494,32 @@ class AutoCastVariable(tf.Variable, tf.__internal__.types.Tensor):\n         try:\n             return self.read_value().__div__(o)\n         except AttributeError:\n-            # See https://docs.python.org/3/library/constants.html#NotImplemented\n+            # See\n+            # https://docs.python.org/3/library/constants.html#NotImplemented\n             return NotImplemented\n \n     def __rdiv__(self, o):\n         try:\n             return self.read_value().__rdiv__(o)\n         except AttributeError:\n-            # See https://docs.python.org/3/library/constants.html#NotImplemented\n+            # See\n+            # https://docs.python.org/3/library/constants.html#NotImplemented\n             return NotImplemented\n \n     def __matmul__(self, o):\n         try:\n             return self.read_value().__matmul__(o)\n         except AttributeError:\n-            # See https://docs.python.org/3/library/constants.html#NotImplemented\n+            # See\n+            # https://docs.python.org/3/library/constants.html#NotImplemented\n             return NotImplemented\n \n     def __rmatmul__(self, o):\n         try:\n             return self.read_value().__rmatmul__(o)\n         except AttributeError:\n-            # See https://docs.python.org/3/library/constants.html#NotImplemented\n+            # See\n+            # https://docs.python.org/3/library/constants.html#NotImplemented\n             return NotImplemented\n \n     # pylint: enable=multiple-statements\n@@ -528,9 +533,9 @@ tf.register_tensor_conversion_function(\n def create_autocast_variable(variable):\n     \"\"\"Creates an AutoCastVariable that wraps another variable.\n \n-    This typically just returns `AutoCastVariable(variable)`. But, if the variable\n-    is a DistributedVariable or one of its subclasses, we instead dynamically\n-    create a class that subclasses from both AutoCastVariable and\n+    This typically just returns `AutoCastVariable(variable)`. But, if the\n+    variable is a DistributedVariable or one of its subclasses, we instead\n+    dynamically create a class that subclasses from both AutoCastVariable and\n     variable.__class__. This is so the returned variable will still pass\n     `isinstance(variable, variable.__class__)`, which is required for\n     DistributedVariables and its subclasses to work properly.\n\n@@ -52,9 +52,9 @@ def set_cpu_logical_devices_to_at_least(num):\n         raise RuntimeError(\"No CPU found\")\n     if len(physical_devices) >= num:\n         return\n-    # By default each physical device corresponds to one logical device. We create\n-    # multiple logical devices for the last physical device so that we have `num`\n-    # logical devices.\n+    # By default each physical device corresponds to one logical device. We\n+    # create multiple logical devices for the last physical device so that we\n+    # have `num` logical devices.\n     num = num - len(physical_devices) + 1\n     logical_devices = []\n     for _ in range(num):\n@@ -103,8 +103,8 @@ class AutoCastVariableTest(tf.test.TestCase, parameterized.TestCase):\n \n     def test_sparse_reads(self):\n         x = get_var([1.0, 2], tf.float32)\n-        # DistributedVariables do not support sparse_read or gather_nd, so we pass\n-        # distribute=False\n+        # DistributedVariables do not support sparse_read or gather_nd, so we\n+        # pass distribute=False\n         x = autocast_variable.create_autocast_variable(x)\n         self.evaluate(x.initializer)\n \n@@ -154,9 +154,10 @@ class AutoCastVariableTest(tf.test.TestCase, parameterized.TestCase):\n         with self.test_session(), distribution.scope():\n             for read_dtype in (tf.float32, tf.float16):\n                 if tf.distribute.has_strategy() and not tf.executing_eagerly():\n-                    # MirroredVariable.assign will (incorrectly) return a Mirrored value\n-                    # instead of a MirroredVariable in graph mode.\n-                    # So we cannot properly wrap it in an AutoCastVariable.\n+                    # MirroredVariable.assign will (incorrectly) return a\n+                    # Mirrored value instead of a MirroredVariable in graph\n+                    # mode.  So we cannot properly wrap it in an\n+                    # AutoCastVariable.\n                     evaluate = self.evaluate\n                 else:\n \n@@ -183,14 +184,16 @@ class AutoCastVariableTest(tf.test.TestCase, parameterized.TestCase):\n                     self.assertEqual(self.evaluate(x.initialized_value()), 7)\n                     if not tf.executing_eagerly():\n                         if not tf.distribute.has_strategy():\n-                            # These functions are not supported for DistributedVariables\n+                            # These functions are not supported for\n+                            # DistributedVariables\n                             x.load(9)\n                             self.assertEqual(x.eval(), 9)\n                         self.assertEqual(self.evaluate(x.initial_value), 7)\n                         self.assertEqual(x.op, x._variable.op)\n                         self.assertEqual(x.graph, x._variable.graph)\n                     if not tf.distribute.has_strategy():\n-                        # These attributes are not supported for DistributedVariables\n+                        # These attributes are not supported for\n+                        # DistributedVariables\n                         self.assertIsNone(x.constraint)\n                         self.assertEqual(x.initializer, x._variable.initializer)\n                     self.assertEqual(evaluate(x.assign(8)), 8)\n@@ -329,17 +332,20 @@ class AutoCastVariableTest(tf.test.TestCase, parameterized.TestCase):\n                 # Attempt to assign float16 values\n                 with self.assertRaisesRegex(\n                     ValueError,\n-                    \"conversion requested dtype float32 for Tensor with dtype float16\",\n+                    \"conversion requested dtype float32 for Tensor with dtype \"\n+                    \"float16\",\n                 ):\n                     self.evaluate(x.assign(v2))\n                 with self.assertRaisesRegex(\n                     ValueError,\n-                    \"conversion requested dtype float32 for Tensor with dtype float16\",\n+                    \"conversion requested dtype float32 for Tensor with dtype \"\n+                    \"float16\",\n                 ):\n                     self.evaluate(x.assign_add(v2))\n                 with self.assertRaisesRegex(\n                     ValueError,\n-                    \"conversion requested dtype float32 for Tensor with dtype float16\",\n+                    \"conversion requested dtype float32 for Tensor with dtype \"\n+                    \"float16\",\n                 ):\n                     self.evaluate(x.assign_sub(v2))\n \n@@ -350,7 +356,8 @@ class AutoCastVariableTest(tf.test.TestCase, parameterized.TestCase):\n                 self.assertAllClose(3.0, self.evaluate(x.assign_sub(3.0)))\n \n                 # Assign multiple times\n-                # This currently doesn't work in graph mode if a strategy is used\n+                # This currently doesn't work in graph mode if a strategy is\n+                # used\n                 if not tf.distribute.has_strategy() or tf.executing_eagerly():\n                     assign = x.assign(1.0)\n                     self.assertAllClose(1.0, self.evaluate(assign))\n@@ -431,9 +438,10 @@ class AutoCastVariableTest(tf.test.TestCase, parameterized.TestCase):\n             x = get_var(0.0, tf.float32)\n             x = autocast_variable.create_autocast_variable(x)\n \n-            # Variable.op raises an AttributeError in Eager mode and is an op in graph\n-            # mode. Variable.assign(...).op is None in Eager mode and an op in Graph\n-            # mode or a tf.function. We test this is also true of AutoCastVariable.\n+            # Variable.op raises an AttributeError in Eager mode and is an op in\n+            # graph mode. Variable.assign(...).op is None in Eager mode and an\n+            # op in Graph mode or a tf.function. We test this is also true of\n+            # AutoCastVariable.\n             if tf.executing_eagerly():\n                 with self.assertRaises(AttributeError):\n                     x.op  # pylint: disable=pointless-statement\n@@ -478,13 +486,13 @@ class AutoCastVariableTest(tf.test.TestCase, parameterized.TestCase):\n             x = get_var(1.0, tf.float32)\n             x = autocast_variable.create_autocast_variable(x)\n             self.evaluate(x.initializer)\n-            # small_val is a value such that 1.0 + small_val == 1.0 in fp16, but not\n-            # in fp32\n+            # small_val is a value such that 1.0 + small_val == 1.0 in fp16, but\n+            # not in fp32\n             small_val = np.finfo(\"float16\").eps / 2\n             small_tensor = tf.constant(small_val, dtype=tf.float32)\n             with autocast_variable.enable_auto_cast_variables(tf.float16):\n-                # Variable should be increased, despite it appearing to be the same\n-                # float16 value.\n+                # Variable should be increased, despite it appearing to be the\n+                # same float16 value.\n                 self.evaluate(x.assign(1.0 + small_tensor))\n                 self.assertEqual(1.0, self.evaluate(x.value()))\n             self.assertEqual(1.0 + small_val, self.evaluate(x))\n@@ -503,7 +511,8 @@ class AutoCastVariableTest(tf.test.TestCase, parameterized.TestCase):\n         with autocast_variable.enable_auto_cast_variables(tf.float16):\n             self.assertEqual(tf.identity(x).dtype, tf.float16)\n \n-            # New threads should not see the modified value of the autocast dtype.\n+            # New threads should not see the modified value of the autocast\n+            # dtype.\n             var_dtype = None\n \n             def f():\n@@ -547,8 +556,8 @@ class AutoCastVariableTest(tf.test.TestCase, parameterized.TestCase):\n                 autocast_variable.create_autocast_variable(x)\n \n     def test_repr(self):\n-        # We do not test with DistributionStrategy because we do not want to rely on\n-        # the exact __repr__ output of a DistributedVariable.\n+        # We do not test with DistributionStrategy because we do not want to\n+        # rely on the exact __repr__ output of a DistributedVariable.\n         x = get_var(1.0, tf.float32, name=\"x\")\n         x = autocast_variable.create_autocast_variable(x)\n         if tf.executing_eagerly():\n@@ -622,8 +631,8 @@ class AutoCastVariableTest(tf.test.TestCase, parameterized.TestCase):\n         opt = optimizer_class(learning_rate=1.0)\n \n         def f():\n-            # Minimize both the AutoCastVariable and the normal tf.Variable. Both\n-            # variables should be updated to the same value.\n+            # Minimize both the AutoCastVariable and the normal tf.Variable.\n+            # Both variables should be updated to the same value.\n             op = opt.minimize(lambda: x + y, var_list=[x, y])\n             return (\n                 None\n@@ -642,8 +651,8 @@ class AutoCastVariableTest(tf.test.TestCase, parameterized.TestCase):\n             self.evaluate(op)\n         # Assert the AutoCastVariable has changed from its initial value\n         self.assertNotEqual(self.evaluate(x), 1.0)\n-        # Assert AutoCastVariable is updated correctly by comparing it to the normal\n-        # variable\n+        # Assert AutoCastVariable is updated correctly by comparing it to the\n+        # normal variable\n         self.assertAlmostEqual(self.evaluate(x), self.evaluate(y))\n         if optimizer_class in (\n             gradient_descent_v2.SGD,\n\n@@ -66,8 +66,8 @@ def _log_device_compatibility_check(policy_name, gpu_details_list):\n         `tf.config.experimental.get_device_details()`.\n     \"\"\"\n     if policy_name != \"mixed_float16\":\n-        # TODO(b/145686977): Log if the policy is 'mixed_bfloat16'. This requires\n-        # checking if a TPU is available.\n+        # TODO(b/145686977): Log if the policy is 'mixed_bfloat16'. This\n+        # requires checking if a TPU is available.\n         return\n     supported_device_strs = []\n     unsupported_device_strs = []\n\n@@ -60,9 +60,9 @@ class DeviceCompatibilityCheckTest(tf.test.TestCase):\n         details_list = [device_details(\"GPU 1\", (7, 1))]\n         regex = re.compile(\n             r\".*compatibility check \\(mixed_float16\\): OK\\n\"\n-            r\"Your GPU will likely run quickly with dtype policy mixed_float16 as \"\n-            r\"it has compute capability of at least 7.0. Your GPU: GPU 1, compute \"\n-            r\"capability 7.1\",\n+            r\"Your GPU will likely run quickly with dtype policy mixed_float16 \"\n+            r\"as it has compute capability of at least 7.0. Your GPU: GPU 1, \"\n+            r\"compute capability 7.1\",\n             flags=re.MULTILINE,\n         )\n         self._test_compat_check(details_list, False, regex)\n@@ -74,8 +74,9 @@ class DeviceCompatibilityCheckTest(tf.test.TestCase):\n         ]\n         regex = re.compile(\n             r\".*compatibility check \\(mixed_float16\\): OK\\n\"\n-            r\"Your GPUs will likely run quickly with dtype policy mixed_float16 as \"\n-            r\"they all have compute capability of at least 7.0\",\n+            r\"Your GPUs will likely run quickly with dtype policy \"\n+            r\"mixed_float16 as they all have compute capability of \"\n+            r\"at least 7.0\",\n             flags=re.MULTILINE,\n         )\n         self._test_compat_check(details_list, False, regex)\n@@ -95,8 +96,8 @@ class DeviceCompatibilityCheckTest(tf.test.TestCase):\n         regex = re.compile(\n             r\".*compatibility check \\(mixed_float16\\): WARNING\\n\"\n             r\"Your GPU may run slowly with dtype policy mixed_float16.*\\n\"\n-            r\"  Unknown GPU, no compute capability \\(probably not an Nvidia GPU\\)\\n\"\n-            r\"See.*\",\n+            r\"  Unknown GPU, no compute capability \"\n+            r\"\\(probably not an Nvidia GPU\\)\\nSee.*\",\n             flags=re.MULTILINE,\n         )\n         self._test_compat_check(details_list, True, regex)\n@@ -134,8 +135,8 @@ class DeviceCompatibilityCheckTest(tf.test.TestCase):\n         details_list = []\n         regex = re.compile(\n             r\".*compatibility check \\(mixed_float16\\): WARNING\\n\"\n-            r\"The dtype policy mixed_float16 may run slowly because this machine \"\n-            r\"does not have a GPU\",\n+            r\"The dtype policy mixed_float16 may run slowly because this \"\n+            r\"machine does not have a GPU\",\n             flags=re.MULTILINE,\n         )\n         self._test_compat_check(details_list, True, regex)\n@@ -148,8 +149,8 @@ class DeviceCompatibilityCheckTest(tf.test.TestCase):\n         ]\n         regex = re.compile(\n             r\".*compatibility check \\(mixed_float16\\): WARNING\\n\"\n-            r\"Some of your GPUs may run slowly with dtype policy mixed_float16.*\\n\"\n-            r\"  GPU 1, compute capability 7.0 \\(x2\\)\\n\"\n+            r\"Some of your GPUs may run slowly with dtype policy \"\n+            r\"mixed_float16.*\\n  GPU 1, compute capability 7.0 \\(x2\\)\\n\"\n             r\"  GPU 2, compute capability 6.0\\n\"\n             r\"See.*\",\n             flags=re.MULTILINE,\n\n@@ -254,20 +254,20 @@ class LayerCorrectnessTest(test_combinations.TestCase):\n     ):\n         \"\"\"Tests a layer by comparing the float32 and mixed precision weights.\n \n-        A float32 layer, a mixed precision layer, and a distributed mixed precision\n-        layer are run. The three layers are identical other than their dtypes and\n-        distribution strategies. The outputs after predict() and weights after fit()\n-        are asserted to be close.\n+        A float32 layer, a mixed precision layer, and a distributed mixed\n+        precision layer are run. The three layers are identical other than their\n+        dtypes and distribution strategies. The outputs after predict() and\n+        weights after fit() are asserted to be close.\n \n         Args:\n-          f32_layer_fn: A function returning a float32 layer. The other two layers\n-            will automatically be created from this\n+          f32_layer_fn: A function returning a float32 layer. The other two\n+            layers will automatically be created from this.\n           input_shape: The shape of the input to the layer, including the batch\n             dimension. Or a list of shapes if the layer takes multiple inputs.\n           rtol: The relative tolerance to be asserted.\n           atol: The absolute tolerance to be asserted.\n-          input_data: A Numpy array with the data of the input. If None, input data\n-            will be randomly generated\n+          input_data: A Numpy array with the data of the input. If None, input\n+            data will be randomly generated.\n         \"\"\"\n \n         if (\n@@ -292,8 +292,8 @@ class LayerCorrectnessTest(test_combinations.TestCase):\n         # Compute per_replica_input_shapes for the distributed model\n         global_batch_size = input_shapes[0][0]\n         assert global_batch_size % strategy.num_replicas_in_sync == 0, (\n-            \"The number of replicas, %d, does not divide the global batch size of \"\n-            \"%d\" % (strategy.num_replicas_in_sync, global_batch_size)\n+            \"The number of replicas, %d, does not divide the global batch \"\n+            \"size of %d\" % (strategy.num_replicas_in_sync, global_batch_size)\n         )\n         per_replica_batch_size = (\n             global_batch_size // strategy.num_replicas_in_sync\n@@ -317,8 +317,8 @@ class LayerCorrectnessTest(test_combinations.TestCase):\n \n         # Generate input data\n         if input_data is None:\n-            # Cast inputs to float16 to avoid measuring error from having f16 layers\n-            # cast to float16.\n+            # Cast inputs to float16 to avoid measuring error from having f16\n+            # layers cast to float16.\n             input_data = [\n                 np.random.normal(size=s).astype(\"float16\") for s in input_shapes\n             ]\n\n@@ -102,8 +102,8 @@ class LayerTest(test_combinations.TestCase):\n                 self.v = self.add_weight(\"v\", dtype=\"int32\", trainable=False)\n \n             def call(self, inputs):\n-                # Only float variables should be autocasted. This will fail if self.v is\n-                # autocasted to float32\n+                # Only float variables should be autocasted. This will fail if\n+                # self.v is autocasted to float32\n                 return tf.cast(inputs, \"int32\") + self.v\n \n         x = tf.constant([1.0])\n@@ -194,16 +194,17 @@ class LayerTest(test_combinations.TestCase):\n         with strategy_fn().scope() as strategy:\n             with policy.policy_scope(\"mixed_float16\"):\n                 layer = mp_test_util.MultiplyLayer(assert_type=tf.float16)\n-                # Learning rate is small enough that if applied to a float16 variable,\n-                # the variable will not change. So this tests the learning rate is not\n-                # applied to a float16 value, but instead the float32 variable.\n+                # Learning rate is small enough that if applied to a float16\n+                # variable, the variable will not change. So this tests the\n+                # learning rate is not applied to a float16 value, but instead\n+                # the float32 variable.\n                 opt = gradient_descent.SGD(2**-14)\n \n                 def run_fn():\n                     with tf.GradientTape() as tape:\n                         y = layer(x)\n-                        # Divide by num_replicas_in_sync, as the effective total loss is the\n-                        # sum of each of the replica's losses.\n+                        # Divide by num_replicas_in_sync, as the effective total\n+                        # loss is the sum of each of the replica's losses.\n                         y /= strategy.num_replicas_in_sync\n \n                     grad = tape.gradient(y, layer.v)\n@@ -214,17 +215,18 @@ class LayerTest(test_combinations.TestCase):\n                     self.evaluate(tf.compat.v1.global_variables_initializer())\n                     self.evaluate(op)\n                 # The gradient with respective to the variable is 1. Since the\n-                # variable is initialized with 1 and the learning rate is 2**-14, the\n-                # new variable value should be: init_val - gradient * learning_rate,\n-                # which is  1 - 1 * 2**-14\n+                # variable is initialized with 1 and the learning rate is\n+                # 2**-14, the new variable value should be: init_val - gradient\n+                # * learning_rate, which is  1 - 1 * 2**-14\n                 self.assertEqual(self.evaluate(layer.v), 1 - 2**-14)\n \n     def _test_checkpointing_layer_weights(\n         self, strategy_fn, mixed_prec_when_saving, mixed_prec_when_loading\n     ):\n-        # In this test, we potentially save with mixed precision enabled and load\n-        # with mixed precision disabled, or vice versa. This is possible because\n-        # variables are float32 regardless of whether mixed precision is enabled.\n+        # In this test, we potentially save with mixed precision enabled and\n+        # load with mixed precision disabled, or vice versa. This is possible\n+        # because variables are float32 regardless of whether mixed precision is\n+        # enabled.\n         save_policy = \"mixed_float16\" if mixed_prec_when_saving else \"float32\"\n         load_policy = \"mixed_float16\" if mixed_prec_when_loading else \"float32\"\n         save_input_dtype = \"float16\" if mixed_prec_when_saving else \"float32\"\n@@ -314,10 +316,11 @@ class LayerTest(test_combinations.TestCase):\n             config = layer.get_config()\n             self.assertIsNone(config[\"dtype\"])\n             layer = mp_test_util.MultiplyLayer.from_config(config)\n-            # If a layer is serialized with the \"_infer\" policy, when deserialized\n-            # into TF 2 it will have the global policy instead of \"_infer\". This is\n-            # because \"_infer\" is serialized into None, and passing dtype=None in\n-            # TensorFlow 2 indicates to use the global policy.\n+            # If a layer is serialized with the \"_infer\" policy, when\n+            # deserialized into TF 2 it will have the global policy instead of\n+            # \"_infer\". This is because \"_infer\" is serialized into None, and\n+            # passing dtype=None in TensorFlow 2 indicates to use the global\n+            # policy.\n             self.assertEqual(layer.dtype, \"float32\")\n             self.assertEqual(layer(x).dtype, \"float32\")\n             self.assertEqual(layer.v.dtype, \"float32\")\n@@ -325,10 +328,10 @@ class LayerTest(test_combinations.TestCase):\n     @parameterized.named_parameters(*TESTCASES)\n     def test_from_config_policy_v1(self, strategy_fn):\n         # Test that layers serialized in previous Keras versions with the\n-        # now-deleted PolicyV1 can be deserialized. In such cases, the PolicyV1 will\n-        # be converted to a Policy, since PolicyV1 no longer exists. Unlike Policy,\n-        # PolicyV1 had a \"loss_scale\" field, which is silently dropped when\n-        # deserialized.\n+        # now-deleted PolicyV1 can be deserialized. In such cases, the PolicyV1\n+        # will be converted to a Policy, since PolicyV1 no longer exists. Unlike\n+        # Policy, PolicyV1 had a \"loss_scale\" field, which is silently dropped\n+        # when deserialized.\n         x = tf.constant([1.0], dtype=tf.float16)\n         with strategy_fn().scope():\n \n@@ -424,8 +427,8 @@ class LayerTest(test_combinations.TestCase):\n         mp_test_util.MultiplyLayer(dtype=policy.Policy(\"float64\"))\n \n     def test_input_spec_dtype(self):\n-        # Test the InputSpec's dtype is compared against the inputs before the layer\n-        # casts them, not after.\n+        # Test the InputSpec's dtype is compared against the inputs before the\n+        # layer casts them, not after.\n         layer = mp_test_util.MultiplyLayer(dtype=\"float64\")\n         layer.input_spec = input_spec.InputSpec(dtype=\"float16\")\n \n\n@@ -50,7 +50,8 @@ class _UnwrapPreventer:\n \n \n def _is_all_finite(grads):\n-    \"\"\"Returns a scalar boolean tensor indicating if all gradients are finite.\"\"\"\n+    \"\"\"Returns a scalar boolean tensor indicating if all gradients are\n+    finite.\"\"\"\n     is_finite_per_grad = [\n         tf.reduce_all(tf.math.is_finite(g)) for g in grads if g is not None\n     ]\n@@ -103,17 +104,18 @@ def _maybe_warn_about_scaling(\n             \"You forgot to call LossScaleOptimizer.get_scaled_loss() and \"\n             \"LossScaleOptimizer.get_unscaled_gradients() before calling \"\n             \"LossScaleOptimizer.apply_gradients(). This will likely result in \"\n-            \"worse model quality, so please call them in the correct places! For \"\n-            f\"example:{example_code}\\nFor more information, see \"\n+            \"worse model quality, so please call them in the correct places! \"\n+            f\"For example:{example_code}\\nFor more information, see \"\n             \"https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/LossScaleOptimizer\"\n         )\n     elif not loss_has_been_scaled:\n         tf_logging.warning(\n             \"You forgot to call LossScaleOptimizer.get_scaled_loss() before \"\n             \"calling LossScaleOptimizer.apply_gradients() (you did call \"\n-            \"get_unscaled_gradients() however). This will likely result in worse \"\n-            \"model quality, so please call get_scaled_loss() in the correct place! \"\n-            f\"For example:{example_code}\\nFor more information, see \"\n+            \"get_unscaled_gradients() however). This will likely result in \"\n+            \"worse model quality, so please call get_scaled_loss() in the \"\n+            f\"correct place! For example:{example_code}\\nFor more information, \"\n+            \"see \"\n             \"https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/LossScaleOptimizer\"\n         )\n     elif not gradients_have_been_unscaled:\n@@ -121,8 +123,9 @@ def _maybe_warn_about_scaling(\n             \"You forgot to call LossScaleOptimizer.get_unscaled_gradients() \"\n             \"before calling LossScaleOptimizer.apply_gradients() (you did call \"\n             \"get_scaled_loss() however). This will likely result in worse \"\n-            \"model quality, so please call get_unscaled_gradients() in the correct \"\n-            f\"place! For example:{example_code}\\nFor more information, see \"\n+            \"model quality, so please call get_unscaled_gradients() in the \"\n+            f\"correct place! For example:{example_code}\\nFor more information, \"\n+            \"see \"\n             \"https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/LossScaleOptimizer\"\n         )\n \n@@ -144,8 +147,8 @@ class _DynamicLossScaleState(tf.__internal__.tracking.Trackable):\n             initial_value=self._initial_loss_scale,\n         )\n         # The number of consecutive steps with finite gradients since the last\n-        # nonfinite gradient or change in loss scale. The name is 'good_steps' for\n-        # backwards compatibility with older checkpoints.\n+        # nonfinite gradient or change in loss scale. The name is 'good_steps'\n+        # for backwards compatibility with older checkpoints.\n         self._counter = self._add_weight(\n             name=\"good_steps\", dtype=tf.int64, initial_value=0\n         )\n@@ -248,8 +251,8 @@ class _DynamicLossScaleState(tf.__internal__.tracking.Trackable):\n             all-reduced gradient of the loss with respect to a weight.\n \n         Returns:\n-          update_op: In eager mode, None. In graph mode, an op to update the loss\n-            scale.\n+          update_op: In eager mode, None. In graph mode, an op to update the\n+            loss scale.\n           should_apply_gradients: Either a bool or a scalar boolean tensor. If\n             False, the caller should skip applying `grads` to the variables this\n             step.\n@@ -264,8 +267,8 @@ class _DynamicLossScaleState(tf.__internal__.tracking.Trackable):\n                 _is_all_finite, args=(grads,)\n             )\n             # Each replica computed the same `is_finite` value, since `grads` is\n-            # all-reduced across replicas. Arbitrarily take `is_finite` from the first\n-            # replica.\n+            # all-reduced across replicas. Arbitrarily take `is_finite` from the\n+            # first replica.\n             is_finite = distribution.experimental_local_results(\n                 is_finite_per_replica\n             )[0]\n@@ -360,15 +363,15 @@ class BaseLossScaleOptimizer(metaclass=LossScaleOptimizerMetaclass):\n     gradients when float16 is used. To prevent underflow, the loss is multiplied\n     (or \"scaled\") by a certain factor called the \"loss scale\", which causes\n     intermediate gradients to be scaled by the loss scale as well. The final\n-    gradients are divided (or \"unscaled\") by the loss scale to bring them back to\n-    their original value.\n+    gradients are divided (or \"unscaled\") by the loss scale to bring them back\n+    to their original value.\n \n     `LossScaleOptimizer` wraps another optimizer and applies loss scaling to it.\n-    By default, the loss scale is dynamically updated over time so you do not have\n-    to choose the loss scale. The `minimize` method automatically scales the loss,\n-    unscales the gradients, and updates the loss scale so all you have to do is\n-    wrap your optimizer with a `LossScaleOptimizer` if you use `minimize`. For\n-    example:\n+    By default, the loss scale is dynamically updated over time so you do not\n+    have to choose the loss scale. The `minimize` method automatically scales\n+    the loss, unscales the gradients, and updates the loss scale so all you have\n+    to do is wrap your optimizer with a `LossScaleOptimizer` if you use\n+    `minimize`. For example:\n \n     >>> opt = tf.keras.optimizers.SGD(0.25)\n     >>> opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n@@ -379,8 +382,8 @@ class BaseLossScaleOptimizer(metaclass=LossScaleOptimizerMetaclass):\n     >>> var.numpy()\n     0.5\n \n-    If a `tf.GradientTape` is used to compute gradients instead of `minimize`, you\n-    must scale the loss and gradients manually. This can be done with the\n+    If a `tf.GradientTape` is used to compute gradients instead of `minimize`,\n+    you must scale the loss and gradients manually. This can be done with the\n     `LossScaleOptimizer.get_scaled_loss` and\n     `LossScaleOptimizer.get_unscaled_gradients` methods. For example:\n \n@@ -394,8 +397,8 @@ class BaseLossScaleOptimizer(metaclass=LossScaleOptimizerMetaclass):\n     0.25\n \n     Warning: If you forget to call `get_scaled_loss` or `get_unscaled_gradients`\n-    (or both) when using a `tf.GradientTape`, the model will likely converge to a\n-    worse quality. Please make sure you call each function exactly once.\n+    (or both) when using a `tf.GradientTape`, the model will likely converge to\n+    a worse quality. Please make sure you call each function exactly once.\n \n     When mixed precision with float16 is used, there is typically no risk of\n     underflow affecting model quality if loss scaling is properly used. See\n@@ -407,46 +410,46 @@ class BaseLossScaleOptimizer(metaclass=LossScaleOptimizerMetaclass):\n       inner_optimizer: The `tf.keras.optimizers.Optimizer` or\n         `tf.keras.optimizers.experimental.Optimizer` instance to wrap.\n       dynamic: Bool indicating whether dynamic loss scaling is used. Defaults to\n-        True. If True, the loss scale will be dynamically updated over time using\n-        an algorithm that keeps the loss scale at approximately its optimal value.\n-        If False, a single fixed loss scale is used and `initial_scale` must be\n-        specified, which is used as the loss scale. Recommended to keep as True,\n-        as choosing a fixed loss scale can be tricky. Currently, there is a small\n-        performance overhead to dynamic loss scaling compared to fixed loss\n-        scaling.\n+        True. If True, the loss scale will be dynamically updated over time\n+        using an algorithm that keeps the loss scale at approximately its\n+        optimal value.  If False, a single fixed loss scale is used and\n+        `initial_scale` must be specified, which is used as the loss scale.\n+        Recommended to keep as True, as choosing a fixed loss scale can be\n+        tricky. Currently, there is a small performance overhead to dynamic loss\n+        scaling compared to fixed loss scaling.\n       initial_scale: The initial loss scale. If `dynamic` is True, this defaults\n         to `2 ** 15`. If `dynamic` is False, this must be specified and acts as\n         the sole loss scale, as the loss scale does not change over time. When\n-        dynamic loss scaling is used, is better for this to be a very high number,\n-        because a loss scale that is too high gets lowered far more quickly than a\n-        loss scale that is too low gets raised.\n+        dynamic loss scaling is used, is better for this to be a very high\n+        number, because a loss scale that is too high gets lowered far more\n+        quickly than a loss scale that is too low gets raised.\n       dynamic_growth_steps: With dynamic loss scaling, every\n         `dynamic_growth_steps` steps with finite gradients, the loss scale is\n         doubled. Defaults to 2000. If a nonfinite gradient is encountered, the\n-        count is reset back to zero, gradients are skipped that step, and the loss\n-        scale is halved. The count can be queried with\n-        `LossScaleOptimizer.dynamic_counter`. This argument can only be specified\n-        if `dynamic` is True.\n+        count is reset back to zero, gradients are skipped that step, and the\n+        loss scale is halved. The count can be queried with\n+        `LossScaleOptimizer.dynamic_counter`. This argument can only be\n+        specified if `dynamic` is True.\n \n     `LossScaleOptimizer` will occasionally skip applying gradients to the\n     variables, in which case the trainable variables will not change that step.\n     This is done because the dynamic loss scale will sometimes be raised too\n-    high, causing overflow in the gradients. Typically, the first 2 to 15 steps of\n-    the model are skipped as the initial loss scale is very high, but afterwards\n-    steps will only be skipped on average 0.05% of the time (the fraction of steps\n-    skipped is `1 / dynamic_growth_steps`).\n+    high, causing overflow in the gradients. Typically, the first 2 to 15 steps\n+    of the model are skipped as the initial loss scale is very high, but\n+    afterwards steps will only be skipped on average 0.05% of the time (the\n+    fraction of steps skipped is `1 / dynamic_growth_steps`).\n \n     `LossScaleOptimizer` delegates all public `Optimizer` methods to the inner\n-    optimizer. Additionally, in methods `minimize` and `get_gradients`, it scales\n-    the loss and unscales the gradients. In methods `minimize` and\n+    optimizer. Additionally, in methods `minimize` and `get_gradients`, it\n+    scales the loss and unscales the gradients. In methods `minimize` and\n     `apply_gradients`, it additionally updates the loss scale and skips applying\n     gradients if any gradient has a nonfinite value.\n \n     ### Hyperparameters\n \n-    If wrapping a `tf.keras.optimizers.Optimizer`, hyperparameters can be accessed\n-    and set on the LossScaleOptimizer, which will be delegated to the wrapped\n-    optimizer.\n+    If wrapping a `tf.keras.optimizers.Optimizer`, hyperparameters can be\n+    accessed and set on the LossScaleOptimizer, which will be delegated to the\n+    wrapped optimizer.\n \n     >>> opt = tf.keras.optimizers.Adam(beta_1=0.8, epsilon=1e-5)\n     >>> opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n@@ -473,9 +476,9 @@ class BaseLossScaleOptimizer(metaclass=LossScaleOptimizerMetaclass):\n     >>> opt.inner_optimizer.epsilon\n     >>> 1e-5\n \n-    In the above example, despite epsilon being set on the LossScaleOptimizer, the\n-    old epsilon value will still be used when training as epsilon was not set on\n-    the inner optimizer.\n+    In the above example, despite epsilon being set on the LossScaleOptimizer,\n+    the old epsilon value will still be used when training as epsilon was not\n+    set on the inner optimizer.\n     \"\"\"\n \n     @property\n@@ -490,15 +493,16 @@ class BaseLossScaleOptimizer(metaclass=LossScaleOptimizerMetaclass):\n \n     @property\n     def dynamic_counter(self):\n-        \"\"\"The number of steps since the loss scale was last increased or decreased.\n+        \"\"\"The number of steps since the loss scale was last increased or\n+        decreased.\n \n         This is None if `LossScaleOptimizer.dynamic` is False.\n \n         The counter is incremented every step. Once it reaches\n-        `LossScaleOptimizer.dynamic_growth_steps`, the loss scale will be doubled\n-        and the counter will be reset back to zero. If nonfinite gradients are\n-        encountered, the loss scale will be halved and the counter will be reset\n-        back to zero.\n+        `LossScaleOptimizer.dynamic_growth_steps`, the loss scale will be\n+        doubled and the counter will be reset back to zero. If nonfinite\n+        gradients are encountered, the loss scale will be halved and the counter\n+        will be reset back to zero.\n         \"\"\"\n         raise NotImplementedError\n \n@@ -517,8 +521,8 @@ class BaseLossScaleOptimizer(metaclass=LossScaleOptimizerMetaclass):\n \n         This is None if `LossScaleOptimizer.dynamic` is False.\n \n-        Every `dynamic_growth_steps` consecutive steps with finite gradients, the\n-        loss scale is increased.\n+        Every `dynamic_growth_steps` consecutive steps with finite gradients,\n+        the loss scale is increased.\n         \"\"\"\n         raise NotImplementedError\n \n@@ -531,18 +535,18 @@ class BaseLossScaleOptimizer(metaclass=LossScaleOptimizerMetaclass):\n         \"\"\"Scales the loss by the loss scale.\n \n         This method is only needed if you compute gradients manually, e.g. with\n-        `tf.GradientTape`. In that case, call this method to scale the loss before\n-        passing the loss to `tf.GradientTape`. If you use\n-        `LossScaleOptimizer.minimize` or `LossScaleOptimizer.get_gradients`, loss\n-        scaling is automatically applied and this method is unneeded.\n+        `tf.GradientTape`. In that case, call this method to scale the loss\n+        before passing the loss to `tf.GradientTape`. If you use\n+        `LossScaleOptimizer.minimize` or `LossScaleOptimizer.get_gradients`,\n+        loss scaling is automatically applied and this method is unneeded.\n \n-        If this method is called, `get_unscaled_gradients` should also be called.\n-        See the `tf.keras.mixed_precision.LossScaleOptimizer` doc for\n+        If this method is called, `get_unscaled_gradients` should also be\n+        called.  See the `tf.keras.mixed_precision.LossScaleOptimizer` doc for\n         an example.\n \n         Args:\n-          loss: The loss, which will be multiplied by the loss scale. Can either be\n-            a tensor or a callable returning a tensor.\n+          loss: The loss, which will be multiplied by the loss scale. Can either\n+            be a tensor or a callable returning a tensor.\n \n         Returns:\n           `loss` multiplied by `LossScaleOptimizer.loss_scale`.\n@@ -556,22 +560,22 @@ class BaseLossScaleOptimizer(metaclass=LossScaleOptimizerMetaclass):\n         \"\"\"Unscales the gradients by the loss scale.\n \n         This method is only needed if you compute gradients manually, e.g. with\n-        `tf.GradientTape`. In that case, call this method to unscale the gradients\n-        after computing them with `tf.GradientTape`. If you use\n-        `LossScaleOptimizer.minimize` or `LossScaleOptimizer.get_gradients`, loss\n-        scaling is automatically applied and this method is unneeded.\n+        `tf.GradientTape`. In that case, call this method to unscale the\n+        gradients after computing them with `tf.GradientTape`. If you use\n+        `LossScaleOptimizer.minimize` or `LossScaleOptimizer.get_gradients`,\n+        loss scaling is automatically applied and this method is unneeded.\n \n         If this method is called, `get_scaled_loss` should also be called. See\n         the `tf.keras.mixed_precision.LossScaleOptimizer` doc for an\n         example.\n \n         Args:\n-          grads: A list of tensors, each which will be divided by the loss scale.\n-            Can have None values, which are ignored.\n+          grads: A list of tensors, each which will be divided by the loss\n+            scale. Can have None values, which are ignored.\n \n         Returns:\n-          A new list the same size as `grads`, where every non-None value in `grads`\n-          is divided by `LossScaleOptimizer.loss_scale`.\n+          A new list the same size as `grads`, where every non-None value in\n+          `grads` is divided by `LossScaleOptimizer.loss_scale`.\n         \"\"\"\n         # Calls to this function would be delegated to `get_unscaled_gradients`\n         # of either `LossScaleOptimizer` or `LossScaleOptimizerV3`, depending on\n@@ -598,15 +602,19 @@ class LossScaleOptimizer(\n     ):\n         if not isinstance(inner_optimizer, optimizer_v2.OptimizerV2):\n             if isinstance(inner_optimizer, optimizer_experimental.Optimizer):\n-                # Give better error message if the new experimental optimizer is passed.\n+                # Give better error message if the new experimental optimizer is\n+                # passed.\n                 raise TypeError(\n-                    f\"You passed an instance of the new experimental optimizer, \"\n-                    f\"`optimizer_experimental.Optimizer`, to LossScaleOptimizer, but \"\n+                    f\"You passed an instance of the new experimental \"\n+                    f\"optimizer, `optimizer_experimental.Optimizer`, \"\n+                    f\"to LossScaleOptimizer, but \"\n                     f\"only the classic optimizers subclassing from \"\n-                    f\"`tf.keras.optimizers.Optimizer` can be passed. Please use \"\n-                    f\"`loss_scale_optimizer.LossScaleOptimizerV3` instead of \"\n-                    f\"`tf.keras.mixed_precision.LossScaleOptimizer`, as the former \"\n-                    f\"supports wrapping instances of the new experimental optimizer. \"\n+                    f\"`tf.keras.optimizers.Optimizer` can be passed. Please \"\n+                    f\"use `loss_scale_optimizer.LossScaleOptimizerV3` \"\n+                    f\"instead of \"\n+                    f\"`tf.keras.mixed_precision.LossScaleOptimizer`, \"\n+                    f\"as the former supports wrapping \"\n+                    f\"instances of the new experimental optimizer. \"\n                     f\"Got optimizer: {inner_optimizer}\"\n                 )\n             msg = (\n@@ -618,14 +626,14 @@ class LossScaleOptimizer(\n                 msg += (\n                     'Please make sure \"inner_optimizer\" is not an instance of '\n                     \"`tensorflow.python.keras.optimizers`, which is \"\n-                    \"the legacy keras code and will be removed in future release. \"\n-                    \"Please use the tf.keras public API instead.\"\n+                    \"the legacy keras code and will be removed in future \"\n+                    \"release. Please use the tf.keras public API instead.\"\n                 )\n             raise TypeError(msg)\n         if not isinstance(dynamic, bool):\n             # Catch errors if a user incorrectly passes a string or float to the\n-            # second argument argument, as this was commonly done for the now-removed\n-            # LossScaleOptimizerV1.\n+            # second argument argument, as this was commonly done for the\n+            # now-removed LossScaleOptimizerV1.\n             raise TypeError(\n                 '\"dynamic\" argument to LossScaleOptimizer.__init__ must '\n                 \"be a bool, but got: %r\" % (dynamic,)\n@@ -639,9 +647,10 @@ class LossScaleOptimizer(\n         if getattr(\n             inner_optimizer, \"_is_wrapped_by_loss_scale_optimizer\", False\n         ):\n-            # TODO(reedwm): Maybe support this. The difficulty is that LSO has the\n-            # same checkpoint format as the inner optimizer, so multiple LSOs wrapping\n-            # the same optimizer causes the checkpointing logic to become confused.\n+            # TODO(reedwm): Maybe support this. The difficulty is that LSO has\n+            # the same checkpoint format as the inner optimizer, so multiple\n+            # LSOs wrapping the same optimizer causes the checkpointing logic to\n+            # become confused.\n             raise ValueError(\n                 '\"inner_optimizer\" is already wrapped by a '\n                 \"LossScaleOptimizer. An optimizer can only be wrapped \"\n@@ -650,8 +659,8 @@ class LossScaleOptimizer(\n         self._optimizer = inner_optimizer\n         self._optimizer._is_wrapped_by_loss_scale_optimizer = True\n \n-        # We don't call super().__init__, since we do not want to call OptimizerV2's\n-        # constructor.\n+        # We don't call super().__init__, since we do not want to call\n+        # OptimizerV2's constructor.\n         tf.__internal__.tracking.DelegatingTrackableMixin.__init__(\n             self, self._optimizer\n         )\n@@ -677,8 +686,8 @@ class LossScaleOptimizer(\n                     \"is False, but got: %s\" % (dynamic_growth_steps,)\n                 )\n \n-        # Used to track whether get_scaled_loss() and get_unscaled_gradients() have\n-        # been called\n+        # Used to track whether get_scaled_loss() and get_unscaled_gradients()\n+        # have been called\n         self._loss_has_been_scaled = False\n         self._gradients_have_been_unscaled = False\n \n@@ -749,7 +758,7 @@ class LossScaleOptimizer(\n         tape = tf.GradientTape() if tape is None else tape\n         with tape:\n             loss = self.get_scaled_loss(loss)\n-        grads_and_vars = self._optimizer._compute_gradients(  # pylint: disable=protected-access\n+        grads_and_vars = self._optimizer._compute_gradients(\n             loss, var_list, grad_loss, tape=tape\n         )\n         grads = [g for g, _ in grads_and_vars]\n@@ -774,8 +783,9 @@ class LossScaleOptimizer(\n             raise ValueError(\n                 \"apply_gradients() must be called in a replica context.\"\n             )\n-        # We check for the strategy here despite already checking in the constructor\n-        # as frequently the optimizer is created outside the strategy's scope.\n+        # We check for the strategy here despite already checking in the\n+        # constructor as frequently the optimizer is created outside the\n+        # strategy's scope.\n         _raise_if_strategy_unsupported()\n         _maybe_warn_about_scaling(\n             self._loss_has_been_scaled, self._gradients_have_been_unscaled\n@@ -784,10 +794,10 @@ class LossScaleOptimizer(\n         grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n         if experimental_aggregate_gradients:\n             # We must aggregate the gradients here instead of in\n-            # self.optimizer.apply_gradients, so that any NaN or Inf gradients are\n-            # propagated to each replica. If any replica has a NaN or Inf gradient,\n-            # they must all have a NaN or Inf gradient so that they all skip the step.\n-            # pylint: disable=protected-access\n+            # self.optimizer.apply_gradients, so that any NaN or Inf gradients\n+            # are propagated to each replica. If any replica has a NaN or Inf\n+            # gradient, they must all have a NaN or Inf gradient so that they\n+            # all skip the step.\n             grads_and_vars = self._optimizer._transform_unaggregated_gradients(\n                 grads_and_vars\n             )\n@@ -807,8 +817,8 @@ class LossScaleOptimizer(\n \n         def do_not_apply_fn():\n             # Normally self._optimizer.iterations is incremented in\n-            # self._optimizer.apply_gradients(). Since that is not called in this\n-            # branch, we increment it here instead.\n+            # self._optimizer.apply_gradients(). Since that is not called in\n+            # this branch, we increment it here instead.\n             return self._optimizer.iterations.assign_add(1, read_value=False)\n \n         def _if_should_apply_grads(grads):\n@@ -846,8 +856,8 @@ class LossScaleOptimizer(\n                     )\n \n                 # Note: We must call this cond() in a cross-replica context.\n-                # DistributionStrategy does not support having a cond in a replica\n-                # context with a branch that calls `merge_call`, and\n+                # DistributionStrategy does not support having a cond in a\n+                # replica context with a branch that calls `merge_call`, and\n                 # self._optimizer.apply_gradients calls `merge_call`.\n                 maybe_apply_op = tf.__internal__.smart_cond.smart_cond(\n                     should_apply_grads, apply_fn, do_not_apply_fn\n@@ -884,8 +894,8 @@ class LossScaleOptimizer(\n         config = config.copy()  # Make a copy, since we mutate config\n         if \"loss_scale\" in config:\n             # If loss_scale is in config, we assume we are deserializing a\n-            # LossScaleOptimizer from TF 2.3 or below. We convert the config so it\n-            # can be deserialized in the current LossScaleOptimizer.\n+            # LossScaleOptimizer from TF 2.3 or below. We convert the config so\n+            # it can be deserialized in the current LossScaleOptimizer.\n             loss_scale = generic_utils.deserialize_keras_object(\n                 config.pop(\"loss_scale\"),\n                 module_objects={\n@@ -918,9 +928,9 @@ class LossScaleOptimizer(\n                     )\n             else:\n                 raise ValueError(\n-                    \"Serialized LossScaleOptimizers with a LossScale that is neither a \"\n-                    \"FixedLossScale nor a DynamicLossScale can no longer be \"\n-                    \"deserialized\"\n+                    \"Serialized LossScaleOptimizers with a LossScale that is \"\n+                    \"neither a FixedLossScale nor a DynamicLossScale can no \"\n+                    \"longer be deserialized\"\n                 )\n             config[\"inner_optimizer\"] = config.pop(\"optimizer\")\n         inner_optimizer = optimizers.deserialize(\n@@ -995,7 +1005,7 @@ class LossScaleOptimizer(\n     def _create_or_restore_slot_variable(\n         self, slot_variable_position, slot_name, variable\n     ):\n-        return self._optimizer._create_or_restore_slot_variable(  # pylint: disable=protected-access\n+        return self._optimizer._create_or_restore_slot_variable(\n             slot_variable_position, slot_name, variable\n         )\n \n@@ -1031,11 +1041,11 @@ class LossScaleOptimizer(\n     def __setattr__(self, name, value):\n         if name == \"lr\":\n             name = \"learning_rate\"\n-        # Delegate setting hyperparameter to inner optimizer if the attribute does\n-        # not exist on the LossScaleOptimizer\n+        # Delegate setting hyperparameter to inner optimizer if the attribute\n+        # does not exist on the LossScaleOptimizer\n         try:\n-            # We cannot check for the 'iterations' attribute as it cannot be set after\n-            # it is accessed.\n+            # We cannot check for the 'iterations' attribute as it cannot be set\n+            # after it is accessed.\n             if name != \"iterations\":\n                 object.__getattribute__(self, name)\n             has_attribute = True\n@@ -1050,11 +1060,11 @@ class LossScaleOptimizer(\n         else:\n             super().__setattr__(name, value)\n \n-    # Explicitly delegate learning_rate. Normally hyperparameters are delegated in\n-    # __getattribute__, but if a hyperparameter is not in self._optimizer._hyper\n-    # (e.g. because self._optimizer itself wraps another optimizer), then it won't\n-    # be delegated. Since learning_rate is a very commonly accessed\n-    # hyperparameter, we delegate it here.\n+    # Explicitly delegate learning_rate. Normally hyperparameters are delegated\n+    # in __getattribute__, but if a hyperparameter is not in\n+    # self._optimizer._hyper (e.g. because self._optimizer itself wraps another\n+    # optimizer), then it won't be delegated. Since learning_rate is a very\n+    # commonly accessed hyperparameter, we delegate it here.\n     @property\n     def learning_rate(self):\n         return self._optimizer.learning_rate\n@@ -1071,8 +1081,8 @@ class LossScaleOptimizer(\n     def lr(self, value):\n         self._optimizer.lr = value\n \n-    # We do not override some OptimizerV2 methods. For each, we describe why we do\n-    # not delegate them to self._optimizer:\n+    # We do not override some OptimizerV2 methods. For each, we describe why we\n+    # do not delegate them to self._optimizer:\n     # * get_updates: get_updates() calls get_gradients(). Since we override\n     #   get_gradients(), we cannot delegate get_updates() to self._optimizer,\n     #   otherwise the overridden get_gradients() method would not be called.\n@@ -1098,8 +1108,8 @@ class LossScaleOptimizerV3(\n     class instead of the `tf.keras.optimizers.Optimizer` class. Some of the\n     methods this class defines and calls are different compared to\n     LossScaleOptimizer due to the differences between the two Optimizer base\n-    classes. Additionally, this class does not support the legacy graph mode, but\n-    LossScaleOptimizer does.\n+    classes. Additionally, this class does not support the legacy graph mode,\n+    but LossScaleOptimizer does.\n \n     Since the new experimental Optimizer does not have a hyperparameter concept,\n     LossScaleOptimizerV3 does not delegate arbitrary hyperparameter accesses to\n@@ -1117,13 +1127,15 @@ class LossScaleOptimizerV3(\n     ):\n         if not isinstance(inner_optimizer, optimizer_experimental.Optimizer):\n             if isinstance(inner_optimizer, optimizer_v2.OptimizerV2):\n-                # Give better error message if the OptimizerV2 class is passed instead\n-                # of the new experimental optimizer.\n+                # Give better error message if the OptimizerV2 class is passed\n+                # instead of the new experimental optimizer.\n                 raise TypeError(\n                     f\"You passed a `tf.keras.optimizer.Optimizer` instance to \"\n-                    f\"LossScaleOptimizerV3, but only the new experimental optimizer \"\n-                    f\"defined in keras/optimizer_expeirmental/optimizer.py can be \"\n-                    f\"passed. Please use `tf.keras.mixed_precision.LossScaleOptimizer` \"\n+                    f\"LossScaleOptimizerV3, but only the new experimental \"\n+                    f\"optimizer defined in \"\n+                    f\"keras/optimizer_expeirmental/optimizer.py can be \"\n+                    f\"passed. Please use \"\n+                    f\"`tf.keras.mixed_precision.LossScaleOptimizer` \"\n                     f\"instead of LossScaleOptimizerV3, as the former supports \"\n                     f\"`tf.keras.optimizer.Optimizer`s. Got optimizer: \"\n                     f\"{inner_optimizer}\"\n@@ -1134,8 +1146,8 @@ class LossScaleOptimizerV3(\n             )\n         if not isinstance(dynamic, bool):\n             # Catch errors if a user incorrectly passes a string or float to the\n-            # second argument argument, as this was commonly done for the now-removed\n-            # LossScaleOptimizerV1.\n+            # second argument argument, as this was commonly done for the\n+            # now-removed LossScaleOptimizerV1.\n             raise TypeError(\n                 f'\"dynamic\" argument to LossScaleOptimizer.__init__ must '\n                 f\"be a bool, but got: {repr(dynamic)}\"\n@@ -1149,9 +1161,10 @@ class LossScaleOptimizerV3(\n         if getattr(\n             inner_optimizer, \"_is_wrapped_by_loss_scale_optimizer\", False\n         ):\n-            # TODO(reedwm): Maybe support this. The difficulty is that LSO has the\n-            # same checkpoint format as the inner optimizer, so multiple LSOs wrapping\n-            # the same optimizer causes the checkpointing logic to become confused.\n+            # TODO(reedwm): Maybe support this. The difficulty is that LSO has\n+            # the same checkpoint format as the inner optimizer, so multiple\n+            # LSOs wrapping the same optimizer causes the checkpointing logic to\n+            # become confused.\n             raise ValueError(\n                 '\"inner_optimizer\" is already wrapped by a '\n                 \"LossScaleOptimizer. An optimizer can only be wrapped \"\n@@ -1160,8 +1173,8 @@ class LossScaleOptimizerV3(\n         self._optimizer = inner_optimizer\n         self._optimizer._is_wrapped_by_loss_scale_optimizer = True\n \n-        # We don't call super().__init__, since we do not want to call Optimizer's\n-        # constructor.\n+        # We don't call super().__init__, since we do not want to call\n+        # Optimizer's constructor.\n         tf.__internal__.tracking.DelegatingTrackableMixin.__init__(\n             self, self._optimizer\n         )\n@@ -1187,8 +1200,8 @@ class LossScaleOptimizerV3(\n                     f\"is False, but got: {dynamic_growth_steps}\"\n                 )\n \n-        # Used to track whether get_scaled_loss() and get_unscaled_gradients() have\n-        # been called\n+        # Used to track whether get_scaled_loss() and get_unscaled_gradients()\n+        # have been called\n         self._loss_has_been_scaled = False\n         self._gradients_have_been_unscaled = False\n \n@@ -1254,7 +1267,7 @@ class LossScaleOptimizerV3(\n         tape = tf.GradientTape() if tape is None else tape\n         with tape:\n             loss = self.get_scaled_loss(loss)\n-        grads_and_vars = self._optimizer.compute_gradients(  # pylint: disable=protected-access\n+        grads_and_vars = self._optimizer.compute_gradients(\n             loss, var_list, tape=tape\n         )\n         grads = [g for g, _ in grads_and_vars]\n@@ -1267,8 +1280,9 @@ class LossScaleOptimizerV3(\n             raise ValueError(\n                 \"apply_gradients() must be called in a replica context.\"\n             )\n-        # We check for the strategy here despite already checking in the constructor\n-        # as frequently the optimizer is created outside the strategy's scope.\n+        # We check for the strategy here despite already checking in the\n+        # constructor as frequently the optimizer is created outside the\n+        # strategy's scope.\n         _raise_if_strategy_unsupported()\n         _maybe_warn_about_scaling(\n             self._loss_has_been_scaled, self._gradients_have_been_unscaled\n@@ -1277,12 +1291,11 @@ class LossScaleOptimizerV3(\n         grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n         if not skip_gradients_aggregation:\n             # We must aggregate the gradients here instead of in\n-            # self.optimizer.apply_gradients, so that any NaN or Inf gradients are\n-            # propagated to each replica. If any replica has a NaN or Inf gradient,\n-            # they must all have a NaN or Inf gradient so that they all skip the step.\n-            # pylint: disable=protected-access\n+            # self.optimizer.apply_gradients, so that any NaN or Inf gradients\n+            # are propagated to each replica. If any replica has a NaN or Inf\n+            # gradient, they must all have a NaN or Inf gradient so that they\n+            # all skip the step.\n             grads_and_vars = self._optimizer.aggregate_gradients(grads_and_vars)\n-            # pylint: enable=protected-access\n \n         grads_and_vars = tuple(grads_and_vars)\n         grads = [g for g, _ in grads_and_vars]\n@@ -1295,8 +1308,8 @@ class LossScaleOptimizerV3(\n \n         def do_not_apply_fn():\n             # Normally self._optimizer.iterations is incremented in\n-            # self._optimizer.apply_gradients(). Since that is not called in this\n-            # branch, we increment it here instead.\n+            # self._optimizer.apply_gradients(). Since that is not called in\n+            # this branch, we increment it here instead.\n             self._optimizer.iterations.assign_add(1, read_value=False)\n \n         def _if_should_apply_grads(grads):\n@@ -1328,8 +1341,8 @@ class LossScaleOptimizerV3(\n                     )\n \n                 # Note: We must call this cond() in a cross-replica context.\n-                # DistributionStrategy does not support having a cond in a replica\n-                # context with a branch that calls `merge_call`, and\n+                # DistributionStrategy does not support having a cond in a\n+                # replica context with a branch that calls `merge_call`, and\n                 # self._optimizer.apply_gradients calls `merge_call`.\n                 tf.__internal__.smart_cond.smart_cond(\n                     should_apply_grads, apply_fn, do_not_apply_fn\n@@ -1385,11 +1398,12 @@ class LossScaleOptimizerV3(\n class FakeOptimizerForRestoration(tf.__internal__.tracking.Trackable):\n     \"\"\"A fake optimizer used to support restoring TensorFlow 2.2 checkpoints.\n \n-    The checkpoint format for LossScaleOptimizers changed after TF 2.2. This class\n-    exists to support restoring TF 2.2 checkpoints in newer version of TensorFlow.\n+    The checkpoint format for LossScaleOptimizers changed after TF 2.2. This\n+    class exists to support restoring TF 2.2 checkpoints in newer version of\n+    TensorFlow.\n \n-    In TF 2.2, LossScaleOptimizer would track the wrapped optimizer by calling the\n-    following in LossScaleOptimizer.__init__\n+    In TF 2.2, LossScaleOptimizer would track the wrapped optimizer by calling\n+    the following in LossScaleOptimizer.__init__\n \n     ```\n     self._track_trackable(self._optimizer, 'base_optimizer')\n@@ -1400,9 +1414,9 @@ class FakeOptimizerForRestoration(tf.__internal__.tracking.Trackable):\n     LossScaleOptimizer is the same as the format without a LossScaleOptimizer,\n     except the loss scale is also stored. This means there is no dependency from\n     the LossScaleOptimizer to the wrapped optimizer. Instead, the\n-    LossScaleOptimizer acts as if it is the wrapped optimizer, from a checkpoint's\n-    perspective, by overriding all Trackable methods and delegating them to the\n-    wrapped optimizer.\n+    LossScaleOptimizer acts as if it is the wrapped optimizer, from a\n+    checkpoint's perspective, by overriding all Trackable methods and delegating\n+    them to the wrapped optimizer.\n \n     To allow restoring TF 2.2. checkpoints, LossScaleOptimizer adds a dependency\n     on this class instead of the inner optimizer. When restored, this class will\n@@ -1419,7 +1433,7 @@ class FakeOptimizerForRestoration(tf.__internal__.tracking.Trackable):\n     def _create_or_restore_slot_variable(\n         self, slot_variable_position, slot_name, variable\n     ):\n-        return self._optimizer._create_or_restore_slot_variable(  # pylint: disable=protected-access\n+        return self._optimizer._create_or_restore_slot_variable(\n             slot_variable_position, slot_name, variable\n         )\n \n@@ -1428,8 +1442,8 @@ def _create_loss_scale_optimizer_from_v1_loss_scale(optimizer, loss_scale):\n     \"\"\"Creates an LSO from a tf.compat.v1.mixed_precision.LossScale.\n \n     This is only used to pass to\n-    `tf.__internal__.mixed_precision.register_loss_scale_wrapper` below, which is\n-    called so that\n+    `tf.__internal__.mixed_precision.register_loss_scale_wrapper` below, which\n+    is called so that\n     `tf.compat.v1.mixed_precision.enable_mixed_precision_graph_rewrite` can\n     wrap a Keras optimizer with a LossScaleOptimizer.\n \n@@ -1505,12 +1519,13 @@ def strategy_supports_loss_scaling():\n     if not tf.distribute.has_strategy():\n         return True\n     strategy = tf.distribute.get_strategy()\n-    # Strategies are supported if either there is only one replica or if variables\n-    # are replicated per device. Otherwise, the current model.fit() implementation\n-    # and most custom training loops incorrectly unscale the gradients. Currently,\n-    # gradients are unscaled once per compute replica, but they should be unscaled\n-    # once per variable replica. When there is one variable replica for each\n-    # compute replica, this works fine, but otherwise issues will occur.\n+    # Strategies are supported if either there is only one replica or if\n+    # variables are replicated per device. Otherwise, the current model.fit()\n+    # implementation and most custom training loops incorrectly unscale the\n+    # gradients. Currently, gradients are unscaled once per compute replica, but\n+    # they should be unscaled once per variable replica. When there is one\n+    # variable replica for each compute replica, this works fine, but otherwise\n+    # issues will occur.\n     # TODO(reedwm): Support all strategies.\n     return isinstance(\n         strategy,\n@@ -1526,7 +1541,8 @@ def strategy_supports_loss_scaling():\n \n \n def _raise_if_strategy_unsupported():\n-    \"\"\"Raise an exception if the current strategy doesn't support loss scaling.\"\"\"\n+    \"\"\"Raise an exception if the current strategy doesn't support loss\n+    scaling.\"\"\"\n     if not strategy_supports_loss_scaling():\n         strategy = tf.distribute.get_strategy()\n         if isinstance(\n@@ -1538,10 +1554,11 @@ def _raise_if_strategy_unsupported():\n             ),\n         ):\n             raise ValueError(\n-                \"Loss scaling is not supported with TPUStrategy. Loss scaling is \"\n-                \"unnecessary with TPUs, since they support bfloat16 instead of \"\n-                \"float16 and bfloat16 does not require loss scaling. You should \"\n-                \"remove the use of the LossScaleOptimizer when TPUs are used.\"\n+                \"Loss scaling is not supported with TPUStrategy. Loss scaling \"\n+                \"is unnecessary with TPUs, since they support bfloat16 instead \"\n+                \"of float16 and bfloat16 does not require loss scaling. You \"\n+                \"should remove the use of the LossScaleOptimizer when TPUs are \"\n+                \"used.\"\n             )\n         else:\n             raise ValueError(\n\n@@ -114,9 +114,9 @@ def opt_and_strategy_and_mode_combinations():\n     \"\"\"Returns combinations for running with multiple optimizers and strategies.\n \n     Returns:\n-      Combinations that run with both OptimizerV2 and the experimental optimizer;\n-      and with the default strategy and mirrored strategy; and in both graph and\n-      eager mode.\n+      Combinations that run with both OptimizerV2 and the experimental\n+      optimizer; and with the default strategy and mirrored strategy; and in\n+      both graph and eager mode.\n     \"\"\"\n     # For the experimental optimizer, don't use graph mode directly since it's\n     # unsupported. Instead, run both without and with a tf.function, in order to\n@@ -150,17 +150,17 @@ def opt_combinations_only():\n @tf_test_utils.with_control_flow_v2\n class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n     def _run_if_in_graph_mode(self, val):\n-        # Running only in graph mode is useful, because optimizers sometimes return\n-        # a value that, in Graph mode, is runnable with self.evaluate. But in Eager\n-        # mode, the optimizer already does the computations and the return value\n-        # cannot be run.\n+        # Running only in graph mode is useful, because optimizers sometimes\n+        # return a value that, in Graph mode, is runnable with self.evaluate.\n+        # But in Eager mode, the optimizer already does the computations and the\n+        # return value cannot be run.\n         if not tf.executing_eagerly():\n             self.evaluate(val)\n \n     def _eval_if_tensor(self, val):\n-        # Calls self.evaluate on val if val is a Tensor or Variable. This is useful,\n-        # since hyperparameters are tf.Variables on OptimizerV2 and are Python\n-        # floats on the experimental optimizer.\n+        # Calls self.evaluate on val if val is a Tensor or Variable. This is\n+        # useful, since hyperparameters are tf.Variables on OptimizerV2 and are\n+        # Python floats on the experimental optimizer.\n         return (\n             self.evaluate(val)\n             if isinstance(val, (tf.Tensor, tf.Variable))\n@@ -196,9 +196,9 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n             opt = create_lso(opt, dynamic=False, initial_scale=loss_scale)\n             self.assertEqual(self.evaluate(opt.loss_scale), loss_scale)\n             self.assertIsInstance(opt.loss_scale, tf.Tensor)\n-            # We need num_replicas_in_sync to divide loss_scale, otherwise loss_scale\n-            # / strategy.num_replicas_in_sync will not be exact, which could lead to\n-            # assertion failures due to rounding issues.\n+            # We need num_replicas_in_sync to divide loss_scale, otherwise\n+            # loss_scale / strategy.num_replicas_in_sync will not be exact,\n+            # which could lead to assertion failures due to rounding issues.\n             self.assertEqual(loss_scale % strategy.num_replicas_in_sync, 0)\n             run_fn = self._run_fn_with_grad_check(\n                 strategy, var, opt, loss_scale / strategy.num_replicas_in_sync\n@@ -208,8 +208,9 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n             run_op = strategy.experimental_run(run_fn)\n             self.evaluate(tf.compat.v1.global_variables_initializer())\n             self._run_if_in_graph_mode(run_op)\n-            # The loss is the identity of the variable. Therefore the gradient is 1,\n-            # and so the variable will be init_val - grad * lr == 5 - 1 * 2 == 3\n+            # The loss is the identity of the variable. Therefore the gradient\n+            # is 1, and so the variable will be init_val - grad * lr == 5 - 1 *\n+            # 2 == 3\n             self.assertAllClose([3.0], self.evaluate(var))\n \n     def testFixedLossScaleAppliedToLossWithGetGradients(self):\n@@ -227,7 +228,8 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n             run_op = opt.get_gradients(loss, [var])\n             self.evaluate(tf.compat.v1.global_variables_initializer())\n             # This will cause an assertion to run, as\n-            # mp_test_util.create_identity_with_grad_check_fn added an assertion op.\n+            # mp_test_util.create_identity_with_grad_check_fn added an assertion\n+            # op.\n             self.evaluate(run_op)\n \n     @test_combinations.generate(opt_combinations_only())\n@@ -308,11 +310,13 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n             run_op = strategy.experimental_run(run_fn)\n             self.evaluate(tf.compat.v1.global_variables_initializer())\n             self._run_if_in_graph_mode(run_op)\n-            # The loss is the identity of the variable. Therefore the gradient is 1,\n-            # and so the variable will be init_val - grad * lr == 5 - 1 * 2 == 3\n+            # The loss is the identity of the variable. Therefore the gradient\n+            # is 1, and so the variable will be init_val - grad * lr == 5 - 1 *\n+            # 2 == 3\n             self.assertAllClose([3.0], self.evaluate(var))\n \n-            # Loss scale will be double, so the expected gradient is also doubled.\n+            # Loss scale will be double, so the expected gradient is also\n+            # doubled.\n             self.evaluate(\n                 expected_gradient.assign(\n                     2 * learning_rate / strategy.num_replicas_in_sync\n@@ -320,8 +324,8 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n             )\n             run_op = strategy.experimental_run(run_fn)\n             self._run_if_in_graph_mode(run_op)\n-            # As before, the 2 is subtracted from the variable, making it's new value\n-            # 1.\n+            # As before, the 2 is subtracted from the variable, making it's new\n+            # value 1.\n             self.assertAllClose([1.0], self.evaluate(var))\n \n     @test_combinations.generate(opt_combinations_only())\n@@ -365,8 +369,8 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n                 self.assertEqual(self.evaluate(opt.loss_scale), 4)\n \n                 if isinstance(opt, loss_scale_optimizer.LossScaleOptimizerV3):\n-                    # Only OptimizerV2 exposes the clipping attributes, so we cannot set\n-                    # them on the new optimizer\n+                    # Only OptimizerV2 exposes the clipping attributes, so we\n+                    # cannot set them on the new optimizer\n                     return\n                 # Test changing the clip amount and running again\n                 setattr(opt, clip_type, 3.0)\n@@ -439,8 +443,9 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n             run_op = strategy.experimental_run(run_fn)\n             self.evaluate(tf.compat.v1.global_variables_initializer())\n             self._run_if_in_graph_mode(run_op)\n-            # The loss is the identity of the variable. Therefore the gradient is 1,\n-            # and so the variable will be init_val - grad * lr == 5 - 1 * 2 == 3\n+            # The loss is the identity of the variable. Therefore the gradient\n+            # is 1, and so the variable will be init_val - grad * lr == 5 - 1 *\n+            # 2 == 3\n             self.assertAllClose([3.0], self.evaluate(var))\n \n     @test_combinations.generate(opt_and_strategy_and_mode_combinations())\n@@ -486,8 +491,8 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n \n     def testCustomAggregater(self):\n         def gradient_aggregator(grads_and_vars):\n-            # Simulate an all-reduce where a replica has a NaN gradient by setting\n-            # the last gradient to NaN\n+            # Simulate an all-reduce where a replica has a NaN gradient by\n+            # setting the last gradient to NaN\n             grads_and_vars = list(grads_and_vars)\n             last_grad, last_var = grads_and_vars[-1]\n             grads_and_vars[-1] = (last_grad * float(\"NaN\"), last_var)\n@@ -535,18 +540,18 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n             self.evaluate(tf.compat.v1.global_variables_initializer())\n             self._run_if_in_graph_mode(run_op)\n             # The momentum accumulator starts at 0 and the gradient is 1. The\n-            # accumulator is incremented by the gradient, so it is now 1. Then the\n-            # variable is subtracted by the accumulator, so the variable is subtracted\n-            # by 1.\n+            # accumulator is incremented by the gradient, so it is now 1. Then\n+            # the variable is subtracted by the accumulator, so the variable is\n+            # subtracted by 1.\n             self.assertAllClose([0.0, 1.0], self.evaluate(var))\n             self.assertEqual(self.evaluate(opt.loss_scale), initial_scale * 2)\n \n             run_op = strategy.experimental_run(run_fn)\n             self._run_if_in_graph_mode(run_op)\n-            # The momentum accumulator was 1 before this step and the gradient is 1.\n-            # The accumulator is incremented by the gradient, so it is now 2. Then the\n-            # variable is subtracted by the accumulator, so the variable is subtracted\n-            # by 2.\n+            # The momentum accumulator was 1 before this step and the gradient\n+            # is 1. The accumulator is incremented by the gradient, so it is\n+            # now 2. Then the variable is subtracted by the accumulator, so the\n+            # variable is subtracted by 2.\n             self.assertAllClose([-2.0, -1.0], self.evaluate(var))\n             self.assertEqual(self.evaluate(opt.loss_scale), initial_scale * 4)\n \n@@ -581,8 +586,8 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n             )  # Grad is 2, so var is 5 - 2\n             self.assertEqual(self.evaluate(opt.iterations), 1)\n \n-            # Test iterations is incremented in opt.minimize even if gradients aren't\n-            # applied to variables due to NaN gradients.\n+            # Test iterations is incremented in opt.minimize even if gradients\n+            # aren't applied to variables due to NaN gradients.\n             loss = lambda: var * float(\"NaN\")\n             run_fn = lambda: opt.minimize(loss, [var])\n             if use_tf_function:\n@@ -639,8 +644,8 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n             self.assertEqual(self.evaluate(opt.learning_rate), 2.0)\n             self.assertIs(lso.lr, opt.lr)\n \n-            # Test setting attribute that is both attribute on LossScaleOptimizer and\n-            # hyperparameter on wrapped optimizer.\n+            # Test setting attribute that is both attribute on\n+            # LossScaleOptimizer and hyperparameter on wrapped optimizer.\n             class MyOpt(gradient_descent.SGD):\n                 def __init__(self):\n                     super().__init__()\n@@ -682,8 +687,9 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n     def testApplyGradientsGetsUnwrappedTensors(self):\n         # Tests that gradients passed to apply_gradients are not wrapped in a\n         # DistributionStrategy wrapper, such as PerReplica, but instead are raw\n-        # Tensors. Optimizer subclasses that override apply_gradients() expect raw\n-        # Tensors, even though the base Optimizer can handle PerReplica gradients.\n+        # Tensors. Optimizer subclasses that override apply_gradients() expect\n+        # raw Tensors, even though the base Optimizer can handle PerReplica\n+        # gradients.\n \n         outer_self = self\n \n@@ -865,8 +871,8 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n                 self.assertEqual(self.evaluate(slot_var).item(), -1)\n             self.assertEqual(self.evaluate(opt.iterations), 1)\n \n-            # Set optimizer variable to check arbitrary optimizer attributes can be\n-            # saved/restored\n+            # Set optimizer variable to check arbitrary optimizer attributes can\n+            # be saved/restored\n             self.evaluate(inner_opt.my_var.assign(1.0))\n \n             # Save a checkpoint.\n@@ -1114,10 +1120,11 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n             )\n             config = optimizers.serialize(opt)\n             if lso_type == \"v1\":\n-                # LossScaleOptimizerV1 was an older experimental version of LSO that is\n-                # now deleted. The config had the same format as LSO but the class\n-                # name was different. This tests that LSO V1 configs can still be\n-                # deserialized, which are deserialized as a (non-V1) LSO\n+                # LossScaleOptimizerV1 was an older experimental version of LSO\n+                # that is now deleted. The config had the same format as LSO but\n+                # the class name was different. This tests that LSO V1 configs\n+                # can still be deserialized, which are deserialized as a\n+                # (non-V1) LSO\n                 config[\"class_name\"] = \"LossScaleOptimizerV1\"\n         else:\n             opt = sgd_experimental.SGD(2.0, momentum=0.5)\n@@ -1244,8 +1251,8 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n             lso.get_scaled_loss(tf.constant(1.0))\n             lso.apply_gradients([(tf.constant(1.0), var)])\n             self.assertIn(\n-                \"You forgot to call LossScaleOptimizer.get_unscaled_gradients() \"\n-                \"before\",\n+                \"You forgot to call \"\n+                \"LossScaleOptimizer.get_unscaled_gradients() before\",\n                 mock_warn.call_args_list[0][0][0],\n             )\n         lso = create_lso(create_sgd(opt_cls))\n@@ -1253,7 +1260,8 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n             lso.get_unscaled_gradients([tf.constant(1.0)])\n             lso.apply_gradients([(tf.constant(1.0), var)])\n             self.assertIn(\n-                \"You forgot to call LossScaleOptimizer.get_scaled_loss() before\",\n+                \"You forgot to call LossScaleOptimizer.get_scaled_loss() \"\n+                \"before\",\n                 mock_warn.call_args_list[0][0][0],\n             )\n         lso = create_lso(create_sgd(opt_cls))\n\n@@ -35,8 +35,8 @@ class MixedPrecisionTest(test_combinations.TestCase):\n \n     def setUp(self):\n         super().setUp()\n-        # Enable the tests to be run on pre-Volta GPUs by telling the grappler pass\n-        # to ignore performance and always transform the graph.\n+        # Enable the tests to be run on pre-Volta GPUs by telling the grappler\n+        # pass to ignore performance and always transform the graph.\n         self._original_ignore_perf_value = os.getenv(self.IGNORE_PERF_VAR)\n         os.environ[self.IGNORE_PERF_VAR] = \"1\"\n \n\n@@ -208,12 +208,13 @@ class KerasModelTest(test_combinations.TestCase):\n                     del y_true\n                     return tf.reduce_mean(y_pred)\n \n-                # Learning rate is small enough that if applied to a float16 variable,\n-                # the variable will not change. So this tests the learning rate not\n-                # applied to a float16 value, but instead the float32 variable.\n+                # Learning rate is small enough that if applied to a float16\n+                # variable, the variable will not change. So this tests the\n+                # learning rate not applied to a float16 value, but instead the\n+                # float32 variable.\n                 opt = gradient_descent.SGD(2**-14)\n-                # Use a fixed loss scale, as this test will fail if gradients are\n-                # skipped for a step due to dynamic loss scaling.\n+                # Use a fixed loss scale, as this test will fail if gradients\n+                # are skipped for a step due to dynamic loss scaling.\n                 opt = loss_scale_optimizer.LossScaleOptimizer(\n                     opt, dynamic=False, initial_scale=8\n                 )\n@@ -297,7 +298,8 @@ class KerasModelTest(test_combinations.TestCase):\n         },\n     )\n     def test_fixed_loss_scaling(self, strategy_fn):\n-        # Note: We do not test mixed precision in this method, only loss scaling.\n+        # Note: We do not test mixed precision in this method, only loss\n+        # scaling.\n         loss_scale = 8.0\n         batch_size = 4\n         with strategy_fn().scope():\n@@ -305,9 +307,9 @@ class KerasModelTest(test_combinations.TestCase):\n             layer = mp_test_util.MultiplyLayer()\n             y = layer(x)\n \n-            # The gradient of 'y' at this point is 1. With loss scaling, the gradient\n-            # is 'loss_scale'. We divide by the batch size since the loss is averaged\n-            # across batch elements.\n+            # The gradient of 'y' at this point is 1. With loss scaling, the\n+            # gradient is 'loss_scale'. We divide by the batch size since the\n+            # loss is averaged across batch elements.\n             expected_gradient = loss_scale / batch_size\n             identity_with_grad_check_fn = (\n                 mp_test_util.create_identity_with_grad_check_fn(\n@@ -334,7 +336,8 @@ class KerasModelTest(test_combinations.TestCase):\n         y = np.ones((batch_size, 1))\n         dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size)\n         model.fit(dataset)\n-        # Variable starts at 1, and should have gradient of 1 subtracted from it.\n+        # Variable starts at 1, and should have gradient of 1 subtracted from\n+        # it.\n         expected = 0\n         self.assertEqual(backend.eval(layer.v), expected)\n \n@@ -352,10 +355,10 @@ class KerasModelTest(test_combinations.TestCase):\n         },\n     )\n     def test_advanced_model(self, strategy_fn, use_loss_scaling=False):\n-        # The advanced model tests mixed-precision-related features that would occur\n-        # in a resnet50 model. It tests a model that has:\n-        #  * Multiple layers, some which use auto-cast variables and some which do\n-        #    not\n+        # The advanced model tests mixed-precision-related features that would\n+        # occur in a resnet50 model. It tests a model that has:\n+        #  * Multiple layers, some which use auto-cast variables and some which\n+        #    do not\n         #  * Regularization on some variables and not others.\n         #  * A fixed loss scale (if use_loss_scaling is True)\n \n@@ -388,9 +391,9 @@ class KerasModelTest(test_combinations.TestCase):\n                 y = layer3(y)\n                 y = layer4(y)\n                 if use_loss_scaling:\n-                    # The gradient of 'y' at this point is 1. With loss scaling, the\n-                    # gradient is 'loss_scale'. We divide by the batch size of 2 since the\n-                    # loss is averaged across batch elements.\n+                    # The gradient of 'y' at this point is 1. With loss scaling,\n+                    # the gradient is 'loss_scale'. We divide by the batch size\n+                    # of 2 since the loss is averaged across batch elements.\n                     expected_gradient = loss_scale / 2\n                     identity_with_grad_check_fn = (\n                         mp_test_util.create_identity_with_grad_check_fn(\n@@ -448,7 +451,8 @@ class KerasModelTest(test_combinations.TestCase):\n         expected_gradient = backend.variable(\n             [initial_loss_scale / batch_size], dtype=tf.float16\n         )\n-        # If this variable is set to True, the model below will have NaN gradients\n+        # If this variable is set to True, the model below will have NaN\n+        # gradients\n         have_nan_gradients = backend.variable(False, dtype=tf.bool)\n         with strategy.scope():\n             opt = gradient_descent.SGD(1.0)\n@@ -504,8 +508,8 @@ class KerasModelTest(test_combinations.TestCase):\n         y = np.ones((batch_size, 1))\n         dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size)\n         model.fit(dataset)\n-        # The variables starts with 1 and has a gradient of 1, so will go down by 1\n-        # each step.\n+        # The variables starts with 1 and has a gradient of 1, so will go down\n+        # by 1 each step.\n         self.assertEqual(backend.eval(layer.v), 0)\n \n         model.fit(dataset)\n@@ -526,8 +530,8 @@ class KerasModelTest(test_combinations.TestCase):\n \n         # Test with finite gradients again\n         backend.set_value(have_nan_gradients, False)\n-        # The loss scale will be halved due to the NaNs, so the gradient will also\n-        # be halved\n+        # The loss scale will be halved due to the NaNs, so the gradient will\n+        # also be halved\n         backend.set_value(\n             expected_gradient, backend.get_value(expected_gradient / 2)\n         )\n@@ -559,8 +563,8 @@ class KerasModelTest(test_combinations.TestCase):\n                 model.optimizer, loss_scale_optimizer.LossScaleOptimizer\n             )\n \n-            # Test if an LSO is passed, optimizer is not automatically wrapped with\n-            # another LSO\n+            # Test if an LSO is passed, optimizer is not automatically wrapped\n+            # with another LSO\n             model = models.Model(x, y)\n             optimizer = loss_scale_optimizer.LossScaleOptimizer(\n                 gradient_descent.SGD(1.0), dynamic_growth_steps=2\n@@ -676,10 +680,11 @@ class KerasModelTest(test_combinations.TestCase):\n         p = policy.Policy(\"mixed_float16\")\n         with strategy_fn().scope(), policy.policy_scope(p):\n             x = layers.Input(shape=(2,), batch_size=2)\n-            # Having a var_name other than 'v' tests that a fixed bug (b/134713714)\n-            # does not reoccur. The bug was that a crash would occur when saving a\n-            # checkpoint where an AutoCastVariable with a slot variable would have a\n-            # different name than the layer attribute's name (layer.v in this case).\n+            # Having a var_name other than 'v' tests that a fixed bug\n+            # (b/134713714) does not reoccur. The bug was that a crash would\n+            # occur when saving a checkpoint where an AutoCastVariable with a\n+            # slot variable would have a different name than the layer\n+            # attribute's name (layer.v in this case).\n             layer = mp_test_util.MultiplyLayer(\n                 assert_type=tf.float16, var_name=var_name\n             )\n@@ -849,8 +854,8 @@ class KerasModelTest(test_combinations.TestCase):\n         },\n     )\n     def test_save_model_with_dynamic_loss_scaling(self, strategy_fn, h5=False):\n-        # TODO(reedwm): Support and test saving model with a mixed_[b]float16 policy\n-        # as well.\n+        # TODO(reedwm): Support and test saving model with a mixed_[b]float16\n+        # policy as well.\n         strategy = strategy_fn()\n         if (\n             isinstance(strategy, tf.distribute.MirroredStrategy)\n@@ -900,9 +905,9 @@ class KerasModelTest(test_combinations.TestCase):\n         (weight,) = model.trainable_weights\n         loaded_weight = backend.get_value(weight)\n         self.assertEqual(loaded_weight, orig_weight)\n-        # Currently the loss scale isn't always saved when the model is saved with\n-        # Model.save(). So we assert the loss scale either has the value when it was\n-        # saved, or the value it was initialized with.\n+        # Currently the loss scale isn't always saved when the model is saved\n+        # with Model.save(). So we assert the loss scale either has the value\n+        # when it was saved, or the value it was initialized with.\n         # TODO(reedwm): Always save/restore the loss scale with Model.save().\n         self.assertIn(backend.get_value(model.optimizer.loss_scale), (1, 2))\n         self.assertIn(\n\n@@ -36,42 +36,45 @@ class Policy:\n     `tf.keras.mixed_precision.set_global_policy`.\n \n     Args:\n-      name: The policy name, which determines the compute and variable dtypes. Can\n-        be any dtype name, such as `'float32'` or `'float64'`, which causes both\n-        the compute and variable dtypes will be that dtype. Can also be the string\n-        `'mixed_float16'` or `'mixed_bfloat16'`, which causes the compute dtype to\n-        be float16 or bfloat16 and the variable dtype to be float32.\n+      name: The policy name, which determines the compute and variable dtypes.\n+        Can be any dtype name, such as `'float32'` or `'float64'`, which causes\n+        both the compute and variable dtypes will be that dtype. Can also be the\n+        string `'mixed_float16'` or `'mixed_bfloat16'`, which causes the compute\n+        dtype to be float16 or bfloat16 and the variable dtype to be float32.\n \n     Typically you only need to interact with dtype policies when using mixed\n     precision, which is the use of float16 or bfloat16 for computations and\n     float32 for variables. This is why the term `mixed_precision` appears in the\n     API name. Mixed precision can be enabled by passing `'mixed_float16'` or\n     `'mixed_bfloat16'` to `tf.keras.mixed_precision.set_global_policy`. See [the\n-    mixed precision guide](https://www.tensorflow.org/guide/keras/mixed_precision)\n-    for more information on how to use mixed precision.\n+    mixed precision\n+    guide](https://www.tensorflow.org/guide/keras/mixed_precision) for more\n+    information on how to use mixed precision.\n \n     >>> tf.keras.mixed_precision.set_global_policy('mixed_float16')\n     >>> layer1 = tf.keras.layers.Dense(10)\n     >>> layer1.dtype_policy  # `layer1` will automatically use mixed precision\n     <Policy \"mixed_float16\">\n-    >>> # Can optionally override layer to use float32 instead of mixed precision.\n+    >>> # Can optionally override layer to use float32\n+    >>> # instead of mixed precision.\n     >>> layer2 = tf.keras.layers.Dense(10, dtype='float32')\n     >>> layer2.dtype_policy\n     <Policy \"float32\">\n     >>> # Set policy back to initial float32 for future examples.\n     >>> tf.keras.mixed_precision.set_global_policy('float32')\n \n-    In the example above, passing `dtype='float32'` to the layer is equivalent to\n-    passing `dtype=tf.keras.mixed_precision.Policy('float32')`. In general,\n+    In the example above, passing `dtype='float32'` to the layer is equivalent\n+    to passing `dtype=tf.keras.mixed_precision.Policy('float32')`. In general,\n     passing a dtype policy name to a layer is equivalent to passing the\n     corresponding policy, so it is never necessary to explicitly construct a\n     `Policy` object.\n \n     Note: `Model.compile` will automatically wrap an optimizer with a\n-    `tf.keras.mixed_precision.LossScaleOptimizer` if you use the `'mixed_float16'`\n-    policy. If you use a custom training loop instead of calling `Model.compile`,\n-    you should explicitly use a `tf.keras.mixed_precision.LossScaleOptimizer` to\n-    avoid numeric underflow with float16.\n+    `tf.keras.mixed_precision.LossScaleOptimizer` if you use the\n+    `'mixed_float16'` policy. If you use a custom training loop instead of\n+    calling `Model.compile`, you should explicitly use a\n+    `tf.keras.mixed_precision.LossScaleOptimizer` to avoid numeric underflow\n+    with float16.\n \n     ### How a layer uses its policy's compute dtype\n \n@@ -92,9 +95,9 @@ class Policy:\n     Note that the base `tf.keras.layers.Layer` class inserts the casts. If\n     subclassing your own layer, you do not have to insert any casts.\n \n-    Currently, only tensors in the first argument to the layer's `call` method are\n-    casted (although this will likely be changed in a future minor release). For\n-    example:\n+    Currently, only tensors in the first argument to the layer's `call` method\n+    are casted (although this will likely be changed in a future minor release).\n+    For example:\n \n     >>> class MyLayer(tf.keras.layers.Layer):\n     ...   # Bug! `b` will not be casted.\n@@ -110,12 +113,13 @@ class Policy:\n     tf.float32\n \n     If writing your own layer with multiple inputs, you should either explicitly\n-    cast other tensors to `self.compute_dtype` in `call` or accept all tensors in\n-    the first argument as a list.\n+    cast other tensors to `self.compute_dtype` in `call` or accept all tensors\n+    in the first argument as a list.\n \n     The casting only occurs in TensorFlow 2. If\n     `tf.compat.v1.disable_v2_behavior()` has been called, you can enable the\n-    casting behavior with `tf.compat.v1.keras.layers.enable_v2_dtype_behavior()`.\n+    casting behavior with\n+    `tf.compat.v1.keras.layers.enable_v2_dtype_behavior()`.\n \n     ### How a layer uses its policy's variable dtype\n \n@@ -123,11 +127,11 @@ class Policy:\n     is the layer's policy's variable dtype.\n \n     If a layer's compute and variable dtypes differ, `add_weight` will wrap\n-    floating-point variables with a special wrapper called an `AutoCastVariable`.\n-    `AutoCastVariable` is identical to the original variable except it casts\n-    itself to the layer's compute dtype when used within `Layer.call`. This means\n-    if you are writing a layer, you do not have to explicitly cast the variables\n-    to the layer's compute dtype. For example:\n+    floating-point variables with a special wrapper called an\n+    `AutoCastVariable`.  `AutoCastVariable` is identical to the original\n+    variable except it casts itself to the layer's compute dtype when used\n+    within `Layer.call`. This means if you are writing a layer, you do not have\n+    to explicitly cast the variables to the layer's compute dtype. For example:\n \n     >>> class SimpleDense(tf.keras.layers.Layer):\n     ...\n@@ -155,14 +159,14 @@ class Policy:\n \n     For the most part, layers will automatically support mixed precision and\n     float64 without any additional work, due to the fact the base layer\n-    automatically casts inputs, creates variables of the correct type, and in the\n-    case of mixed precision, wraps variables with `AutoCastVariables`.\n+    automatically casts inputs, creates variables of the correct type, and in\n+    the case of mixed precision, wraps variables with `AutoCastVariables`.\n \n     The primary case where you need extra work to support mixed precision or\n     float64 is when you create a new tensor, such as with `tf.ones` or\n     `tf.random.normal`, In such cases, you must create the tensor of the correct\n-    dtype. For example, if you call `tf.random.normal`, you must pass the compute\n-    dtype, which is the dtype the inputs have been casted to:\n+    dtype. For example, if you call `tf.random.normal`, you must pass the\n+    compute dtype, which is the dtype the inputs have been casted to:\n \n     >>> class AddRandom(tf.keras.layers.Layer):\n     ...\n@@ -178,8 +182,8 @@ class Policy:\n \n     If you did not pass `dtype=inputs.dtype` to `tf.random.normal`, a\n     `TypeError` would have occurred. This is because the `tf.random.normal`'s\n-    dtype defaults to `\"float32\"`, but the input dtype is float16. You cannot add\n-    a float32 tensor with a float16 tensor.\n+    dtype defaults to `\"float32\"`, but the input dtype is float16. You cannot\n+    add a float32 tensor with a float16 tensor.\n     \"\"\"\n \n     def __init__(self, name):\n@@ -227,15 +231,15 @@ class Policy:\n             return \"bfloat16\", \"float32\"\n         elif name == \"_infer\":\n             # The \"_infer\" policy exists only for compatibility with TF 1, where\n-            # \"_infer\" is the default. The behavior matches the behavior of TF 1's\n-            # behavior before policies were introduced. With \"_infer\", the computation\n-            # and variable dtype are inferred from the first input the first time the\n-            # layer is called. Once the layer is called for the first time, the\n-            # layer's policy will change to the dtype of the first input, and it will\n-            # no longer have the \"_infer\" policy.\n+            # \"_infer\" is the default. The behavior matches the behavior of TF\n+            # 1's behavior before policies were introduced. With \"_infer\", the\n+            # computation and variable dtype are inferred from the first input\n+            # the first time the layer is called. Once the layer is called for\n+            # the first time, the layer's policy will change to the dtype of the\n+            # first input, and it will no longer have the \"_infer\" policy.\n             #\n-            # The infer policy should be considered an implementation detail and may\n-            # be removed in the future.\n+            # The infer policy should be considered an implementation detail and\n+            # may be removed in the future.\n             return None, None\n \n         try:\n@@ -255,10 +259,11 @@ class Policy:\n \n         This is the dtype layers will create their variables in, unless a layer\n         explicitly chooses a different dtype. If this is different than\n-        `Policy.compute_dtype`, Layers will cast variables to the compute dtype to\n-        avoid type errors.\n+        `Policy.compute_dtype`, Layers will cast variables to the compute dtype\n+        to avoid type errors.\n \n-        Variable regularizers are run in the variable dtype, not the compute dtype.\n+        Variable regularizers are run in the variable dtype, not the compute\n+        dtype.\n \n         Returns:\n           The variable dtype of this policy, as a string.\n@@ -272,21 +277,22 @@ class Policy:\n         This is the dtype layers will do their computations in. Typically layers\n         output tensors with the compute dtype as well.\n \n-        Note that even if the compute dtype is float16 or bfloat16, hardware devices\n-        may not do individual adds, multiplies, and other fundamental operations in\n-        float16 or bfloat16, but instead may do some of them in float32 for numeric\n-        stability. The compute dtype is the dtype of the inputs and outputs of the\n-        TensorFlow ops that the layer executes. Internally, many TensorFlow ops will\n-        do certain internal calculations in float32 or some other device-internal\n-        intermediate format with higher precision than float16/bfloat16, to increase\n-        numeric stability.\n+        Note that even if the compute dtype is float16 or bfloat16, hardware\n+        devices may not do individual adds, multiplies, and other fundamental\n+        operations in float16 or bfloat16, but instead may do some of them in\n+        float32 for numeric stability. The compute dtype is the dtype of the\n+        inputs and outputs of the TensorFlow ops that the layer executes.\n+        Internally, many TensorFlow ops will do certain internal calculations in\n+        float32 or some other device-internal intermediate format with higher\n+        precision than float16/bfloat16, to increase numeric stability.\n \n         For example, a `tf.keras.layers.Dense` layer, when run on a GPU with a\n-        float16 compute dtype, will pass float16 inputs to `tf.linalg.matmul`. But,\n-        `tf.linalg.matmul` will do use float32 intermediate math. The performance\n-        benefit of float16 is still apparent, due to increased memory bandwidth and\n-        the fact modern GPUs have specialized hardware for computing matmuls on\n-        float16 inputs while still keeping intermediate computations in float32.\n+        float16 compute dtype, will pass float16 inputs to `tf.linalg.matmul`.\n+        But, `tf.linalg.matmul` will do use float32 intermediate math. The\n+        performance benefit of float16 is still apparent, due to increased\n+        memory bandwidth and the fact modern GPUs have specialized hardware for\n+        computing matmuls on float16 inputs while still keeping intermediate\n+        computations in float32.\n \n         Returns:\n           The compute dtype of this policy, as a string.\n@@ -327,9 +333,10 @@ def global_policy():\n     \"\"\"Returns the global dtype policy.\n \n     The global policy is the default `tf.keras.mixed_precision.Policy` used for\n-    layers, if no policy is passed to the layer constructor. If no policy has been\n-    set with `keras.mixed_precision.set_global_policy`, this will return a policy\n-    constructed from `tf.keras.backend.floatx()` (floatx defaults to float32).\n+    layers, if no policy is passed to the layer constructor. If no policy has\n+    been set with `keras.mixed_precision.set_global_policy`, this will return a\n+    policy constructed from `tf.keras.backend.floatx()` (floatx defaults to\n+    float32).\n \n     >>> tf.keras.mixed_precision.global_policy()\n     <Policy \"float32\">\n@@ -358,17 +365,17 @@ def global_policy():\n def _check_if_mixed_precision_graph_rewrite_is_enabled(policy):\n     if tf.__internal__.train.is_mixed_precision_graph_rewrite_enabled():\n         raise ValueError(\n-            'The global dtype policy cannot be set to \"{policy.name}\", because the '\n-            \"mixed precision graph rewrite has already been enabled.\\n\"\n+            'The global dtype policy cannot be set to \"{policy.name}\", because '\n+            \"the mixed precision graph rewrite has already been enabled.\\n\"\n             \"At most, one of the following can be called:\\n\\n\"\n             \"  1. tf.compat.v1.train.enable_mixed_precision_graph_rewrite() \"\n             \"(You called this first)\\n\"\n             \"  2. tf.keras.mixed_precision.set_global_policy() with a mixed \"\n             \"precision policy (You called this second)\\n\\n\"\n-            \"You called both functions, which is an error, because both functions \"\n-            \"enable you to use mixed precision. If in doubt which function to use, \"\n-            \"use the second, as it supports Eager execution and is more \"\n-            \"customizable.\".format(policy=policy)\n+            \"You called both functions, which is an error, because both \"\n+            \"functions enable you to use mixed precision. If in doubt which \"\n+            \"function to use, use the second, as it supports Eager execution \"\n+            \"and is more customizable.\".format(policy=policy)\n         )\n \n \n@@ -384,7 +391,8 @@ def set_global_policy(policy):\n     <Policy \"mixed_float16\">\n     >>> tf.keras.layers.Dense(10).dtype_policy\n     <Policy \"mixed_float16\">\n-    >>> # Global policy is not used if a policy is directly passed to constructor\n+    >>> # Global policy is not used if a policy\n+    >>> # is directly passed to constructor\n     >>> tf.keras.layers.Dense(10, dtype='float64').dtype_policy\n     <Policy \"float64\">\n     >>> tf.keras.mixed_precision.set_global_policy('float32')\n@@ -467,9 +475,9 @@ def _is_convertible_to_dtype(dtype):\n def _policy_equivalent_to_dtype(policy):\n     \"\"\"Returns True if the Policy is equivalent to a single dtype.\n \n-    A policy is equivalent to a single dtype if the policy's compute and variable\n-    dtypes are the same and the policy's type is Policy and not a subclass of\n-    Policy.\n+    A policy is equivalent to a single dtype if the policy's compute and\n+    variable dtypes are the same and the policy's type is Policy and not a\n+    subclass of Policy.\n \n     The \"_infer\" policy is considered equivalent to a single dtype.\n \n@@ -489,8 +497,8 @@ def _policy_equivalent_to_dtype(policy):\n def serialize(policy):\n     if _policy_equivalent_to_dtype(policy):\n         # We return either None or the policy name for compatibility with older\n-        # versions of Keras. If the policy name is returned, it is a dtype string\n-        # such as 'float32'.\n+        # versions of Keras. If the policy name is returned, it is a dtype\n+        # string such as 'float32'.\n         return None if policy.name == \"_infer\" else policy.name\n     return generic_utils.serialize_keras_object(policy)\n \n\n@@ -126,7 +126,8 @@ class PolicyTest(tf.test.TestCase, parameterized.TestCase):\n         try:\n             mp_policy.set_global_policy(\"mixed_float16\")\n             self.assertEqual(mp_policy.global_policy().name, \"mixed_float16\")\n-            with tf.Graph().as_default():  # Policies are not associated with a graph\n+            # Policies are not associated with a graph\n+            with tf.Graph().as_default():\n                 self.assertEqual(\n                     mp_policy.global_policy().name, \"mixed_float16\"\n                 )\n@@ -143,15 +144,15 @@ class PolicyTest(tf.test.TestCase, parameterized.TestCase):\n         with self.assertRaisesRegex(\n             ValueError,\n             \"set_global_policy can only be used to set the global policy to \"\n-            'floating-point policies, such as \"float32\" and \"mixed_float16\", but '\n-            \"got policy: int32\",\n+            'floating-point policies, such as \"float32\" and \"mixed_float16\", '\n+            \"but got policy: int32\",\n         ):\n             mp_policy.set_global_policy(\"int32\")\n         with self.assertRaisesRegex(\n             ValueError,\n             \"set_global_policy can only be used to set the global policy to \"\n-            'floating-point policies, such as \"float32\" and \"mixed_float16\", but '\n-            \"got policy: complex64\",\n+            'floating-point policies, such as \"float32\" and \"mixed_float16\", '\n+            \"but got policy: complex64\",\n         ):\n             mp_policy.set_global_policy(mp_policy.Policy(\"complex64\"))\n \n@@ -170,7 +171,8 @@ class PolicyTest(tf.test.TestCase, parameterized.TestCase):\n         else:\n             self.assertRegex(\n                 mock_warn.call_args[0][0],\n-                r\"Mixed precision compatibility check \\(mixed_float16\\): WARNING.*\",\n+                r\"Mixed precision compatibility check \\(mixed_float16\\): \"\n+                r\"WARNING.*\",\n             )\n \n         if tf.config.list_physical_devices(\"GPU\"):\n@@ -206,8 +208,8 @@ class PolicyTest(tf.test.TestCase, parameterized.TestCase):\n         ):\n             config = policy.get_config()\n             new_policy = mp_policy.Policy.from_config(config)\n-            # Comparing strings is the easiest way to ensure the policies are the\n-            # same, as policy does not override the == operator.\n+            # Comparing strings is the easiest way to ensure the policies are\n+            # the same, as policy does not override the == operator.\n             self.assertEqual(str(policy), str(new_policy))\n \n     @test_utils.enable_v2_dtype_behavior\n\n@@ -44,7 +44,8 @@ def create_identity_with_grad_check_fn(expected_gradient, expected_dtype=None):\n         x = tf.identity(x)\n \n         def grad(dx):\n-            \"\"\"Gradient function that asserts the gradient has a certain value.\"\"\"\n+            \"\"\"Gradient function that asserts the gradient has a certain\n+            value.\"\"\"\n             if expected_dtype:\n                 assert (\n                     dx.dtype == expected_dtype\n@@ -55,9 +56,9 @@ def create_identity_with_grad_check_fn(expected_gradient, expected_dtype=None):\n             expected_tensor = tf.convert_to_tensor(\n                 expected_gradient, dtype=dx.dtype, name=\"expected_gradient\"\n             )\n-            # Control dependency is to ensure input is available. It's possible the\n-            # dataset will throw a StopIteration to indicate there is no more data, in\n-            # which case we don't want to run the assertion.\n+            # Control dependency is to ensure input is available. It's possible\n+            # the dataset will throw a StopIteration to indicate there is no\n+            # more data, in which case we don't want to run the assertion.\n             with tf.control_dependencies([x]):\n                 assert_op = tf.compat.v1.assert_equal(dx, expected_tensor)\n             with tf.control_dependencies([assert_op]):\n@@ -78,13 +79,13 @@ def create_identity_with_nan_gradients_fn(have_nan_gradients):\n     \"\"\"Returns a function that optionally has NaN gradients.\n \n     This serves as a hook to introduce NaN gradients to a model. This returns an\n-    identity function. The identity's gradient function will check if the boolean\n-    tensor `have_nan_gradients` is True. If so, the gradient will be NaN.\n-    Otherwise, the gradient will also be the identity.\n+    identity function. The identity's gradient function will check if the\n+    boolean tensor `have_nan_gradients` is True. If so, the gradient will be\n+    NaN.  Otherwise, the gradient will also be the identity.\n \n     Args:\n-      have_nan_gradients: A scalar boolean tensor. If True, gradients will be NaN.\n-        Otherwise, the gradient function is the identity function.\n+      have_nan_gradients: A scalar boolean tensor. If True, gradients will be\n+        NaN. Otherwise, the gradient function is the identity function.\n \n     Returns:\n       An identity function whose gradient function will return NaNs, if\n@@ -121,12 +122,14 @@ class AssertTypeLayer(base_layer.Layer):\n         super().__init__(**kwargs)\n \n     def assert_input_types(self, inputs):\n-        \"\"\"Asserts `inputs` are of the correct type. Should be called in call().\"\"\"\n+        \"\"\"Asserts `inputs` are of the correct type. Should be called in\n+        call().\"\"\"\n         if self._assert_type:\n             inputs_flattened = tf.nest.flatten(inputs)\n             for inp in inputs_flattened:\n                 assert inp.dtype.base_dtype == self._assert_type, (\n-                    \"Input tensor has type %s which does not match assert type %s\"\n+                    \"Input tensor has type %s which does \"\n+                    \"not match assert type %s\"\n                     % (inp.dtype.name, self._assert_type)\n                 )\n \n@@ -149,9 +152,9 @@ class MultiplyLayer(AssertTypeLayer):\n           activity_regularizer: The activity regularizer.\n           use_operator: If True, add using the * operator. If False, add using\n             tf.multiply.\n-          var_name: The name of the variable. It can be useful to pass a name other\n-            than 'v', to test having the attribute name (self.v) being different\n-            from the variable name.\n+          var_name: The name of the variable. It can be useful to pass a name\n+            other than 'v', to test having the attribute name (self.v) being\n+            different from the variable name.\n           **kwargs: Passed to AssertTypeLayer constructor.\n         \"\"\"\n         self._regularizer = regularizer\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
