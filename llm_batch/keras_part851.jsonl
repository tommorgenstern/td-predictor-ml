{"custom_id": "keras#3fab2ddda6eefe951dda8b7e8b75d414b545249b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 5 | Churn Cumulative: 462 | Contributors (this commit): 6 | Commits (past 90d): 8 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -299,6 +299,11 @@ class TestTrainer(testing.TestCase):\n                     \"TODO: Graph mode without XLA in TF backend leads to \"\n                     \"unexpected logs, need further checks.\"\n                 )\n+        if jit_compile and backend.backend() == \"torch\":\n+            self.skipTest(\n+                \"TODO: compilation with torch backend leads to \"\n+                \"unexpected logs, need further checks.\"\n+            )\n \n         model = ExampleModel(units=3)\n         epochs = 3\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3591299c23367a693912bb93d3297eb8b5be3491", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 35 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,3 +1,4 @@\n+from keras.src import backend\n from keras.src import constraints\n from keras.src import initializers\n from keras.src import ops\n@@ -166,6 +167,12 @@ class GroupNormalization(Layer):\n         return reshaped_inputs\n \n     def _apply_normalization(self, reshaped_inputs, input_shape):\n+        inputs_dtype = reshaped_inputs.dtype\n+        compute_dtype = backend.result_type(inputs_dtype, \"float32\")\n+        # GN is prone to overflow with float16/bfloat16 inputs, so we upcast to\n+        # float32 for the subsequent computations.\n+        reshaped_inputs = ops.cast(reshaped_inputs, compute_dtype)\n+\n         group_reduction_axes = list(range(1, len(reshaped_inputs.shape)))\n \n         axis = -2 if self.axis == -1 else self.axis - 1\n@@ -190,6 +197,8 @@ class GroupNormalization(Layer):\n             res = res + beta\n \n         normalized_inputs = reshaped_inputs * inv + res\n+        normalized_inputs = ops.cast(normalized_inputs, inputs_dtype)\n+\n         return normalized_inputs\n \n     def _create_broadcast_shape(self, input_shape):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c31fad7b695faad63108c39bd008da9681bd8183", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 142 | Lines Deleted: 0 | Files Changed: 15 | Hunks: 19 | Methods Changed: 13 | Complexity Δ (Sum/Max): 16/5 | Churn Δ: 142 | Churn Cumulative: 3954 | Contributors (this commit): 20 | Commits (past 90d): 52 | Contributors (cumulative): 98 | DMM Complexity: 1.0\n\nDIFF:\n@@ -7,6 +7,7 @@ since your modifications would be overwritten.\n from keras.src.activations import deserialize\n from keras.src.activations import get\n from keras.src.activations import serialize\n+from keras.src.activations.activations import celu\n from keras.src.activations.activations import elu\n from keras.src.activations.activations import exponential\n from keras.src.activations.activations import gelu\n\n@@ -62,6 +62,7 @@ from keras.src.ops.nn import average_pool\n from keras.src.ops.nn import batch_normalization\n from keras.src.ops.nn import binary_crossentropy\n from keras.src.ops.nn import categorical_crossentropy\n+from keras.src.ops.nn import celu\n from keras.src.ops.nn import conv\n from keras.src.ops.nn import conv_transpose\n from keras.src.ops.nn import ctc_decode\n\n@@ -8,6 +8,7 @@ from keras.src.ops.nn import average_pool\n from keras.src.ops.nn import batch_normalization\n from keras.src.ops.nn import binary_crossentropy\n from keras.src.ops.nn import categorical_crossentropy\n+from keras.src.ops.nn import celu\n from keras.src.ops.nn import conv\n from keras.src.ops.nn import conv_transpose\n from keras.src.ops.nn import ctc_decode\n\n@@ -7,6 +7,7 @@ since your modifications would be overwritten.\n from keras.src.activations import deserialize\n from keras.src.activations import get\n from keras.src.activations import serialize\n+from keras.src.activations.activations import celu\n from keras.src.activations.activations import elu\n from keras.src.activations.activations import exponential\n from keras.src.activations.activations import gelu\n\n@@ -62,6 +62,7 @@ from keras.src.ops.nn import average_pool\n from keras.src.ops.nn import batch_normalization\n from keras.src.ops.nn import binary_crossentropy\n from keras.src.ops.nn import categorical_crossentropy\n+from keras.src.ops.nn import celu\n from keras.src.ops.nn import conv\n from keras.src.ops.nn import conv_transpose\n from keras.src.ops.nn import ctc_decode\n\n@@ -8,6 +8,7 @@ from keras.src.ops.nn import average_pool\n from keras.src.ops.nn import batch_normalization\n from keras.src.ops.nn import binary_crossentropy\n from keras.src.ops.nn import categorical_crossentropy\n+from keras.src.ops.nn import celu\n from keras.src.ops.nn import conv\n from keras.src.ops.nn import conv_transpose\n from keras.src.ops.nn import ctc_decode\n\n@@ -1,5 +1,6 @@\n import types\n \n+from keras.src.activations.activations import celu\n from keras.src.activations.activations import elu\n from keras.src.activations.activations import exponential\n from keras.src.activations.activations import gelu\n@@ -27,6 +28,7 @@ ALL_OBJECTS = {\n     leaky_relu,\n     relu6,\n     softmax,\n+    celu,\n     elu,\n     selu,\n     softplus,\n\n@@ -302,6 +302,27 @@ def gelu(x, approximate=False):\n     return ops.gelu(x, approximate=approximate)\n \n \n+@keras_export(\"keras.activations.celu\")\n+def celu(x, alpha=1.0):\n+    \"\"\"Continuously Differentiable Exponential Linear Unit.\n+\n+    The CeLU activation function is defined as:\n+\n+    `celu(x) = alpha * (exp(x / alpha) - 1) for x < 0`,`celu(x) = x for x >= 0`.\n+\n+    where `alpha` is a scaling parameter that controls the activation's shape.\n+\n+    Args:\n+        x: Input tensor.\n+        alpha: The α value for the CeLU formulation. Defaults to `1.0`.\n+\n+    Reference:\n+\n+    - [Barron, J. T., 2017](https://arxiv.org/abs/1704.07483)\n+    \"\"\"\n+    return ops.celu(x, alpha=alpha)\n+\n+\n @keras_export(\"keras.activations.tanh\")\n def tanh(x):\n     \"\"\"Hyperbolic tangent activation function.\n\n@@ -582,6 +582,22 @@ class ActivationsTest(testing.TestCase):\n         expected = gelu(x, True)\n         self.assertAllClose(result, expected, rtol=1e-05)\n \n+    def test_celu(self):\n+        def celu(x, alpha=1.0):\n+            return np.maximum(x, 0.0) + alpha * np.expm1(\n+                np.minimum(x, 0.0) / alpha\n+            )\n+\n+        x = np.random.random((2, 5))\n+        result = activations.celu(x[np.newaxis, :])[0]\n+        expected = celu(x)\n+        self.assertAllClose(result, expected, rtol=1e-05)\n+\n+        x = np.random.random((2, 5))\n+        result = activations.celu(x[np.newaxis, :], alpha=0.5)[0]\n+        expected = celu(x, True)\n+        self.assertAllClose(result, expected, rtol=1e-05)\n+\n     def test_elu(self):\n         x = np.random.random((2, 5))\n         result = activations.elu(x[np.newaxis, :])[0]\n\n@@ -85,6 +85,11 @@ def gelu(x, approximate=True):\n     return jnn.gelu(x, approximate)\n \n \n+def celu(x, alpha=1.0):\n+    x = convert_to_tensor(x)\n+    return jnn.celu(x, alpha=alpha)\n+\n+\n def softmax(x, axis=-1):\n     x = convert_to_tensor(x)\n     return jnn.softmax(x, axis=axis)\n\n@@ -113,6 +113,14 @@ def gelu(x, approximate=True):\n         )\n \n \n+def celu(x, alpha=1.0):\n+    x = convert_to_tensor(x)\n+    alpha = np.array(alpha, x.dtype)\n+    return np.maximum(x, np.array(0.0, dtype=x.dtype)) + alpha * np.expm1(\n+        np.minimum(x, np.array(0.0, dtype=x.dtype)) / alpha\n+    )\n+\n+\n def softmax(x, axis=None):\n     exp_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n     return exp_x / np.sum(exp_x, axis=axis, keepdims=True)\n\n@@ -76,6 +76,12 @@ def gelu(x, approximate=True):\n     return tf.nn.gelu(x, approximate=approximate)\n \n \n+def celu(x, alpha=1.0):\n+    return tf.maximum(x, 0.0) + alpha * tf.math.expm1(\n+        tf.minimum(x, 0.0) / alpha\n+    )\n+\n+\n def softmax(x, axis=-1):\n     logits = x\n     if axis is None:\n\n@@ -88,6 +88,11 @@ def gelu(x, approximate=True):\n     return tnn.gelu(x)\n \n \n+def celu(x, alpha=1.0):\n+    x = convert_to_tensor(x)\n+    return tnn.celu(x, alpha=alpha)\n+\n+\n def softmax(x, axis=-1):\n     x = convert_to_tensor(x)\n     dtype = backend.standardize_dtype(x.dtype)\n\n@@ -498,6 +498,46 @@ def gelu(x, approximate=True):\n     return backend.nn.gelu(x, approximate)\n \n \n+class Celu(Operation):\n+    def __init__(self, alpha=1.0):\n+        super().__init__()\n+        self.alpha = alpha\n+\n+    def call(self, x):\n+        return backend.nn.celu(x, self.alpha)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+@keras_export([\"keras.ops.celu\", \"keras.ops.nn.celu\"])\n+def celu(x, alpha=1.0):\n+    \"\"\"Continuously-differentiable exponential linear unit.\n+\n+    It is defined as:\n+\n+    `f(x) =  alpha * (exp(x / alpha) - 1) for x < 0`, `f(x) = x for x >= 0`.\n+\n+    Args:\n+        x: Input tensor.\n+        alpha: the α value for the CELU formulation. Defaults to `1.0`.\n+\n+    Returns:\n+        A tensor with the same shape as `x`.\n+\n+    Example:\n+\n+    >>> x = np.array([-1., 0., 1.])\n+    >>> x_celu = keras.ops.celu(x)\n+    >>> print(x_celu)\n+    array([-0.63212056, 0. , 1. ], shape=(3,), dtype=float64)\n+\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return Celu(alpha).symbolic_call(x)\n+    return backend.nn.celu(x, alpha)\n+\n+\n class Softmax(Operation):\n     def __init__(self, axis=-1):\n         super().__init__()\n\n@@ -141,6 +141,10 @@ class NNOpsDynamicShapeTest(testing.TestCase):\n         x = KerasTensor([None, 2, 3])\n         self.assertEqual(knn.gelu(x).shape, (None, 2, 3))\n \n+    def test_celu(self):\n+        x = KerasTensor([None, 2, 3])\n+        self.assertEqual(knn.celu(x).shape, (None, 2, 3))\n+\n     def test_softmax(self):\n         x = KerasTensor([None, 2, 3])\n         self.assertEqual(knn.softmax(x).shape, (None, 2, 3))\n@@ -786,6 +790,10 @@ class NNOpsStaticShapeTest(testing.TestCase):\n         x = KerasTensor([1, 2, 3])\n         self.assertEqual(knn.gelu(x).shape, (1, 2, 3))\n \n+    def test_celu(self):\n+        x = KerasTensor([1, 2, 3])\n+        self.assertEqual(knn.celu(x).shape, (1, 2, 3))\n+\n     def test_softmax(self):\n         x = KerasTensor([1, 2, 3])\n         self.assertEqual(knn.softmax(x).shape, (1, 2, 3))\n@@ -1292,6 +1300,13 @@ class NNOpsCorrectnessTest(testing.TestCase):\n             [-0.15880796, 0.0, 0.841192, 1.9545977, 2.9963627],\n         )\n \n+    def test_celu(self):\n+        x = np.array([-1, 0, 1, 2, 3], dtype=np.float32)\n+        self.assertAllClose(\n+            knn.celu(x),\n+            [-0.63212055, 0.0, 1.0, 2.0, 3.0],\n+        )\n+\n     def test_softmax(self):\n         x = np.array([[1, 2, 3], [1, 2, 3]], dtype=np.float32)\n         self.assertAllClose(\n@@ -2363,6 +2378,24 @@ class NNOpsDtypeTest(testing.TestCase):\n             expected_dtype,\n         )\n \n+    @parameterized.named_parameters(named_product(dtype=FLOAT_DTYPES))\n+    def test_celu(self, dtype):\n+        import jax.nn as jnn\n+        import jax.numpy as jnp\n+\n+        x = knp.ones((), dtype=dtype)\n+        x_jax = jnp.ones((), dtype=dtype)\n+        expected_dtype = standardize_dtype(jnn.celu(x_jax).dtype)\n+\n+        self.assertEqual(\n+            standardize_dtype(knn.celu(x).dtype),\n+            expected_dtype,\n+        )\n+        self.assertEqual(\n+            standardize_dtype(knn.Celu().symbolic_call(x).dtype),\n+            expected_dtype,\n+        )\n+\n     @parameterized.named_parameters(named_product(dtype=FLOAT_DTYPES))\n     def test_hard_sigmoid(self, dtype):\n         import jax.nn as jnn\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1cc1eb5856cb05675e242a617dba8c047eb77dbb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 14 | Churn Cumulative: 564 | Contributors (this commit): 9 | Commits (past 90d): 12 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -699,7 +699,7 @@ def deserialize_node(node_data, created_layers):\n             inbound_node_index = history[1]\n             inbound_tensor_index = history[2]\n             if len(layer._inbound_nodes) <= inbound_node_index:\n-                raise ValueError(\n+                raise IndexError(\n                     \"Layer node index out of bounds.\\n\"\n                     f\"inbound_layer = {layer}\\n\"\n                     f\"inbound_layer._inbound_nodes = {layer._inbound_nodes}\\n\"\n\n@@ -723,6 +723,18 @@ class SavingTest(testing.TestCase):\n             pool.join()\n         [r.get() for r in results]  # No error occurs here\n \n+    def test_load_model_containing_reused_layer(self):\n+        # https://github.com/keras-team/keras/issues/20307\n+        inputs = keras.Input((4,))\n+        reused_layer = keras.layers.Dense(4)\n+        x = reused_layer(inputs)\n+        x = keras.layers.Dense(4)(x)\n+        outputs = reused_layer(x)\n+        model = keras.Model(inputs, outputs)\n+\n+        self.assertLen(model.layers, 3)  # Input + 2 Dense layers\n+        self._test_inference_after_instantiation(model)\n+\n \n @pytest.mark.requires_trainable_backend\n class SavingAPITest(testing.TestCase):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6b662d100cbfd41131744fd5fd8863a9671b2567", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 739 | Lines Deleted: 187 | Files Changed: 9 | Hunks: 64 | Methods Changed: 65 | Complexity Δ (Sum/Max): 43/41 | Churn Δ: 926 | Churn Cumulative: 2143 | Contributors (this commit): 14 | Commits (past 90d): 40 | Contributors (cumulative): 52 | DMM Complexity: 0.4976190476190476\n\nDIFF:\n@@ -381,6 +381,7 @@ class JAXTrainer(base_trainer.Trainer):\n         )\n \n         self._symbolic_build(iterator=epoch_iterator)\n+        epoch_iterator.reset()\n \n         # Container that configures and calls callbacks.\n         if not isinstance(callbacks, callbacks_module.CallbackList):\n@@ -405,7 +406,7 @@ class JAXTrainer(base_trainer.Trainer):\n             callbacks.on_epoch_begin(epoch)\n \n             self._jax_state_synced = True\n-            for step, data in epoch_iterator.enumerate_epoch():\n+            for step, data in epoch_iterator:\n                 # Callbacks\n                 callbacks.on_train_batch_begin(step)\n \n@@ -539,6 +540,7 @@ class JAXTrainer(base_trainer.Trainer):\n             )\n \n         self._symbolic_build(iterator=epoch_iterator)\n+        epoch_iterator.reset()\n \n         # Container that configures and calls callbacks.\n         if not isinstance(callbacks, callbacks_module.CallbackList):\n@@ -560,7 +562,7 @@ class JAXTrainer(base_trainer.Trainer):\n         self.reset_metrics()\n \n         self._jax_state_synced = True\n-        for step, data in epoch_iterator.enumerate_epoch():\n+        for step, data in epoch_iterator:\n             callbacks.on_test_batch_begin(step)\n \n             if self._jax_state_synced:\n@@ -625,7 +627,7 @@ class JAXTrainer(base_trainer.Trainer):\n \n         if not all(layer.built for layer in self._flatten_layers()):\n             # Build the model on one batch of data.\n-            for _, data in epoch_iterator.enumerate_epoch():\n+            for _, data in epoch_iterator:\n                 # Build model\n                 x, _, _ = data_adapter_utils.unpack_x_y_sample_weight(data[0])\n                 with backend.StatelessScope():\n@@ -667,7 +669,7 @@ class JAXTrainer(base_trainer.Trainer):\n         self._jax_state_synced = True\n         outputs = None\n         non_trainable_variables = None\n-        for step, x in epoch_iterator.enumerate_epoch():\n+        for step, x in epoch_iterator:\n             callbacks.on_predict_batch_begin(step)\n             if self._jax_state_synced:\n                 # The state may have been synced by a callback.\n\n@@ -212,7 +212,7 @@ class NumpyTrainer(base_trainer.Trainer):\n         self.stop_predicting = False\n         callbacks.on_predict_begin()\n         outputs = None\n-        for step, data in epoch_iterator.enumerate_epoch():\n+        for step, data in epoch_iterator:\n             callbacks.on_predict_batch_begin(step)\n             batch_outputs = self.predict_function(data)\n             outputs = append_to_outputs(batch_outputs, outputs)\n@@ -256,7 +256,7 @@ class NumpyTrainer(base_trainer.Trainer):\n \n         if not all(layer.built for layer in self._flatten_layers()):\n             # Build the model on one batch of data.\n-            for _, data in epoch_iterator.enumerate_epoch():\n+            for _, data in epoch_iterator:\n                 data_batch = data[0]\n                 self._symbolic_build(data_batch)\n                 break\n@@ -278,7 +278,7 @@ class NumpyTrainer(base_trainer.Trainer):\n         callbacks.on_test_begin()\n         logs = {}\n         self.reset_metrics()\n-        for step, data in epoch_iterator.enumerate_epoch():\n+        for step, data in epoch_iterator:\n             callbacks.on_test_batch_begin(step)\n             logs = self.test_function(data)\n             callbacks.on_test_batch_end(step, logs)\n\n@@ -103,7 +103,7 @@ class DistributeTest(testing.TestCase):\n             distribute_strategy=strategy,\n         )\n         steps_seen = []\n-        for step, data_iterator in epoch_iterator.enumerate_epoch():\n+        for step, data_iterator in epoch_iterator:\n             steps_seen.append(step)\n             batch = next(data_iterator)\n             self.assertEqual(len(batch), 3)\n\n@@ -98,14 +98,18 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             y_pred = self(x)\n         return y_pred\n \n-    def make_train_function(self, force=False):\n-        if self.train_function is not None and not force:\n-            return self.train_function\n+    def _make_function(self, step_function):\n \n         @tf.autograph.experimental.do_not_convert\n         def one_step_on_data(data):\n             \"\"\"Runs a single training step on a batch of data.\"\"\"\n-            return self.train_step(data)\n+            outputs = self.distribute_strategy.run(step_function, args=(data,))\n+            outputs = reduce_per_replica(\n+                outputs,\n+                self.distribute_strategy,\n+                reduction=\"auto\",\n+            )\n+            return outputs\n \n         if not self.run_eagerly:\n             one_step_on_data = tf.function(\n@@ -114,79 +118,82 @@ class TensorFlowTrainer(base_trainer.Trainer):\n                 jit_compile=self.jit_compile,\n             )\n \n-        @tf.autograph.experimental.do_not_convert\n-        def one_step_on_iterator(iterator):\n-            \"\"\"Runs a single training step given a Dataset iterator.\"\"\"\n-            data = next(iterator)\n-            outputs = self.distribute_strategy.run(\n-                one_step_on_data, args=(data,)\n-            )\n-            outputs = reduce_per_replica(\n-                outputs,\n-                self.distribute_strategy,\n-                reduction=\"auto\",\n-            )\n-            return outputs\n-\n         @tf.autograph.experimental.do_not_convert\n         def multi_step_on_iterator(iterator):\n-            for _ in range(self.steps_per_execution):\n-                outputs = one_step_on_iterator(iterator)\n-            return outputs\n+            if self.steps_per_execution == 1:\n+                return tf.experimental.Optional.from_value(\n+                    one_step_on_data(iterator.get_next())\n+                )\n \n-        if self.steps_per_execution > 1:\n-            train_function = multi_step_on_iterator\n-        else:\n-            train_function = one_step_on_iterator\n+            # the spec is set lazily during the tracing of `tf.while_loop`\n+            empty_outputs = tf.experimental.Optional.empty(None)\n+\n+            def cond(execution_step, optional_outputs, next_optional_inputs):\n+                return tf.logical_and(\n+                    tf.less(execution_step, self.steps_per_execution),\n+                    next_optional_inputs.has_value(),\n+                )\n+\n+            def body(execution_step, optional_outputs, next_optional_inputs):\n+                next_optional_outputs = tf.experimental.Optional.from_value(\n+                    one_step_on_data(next_optional_inputs.get_value())\n+                )\n+                empty_outputs._element_spec = next_optional_outputs.element_spec\n+                return (\n+                    execution_step + 1,\n+                    next_optional_outputs,\n+                    # We don't want to iterate if we have reached\n+                    # `steps_per_execution` steps\n+                    tf.cond(\n+                        tf.less(execution_step + 1, self.steps_per_execution),\n+                        lambda: iterator.get_next_as_optional(),\n+                        lambda: next_optional_inputs,\n+                    ),\n+                )\n+\n+            execution_step = tf.constant(0)\n+            next_optional_inputs = iterator.get_next_as_optional()\n+\n+            # Run the while loop\n+            _, final_optional_outputs, _ = tf.while_loop(\n+                cond,\n+                body,\n+                loop_vars=[execution_step, empty_outputs, next_optional_inputs],\n+            )\n+            final_optional_outputs._element_spec = empty_outputs.element_spec\n+            return final_optional_outputs\n \n         if not self.run_eagerly:\n-            train_function = tf.function(train_function, reduce_retracing=True)\n+            multi_step_on_iterator = tf.function(\n+                multi_step_on_iterator, reduce_retracing=True\n+            )\n \n-        self.train_function = train_function\n+        def function(iterator):\n+            if isinstance(\n+                iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n+            ):\n+                opt_outputs = multi_step_on_iterator(iterator)\n+                if not opt_outputs.has_value():\n+                    raise StopIteration\n+                return opt_outputs.get_value()\n+            else:\n+                for step, data in zip(\n+                    range(self.steps_per_execution), iterator\n+                ):\n+                    outputs = one_step_on_data(data)\n+                return outputs\n+\n+        return function\n+\n+    def make_train_function(self, force=False):\n+        if self.train_function is not None and not force:\n+            return self.train_function\n+        self.train_function = self._make_function(self.train_step)\n \n     def make_test_function(self, force=False):\n         if self.test_function is not None and not force:\n             return self.test_function\n-\n-        @tf.autograph.experimental.do_not_convert\n-        def one_step_on_data(data):\n-            \"\"\"Runs a single test step on a batch of data.\"\"\"\n-            return self.test_step(data)\n-\n-        if not self.run_eagerly and self.jit_compile:\n-            one_step_on_data = tf.function(\n-                one_step_on_data, reduce_retracing=True, jit_compile=True\n-            )\n-\n-        @tf.autograph.experimental.do_not_convert\n-        def one_step_on_iterator(iterator):\n-            \"\"\"Runs a single test step given a Dataset iterator.\"\"\"\n-            data = next(iterator)\n-            outputs = self.distribute_strategy.run(\n-                one_step_on_data, args=(data,)\n-            )\n-            outputs = reduce_per_replica(\n-                outputs,\n-                self.distribute_strategy,\n-                reduction=\"auto\",\n-            )\n-            return outputs\n-\n-        @tf.autograph.experimental.do_not_convert\n-        def multi_step_on_iterator(iterator):\n-            for _ in range(self.steps_per_execution):\n-                outputs = one_step_on_iterator(iterator)\n-            return outputs\n-\n-        if self.steps_per_execution > 1:\n-            test_function = multi_step_on_iterator\n-        else:\n-            test_function = one_step_on_iterator\n-\n-        if not self.run_eagerly:\n-            test_function = tf.function(test_function, reduce_retracing=True)\n-\n-        self.test_function = test_function\n+        self.test_function = self._make_function(self.test_step)\n \n     def make_predict_function(self, force=False):\n         if self.predict_function is not None and not force:\n@@ -292,6 +299,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n         )\n \n         self._maybe_symbolic_build(iterator=epoch_iterator)\n+        epoch_iterator.reset()\n \n         # Container that configures and calls callbacks.\n         if not isinstance(callbacks, callbacks_module.CallbackList):\n@@ -315,7 +323,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             self.reset_metrics()\n             callbacks.on_epoch_begin(epoch)\n             with epoch_iterator.catch_stop_iteration():\n-                for step, iterator in epoch_iterator.enumerate_epoch():\n+                for step, iterator in epoch_iterator:\n                     callbacks.on_train_batch_begin(step)\n                     logs = self.train_function(iterator)\n                     callbacks.on_train_batch_end(step, logs)\n@@ -408,6 +416,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             )\n \n         self._maybe_symbolic_build(iterator=epoch_iterator)\n+        epoch_iterator.reset()\n \n         # Container that configures and calls callbacks.\n         if not isinstance(callbacks, callbacks_module.CallbackList):\n@@ -427,7 +436,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n         logs = {}\n         self.reset_metrics()\n         with epoch_iterator.catch_stop_iteration():\n-            for step, iterator in epoch_iterator.enumerate_epoch():\n+            for step, iterator in epoch_iterator:\n                 callbacks.on_test_batch_begin(step)\n                 logs = self.test_function(iterator)\n                 callbacks.on_test_batch_end(step, logs)\n@@ -493,7 +502,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n                         return data\n                     else:\n                         # Re-raise the error for\n-                        # TFEpochIterator.catch_stop_iteration() to catch when\n+                        # EpochIterator.catch_stop_iteration() to catch when\n                         # no data left.\n                         raise e\n                 data.append(single_step_data)\n@@ -504,7 +513,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n         callbacks.on_predict_begin()\n         outputs = None\n         with epoch_iterator.catch_stop_iteration():\n-            for step, iterator in epoch_iterator.enumerate_epoch():\n+            for step, iterator in epoch_iterator:\n                 callbacks.on_predict_batch_begin(step)\n                 data = get_data(iterator)\n                 batch_outputs = self.predict_function(data)\n@@ -638,9 +647,9 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             return\n \n         # Unlike jax/torch iterator, tf iterator returns an iterator instead\n-        # of data batch in `iterator.enumerate_epoch()`.\n+        # of data batch in `iterator`.\n         if iterator is not None:\n-            for _, it in iterator.enumerate_epoch():\n+            for _, it in iterator:\n                 maybe_distributed_data_batch = next(it)\n                 has_distributed_values = tree.map_structure(\n                     lambda x: isinstance(x, tf.distribute.DistributedValues),\n@@ -663,63 +672,31 @@ class TFEpochIterator(EpochIterator):\n     def __init__(self, distribute_strategy=None, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n         self._distribute_strategy = distribute_strategy\n-        dataset = self._get_iterator()\n+        dataset = self.data_adapter.get_tf_dataset()\n         if not isinstance(dataset, tf.distribute.DistributedDataset):\n             dataset = self._distribute_strategy.experimental_distribute_dataset(\n                 dataset\n             )\n         self._distributed_dataset = dataset\n-        self._steps_seen = 0\n \n     def _get_iterator(self):\n-        return self.data_adapter.get_tf_dataset()\n-\n-    def enumerate_epoch(self):\n-        self.data_adapter.on_epoch_begin()\n-        if self.steps_per_epoch:\n-            if not self._current_iterator:\n-                self._current_iterator = iter(self._distributed_dataset)\n-            for step in range(\n-                0, self.steps_per_epoch, self.steps_per_execution\n-            ):\n-                yield step, self._current_iterator\n-        else:\n-            iterator = iter(self._distributed_dataset)\n-            if self.num_batches:\n-                for step in range(\n-                    0, self.num_batches, self.steps_per_execution\n-                ):\n-                    yield step, iterator\n-            else:\n-                step = -1\n-                while True:\n-                    step += self.steps_per_execution\n-                    self._steps_seen = step + 1\n-                    yield step, iterator\n-        self.data_adapter.on_epoch_end()\n+        return self._distributed_dataset\n \n     def tf_sync(self):\n         tf_context.async_wait()\n \n+    def __next__(self):\n+        return next(self._epoch_iterator)\n+\n     @contextlib.contextmanager\n     def catch_stop_iteration(self):\n         \"\"\"Catches errors when an iterator runs out of data.\"\"\"\n+        with super().catch_stop_iteration():\n             try:\n                 yield\n                 self.tf_sync()\n-        except (StopIteration, tf.errors.OutOfRangeError):\n-            if self._num_batches is None:\n-                self._num_batches = self._steps_seen\n-            warnings.warn(\n-                \"Your input ran out of data; interrupting training. \"\n-                \"Make sure that your dataset or generator can generate \"\n-                \"at least `steps_per_epoch * epochs` batches. \"\n-                \"You may need to use the `.repeat()` \"\n-                \"function when building your dataset.\",\n-                stacklevel=2,\n-            )\n-            self._current_iterator = None\n-            self.data_adapter.on_epoch_end()\n+            except tf.errors.OutOfRangeError:\n+                raise StopIteration\n \n \n def reduce_per_replica(values, strategy, reduction):\n\n@@ -222,6 +222,7 @@ class TorchTrainer(base_trainer.Trainer):\n         )\n \n         self._symbolic_build(iterator=epoch_iterator)\n+        epoch_iterator.reset()\n \n         # Container that configures and calls callbacks.\n         if not isinstance(callbacks, callbacks_module.CallbackList):\n@@ -250,7 +251,7 @@ class TorchTrainer(base_trainer.Trainer):\n             self.train()\n \n             logs = {}\n-            for step, data in epoch_iterator.enumerate_epoch():\n+            for step, data in epoch_iterator:\n                 # Callbacks\n                 callbacks.on_train_batch_begin(step)\n \n@@ -347,6 +348,7 @@ class TorchTrainer(base_trainer.Trainer):\n             )\n \n         self._symbolic_build(iterator=epoch_iterator)\n+        epoch_iterator.reset()\n \n         # Container that configures and calls callbacks.\n         if not isinstance(callbacks, callbacks_module.CallbackList):\n@@ -368,7 +370,7 @@ class TorchTrainer(base_trainer.Trainer):\n         callbacks.on_test_begin()\n         logs = {}\n         self.reset_metrics()\n-        for step, data in epoch_iterator.enumerate_epoch():\n+        for step, data in epoch_iterator:\n             callbacks.on_test_batch_begin(step)\n             logs = self.test_function(data)\n             callbacks.on_test_batch_end(step, logs)\n@@ -428,7 +430,7 @@ class TorchTrainer(base_trainer.Trainer):\n         self.stop_predicting = False\n         callbacks.on_predict_begin()\n         outputs = None\n-        for step, data in epoch_iterator.enumerate_epoch():\n+        for step, data in epoch_iterator:\n             callbacks.on_predict_batch_begin(step)\n             batch_outputs = self.predict_function(data)\n             outputs = append_to_outputs(batch_outputs, outputs)\n\n@@ -39,6 +39,7 @@ or until there is no data\n \n \"\"\"\n \n+import contextlib\n import warnings\n \n from keras.src.trainers import data_adapters\n@@ -58,9 +59,9 @@ class EpochIterator:\n     ):\n         self.steps_per_epoch = steps_per_epoch\n         self.steps_per_execution = steps_per_execution\n-        if steps_per_epoch:\n         self._current_iterator = None\n-            self._insufficient_data = False\n+        self._epoch_iterator = None\n+        self._steps_seen = 0\n         self.data_adapter = data_adapters.get_data_adapter(\n             x=x,\n             y=y,\n@@ -75,49 +76,79 @@ class EpochIterator:\n     def _get_iterator(self):\n         return self.data_adapter.get_numpy_iterator()\n \n-    def enumerate_epoch(self):\n-        buffer = []\n-        self.data_adapter.on_epoch_begin()\n-        if self.steps_per_epoch:\n-            if self._current_iterator is None:\n-                self._current_iterator = iter(self._get_iterator())\n-                self._insufficient_data = False\n-\n-            for step in range(self.steps_per_epoch):\n-                if self._insufficient_data:\n-                    break\n-\n-                try:\n-                    data = next(self._current_iterator)\n-                    buffer.append(data)\n-                    if len(buffer) == self.steps_per_execution:\n-                        yield step - len(buffer) + 1, buffer\n-                        buffer = []\n-                except (StopIteration,):\n+    def _interrupted_warning(self):\n         warnings.warn(\n-                        \"Your input ran out of data; interrupting epoch. \"\n+            \"Your input ran out of data; interrupting training. \"\n             \"Make sure that your dataset or generator can generate \"\n             \"at least `steps_per_epoch * epochs` batches. \"\n             \"You may need to use the `.repeat()` \"\n             \"function when building your dataset.\",\n             stacklevel=2,\n         )\n+\n+    def reset(self):\n         self._current_iterator = None\n-                    self._insufficient_data = True\n-            if buffer:\n-                yield step - len(buffer) + 1, buffer\n+        self._num_batches = self.data_adapter.num_batches\n+        self._steps_seen = 0\n+        self._epoch_iterator = None\n+\n+    def _enumerate_iterator(self):\n+        self.data_adapter.on_epoch_begin()\n+        steps_per_epoch = self.steps_per_epoch or self._num_batches or -1\n+\n+        if steps_per_epoch > 0:\n+            if self._current_iterator is None or self.steps_per_epoch is None:\n+                self._current_iterator = iter(self._get_iterator())\n+                self._steps_seen = 0\n+            for step in range(0, steps_per_epoch, self.steps_per_execution):\n+                if self._num_batches and self._steps_seen >= self._num_batches:\n+                    if self.steps_per_epoch:\n+                        self._interrupted_warning()\n+                    break\n+                self._steps_seen += self.steps_per_execution\n+                yield step, self._current_iterator\n+            if self._num_batches and self._steps_seen >= self._num_batches:\n+                self._current_iterator = iter(self._get_iterator())\n+                self._steps_seen = 0\n         else:\n-            for step, data in enumerate(self._get_iterator()):\n-                buffer.append(data)\n-                if len(buffer) == self.steps_per_execution:\n-                    yield step - len(buffer) + 1, buffer\n+            iterator = iter(self._get_iterator())\n+            step = -self.steps_per_execution\n+            while True:\n+                step += self.steps_per_execution\n+                self._steps_seen = step + self.steps_per_execution\n+                yield step, iterator\n+        self.data_adapter.on_epoch_end()\n+\n+    def __iter__(self):\n+        self._epoch_iterator = self._enumerate_iterator()\n+        return self\n+\n+    def __next__(self):\n         buffer = []\n+        step, iterator = next(self._epoch_iterator)\n+        with self.catch_stop_iteration():\n+            for _ in range(self.steps_per_execution):\n+                data = next(iterator)\n+                buffer.append(data)\n+            return step, buffer\n         if buffer:\n-                yield step - len(buffer) + 1, buffer\n-            if not self._num_batches:\n-                # Infer the number of batches returned by the data_adapter.\n-                # Assumed static.\n-                self._num_batches = step + 1\n+            return step, buffer\n+        raise StopIteration\n+\n+    def enumerate_epoch(self):\n+        for step, data in self:\n+            yield step, data\n+\n+    @contextlib.contextmanager\n+    def catch_stop_iteration(self):\n+        \"\"\"Catches errors when an iterator runs out of data.\"\"\"\n+        try:\n+            yield\n+        except StopIteration:\n+            if self._num_batches is None:\n+                self._num_batches = self._steps_seen\n+            self._interrupted_warning()\n+            self._current_iterator = None\n             self.data_adapter.on_epoch_end()\n \n     @property\n\n@@ -10,7 +10,10 @@ from keras.src.trainers import epoch_iterator\n \n \n class TestEpochIterator(testing.TestCase):\n-    def test_basic_flow(self):\n+    @parameterized.named_parameters(\n+        [(\"iterator\", \"iterator\"), (\"enumerate_epoch\", \"enumerate_epoch\")]\n+    )\n+    def test_basic_flow(self, call_type):\n         x = np.random.random((100, 16))\n         y = np.random.random((100, 4))\n         sample_weight = np.random.random((100,))\n@@ -24,7 +27,11 @@ class TestEpochIterator(testing.TestCase):\n             shuffle=shuffle,\n         )\n         steps_seen = []\n-        for step, batch in iterator.enumerate_epoch():\n+        if call_type == \"iterator\":\n+            generator = iterator\n+        else:\n+            generator = iterator.enumerate_epoch()\n+        for step, batch in generator:\n             batch = batch[0]\n             steps_seen.append(step)\n             self.assertEqual(len(batch), 3)\n@@ -44,12 +51,12 @@ class TestEpochIterator(testing.TestCase):\n             steps_per_epoch=steps_per_epoch,\n         )\n         steps_seen = []\n-        for step, _ in iterator.enumerate_epoch():\n+        with pytest.warns(match=\"Your input ran out of data\"):\n+            for step, _ in iterator:\n                 steps_seen.append(step)\n         self.assertLen(steps_seen, steps_per_epoch - 2)\n \n         self.assertIsInstance(iterator, epoch_iterator.EpochIterator)\n-        self.assertTrue(iterator._insufficient_data)\n \n     def test_unsupported_y_arg_tfdata(self):\n         with self.assertRaisesRegex(ValueError, \"`y` should not be passed\"):\n@@ -89,7 +96,7 @@ class TestEpochIterator(testing.TestCase):\n             torch_dataset, batch_size=8, shuffle=True\n         )\n         iterator = epoch_iterator.EpochIterator(torch_dataloader)\n-        for _, batch in iterator.enumerate_epoch():\n+        for _, batch in iterator:\n             batch = batch[0]\n             self.assertEqual(batch[0].shape, (8, 2))\n             self.assertEqual(batch[1].shape, (8, 1))\n@@ -219,7 +226,7 @@ class TestEpochIterator(testing.TestCase):\n \n         num_epochs = 5\n         for epoch in range(num_epochs):\n-            for step, batch in epoch_iter.enumerate_epoch():\n+            for step, batch in epoch_iter:\n                 pass\n \n         self.assertAllEqual(ds.tracker, [1, 2] * num_epochs)\n\n@@ -1050,7 +1050,7 @@ class Trainer:\n                 )\n \n             if data_batch is None:\n-                for _, data in iterator.enumerate_epoch():\n+                for _, data in iterator:\n                     data_batch = data[0]\n                     break\n             data_batch = tree.map_structure(to_symbolic_input, data_batch)\n\n@@ -170,6 +170,67 @@ def sparse_generator(generator_type):\n         raise ValueError(f\"Invalid generator type {generator_type}\")\n \n \n+class EpochAgnosticMeanSquaredError(metrics.MeanSquaredError):\n+    def __init__(self):\n+        super().__init__(name=\"mse\")\n+        super().reset_state()\n+\n+    def reset_state(self):\n+        # prevent reset at each starting epoch\n+        pass\n+\n+\n+class StepObserver(Callback):\n+    def __init__(self):\n+        super().__init__()\n+        self.begin_count = 0\n+        self.end_count = 0\n+        self.epoch_begin_count = 0\n+        self.epoch_end_count = 0\n+        self.batch_loss_history = []\n+\n+    def on_epoch_begin(self, epoch, logs=None):\n+        self.epoch_begin_count += 1\n+\n+    def on_epoch_end(self, epoch, logs=None):\n+        self.epoch_end_count += 1\n+\n+    def on_batch_begin(self, batch, logs=None):\n+        self.begin_count += 1\n+\n+    def on_batch_end(self, batch, logs=None):\n+        self.end_count += 1\n+        self.batch_loss_history.append(logs[\"mse\"])\n+\n+\n+class StepCount(Callback):\n+    def __init__(self, batches_indices, batch_size):\n+        super().__init__()\n+        self.begin_count = 0\n+        self.end_count = 0\n+        self.epoch_begin_count = 0\n+        self.epoch_end_count = 0\n+        self.batches = batches_indices\n+        self.batch_size = batch_size\n+\n+    def on_epoch_begin(self, epoch, logs=None):\n+        self.begin_count = 0\n+        self.end_count = 0\n+        self.epoch_begin_count += 1\n+\n+    def on_epoch_end(self, epoch, logs=None):\n+        self.epoch_end_count += 1\n+\n+    def on_batch_begin(self, batch, logs=None):\n+        if self.begin_count < len(self.batches):\n+            assert batch == self.batches[self.begin_count] // self.batch_size\n+        self.begin_count += 1\n+\n+    def on_batch_end(self, batch, logs=None):\n+        assert batch == self.batches[self.end_count] // self.batch_size\n+        self.end_count += 1\n+\n+\n class TestTrainer(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_metric_tracking(self):\n@@ -294,7 +355,7 @@ class TestTrainer(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_fit_flow(self, run_eagerly, jit_compile, use_steps_per_epoch):\n         if not run_eagerly and not jit_compile and use_steps_per_epoch:\n-            if backend.backend() == \"tensorflow\":\n+            if False and backend.backend() == \"tensorflow\":\n                 self.skipTest(\n                     \"TODO: Graph mode without XLA in TF backend leads to \"\n                     \"unexpected logs, need further checks.\"\n@@ -653,40 +714,67 @@ class TestTrainer(testing.TestCase):\n             callbacks=[ModelWeightCheck()],\n         )\n \n+    @parameterized.named_parameters(\n+        named_product(\n+            steps_per_execution=[3, 101], mode=[\"eager\", \"non_jit\", \"jit\"]\n+        )\n+    )\n     @pytest.mark.requires_trainable_backend\n     @pytest.mark.skipif(\n         backend.backend() == \"torch\",\n         reason=\"`steps_per_execution` not implemented for torch yet\",\n     )\n-    def test_steps_per_execution_steps_count(self):\n-        class StepCount(Callback):\n-            def __init__(self):\n-                super().__init__()\n-                self.count = 0\n-                self.batches = [0, 3, 6]\n-\n-            def on_batch_begin(self, batch, logs=None):\n-                assert batch == self.batches[self.count]\n-                self.count += 1\n-\n-        x = np.ones((100, 4))\n-        y = np.ones((100, 1))\n+    def test_steps_per_execution_steps_count(self, steps_per_execution, mode):\n+        data_size = 100\n         batch_size = 16\n+        epochs = 2\n+\n+        batches_indices = list(\n+            range(0, data_size, steps_per_execution * batch_size)\n+        )\n+\n+        x = np.ones((data_size, 4))\n+        y = np.ones((data_size, 1))\n+\n         model = ExampleModel(units=1)\n         model.compile(\n             loss=\"mse\",\n-            optimizer=\"adam\",\n-            steps_per_execution=3,\n-            jit_compile=True,  # TODO: fails in eager?\n+            optimizer=\"sgd\",\n+            steps_per_execution=steps_per_execution,\n+            run_eagerly=(mode == \"eager\"),\n+            jit_compile=(mode == \"jit\"),\n+        )\n+        step_count = StepCount(batches_indices, batch_size)\n+\n+        history = model.fit(\n+            x=x,\n+            y=y,\n+            batch_size=batch_size,\n+            epochs=epochs,\n+            callbacks=[step_count],\n+            verbose=0,\n+        )\n+\n+        self.assertEqual(step_count.begin_count, len(batches_indices))\n+        self.assertEqual(step_count.end_count, step_count.begin_count)\n+        self.assertEqual(step_count.epoch_begin_count, epochs)\n+        self.assertEqual(\n+            step_count.epoch_end_count, step_count.epoch_begin_count\n         )\n-        step_count = StepCount()\n-        model.fit(x=x, y=y, batch_size=16, callbacks=[step_count], verbose=0)\n-        self.assertEqual(step_count.count, 3)\n \n         model_2 = ExampleModel(units=1)\n-        model_2.compile(loss=\"mse\", optimizer=\"adam\", steps_per_execution=1)\n-        model_2.fit(x=x, y=y, batch_size=batch_size, verbose=0)\n+        model_2.compile(\n+            loss=\"mse\",\n+            optimizer=\"sgd\",\n+            steps_per_execution=1,\n+            run_eagerly=(mode == \"eager\"),\n+            jit_compile=(mode == \"jit\"),\n+        )\n+        history_2 = model_2.fit(\n+            x=x, y=y, batch_size=batch_size, epochs=epochs, verbose=0\n+        )\n \n+        self.assertAllClose(history.history[\"loss\"], history_2.history[\"loss\"])\n         self.assertAllClose(model.get_weights(), model_2.get_weights())\n         self.assertAllClose(\n             model.predict(x, batch_size=batch_size),\n@@ -694,6 +782,451 @@ class TestTrainer(testing.TestCase):\n         )\n         self.assertAllClose(model.evaluate(x, y), model_2.evaluate(x, y))\n \n+    @parameterized.named_parameters(\n+        named_product(\n+            steps_per_execution=[3, 101], mode=[\"eager\", \"non_jit\", \"jit\"]\n+        )\n+    )\n+    @pytest.mark.requires_trainable_backend\n+    @pytest.mark.skipif(\n+        backend.backend() == \"torch\",\n+        reason=\"`steps_per_execution` not implemented for torch yet\",\n+    )\n+    def test_steps_per_execution_steps_count_unknown_dataset_size(\n+        self, steps_per_execution, mode\n+    ):\n+        data_size = 100\n+        batch_size = 16\n+        epochs = 2\n+\n+        batches_indices = list(\n+            range(0, data_size, steps_per_execution * batch_size)\n+        )\n+\n+        def data_generator():\n+            x = np.ones((data_size, 4), dtype=np.float32)\n+            y = np.ones((data_size, 1), dtype=np.float32)\n+            for _x, _y in zip(x, y):\n+                yield _x, _y\n+\n+        import tensorflow as tf\n+\n+        dataset = tf.data.Dataset.from_generator(\n+            data_generator,\n+            output_signature=(\n+                tf.TensorSpec(shape=(4,), dtype=tf.float32),\n+                tf.TensorSpec(shape=(1,), dtype=tf.float32),\n+            ),\n+        )\n+        dataset = dataset.batch(batch_size)\n+\n+        model = ExampleModel(units=1)\n+        model.compile(\n+            loss=\"mse\",\n+            optimizer=\"sgd\",\n+            steps_per_execution=steps_per_execution,\n+            run_eagerly=(mode == \"eager\"),\n+            jit_compile=(mode == \"jit\"),\n+        )\n+        step_count = StepCount(batches_indices, batch_size)\n+\n+        history = model.fit(\n+            dataset,\n+            epochs=epochs,\n+            callbacks=[step_count],\n+            verbose=0,\n+        )\n+\n+        self.assertGreaterEqual(step_count.begin_count, len(batches_indices))\n+        self.assertEqual(step_count.end_count, len(batches_indices))\n+        self.assertEqual(step_count.epoch_begin_count, epochs)\n+        self.assertEqual(\n+            step_count.epoch_end_count, step_count.epoch_begin_count\n+        )\n+\n+        model_2 = ExampleModel(units=1)\n+        model_2.compile(\n+            loss=\"mse\",\n+            optimizer=\"sgd\",\n+            steps_per_execution=1,\n+            run_eagerly=(mode == \"eager\"),\n+            jit_compile=(mode == \"jit\"),\n+        )\n+        history_2 = model_2.fit(dataset, epochs=epochs, verbose=0)\n+\n+        self.assertAllClose(history.history[\"loss\"], history_2.history[\"loss\"])\n+        self.assertAllClose(model.get_weights(), model_2.get_weights())\n+        self.assertAllClose(\n+            model.predict(dataset),\n+            model_2.predict(dataset),\n+        )\n+        self.assertAllClose(model.evaluate(dataset), model_2.evaluate(dataset))\n+\n+    @parameterized.named_parameters(\n+        named_product(\n+            steps_per_epoch_test=[\n+                \"match_one_epoch\",\n+                \"match_multi_epoch\",\n+                \"not_match_too_low\",\n+                \"not_match_but_high_enough\",\n+            ],\n+            mode=[\"eager\", \"non_jit\", \"jit\"],\n+        )\n+    )\n+    @pytest.mark.requires_trainable_backend\n+    @pytest.mark.skipif(\n+        backend.backend() == \"torch\",\n+        reason=\"`steps_per_execution` not implemented for torch yet\",\n+    )\n+    def test_steps_per_execution_steps_per_epoch(\n+        self, steps_per_epoch_test, mode\n+    ):\n+        batch_size = 8\n+        epochs = 2\n+        steps_per_execution = 2\n+        num_batches = 5 * steps_per_execution\n+        data_size = num_batches * batch_size\n+\n+        if steps_per_epoch_test == \"match_one_epoch\":\n+            steps_per_epoch = num_batches\n+        elif steps_per_epoch_test == \"match_multi_epoch\":\n+            steps_per_epoch = num_batches // steps_per_execution\n+        elif steps_per_epoch_test == \"not_match_too_low\":\n+            steps_per_epoch = num_batches - steps_per_execution\n+        elif steps_per_epoch_test == \"not_match_but_high_enough\":\n+            steps_per_epoch = num_batches + steps_per_execution\n+\n+        x = np.ones((data_size, 4))\n+        y = np.ones((data_size, 1))\n+\n+        model = ExampleModel(units=1)\n+        model.compile(\n+            loss=\"mse\",\n+            optimizer=\"sgd\",\n+            metrics=[EpochAgnosticMeanSquaredError()],\n+            steps_per_execution=steps_per_execution,\n+            run_eagerly=(mode == \"eager\"),\n+            jit_compile=(mode == \"jit\"),\n+        )\n+        step_observer = StepObserver()\n+\n+        model.fit(\n+            x=x,\n+            y=y,\n+            batch_size=batch_size,\n+            epochs=epochs,\n+            steps_per_epoch=steps_per_epoch,\n+            callbacks=[step_observer],\n+            verbose=0,\n+        )\n+        if steps_per_epoch_test != \"not_match_too_low\":\n+            training_batch_count = (\n+                epochs\n+                * min(steps_per_epoch, num_batches)\n+                // steps_per_execution\n+            )\n+        else:\n+            complete_epochs = (num_batches // steps_per_execution) // (\n+                steps_per_epoch // steps_per_execution\n+            )\n+            remaining_steps = (num_batches // steps_per_execution) % (\n+                steps_per_epoch // steps_per_execution\n+            )\n+            steps_cycles = [\n+                complete_epochs * steps_per_epoch // steps_per_execution,\n+                remaining_steps,\n+            ] * epochs\n+            steps_per_epochs = steps_cycles[:epochs]\n+            training_batch_count = sum(steps_per_epochs)\n+\n+        self.assertEqual(step_observer.begin_count, training_batch_count)\n+        self.assertEqual(step_observer.end_count, step_observer.begin_count)\n+        self.assertEqual(step_observer.epoch_begin_count, epochs)\n+        self.assertEqual(\n+            step_observer.epoch_end_count, step_observer.epoch_begin_count\n+        )\n+\n+        if steps_per_epoch_test != \"not_match_too_low\":\n+            model_2 = ExampleModel(units=1)\n+            model_2.compile(\n+                loss=\"mse\",\n+                optimizer=\"sgd\",\n+                metrics=[EpochAgnosticMeanSquaredError()],\n+                steps_per_execution=1,\n+                run_eagerly=(mode == \"eager\"),\n+                jit_compile=(mode == \"jit\"),\n+            )\n+            step_observer_2 = StepObserver()\n+\n+            if steps_per_epoch_test in (\n+                \"not_match_but_high_enough\",\n+                \"match_one_epoch\",\n+            ):\n+                model_2_epochs = epochs\n+            else:\n+                model_2_epochs = 1\n+\n+            model_2.fit(\n+                x=x,\n+                y=y,\n+                batch_size=batch_size,\n+                epochs=model_2_epochs,\n+                callbacks=[step_observer_2],\n+                verbose=0,\n+            )\n+\n+            losses = step_observer.batch_loss_history\n+            losses_2 = step_observer_2.batch_loss_history[\n+                steps_per_execution - 1 :: steps_per_execution\n+            ]\n+            self.assertAllClose(losses, losses_2)\n+            self.assertAllClose(model.get_weights(), model_2.get_weights())\n+            self.assertAllClose(\n+                model.predict(x, batch_size=batch_size),\n+                model_2.predict(x, batch_size=batch_size),\n+            )\n+            self.assertAllClose(model.evaluate(x, y), model_2.evaluate(x, y))\n+\n+    @parameterized.named_parameters(\n+        named_product(\n+            steps_per_epoch_test=[\n+                \"match_one_epoch\",\n+                \"match_multi_epoch\",\n+                \"not_match_too_low\",\n+                \"not_match_but_high_enough\",\n+            ],\n+            mode=[\"eager\", \"non_jit\", \"jit\"],\n+        )\n+    )\n+    @pytest.mark.requires_trainable_backend\n+    def test_steps_per_epoch(self, steps_per_epoch_test, mode):\n+        batch_size = 8\n+        epochs = 4\n+        num_batches = 10\n+        data_size = num_batches * batch_size\n+\n+        if steps_per_epoch_test == \"match_one_epoch\":\n+            steps_per_epoch = num_batches\n+        elif steps_per_epoch_test == \"match_multi_epoch\":\n+            steps_per_epoch = num_batches // (epochs // 2)\n+        elif steps_per_epoch_test == \"not_match_too_low\":\n+            steps_per_epoch = num_batches - 1\n+        elif steps_per_epoch_test == \"not_match_but_high_enough\":\n+            steps_per_epoch = num_batches + 1\n+\n+        x = np.ones((data_size, 4))\n+        y = np.ones((data_size, 1))\n+\n+        model = ExampleModel(units=1)\n+        model.compile(\n+            loss=\"mse\",\n+            optimizer=\"sgd\",\n+            metrics=[EpochAgnosticMeanSquaredError()],\n+            run_eagerly=(mode == \"eager\"),\n+            jit_compile=(mode == \"jit\"),\n+        )\n+        step_observer = StepObserver()\n+\n+        model.fit(\n+            x=x,\n+            y=y,\n+            batch_size=batch_size,\n+            epochs=epochs,\n+            steps_per_epoch=steps_per_epoch,\n+            callbacks=[step_observer],\n+            verbose=0,\n+        )\n+        if steps_per_epoch_test != \"not_match_too_low\":\n+            training_batch_count = epochs * min(steps_per_epoch, num_batches)\n+        else:\n+            complete_epochs = num_batches // steps_per_epoch\n+            remaining_steps = num_batches % steps_per_epoch\n+            steps_cycles = [\n+                complete_epochs * steps_per_epoch,\n+                remaining_steps,\n+            ] * epochs\n+            steps_per_epochs = steps_cycles[:epochs]\n+            training_batch_count = sum(steps_per_epochs)\n+\n+        self.assertEqual(step_observer.begin_count, training_batch_count)\n+        self.assertEqual(step_observer.end_count, step_observer.begin_count)\n+        self.assertEqual(step_observer.epoch_begin_count, epochs)\n+        self.assertEqual(\n+            step_observer.epoch_end_count, step_observer.epoch_begin_count\n+        )\n+\n+        if steps_per_epoch_test != \"not_match_too_low\":\n+            model_2 = ExampleModel(units=1)\n+            model_2.compile(\n+                loss=\"mse\",\n+                optimizer=\"sgd\",\n+                metrics=[EpochAgnosticMeanSquaredError()],\n+                steps_per_execution=1,\n+                run_eagerly=(mode == \"eager\"),\n+                jit_compile=(mode == \"jit\"),\n+            )\n+            step_observer_2 = StepObserver()\n+\n+            if steps_per_epoch_test in (\n+                \"not_match_but_high_enough\",\n+                \"match_one_epoch\",\n+            ):\n+                model_2_epochs = epochs\n+            elif steps_per_epoch_test == \"match_multi_epoch\":\n+                model_2_epochs = epochs // (num_batches // steps_per_epoch)\n+            else:\n+                model_2_epochs = 1\n+\n+            model_2.fit(\n+                x=x,\n+                y=y,\n+                batch_size=batch_size,\n+                epochs=model_2_epochs,\n+                callbacks=[step_observer_2],\n+                verbose=0,\n+            )\n+\n+            losses = step_observer.batch_loss_history\n+            losses_2 = step_observer_2.batch_loss_history\n+\n+            self.assertAllClose(losses, losses_2)\n+            self.assertAllClose(model.get_weights(), model_2.get_weights())\n+            self.assertAllClose(\n+                model.predict(x, batch_size=batch_size),\n+                model_2.predict(x, batch_size=batch_size),\n+            )\n+            self.assertAllClose(model.evaluate(x, y), model_2.evaluate(x, y))\n+\n+    @parameterized.named_parameters(\n+        named_product(\n+            steps_per_epoch_test=[\n+                \"match\",\n+                \"not_match_too_low\",\n+                \"not_match_but_high_enough\",\n+            ],\n+            mode=[\"eager\", \"non_jit\", \"jit\"],\n+        )\n+    )\n+    @pytest.mark.requires_trainable_backend\n+    @pytest.mark.skipif(\n+        backend.backend() == \"torch\",\n+        reason=\"`steps_per_execution` not implemented for torch yet\",\n+    )\n+    def test_steps_per_execution_steps_per_epoch_unknown_data_size(\n+        self, steps_per_epoch_test, mode\n+    ):\n+        batch_size = 8\n+        epochs = 2\n+        steps_per_execution = 2\n+        num_batches = 5 * epochs * steps_per_execution\n+        data_size = num_batches * batch_size\n+\n+        if steps_per_epoch_test == \"match\":\n+            steps_per_epoch = num_batches // epochs\n+        elif steps_per_epoch_test == \"not_match_too_low\":\n+            steps_per_epoch = num_batches - steps_per_execution\n+        elif steps_per_epoch_test == \"not_match_but_high_enough\":\n+            steps_per_epoch = num_batches + steps_per_execution\n+\n+        def data_generator():\n+            x = np.ones((data_size, 4), dtype=np.float32)\n+            y = np.ones((data_size, 1), dtype=np.float32)\n+            for _x, _y in zip(x, y):\n+                yield _x, _y\n+\n+        import tensorflow as tf\n+\n+        dataset = tf.data.Dataset.from_generator(\n+            data_generator,\n+            output_signature=(\n+                tf.TensorSpec(shape=(4,), dtype=tf.float32),\n+                tf.TensorSpec(shape=(1,), dtype=tf.float32),\n+            ),\n+        )\n+        dataset = dataset.batch(batch_size)\n+\n+        model = ExampleModel(units=1)\n+        model.compile(\n+            loss=\"mse\",\n+            optimizer=\"sgd\",\n+            metrics=[EpochAgnosticMeanSquaredError()],\n+            steps_per_execution=steps_per_execution,\n+            run_eagerly=(mode == \"eager\"),\n+            jit_compile=(mode == \"jit\"),\n+        )\n+        step_observer = StepObserver()\n+\n+        model.fit(\n+            dataset,\n+            epochs=epochs,\n+            steps_per_epoch=steps_per_epoch,\n+            callbacks=[step_observer],\n+            verbose=0,\n+        )\n+        if steps_per_epoch_test != \"not_match_too_low\":\n+            training_batch_count = (\n+                epochs\n+                * min(steps_per_epoch, num_batches)\n+                // steps_per_execution\n+            )\n+        else:\n+            complete_epochs = (num_batches // steps_per_execution) // (\n+                steps_per_epoch // steps_per_execution\n+            )\n+            remaining_steps = (num_batches // steps_per_execution) % (\n+                steps_per_epoch // steps_per_execution\n+            )\n+            steps_cycles = [\n+                complete_epochs * steps_per_epoch // steps_per_execution,\n+                remaining_steps,\n+            ] * epochs\n+            steps_per_epochs = steps_cycles[:epochs]\n+            training_batch_count = sum(steps_per_epochs)\n+\n+        self.assertGreaterEqual(step_observer.begin_count, training_batch_count)\n+        self.assertEqual(step_observer.end_count, training_batch_count)\n+        self.assertEqual(step_observer.epoch_begin_count, epochs)\n+        self.assertEqual(\n+            step_observer.epoch_end_count, step_observer.epoch_begin_count\n+        )\n+\n+        if steps_per_epoch_test != \"not_match_too_low\":\n+            model_2 = ExampleModel(units=1)\n+            model_2.compile(\n+                loss=\"mse\",\n+                optimizer=\"sgd\",\n+                metrics=[EpochAgnosticMeanSquaredError()],\n+                steps_per_execution=1,\n+                run_eagerly=(mode == \"eager\"),\n+                jit_compile=(mode == \"jit\"),\n+            )\n+            step_observer_2 = StepObserver()\n+\n+            if steps_per_epoch_test == \"not_match_but_high_enough\":\n+                model_2_epochs = epochs\n+            else:\n+                model_2_epochs = 1\n+\n+            model_2.fit(\n+                dataset,\n+                epochs=model_2_epochs,\n+                callbacks=[step_observer_2],\n+                verbose=0,\n+            )\n+\n+            losses = step_observer.batch_loss_history\n+            losses_2 = step_observer_2.batch_loss_history[\n+                steps_per_execution - 1 :: steps_per_execution\n+            ]\n+            self.assertAllClose(losses, losses_2)\n+            self.assertAllClose(model.get_weights(), model_2.get_weights())\n+            self.assertAllClose(\n+                model.predict(dataset), model_2.predict(dataset)\n+            )\n+            self.assertAllClose(\n+                model.evaluate(dataset), model_2.evaluate(dataset)\n+            )\n+\n     @pytest.mark.skipif(\n         backend.backend() == \"torch\",\n         reason=\"`steps_per_execution` not implemented for torch yet\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
