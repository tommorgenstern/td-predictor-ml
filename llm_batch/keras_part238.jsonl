{"custom_id": "keras#32ff1d679d62bde2d84a6c7a7ac90b37419c5e03", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1414 | Contributors (this commit): 22 | Commits (past 90d): 5 | Contributors (cumulative): 22 | DMM Complexity: None\n\nDIFF:\n@@ -203,7 +203,6 @@ PAGES = [\n             layers.SimpleRNNCell,\n             layers.GRUCell,\n             layers.LSTMCell,\n-            layers.StackedRNNCells,\n             layers.CuDNNGRU,\n             layers.CuDNNLSTM,\n         ],\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d035967a5d2795734c89a0a3c002f7eb5c34eff1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 9365 | Contributors (this commit): 54 | Commits (past 90d): 21 | Contributors (cumulative): 54 | DMM Complexity: 0.0\n\nDIFF:\n@@ -479,6 +479,7 @@ class RNN(Layer):\n                                for dim in state_size]\n         if self.stateful:\n             self.reset_states()\n+        self.built = True\n \n     def get_initial_state(self, inputs):\n         # build an all-zero tensor of shape (samples, output_dim)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e3e15c699139a11c6124e13bacc5da4fb51d9a96", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 215 | Contributors (this commit): 6 | Commits (past 90d): 1 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -48,13 +48,13 @@ def add_ngram(sequences, token_indice, ngram_range=2):\n     >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n     >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017, (7, 9, 2): 2018}\n     >>> add_ngram(sequences, token_indice, ngram_range=3)\n-    [[1, 3, 4, 5, 1337], [1, 3, 7, 9, 2, 1337, 2018]]\n+    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42, 2018]]\n     \"\"\"\n     new_sequences = []\n     for input_list in sequences:\n         new_list = input_list[:]\n-        for i in range(len(new_list) - ngram_range + 1):\n         for ngram_value in range(2, ngram_range + 1):\n+            for i in range(len(new_list) - ngram_value + 1):\n                 ngram = tuple(new_list[i:i + ngram_value])\n                 if ngram in token_indice:\n                     new_list.append(token_indice[ngram])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#068a680480ebf27ecbe57f1406d60157b7d2df38", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 16 | Churn Cumulative: 3440 | Contributors (this commit): 53 | Commits (past 90d): 25 | Contributors (cumulative): 63 | DMM Complexity: 1.0\n\nDIFF:\n@@ -581,7 +581,7 @@ class ImageDataGenerator(object):\n             The inputs, normalized.\n         \"\"\"\n         if self.preprocessing_function:\n-            x = self.image_data_generator.preprocessing_function(x)\n+            x = self.preprocessing_function(x)\n         if self.rescale:\n             x *= self.rescale\n         if self.samplewise_center:\n\n@@ -220,8 +220,18 @@ class TestImage(object):\n         with pytest.raises(ValueError):\n             generator.flow_from_directory(str(tmpdir), class_mode='output')\n \n+        def preprocessing_function(x):\n+            \"\"\"This will fail if not provided by a Numpy array.\n+            Note: This is made to enforce backward compatibility.\n+            \"\"\"\n+\n+            assert x.shape == (26, 26, 3)\n+            assert type(x) is np.ndarray\n+\n+            return np.zeros_like(x)\n+\n         # Test usage as Sequence\n-        generator = image.ImageDataGenerator()\n+        generator = image.ImageDataGenerator(preprocessing_function=preprocessing_function)\n         dir_seq = generator.flow_from_directory(str(tmpdir),\n                                                 target_size=(26, 26),\n                                                 color_mode='rgb',\n@@ -232,6 +242,8 @@ class TestImage(object):\n         assert x1.shape == (3, 26, 26, 3)\n         assert y1.shape == (3, num_classes)\n         x1, y1 = dir_seq[5]\n+        assert (x1 == 0).all()\n+\n         with pytest.raises(ValueError):\n             x1, y1 = dir_seq[9]\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bc54e152666bbd7ed741ec812ea2fc24c894ed11", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 11 | Churn Cumulative: 1152 | Contributors (this commit): 9 | Commits (past 90d): 5 | Contributors (cumulative): 9 | DMM Complexity: 0.2857142857142857\n\nDIFF:\n@@ -219,6 +219,11 @@ def MobileNet(input_shape=None,\n                              '`0.25`, `0.50`, `0.75` or `1.0` only.')\n \n         if rows != cols or rows not in [128, 160, 192, 224]:\n+            if rows is None:\n+                rows = 224\n+                warnings.warn('MobileNet shape is undefined.'\n+                              ' Weights for input shape (224, 224) will be loaded.')\n+            else:\n                 raise ValueError('If imagenet weights are being loaded, '\n                                  'input must have a static square shape (one of '\n                                  '(128, 128), (160, 160), (192, 192), or (224, 224)).'\n@@ -451,7 +456,8 @@ def _depthwise_conv_block(inputs, pointwise_conv_filters, alpha,\n                         strides=strides,\n                         use_bias=False,\n                         name='conv_dw_%d' % block_id)(x)\n-    x = BatchNormalization(axis=channel_axis, name='conv_dw_%d_bn' % block_id)(x)\n+    x = BatchNormalization(\n+        axis=channel_axis, name='conv_dw_%d_bn' % block_id)(x)\n     x = Activation(relu6, name='conv_dw_%d_relu' % block_id)(x)\n \n     x = Conv2D(pointwise_conv_filters, (1, 1),\n@@ -459,5 +465,6 @@ def _depthwise_conv_block(inputs, pointwise_conv_filters, alpha,\n                use_bias=False,\n                strides=(1, 1),\n                name='conv_pw_%d' % block_id)(x)\n-    x = BatchNormalization(axis=channel_axis, name='conv_pw_%d_bn' % block_id)(x)\n+    x = BatchNormalization(\n+        axis=channel_axis, name='conv_pw_%d_bn' % block_id)(x)\n     return Activation(relu6, name='conv_pw_%d_relu' % block_id)(x)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fa0e9237e049ba8e405810dce486cc59f4fd309f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 8848 | Contributors (this commit): 59 | Commits (past 90d): 18 | Contributors (cumulative): 59 | DMM Complexity: None\n\nDIFF:\n@@ -3370,7 +3370,7 @@ def load_weights_from_hdf5_group(f, layers, reshape=False):\n     for k, name in enumerate(layer_names):\n         g = f[name]\n         weight_names = _load_attributes_from_hdf5_group(g, 'weight_names')\n-        weight_values = [g[weight_name] for weight_name in weight_names]\n+        weight_values = [np.asarray(g[weight_name]) for weight_name in weight_names]\n         layer = filtered_layers[k]\n         symbolic_weights = layer.weights\n         weight_values = preprocess_weights_for_loading(layer,\n@@ -3438,7 +3438,7 @@ def load_weights_from_hdf5_group_by_name(f, layers, skip_mismatch=False,\n     for k, name in enumerate(layer_names):\n         g = f[name]\n         weight_names = _load_attributes_from_hdf5_group(g, 'weight_names')\n-        weight_values = [g[weight_name] for weight_name in weight_names]\n+        weight_values = [np.asarray(g[weight_name]) for weight_name in weight_names]\n \n         for layer in index.get(name, []):\n             symbolic_weights = layer.weights\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5216360a3c70b0f4d685966ef449645fa131ade8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 244 | Lines Deleted: 45 | Files Changed: 4 | Hunks: 20 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 289 | Churn Cumulative: 4829 | Contributors (this commit): 70 | Commits (past 90d): 28 | Contributors (cumulative): 77 | DMM Complexity: None\n\nDIFF:\n@@ -259,6 +259,20 @@ PAGES = [\n             preprocessing.sequence.TimeseriesGenerator,\n         ]\n     },\n+    {\n+        'page': 'preprocessing/image.md',\n+        'functions': [\n+            preprocessing.image.random_rotation,\n+            preprocessing.image.random_shift,\n+            preprocessing.image.random_shear,\n+            preprocessing.image.random_zoom,\n+            preprocessing.image.random_channel_shift,\n+            preprocessing.image.random_brightness,\n+        ],\n+        'classes': [\n+            preprocessing.image.ImageDataGenerator,\n+        ]\n+    },\n     {\n         'page': 'layers/wrappers.md',\n         'all_module_classes': [wrappers],\n\n@@ -0,0 +1,3 @@\n+from . import image\n+from . import sequence\n+from . import text\n\n@@ -176,6 +176,17 @@ def random_zoom(x, zoom_range, row_axis=1, col_axis=2, channel_axis=0,\n \n \n def random_channel_shift(x, intensity, channel_axis=0):\n+    \"\"\"Perform a random channel shift.\n+\n+    # Arguments\n+        x: Input tensor. Must be 3D.\n+        intensity: Transformation intensity.\n+        channel_axis: Index of axis for channels in the input tensor.\n+\n+    # Returns\n+        Numpy image tensor.\n+\n+    \"\"\"\n     x = np.rollaxis(x, channel_axis, 0)\n     min_x, max_x = np.min(x), np.max(x)\n     channel_images = [np.clip(x_channel + np.random.uniform(-intensity, intensity), min_x, max_x)\n@@ -186,6 +197,20 @@ def random_channel_shift(x, intensity, channel_axis=0):\n \n \n def random_brightness(x, brightness_range):\n+    \"\"\"Perform a random brightness shift.\n+\n+    # Arguments\n+        x: Input tensor. Must be 3D.\n+        brightness_range: Tuple of floats; brightness range.\n+        channel_axis: Index of axis for channels in the input tensor.\n+\n+    # Returns\n+        Numpy image tensor.\n+\n+    # Raises\n+        ValueError if `brightness_range` isn't a tuple.\n+\n+    \"\"\"\n     if len(brightness_range) != 2:\n         raise ValueError('`brightness_range should be tuple or list of two floats. '\n                          'Received arg: ', brightness_range)\n@@ -387,51 +412,150 @@ def list_pictures(directory, ext='jpg|jpeg|bmp|png|ppm'):\n \n \n class ImageDataGenerator(object):\n-    \"\"\"Generate minibatches of image data with real-time data augmentation.\n+    \"\"\"Generate batches of tensor image data with real-time data augmentation.\n+     The data will be looped over (in batches).\n \n     # Arguments\n-        featurewise_center: set input mean to 0 over the dataset.\n-        samplewise_center: set each sample mean to 0.\n-        featurewise_std_normalization: divide inputs by std of the dataset.\n-        samplewise_std_normalization: divide each input by its std.\n-        zca_whitening: apply ZCA whitening.\n+        featurewise_center: Boolean. Set input mean to 0 over the dataset, feature-wise.\n+        samplewise_center: Boolean. Set each sample mean to 0.\n+        featurewise_std_normalization: Boolean. Divide inputs by std of the dataset, feature-wise.\n+        samplewise_std_normalization: Boolean. Divide each input by its std.\n         zca_epsilon: epsilon for ZCA whitening. Default is 1e-6.\n-        rotation_range: degrees (0 to 180).\n-        width_shift_range: fraction of total width, if < 1, or pixels if >= 1.\n-        height_shift_range: fraction of total height, if < 1, or pixels if >= 1.\n-        brightness_range: the range of brightness to apply\n-        shear_range: shear intensity (shear angle in degrees).\n-        zoom_range: amount of zoom. if scalar z, zoom will be randomly picked\n-            in the range [1-z, 1+z]. A sequence of two can be passed instead\n-            to select this range.\n-        channel_shift_range: shift range for each channel.\n-        fill_mode: points outside the boundaries are filled according to the\n-            given mode ('constant', 'nearest', 'reflect' or 'wrap'). Default\n-            is 'nearest'.\n+        zca_whitening: Boolean. Apply ZCA whitening.\n+        rotation_range: Int. Degree range for random rotations.\n+        width_shift_range: Float (fraction of total width). Range for random horizontal shifts.\n+        height_shift_range: Float (fraction of total height). Range for random vertical shifts.\n+        shear_range: Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n+        zoom_range: Float or [lower, upper]. Range for random zoom. If a float, `[lower, upper] = [1-zoom_range, 1+zoom_range]`.\n+        channel_shift_range: Float. Range for random channel shifts.\n+        fill_mode: One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}.  Default is 'nearest'.\n         Points outside the boundaries of the input are filled according to the given mode:\n             'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k)\n             'nearest':  aaaaaaaa|abcd|dddddddd\n             'reflect':  abcddcba|abcd|dcbaabcd\n             'wrap':  abcdabcd|abcd|abcdabcd\n-        cval: value used for points outside the boundaries when fill_mode is\n-            'constant'. Default is 0.\n-        horizontal_flip: whether to randomly flip images horizontally.\n-        vertical_flip: whether to randomly flip images vertically.\n-        rescale: rescaling factor. If None or 0, no rescaling is applied,\n-            otherwise we multiply the data by the value provided. This is\n-            applied after the `preprocessing_function` (if any provided)\n-            but before any other transformation.\n+        cval: Float or Int. Value used for points outside the boundaries when `fill_mode = \"constant\"`.\n+        horizontal_flip: Boolean. Randomly flip inputs horizontally.\n+        vertical_flip: Boolean. Randomly flip inputs vertically.\n+        rescale: rescaling factor. Defaults to None. If None or 0, no rescaling is applied,\n+                otherwise we multiply the data by the value provided (before applying\n+                any other transformation).\n         preprocessing_function: function that will be implied on each input.\n-            The function will run before any other modification on it.\n+                The function will run after the image is resized and augmented.\n                 The function should take one argument:\n                 one image (Numpy tensor with rank 3),\n                 and should output a Numpy tensor with the same shape.\n-        data_format: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension\n-            (the depth) is at index 1, in 'channels_last' mode it is at index 3.\n+        data_format: One of {\"channels_first\", \"channels_last\"}.\n+            \"channels_last\" mode means that the images should have shape `(samples, height, width, channels)`,\n+            \"channels_first\" mode means that the images should have shape `(samples, channels, height, width)`.\n             It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n             If you never set it, then it will be \"channels_last\".\n-        validation_split: fraction of images reserved for validation (strictly between 0 and 1).\n+        validation_split: Float. Fraction of images reserved for validation (strictly between 0 and 1).\n+\n+    # Examples\n+    Example of using `.flow(x, y)`:\n+\n+    ```python\n+    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n+    y_train = np_utils.to_categorical(y_train, num_classes)\n+    y_test = np_utils.to_categorical(y_test, num_classes)\n+\n+    datagen = ImageDataGenerator(\n+        featurewise_center=True,\n+        featurewise_std_normalization=True,\n+        rotation_range=20,\n+        width_shift_range=0.2,\n+        height_shift_range=0.2,\n+        horizontal_flip=True)\n+\n+    # compute quantities required for featurewise normalization\n+    # (std, mean, and principal components if ZCA whitening is applied)\n+    datagen.fit(x_train)\n+\n+    # fits the model on batches with real-time data augmentation:\n+    model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n+                        steps_per_epoch=len(x_train) / 32, epochs=epochs)\n+\n+    # here's a more \"manual\" example\n+    for e in range(epochs):\n+        print('Epoch', e)\n+        batches = 0\n+        for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\n+            model.fit(x_batch, y_batch)\n+            batches += 1\n+            if batches >= len(x_train) / 32:\n+                # we need to break the loop by hand because\n+                # the generator loops indefinitely\n+                break\n+    ```\n+    Example of using `.flow_from_directory(directory)`:\n+\n+    ```python\n+    train_datagen = ImageDataGenerator(\n+            rescale=1./255,\n+            shear_range=0.2,\n+            zoom_range=0.2,\n+            horizontal_flip=True)\n+\n+    test_datagen = ImageDataGenerator(rescale=1./255)\n+\n+    train_generator = train_datagen.flow_from_directory(\n+            'data/train',\n+            target_size=(150, 150),\n+            batch_size=32,\n+            class_mode='binary')\n+\n+    validation_generator = test_datagen.flow_from_directory(\n+            'data/validation',\n+            target_size=(150, 150),\n+            batch_size=32,\n+            class_mode='binary')\n+\n+    model.fit_generator(\n+            train_generator,\n+            steps_per_epoch=2000,\n+            epochs=50,\n+            validation_data=validation_generator,\n+            validation_steps=800)\n+    ```\n+\n+    Example of transforming images and masks together.\n+\n+    ```python\n+    # we create two instances with the same arguments\n+    data_gen_args = dict(featurewise_center=True,\n+                         featurewise_std_normalization=True,\n+                         rotation_range=90.,\n+                         width_shift_range=0.1,\n+                         height_shift_range=0.1,\n+                         zoom_range=0.2)\n+    image_datagen = ImageDataGenerator(**data_gen_args)\n+    mask_datagen = ImageDataGenerator(**data_gen_args)\n+\n+    # Provide the same seed and keyword arguments to the fit and flow methods\n+    seed = 1\n+    image_datagen.fit(images, augment=True, seed=seed)\n+    mask_datagen.fit(masks, augment=True, seed=seed)\n+\n+    image_generator = image_datagen.flow_from_directory(\n+        'data/images',\n+        class_mode=None,\n+        seed=seed)\n+\n+    mask_generator = mask_datagen.flow_from_directory(\n+        'data/masks',\n+        class_mode=None,\n+        seed=seed)\n+\n+    # combine generators into one which yields image and masks\n+    train_generator = zip(image_generator, mask_generator)\n+\n+    model.fit_generator(\n+        train_generator,\n+        steps_per_epoch=2000,\n+        epochs=50)\n+    ```\n     \"\"\"\n \n     def __init__(self,\n@@ -537,6 +661,29 @@ class ImageDataGenerator(object):\n \n     def flow(self, x, y=None, batch_size=32, shuffle=True, seed=None,\n              save_to_dir=None, save_prefix='', save_format='png', subset=None):\n+        \"\"\"Takes numpy data & label arrays, and generates batches of\n+            augmented/normalized data.\n+\n+        # Arguments\n+               x: data. Should have rank 4.\n+                In case of grayscale data,\n+                the channels axis should have value 1, and in case\n+                of RGB data, it should have value 3.\n+               y: labels.\n+               batch_size: int (default: 32).\n+               shuffle: boolean (default: True).\n+               seed: int (default: None).\n+               save_to_dir: None or str (default: None).\n+                This allows you to optionally specify a directory\n+                to which to save the augmented pictures being generated\n+                (useful for visualizing what you are doing).\n+               save_prefix: str (default: `''`). Prefix to use for filenames of saved pictures\n+                (only relevant if `save_to_dir` is set).\n+                save_format: one of \"png\", \"jpeg\" (only relevant if `save_to_dir` is set). Default: \"png\".\n+\n+        # Returns\n+            An Iterator yielding tuples of `(x, y)` where `x` is a numpy array of image data and\n+             `y` is a numpy array of corresponding labels.\"\"\"\n         return NumpyArrayIterator(\n             x, y, self,\n             batch_size=batch_size,\n@@ -558,6 +705,45 @@ class ImageDataGenerator(object):\n                             follow_links=False,\n                             subset=None,\n                             interpolation='nearest'):\n+        \"\"\"Takes the path to a directory, and generates batches of augmented/normalized data.\n+\n+        # Arguments\n+                directory: path to the target directory.\n+                 It should contain one subdirectory per class.\n+                 Any PNG, JPG, BMP, PPM or TIF images inside each of the subdirectories directory tree will be included in the generator.\n+                See [this script](https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d) for more details.\n+                target_size: tuple of integers `(height, width)`, default: `(256, 256)`.\n+                 The dimensions to which all images found will be resized.\n+                color_mode: one of \"grayscale\", \"rbg\". Default: \"rgb\".\n+                 Whether the images will be converted to have 1 or 3 color channels.\n+                classes: optional list of class subdirectories (e.g. `['dogs', 'cats']`).\n+                 Default: None. If not provided, the list of classes will\n+                 be automatically inferred from the subdirectory names/structure under `directory`,\n+                 where each subdirectory will be treated as a different class\n+                 (and the order of the classes, which will map to the label indices, will be alphanumeric).\n+                 The dictionary containing the mapping from class names to class\n+                 indices can be obtained via the attribute `class_indices`.\n+                class_mode: one of \"categorical\", \"binary\", \"sparse\", \"input\" or None.\n+                 Default: \"categorical\". Determines the type of label arrays that are\n+                 returned: \"categorical\" will be 2D one-hot encoded labels, \"binary\" will be 1D binary labels,\n+                 \"sparse\" will be 1D integer labels, \"input\" will be images identical to input images (mainly used to work with autoencoders).\n+                 If None, no labels are returned (the generator will only yield batches of image data, which is useful to use\n+                 `model.predict_generator()`, `model.evaluate_generator()`, etc.).\n+                  Please note that in case of class_mode None,\n+                   the data still needs to reside in a subdirectory of `directory` for it to work correctly.\n+                batch_size: size of the batches of data (default: 32).\n+                shuffle: whether to shuffle the data (default: True)\n+                seed: optional random seed for shuffling and transformations.\n+                save_to_dir: None or str (default: None). This allows you to optionally specify a directory to which to save\n+                 the augmented pictures being generated (useful for visualizing what you are doing).\n+                save_prefix: str. Prefix to use for filenames of saved pictures (only relevant if `save_to_dir` is set).\n+                save_format: one of \"png\", \"jpeg\" (only relevant if `save_to_dir` is set). Default: \"png\".\n+                follow_links: whether to follow symlinks inside class subdirectories (default: False).\n+\n+        # Returns\n+            A DirectoryIterator yielding tuples of `(x, y)` where `x` is a numpy array of image data and\n+             `y` is a numpy array of corresponding labels.\n+        \"\"\"\n         return DirectoryIterator(\n             directory, self,\n             target_size=target_size, color_mode=color_mode,\n@@ -718,23 +904,17 @@ class ImageDataGenerator(object):\n             augment=False,\n             rounds=1,\n             seed=None):\n-        \"\"\"Fits internal statistics to some sample data.\n-\n-        Required for featurewise_center, featurewise_std_normalization\n-        and zca_whitening.\n+        \"\"\"Compute the internal data stats related to the data-dependent transformations, based on an array of sample data.\n+        Only required if featurewise_center or featurewise_std_normalization or zca_whitening.\n \n         # Arguments\n-            x: Numpy array, the data to fit on. Should have rank 4.\n+            x: sample data. Should have rank 4.\n              In case of grayscale data,\n              the channels axis should have value 1, and in case\n              of RGB data, it should have value 3.\n-            augment: Whether to fit on randomly augmented samples\n-            rounds: If `augment`,\n-                how many augmentation passes to do over the data\n-            seed: random seed.\n-\n-        # Raises\n-            ValueError: in case of invalid input `x`.\n+            augment: Boolean (default: False). Whether to fit on randomly augmented samples.\n+            rounds: int (default: 1). If augment, how many augmentation passes over the data to use.\n+            seed: int (default: None). Random seed.\n        \"\"\"\n         x = np.asarray(x, dtype=K.floatx())\n         if x.ndim != 4:\n\n@@ -6,7 +6,7 @@ from itertools import compress\n \n import pytest\n \n-modules = ['keras.layers', 'keras.models', 'keras', 'keras.backend.tensorflow_backend']\n+modules = ['keras.layers', 'keras.models', 'keras', 'keras.backend.tensorflow_backend', 'keras.preprocessing.image']\n accepted_name = ['from_config']\n accepted_module = ['keras.legacy.layers', 'keras.utils.generic_utils']\n \n@@ -27,12 +27,14 @@ def handle_class(name, member):\n \n \n def handle_function(name, member):\n-    if is_accepted(name, member):\n+    if is_accepted(name, member) or member_too_small(member):\n+        # We don't need to check this one.\n         return\n     doc = member.__doc__\n-    if doc is None and not member_too_small(member):\n+    if doc is None:\n         raise ValueError(\"{} function doesn't have any documentation\".format(name),\n                          member.__module__, inspect.getmodule(member).__file__)\n+\n     args = list(inspect.signature(member).parameters.keys())\n     assert_args_presence(args, doc, member, name)\n     assert_function_style(name, member, doc, args)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9f8f520767a322165b01303f84943e59be342beb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1388 | Contributors (this commit): 17 | Commits (past 90d): 11 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -328,7 +328,7 @@ class Sequence(object):\n                 self.batch_size = batch_size\n \n             def __len__(self):\n-                return np.ceil(len(self.x) / float(self.batch_size))\n+                return int(np.ceil(len(self.x) / float(self.batch_size)))\n \n             def __getitem__(self, idx):\n                 batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a69008527787c387be7d7d4f6de91f9f08396dbc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 33 | Lines Deleted: 15 | Files Changed: 3 | Hunks: 9 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 48 | Churn Cumulative: 2208 | Contributors (this commit): 37 | Commits (past 90d): 15 | Contributors (cumulative): 40 | DMM Complexity: None\n\nDIFF:\n@@ -273,6 +273,17 @@ PAGES = [\n             preprocessing.image.ImageDataGenerator,\n         ]\n     },\n+    {\n+        'page': 'preprocessing/text.md',\n+        'functions': [\n+            preprocessing.text.hashing_trick,\n+            preprocessing.text.one_hot,\n+            preprocessing.text.text_to_word_sequence,\n+        ],\n+        'classes': [\n+            preprocessing.text.Tokenizer,\n+        ]\n+    },\n     {\n         'page': 'layers/wrappers.md',\n         'all_module_classes': [wrappers],\n\n@@ -28,9 +28,11 @@ def text_to_word_sequence(text,\n \n     # Arguments\n         text: Input text (string).\n-        filters: Sequence of characters to filter out.\n-        lower: Whether to convert the input to lowercase.\n-        split: Sentence split marker (string).\n+        filters: list (or concatenation) of characters to filter out, such as\n+         punctuation. Default: '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n' , includes\n+         basic punctuation, tabs, and newlines.\n+        lower: boolean. Whether to convert the input to lowercase.\n+        split: str. Separator for word splitting.\n \n     # Returns\n         A list of words (or tokens).\n@@ -68,13 +70,15 @@ def one_hot(text, n,\n \n     # Arguments\n         text: Input text (string).\n-        n: Dimension of the hashing space.\n-        filters: Sequence of characters to filter out.\n-        lower: Whether to convert the input to lowercase.\n-        split: Sentence split marker (string).\n+        n: int. Size of vocabulary.\n+        filters: list (or concatenation) of characters to filter out, such as\n+         punctuation. Default: '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n' , includes\n+         basic punctuation, tabs, and newlines.\n+        lower: boolean. Whether to set the text to lowercase.\n+        split: str. Separator for word splitting.\n \n     # Returns\n-        A list of integer word indices (unicity non-guaranteed).\n+        List of integers in [1, n]. Each integer encodes a word (unicity non-guaranteed).\n     \"\"\"\n     return hashing_trick(text, n,\n                          hash_function=hash,\n@@ -93,14 +97,16 @@ def hashing_trick(text, n,\n     # Arguments\n         text: Input text (string).\n         n: Dimension of the hashing space.\n-        hash_function: if `None` uses python `hash` function, can be 'md5' or\n+        hash_function: defaults to python `hash` function, can be 'md5' or\n             any function that takes in input a string and returns a int.\n-            Note that `hash` is not a stable hashing function, so\n+            Note that 'hash' is not a stable hashing function, so\n             it is not consistent across different runs, while 'md5'\n             is a stable hashing function.\n-        filters: Sequence of characters to filter out.\n-        lower: Whether to convert the input to lowercase.\n-        split: Sentence split marker (string).\n+        filters: list (or concatenation) of characters to filter out, such as\n+         punctuation. Default: '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n' , includes\n+         basic punctuation, tabs, and newlines.\n+        lower: boolean. Whether to set the text to lowercase.\n+        split: str. Separator for word splitting.\n \n     # Returns\n         A list of integer word indices (unicity non-guaranteed).\n@@ -141,7 +147,7 @@ class Tokenizer(object):\n             filtered from the texts. The default is all punctuation, plus\n             tabs and line breaks, minus the `'` character.\n         lower: boolean. Whether to convert the texts to lowercase.\n-        split: character or string to use for token splitting.\n+        split: str. Separator for word splitting.\n         char_level: if True, every character will be treated as a token.\n         oov_token: if given, it will be added to word_index and used to\n             replace out-of-vocabulary words during text_to_sequence calls\n\n@@ -6,7 +6,8 @@ from itertools import compress\n \n import pytest\n \n-modules = ['keras.layers', 'keras.models', 'keras', 'keras.backend.tensorflow_backend', 'keras.preprocessing.image']\n+modules = ['keras.layers', 'keras.models', 'keras', 'keras.backend.tensorflow_backend', 'keras.preprocessing.image',\n+           'keras.preprocessing.text']\n accepted_name = ['from_config']\n accepted_module = ['keras.legacy.layers', 'keras.utils.generic_utils']\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#369854e5da3f9c58eedd9b77e778cf87755bd6a4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 10697 | Contributors (this commit): 54 | Commits (past 90d): 7 | Contributors (cumulative): 54 | DMM Complexity: None\n\nDIFF:\n@@ -1084,7 +1084,7 @@ class _SeparableConv(_Conv):\n         depth_multiplier: The number of depthwise convolution output channels\n             for each input channel.\n             The total number of depthwise convolution output\n-            channels will be equal to `filterss_in * depth_multiplier`.\n+            channels will be equal to `filters_in * depth_multiplier`.\n         activation: Activation function to use\n             (see [activations](../activations.md)).\n             If you don't specify anything, no activation is applied\n@@ -1293,7 +1293,7 @@ class SeparableConv1D(_SeparableConv):\n         depth_multiplier: The number of depthwise convolution output channels\n             for each input channel.\n             The total number of depthwise convolution output\n-            channels will be equal to `filterss_in * depth_multiplier`.\n+            channels will be equal to `filters_in * depth_multiplier`.\n         activation: Activation function to use\n             (see [activations](../activations.md)).\n             If you don't specify anything, no activation is applied\n@@ -1422,7 +1422,7 @@ class SeparableConv2D(_SeparableConv):\n         depth_multiplier: The number of depthwise convolution output channels\n             for each input channel.\n             The total number of depthwise convolution output\n-            channels will be equal to `filterss_in * depth_multiplier`.\n+            channels will be equal to `filters_in * depth_multiplier`.\n         activation: Activation function to use\n             (see [activations](../activations.md)).\n             If you don't specify anything, no activation is applied\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2f4685c8195597d5c150b8fadc1ec4d8827d95cc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 63 | Lines Deleted: 16 | Files Changed: 3 | Hunks: 18 | Methods Changed: 9 | Complexity Δ (Sum/Max): 16/14 | Churn Δ: 79 | Churn Cumulative: 7802 | Contributors (this commit): 109 | Commits (past 90d): 37 | Contributors (cumulative): 119 | DMM Complexity: 0.5151515151515151\n\nDIFF:\n@@ -927,7 +927,7 @@ class Model(Container):\n \n                         # Keep track of state updates created by\n                         # stateful metrics (i.e. metrics layers).\n-                        if isinstance(metric_fn, Layer):\n+                        if isinstance(metric_fn, Layer) and metric_fn.stateful:\n                             self.stateful_metric_names.append(metric_name)\n                             self.metrics_updates += metric_fn.updates\n \n@@ -1175,7 +1175,7 @@ class Model(Container):\n         for epoch in range(initial_epoch, epochs):\n             # Reset stateful metrics\n             for m in self.metrics:\n-                if isinstance(m, Layer):\n+                if isinstance(m, Layer) and m.stateful:\n                     m.reset_states()\n             callbacks.on_epoch_begin(epoch)\n             epoch_logs = {}\n@@ -1364,7 +1364,7 @@ class Model(Container):\n \n         if hasattr(self, 'metrics'):\n             for m in self.metrics:\n-                if isinstance(m, Layer):\n+                if isinstance(m, Layer) and m.stateful:\n                     m.reset_states()\n             stateful_metric_indices = [\n                 i for i, name in enumerate(self.metrics_names)\n@@ -1398,7 +1398,7 @@ class Model(Container):\n                             outs.append(0.)\n                     for i, batch_out in enumerate(batch_outs):\n                         if i in stateful_metric_indices:\n-                            outs[i] = batch_out\n+                            outs[i] = float(batch_out)\n                         else:\n                             outs[i] += batch_out\n                 else:\n@@ -2185,6 +2185,9 @@ class Model(Container):\n             # Construct epoch logs.\n             epoch_logs = {}\n             while epoch < epochs:\n+                for m in self.metrics:\n+                    if isinstance(m, Layer) and m.stateful:\n+                        m.reset_states()\n                 callbacks.on_epoch_begin(epoch)\n                 steps_done = 0\n                 batch_index = 0\n@@ -2320,9 +2323,20 @@ class Model(Container):\n         \"\"\"\n         self._make_test_function()\n \n+        stateful_metric_indices = []\n+        if hasattr(self, 'metrics'):\n+            for i, m in enumerate(self.metrics):\n+                if isinstance(m, Layer) and m.stateful:\n+                    m.reset_states()\n+            stateful_metric_indices = [\n+                i for i, name in enumerate(self.metrics_names)\n+                if str(name) in self.stateful_metric_names]\n+        else:\n+            stateful_metric_indices = []\n+\n         steps_done = 0\n         wait_time = 0.01\n-        all_outs = []\n+        outs_per_batch = []\n         batch_sizes = []\n         is_sequence = isinstance(generator, Sequence)\n         if not is_sequence and use_multiprocessing and workers > 1:\n@@ -2376,6 +2390,9 @@ class Model(Container):\n                                      'or (x, y). Found: ' +\n                                      str(generator_output))\n                 outs = self.test_on_batch(x, y, sample_weight=sample_weight)\n+                if not isinstance(outs, list):\n+                    outs = [outs]\n+                outs_per_batch.append(outs)\n \n                 if isinstance(x, list):\n                     batch_size = x[0].shape[0]\n@@ -2386,7 +2403,6 @@ class Model(Container):\n                 if batch_size == 0:\n                     raise ValueError('Received an empty batch. '\n                                      'Batches should at least contain one item.')\n-                all_outs.append(outs)\n \n                 steps_done += 1\n                 batch_sizes.append(batch_size)\n@@ -2395,14 +2411,15 @@ class Model(Container):\n             if enqueuer is not None:\n                 enqueuer.stop()\n \n-        if not isinstance(outs, list):\n-            return np.average(np.asarray(all_outs),\n-                              weights=batch_sizes)\n-        else:\n         averages = []\n         for i in range(len(outs)):\n-                averages.append(np.average([out[i] for out in all_outs],\n+            if i not in stateful_metric_indices:\n+                averages.append(np.average([out[i] for out in outs_per_batch],\n                                            weights=batch_sizes))\n+            else:\n+                averages.append(float(outs_per_batch[-1][i]))\n+        if len(averages) == 1:\n+            return averages[0]\n         return averages\n \n     @interfaces.legacy_generator_methods_support\n\n@@ -337,7 +337,10 @@ class Progbar(object):\n                     self._values[k][0] += v * (current - self._seen_so_far)\n                     self._values[k][1] += (current - self._seen_so_far)\n             else:\n-                self._values[k] = v\n+                # Stateful metrics output a numeric value.  This representation\n+                # means \"take an average from a single value\" but keeps the\n+                # numeric formatting.\n+                self._values[k] = [v, 1]\n         self._seen_so_far = current\n \n         now = time.time()\n\n@@ -116,13 +116,12 @@ def test_stateful_metrics():\n         Assumes predictions and targets of shape `(samples, 1)`.\n \n         # Arguments\n-            threshold: Float, lower limit on prediction value that counts as a\n-                positive class prediction.\n             name: String, name for the metric.\n         \"\"\"\n \n         def __init__(self, name='true_positives', **kwargs):\n             super(BinaryTruePositives, self).__init__(name=name, **kwargs)\n+            self.stateful = True\n             self.true_positives = K.variable(value=0, dtype='int32')\n \n         def reset_states(self):\n@@ -162,11 +161,16 @@ def test_stateful_metrics():\n                   loss='binary_crossentropy',\n                   metrics=['acc', metric_fn])\n \n-    # Test fit, evaluate\n     samples = 1000\n     x = np.random.random((samples, 2))\n     y = np.random.randint(2, size=(samples, 1))\n-    model.fit(x, y, epochs=1, batch_size=10)\n+\n+    val_samples = 10\n+    val_x = np.random.random((val_samples, 2))\n+    val_y = np.random.randint(2, size=(val_samples, 1))\n+\n+    # Test fit and evaluate\n+    history = model.fit(x, y, validation_data=(val_x, val_y), epochs=1, batch_size=10)\n     outs = model.evaluate(x, y, batch_size=10)\n     preds = model.predict(x)\n \n@@ -176,6 +180,29 @@ def test_stateful_metrics():\n     # Test correctness (e.g. updates should have been run)\n     np.testing.assert_allclose(outs[2], ref_true_pos(y, preds), atol=1e-5)\n \n+    # Test correctness of the validation metric computation\n+    val_preds = model.predict(val_x)\n+    val_outs = model.evaluate(val_x, val_y, batch_size=10)\n+    np.testing.assert_allclose(val_outs[2], ref_true_pos(val_y, val_preds), atol=1e-5)\n+    np.testing.assert_allclose(val_outs[2], history.history['val_true_positives'][-1], atol=1e-5)\n+\n+    # Test with generators\n+    gen = [(np.array([x0]), np.array([y0])) for x0, y0 in zip(x, y)]\n+    val_gen = [(np.array([x0]), np.array([y0])) for x0, y0 in zip(val_x, val_y)]\n+    history = model.fit_generator(iter(gen), epochs=1, steps_per_epoch=samples,\n+                                  validation_data=iter(val_gen), validation_steps=val_samples)\n+    outs = model.evaluate_generator(iter(gen), steps=samples)\n+    preds = model.predict_generator(iter(gen), steps=samples)\n+\n+    # Test correctness of the metric re ref_true_pos()\n+    np.testing.assert_allclose(outs[2], ref_true_pos(y, preds), atol=1e-5)\n+\n+    # Test correctness of the validation metric computation\n+    val_preds = model.predict_generator(iter(val_gen), steps=val_samples)\n+    val_outs = model.evaluate_generator(iter(val_gen), steps=val_samples)\n+    np.testing.assert_allclose(val_outs[2], ref_true_pos(val_y, val_preds), atol=1e-5)\n+    np.testing.assert_allclose(val_outs[2], history.history['val_true_positives'][-1], atol=1e-5)\n+\n \n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a3d160b9467c99cbb27f9aa0382c759f45c8ee66", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 9382 | Contributors (this commit): 108 | Commits (past 90d): 18 | Contributors (cumulative): 108 | DMM Complexity: None\n\nDIFF:\n@@ -73,7 +73,8 @@ def get_uid(prefix=''):\n \n \n def reset_uids():\n-    \"\"\"Reset graph identifiers.\"\"\"\n+    \"\"\"Resets graph identifiers.\n+    \"\"\"\n     global _GRAPH_UID_DICTS\n     _GRAPH_UID_DICTS = {}\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#709f791af201caaab4aa180bda259989087cfe47", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 51 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 11 | Methods Changed: 8 | Complexity Δ (Sum/Max): 9/8 | Churn Δ: 59 | Churn Cumulative: 4402 | Contributors (this commit): 71 | Commits (past 90d): 13 | Contributors (cumulative): 91 | DMM Complexity: 1.0\n\nDIFF:\n@@ -898,7 +898,7 @@ class ReduceLROnPlateau(Callback):\n             monitored has stopped increasing; in `auto`\n             mode, the direction is automatically inferred\n             from the name of the monitored quantity.\n-        epsilon: threshold for measuring the new optimum,\n+        min_delta: threshold for measuring the new optimum,\n             to only focus on significant changes.\n         cooldown: number of epochs to wait before resuming\n             normal operation after lr has been reduced.\n@@ -906,16 +906,21 @@ class ReduceLROnPlateau(Callback):\n     \"\"\"\n \n     def __init__(self, monitor='val_loss', factor=0.1, patience=10,\n-                 verbose=0, mode='auto', epsilon=1e-4, cooldown=0, min_lr=0):\n+                 verbose=0, mode='auto', min_delta=1e-4, cooldown=0, min_lr=0,\n+                 **kwargs):\n         super(ReduceLROnPlateau, self).__init__()\n \n         self.monitor = monitor\n         if factor >= 1.0:\n             raise ValueError('ReduceLROnPlateau '\n                              'does not support a factor >= 1.0.')\n+        if 'epsilon' in kwargs:\n+            min_delta = kwargs.pop('epsilon')\n+            warnings.warn('`epsilon` argument is deprecated and '\n+                          'will be removed, use `min_delta` insted.')\n         self.factor = factor\n         self.min_lr = min_lr\n-        self.epsilon = epsilon\n+        self.min_delta = min_delta\n         self.patience = patience\n         self.verbose = verbose\n         self.cooldown = cooldown\n@@ -936,10 +941,10 @@ class ReduceLROnPlateau(Callback):\n             self.mode = 'auto'\n         if (self.mode == 'min' or\n            (self.mode == 'auto' and 'acc' not in self.monitor)):\n-            self.monitor_op = lambda a, b: np.less(a, b - self.epsilon)\n+            self.monitor_op = lambda a, b: np.less(a, b - self.min_delta)\n             self.best = np.Inf\n         else:\n-            self.monitor_op = lambda a, b: np.greater(a, b + self.epsilon)\n+            self.monitor_op = lambda a, b: np.greater(a, b + self.min_delta)\n             self.best = -np.Inf\n         self.cooldown_counter = 0\n         self.wait = 0\n@@ -967,6 +972,7 @@ class ReduceLROnPlateau(Callback):\n                 self.best = current\n                 self.wait = 0\n             elif not self.in_cooldown():\n+                self.wait += 1\n                 if self.wait >= self.patience:\n                     old_lr = float(K.get_value(self.model.optimizer.lr))\n                     if old_lr > self.min_lr:\n@@ -978,7 +984,6 @@ class ReduceLROnPlateau(Callback):\n                                   'rate to %s.' % (epoch + 1, new_lr))\n                         self.cooldown_counter = self.cooldown\n                         self.wait = 0\n-                self.wait += 1\n \n     def in_cooldown(self):\n         return self.cooldown_counter > 0\n\n@@ -334,18 +334,56 @@ def test_ReduceLROnPlateau():\n     model = make_model()\n \n     # This should reduce the LR after the first epoch (due to high epsilon).\n-    cbks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, epsilon=10, patience=1, cooldown=5)]\n+    cbks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, min_delta=10, patience=1, cooldown=5)]\n     model.fit(X_train, y_train, batch_size=batch_size,\n               validation_data=(X_test, y_test), callbacks=cbks, epochs=5, verbose=2)\n     assert np.allclose(float(K.get_value(model.optimizer.lr)), 0.01, atol=K.epsilon())\n \n     model = make_model()\n-    cbks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, epsilon=0, patience=1, cooldown=5)]\n+    cbks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, min_delta=0, patience=1, cooldown=5)]\n     model.fit(X_train, y_train, batch_size=batch_size,\n               validation_data=(X_test, y_test), callbacks=cbks, epochs=5, verbose=2)\n     assert np.allclose(float(K.get_value(model.optimizer.lr)), 0.1, atol=K.epsilon())\n \n \n+@keras_test\n+def test_ReduceLROnPlateau_patience():\n+    class DummyOptimizer(object):\n+        def __init__(self):\n+            self.lr = K.variable(1.0)\n+\n+    class DummyModel(object):\n+        def __init__(self):\n+            self.optimizer = DummyOptimizer()\n+\n+    reduce_on_plateau = callbacks.ReduceLROnPlateau(monitor='val_loss',\n+                                                    patience=2)\n+    reduce_on_plateau.model = DummyModel()\n+\n+    losses = [0.0860, 0.1096, 0.1040]\n+    lrs = []\n+\n+    for epoch in range(len(losses)):\n+        reduce_on_plateau.on_epoch_end(epoch, logs={'val_loss': losses[epoch]})\n+        lrs.append(K.get_value(reduce_on_plateau.model.optimizer.lr))\n+\n+    # The learning rates should be 1.0 except the last one\n+    assert all([lr == 1.0 for lr in lrs[:-1]]) and lrs[-1] < 1.0\n+\n+\n+@keras_test\n+def test_ReduceLROnPlateau_backwards_compatibility():\n+    import warnings\n+    with warnings.catch_warnings(record=True) as ws:\n+        reduce_on_plateau = callbacks.ReduceLROnPlateau(epsilon=1e-13)\n+        # Check if warnings are disabled\n+        if os.environ.get(\"PYTHONWARNINGS\") != \"ignore\":\n+            assert \"`epsilon` argument is deprecated\" in str(ws[0].message)\n+    assert not hasattr(reduce_on_plateau, 'epsilon')\n+    assert hasattr(reduce_on_plateau, 'min_delta')\n+    assert reduce_on_plateau.min_delta == 1e-13\n+\n+\n @keras_test\n def test_CSVLogger(tmpdir):\n     np.random.seed(1337)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
