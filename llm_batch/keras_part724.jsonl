{"custom_id": "keras#bc2c65edaf86bb6e2566cb13a5421f97cc079ec3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 257 | Lines Deleted: 663 | Files Changed: 14 | Hunks: 55 | Methods Changed: 47 | Complexity Δ (Sum/Max): -44/1 | Churn Δ: 920 | Churn Cumulative: 12649 | Contributors (this commit): 23 | Commits (past 90d): 179 | Contributors (cumulative): 95 | DMM Complexity: 0.5381818181818182\n\nDIFF:\n@@ -1,209 +1,35 @@\n-import warnings\n-\n-\n-def _convert_conv_tranpose_padding_args_from_keras_to_jax(\n-    kernel_size, stride, dilation_rate, padding, output_padding\n-):\n-    \"\"\"Convert the padding arguments from Keras to the ones used by JAX.\n-    JAX starts with an shape of size `(input-1) * stride - kernel_size + 2`,\n-    then adds `left_pad` on the left, and `right_pad` on the right.\n-    In Keras, the `padding` argument determines a base shape, to which\n-    `output_padding` is added on the right. If `output_padding` is None, it will\n-    be given a default value.\n-    \"\"\"\n-\n-    assert padding.lower() in {\"valid\", \"same\"}\n-    kernel_size = (kernel_size - 1) * dilation_rate + 1\n-\n-    if padding.lower() == \"valid\":\n-        # If output_padding is None, we fill it so that the shape of the ouput\n-        # is `(input-1)*s + max(kernel_size, stride)`\n-        output_padding = (\n-            max(kernel_size, stride) - kernel_size\n-            if output_padding is None\n-            else output_padding\n-        )\n-        left_pad = kernel_size - 1\n-        right_pad = kernel_size - 1 + output_padding\n-\n-    else:\n-        if output_padding is None:\n-            # When output_padding is None, we want the shape of the ouput to\n-            # be `input * s`, therefore a total padding of\n-            # `stride + kernel_size - 2`\n-            pad_len = stride + kernel_size - 2\n-        else:\n-            # When output_padding is filled, we want the shape of the ouput to\n-            # be `(input-1)*stride + kernel_size%2 + output_padding`\n-            pad_len = kernel_size + kernel_size % 2 - 2 + output_padding\n-        left_pad = min(pad_len // 2 + pad_len % 2, kernel_size - 1)\n-        right_pad = pad_len - left_pad\n-\n-    return left_pad, right_pad\n-\n-\n-def _convert_conv_tranpose_padding_args_from_keras_to_torch(\n-    kernel_size, stride, dilation_rate, padding, output_padding\n-):\n-    \"\"\"Convert the padding arguments from Keras to the ones used by Torch.\n-    Torch starts with an output shape of `(input-1) * stride + kernel_size`,\n-    then removes `torch_padding` from both sides, and adds\n-    `torch_output_padding` on the right.\n-    Because in Torch the output_padding can only be added to the right,\n-    consistency with Tensorflow is not always possible. In particular this is\n-    the case when both the Torch padding and output_padding values are stricly\n-    positive.\n-    \"\"\"\n-    assert padding.lower() in {\"valid\", \"same\"}\n-    original_kernel_size = kernel_size\n-    kernel_size = (kernel_size - 1) * dilation_rate + 1\n-\n-    if padding.lower() == \"valid\":\n-        # If output_padding is None, we fill it so that the shape of the ouput\n-        # is `(i-1)*s + max(k, s)`\n-        output_padding = (\n-            max(kernel_size, stride) - kernel_size\n-            if output_padding is None\n-            else output_padding\n-        )\n-        torch_padding = 0\n-        torch_output_padding = output_padding\n-\n-    else:\n-        # When output_padding is None, we want the shape of the ouput to be\n-        # `input * s`, otherwise we use the value provided.\n-        output_padding = (\n-            stride - kernel_size % 2\n-            if output_padding is None\n-            else output_padding\n-        )\n-        torch_padding = max(\n-            -((kernel_size % 2 - kernel_size + output_padding) // 2), 0\n-        )\n-        torch_output_padding = (\n-            2 * torch_padding + kernel_size % 2 - kernel_size + output_padding\n-        )\n-\n-    if torch_padding > 0 and torch_output_padding > 0:\n-        warnings.warn(\n-            f\"You might experience inconsistencies accross backends when \"\n-            f\"calling conv transpose with kernel_size={original_kernel_size}, \"\n-            f\"stride={stride}, dilation_rate={dilation_rate}, \"\n-            f\"padding={padding}, output_padding={output_padding}.\"\n-        )\n-\n-    if torch_output_padding >= stride:\n-        raise ValueError(\n-            f\"The padding arguments (padding={padding}) and \"\n-            f\"output_padding={output_padding}) lead to a Torch \"\n-            f\"output_padding ({torch_output_padding}) that is greater than \"\n-            f\"strides ({stride}). This is not supported. You can change the \"\n-            f\"padding arguments, kernel or stride, or run on another backend. \"\n-        )\n-\n-    return torch_padding, torch_output_padding\n-\n-\n-def compute_conv_transpose_padding_args_for_jax(\n-    input_shape,\n-    kernel_shape,\n-    strides,\n+def compute_conv_transpose_output_length(\n+    input_length,\n+    kernel_size,\n     padding,\n-    output_padding,\n-    dilation_rate,\n+    output_padding=None,\n+    stride=1,\n+    dilation=1,\n ):\n-    num_spatial_dims = len(input_shape) - 2\n-    kernel_spatial_shape = kernel_shape[:-2]\n+    \"\"\"Computes output size of a transposed convolution given input size.\"\"\"\n+    assert padding in {\"same\", \"valid\"}\n+    if input_length is None:\n+        return None\n \n-    jax_padding = []\n-    for i in range(num_spatial_dims):\n-        output_padding_i = (\n-            output_padding\n-            if output_padding is None or isinstance(output_padding, int)\n-            else output_padding[i]\n-        )\n-        strides_i = strides if isinstance(strides, int) else strides[i]\n-        dilation_rate_i = (\n-            dilation_rate\n-            if isinstance(dilation_rate, int)\n-            else dilation_rate[i]\n-        )\n-        (\n-            pad_left,\n-            pad_right,\n-        ) = _convert_conv_tranpose_padding_args_from_keras_to_jax(\n-            kernel_size=kernel_spatial_shape[i],\n-            stride=strides_i,\n-            dilation_rate=dilation_rate_i,\n-            padding=padding,\n-            output_padding=output_padding_i,\n-        )\n-        jax_padding.append((pad_left, pad_right))\n+    # Get the dilated kernel size\n+    kernel_size = kernel_size + (kernel_size - 1) * (dilation - 1)\n \n-    return jax_padding\n-\n-\n-def compute_conv_transpose_padding_args_for_torch(\n-    input_shape,\n-    kernel_shape,\n-    strides,\n-    padding,\n-    output_padding,\n-    dilation_rate,\n-):\n-    num_spatial_dims = len(input_shape) - 2\n-    kernel_spatial_shape = kernel_shape[:-2]\n-\n-    torch_paddings = []\n-    torch_output_paddings = []\n-    for i in range(num_spatial_dims):\n-        output_padding_i = (\n-            output_padding\n-            if output_padding is None or isinstance(output_padding, int)\n-            else output_padding[i]\n-        )\n-        strides_i = strides if isinstance(strides, int) else strides[i]\n-        dilation_rate_i = (\n-            dilation_rate\n-            if isinstance(dilation_rate, int)\n-            else dilation_rate[i]\n-        )\n-        (\n-            torch_padding,\n-            torch_output_padding,\n-        ) = _convert_conv_tranpose_padding_args_from_keras_to_torch(\n-            kernel_size=kernel_spatial_shape[i],\n-            stride=strides_i,\n-            dilation_rate=dilation_rate_i,\n-            padding=padding,\n-            output_padding=output_padding_i,\n-        )\n-        torch_paddings.append(torch_padding)\n-        torch_output_paddings.append(torch_output_padding)\n-\n-    return torch_paddings, torch_output_paddings\n-\n-\n-def _get_output_shape_given_tf_padding(\n-    input_size, kernel_size, strides, padding, output_padding, dilation_rate\n-):\n-    assert padding.lower() in {\"valid\", \"same\"}\n-\n-    kernel_size = (kernel_size - 1) * dilation_rate + 1\n-\n-    if padding.lower() == \"valid\":\n-        output_padding = (\n-            max(kernel_size, strides) - kernel_size\n-            if output_padding is None\n-            else output_padding\n-        )\n-        return (input_size - 1) * strides + kernel_size + output_padding\n-\n-    else:\n+    # Infer length if output padding is None, else compute the exact length\n     if output_padding is None:\n-            return input_size * strides\n+        if padding == \"valid\":\n+            length = input_length * stride + max(kernel_size - stride, 0)\n         else:\n-            return (input_size - 1) * strides + kernel_size % 2 + output_padding\n+            length = input_length * stride\n+    else:\n+        if padding == \"same\":\n+            pad = kernel_size // 2\n+        else:\n+            pad = 0\n+\n+        length = (\n+            (input_length - 1) * stride + kernel_size - 2 * pad + output_padding\n+        )\n+    return length\n \n \n def compute_conv_transpose_output_shape(\n@@ -236,19 +62,94 @@ def compute_conv_transpose_output_shape(\n         current_output_padding = (\n             None if output_padding is None else output_padding[i]\n         )\n-\n-        shape_i = _get_output_shape_given_tf_padding(\n-            input_size=input_spatial_shape[i],\n-            kernel_size=kernel_spatial_shape[i],\n-            strides=strides[i],\n+        output_shape.append(\n+            compute_conv_transpose_output_length(\n+                input_spatial_shape[i],\n+                kernel_spatial_shape[i],\n                 padding=padding,\n                 output_padding=current_output_padding,\n-            dilation_rate=dilation_rate[i],\n+                stride=strides[i],\n+                dilation=dilation_rate[i],\n+            )\n         )\n-        output_shape.append(shape_i)\n \n     if data_format == \"channels_last\":\n         output_shape = [input_shape[0]] + output_shape + [filters]\n     else:\n         output_shape = [input_shape[0], filters] + output_shape\n     return output_shape\n+\n+\n+def _compute_conv_transpose_padding_one_dim(\n+    input_length,\n+    output_length,\n+    kernel_size,\n+    stride,\n+    padding,\n+    dilation_rate,\n+):\n+    \"\"\"Computes adjusted padding for `conv_transpose` in one dim.\"\"\"\n+    kernel_size = (kernel_size - 1) * dilation_rate + 1\n+    if padding == \"valid\":\n+        padding_before = 0\n+    else:\n+        # padding == \"same\".\n+        padding_needed = max(\n+            0, (input_length - 1) * stride + kernel_size - output_length\n+        )\n+        padding_before = padding_needed // 2\n+\n+    expanded_input_length = (input_length - 1) * stride + 1\n+    padded_out_length = output_length + kernel_size - 1\n+    pad_before = kernel_size - 1 - padding_before\n+    pad_after = padded_out_length - expanded_input_length - pad_before\n+    return (pad_before, pad_after)\n+\n+\n+def compute_conv_transpose_padding(\n+    input_shape,\n+    kernel_shape,\n+    strides=1,\n+    padding=\"valid\",\n+    output_padding=None,\n+    data_format=\"channels_last\",\n+    dilation_rate=1,\n+):\n+    \"\"\"Computes adjusted padding for `conv_transpose`.\"\"\"\n+    num_spatial_dims = len(input_shape) - 2\n+    if isinstance(output_padding, int):\n+        output_padding = (output_padding,) * num_spatial_dims\n+    if isinstance(strides, int):\n+        strides = (strides,) * num_spatial_dims\n+    if isinstance(dilation_rate, int):\n+        dilation_rate = (dilation_rate,) * num_spatial_dims\n+\n+    kernel_spatial_shape = kernel_shape[:-2]\n+    if data_format == \"channels_last\":\n+        input_spatial_shape = input_shape[1:-1]\n+    else:\n+        input_spatial_shape = input_shape[2:]\n+    padding_values = []\n+    for i in range(num_spatial_dims):\n+        input_length = input_spatial_shape[i]\n+        current_output_padding = (\n+            None if output_padding is None else output_padding[i]\n+        )\n+        output_length = compute_conv_transpose_output_length(\n+            input_spatial_shape[i],\n+            kernel_spatial_shape[i],\n+            padding=padding,\n+            output_padding=current_output_padding,\n+            stride=strides[i],\n+            dilation=dilation_rate[i],\n+        )\n+        padding_value = _compute_conv_transpose_padding_one_dim(\n+            input_length,\n+            output_length,\n+            kernel_spatial_shape[i],\n+            strides[i],\n+            padding=padding,\n+            dilation_rate=dilation_rate[i],\n+        )\n+        padding_values.append(padding_value)\n+    return padding_values\n\n@@ -6,7 +6,7 @@ from jax import nn as jnn\n \n from keras_core.backend import standardize_data_format\n from keras_core.backend.common.backend_utils import (\n-    compute_conv_transpose_padding_args_for_jax,\n+    compute_conv_transpose_padding,\n )\n from keras_core.backend.config import epsilon\n from keras_core.backend.jax.core import cast\n@@ -361,13 +361,14 @@ def conv_transpose(\n ):\n     data_format = standardize_data_format(data_format)\n     num_spatial_dims = inputs.ndim - 2\n-    padding_values = compute_conv_transpose_padding_args_for_jax(\n-        input_shape=inputs.shape,\n-        kernel_shape=kernel.shape,\n-        strides=strides,\n-        padding=padding,\n-        output_padding=output_padding,\n-        dilation_rate=dilation_rate,\n+    padding_values = compute_conv_transpose_padding(\n+        inputs.shape,\n+        kernel.shape,\n+        strides,\n+        padding,\n+        output_padding,\n+        data_format,\n+        dilation_rate,\n     )\n     dimension_numbers = _convert_to_lax_conv_dimension_numbers(\n         num_spatial_dims,\n\n@@ -5,7 +5,7 @@ from jax import numpy as jnp\n \n from keras_core.backend import standardize_data_format\n from keras_core.backend.common.backend_utils import (\n-    compute_conv_transpose_padding_args_for_jax,\n+    compute_conv_transpose_padding,\n )\n from keras_core.backend.config import epsilon\n from keras_core.backend.numpy.core import cast\n@@ -372,13 +372,14 @@ def conv_transpose(\n ):\n     data_format = standardize_data_format(data_format)\n     num_spatial_dims = inputs.ndim - 2\n-    padding_values = compute_conv_transpose_padding_args_for_jax(\n-        input_shape=inputs.shape,\n-        kernel_shape=kernel.shape,\n-        strides=strides,\n-        padding=padding,\n-        output_padding=output_padding,\n-        dilation_rate=dilation_rate,\n+    padding_values = compute_conv_transpose_padding(\n+        inputs.shape,\n+        kernel.shape,\n+        strides,\n+        padding,\n+        output_padding,\n+        data_format,\n+        dilation_rate,\n     )\n     dimension_numbers = _convert_to_lax_conv_dimension_numbers(\n         num_spatial_dims,\n\n@@ -282,13 +282,6 @@ def stft(\n     else:\n         win = torch.ones((sequence_length,), dtype=x.dtype, device=get_device())\n \n-    need_unpack = False\n-    *batch_shape, samples = x.shape\n-    if len(x.shape) > 2:\n-        need_unpack = True\n-        flat_batchsize = math.prod(batch_shape)\n-        x = torch.reshape(x, (flat_batchsize, samples))\n-\n     x = torch.stft(\n         x,\n         n_fft=fft_length,\n@@ -298,10 +291,6 @@ def stft(\n         center=center,\n         return_complex=True,\n     )\n-    if need_unpack:\n-        fft_unique_bins, num_sequences = x.shape[-2:]\n-        x = torch.reshape(x, (*batch_shape, fft_unique_bins, num_sequences))\n-\n     x = torch.swapaxes(x, -2, -1)\n     return x.real, x.imag\n \n@@ -315,68 +304,36 @@ def istft(\n     window=\"hann\",\n     center=True,\n ):\n-    complex_input = _get_complex_tensor_from_tuple(x)\n-    dtype = complex_input.real.dtype\n-    win = None\n-    if window is not None:\n-        if isinstance(window, str):\n-            if window == \"hann\":\n-                win = torch.hann_window(\n-                    sequence_length,\n-                    periodic=True,\n-                    dtype=dtype,\n-                    device=get_device(),\n-                )\n-            else:\n-                win = torch.hamming_window(\n-                    sequence_length,\n-                    periodic=True,\n-                    dtype=dtype,\n-                    device=get_device(),\n-                )\n-        else:\n-            win = convert_to_tensor(window, dtype=dtype)\n-        if len(win.shape) != 1 or win.shape[-1] != sequence_length:\n-            raise ValueError(\n-                \"The shape of `window` must be equal to [sequence_length].\"\n-                f\"Received: window shape={win.shape}\"\n-            )\n-\n-    if sequence_length == fft_length and center is True and win is not None:\n-        # can be falled back to torch.istft\n-        need_unpack = False\n-        *batch_shape, num_sequences, fft_unique_bins = complex_input.shape\n-        if len(complex_input.shape) > 3:\n-            need_unpack = True\n-            flat_batchsize = math.prod(batch_shape)\n-            complex_input = torch.reshape(\n-                complex_input, (flat_batchsize, num_sequences, fft_unique_bins)\n-            )\n-        complex_input = torch.swapaxes(complex_input, -2, -1)\n-        x = torch.istft(\n-            complex_input,\n-            n_fft=fft_length,\n-            hop_length=sequence_stride,\n-            win_length=sequence_length,\n-            window=win,\n-            center=center,\n-            length=length,\n-            return_complex=False,\n-        )\n-        if need_unpack:\n-            samples = x.shape[-1]\n-            x = torch.reshape(x, (*batch_shape, samples))\n-        return x\n-\n-    # custom implementation with irfft and _overlap_sequences\n-    # references:\n+    # ref:\n     # torch: aten/src/ATen/native/SpectralOps.cpp\n     # tf: tf.signal.inverse_stft_window_fn\n     x = irfft(x, fft_length)\n \n     expected_output_len = fft_length + sequence_stride * (x.shape[-2] - 1)\n \n-    if win is not None:\n+    if window is not None:\n+        if isinstance(window, str):\n+            if window == \"hann\":\n+                win = torch.hann_window(\n+                    sequence_length,\n+                    periodic=True,\n+                    dtype=x.dtype,\n+                    device=get_device(),\n+                )\n+            else:\n+                win = torch.hamming_window(\n+                    sequence_length,\n+                    periodic=True,\n+                    dtype=x.dtype,\n+                    device=get_device(),\n+                )\n+        else:\n+            win = convert_to_tensor(window, dtype=x.dtype)\n+        if len(win.shape) != 1 or win.shape[-1] != sequence_length:\n+            raise ValueError(\n+                \"The shape of `window` must be equal to [sequence_length].\"\n+                f\"Received: window shape={win.shape}\"\n+            )\n         l_pad = (fft_length - sequence_length) // 2\n         r_pad = fft_length - sequence_length - l_pad\n         win = pad(win, [[l_pad, r_pad]], \"constant\")\n\n@@ -4,7 +4,7 @@ import torch.nn.functional as tnn\n \n from keras_core.backend import standardize_data_format\n from keras_core.backend.common.backend_utils import (\n-    compute_conv_transpose_padding_args_for_torch,\n+    compute_conv_transpose_padding,\n )\n from keras_core.backend.config import epsilon\n from keras_core.backend.torch.core import cast\n@@ -446,32 +446,40 @@ def conv_transpose(\n     strides = standardize_tuple(strides, num_spatial_dims, \"strides\")\n \n     data_format = standardize_data_format(data_format)\n-    (\n-        torch_padding,\n-        torch_output_padding,\n-    ) = compute_conv_transpose_padding_args_for_torch(\n-        input_shape=inputs.shape,\n-        kernel_shape=kernel.shape,\n-        strides=strides,\n-        padding=padding,\n-        output_padding=output_padding,\n-        dilation_rate=dilation_rate,\n+    padding_values = compute_conv_transpose_padding(\n+        inputs.shape,\n+        kernel.shape,\n+        strides,\n+        padding,\n+        output_padding,\n+        data_format,\n+        dilation_rate,\n     )\n     if data_format == \"channels_last\":\n         inputs = _transpose_spatial_inputs(inputs)\n     # Transpose kernel from keras format to torch format.\n     kernel = _transpose_conv_kernel(kernel)\n     kernel_spatial_shape = kernel.shape[2:]\n+    padding_arg = []\n+    output_padding_arg = []\n     if isinstance(dilation_rate, int):\n         dilation_rate = [dilation_rate] * len(kernel_spatial_shape)\n+    for i, value in enumerate(padding_values):\n+        both_side_padding = value[0]\n+        longer_side_padding = value[1] - value[0]\n+        padding_arg.append(\n+            dilation_rate[i] * (kernel_spatial_shape[i] - 1)\n+            - both_side_padding,\n+        )\n+        output_padding_arg.append(longer_side_padding)\n \n     if num_spatial_dims == 1:\n         outputs = tnn.conv_transpose1d(\n             inputs,\n             kernel,\n             stride=strides,\n-            padding=torch_padding,\n-            output_padding=torch_output_padding,\n+            padding=padding_arg,\n+            output_padding=output_padding_arg,\n             dilation=dilation_rate,\n         )\n     elif num_spatial_dims == 2:\n@@ -479,8 +487,8 @@ def conv_transpose(\n             inputs,\n             kernel,\n             stride=strides,\n-            padding=torch_padding,\n-            output_padding=torch_output_padding,\n+            padding=padding_arg,\n+            output_padding=output_padding_arg,\n             dilation=dilation_rate,\n         )\n     elif num_spatial_dims == 3:\n@@ -488,8 +496,8 @@ def conv_transpose(\n             inputs,\n             kernel,\n             stride=strides,\n-            padding=torch_padding,\n-            output_padding=torch_output_padding,\n+            padding=padding_arg,\n+            output_padding=output_padding_arg,\n             dilation=dilation_rate,\n         )\n     else:\n\n@@ -5,14 +5,11 @@ from absl.testing import parameterized\n from keras_core import backend\n from keras_core import layers\n from keras_core import testing\n-from keras_core.backend.common.backend_utils import (\n-    _convert_conv_tranpose_padding_args_from_keras_to_torch,\n-)\n from keras_core.backend.common.backend_utils import (\n     compute_conv_transpose_output_shape,\n )\n from keras_core.backend.common.backend_utils import (\n-    compute_conv_transpose_padding_args_for_jax,\n+    compute_conv_transpose_padding,\n )\n \n \n@@ -293,15 +290,16 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             data_format,\n             dilation_rate,\n         )\n-        jax_padding = compute_conv_transpose_padding_args_for_jax(\n-            input_shape=x.shape,\n-            kernel_shape=kernel_weights.shape,\n-            strides=strides,\n-            padding=padding,\n-            output_padding=output_padding,\n-            dilation_rate=dilation_rate,\n+        (h_pad,) = compute_conv_transpose_padding(\n+            x.shape,\n+            kernel_weights.shape,\n+            strides,\n+            padding,\n+            output_padding,\n+            data_format,\n+            dilation_rate,\n         )\n-        h_pad_side1 = h_kernel - 1 - jax_padding[0][0]\n+        h_pad_side1 = h_kernel - 1 - h_pad[0]\n \n         if h_dilation > 1:\n             # Increase kernel size\n@@ -368,16 +366,17 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             data_format,\n             dilation_rate,\n         )\n-        jax_padding = compute_conv_transpose_padding_args_for_jax(\n-            input_shape=x.shape,\n-            kernel_shape=kernel_weights.shape,\n-            strides=strides,\n-            padding=padding,\n-            output_padding=output_padding,\n-            dilation_rate=dilation_rate,\n+        h_pad, w_pad = compute_conv_transpose_padding(\n+            x.shape,\n+            kernel_weights.shape,\n+            strides,\n+            padding,\n+            output_padding,\n+            data_format,\n+            dilation_rate,\n         )\n-        h_pad_side1 = h_kernel - 1 - jax_padding[0][0]\n-        w_pad_side1 = w_kernel - 1 - jax_padding[1][0]\n+        h_pad_side1 = h_kernel - 1 - h_pad[0]\n+        w_pad_side1 = w_kernel - 1 - w_pad[0]\n \n         if h_dilation > 1 or w_dilation > 1:\n             # Increase kernel size\n@@ -459,17 +458,18 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             data_format,\n             dilation_rate,\n         )\n-        jax_padding = compute_conv_transpose_padding_args_for_jax(\n-            input_shape=x.shape,\n-            kernel_shape=kernel_weights.shape,\n-            strides=strides,\n-            padding=padding,\n-            output_padding=output_padding,\n-            dilation_rate=dilation_rate,\n+        h_pad, w_pad, d_pad = compute_conv_transpose_padding(\n+            x.shape,\n+            kernel_weights.shape,\n+            strides,\n+            padding,\n+            output_padding,\n+            data_format,\n+            dilation_rate,\n         )\n-        h_pad_side1 = h_kernel - 1 - jax_padding[0][0]\n-        w_pad_side1 = w_kernel - 1 - jax_padding[1][0]\n-        d_pad_side1 = d_kernel - 1 - jax_padding[2][0]\n+        h_pad_side1 = h_kernel - 1 - h_pad[0]\n+        w_pad_side1 = w_kernel - 1 - w_pad[0]\n+        d_pad_side1 = d_kernel - 1 - d_pad[0]\n \n         if h_dilation > 1 or w_dilation > 1 or d_dilation > 1:\n             # Increase kernel size\n@@ -749,89 +749,3 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             dilation_rate,\n         )\n         self.assertAllClose(outputs, expected, atol=1e-5)\n-\n-    @parameterized.product(\n-        kernel_size=list(range(1, 5)),\n-        strides=list(range(1, 5)),\n-        padding=[\"same\", \"valid\"],\n-        output_padding=[None] + list(range(1, 5)),\n-    )\n-    def test_conv1d_transpose_consistency(\n-        self, kernel_size, strides, padding, output_padding\n-    ):\n-        \"\"\"Test conv transpose, on an 1D array of size 3, against several\n-        convolution parameters. In particular, tests if Torch inconsistencies\n-        are raised.\n-        \"\"\"\n-\n-        # output_padding cannot be greater than strides\n-        if isinstance(output_padding, int) and output_padding >= strides:\n-            pytest.skip(\n-                \"`output_padding` greater than `strides` is not supported\"\n-            )\n-\n-        input = np.ones(shape=(1, 3, 1))\n-        kernel_weights = np.arange(1, kernel_size + 1).reshape(\n-            (kernel_size, 1, 1)\n-        )\n-\n-        # Exepected result\n-        expected_res = self.np_conv1d_transpose(\n-            x=input,\n-            kernel_weights=kernel_weights,\n-            bias_weights=np.zeros(shape=(1,)),\n-            strides=strides,\n-            padding=padding,\n-            output_padding=output_padding,\n-            data_format=\"channels_last\",\n-            dilation_rate=1,\n-        )\n-\n-        # keras-core layer\n-        kc_layer = layers.Conv1DTranspose(\n-            filters=1,\n-            kernel_size=kernel_size,\n-            strides=strides,\n-            padding=padding,\n-            output_padding=output_padding,\n-            dilation_rate=1,\n-        )\n-        kc_layer.build(input_shape=(1, 3, 1))\n-        kc_layer.kernel.assign(kernel_weights)\n-\n-        # Special cases for Torch\n-        if backend.backend() == \"torch\":\n-            # The following set of arguments lead to Torch output padding to be\n-            # greater than strides, which is not supported by Torch.\n-            # An error is raised.\n-            if (kernel_size, strides, padding, output_padding) in [\n-                (2, 1, \"same\", None),\n-                (4, 1, \"same\", None),\n-            ]:\n-                with pytest.raises(ValueError):\n-                    kc_res = kc_layer(input)\n-                return\n-\n-            # When both torch_padding and torch_output_padding are greater\n-            # than 0, Torch outputs are inconsistent with the ones from\n-            # Tensorflow. A warning is raised, and we expect the results to be\n-            # different.\n-            (\n-                torch_padding,\n-                torch_output_padding,\n-            ) = _convert_conv_tranpose_padding_args_from_keras_to_torch(\n-                kernel_size=kernel_size,\n-                stride=strides,\n-                dilation_rate=1,\n-                padding=padding,\n-                output_padding=output_padding,\n-            )\n-            if torch_padding > 0 and torch_output_padding > 0:\n-                with pytest.raises(AssertionError):\n-                    kc_res = kc_layer(input)\n-                    self.assertAllClose(expected_res, kc_res, atol=1e-5)\n-                return\n-\n-        # Compare results\n-        kc_res = kc_layer(input)\n-        self.assertAllClose(expected_res, kc_res, atol=1e-5)\n\n@@ -161,12 +161,6 @@ class Functional(Function, Model):\n         output_layers = [x._keras_history[0] for x in self.outputs]\n         self.output_names = [x.name for x in output_layers]\n \n-    def _lock_state(self):\n-        # Unlike other layers, we allow Functional state to be mutable after\n-        # build. E.g. to attach a layer to a model that is not part of the\n-        # functional DAG.\n-        pass\n-\n     @property\n     def layers(self):\n         layers = []\n\n@@ -51,16 +51,6 @@ class FunctionalTest(testing.TestCase):\n         out_val = model(in_val)\n         self.assertAllClose(out_val, np.ones((2, 3)))\n \n-    @pytest.mark.requires_trainable_backend\n-    def test_mutable_state(self):\n-        inputs = Input(shape=(3,), batch_size=2, name=\"input\")\n-        x = layers.Dense(5)(inputs)\n-        outputs = layers.Dense(5)(x)\n-        model = Functional(inputs, outputs)\n-        # Allow attaching state to a model that isn't directly part of the DAG.\n-        # Most useful for functional subclasses.\n-        model.extra_layer = layers.Dense(5)\n-\n     @pytest.mark.requires_trainable_backend\n     def test_basic_flow_multi_output(self):\n         inputs = Input(shape=(3,), batch_size=2, name=\"input\")\n\n@@ -691,6 +691,11 @@ class STFT(Operation):\n         self.center = center\n \n     def compute_output_spec(self, x):\n+        if len(x.shape) not in {1, 2}:\n+            raise ValueError(\n+                f\"Input should have rank 1 (single sequence) or 2 \"\n+                f\"(batched sequences). Received: input shape = {x.shape}\"\n+            )\n         if x.shape[-1] is not None:\n             padded = 0 if self.center is False else (self.fft_length // 2) * 2\n             num_sequences = (\n\n@@ -746,8 +746,8 @@ class MathOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(real_ref, real_output, atol=1e-5, rtol=1e-5)\n         self.assertAllClose(imag_ref, imag_output, atol=1e-5, rtol=1e-5)\n \n-        # Test N-D case.\n-        x = np.random.random((2, 3, 32))\n+        # Test 2D case.\n+        x = np.random.random((3, 32))\n         real_output, imag_output = kmath.stft(\n             x, sequence_length, sequence_stride, fft_length, window, center\n         )\n@@ -794,16 +794,16 @@ class MathOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             window=window,\n             center=center,\n         )\n-        if backend.backend() in (\"numpy\", \"jax\", \"torch\"):\n-            # these backends have different implementation for the boundary of\n+        if backend.backend() in (\"numpy\", \"jax\"):\n+            # numpy and jax have different implementation for the boundary of\n             # the output, so we need to truncate 5% befroe assertAllClose\n             truncated_len = int(output.shape[-1] * 0.05)\n             output = output[..., truncated_len:-truncated_len]\n             ref = ref[..., truncated_len:-truncated_len]\n         self.assertAllClose(output, ref, atol=1e-5, rtol=1e-5)\n \n-        # Test N-D case.\n-        x = np.random.random((2, 3, 256))\n+        # Test 2D case.\n+        x = np.random.random((3, 256))\n         real_x, imag_x = _stft(\n             x, sequence_length, sequence_stride, fft_length, window, center\n         )\n@@ -823,8 +823,8 @@ class MathOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             window=window,\n             center=center,\n         )\n-        if backend.backend() in (\"numpy\", \"jax\", \"torch\"):\n-            # these backends have different implementation for the boundary of\n+        if backend.backend() in (\"numpy\", \"jax\"):\n+            # numpy and jax have different implementation for the boundary of\n             # the output, so we need to truncate 5% befroe assertAllClose\n             truncated_len = int(output.shape[-1] * 0.05)\n             output = output[..., truncated_len:-truncated_len]\n\n@@ -222,18 +222,20 @@ def reduce_shape(shape, axis=None, keepdims=False):\n     shape = list(shape)\n     if axis is None:\n         if keepdims:\n-            return tuple([1 for _ in shape])\n+            output_shape = [1 for _ in range(shape)]\n         else:\n-            return tuple([])\n+            output_shape = []\n+        return output_shape\n \n     if keepdims:\n         for ax in axis:\n             shape[ax] = 1\n-        return tuple(shape)\n+        return shape\n     else:\n-        for ax in sorted(axis, reverse=True):\n-            del shape[ax]\n-        return tuple(shape)\n+        for ax in axis:\n+            shape[ax] = -1\n+        output_shape = list(filter((-1).__ne__, shape))\n+        return output_shape\n \n \n @keras_core_export(\"keras_core.utils.get_source_inputs\")\n\n@@ -17,170 +17,3 @@ class OperationUtilsTest(testing.TestCase):\n     def test_get_source_inputs_return_input_tensor(self):\n         inputs = input_layer.Input(shape=(10,))\n         self.assertIs(operation_utils.get_source_inputs(inputs)[0], inputs)\n-\n-    def test_compute_pooling_output_shape(self):\n-        input_shape = (1, 4, 4, 1)\n-        pool_size = (2, 2)\n-        strides = (2, 2)\n-        output_shape = operation_utils.compute_pooling_output_shape(\n-            input_shape, pool_size, strides\n-        )\n-        expected_output_shape = (1, 2, 2, 1)\n-        self.assertEqual(output_shape, expected_output_shape)\n-\n-    def test_compute_pooling_output_shape_with_none(self):\n-        input_shape = (None, 4, 4, 1)\n-        pool_size = (2, 2)\n-        strides = (2, 2)\n-        output_shape = operation_utils.compute_pooling_output_shape(\n-            input_shape, pool_size, strides\n-        )\n-        expected_output_shape = (None, 2, 2, 1)\n-        self.assertEqual(output_shape, expected_output_shape)\n-\n-    def test_compute_pooling_output_shape_valid_padding(self):\n-        input_shape = (1, 4, 4, 1)\n-        pool_size = (2, 2)\n-        strides = (2, 2)\n-        output_shape = operation_utils.compute_pooling_output_shape(\n-            input_shape, pool_size, strides, padding=\"valid\"\n-        )\n-        self.assertEqual(output_shape, (1, 2, 2, 1))\n-\n-    def test_compute_pooling_output_shape_channels_last(self):\n-        input_shape = (1, 4, 4, 3)\n-        pool_size = (2, 2)\n-        strides = (2, 2)\n-        output_shape = operation_utils.compute_pooling_output_shape(\n-            input_shape,\n-            pool_size,\n-            strides,\n-            padding=\"valid\",\n-            data_format=\"channels_last\",\n-        )\n-        self.assertEqual(output_shape, (1, 2, 2, 3))\n-\n-    def test_compute_pooling_output_shape_same_padding_stride1(self):\n-        input_shape = (1, 4, 4, 3)\n-        pool_size = (2, 2)\n-        strides = (1, 1)\n-        output_shape = operation_utils.compute_pooling_output_shape(\n-            input_shape,\n-            pool_size,\n-            strides,\n-            padding=\"same\",\n-            data_format=\"channels_last\",\n-        )\n-        self.assertEqual(output_shape, (1, 4, 4, 3))\n-\n-    def test_compute_conv_output_shape(self):\n-        input_shape = (1, 4, 4, 1)\n-        filters = 1\n-        kernel_size = (3, 3)\n-        strides = (1, 1)\n-        output_shape = operation_utils.compute_conv_output_shape(\n-            input_shape, filters, kernel_size, strides\n-        )\n-        expected_output_shape = (1, 2, 2, 1)\n-        self.assertEqual(output_shape, expected_output_shape)\n-\n-    def test_compute_conv_output_shape_with_none(self):\n-        input_shape = (None, 4, 4, 1)\n-        kernel_size = (3, 3)\n-        filters = 1\n-        strides = (1, 1)\n-        output_shape = operation_utils.compute_conv_output_shape(\n-            input_shape, filters, kernel_size, strides\n-        )\n-        expected_output_shape = (None, 2, 2, 1)\n-        self.assertEqual(output_shape, expected_output_shape)\n-\n-    def test_compute_conv_output_shape_valid_padding(self):\n-        input_shape = (1, 4, 4, 1)\n-        kernel_size = (3, 3)\n-        filters = 1\n-        strides = (2, 2)\n-        output_shape = operation_utils.compute_conv_output_shape(\n-            input_shape, filters, kernel_size, strides, padding=\"valid\"\n-        )\n-        self.assertEqual(output_shape, (1, 1, 1, 1))\n-\n-    def test_compute_conv_output_shape_channels_last(self):\n-        input_shape = (1, 4, 4, 3)\n-        kernel_size = (3, 3)\n-        filters = 3\n-        strides = (2, 2)\n-        output_shape = operation_utils.compute_conv_output_shape(\n-            input_shape,\n-            filters,\n-            kernel_size,\n-            strides,\n-            padding=\"valid\",\n-            data_format=\"channels_last\",\n-        )\n-        self.assertEqual(output_shape, (1, 1, 1, 3))\n-\n-    def test_compute_conv_output_shape_same_padding_stride1(self):\n-        input_shape = (1, 4, 4, 3)\n-        kernel_size = (3, 3)\n-        filters = 3\n-        strides = (1, 1)\n-        output_shape = operation_utils.compute_conv_output_shape(\n-            input_shape,\n-            filters,\n-            kernel_size,\n-            strides,\n-            padding=\"same\",\n-            data_format=\"channels_last\",\n-        )\n-        self.assertEqual(output_shape, (1, 4, 4, 3))\n-\n-    def test_compute_reshape_output_shape(self):\n-        input_shape = (1, 4, 4, 1)\n-        target_shape = (16, 1)\n-        output_shape = operation_utils.compute_reshape_output_shape(\n-            input_shape, new_shape=target_shape, new_shape_arg_name=\"New shape\"\n-        )\n-        self.assertEqual(output_shape, target_shape)\n-\n-    def test_reduce_shape_no_axes_no_keepdims(self):\n-        input_shape = (1, 4, 4, 1)\n-        output_shape = operation_utils.reduce_shape(input_shape)\n-        expected_output_shape = ()\n-        self.assertEqual(output_shape, expected_output_shape)\n-\n-    def test_reduce_shape_no_axes_with_keepdims(self):\n-        input_shape = (1, 4, 4, 1)\n-        output_shape = operation_utils.reduce_shape(input_shape, keepdims=True)\n-        expected_output_shape = (1, 1, 1, 1)\n-        self.assertEqual(output_shape, expected_output_shape)\n-\n-    def test_reduce_shape_single_axis_no_keepdims(self):\n-        input_shape = (1, 4, 4, 1)\n-        axes = [1]\n-        output_shape = operation_utils.reduce_shape(input_shape, axes)\n-        expected_output_shape = (1, 4, 1)\n-        self.assertEqual(output_shape, expected_output_shape)\n-\n-    def test_reduce_shape_single_axis_with_keepdims(self):\n-        input_shape = (1, 4, 4, 1)\n-        axes = [1]\n-        output_shape = operation_utils.reduce_shape(\n-            input_shape, axes, keepdims=True\n-        )\n-        expected_output_shape = (1, 1, 4, 1)\n-        self.assertEqual(output_shape, expected_output_shape)\n-\n-    def test_reduce_shape_multiple_axes_no_keepdims(self):\n-        input_shape = (1, 4, 4, 1)\n-        axes = [1, 2]\n-        output_shape = operation_utils.reduce_shape(input_shape, axes)\n-        expected_output_shape = (1, 1)\n-        self.assertEqual(output_shape, expected_output_shape)\n-\n-    def test_reduce_shape_out_of_order_axes_no_keepdims(self):\n-        input_shape = (1, 4, 4, 1)\n-        axes = [2, 1]\n-        output_shape = operation_utils.reduce_shape(input_shape, axes)\n-        expected_output_shape = (1, 1)\n-        self.assertEqual(output_shape, expected_output_shape)\n\n@@ -154,22 +154,33 @@ class RandomTest(testing.TestCase, parameterized.TestCase):\n         x = random.randint((3, 5), 0, 10, seed=rng)\n         self.assertTrue(isinstance(x, jnp.ndarray))\n \n+    @pytest.mark.skipif(\n+        keras_core.backend.backend() != \"jax\",\n+        reason=\"This test requires `jax` as the backend.\",\n+    )\n+    def test_jax_unseed_disallowed_during_tracing(self):\n+        import jax\n+\n+        @jax.jit\n+        def jit_fn():\n+            return random.randint((2, 2), 0, 10, seed=None)\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \"you should only use seeded random ops\"\n+        ):\n+            jit_fn()\n+\n     def test_global_seed_generator(self):\n         # Check that unseeded RNG calls use and update global_rng_state()\n-        # and that this works across traced function boundaries\n \n         def random_numbers(seed):\n-            rng_state = seed_generator.global_rng_state()\n+            rng_state = seed_generator.global_seed_generator().state\n             rng_state.assign(seed)\n             x = random.normal((), seed=None)\n             y = random.normal((), seed=None)\n             return x, y, rng_state.value\n \n-        if backend.backend() == \"jax\":\n-            import jax\n-\n-            random_numbers = jax.jit(random_numbers)\n-        elif backend.backend() == \"tensorflow\":\n+        if backend.backend() == \"tensorflow\":\n             import tensorflow as tf\n \n             random_numbers = tf.function(jit_compile=True)(random_numbers)\n@@ -204,4 +215,4 @@ class RandomTest(testing.TestCase, parameterized.TestCase):\n         self.assertGreater(np.abs(y1 - y3), 1e-4)\n         self.assertGreater(np.abs(y2 - y3), 1e-4)\n \n-        seed_generator.global_rng_state().assign(seed)\n+        seed_generator.global_seed_generator().state.assign(seed)\n\n@@ -5,6 +5,7 @@ import numpy as np\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.backend.common import global_state\n+from keras_core.utils import jax_utils\n \n \n @keras_core_export(\"keras_core.random.SeedGenerator\")\n@@ -90,6 +91,16 @@ class SeedGenerator:\n \n \n def global_seed_generator():\n+    if jax_utils.is_in_jax_tracing_scope():\n+        raise ValueError(\n+            \"When tracing a JAX function, \"\n+            \"you should only use seeded random ops, e.g. \"\n+            \"you should create a `SeedGenerator` instance, attach it \"\n+            \"to your layer/model, and pass the instance as the `seed` \"\n+            \"argument when calling random ops. Unseeded random ops \"\n+            \"would get incorrectly traced by JAX and would become constant \"\n+            \"after tracing.\"\n+        )\n     gen = global_state.get_global_attribute(\"global_seed_generator\")\n     if gen is None:\n         gen = SeedGenerator()\n@@ -97,40 +108,6 @@ def global_seed_generator():\n     return gen\n \n \n-@keras_core_export(\"keras_core.random.global_rng_state\")\n-def global_rng_state():\n-    \"\"\"Returns the state variable for the default global RNG.\n-\n-    Returns:\n-        A `KerasVariable` with shape `(2,)` and dtype `uint32`.\n-\n-    This is the global state used by unseeded (`seed=None`) Keras\n-    random ops, e.g. `keras_core.random.normal(shape=(), seed=None)`.\n-\n-    In JAX, if you're using unseeded random ops, be mindful that\n-    their outputs will be unchanged across different calls of\n-    a traced function (e.g. a `jax.jit`-transformed function) since\n-    traced functions in JAX are fully stateless. To get\n-    different outputs across different calls, you will need to pass the\n-    global RNG state in and out of the function boundary, like this:\n-\n-    ```python\n-    @jax.jit\n-    def random_numbers(seed):\n-        rng_state = keras_core.random.global_rng_state()\n-        rng_state.assign(seed)\n-        x = keras_core.random.normal((), seed=None)\n-        y = keras_core.random.normal((), seed=None)\n-        return x, y, rng_state.value\n-\n-    seed = jax.numpy.array([0, 0])\n-    x, y, seed = random_numbers(seed)\n-    new_x, new_y, seed = random_numbers(seed)\n-    ```\n-    \"\"\"\n-    return global_seed_generator().state\n-\n-\n def make_default_seed():\n     return python_random.randint(1, int(1e9))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ce17b5e1b342cd981b1a8223d6da4572630d5692", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 609 | Lines Deleted: 215 | Files Changed: 12 | Hunks: 48 | Methods Changed: 41 | Complexity Δ (Sum/Max): 45/17 | Churn Δ: 824 | Churn Cumulative: 12858 | Contributors (this commit): 22 | Commits (past 90d): 162 | Contributors (cumulative): 84 | DMM Complexity: 0.4896551724137931\n\nDIFF:\n@@ -1,35 +1,209 @@\n-def compute_conv_transpose_output_length(\n-    input_length,\n-    kernel_size,\n-    padding,\n-    output_padding=None,\n-    stride=1,\n-    dilation=1,\n+import warnings\n+\n+\n+def _convert_conv_tranpose_padding_args_from_keras_to_jax(\n+    kernel_size, stride, dilation_rate, padding, output_padding\n ):\n-    \"\"\"Computes output size of a transposed convolution given input size.\"\"\"\n-    assert padding in {\"same\", \"valid\"}\n-    if input_length is None:\n-        return None\n+    \"\"\"Convert the padding arguments from Keras to the ones used by JAX.\n+    JAX starts with an shape of size `(input-1) * stride - kernel_size + 2`,\n+    then adds `left_pad` on the left, and `right_pad` on the right.\n+    In Keras, the `padding` argument determines a base shape, to which\n+    `output_padding` is added on the right. If `output_padding` is None, it will\n+    be given a default value.\n+    \"\"\"\n \n-    # Get the dilated kernel size\n-    kernel_size = kernel_size + (kernel_size - 1) * (dilation - 1)\n+    assert padding.lower() in {\"valid\", \"same\"}\n+    kernel_size = (kernel_size - 1) * dilation_rate + 1\n \n-    # Infer length if output padding is None, else compute the exact length\n-    if output_padding is None:\n-        if padding == \"valid\":\n-            length = input_length * stride + max(kernel_size - stride, 0)\n-        else:\n-            length = input_length * stride\n-    else:\n-        if padding == \"same\":\n-            pad = kernel_size // 2\n-        else:\n-            pad = 0\n-\n-        length = (\n-            (input_length - 1) * stride + kernel_size - 2 * pad + output_padding\n+    if padding.lower() == \"valid\":\n+        # If output_padding is None, we fill it so that the shape of the ouput\n+        # is `(input-1)*s + max(kernel_size, stride)`\n+        output_padding = (\n+            max(kernel_size, stride) - kernel_size\n+            if output_padding is None\n+            else output_padding\n         )\n-    return length\n+        left_pad = kernel_size - 1\n+        right_pad = kernel_size - 1 + output_padding\n+\n+    else:\n+        if output_padding is None:\n+            # When output_padding is None, we want the shape of the ouput to\n+            # be `input * s`, therefore a total padding of\n+            # `stride + kernel_size - 2`\n+            pad_len = stride + kernel_size - 2\n+        else:\n+            # When output_padding is filled, we want the shape of the ouput to\n+            # be `(input-1)*stride + kernel_size%2 + output_padding`\n+            pad_len = kernel_size + kernel_size % 2 - 2 + output_padding\n+        left_pad = min(pad_len // 2 + pad_len % 2, kernel_size - 1)\n+        right_pad = pad_len - left_pad\n+\n+    return left_pad, right_pad\n+\n+\n+def _convert_conv_tranpose_padding_args_from_keras_to_torch(\n+    kernel_size, stride, dilation_rate, padding, output_padding\n+):\n+    \"\"\"Convert the padding arguments from Keras to the ones used by Torch.\n+    Torch starts with an output shape of `(input-1) * stride + kernel_size`,\n+    then removes `torch_padding` from both sides, and adds\n+    `torch_output_padding` on the right.\n+    Because in Torch the output_padding can only be added to the right,\n+    consistency with Tensorflow is not always possible. In particular this is\n+    the case when both the Torch padding and output_padding values are stricly\n+    positive.\n+    \"\"\"\n+    assert padding.lower() in {\"valid\", \"same\"}\n+    original_kernel_size = kernel_size\n+    kernel_size = (kernel_size - 1) * dilation_rate + 1\n+\n+    if padding.lower() == \"valid\":\n+        # If output_padding is None, we fill it so that the shape of the ouput\n+        # is `(i-1)*s + max(k, s)`\n+        output_padding = (\n+            max(kernel_size, stride) - kernel_size\n+            if output_padding is None\n+            else output_padding\n+        )\n+        torch_padding = 0\n+        torch_output_padding = output_padding\n+\n+    else:\n+        # When output_padding is None, we want the shape of the ouput to be\n+        # `input * s`, otherwise we use the value provided.\n+        output_padding = (\n+            stride - kernel_size % 2\n+            if output_padding is None\n+            else output_padding\n+        )\n+        torch_padding = max(\n+            -((kernel_size % 2 - kernel_size + output_padding) // 2), 0\n+        )\n+        torch_output_padding = (\n+            2 * torch_padding + kernel_size % 2 - kernel_size + output_padding\n+        )\n+\n+    if torch_padding > 0 and torch_output_padding > 0:\n+        warnings.warn(\n+            f\"You might experience inconsistencies accross backends when \"\n+            f\"calling conv transpose with kernel_size={original_kernel_size}, \"\n+            f\"stride={stride}, dilation_rate={dilation_rate}, \"\n+            f\"padding={padding}, output_padding={output_padding}.\"\n+        )\n+\n+    if torch_output_padding >= stride:\n+        raise ValueError(\n+            f\"The padding arguments (padding={padding}) and \"\n+            f\"output_padding={output_padding}) lead to a Torch \"\n+            f\"output_padding ({torch_output_padding}) that is greater than \"\n+            f\"strides ({stride}). This is not supported. You can change the \"\n+            f\"padding arguments, kernel or stride, or run on another backend. \"\n+        )\n+\n+    return torch_padding, torch_output_padding\n+\n+\n+def compute_conv_transpose_padding_args_for_jax(\n+    input_shape,\n+    kernel_shape,\n+    strides,\n+    padding,\n+    output_padding,\n+    dilation_rate,\n+):\n+    num_spatial_dims = len(input_shape) - 2\n+    kernel_spatial_shape = kernel_shape[:-2]\n+\n+    jax_padding = []\n+    for i in range(num_spatial_dims):\n+        output_padding_i = (\n+            output_padding\n+            if output_padding is None or isinstance(output_padding, int)\n+            else output_padding[i]\n+        )\n+        strides_i = strides if isinstance(strides, int) else strides[i]\n+        dilation_rate_i = (\n+            dilation_rate\n+            if isinstance(dilation_rate, int)\n+            else dilation_rate[i]\n+        )\n+        (\n+            pad_left,\n+            pad_right,\n+        ) = _convert_conv_tranpose_padding_args_from_keras_to_jax(\n+            kernel_size=kernel_spatial_shape[i],\n+            stride=strides_i,\n+            dilation_rate=dilation_rate_i,\n+            padding=padding,\n+            output_padding=output_padding_i,\n+        )\n+        jax_padding.append((pad_left, pad_right))\n+\n+    return jax_padding\n+\n+\n+def compute_conv_transpose_padding_args_for_torch(\n+    input_shape,\n+    kernel_shape,\n+    strides,\n+    padding,\n+    output_padding,\n+    dilation_rate,\n+):\n+    num_spatial_dims = len(input_shape) - 2\n+    kernel_spatial_shape = kernel_shape[:-2]\n+\n+    torch_paddings = []\n+    torch_output_paddings = []\n+    for i in range(num_spatial_dims):\n+        output_padding_i = (\n+            output_padding\n+            if output_padding is None or isinstance(output_padding, int)\n+            else output_padding[i]\n+        )\n+        strides_i = strides if isinstance(strides, int) else strides[i]\n+        dilation_rate_i = (\n+            dilation_rate\n+            if isinstance(dilation_rate, int)\n+            else dilation_rate[i]\n+        )\n+        (\n+            torch_padding,\n+            torch_output_padding,\n+        ) = _convert_conv_tranpose_padding_args_from_keras_to_torch(\n+            kernel_size=kernel_spatial_shape[i],\n+            stride=strides_i,\n+            dilation_rate=dilation_rate_i,\n+            padding=padding,\n+            output_padding=output_padding_i,\n+        )\n+        torch_paddings.append(torch_padding)\n+        torch_output_paddings.append(torch_output_padding)\n+\n+    return torch_paddings, torch_output_paddings\n+\n+\n+def _get_output_shape_given_tf_padding(\n+    input_size, kernel_size, strides, padding, output_padding, dilation_rate\n+):\n+    assert padding.lower() in {\"valid\", \"same\"}\n+\n+    kernel_size = (kernel_size - 1) * dilation_rate + 1\n+\n+    if padding.lower() == \"valid\":\n+        output_padding = (\n+            max(kernel_size, strides) - kernel_size\n+            if output_padding is None\n+            else output_padding\n+        )\n+        return (input_size - 1) * strides + kernel_size + output_padding\n+\n+    else:\n+        if output_padding is None:\n+            return input_size * strides\n+        else:\n+            return (input_size - 1) * strides + kernel_size % 2 + output_padding\n \n \n def compute_conv_transpose_output_shape(\n@@ -62,94 +236,19 @@ def compute_conv_transpose_output_shape(\n         current_output_padding = (\n             None if output_padding is None else output_padding[i]\n         )\n-        output_shape.append(\n-            compute_conv_transpose_output_length(\n-                input_spatial_shape[i],\n-                kernel_spatial_shape[i],\n+\n+        shape_i = _get_output_shape_given_tf_padding(\n+            input_size=input_spatial_shape[i],\n+            kernel_size=kernel_spatial_shape[i],\n+            strides=strides[i],\n             padding=padding,\n             output_padding=current_output_padding,\n-                stride=strides[i],\n-                dilation=dilation_rate[i],\n-            )\n+            dilation_rate=dilation_rate[i],\n         )\n+        output_shape.append(shape_i)\n \n     if data_format == \"channels_last\":\n         output_shape = [input_shape[0]] + output_shape + [filters]\n     else:\n         output_shape = [input_shape[0], filters] + output_shape\n     return output_shape\n-\n-\n-def _compute_conv_transpose_padding_one_dim(\n-    input_length,\n-    output_length,\n-    kernel_size,\n-    stride,\n-    padding,\n-    dilation_rate,\n-):\n-    \"\"\"Computes adjusted padding for `conv_transpose` in one dim.\"\"\"\n-    kernel_size = (kernel_size - 1) * dilation_rate + 1\n-    if padding == \"valid\":\n-        padding_before = 0\n-    else:\n-        # padding == \"same\".\n-        padding_needed = max(\n-            0, (input_length - 1) * stride + kernel_size - output_length\n-        )\n-        padding_before = padding_needed // 2\n-\n-    expanded_input_length = (input_length - 1) * stride + 1\n-    padded_out_length = output_length + kernel_size - 1\n-    pad_before = kernel_size - 1 - padding_before\n-    pad_after = padded_out_length - expanded_input_length - pad_before\n-    return (pad_before, pad_after)\n-\n-\n-def compute_conv_transpose_padding(\n-    input_shape,\n-    kernel_shape,\n-    strides=1,\n-    padding=\"valid\",\n-    output_padding=None,\n-    data_format=\"channels_last\",\n-    dilation_rate=1,\n-):\n-    \"\"\"Computes adjusted padding for `conv_transpose`.\"\"\"\n-    num_spatial_dims = len(input_shape) - 2\n-    if isinstance(output_padding, int):\n-        output_padding = (output_padding,) * num_spatial_dims\n-    if isinstance(strides, int):\n-        strides = (strides,) * num_spatial_dims\n-    if isinstance(dilation_rate, int):\n-        dilation_rate = (dilation_rate,) * num_spatial_dims\n-\n-    kernel_spatial_shape = kernel_shape[:-2]\n-    if data_format == \"channels_last\":\n-        input_spatial_shape = input_shape[1:-1]\n-    else:\n-        input_spatial_shape = input_shape[2:]\n-    padding_values = []\n-    for i in range(num_spatial_dims):\n-        input_length = input_spatial_shape[i]\n-        current_output_padding = (\n-            None if output_padding is None else output_padding[i]\n-        )\n-        output_length = compute_conv_transpose_output_length(\n-            input_spatial_shape[i],\n-            kernel_spatial_shape[i],\n-            padding=padding,\n-            output_padding=current_output_padding,\n-            stride=strides[i],\n-            dilation=dilation_rate[i],\n-        )\n-        padding_value = _compute_conv_transpose_padding_one_dim(\n-            input_length,\n-            output_length,\n-            kernel_spatial_shape[i],\n-            strides[i],\n-            padding=padding,\n-            dilation_rate=dilation_rate[i],\n-        )\n-        padding_values.append(padding_value)\n-    return padding_values\n\n@@ -6,7 +6,7 @@ from jax import nn as jnn\n \n from keras_core.backend import standardize_data_format\n from keras_core.backend.common.backend_utils import (\n-    compute_conv_transpose_padding,\n+    compute_conv_transpose_padding_args_for_jax,\n )\n from keras_core.backend.config import epsilon\n from keras_core.backend.jax.core import cast\n@@ -361,14 +361,13 @@ def conv_transpose(\n ):\n     data_format = standardize_data_format(data_format)\n     num_spatial_dims = inputs.ndim - 2\n-    padding_values = compute_conv_transpose_padding(\n-        inputs.shape,\n-        kernel.shape,\n-        strides,\n-        padding,\n-        output_padding,\n-        data_format,\n-        dilation_rate,\n+    padding_values = compute_conv_transpose_padding_args_for_jax(\n+        input_shape=inputs.shape,\n+        kernel_shape=kernel.shape,\n+        strides=strides,\n+        padding=padding,\n+        output_padding=output_padding,\n+        dilation_rate=dilation_rate,\n     )\n     dimension_numbers = _convert_to_lax_conv_dimension_numbers(\n         num_spatial_dims,\n\n@@ -5,7 +5,7 @@ from jax import numpy as jnp\n \n from keras_core.backend import standardize_data_format\n from keras_core.backend.common.backend_utils import (\n-    compute_conv_transpose_padding,\n+    compute_conv_transpose_padding_args_for_jax,\n )\n from keras_core.backend.config import epsilon\n from keras_core.backend.numpy.core import cast\n@@ -372,14 +372,13 @@ def conv_transpose(\n ):\n     data_format = standardize_data_format(data_format)\n     num_spatial_dims = inputs.ndim - 2\n-    padding_values = compute_conv_transpose_padding(\n-        inputs.shape,\n-        kernel.shape,\n-        strides,\n-        padding,\n-        output_padding,\n-        data_format,\n-        dilation_rate,\n+    padding_values = compute_conv_transpose_padding_args_for_jax(\n+        input_shape=inputs.shape,\n+        kernel_shape=kernel.shape,\n+        strides=strides,\n+        padding=padding,\n+        output_padding=output_padding,\n+        dilation_rate=dilation_rate,\n     )\n     dimension_numbers = _convert_to_lax_conv_dimension_numbers(\n         num_spatial_dims,\n\n@@ -282,6 +282,13 @@ def stft(\n     else:\n         win = torch.ones((sequence_length,), dtype=x.dtype, device=get_device())\n \n+    need_unpack = False\n+    *batch_shape, samples = x.shape\n+    if len(x.shape) > 2:\n+        need_unpack = True\n+        flat_batchsize = math.prod(batch_shape)\n+        x = torch.reshape(x, (flat_batchsize, samples))\n+\n     x = torch.stft(\n         x,\n         n_fft=fft_length,\n@@ -291,6 +298,10 @@ def stft(\n         center=center,\n         return_complex=True,\n     )\n+    if need_unpack:\n+        fft_unique_bins, num_sequences = x.shape[-2:]\n+        x = torch.reshape(x, (*batch_shape, fft_unique_bins, num_sequences))\n+\n     x = torch.swapaxes(x, -2, -1)\n     return x.real, x.imag\n \n@@ -304,36 +315,68 @@ def istft(\n     window=\"hann\",\n     center=True,\n ):\n-    # ref:\n-    # torch: aten/src/ATen/native/SpectralOps.cpp\n-    # tf: tf.signal.inverse_stft_window_fn\n-    x = irfft(x, fft_length)\n-\n-    expected_output_len = fft_length + sequence_stride * (x.shape[-2] - 1)\n-\n+    complex_input = _get_complex_tensor_from_tuple(x)\n+    dtype = complex_input.real.dtype\n+    win = None\n     if window is not None:\n         if isinstance(window, str):\n             if window == \"hann\":\n                 win = torch.hann_window(\n                     sequence_length,\n                     periodic=True,\n-                    dtype=x.dtype,\n+                    dtype=dtype,\n                     device=get_device(),\n                 )\n             else:\n                 win = torch.hamming_window(\n                     sequence_length,\n                     periodic=True,\n-                    dtype=x.dtype,\n+                    dtype=dtype,\n                     device=get_device(),\n                 )\n         else:\n-            win = convert_to_tensor(window, dtype=x.dtype)\n+            win = convert_to_tensor(window, dtype=dtype)\n         if len(win.shape) != 1 or win.shape[-1] != sequence_length:\n             raise ValueError(\n                 \"The shape of `window` must be equal to [sequence_length].\"\n                 f\"Received: window shape={win.shape}\"\n             )\n+\n+    if sequence_length == fft_length and center is True and win is not None:\n+        # can be falled back to torch.istft\n+        need_unpack = False\n+        *batch_shape, num_sequences, fft_unique_bins = complex_input.shape\n+        if len(complex_input.shape) > 3:\n+            need_unpack = True\n+            flat_batchsize = math.prod(batch_shape)\n+            complex_input = torch.reshape(\n+                complex_input, (flat_batchsize, num_sequences, fft_unique_bins)\n+            )\n+        complex_input = torch.swapaxes(complex_input, -2, -1)\n+        x = torch.istft(\n+            complex_input,\n+            n_fft=fft_length,\n+            hop_length=sequence_stride,\n+            win_length=sequence_length,\n+            window=win,\n+            center=center,\n+            length=length,\n+            return_complex=False,\n+        )\n+        if need_unpack:\n+            samples = x.shape[-1]\n+            x = torch.reshape(x, (*batch_shape, samples))\n+        return x\n+\n+    # custom implementation with irfft and _overlap_sequences\n+    # references:\n+    # torch: aten/src/ATen/native/SpectralOps.cpp\n+    # tf: tf.signal.inverse_stft_window_fn\n+    x = irfft(x, fft_length)\n+\n+    expected_output_len = fft_length + sequence_stride * (x.shape[-2] - 1)\n+\n+    if win is not None:\n         l_pad = (fft_length - sequence_length) // 2\n         r_pad = fft_length - sequence_length - l_pad\n         win = pad(win, [[l_pad, r_pad]], \"constant\")\n\n@@ -4,7 +4,7 @@ import torch.nn.functional as tnn\n \n from keras_core.backend import standardize_data_format\n from keras_core.backend.common.backend_utils import (\n-    compute_conv_transpose_padding,\n+    compute_conv_transpose_padding_args_for_torch,\n )\n from keras_core.backend.config import epsilon\n from keras_core.backend.torch.core import cast\n@@ -446,40 +446,32 @@ def conv_transpose(\n     strides = standardize_tuple(strides, num_spatial_dims, \"strides\")\n \n     data_format = standardize_data_format(data_format)\n-    padding_values = compute_conv_transpose_padding(\n-        inputs.shape,\n-        kernel.shape,\n-        strides,\n-        padding,\n-        output_padding,\n-        data_format,\n-        dilation_rate,\n+    (\n+        torch_padding,\n+        torch_output_padding,\n+    ) = compute_conv_transpose_padding_args_for_torch(\n+        input_shape=inputs.shape,\n+        kernel_shape=kernel.shape,\n+        strides=strides,\n+        padding=padding,\n+        output_padding=output_padding,\n+        dilation_rate=dilation_rate,\n     )\n     if data_format == \"channels_last\":\n         inputs = _transpose_spatial_inputs(inputs)\n     # Transpose kernel from keras format to torch format.\n     kernel = _transpose_conv_kernel(kernel)\n     kernel_spatial_shape = kernel.shape[2:]\n-    padding_arg = []\n-    output_padding_arg = []\n     if isinstance(dilation_rate, int):\n         dilation_rate = [dilation_rate] * len(kernel_spatial_shape)\n-    for i, value in enumerate(padding_values):\n-        both_side_padding = value[0]\n-        longer_side_padding = value[1] - value[0]\n-        padding_arg.append(\n-            dilation_rate[i] * (kernel_spatial_shape[i] - 1)\n-            - both_side_padding,\n-        )\n-        output_padding_arg.append(longer_side_padding)\n \n     if num_spatial_dims == 1:\n         outputs = tnn.conv_transpose1d(\n             inputs,\n             kernel,\n             stride=strides,\n-            padding=padding_arg,\n-            output_padding=output_padding_arg,\n+            padding=torch_padding,\n+            output_padding=torch_output_padding,\n             dilation=dilation_rate,\n         )\n     elif num_spatial_dims == 2:\n@@ -487,8 +479,8 @@ def conv_transpose(\n             inputs,\n             kernel,\n             stride=strides,\n-            padding=padding_arg,\n-            output_padding=output_padding_arg,\n+            padding=torch_padding,\n+            output_padding=torch_output_padding,\n             dilation=dilation_rate,\n         )\n     elif num_spatial_dims == 3:\n@@ -496,8 +488,8 @@ def conv_transpose(\n             inputs,\n             kernel,\n             stride=strides,\n-            padding=padding_arg,\n-            output_padding=output_padding_arg,\n+            padding=torch_padding,\n+            output_padding=torch_output_padding,\n             dilation=dilation_rate,\n         )\n     else:\n\n@@ -5,11 +5,14 @@ from absl.testing import parameterized\n from keras_core import backend\n from keras_core import layers\n from keras_core import testing\n+from keras_core.backend.common.backend_utils import (\n+    _convert_conv_tranpose_padding_args_from_keras_to_torch,\n+)\n from keras_core.backend.common.backend_utils import (\n     compute_conv_transpose_output_shape,\n )\n from keras_core.backend.common.backend_utils import (\n-    compute_conv_transpose_padding,\n+    compute_conv_transpose_padding_args_for_jax,\n )\n \n \n@@ -290,16 +293,15 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             data_format,\n             dilation_rate,\n         )\n-        (h_pad,) = compute_conv_transpose_padding(\n-            x.shape,\n-            kernel_weights.shape,\n-            strides,\n-            padding,\n-            output_padding,\n-            data_format,\n-            dilation_rate,\n+        jax_padding = compute_conv_transpose_padding_args_for_jax(\n+            input_shape=x.shape,\n+            kernel_shape=kernel_weights.shape,\n+            strides=strides,\n+            padding=padding,\n+            output_padding=output_padding,\n+            dilation_rate=dilation_rate,\n         )\n-        h_pad_side1 = h_kernel - 1 - h_pad[0]\n+        h_pad_side1 = h_kernel - 1 - jax_padding[0][0]\n \n         if h_dilation > 1:\n             # Increase kernel size\n@@ -366,17 +368,16 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             data_format,\n             dilation_rate,\n         )\n-        h_pad, w_pad = compute_conv_transpose_padding(\n-            x.shape,\n-            kernel_weights.shape,\n-            strides,\n-            padding,\n-            output_padding,\n-            data_format,\n-            dilation_rate,\n+        jax_padding = compute_conv_transpose_padding_args_for_jax(\n+            input_shape=x.shape,\n+            kernel_shape=kernel_weights.shape,\n+            strides=strides,\n+            padding=padding,\n+            output_padding=output_padding,\n+            dilation_rate=dilation_rate,\n         )\n-        h_pad_side1 = h_kernel - 1 - h_pad[0]\n-        w_pad_side1 = w_kernel - 1 - w_pad[0]\n+        h_pad_side1 = h_kernel - 1 - jax_padding[0][0]\n+        w_pad_side1 = w_kernel - 1 - jax_padding[1][0]\n \n         if h_dilation > 1 or w_dilation > 1:\n             # Increase kernel size\n@@ -458,18 +459,17 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             data_format,\n             dilation_rate,\n         )\n-        h_pad, w_pad, d_pad = compute_conv_transpose_padding(\n-            x.shape,\n-            kernel_weights.shape,\n-            strides,\n-            padding,\n-            output_padding,\n-            data_format,\n-            dilation_rate,\n+        jax_padding = compute_conv_transpose_padding_args_for_jax(\n+            input_shape=x.shape,\n+            kernel_shape=kernel_weights.shape,\n+            strides=strides,\n+            padding=padding,\n+            output_padding=output_padding,\n+            dilation_rate=dilation_rate,\n         )\n-        h_pad_side1 = h_kernel - 1 - h_pad[0]\n-        w_pad_side1 = w_kernel - 1 - w_pad[0]\n-        d_pad_side1 = d_kernel - 1 - d_pad[0]\n+        h_pad_side1 = h_kernel - 1 - jax_padding[0][0]\n+        w_pad_side1 = w_kernel - 1 - jax_padding[1][0]\n+        d_pad_side1 = d_kernel - 1 - jax_padding[2][0]\n \n         if h_dilation > 1 or w_dilation > 1 or d_dilation > 1:\n             # Increase kernel size\n@@ -749,3 +749,89 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             dilation_rate,\n         )\n         self.assertAllClose(outputs, expected, atol=1e-5)\n+\n+    @parameterized.product(\n+        kernel_size=list(range(1, 5)),\n+        strides=list(range(1, 5)),\n+        padding=[\"same\", \"valid\"],\n+        output_padding=[None] + list(range(1, 5)),\n+    )\n+    def test_conv1d_transpose_consistency(\n+        self, kernel_size, strides, padding, output_padding\n+    ):\n+        \"\"\"Test conv transpose, on an 1D array of size 3, against several\n+        convolution parameters. In particular, tests if Torch inconsistencies\n+        are raised.\n+        \"\"\"\n+\n+        # output_padding cannot be greater than strides\n+        if isinstance(output_padding, int) and output_padding >= strides:\n+            pytest.skip(\n+                \"`output_padding` greater than `strides` is not supported\"\n+            )\n+\n+        input = np.ones(shape=(1, 3, 1))\n+        kernel_weights = np.arange(1, kernel_size + 1).reshape(\n+            (kernel_size, 1, 1)\n+        )\n+\n+        # Exepected result\n+        expected_res = self.np_conv1d_transpose(\n+            x=input,\n+            kernel_weights=kernel_weights,\n+            bias_weights=np.zeros(shape=(1,)),\n+            strides=strides,\n+            padding=padding,\n+            output_padding=output_padding,\n+            data_format=\"channels_last\",\n+            dilation_rate=1,\n+        )\n+\n+        # keras-core layer\n+        kc_layer = layers.Conv1DTranspose(\n+            filters=1,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            output_padding=output_padding,\n+            dilation_rate=1,\n+        )\n+        kc_layer.build(input_shape=(1, 3, 1))\n+        kc_layer.kernel.assign(kernel_weights)\n+\n+        # Special cases for Torch\n+        if backend.backend() == \"torch\":\n+            # The following set of arguments lead to Torch output padding to be\n+            # greater than strides, which is not supported by Torch.\n+            # An error is raised.\n+            if (kernel_size, strides, padding, output_padding) in [\n+                (2, 1, \"same\", None),\n+                (4, 1, \"same\", None),\n+            ]:\n+                with pytest.raises(ValueError):\n+                    kc_res = kc_layer(input)\n+                return\n+\n+            # When both torch_padding and torch_output_padding are greater\n+            # than 0, Torch outputs are inconsistent with the ones from\n+            # Tensorflow. A warning is raised, and we expect the results to be\n+            # different.\n+            (\n+                torch_padding,\n+                torch_output_padding,\n+            ) = _convert_conv_tranpose_padding_args_from_keras_to_torch(\n+                kernel_size=kernel_size,\n+                stride=strides,\n+                dilation_rate=1,\n+                padding=padding,\n+                output_padding=output_padding,\n+            )\n+            if torch_padding > 0 and torch_output_padding > 0:\n+                with pytest.raises(AssertionError):\n+                    kc_res = kc_layer(input)\n+                    self.assertAllClose(expected_res, kc_res, atol=1e-5)\n+                return\n+\n+        # Compare results\n+        kc_res = kc_layer(input)\n+        self.assertAllClose(expected_res, kc_res, atol=1e-5)\n\n@@ -161,6 +161,12 @@ class Functional(Function, Model):\n         output_layers = [x._keras_history[0] for x in self.outputs]\n         self.output_names = [x.name for x in output_layers]\n \n+    def _lock_state(self):\n+        # Unlike other layers, we allow Functional state to be mutable after\n+        # build. E.g. to attach a layer to a model that is not part of the\n+        # functional DAG.\n+        pass\n+\n     @property\n     def layers(self):\n         layers = []\n\n@@ -51,6 +51,16 @@ class FunctionalTest(testing.TestCase):\n         out_val = model(in_val)\n         self.assertAllClose(out_val, np.ones((2, 3)))\n \n+    @pytest.mark.requires_trainable_backend\n+    def test_mutable_state(self):\n+        inputs = Input(shape=(3,), batch_size=2, name=\"input\")\n+        x = layers.Dense(5)(inputs)\n+        outputs = layers.Dense(5)(x)\n+        model = Functional(inputs, outputs)\n+        # Allow attaching state to a model that isn't directly part of the DAG.\n+        # Most useful for functional subclasses.\n+        model.extra_layer = layers.Dense(5)\n+\n     @pytest.mark.requires_trainable_backend\n     def test_basic_flow_multi_output(self):\n         inputs = Input(shape=(3,), batch_size=2, name=\"input\")\n\n@@ -691,11 +691,6 @@ class STFT(Operation):\n         self.center = center\n \n     def compute_output_spec(self, x):\n-        if len(x.shape) not in {1, 2}:\n-            raise ValueError(\n-                f\"Input should have rank 1 (single sequence) or 2 \"\n-                f\"(batched sequences). Received: input shape = {x.shape}\"\n-            )\n         if x.shape[-1] is not None:\n             padded = 0 if self.center is False else (self.fft_length // 2) * 2\n             num_sequences = (\n\n@@ -746,8 +746,8 @@ class MathOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(real_ref, real_output, atol=1e-5, rtol=1e-5)\n         self.assertAllClose(imag_ref, imag_output, atol=1e-5, rtol=1e-5)\n \n-        # Test 2D case.\n-        x = np.random.random((3, 32))\n+        # Test N-D case.\n+        x = np.random.random((2, 3, 32))\n         real_output, imag_output = kmath.stft(\n             x, sequence_length, sequence_stride, fft_length, window, center\n         )\n@@ -794,16 +794,16 @@ class MathOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             window=window,\n             center=center,\n         )\n-        if backend.backend() in (\"numpy\", \"jax\"):\n-            # numpy and jax have different implementation for the boundary of\n+        if backend.backend() in (\"numpy\", \"jax\", \"torch\"):\n+            # these backends have different implementation for the boundary of\n             # the output, so we need to truncate 5% befroe assertAllClose\n             truncated_len = int(output.shape[-1] * 0.05)\n             output = output[..., truncated_len:-truncated_len]\n             ref = ref[..., truncated_len:-truncated_len]\n         self.assertAllClose(output, ref, atol=1e-5, rtol=1e-5)\n \n-        # Test 2D case.\n-        x = np.random.random((3, 256))\n+        # Test N-D case.\n+        x = np.random.random((2, 3, 256))\n         real_x, imag_x = _stft(\n             x, sequence_length, sequence_stride, fft_length, window, center\n         )\n@@ -823,8 +823,8 @@ class MathOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             window=window,\n             center=center,\n         )\n-        if backend.backend() in (\"numpy\", \"jax\"):\n-            # numpy and jax have different implementation for the boundary of\n+        if backend.backend() in (\"numpy\", \"jax\", \"torch\"):\n+            # these backends have different implementation for the boundary of\n             # the output, so we need to truncate 5% befroe assertAllClose\n             truncated_len = int(output.shape[-1] * 0.05)\n             output = output[..., truncated_len:-truncated_len]\n\n@@ -222,20 +222,18 @@ def reduce_shape(shape, axis=None, keepdims=False):\n     shape = list(shape)\n     if axis is None:\n         if keepdims:\n-            output_shape = [1 for _ in range(shape)]\n+            return tuple([1 for _ in shape])\n         else:\n-            output_shape = []\n-        return output_shape\n+            return tuple([])\n \n     if keepdims:\n         for ax in axis:\n             shape[ax] = 1\n-        return shape\n+        return tuple(shape)\n     else:\n-        for ax in axis:\n-            shape[ax] = -1\n-        output_shape = list(filter((-1).__ne__, shape))\n-        return output_shape\n+        for ax in sorted(axis, reverse=True):\n+            del shape[ax]\n+        return tuple(shape)\n \n \n @keras_core_export(\"keras_core.utils.get_source_inputs\")\n\n@@ -17,3 +17,170 @@ class OperationUtilsTest(testing.TestCase):\n     def test_get_source_inputs_return_input_tensor(self):\n         inputs = input_layer.Input(shape=(10,))\n         self.assertIs(operation_utils.get_source_inputs(inputs)[0], inputs)\n+\n+    def test_compute_pooling_output_shape(self):\n+        input_shape = (1, 4, 4, 1)\n+        pool_size = (2, 2)\n+        strides = (2, 2)\n+        output_shape = operation_utils.compute_pooling_output_shape(\n+            input_shape, pool_size, strides\n+        )\n+        expected_output_shape = (1, 2, 2, 1)\n+        self.assertEqual(output_shape, expected_output_shape)\n+\n+    def test_compute_pooling_output_shape_with_none(self):\n+        input_shape = (None, 4, 4, 1)\n+        pool_size = (2, 2)\n+        strides = (2, 2)\n+        output_shape = operation_utils.compute_pooling_output_shape(\n+            input_shape, pool_size, strides\n+        )\n+        expected_output_shape = (None, 2, 2, 1)\n+        self.assertEqual(output_shape, expected_output_shape)\n+\n+    def test_compute_pooling_output_shape_valid_padding(self):\n+        input_shape = (1, 4, 4, 1)\n+        pool_size = (2, 2)\n+        strides = (2, 2)\n+        output_shape = operation_utils.compute_pooling_output_shape(\n+            input_shape, pool_size, strides, padding=\"valid\"\n+        )\n+        self.assertEqual(output_shape, (1, 2, 2, 1))\n+\n+    def test_compute_pooling_output_shape_channels_last(self):\n+        input_shape = (1, 4, 4, 3)\n+        pool_size = (2, 2)\n+        strides = (2, 2)\n+        output_shape = operation_utils.compute_pooling_output_shape(\n+            input_shape,\n+            pool_size,\n+            strides,\n+            padding=\"valid\",\n+            data_format=\"channels_last\",\n+        )\n+        self.assertEqual(output_shape, (1, 2, 2, 3))\n+\n+    def test_compute_pooling_output_shape_same_padding_stride1(self):\n+        input_shape = (1, 4, 4, 3)\n+        pool_size = (2, 2)\n+        strides = (1, 1)\n+        output_shape = operation_utils.compute_pooling_output_shape(\n+            input_shape,\n+            pool_size,\n+            strides,\n+            padding=\"same\",\n+            data_format=\"channels_last\",\n+        )\n+        self.assertEqual(output_shape, (1, 4, 4, 3))\n+\n+    def test_compute_conv_output_shape(self):\n+        input_shape = (1, 4, 4, 1)\n+        filters = 1\n+        kernel_size = (3, 3)\n+        strides = (1, 1)\n+        output_shape = operation_utils.compute_conv_output_shape(\n+            input_shape, filters, kernel_size, strides\n+        )\n+        expected_output_shape = (1, 2, 2, 1)\n+        self.assertEqual(output_shape, expected_output_shape)\n+\n+    def test_compute_conv_output_shape_with_none(self):\n+        input_shape = (None, 4, 4, 1)\n+        kernel_size = (3, 3)\n+        filters = 1\n+        strides = (1, 1)\n+        output_shape = operation_utils.compute_conv_output_shape(\n+            input_shape, filters, kernel_size, strides\n+        )\n+        expected_output_shape = (None, 2, 2, 1)\n+        self.assertEqual(output_shape, expected_output_shape)\n+\n+    def test_compute_conv_output_shape_valid_padding(self):\n+        input_shape = (1, 4, 4, 1)\n+        kernel_size = (3, 3)\n+        filters = 1\n+        strides = (2, 2)\n+        output_shape = operation_utils.compute_conv_output_shape(\n+            input_shape, filters, kernel_size, strides, padding=\"valid\"\n+        )\n+        self.assertEqual(output_shape, (1, 1, 1, 1))\n+\n+    def test_compute_conv_output_shape_channels_last(self):\n+        input_shape = (1, 4, 4, 3)\n+        kernel_size = (3, 3)\n+        filters = 3\n+        strides = (2, 2)\n+        output_shape = operation_utils.compute_conv_output_shape(\n+            input_shape,\n+            filters,\n+            kernel_size,\n+            strides,\n+            padding=\"valid\",\n+            data_format=\"channels_last\",\n+        )\n+        self.assertEqual(output_shape, (1, 1, 1, 3))\n+\n+    def test_compute_conv_output_shape_same_padding_stride1(self):\n+        input_shape = (1, 4, 4, 3)\n+        kernel_size = (3, 3)\n+        filters = 3\n+        strides = (1, 1)\n+        output_shape = operation_utils.compute_conv_output_shape(\n+            input_shape,\n+            filters,\n+            kernel_size,\n+            strides,\n+            padding=\"same\",\n+            data_format=\"channels_last\",\n+        )\n+        self.assertEqual(output_shape, (1, 4, 4, 3))\n+\n+    def test_compute_reshape_output_shape(self):\n+        input_shape = (1, 4, 4, 1)\n+        target_shape = (16, 1)\n+        output_shape = operation_utils.compute_reshape_output_shape(\n+            input_shape, new_shape=target_shape, new_shape_arg_name=\"New shape\"\n+        )\n+        self.assertEqual(output_shape, target_shape)\n+\n+    def test_reduce_shape_no_axes_no_keepdims(self):\n+        input_shape = (1, 4, 4, 1)\n+        output_shape = operation_utils.reduce_shape(input_shape)\n+        expected_output_shape = ()\n+        self.assertEqual(output_shape, expected_output_shape)\n+\n+    def test_reduce_shape_no_axes_with_keepdims(self):\n+        input_shape = (1, 4, 4, 1)\n+        output_shape = operation_utils.reduce_shape(input_shape, keepdims=True)\n+        expected_output_shape = (1, 1, 1, 1)\n+        self.assertEqual(output_shape, expected_output_shape)\n+\n+    def test_reduce_shape_single_axis_no_keepdims(self):\n+        input_shape = (1, 4, 4, 1)\n+        axes = [1]\n+        output_shape = operation_utils.reduce_shape(input_shape, axes)\n+        expected_output_shape = (1, 4, 1)\n+        self.assertEqual(output_shape, expected_output_shape)\n+\n+    def test_reduce_shape_single_axis_with_keepdims(self):\n+        input_shape = (1, 4, 4, 1)\n+        axes = [1]\n+        output_shape = operation_utils.reduce_shape(\n+            input_shape, axes, keepdims=True\n+        )\n+        expected_output_shape = (1, 1, 4, 1)\n+        self.assertEqual(output_shape, expected_output_shape)\n+\n+    def test_reduce_shape_multiple_axes_no_keepdims(self):\n+        input_shape = (1, 4, 4, 1)\n+        axes = [1, 2]\n+        output_shape = operation_utils.reduce_shape(input_shape, axes)\n+        expected_output_shape = (1, 1)\n+        self.assertEqual(output_shape, expected_output_shape)\n+\n+    def test_reduce_shape_out_of_order_axes_no_keepdims(self):\n+        input_shape = (1, 4, 4, 1)\n+        axes = [2, 1]\n+        output_shape = operation_utils.reduce_shape(input_shape, axes)\n+        expected_output_shape = (1, 1)\n+        self.assertEqual(output_shape, expected_output_shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
