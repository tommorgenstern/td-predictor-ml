{"custom_id": "keras#9dc9a78cc6502226775a99725c654fab3298aa5f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 292 | Lines Deleted: 233 | Files Changed: 11 | Hunks: 24 | Methods Changed: 20 | Complexity Δ (Sum/Max): 6/13 | Churn Δ: 525 | Churn Cumulative: 20087 | Contributors (this commit): 94 | Commits (past 90d): 54 | Contributors (cumulative): 134 | DMM Complexity: 0.0\n\nDIFF:\n@@ -21,26 +21,13 @@ from keras import backend\n from keras.engine import base_layer\n from keras.engine import base_preprocessing_layer\n from keras.layers.preprocessing import preprocessing_utils as utils\n-from keras.preprocessing.image import smart_resize\n+from keras.utils import image_utils\n from keras.utils import tf_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n from tensorflow.python.util.tf_export import keras_export\n from tensorflow.tools.docs import doc_controls\n \n-ResizeMethod = tf.image.ResizeMethod\n-\n-_RESIZE_METHODS = {\n-    'bilinear': ResizeMethod.BILINEAR,\n-    'nearest': ResizeMethod.NEAREST_NEIGHBOR,\n-    'bicubic': ResizeMethod.BICUBIC,\n-    'area': ResizeMethod.AREA,\n-    'lanczos3': ResizeMethod.LANCZOS3,\n-    'lanczos5': ResizeMethod.LANCZOS5,\n-    'gaussian': ResizeMethod.GAUSSIAN,\n-    'mitchellcubic': ResizeMethod.MITCHELLCUBIC\n-}\n-\n H_AXIS = -3\n W_AXIS = -2\n \n@@ -95,7 +82,7 @@ class Resizing(base_layer.Layer):\n     self.width = width\n     self.interpolation = interpolation\n     self.crop_to_aspect_ratio = crop_to_aspect_ratio\n-    self._interpolation_method = get_interpolation(interpolation)\n+    self._interpolation_method = image_utils.get_interpolation(interpolation)\n     super(Resizing, self).__init__(**kwargs)\n     base_preprocessing_layer.keras_kpl_gauge.get_cell('Resizing').set(True)\n \n@@ -113,7 +100,7 @@ class Resizing(base_layer.Layer):\n       def resize_to_aspect(x):\n         if tf_utils.is_ragged(inputs):\n           x = x.to_tensor()\n-        return smart_resize(\n+        return image_utils.smart_resize(\n             x,\n             size=size,\n             interpolation=self._interpolation_method)\n@@ -200,7 +187,7 @@ class CenterCrop(base_layer.Layer):\n                                            self.height, self.width)\n \n     def upsize():\n-      outputs = smart_resize(inputs, [self.height, self.width])\n+      outputs = image_utils.smart_resize(inputs, [self.height, self.width])\n       # smart_resize will always output float32, so we need to re-cast.\n       return tf.cast(outputs, self.compute_dtype)\n \n@@ -514,7 +501,7 @@ class RandomCrop(base_layer.BaseRandomLayer):\n                                          self.height, self.width)\n \n   def _resize(self, inputs):\n-    outputs = smart_resize(inputs, [self.height, self.width])\n+    outputs = image_utils.smart_resize(inputs, [self.height, self.width])\n     # smart_resize will always output float32, so we need to re-cast.\n     return tf.cast(outputs, self.compute_dtype)\n \n@@ -1650,7 +1637,7 @@ class RandomHeight(base_layer.BaseRandomLayer):\n       raise ValueError('`factor` must have values larger than -1, '\n                        'got {}'.format(factor))\n     self.interpolation = interpolation\n-    self._interpolation_method = get_interpolation(interpolation)\n+    self._interpolation_method = image_utils.get_interpolation(interpolation)\n     self.seed = seed\n \n   def call(self, inputs, training=True):\n@@ -1757,7 +1744,7 @@ class RandomWidth(base_layer.BaseRandomLayer):\n       raise ValueError('`factor` must have values larger than -1, '\n                        'got {}'.format(factor))\n     self.interpolation = interpolation\n-    self._interpolation_method = get_interpolation(interpolation)\n+    self._interpolation_method = image_utils.get_interpolation(interpolation)\n     self.seed = seed\n \n   def call(self, inputs, training=True):\n@@ -1801,11 +1788,3 @@ class RandomWidth(base_layer.BaseRandomLayer):\n     base_config = super(RandomWidth, self).get_config()\n     return dict(list(base_config.items()) + list(config.items()))\n \n-\n-def get_interpolation(interpolation):\n-  interpolation = interpolation.lower()\n-  if interpolation not in _RESIZE_METHODS:\n-    raise NotImplementedError(\n-        'Value not recognized for `interpolation`: {}. Supported values '\n-        'are: {}'.format(interpolation, _RESIZE_METHODS.keys()))\n-  return _RESIZE_METHODS[interpolation]\n\n@@ -31,4 +31,3 @@ from keras import backend\n from keras.preprocessing import image\n from keras.preprocessing import sequence\n from keras.preprocessing import text\n-from keras.utils import all_utils as utils\n\n@@ -40,7 +40,6 @@ import warnings\n from keras import backend\n from keras.utils import data_utils\n import numpy as np\n-import tensorflow.compat.v2 as tf\n from tensorflow.python.util.tf_export import keras_export\n \n try:\n@@ -68,122 +67,6 @@ if pil_image is not None:\n   }\n \n \n-@keras_export('keras.preprocessing.image.smart_resize', v1=[])\n-def smart_resize(x, size, interpolation='bilinear'):\n-  \"\"\"Resize images to a target size without aspect ratio distortion.\n-\n-  Warning: `tf.keras.preprocessing.image.smart_resize` is not recommended for\n-  new code. Prefer `tf.keras.layers.Resizing`, which provides the same\n-  functionality as a preprocessing layer and adds `tf.RaggedTensor` support. See\n-  the [preprocessing layer guide](\n-  https://www.tensorflow.org/guide/keras/preprocessing_layers)\n-  for an overview of preprocessing layers.\n-\n-  TensorFlow image datasets typically yield images that have each a different\n-  size. However, these images need to be batched before they can be\n-  processed by Keras layers. To be batched, images need to share the same height\n-  and width.\n-\n-  You could simply do:\n-\n-  ```python\n-  size = (200, 200)\n-  ds = ds.map(lambda img: tf.image.resize(img, size))\n-  ```\n-\n-  However, if you do this, you distort the aspect ratio of your images, since\n-  in general they do not all have the same aspect ratio as `size`. This is\n-  fine in many cases, but not always (e.g. for GANs this can be a problem).\n-\n-  Note that passing the argument `preserve_aspect_ratio=True` to `resize`\n-  will preserve the aspect ratio, but at the cost of no longer respecting the\n-  provided target size. Because `tf.image.resize` doesn't crop images,\n-  your output images will still have different sizes.\n-\n-  This calls for:\n-\n-  ```python\n-  size = (200, 200)\n-  ds = ds.map(lambda img: smart_resize(img, size))\n-  ```\n-\n-  Your output images will actually be `(200, 200)`, and will not be distorted.\n-  Instead, the parts of the image that do not fit within the target size\n-  get cropped out.\n-\n-  The resizing process is:\n-\n-  1. Take the largest centered crop of the image that has the same aspect ratio\n-  as the target size. For instance, if `size=(200, 200)` and the input image has\n-  size `(340, 500)`, we take a crop of `(340, 340)` centered along the width.\n-  2. Resize the cropped image to the target size. In the example above,\n-  we resize the `(340, 340)` crop to `(200, 200)`.\n-\n-  Args:\n-    x: Input image or batch of images (as a tensor or NumPy array). Must be in\n-      format `(height, width, channels)` or `(batch_size, height, width,\n-      channels)`.\n-    size: Tuple of `(height, width)` integer. Target size.\n-    interpolation: String, interpolation to use for resizing. Defaults to\n-      `'bilinear'`. Supports `bilinear`, `nearest`, `bicubic`, `area`,\n-      `lanczos3`, `lanczos5`, `gaussian`, `mitchellcubic`.\n-\n-  Returns:\n-    Array with shape `(size[0], size[1], channels)`. If the input image was a\n-    NumPy array, the output is a NumPy array, and if it was a TF tensor,\n-    the output is a TF tensor.\n-  \"\"\"\n-  if len(size) != 2:\n-    raise ValueError('Expected `size` to be a tuple of 2 integers, '\n-                     f'but got: {size}.')\n-  img = tf.convert_to_tensor(x)\n-  if img.shape.rank is not None:\n-    if img.shape.rank < 3 or img.shape.rank > 4:\n-      raise ValueError(\n-          'Expected an image array with shape `(height, width, channels)`, '\n-          'or `(batch_size, height, width, channels)`, but '\n-          f'got input with incorrect rank, of shape {img.shape}.')\n-  shape = tf.shape(img)\n-  height, width = shape[-3], shape[-2]\n-  target_height, target_width = size\n-  if img.shape.rank is not None:\n-    static_num_channels = img.shape[-1]\n-  else:\n-    static_num_channels = None\n-\n-  crop_height = tf.cast(\n-      tf.cast(width * target_height, 'float32') / target_width, 'int32')\n-  crop_width = tf.cast(\n-      tf.cast(height * target_width, 'float32') / target_height, 'int32')\n-\n-  # Set back to input height / width if crop_height / crop_width is not smaller.\n-  crop_height = tf.minimum(height, crop_height)\n-  crop_width = tf.minimum(width, crop_width)\n-\n-  crop_box_hstart = tf.cast(\n-      tf.cast(height - crop_height, 'float32') / 2, 'int32')\n-  crop_box_wstart = tf.cast(tf.cast(width - crop_width, 'float32') / 2, 'int32')\n-\n-  if img.shape.rank == 4:\n-    crop_box_start = tf.stack([0, crop_box_hstart, crop_box_wstart, 0])\n-    crop_box_size = tf.stack([-1, crop_height, crop_width, -1])\n-  else:\n-    crop_box_start = tf.stack([crop_box_hstart, crop_box_wstart, 0])\n-    crop_box_size = tf.stack([crop_height, crop_width, -1])\n-\n-  img = tf.slice(img, crop_box_start, crop_box_size)\n-  img = tf.image.resize(images=img, size=size, method=interpolation)\n-  # Apparent bug in resize_images_v2 may cause shape to be lost\n-  if img.shape.rank is not None:\n-    if img.shape.rank == 4:\n-      img.set_shape((None, None, None, static_num_channels))\n-    if img.shape.rank == 3:\n-      img.set_shape((None, None, static_num_channels))\n-  if isinstance(x, np.ndarray):\n-    return img.numpy()\n-  return img\n-\n-\n @keras_export('keras.utils.array_to_img',\n               'keras.preprocessing.image.array_to_img')\n def array_to_img(x, data_format=None, scale=True, dtype=None):\n\n@@ -83,44 +83,6 @@ def _generate_test_images(include_rgba=False,\n @test_utils.run_v2_only\n class TestImage(test_combinations.TestCase):\n \n-  def test_smart_resize(self):\n-    test_input = np.random.random((20, 40, 3))\n-    output = image.smart_resize(test_input, size=(50, 50))\n-    self.assertIsInstance(output, np.ndarray)\n-    self.assertListEqual(list(output.shape), [50, 50, 3])\n-    output = image.smart_resize(test_input, size=(10, 10))\n-    self.assertListEqual(list(output.shape), [10, 10, 3])\n-    output = image.smart_resize(test_input, size=(100, 50))\n-    self.assertListEqual(list(output.shape), [100, 50, 3])\n-    output = image.smart_resize(test_input, size=(5, 15))\n-    self.assertListEqual(list(output.shape), [5, 15, 3])\n-\n-  @parameterized.named_parameters(('size1', (50, 50)), ('size2', (10, 10)),\n-                                  ('size3', (100, 50)), ('size4', (5, 15)))\n-  def test_smart_resize_tf_dataset(self, size):\n-    test_input_np = np.random.random((2, 20, 40, 3))\n-    test_ds = tf.data.Dataset.from_tensor_slices(test_input_np)\n-\n-    resize = lambda img: image.smart_resize(img, size=size)\n-    test_ds = test_ds.map(resize)\n-    for sample in test_ds.as_numpy_iterator():\n-      self.assertIsInstance(sample, np.ndarray)\n-      self.assertListEqual(list(sample.shape), [size[0], size[1], 3])\n-\n-  def test_smart_resize_batch(self):\n-    img = np.random.random((2, 20, 40, 3))\n-    out = image.smart_resize(img, size=(20, 20))\n-    self.assertListEqual(list(out.shape), [2, 20, 20, 3])\n-    self.assertAllClose(out, img[:, :, 10:-10, :])\n-\n-  def test_smart_resize_errors(self):\n-    with self.assertRaisesRegex(ValueError, 'a tuple of 2 integers'):\n-      image.smart_resize(np.random.random((20, 20, 2)), size=(10, 5, 3))\n-    with self.assertRaisesRegex(ValueError, 'incorrect rank'):\n-      image.smart_resize(np.random.random((2, 4)), size=(10, 5))\n-    with self.assertRaisesRegex(ValueError, 'incorrect rank'):\n-      image.smart_resize(np.random.random((2, 4, 4, 5, 3)), size=(10, 5))\n-\n   def test_iterator_empty_directory(self):\n     # Testing with different batch sizes\n     for batch_size in [0, 32]:\n\n@@ -26,7 +26,7 @@ from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n from keras.layers.rnn import legacy_cells\n from keras.legacy_tf_layers import base as base_layer\n-from keras.utils import all_utils as utils\n+from keras import utils\n \n \n class KerasIntegrationTest(test_combinations.TestCase):\n\n@@ -0,0 +1,44 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Public Keras utilities.\"\"\"\n+# pylint: disable=g-bad-import-order\n+\n+from keras.utils.data_utils import get_file\n+from keras.utils.generic_utils import Progbar\n+from keras.utils.image_dataset import image_dataset_from_directory\n+from keras.utils.text_dataset import text_dataset_from_directory\n+from keras.utils.tf_utils import set_random_seed\n+from keras.utils.timeseries_dataset import timeseries_dataset_from_array\n+from keras.utils.vis_utils import model_to_dot\n+from keras.utils.vis_utils import plot_model\n+from keras.utils.np_utils import normalize\n+from keras.utils.np_utils import to_categorical\n+\n+# Sequence related\n+from keras.utils.data_utils import Sequence\n+from keras.utils.data_utils import GeneratorEnqueuer\n+from keras.utils.data_utils import OrderedEnqueuer\n+from keras.utils.data_utils import SequenceEnqueuer\n+\n+# Serialization related\n+from keras.utils.generic_utils import custom_object_scope\n+from keras.utils.generic_utils import CustomObjectScope\n+from keras.utils.generic_utils import deserialize_keras_object\n+from keras.utils.generic_utils import get_custom_objects\n+from keras.utils.generic_utils import serialize_keras_object\n+\n+# Internal\n+from keras.utils.layer_utils import get_source_inputs\n+\n\n@@ -1,41 +0,0 @@\n-# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-# ==============================================================================\n-\"\"\"Public Keras utilities.\n-\n-This module is used as a shortcut to access all the symbols. Those symbols was\n-exposed under __init__, and was causing some hourglass import issue.\n-\"\"\"\n-\n-# pylint: disable=unused-import\n-from keras.utils.data_utils import GeneratorEnqueuer\n-from keras.utils.data_utils import get_file\n-from keras.utils.data_utils import OrderedEnqueuer\n-from keras.utils.data_utils import Sequence\n-from keras.utils.data_utils import SequenceEnqueuer\n-from keras.utils.generic_utils import custom_object_scope\n-from keras.utils.generic_utils import CustomObjectScope\n-from keras.utils.generic_utils import deserialize_keras_object\n-from keras.utils.generic_utils import get_custom_objects\n-from keras.utils.generic_utils import Progbar\n-from keras.utils.generic_utils import serialize_keras_object\n-from keras.utils.image_dataset import image_dataset_from_directory\n-from keras.utils.layer_utils import get_source_inputs\n-from keras.utils.np_utils import normalize\n-from keras.utils.np_utils import to_categorical\n-from keras.utils.text_dataset import text_dataset_from_directory\n-from keras.utils.tf_utils import set_random_seed\n-from keras.utils.timeseries_dataset import timeseries_dataset_from_array\n-from keras.utils.vis_utils import model_to_dot\n-from keras.utils.vis_utils import plot_model\n\n@@ -18,9 +18,8 @@ import tensorflow.compat.v2 as tf\n # pylint: disable=g-classes-have-attributes\n \n import numpy as np\n-from keras.layers.preprocessing import image_preprocessing\n-from keras.preprocessing import image as keras_image_ops\n from keras.utils import dataset_utils\n+from keras.utils import image_utils\n from tensorflow.python.util.tf_export import keras_export\n \n \n@@ -184,7 +183,7 @@ def image_dataset_from_directory(directory,\n     raise ValueError(\n         '`color_mode` must be one of {\"rgb\", \"rgba\", \"grayscale\"}. '\n         f'Received: color_mode={color_mode}')\n-  interpolation = image_preprocessing.get_interpolation(interpolation)\n+  interpolation = image_utils.get_interpolation(interpolation)\n   dataset_utils.check_validation_split_arg(\n       validation_split, subset, shuffle, seed)\n \n@@ -263,8 +262,7 @@ def load_image(path, image_size, num_channels, interpolation,\n   img = tf.image.decode_image(\n       img, channels=num_channels, expand_animations=False)\n   if crop_to_aspect_ratio:\n-    img = keras_image_ops.smart_resize(img, image_size,\n-                                       interpolation=interpolation)\n+    img = image_utils.smart_resize(img, image_size, interpolation=interpolation)\n   else:\n     img = tf.image.resize(img, image_size, method=interpolation)\n   img.set_shape((image_size[0], image_size[1], num_channels))\n\n@@ -0,0 +1,161 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Utilities related to image handling.\"\"\"\n+# pylint: disable=g-direct-tensorflow-import\n+\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n+from tensorflow.python.util.tf_export import keras_export\n+\n+\n+ResizeMethod = tf.image.ResizeMethod\n+\n+_RESIZE_METHODS = {\n+    'bilinear': ResizeMethod.BILINEAR,\n+    'nearest': ResizeMethod.NEAREST_NEIGHBOR,\n+    'bicubic': ResizeMethod.BICUBIC,\n+    'area': ResizeMethod.AREA,\n+    'lanczos3': ResizeMethod.LANCZOS3,\n+    'lanczos5': ResizeMethod.LANCZOS5,\n+    'gaussian': ResizeMethod.GAUSSIAN,\n+    'mitchellcubic': ResizeMethod.MITCHELLCUBIC\n+}\n+\n+\n+@keras_export('keras.preprocessing.image.smart_resize', v1=[])\n+def smart_resize(x, size, interpolation='bilinear'):\n+  \"\"\"Resize images to a target size without aspect ratio distortion.\n+\n+  Warning: `tf.keras.preprocessing.image.smart_resize` is not recommended for\n+  new code. Prefer `tf.keras.layers.Resizing`, which provides the same\n+  functionality as a preprocessing layer and adds `tf.RaggedTensor` support. See\n+  the [preprocessing layer guide](\n+  https://www.tensorflow.org/guide/keras/preprocessing_layers)\n+  for an overview of preprocessing layers.\n+\n+  TensorFlow image datasets typically yield images that have each a different\n+  size. However, these images need to be batched before they can be\n+  processed by Keras layers. To be batched, images need to share the same height\n+  and width.\n+\n+  You could simply do:\n+\n+  ```python\n+  size = (200, 200)\n+  ds = ds.map(lambda img: tf.image.resize(img, size))\n+  ```\n+\n+  However, if you do this, you distort the aspect ratio of your images, since\n+  in general they do not all have the same aspect ratio as `size`. This is\n+  fine in many cases, but not always (e.g. for GANs this can be a problem).\n+\n+  Note that passing the argument `preserve_aspect_ratio=True` to `resize`\n+  will preserve the aspect ratio, but at the cost of no longer respecting the\n+  provided target size. Because `tf.image.resize` doesn't crop images,\n+  your output images will still have different sizes.\n+\n+  This calls for:\n+\n+  ```python\n+  size = (200, 200)\n+  ds = ds.map(lambda img: smart_resize(img, size))\n+  ```\n+\n+  Your output images will actually be `(200, 200)`, and will not be distorted.\n+  Instead, the parts of the image that do not fit within the target size\n+  get cropped out.\n+\n+  The resizing process is:\n+\n+  1. Take the largest centered crop of the image that has the same aspect ratio\n+  as the target size. For instance, if `size=(200, 200)` and the input image has\n+  size `(340, 500)`, we take a crop of `(340, 340)` centered along the width.\n+  2. Resize the cropped image to the target size. In the example above,\n+  we resize the `(340, 340)` crop to `(200, 200)`.\n+\n+  Args:\n+    x: Input image or batch of images (as a tensor or NumPy array). Must be in\n+      format `(height, width, channels)` or `(batch_size, height, width,\n+      channels)`.\n+    size: Tuple of `(height, width)` integer. Target size.\n+    interpolation: String, interpolation to use for resizing. Defaults to\n+      `'bilinear'`. Supports `bilinear`, `nearest`, `bicubic`, `area`,\n+      `lanczos3`, `lanczos5`, `gaussian`, `mitchellcubic`.\n+\n+  Returns:\n+    Array with shape `(size[0], size[1], channels)`. If the input image was a\n+    NumPy array, the output is a NumPy array, and if it was a TF tensor,\n+    the output is a TF tensor.\n+  \"\"\"\n+  if len(size) != 2:\n+    raise ValueError('Expected `size` to be a tuple of 2 integers, '\n+                     f'but got: {size}.')\n+  img = tf.convert_to_tensor(x)\n+  if img.shape.rank is not None:\n+    if img.shape.rank < 3 or img.shape.rank > 4:\n+      raise ValueError(\n+          'Expected an image array with shape `(height, width, channels)`, '\n+          'or `(batch_size, height, width, channels)`, but '\n+          f'got input with incorrect rank, of shape {img.shape}.')\n+  shape = tf.shape(img)\n+  height, width = shape[-3], shape[-2]\n+  target_height, target_width = size\n+  if img.shape.rank is not None:\n+    static_num_channels = img.shape[-1]\n+  else:\n+    static_num_channels = None\n+\n+  crop_height = tf.cast(\n+      tf.cast(width * target_height, 'float32') / target_width, 'int32')\n+  crop_width = tf.cast(\n+      tf.cast(height * target_width, 'float32') / target_height, 'int32')\n+\n+  # Set back to input height / width if crop_height / crop_width is not smaller.\n+  crop_height = tf.minimum(height, crop_height)\n+  crop_width = tf.minimum(width, crop_width)\n+\n+  crop_box_hstart = tf.cast(\n+      tf.cast(height - crop_height, 'float32') / 2, 'int32')\n+  crop_box_wstart = tf.cast(tf.cast(width - crop_width, 'float32') / 2, 'int32')\n+\n+  if img.shape.rank == 4:\n+    crop_box_start = tf.stack([0, crop_box_hstart, crop_box_wstart, 0])\n+    crop_box_size = tf.stack([-1, crop_height, crop_width, -1])\n+  else:\n+    crop_box_start = tf.stack([crop_box_hstart, crop_box_wstart, 0])\n+    crop_box_size = tf.stack([crop_height, crop_width, -1])\n+\n+  img = tf.slice(img, crop_box_start, crop_box_size)\n+  img = tf.image.resize(images=img, size=size, method=interpolation)\n+  # Apparent bug in resize_images_v2 may cause shape to be lost\n+  if img.shape.rank is not None:\n+    if img.shape.rank == 4:\n+      img.set_shape((None, None, None, static_num_channels))\n+    if img.shape.rank == 3:\n+      img.set_shape((None, None, static_num_channels))\n+  if isinstance(x, np.ndarray):\n+    return img.numpy()\n+  return img\n+\n+\n+def get_interpolation(interpolation):\n+  interpolation = interpolation.lower()\n+  if interpolation not in _RESIZE_METHODS:\n+    raise NotImplementedError(\n+        'Value not recognized for `interpolation`: {}. Supported values '\n+        'are: {}'.format(interpolation, _RESIZE_METHODS.keys()))\n+  return _RESIZE_METHODS[interpolation]\n+\n+\n\n@@ -0,0 +1,68 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests for image_utils.\"\"\"\n+\n+from absl.testing import parameterized\n+from keras.testing_infra import test_combinations\n+from keras.testing_infra import test_utils\n+from keras.utils import image_utils\n+import numpy as np\n+import tensorflow.compat.v2 as tf\n+\n+\n+@test_utils.run_v2_only\n+class TestImageUtils(test_combinations.TestCase):\n+\n+  def test_smart_resize(self):\n+    test_input = np.random.random((20, 40, 3))\n+    output = image_utils.smart_resize(test_input, size=(50, 50))\n+    self.assertIsInstance(output, np.ndarray)\n+    self.assertListEqual(list(output.shape), [50, 50, 3])\n+    output = image_utils.smart_resize(test_input, size=(10, 10))\n+    self.assertListEqual(list(output.shape), [10, 10, 3])\n+    output = image_utils.smart_resize(test_input, size=(100, 50))\n+    self.assertListEqual(list(output.shape), [100, 50, 3])\n+    output = image_utils.smart_resize(test_input, size=(5, 15))\n+    self.assertListEqual(list(output.shape), [5, 15, 3])\n+\n+  @parameterized.named_parameters(('size1', (50, 50)), ('size2', (10, 10)),\n+                                  ('size3', (100, 50)), ('size4', (5, 15)))\n+  def test_smart_resize_tf_dataset(self, size):\n+    test_input_np = np.random.random((2, 20, 40, 3))\n+    test_ds = tf.data.Dataset.from_tensor_slices(test_input_np)\n+\n+    resize = lambda img: image_utils.smart_resize(img, size=size)\n+    test_ds = test_ds.map(resize)\n+    for sample in test_ds.as_numpy_iterator():\n+      self.assertIsInstance(sample, np.ndarray)\n+      self.assertListEqual(list(sample.shape), [size[0], size[1], 3])\n+\n+  def test_smart_resize_batch(self):\n+    img = np.random.random((2, 20, 40, 3))\n+    out = image_utils.smart_resize(img, size=(20, 20))\n+    self.assertListEqual(list(out.shape), [2, 20, 20, 3])\n+    self.assertAllClose(out, img[:, :, 10:-10, :])\n+\n+  def test_smart_resize_errors(self):\n+    with self.assertRaisesRegex(ValueError, 'a tuple of 2 integers'):\n+      image_utils.smart_resize(np.random.random((20, 20, 2)), size=(10, 5, 3))\n+    with self.assertRaisesRegex(ValueError, 'incorrect rank'):\n+      image_utils.smart_resize(np.random.random((2, 4)), size=(10, 5))\n+    with self.assertRaisesRegex(ValueError, 'incorrect rank'):\n+      image_utils.smart_resize(np.random.random((2, 4, 4, 5, 3)), size=(10, 5))\n+\n+\n+if __name__ == '__main__':\n+  tf.test.main()\n\n@@ -21,7 +21,7 @@ import tensorflow.compat.v2 as tf\n import os\n import sys\n import re\n-from keras import activations\n+\n from keras.utils import io_utils\n from tensorflow.python.util.tf_export import keras_export\n \n@@ -256,7 +256,13 @@ def model_to_dot(model,\n     # Rebuild the label as a table including the layer's activation.\n     if (show_layer_activations and hasattr(layer, 'activation') and\n         layer.activation is not None):\n-      label = '{%s|%s}' % (label, activations.serialize(layer.activation))\n+      if hasattr(layer.activation, 'name'):\n+        activation_name = layer.activation.name\n+      elif hasattr(layer.activation, '__name__'):\n+        activation_name = layer.activation.__name__\n+      else:\n+        activation_name = str(layer.activation)\n+      label = '{%s|%s}' % (label, activation_name)\n \n     # Rebuild the label as a table including the layer's name.\n     if show_layer_names:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4352f38b114552f15d8e067fd2f029287b908488", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 16889 | Contributors (this commit): 125 | Commits (past 90d): 32 | Contributors (cumulative): 125 | DMM Complexity: None\n\nDIFF:\n@@ -1861,7 +1861,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n \n     if not self.run_eagerly:\n       predict_function = tf.function(\n-          predict_function, experimental_relax_shapes=False)\n+          predict_function, experimental_relax_shapes=True)\n     self.predict_function = predict_function\n \n     return self.predict_function\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#90aa76f6c48ec5252b2db7926ff060e262dfc1cc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1279 | Contributors (this commit): 7 | Commits (past 90d): 2 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -242,7 +242,8 @@ class TensorLikeDataAdapterTest(DataAdapterTestBase):\n     # Verify predicting on pandas vs numpy returns the same result\n     predict_1_pandas = model_1.predict(input_a_df)\n     predict_2_pandas = model_2.predict([input_a_df, input_b_df])\n-    predict_3_pandas = model_3.predict(input_a_df[0])\n+    predict_3_pandas = model_3.predict(input_a_df[[0]])\n+    predict_3_pandas_batch = model_3.predict_on_batch(input_a_df[0])\n \n     predict_1_numpy = model_1.predict(input_a_np)\n     predict_2_numpy = model_2.predict([input_a_np, input_b_np])\n@@ -250,6 +251,7 @@ class TensorLikeDataAdapterTest(DataAdapterTestBase):\n \n     self.assertAllClose(predict_1_numpy, predict_1_pandas)\n     self.assertAllClose(predict_2_numpy, predict_2_pandas)\n+    self.assertAllClose(predict_3_numpy, predict_3_pandas_batch)\n     self.assertAllClose(predict_3_numpy, predict_3_pandas)\n \n     # Extra ways to pass in dataframes\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c5b922d77f465e3841c94b69682f46f796202044", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 9 | Methods Changed: 6 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 33 | Churn Cumulative: 378 | Contributors (this commit): 4 | Commits (past 90d): 12 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -17,6 +17,7 @@\n from keras.optimizers.optimizer_experimental import optimizer\n from keras.utils import generic_utils\n import tensorflow.compat.v2 as tf\n+import re\n # pylint: disable=g-direct-tensorflow-import\n from tensorflow.python.util.tf_export import keras_export\n \n@@ -47,6 +48,11 @@ class AdamW(optimizer.Optimizer):\n       learning rate. Defaults to 0.001.\n     weight_decay: A `tf.Tensor`, floating point value. The weight decay.\n       Defaults to 0.004.\n+    exclude_from_weight_decay: List of regex patterns of\n+              variables excluded from weight decay. Variables whose name\n+              contain a substring matching the pattern will be excluded.\n+              Note `decay_var_list` in `minimize` or `apply_gradients` takes\n+              priority over `exclude_from_weight_decay` if specified.\n     beta_1: A float value or a constant float tensor, or a callable\n       that takes no arguments and returns the actual value to use. The\n       exponential decay rate for the 1st moment estimates. Defaults to 0.9.\n@@ -89,6 +95,7 @@ class AdamW(optimizer.Optimizer):\n   def __init__(self,\n                learning_rate=0.001,\n                weight_decay=0.004,\n+               exclude_from_weight_decay=None,\n                beta_1=0.9,\n                beta_2=0.999,\n                epsilon=1e-7,\n@@ -114,6 +121,7 @@ class AdamW(optimizer.Optimizer):\n         **kwargs)\n     self._learning_rate = self._build_learning_rate(learning_rate)\n     self.weight_decay = weight_decay\n+    self.exclude_from_weight_decay = exclude_from_weight_decay\n     self.beta_1 = beta_1\n     self.beta_2 = beta_2\n     self.epsilon = epsilon\n@@ -173,7 +181,7 @@ class AdamW(optimizer.Optimizer):\n     alpha = (lr * tf.sqrt(1 - beta_2_power) / (1 - beta_1_power))\n \n     # Apply step weight decay\n-    if self.weight_decay != 0:\n+    if self.weight_decay and self._do_use_weight_decay(variable):\n       wd = tf.cast(self.weight_decay, variable.dtype)\n       variable.assign_sub(variable * (1 - lr * wd))\n \n@@ -208,6 +216,7 @@ class AdamW(optimizer.Optimizer):\n     config.update({\n         'learning_rate': self._serialize_hyperparameter(self._learning_rate),\n         'weight_decay': self.weight_decay,\n+        \"exclude_from_weight_decay\": self.exclude_from_weight_decay,\n         'beta_1': self.beta_1,\n         'beta_2': self.beta_2,\n         'epsilon': self.epsilon,\n@@ -215,6 +224,24 @@ class AdamW(optimizer.Optimizer):\n     })\n     return config\n \n+  def _do_use_weight_decay(self, variable):\n+    \"\"\"Whether to use L2 weight decay for `var`.\"\"\"\n+    if self.exclude_from_weight_decay is None:\n+      return True\n+\n+    print(variable.ref())\n+    print(self.exclude_from_weight_decay)\n+\n+    return not self.is_variable_matched_by_regexes(variable.ref(), self.exclude_from_weight_decay)\n+\n+  def is_variable_matched_by_regexes(variable, regexes):\n+    \"\"\"Whether variable is matched in regexes list by its name.\"\"\"\n+    if regexes:\n+        var_name = variable.name\n+        for r in regexes:\n+            if re.search(r, var_name):\n+                return True\n+    return False\n \n AdamW.__doc__ = AdamW.__doc__.replace(\n     '{{base_optimizer_keyword_args}}', optimizer.base_optimizer_keyword_args)\n\n@@ -56,7 +56,7 @@ adam_new_fn = tf.__internal__.test.combinations.NamedObject(\n adamax_new_fn = tf.__internal__.test.combinations.NamedObject(\n     \"experimentaladamax\", lambda: adamax_new.Adamax(0.002))\n adamw_new_fn = tf.__internal__.test.combinations.NamedObject(\n-    \"experimentaladamw\", lambda: adamw_new.AdamW(0.002, weight_decay=0.004))\n+    \"experimentaladamw\", lambda: adamw_new.AdamW(0.002, weight_decay=0.004, exclude_from_weight_decay=[\"bias\"]))\n ftrl_new_fn = tf.__internal__.test.combinations.NamedObject(\n     \"experimentalftrl\", lambda: ftrl_new.Ftrl(0.002))\n nadam_new_fn = tf.__internal__.test.combinations.NamedObject(\n@@ -313,7 +313,7 @@ class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n     optimizer_1 = optimizer_fn()\n     optimizer_2 = optimizer_fn()\n     x1 = tf.Variable(np.ones([5]), dtype=tf.float64)\n-    x2 = tf.Variable(np.ones([5]), dtype=tf.float64)\n+    x2 = tf.Variable(np.ones([5]), dtype=tf.float64, name=\"bias\")\n     grads = tf.convert_to_tensor([0, 1., 1.5, 0, 0], dtype=tf.float64)\n     sparse_grads = tf.IndexedSlices(\n         tf.convert_to_tensor([1., 1.5], dtype=tf.float64),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#880cfc01634eef161e74e07f1df59cd5f137e899", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 77 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -59,8 +59,9 @@ class ThresholdedReLU(Layer):\n     self.theta = backend.cast_to_floatx(theta)\n \n   def call(self, inputs):\n-    theta = tf.cast(self.theta, inputs.dtype)\n-    return inputs * tf.cast(tf.greater(inputs, theta), inputs.dtype)\n+    dtype = getattr(inputs, 'dtype', tf.keras.backend.floatx())\n+    theta = tf.cast(self.theta, dtype)\n+    return inputs * tf.cast(tf.greater(inputs, theta), dtype)\n \n   def get_config(self):\n     config = {'theta': float(self.theta)}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ea07a94bb71b10e1729cdf64b1ad63a269815d0b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 30 | Files Changed: 2 | Hunks: 13 | Methods Changed: 12 | Complexity Δ (Sum/Max): -2/3 | Churn Δ: 43 | Churn Cumulative: 421 | Contributors (this commit): 4 | Commits (past 90d): 14 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -48,11 +48,6 @@ class AdamW(optimizer.Optimizer):\n       learning rate. Defaults to 0.001.\n     weight_decay: A `tf.Tensor`, floating point value. The weight decay.\n       Defaults to 0.004.\n-    exclude_from_weight_decay: List of regex patterns of\n-              variables excluded from weight decay. Variables whose name\n-              contain a substring matching the pattern will be excluded.\n-              Note `decay_var_list` in `minimize` or `apply_gradients` takes\n-              priority over `exclude_from_weight_decay` if specified.\n     beta_1: A float value or a constant float tensor, or a callable\n       that takes no arguments and returns the actual value to use. The\n       exponential decay rate for the 1st moment estimates. Defaults to 0.9.\n@@ -95,7 +90,6 @@ class AdamW(optimizer.Optimizer):\n   def __init__(self,\n                learning_rate=0.001,\n                weight_decay=0.004,\n-               exclude_from_weight_decay=None,\n                beta_1=0.9,\n                beta_2=0.999,\n                epsilon=1e-7,\n@@ -121,7 +115,6 @@ class AdamW(optimizer.Optimizer):\n         **kwargs)\n     self._learning_rate = self._build_learning_rate(learning_rate)\n     self.weight_decay = weight_decay\n-    self.exclude_from_weight_decay = exclude_from_weight_decay\n     self.beta_1 = beta_1\n     self.beta_2 = beta_2\n     self.epsilon = epsilon\n@@ -131,7 +124,7 @@ class AdamW(optimizer.Optimizer):\n       raise ValueError('Missing value of `weight_decay` which is required and'\n                        ' must be a float value.')\n \n-  def build(self, var_list):\n+  def build(self, var_list, exclude_from_weight_decay=None):\n     \"\"\"Initialize optimizer variables.\n \n     AdamW optimizer has 3 types of variables: momentums, velocities and\n@@ -144,6 +137,7 @@ class AdamW(optimizer.Optimizer):\n     if hasattr(self, '_built') and self._built:\n       return\n     self._built = True\n+    self._exclude_from_weight_decay = exclude_from_weight_decay\n     self._momentums = []\n     self._velocities = []\n     for var in var_list:\n@@ -181,7 +175,7 @@ class AdamW(optimizer.Optimizer):\n     alpha = (lr * tf.sqrt(1 - beta_2_power) / (1 - beta_1_power))\n \n     # Apply step weight decay\n-    if self.weight_decay and self._do_use_weight_decay(variable):\n+    if self.weight_decay and variable not in self._exclude_from_weight_decay:\n       wd = tf.cast(self.weight_decay, variable.dtype)\n       variable.assign_sub(variable * (1 - lr * wd))\n \n@@ -216,7 +210,6 @@ class AdamW(optimizer.Optimizer):\n     config.update({\n         'learning_rate': self._serialize_hyperparameter(self._learning_rate),\n         'weight_decay': self.weight_decay,\n-        \"exclude_from_weight_decay\": self.exclude_from_weight_decay,\n         'beta_1': self.beta_1,\n         'beta_2': self.beta_2,\n         'epsilon': self.epsilon,\n@@ -224,24 +217,8 @@ class AdamW(optimizer.Optimizer):\n     })\n     return config\n \n-  def _do_use_weight_decay(self, variable):\n-    \"\"\"Whether to use L2 weight decay for `var`.\"\"\"\n-    if self.exclude_from_weight_decay is None:\n-      return True\n-\n-    print(variable.ref())\n-    print(self.exclude_from_weight_decay)\n-\n-    return not self.is_variable_matched_by_regexes(variable.ref(), self.exclude_from_weight_decay)\n-\n-  def is_variable_matched_by_regexes(variable, regexes):\n-    \"\"\"Whether variable is matched in regexes list by its name.\"\"\"\n-    if regexes:\n-        var_name = variable.name\n-        for r in regexes:\n-            if re.search(r, var_name):\n-                return True\n-    return False\n+  def exclude_from_weight_decay(self, var_list):\n+    self._exclude_from_weight_decay = var_list\n \n AdamW.__doc__ = AdamW.__doc__.replace(\n     '{{base_optimizer_keyword_args}}', optimizer.base_optimizer_keyword_args)\n\n@@ -56,7 +56,7 @@ adam_new_fn = tf.__internal__.test.combinations.NamedObject(\n adamax_new_fn = tf.__internal__.test.combinations.NamedObject(\n     \"experimentaladamax\", lambda: adamax_new.Adamax(0.002))\n adamw_new_fn = tf.__internal__.test.combinations.NamedObject(\n-    \"experimentaladamw\", lambda: adamw_new.AdamW(0.002, weight_decay=0.004, exclude_from_weight_decay=[\"bias\"]))\n+    \"experimentaladamw\", lambda: adamw_new.AdamW(0.002, weight_decay=0.004))\n ftrl_new_fn = tf.__internal__.test.combinations.NamedObject(\n     \"experimentalftrl\", lambda: ftrl_new.Ftrl(0.002))\n nadam_new_fn = tf.__internal__.test.combinations.NamedObject(\n@@ -281,6 +281,8 @@ class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n         [keras.layers.Input(shape=(1,)),\n          keras.layers.Dense(1)])\n     optimizer = optimizer_fn()\n+    if type(optimizer) is adamw_new.AdamW:\n+      optimizer.exclude_from_weight_decay(model.layers[-1].weights[-1])\n     optimizer.clipnorm = 0.1\n     x = tf.expand_dims(tf.convert_to_tensor([1, 1, 1, 0, 0, 0]), axis=1)\n     y = tf.expand_dims(tf.convert_to_tensor([1, 1, 1, 0, 0, 0]), axis=1)\n@@ -313,7 +315,7 @@ class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n     optimizer_1 = optimizer_fn()\n     optimizer_2 = optimizer_fn()\n     x1 = tf.Variable(np.ones([5]), dtype=tf.float64)\n-    x2 = tf.Variable(np.ones([5]), dtype=tf.float64, name=\"bias\")\n+    x2 = tf.Variable(np.ones([5]), dtype=tf.float64)\n     grads = tf.convert_to_tensor([0, 1., 1.5, 0, 0], dtype=tf.float64)\n     sparse_grads = tf.IndexedSlices(\n         tf.convert_to_tensor([1., 1.5], dtype=tf.float64),\n@@ -380,6 +382,8 @@ class DistributedTrainingTest(tf.test.TestCase, parameterized.TestCase):\n           [keras.layers.Input(shape=(1,)),\n            keras.layers.Dense(1)])\n       optimizer = optimizer_fn()\n+      if type(optimizer) is adamw_new.AdamW:\n+        optimizer.exclude_from_weight_decay(model.layers[-1].weights[-1])\n       x = tf.expand_dims(tf.convert_to_tensor([1, 1, 1, 0, 0, 0]), axis=1)\n       y = tf.expand_dims(tf.convert_to_tensor([1, 1, 1, 0, 0, 0]), axis=1)\n       model.compile(loss=\"mse\", optimizer=optimizer)\n@@ -404,6 +408,8 @@ class DistributedTrainingTest(tf.test.TestCase, parameterized.TestCase):\n           [keras.layers.Input(shape=(1,)),\n            keras.layers.Dense(1)])\n       optimizer = optimizer_fn()\n+      if type(optimizer) is adamw_new.AdamW:\n+        optimizer.exclude_from_weight_decay(model.layers[-1].weights[-1])\n \n       def per_worker_dataset_fn():\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5209eb5c0aac31811e355fc9ba24fe0beb0fa135", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 315 | Contributors (this commit): 4 | Commits (past 90d): 6 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -17,7 +17,6 @@\n from keras.optimizers.optimizer_experimental import optimizer\n from keras.utils import generic_utils\n import tensorflow.compat.v2 as tf\n-import re\n # pylint: disable=g-direct-tensorflow-import\n from tensorflow.python.util.tf_export import keras_export\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#506df8753ff6d2b55c9a99627acc6e58cbada775", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 14 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -98,8 +98,8 @@ def image_dataset_from_directory(directory,\n     batch_size: Size of the batches of data. Default: 32.\n       If `None`, the data will not be batched\n       (the dataset will yield individual samples).\n-    image_size: Size to resize images to after they are read from disk.\n-        Defaults to `(256, 256)`.\n+    image_size: Size to resize images to after they are read from disk,\n+        specified as `(height, width)`. Defaults to `(256, 256)`.\n         Since the pipeline processes batches of images that must all have\n         the same size, this must be provided.\n     shuffle: Whether to shuffle the data. Default: True.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c216e4cd9fc9fbb4478bae603d7e9242d7f9ff35", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 12 | Churn Cumulative: 327 | Contributors (this commit): 4 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: 0.7\n\nDIFF:\n@@ -136,7 +136,12 @@ class AdamW(optimizer.Optimizer):\n     if hasattr(self, '_built') and self._built:\n       return\n     self._built = True\n+\n+    if exclude_from_weight_decay == None:\n+      self._exclude_from_weight_decay = []\n+    else:\n       self._exclude_from_weight_decay = exclude_from_weight_decay\n+\n     self._momentums = []\n     self._velocities = []\n     for var in var_list:\n@@ -217,7 +222,14 @@ class AdamW(optimizer.Optimizer):\n     return config\n \n   def exclude_from_weight_decay(self, var_list):\n+    if self._built:\n+      if var_list == None:\n+        self._exclude_from_weight_decay = []\n+      else:\n         self._exclude_from_weight_decay = var_list\n+    else:\n+      raise ValueError('This optimizer has not yet been built. '\n+                       'Build the optimizer first and than use `exclude_from_weight_decay()`')\n \n AdamW.__doc__ = AdamW.__doc__.replace(\n     '{{base_optimizer_keyword_args}}', optimizer.base_optimizer_keyword_args)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#62cd177f7d8da4b6dc255a2202e3c6f36d8f1797", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 80 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -59,8 +59,7 @@ class ThresholdedReLU(Layer):\n     self.theta = backend.cast_to_floatx(theta)\n \n   def call(self, inputs):\n-    dtype = getattr(inputs, 'dtype', tf.keras.backend.floatx())\n-    theta = tf.cast(self.theta, dtype)\n+    dtype = self.compute_dtype\n     return inputs * tf.cast(tf.greater(inputs, theta), dtype)\n \n   def get_config(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b5414dcd4c4883912c8f7ada682c1e428ff14b82", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 82 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -60,7 +60,7 @@ class ThresholdedReLU(Layer):\n \n   def call(self, inputs):\n     dtype = self.compute_dtype\n-    return inputs * tf.cast(tf.greater(inputs, theta), dtype)\n+    return inputs * tf.cast(tf.greater(inputs, self.theta), dtype)\n \n   def get_config(self):\n     config = {'theta': float(self.theta)}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
