{"custom_id": "keras#e31d26b33f420a7bc2610838ae5090ebce4cc4c4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 2 | Churn Cumulative: 4130 | Contributors (this commit): 34 | Commits (past 90d): 26 | Contributors (cumulative): 34 | DMM Complexity: 0.0\n\nDIFF:\n@@ -150,8 +150,10 @@ def model_from_config(config, custom_objects={}):\n     model = container_from_config(config, custom_objects=custom_objects)\n     if model_name == 'Graph':\n         model.__class__ = Graph\n+        model.name = model_name\n     elif model_name == 'Sequential':\n         model.__class__ = Sequential\n+        model.name = model_name\n \n     if 'optimizer' in config:\n         # if it has an optimizer, the model is assumed to be compiled\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2091bfe91187dc7903bea07cdf070f81ea1bdf56", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 84 | Lines Deleted: 97 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/2 | Churn Δ: 181 | Churn Cumulative: 278 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -1,97 +0,0 @@\n-'''Example script to predict sequence using stateful rnns.\n-At least 10 epochs are required before the generated text\n-starts sounding coherent.\n-'''\n-\n-import numpy as np\n-import matplotlib.pyplot as mpl\n-from keras.models import Sequential\n-from keras.layers.core import Dense\n-from keras.layers.recurrent import LSTM\n-\n-\n-# since we are using stateful rnn tsteps can be set to 1\n-tsteps = 1\n-batch_size = 25\n-epochs = 25\n-# number of elements ahead that are used to make the prediction\n-lahead = 1\n-\n-\n-def gen_cosine_amp(amp=100, period=25, x0=0, xn=50000, step=1, k=0.0001):\n-    \"\"\"\n-    Generates an absolute cosine time series with the amplitude exponentially\n-    decreasing\n-\n-    Keyword arguments:\n-    amp -- amplitude of the cosine function\n-    period -- period of the cosine function\n-    x0 -- initial x of the time series\n-    xn -- final x of the time series\n-    step -- step of the time series discretization\n-    k -- exponential rate\n-    \"\"\"\n-    cos = np.zeros(((xn - x0) * step, 1, 1))\n-    for i in range(len(cos)):\n-        idx = x0 + i * step\n-        cos[i, 0, 0] = amp * np.cos(idx / (2 * np.pi * period))\n-        cos[i, 0, 0] = cos[i, 0, 0] * np.exp(-k * idx)\n-    return cos\n-\n-\n-print('Creating Data')\n-cos = gen_cosine_amp()\n-print('Input shape:')\n-print(cos.shape)\n-print('Calculating expected predicted_out')\n-expected_out = np.zeros((len(cos), 1))\n-for i in range(len(cos) - lahead):\n-    expected_out[i, 0] = np.mean(cos[i + 1:i + lahead + 1])\n-\n-print('Output shape')\n-print(expected_out.shape)\n-\n-print('Creating Model')\n-model = Sequential()\n-model.add(\n-    LSTM(\n-        50,\n-        batch_input_shape=(\n-            batch_size,\n-            tsteps,\n-            1),\n-        return_sequences=True,\n-        stateful=True))\n-model.add(\n-    LSTM(\n-        50,\n-        batch_input_shape=(\n-            batch_size,\n-            tsteps,\n-            1),\n-        return_sequences=False,\n-        stateful=True))\n-model.add(Dense(1))\n-model.compile(loss='rmse', optimizer='rmsprop')\n-\n-print('Training')\n-for i in range(epochs):\n-    model.fit(\n-        cos,\n-        expected_out,\n-        batch_size=batch_size,\n-        verbose=1,\n-        nb_epoch=1)\n-    model.reset_states()\n-\n-print('Predicting')\n-predicted_out = model.predict(cos, batch_size=batch_size)\n-\n-print('Ploting Results')\n-mpl.subplot(2, 1, 1)\n-mpl.plot(expected_out)\n-mpl.title('Expected')\n-mpl.subplot(2, 1, 2)\n-mpl.plot(predicted_out)\n-mpl.title('Predicted')\n-mpl.show()\n\n@@ -0,0 +1,84 @@\n+'''Example script showing how to use stateful RNNs\n+to model long sequences efficiently.\n+'''\n+from __future__ import print_function\n+import numpy as np\n+import matplotlib.pyplot as plt\n+from keras.models import Sequential\n+from keras.layers.core import Dense\n+from keras.layers.recurrent import LSTM\n+\n+\n+# since we are using stateful rnn tsteps can be set to 1\n+tsteps = 1\n+batch_size = 25\n+epochs = 25\n+# number of elements ahead that are used to make the prediction\n+lahead = 1\n+\n+\n+def gen_cosine_amp(amp=100, period=25, x0=0, xn=50000, step=1, k=0.0001):\n+    \"\"\"Generates an absolute cosine time series with the amplitude\n+    exponentially decreasing\n+\n+    Arguments:\n+        amp: amplitude of the cosine function\n+        period: period of the cosine function\n+        x0: initial x of the time series\n+        xn: final x of the time series\n+        step: step of the time series discretization\n+        k: exponential rate\n+    \"\"\"\n+    cos = np.zeros(((xn - x0) * step, 1, 1))\n+    for i in range(len(cos)):\n+        idx = x0 + i * step\n+        cos[i, 0, 0] = amp * np.cos(idx / (2 * np.pi * period))\n+        cos[i, 0, 0] = cos[i, 0, 0] * np.exp(-k * idx)\n+    return cos\n+\n+\n+print('Generating Data')\n+cos = gen_cosine_amp()\n+print('Input shape:', cos.shape)\n+\n+expected_output = np.zeros((len(cos), 1))\n+for i in range(len(cos) - lahead):\n+    expected_output[i, 0] = np.mean(cos[i + 1:i + lahead + 1])\n+\n+print('Output shape')\n+print(expected_output.shape)\n+\n+print('Creating Model')\n+model = Sequential()\n+model.add(LSTM(50,\n+               batch_input_shape=(batch_size, tsteps, 1),\n+               return_sequences=True,\n+               stateful=True))\n+model.add(LSTM(50,\n+               batch_input_shape=(batch_size, tsteps, 1),\n+               return_sequences=False,\n+               stateful=True))\n+model.add(Dense(1))\n+model.compile(loss='rmse', optimizer='rmsprop')\n+\n+print('Training')\n+for i in range(epochs):\n+    print('Epoch', i, '/', epochs)\n+    model.fit(cos,\n+              expected_output,\n+              batch_size=batch_size,\n+              verbose=1,\n+              nb_epoch=1)\n+    model.reset_states()\n+\n+print('Predicting')\n+predicted_output = model.predict(cos, batch_size=batch_size)\n+\n+print('Ploting Results')\n+plt.subplot(2, 1, 1)\n+plt.plot(expected_output)\n+plt.title('Expected')\n+plt.subplot(2, 1, 2)\n+plt.plot(predicted_output)\n+plt.title('Predicted')\n+plt.show()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#34c54cb19c51c6345f2bcbcc109b75e9f7bf32f6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 146 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -65,7 +65,7 @@ class GaussianDropout(MaskedLayer):\n             # self.p refers to drop probability rather than\n             # retain probability (as in paper), for consistency\n             X *= K.random_normal(shape=K.shape(X), mean=1.0,\n-                                 std=self.p / (1.0 - self.p))\n+                                 std=K.sqrt(self.p / (1.0 - self.p)))\n         return X\n \n     def get_config(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#73f1ef2e952980cefc541642d66cb3e102868148", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 13 | Files Changed: 6 | Hunks: 10 | Methods Changed: 8 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 12299 | Contributors (this commit): 49 | Commits (past 90d): 214 | Contributors (cumulative): 81 | DMM Complexity: 0.0\n\nDIFF:\n@@ -11,7 +11,6 @@ def softmax(x):\n         def step(x, states):\n             return K.softmax(x), []\n         last_output, outputs, states = K.rnn(step, x,\n-                                             K.shape(x)[-1],\n                                              [],\n                                              mask=None)\n         return outputs\n\n@@ -388,7 +388,7 @@ def gradients(loss, variables):\n \n # CONTROL FLOW\n \n-def rnn(step_function, inputs, output_dim, initial_states,\n+def rnn(step_function, inputs, initial_states,\n         go_backwards=False, mask=None):\n     '''Iterates over the time dimension of a tensor.\n \n@@ -406,9 +406,6 @@ def rnn(step_function, inputs, output_dim, initial_states,\n             output: tensor with shape (samples, ...) (no time dimension),\n             new_states: list of tensors, same length and shapes\n                 as 'states'.\n-    output_dim:\n-        Number of output dimensions (for tensorflow back-end can safely be set\n-        to None, it will be inferred automatically)\n     initial_states: tensor with shape (samples, ...) (no time dimension),\n         containing the initial values for the states used in\n         the step function.\n\n@@ -403,7 +403,7 @@ def gradients(loss, variables):\n \n # CONTROL FLOW\n \n-def rnn(step_function, inputs, output_dim, initial_states,\n+def rnn(step_function, inputs, initial_states,\n         go_backwards=False, mask=None):\n     '''Iterates over the time dimension of a tensor.\n \n@@ -421,8 +421,6 @@ def rnn(step_function, inputs, output_dim, initial_states,\n             output: tensor with shape (samples, ...) (no time dimension),\n             new_states: list of tensors, same length and shapes\n                 as 'states'.\n-    output_dim:\n-        Number of output dimensions\n     initial_states: tensor with shape (samples, ...) (no time dimension),\n         containing the initial values for the states used in\n         the step function.\n@@ -457,7 +455,7 @@ def rnn(step_function, inputs, output_dim, initial_states,\n         return [output] + return_states\n \n     # build an all-zero tensor of shape (samples, output_dim)\n-    initial_output = T.zeros((inputs.shape[1], output_dim))\n+    initial_output = step_function(inputs[0], initial_states)[0] * 0\n     # Theano gets confused by broadcasting patterns in the scan op\n     initial_output = T.unbroadcast(initial_output, 0, 1)\n \n\n@@ -1118,7 +1118,6 @@ class TimeDistributedDense(MaskedLayer):\n             return output, []\n \n         last_output, outputs, states = K.rnn(step, X,\n-                                             output_dim=self.output_dim,\n                                              initial_states=[],\n                                              mask=None)\n         outputs = self.activation(outputs)\n\n@@ -140,7 +140,7 @@ class Recurrent(MaskedLayer):\n         else:\n             initial_states = self.get_initial_states(X)\n \n-        last_output, outputs, states = K.rnn(self.step, X, self.output_dim,\n+        last_output, outputs, states = K.rnn(self.step, X,\n                                              initial_states,\n                                              go_backwards=self.go_backwards,\n                                              mask=mask)\n\n@@ -225,7 +225,6 @@ class TestBackend(object):\n         inputs = KTH.variable(input_val)\n         initial_states = [KTH.variable(init_state_val)]\n         last_output, outputs, new_states = KTH.rnn(th_rnn_step_fn, inputs,\n-                                                   output_dim,\n                                                    initial_states,\n                                                    go_backwards=False,\n                                                    mask=None)\n@@ -238,7 +237,6 @@ class TestBackend(object):\n         inputs = KTF.variable(input_val)\n         initial_states = [KTF.variable(init_state_val)]\n         last_output, outputs, new_states = KTF.rnn(tf_rnn_step_fn, inputs,\n-                                                   output_dim,\n                                                    initial_states,\n                                                    go_backwards=False,\n                                                    mask=None)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#05dcfe15fe94768cd31114486747edfd6381d09c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 7 | Churn Cumulative: 138 | Contributors (this commit): 6 | Commits (past 90d): 4 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -41,7 +41,7 @@ def one_hot(text, n, filters=base_filter(), lower=True, split=\" \"):\n \n class Tokenizer(object):\n     def __init__(self, nb_words=None, filters=base_filter(),\n-                 lower=True, split=' '):\n+                 lower=True, split=' ', char_level=False):\n         '''The class allows to vectorize a text corpus, by turning each\n         text into either a sequence of integers (each integer being the index\n         of a token in a dictionary) or into a vector where the coefficient\n@@ -71,6 +71,7 @@ class Tokenizer(object):\n         self.lower = lower\n         self.nb_words = nb_words\n         self.document_count = 0\n+        self.char_level = char_level\n \n     def fit_on_texts(self, texts):\n         '''\n@@ -83,7 +84,7 @@ class Tokenizer(object):\n         self.document_count = 0\n         for text in texts:\n             self.document_count += 1\n-            seq = text_to_word_sequence(text, self.filters, self.lower, self.split)\n+            seq = text if self.char_level else text_to_word_sequence(text, self.filters, self.lower, self.split)\n             for w in seq:\n                 if w in self.word_counts:\n                     self.word_counts[w] += 1\n@@ -142,7 +143,7 @@ class Tokenizer(object):\n         '''\n         nb_words = self.nb_words\n         for text in texts:\n-            seq = text_to_word_sequence(text, self.filters, self.lower, self.split)\n+            seq = text if self.char_level else text_to_word_sequence(text, self.filters, self.lower, self.split)\n             vect = []\n             for w in seq:\n                 i = self.word_index.get(w)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#371dcc9071e7678c308ad09a85e3e027e9d8bdba", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 139 | Contributors (this commit): 6 | Commits (past 90d): 5 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -56,6 +56,7 @@ class Tokenizer(object):\n                 tabs and line breaks, minus the `'` character.\n             lower: boolean. Whether to convert the texts to lowercase.\n             split: character or string to use for token splitting.\n+            char_level: if True, every character will be treated as a word.\n \n         By default, all punctuation is removed, turning the texts into\n         space-separated sequences of words\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ace7b7fe7f34ae02df078f0a92b4b37be7bc3ff9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 1846 | Contributors (this commit): 10 | Commits (past 90d): 57 | Contributors (cumulative): 15 | DMM Complexity: 0.5\n\nDIFF:\n@@ -427,7 +427,10 @@ def rnn(step_function, inputs, output_dim, initial_states,\n         new_states: list of tensors, latest states returned by\n             the step function, of shape (samples, ...).\n     '''\n-    inputs = tf.transpose(inputs, (1, 0, 2))\n+    ndim = len(inputs.get_shape())\n+    assert ndim >= 3, \"Input should be at least 3D.\"\n+    axes = [1, 0] + range(2, ndim)\n+    inputs = tf.transpose(inputs, (axes))\n     input_list = tf.unpack(inputs)\n     if mask is None:\n         mask = ones_like(tf.slice(inputs, [0, 0, 0], [-1, -1, 1]))\n@@ -482,7 +485,8 @@ def rnn(step_function, inputs, output_dim, initial_states,\n     outputs = tf.pack(successive_outputs)\n     new_states = successive_states[-1]\n \n-    outputs = tf.transpose(outputs, (1, 0, 2))\n+    axes = [1, 0] + range(2, len(outputs.get_shape()))\n+    outputs = tf.transpose(outputs, axes)\n     return last_output, outputs, new_states\n \n \n\n@@ -441,7 +441,10 @@ def rnn(step_function, inputs, output_dim, initial_states,\n         new_states: list of tensors, latest states returned by\n             the step function, of shape (samples, ...).\n     '''\n-    inputs = inputs.dimshuffle((1, 0, 2))\n+    ndim = inputs.ndim\n+    assert ndim >= 3, \"Input should be at least 3D.\"\n+    axes = [1, 0] + range(2, ndim)\n+    inputs = inputs.dimshuffle(axes)\n     if mask is None:\n         mask = expand_dims(ones_like(T.sum(inputs, axis=-1)))\n     else:\n@@ -478,7 +481,8 @@ def rnn(step_function, inputs, output_dim, initial_states,\n     outputs = T.squeeze(outputs)\n     last_output = outputs[-1]\n \n-    outputs = outputs.dimshuffle((1, 0, 2))\n+    axes = [1, 0] + range(2, outputs.ndim)\n+    outputs = outputs.dimshuffle(axes)\n     states = [T.squeeze(state[-1]) for state in states]\n     return last_output, outputs, states\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d9c4c02601954cff2991436c910de31707c4417c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 11 | Files Changed: 1 | Hunks: 9 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 18 | Churn Cumulative: 80 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -5,9 +5,8 @@ import numpy as np\n import os\n import shutil\n \n-def setup_function(func):\n-    np.random.seed(1337)\n \n+def setup_function(func):\n     os.mkdir('test_images')\n     os.mkdir('test_images/rgb')\n     os.mkdir('test_images/gsc')\n@@ -24,12 +23,12 @@ def setup_function(func):\n         im = Image.fromarray(imarray.astype('uint8').squeeze()).convert('L')\n         im.save('test_images/gsc/gsc_test_image_'+str(n)+'.png')\n \n+\n def teardown_function(func):\n     shutil.rmtree('test_images')\n \n-def test_image_data_generator():\n-    np.random.seed(1337)\n \n+def test_image_data_generator():\n     for color_mode in ['gsc', 'rgb']:\n         file_list = list_pictures('test_images/' + color_mode)\n         img_list = []\n@@ -42,21 +41,18 @@ def test_image_data_generator():\n             samplewise_center=True,\n             featurewise_std_normalization=True,\n             samplewise_std_normalization=True,\n-\n             zca_whitening=True,\n             rotation_range=90.,\n             width_shift_range=10.,\n             height_shift_range=10.,\n             horizontal_flip=True,\n-            vertical_flip=True\n-        )\n-\n+            vertical_flip=True)\n         generator.fit(images, augment=True)\n \n-        for x,y in generator.flow(images,np.arange(images.shape[0]), shuffle=True, save_to_dir='test_images'):\n+        for x, y in generator.flow(images, np.arange(images.shape[0]),\n+                                   shuffle=True, save_to_dir='test_images'):\n             assert x.shape[1:] == images.shape[1:]\n-            # TODO: make sure the normalization is working as inteded\n-\n+            break\n \n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0300ae2f4c0f5f578f3de3ccf1886378033e6894", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 1855 | Contributors (this commit): 10 | Commits (past 90d): 59 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -411,8 +411,8 @@ def rnn(step_function, inputs, initial_states,\n         the step function.\n     go_backwards: boolean. If True, do the iteration over\n         the time dimension in reverse order.\n-    mask: binary tensor with shape (samples, time, 1), with a zero for every element\n-        that is masked.\n+    mask: binary tensor with shape (samples, time, 1),\n+        with a zero for every element that is masked.\n \n     Returns\n     -------\n\n@@ -9,6 +9,7 @@ from .common import _FLOATX, _EPSILON\n # INTERNAL UTILS\n theano.config.floatX = _FLOATX\n \n+\n def _on_gpu():\n     '''Return whether the session is set to\n     run on GPU or not (i.e. on CPU).\n@@ -426,8 +427,8 @@ def rnn(step_function, inputs, initial_states,\n         the step function.\n     go_backwards: boolean. If True, do the iteration over\n         the time dimension in reverse order.\n-    mask: binary tensor with shape (samples, time, 1), with a zero for every element\n-        that is masked.\n+    mask: binary tensor with shape (samples, time, 1),\n+        with a zero for every element that is masked.\n \n     Returns\n     -------\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#571f1d4fcff025b30b99f15a757c58916b9355c3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 1863 | Contributors (this commit): 10 | Commits (past 90d): 61 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -426,7 +426,7 @@ def rnn(step_function, inputs, initial_states,\n     '''\n     ndim = len(inputs.get_shape())\n     assert ndim >= 3, \"Input should be at least 3D.\"\n-    axes = [1, 0] + range(2, ndim)\n+    axes = [1, 0] + list(range(2, ndim))\n     inputs = tf.transpose(inputs, (axes))\n     input_list = tf.unpack(inputs)\n     if mask is None:\n@@ -482,7 +482,7 @@ def rnn(step_function, inputs, initial_states,\n     outputs = tf.pack(successive_outputs)\n     new_states = successive_states[-1]\n \n-    axes = [1, 0] + range(2, len(outputs.get_shape()))\n+    axes = [1, 0] + list(range(2, len(outputs.get_shape())))\n     outputs = tf.transpose(outputs, axes)\n     return last_output, outputs, new_states\n \n\n@@ -442,7 +442,7 @@ def rnn(step_function, inputs, initial_states,\n     '''\n     ndim = inputs.ndim\n     assert ndim >= 3, \"Input should be at least 3D.\"\n-    axes = [1, 0] + range(2, ndim)\n+    axes = [1, 0] + list(range(2, ndim))\n     inputs = inputs.dimshuffle(axes)\n     if mask is None:\n         mask = expand_dims(ones_like(T.sum(inputs, axis=-1)))\n@@ -480,7 +480,7 @@ def rnn(step_function, inputs, initial_states,\n     outputs = T.squeeze(outputs)\n     last_output = outputs[-1]\n \n-    axes = [1, 0] + range(2, outputs.ndim)\n+    axes = [1, 0] + list(range(2, outputs.ndim))\n     outputs = outputs.dimshuffle(axes)\n     states = [T.squeeze(state[-1]) for state in states]\n     return last_output, outputs, states\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2143046261e91e8b893bc9cbeedf08b732555e36", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 2713 | Contributors (this commit): 17 | Commits (past 90d): 25 | Contributors (cumulative): 17 | DMM Complexity: 0.0\n\nDIFF:\n@@ -132,9 +132,13 @@ class Recurrent(MaskedLayer):\n             if not self.input_shape[1]:\n                 raise Exception('When using TensorFlow, you should define ' +\n                                 'explicitly the number of timesteps of ' +\n-                                'your sequences. Make sure the first layer ' +\n-                                'has a \"batch_input_shape\" argument ' +\n-                                'including the samples axis.')\n+                                'your sequences.\\n' +\n+                                'If your first layer is an Embedding, ' +\n+                                'make sure to pass it an \"input_length\" ' +\n+                                'argument. Otherwise, make sure ' +\n+                                'the first layer has ' +\n+                                'an \"input_shape\" or \"batch_input_shape\" ' +\n+                                'argument, including the time axis.')\n         if self.stateful:\n             initial_states = self.states\n         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5657a38515a97be711bf8b398fdff1e2fe2ff13e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 971 | Contributors (this commit): 10 | Commits (past 90d): 34 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -14,7 +14,7 @@ def _on_gpu():\n     '''Return whether the session is set to\n     run on GPU or not (i.e. on CPU).\n     '''\n-    return theano.config.device[:3] == 'gpu'\n+    return theano.config.device[:3] == 'gpu' or theano.sandbox.cuda.cuda_enabled\n \n \n if _on_gpu():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ea7f400d57cfb03397326eb2f8e972670d534cc2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1869 | Contributors (this commit): 11 | Commits (past 90d): 64 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -440,7 +440,7 @@ def rnn(step_function, inputs, initial_states,\n         mask = tf.cast(mask, tf.bool)\n     else:\n         # Transpose not supported by bool tensor types, hence round-trip to uint8.\n-        mask = tf.cast(tf.transpose(tf.cast(mask, tf.uint8), (1, 0, 2)), tf.bool)\n+        mask = tf.cast(tf.transpose(tf.cast(mask, tf.uint8), axes), tf.bool)\n \n     mask_list = tf.unpack(mask)\n \n\n@@ -447,7 +447,7 @@ def rnn(step_function, inputs, initial_states,\n     if mask is None:\n         mask = expand_dims(ones_like(T.sum(inputs, axis=-1)))\n     else:\n-        mask = mask.dimshuffle((1, 0, 2))\n+        mask = mask.dimshuffle(axes)\n \n     def _step(input, mask, output_tm1, *states):\n         output, new_states = step_function(input, states)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e2e281e14f619d9ade61c46567e2c599db070f16", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 57 | Lines Deleted: 7 | Files Changed: 3 | Hunks: 11 | Methods Changed: 7 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 64 | Churn Cumulative: 294 | Contributors (this commit): 7 | Commits (past 90d): 10 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -11,29 +11,77 @@ class Constraint(object):\n \n \n class MaxNorm(Constraint):\n-    def __init__(self, m=2):\n+    '''Constrain the weights incident to each hidden unit to have a norm less than or equal to a desired value.\n+\n+    # Arguments\n+        m: the maximum norm for the incoming weights.\n+        axis: integer, axis along which to calculate weight norms. For instance,\n+            in a `Dense` layer the weight matrix has shape (input_dim, output_dim),\n+            set `axis` to `0` to constrain each weight vector of length (input_dim).\n+            In a `MaxoutDense` layer the weight tensor has shape (nb_feature, input_dim, output_dim),\n+            set `axis` to `1` to constrain each weight vector of length (input_dim),\n+            i.e. constrain the filters incident to the `max` operation.\n+            In a `Convolution2D` layer with the Theano backend, the weight tensor\n+            has shape (nb_filter, stack_size, nb_row, nb_col), set `axis` to `[1,2,3]`\n+            to constrain the weights of each filter tensor of size (stack_size, nb_row, nb_col).\n+            In a `Convolution2D` layer with the TensorFlow backend, the weight tensor\n+            has shape (nb_row, nb_col, stack_size, nb_filter), set `axis` to `[0,1,2]`\n+            to constrain the weights of each filter tensor of size (nb_row, nb_col, stack_size).\n+\n+    # References\n+        - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting Srivastava, Hinton, et al. 2014](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n+    '''\n+    def __init__(self, m=2, axis=0):\n         self.m = m\n+        self.axis = axis\n \n     def __call__(self, p):\n-        norms = K.sqrt(K.sum(K.square(p), axis=0))\n+        norms = K.sqrt(K.sum(K.square(p), axis=self.axis, keepdims=True))\n         desired = K.clip(norms, 0, self.m)\n-        p = p * (desired / (1e-7 + norms))\n+        p = p * (desired / (K.epsilon() + norms))\n         return p\n \n     def get_config(self):\n         return {\"name\": self.__class__.__name__,\n-                \"m\": self.m}\n+                \"m\": self.m,\n+                \"axis\": self.axis}\n \n \n class NonNeg(Constraint):\n+    '''Constrain the weights to be non-negative.\n+    '''\n     def __call__(self, p):\n         p *= K.cast(p >= 0., K.floatx())\n         return p\n \n \n class UnitNorm(Constraint):\n+    '''Constrain the weights incident to each hidden unit to have unit norm.\n+\n+    # Arguments\n+        axis: integer, axis along which to calculate weight norms. For instance,\n+            in a `Dense` layer the weight matrix has shape (input_dim, output_dim),\n+            set `axis` to `0` to constrain each weight vector of length (input_dim).\n+            In a `MaxoutDense` layer the weight tensor has shape (nb_feature, input_dim, output_dim),\n+            set `axis` to `1` to constrain each weight vector of length (input_dim),\n+            i.e. constrain the filters incident to the `max` operation.\n+            In a `Convolution2D` layer with the Theano backend, the weight tensor\n+            has shape (nb_filter, stack_size, nb_row, nb_col), set `axis` to `[1,2,3]`\n+            to constrain the weights of each filter tensor of size (stack_size, nb_row, nb_col).\n+            In a `Convolution2D` layer with the TensorFlow backend, the weight tensor\n+            has shape (nb_row, nb_col, stack_size, nb_filter), set `axis` to `[0,1,2]`\n+            to constrain the weights of each filter tensor of size (nb_row, nb_col, stack_size).\n+    '''\n+    def __init__(self, axis=0):\n+        self.axis = axis\n+\n     def __call__(self, p):\n-        return p / K.sqrt(K.sum(K.square(p), axis=-1, keepdims=True))\n+        return p / (K.epsilon() + K.sqrt(K.sum(K.square(p), axis=self.axis, keepdims=True)))\n+\n+    def get_config(self):\n+        return {\"name\": self.__class__.__name__,\n+                \"axis\": self.axis}\n+\n \n identity = Constraint\n maxnorm = MaxNorm\n@@ -41,5 +89,7 @@ nonneg = NonNeg\n unitnorm = UnitNorm\n \n from .utils.generic_utils import get_from_module\n+\n+\n def get(identifier, kwargs=None):\n     return get_from_module(identifier, globals(), 'constraint', instantiate=True, kwargs=kwargs)\n\n@@ -23,7 +23,7 @@ def test_unitnorm_constraint():\n     lookup.compile(loss='binary_crossentropy', optimizer='sgd',\n                    class_mode='binary')\n     lookup.train_on_batch(X1, np.array([[1], [0]], dtype='int32'))\n-    norm = np.linalg.norm(K.get_value(lookup.params[0]), axis=1)\n+    norm = np.linalg.norm(K.get_value(lookup.params[0]), axis=0)\n     assert_allclose(norm, np.ones_like(norm).astype('float32'), rtol=1e-05)\n \n \n\n@@ -54,7 +54,7 @@ def test_identity_oddballs():\n def test_unitnorm():\n     unitnorm_instance = constraints.unitnorm()\n     normalized = unitnorm_instance(K.variable(example_array))\n-    norm_of_normalized = np.sqrt(np.sum(K.eval(normalized)**2, axis=1))\n+    norm_of_normalized = np.sqrt(np.sum(K.eval(normalized)**2, axis=0))\n     # in the unit norm constraint, it should be equal to 1.\n     difference = norm_of_normalized - 1.\n     largest_difference = np.max(np.abs(difference))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8823fa520bf35478f9d6d4b36f291d1e14300a05", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 453 | Contributors (this commit): 7 | Commits (past 90d): 14 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -112,6 +112,7 @@ class BatchNormalization(Layer):\n         config = {\"name\": self.__class__.__name__,\n                   \"epsilon\": self.epsilon,\n                   \"mode\": self.mode,\n+                  \"axis\": self.axis,\n                   \"momentum\": self.momentum}\n         base_config = super(BatchNormalization, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1e58b895236f6a80f5e07de74af25f16d9cc4625", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 39 | Contributors (this commit): 1 | Commits (past 90d): 5 | Contributors (cumulative): 1 | DMM Complexity: 0.0\n\nDIFF:\n@@ -101,14 +101,7 @@ def test_batchnorm_weight_init():\n def test_batchnorm_config():\n     norm = normalization.BatchNormalization(input_shape=(10, 10), mode=1,\n                                             epsilon=0.1, momentum=0.9)\n-    conf = norm.get_config()\n-    del conf['cache_enabled']\n-    del conf['trainable']\n-    del conf['custom_name']\n-    conf_target = {\"input_shape\": (10, 10),\n-                   \"name\": normalization.BatchNormalization.__name__,\n-                   \"epsilon\": 0.1, \"mode\": 1, \"momentum\": 0.9}\n-    assert(conf == conf_target)\n+    norm.get_config()\n \n \n def test_batchnorm_save_weights():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#36892dba8f5dd2847a565cf9b1f0ebfd74c29a5d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 977 | Contributors (this commit): 10 | Commits (past 90d): 36 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -495,6 +495,10 @@ def switch(condition, then_expression, else_expression):\n # NN OPERATIONS\n \n def relu(x, alpha=0., max_value=None):\n+    assert hasattr(T.nnet, 'relu'), ('It looks like like your version of '\n+                                     'Theano is out of date. '\n+                                     'Install the latest version with:\\n'\n+                                     'pip install git+git://github.com/Theano/Theano.git --upgrade')\n     x = T.nnet.relu(x, alpha)\n     if max_value is not None:\n         x = T.minimum(x, max_value)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#399c00c7f87660f5a660df72fdf6fd1192c32be2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 9 | Churn Cumulative: 4139 | Contributors (this commit): 34 | Commits (past 90d): 26 | Contributors (cumulative): 34 | DMM Complexity: None\n\nDIFF:\n@@ -516,14 +516,7 @@ class Sequential(Model, containers.Sequential):\n                 used for scaling the loss function (during training only).\n             sample_weight: list or numpy array with 1:1 mapping to\n                 the training samples, used for scaling the loss function\n-                (during training only). For time-distributed data,\n-                there is one weight per sample *per timestep*,\n-                i.e. if your output data is shaped\n-                `(nb_samples, timesteps, output_dim)`,\n-                your mask should be of shape `(nb_samples, timesteps, 1)`.\n-                This allows you to mask out or reweight individual\n-                output timesteps, which is useful\n-                in sequence to sequence learning.\n+                (during training only).\n         '''\n         if type(X) == list:\n             if len(set([len(a) for a in X] + [len(y)])) != 1:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#26ab219159ec4afa5940e0cd2cf2dcffb4b2399d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 2383 | Contributors (this commit): 16 | Commits (past 90d): 22 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -184,9 +184,10 @@ class Convolution2D(Layer):\n \n     # Output shape\n         4D tensor with shape:\n-        `(samples, nb_filter, nb_row, nb_col)` if dim_ordering='th'\n+        `(samples, nb_filter, new_rows, new_cols)` if dim_ordering='th'\n         or 4D tensor with shape:\n-        `(samples, nb_row, nb_col, nb_filter)` if dim_ordering='tf'.\n+        `(samples, new_rows, new_cols, nb_filter)` if dim_ordering='tf'.\n+        `rows` and `cols` values might have changed due to padding.\n \n \n     # Arguments\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ed1297b39310d37b384ba75e0eb771e9c0e4b80b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 979 | Contributors (this commit): 10 | Commits (past 90d): 37 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -498,7 +498,7 @@ def relu(x, alpha=0., max_value=None):\n     assert hasattr(T.nnet, 'relu'), ('It looks like like your version of '\n                                      'Theano is out of date. '\n                                      'Install the latest version with:\\n'\n-                                     'pip install git+git://github.com/Theano/Theano.git --upgrade')\n+                                     'pip install git+git://github.com/Theano/Theano.git --upgrade --nodeps')\n     x = T.nnet.relu(x, alpha)\n     if max_value is not None:\n         x = T.minimum(x, max_value)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2e90ae18a6815d787d7be663024e5878e114c13d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 981 | Contributors (this commit): 10 | Commits (past 90d): 38 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -498,7 +498,7 @@ def relu(x, alpha=0., max_value=None):\n     assert hasattr(T.nnet, 'relu'), ('It looks like like your version of '\n                                      'Theano is out of date. '\n                                      'Install the latest version with:\\n'\n-                                     'pip install git+git://github.com/Theano/Theano.git --upgrade --nodeps')\n+                                     'pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps')\n     x = T.nnet.relu(x, alpha)\n     if max_value is not None:\n         x = T.minimum(x, max_value)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#403b4fc7a25da5d957b24f1c269103ef6e290bd6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 11 | Files Changed: 1 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 24 | Churn Cumulative: 143 | Contributors (this commit): 5 | Commits (past 90d): 4 | Contributors (cumulative): 5 | DMM Complexity: 0.0\n\nDIFF:\n@@ -142,18 +142,19 @@ class ImageDataGenerator(object):\n     def flow(self, X, y, batch_size=32, shuffle=False, seed=None,\n              save_to_dir=None, save_prefix=\"\", save_format=\"jpeg\"):\n         assert len(X) == len(y)\n-        if seed:\n-            random.seed(seed)\n-\n-        if shuffle:\n-            seed = random.randint(1, 10e6)\n-            np.random.seed(seed)\n-            np.random.shuffle(X)\n-            np.random.seed(seed)\n-            np.random.shuffle(y)\n \n         b = 0\n+        total_b = 0\n         while 1:\n+            if b == 0:\n+                if seed is not None:\n+                    np.random.seed(seed + total_b)\n+\n+                if shuffle:\n+                    index_array = np.random.permutation(X.shape[0])\n+                else:\n+                    index_array = np.arange(X.shape[0])\n+\n             current_index = (b * batch_size) % X.shape[0]\n             if X.shape[0] >= current_index + batch_size:\n                 current_batch_size = batch_size\n@@ -161,7 +162,7 @@ class ImageDataGenerator(object):\n                 current_batch_size = X.shape[0] - current_index\n             bX = np.zeros(tuple([current_batch_size] + list(X.shape)[1:]))\n             for i in range(current_batch_size):\n-                x = X[current_index + i]\n+                x = X[index_array[current_index + i]]\n                 x = self.random_transform(x.astype(\"float32\"))\n                 x = self.standardize(x)\n                 bX[i] = x\n@@ -173,7 +174,8 @@ class ImageDataGenerator(object):\n                 b += 1\n             else:\n                 b = 0\n-            yield bX, y[current_index: current_index + batch_size]\n+            total_b += 1\n+            yield bX, y[index_array[current_index: current_index + batch_size]]\n \n     def standardize(self, x):\n         if self.featurewise_center:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#05fe5f564ac23a9e4ae9a5ae86852dd3ca4b8d6b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 2 | Churn Cumulative: 145 | Contributors (this commit): 5 | Commits (past 90d): 5 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -168,7 +168,7 @@ class ImageDataGenerator(object):\n             if save_to_dir:\n                 for i in range(current_batch_size):\n                     img = array_to_img(bX[i], scale=True)\n-                    img.save(save_to_dir + \"/\" + save_prefix + \"_\" + str(i) + \".\" + save_format)\n+                    img.save(save_to_dir + \"/\" + save_prefix + \"_\" + str(current_index + i) + \".\" + save_format)\n             if current_batch_size == batch_size:\n                 b += 1\n             else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4922a67f09d5a54bcebc28cfe5baced9981bbeee", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 21 | Churn Cumulative: 4160 | Contributors (this commit): 34 | Commits (past 90d): 26 | Contributors (cumulative): 34 | DMM Complexity: 0.0\n\nDIFF:\n@@ -89,11 +89,12 @@ def weighted_objective(fn):\n             #  to the number of unmasked samples.\n             score_array /= K.mean(mask)\n \n-        # reduce score_array to 1D\n+        # reduce score_array to same ndim as weight array\n         ndim = K.ndim(score_array)\n-        for d in range(ndim-1):\n-            score_array = K.mean(score_array, axis=-1)\n+        weight_ndim = K.ndim(weights)\n+        score_array = K.mean(score_array, axis=list(range(weight_ndim, ndim)))\n \n+        # apply sample weighting\n         if weights is not None:\n             score_array *= weights\n         return K.mean(score_array)\n@@ -104,8 +105,9 @@ def standardize_weights(y, sample_weight=None, class_weight=None):\n     '''\n     '''\n     if sample_weight is not None:\n-        assert len(sample_weight) == len(y)\n-        return sample_weight.flatten()\n+        assert sample_weight.ndim <= y.ndim\n+        assert y.shape[:sample_weight.ndim] == sample_weight.shape\n+        return sample_weight\n     elif isinstance(class_weight, dict):\n         if len(y.shape) > 2:\n             raise Exception('class_weight not supported for '\n@@ -514,9 +516,14 @@ class Sequential(Model, containers.Sequential):\n                 class accuracy in the logs to stdout at each epoch.\n             class_weight: dictionary mapping classes to a weight value,\n                 used for scaling the loss function (during training only).\n-            sample_weight: list or numpy array with 1:1 mapping to\n+            sample_weight: list or numpy array of weights for\n                 the training samples, used for scaling the loss function\n-                (during training only).\n+                (during training only). You can either pass a flat (1D)\n+                Numpy array with the same length as the input samples\n+                (1:1 mapping between weights and samples),\n+                or in the case of temporal data,\n+                you can pass a 2D array with shape (samples, sequence_length),\n+                to apply a different weight to every timestep of every sample.\n         '''\n         if type(X) == list:\n             if len(set([len(a) for a in X] + [len(y)])) != 1:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5cf50f6a6cb7d0ed5c309dbb7a647ad2ce454322", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 18 | Churn Cumulative: 243 | Contributors (this commit): 7 | Commits (past 90d): 9 | Contributors (cumulative): 9 | DMM Complexity: 0.8\n\nDIFF:\n@@ -60,10 +60,14 @@ def random_barrel_transform(x, intensity):\n     pass\n \n \n-def random_shear(x, intensity):\n-    # TODO\n-    pass\n-\n+def random_shear(x, intensity, fill_mode=\"nearest\", cval=0.):\n+    shear = random.uniform(-intensity, intensity)\n+    shear_matrix = np.array([[1.0, -math.sin(shear), 0.0],\n+                            [0.0, math.cos(shear), 0.0],\n+                            [0.0, 0.0, 1.0]])\n+    x = ndimage.interpolation.affine_transform(x, shear_matrix,\n+                                               mode=fill_mode, order=3, cval=cval)\n+    return x\n \n def random_channel_shift(x, rg):\n     # TODO\n@@ -132,8 +136,10 @@ class ImageDataGenerator(object):\n                  rotation_range=0.,  # degrees (0 to 180)\n                  width_shift_range=0.,  # fraction of total width\n                  height_shift_range=0.,  # fraction of total height\n+                 shear_range=0.,  # shear intensity (shear angle in radians)\n                  horizontal_flip=False,\n                  vertical_flip=False):\n+\n         self.__dict__.update(locals())\n         self.mean = None\n         self.std = None\n@@ -204,7 +210,8 @@ class ImageDataGenerator(object):\n         if self.vertical_flip:\n             if random.random() < 0.5:\n                 x = vertical_flip(x)\n-\n+        if self.shear_range:\n+            x = random_shear(x,self.shear_range)\n         # TODO:\n         # zoom\n         # barrel/fisheye\n\n@@ -45,6 +45,7 @@ def test_image_data_generator():\n             rotation_range=90.,\n             width_shift_range=10.,\n             height_shift_range=10.,\n+            shear_range=0.5,\n             horizontal_flip=True,\n             vertical_flip=True)\n         generator.fit(images, augment=True)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
