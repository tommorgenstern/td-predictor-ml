{"custom_id": "keras#9551d2d1605b3773285492da0dc093507abc880f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 366 | Lines Deleted: 289 | Files Changed: 2 | Hunks: 20 | Methods Changed: 9 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 655 | Churn Cumulative: 7046 | Contributors (this commit): 59 | Commits (past 90d): 2 | Contributors (cumulative): 61 | DMM Complexity: 1.0\n\nDIFF:\n@@ -7,8 +7,6 @@ from .. import utils\n \n import keras_preprocessing\n \n-keras_preprocessing.set_keras_submodules(backend=backend, utils=utils)\n-\n from . import image\n from . import sequence\n from . import text\n\n@@ -25,26 +25,20 @@ load_img = image.load_img\n def array_to_img(x, data_format=None, scale=True, dtype=None):\n     if data_format is None:\n         data_format = backend.image_data_format()\n-    if 'dtype' in generic_utils.getargspec(image.array_to_img).args:\n     if dtype is None:\n         dtype = backend.floatx()\n     return image.array_to_img(x,\n                               data_format=data_format,\n                               scale=scale,\n                               dtype=dtype)\n-    return image.array_to_img(x,\n-                              data_format=data_format,\n-                              scale=scale)\n \n \n def img_to_array(img, data_format=None, dtype=None):\n     if data_format is None:\n         data_format = backend.image_data_format()\n-    if 'dtype' in generic_utils.getargspec(image.img_to_array).args:\n     if dtype is None:\n         dtype = backend.floatx()\n     return image.img_to_array(img, data_format=data_format, dtype=dtype)\n-    return image.img_to_array(img, data_format=data_format)\n \n \n def save_img(path,\n@@ -62,67 +56,11 @@ def save_img(path,\n \n \n class Iterator(image.Iterator, utils.Sequence):\n-    \"\"\"Base class for image data iterators.\n-\n-    Every `Iterator` must implement the `_get_batches_of_transformed_samples`\n-    method.\n-\n-    # Arguments\n-        n: Integer, total number of samples in the dataset to loop over.\n-        batch_size: Integer, size of a batch.\n-        shuffle: Boolean, whether to shuffle the data between epochs.\n-        seed: Random seeding for data shuffling.\n-    \"\"\"\n     pass\n \n \n class DirectoryIterator(image.DirectoryIterator, Iterator):\n-    \"\"\"Iterator capable of reading images from a directory on disk.\n-\n-    # Arguments\n-        directory: Path to the directory to read images from.\n-            Each subdirectory in this directory will be\n-            considered to contain images from one class,\n-            or alternatively you could specify class subdirectories\n-            via the `classes` argument.\n-        image_data_generator: Instance of `ImageDataGenerator`\n-            to use for random transformations and normalization.\n-        target_size: tuple of integers, dimensions to resize input images to.\n-        color_mode: One of `\"rgb\"`, `\"rgba\"`, `\"grayscale\"`.\n-            Color mode to read images.\n-        classes: Optional list of strings, names of subdirectories\n-            containing images from each class (e.g. `[\"dogs\", \"cats\"]`).\n-            It will be computed automatically if not set.\n-        class_mode: Mode for yielding the targets:\n-            `\"binary\"`: binary targets (if there are only two classes),\n-            `\"categorical\"`: categorical targets,\n-            `\"sparse\"`: integer targets,\n-            `\"input\"`: targets are images identical to input images (mainly\n-                used to work with autoencoders),\n-            `None`: no targets get yielded (only input images are yielded).\n-        batch_size: Integer, size of a batch.\n-        shuffle: Boolean, whether to shuffle the data between epochs.\n-            If set to False, sorts the data in alphanumeric order.\n-        seed: Random seed for data shuffling.\n-        data_format: String, one of `channels_first`, `channels_last`.\n-        save_to_dir: Optional directory where to save the pictures\n-            being yielded, in a viewable format. This is useful\n-            for visualizing the random transformations being\n-            applied, for debugging purposes.\n-        save_prefix: String prefix to use for saving sample\n-            images (if `save_to_dir` is set).\n-        save_format: Format to use for saving sample images\n-            (if `save_to_dir` is set).\n-        subset: Subset of data (`\"training\"` or `\"validation\"`) if\n-            validation_split is set in ImageDataGenerator.\n-        interpolation: Interpolation method used to resample the image if the\n-            target size is different from that of the loaded image.\n-            Supported methods are \"nearest\", \"bilinear\", and \"bicubic\".\n-            If PIL version 1.1.3 or newer is installed, \"lanczos\" is also\n-            supported. If PIL version 3.4.0 or newer is installed, \"box\" and\n-            \"hamming\" are also supported. By default, \"nearest\" is used.\n-        dtype: Dtype to use for generated arrays.\n-    \"\"\"\n+    __doc__ = image.DirectoryIterator.__doc__\n \n     def __init__(self, directory, image_data_generator,\n                  target_size=(256, 256),\n@@ -142,12 +80,8 @@ class DirectoryIterator(image.DirectoryIterator, Iterator):\n                  dtype=None):\n         if data_format is None:\n             data_format = backend.image_data_format()\n-        kwargs = {}\n-        if 'dtype' in generic_utils.getargspec(\n-                image.ImageDataGenerator.__init__).args:\n         if dtype is None:\n             dtype = backend.floatx()\n-            kwargs['dtype'] = dtype\n         super(DirectoryIterator, self).__init__(\n             directory, image_data_generator,\n             target_size=target_size,\n@@ -164,38 +98,11 @@ class DirectoryIterator(image.DirectoryIterator, Iterator):\n             follow_links=follow_links,\n             subset=subset,\n             interpolation=interpolation,\n-            **kwargs)\n+            dtype=dtype)\n \n \n class NumpyArrayIterator(image.NumpyArrayIterator, Iterator):\n-    \"\"\"Iterator yielding data from a Numpy array.\n-\n-    # Arguments\n-        x: Numpy array of input data or tuple.\n-            If tuple, the second elements is either\n-            another numpy array or a list of numpy arrays,\n-            each of which gets passed\n-            through as an output without any modifications.\n-        y: Numpy array of targets data.\n-        image_data_generator: Instance of `ImageDataGenerator`\n-            to use for random transformations and normalization.\n-        batch_size: Integer, size of a batch.\n-        shuffle: Boolean, whether to shuffle the data between epochs.\n-        sample_weight: Numpy array of sample weights.\n-        seed: Random seed for data shuffling.\n-        data_format: String, one of `channels_first`, `channels_last`.\n-        save_to_dir: Optional directory where to save the pictures\n-            being yielded, in a viewable format. This is useful\n-            for visualizing the random transformations being\n-            applied, for debugging purposes.\n-        save_prefix: String prefix to use for saving sample\n-            images (if `save_to_dir` is set).\n-        save_format: Format to use for saving sample images\n-            (if `save_to_dir` is set).\n-        subset: Subset of data (`\"training\"` or `\"validation\"`) if\n-            validation_split is set in ImageDataGenerator.\n-        dtype: Dtype to use for the generated arrays.\n-    \"\"\"\n+    __doc__ = image.NumpyArrayIterator.__doc__\n \n     def __init__(self, x, y, image_data_generator,\n                  batch_size=32,\n@@ -210,12 +117,8 @@ class NumpyArrayIterator(image.NumpyArrayIterator, Iterator):\n                  dtype=None):\n         if data_format is None:\n             data_format = backend.image_data_format()\n-        kwargs = {}\n-        if 'dtype' in generic_utils.getargspec(\n-                image.NumpyArrayIterator.__init__).args:\n         if dtype is None:\n             dtype = backend.floatx()\n-            kwargs['dtype'] = dtype\n         super(NumpyArrayIterator, self).__init__(\n             x, y, image_data_generator,\n             batch_size=batch_size,\n@@ -227,189 +130,64 @@ class NumpyArrayIterator(image.NumpyArrayIterator, Iterator):\n             save_prefix=save_prefix,\n             save_format=save_format,\n             subset=subset,\n-            **kwargs)\n+            dtype=dtype)\n+\n+\n+class DataFrameIterator(image.DataFrameIterator, Iterator):\n+    __doc__ = image.DataFrameIterator.__doc__\n+\n+    def __init__(self,\n+                 dataframe,\n+                 directory=None,\n+                 image_data_generator=None,\n+                 x_col='filename',\n+                 y_col='class',\n+                 weight_col=None,\n+                 target_size=(256, 256),\n+                 color_mode='rgb',\n+                 classes=None,\n+                 class_mode='categorical',\n+                 batch_size=32,\n+                 shuffle=True,\n+                 seed=None,\n+                 data_format='channels_last',\n+                 save_to_dir=None,\n+                 save_prefix='',\n+                 save_format='png',\n+                 subset=None,\n+                 interpolation='nearest',\n+                 dtype='float32',\n+                 validate_filenames=True):\n+        if data_format is None:\n+            data_format = backend.image_data_format()\n+        if dtype is None:\n+            dtype = backend.floatx()\n+        super(DataFrameIterator, self).__init__(\n+            dataframe,\n+            directory=directory,\n+            image_data_generator=image_data_generator,\n+            x_col=x_col,\n+            y_col=y_col,\n+            weight_col=weight_col,\n+            target_size=target_size,\n+            color_mode=color_mode,\n+            classes=classes,\n+            class_mode=class_mode,\n+            batch_size=batch_size,\n+            shuffle=shuffle,\n+            seed=seed,\n+            data_format=data_format,\n+            save_to_dir=save_to_dir,\n+            save_prefix=save_prefix,\n+            save_format=save_format,\n+            subset=subset,\n+            interpolation=interpolation,\n+            dtype=dtype,\n+            validate_filenames=validate_filenames)\n \n \n class ImageDataGenerator(image.ImageDataGenerator):\n-    \"\"\"Generate batches of tensor image data with real-time data augmentation.\n-     The data will be looped over (in batches).\n-\n-    # Arguments\n-        featurewise_center: Boolean.\n-            Set input mean to 0 over the dataset, feature-wise.\n-        samplewise_center: Boolean. Set each sample mean to 0.\n-        featurewise_std_normalization: Boolean.\n-            Divide inputs by std of the dataset, feature-wise.\n-        samplewise_std_normalization: Boolean. Divide each input by its std.\n-        zca_epsilon: epsilon for ZCA whitening. Default is 1e-6.\n-        zca_whitening: Boolean. Apply ZCA whitening.\n-        rotation_range: Int. Degree range for random rotations.\n-        width_shift_range: Float, 1-D array-like or int\n-            - float: fraction of total width, if < 1, or pixels if >= 1.\n-            - 1-D array-like: random elements from the array.\n-            - int: integer number of pixels from interval\n-                `(-width_shift_range, +width_shift_range)`\n-            - With `width_shift_range=2` possible values\n-                are integers `[-1, 0, +1]`,\n-                same as with `width_shift_range=[-1, 0, +1]`,\n-                while with `width_shift_range=1.0` possible values are floats\n-                in the half-open interval `[-1.0, +1.0[`.\n-        height_shift_range: Float, 1-D array-like or int\n-            - float: fraction of total height, if < 1, or pixels if >= 1.\n-            - 1-D array-like: random elements from the array.\n-            - int: integer number of pixels from interval\n-                `(-height_shift_range, +height_shift_range)`\n-            - With `height_shift_range=2` possible values\n-                are integers `[-1, 0, +1]`,\n-                same as with `height_shift_range=[-1, 0, +1]`,\n-                while with `height_shift_range=1.0` possible values are floats\n-                in the half-open interval `[-1.0, +1.0[`.\n-        brightness_range: Tuple or list of two floats. Range for picking\n-            a brightness shift value from.\n-        shear_range: Float. Shear Intensity\n-            (Shear angle in counter-clockwise direction in degrees)\n-        zoom_range: Float or [lower, upper]. Range for random zoom.\n-            If a float, `[lower, upper] = [1-zoom_range, 1+zoom_range]`.\n-        channel_shift_range: Float. Range for random channel shifts.\n-        fill_mode: One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}.\n-            Default is 'nearest'.\n-            Points outside the boundaries of the input are filled\n-            according to the given mode:\n-            - 'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k)\n-            - 'nearest':  aaaaaaaa|abcd|dddddddd\n-            - 'reflect':  abcddcba|abcd|dcbaabcd\n-            - 'wrap':  abcdabcd|abcd|abcdabcd\n-        cval: Float or Int.\n-            Value used for points outside the boundaries\n-            when `fill_mode = \"constant\"`.\n-        horizontal_flip: Boolean. Randomly flip inputs horizontally.\n-        vertical_flip: Boolean. Randomly flip inputs vertically.\n-        rescale: rescaling factor. Defaults to None.\n-            If None or 0, no rescaling is applied,\n-            otherwise we multiply the data by the value provided\n-            (after applying all other transformations).\n-        preprocessing_function: function that will be implied on each input.\n-            The function will run after the image is resized and augmented.\n-            The function should take one argument:\n-            one image (Numpy tensor with rank 3),\n-            and should output a Numpy tensor with the same shape.\n-        data_format: Image data format,\n-            either \"channels_first\" or \"channels_last\".\n-            \"channels_last\" mode means that the images should have shape\n-            `(samples, height, width, channels)`,\n-            \"channels_first\" mode means that the images should have shape\n-            `(samples, channels, height, width)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-        validation_split: Float. Fraction of images reserved for validation\n-            (strictly between 0 and 1).\n-        dtype: Dtype to use for the generated arrays.\n-\n-    # Examples\n-    Example of using `.flow(x, y)`:\n-\n-    ```python\n-    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n-    y_train = np_utils.to_categorical(y_train, num_classes)\n-    y_test = np_utils.to_categorical(y_test, num_classes)\n-\n-    datagen = ImageDataGenerator(\n-        featurewise_center=True,\n-        featurewise_std_normalization=True,\n-        rotation_range=20,\n-        width_shift_range=0.2,\n-        height_shift_range=0.2,\n-        horizontal_flip=True)\n-\n-    # compute quantities required for featurewise normalization\n-    # (std, mean, and principal components if ZCA whitening is applied)\n-    datagen.fit(x_train)\n-\n-    # fits the model on batches with real-time data augmentation:\n-    model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n-                        steps_per_epoch=len(x_train) / 32, epochs=epochs)\n-\n-    # here's a more \"manual\" example\n-    for e in range(epochs):\n-        print('Epoch', e)\n-        batches = 0\n-        for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\n-            model.fit(x_batch, y_batch)\n-            batches += 1\n-            if batches >= len(x_train) / 32:\n-                # we need to break the loop by hand because\n-                # the generator loops indefinitely\n-                break\n-    ```\n-    Example of using `.flow_from_directory(directory)`:\n-\n-    ```python\n-    train_datagen = ImageDataGenerator(\n-            rescale=1./255,\n-            shear_range=0.2,\n-            zoom_range=0.2,\n-            horizontal_flip=True)\n-\n-    test_datagen = ImageDataGenerator(rescale=1./255)\n-\n-    train_generator = train_datagen.flow_from_directory(\n-            'data/train',\n-            target_size=(150, 150),\n-            batch_size=32,\n-            class_mode='binary')\n-\n-    validation_generator = test_datagen.flow_from_directory(\n-            'data/validation',\n-            target_size=(150, 150),\n-            batch_size=32,\n-            class_mode='binary')\n-\n-    model.fit_generator(\n-            train_generator,\n-            steps_per_epoch=2000,\n-            epochs=50,\n-            validation_data=validation_generator,\n-            validation_steps=800)\n-    ```\n-\n-    Example of transforming images and masks together.\n-\n-    ```python\n-    # we create two instances with the same arguments\n-    data_gen_args = dict(featurewise_center=True,\n-                         featurewise_std_normalization=True,\n-                         rotation_range=90,\n-                         width_shift_range=0.1,\n-                         height_shift_range=0.1,\n-                         zoom_range=0.2)\n-    image_datagen = ImageDataGenerator(**data_gen_args)\n-    mask_datagen = ImageDataGenerator(**data_gen_args)\n-\n-    # Provide the same seed and keyword arguments to the fit and flow methods\n-    seed = 1\n-    image_datagen.fit(images, augment=True, seed=seed)\n-    mask_datagen.fit(masks, augment=True, seed=seed)\n-\n-    image_generator = image_datagen.flow_from_directory(\n-        'data/images',\n-        class_mode=None,\n-        seed=seed)\n-\n-    mask_generator = mask_datagen.flow_from_directory(\n-        'data/masks',\n-        class_mode=None,\n-        seed=seed)\n-\n-    # combine generators into one which yields image and masks\n-    train_generator = zip(image_generator, mask_generator)\n-\n-    model.fit_generator(\n-        train_generator,\n-        steps_per_epoch=2000,\n-        epochs=50)\n-    ```\n-    \"\"\"\n+    __doc__ = image.ImageDataGenerator.__doc__\n \n     def __init__(self,\n                  featurewise_center=False,\n@@ -431,17 +209,14 @@ class ImageDataGenerator(image.ImageDataGenerator):\n                  vertical_flip=False,\n                  rescale=None,\n                  preprocessing_function=None,\n-                 data_format=None,\n+                 data_format='channels_last',\n                  validation_split=0.0,\n-                 dtype=None):\n+                 interpolation_order=1,\n+                 dtype='float32'):\n         if data_format is None:\n             data_format = backend.image_data_format()\n-        kwargs = {}\n-        if 'dtype' in generic_utils.getargspec(\n-                image.ImageDataGenerator.__init__).args:\n         if dtype is None:\n             dtype = backend.floatx()\n-            kwargs['dtype'] = dtype\n         super(ImageDataGenerator, self).__init__(\n             featurewise_center=featurewise_center,\n             samplewise_center=samplewise_center,\n@@ -464,7 +239,311 @@ class ImageDataGenerator(image.ImageDataGenerator):\n             preprocessing_function=preprocessing_function,\n             data_format=data_format,\n             validation_split=validation_split,\n-            **kwargs)\n+            interpolation_order=interpolation_order,\n+            dtype=dtype)\n+\n+    def flow(self,\n+             x,\n+             y=None,\n+             batch_size=32,\n+             shuffle=True,\n+             sample_weight=None,\n+             seed=None,\n+             save_to_dir=None,\n+             save_prefix='',\n+             save_format='png',\n+             subset=None):\n+        \"\"\"Takes data & label arrays, generates batches of augmented data.\n+\n+        # Arguments\n+            x: Input data. Numpy array of rank 4 or a tuple.\n+                If tuple, the first element\n+                should contain the images and the second element\n+                another numpy array or a list of numpy arrays\n+                that gets passed to the output\n+                without any modifications.\n+                Can be used to feed the model miscellaneous data\n+                along with the images.\n+                In case of grayscale data, the channels axis of the image array\n+                should have value 1, in case\n+                of RGB data, it should have value 3, and in case\n+                of RGBA data, it should have value 4.\n+            y: Labels.\n+            batch_size: Int (default: 32).\n+            shuffle: Boolean (default: True).\n+            sample_weight: Sample weights.\n+            seed: Int (default: None).\n+            save_to_dir: None or str (default: None).\n+                This allows you to optionally specify a directory\n+                to which to save the augmented pictures being generated\n+                (useful for visualizing what you are doing).\n+            save_prefix: Str (default: `''`).\n+                Prefix to use for filenames of saved pictures\n+                (only relevant if `save_to_dir` is set).\n+            save_format: one of \"png\", \"jpeg\"\n+                (only relevant if `save_to_dir` is set). Default: \"png\".\n+            subset: Subset of data (`\"training\"` or `\"validation\"`) if\n+                `validation_split` is set in `ImageDataGenerator`.\n+\n+        # Returns\n+            An `Iterator` yielding tuples of `(x, y)`\n+                where `x` is a numpy array of image data\n+                (in the case of a single image input) or a list\n+                of numpy arrays (in the case with\n+                additional inputs) and `y` is a numpy array\n+                of corresponding labels. If 'sample_weight' is not None,\n+                the yielded tuples are of the form `(x, y, sample_weight)`.\n+                If `y` is None, only the numpy array `x` is returned.\n+        \"\"\"\n+        return NumpyArrayIterator(\n+            x,\n+            y,\n+            self,\n+            batch_size=batch_size,\n+            shuffle=shuffle,\n+            sample_weight=sample_weight,\n+            seed=seed,\n+            data_format=self.data_format,\n+            save_to_dir=save_to_dir,\n+            save_prefix=save_prefix,\n+            save_format=save_format,\n+            subset=subset\n+        )\n+\n+    def flow_from_directory(self,\n+                            directory,\n+                            target_size=(256, 256),\n+                            color_mode='rgb',\n+                            classes=None,\n+                            class_mode='categorical',\n+                            batch_size=32,\n+                            shuffle=True,\n+                            seed=None,\n+                            save_to_dir=None,\n+                            save_prefix='',\n+                            save_format='png',\n+                            follow_links=False,\n+                            subset=None,\n+                            interpolation='nearest'):\n+        \"\"\"Takes the path to a directory & generates batches of augmented data.\n+\n+        # Arguments\n+            directory: string, path to the target directory.\n+                It should contain one subdirectory per class.\n+                Any PNG, JPG, BMP, PPM or TIF images\n+                inside each of the subdirectories directory tree\n+                will be included in the generator.\n+                See [this script](\n+                https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d)\n+                for more details.\n+            target_size: Tuple of integers `(height, width)`,\n+                default: `(256, 256)`.\n+                The dimensions to which all images found will be resized.\n+            color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n+                Whether the images will be converted to\n+                have 1, 3, or 4 channels.\n+            classes: Optional list of class subdirectories\n+                (e.g. `['dogs', 'cats']`). Default: None.\n+                If not provided, the list of classes will be automatically\n+                inferred from the subdirectory names/structure\n+                under `directory`, where each subdirectory will\n+                be treated as a different class\n+                (and the order of the classes, which will map to the label\n+                indices, will be alphanumeric).\n+                The dictionary containing the mapping from class names to class\n+                indices can be obtained via the attribute `class_indices`.\n+            class_mode: One of \"categorical\", \"binary\", \"sparse\",\n+                \"input\", or None. Default: \"categorical\".\n+                Determines the type of label arrays that are returned:\n+                - \"categorical\" will be 2D one-hot encoded labels,\n+                - \"binary\" will be 1D binary labels,\n+                    \"sparse\" will be 1D integer labels,\n+                - \"input\" will be images identical\n+                    to input images (mainly used to work with autoencoders).\n+                - If None, no labels are returned\n+                  (the generator will only yield batches of image data,\n+                  which is useful to use with `model.predict_generator()`).\n+                  Please note that in case of class_mode None,\n+                  the data still needs to reside in a subdirectory\n+                  of `directory` for it to work correctly.\n+            batch_size: Size of the batches of data (default: 32).\n+            shuffle: Whether to shuffle the data (default: True)\n+                If set to False, sorts the data in alphanumeric order.\n+            seed: Optional random seed for shuffling and transformations.\n+            save_to_dir: None or str (default: None).\n+                This allows you to optionally specify\n+                a directory to which to save\n+                the augmented pictures being generated\n+                (useful for visualizing what you are doing).\n+            save_prefix: Str. Prefix to use for filenames of saved pictures\n+                (only relevant if `save_to_dir` is set).\n+            save_format: One of \"png\", \"jpeg\"\n+                (only relevant if `save_to_dir` is set). Default: \"png\".\n+            follow_links: Whether to follow symlinks inside\n+                class subdirectories (default: False).\n+            subset: Subset of data (`\"training\"` or `\"validation\"`) if\n+                `validation_split` is set in `ImageDataGenerator`.\n+            interpolation: Interpolation method used to\n+                resample the image if the\n+                target size is different from that of the loaded image.\n+                Supported methods are `\"nearest\"`, `\"bilinear\"`,\n+                and `\"bicubic\"`.\n+                If PIL version 1.1.3 or newer is installed, `\"lanczos\"` is also\n+                supported. If PIL version 3.4.0 or newer is installed,\n+                `\"box\"` and `\"hamming\"` are also supported.\n+                By default, `\"nearest\"` is used.\n+\n+        # Returns\n+            A `DirectoryIterator` yielding tuples of `(x, y)`\n+                where `x` is a numpy array containing a batch\n+                of images with shape `(batch_size, *target_size, channels)`\n+                and `y` is a numpy array of corresponding labels.\n+        \"\"\"\n+        return DirectoryIterator(\n+            directory,\n+            self,\n+            target_size=target_size,\n+            color_mode=color_mode,\n+            classes=classes,\n+            class_mode=class_mode,\n+            data_format=self.data_format,\n+            batch_size=batch_size,\n+            shuffle=shuffle,\n+            seed=seed,\n+            save_to_dir=save_to_dir,\n+            save_prefix=save_prefix,\n+            save_format=save_format,\n+            follow_links=follow_links,\n+            subset=subset,\n+            interpolation=interpolation\n+        )\n+\n+    def flow_from_dataframe(self,\n+                            dataframe,\n+                            directory=None,\n+                            x_col=\"filename\",\n+                            y_col=\"class\",\n+                            weight_col=None,\n+                            target_size=(256, 256),\n+                            color_mode='rgb',\n+                            classes=None,\n+                            class_mode='categorical',\n+                            batch_size=32,\n+                            shuffle=True,\n+                            seed=None,\n+                            save_to_dir=None,\n+                            save_prefix='',\n+                            save_format='png',\n+                            subset=None,\n+                            interpolation='nearest',\n+                            validate_filenames=True,\n+                            **kwargs):\n+        \"\"\"Takes the dataframe and the path to a directory\n+         and generates batches of augmented/normalized data.\n+\n+        **A simple tutorial can be found **[here](\n+                                    http://bit.ly/keras_flow_from_dataframe).\n+\n+        # Arguments\n+            dataframe: Pandas dataframe containing the filepaths relative to\n+                `directory` (or absolute paths if `directory` is None) of the\n+                images in a string column. It should include other column/s\n+                depending on the `class_mode`:\n+                - if `class_mode` is `\"categorical\"` (default value) it must\n+                    include the `y_col` column with the class/es of each image.\n+                    Values in column can be string/list/tuple if a single class\n+                    or list/tuple if multiple classes.\n+                - if `class_mode` is `\"binary\"` or `\"sparse\"` it must include\n+                    the given `y_col` column with class values as strings.\n+                - if `class_mode` is `\"raw\"` or `\"multi_output\"` it should contain\n+                the columns specified in `y_col`.\n+                - if `class_mode` is `\"input\"` or `None` no extra column is needed.\n+            directory: string, path to the directory to read images from. If `None`,\n+                data in `x_col` column should be absolute paths.\n+            x_col: string, column in `dataframe` that contains the filenames (or\n+                absolute paths if `directory` is `None`).\n+            y_col: string or list, column/s in `dataframe` that has the target data.\n+            weight_col: string, column in `dataframe` that contains the sample\n+                weights. Default: `None`.\n+            target_size: tuple of integers `(height, width)`, default: `(256, 256)`.\n+                The dimensions to which all images found will be resized.\n+            color_mode: one of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n+                Whether the images will be converted to have 1 or 3 color channels.\n+            classes: optional list of classes (e.g. `['dogs', 'cats']`).\n+                Default: None. If not provided, the list of classes will be\n+                automatically inferred from the `y_col`,\n+                which will map to the label indices, will be alphanumeric).\n+                The dictionary containing the mapping from class names to class\n+                indices can be obtained via the attribute `class_indices`.\n+            class_mode: one of \"binary\", \"categorical\", \"input\", \"multi_output\",\n+                \"raw\", sparse\" or None. Default: \"categorical\".\n+                Mode for yielding the targets:\n+                - `\"binary\"`: 1D numpy array of binary labels,\n+                - `\"categorical\"`: 2D numpy array of one-hot encoded labels.\n+                    Supports multi-label output.\n+                - `\"input\"`: images identical to input images (mainly used to\n+                    work with autoencoders),\n+                - `\"multi_output\"`: list with the values of the different columns,\n+                - `\"raw\"`: numpy array of values in `y_col` column(s),\n+                - `\"sparse\"`: 1D numpy array of integer labels,\n+                - `None`, no targets are returned (the generator will only yield\n+                    batches of image data, which is useful to use in\n+                    `model.predict_generator()`).\n+            batch_size: size of the batches of data (default: 32).\n+            shuffle: whether to shuffle the data (default: True)\n+            seed: optional random seed for shuffling and transformations.\n+            save_to_dir: None or str (default: None).\n+                This allows you to optionally specify a directory\n+                to which to save the augmented pictures being generated\n+                (useful for visualizing what you are doing).\n+            save_prefix: str. Prefix to use for filenames of saved pictures\n+                (only relevant if `save_to_dir` is set).\n+            save_format: one of \"png\", \"jpeg\"\n+                (only relevant if `save_to_dir` is set). Default: \"png\".\n+            follow_links: whether to follow symlinks inside class subdirectories\n+                (default: False).\n+            subset: Subset of data (`\"training\"` or `\"validation\"`) if\n+                `validation_split` is set in `ImageDataGenerator`.\n+            interpolation: Interpolation method used to resample the image if the\n+                target size is different from that of the loaded image.\n+                Supported methods are `\"nearest\"`, `\"bilinear\"`, and `\"bicubic\"`.\n+                If PIL version 1.1.3 or newer is installed, `\"lanczos\"` is also\n+                supported. If PIL version 3.4.0 or newer is installed, `\"box\"` and\n+                `\"hamming\"` are also supported. By default, `\"nearest\"` is used.\n+            validate_filenames: Boolean, whether to validate image filenames in\n+                `x_col`. If `True`, invalid images will be ignored. Disabling this\n+                option can lead to speed-up in the execution of this function.\n+                Default: `True`.\n+\n+        # Returns\n+            A `DataFrameIterator` yielding tuples of `(x, y)`\n+            where `x` is a numpy array containing a batch\n+            of images with shape `(batch_size, *target_size, channels)`\n+            and `y` is a numpy array of corresponding labels.\n+        \"\"\"\n+        return DataFrameIterator(\n+            dataframe,\n+            directory,\n+            self,\n+            x_col=x_col,\n+            y_col=y_col,\n+            weight_col=weight_col,\n+            target_size=target_size,\n+            color_mode=color_mode,\n+            classes=classes,\n+            class_mode=class_mode,\n+            data_format=self.data_format,\n+            batch_size=batch_size,\n+            shuffle=shuffle,\n+            seed=seed,\n+            save_to_dir=save_to_dir,\n+            save_prefix=save_prefix,\n+            save_format=save_format,\n+            subset=subset,\n+            interpolation=interpolation,\n+            validate_filenames=validate_filenames,\n+            **kwargs\n+        )\n \n \n array_to_img.__doc__ = image.array_to_img.__doc__\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e3d20c69351035279e438527cb2fdb4cb2fa2166", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 15 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 15 | Churn Cumulative: 229 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -9,18 +9,10 @@ from .. import utils\n \n import keras_applications\n \n-if not hasattr(keras_applications, 'get_submodules_from_kwargs'):\n-    keras_applications.set_keras_submodules(\n-        backend=backend,\n-        layers=layers,\n-        models=models,\n-        utils=utils)\n-\n \n def keras_modules_injection(base_fun):\n \n     def wrapper(*args, **kwargs):\n-        if hasattr(keras_applications, 'get_submodules_from_kwargs'):\n         kwargs['backend'] = backend\n         kwargs['layers'] = layers\n         kwargs['models'] = models\n\n@@ -62,13 +62,6 @@ def _test_application_notop(app, last_dim):\n     assert output_shape[-1] == last_dim\n \n \n-def test_mobilenet_v2_legacy_import():\n-    from keras.applications import mobilenetv2\n-    assert hasattr(mobilenetv2, 'MobileNetV2')\n-    from keras.applications import mobilenet_v2\n-    assert hasattr(mobilenet_v2, 'MobileNetV2')\n-\n-\n def test_applications():\n     for _ in range(3):\n         app, last_dim = random.choice(MODEL_LIST)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#99ebe7759fd317aedae734865f68dd4387100081", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 235 | Contributors (this commit): 6 | Commits (past 90d): 4 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -34,4 +34,3 @@ from .densenet import DenseNet121, DenseNet169, DenseNet201\n from .nasnet import NASNetMobile, NASNetLarge\n from .resnet import ResNet101, ResNet152\n from .resnet_v2 import ResNet50V2, ResNet101V2, ResNet152V2\n-from .resnext import ResNeXt50, ResNeXt101\n\n@@ -8,6 +8,11 @@ from keras import backend as K\n \n MODEL_LIST = [\n     (applications.ResNet50, 2048),\n+    (applications.ResNet101, 2048),\n+    (applications.ResNet152, 2048),\n+    (applications.ResNet50V2, 2048),\n+    (applications.ResNet101V2, 2048),\n+    (applications.ResNet152V2, 2048),\n     (applications.VGG16, 512),\n     (applications.VGG19, 512),\n     (applications.Xception, 2048),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ab3ef6f3f0b859e5b501aa696f388f277cb31de2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 298 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 5 | Methods Changed: 15 | Complexity Δ (Sum/Max): 23/13 | Churn Δ: 302 | Churn Cumulative: 1338 | Contributors (this commit): 11 | Commits (past 90d): 6 | Contributors (cumulative): 16 | DMM Complexity: 0.9556962025316456\n\nDIFF:\n@@ -324,6 +324,112 @@ class BinaryCrossentropy(LossFunctionWrapper):\n         self.from_logits = from_logits\n \n \n+class CategoricalCrossentropy(LossFunctionWrapper):\n+    \"\"\"Computes the crossentropy loss between the labels and predictions.\n+\n+    Use this crossentropy loss function when there are two or more label classes.\n+    We expect labels to be provided in a `one_hot` representation. If you want to\n+    provide labels as integers, please use `SparseCategoricalCrossentropy` loss.\n+    There should be `# classes` floating point values per feature.\n+\n+    In the snippet below, there is `# classes` floating pointing values per\n+    example. The shape of both `y_pred` and `y_true` are\n+    `[batch_size, num_classes]`.\n+\n+    Standalone usage:\n+\n+    ```python\n+    cce = keras.losses.CategoricalCrossentropy()\n+    loss = cce(\n+        [[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]],\n+        [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n+    ```\n+\n+    Usage with the `compile` API:\n+\n+    ```python\n+    model = keras.Model(inputs, outputs)\n+    model.compile('sgd', loss=keras.losses.CategoricalCrossentropy())\n+    ```\n+\n+    # Arguments\n+        from_logits: Whether to interpret `y_pred` as a tensor of\n+            [logit](https://en.wikipedia.org/wiki/Logit) values. By default,\n+            we assume that `y_pred` contains probabilities\n+            (i.e., values in [0, 1]).\n+        label_smoothing: Float in [0, 1]. When 0, no smoothing occurs. When > 0, we\n+            compute the loss between the predicted labels and a smoothed version of\n+            the true labels, where the smoothing squeezes the labels towards 0.5.\n+            Larger values of `label_smoothing` correspond to heavier smoothing.\n+        reduction: (Optional) Type of loss reduction to apply to loss.\n+            Default value is `SUM_OVER_BATCH_SIZE`.\n+        name: (Optional) Name for the op.\n+    \"\"\"\n+\n+    def __init__(self,\n+                 from_logits=False,\n+                 label_smoothing=0,\n+                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n+                 name='categorical_crossentropy'):\n+        super(CategoricalCrossentropy, self).__init__(\n+            categorical_crossentropy,\n+            name=name,\n+            reduction=reduction,\n+            from_logits=from_logits,\n+            label_smoothing=label_smoothing)\n+\n+\n+class SparseCategoricalCrossentropy(LossFunctionWrapper):\n+    \"\"\"Computes the crossentropy loss between the labels and predictions.\n+\n+    Use this crossentropy loss function when there are two or more label classes.\n+    We expect labels to be provided as integers. If you want to provide labels\n+    using `one-hot` representation, please use `CategoricalCrossentropy` loss.\n+    There should be `# classes` floating point values per feature for `y_pred`\n+    and a single floating point value per feature for `y_true`.\n+\n+    In the snippet below, there is a single floating point value per example for\n+    `y_true` and `# classes` floating pointing values per example for `y_pred`.\n+    The shape of `y_true` is `[batch_size]` and the shape of `y_pred` is\n+    `[batch_size, num_classes]`.\n+\n+    Standalone usage:\n+\n+    ```python\n+    cce = keras.losses.SparseCategoricalCrossentropy()\n+    loss = cce(\n+        [0, 1, 2],\n+        [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n+    ```\n+\n+    Usage with the `compile` API:\n+\n+    ```python\n+    model = keras.Model(inputs, outputs)\n+    model.compile('sgd', loss=keras.losses.SparseCategoricalCrossentropy())\n+    ```\n+\n+    # Arguments\n+        from_logits: Whether to interpret `y_pred` as a tensor of\n+            [logit](https://en.wikipedia.org/wiki/Logit) values. By default,\n+            we assume that `y_pred` contains probabilities\n+            (i.e., values in [0, 1]).\n+        reduction: (Optional) Type of loss reduction to apply to loss.\n+            Default value is `SUM_OVER_BATCH_SIZE`.\n+        name: (Optional) Name for the op.\n+    \"\"\"\n+\n+    def __init__(self,\n+                 from_logits=False,\n+                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n+                 name='sparse_categorical_crossentropy'):\n+        super(SparseCategoricalCrossentropy, self).__init__(\n+            sparse_categorical_crossentropy,\n+            name=name,\n+            reduction=reduction,\n+            from_logits=from_logits)\n+\n+\n def mean_squared_error(y_true, y_pred):\n     if not K.is_tensor(y_pred):\n         y_pred = K.constant(y_pred)\n@@ -391,12 +497,23 @@ def logcosh(y_true, y_pred):\n     return K.mean(_logcosh(y_pred - y_true), axis=-1)\n \n \n-def categorical_crossentropy(y_true, y_pred):\n-    return K.categorical_crossentropy(y_true, y_pred)\n+def categorical_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0):\n+    if not K.is_tensor(y_pred):\n+        y_pred = K.constant(y_pred)\n+    y_true = K.cast(y_true, y_pred.dtype)\n+    label_smoothing = K.cast_to_floatx(label_smoothing)\n+\n+    def _smooth_labels():\n+        num_classes = K.cast(K.shape(y_true)[1], y_pred.dtype)\n+        return y_true * (1.0 - label_smoothing) + (label_smoothing / num_classes)\n+\n+    y_true = K.switch(K.greater(label_smoothing, 0), _smooth_labels, lambda: y_true)\n+    return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n \n \n-def sparse_categorical_crossentropy(y_true, y_pred):\n-    return K.sparse_categorical_crossentropy(y_true, y_pred)\n+def sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1):\n+    return K.sparse_categorical_crossentropy(\n+        y_true, y_pred, from_logits=from_logits, axis=axis)\n \n \n def binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0):\n@@ -439,6 +556,15 @@ kld = KLD = kullback_leibler_divergence\n cosine = cosine_proximity\n \n \n+def is_categorical_crossentropy(loss):\n+    return (isinstance(loss, CategoricalCrossentropy or\n+            (isinstance(loss, LossFunctionWrapper) and\n+                loss.fn == categorical_crossentropy) or\n+            (hasattr(loss, '__name__') and\n+                loss.__name__ == 'categorical_crossentropy') or\n+            loss == 'categorical_crossentropy'))\n+\n+\n def serialize(loss):\n     return serialize_keras_object(loss)\n \n\n@@ -543,5 +543,173 @@ class TestBinaryCrossentropy:\n         assert np.isclose(K.eval(loss), expected_value, atol=1e-3)\n \n \n+class TestCategoricalCrossentropy:\n+\n+    def test_config(self):\n+        cce_obj = losses.CategoricalCrossentropy(\n+            reduction=losses_utils.Reduction.SUM, name='bce_1')\n+        assert cce_obj.name == 'bce_1'\n+        assert cce_obj.reduction == losses_utils.Reduction.SUM\n+\n+    def test_all_correct_unweighted(self):\n+        y_true = K.constant([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n+        y_pred = K.constant([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])\n+        cce_obj = losses.CategoricalCrossentropy()\n+        loss = cce_obj(y_true, y_pred)\n+        assert np.isclose(K.eval(loss), 0.0, atol=1e-3)\n+\n+        # Test with logits.\n+        logits = K.constant([[10., 0., 0.], [0., 10., 0.], [0., 0., 10.]])\n+        cce_obj = losses.CategoricalCrossentropy(from_logits=True)\n+        loss = cce_obj(y_true, logits)\n+        assert np.isclose(K.eval(loss), 0.0, atol=1e-3)\n+\n+    def test_unweighted(self):\n+        cce_obj = losses.CategoricalCrossentropy()\n+        y_true = K.constant([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n+        y_pred = K.constant(\n+            [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n+        loss = cce_obj(y_true, y_pred)\n+        assert np.isclose(K.eval(loss), .3239, atol=1e-3)\n+\n+        # Test with logits.\n+        logits = K.constant([[8., 1., 1.], [0., 9., 1.], [2., 3., 5.]])\n+        cce_obj = losses.CategoricalCrossentropy(from_logits=True)\n+        loss = cce_obj(y_true, logits)\n+        assert np.isclose(K.eval(loss), .05737, atol=1e-3)\n+\n+    def test_scalar_weighted(self):\n+        cce_obj = losses.CategoricalCrossentropy()\n+        y_true = K.constant([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n+        y_pred = K.constant(\n+            [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n+        loss = cce_obj(y_true, y_pred, sample_weight=2.3)\n+        assert np.isclose(K.eval(loss), .7449, atol=1e-3)\n+\n+        # Test with logits.\n+        logits = K.constant([[8., 1., 1.], [0., 9., 1.], [2., 3., 5.]])\n+        cce_obj = losses.CategoricalCrossentropy(from_logits=True)\n+        loss = cce_obj(y_true, logits, sample_weight=2.3)\n+        assert np.isclose(K.eval(loss), .132, atol=1e-3)\n+\n+    def test_sample_weighted(self):\n+        cce_obj = losses.CategoricalCrossentropy()\n+        y_true = K.constant([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n+        y_pred = K.constant(\n+            [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n+        sample_weight = K.constant([[1.2], [3.4], [5.6]], shape=(3, 1))\n+        loss = cce_obj(y_true, y_pred, sample_weight=sample_weight)\n+        assert np.isclose(K.eval(loss), 1.0696, atol=1e-3)\n+\n+        # Test with logits.\n+        logits = K.constant([[8., 1., 1.], [0., 9., 1.], [2., 3., 5.]])\n+        cce_obj = losses.CategoricalCrossentropy(from_logits=True)\n+        loss = cce_obj(y_true, logits, sample_weight=sample_weight)\n+        assert np.isclose(K.eval(loss), 0.31829, atol=1e-3)\n+\n+    def test_no_reduction(self):\n+        y_true = K.constant([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n+        logits = K.constant([[8., 1., 1.], [0., 9., 1.], [2., 3., 5.]])\n+        cce_obj = losses.CategoricalCrossentropy(\n+            from_logits=True, reduction=losses_utils.Reduction.NONE)\n+        loss = cce_obj(y_true, logits)\n+        assert np.allclose(K.eval(loss), (0.001822, 0.000459, 0.169846), atol=1e-3)\n+\n+    def test_label_smoothing(self):\n+        logits = K.constant([[100.0, -100.0, -100.0]])\n+        y_true = K.constant([[1, 0, 0]])\n+        label_smoothing = 0.1\n+        # Softmax Cross Entropy Loss: -\\sum_i p_i \\log q_i\n+        # where for a softmax activation\n+        # \\log q_i = x_i - \\log \\sum_j \\exp x_j\n+        #          = x_i - x_max - \\log \\sum_j \\exp (x_j - x_max)\n+        # For our activations, [100, -100, -100]\n+        # \\log ( exp(0) + exp(-200) + exp(-200) ) = 0\n+        # so our log softmaxes become: [0, -200, -200]\n+        # Label smoothing: z' = z * (1 - L) + L/n\n+        #                  1  = 1 - L + L/n\n+        #                  0  = L/n\n+        # Applying the above two fns to the given input:\n+        # -0 * (1 - L + L/n) + 200 * L/n + 200 * L/n = 400 L/n\n+        cce_obj = losses.CategoricalCrossentropy(\n+            from_logits=True, label_smoothing=label_smoothing)\n+        loss = cce_obj(y_true, logits)\n+        expected_value = 400.0 * label_smoothing / 3.0\n+        assert np.isclose(K.eval(loss), expected_value, atol=1e-3)\n+\n+\n+class TestSparseCategoricalCrossentropy:\n+\n+    def test_config(self):\n+        cce_obj = losses.SparseCategoricalCrossentropy(\n+            reduction=losses_utils.Reduction.SUM, name='scc')\n+        assert cce_obj.name == 'scc'\n+        assert cce_obj.reduction == losses_utils.Reduction.SUM\n+\n+    def test_all_correct_unweighted(self):\n+        y_true = K.constant([[0], [1], [2]])\n+        y_pred = K.constant([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])\n+        cce_obj = losses.SparseCategoricalCrossentropy()\n+        loss = cce_obj(y_true, y_pred)\n+        assert np.isclose(K.eval(loss), 0.0, atol=1e-3)\n+\n+        # Test with logits.\n+        logits = K.constant([[10., 0., 0.], [0., 10., 0.], [0., 0., 10.]])\n+        cce_obj = losses.SparseCategoricalCrossentropy(from_logits=True)\n+        loss = cce_obj(y_true, logits)\n+        assert np.isclose(K.eval(loss), 0.0, atol=1e-3)\n+\n+    def test_unweighted(self):\n+        cce_obj = losses.SparseCategoricalCrossentropy()\n+        y_true = K.constant([0, 1, 2])\n+        y_pred = K.constant(\n+            [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n+        loss = cce_obj(y_true, y_pred)\n+        assert np.isclose(K.eval(loss), .3239, atol=1e-3)\n+\n+        # Test with logits.\n+        logits = K.constant([[8., 1., 1.], [0., 9., 1.], [2., 3., 5.]])\n+        cce_obj = losses.SparseCategoricalCrossentropy(from_logits=True)\n+        loss = cce_obj(y_true, logits)\n+        assert np.isclose(K.eval(loss), .0573, atol=1e-3)\n+\n+    def test_scalar_weighted(self):\n+        cce_obj = losses.SparseCategoricalCrossentropy()\n+        y_true = K.constant([[0], [1], [2]])\n+        y_pred = K.constant(\n+            [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n+        loss = cce_obj(y_true, y_pred, sample_weight=2.3)\n+        assert np.isclose(K.eval(loss), .7449, atol=1e-3)\n+\n+        # Test with logits.\n+        logits = K.constant([[8., 1., 1.], [0., 9., 1.], [2., 3., 5.]])\n+        cce_obj = losses.SparseCategoricalCrossentropy(from_logits=True)\n+        loss = cce_obj(y_true, logits, sample_weight=2.3)\n+        assert np.isclose(K.eval(loss), .1317, atol=1e-3)\n+\n+    def test_sample_weighted(self):\n+        cce_obj = losses.SparseCategoricalCrossentropy()\n+        y_true = K.constant([[0], [1], [2]])\n+        y_pred = K.constant(\n+            [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n+        sample_weight = K.constant([[1.2], [3.4], [5.6]], shape=(3, 1))\n+        loss = cce_obj(y_true, y_pred, sample_weight=sample_weight)\n+        assert np.isclose(K.eval(loss), 1.0696, atol=1e-3)\n+\n+        # Test with logits.\n+        logits = K.constant([[8., 1., 1.], [0., 9., 1.], [2., 3., 5.]])\n+        cce_obj = losses.SparseCategoricalCrossentropy(from_logits=True)\n+        loss = cce_obj(y_true, logits, sample_weight=sample_weight)\n+        assert np.isclose(K.eval(loss), 0.31829, atol=1e-3)\n+\n+    def test_no_reduction(self):\n+        y_true = K.constant([[0], [1], [2]])\n+        logits = K.constant([[8., 1., 1.], [0., 9., 1.], [2., 3., 5.]])\n+        cce_obj = losses.SparseCategoricalCrossentropy(\n+            from_logits=True, reduction=losses_utils.Reduction.NONE)\n+        loss = cce_obj(y_true, logits)\n+        assert np.allclose(K.eval(loss), (0.001822, 0.000459, 0.169846), atol=1e-3)\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
