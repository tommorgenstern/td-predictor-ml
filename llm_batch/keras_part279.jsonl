{"custom_id": "keras#7b9c8727760b2a8d02e409efaa6ff9e0333b02e1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 12059 | Contributors (this commit): 67 | Commits (past 90d): 3 | Contributors (cumulative): 67 | DMM Complexity: None\n\nDIFF:\n@@ -731,7 +731,7 @@ class Conv2DTranspose(Conv2D):\n         - [A guide to convolution arithmetic for deep learning](\n            https://arxiv.org/abs/1603.07285v1)\n         - [Deconvolutional Networks](\n-           http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)\n+           https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n     \"\"\"\n \n     @interfaces.legacy_deconv2d_support\n@@ -1006,7 +1006,7 @@ class Conv3DTranspose(Conv3D):\n         - [A guide to convolution arithmetic for deep learning](\n            https://arxiv.org/abs/1603.07285v1)\n         - [Deconvolutional Networks](\n-           http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)\n+           https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n     \"\"\"\n \n     def __init__(self, filters,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fca79866f4dd8df054d1643774175358f057d097", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 6372 | Contributors (this commit): 58 | Commits (past 90d): 2 | Contributors (cumulative): 58 | DMM Complexity: None\n\nDIFF:\n@@ -262,7 +262,7 @@ class ImageDataGenerator(image.ImageDataGenerator):\n                 are integers `[-1, 0, +1]`,\n                 same as with `height_shift_range=[-1, 0, +1]`,\n                 while with `height_shift_range=1.0` possible values are floats\n-                in the interval [-1.0, +1.0).\n+                in the interval [-1.0, +1.0].\n         brightness_range: Tuple or list of two floats. Range for picking\n             a brightness shift value from.\n         shear_range: Float. Shear Intensity\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c45ac7892ba32c167de80e6bba92ec519dae29d4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 6376 | Contributors (this commit): 58 | Commits (past 90d): 3 | Contributors (cumulative): 58 | DMM Complexity: None\n\nDIFF:\n@@ -252,7 +252,7 @@ class ImageDataGenerator(image.ImageDataGenerator):\n                 are integers `[-1, 0, +1]`,\n                 same as with `width_shift_range=[-1, 0, +1]`,\n                 while with `width_shift_range=1.0` possible values are floats\n-                in the interval [-1.0, +1.0).\n+                in the half-open interval `[-1.0, +1.0[`.\n         height_shift_range: Float, 1-D array-like or int\n             - float: fraction of total height, if < 1, or pixels if >= 1.\n             - 1-D array-like: random elements from the array.\n@@ -262,7 +262,7 @@ class ImageDataGenerator(image.ImageDataGenerator):\n                 are integers `[-1, 0, +1]`,\n                 same as with `height_shift_range=[-1, 0, +1]`,\n                 while with `height_shift_range=1.0` possible values are floats\n-                in the interval [-1.0, +1.0].\n+                in the half-open interval `[-1.0, +1.0[`.\n         brightness_range: Tuple or list of two floats. Range for picking\n             a brightness shift value from.\n         shear_range: Float. Shear Intensity\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2e0de19d629e2eb5be4f614049e5f0d32887d155", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 46 | Contributors (this commit): 7 | Commits (past 90d): 2 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -21,6 +21,7 @@ from .generic_utils import Progbar\n from .layer_utils import convert_all_kernels_in_model\n from .layer_utils import get_source_inputs\n from .layer_utils import print_summary\n+from .vis_utils import model_to_dot\n from .vis_utils import plot_model\n from .np_utils import to_categorical\n from .np_utils import normalize\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e11c48d9ce3ee47bb8a966549b14cbd5b10ee70d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 25 | Churn Cumulative: 2636 | Contributors (this commit): 26 | Commits (past 90d): 13 | Contributors (cumulative): 33 | DMM Complexity: 0.8571428571428571\n\nDIFF:\n@@ -170,6 +170,9 @@ def get_file(fname,\n         Path to the downloaded file\n     \"\"\"  # noqa\n     if cache_dir is None:\n+        if 'KERAS_HOME' in os.environ:\n+            cache_dir = os.environ.get('KERAS_HOME')\n+        else:\n             cache_dir = os.path.join(os.path.expanduser('~'), '.keras')\n     if md5_hash is not None and file_hash is None:\n         file_hash = md5_hash\n\n@@ -5,6 +5,7 @@ import time\n import sys\n import tarfile\n import threading\n+import shutil\n import zipfile\n from itertools import cycle\n import multiprocessing as mp\n@@ -13,6 +14,7 @@ import pytest\n import six\n from six.moves.urllib.parse import urljoin\n from six.moves.urllib.request import pathname2url\n+from six.moves import reload_module\n \n from flaky import flaky\n \n@@ -83,6 +85,25 @@ def test_data_utils(in_tmpdir):\n \n     origin = urljoin('file://', pathname2url(os.path.abspath('test.tar.gz')))\n \n+    path = get_file(dirname, origin, untar=True)\n+    filepath = path + '.tar.gz'\n+    data_keras_home = os.path.dirname(os.path.dirname(os.path.abspath(filepath)))\n+    assert data_keras_home == os.path.dirname(K._config_path)\n+    os.remove(filepath)\n+\n+    _keras_home = os.path.join(os.path.abspath('.'), '.keras')\n+    if not os.path.exists(_keras_home):\n+        os.makedirs(_keras_home)\n+    os.environ['KERAS_HOME'] = _keras_home\n+    reload_module(K)\n+    path = get_file(dirname, origin, untar=True)\n+    filepath = path + '.tar.gz'\n+    data_keras_home = os.path.dirname(os.path.dirname(os.path.abspath(filepath)))\n+    assert data_keras_home == os.path.dirname(K._config_path)\n+    os.environ.pop('KERAS_HOME')\n+    shutil.rmtree(_keras_home)\n+    reload_module(K)\n+\n     path = get_file(dirname, origin, untar=True)\n     filepath = path + '.tar.gz'\n     hashval_sha256 = _hash_file(filepath)\n@@ -106,6 +127,7 @@ def test_data_utils(in_tmpdir):\n     assert validate_file(path, hashval_md5)\n \n     os.remove(path)\n+    os.remove(os.path.join(os.path.dirname(path), 'test.txt'))\n     os.remove('test.txt')\n     os.remove('test.zip')\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#88cf9707530f9bb3246779aee0138e49efecc500", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 446 | Contributors (this commit): 13 | Commits (past 90d): 1 | Contributors (cumulative): 13 | DMM Complexity: 0.0\n\nDIFF:\n@@ -101,7 +101,5 @@ def get_word_index(path='reuters_word_index.json'):\n         path,\n         origin='https://s3.amazonaws.com/text-datasets/reuters_word_index.json',\n         file_hash='4d44cc38712099c9e383dc6e5f11a921')\n-    f = open(path)\n-    data = json.load(f)\n-    f.close()\n-    return data\n+    with open(path) as f:\n+        return json.load(f)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#425e99a9e3d00c7d505d585e00e85ee716e3c350", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 3 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 3483 | Contributors (this commit): 39 | Commits (past 90d): 11 | Contributors (cumulative): 50 | DMM Complexity: None\n\nDIFF:\n@@ -34,7 +34,7 @@ def tokenize(sent):\n     >>> tokenize('Bob dropped the apple. Where is the apple?')\n     ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n     '''\n-    return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]\n+    return [x.strip() for x in re.split(r'(\\W+)?', sent) if x.strip()]\n \n \n def parse_stories(lines, only_supporting=False):\n\n@@ -78,7 +78,7 @@ def tokenize(sent):\n     >>> tokenize('Bob dropped the apple. Where is the apple?')\n     ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n     '''\n-    return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]\n+    return [x.strip() for x in re.split(r'(\\W+)?', sent) if x.strip()]\n \n \n def parse_stories(lines, only_supporting=False):\n\n@@ -1130,12 +1130,12 @@ def test_target_tensors():\n     # multi-output, not enough target tensors when `target_tensors` is not a dict\n     with pytest.raises(ValueError,\n                        match='When passing a list as `target_tensors`, it should '\n-                             'have one entry per model output. The model has \\d '\n+                             'have one entry per model output. The model has \\\\d '\n                              'outputs, but you passed target_tensors='):\n         model.compile(optimizer='rmsprop', loss='mse',\n                       target_tensors=[target_a])\n     with pytest.raises(ValueError,\n-                       match='The model has \\d outputs, but you passed a single '\n+                       match='The model has \\\\d outputs, but you passed a single '\n                              'tensor as `target_tensors`. Expected a list or '\n                              'a dict of tensors.'):\n         model.compile(optimizer='rmsprop', loss='mse',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5394c04a3a3b16db1d3cb4c24b403c79cf2b3108", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 3 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -0,0 +1,3 @@\n+from __future__ import absolute_import\r\n+\r\n+from . import scikit_learn\r\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1d81a20292ca6926e595d06a6cd725dbb104a146", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 10 | Files Changed: 3 | Hunks: 9 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/4 | Churn Δ: 40 | Churn Cumulative: 10499 | Contributors (this commit): 68 | Commits (past 90d): 6 | Contributors (cumulative): 77 | DMM Complexity: 0.8235294117647058\n\nDIFF:\n@@ -268,8 +268,8 @@ class Identity(Initializer):\n     \"\"\"Initializer that generates the identity matrix.\n \n     Only use for 2D matrices.\n-    If the long side of the matrix is a multiple of the short side,\n-    multiple identity matrices are concatenated along the long side.\n+    If the desired matrix is not square, it pads with zeros on the\n+    additional rows/columns\n \n     # Arguments\n         gain: Multiplicative factor to apply to the identity matrix.\n@@ -283,17 +283,20 @@ class Identity(Initializer):\n             raise ValueError(\n                 'Identity matrix initializer can only be used for 2D matrices.')\n \n-        if max(shape) % min(shape) != 0:\n-            raise ValueError('Long side should be multiple of short side.')\n-\n         if shape[0] == shape[1]:\n             return self.gain * np.identity(shape[0])\n         elif shape[0] > shape[1]:\n             return self.gain * np.concatenate(\n-                [np.identity(shape[1])] * (shape[0] // shape[1]), axis=0)\n+                [np.identity(shape[1]),\n+                 np.zeros((shape[0] - shape[1], shape[1]))],\n+                axis=0\n+            )\n         else:\n             return self.gain * np.concatenate(\n-                [np.identity(shape[0])] * (shape[1] // shape[0]), axis=1)\n+                [np.identity(shape[0]),\n+                 np.zeros((shape[0], shape[1] - shape[0]))],\n+                axis=1\n+            )\n \n     def get_config(self):\n         return {\n\n@@ -1267,6 +1267,14 @@ class GRUCell(Layer):\n \n     def build(self, input_shape):\n         input_dim = input_shape[-1]\n+\n+        if isinstance(self.recurrent_initializer, initializers.Identity):\n+            def recurrent_identity(shape, gain=1.):\n+                return gain * np.concatenate(\n+                    [np.identity(shape[0])] * (shape[1] // shape[0]), axis=1)\n+\n+            self.recurrent_initializer = recurrent_identity\n+\n         self.kernel = self.add_weight(shape=(input_dim, self.units * 3),\n                                       name='kernel',\n                                       initializer=self.kernel_initializer,\n@@ -1862,6 +1870,14 @@ class LSTMCell(Layer):\n \n     def build(self, input_shape):\n         input_dim = input_shape[-1]\n+\n+        if type(self.recurrent_initializer).__name__ == 'Identity':\n+            def recurrent_identity(shape, gain=1.):\n+                return gain * np.concatenate(\n+                    [np.identity(shape[0])] * (shape[1] // shape[0]), axis=1)\n+\n+            self.recurrent_initializer = recurrent_identity\n+\n         self.kernel = self.add_weight(shape=(input_dim, self.units * 4),\n                                       name='kernel',\n                                       initializer=self.kernel_initializer,\n\n@@ -108,13 +108,14 @@ def test_orthogonal(tensor_shape):\n                          [(100, 100), (10, 20), (30, 80), (1, 2, 3, 4)],\n                          ids=['FC', 'RNN', 'RNN_INVALID', 'CONV'])\n def test_identity(tensor_shape):\n-    if len(tensor_shape) > 2 or max(tensor_shape) % min(tensor_shape) != 0:\n+    target_mean = (1. * min(tensor_shape)) / (tensor_shape[0] * tensor_shape[1])\n+    if len(tensor_shape) > 2:\n         with pytest.raises(ValueError):\n             _runner(initializers.identity(), tensor_shape,\n-                    target_mean=1. / tensor_shape[0], target_max=1.)\n+                    target_mean=target_mean, target_max=1.)\n     else:\n         _runner(initializers.identity(), tensor_shape,\n-                target_mean=1. / tensor_shape[0], target_max=1.)\n+                target_mean=target_mean, target_max=1.)\n \n \n @pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5a8c85f1261e926a7f4bb52fb72935c574476ac3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 3331 | Contributors (this commit): 42 | Commits (past 90d): 3 | Contributors (cumulative): 46 | DMM Complexity: None\n\nDIFF:\n@@ -182,7 +182,7 @@ def is_valid_str(in_str):\n \n \n # Uses generator functions to supply train/test with\n-# data. Image renderings are text are created on the fly\n+# data. Image renderings and text are created on the fly\n # each time with random perturbations\n \n class TextImageGenerator(keras.callbacks.Callback):\n\n@@ -291,7 +291,7 @@ class Adagrad(Optimizer):\n     Adagrad is an optimizer with parameter-specific learning rates,\n     which are adapted relative to how frequently a parameter gets\n     updated during training. The more updates a parameter receives,\n-    the smaller the updates.\n+    the smaller the learning rate.\n \n     It is recommended to leave the parameters of this optimizer\n     at their default values.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0cd3b07eb5de1aaaad84d1ff7f7c2ed7dab4b23c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 158 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -6,12 +6,6 @@ from keras import applications\n from keras import backend as K\n \n \n-pytestmark = pytest.mark.skipif(\n-    os.environ.get('CORE_CHANGED', 'True') == 'False' and\n-    os.environ.get('APP_CHANGED', 'True') == 'False',\n-    reason='Runs only when the relevant files have been modified.')\n-\n-\n MODEL_LIST = [\n     (applications.ResNet50, 2048),\n     (applications.VGG16, 512),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0505393746d56ddacc34bb1c016dba79429c9ac9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 29 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 34 | Churn Cumulative: 2668 | Contributors (this commit): 32 | Commits (past 90d): 13 | Contributors (cumulative): 35 | DMM Complexity: None\n\nDIFF:\n@@ -117,8 +117,8 @@ def count_leading_spaces(s):\n def process_list_block(docstring, starting_point, section_end,\n                        leading_spaces, marker):\n     ending_point = docstring.find('\\n\\n', starting_point)\n-    block = docstring[starting_point:(None if ending_point == -1 else\n-                                      ending_point - 1)]\n+    block = docstring[starting_point:(ending_point - 1 if ending_point > -1 else\n+                                      section_end)]\n     # Place marker for later reinjection.\n     docstring_slice = docstring[starting_point:section_end].replace(block, marker)\n     docstring = (docstring[:starting_point]\n\n@@ -326,9 +326,33 @@ y = layer(x)\n '''}\n \n \n-def test_doc_lists():\n-    docstring = autogen.process_docstring(test_doc1['doc'])\n-    assert markdown(docstring) == markdown(test_doc1['result'])\n+test_doc_with_arguments_as_last_block = {\n+    'doc': \"\"\"Base class for recurrent layers.\n+\n+    # Arguments\n+        return_sequences: Boolean. Whether to return the last output\n+            in the output sequence, or the full sequence.\n+        return_state: Boolean. Whether to return the last state\n+            in addition to the output.\n+    \"\"\",\n+    'result': '''Base class for recurrent layers.\n+\n+__Arguments__\n+\n+- __return_sequences__: Boolean. Whether to return the last output\n+    in the output sequence, or the full sequence.\n+- __return_state__: Boolean. Whether to return the last state\n+    in addition to the output.\n+'''}\n+\n+\n+@pytest.mark.parametrize('docs_descriptor', [\n+    test_doc1,\n+    test_doc_with_arguments_as_last_block,\n+])\n+def test_doc_lists(docs_descriptor):\n+    docstring = autogen.process_docstring(docs_descriptor['doc'])\n+    assert markdown(docstring) == markdown(docs_descriptor['result'])\n \n \n dummy_docstring = \"\"\"Multiplies 2 tensors (and/or variables) and returns a *tensor*.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3821c77da30e420fb78231d306b18dbfa1131fb7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 4 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 1937 | Contributors (this commit): 14 | Commits (past 90d): 5 | Contributors (cumulative): 17 | DMM Complexity: 0.0\n\nDIFF:\n@@ -21,8 +21,7 @@ def load_data(path='mnist.npz'):\n     path = get_file(path,\n                     origin='https://s3.amazonaws.com/img-datasets/mnist.npz',\n                     file_hash='8a61469f7ea1b51cbae51d4f78837e45')\n-    f = np.load(path)\n+    with np.load(path) as f:\n         x_train, y_train = f['x_train'], f['y_train']\n         x_test, y_test = f['x_test'], f['y_test']\n-    f.close()\n     return (x_train, y_train), (x_test, y_test)\n\n@@ -315,8 +315,7 @@ def test_multiprocessing_training_from_file(in_tmpdir):\n         batch_size = 10\n         n_samples = 50\n \n-        arr = np.load('data.npz')\n-\n+        with np.load('data.npz') as arr:\n             while True:\n                 batch_index = np.random.randint(0, n_samples - batch_size)\n                 start = batch_index\n@@ -407,8 +406,7 @@ def test_multithreading_from_file():\n         batch_size = 10\n         n_samples = 50\n \n-        arr = np.load('data_threads.npz')\n-\n+        with np.load('data_threads.npz') as arr:\n             while True:\n                 batch_index = np.random.randint(0, n_samples - batch_size)\n                 start = batch_index\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#87a746878ba2359a7fb8135ed5829e6c5003b4db", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 21 | Churn Cumulative: 3747 | Contributors (this commit): 30 | Commits (past 90d): 5 | Contributors (cumulative): 30 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1720,6 +1720,12 @@ def separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n     if isinstance(dilation_rate, int):\n         dilation_rate = (dilation_rate,)\n \n+    if dilation_rate != (1,):\n+        raise ValueError(\n+            'Dilated separable 1D convolution is currently not supported '\n+            'by CNTK backend. Please set `dilation_rate` to 1. '\n+            'You passed: %s' % (dilation_rate,))\n+\n     if data_format == 'channels_last':\n         spatial_start_dim = 2\n     else:\n@@ -1737,20 +1743,6 @@ def separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n     pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel, data_format)\n     padding = _preprocess_border_mode(padding)\n \n-    if dilation_rate == (1, 1):\n-        x = C.convolution(depthwise_kernel, x,\n-                          strides=strides,\n-                          auto_padding=[False, padding, padding],\n-                          groups=x.shape[0])\n-        x = C.convolution(pointwise_kernel, x,\n-                          strides=(1, 1, 1),\n-                          auto_padding=[False])\n-    else:\n-        if dilation_rate[0] != dilation_rate[1]:\n-            raise ValueError('CNTK Backend: non-square dilation_rate is '\n-                             'not supported.')\n-        if strides != (1, 1):\n-            raise ValueError('Invalid strides for dilated convolution')\n     x = C.convolution(depthwise_kernel, x,\n                       strides=strides,\n                       auto_padding=[False, padding, padding],\n@@ -1758,6 +1750,7 @@ def separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n     x = C.convolution(pointwise_kernel, x,\n                       strides=(1, 1, 1),\n                       auto_padding=[False])\n+\n     x = _postprocess_conv2d_output(x, data_format)\n     return squeeze(x, spatial_start_dim)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6096ded90df902e1f8a21f666748a03100d140c0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 15 | Churn Cumulative: 668 | Contributors (this commit): 9 | Commits (past 90d): 3 | Contributors (cumulative): 9 | DMM Complexity: 0.0\n\nDIFF:\n@@ -283,20 +283,7 @@ class Identity(Initializer):\n             raise ValueError(\n                 'Identity matrix initializer can only be used for 2D matrices.')\n \n-        if shape[0] == shape[1]:\n-            return self.gain * np.identity(shape[0])\n-        elif shape[0] > shape[1]:\n-            return self.gain * np.concatenate(\n-                [np.identity(shape[1]),\n-                 np.zeros((shape[0] - shape[1], shape[1]))],\n-                axis=0\n-            )\n-        else:\n-            return self.gain * np.concatenate(\n-                [np.identity(shape[0]),\n-                 np.zeros((shape[0], shape[1] - shape[0]))],\n-                axis=1\n-            )\n+        return self.gain * np.eye(shape[0], shape[1])\n \n     def get_config(self):\n         return {\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1336cdb14ff03de754aec6899794742ca91057b2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 817 | Lines Deleted: 102 | Files Changed: 5 | Hunks: 98 | Methods Changed: 54 | Complexity Δ (Sum/Max): 61/28 | Churn Δ: 919 | Churn Cumulative: 15864 | Contributors (this commit): 163 | Commits (past 90d): 12 | Contributors (cumulative): 222 | DMM Complexity: 0.7425\n\nDIFF:\n@@ -17,6 +17,7 @@ import io\n from collections import deque\n from collections import OrderedDict\n from collections import Iterable\n+from collections import defaultdict\n from .utils.generic_utils import Progbar\n from . import backend as K\n from .engine.training_utils import standardize_input_data\n@@ -27,6 +28,11 @@ except ImportError:\n     requests = None\n \n \n+_TRAIN = 'train'\n+_TEST = 'test'\n+_PREDICT = 'predict'\n+\n+\n class CallbackList(object):\n     \"\"\"Container abstracting a list of callbacks.\n \n@@ -40,107 +46,227 @@ class CallbackList(object):\n         callbacks = callbacks or []\n         self.callbacks = [c for c in callbacks]\n         self.queue_length = queue_length\n+        self.params = {}\n+        self.model = None\n+        self._reset_batch_timing()\n+\n+    def _reset_batch_timing(self):\n+        self._delta_t_batch = 0.\n+        self._delta_ts = defaultdict(lambda: deque([], maxlen=self.queue_length))\n \n     def append(self, callback):\n         self.callbacks.append(callback)\n \n     def set_params(self, params):\n+        self.params = params\n         for callback in self.callbacks:\n             callback.set_params(params)\n \n     def set_model(self, model):\n+        self.model = model\n         for callback in self.callbacks:\n             callback.set_model(model)\n \n+    def _call_batch_hook(self, mode, hook, batch, logs=None):\n+        \"\"\"Helper function for all batch_{begin | end} methods.\"\"\"\n+        if not self.callbacks:\n+            return\n+        hook_name = 'on_{mode}_batch_{hook}'.format(mode=mode, hook=hook)\n+        if hook == 'end':\n+            if not hasattr(self, '_t_enter_batch'):\n+                self._t_enter_batch = time.time()\n+            # Batch is ending, calculate batch time\n+            self._delta_t_batch = time.time() - self._t_enter_batch\n+\n+        logs = logs or {}\n+        t_before_callbacks = time.time()\n+        for callback in self.callbacks:\n+            batch_hook = getattr(callback, hook_name)\n+            batch_hook(batch, logs)\n+        self._delta_ts[hook_name].append(time.time() - t_before_callbacks)\n+\n+        delta_t_median = np.median(self._delta_ts[hook_name])\n+        if (self._delta_t_batch > 0. and\n+           delta_t_median > 0.95 * self._delta_t_batch and\n+           delta_t_median > 0.1):\n+            warnings.warn(\n+                'Method (%s) is slow compared '\n+                'to the batch update (%f). Check your callbacks.', hook_name,\n+                delta_t_median)\n+        if hook == 'begin':\n+            self._t_enter_batch = time.time()\n+\n+    def _call_begin_hook(self, mode):\n+        \"\"\"Helper function for on_{train|test|predict}_begin methods.\"\"\"\n+        if mode == _TRAIN:\n+            self.on_train_begin()\n+        elif mode == _TEST:\n+            self.on_test_begin()\n+        else:\n+            self.on_predict_begin()\n+\n+    def _call_end_hook(self, mode):\n+        \"\"\"Helper function for on_{train|test|predict}_end methods.\"\"\"\n+        if mode == _TRAIN:\n+            self.on_train_end()\n+        elif mode == _TEST:\n+            self.on_test_end()\n+        else:\n+            self.on_predict_end()\n+\n+    def on_batch_begin(self, batch, logs=None):\n+        self._call_batch_hook(_TRAIN, 'begin', batch, logs=logs)\n+\n+    def on_batch_end(self, batch, logs=None):\n+        self._call_batch_hook(_TRAIN, 'end', batch, logs=logs)\n+\n     def on_epoch_begin(self, epoch, logs=None):\n-        \"\"\"Called at the start of an epoch.\n+        \"\"\"Calls the `on_epoch_begin` methods of its callbacks.\n+\n+        This function should only be called during train mode.\n \n         # Arguments\n             epoch: integer, index of epoch.\n-            logs: dictionary of logs.\n+            logs: dict, Currently no data is passed to this argument for this method\n+                but that may change in the future.\n         \"\"\"\n         logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_epoch_begin(epoch, logs)\n-        self._delta_t_batch = 0.\n-        self._delta_ts_batch_begin = deque([], maxlen=self.queue_length)\n-        self._delta_ts_batch_end = deque([], maxlen=self.queue_length)\n+        self._reset_batch_timing()\n \n     def on_epoch_end(self, epoch, logs=None):\n-        \"\"\"Called at the end of an epoch.\n+        \"\"\"Calls the `on_epoch_end` methods of its callbacks.\n+\n+        This function should only be called during train mode.\n \n         # Arguments\n             epoch: integer, index of epoch.\n-            logs: dictionary of logs.\n+            logs: dict, metric results for this training epoch, and for the\n+                validation epoch if validation is performed. Validation result keys\n+                are prefixed with `val_`.\n         \"\"\"\n         logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_epoch_end(epoch, logs)\n \n-    def on_batch_begin(self, batch, logs=None):\n-        \"\"\"Called right before processing a batch.\n+    def on_train_batch_begin(self, batch, logs=None):\n+        \"\"\"Calls the `on_train_batch_begin` methods of its callbacks.\n \n         # Arguments\n             batch: integer, index of batch within the current epoch.\n-            logs: dictionary of logs.\n+            logs: dict, has keys `batch` and `size` representing the current\n+                batch number and the size of the batch.\n         \"\"\"\n-        logs = logs or {}\n-        t_before_callbacks = time.time()\n-        for callback in self.callbacks:\n-            callback.on_batch_begin(batch, logs)\n-        self._delta_ts_batch_begin.append(time.time() - t_before_callbacks)\n-        delta_t_median = np.median(self._delta_ts_batch_begin)\n-        if (self._delta_t_batch > 0. and\n-           delta_t_median > 0.95 * self._delta_t_batch and\n-           delta_t_median > 0.1):\n-            warnings.warn('Method on_batch_begin() is slow compared '\n-                          'to the batch update (%f). Check your callbacks.'\n-                          % delta_t_median)\n-        self._t_enter_batch = time.time()\n+        self._call_batch_hook(_TRAIN, 'begin', batch, logs=logs)\n \n-    def on_batch_end(self, batch, logs=None):\n-        \"\"\"Called at the end of a batch.\n+    def on_train_batch_end(self, batch, logs=None):\n+        \"\"\"Calls the `on_train_batch_end` methods of its callbacks.\n \n         # Arguments\n             batch: integer, index of batch within the current epoch.\n-            logs: dictionary of logs.\n+            logs: dict, metric results for this batch.\n         \"\"\"\n-        logs = logs or {}\n-        if not hasattr(self, '_t_enter_batch'):\n-            self._t_enter_batch = time.time()\n-        self._delta_t_batch = time.time() - self._t_enter_batch\n-        t_before_callbacks = time.time()\n-        for callback in self.callbacks:\n-            callback.on_batch_end(batch, logs)\n-        self._delta_ts_batch_end.append(time.time() - t_before_callbacks)\n-        delta_t_median = np.median(self._delta_ts_batch_end)\n-        if (self._delta_t_batch > 0. and\n-           (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1)):\n-            warnings.warn('In your callbacks, method `on_batch_end()` '\n-                          'is slow compared to a model step '\n-                          '(%f vs %f). Check your callbacks.'\n-                          % (delta_t_median, self._delta_t_batch))\n+        self._call_batch_hook(_TRAIN, 'end', batch, logs=logs)\n+\n+    def on_test_batch_begin(self, batch, logs=None):\n+        \"\"\"Calls the `on_test_batch_begin` methods of its callbacks.\n+\n+        # Arguments\n+            batch: integer, index of batch within the current epoch.\n+            logs: dict, has keys `batch` and `size` representing the current\n+                batch number and the size of the batch.\n+        \"\"\"\n+        self._call_batch_hook(_TEST, 'begin', batch, logs=logs)\n+\n+    def on_test_batch_end(self, batch, logs=None):\n+        \"\"\"Calls the `on_test_batch_end` methods of its callbacks.\n+\n+        # Arguments\n+            batch: integer, index of batch within the current epoch.\n+            logs: dict, metric results for this batch.\n+        \"\"\"\n+        self._call_batch_hook(_TEST, 'end', batch, logs=logs)\n+\n+    def on_predict_batch_begin(self, batch, logs=None):\n+        \"\"\"Calls the `on_predict_batch_begin` methods of its callbacks.\n+\n+        # Arguments\n+            batch: integer, index of batch within the current epoch.\n+            logs: dict, has keys `batch` and `size` representing the current\n+                batch number and the size of the batch.\n+        \"\"\"\n+        self._call_batch_hook(_PREDICT, 'begin', batch, logs=logs)\n+\n+    def on_predict_batch_end(self, batch, logs=None):\n+        \"\"\"Calls the `on_predict_batch_end` methods of its callbacks.\n+\n+        # Argument\n+            batch: integer, index of batch within the current epoch.\n+            logs: dict, metric results for this batch.\n+        \"\"\"\n+        self._call_batch_hook(_PREDICT, 'end', batch, logs=logs)\n \n     def on_train_begin(self, logs=None):\n-        \"\"\"Called at the beginning of training.\n+        \"\"\"Calls the `on_train_begin` methods of its callbacks.\n \n         # Arguments\n-            logs: dictionary of logs.\n+            logs: dict, currently no data is passed to this argument for this method\n+                but that may change in the future.\n         \"\"\"\n-        logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_train_begin(logs)\n \n     def on_train_end(self, logs=None):\n-        \"\"\"Called at the end of training.\n+        \"\"\"Calls the `on_train_end` methods of its callbacks.\n \n         # Arguments\n-            logs: dictionary of logs.\n+            logs: dict, currently no data is passed to this argument for this method\n+                but that may change in the future.\n         \"\"\"\n-        logs = logs or {}\n         for callback in self.callbacks:\n             callback.on_train_end(logs)\n \n+    def on_test_begin(self, logs=None):\n+        \"\"\"Calls the `on_test_begin` methods of its callbacks.\n+\n+        # Arguments\n+            logs: dict, currently no data is passed to this argument for this method\n+                but that may change in the future.\n+        \"\"\"\n+        for callback in self.callbacks:\n+            callback.on_test_begin(logs)\n+\n+    def on_test_end(self, logs=None):\n+        \"\"\"Calls the `on_test_end` methods of its callbacks.\n+\n+        # Arguments\n+            logs: dict, currently no data is passed to this argument for this method\n+                but that may change in the future.\n+        \"\"\"\n+        for callback in self.callbacks:\n+            callback.on_test_end(logs)\n+\n+    def on_predict_begin(self, logs=None):\n+        \"\"\"Calls the `on_predict_begin` methods of its callbacks.\n+\n+        # Arguments\n+            logs: dict, currently no data is passed to this argument for this method\n+                but that may change in the future.\n+        \"\"\"\n+        for callback in self.callbacks:\n+            callback.on_predict_begin(logs)\n+\n+    def on_predict_end(self, logs=None):\n+        \"\"\"Calls the `on_predict_end` methods of its callbacks.\n+\n+        # Arguments\n+            logs: dict, currently no data is passed to this argument for this method\n+                but that may change in the future.\n+        \"\"\"\n+        for callback in self.callbacks:\n+            callback.on_predict_end(logs)\n+\n     def __iter__(self):\n         return iter(self.callbacks)\n \n@@ -182,23 +308,169 @@ class Callback(object):\n     def set_model(self, model):\n         self.model = model\n \n-    def on_epoch_begin(self, epoch, logs=None):\n-        pass\n-\n-    def on_epoch_end(self, epoch, logs=None):\n-        pass\n-\n     def on_batch_begin(self, batch, logs=None):\n-        pass\n+        \"\"\"A backwards compatibility alias for `on_train_batch_begin`.\"\"\"\n \n     def on_batch_end(self, batch, logs=None):\n-        pass\n+        \"\"\"A backwards compatibility alias for `on_train_batch_end`.\"\"\"\n+\n+    def on_epoch_begin(self, epoch, logs=None):\n+        \"\"\"Called at the start of an epoch.\n+\n+        Subclasses should override for any actions to run. This function should only\n+        be called during train mode.\n+\n+        # Arguments\n+            epoch: integer, index of epoch.\n+            logs: dict, currently no data is passed to this argument for this method\n+                but that may change in the future.\n+        \"\"\"\n+\n+    def on_epoch_end(self, epoch, logs=None):\n+        \"\"\"Called at the end of an epoch.\n+\n+        Subclasses should override for any actions to run. This function should only\n+        be called during train mode.\n+\n+        # Arguments\n+            epoch: integer, index of epoch.\n+            logs: dict, metric results for this training epoch, and for the\n+                validation epoch if validation is performed. Validation result keys\n+                are prefixed with `val_`.\n+        \"\"\"\n+\n+    def on_train_batch_begin(self, batch, logs=None):\n+        \"\"\"Called at the beginning of a training batch in `fit` methods.\n+\n+        Subclasses should override for any actions to run.\n+\n+        # Arguments\n+            batch: integer, index of batch within the current epoch.\n+            logs: dict, has keys `batch` and `size` representing the current\n+                batch number and the size of the batch.\n+        \"\"\"\n+        # For backwards compatibility\n+        self.on_batch_begin(batch, logs=logs)\n+\n+    def on_train_batch_end(self, batch, logs=None):\n+        \"\"\"Called at the end of a training batch in `fit` methods.\n+\n+        Subclasses should override for any actions to run.\n+\n+        # Arguments\n+            batch: integer, index of batch within the current epoch.\n+            logs: dict, metric results for this batch.\n+        \"\"\"\n+        # For backwards compatibility\n+        self.on_batch_end(batch, logs=logs)\n+\n+    def on_test_batch_begin(self, batch, logs=None):\n+        \"\"\"Called at the beginning of a batch in `evaluate` methods.\n+\n+        Also called at the beginning of a validation batch in the `fit` methods,\n+        if validation data is provided.\n+\n+        Subclasses should override for any actions to run.\n+\n+        # Arguments\n+            batch: integer, index of batch within the current epoch.\n+            logs: dict, has keys `batch` and `size` representing the current\n+                batch number and the size of the batch.\n+        \"\"\"\n+\n+    def on_test_batch_end(self, batch, logs=None):\n+        \"\"\"Called at the end of a batch in `evaluate` methods.\n+\n+        Also called at the end of a validation batch in the `fit` methods,\n+        if validation data is provided.\n+\n+        Subclasses should override for any actions to run.\n+\n+        # Arguments\n+            batch: integer, index of batch within the current epoch.\n+            logs: dict, metric results for this batch.\n+        \"\"\"\n+\n+    def on_predict_batch_begin(self, batch, logs=None):\n+        \"\"\"Called at the beginning of a batch in `predict` methods.\n+\n+        Subclasses should override for any actions to run.\n+\n+        # Arguments\n+            batch: integer, index of batch within the current epoch.\n+            logs: dict, has keys `batch` and `size` representing the current\n+                batch number and the size of the batch.\n+        \"\"\"\n+\n+    def on_predict_batch_end(self, batch, logs=None):\n+        \"\"\"Called at the end of a batch in `predict` methods.\n+\n+        Subclasses should override for any actions to run.\n+\n+        # Arguments\n+            batch: integer, index of batch within the current epoch.\n+            logs: dict, metric results for this batch.\n+        \"\"\"\n \n     def on_train_begin(self, logs=None):\n-        pass\n+        \"\"\"Called at the beginning of training.\n+\n+        Subclasses should override for any actions to run.\n+\n+        # Arguments\n+            logs: dict, currently no data is passed to this argument for this method\n+                but that may change in the future.\n+        \"\"\"\n \n     def on_train_end(self, logs=None):\n-        pass\n+        \"\"\"Called at the end of training.\n+\n+        Subclasses should override for any actions to run.\n+\n+        # Arguments\n+            logs: dict, currently no data is passed to this argument for this method\n+                but that may change in the future.\n+        \"\"\"\n+\n+    def on_test_begin(self, logs=None):\n+        \"\"\"Called at the beginning of evaluation or validation.\n+\n+        Subclasses should override for any actions to run.\n+\n+        # Arguments\n+            logs: dict, currently no data is passed to this argument for this method\n+                but that may change in the future.\n+        \"\"\"\n+\n+    def on_test_end(self, logs=None):\n+        \"\"\"Called at the end of evaluation or validation.\n+\n+        Subclasses should override for any actions to run.\n+\n+        # Arguments\n+            logs: dict, currently no data is passed to this argument for this method\n+                but that may change in the future.\n+        \"\"\"\n+\n+    def on_predict_begin(self, logs=None):\n+        \"\"\"Called at the beginning of prediction.\n+\n+        Subclasses should override for any actions to run.\n+\n+        # Arguments\n+            logs: dict, currently no data is passed to this argument for this method\n+                but that may change in the future.\n+        \"\"\"\n+\n+    def on_predict_end(self, logs=None):\n+        \"\"\"Called at the end of prediction.\n+\n+        Subclasses should override for any actions to run.\n+\n+        # Arguments\n+            logs: dict, currently no data is passed to this argument for this method\n+                but that may change in the future.\n+        \"\"\"\n \n \n class BaseLogger(Callback):\n\n@@ -823,6 +823,12 @@ class Model(Network):\n                                  str(x[0].shape[0]) + ' samples')\n         return x, y, sample_weights\n \n+    def _get_callback_model(self):\n+        \"\"\"Returns the Callback Model for this Model.\"\"\"\n+        if hasattr(self, 'callback_model') and self.callback_model:\n+            return self.callback_model\n+        return self\n+\n     def fit(self,\n             x=None,\n             y=None,\n@@ -869,7 +875,8 @@ class Model(Network):\n             verbose: Integer. 0, 1, or 2. Verbosity mode.\n                 0 = silent, 1 = progress bar, 2 = one line per epoch.\n             callbacks: List of `keras.callbacks.Callback` instances.\n-                List of callbacks to apply during training.\n+                List of callbacks to apply during training and validation\n+                (if ).\n                 See [callbacks](/callbacks).\n             validation_split: Float between 0 and 1.\n                 Fraction of the training data to be used as validation data.\n@@ -1043,7 +1050,8 @@ class Model(Network):\n                  batch_size=None,\n                  verbose=1,\n                  sample_weight=None,\n-                 steps=None):\n+                 steps=None,\n+                 callbacks=None):\n         \"\"\"Returns the loss value & metrics values for the model in test mode.\n \n         Computation is done in batches.\n@@ -1082,6 +1090,9 @@ class Model(Network):\n                 Total number of steps (batches of samples)\n                 before declaring the evaluation round finished.\n                 Ignored with the default value of `None`.\n+            callbacks: List of `keras.callbacks.Callback` instances.\n+                List of callbacks to apply during evaluation.\n+                See [callbacks](/callbacks).\n \n         # Returns\n             Scalar test loss (if the model has a single output and no metrics)\n@@ -1111,12 +1122,14 @@ class Model(Network):\n         return training_arrays.test_loop(self, f, ins,\n                                          batch_size=batch_size,\n                                          verbose=verbose,\n-                                         steps=steps)\n+                                         steps=steps,\n+                                         callbacks=callbacks)\n \n     def predict(self, x,\n                 batch_size=None,\n                 verbose=0,\n-                steps=None):\n+                steps=None,\n+                callbacks=None):\n         \"\"\"Generates output predictions for the input samples.\n \n         Computation is done in batches.\n@@ -1129,6 +1142,9 @@ class Model(Network):\n             steps: Total number of steps (batches of samples)\n                 before declaring the prediction round finished.\n                 Ignored with the default value of `None`.\n+            callbacks: List of `keras.callbacks.Callback` instances.\n+                List of callbacks to apply during prediction.\n+                See [callbacks](/callbacks).\n \n         # Returns\n             Numpy array(s) of predictions.\n@@ -1167,7 +1183,8 @@ class Model(Network):\n         return training_arrays.predict_loop(self, f, ins,\n                                             batch_size=batch_size,\n                                             verbose=verbose,\n-                                            steps=steps)\n+                                            steps=steps,\n+                                            callbacks=callbacks)\n \n     def train_on_batch(self, x, y,\n                        sample_weight=None,\n@@ -1421,6 +1438,7 @@ class Model(Network):\n     @interfaces.legacy_generator_methods_support\n     def evaluate_generator(self, generator,\n                            steps=None,\n+                           callbacks=None,\n                            max_queue_size=10,\n                            workers=1,\n                            use_multiprocessing=False,\n@@ -1440,6 +1458,9 @@ class Model(Network):\n                 to yield from `generator` before stopping.\n                 Optional for `Sequence`: if unspecified, will use\n                 the `len(generator)` as a number of steps.\n+            callbacks: List of `keras.callbacks.Callback` instances.\n+                List of callbacks to apply during training.\n+                See [callbacks](/callbacks).\n             max_queue_size: maximum size for the generator queue\n             workers: Integer. Maximum number of processes to spin up\n                 when using process based threading.\n@@ -1467,6 +1488,7 @@ class Model(Network):\n         return training_generator.evaluate_generator(\n             self, generator,\n             steps=steps,\n+            callbacks=callbacks,\n             max_queue_size=max_queue_size,\n             workers=workers,\n             use_multiprocessing=use_multiprocessing,\n@@ -1475,6 +1497,7 @@ class Model(Network):\n     @interfaces.legacy_generator_methods_support\n     def predict_generator(self, generator,\n                           steps=None,\n+                          callbacks=None,\n                           max_queue_size=10,\n                           workers=1,\n                           use_multiprocessing=False,\n@@ -1493,6 +1516,9 @@ class Model(Network):\n                 to yield from `generator` before stopping.\n                 Optional for `Sequence`: if unspecified, will use\n                 the `len(generator)` as a number of steps.\n+            callbacks: List of `keras.callbacks.Callback` instances.\n+                List of callbacks to apply during training.\n+                See [callbacks](/callbacks).\n             max_queue_size: Maximum size for the generator queue.\n             workers: Integer. Maximum number of processes to spin up\n                 when using process based threading.\n@@ -1517,6 +1543,7 @@ class Model(Network):\n         return training_generator.predict_generator(\n             self, generator,\n             steps=steps,\n+            callbacks=callbacks,\n             max_queue_size=max_queue_size,\n             workers=workers,\n             use_multiprocessing=use_multiprocessing,\n\n@@ -44,7 +44,8 @@ def fit_loop(model, fit_function, fit_inputs,\n         batch_size: Integer batch size or None if unknown.\n         epochs: Number of times to iterate over the data\n         verbose: Verbosity mode, 0, 1 or 2\n-        callbacks: List of callbacks to be called during training\n+        callbacks: List of callbacks to be called during training and validation\n+            (if `val_function` and `val_inputs` are not `None`).\n         val_function: Keras function to call for validation\n         val_inputs: List of tensors to be fed to `val_function`\n         shuffle: Whether to shuffle the data at the beginning of each epoch\n@@ -110,10 +111,7 @@ def fit_loop(model, fit_function, fit_inputs,\n \n     # it's possible to callback a different model than itself\n     # (used by Sequential models)\n-    if hasattr(model, 'callback_model') and model.callback_model:\n-        callback_model = model.callback_model\n-    else:\n-        callback_model = model\n+    callback_model = model._get_callback_model()\n \n     callbacks.set_model(callback_model)\n     callbacks.set_params({\n@@ -125,8 +123,8 @@ def fit_loop(model, fit_function, fit_inputs,\n         'do_validation': do_validation,\n         'metrics': callback_metrics or [],\n     })\n-    callbacks.on_train_begin()\n-    callback_model.stop_training = False\n+    callbacks._call_begin_hook('train')\n+    callbacks.model.stop_training = False\n     for cbk in callbacks:\n         cbk.validation_data = val_inputs\n \n@@ -148,23 +146,22 @@ def fit_loop(model, fit_function, fit_inputs,\n         epoch_logs = {}\n         if steps_per_epoch is not None:\n             for step_index in range(steps_per_epoch):\n-                batch_logs = {}\n-                batch_logs['batch'] = step_index\n-                batch_logs['size'] = 1\n-                callbacks.on_batch_begin(step_index, batch_logs)\n+                batch_logs = {'batch': step_index, 'size': 1}\n+                callbacks._call_batch_hook('train', 'begin', step_index, batch_logs)\n                 outs = fit_function(fit_inputs)\n \n                 outs = to_list(outs)\n                 for l, o in zip(out_labels, outs):\n                     batch_logs[l] = o\n \n-                callbacks.on_batch_end(step_index, batch_logs)\n+                callbacks._call_batch_hook('train', 'end', step_index, batch_logs)\n                 if callback_model.stop_training:\n                     break\n \n             if do_validation:\n                 val_outs = test_loop(model, val_function, val_inputs,\n                                      steps=validation_steps,\n+                                     callbacks=callbacks,\n                                      verbose=0)\n                 val_outs = to_list(val_outs)\n                 # Same labels assumed.\n@@ -190,10 +187,8 @@ def fit_loop(model, fit_function, fit_inputs,\n                     raise TypeError('TypeError while preparing batch. '\n                                     'If using HDF5 input data, '\n                                     'pass shuffle=\"batch\".')\n-                batch_logs = {}\n-                batch_logs['batch'] = batch_index\n-                batch_logs['size'] = len(batch_ids)\n-                callbacks.on_batch_begin(batch_index, batch_logs)\n+                batch_logs = {'batch': batch_index, 'size': len(batch_ids)}\n+                callbacks._call_batch_hook('train', 'begin', batch_index, batch_logs)\n                 for i in indices_for_conversion_to_dense:\n                     ins_batch[i] = ins_batch[i].toarray()\n \n@@ -202,27 +197,32 @@ def fit_loop(model, fit_function, fit_inputs,\n                 for l, o in zip(out_labels, outs):\n                     batch_logs[l] = o\n \n-                callbacks.on_batch_end(batch_index, batch_logs)\n-                if callback_model.stop_training:\n+                callbacks._call_batch_hook('train', 'end', batch_index, batch_logs)\n+                if callbacks.model.stop_training:\n                     break\n \n                 if batch_index == len(batches) - 1:  # Last batch.\n                     if do_validation:\n                         val_outs = test_loop(model, val_function, val_inputs,\n                                              batch_size=batch_size,\n+                                             callbacks=callbacks,\n                                              verbose=0)\n                         val_outs = to_list(val_outs)\n                         # Same labels assumed.\n                         for l, o in zip(out_labels, val_outs):\n                             epoch_logs['val_' + l] = o\n         callbacks.on_epoch_end(epoch, epoch_logs)\n-        if callback_model.stop_training:\n+        if callbacks.model.stop_training:\n             break\n-    callbacks.on_train_end()\n+    callbacks._call_end_hook('train')\n     return model.history\n \n \n-def predict_loop(model, f, ins, batch_size=32, verbose=0, steps=None):\n+def predict_loop(model, f, ins,\n+                 batch_size=32,\n+                 verbose=0,\n+                 steps=None,\n+                 callbacks=None):\n     \"\"\"Abstract method to loop over some data in batches.\n \n     # Arguments\n@@ -234,6 +234,8 @@ def predict_loop(model, f, ins, batch_size=32, verbose=0, steps=None):\n         steps: Total number of steps (batches of samples)\n             before declaring `predict_loop` finished.\n             Ignored with the default value of `None`.\n+        callbacks: List of callbacks or an instance of\n+            `keras.callbacks.CallbackList` to be called during prediction.\n \n     # Returns\n         Array of predictions (if the model has a single output)\n@@ -244,6 +246,20 @@ def predict_loop(model, f, ins, batch_size=32, verbose=0, steps=None):\n                                     batch_size=batch_size,\n                                     steps=steps,\n                                     steps_name='steps')\n+\n+    # Check if callbacks have not been already configured\n+    if not isinstance(callbacks, cbks.CallbackList):\n+        callbacks = cbks.CallbackList(callbacks)\n+        callback_model = model._get_callback_model()\n+        callbacks.set_model(callback_model)\n+        callback_params = {\n+            'batch_size': batch_size,\n+            'steps': steps,\n+            'samples': num_samples,\n+            'verbose': verbose,\n+        }\n+        callbacks.set_params(callback_params)\n+\n     if verbose == 1:\n         if steps is not None:\n             progbar = Progbar(target=steps)\n@@ -255,6 +271,9 @@ def predict_loop(model, f, ins, batch_size=32, verbose=0, steps=None):\n         if issparse(ins[i]) and not K.is_sparse(model._feed_inputs[i]):\n             indices_for_conversion_to_dense.append(i)\n \n+    callbacks.model.stop_training = False\n+    callbacks._call_begin_hook('predict')\n+\n     if steps is not None:\n         # Step-based predictions.\n         # Since we do not know how many samples\n@@ -264,6 +283,8 @@ def predict_loop(model, f, ins, batch_size=32, verbose=0, steps=None):\n         # and concatenate them upon returning.\n         unconcatenated_outs = []\n         for step in range(steps):\n+            batch_logs = {'batch': step, 'size': 1}\n+            callbacks._call_batch_hook('predict', 'begin', step, batch_logs)\n             batch_outs = f(ins)\n             batch_outs = to_list(batch_outs)\n             if step == 0:\n@@ -271,8 +292,12 @@ def predict_loop(model, f, ins, batch_size=32, verbose=0, steps=None):\n                     unconcatenated_outs.append([])\n             for i, batch_out in enumerate(batch_outs):\n                 unconcatenated_outs[i].append(batch_out)\n+\n+            batch_logs['outputs'] = batch_outs\n+            callbacks._call_batch_hook('predict', 'end', step, batch_logs)\n             if verbose == 1:\n                 progbar.update(step + 1)\n+        callbacks.on_predict_end()\n         if len(unconcatenated_outs) == 1:\n             return np.concatenate(unconcatenated_outs[0], axis=0)\n         return [np.concatenate(unconcatenated_outs[i], axis=0)\n@@ -292,6 +317,8 @@ def predict_loop(model, f, ins, batch_size=32, verbose=0, steps=None):\n             for i in indices_for_conversion_to_dense:\n                 ins_batch[i] = ins_batch[i].toarray()\n \n+            batch_logs = {'batch': batch_index, 'size': len(batch_ids)}\n+            callbacks._call_batch_hook('predict', 'begin', batch_index, batch_logs)\n             batch_outs = f(ins_batch)\n             batch_outs = to_list(batch_outs)\n             if batch_index == 0:\n@@ -301,12 +328,20 @@ def predict_loop(model, f, ins, batch_size=32, verbose=0, steps=None):\n                     outs.append(np.zeros(shape, dtype=batch_out.dtype))\n             for i, batch_out in enumerate(batch_outs):\n                 outs[i][batch_start:batch_end] = batch_out\n+\n+            batch_logs['outputs'] = batch_outs\n+            callbacks._call_batch_hook('predict', 'end', batch_index, batch_logs)\n             if verbose == 1:\n                 progbar.update(batch_end)\n+        callbacks._call_end_hook('predict')\n         return unpack_singleton(outs)\n \n \n-def test_loop(model, f, ins, batch_size=None, verbose=0, steps=None):\n+def test_loop(model, f, ins,\n+              batch_size=None,\n+              verbose=0,\n+              steps=None,\n+              callbacks=None):\n     \"\"\"Abstract method to loop over some data in batches.\n \n     # Arguments\n@@ -318,6 +353,8 @@ def test_loop(model, f, ins, batch_size=None, verbose=0, steps=None):\n         steps: Total number of steps (batches of samples)\n             before declaring predictions finished.\n             Ignored with the default value of `None`.\n+        callbacks: List of callbacks or an instance of\n+            `keras.callbacks.CallbackList` to be called during evaluation.\n \n     # Returns\n         Scalar loss (if the model has a single output and no metrics)\n@@ -339,6 +376,24 @@ def test_loop(model, f, ins, batch_size=None, verbose=0, steps=None):\n                                     batch_size=batch_size,\n                                     steps=steps,\n                                     steps_name='steps')\n+\n+    # Check if callbacks have not been already configured\n+    if not isinstance(callbacks, cbks.CallbackList):\n+        callbacks = cbks.CallbackList(callbacks)\n+        callback_model = model._get_callback_model()\n+        callbacks.set_model(callback_model)\n+        callback_metrics = []\n+        if hasattr(model, 'metrics_names'):\n+            callback_metrics = list(model.metrics_names)\n+        callback_params = {\n+            'batch_size': batch_size,\n+            'steps': steps,\n+            'samples': num_samples,\n+            'verbose': verbose,\n+            'metrics': callback_metrics,\n+        }\n+        callbacks.set_params(callback_params)\n+\n     outs = []\n     if verbose == 1:\n         if steps is not None:\n@@ -356,8 +411,13 @@ def test_loop(model, f, ins, batch_size=None, verbose=0, steps=None):\n         if issparse(ins[i]) and not K.is_sparse(feed[i]):\n             indices_for_conversion_to_dense.append(i)\n \n+    callbacks.model.stop_training = False\n+    callbacks._call_begin_hook('test')\n+\n     if steps is not None:\n         for step in range(steps):\n+            batch_logs = {'batch': step, 'size': 1}\n+            callbacks._call_batch_hook('test', 'begin', step, batch_logs)\n             batch_outs = f(ins)\n             if isinstance(batch_outs, list):\n                 if step == 0:\n@@ -372,6 +432,12 @@ def test_loop(model, f, ins, batch_size=None, verbose=0, steps=None):\n                 if step == 0:\n                     outs.append(0.)\n                 outs[0] += batch_outs\n+\n+            if hasattr(model, 'metrics_names'):\n+                for l, o in zip(model.metrics_names, batch_outs):\n+                    batch_logs[l] = o\n+            callbacks._call_batch_hook('test', 'end', step, batch_logs)\n+\n             if verbose == 1:\n                 progbar.update(step + 1)\n         for i in range(len(outs)):\n@@ -390,6 +456,8 @@ def test_loop(model, f, ins, batch_size=None, verbose=0, steps=None):\n             for i in indices_for_conversion_to_dense:\n                 ins_batch[i] = ins_batch[i].toarray()\n \n+            batch_logs = {'batch': batch_index, 'size': len(batch_ids)}\n+            callbacks._call_batch_hook('test', 'begin', batch_index, batch_logs)\n             batch_outs = f(ins_batch)\n             if isinstance(batch_outs, list):\n                 if batch_index == 0:\n@@ -405,9 +473,15 @@ def test_loop(model, f, ins, batch_size=None, verbose=0, steps=None):\n                     outs.append(0.)\n                 outs[0] += batch_outs * len(batch_ids)\n \n+            if hasattr(model, 'metrics_names'):\n+                for l, o in zip(model.metrics_names, batch_outs):\n+                    batch_logs[l] = o\n+            callbacks._call_batch_hook('test', 'end', batch_index, batch_logs)\n+\n             if verbose == 1:\n                 progbar.update(batch_end)\n         for i in range(len(outs)):\n             if i not in stateful_metric_indices:\n                 outs[i] /= num_samples\n+    callbacks._call_end_hook('test')\n     return unpack_singleton(outs)\n\n@@ -88,10 +88,8 @@ def fit_generator(model,\n     callbacks = cbks.CallbackList(_callbacks)\n \n     # it's possible to callback a different model than self:\n-    if hasattr(model, 'callback_model') and model.callback_model:\n-        callback_model = model.callback_model\n-    else:\n-        callback_model = model\n+    callback_model = model._get_callback_model()\n+\n     callbacks.set_model(callback_model)\n     callbacks.set_params({\n         'epochs': epochs,\n@@ -100,7 +98,7 @@ def fit_generator(model,\n         'do_validation': do_validation,\n         'metrics': callback_metrics,\n     })\n-    callbacks.on_train_begin()\n+    callbacks._call_begin_hook('train')\n \n     enqueuer = None\n     val_enqueuer = None\n@@ -168,7 +166,7 @@ def fit_generator(model,\n             else:\n                 output_generator = generator\n \n-        callback_model.stop_training = False\n+        callbacks.model.stop_training = False\n         # Construct epoch logs.\n         epoch_logs = {}\n         while epoch < epochs:\n@@ -196,8 +194,6 @@ def fit_generator(model,\n                                      'a tuple `(x, y, sample_weight)` '\n                                      'or `(x, y)`. Found: ' +\n                                      str(generator_output))\n-                # build batch logs\n-                batch_logs = {}\n                 if x is None or len(x) == 0:\n                     # Handle data tensors support when no input given\n                     # step-size = 1 for data tensors\n@@ -208,8 +204,8 @@ def fit_generator(model,\n                     batch_size = list(x.values())[0].shape[0]\n                 else:\n                     batch_size = x.shape[0]\n-                batch_logs['batch'] = batch_index\n-                batch_logs['size'] = batch_size\n+                # build batch logs\n+                batch_logs = {'batch': batch_index, 'size': batch_size}\n                 callbacks.on_batch_begin(batch_index, batch_logs)\n \n                 outs = model.train_on_batch(x, y,\n@@ -220,17 +216,20 @@ def fit_generator(model,\n                 for l, o in zip(out_labels, outs):\n                     batch_logs[l] = o\n \n-                callbacks.on_batch_end(batch_index, batch_logs)\n+                callbacks._call_batch_hook('train', 'end', batch_index, batch_logs)\n \n                 batch_index += 1\n                 steps_done += 1\n \n                 # Epoch finished.\n                 if steps_done >= steps_per_epoch and do_validation:\n+                    # Note that `callbacks` here is an instance of\n+                    # `keras.callbacks.CallbackList`\n                     if val_gen:\n                         val_outs = model.evaluate_generator(\n                             val_enqueuer_gen,\n                             validation_steps,\n+                            callbacks=callbacks,\n                             workers=0)\n                     else:\n                         # No need for try/except because\n@@ -239,18 +238,19 @@ def fit_generator(model,\n                             val_x, val_y,\n                             batch_size=batch_size,\n                             sample_weight=val_sample_weights,\n+                            callbacks=callbacks,\n                             verbose=0)\n                     val_outs = to_list(val_outs)\n                     # Same labels assumed.\n                     for l, o in zip(out_labels, val_outs):\n                         epoch_logs['val_' + l] = o\n \n-                if callback_model.stop_training:\n+                if callbacks.model.stop_training:\n                     break\n \n             callbacks.on_epoch_end(epoch, epoch_logs)\n             epoch += 1\n-            if callback_model.stop_training:\n+            if callbacks.model.stop_training:\n                 break\n \n     finally:\n@@ -261,12 +261,13 @@ def fit_generator(model,\n             if val_enqueuer is not None:\n                 val_enqueuer.stop()\n \n-    callbacks.on_train_end()\n+    callbacks._call_end_hook('train')\n     return model.history\n \n \n def evaluate_generator(model, generator,\n                        steps=None,\n+                       callbacks=None,\n                        max_queue_size=10,\n                        workers=1,\n                        use_multiprocessing=False,\n@@ -303,6 +304,24 @@ def evaluate_generator(model, generator,\n                              ' `keras.utils.Sequence` class.')\n     enqueuer = None\n \n+    # Check if callbacks have not been already configured\n+    if not isinstance(callbacks, cbks.CallbackList):\n+        callbacks = cbks.CallbackList(callbacks)\n+        callback_model = model._get_callback_model()\n+        callbacks.set_model(callback_model)\n+        callback_metrics = []\n+        if hasattr(model, 'metrics_names'):\n+            callback_metrics = list(model.metrics_names)\n+        callback_params = {\n+            'steps': steps,\n+            'verbose': verbose,\n+            'metrics': callback_metrics,\n+        }\n+        callbacks.set_params(callback_params)\n+\n+    callbacks.model.stop_training = False\n+    callbacks._call_begin_hook('test')\n+\n     try:\n         if workers > 0:\n             if use_sequence_api:\n@@ -341,9 +360,6 @@ def evaluate_generator(model, generator,\n                                  '(x, y, sample_weight) '\n                                  'or (x, y). Found: ' +\n                                  str(generator_output))\n-            outs = model.test_on_batch(x, y, sample_weight=sample_weight)\n-            outs = to_list(outs)\n-            outs_per_batch.append(outs)\n \n             if x is None or len(x) == 0:\n                 # Handle data tensors support when no input given\n@@ -359,10 +375,24 @@ def evaluate_generator(model, generator,\n                 raise ValueError('Received an empty batch. '\n                                  'Batches should contain '\n                                  'at least one item.')\n+\n+            batch_logs = {'batch': steps_done, 'size': batch_size}\n+            callbacks._call_batch_hook('test', 'begin', steps_done, batch_logs)\n+            outs = model.test_on_batch(x, y, sample_weight=sample_weight)\n+            outs = to_list(outs)\n+            outs_per_batch.append(outs)\n+\n+            if hasattr(model, 'metrics_names'):\n+                for l, o in zip(model.metrics_names, outs):\n+                    batch_logs[l] = o\n+            callbacks._call_batch_hook('test', 'end', steps_done, batch_logs)\n+\n             steps_done += 1\n             batch_sizes.append(batch_size)\n+\n             if verbose == 1:\n                 progbar.update(steps_done)\n+        callbacks._call_end_hook('test')\n \n     finally:\n         if enqueuer is not None:\n@@ -380,6 +410,7 @@ def evaluate_generator(model, generator,\n \n def predict_generator(model, generator,\n                       steps=None,\n+                      callbacks=None,\n                       max_queue_size=10,\n                       workers=1,\n                       use_multiprocessing=False,\n@@ -406,6 +437,20 @@ def predict_generator(model, generator,\n                              ' `keras.utils.Sequence` class.')\n     enqueuer = None\n \n+    # Check if callbacks have not been already configured\n+    if not isinstance(callbacks, cbks.CallbackList):\n+        callbacks = cbks.CallbackList(callbacks)\n+        callback_model = model._get_callback_model()\n+        callbacks.set_model(callback_model)\n+        callback_params = {\n+            'steps': steps,\n+            'verbose': verbose,\n+        }\n+        callbacks.set_params(callback_params)\n+\n+    callbacks.model.stop_training = False\n+    callbacks._call_begin_hook('predict')\n+\n     try:\n         if workers > 0:\n             if use_sequence_api:\n@@ -446,6 +491,24 @@ def predict_generator(model, generator,\n                 # yields inputs (not targets and sample weights).\n                 x = generator_output\n \n+            if x is None or len(x) == 0:\n+                # Handle data tensors support when no input given\n+                # step-size = 1 for data tensors\n+                batch_size = 1\n+            elif isinstance(x, list):\n+                batch_size = x[0].shape[0]\n+            elif isinstance(x, dict):\n+                batch_size = list(x.values())[0].shape[0]\n+            else:\n+                batch_size = x.shape[0]\n+            if batch_size == 0:\n+                raise ValueError('Received an empty batch. '\n+                                 'Batches should contain '\n+                                 'at least one item.')\n+\n+            batch_logs = {'batch': steps_done, 'size': batch_size}\n+            callbacks._call_batch_hook('predict', 'begin', steps_done, batch_logs)\n+\n             outs = model.predict_on_batch(x)\n             outs = to_list(outs)\n \n@@ -455,10 +518,14 @@ def predict_generator(model, generator,\n \n             for i, out in enumerate(outs):\n                 all_outs[i].append(out)\n+\n+            batch_logs['outputs'] = outs\n+            callbacks._call_batch_hook('predict', 'end', steps_done, batch_logs)\n+\n             steps_done += 1\n             if verbose == 1:\n                 progbar.update(steps_done)\n-\n+        callbacks._call_end_hook('predict')\n     finally:\n         if enqueuer is not None:\n             enqueuer.stop()\n\n@@ -7,6 +7,7 @@ from numpy.testing import assert_allclose\n from csv import reader\n from csv import Sniffer\n import shutil\n+from collections import defaultdict\n from keras import optimizers\n from keras import initializers\n from keras import callbacks\n@@ -65,6 +66,280 @@ def get_data_callbacks(num_train=train_samples,\n                          num_classes=num_classes)\n \n \n+class Counter(callbacks.Callback):\n+    \"\"\"Counts the number of times each callback method was run.\n+\n+    # Arguments\n+        method_counts: dict, contains the counts of time each callback method was\n+            run.\n+    \"\"\"\n+\n+    def __init__(self):\n+        self.method_counts = defaultdict(int)\n+        methods_to_count = [\n+            'on_batch_begin', 'on_batch_end', 'on_epoch_begin', 'on_epoch_end',\n+            'on_train_batch_begin', 'on_train_batch_end',\n+            'on_test_batch_begin', 'on_test_batch_end',\n+            'on_predict_batch_begin', 'on_predict_batch_end',\n+            'on_train_begin', 'on_train_end', 'on_predict_begin', 'on_predict_end',\n+            'on_test_begin', 'on_test_end',\n+        ]\n+        for method_name in methods_to_count:\n+            setattr(self, method_name,\n+                    self.wrap_with_counts(method_name, getattr(self, method_name)))\n+\n+    def wrap_with_counts(self, method_name, method):\n+\n+        def _call_and_count(*args, **kwargs):\n+            self.method_counts[method_name] += 1\n+            return method(*args, **kwargs)\n+\n+        return _call_and_count\n+\n+\n+class TestCallbackCounts(object):\n+\n+    def _check_counts(self, counter, expected_counts):\n+        \"\"\"Checks that the counts registered by `counter` are those expected.\"\"\"\n+        for method_name, expected_count in expected_counts.items():\n+            count = counter.method_counts[method_name]\n+            assert count == expected_count, \\\n+                'For method {}: expected {}, got: {}'.format(\n+                    method_name, expected_count, count)\n+\n+    def _get_model(self):\n+        layers = [\n+            Dense(10, activation='relu', input_dim=input_dim),\n+            Dense(num_classes, activation='softmax')\n+        ]\n+        model = Sequential(layers=layers)\n+        model.compile(optimizer='adam', loss='binary_crossentropy')\n+        return model\n+\n+    def test_callback_hooks_are_called_in_fit(self):\n+        np.random.seed(1337)\n+        (X_train, y_train), (X_test, y_test) = get_data_callbacks(num_train=10,\n+                                                                  num_test=4)\n+        y_train = np_utils.to_categorical(y_train)\n+        y_test = np_utils.to_categorical(y_test)\n+\n+        model = self._get_model()\n+        counter = Counter()\n+        model.fit(X_train, y_train, validation_data=(X_test, y_test),\n+                  batch_size=2, epochs=5, callbacks=[counter])\n+\n+        self._check_counts(\n+            counter, {\n+                'on_batch_begin': 25,\n+                'on_batch_end': 25,\n+                'on_epoch_begin': 5,\n+                'on_epoch_end': 5,\n+                'on_predict_batch_begin': 0,\n+                'on_predict_batch_end': 0,\n+                'on_predict_begin': 0,\n+                'on_predict_end': 0,\n+                'on_test_batch_begin': 10,\n+                'on_test_batch_end': 10,\n+                'on_test_begin': 5,\n+                'on_test_end': 5,\n+                'on_train_batch_begin': 25,\n+                'on_train_batch_end': 25,\n+                'on_train_begin': 1,\n+                'on_train_end': 1,\n+            })\n+\n+    def test_callback_hooks_are_called_in_evaluate(self):\n+        np.random.seed(1337)\n+        (_, _), (X_test, y_test) = get_data_callbacks(num_test=10)\n+\n+        y_test = np_utils.to_categorical(y_test)\n+\n+        model = self._get_model()\n+        counter = Counter()\n+        model.evaluate(X_test, y_test, batch_size=2, callbacks=[counter])\n+        self._check_counts(\n+            counter, {\n+                'on_test_batch_begin': 5,\n+                'on_test_batch_end': 5,\n+                'on_test_begin': 1,\n+                'on_test_end': 1,\n+                'on_batch_begin': 0,\n+                'on_batch_end': 0,\n+                'on_epoch_begin': 0,\n+                'on_epoch_end': 0,\n+                'on_predict_batch_begin': 0,\n+                'on_predict_batch_end': 0,\n+                'on_predict_begin': 0,\n+                'on_predict_end': 0,\n+                'on_train_batch_begin': 0,\n+                'on_train_batch_end': 0,\n+                'on_train_begin': 0,\n+                'on_train_end': 0,\n+            })\n+\n+    def test_callback_hooks_are_called_in_predict(self):\n+        np.random.seed(1337)\n+        (_, _), (X_test, _) = get_data_callbacks(num_test=10)\n+\n+        model = self._get_model()\n+        counter = Counter()\n+        model.predict(X_test, batch_size=2, callbacks=[counter])\n+        self._check_counts(\n+            counter, {\n+                'on_predict_batch_begin': 5,\n+                'on_predict_batch_end': 5,\n+                'on_predict_begin': 1,\n+                'on_predict_end': 1,\n+                'on_batch_begin': 0,\n+                'on_batch_end': 0,\n+                'on_epoch_begin': 0,\n+                'on_epoch_end': 0,\n+                'on_test_batch_begin': 0,\n+                'on_test_batch_end': 0,\n+                'on_test_begin': 0,\n+                'on_test_end': 0,\n+                'on_train_batch_begin': 0,\n+                'on_train_batch_end': 0,\n+                'on_train_begin': 0,\n+                'on_train_end': 0,\n+            })\n+\n+    def test_callback_hooks_are_called_in_fit_generator(self):\n+        np.random.seed(1337)\n+        (X_train, y_train), (X_test, y_test) = get_data_callbacks(num_train=10,\n+                                                                  num_test=4)\n+        y_train = np_utils.to_categorical(y_train)\n+        y_test = np_utils.to_categorical(y_test)\n+        train_generator = data_generator(X_train, y_train, batch_size=2)\n+        validation_generator = data_generator(X_test, y_test, batch_size=2)\n+\n+        model = self._get_model()\n+        counter = Counter()\n+        model.fit_generator(train_generator, steps_per_epoch=len(X_train) // 2,\n+                            epochs=5, validation_data=validation_generator,\n+                            validation_steps=len(X_test) // 2, callbacks=[counter])\n+\n+        self._check_counts(\n+            counter, {\n+                'on_batch_begin': 25,\n+                'on_batch_end': 25,\n+                'on_epoch_begin': 5,\n+                'on_epoch_end': 5,\n+                'on_predict_batch_begin': 0,\n+                'on_predict_batch_end': 0,\n+                'on_predict_begin': 0,\n+                'on_predict_end': 0,\n+                'on_test_batch_begin': 10,\n+                'on_test_batch_end': 10,\n+                'on_test_begin': 5,\n+                'on_test_end': 5,\n+                'on_train_batch_begin': 25,\n+                'on_train_batch_end': 25,\n+                'on_train_begin': 1,\n+                'on_train_end': 1,\n+            })\n+\n+    def test_callback_hooks_are_called_in_evaluate_generator(self):\n+        np.random.seed(1337)\n+        (_, _), (X_test, y_test) = get_data_callbacks(num_test=10)\n+        y_test = np_utils.to_categorical(y_test)\n+\n+        model = self._get_model()\n+        counter = Counter()\n+        model.evaluate_generator(data_generator(X_test, y_test, batch_size=2),\n+                                 steps=len(X_test) // 2, callbacks=[counter])\n+        self._check_counts(\n+            counter, {\n+                'on_test_batch_begin': 5,\n+                'on_test_batch_end': 5,\n+                'on_test_begin': 1,\n+                'on_test_end': 1,\n+                'on_batch_begin': 0,\n+                'on_batch_end': 0,\n+                'on_epoch_begin': 0,\n+                'on_epoch_end': 0,\n+                'on_predict_batch_begin': 0,\n+                'on_predict_batch_end': 0,\n+                'on_predict_begin': 0,\n+                'on_predict_end': 0,\n+                'on_train_batch_begin': 0,\n+                'on_train_batch_end': 0,\n+                'on_train_begin': 0,\n+                'on_train_end': 0,\n+            })\n+\n+    def test_callback_hooks_are_called_in_predict_generator(self):\n+        np.random.seed(1337)\n+        (_, _), (X_test, _) = get_data_callbacks(num_test=10)\n+\n+        def data_generator(x, batch_size):\n+            x = to_list(x)\n+            max_batch_index = len(x[0]) // batch_size\n+            i = 0\n+            while 1:\n+                x_batch = [\n+                    array[i * batch_size: (i + 1) * batch_size] for array in x]\n+                x_batch = unpack_singleton(x_batch)\n+\n+                yield x_batch\n+                i += 1\n+                i = i % max_batch_index\n+\n+        model = self._get_model()\n+        counter = Counter()\n+        model.predict_generator(data_generator(X_test, batch_size=2),\n+                                steps=len(X_test) // 2, callbacks=[counter])\n+        self._check_counts(\n+            counter, {\n+                'on_predict_batch_begin': 5,\n+                'on_predict_batch_end': 5,\n+                'on_predict_begin': 1,\n+                'on_predict_end': 1,\n+                'on_batch_begin': 0,\n+                'on_batch_end': 0,\n+                'on_epoch_begin': 0,\n+                'on_epoch_end': 0,\n+                'on_test_batch_begin': 0,\n+                'on_test_batch_end': 0,\n+                'on_test_begin': 0,\n+                'on_test_end': 0,\n+                'on_train_batch_begin': 0,\n+                'on_train_batch_end': 0,\n+                'on_train_begin': 0,\n+                'on_train_end': 0,\n+            })\n+\n+    def test_callback_list_methods(self):\n+        counter = Counter()\n+        callback_list = callbacks.CallbackList([counter])\n+\n+        batch = 0\n+        callback_list.on_test_batch_begin(batch)\n+        callback_list.on_test_batch_end(batch)\n+        callback_list.on_predict_batch_begin(batch)\n+        callback_list.on_predict_batch_end(batch)\n+\n+        self._check_counts(\n+            counter, {\n+                'on_test_batch_begin': 1,\n+                'on_test_batch_end': 1,\n+                'on_predict_batch_begin': 1,\n+                'on_predict_batch_end': 1,\n+                'on_predict_begin': 0,\n+                'on_predict_end': 0,\n+                'on_batch_begin': 0,\n+                'on_batch_end': 0,\n+                'on_epoch_begin': 0,\n+                'on_epoch_end': 0,\n+                'on_test_begin': 0,\n+                'on_test_end': 0,\n+                'on_train_batch_begin': 0,\n+                'on_train_batch_end': 0,\n+                'on_train_begin': 0,\n+                'on_train_end': 0,\n+            })\n+\n+\n def test_TerminateOnNaN():\n     np.random.seed(1337)\n     (X_train, y_train), (X_test, y_test) = get_data_callbacks()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
