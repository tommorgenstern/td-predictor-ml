{"custom_id": "keras#203a51b5ce23d0d8d856e60190a2de07cb18c2f6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 37 | Churn Cumulative: 2636 | Contributors (this commit): 32 | Commits (past 90d): 14 | Contributors (cumulative): 35 | DMM Complexity: 1.0\n\nDIFF:\n@@ -208,7 +208,7 @@ def print_summary(model,\n           fit_into_line = fit_into_line[:cutoff]\n \n         if col == 0:\n-            line += '|' * (nested_level) + ' '\n+            line += '|' * nested_level + ' '\n         line += fit_into_line\n         line += ' ' * space if space else ''\n         left_to_print[col] = left_to_print[col][cutoff:]\n\n@@ -88,7 +88,6 @@ class LayerUtilsTest(tf.test.TestCase):\n \n     x = inner_inputs = keras.Input(shape)\n     x = make_model()(x)\n-    x = make_model()(x)\n     inner_model = keras.Model(inner_inputs, x)\n \n     inputs = keras.Input(shape)\n@@ -111,7 +110,39 @@ class LayerUtilsTest(tf.test.TestCase):\n       reader = open(fpath, 'r')\n       lines = reader.readlines()\n       reader.close()\n-      self.assertEqual(len(lines), 34)\n+      check_str = \"\"\"Model: \"model_2\"\n+_________________________________________________________________\n+ Layer (type)                Output Shape              Param #   \n+=================================================================\n+ input_3 (InputLayer)        [(None, None, None, 3)]   0         \n+                                                                 \n+ model_1 (Functional)        (None, None, None, 3)     24        \n+|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n+| input_1 (InputLayer)      [(None, None, None, 3)]   0         |\n+|                                                               |\n+| model (Functional)        (None, None, None, 3)     24        |\n+||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n+|| input_2 (InputLayer)    [(None, None, None, 3)]   0         ||\n+||                                                             ||\n+|| conv2d (Conv2D)         (None, None, None, 3)     12        ||\n+||                                                             ||\n+|| batch_normalization (BatchN  (None, None, None, 3)  12      ||\n+|| ormalization)                                               ||\n+|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n+¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n+=================================================================\n+Total params: 24\n+Trainable params: 18\n+Non-trainable params: 6\n+_________________________________________________________________\n+\"\"\"\n+\n+      fin_str = \"\"\n+      for line in lines:\n+        fin_str += line\n+\n+      self.assertIn(fin_str, check_str)\n+      self.assertEqual(len(lines), 25)\n     except ImportError:\n       pass\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5ed8252b9680195629687ac84bae4bc28b182cf7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 3 | Methods Changed: 9 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 443 | Contributors (this commit): 3 | Commits (past 90d): 6 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -63,8 +63,8 @@ class LayerUtilsTest(tf.test.TestCase):\n     fpath = os.path.join(temp_dir, file_name)\n     writer = open(fpath, 'w')\n \n-    def print_to_file(text, end='\\n'):\n-      print(text, end=end, file=writer)\n+    def print_to_file(text):\n+      print(text, file=writer)\n \n     try:\n       layer_utils.print_summary(model, print_fn=print_to_file)\n@@ -99,8 +99,8 @@ class LayerUtilsTest(tf.test.TestCase):\n     fpath = os.path.join(temp_dir, file_name)\n     writer = open(fpath, 'w')\n \n-    def print_to_file(text, end='\\n'):\n-      print(text, end=end, file=writer)\n+    def print_to_file(text):\n+      print(text, file=writer)\n \n     try:\n       layer_utils.print_summary(\n@@ -203,8 +203,8 @@ _________________________________________________________________\n     fpath = os.path.join(temp_dir, file_name)\n     writer = open(fpath, 'w')\n \n-    def print_to_file(text, end='\\n'):\n-      print(text, end=end, file=writer)\n+    def print_to_file(text):\n+      print(text, file=writer)\n \n     try:\n       layer_utils.print_summary(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7c10f1dc2dd93d281efce05c11bc21423be2f30f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 46 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 7 | Methods Changed: 5 | Complexity Δ (Sum/Max): -1/3 | Churn Δ: 46 | Churn Cumulative: 23739 | Contributors (this commit): 87 | Commits (past 90d): 36 | Contributors (cumulative): 105 | DMM Complexity: 0.65\n\nDIFF:\n@@ -284,6 +284,7 @@ class Conv(Layer):\n   def compute_output_shape(self, input_shape):\n     input_shape = tf.TensorShape(input_shape).as_list()\n     batch_rank = len(input_shape) - self.rank - 1\n+    try:\n       if self.data_format == 'channels_last':\n         return tf.TensorShape(\n             input_shape[:batch_rank]\n@@ -294,6 +295,14 @@ class Conv(Layer):\n             input_shape[:batch_rank] + [self.filters] +\n             self._spatial_output_shape(input_shape[batch_rank + 1:]))\n \n+    except ValueError:\n+        raise ValueError(f'One of the dimensions in the output is <= 0 '\n+                         f'due to downsampling in {self.name}. Consider '\n+                         f'increasing the input size. '\n+                         f'Received input shape {input_shape} which would produce '\n+                         f'output shape with a zero or negative value in a '\n+                         f'dimension.')\n+\n   def _recreate_conv_op(self, inputs):  # pylint: disable=unused-argument\n     return False\n \n\n@@ -161,6 +161,13 @@ class Conv1DTest(keras_parameterized.TestCase):\n       fn(inpt2)\n       self.assertEqual(outp1_shape, layer(inpt1).shape)\n \n+  def test_conv1d_invalid_output_shapes(self):\n+    kwargs = {'filters': 2, 'kernel_size': 20}\n+    with self.assertRaisesRegex(ValueError,\n+                                r\"\"\"One of the dimensions in the output is <= 0\"\"\"):\n+      layer = keras.layers.convolutional.Conv1D(**kwargs)\n+      layer.build((None, 5, 2))\n+\n \n @keras_parameterized.run_all_keras_modes\n class Conv2DTest(keras_parameterized.TestCase):\n@@ -293,6 +300,13 @@ class Conv2DTest(keras_parameterized.TestCase):\n     with self.assertRaises(ValueError):\n       keras.layers.Conv2D(**kwargs)\n   \n+  def test_conv2d_invalid_output_shapes(self):\n+    kwargs = {'filters': 2, 'kernel_size': 20}\n+    with self.assertRaisesRegex(ValueError,\n+                                r\"\"\"One of the dimensions in the output is <= 0\"\"\"):\n+      layer = keras.layers.convolutional.Conv2D(**kwargs)\n+      layer.build((None, 5, 5, 2))\n+\n \n @keras_parameterized.run_all_keras_modes\n class Conv3DTest(keras_parameterized.TestCase):\n@@ -428,6 +442,13 @@ class Conv3DTest(keras_parameterized.TestCase):\n             input_shape=(None, 3, None, None, None),\n             input_data=input_data)\n \n+  def test_conv3d_invalid_output_shapes(self):\n+    kwargs = {'filters': 2, 'kernel_size': 20}\n+    with self.assertRaisesRegex(ValueError,\n+                                r\"\"\"One of the dimensions in the output is <= 0\"\"\"):\n+      layer = keras.layers.convolutional.Conv3D(**kwargs)\n+      layer.build((None, 5, 5, 5, 2))\n+\n \n @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class GroupedConvTest(keras_parameterized.TestCase):\n\n@@ -172,6 +172,14 @@ class LocallyConnected1D(Layer):\n                                                        self.padding,\n                                                        self.strides[0])\n \n+    if self.output_length <= 0:\n+      raise ValueError(f'One of the dimensions in the output is <= 0 '\n+                       f'due to downsampling in {self.name}. Consider '\n+                       f'increasing the input size. '\n+                       f'Received input shape {input_shape} which would produce '\n+                       f'output shape with a zero or negative value in a '\n+                       f'dimension.')\n+\n     if self.implementation == 1:\n       self.kernel_shape = (self.output_length, self.kernel_size[0] * input_dim,\n                            self.filters)\n@@ -483,6 +491,14 @@ class LocallyConnected2D(Layer):\n     self.output_row = output_row\n     self.output_col = output_col\n \n+    if self.output_row <= 0 or self.output_col <= 0:\n+      raise ValueError(f'One of the dimensions in the output is <= 0 '\n+                       f'due to downsampling in {self.name}. Consider '\n+                       f'increasing the input size. '\n+                       f'Received input shape {input_shape} which would produce '\n+                       f'output shape with a zero or negative value in a '\n+                       f'dimension.')\n+\n     if self.implementation == 1:\n       self.kernel_shape = (output_row * output_col, self.kernel_size[0] *\n                            self.kernel_size[1] * input_filter, self.filters)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4c9c7d1d783245d9c251cf8cbce0564704a064a4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 39 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 7 | Methods Changed: 6 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 43 | Churn Cumulative: 739 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -157,6 +157,12 @@ class LocallyConnected1DLayersTest(tf.test.TestCase, parameterized.TestCase):\n         self.assertEqual(layer.kernel.constraint, k_constraint)\n         self.assertEqual(layer.bias.constraint, b_constraint)\n \n+  def test_locallyconnected1d_invalid_output_shapes(self):\n+    kwargs = {'filters': 2, 'kernel_size': 10}\n+    with self.assertRaisesRegex(ValueError,\n+                                r\"\"\"One of the dimensions in the output is <= 0 \"\"\"):\n+      layer = keras.layers.LocallyConnected1D(**kwargs)\n+      layer.build((None, 5, 2))\n \n @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n class LocallyConnected2DLayersTest(tf.test.TestCase, parameterized.TestCase):\n@@ -264,6 +270,12 @@ class LocallyConnected2DLayersTest(tf.test.TestCase, parameterized.TestCase):\n         self.assertEqual(layer.kernel.constraint, k_constraint)\n         self.assertEqual(layer.bias.constraint, b_constraint)\n \n+  def test_locallyconnected2d_invalid_output_shapes(self):\n+    kwargs = {'filters': 2, 'kernel_size': 10}\n+    with self.assertRaisesRegex(ValueError,\n+                                r\"\"\"One of the dimensions in the output is <= 0 \"\"\"):\n+      layer = keras.layers.LocallyConnected2D(**kwargs)\n+      layer.build((None, 5, 5, 2))\n \n @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n class LocallyConnectedImplementationModeTest(tf.test.TestCase,\n@@ -283,8 +295,19 @@ class LocallyConnectedImplementationModeTest(tf.test.TestCase,\n \n       np.random.seed(1)\n       tf_test_util.random_seed.set_seed(1)\n-      targets = np.random.randint(0, num_classes, (num_samples,))\n+      # Following code generates sparse targets and converts them\n+      # to one-hot encoded vectors\n+      # Create sparse targets eg. [0,1,2]\n+      sparse_targets = np.random.randint(0, num_classes, (num_samples,))\n \n+      # Convert to one-hot encoding\n+      # Final targets:\n+      # [[ 1. 0. 0. ]\n+      #  [ 0. 1. 0. ]\n+      #  [ 0. 0. 1. ]]\n+\n+      targets = np.zeros((sparse_targets.size, num_classes))\n+      targets[np.arange(sparse_targets.size), sparse_targets] = 1\n       height = 7\n       filters = 2\n       inputs = get_inputs(data_format, filters, height, num_samples, width)\n@@ -387,7 +410,19 @@ class LocallyConnectedImplementationModeTest(tf.test.TestCase,\n \n       np.random.seed(1)\n       tf_test_util.random_seed.set_seed(1)\n-      targets = np.random.randint(0, num_classes, (num_samples,))\n+      # Following code generates sparse targets and converts them\n+      # to one-hot encoded vectors\n+      # Create sparse targets eg. [0,1,2]\n+      sparse_targets = np.random.randint(0, num_classes, (num_samples,))\n+\n+      # Convert to one-hot encoding\n+      # Final targets:\n+      # [[ 1. 0. 0. ]\n+      #  [ 0. 1. 0. ]\n+      #  [ 0. 0. 1. ]]\n+\n+      targets = np.zeros((sparse_targets.size, num_classes))\n+      targets[np.arange(sparse_targets.size), sparse_targets] = 1\n \n       height = 7\n       filters = 2\n@@ -555,7 +590,7 @@ def get_model(implementation,\n   model.compile(\n       optimizer=RMSPropOptimizer(0.01),\n       metrics=[keras.metrics.categorical_accuracy],\n-      loss=xent\n+      loss=keras.losses.CategoricalCrossentropy(from_logits=True)\n   )\n   return model\n \n@@ -589,7 +624,7 @@ def get_model_saveable(implementation, filters, kernel_size, strides, layers,\n   model.compile(\n       optimizer=rmsprop.RMSProp(learning_rate=0.01),\n       metrics=[keras.metrics.categorical_accuracy],\n-      loss=xent)\n+      loss=keras.losses.CategoricalCrossentropy(from_logits=True))\n   return model\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#346bf40e3bf6723298cb507ff444ade9cfe4a1d1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 37 | Churn Cumulative: 7267 | Contributors (this commit): 96 | Commits (past 90d): 16 | Contributors (cumulative): 96 | DMM Complexity: None\n\nDIFF:\n@@ -1587,26 +1587,35 @@ class ModelCheckpoint(Callback):\n class BackupAndRestore(Callback):\n   \"\"\"Callback to back up and restore the training state.\n \n-  `BackupAndRestore` callback is intended to recover from interruptions that\n-  happened in the middle of a model.fit execution by backing up the\n-  training states in a temporary checkpoint file (based on TF CheckpointManager)\n-  at the end of each epoch. If training restarted before completion, the\n-  training state and model are restored to the most recently saved state at the\n-  beginning of a new model.fit() run.\n-  Note that user is responsible to bring jobs back up.\n+  `BackupAndRestore` callback is intended to recover training from an\n+  interruption that has happened in the middle of a `Model.fit` execution, by\n+  backing up the training states in a temporary checkpoint file (with the help\n+  of a `tf.train.CheckpointManager`), at the end of each epoch. Each backup\n+  overwrites the previously written checkpoint file, so at any given time there\n+  is at most one such checkpoint file for backup/restoring purpose.\n+\n+  If training restarts before completion, the training state (which includes the\n+  `Model` weights and epoch number) is restored to the most recently saved state\n+  at the beginning of a new `Model.fit` run. At the completion of a `Model.fit`\n+  run, the temporary checkpoint file is deleted.\n+\n+  Note that the user is responsible to bring jobs back after the interruption.\n   This callback is important for the backup and restore mechanism for fault\n-  tolerance purpose. And the model to be restored from an previous checkpoint is\n+  tolerance purpose, and the model to be restored from an previous checkpoint is\n   expected to be the same as the one used to back up. If user changes arguments\n   passed to compile or fit, the checkpoint saved for fault tolerance can become\n   invalid.\n \n   Note:\n-  1. This callback is not compatible with disabling eager execution.\n-  2. A checkpoint is saved at the end of each epoch, when restoring we'll redo\n-  any partial work from an unfinished epoch in which the training got restarted\n-  (so the work done before a interruption doesn't affect the final model state).\n-  3. This works for both single worker and multi-worker mode, only\n-  MirroredStrategy and MultiWorkerMirroredStrategy are supported for now.\n+  1. This callback is not compatible with eager execution disabled.\n+  2. A checkpoint is saved at the end of each epoch. After restoring,\n+  `Model.fit` redoes any partial work during the unfinished epoch in which the\n+  training got restarted (so the work done before the interruption doesn't\n+  affect the final model state).\n+  3. This works for both single worker and multi-worker modes. When `Model.fit`\n+  is used with `tf.distribute`, it supports `tf.distribute.MirroredStrategy`,\n+  `tf.distribute.MultiWorkerMirroredStrategy`, `tf.distribute.TPUStrategy`, and\n+  `tf.distribute.experimental.ParameterServerStrategy`.\n \n   Example:\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9f6107cb8460eab3a4e34786fb75932a1e812290", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 19206 | Contributors (this commit): 82 | Commits (past 90d): 26 | Contributors (cumulative): 82 | DMM Complexity: 1.0\n\nDIFF:\n@@ -193,6 +193,8 @@ class Conv(Layer):\n     kernel_shape = self.kernel_size + (input_channel // self.groups,\n                                        self.filters)\n \n+    output_shape = self.compute_output_shape(input_shape)\n+\n     self.kernel = self.add_weight(\n         name='kernel',\n         shape=kernel_shape,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#30a26660c1f849ed3f83b0980eb7fa2046638e4c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 26 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 51 | Churn Cumulative: 494 | Contributors (this commit): 3 | Commits (past 90d): 7 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -110,32 +110,31 @@ class LayerUtilsTest(tf.test.TestCase):\n       reader = open(fpath, 'r')\n       lines = reader.readlines()\n       reader.close()\n-      check_str = \"\"\"Model: \"model_2\"\n-_________________________________________________________________\n- Layer (type)                Output Shape              Param #   \n-=================================================================\n- input_3 (InputLayer)        [(None, None, None, 3)]   0         \n-                                                                 \n- model_1 (Functional)        (None, None, None, 3)     24        \n-|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n-| input_1 (InputLayer)      [(None, None, None, 3)]   0         |\n-|                                                               |\n-| model (Functional)        (None, None, None, 3)     24        |\n-||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n-|| input_2 (InputLayer)    [(None, None, None, 3)]   0         ||\n-||                                                             ||\n-|| conv2d (Conv2D)         (None, None, None, 3)     12        ||\n-||                                                             ||\n-|| batch_normalization (BatchN  (None, None, None, 3)  12      ||\n-|| ormalization)                                               ||\n-|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n-¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n-=================================================================\n-Total params: 24\n-Trainable params: 18\n-Non-trainable params: 6\n-_________________________________________________________________\n-\"\"\"\n+      check_str = ('Model: \"model_2\"\\n'\n+                  '_________________________________________________________________\\n'\n+                  ' Layer (type)                Output Shape              Param #   \\n'\n+                  '=================================================================\\n'\n+                  ' input_3 (InputLayer)        [(None, None, None, 3)]   0         \\n'\n+                  '                                                                 \\n'\n+                  ' model_1 (Functional)        (None, None, None, 3)     24        \\n'\n+                  '|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n'\n+                  '| input_1 (InputLayer)      [(None, None, None, 3)]   0         |\\n'\n+                  '|                                                               |\\n'\n+                  '| model (Functional)        (None, None, None, 3)     24        |\\n'\n+                  '||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\\n'\n+                  '|| input_2 (InputLayer)    [(None, None, None, 3)]   0         ||\\n'\n+                  '||                                                             ||\\n'\n+                  '|| conv2d (Conv2D)         (None, None, None, 3)     12        ||\\n'\n+                  '||                                                             ||\\n'\n+                  '|| batch_normalization (BatchN  (None, None, None, 3)  12      ||\\n'\n+                  '|| ormalization)                                               ||\\n'\n+                  '|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n'\n+                  '¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\\n'\n+                  '=================================================================\\n'\n+                  'Total params: 24\\n'\n+                  'Trainable params: 18\\n'\n+                  'Non-trainable params: 6\\n'\n+                  '_________________________________________________________________\\n')\n \n       fin_str = \"\"\n       for line in lines:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#639afd1276db8e9821c79569faa73061563001ed", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 2 | Churn Cumulative: 19208 | Contributors (this commit): 83 | Commits (past 90d): 27 | Contributors (cumulative): 83 | DMM Complexity: None\n\nDIFF:\n@@ -1984,7 +1984,7 @@ class SeparableConv1D(SeparableConv):\n   Input shape:\n     3D tensor with shape:\n     `(batch_size, channels, steps)` if data_format='channels_first'\n-    or 5D tensor with shape:\n+    or 3D tensor with shape:\n     `(batch_size, steps, channels)` if data_format='channels_last'.\n \n   Output shape:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#228ce89b56f1be222ae0deb6e744b0f4d0daad54", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 1303 | Contributors (this commit): 21 | Commits (past 90d): 10 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -290,7 +290,7 @@ def model_to_dot(model,\n             [format_shape(ishape) for ishape in layer.input_shapes])\n       else:\n         inputlabels = '?'\n-      label = '%s\\n|{input:|output:}|{{%s}|{%s}}' % (label,\n+      label = '%s|{input:|output:}|{{%s}|{%s}}' % (label,\n                                                      inputlabels,\n                                                      outputlabels)\n \n\n@@ -105,7 +105,12 @@ class ModelToDotFormatTest(tf.test.TestCase, parameterized.TestCase):\n     except ImportError:\n       pass\n \n-  def test_plot_model_cnn_with_activations(self):\n+  @parameterized.parameters(\n+      {'show_shapes': False, 'show_dtype': False},\n+      {'show_shapes': False, 'show_dtype': True},\n+      {'show_shapes': True, 'show_dtype': False},\n+      {'show_shapes': True, 'show_dtype': True})\n+  def test_plot_model_cnn_with_activations(self, show_shapes, show_dtype):\n     model = keras.Sequential()\n     model.add(\n         keras.layers.Conv2D(\n@@ -120,8 +125,8 @@ class ModelToDotFormatTest(tf.test.TestCase, parameterized.TestCase):\n       vis_utils.plot_model(\n           model,\n           to_file=dot_img_file,\n-          show_shapes=True,\n-          show_dtype=True,\n+          show_shapes=show_shapes,\n+          show_dtype=show_dtype,\n           show_layer_activations=True)\n       self.assertTrue(tf.io.gfile.exists(dot_img_file))\n       tf.io.gfile.remove(dot_img_file)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4edd952aef5092f1541b67397feac9df2bfc9278", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 1059 | Contributors (this commit): 21 | Commits (past 90d): 7 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -290,9 +290,8 @@ def model_to_dot(model,\n           [format_shape(ishape) for ishape in layer.input_shapes])\n       else:\n         inputlabels = '?'\n-      label = '%s|{input:|output:}|{{%s}|{%s}}' % (label,\n-                                                     inputlabels,\n-                                                     outputlabels)\n+      label = '%s|{input:|output:}|{{%s}|{%s}}' % (\n+        label, inputlabels, outputlabels)\n \n     if not expand_nested or not isinstance(\n         layer, functional.Functional):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a5803bf64c6dff5af45a519e4c195812efa044e4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1063 | Contributors (this commit): 21 | Commits (past 90d): 8 | Contributors (cumulative): 21 | DMM Complexity: None\n\nDIFF:\n@@ -290,8 +290,8 @@ def model_to_dot(model,\n             [format_shape(ishape) for ishape in layer.input_shapes])\n       else:\n         inputlabels = '?'\n-      label = '%s|{input:|output:}|{{%s}|{%s}}' % (\n-        label, inputlabels, outputlabels)\n+      label = f'{label}|{{input:|output:}}|' \\\n+          + f'{{{{{inputlabels}}}|{{{outputlabels}}}}}'\n \n     if not expand_nested or not isinstance(\n         layer, functional.Functional):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7658bfc42984b702e9a211d0e92eef83a338eba6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 1068 | Contributors (this commit): 21 | Commits (past 90d): 9 | Contributors (cumulative): 21 | DMM Complexity: None\n\nDIFF:\n@@ -290,9 +290,8 @@ def model_to_dot(model,\n             [format_shape(ishape) for ishape in layer.input_shapes])\n       else:\n         inputlabels = '?'\n-      label = f'{label}|{{input:|output:}}|' \\\n-          + f'{{{{{inputlabels}}}|{{{outputlabels}}}}}'\n-\n+      label = '{%s}|{input:|output:}|{{%s}}|{{%s}}' % (\n+          label, inputlabels, outputlabels)\n     if not expand_nested or not isinstance(\n         layer, functional.Functional):\n       node = pydot.Node(layer_id, label=label)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3c6611999cbfaeedb23ba14ca0ecf2450c752877", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 4164 | Contributors (this commit): 8 | Commits (past 90d): 16 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1437,16 +1437,20 @@ class TrainingTest(keras_parameterized.TestCase):\n     x = rng.normal(size=(n_samples, n_features))\n     y = rng.randint(low=0, high=2, size=x.shape[0])\n     model = sequential.Sequential([layers_module.Dense(1,)])\n-    model.compile('adam', 'binary_crossentropy', metrics=['accuracy'], run_eagerly=testing_utils.should_run_eagerly())\n+    model.compile('adam', 'binary_crossentropy', \n+                  metrics=['accuracy'], \n+                  run_eagerly=testing_utils.should_run_eagerly())\n     loss = {}\n     accurancy = {}\n     loss_1 = {}\n     accurancy_1 = {}\n     for i in range(3):\n-      loss[i], accurancy[i] = model.test_on_batch(x[:batch_size], y[:batch_size])\n-    model.evaluate(x[:batch_size],y[:batch_size], batch_size=batch_size, verbose=0)\n+      loss[i], accurancy[i] = model.test_on_batch(x[:batch_size], \n+                                                  y[:batch_size])\n+    model.evaluate(x,y, batch_size=batch_size, verbose=0)\n     for i in range(3):\n-      loss_1[i], accurancy_1[i] = model.test_on_batch(x[:batch_size], y[:batch_size])\n+      loss_1[i], accurancy_1[i] = model.test_on_batch(x[:batch_size], \n+                                                      y[:batch_size])\n     self.assertAllEqual(loss, loss_1, \n                         \"https://github.com/keras-team/keras/issues/14086\")\n     self.assertAllEqual(accurancy, accurancy_1, \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5944a544f7f629ed44016028ccb11563c4f61143", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 32 | Files Changed: 2 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 56 | Churn Cumulative: 20154 | Contributors (this commit): 115 | Commits (past 90d): 59 | Contributors (cumulative): 122 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1847,6 +1847,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     self._assert_compile_was_called()\n     self._check_call_args('train_on_batch')\n     _disallow_inside_tf_function('train_on_batch')\n+    if reset_metrics:\n+      self.reset_metrics()\n     with self.distribute_strategy.scope(), \\\n          training_utils.RespectCompiledTrainableState(self):\n       iterator = data_adapter.single_batch_iterator(self.distribute_strategy, x,\n@@ -1855,8 +1857,6 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n       self.train_function = self.make_train_function()\n       logs = self.train_function(iterator)\n \n-    if reset_metrics:\n-      self.reset_metrics()\n     logs = tf_utils.sync_to_numpy_or_python_type(logs)\n     if return_dict:\n       return logs\n@@ -1906,14 +1906,14 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     self._assert_compile_was_called()\n     self._check_call_args('test_on_batch')\n     _disallow_inside_tf_function('test_on_batch')\n+    if reset_metrics:\n+      self.reset_metrics()\n     with self.distribute_strategy.scope():\n       iterator = data_adapter.single_batch_iterator(self.distribute_strategy, x,\n                                                     y, sample_weight)\n       self.test_function = self.make_test_function()\n       logs = self.test_function(iterator)\n \n-    if reset_metrics:\n-      self.reset_metrics()\n     logs = tf_utils.sync_to_numpy_or_python_type(logs)\n     if return_dict:\n       return logs\n\n@@ -1428,34 +1428,6 @@ class TrainingTest(keras_parameterized.TestCase):\n     self.assertIsInstance(loss, float)\n     self.assertIsInstance(accuracy, float)\n \n-  @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n-  @unittest.expectedFailure\n-  def test_loss_acc_is_corrupted(self):\n-    batch_size = 32\n-    n_samples, n_features = batch_size * 10, 5\n-    rng = np.random.RandomState(0)\n-    x = rng.normal(size=(n_samples, n_features))\n-    y = rng.randint(low=0, high=2, size=x.shape[0])\n-    model = sequential.Sequential([layers_module.Dense(1,)])\n-    model.compile('adam', 'binary_crossentropy', \n-                  metrics=['accuracy'], \n-                  run_eagerly=testing_utils.should_run_eagerly())\n-    loss = {}\n-    accurancy = {}\n-    loss_1 = {}\n-    accurancy_1 = {}\n-    for i in range(3):\n-      loss[i], accurancy[i] = model.test_on_batch(x[:batch_size], \n-                                                  y[:batch_size])\n-    model.evaluate(x,y, batch_size=batch_size, verbose=0)\n-    for i in range(3):\n-      loss_1[i], accurancy_1[i] = model.test_on_batch(x[:batch_size], \n-                                                      y[:batch_size])\n-    self.assertAllEqual(loss, loss_1, \n-                        \"https://github.com/keras-team/keras/issues/14086\")\n-    self.assertAllEqual(accurancy, accurancy_1, \n-                        \"https://github.com/keras-team/keras/issues/14086\")\n-\n   @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n   def test_int_output(self):\n     x, y = np.ones((10, 1)), np.ones((10, 1))\n@@ -2958,6 +2930,26 @@ class TestTrainingWithMetrics(keras_parameterized.TestCase):\n     model.evaluate(x_test, y_test, batch_size=5)\n     self.assertEqual(self.evaluate(acc_obj.count), 10)\n \n+  @keras_parameterized.run_all_keras_modes\n+  def test_metric_state_reset_between_test_on_batch_and_evaluate(self):\n+    model = sequential.Sequential()\n+    model.add(layers_module.Dense(3, activation='relu', input_dim=4))\n+    model.add(layers_module.Dense(1, activation='sigmoid'))\n+    acc_obj = metrics_module.BinaryAccuracy()\n+    model.compile(\n+        loss='mae',\n+        metrics=[acc_obj],\n+        optimizer=RMSPropOptimizer(learning_rate=0.001),\n+        run_eagerly=testing_utils.should_run_eagerly())\n+\n+    x_test = np.random.random((10, 4))\n+    y_test = np.random.random((10, 1))\n+    loss, acc = model.test_on_batch(x_test[:2],y_test[:2])\n+    model.evaluate(x_test, y_test)\n+    loss_1, acc_1 = model.test_on_batch(x_test[:2],y_test[:2])\n+    self.assertEqual(loss, loss_1)\n+    self.assertEqual(acc, acc_1)\n+\n   @keras_parameterized.run_with_all_model_types(exclude_models=['sequential'])\n   @keras_parameterized.run_all_keras_modes\n   def test_metrics_valid_compile_input_formats(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b791677cfe67997158be74b1196380f4e115a89b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 4217 | Contributors (this commit): 8 | Commits (past 90d): 18 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2945,10 +2945,13 @@ class TestTrainingWithMetrics(keras_parameterized.TestCase):\n     x_test = np.random.random((10, 4))\n     y_test = np.random.random((10, 1))\n     loss, acc = model.test_on_batch(x_test[:2],y_test[:2])\n-    model.evaluate(x_test, y_test)\n+    loss_eval, acc_eval = model.evaluate(x_test, y_test)\n     loss_1, acc_1 = model.test_on_batch(x_test[:2],y_test[:2])\n+    loss_eval_1, acc_eval_1 = model.evaluate(x_test, y_test)\n     self.assertEqual(loss, loss_1)\n     self.assertEqual(acc, acc_1)\n+    self.assertEqual(loss_eval, loss_eval_1)\n+    self.assertEqual(acc_eval, acc_eval_1)\n \n   @keras_parameterized.run_with_all_model_types(exclude_models=['sequential'])\n   @keras_parameterized.run_all_keras_modes\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6241e97f1c2a76676da6e33938ef8c821d2e5135", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 52 | Lines Deleted: 10 | Files Changed: 3 | Hunks: 16 | Methods Changed: 11 | Complexity Δ (Sum/Max): 6/3 | Churn Δ: 62 | Churn Cumulative: 9277 | Contributors (this commit): 8 | Commits (past 90d): 38 | Contributors (cumulative): 17 | DMM Complexity: 0.6818181818181818\n\nDIFF:\n@@ -656,6 +656,13 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n                                                    binary_output)\n \n     if self.output_mode == TF_IDF:\n+      if self.sparse:\n+        value_weights = tf.gather(self.idf_weights_const,\n+                                  bincounts.indices[:, -1])\n+        return tf.SparseTensor(bincounts.indices,\n+                               value_weights * bincounts.values,\n+                               bincounts.dense_shape)\n+      else:\n         return tf.multiply(bincounts, self.idf_weights_const)\n \n     return bincounts\n\n@@ -1149,7 +1149,11 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     count_data = layer(input_data)\n     self.assertAllEqual(count_data.shape.as_list(), [16, 2])\n \n-  def test_ifidf_output_hard_maximum(self):\n+  @parameterized.named_parameters(\n+      (\"sparse\", True),\n+      (\"dense\", False),\n+  )\n+  def test_ifidf_output_hard_maximum(self, sparse):\n     \"\"\"Check tf-idf output when pad_to_max_tokens=True.\"\"\"\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n     # OOV idf weight (bucket 0) should 0.5, the average of passed weights.\n@@ -1169,14 +1173,21 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n         oov_token=\"[OOV]\",\n         output_mode=index_lookup.TF_IDF,\n         pad_to_max_tokens=True,\n-        dtype=tf.string)\n+        dtype=tf.string,\n+        sparse=sparse)\n     layer.set_vocabulary(vocab_data, idf_weights=idf_weights)\n     layer_output = layer(input_data)\n     model = keras.Model(inputs=input_data, outputs=layer_output)\n     output_dataset = model.predict(input_array)\n+    if sparse:\n+      output_dataset = tf.sparse.to_dense(output_dataset)\n     self.assertAllClose(expected_output, output_dataset)\n \n-  def test_ifidf_output_soft_maximum(self):\n+  @parameterized.named_parameters(\n+      (\"sparse\", True),\n+      (\"dense\", False),\n+  )\n+  def test_ifidf_output_soft_maximum(self, sparse):\n     \"\"\"Check tf-idf output when pad_to_max_tokens=False.\"\"\"\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n     # OOV idf weight (bucket 0) should 0.5, the average of passed weights.\n@@ -1195,11 +1206,14 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n         mask_token=\"\",\n         oov_token=\"[OOV]\",\n         output_mode=index_lookup.TF_IDF,\n-        dtype=tf.string)\n+        dtype=tf.string,\n+        sparse=sparse)\n     layer.set_vocabulary(vocab_data, idf_weights=idf_weights)\n     layer_output = layer(input_data)\n     model = keras.Model(inputs=input_data, outputs=layer_output)\n     output_dataset = model.predict(input_array)\n+    if sparse:\n+      output_dataset = tf.sparse.to_dense(output_dataset)\n     self.assertAllClose(expected_output, output_dataset)\n \n   def test_ifidf_output_shape(self):\n\n@@ -1264,7 +1264,11 @@ class TextVectorizationOutputTest(\n     output_dataset = model.predict(input_array)\n     self.assertAllEqual(expected_output, output_dataset)\n \n-  def test_tfidf_output_hard_maximum(self):\n+  @parameterized.named_parameters(\n+      (\"sparse\", True),\n+      (\"dense\", False),\n+  )\n+  def test_tfidf_output_hard_maximum(self, sparse):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n     # OOV idf weight (bucket 0) should 0.5, the average of passed weights.\n     idf_weights = [.4, .25, .75, .6]\n@@ -1286,16 +1290,23 @@ class TextVectorizationOutputTest(\n         standardize=None,\n         split=None,\n         output_mode=text_vectorization.TF_IDF,\n-        pad_to_max_tokens=True)\n+        pad_to_max_tokens=True,\n+        sparse=sparse)\n     layer.set_vocabulary(vocab_data, idf_weights=idf_weights)\n     int_data = layer(input_data)\n     self.assertAllEqual(expected_output_shape, int_data.shape.as_list())\n \n     model = keras.Model(inputs=input_data, outputs=int_data)\n     output_dataset = model.predict(input_array)\n+    if sparse:\n+      output_dataset = tf.sparse.to_dense(output_dataset)\n     self.assertAllClose(expected_output, output_dataset)\n \n-  def test_tfidf_output_soft_maximum(self):\n+  @parameterized.named_parameters(\n+      (\"sparse\", True),\n+      (\"dense\", False),\n+  )\n+  def test_tfidf_output_soft_maximum(self, sparse):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n     # OOV idf weight (bucket 0) should 0.5, the average of passed weights.\n     idf_weights = [.4, .25, .75, .6]\n@@ -1317,16 +1328,23 @@ class TextVectorizationOutputTest(\n         standardize=None,\n         split=None,\n         output_mode=text_vectorization.TF_IDF,\n-        pad_to_max_tokens=False)\n+        pad_to_max_tokens=False,\n+        sparse=sparse)\n     layer.set_vocabulary(vocab_data, idf_weights=idf_weights)\n     int_data = layer(input_data)\n     self.assertAllEqual(expected_output_shape, int_data.shape.as_list())\n \n     model = keras.Model(inputs=input_data, outputs=int_data)\n     output_dataset = model.predict(input_array)\n+    if sparse:\n+      output_dataset = tf.sparse.to_dense(output_dataset)\n     self.assertAllClose(expected_output, output_dataset)\n \n-  def test_tfidf_output_set_oov_weight(self):\n+  @parameterized.named_parameters(\n+      (\"sparse\", True),\n+      (\"dense\", False),\n+  )\n+  def test_tfidf_output_set_oov_weight(self, sparse):\n     vocab_data = [\"[UNK]\", \"earth\", \"wind\", \"and\", \"fire\"]\n     idf_weights = [.1, .4, .25, .75, .6]\n     input_array = np.array([[\"earth\", \"wind\", \"and\", \"earth\"],\n@@ -1347,13 +1365,16 @@ class TextVectorizationOutputTest(\n         standardize=None,\n         split=None,\n         output_mode=text_vectorization.TF_IDF,\n-        pad_to_max_tokens=False)\n+        pad_to_max_tokens=False,\n+        sparse=sparse)\n     layer.set_vocabulary(vocab_data, idf_weights=idf_weights)\n     int_data = layer(input_data)\n     self.assertAllEqual(expected_output_shape, int_data.shape.as_list())\n \n     model = keras.Model(inputs=input_data, outputs=int_data)\n     output_dataset = model.predict(input_array)\n+    if sparse:\n+      output_dataset = tf.sparse.to_dense(output_dataset)\n     self.assertAllClose(expected_output, output_dataset)\n \n   def test_accept_1D_input(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1dd712893462e9d656531f769a39556c7d0a1c02", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 2 | Files Changed: 3 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 19 | Churn Cumulative: 16484 | Contributors (this commit): 115 | Commits (past 90d): 46 | Contributors (cumulative): 122 | DMM Complexity: 0.5714285714285714\n\nDIFF:\n@@ -105,6 +105,15 @@ class DatasetCreatorModelFitParameterServerStrategyOnlyTest(\n     files = tf.compat.v1.gfile.ListDirectory(log_dir)\n     self.assertGreaterEqual(len(files), 1)\n \n+  def testModelFitVerbose1(self, strategy, use_dataset_creator):\n+    with self.assertRaisesRegex(ValueError,\n+                                \"`verbose=1` is not allowed with \"\n+                                \"`ParameterServerStrategy` for performance \"\n+                                \"reasons. Received: `verbose`=1\"):\n+      self._model_fit(\n+          strategy, use_dataset_creator=use_dataset_creator,\n+          verbose=1)\n+\n   def testModelEvaluateErrorOnBatchLevelCallbacks(self, strategy,\n                                                   use_dataset_creator):\n \n\n@@ -119,7 +119,8 @@ class DatasetCreatorModelFitTestBase(tf.test.TestCase, parameterized.TestCase):\n                  with_normalization_layer=False,\n                  callbacks=None,\n                  use_lookup_layer=False,\n-                 use_dataset_creator=True):\n+                 use_dataset_creator=True,\n+                 verbose=\"auto\"):\n     if callbacks is None:\n       callbacks = []\n \n@@ -153,7 +154,8 @@ class DatasetCreatorModelFitTestBase(tf.test.TestCase, parameterized.TestCase):\n         steps_per_epoch=steps_per_epoch,\n         callbacks=callbacks,\n         validation_data=validation_data,\n-        validation_steps=steps_per_epoch)\n+        validation_steps=steps_per_epoch,\n+        verbose=verbose)\n     return model\n \n   def _model_evaluate(self,\n\n@@ -1109,6 +1109,10 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         verbose = 2  # Default to epoch-level logging for PSStrategy.\n       else:\n         verbose = 1  # Default to batch-level logging otherwise.\n+    elif verbose == 1 and self.distribute_strategy._should_use_with_coordinator:  # pylint: disable=protected-access\n+      raise ValueError(\n+          '`verbose=1` is not allowed with `ParameterServerStrategy` for '\n+          f'performance reasons. Received: `verbose`={verbose}')\n \n     if validation_split:\n       # Create the validation data using the training data. Only supported for\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#384997b663325d57baea72f7457174551f8bbb5d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 104 | Lines Deleted: 54 | Files Changed: 7 | Hunks: 41 | Methods Changed: 21 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 158 | Churn Cumulative: 13675 | Contributors (this commit): 8 | Commits (past 90d): 69 | Contributors (cumulative): 37 | DMM Complexity: 0.6\n\nDIFF:\n@@ -119,6 +119,12 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n       containing the vocbulary terms. If passing a file path, the file should\n       contain one line per term in the vocabulary. If this argument is set,\n       there is no need to `adapt` the layer.\n+    idf_weights: Only valid when `output_mode` is `\"tf_idf\"`. A tuple, list, 1D\n+      numpy array, or 1D tensor or the same length as the vocabulary, containing\n+      the floating point inverse document frequency weights, which will be\n+      multiplied by per sample term counts for the final `tf_idf` weight. If the\n+      `vocabulary` argument is set, and `output_mode` is `\"tf_idf\"`, this\n+      argument must be supplied.\n     invert: Only valid when `output_mode` is `\"int\"`. If True, this layer will\n       map indices to vocabulary items instead of mapping vocabulary items to\n       indices. Default to False.\n@@ -156,6 +162,7 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n                mask_token,\n                oov_token,\n                vocabulary=None,\n+               idf_weights=None,\n                invert=False,\n                output_mode=\"int\",\n                sparse=False,\n@@ -197,6 +204,11 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n                        f\"Received: sparse={sparse} and \"\n                        f\"output_mode={output_mode}\")\n \n+    if idf_weights is not None and output_mode != TF_IDF:\n+      raise ValueError(f\"`idf_weights` should only be set if `output_mode` is \"\n+                       f\"`'tf_idf'`. Received: idf_weights={idf_weights} and \"\n+                       f\"output_mode={output_mode}\")\n+\n     self.invert = invert\n     self.max_tokens = max_tokens\n     self.num_oov_indices = num_oov_indices\n@@ -208,6 +220,7 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n     self._frozen_vocab_size = None\n \n     self.input_vocabulary = vocabulary\n+    self.input_idf_weights = idf_weights\n     # VocabularySavedModelSaver will clear the config vocabulary to restore the\n     # lookup table ops directly. We persist this hidden option to persist the\n     # fact that we have have a non-adaptable layer with a manually set vocab.\n@@ -260,7 +273,7 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n       self.idf_weights_const = self.idf_weights.value()\n \n     if vocabulary is not None:\n-      self.set_vocabulary(vocabulary)\n+      self.set_vocabulary(vocabulary, idf_weights)\n     else:\n       # When restoring from a keras SavedModel, the loading code will expect to\n       # find and restore a lookup_table attribute on the layer. This table needs\n@@ -342,6 +355,7 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n         \"output_mode\": self.output_mode,\n         \"pad_to_max_tokens\": self.pad_to_max_tokens,\n         \"vocabulary\": utils.listify_tensors(self.input_vocabulary),\n+        \"idf_weights\": utils.listify_tensors(self.input_idf_weights),\n     }\n \n     base_config = super().get_config()\n\n@@ -1174,8 +1174,9 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n         output_mode=index_lookup.TF_IDF,\n         pad_to_max_tokens=True,\n         dtype=tf.string,\n-        sparse=sparse)\n-    layer.set_vocabulary(vocab_data, idf_weights=idf_weights)\n+        sparse=sparse,\n+        vocabulary=vocab_data,\n+        idf_weights=idf_weights)\n     layer_output = layer(input_data)\n     model = keras.Model(inputs=input_data, outputs=layer_output)\n     output_dataset = model.predict(input_array)\n@@ -1207,8 +1208,9 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n         oov_token=\"[OOV]\",\n         output_mode=index_lookup.TF_IDF,\n         dtype=tf.string,\n-        sparse=sparse)\n-    layer.set_vocabulary(vocab_data, idf_weights=idf_weights)\n+        sparse=sparse,\n+        vocabulary=vocab_data,\n+        idf_weights=idf_weights)\n     layer_output = layer(input_data)\n     model = keras.Model(inputs=input_data, outputs=layer_output)\n     output_dataset = model.predict(input_array)\n@@ -1224,8 +1226,9 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n         mask_token=\"\",\n         oov_token=\"[OOV]\",\n         output_mode=index_lookup.TF_IDF,\n-        dtype=tf.string)\n-    layer.set_vocabulary(vocabulary=[\"foo\"], idf_weights=[1.0])\n+        dtype=tf.string,\n+        vocabulary=[\"foo\"],\n+        idf_weights=[1.0])\n     layer_output = layer(input_data)\n     self.assertAllEqual(layer_output.shape.as_list(), [16, 2])\n \n@@ -1722,43 +1725,45 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n   def test_vocab_with_idf_weights_non_tfidf_output_fails(self):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n     weight_data = [1, 1, 1, 1, 1]\n-    layer = index_lookup.IndexLookup(\n+    with self.assertRaisesRegex(ValueError,\n+                                \"`idf_weights` should only be set if\"):\n+      index_lookup.IndexLookup(\n           max_tokens=None,\n           num_oov_indices=1,\n           mask_token=\"\",\n           oov_token=\"[OOV]\",\n           output_mode=index_lookup.MULTI_HOT,\n-        dtype=tf.string)\n-    with self.assertRaisesRegex(ValueError,\n-                                \"`idf_weights` should only be set if\"):\n-      layer.set_vocabulary(vocab_data, idf_weights=weight_data)\n+          dtype=tf.string,\n+          vocabulary=vocab_data,\n+          idf_weights=weight_data)\n \n   def test_vocab_with_idf_weights_length_mismatch_fails(self):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n     weight_data = [1, 1, 1, 1, 1]  # too long\n-    layer = index_lookup.IndexLookup(\n+    with self.assertRaisesRegex(\n+        ValueError, \"`idf_weights` must be the same length as vocab\"):\n+      index_lookup.IndexLookup(\n           max_tokens=None,\n           num_oov_indices=1,\n           mask_token=\"\",\n           oov_token=\"[OOV]\",\n           output_mode=index_lookup.TF_IDF,\n-        dtype=tf.string)\n-    with self.assertRaisesRegex(\n-        ValueError, \"`idf_weights` must be the same length as vocab\"):\n-      layer.set_vocabulary(vocab_data, idf_weights=weight_data)\n+          dtype=tf.string,\n+          vocabulary=vocab_data,\n+          idf_weights=weight_data)\n \n   def test_vocab_without_idf_weights_tfidf_output_fails(self):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n-    layer = index_lookup.IndexLookup(\n+    with self.assertRaisesRegex(\n+        ValueError, \"`idf_weights` must be set if output_mode is TF_IDF\"):\n+      index_lookup.IndexLookup(\n           max_tokens=None,\n           num_oov_indices=1,\n           mask_token=\"\",\n           oov_token=\"[OOV]\",\n           output_mode=index_lookup.TF_IDF,\n-        dtype=tf.string)\n-    with self.assertRaisesRegex(\n-        ValueError, \"`idf_weights` must be set if output_mode is TF_IDF\"):\n-      layer.set_vocabulary(vocab_data)\n+          dtype=tf.string,\n+          vocabulary=vocab_data)\n \n   def test_non_unique_int_vocab_fails(self):\n     vocab_data = [12, 13, 14, 15, 15]\n\n@@ -85,6 +85,12 @@ class IntegerLookup(index_lookup.IndexLookup):\n       tensor containing the integer vocbulary terms. If passing a file path, the\n       file should contain one line per term in the vocabulary. If this argument\n       is set, there is no need to `adapt` the layer.\n+    idf_weights: Only valid when `output_mode` is `\"tf_idf\"`. A tuple, list, 1D\n+      numpy array, or 1D tensor or the same length as the vocabulary, containing\n+      the floating point inverse document frequency weights, which will be\n+      multiplied by per sample term counts for the final `tf_idf` weight. If the\n+      `vocabulary` argument is set, and `output_mode` is `\"tf_idf\"`, this\n+      argument must be supplied.\n     invert: Only valid when `output_mode` is `\"int\"`. If True, this layer will\n       map indices to vocabulary items instead of mapping vocabulary items to\n       indices. Default to False.\n@@ -233,8 +239,8 @@ class IntegerLookup(index_lookup.IndexLookup):\n   >>> vocab = [12, 36, 1138, 42]\n   >>> idf_weights = [0.25, 0.75, 0.6, 0.4]\n   >>> data = tf.constant([[12, 1138, 42, 42], [42, 7, 36, 7]]) # Note OOV tokens\n-  >>> layer = tf.keras.layers.IntegerLookup(output_mode='tf_idf')\n-  >>> layer.set_vocabulary(vocab, idf_weights=idf_weights)\n+  >>> layer = tf.keras.layers.IntegerLookup(\n+  ...     output_mode='tf_idf', vocab, idf_weights=idf_weights)\n   >>> layer(data)\n   <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n     array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],\n@@ -246,8 +252,8 @@ class IntegerLookup(index_lookup.IndexLookup):\n   >>> vocab = [-1, 12, 36, 1138, 42]\n   >>> idf_weights = [0.9, 0.25, 0.75, 0.6, 0.4]\n   >>> data = tf.constant([[12, 1138, 42, 42], [42, 7, 36, 7]]) # Note OOV tokens\n-  >>> layer = tf.keras.layers.IntegerLookup(output_mode='tf_idf')\n-  >>> layer.set_vocabulary(vocab, idf_weights=idf_weights)\n+  >>> layer = tf.keras.layers.IntegerLookup(\n+  ...     output_mode='tf_idf', vocab, idf_weights=idf_weights)\n   >>> layer(data)\n   <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n     array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],\n@@ -303,6 +309,7 @@ class IntegerLookup(index_lookup.IndexLookup):\n                mask_token=None,\n                oov_token=-1,\n                vocabulary=None,\n+               idf_weights=None,\n                invert=False,\n                output_mode=\"int\",\n                sparse=False,\n@@ -359,6 +366,7 @@ class IntegerLookup(index_lookup.IndexLookup):\n         mask_token=mask_token,\n         oov_token=oov_token,\n         vocabulary=vocabulary,\n+        idf_weights=idf_weights,\n         invert=invert,\n         output_mode=output_mode,\n         sparse=sparse,\n\n@@ -237,8 +237,7 @@ class CategoricalEncodingAdaptTest(\n       for _ in itertools.count(1):\n         yield random.randint(0, 100)\n \n-    ds = tf.data.Dataset.from_generator(word_gen, tf.int64,\n-                                            tf.TensorShape([]))\n+    ds = tf.data.Dataset.from_generator(word_gen, tf.int64, tf.TensorShape([]))\n     batched_ds = ds.take(2)\n     input_t = keras.Input(shape=(), dtype=tf.int64)\n     layer = integer_lookup.IntegerLookup(\n\n@@ -81,6 +81,12 @@ class StringLookup(index_lookup.IndexLookup):\n       tensor containing the string vocbulary terms. If passing a file path, the\n       file should contain one line per term in the vocabulary. If this argument\n       is set, there is no need to `adapt` the layer.\n+    idf_weights: Only valid when `output_mode` is `\"tf_idf\"`. A tuple, list, 1D\n+      numpy array, or 1D tensor or the same length as the vocabulary, containing\n+      the floating point inverse document frequency weights, which will be\n+      multiplied by per sample term counts for the final `tf_idf` weight. If the\n+      `vocabulary` argument is set, and `output_mode` is `\"tf_idf\"`, this\n+      argument must be supplied.\n     invert: Only valid when `output_mode` is `\"int\"`. If True, this layer will\n       map indices to vocabulary items instead of mapping vocabulary items to\n       indices. Default to False.\n@@ -297,6 +303,7 @@ class StringLookup(index_lookup.IndexLookup):\n                mask_token=None,\n                oov_token=\"[UNK]\",\n                vocabulary=None,\n+               idf_weights=None,\n                encoding=None,\n                invert=False,\n                output_mode=\"int\",\n@@ -324,6 +331,7 @@ class StringLookup(index_lookup.IndexLookup):\n         mask_token=mask_token,\n         oov_token=oov_token,\n         vocabulary=vocabulary,\n+        idf_weights=idf_weights,\n         invert=invert,\n         output_mode=output_mode,\n         sparse=sparse,\n\n@@ -163,6 +163,12 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n       tensor containing the string vocbulary terms. If passing a file path, the\n       file should contain one line per term in the vocabulary. If this argument\n       is set, there is no need to `adapt` the layer.\n+    idf_weights: Only valid when `output_mode` is `\"tf_idf\"`. A tuple, list, 1D\n+      numpy array, or 1D tensor or the same length as the vocabulary, containing\n+      the floating point inverse document frequency weights, which will be\n+      multiplied by per sample term counts for the final `tf_idf` weight. If the\n+      `vocabulary` argument is set, and `output_mode` is `\"tf_idf\"`, this\n+      argument must be supplied.\n     ragged: Boolean. Only applicable to `\"int\"` output mode. If True, returns a\n       `RaggedTensor` instead of a dense `Tensor`, where each sequence may have a\n       different length after string splitting. Defaults to False.\n@@ -244,6 +250,7 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n                output_sequence_length=None,\n                pad_to_max_tokens=False,\n                vocabulary=None,\n+               idf_weights=None,\n                sparse=False,\n                ragged=False,\n                **kwargs):\n@@ -348,6 +355,7 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n     self._lookup_layer = string_lookup.StringLookup(\n         max_tokens=max_tokens,\n         vocabulary=vocabulary,\n+        idf_weights=idf_weights,\n         pad_to_max_tokens=pad_to_max_tokens,\n         mask_token=\"\",\n         output_mode=output_mode if output_mode is not None else INT,\n@@ -401,6 +409,7 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n \n   def get_config(self):\n     vocab = self._lookup_layer.input_vocabulary\n+    idf_weights = self._lookup_layer.input_idf_weights\n     config = {\n         \"max_tokens\": self._lookup_layer.max_tokens,\n         \"standardize\": self._standardize,\n@@ -412,6 +421,7 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n         \"sparse\": self._lookup_layer.sparse,\n         \"ragged\": self._ragged,\n         \"vocabulary\": utils.listify_tensors(vocab),\n+        \"idf_weights\": utils.listify_tensors(idf_weights),\n     }\n     base_config = super(TextVectorization, self).get_config()\n     return dict(list(base_config.items()) + list(config.items()))\n\n@@ -1291,8 +1291,9 @@ class TextVectorizationOutputTest(\n         split=None,\n         output_mode=text_vectorization.TF_IDF,\n         pad_to_max_tokens=True,\n-        sparse=sparse)\n-    layer.set_vocabulary(vocab_data, idf_weights=idf_weights)\n+        sparse=sparse,\n+        vocabulary=vocab_data,\n+        idf_weights=idf_weights)\n     int_data = layer(input_data)\n     self.assertAllEqual(expected_output_shape, int_data.shape.as_list())\n \n@@ -1329,8 +1330,9 @@ class TextVectorizationOutputTest(\n         split=None,\n         output_mode=text_vectorization.TF_IDF,\n         pad_to_max_tokens=False,\n-        sparse=sparse)\n-    layer.set_vocabulary(vocab_data, idf_weights=idf_weights)\n+        sparse=sparse,\n+        vocabulary=vocab_data,\n+        idf_weights=idf_weights)\n     int_data = layer(input_data)\n     self.assertAllEqual(expected_output_shape, int_data.shape.as_list())\n \n@@ -1366,8 +1368,9 @@ class TextVectorizationOutputTest(\n         split=None,\n         output_mode=text_vectorization.TF_IDF,\n         pad_to_max_tokens=False,\n-        sparse=sparse)\n-    layer.set_vocabulary(vocab_data, idf_weights=idf_weights)\n+        sparse=sparse,\n+        vocabulary=vocab_data,\n+        idf_weights=idf_weights)\n     int_data = layer(input_data)\n     self.assertAllEqual(expected_output_shape, int_data.shape.as_list())\n \n@@ -1419,7 +1422,10 @@ class TextVectorizationModelBuildingTest(\n       })\n   def test_end_to_end_bagged_modeling(self, output_mode, pad_to_max_tokens):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n+    if output_mode == text_vectorization.TF_IDF:\n       idf_weights = [.5, .25, .2, .125]\n+    else:\n+      idf_weights = None\n     input_array = np.array([[\"earth\", \"wind\", \"and\", \"earth\"],\n                             [\"ohio\", \"and\", \"earth\", \"michigan\"]])\n \n@@ -1429,11 +1435,9 @@ class TextVectorizationModelBuildingTest(\n         standardize=None,\n         split=None,\n         output_mode=output_mode,\n-        pad_to_max_tokens=pad_to_max_tokens)\n-    if output_mode == text_vectorization.TF_IDF:\n-      layer.set_vocabulary(vocab_data, idf_weights=idf_weights)\n-    else:\n-      layer.set_vocabulary(vocab_data)\n+        pad_to_max_tokens=pad_to_max_tokens,\n+        vocabulary=vocab_data,\n+        idf_weights=idf_weights)\n \n     int_data = layer(input_data)\n     float_data = backend.cast(int_data, dtype=\"float32\")\n@@ -1519,38 +1523,40 @@ class TextVectorizationErrorTest(keras_parameterized.TestCase,\n   def test_setting_vocab_without_idf_weights_fails_in_tfidf_mode(self):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n \n-    layer = text_vectorization.TextVectorization(\n+    with self.assertRaisesRegex(\n+        ValueError, \"`idf_weights` must be set if output_mode is TF_IDF\"):\n+      text_vectorization.TextVectorization(\n           max_tokens=5,\n           standardize=None,\n           split=None,\n-        output_mode=text_vectorization.TF_IDF)\n-    with self.assertRaisesRegex(\n-        ValueError, \"`idf_weights` must be set if output_mode is TF_IDF\"):\n-      layer.set_vocabulary(vocab_data)\n+          output_mode=text_vectorization.TF_IDF,\n+          vocabulary=vocab_data)\n \n   def test_idf_weights_length_mismatch_fails(self):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n     idf_weights = [1, 2, 3]\n-    layer = text_vectorization.TextVectorization(\n+    with self.assertRaisesRegex(\n+        ValueError, \"`idf_weights` must be the same length as vocab\"):\n+      text_vectorization.TextVectorization(\n           max_tokens=5,\n           standardize=None,\n           split=None,\n-        output_mode=text_vectorization.TF_IDF)\n-    with self.assertRaisesRegex(\n-        ValueError, \"`idf_weights` must be the same length as vocab\"):\n-      layer.set_vocabulary(vocab_data, idf_weights)\n+          output_mode=text_vectorization.TF_IDF,\n+          vocabulary=vocab_data,\n+          idf_weights=idf_weights)\n \n   def test_set_tfidf_in_non_tfidf_fails(self):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n     idf_weights = [1, 2, 3, 4]\n-    layer = text_vectorization.TextVectorization(\n+    with self.assertRaisesRegex(ValueError,\n+                                \"`idf_weights` should only be set if\"):\n+      text_vectorization.TextVectorization(\n           max_tokens=5,\n           standardize=None,\n           split=None,\n-        output_mode=text_vectorization.MULTI_HOT)\n-    with self.assertRaisesRegex(ValueError,\n-                                \"`idf_weights` should only be set if\"):\n-      layer.set_vocabulary(vocab_data, idf_weights)\n+          output_mode=text_vectorization.MULTI_HOT,\n+          vocabulary=vocab_data,\n+          idf_weights=idf_weights)\n \n   def test_zero_max_tokens_fails(self):\n     with self.assertRaisesRegex(ValueError, \"max_tokens.*\"):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
