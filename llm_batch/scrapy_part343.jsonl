{"custom_id": "scrapy#010cf9d42089f33dbc6408f034adab289becbea8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 451 | Contributors (this commit): 16 | Commits (past 90d): 3 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -36,7 +36,7 @@ def get_meta_refresh(\n     response: \"scrapy.http.response.text.TextResponse\",\n     ignore_tags: Optional[Iterable[str]] = ('script', 'noscript'),\n ) -> Union[Tuple[None, None], Tuple[float, str]]:\n-    \"\"\"Parse the http-equiv refrsh parameter from the given response\"\"\"\n+    \"\"\"Parse the http-equiv refresh parameter from the given response\"\"\"\n     if response not in _metaref_cache:\n         text = response.text[0:4096]\n         _metaref_cache[response] = html.get_meta_refresh(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#1e44d4614ec7d34c4fb8f50a3429e4b1ddeb2253", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1467 | Contributors (this commit): 22 | Commits (past 90d): 7 | Contributors (cumulative): 22 | DMM Complexity: None\n\nDIFF:\n@@ -182,7 +182,7 @@ class ImagesPipelineTestCase(unittest.TestCase):\n         with warnings.catch_warnings(record=True) as w:\n             warnings.simplefilter('always')\n             SIZE = (100, 100)\n-            # straigh forward case: RGB and JPEG\n+            # straight forward case: RGB and JPEG\n             COLOUR = (0, 127, 255)\n             im, _ = _create_image('JPEG', 'RGB', SIZE, COLOUR)\n             converted, _ = self.pipeline.convert_image(im)\n@@ -216,7 +216,7 @@ class ImagesPipelineTestCase(unittest.TestCase):\n     def test_convert_image_new(self):\n         # tests for new API\n         SIZE = (100, 100)\n-        # straigh forward case: RGB and JPEG\n+        # straight forward case: RGB and JPEG\n         COLOUR = (0, 127, 255)\n         im, buf = _create_image('JPEG', 'RGB', SIZE, COLOUR)\n         converted, converted_buf = self.pipeline.convert_image(im, response_body=buf)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#860fbef608445230c16d0ddd4c2b676866449862", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2579 | Contributors (this commit): 28 | Commits (past 90d): 4 | Contributors (cumulative): 28 | DMM Complexity: None\n\nDIFF:\n@@ -355,7 +355,7 @@ class RequestTest(unittest.TestCase):\n             )\n             self.assertEqual(r.method, \"DELETE\")\n \n-        # If `ignore_unknon_options` is set to `False` it raises an error with\n+        # If `ignore_unknown_options` is set to `False` it raises an error with\n         # the unknown options: --foo and -z\n         self.assertRaises(\n             ValueError,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#2cb1e6668a51294df909b0ac5f7e35b7e858446e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1229 | Contributors (this commit): 36 | Commits (past 90d): 3 | Contributors (cumulative): 36 | DMM Complexity: None\n\nDIFF:\n@@ -191,7 +191,7 @@ def _select_value(ele: SelectElement, n: str, v: str):\n         o = ele.value_options\n         return (n, o[0]) if o else (None, None)\n     if v is not None and multiple:\n-        # This is a workround to bug in lxml fixed 2.3.1\n+        # This is a workaround to bug in lxml fixed 2.3.1\n         # fix https://github.com/lxml/lxml/commit/57f49eed82068a20da3db8f1b18ae00c1bab8b12#L1L1139\n         selected_options = ele.xpath('.//option[@selected]')\n         values = [(o.get('value') or o.text or '').strip() for o in selected_options]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#8a526d161c0a7d4818f16f6a9e1ae563e16abab6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 66 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -20,7 +20,7 @@ class UserAgentMiddlewareTest(TestCase):\n         self.assertEqual(req.headers['User-Agent'], b'default_useragent')\n \n     def test_remove_agent(self):\n-        # settings UESR_AGENT to None should remove the user agent\n+        # settings USER_AGENT to None should remove the user agent\n         spider, mw = self.get_spider_and_mw('default_useragent')\n         spider.user_agent = None\n         mw.spider_opened(spider)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#0a84ce448cdbbd077ec9e39a892b0c14fdb77217", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 6826 | Contributors (this commit): 36 | Commits (past 90d): 9 | Contributors (cumulative): 36 | DMM Complexity: None\n\nDIFF:\n@@ -690,7 +690,7 @@ class InstrumentedFeedSlot(_FeedSlot):\n \n     def finish_exporting(self):\n         self.update_listener('finish')\n-        super().start_exporting()\n+        super().finish_exporting()\n \n     @classmethod\n     def subscribe__listener(cls, listener):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#2e54237649bc8301a1c44ab60c6d7908eb9f71cc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 755 | Contributors (this commit): 35 | Commits (past 90d): 7 | Contributors (cumulative): 35 | DMM Complexity: None\n\nDIFF:\n@@ -60,6 +60,7 @@ setup(\n     description='A high-level Web Crawling and Web Scraping framework',\n     long_description=open('README.rst', encoding=\"utf-8\").read(),\n     author='Scrapy developers',\n+    author_email='Pablo Hoffman',\n     maintainer='Pablo Hoffman',\n     maintainer_email='pablo@pablohoffman.com',\n     license='BSD',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#3b5ce4c182d6b243645b9ce27d5f5084dbc4cc88", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 757 | Contributors (this commit): 35 | Commits (past 90d): 8 | Contributors (cumulative): 35 | DMM Complexity: None\n\nDIFF:\n@@ -60,7 +60,7 @@ setup(\n     description='A high-level Web Crawling and Web Scraping framework',\n     long_description=open('README.rst', encoding=\"utf-8\").read(),\n     author='Scrapy developers',\n-    author_email='Pablo Hoffman',\n+    author_email='pablo@pablohoffman.com',\n     maintainer='Pablo Hoffman',\n     maintainer_email='pablo@pablohoffman.com',\n     license='BSD',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#7ae32ea38d9b78402528ac3dffc8e1c5f1cf86b7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 684 | Contributors (this commit): 25 | Commits (past 90d): 4 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -171,7 +171,7 @@ class ImagesPipeline(FilesPipeline):\n                           'method called without response_body argument.',\n                           category=ScrapyDeprecationWarning, stacklevel=2)\n \n-        if image.format == 'PNG' and image.mode == 'RGBA':\n+        if image.format in ('PNG', 'WEBP') and image.mode == 'RGBA':\n             background = self._Image.new('RGBA', image.size, (255, 255, 255))\n             background.paste(image, image)\n             image = background.convert('RGB')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#303f0a70fcf8067adf0a909c2096a5009162383a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 196 | Lines Deleted: 81 | Files Changed: 5 | Hunks: 62 | Methods Changed: 40 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 277 | Churn Cumulative: 5123 | Contributors (this commit): 70 | Commits (past 90d): 28 | Contributors (cumulative): 119 | DMM Complexity: 0.9056603773584906\n\nDIFF:\n@@ -61,13 +61,17 @@ class ImagesPipeline(FilesPipeline):\n                 \"ImagesPipeline requires installing Pillow 4.0.0 or later\"\n             )\n \n-        super().__init__(store_uri, settings=settings, download_func=download_func)\n+        super().__init__(\n+            store_uri, settings=settings, download_func=download_func\n+        )\n \n         if isinstance(settings, dict) or settings is None:\n             settings = Settings(settings)\n \n         resolve = functools.partial(\n-            self._key_for_pipe, base_class_name=\"ImagesPipeline\", settings=settings\n+            self._key_for_pipe,\n+            base_class_name=\"ImagesPipeline\",\n+            settings=settings,\n         )\n         self.expires = settings.getint(resolve(\"IMAGES_EXPIRES\"), self.EXPIRES)\n \n@@ -82,8 +86,12 @@ class ImagesPipeline(FilesPipeline):\n         self.images_result_field = settings.get(\n             resolve(\"IMAGES_RESULT_FIELD\"), self.IMAGES_RESULT_FIELD\n         )\n-        self.min_width = settings.getint(resolve(\"IMAGES_MIN_WIDTH\"), self.MIN_WIDTH)\n-        self.min_height = settings.getint(resolve(\"IMAGES_MIN_HEIGHT\"), self.MIN_HEIGHT)\n+        self.min_width = settings.getint(\n+            resolve(\"IMAGES_MIN_WIDTH\"), self.MIN_WIDTH\n+        )\n+        self.min_height = settings.getint(\n+            resolve(\"IMAGES_MIN_HEIGHT\"), self.MIN_HEIGHT\n+        )\n         self.thumbs = settings.get(resolve(\"IMAGES_THUMBS\"), self.THUMBS)\n \n         self._deprecated_convert_image = None\n@@ -117,7 +125,9 @@ class ImagesPipeline(FilesPipeline):\n \n     def image_downloaded(self, response, request, info, *, item=None):\n         checksum = None\n-        for path, image, buf in self.get_images(response, request, info, item=item):\n+        for path, image, buf in self.get_images(\n+            response, request, info, item=item\n+        ):\n             if checksum is None:\n                 buf.seek(0)\n                 checksum = md5sum(buf)\n@@ -144,8 +154,8 @@ class ImagesPipeline(FilesPipeline):\n             )\n \n         if self._deprecated_convert_image is None:\n-            self._deprecated_convert_image = \"response_body\" not in get_func_args(\n-                self.convert_image\n+            self._deprecated_convert_image = (\n+                \"response_body\" not in get_func_args(self.convert_image)\n             )\n             if self._deprecated_convert_image:\n                 warnings.warn(\n@@ -181,8 +191,8 @@ class ImagesPipeline(FilesPipeline):\n                 stacklevel=2,\n             )\n \n-        if image.format in ('PNG', 'WEBP') and image.mode == 'RGBA':\n-            background = self._Image.new('RGBA', image.size, (255, 255, 255))\n+        if image.format in (\"PNG\", \"WEBP\") and image.mode == \"RGBA\":\n+            background = self._Image.new(\"RGBA\", image.size, (255, 255, 255))\n             background.paste(image, image)\n             image = background.convert(\"RGB\")\n         elif image.mode == \"P\":\n@@ -216,13 +226,17 @@ class ImagesPipeline(FilesPipeline):\n \n     def item_completed(self, results, item, info):\n         with suppress(KeyError):\n-            ItemAdapter(item)[self.images_result_field] = [x for ok, x in results if ok]\n+            ItemAdapter(item)[self.images_result_field] = [\n+                x for ok, x in results if ok\n+            ]\n         return item\n \n     def file_path(self, request, response=None, info=None, *, item=None):\n         image_guid = hashlib.sha1(to_bytes(request.url)).hexdigest()\n         return f\"full/{image_guid}.jpg\"\n \n-    def thumb_path(self, request, thumb_id, response=None, info=None, *, item=None):\n+    def thumb_path(\n+        self, request, thumb_id, response=None, info=None, *, item=None\n+    ):\n         thumb_guid = hashlib.sha1(to_bytes(request.url)).hexdigest()\n         return f\"thumbs/{thumb_id}/{thumb_guid}.jpg\"\n\n@@ -21,7 +21,10 @@ from scrapy.utils.console import DEFAULT_PYTHON_SHELLS, start_python_console\n from scrapy.utils.datatypes import SequenceExclude\n from scrapy.utils.misc import load_object\n from scrapy.utils.response import open_in_browser\n-from scrapy.utils.reactor import is_asyncio_reactor_installed, set_asyncio_event_loop\n+from scrapy.utils.reactor import (\n+    is_asyncio_reactor_installed,\n+    set_asyncio_event_loop,\n+)\n \n \n class Shell:\n@@ -37,7 +40,9 @@ class Shell:\n         self.code = code\n         self.vars = {}\n \n-    def start(self, url=None, request=None, response=None, spider=None, redirect=True):\n+    def start(\n+        self, url=None, request=None, response=None, spider=None, redirect=True\n+    ):\n         # disable accidental Ctrl-C key press from shutting down the engine\n         signal.signal(signal.SIGINT, signal.SIG_IGN)\n         if url:\n@@ -80,7 +85,7 @@ class Shell:\n     def _schedule(self, request, spider):\n         if is_asyncio_reactor_installed():\n             # set the asyncio event loop for the current thread\n-            event_loop_path = self.crawler.settings['ASYNCIO_EVENT_LOOP']\n+            event_loop_path = self.crawler.settings[\"ASYNCIO_EVENT_LOOP\"]\n             set_asyncio_event_loop(event_loop_path)\n         spider = self._open_spider(request, spider)\n         d = _request_deferred(request)\n\n@@ -59,14 +59,14 @@ setup(\n         \"Source\": \"https://github.com/scrapy/scrapy\",\n         \"Tracker\": \"https://github.com/scrapy/scrapy/issues\",\n     },\n-    description='A high-level Web Crawling and Web Scraping framework',\n-    long_description=open('README.rst', encoding=\"utf-8\").read(),\n-    author='Scrapy developers',\n-    author_email='pablo@pablohoffman.com',\n-    maintainer='Pablo Hoffman',\n-    maintainer_email='pablo@pablohoffman.com',\n-    license='BSD',\n-    packages=find_packages(exclude=('tests', 'tests.*')),\n+    description=\"A high-level Web Crawling and Web Scraping framework\",\n+    long_description=open(\"README.rst\", encoding=\"utf-8\").read(),\n+    author=\"Scrapy developers\",\n+    author_email=\"pablo@pablohoffman.com\",\n+    maintainer=\"Pablo Hoffman\",\n+    maintainer_email=\"pablo@pablohoffman.com\",\n+    license=\"BSD\",\n+    packages=find_packages(exclude=(\"tests\", \"tests.*\")),\n     include_package_data=True,\n     zip_safe=False,\n     entry_points={\"console_scripts\": [\"scrapy = scrapy.cmdline:execute\"]},\n\n@@ -20,17 +20,23 @@ class ShellTest(ProcessTest, SiteTest, unittest.TestCase):\n \n     @defer.inlineCallbacks\n     def test_response_body(self):\n-        _, out, _ = yield self.execute([self.url(\"/text\"), \"-c\", \"response.body\"])\n+        _, out, _ = yield self.execute(\n+            [self.url(\"/text\"), \"-c\", \"response.body\"]\n+        )\n         assert b\"Works\" in out\n \n     @defer.inlineCallbacks\n     def test_response_type_text(self):\n-        _, out, _ = yield self.execute([self.url(\"/text\"), \"-c\", \"type(response)\"])\n+        _, out, _ = yield self.execute(\n+            [self.url(\"/text\"), \"-c\", \"type(response)\"]\n+        )\n         assert b\"TextResponse\" in out\n \n     @defer.inlineCallbacks\n     def test_response_type_html(self):\n-        _, out, _ = yield self.execute([self.url(\"/html\"), \"-c\", \"type(response)\"])\n+        _, out, _ = yield self.execute(\n+            [self.url(\"/html\"), \"-c\", \"type(response)\"]\n+        )\n         assert b\"HtmlResponse\" in out\n \n     @defer.inlineCallbacks\n@@ -48,7 +54,9 @@ class ShellTest(ProcessTest, SiteTest, unittest.TestCase):\n \n     @defer.inlineCallbacks\n     def test_redirect(self):\n-        _, out, _ = yield self.execute([self.url(\"/redirect\"), \"-c\", \"response.url\"])\n+        _, out, _ = yield self.execute(\n+            [self.url(\"/redirect\"), \"-c\", \"response.url\"]\n+        )\n         assert out.strip().endswith(b\"/redirected\")\n \n     @defer.inlineCallbacks\n@@ -92,7 +100,9 @@ class ShellTest(ProcessTest, SiteTest, unittest.TestCase):\n     @defer.inlineCallbacks\n     def test_request_replace(self):\n         url = self.url(\"/text\")\n-        code = f\"fetch('{url}') or fetch(response.request.replace(method='POST'))\"\n+        code = (\n+            f\"fetch('{url}') or fetch(response.request.replace(method='POST'))\"\n+        )\n         errcode, out, _ = yield self.execute([\"-c\", code])\n         self.assertEqual(errcode, 0, out)\n \n@@ -123,14 +133,16 @@ class ShellTest(ProcessTest, SiteTest, unittest.TestCase):\n         if NON_EXISTING_RESOLVABLE:\n             raise unittest.SkipTest(\"Non-existing hosts are resolvable\")\n         url = \"www.somedomainthatdoesntexi.st\"\n-        errcode, out, err = yield self.execute([url, \"-c\", \"item\"], check_code=False)\n+        errcode, out, err = yield self.execute(\n+            [url, \"-c\", \"item\"], check_code=False\n+        )\n         self.assertEqual(errcode, 1, out or err)\n-        self.assertIn(b'DNS lookup failed', err)\n+        self.assertIn(b\"DNS lookup failed\", err)\n \n     @defer.inlineCallbacks\n     def test_shell_fetch_async(self):\n         reactor_path = \"twisted.internet.asyncioreactor.AsyncioSelectorReactor\"\n-        url = self.url('/html')\n+        url = self.url(\"/html\")\n         code = f\"fetch('{url}')\"\n         args = [\"-c\", code, \"--set\", f\"TWISTED_REACTOR={reactor_path}\"]\n         _, _, err = yield self.execute(args, check_code=True)\n\n@@ -8,8 +8,14 @@ from w3lib import __version__ as w3lib_version\n from w3lib.encoding import resolve_encoding\n \n from scrapy.exceptions import NotSupported\n-from scrapy.http import (Headers, HtmlResponse, Request, Response,\n-                         TextResponse, XmlResponse)\n+from scrapy.http import (\n+    Headers,\n+    HtmlResponse,\n+    Request,\n+    Response,\n+    TextResponse,\n+    XmlResponse,\n+)\n from scrapy.link import Link\n from scrapy.selector import Selector\n from scrapy.utils.python import to_unicode\n@@ -24,9 +30,13 @@ class BaseResponseTest(unittest.TestCase):\n         # Response requires url in the constructor\n         self.assertRaises(Exception, self.response_class)\n         self.assertTrue(\n-            isinstance(self.response_class(\"http://example.com/\"), self.response_class)\n+            isinstance(\n+                self.response_class(\"http://example.com/\"), self.response_class\n+            )\n+        )\n+        self.assertRaises(\n+            TypeError, self.response_class, b\"http://example.com\"\n         )\n-        self.assertRaises(TypeError, self.response_class, b\"http://example.com\")\n         # body can be str or None\n         self.assertTrue(\n             isinstance(\n@@ -60,7 +70,9 @@ class BaseResponseTest(unittest.TestCase):\n \n         headers = {\"foo\": \"bar\"}\n         body = b\"a body\"\n-        r = self.response_class(\"http://www.example.com\", headers=headers, body=body)\n+        r = self.response_class(\n+            \"http://www.example.com\", headers=headers, body=body\n+        )\n \n         assert r.headers is not headers\n         self.assertEqual(r.headers[b\"foo\"], b\"bar\")\n@@ -70,7 +82,10 @@ class BaseResponseTest(unittest.TestCase):\n         r = self.response_class(\"http://www.example.com\", status=\"301\")\n         self.assertEqual(r.status, 301)\n         self.assertRaises(\n-            ValueError, self.response_class, \"http://example.com\", status=\"lala200\"\n+            ValueError,\n+            self.response_class,\n+            \"http://example.com\",\n+            status=\"lala200\",\n         )\n \n     def test_copy(self):\n@@ -84,7 +99,9 @@ class BaseResponseTest(unittest.TestCase):\n         self.assertEqual(r1.body, r2.body)\n \n         # make sure flags list is shallow copied\n-        assert r1.flags is not r2.flags, \"flags must be a shallow copy, not identical\"\n+        assert (\n+            r1.flags is not r2.flags\n+        ), \"flags must be a shallow copy, not identical\"\n         self.assertEqual(r1.flags, r2.flags)\n \n         # make sure headers attribute is shallow copied\n@@ -111,7 +128,9 @@ class BaseResponseTest(unittest.TestCase):\n \n     def test_unavailable_meta(self):\n         r1 = self.response_class(\"http://www.example.com\", body=b\"Some body\")\n-        with self.assertRaisesRegex(AttributeError, r\"Response\\.meta not available\"):\n+        with self.assertRaisesRegex(\n+            AttributeError, r\"Response\\.meta not available\"\n+        ):\n             r1.meta\n \n     def test_unavailable_cb_kwargs(self):\n@@ -168,7 +187,9 @@ class BaseResponseTest(unittest.TestCase):\n \n     def test_immutable_attributes(self):\n         r = self.response_class(\"http://example.com\")\n-        self.assertRaises(AttributeError, setattr, r, \"url\", \"http://example2.com\")\n+        self.assertRaises(\n+            AttributeError, setattr, r, \"url\", \"http://example2.com\"\n+        )\n         self.assertRaises(AttributeError, setattr, r, \"body\", \"xxx\")\n \n     def test_urljoin(self):\n@@ -192,7 +213,9 @@ class BaseResponseTest(unittest.TestCase):\n     # Response.follow\n \n     def test_follow_url_absolute(self):\n-        self._assert_followed_url(\"http://foo.example.com\", \"http://foo.example.com\")\n+        self._assert_followed_url(\n+            \"http://foo.example.com\", \"http://foo.example.com\"\n+        )\n \n     def test_follow_url_relative(self):\n         self._assert_followed_url(\"foo\", \"http://example.com/foo\")\n@@ -212,8 +235,7 @@ class BaseResponseTest(unittest.TestCase):\n         strict=True,\n     )\n     def test_follow_whitespace_url(self):\n-        self._assert_followed_url('foo ',\n-                                  'http://example.com/foo')\n+        self._assert_followed_url(\"foo \", \"http://example.com/foo\")\n \n     @mark.xfail(\n         parse_version(w3lib_version) < parse_version(\"2.1.1\"),\n@@ -221,8 +243,9 @@ class BaseResponseTest(unittest.TestCase):\n         strict=True,\n     )\n     def test_follow_whitespace_link(self):\n-        self._assert_followed_url(Link('http://example.com/foo '),\n-                                  'http://example.com/foo')\n+        self._assert_followed_url(\n+            Link(\"http://example.com/foo \"), \"http://example.com/foo\"\n+        )\n \n     def test_follow_flags(self):\n         res = self.response_class(\"http://example.com/\")\n@@ -320,7 +343,9 @@ class BaseResponseTest(unittest.TestCase):\n         self.assertEqual(req.url, target_url)\n         return req\n \n-    def _assert_followed_all_urls(self, follow_obj, target_urls, response=None):\n+    def _assert_followed_all_urls(\n+        self, follow_obj, target_urls, response=None\n+    ):\n         if response is None:\n             response = self._links_response()\n         followed = response.follow_all(follow_obj)\n@@ -360,16 +385,22 @@ class TextResponseTest(BaseResponseTest):\n     def test_unicode_url(self):\n         # instantiate with unicode url without encoding (should set default encoding)\n         resp = self.response_class(\"http://www.example.com/\")\n-        self._assert_response_encoding(resp, self.response_class._DEFAULT_ENCODING)\n+        self._assert_response_encoding(\n+            resp, self.response_class._DEFAULT_ENCODING\n+        )\n \n         # make sure urls are converted to str\n-        resp = self.response_class(url=\"http://www.example.com/\", encoding=\"utf-8\")\n+        resp = self.response_class(\n+            url=\"http://www.example.com/\", encoding=\"utf-8\"\n+        )\n         assert isinstance(resp.url, str)\n \n         resp = self.response_class(\n             url=\"http://www.example.com/price/\\xa3\", encoding=\"utf-8\"\n         )\n-        self.assertEqual(resp.url, to_unicode(b\"http://www.example.com/price/\\xc2\\xa3\"))\n+        self.assertEqual(\n+            resp.url, to_unicode(b\"http://www.example.com/price/\\xc2\\xa3\")\n+        )\n         resp = self.response_class(\n             url=\"http://www.example.com/price/\\xa3\", encoding=\"latin-1\"\n         )\n@@ -378,7 +409,9 @@ class TextResponseTest(BaseResponseTest):\n             \"http://www.example.com/price/\\xa3\",\n             headers={\"Content-type\": [\"text/html; charset=utf-8\"]},\n         )\n-        self.assertEqual(resp.url, to_unicode(b\"http://www.example.com/price/\\xc2\\xa3\"))\n+        self.assertEqual(\n+            resp.url, to_unicode(b\"http://www.example.com/price/\\xc2\\xa3\")\n+        )\n         resp = self.response_class(\n             \"http://www.example.com/price/\\xa3\",\n             headers={\"Content-type\": [\"text/html; charset=iso-8859-1\"]},\n@@ -466,7 +499,10 @@ class TextResponseTest(BaseResponseTest):\n \n         # TextResponse (and subclasses) must be passed a encoding when instantiating with unicode bodies\n         self.assertRaises(\n-            TypeError, self.response_class, \"http://www.example.com\", body=\"\\xa3\"\n+            TypeError,\n+            self.response_class,\n+            \"http://www.example.com\",\n+            body=\"\\xa3\",\n         )\n \n     def test_declared_encoding_invalid(self):\n@@ -482,7 +518,9 @@ class TextResponseTest(BaseResponseTest):\n     def test_utf16(self):\n         \"\"\"Test utf-16 because UnicodeDammit is known to have problems with\"\"\"\n         r = self.response_class(\n-            \"http://www.example.com\", body=b\"\\xff\\xfeh\\x00i\\x00\", encoding=\"utf-16\"\n+            \"http://www.example.com\",\n+            body=b\"\\xff\\xfeh\\x00i\\x00\",\n+            encoding=\"utf-16\",\n         )\n         self._assert_response_values(r, \"utf-16\", \"hi\")\n \n@@ -531,7 +569,9 @@ class TextResponseTest(BaseResponseTest):\n     def test_replace_wrong_encoding(self):\n         \"\"\"Test invalid chars are replaced properly\"\"\"\n         r = self.response_class(\n-            \"http://www.example.com\", encoding=\"utf-8\", body=b\"PREFIX\\xe3\\xabSUFFIX\"\n+            \"http://www.example.com\",\n+            encoding=\"utf-8\",\n+            body=b\"PREFIX\\xe3\\xabSUFFIX\",\n         )\n         # XXX: Policy for replacing invalid chars may suffer minor variations\n         # but it should always contain the unicode replacement char ('\\ufffd')\n@@ -541,7 +581,9 @@ class TextResponseTest(BaseResponseTest):\n \n         # Do not destroy html tags due to encoding bugs\n         r = self.response_class(\n-            \"http://example.com\", encoding=\"utf-8\", body=b\"\\xf0<span>value</span>\"\n+            \"http://example.com\",\n+            encoding=\"utf-8\",\n+            body=b\"\\xf0<span>value</span>\",\n         )\n         assert \"<span>value</span>\" in r.text, repr(r.text)\n \n@@ -555,13 +597,17 @@ class TextResponseTest(BaseResponseTest):\n \n         self.assertIsInstance(response.selector, Selector)\n         self.assertEqual(response.selector.type, \"html\")\n-        self.assertIs(response.selector, response.selector)  # property is cached\n+        self.assertIs(\n+            response.selector, response.selector\n+        )  # property is cached\n         self.assertIs(response.selector.response, response)\n \n         self.assertEqual(\n             response.selector.xpath(\"//title/text()\").getall(), [\"Some page\"]\n         )\n-        self.assertEqual(response.selector.css(\"title::text\").getall(), [\"Some page\"])\n+        self.assertEqual(\n+            response.selector.css(\"title::text\").getall(), [\"Some page\"]\n+        )\n         self.assertEqual(response.selector.re(\"Some (.*)</title>\"), [\"page\"])\n \n     def test_selector_shortcuts(self):\n@@ -601,23 +647,23 @@ class TextResponseTest(BaseResponseTest):\n     def test_urljoin_with_base_url(self):\n         \"\"\"Test urljoin shortcut which also evaluates base-url through get_base_url().\"\"\"\n         body = b'<html><body><base href=\"https://example.net\"></body></html>'\n-        joined = self.response_class(\"http://www.example.com\", body=body).urljoin(\n-            \"/test\"\n-        )\n+        joined = self.response_class(\n+            \"http://www.example.com\", body=body\n+        ).urljoin(\"/test\")\n         absolute = \"https://example.net/test\"\n         self.assertEqual(joined, absolute)\n \n         body = b'<html><body><base href=\"/elsewhere\"></body></html>'\n-        joined = self.response_class(\"http://www.example.com\", body=body).urljoin(\n-            \"test\"\n-        )\n+        joined = self.response_class(\n+            \"http://www.example.com\", body=body\n+        ).urljoin(\"test\")\n         absolute = \"http://www.example.com/test\"\n         self.assertEqual(joined, absolute)\n \n         body = b'<html><body><base href=\"/elsewhere/\"></body></html>'\n-        joined = self.response_class(\"http://www.example.com\", body=body).urljoin(\n-            \"test\"\n-        )\n+        joined = self.response_class(\n+            \"http://www.example.com\", body=body\n+        ).urljoin(\"test\")\n         absolute = \"http://www.example.com/elsewhere/test\"\n         self.assertEqual(joined, absolute)\n \n@@ -654,12 +700,17 @@ class TextResponseTest(BaseResponseTest):\n \n     def test_follow_selector_list(self):\n         resp = self._links_response()\n-        self.assertRaisesRegex(ValueError, \"SelectorList\", resp.follow, resp.css(\"a\"))\n+        self.assertRaisesRegex(\n+            ValueError, \"SelectorList\", resp.follow, resp.css(\"a\")\n+        )\n \n     def test_follow_selector_invalid(self):\n         resp = self._links_response()\n         self.assertRaisesRegex(\n-            ValueError, \"Unsupported\", resp.follow, resp.xpath(\"count(//div)\")[0]\n+            ValueError,\n+            \"Unsupported\",\n+            resp.follow,\n+            resp.xpath(\"count(//div)\")[0],\n         )\n \n     def test_follow_selector_attribute(self):\n@@ -672,7 +723,9 @@ class TextResponseTest(BaseResponseTest):\n             url=\"http://example.com\",\n             body=b\"<html><body><a name=123>click me</a></body></html>\",\n         )\n-        self.assertRaisesRegex(ValueError, \"no href\", resp.follow, resp.css(\"a\")[0])\n+        self.assertRaisesRegex(\n+            ValueError, \"no href\", resp.follow, resp.css(\"a\")[0]\n+        )\n \n     def test_follow_whitespace_selector(self):\n         resp = self.response_class(\n@@ -683,7 +736,9 @@ class TextResponseTest(BaseResponseTest):\n             resp.css(\"a\")[0], \"http://example.com/foo\", response=resp\n         )\n         self._assert_followed_url(\n-            resp.css(\"a::attr(href)\")[0], \"http://example.com/foo\", response=resp\n+            resp.css(\"a::attr(href)\")[0],\n+            \"http://example.com/foo\",\n+            response=resp,\n         )\n \n     def test_follow_encoding(self):\n@@ -737,7 +792,9 @@ class TextResponseTest(BaseResponseTest):\n             \"http://example.com/innertag.html\",\n         ]\n         response = self._links_response()\n-        extracted = [r.url for r in response.follow_all(css='a[href*=\"example.com\"]')]\n+        extracted = [\n+            r.url for r in response.follow_all(css='a[href*=\"example.com\"]')\n+        ]\n         self.assertEqual(expected, extracted)\n \n     def test_follow_all_css_skip_invalid(self):\n@@ -749,7 +806,9 @@ class TextResponseTest(BaseResponseTest):\n         response = self._links_response_no_href()\n         extracted1 = [r.url for r in response.follow_all(css=\".pagination a\")]\n         self.assertEqual(expected, extracted1)\n-        extracted2 = [r.url for r in response.follow_all(response.css(\".pagination a\"))]\n+        extracted2 = [\n+            r.url for r in response.follow_all(response.css(\".pagination a\"))\n+        ]\n         self.assertEqual(expected, extracted2)\n \n     def test_follow_all_xpath(self):\n@@ -758,7 +817,9 @@ class TextResponseTest(BaseResponseTest):\n             \"http://example.com/innertag.html\",\n         ]\n         response = self._links_response()\n-        extracted = response.follow_all(xpath='//a[contains(@href, \"example.com\")]')\n+        extracted = response.follow_all(\n+            xpath='//a[contains(@href, \"example.com\")]'\n+        )\n         self.assertEqual(expected, [r.url for r in extracted])\n \n     def test_follow_all_xpath_skip_invalid(self):\n@@ -769,12 +830,15 @@ class TextResponseTest(BaseResponseTest):\n         ]\n         response = self._links_response_no_href()\n         extracted1 = [\n-            r.url for r in response.follow_all(xpath='//div[@id=\"pagination\"]/a')\n+            r.url\n+            for r in response.follow_all(xpath='//div[@id=\"pagination\"]/a')\n         ]\n         self.assertEqual(expected, extracted1)\n         extracted2 = [\n             r.url\n-            for r in response.follow_all(response.xpath('//div[@id=\"pagination\"]/a'))\n+            for r in response.follow_all(\n+                response.xpath('//div[@id=\"pagination\"]/a')\n+            )\n         ]\n         self.assertEqual(expected, extracted2)\n \n@@ -788,11 +852,15 @@ class TextResponseTest(BaseResponseTest):\n \n     def test_json_response(self):\n         json_body = b\"\"\"{\"ip\": \"109.187.217.200\"}\"\"\"\n-        json_response = self.response_class(\"http://www.example.com\", body=json_body)\n+        json_response = self.response_class(\n+            \"http://www.example.com\", body=json_body\n+        )\n         self.assertEqual(json_response.json(), {\"ip\": \"109.187.217.200\"})\n \n         text_body = b\"\"\"<html><body>text</body></html>\"\"\"\n-        text_response = self.response_class(\"http://www.example.com\", body=text_body)\n+        text_response = self.response_class(\n+            \"http://www.example.com\", body=text_body\n+        )\n         with self.assertRaises(ValueError):\n             text_response.json()\n \n@@ -859,7 +927,9 @@ class XmlResponseTest(TextResponseTest):\n     def test_xml_encoding(self):\n         body = b\"<xml></xml>\"\n         r1 = self.response_class(\"http://www.example.com\", body=body)\n-        self._assert_response_values(r1, self.response_class._DEFAULT_ENCODING, body)\n+        self._assert_response_values(\n+            r1, self.response_class._DEFAULT_ENCODING, body\n+        )\n \n         body = b\"\"\"<?xml version=\"1.0\" encoding=\"iso-8859-1\"?><xml></xml>\"\"\"\n         r2 = self.response_class(\"http://www.example.com\", body=body)\n@@ -867,7 +937,9 @@ class XmlResponseTest(TextResponseTest):\n \n         # make sure replace() preserves the explicit encoding passed in the __init__ method\n         body = b\"\"\"<?xml version=\"1.0\" encoding=\"iso-8859-1\"?><xml></xml>\"\"\"\n-        r3 = self.response_class(\"http://www.example.com\", body=body, encoding=\"utf-8\")\n+        r3 = self.response_class(\n+            \"http://www.example.com\", body=body, encoding=\"utf-8\"\n+        )\n         body2 = b\"New body\"\n         r4 = r3.replace(body=body2)\n         self._assert_response_values(r4, \"utf-8\", body2)\n@@ -889,10 +961,14 @@ class XmlResponseTest(TextResponseTest):\n \n         self.assertIsInstance(response.selector, Selector)\n         self.assertEqual(response.selector.type, \"xml\")\n-        self.assertIs(response.selector, response.selector)  # property is cached\n+        self.assertIs(\n+            response.selector, response.selector\n+        )  # property is cached\n         self.assertIs(response.selector.response, response)\n \n-        self.assertEqual(response.selector.xpath(\"//elem/text()\").getall(), [\"value\"])\n+        self.assertEqual(\n+            response.selector.xpath(\"//elem/text()\").getall(), [\"value\"]\n+        )\n \n     def test_selector_shortcuts(self):\n         body = b'<?xml version=\"1.0\" encoding=\"utf-8\"?><xml><elem>value</elem></xml>'\n@@ -944,7 +1020,11 @@ class CustomResponseTest(TextResponseTest):\n     def test_copy(self):\n         super().test_copy()\n         r1 = self.response_class(\n-            url=\"https://example.org\", status=200, foo=\"foo\", bar=\"bar\", lost=\"lost\"\n+            url=\"https://example.org\",\n+            status=200,\n+            foo=\"foo\",\n+            bar=\"bar\",\n+            lost=\"lost\",\n         )\n         r2 = r1.copy()\n         self.assertIsInstance(r2, self.response_class)\n@@ -956,7 +1036,11 @@ class CustomResponseTest(TextResponseTest):\n     def test_replace(self):\n         super().test_replace()\n         r1 = self.response_class(\n-            url=\"https://example.org\", status=200, foo=\"foo\", bar=\"bar\", lost=\"lost\"\n+            url=\"https://example.org\",\n+            status=200,\n+            foo=\"foo\",\n+            bar=\"bar\",\n+            lost=\"lost\",\n         )\n \n         r2 = r1.replace(foo=\"new-foo\", bar=\"new-bar\", lost=\"new-lost\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c5cdd0d30ceb68ccba04af0e71d1b8e6678e2962", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 52 | Lines Deleted: 133 | Files Changed: 4 | Hunks: 44 | Methods Changed: 30 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 185 | Churn Cumulative: 4535 | Contributors (this commit): 53 | Commits (past 90d): 24 | Contributors (cumulative): 84 | DMM Complexity: 0.09876543209876543\n\nDIFF:\n@@ -61,9 +61,7 @@ class ImagesPipeline(FilesPipeline):\n                 \"ImagesPipeline requires installing Pillow 4.0.0 or later\"\n             )\n \n-        super().__init__(\n-            store_uri, settings=settings, download_func=download_func\n-        )\n+        super().__init__(store_uri, settings=settings, download_func=download_func)\n \n         if isinstance(settings, dict) or settings is None:\n             settings = Settings(settings)\n@@ -86,12 +84,8 @@ class ImagesPipeline(FilesPipeline):\n         self.images_result_field = settings.get(\n             resolve(\"IMAGES_RESULT_FIELD\"), self.IMAGES_RESULT_FIELD\n         )\n-        self.min_width = settings.getint(\n-            resolve(\"IMAGES_MIN_WIDTH\"), self.MIN_WIDTH\n-        )\n-        self.min_height = settings.getint(\n-            resolve(\"IMAGES_MIN_HEIGHT\"), self.MIN_HEIGHT\n-        )\n+        self.min_width = settings.getint(resolve(\"IMAGES_MIN_WIDTH\"), self.MIN_WIDTH)\n+        self.min_height = settings.getint(resolve(\"IMAGES_MIN_HEIGHT\"), self.MIN_HEIGHT)\n         self.thumbs = settings.get(resolve(\"IMAGES_THUMBS\"), self.THUMBS)\n \n         self._deprecated_convert_image = None\n@@ -125,9 +119,7 @@ class ImagesPipeline(FilesPipeline):\n \n     def image_downloaded(self, response, request, info, *, item=None):\n         checksum = None\n-        for path, image, buf in self.get_images(\n-            response, request, info, item=item\n-        ):\n+        for path, image, buf in self.get_images(response, request, info, item=item):\n             if checksum is None:\n                 buf.seek(0)\n                 checksum = md5sum(buf)\n@@ -154,8 +146,8 @@ class ImagesPipeline(FilesPipeline):\n             )\n \n         if self._deprecated_convert_image is None:\n-            self._deprecated_convert_image = (\n-                \"response_body\" not in get_func_args(self.convert_image)\n+            self._deprecated_convert_image = \"response_body\" not in get_func_args(\n+                self.convert_image\n             )\n             if self._deprecated_convert_image:\n                 warnings.warn(\n@@ -226,17 +218,13 @@ class ImagesPipeline(FilesPipeline):\n \n     def item_completed(self, results, item, info):\n         with suppress(KeyError):\n-            ItemAdapter(item)[self.images_result_field] = [\n-                x for ok, x in results if ok\n-            ]\n+            ItemAdapter(item)[self.images_result_field] = [x for ok, x in results if ok]\n         return item\n \n     def file_path(self, request, response=None, info=None, *, item=None):\n         image_guid = hashlib.sha1(to_bytes(request.url)).hexdigest()\n         return f\"full/{image_guid}.jpg\"\n \n-    def thumb_path(\n-        self, request, thumb_id, response=None, info=None, *, item=None\n-    ):\n+    def thumb_path(self, request, thumb_id, response=None, info=None, *, item=None):\n         thumb_guid = hashlib.sha1(to_bytes(request.url)).hexdigest()\n         return f\"thumbs/{thumb_id}/{thumb_guid}.jpg\"\n\n@@ -40,9 +40,7 @@ class Shell:\n         self.code = code\n         self.vars = {}\n \n-    def start(\n-        self, url=None, request=None, response=None, spider=None, redirect=True\n-    ):\n+    def start(self, url=None, request=None, response=None, spider=None, redirect=True):\n         # disable accidental Ctrl-C key press from shutting down the engine\n         signal.signal(signal.SIGINT, signal.SIG_IGN)\n         if url:\n\n@@ -20,23 +20,17 @@ class ShellTest(ProcessTest, SiteTest, unittest.TestCase):\n \n     @defer.inlineCallbacks\n     def test_response_body(self):\n-        _, out, _ = yield self.execute(\n-            [self.url(\"/text\"), \"-c\", \"response.body\"]\n-        )\n+        _, out, _ = yield self.execute([self.url(\"/text\"), \"-c\", \"response.body\"])\n         assert b\"Works\" in out\n \n     @defer.inlineCallbacks\n     def test_response_type_text(self):\n-        _, out, _ = yield self.execute(\n-            [self.url(\"/text\"), \"-c\", \"type(response)\"]\n-        )\n+        _, out, _ = yield self.execute([self.url(\"/text\"), \"-c\", \"type(response)\"])\n         assert b\"TextResponse\" in out\n \n     @defer.inlineCallbacks\n     def test_response_type_html(self):\n-        _, out, _ = yield self.execute(\n-            [self.url(\"/html\"), \"-c\", \"type(response)\"]\n-        )\n+        _, out, _ = yield self.execute([self.url(\"/html\"), \"-c\", \"type(response)\"])\n         assert b\"HtmlResponse\" in out\n \n     @defer.inlineCallbacks\n@@ -54,9 +48,7 @@ class ShellTest(ProcessTest, SiteTest, unittest.TestCase):\n \n     @defer.inlineCallbacks\n     def test_redirect(self):\n-        _, out, _ = yield self.execute(\n-            [self.url(\"/redirect\"), \"-c\", \"response.url\"]\n-        )\n+        _, out, _ = yield self.execute([self.url(\"/redirect\"), \"-c\", \"response.url\"])\n         assert out.strip().endswith(b\"/redirected\")\n \n     @defer.inlineCallbacks\n@@ -100,9 +92,7 @@ class ShellTest(ProcessTest, SiteTest, unittest.TestCase):\n     @defer.inlineCallbacks\n     def test_request_replace(self):\n         url = self.url(\"/text\")\n-        code = (\n-            f\"fetch('{url}') or fetch(response.request.replace(method='POST'))\"\n-        )\n+        code = f\"fetch('{url}') or fetch(response.request.replace(method='POST'))\"\n         errcode, out, _ = yield self.execute([\"-c\", code])\n         self.assertEqual(errcode, 0, out)\n \n@@ -133,9 +123,7 @@ class ShellTest(ProcessTest, SiteTest, unittest.TestCase):\n         if NON_EXISTING_RESOLVABLE:\n             raise unittest.SkipTest(\"Non-existing hosts are resolvable\")\n         url = \"www.somedomainthatdoesntexi.st\"\n-        errcode, out, err = yield self.execute(\n-            [url, \"-c\", \"item\"], check_code=False\n-        )\n+        errcode, out, err = yield self.execute([url, \"-c\", \"item\"], check_code=False)\n         self.assertEqual(errcode, 1, out or err)\n         self.assertIn(b\"DNS lookup failed\", err)\n \n@@ -146,6 +134,4 @@ class ShellTest(ProcessTest, SiteTest, unittest.TestCase):\n         code = f\"fetch('{url}')\"\n         args = [\"-c\", code, \"--set\", f\"TWISTED_REACTOR={reactor_path}\"]\n         _, _, err = yield self.execute(args, check_code=True)\n-        self.assertNotIn(\n-            b\"RuntimeError: There is no current event loop in thread\", err\n-        )\n+        self.assertNotIn(b\"RuntimeError: There is no current event loop in thread\", err)\n\n@@ -30,13 +30,9 @@ class BaseResponseTest(unittest.TestCase):\n         # Response requires url in the constructor\n         self.assertRaises(Exception, self.response_class)\n         self.assertTrue(\n-            isinstance(\n-                self.response_class(\"http://example.com/\"), self.response_class\n-            )\n-        )\n-        self.assertRaises(\n-            TypeError, self.response_class, b\"http://example.com\"\n+            isinstance(self.response_class(\"http://example.com/\"), self.response_class)\n         )\n+        self.assertRaises(TypeError, self.response_class, b\"http://example.com\")\n         # body can be str or None\n         self.assertTrue(\n             isinstance(\n@@ -70,9 +66,7 @@ class BaseResponseTest(unittest.TestCase):\n \n         headers = {\"foo\": \"bar\"}\n         body = b\"a body\"\n-        r = self.response_class(\n-            \"http://www.example.com\", headers=headers, body=body\n-        )\n+        r = self.response_class(\"http://www.example.com\", headers=headers, body=body)\n \n         assert r.headers is not headers\n         self.assertEqual(r.headers[b\"foo\"], b\"bar\")\n@@ -99,9 +93,7 @@ class BaseResponseTest(unittest.TestCase):\n         self.assertEqual(r1.body, r2.body)\n \n         # make sure flags list is shallow copied\n-        assert (\n-            r1.flags is not r2.flags\n-        ), \"flags must be a shallow copy, not identical\"\n+        assert r1.flags is not r2.flags, \"flags must be a shallow copy, not identical\"\n         self.assertEqual(r1.flags, r2.flags)\n \n         # make sure headers attribute is shallow copied\n@@ -128,9 +120,7 @@ class BaseResponseTest(unittest.TestCase):\n \n     def test_unavailable_meta(self):\n         r1 = self.response_class(\"http://www.example.com\", body=b\"Some body\")\n-        with self.assertRaisesRegex(\n-            AttributeError, r\"Response\\.meta not available\"\n-        ):\n+        with self.assertRaisesRegex(AttributeError, r\"Response\\.meta not available\"):\n             r1.meta\n \n     def test_unavailable_cb_kwargs(self):\n@@ -187,9 +177,7 @@ class BaseResponseTest(unittest.TestCase):\n \n     def test_immutable_attributes(self):\n         r = self.response_class(\"http://example.com\")\n-        self.assertRaises(\n-            AttributeError, setattr, r, \"url\", \"http://example2.com\"\n-        )\n+        self.assertRaises(AttributeError, setattr, r, \"url\", \"http://example2.com\")\n         self.assertRaises(AttributeError, setattr, r, \"body\", \"xxx\")\n \n     def test_urljoin(self):\n@@ -213,9 +201,7 @@ class BaseResponseTest(unittest.TestCase):\n     # Response.follow\n \n     def test_follow_url_absolute(self):\n-        self._assert_followed_url(\n-            \"http://foo.example.com\", \"http://foo.example.com\"\n-        )\n+        self._assert_followed_url(\"http://foo.example.com\", \"http://foo.example.com\")\n \n     def test_follow_url_relative(self):\n         self._assert_followed_url(\"foo\", \"http://example.com/foo\")\n@@ -343,9 +329,7 @@ class BaseResponseTest(unittest.TestCase):\n         self.assertEqual(req.url, target_url)\n         return req\n \n-    def _assert_followed_all_urls(\n-        self, follow_obj, target_urls, response=None\n-    ):\n+    def _assert_followed_all_urls(self, follow_obj, target_urls, response=None):\n         if response is None:\n             response = self._links_response()\n         followed = response.follow_all(follow_obj)\n@@ -385,22 +369,16 @@ class TextResponseTest(BaseResponseTest):\n     def test_unicode_url(self):\n         # instantiate with unicode url without encoding (should set default encoding)\n         resp = self.response_class(\"http://www.example.com/\")\n-        self._assert_response_encoding(\n-            resp, self.response_class._DEFAULT_ENCODING\n-        )\n+        self._assert_response_encoding(resp, self.response_class._DEFAULT_ENCODING)\n \n         # make sure urls are converted to str\n-        resp = self.response_class(\n-            url=\"http://www.example.com/\", encoding=\"utf-8\"\n-        )\n+        resp = self.response_class(url=\"http://www.example.com/\", encoding=\"utf-8\")\n         assert isinstance(resp.url, str)\n \n         resp = self.response_class(\n             url=\"http://www.example.com/price/\\xa3\", encoding=\"utf-8\"\n         )\n-        self.assertEqual(\n-            resp.url, to_unicode(b\"http://www.example.com/price/\\xc2\\xa3\")\n-        )\n+        self.assertEqual(resp.url, to_unicode(b\"http://www.example.com/price/\\xc2\\xa3\"))\n         resp = self.response_class(\n             url=\"http://www.example.com/price/\\xa3\", encoding=\"latin-1\"\n         )\n@@ -409,9 +387,7 @@ class TextResponseTest(BaseResponseTest):\n             \"http://www.example.com/price/\\xa3\",\n             headers={\"Content-type\": [\"text/html; charset=utf-8\"]},\n         )\n-        self.assertEqual(\n-            resp.url, to_unicode(b\"http://www.example.com/price/\\xc2\\xa3\")\n-        )\n+        self.assertEqual(resp.url, to_unicode(b\"http://www.example.com/price/\\xc2\\xa3\"))\n         resp = self.response_class(\n             \"http://www.example.com/price/\\xa3\",\n             headers={\"Content-type\": [\"text/html; charset=iso-8859-1\"]},\n@@ -597,17 +573,13 @@ class TextResponseTest(BaseResponseTest):\n \n         self.assertIsInstance(response.selector, Selector)\n         self.assertEqual(response.selector.type, \"html\")\n-        self.assertIs(\n-            response.selector, response.selector\n-        )  # property is cached\n+        self.assertIs(response.selector, response.selector)  # property is cached\n         self.assertIs(response.selector.response, response)\n \n         self.assertEqual(\n             response.selector.xpath(\"//title/text()\").getall(), [\"Some page\"]\n         )\n-        self.assertEqual(\n-            response.selector.css(\"title::text\").getall(), [\"Some page\"]\n-        )\n+        self.assertEqual(response.selector.css(\"title::text\").getall(), [\"Some page\"])\n         self.assertEqual(response.selector.re(\"Some (.*)</title>\"), [\"page\"])\n \n     def test_selector_shortcuts(self):\n@@ -647,23 +619,23 @@ class TextResponseTest(BaseResponseTest):\n     def test_urljoin_with_base_url(self):\n         \"\"\"Test urljoin shortcut which also evaluates base-url through get_base_url().\"\"\"\n         body = b'<html><body><base href=\"https://example.net\"></body></html>'\n-        joined = self.response_class(\n-            \"http://www.example.com\", body=body\n-        ).urljoin(\"/test\")\n+        joined = self.response_class(\"http://www.example.com\", body=body).urljoin(\n+            \"/test\"\n+        )\n         absolute = \"https://example.net/test\"\n         self.assertEqual(joined, absolute)\n \n         body = b'<html><body><base href=\"/elsewhere\"></body></html>'\n-        joined = self.response_class(\n-            \"http://www.example.com\", body=body\n-        ).urljoin(\"test\")\n+        joined = self.response_class(\"http://www.example.com\", body=body).urljoin(\n+            \"test\"\n+        )\n         absolute = \"http://www.example.com/test\"\n         self.assertEqual(joined, absolute)\n \n         body = b'<html><body><base href=\"/elsewhere/\"></body></html>'\n-        joined = self.response_class(\n-            \"http://www.example.com\", body=body\n-        ).urljoin(\"test\")\n+        joined = self.response_class(\"http://www.example.com\", body=body).urljoin(\n+            \"test\"\n+        )\n         absolute = \"http://www.example.com/elsewhere/test\"\n         self.assertEqual(joined, absolute)\n \n@@ -700,9 +672,7 @@ class TextResponseTest(BaseResponseTest):\n \n     def test_follow_selector_list(self):\n         resp = self._links_response()\n-        self.assertRaisesRegex(\n-            ValueError, \"SelectorList\", resp.follow, resp.css(\"a\")\n-        )\n+        self.assertRaisesRegex(ValueError, \"SelectorList\", resp.follow, resp.css(\"a\"))\n \n     def test_follow_selector_invalid(self):\n         resp = self._links_response()\n@@ -723,9 +693,7 @@ class TextResponseTest(BaseResponseTest):\n             url=\"http://example.com\",\n             body=b\"<html><body><a name=123>click me</a></body></html>\",\n         )\n-        self.assertRaisesRegex(\n-            ValueError, \"no href\", resp.follow, resp.css(\"a\")[0]\n-        )\n+        self.assertRaisesRegex(ValueError, \"no href\", resp.follow, resp.css(\"a\")[0])\n \n     def test_follow_whitespace_selector(self):\n         resp = self.response_class(\n@@ -792,9 +760,7 @@ class TextResponseTest(BaseResponseTest):\n             \"http://example.com/innertag.html\",\n         ]\n         response = self._links_response()\n-        extracted = [\n-            r.url for r in response.follow_all(css='a[href*=\"example.com\"]')\n-        ]\n+        extracted = [r.url for r in response.follow_all(css='a[href*=\"example.com\"]')]\n         self.assertEqual(expected, extracted)\n \n     def test_follow_all_css_skip_invalid(self):\n@@ -806,9 +772,7 @@ class TextResponseTest(BaseResponseTest):\n         response = self._links_response_no_href()\n         extracted1 = [r.url for r in response.follow_all(css=\".pagination a\")]\n         self.assertEqual(expected, extracted1)\n-        extracted2 = [\n-            r.url for r in response.follow_all(response.css(\".pagination a\"))\n-        ]\n+        extracted2 = [r.url for r in response.follow_all(response.css(\".pagination a\"))]\n         self.assertEqual(expected, extracted2)\n \n     def test_follow_all_xpath(self):\n@@ -817,9 +781,7 @@ class TextResponseTest(BaseResponseTest):\n             \"http://example.com/innertag.html\",\n         ]\n         response = self._links_response()\n-        extracted = response.follow_all(\n-            xpath='//a[contains(@href, \"example.com\")]'\n-        )\n+        extracted = response.follow_all(xpath='//a[contains(@href, \"example.com\")]')\n         self.assertEqual(expected, [r.url for r in extracted])\n \n     def test_follow_all_xpath_skip_invalid(self):\n@@ -830,15 +792,12 @@ class TextResponseTest(BaseResponseTest):\n         ]\n         response = self._links_response_no_href()\n         extracted1 = [\n-            r.url\n-            for r in response.follow_all(xpath='//div[@id=\"pagination\"]/a')\n+            r.url for r in response.follow_all(xpath='//div[@id=\"pagination\"]/a')\n         ]\n         self.assertEqual(expected, extracted1)\n         extracted2 = [\n             r.url\n-            for r in response.follow_all(\n-                response.xpath('//div[@id=\"pagination\"]/a')\n-            )\n+            for r in response.follow_all(response.xpath('//div[@id=\"pagination\"]/a'))\n         ]\n         self.assertEqual(expected, extracted2)\n \n@@ -852,15 +811,11 @@ class TextResponseTest(BaseResponseTest):\n \n     def test_json_response(self):\n         json_body = b\"\"\"{\"ip\": \"109.187.217.200\"}\"\"\"\n-        json_response = self.response_class(\n-            \"http://www.example.com\", body=json_body\n-        )\n+        json_response = self.response_class(\"http://www.example.com\", body=json_body)\n         self.assertEqual(json_response.json(), {\"ip\": \"109.187.217.200\"})\n \n         text_body = b\"\"\"<html><body>text</body></html>\"\"\"\n-        text_response = self.response_class(\n-            \"http://www.example.com\", body=text_body\n-        )\n+        text_response = self.response_class(\"http://www.example.com\", body=text_body)\n         with self.assertRaises(ValueError):\n             text_response.json()\n \n@@ -927,9 +882,7 @@ class XmlResponseTest(TextResponseTest):\n     def test_xml_encoding(self):\n         body = b\"<xml></xml>\"\n         r1 = self.response_class(\"http://www.example.com\", body=body)\n-        self._assert_response_values(\n-            r1, self.response_class._DEFAULT_ENCODING, body\n-        )\n+        self._assert_response_values(r1, self.response_class._DEFAULT_ENCODING, body)\n \n         body = b\"\"\"<?xml version=\"1.0\" encoding=\"iso-8859-1\"?><xml></xml>\"\"\"\n         r2 = self.response_class(\"http://www.example.com\", body=body)\n@@ -937,9 +890,7 @@ class XmlResponseTest(TextResponseTest):\n \n         # make sure replace() preserves the explicit encoding passed in the __init__ method\n         body = b\"\"\"<?xml version=\"1.0\" encoding=\"iso-8859-1\"?><xml></xml>\"\"\"\n-        r3 = self.response_class(\n-            \"http://www.example.com\", body=body, encoding=\"utf-8\"\n-        )\n+        r3 = self.response_class(\"http://www.example.com\", body=body, encoding=\"utf-8\")\n         body2 = b\"New body\"\n         r4 = r3.replace(body=body2)\n         self._assert_response_values(r4, \"utf-8\", body2)\n@@ -961,14 +912,10 @@ class XmlResponseTest(TextResponseTest):\n \n         self.assertIsInstance(response.selector, Selector)\n         self.assertEqual(response.selector.type, \"xml\")\n-        self.assertIs(\n-            response.selector, response.selector\n-        )  # property is cached\n+        self.assertIs(response.selector, response.selector)  # property is cached\n         self.assertIs(response.selector.response, response)\n \n-        self.assertEqual(\n-            response.selector.xpath(\"//elem/text()\").getall(), [\"value\"]\n-        )\n+        self.assertEqual(response.selector.xpath(\"//elem/text()\").getall(), [\"value\"])\n \n     def test_selector_shortcuts(self):\n         body = b'<?xml version=\"1.0\" encoding=\"utf-8\"?><xml><elem>value</elem></xml>'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
