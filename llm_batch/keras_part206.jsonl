{"custom_id": "keras#9166733c3c144739868fe0c30d57b861b4947b44", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 15 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 31 | Churn Cumulative: 8520 | Contributors (this commit): 89 | Commits (past 90d): 30 | Contributors (cumulative): 89 | DMM Complexity: 0.0\n\nDIFF:\n@@ -164,7 +164,22 @@ def get_session():\n         session = _SESSION\n     if not _MANUAL_VAR_INIT:\n         with session.graph.as_default():\n-            _initialize_variables()\n+            variables = tf.global_variables()\n+            candidate_vars = []\n+            for v in variables:\n+                if not getattr(v, '_keras_initialized', False):\n+                    candidate_vars.append(v)\n+            # This step is expensive, so we only run it on variables\n+            # not already marked as initialized.\n+            is_initialized = session.run(\n+                [tf.is_variable_initialized(v) for v in candidate_vars])\n+            uninitialized_vars = []\n+            for flag, v in zip(is_initialized, candidate_vars):\n+                if not flag:\n+                    uninitialized_vars.append(v)\n+                v._keras_initialized = True\n+            if uninitialized_vars:\n+                session.run(tf.variables_initializer(uninitialized_vars))\n     return session\n \n \n@@ -301,20 +316,6 @@ def variable(value, dtype=None, name=None, constraint=None):\n     return v\n \n \n-def _initialize_variables():\n-    \"\"\"Utility to initialize uninitialized variables on the fly.\n-    \"\"\"\n-    variables = tf.global_variables()\n-    uninitialized_variables = []\n-    for v in variables:\n-        if not hasattr(v, '_keras_initialized') or not v._keras_initialized:\n-            uninitialized_variables.append(v)\n-            v._keras_initialized = True\n-    if uninitialized_variables:\n-        sess = get_session()\n-        sess.run(tf.variables_initializer(uninitialized_variables))\n-\n-\n def constant(value, dtype=None, shape=None, name=None):\n     \"\"\"Creates a constant tensor.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5cd8a7bcf6c01ca641c4f7f3e899a48f38587dc2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 8530 | Contributors (this commit): 90 | Commits (past 90d): 31 | Contributors (cumulative): 90 | DMM Complexity: None\n\nDIFF:\n@@ -2183,6 +2183,16 @@ def get_variable_shape(x):\n def print_tensor(x, message=''):\n     \"\"\"Prints `message` and the tensor value when evaluated.\n  \n+     Note that `print_tensor` returns a new tensor identical to `x`\n+     which should be used in the following code. Otherwise the\n+     print operation is not taken into account during evaluation.\n+ \n+     # Example\n+     ```python\n+         >>> x = K.print_tensor(x, message=\"x is: \")\n+         >>> y = K.foo_bar(x)\n+     ```\n+     \n     # Arguments\n         x: Tensor to print.\n         message: Message to print jointly with the tensor.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7a715593911db2f7dd2b02a0a6cb383478fbb8f0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 8531 | Contributors (this commit): 90 | Commits (past 90d): 32 | Contributors (cumulative): 90 | DMM Complexity: None\n\nDIFF:\n@@ -2190,7 +2190,6 @@ def print_tensor(x, message=''):\n      # Example\n      ```python\n          >>> x = K.print_tensor(x, message=\"x is: \")\n-         >>> y = K.foo_bar(x)\n      ```\n \n     # Arguments\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b24f44480a32e9911a0a8f7a845bc82c877be653", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 12266 | Contributors (this commit): 71 | Commits (past 90d): 8 | Contributors (cumulative): 71 | DMM Complexity: 0.0\n\nDIFF:\n@@ -682,6 +682,7 @@ class Lambda(Layer):\n \n     @classmethod\n     def from_config(cls, config, custom_objects=None):\n+        config = config.copy()\n         globs = globals()\n         if custom_objects:\n             globs = dict(list(globs.items()) + list(custom_objects.items()))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fc1178a7e6335766df6ced6d341648f5727ffc8d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1035 | Contributors (this commit): 21 | Commits (past 90d): 2 | Contributors (cumulative): 21 | DMM Complexity: None\n\nDIFF:\n@@ -39,7 +39,7 @@ def print_summary(model, line_length=None, positions=None, print_fn=print):\n         # header names for the different log elements\n         to_display = ['Layer (type)', 'Output Shape', 'Param #']\n     else:\n-        line_length = line_length or 100\n+        line_length = line_length or 98\n         positions = positions or [.33, .55, .67, 1.]\n         if positions[-1] <= 1:\n             positions = [int(line_length * p) for p in positions]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d4f6ff8a88e215875480da985de6b9acbb322f44", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 11 | Files Changed: 1 | Hunks: 11 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 22 | Churn Cumulative: 808 | Contributors (this commit): 10 | Commits (past 90d): 5 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -76,7 +76,7 @@ def speckle(img):\n # and a random amount of speckle noise\n \n def paint_text(text, w, h, rotate=False, ud=False, multi_fonts=False):\n-    surface = cairo.ImageSurface(cairo.FORMAT_RGB24, w, h)\n+    surface = cairo.ImageSurface(cairo.FORMAT_RGB24, width=w, height=h)\n     with cairo.Context(surface) as context:\n         context.set_source_rgb(1, 1, 1)  # White\n         context.paint()\n@@ -237,9 +237,9 @@ class TextImageGenerator(keras.callbacks.Callback):\n         # width and height are backwards from typical Keras convention\n         # because width is the time dimension when it gets fed into the RNN\n         if K.image_data_format() == 'channels_first':\n-            X_data = np.ones([size, 1, self.img_w, self.img_h])\n+            X_data = np.ones([size, 1, self.img_h, self.img_w])\n         else:\n-            X_data = np.ones([size, self.img_w, self.img_h, 1])\n+            X_data = np.ones([size, self.img_h, self.img_w, 1])\n \n         labels = np.ones([size, self.absolute_max_string_len])\n         input_length = np.zeros([size, 1])\n@@ -250,18 +250,18 @@ class TextImageGenerator(keras.callbacks.Callback):\n             # achieving translational invariance\n             if train and i > size - 4:\n                 if K.image_data_format() == 'channels_first':\n-                    X_data[i, 0, 0:self.img_w, :] = self.paint_func('')[0, :, :].T\n+                    X_data[i, 0, 0:self.img_h, :] = self.paint_func('')[0, :, :]\n                 else:\n-                    X_data[i, 0:self.img_w, :, 0] = self.paint_func('',)[0, :, :].T\n+                    X_data[i, 0:self.img_h, :, 0] = self.paint_func('',)[0, :, :]\n                 labels[i, 0] = self.blank_label\n                 input_length[i] = self.img_w // self.downsample_factor - 2\n                 label_length[i] = 1\n                 source_str.append('')\n             else:\n                 if K.image_data_format() == 'channels_first':\n-                    X_data[i, 0, 0:self.img_w, :] = self.paint_func(self.X_text[index + i])[0, :, :].T\n+                    X_data[i, 0, 0:self.img_h, :] = self.paint_func(self.X_text[index + i])[0, :, :]\n                 else:\n-                    X_data[i, 0:self.img_w, :, 0] = self.paint_func(self.X_text[index + i])[0, :, :].T\n+                    X_data[i, 0:self.img_h, :, 0] = self.paint_func(self.X_text[index + i])[0, :, :]\n                 labels[i, :] = self.Y_data[index + i]\n                 input_length[i] = self.img_w // self.downsample_factor - 2\n                 label_length[i] = self.Y_len[index + i]\n@@ -388,7 +388,7 @@ class VizCallback(keras.callbacks.Callback):\n                 the_input = word_batch['the_input'][i, 0, :, :]\n             else:\n                 the_input = word_batch['the_input'][i, :, :, 0]\n-            pylab.imshow(the_input.T, cmap='Greys_r')\n+            pylab.imshow(the_input, cmap='Greys_r')\n             pylab.xlabel('Truth = \\'%s\\'\\nDecoded = \\'%s\\'' % (word_batch['source_str'][i], res[i]))\n         fig = pylab.gcf()\n         fig.set_size_inches(10, 13)\n@@ -412,9 +412,9 @@ def train(run_name, start_epoch, stop_epoch, img_w):\n     minibatch_size = 32\n \n     if K.image_data_format() == 'channels_first':\n-        input_shape = (1, img_w, img_h)\n+        input_shape = (1, img_h, img_w)\n     else:\n-        input_shape = (img_w, img_h, 1)\n+        input_shape = (img_h, img_w, 1)\n \n     fdir = os.path.dirname(get_file('wordlists.tgz',\n                                     origin='http://www.mythic-ai.com/datasets/wordlists.tgz', untar=True))\n@@ -438,7 +438,7 @@ def train(run_name, start_epoch, stop_epoch, img_w):\n                    name='conv2')(inner)\n     inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n \n-    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n+    conv_to_rnn_dims = ((img_h // (pool_size ** 2)) * conv_filters, img_w // (pool_size ** 2))\n     inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n \n     # cuts down input size going into RNN:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ffdae928837946a31799aab0950a9aa82c6f5ce0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 25 | Churn Cumulative: 8250 | Contributors (this commit): 50 | Commits (past 90d): 14 | Contributors (cumulative): 50 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3016,7 +3016,7 @@ def preprocess_weights_for_loading(layer, weights,\n                    'Conv2DTranspose',\n                    'ConvLSTM2D']\n     if layer.__class__.__name__ in conv_layers:\n-        if original_backend and K.backend() != original_backend:\n+        if _need_convert_kernel(original_backend):\n             weights[0] = conv_utils.convert_kernel(weights[0])\n             if layer.__class__.__name__ == 'ConvLSTM2D':\n                 weights[1] = conv_utils.convert_kernel(weights[1])\n@@ -3027,6 +3027,29 @@ def preprocess_weights_for_loading(layer, weights,\n     return weights\n \n \n+def _need_convert_kernel(original_backend):\n+    \"\"\"Check if conversion on kernel matrices is required during weight loading.\n+\n+    The convolution operation is implemented differently in different backends.\n+    While TH implements convolution, TF and CNTK implement the correlation operation.\n+    So the channel axis needs to be flipped when we're loading TF weights onto a TH model,\n+    or vice verca. However, there's no conversion required between TF and CNTK.\n+\n+    # Arguments\n+        original_backend: Keras backend the weights were trained with, as a string.\n+\n+    # Returns\n+        `True` if conversion on kernel matrices is required, otherwise `False`.\n+    \"\"\"\n+    if original_backend is None:\n+        # backend information not available\n+        return False\n+    uses_correlation = {'tensorflow': True,\n+                        'theano': False,\n+                        'cntk': True}\n+    return uses_correlation[original_backend] != uses_correlation[K.backend()]\n+\n+\n def load_weights_from_hdf5_group(f, layers):\n     \"\"\"Implements topological (order-based) weight loading.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cc7ec458053b7a2cf93b5b1d2b5adefb90e051ea", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 8533 | Contributors (this commit): 90 | Commits (past 90d): 30 | Contributors (cumulative): 90 | DMM Complexity: None\n\nDIFF:\n@@ -2667,7 +2667,7 @@ def elu(x, alpha=1.):\n     \"\"\"Exponential linear unit.\n \n     # Arguments\n-        x: A tenor or variable to compute the activation function for.\n+        x: A tensor or variable to compute the activation function for.\n         alpha: A scalar, slope of positive section.\n \n     # Returns\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5562bcb921e3ff7942162a3989cc729b74828f7d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1600 | Contributors (this commit): 11 | Commits (past 90d): 1 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -456,7 +456,7 @@ class GlobalAveragePooling1D(_GlobalPooling1D):\n \n     # Output shape\n         2D tensor with shape:\n-        `(batch_size, channels)`\n+        `(batch_size, features)`\n     \"\"\"\n \n     def call(self, inputs):\n@@ -471,7 +471,7 @@ class GlobalMaxPooling1D(_GlobalPooling1D):\n \n     # Output shape\n         2D tensor with shape:\n-        `(batch_size, channels)`\n+        `(batch_size, features)`\n     \"\"\"\n \n     def call(self, inputs):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bd5d6162f1a6815588e8e9f48bc92201aa7e0ce4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 271 | Contributors (this commit): 9 | Commits (past 90d): 1 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -75,7 +75,9 @@ def create_base_network(input_dim):\n def compute_accuracy(predictions, labels):\n     '''Compute classification accuracy with a fixed threshold on distances.\n     '''\n-    return labels[predictions.ravel() < 0.5].mean()\n+    preds = predictions.ravel() < 0.5\n+    return ((preds & labels).sum() +\n+            (np.logical_not(preds) & np.logical_not(labels)).sum()) / float(labels.size)\n \n \n # the data, shuffled and split between train and test sets\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8ac788a5614570d222c484ab49cf9e878eeab9ff", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 5402 | Contributors (this commit): 62 | Commits (past 90d): 19 | Contributors (cumulative): 62 | DMM Complexity: None\n\nDIFF:\n@@ -1869,7 +1869,7 @@ class Model(Container):\n             steps_per_epoch: Total number of steps (batches of samples)\n                 to yield from `generator` before declaring one epoch\n                 finished and starting the next epoch. It should typically\n-                be equal to the number of unique samples if your dataset\n+                be equal to the number of unique samples of your dataset\n                 divided by the batch size.\n             epochs: Integer, total number of iterations on the data.\n             verbose: Verbosity mode, 0, 1, or 2.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b88d5c3ab0ff858f40b6fae4691349411c00ac94", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 275 | Contributors (this commit): 9 | Commits (past 90d): 2 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -7,8 +7,8 @@ for mode details).\n [1] \"Dimensionality Reduction by Learning an Invariant Mapping\"\n     http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n \n-Gets to 99.5% test accuracy after 20 epochs.\n-3 seconds per epoch on a Titan X GPU\n+Gets to 97.2% test accuracy after 20 epochs.\n+2 seconds per epoch on a Titan X Maxwell GPU\n '''\n from __future__ import absolute_import\n from __future__ import print_function\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2dfba02e0a507eddaf3db3d7f3660d75ce740639", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 51 | Contributors (this commit): 5 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -71,7 +71,7 @@ def poisson(y_true, y_pred):\n def cosine_proximity(y_true, y_pred):\n     y_true = K.l2_normalize(y_true, axis=-1)\n     y_pred = K.l2_normalize(y_pred, axis=-1)\n-    return -K.mean(y_true * y_pred, axis=-1)\n+    return -K.sum(y_true * y_pred, axis=-1)\n \n \n # Aliases.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#710898f759b9ec229f3513bb9f58fd032c1aaed6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 14 | Churn Cumulative: 6072 | Contributors (this commit): 83 | Commits (past 90d): 25 | Contributors (cumulative): 87 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1412,7 +1412,7 @@ def rnn(step_function, inputs, initial_states,\n             # Theano likes to make shape==1 dimensions\n             # in the initial states (outputs_info) broadcastable\n             if len(initial_states) > 0:\n-                initial_states[0] = T.unbroadcast(initial_states[0], 1)\n+                initial_states[0] = T.unbroadcast(initial_states[0], 0, 1)\n \n             results, _ = theano.scan(\n                 _step,\n\n@@ -552,5 +552,17 @@ def test_stacked_rnn_attributes():\n     assert layer.get_losses_for(x) == [y]\n \n \n+@rnn_test\n+def test_batch_size_equal_one(layer_class):\n+    inputs = Input(batch_shape=(1, timesteps, embedding_dim))\n+    layer = layer_class(units)\n+    outputs = layer(inputs)\n+    model = Model(inputs, outputs)\n+    model.compile('sgd', 'mse')\n+    x = np.random.random((1, timesteps, embedding_dim))\n+    y = np.random.random((1, units))\n+    model.train_on_batch(x, y)\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#771be1a587780ddeea9ad90ca435a11ff297830e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 4 | Churn Cumulative: 8254 | Contributors (this commit): 51 | Commits (past 90d): 11 | Contributors (cumulative): 51 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1372,7 +1372,7 @@ class InputLayer(Layer):\n \n \n def Input(shape=None, batch_shape=None,\n-          name=None, dtype=K.floatx(), sparse=False,\n+          name=None, dtype=None, sparse=False,\n           tensor=None):\n     \"\"\"`Input()` is used to instantiate a Keras tensor.\n \n@@ -1430,6 +1430,8 @@ def Input(shape=None, batch_shape=None,\n                        'dimension.')\n     if shape and not batch_shape:\n         batch_shape = (None,) + tuple(shape)\n+    if not dtype:\n+        dtype = K.floatx()\n     input_layer = InputLayer(batch_input_shape=batch_shape,\n                              name=name, dtype=dtype,\n                              sparse=sparse,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fb4a0849cf4dc2965af86510f02ec46abab1a6a4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 32 | Lines Deleted: 16 | Files Changed: 9 | Hunks: 16 | Methods Changed: 11 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 48 | Churn Cumulative: 3695 | Contributors (this commit): 19 | Commits (past 90d): 29 | Contributors (cumulative): 55 | DMM Complexity: 0.3125\n\nDIFF:\n@@ -83,7 +83,8 @@ def decode_predictions(preds, top=5):\n     if CLASS_INDEX is None:\n         fpath = get_file('imagenet_class_index.json',\n                          CLASS_INDEX_PATH,\n-                         cache_subdir='models')\n+                         cache_subdir='models',\n+                         file_hash='c2c37ea517e94d9795004a39431a14cb')\n         CLASS_INDEX = json.load(open(fpath))\n     results = []\n     for pred in preds:\n\n@@ -362,13 +362,13 @@ def InceptionResNetV2(include_top=True,\n             weights_path = get_file(weights_filename,\n                                     BASE_WEIGHT_URL + weights_filename,\n                                     cache_subdir='models',\n-                                    md5_hash='e693bd0210a403b3192acc6073ad2e96')\n+                                    file_hash='e693bd0210a403b3192acc6073ad2e96')\n         else:\n             weights_filename = 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n             weights_path = get_file(weights_filename,\n                                     BASE_WEIGHT_URL + weights_filename,\n                                     cache_subdir='models',\n-                                    md5_hash='d19885ff4a710c122648d3b5c3b684e4')\n+                                    file_hash='d19885ff4a710c122648d3b5c3b684e4')\n         model.load_weights(weights_path)\n \n     return model\n\n@@ -377,13 +377,13 @@ def InceptionV3(include_top=True,\n                 'inception_v3_weights_tf_dim_ordering_tf_kernels.h5',\n                 WEIGHTS_PATH,\n                 cache_subdir='models',\n-                md5_hash='9a0d58056eeedaa3f26cb7ebd46da564')\n+                file_hash='9a0d58056eeedaa3f26cb7ebd46da564')\n         else:\n             weights_path = get_file(\n                 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                 WEIGHTS_PATH_NO_TOP,\n                 cache_subdir='models',\n-                md5_hash='bcbd6486424b2319ff4ef7d526e38f63')\n+                file_hash='bcbd6486424b2319ff4ef7d526e38f63')\n         model.load_weights(weights_path)\n     return model\n \n\n@@ -162,11 +162,13 @@ def VGG16(include_top=True, weights='imagenet',\n         if include_top:\n             weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n                                     WEIGHTS_PATH,\n-                                    cache_subdir='models')\n+                                    cache_subdir='models',\n+                                    file_hash='64373286793e3c8b2b4e3219cbf3544b')\n         else:\n             weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                                     WEIGHTS_PATH_NO_TOP,\n-                                    cache_subdir='models')\n+                                    cache_subdir='models',\n+                                    file_hash='6d6bbae143d832006294945121d1f1fc')\n         model.load_weights(weights_path)\n         if K.backend() == 'theano':\n             layer_utils.convert_all_kernels_in_model(model)\n\n@@ -165,11 +165,13 @@ def VGG19(include_top=True, weights='imagenet',\n         if include_top:\n             weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n                                     WEIGHTS_PATH,\n-                                    cache_subdir='models')\n+                                    cache_subdir='models',\n+                                    file_hash='cbe5617147190e668d6c5d5026f83318')\n         else:\n             weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                                     WEIGHTS_PATH_NO_TOP,\n-                                    cache_subdir='models')\n+                                    cache_subdir='models',\n+                                    file_hash='253f8cb515780f3b799900260a226db6')\n         model.load_weights(weights_path)\n         if K.backend() == 'theano':\n             layer_utils.convert_all_kernels_in_model(model)\n\n@@ -249,11 +249,13 @@ def Xception(include_top=True, weights='imagenet',\n         if include_top:\n             weights_path = get_file('xception_weights_tf_dim_ordering_tf_kernels.h5',\n                                     TF_WEIGHTS_PATH,\n-                                    cache_subdir='models')\n+                                    cache_subdir='models',\n+                                    file_hash='0a58e3b7378bc2990ea3b43d5981f1f6')\n         else:\n             weights_path = get_file('xception_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                                     TF_WEIGHTS_PATH_NO_TOP,\n-                                    cache_subdir='models')\n+                                    cache_subdir='models',\n+                                    file_hash='b0042744bf5b25fce3cb969f33bebb97')\n         model.load_weights(weights_path)\n \n     if old_data_format:\n\n@@ -48,7 +48,9 @@ def load_data(path='imdb.npz', num_words=None, skip_top=0,\n     if kwargs:\n         raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n \n-    path = get_file(path, origin='https://s3.amazonaws.com/text-datasets/imdb.npz')\n+    path = get_file(path,\n+                    origin='https://s3.amazonaws.com/text-datasets/imdb.npz',\n+                    file_hash='599dadb1135973df5b59232a0e9a887c')\n     with np.load(path) as f:\n         x_train, labels_train = f['x_train'], f['y_train']\n         x_test, labels_test = f['x_test'], f['y_test']\n@@ -105,7 +107,8 @@ def get_word_index(path='imdb_word_index.json'):\n         The word index dictionary.\n     \"\"\"\n     path = get_file(path,\n-                    origin='https://s3.amazonaws.com/text-datasets/imdb_word_index.json')\n+                    origin='https://s3.amazonaws.com/text-datasets/imdb_word_index.json',\n+                    file_hash='bfafd718b763782e994055a2d397834f')\n     f = open(path)\n     data = json.load(f)\n     f.close()\n\n@@ -12,7 +12,9 @@ def load_data(path='mnist.npz'):\n     # Returns\n         Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n     \"\"\"\n-    path = get_file(path, origin='https://s3.amazonaws.com/img-datasets/mnist.npz')\n+    path = get_file(path,\n+                    origin='https://s3.amazonaws.com/img-datasets/mnist.npz',\n+                    file_hash='8a61469f7ea1b51cbae51d4f78837e45')\n     f = np.load(path)\n     x_train, y_train = f['x_train'], f['y_train']\n     x_test, y_test = f['x_test'], f['y_test']\n\n@@ -46,7 +46,9 @@ def load_data(path='reuters.npz', num_words=None, skip_top=0,\n     if kwargs:\n         raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n \n-    path = get_file(path, origin='https://s3.amazonaws.com/text-datasets/reuters.npz')\n+    path = get_file(path,\n+                    origin='https://s3.amazonaws.com/text-datasets/reuters.npz',\n+                    file_hash='87aedbeb0cb229e378797a632c1997b6')\n     with np.load(path) as f:\n         xs, labels = f['x'], f['y']\n \n@@ -90,7 +92,9 @@ def get_word_index(path='reuters_word_index.json'):\n     # Returns\n         The word index dictionary.\n     \"\"\"\n-    path = get_file(path, origin='https://s3.amazonaws.com/text-datasets/reuters_word_index.json')\n+    path = get_file(path,\n+                    origin='https://s3.amazonaws.com/text-datasets/reuters_word_index.json',\n+                    file_hash='4d44cc38712099c9e383dc6e5f11a921')\n     f = open(path)\n     data = json.load(f)\n     f.close()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#408de9b67f56636b9802adae82c06f70f60ae000", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 14 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 25 | Churn Cumulative: 12548 | Contributors (this commit): 72 | Commits (past 90d): 8 | Contributors (cumulative): 76 | DMM Complexity: 0.0\n\nDIFF:\n@@ -372,24 +372,17 @@ class Reshape(Layer):\n         return tuple(output_shape)\n \n     def compute_output_shape(self, input_shape):\n+        if None in input_shape[1:]:\n+            # input shape (partially) unknown? replace -1's with None's\n+            return ((input_shape[0],) +\n+                    tuple(s if s != -1 else None for s in self.target_shape))\n+        else:\n+            # input shape known? then we can compute the output shape\n             return (input_shape[0],) + self._fix_unknown_dimension(\n                 input_shape[1:], self.target_shape)\n \n     def call(self, inputs):\n-        # In case the target shape is not fully defined,\n-        # we need access to the shape of `inputs`.\n-        # solution: rely on `K.int_shape`.\n-        target_shape = self.target_shape\n-        if -1 in target_shape:\n-            # Target shape not fully defined.\n-            input_shape = None\n-            try:\n-                input_shape = K.int_shape(inputs)\n-            except TypeError:\n-                pass\n-            if input_shape is not None:\n-                target_shape = self.compute_output_shape(input_shape)[1:]\n-        return K.reshape(inputs, (-1,) + target_shape)\n+        return K.reshape(inputs, (K.shape(inputs)[0],) + self.target_shape)\n \n     def get_config(self):\n         config = {'target_shape': self.target_shape}\n\n@@ -79,6 +79,10 @@ def test_reshape():\n                kwargs={'target_shape': (1, -1)},\n                input_shape=(3, 2, 4))\n \n+    layer_test(layers.Reshape,\n+               kwargs={'target_shape': (-1, 1)},\n+               input_shape=(None, None, 4))\n+\n \n @keras_test\n def test_permute():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#db4b0a7a1938fe181f61cba24880e12bba8faaac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 2 | Files Changed: 3 | Hunks: 9 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 3789 | Contributors (this commit): 22 | Commits (past 90d): 30 | Contributors (cumulative): 30 | DMM Complexity: None\n\nDIFF:\n@@ -3,6 +3,7 @@ from numpy.testing import assert_allclose\n import numpy as np\n import scipy.sparse as sparse\n import warnings\n+from keras.utils.test_utils import keras_test\n \n from keras import backend as K\n from keras.backend import floatx, set_floatx, variable\n@@ -86,6 +87,7 @@ def assert_list_keras_shape(z_list):\n             assert z._keras_shape == z.shape\n \n \n+@keras_test\n def check_single_tensor_operation(function_name, x_shape_or_val, backend_list, **kwargs):\n     shape_or_val = kwargs.pop('shape_or_val', True)\n     assert_value_equality = kwargs.pop('assert_value_equality', True)\n@@ -114,6 +116,7 @@ def check_single_tensor_operation(function_name, x_shape_or_val, backend_list, *\n     assert_list_keras_shape(z_list)\n \n \n+@keras_test\n def check_two_tensor_operation(function_name, x_shape_or_val,\n                                y_shape_or_val, backend_list, **kwargs):\n     shape_or_val = kwargs.pop('shape_or_val', True)\n@@ -152,6 +155,7 @@ def check_two_tensor_operation(function_name, x_shape_or_val,\n     assert_list_keras_shape(z_list)\n \n \n+@keras_test\n def check_composed_tensor_operations(first_function_name, first_function_args,\n                                      second_function_name, second_function_args,\n                                      input_shape, backend_list):\n\n@@ -12,8 +12,8 @@ from keras import regularizers\n def test_convolutional_recurrent():\n     num_row = 3\n     num_col = 3\n-    filters = 5\n-    num_samples = 2\n+    filters = 2\n+    num_samples = 1\n     input_channel = 2\n     input_num_row = 5\n     input_num_col = 5\n\n@@ -380,6 +380,7 @@ def test_state_reuse(layer_class):\n     outputs = model.predict(inputs)\n \n \n+@keras_test\n def test_minimal_rnn_cell_non_layer():\n \n     class MinimalRNNCell(object):\n@@ -415,6 +416,7 @@ def test_minimal_rnn_cell_non_layer():\n     model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n \n \n+@keras_test\n def test_minimal_rnn_cell_non_layer_multiple_states():\n \n     class MinimalRNNCell(object):\n@@ -454,6 +456,7 @@ def test_minimal_rnn_cell_non_layer_multiple_states():\n     model.train_on_batch(np.zeros((6, 5, 5)), np.zeros((6, 32)))\n \n \n+@keras_test\n def test_minimal_rnn_cell_layer():\n \n     class MinimalRNNCell(keras.layers.Layer):\n@@ -530,6 +533,7 @@ def test_minimal_rnn_cell_layer():\n     assert_allclose(y_np, y_np_2, atol=1e-4)\n \n \n+@keras_test\n def test_stacked_rnn_attributes():\n     cells = [recurrent.LSTMCell(3),\n              recurrent.LSTMCell(3, kernel_regularizer='l2')]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#671a3633e636c912c13f63b7f563c801a919763e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 956 | Contributors (this commit): 8 | Commits (past 90d): 6 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -301,6 +301,13 @@ class Sequence(object):\n     \"\"\"Base object for fitting to a sequence of data, such as a dataset.\n \n     Every `Sequence` must implements the `__getitem__` and the `__len__` methods.\n+    If you want to modify your dataset between epochs you may implement `on_epoch_end`.\n+    The method `__getitem__` should return a complete batch.\n+\n+    # Notes\n+\n+    `Sequence` are a safer way to do multiprocessing. This structure guarantees that the network will only train once\n+     on each sample per epoch which is not the case with generators.\n \n     # Examples\n \n@@ -352,11 +359,10 @@ class Sequence(object):\n         \"\"\"\n         raise NotImplementedError\n \n-    @abstractmethod\n     def on_epoch_end(self):\n         \"\"\"Method called at the end of every epoch.\n         \"\"\"\n-        raise NotImplementedError\n+        pass\n \n \n def get_index(ds, i):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#393af21492e9c2ca48542df4d5a8ad9ad01f9d7b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 12 | Churn Cumulative: 12299 | Contributors (this commit): 73 | Commits (past 90d): 7 | Contributors (cumulative): 73 | DMM Complexity: 1.0\n\nDIFF:\n@@ -97,9 +97,15 @@ class Dropout(Layer):\n         self.seed = seed\n         self.supports_masking = True\n \n-    def _get_noise_shape(self, _):\n+    def _get_noise_shape(self, inputs):\n+        if self.noise_shape is None:\n             return self.noise_shape\n \n+        symbolic_shape = K.shape(inputs)\n+        noise_shape = [symbolic_shape[axis] if shape is None else shape\n+                       for axis, shape in enumerate(self.noise_shape)]\n+        return tuple(noise_shape)\n+\n     def call(self, inputs, training=None):\n         if 0. < self.rate < 1.:\n             noise_shape = self._get_noise_shape(inputs)\n@@ -112,7 +118,9 @@ class Dropout(Layer):\n         return inputs\n \n     def get_config(self):\n-        config = {'rate': self.rate}\n+        config = {'rate': self.rate,\n+                  'noise_shape': self.noise_shape,\n+                  'seed': self.seed}\n         base_config = super(Dropout, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1bbfdb6174c2833c7aca8261a3f97bc5235bc66b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 68 | Lines Deleted: 4 | Files Changed: 4 | Hunks: 10 | Methods Changed: 5 | Complexity Δ (Sum/Max): 13/5 | Churn Δ: 72 | Churn Cumulative: 19657 | Contributors (this commit): 115 | Commits (past 90d): 81 | Contributors (cumulative): 196 | DMM Complexity: 0.2982456140350877\n\nDIFF:\n@@ -674,14 +674,16 @@ def squeeze(x, axis):\n \n \n def tile(x, n):\n-    if isinstance(n, list):\n+    if isinstance(n, int):\n+        n = (n,)\n+    elif isinstance(n, list):\n         n = tuple(n)\n \n     shape = int_shape(x)\n     num_dynamic_axis = _get_dynamic_axis_num(x)\n     # Padding the axis\n     if len(n) < len(shape):\n-        n = tuple([None for _ in range(len(shape) - len(n))]) + n\n+        n = tuple([1 for _ in range(len(shape) - len(n))]) + n\n \n     if len(n) != len(shape):\n         raise NotImplementedError\n@@ -2063,6 +2065,20 @@ def stop_gradient(variables):\n \n \n def switch(condition, then_expression, else_expression):\n+    ndim_cond = ndim(condition)\n+    ndim_expr = ndim(then_expression)\n+    if ndim_cond > ndim_expr:\n+        raise ValueError('Rank of condition should be less'\n+                         ' than or equal to rank of then and'\n+                         ' else expressions. ndim(condition)=' +\n+                         str(cond_ndim) + ', ndim(then_expression)'\n+                         '=' + str(expr_ndim))\n+    elif ndim_cond < ndim_expr:\n+        shape_expr = int_shape(then_expression)\n+        ndim_diff = ndim_expr - ndim_cond\n+        for i in range(ndim_diff):\n+            condition = expand_dims(condition)\n+            condition = tile(condition, shape_expr[ndim_cond + i])\n     return C.element_select(condition,\n                             then_expression,\n                             else_expression)\n\n@@ -2561,15 +2561,20 @@ def switch(condition, then_expression, else_expression):\n     should be symbolic tensors of the *same shape*.\n \n     # Arguments\n-        condition: scalar tensor (`int` or `bool`).\n+        condition: tensor (`int` or `bool`).\n         then_expression: either a tensor, or a callable that returns a tensor.\n         else_expression: either a tensor, or a callable that returns a tensor.\n \n     # Returns\n         The selected tensor.\n+\n+    # Raises\n+        ValueError: If rank of `condition` is greater than rank of expressions.\n     \"\"\"\n     if condition.dtype != tf.bool:\n         condition = tf.cast(condition, 'bool')\n+    cond_ndim = ndim(condition)\n+    if not cond_ndim:\n         if not callable(then_expression):\n             def then_expression_fn():\n                 return then_expression\n@@ -2583,6 +2588,30 @@ def switch(condition, then_expression, else_expression):\n         x = tf.cond(condition,\n                     then_expression_fn,\n                     else_expression_fn)\n+    else:\n+        # tf.where needs its condition tensor\n+        # to be the same shape as its two\n+        # result tensors\n+        if callable(then_expression):\n+            then_expression = then_expression()\n+        if callable(else_expression):\n+            else_expression = else_expression()\n+        expr_ndim = ndim(then_expression)\n+        if cond_ndim > expr_ndim:\n+            raise ValueError('Rank of `condition` should be less than or'\n+                             ' equal to rank of `then_expression` and '\n+                             '`else_expression`. ndim(condition)=' +\n+                             str(cond_ndim) + ', ndim(then_expression)'\n+                             '=' + str(expr_ndim))\n+        if cond_ndim > 1:\n+            ndim_diff = expr_ndim - cond_ndim\n+            cond_shape = tf.concat([tf.shape(condition), [1] * ndim_diff], axis=0)\n+            condition = tf.reshape(condition, cond_shape)\n+            expr_shape = tf.shape(then_expression)\n+            shape_diff = expr_shape - cond_shape\n+            tile_shape = tf.where(shape_diff > 0, expr_shape, tf.ones_like(expr_shape))\n+            condition = tf.tile(condition, tile_shape)\n+        x = tf.where(condition, then_expression, else_expression)\n     return x\n \n \n\n@@ -1457,6 +1457,12 @@ def switch(condition, then_expression, else_expression):\n         then_expression = then_expression()\n     if callable(else_expression):\n         else_expression = else_expression()\n+    cond_ndim = ndim(condition)\n+    expr_ndim = ndim(then_expression)\n+    if cond_ndim < expr_ndim:\n+        ndim_diff = expr_ndim - cond_ndim\n+        for _ in range(ndim_diff):\n+            condition = expand_dims(condition)\n     return T.switch(condition, then_expression, else_expression)\n \n \n\n@@ -648,13 +648,26 @@ class TestBackend(object):\n                             rtol=1e-5)\n \n     def test_switch(self):\n+        # scalar\n         val = np.random.random()\n         z_list = []\n         for k in BACKENDS:\n             x = k.variable(val)\n             x = k.switch(k.greater_equal(x, 0.5), x * 0.1, x * 0.2)\n             z_list.append(k.eval(x))\n-\n+        assert_list_pairwise(z_list)\n+        # non scalar\n+        shapes = []\n+        shapes.append([(4, 3, 2), (4, 3, 2), (4, 3, 2)])\n+        shapes.append([(4, 3,), (4, 3, 2), (4, 3, 2)])\n+        shapes.append([(4,), (4, 3, 2), (4, 3, 2)])\n+        for s in shapes:\n+            z_list = []\n+            arrays = list(map(np.random.random, s))\n+            for k in BACKENDS:\n+                x, then_expr, else_expr = map(k.variable, arrays)\n+                cond = k.greater_equal(x, 0.5)\n+                z_list.append(k.eval(k.switch(cond, then_expr, else_expr)))\n             assert_list_pairwise(z_list)\n \n     def test_dropout(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#22b66dfb44ad6c9e18a66adaa9933ce502499e8a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 222 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 222 | Churn Cumulative: 222 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,222 @@\n+'''Sequence to sequence example in Keras (character-level).\n+\n+This script demonstrates how to implement a basic character-level\n+sequence-to-sequence model. We apply it to translating\n+short English sentences into short French sentences,\n+character-by-character. Note that it is fairly unusual to\n+do character-level machine translation, as word-level\n+models are more common in this domain.\n+\n+# Summary of the algorithm:\n+\n+- We start with input sequences from a domain (e.g. English sentences)\n+    and correspding target sequences from another domain\n+    (e.g. French sentences).\n+- An encoder LSTM turns input sequences to 2 state vectors\n+    (we keep the last LSTM state and discard the outputs).\n+- A decoder LSTM is trained to turn the target sequences into\n+    the same sequence but offset by one timestep in the future,\n+    a training process called \"teacher forcing\" in this context.\n+    Is uses as initial state the state vectors from the encoder.\n+    Effectively, the decoder learns to generate `targets[t+1...]`\n+    given `targets[...t]`, conditioned on the input sequence.\n+- In inference mode, when we want to decode unknown input sequences, we:\n+    - Encode the input sequence into state vectors\n+    - Start with a target sequence of size 1\n+        (just the start-of-sequence character)\n+    - Feed the state vectors and 1-char target sequence\n+        to the decoder to produce predictions for the next character\n+    - Sample the next character using these predictions\n+        (we simply use argmax).\n+    - Append the sampled character to the target sequence\n+    - Repeat until we generate the end-of-sequence character or we\n+        hit the character limit.\n+\n+# Data download:\n+\n+English to French sentence pairs.\n+http://www.manythings.org/anki/fra-eng.zip\n+\n+Lots of neat sentence pairs datasets can be found at:\n+http://www.manythings.org/anki/\n+\n+# References:\n+\n+- Sequence to Sequence Learning with Neural Networks\n+    https://arxiv.org/abs/1409.3215\n+- Learning Phrase Representations using\n+    RNN Encoder-Decoder for Statistical Machine Translation\n+    https://arxiv.org/abs/1406.1078\n+'''\n+from __future__ import print_function\n+\n+from keras.models import Model\n+from keras.layers import Input, LSTM, Dense\n+import numpy as np\n+\n+batch_size = 64  # Batch size for training.\n+epochs = 100  # Number of epochs to train for.\n+latent_dim = 256  # Latent dimensionality of the encoding space.\n+num_samples = 10000  # Number of samples to train on.\n+# Path to the data txt file on disk.\n+data_path = '/Users/fchollet/Downloads/fra-eng/fra.txt'\n+\n+# Vectorize the data.\n+input_texts = []\n+target_texts = []\n+input_characters = set()\n+target_characters = set()\n+lines = open(data_path).read().split('\\n')\n+for line in lines[: min(num_samples, len(lines) - 1)]:\n+    input_text, target_text = line.split('\\t')\n+    # We use \"tab\" as the \"start sequence\" character\n+    # for the targets, and \"\\n\" as \"end sequence\" character.\n+    target_text = '\\t' + target_text + '\\n'\n+    input_texts.append(input_text)\n+    target_texts.append(target_text)\n+    for char in input_text:\n+        if char not in input_characters:\n+            input_characters.add(char)\n+    for char in target_text:\n+        if char not in target_characters:\n+            target_characters.add(char)\n+\n+input_characters = sorted(list(input_characters))\n+target_characters = sorted(list(target_characters))\n+num_encoder_tokens = len(input_characters)\n+num_decoder_tokens = len(target_characters)\n+max_encoder_seq_length = max([len(txt) for txt in input_texts])\n+max_decoder_seq_length = max([len(txt) for txt in target_texts])\n+\n+print('Number of samples:', len(input_texts))\n+print('Number of unique input tokens:', num_encoder_tokens)\n+print('Number of unique output tokens:', num_decoder_tokens)\n+print('Max sequence length for inputs:', max_encoder_seq_length)\n+print('Max sequence length for outputs:', max_decoder_seq_length)\n+\n+input_token_index = dict(\n+    [(char, i) for i, char in enumerate(input_characters)])\n+target_token_index = dict(\n+    [(char, i) for i, char in enumerate(target_characters)])\n+\n+encoder_input_data = np.zeros(\n+    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n+    dtype='float32')\n+decoder_input_data = np.zeros(\n+    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n+    dtype='float32')\n+decoder_target_data = np.zeros(\n+    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n+    dtype='float32')\n+\n+for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n+    for t, char in enumerate(input_text):\n+        encoder_input_data[i, t, input_token_index[char]] = 1.\n+    for t, char in enumerate(target_text):\n+        # decoder_target_data is ahead of decoder_target_data by one timestep\n+        decoder_input_data[i, t, target_token_index[char]] = 1.\n+        if t > 0:\n+            # decoder_target_data will be ahead by one timestep\n+            # and will not include the start character.\n+            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n+\n+# Define an input sequence and process it.\n+encoder_inputs = Input(shape=(None, num_encoder_tokens))\n+encoder = LSTM(latent_dim, return_state=True)\n+encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n+# We discard `encoder_outputs` and only keep the states.\n+encoder_states = [state_h, state_c]\n+\n+# Set up the decoder, using `encoder_states` as initial state.\n+decoder_inputs = Input(shape=(None, num_decoder_tokens))\n+decoder_lstm = LSTM(latent_dim, return_sequences=True)\n+decoder_outputs = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n+decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n+decoder_outputs = decoder_dense(decoder_outputs)\n+\n+# Define the model that will turn\n+# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n+model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n+\n+# Run training\n+model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n+model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n+          batch_size=batch_size,\n+          epochs=epochs,\n+          validation_split=0.2)\n+# Save model\n+model.save('s2s.h5')\n+\n+# Next: inference mode (sampling).\n+# Here's the drill:\n+# 1) encode input and retrieve initial decoder state\n+# 2) run one step of decoder with this initial state\n+# and a \"start of sequence\" token as target.\n+# Output will be the next target token\n+# 3) Append the target token and repeat\n+\n+# Define sampling models\n+encoder_model = Model(encoder_inputs, encoder_states)\n+\n+decoder_state_input_h = Input(shape=(latent_dim,))\n+decoder_state_input_c = Input(shape=(latent_dim,))\n+decoder_states = [decoder_state_input_h, decoder_state_input_c]\n+decoder_outputs = decoder_lstm(decoder_inputs,\n+                               initial_state=decoder_states)\n+decoder_outputs = decoder_dense(decoder_outputs)\n+decoder_model = Model(\n+    [decoder_inputs] + decoder_states,\n+    decoder_outputs)\n+\n+# Reverse-lookup token index to decode sequences back to\n+# something readable.\n+reverse_input_char_index = dict(\n+    (i, char) for char, i in input_token_index.items())\n+reverse_target_char_index = dict(\n+    (i, char) for char, i in target_token_index.items())\n+\n+\n+def decode_sequence(input_seq):\n+    # Encode the input as state vectors.\n+    states_value = encoder_model.predict(input_seq)\n+\n+    # Generate empty target sequence of length 1.\n+    target_seq = np.zeros((1, 1, num_decoder_tokens))\n+    # Populate the first character of target sequence with the start character.\n+    target_seq[0, 0, target_token_index['\\t']] = 1.\n+\n+    # Sampling loop for a batch of sequences\n+    # (to simplify, here we assume a batch of size 1).\n+    stop_condition = False\n+    decoded_sentence = ''\n+    while not stop_condition:\n+        output_tokens = decoder_model.predict([target_seq] + states_value)\n+\n+        # Sample a token\n+        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n+        sampled_char = reverse_target_char_index[sampled_token_index]\n+        decoded_sentence += sampled_char\n+\n+        # Exit condition: either hit max length\n+        # or find stop character.\n+        if (sampled_char == '\\n' or\n+           len(decoded_sentence) > max_decoder_seq_length):\n+            stop_condition = True\n+\n+        # Add the sampled character to the sequence\n+        char_vector = np.zeros((1, 1, num_decoder_tokens))\n+        char_vector[0, 0, sampled_token_index] = 1.\n+\n+        target_seq = np.concatenate([target_seq, char_vector], axis=1)\n+\n+    return decoded_sentence\n+\n+\n+for seq_index in range(100):\n+    # Take one sequence (part of the training test)\n+    # for trying out decoding.\n+    input_seq = encoder_input_data[seq_index: seq_index + 1]\n+    decoded_sentence = decode_sequence(input_seq)\n+    print('-')\n+    print('Input sentence:', input_texts[seq_index])\n+    print('Decoded sentence:', decoded_sentence)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
