{"custom_id": "scrapy#2b4bcfaf494073520e84bbf301d5141a2e19a3e6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 532 | Contributors (this commit): 12 | Commits (past 90d): 2 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -57,7 +57,6 @@ class Scheduler(object):\n         dupefilter = create_instance(dupefilter_cls, settings, crawler)\n         pqclass = load_object(settings['SCHEDULER_PRIORITY_QUEUE'])\n         if pqclass is PriorityQueue:\n-            # backwards compatibility\n             warnings.warn(\"SCHEDULER_PRIORITY_QUEUE='queuelib.PriorityQueue'\"\n                           \" is no longer supported because of API changes; \"\n                           \"please use 'scrapy.pqueues.ScrapyPriorityQueue'\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#554d8728227a9ea96e5ea3a8a4fd782d42fdbd66", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 537 | Contributors (this commit): 12 | Commits (past 90d): 3 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -77,13 +77,8 @@ class Scheduler(object):\n \n     def open(self, spider):\n         self.spider = spider\n-\n-        # in-memory PriorityQueue instance\n         self.mqs = self._mq()\n-\n-        # on-disk PriorityQueue instance\n         self.dqs = self._dq() if self.dqdir else None\n-\n         return self.df.open()\n \n     def close(self, reason):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#f08f841d0bebd097358889c0c98f83f051828f15", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 5 | Churn Cumulative: 542 | Contributors (this commit): 12 | Commits (past 90d): 4 | Contributors (cumulative): 12 | DMM Complexity: 0.0\n\nDIFF:\n@@ -101,7 +101,7 @@ class Scheduler(object):\n         return True\n \n     def next_request(self):\n-        request = self._mqpop()\n+        request = self.mqs.pop()\n         if request:\n             self.stats.inc_value('scheduler/dequeued/memory', spider=self.spider)\n         else:\n@@ -141,9 +141,6 @@ class Scheduler(object):\n         if self.dqs:\n             return self.dqs.pop()\n \n-    def _mqpop(self):\n-        return self.mqs.pop()\n-\n     def _newmq(self, priority):\n         \"\"\" Factory for creating memory queues. \"\"\"\n         return self.mqclass()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#484bd0d22a11a04ab775ac4f72c75f3ec9050d98", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 134 | Lines Deleted: 8 | Files Changed: 5 | Hunks: 15 | Methods Changed: 8 | Complexity Δ (Sum/Max): 23/10 | Churn Δ: 142 | Churn Cumulative: 2869 | Contributors (this commit): 23 | Commits (past 90d): 29 | Contributors (cumulative): 52 | DMM Complexity: 0.797752808988764\n\nDIFF:\n@@ -2,6 +2,7 @@\n Item Exporters are used to export/serialize items into different formats.\n \"\"\"\n \n+from collections import Mapping\n import csv\n import io\n import sys\n@@ -64,6 +65,14 @@ class BaseItemExporter(object):\n                 field_iter = six.iterkeys(item.fields)\n             else:\n                 field_iter = six.iterkeys(item)\n+        elif isinstance(self.fields_to_export, Mapping):\n+            if include_empty:\n+                field_iter = self.fields_to_export.items()\n+            else:\n+                field_iter = (\n+                    (x, y) for x, y in self.fields_to_export.items()\n+                    if x in item\n+                )\n         else:\n             if include_empty:\n                 field_iter = self.fields_to_export\n@@ -71,13 +80,22 @@ class BaseItemExporter(object):\n                 field_iter = (x for x in self.fields_to_export if x in item)\n \n         for field_name in field_iter:\n-            if field_name in item:\n-                field = {} if isinstance(item, dict) else item.fields[field_name]\n-                value = self.serialize_field(field, field_name, item[field_name])\n+            if isinstance(field_name, six.string_types):\n+                item_field, output_field = field_name, field_name\n+            else:\n+                item_field, output_field = field_name\n+            if item_field in item:\n+                if isinstance(item, dict):\n+                    field = {}\n+                else:\n+                    field = item.fields[item_field]\n+                value = self.serialize_field(\n+                    field, output_field, item[item_field]\n+                )\n             else:\n                 value = default_value\n \n-            yield field_name, value\n+            yield output_field, value\n \n \n class JsonLinesItemExporter(BaseItemExporter):\n@@ -259,7 +277,11 @@ class CsvItemExporter(BaseItemExporter):\n                 else:\n                     # use fields declared in Item\n                     self.fields_to_export = list(item.fields.keys())\n-            row = list(self._build_row(self.fields_to_export))\n+            if isinstance(self.fields_to_export, Mapping):\n+                fields = self.fields_to_export.values()\n+            else:\n+                fields = self.fields_to_export\n+            row = list(self._build_row(fields))\n             self.csv_writer.writerow(row)\n \n \n\n@@ -201,7 +201,8 @@ class FeedExporter(object):\n             raise NotConfigured\n         self.store_empty = settings.getbool('FEED_STORE_EMPTY')\n         self._exporting = False\n-        self.export_fields = settings.getlist('FEED_EXPORT_FIELDS') or None\n+        self.export_fields = settings.getdictorlist('FEED_EXPORT_FIELDS')\n+        self.export_fields = self.export_fields or None\n         self.indent = None\n         if settings.get('FEED_EXPORT_INDENT') is not None:\n             self.indent = settings.getint('FEED_EXPORT_INDENT')\n\n@@ -1,7 +1,7 @@\n import six\n import json\n import copy\n-from collections import MutableMapping\n+from collections import MutableMapping, OrderedDict\n from importlib import import_module\n from pprint import pformat\n \n@@ -198,6 +198,39 @@ class BaseSettings(MutableMapping):\n             value = json.loads(value)\n         return dict(value)\n \n+    def getdictorlist(self, name, default=None):\n+        \"\"\"Get a setting value as either an ``OrderedDict`` or a list.\n+\n+        If the setting is already a dict or a list, a copy of it will be\n+        returned.\n+\n+        If it is a string it will be evaluated as JSON, or as a comma-separated\n+        list of strings as a fallback.\n+\n+        For example, settings populated through environment variables will\n+        return:\n+\n+        -   ``OrdetedDict([('key1', 'value1'), ('key2', 'value2')])`` if set to\n+            ``'{\"key1\": \"value1\", \"key2\": \"value2\"}'``\n+\n+        -   ``['one', 'two']`` if set to ``'[\"one\", \"two\"]'`` or ``'one,two'``\n+\n+        :param name: the setting name\n+        :type name: string\n+\n+        :param default: the value to return if no setting is found\n+        :type default: any\n+        \"\"\"\n+        value = self.get(name, default)\n+        if value is None:\n+            return {}\n+        if isinstance(value, six.string_types):\n+            try:\n+                return json.loads(value, object_pairs_hook=OrderedDict)\n+            except ValueError:\n+                return value.split(',')\n+        return copy.deepcopy(value)\n+\n     def getwithbase(self, name):\n         \"\"\"Get a composition of a dictionary-like setting and its `_BASE`\n         counterpart.\n\n@@ -1,4 +1,7 @@\n+# -*- coding:utf-8 -*-\n+\n from __future__ import absolute_import\n+from collections import OrderedDict\n import re\n import json\n import marshal\n@@ -83,6 +86,14 @@ class BaseItemExporterTest(unittest.TestCase):\n         assert isinstance(name, six.text_type)\n         self.assertEqual(name, u'John\\xa3')\n \n+        ie = self._get_exporter(\n+            fields_to_export=OrderedDict([('name', u'名稱')])\n+        )\n+        self.assertEqual(\n+            list(ie._get_serialized_fields(self.i)),\n+            [(u'名稱', u'John\\xa3')]\n+        )\n+\n     def test_field_custom_serializer(self):\n         def custom_serializer(value):\n             return str(int(value) + 2)\n@@ -214,6 +225,7 @@ class MarshalItemExporterTest(BaseItemExporterTest):\n \n class CsvItemExporterTest(BaseItemExporterTest):\n     def _get_exporter(self, **kwargs):\n+        self.output = tempfile.TemporaryFile()\n         return CsvItemExporter(self.output, **kwargs)\n \n     def assertCsvEqual(self, first, second, msg=None):\n@@ -224,7 +236,8 @@ class CsvItemExporterTest(BaseItemExporterTest):\n         return self.assertEqual(csvsplit(first), csvsplit(second), msg)\n \n     def _check_output(self):\n-        self.assertCsvEqual(to_unicode(self.output.getvalue()), u'age,name\\r\\n22,John\\xa3\\r\\n')\n+        self.output.seek(0)\n+        self.assertCsvEqual(to_unicode(self.output.read()), u'age,name\\r\\n22,John\\xa3\\r\\n')\n \n     def assertExportResult(self, item, expected, **kwargs):\n         fp = BytesIO()\n\n@@ -1,4 +1,5 @@\n from __future__ import absolute_import\n+from collections import OrderedDict\n import os\n import csv\n import json\n@@ -578,6 +579,62 @@ class FeedExportTest(unittest.TestCase):\n         yield self.assertExported(items, header, rows,\n                                   settings=settings, ordered=True)\n \n+        # fields may be defined as a comma-separated list\n+        header = [\"foo\", \"baz\", \"hello\"]\n+        settings = {'FEED_EXPORT_FIELDS': \",\".join(header)}\n+        rows = [\n+            {'foo': 'bar1', 'baz': '',      'hello': ''},\n+            {'foo': 'bar2', 'baz': '',      'hello': 'world2'},\n+            {'foo': 'bar3', 'baz': 'quux3', 'hello': ''},\n+            {'foo': '',     'baz': '',      'hello': 'world4'},\n+        ]\n+        yield self.assertExported(items, header, rows,\n+                                  settings=settings, ordered=True)\n+\n+        # fields may also be defined as a JSON array\n+        header = [\"foo\", \"baz\", \"hello\"]\n+        settings = {'FEED_EXPORT_FIELDS': json.dumps(header)}\n+        rows = [\n+            {'foo': 'bar1', 'baz': '',      'hello': ''},\n+            {'foo': 'bar2', 'baz': '',      'hello': 'world2'},\n+            {'foo': 'bar3', 'baz': 'quux3', 'hello': ''},\n+            {'foo': '',     'baz': '',      'hello': 'world4'},\n+        ]\n+        yield self.assertExported(items, header, rows,\n+                                  settings=settings, ordered=True)\n+\n+        # custom output field names can be specified\n+        header = OrderedDict((\n+            (\"foo\", \"Foo\"),\n+            (\"baz\", \"Baz\"),\n+            (\"hello\", \"Hello\"),\n+        ))\n+        settings = {'FEED_EXPORT_FIELDS': header}\n+        rows = [\n+            {'Foo': 'bar1', 'Baz': '',      'Hello': ''},\n+            {'Foo': 'bar2', 'Baz': '',      'Hello': 'world2'},\n+            {'Foo': 'bar3', 'Baz': 'quux3', 'Hello': ''},\n+            {'Foo': '',     'Baz': '',      'Hello': 'world4'},\n+        ]\n+        yield self.assertExported(items, list(header.values()), rows,\n+                                  settings=settings, ordered=True)\n+\n+        # custom output field names can be specified as a JSON object\n+        header = OrderedDict((\n+            (\"foo\", \"Foo\"),\n+            (\"baz\", \"Baz\"),\n+            (\"hello\", \"Hello\"),\n+        ))\n+        settings = {'FEED_EXPORT_FIELDS': json.dumps(header)}\n+        rows = [\n+            {'Foo': 'bar1', 'Baz': '',      'Hello': ''},\n+            {'Foo': 'bar2', 'Baz': '',      'Hello': 'world2'},\n+            {'Foo': 'bar3', 'Baz': 'quux3', 'Hello': ''},\n+            {'Foo': '',     'Baz': '',      'Hello': 'world4'},\n+        ]\n+        yield self.assertExported(items, list(header.values()), rows,\n+                                  settings=settings, ordered=True)\n+\n     @defer.inlineCallbacks\n     def test_export_dicts(self):\n         # When dicts are used, only keys from the first row are used as\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#f5e0b6b89ace437af850e0225651329101a59862", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 20 | Churn Cumulative: 930 | Contributors (this commit): 12 | Commits (past 90d): 4 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -51,8 +51,8 @@ class Command(ScrapyCommand):\n             help=\"use this callback for parsing, instead looking for a callback\")\n         parser.add_option(\"-m\", \"--meta\", dest=\"meta\",\n             help=\"inject extra meta into the Request, it must be a valid raw json string\")\n-        parser.add_option(\"--cb_kwargs\", dest=\"cb_kwargs\",\n-            help=\"inject extra cb_kwargs into the Request, it must be a valid raw json string\")\n+        parser.add_option(\"--cbkwargs\", dest=\"cbkwargs\",\n+            help=\"inject extra cbkwargs into the Request, it must be a valid raw json string\")\n         parser.add_option(\"-d\", \"--depth\", dest=\"depth\", type=\"int\", default=1,\n             help=\"maximum depth for parsing requests [default: %default]\")\n         parser.add_option(\"-v\", \"--verbose\", dest=\"verbose\", action=\"store_true\",\n@@ -212,9 +212,9 @@ class Command(ScrapyCommand):\n         if opts.meta:\n             request.meta.update(opts.meta)\n \n-        # update cb_kwargs if any extra cb_kwargs was passed through the --cb_kwargs option.\n-        if opts.cb_kwargs:\n-            request.cb_kwargs.update(opts.cb_kwargs)\n+        # update cb_kwargs if any extra values were was passed through the --cbkwargs option.\n+        if opts.cbkwargs:\n+            request.cb_kwargs.update(opts.cbkwargs)\n \n         request.meta['_depth'] = 1\n         request.meta['_callback'] = request.callback\n@@ -243,12 +243,12 @@ class Command(ScrapyCommand):\n                                  \"Example: --meta='{\\\"foo\\\" : \\\"bar\\\"}'\", print_help=False)\n \n     def process_request_cb_kwargs(self, opts):\n-        if opts.cb_kwargs:\n+        if opts.cbkwargs:\n             try:\n-                opts.cb_kwargs = json.loads(opts.cb_kwargs)\n+                opts.cbkwargs = json.loads(opts.cbkwargs)\n             except ValueError:\n-                raise UsageError(\"Invalid --cb_kwargs value, pass a valid json string to --cb_kwargs. \"\n-                                 \"Example: --cb_kwargs='{\\\"foo\\\" : \\\"bar\\\"}'\", print_help=False)\n+                raise UsageError(\"Invalid --cbkwargs value, pass a valid json string to --cbkwargs. \"\n+                                 \"Example: --cbkwargs='{\\\"foo\\\" : \\\"bar\\\"}'\", print_help=False)\n \n     def run(self, args, opts):\n         # parse arguments\n\n@@ -130,7 +130,7 @@ ITEM_PIPELINES = {'%s.pipelines.MyPipeline': 1}\n     def test_request_with_cb_kwargs(self):\n         raw_json_string = '{\"foo\" : \"bar\", \"key\": \"value\"}'\n         _, _, stderr = yield self.execute(['--spider', self.spider_name,\n-                                           '--cb_kwargs', raw_json_string,\n+                                           '--cbkwargs', raw_json_string,\n                                            '-c', 'parse_request_with_cb_kwargs',\n                                            self.url('/html')])\n         self.assertIn(\"DEBUG: It Works!\", _textmode(stderr))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#0522fe35c334141e90741644fec368cdbd12044e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 683 | Contributors (this commit): 12 | Commits (past 90d): 3 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -52,7 +52,7 @@ class Command(ScrapyCommand):\n         parser.add_option(\"-m\", \"--meta\", dest=\"meta\",\n             help=\"inject extra meta into the Request, it must be a valid raw json string\")\n         parser.add_option(\"--cbkwargs\", dest=\"cbkwargs\",\n-            help=\"inject extra cbkwargs into the Request, it must be a valid raw json string\")\n+            help=\"inject extra callback kwargs into the Request, it must be a valid raw json string\")\n         parser.add_option(\"-d\", \"--depth\", dest=\"depth\", type=\"int\", default=1,\n             help=\"maximum depth for parsing requests [default: %default]\")\n         parser.add_option(\"-v\", \"--verbose\", dest=\"verbose\", action=\"store_true\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#7acf4eec792f155a8b0e92c3bb1efa1ff5882ac8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 164 | Contributors (this commit): 9 | Commits (past 90d): 1 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -9,6 +9,9 @@ from gzip import GzipFile\n import six\n import re\n \n+from scrapy.utils.decorators import deprecated\n+\n+\n # - Python>=3.5 GzipFile's read() has issues returning leftover\n #   uncompressed data when input is corrupted\n #   (regression or bug-fix compared to Python 3.4)\n@@ -53,6 +56,7 @@ def gunzip(data):\n _is_gzipped = re.compile(br'^application/(x-)?gzip\\b', re.I).search\n _is_octetstream = re.compile(br'^(application|binary)/octet-stream\\b', re.I).search\n \n+@deprecated\n def is_gzipped(response):\n     \"\"\"Return True if the response is gzipped, or False otherwise\"\"\"\n     ctype = response.headers.get('Content-Type', b'')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#3a493b60661760b26ebc9dd2f4c5c7e4b8df93c9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 5 | Hunks: 6 | Methods Changed: 8 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 12 | Churn Cumulative: 1616 | Contributors (this commit): 29 | Commits (past 90d): 6 | Contributors (cumulative): 48 | DMM Complexity: None\n\nDIFF:\n@@ -94,7 +94,7 @@ class ContractsManager(object):\n             try:\n                 output = cb(response)\n                 output = list(iterate_spider_output(output))\n-            except:\n+            except Exception:\n                 case = _create_testcase(method, 'callback')\n                 results.addError(case, sys.exc_info())\n \n\n@@ -49,7 +49,7 @@ class SpiderMiddlewareManager(MiddlewareManager):\n                                              .format(fname(method), type(result)))\n                 except _InvalidOutput:\n                     raise\n-                except:\n+                except Exception:\n                     return scrape_func(Failure(), request, spider)\n             return scrape_func(response, request, spider)\n \n\n@@ -48,7 +48,7 @@ def mustbe_deferred(f, *args, **kw):\n     # exception in Scrapy - see #125\n     except IgnoreRequest as e:\n         return defer_fail(failure.Failure(e))\n-    except:\n+    except Exception:\n         return defer_fail(failure.Failure())\n     else:\n         return defer_result(result)\n@@ -102,5 +102,5 @@ def iter_errback(iterable, errback, *a, **kw):\n             yield next(it)\n         except StopIteration:\n             break\n-        except:\n+        except Exception:\n             errback(failure.Failure(), *a, **kw)\n\n@@ -86,7 +86,7 @@ def extract_regex(regex, text, encoding='utf-8'):\n \n     try:\n         strings = [regex.search(text).group('extract')]   # named group\n-    except:\n+    except Exception:\n         strings = regex.findall(text)    # full regex or numbered groups\n     strings = flatten(strings)\n \n\n@@ -177,7 +177,7 @@ class Root(Resource):\n         try:\n             from tests import tests_datadir\n             self.putChild(b\"files\", File(os.path.join(tests_datadir, 'test_site/files/')))\n-        except:\n+        except Exception:\n             pass\n         self.putChild(b\"redirect-to\", RedirectTo())\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#aa46e1995cd5cb1099aba17535372b538bd656b3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 12 | Churn Cumulative: 63 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -24,7 +24,11 @@ class CoreStats(object):\n         self.stats.set_value('start_time', datetime.datetime.utcnow(), spider=spider)\n \n     def spider_closed(self, spider, reason):\n-        self.stats.set_value('finish_time', datetime.datetime.utcnow(), spider=spider)\n+        finish_time = datetime.datetime.utcnow()\n+        elapsed_time = finish_time - self.stats.get_value('start_time')\n+        elapsed_time_seconds = elapsed_time.total_seconds()\n+        self.stats.set_value('elapsed_time_seconds', elapsed_time_seconds, spider=spider)\n+        self.stats.set_value('finish_time', finish_time, spider=spider)\n         self.stats.set_value('finish_reason', reason, spider=spider)\n \n     def item_scraped(self, item, spider):\n\n@@ -53,9 +53,5 @@ class TestCloseSpider(TestCase):\n         yield crawler.crawl(total=1000000, mockserver=self.mockserver)\n         reason = crawler.spider.meta['close_reason']\n         self.assertEqual(reason, 'closespider_timeout')\n-        stats = crawler.stats\n-        start = stats.get_value('start_time')\n-        stop = stats.get_value('finish_time')\n-        diff = stop - start\n-        total_seconds = diff.seconds + diff.microseconds\n+        total_seconds = crawler.stats.get_value('elapsed_time_seconds')\n         self.assertTrue(total_seconds >= close_on)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#398639a0bfe749eee07e51249f04b2c6c93eab73", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 44 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 46 | Churn Cumulative: 768 | Contributors (this commit): 13 | Commits (past 90d): 7 | Contributors (cumulative): 20 | DMM Complexity: 0.975\n\nDIFF:\n@@ -132,7 +132,7 @@ class ImagesPipeline(FilesPipeline):\n \n         for thumb_id, size in six.iteritems(self.thumbs):\n             thumb_path = self.thumb_path(request, thumb_id, response=response, info=info)\n-            thumb_image, thumb_buf = self.convert_image(image, size)\n+            thumb_image, thumb_buf = self.convert_image(image, buf, size)\n             yield thumb_path, thumb_image, thumb_buf\n \n     def convert_image(self, image, response_body, size=None):\n@@ -153,7 +153,8 @@ class ImagesPipeline(FilesPipeline):\n             image.thumbnail(size, Image.ANTIALIAS)\n \n         if not size and image.format == 'JPEG':\n-            return image, response_body\n+            buf = BytesIO(response_body.read())\n+            return image, buf\n \n         buf = BytesIO()\n         image.save(buf, 'JPEG')\n\n@@ -83,6 +83,47 @@ class ImagesPipelineTestCase(unittest.TestCase):\n         converted, converted_buf = self.pipeline.convert_image(im, buf)\n         self.assertEqual(converted.mode, 'RGB')\n         self.assertEqual(converted.getcolors(), [(10000, COLOUR)])\n+\n+        # check that we don't convert JPEGs again\n+        buf = io.BytesIO((b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00'\n+        b'\\xff\\xdb\\x00C\\x00\\x08\\x06\\x06\\x07\\x06\\x05\\x08\\x07\\x07\\x07\\t\\t\\x08\\n\\x0c'\n+        b'\\x14\\r\\x0c\\x0b\\x0b\\x0c\\x19\\x12\\x13\\x0f\\x14\\x1d\\x1a\\x1f\\x1e\\x1d\\x1a\\x1c\\x1c '\n+        b'$.\\' \",#\\x1c\\x1c(7),01444\\x1f\\'9=82<.342\\xff\\xdb\\x00C\\x01\\t\\t\\t\\x0c\\x0b\\x0c'\n+        b'\\x18\\r\\r\\x182!\\x1c!222222222222222222222222222222222222222222222222'\n+        b'22\\xff\\xc0\\x00\\x11\\x08\\x00\\x14\\x00\\x14\\x03\\x01\"\\x00\\x02\\x11\\x01\\x03\\x11'\n+        b'\\x01\\xff\\xc4\\x00\\x1f\\x00\\x00\\x01\\x05\\x01\\x01\\x01\\x01\\x01\\x01\\x00'\n+        b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\x0b\\xff\\xc4'\n+        b'\\x00\\xb5\\x10\\x00\\x02\\x01\\x03\\x03\\x02\\x04\\x03\\x05\\x05\\x04\\x04\\x00'\n+        b'\\x00\\x01}\\x01\\x02\\x03\\x00\\x04\\x11\\x05\\x12!1A\\x06\\x13Qa\\x07\"q\\x142\\x81'\n+        b\"\\x91\\xa1\\x08#B\\xb1\\xc1\\x15R\\xd1\\xf0$3br\\x82\\t\\n\\x16\\x17\\x18\\x19\\x1a%&'()*456\"\n+        b'789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\\x83\\x84\\x85\\x86\\x87\\x88\\x89\\x8a'\n+        b'\\x92\\x93\\x94\\x95\\x96\\x97\\x98\\x99\\x9a\\xa2\\xa3\\xa4\\xa5\\xa6\\xa7\\xa8'\n+        b'\\xa9\\xaa\\xb2\\xb3\\xb4\\xb5\\xb6\\xb7\\xb8\\xb9\\xba\\xc2\\xc3\\xc4\\xc5\\xc6'\n+        b'\\xc7\\xc8\\xc9\\xca\\xd2\\xd3\\xd4\\xd5\\xd6\\xd7\\xd8\\xd9\\xda\\xe1\\xe2\\xe3'\n+        b'\\xe4\\xe5\\xe6\\xe7\\xe8\\xe9\\xea\\xf1\\xf2\\xf3\\xf4\\xf5\\xf6\\xf7\\xf8\\xf9'\n+        b'\\xfa\\xff\\xc4\\x00\\x1f\\x01\\x00\\x03\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01'\n+        b'\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\x0b\\xff\\xc4'\n+        b'\\x00\\xb5\\x11\\x00\\x02\\x01\\x02\\x04\\x04\\x03\\x04\\x07\\x05\\x04\\x04\\x00'\n+        b'\\x01\\x02w\\x00\\x01\\x02\\x03\\x11\\x04\\x05!1\\x06\\x12AQ\\x07aq\\x13\"2\\x81\\x08'\n+        b\"\\x14B\\x91\\xa1\\xb1\\xc1\\t#3R\\xf0\\x15br\\xd1\\n\\x16$4\\xe1%\\xf1\\x17\\x18\\x19\\x1a&'\"\n+        b'()*56789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\\x82\\x83\\x84\\x85\\x86\\x87\\x88'\n+        b'\\x89\\x8a\\x92\\x93\\x94\\x95\\x96\\x97\\x98\\x99\\x9a\\xa2\\xa3\\xa4\\xa5\\xa6'\n+        b'\\xa7\\xa8\\xa9\\xaa\\xb2\\xb3\\xb4\\xb5\\xb6\\xb7\\xb8\\xb9\\xba\\xc2\\xc3\\xc4'\n+        b'\\xc5\\xc6\\xc7\\xc8\\xc9\\xca\\xd2\\xd3\\xd4\\xd5\\xd6\\xd7\\xd8\\xd9\\xda\\xe2'\n+        b'\\xe3\\xe4\\xe5\\xe6\\xe7\\xe8\\xe9\\xea\\xf2\\xf3\\xf4\\xf5\\xf6\\xf7\\xf8\\xf9'\n+        b'\\xfa\\xff\\xda\\x00\\x0c\\x03\\x01\\x00\\x02\\x11\\x03\\x11\\x00?\\x00\\xbb'\n+        b'\\xe2\\x1b\\xcb\\x88\\xe4\\x90\\t\\x0e1\\xd2\\xb9\\xab\\x1dF\\xe6\\xda\\xe0\\xb4l\\xd9'\n+        b'5>\\xaf\\xac\\xc7y}$k\\x92\\x03u\\xaaL\\xeb\\x18VL\\x9fZ+\\xb9\\xb9EBV]Ow\\x0f\\x8a\\xc0'\n+        b'\\xac\\x14\\xbd\\xa2NG_\\xa5x\\x8esg\\xfb\\xd9\\x8e\\xed\\xc79\\xa2\\xa1\\xd0\\xf4\\x8bk'\n+        b'\\x9d5e\\xdeN\\xe6=\\xa8\\xae\\xa9V\\xc2\\xb6|\\xdf2\\xeep:w\\xfc\\x84d\\x04g\\x9e\\xf5\\xd3'\n+        b'L\\xa9\\x0c\\x1f*/>\\xa2\\x8a+\\xca\\x93z\\x1c\\x15]\\xa9\\xc6\\xc4Q\\xea\\x97V\\xca'\n+        b'c\\x85\\xc2\\xaes\\x80(\\xa2\\x8a\\xe3\\x92W<\\xdb\\x9f\\xff\\xd9'))\n+        im = Image.open(buf)\n+        buf.seek(0)\n+        converted, converted_buf = self.pipeline.convert_image(im, buf)\n+        converted_buf.seek(0)\n+        buf.seek(0)\n+        self.assertEqual(im.format, \"JPEG\")\n         self.assertEqual(converted_buf.read(), buf.read())\n \n         # check that thumbnail keep image ratio\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#e6048d55f905ca0be2b32f9b566d257f34752c71", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 177 | Contributors (this commit): 8 | Commits (past 90d): 1 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -31,7 +31,7 @@ class DummyPolicy(object):\n     def should_cache_response(self, response, request):\n         return response.status not in self.ignore_http_codes\n \n-    def is_cached_response_fresh(self, response, request):\n+    def is_cached_response_fresh(self, cachedresponse, request):\n         return True\n \n     def is_cached_response_valid(self, cachedresponse, response, request):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#4cfdc14974313f23d7bb8be9311195f9cfa74968", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 179 | Contributors (this commit): 8 | Commits (past 90d): 2 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -70,7 +70,7 @@ class RFC2616Policy(object):\n         return True\n \n     def should_cache_response(self, response, request):\n-        # What is cacheable - https://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec14.9.1\n+        # What is cacheable - https://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9.1\n         # Response cacheability - https://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.4\n         # Status code 206 is not included because cache can not deal with partial contents\n         cc = self._parse_cachecontrol(response)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#d27c2c68ba4f201c18255a6ec8a735f140b13773", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 22 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 24 | Churn Cumulative: 771 | Contributors (this commit): 23 | Commits (past 90d): 4 | Contributors (cumulative): 30 | DMM Complexity: 0.9166666666666666\n\nDIFF:\n@@ -6,7 +6,7 @@ from unittest import TextTestRunner, TextTestResult as _TextTestResult\n \n from scrapy.commands import ScrapyCommand\n from scrapy.contracts import ContractsManager\n-from scrapy.utils.misc import load_object\n+from scrapy.utils.misc import load_object, set_environ\n from scrapy.utils.conf import build_component_list\n \n \n@@ -68,6 +68,7 @@ class Command(ScrapyCommand):\n \n         spider_loader = self.crawler_process.spider_loader\n \n+        with set_environ(SCRAPY_CHECK=True):\n             for spidername in args or spider_loader.list():\n                 spidercls = spider_loader.load(spidername)\n                 spidercls.start_requests = lambda s: conman.from_spider(s, result)\n\n@@ -1,6 +1,8 @@\n \"\"\"Helper functions which don't fit anywhere else\"\"\"\n+import os\n import re\n import hashlib\n+from contextlib import contextmanager\n from importlib import import_module\n from pkgutil import iter_modules\n \n@@ -10,7 +12,6 @@ from w3lib.html import replace_entities\n from scrapy.utils.python import flatten, to_unicode\n from scrapy.item import BaseItem\n \n-\n _ITERABLE_SINGLE_VALUES = dict, BaseItem, six.text_type, bytes\n \n \n@@ -142,3 +143,21 @@ def create_instance(objcls, settings, crawler, *args, **kwargs):\n         return objcls.from_settings(settings, *args, **kwargs)\n     else:\n         return objcls(*args, **kwargs)\n+\n+\n+@contextmanager\n+def set_environ(**kwargs):\n+    \"\"\"Temporarily set environment variables inside the context manager and\n+    fully restore previous environment afterwards\n+    \"\"\"\n+\n+    original_env = {k: os.environ.get(k) for k in kwargs}\n+    os.environ.update(kwargs)\n+    try:\n+        yield\n+    finally:\n+        for k, v in original_env:\n+            if v is None:\n+                del os.environ[k]\n+            else:\n+                os.environ[k] = v\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#50730ed2280dec6384986d34999cd277d7568ff9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 321 | Contributors (this commit): 10 | Commits (past 90d): 2 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -68,7 +68,7 @@ class Command(ScrapyCommand):\n \n         spider_loader = self.crawler_process.spider_loader\n \n-        with set_environ(SCRAPY_CHECK=True):\n+        with set_environ(SCRAPY_CHECK='true'):\n             for spidername in args or spider_loader.list():\n                 spidercls = spider_loader.load(spidername)\n                 spidercls.start_requests = lambda s: conman.from_spider(s, result)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#07adca34e1378b11dff9e3f11d3760c54f5fa1ef", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 454 | Contributors (this commit): 20 | Commits (past 90d): 4 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -156,7 +156,7 @@ def set_environ(**kwargs):\n     try:\n         yield\n     finally:\n-        for k, v in original_env:\n+        for k, v in original_env.items():\n             if v is None:\n                 del os.environ[k]\n             else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c6769d6887b5c311c9083a5ac0349e81d1a2aea7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 45 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 48 | Churn Cumulative: 816 | Contributors (this commit): 13 | Commits (past 90d): 9 | Contributors (cumulative): 20 | DMM Complexity: 0.025\n\nDIFF:\n@@ -151,10 +151,8 @@ class ImagesPipeline(FilesPipeline):\n         if size:\n             image = image.copy()\n             image.thumbnail(size, Image.ANTIALIAS)\n-\n-        if not size and image.format == 'JPEG':\n-            buf = BytesIO(response_body.read())\n-            return image, buf\n+        elif image.format == 'JPEG':\n+            return image, response_body\n \n         buf = BytesIO()\n         image.save(buf, 'JPEG')\n\n@@ -83,48 +83,8 @@ class ImagesPipelineTestCase(unittest.TestCase):\n         converted, converted_buf = self.pipeline.convert_image(im, buf)\n         self.assertEqual(converted.mode, 'RGB')\n         self.assertEqual(converted.getcolors(), [(10000, COLOUR)])\n-\n         # check that we don't convert JPEGs again\n-        buf = io.BytesIO((b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00'\n-        b'\\xff\\xdb\\x00C\\x00\\x08\\x06\\x06\\x07\\x06\\x05\\x08\\x07\\x07\\x07\\t\\t\\x08\\n\\x0c'\n-        b'\\x14\\r\\x0c\\x0b\\x0b\\x0c\\x19\\x12\\x13\\x0f\\x14\\x1d\\x1a\\x1f\\x1e\\x1d\\x1a\\x1c\\x1c '\n-        b'$.\\' \",#\\x1c\\x1c(7),01444\\x1f\\'9=82<.342\\xff\\xdb\\x00C\\x01\\t\\t\\t\\x0c\\x0b\\x0c'\n-        b'\\x18\\r\\r\\x182!\\x1c!222222222222222222222222222222222222222222222222'\n-        b'22\\xff\\xc0\\x00\\x11\\x08\\x00\\x14\\x00\\x14\\x03\\x01\"\\x00\\x02\\x11\\x01\\x03\\x11'\n-        b'\\x01\\xff\\xc4\\x00\\x1f\\x00\\x00\\x01\\x05\\x01\\x01\\x01\\x01\\x01\\x01\\x00'\n-        b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\x0b\\xff\\xc4'\n-        b'\\x00\\xb5\\x10\\x00\\x02\\x01\\x03\\x03\\x02\\x04\\x03\\x05\\x05\\x04\\x04\\x00'\n-        b'\\x00\\x01}\\x01\\x02\\x03\\x00\\x04\\x11\\x05\\x12!1A\\x06\\x13Qa\\x07\"q\\x142\\x81'\n-        b\"\\x91\\xa1\\x08#B\\xb1\\xc1\\x15R\\xd1\\xf0$3br\\x82\\t\\n\\x16\\x17\\x18\\x19\\x1a%&'()*456\"\n-        b'789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\\x83\\x84\\x85\\x86\\x87\\x88\\x89\\x8a'\n-        b'\\x92\\x93\\x94\\x95\\x96\\x97\\x98\\x99\\x9a\\xa2\\xa3\\xa4\\xa5\\xa6\\xa7\\xa8'\n-        b'\\xa9\\xaa\\xb2\\xb3\\xb4\\xb5\\xb6\\xb7\\xb8\\xb9\\xba\\xc2\\xc3\\xc4\\xc5\\xc6'\n-        b'\\xc7\\xc8\\xc9\\xca\\xd2\\xd3\\xd4\\xd5\\xd6\\xd7\\xd8\\xd9\\xda\\xe1\\xe2\\xe3'\n-        b'\\xe4\\xe5\\xe6\\xe7\\xe8\\xe9\\xea\\xf1\\xf2\\xf3\\xf4\\xf5\\xf6\\xf7\\xf8\\xf9'\n-        b'\\xfa\\xff\\xc4\\x00\\x1f\\x01\\x00\\x03\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01'\n-        b'\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\x0b\\xff\\xc4'\n-        b'\\x00\\xb5\\x11\\x00\\x02\\x01\\x02\\x04\\x04\\x03\\x04\\x07\\x05\\x04\\x04\\x00'\n-        b'\\x01\\x02w\\x00\\x01\\x02\\x03\\x11\\x04\\x05!1\\x06\\x12AQ\\x07aq\\x13\"2\\x81\\x08'\n-        b\"\\x14B\\x91\\xa1\\xb1\\xc1\\t#3R\\xf0\\x15br\\xd1\\n\\x16$4\\xe1%\\xf1\\x17\\x18\\x19\\x1a&'\"\n-        b'()*56789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\\x82\\x83\\x84\\x85\\x86\\x87\\x88'\n-        b'\\x89\\x8a\\x92\\x93\\x94\\x95\\x96\\x97\\x98\\x99\\x9a\\xa2\\xa3\\xa4\\xa5\\xa6'\n-        b'\\xa7\\xa8\\xa9\\xaa\\xb2\\xb3\\xb4\\xb5\\xb6\\xb7\\xb8\\xb9\\xba\\xc2\\xc3\\xc4'\n-        b'\\xc5\\xc6\\xc7\\xc8\\xc9\\xca\\xd2\\xd3\\xd4\\xd5\\xd6\\xd7\\xd8\\xd9\\xda\\xe2'\n-        b'\\xe3\\xe4\\xe5\\xe6\\xe7\\xe8\\xe9\\xea\\xf2\\xf3\\xf4\\xf5\\xf6\\xf7\\xf8\\xf9'\n-        b'\\xfa\\xff\\xda\\x00\\x0c\\x03\\x01\\x00\\x02\\x11\\x03\\x11\\x00?\\x00\\xbb'\n-        b'\\xe2\\x1b\\xcb\\x88\\xe4\\x90\\t\\x0e1\\xd2\\xb9\\xab\\x1dF\\xe6\\xda\\xe0\\xb4l\\xd9'\n-        b'5>\\xaf\\xac\\xc7y}$k\\x92\\x03u\\xaaL\\xeb\\x18VL\\x9fZ+\\xb9\\xb9EBV]Ow\\x0f\\x8a\\xc0'\n-        b'\\xac\\x14\\xbd\\xa2NG_\\xa5x\\x8esg\\xfb\\xd9\\x8e\\xed\\xc79\\xa2\\xa1\\xd0\\xf4\\x8bk'\n-        b'\\x9d5e\\xdeN\\xe6=\\xa8\\xae\\xa9V\\xc2\\xb6|\\xdf2\\xeep:w\\xfc\\x84d\\x04g\\x9e\\xf5\\xd3'\n-        b'L\\xa9\\x0c\\x1f*/>\\xa2\\x8a+\\xca\\x93z\\x1c\\x15]\\xa9\\xc6\\xc4Q\\xea\\x97V\\xca'\n-        b'c\\x85\\xc2\\xaes\\x80(\\xa2\\x8a\\xe3\\x92W<\\xdb\\x9f\\xff\\xd9'))\n-        im = Image.open(buf)\n-        buf.seek(0)\n-        converted, converted_buf = self.pipeline.convert_image(im, buf)\n-        converted_buf.seek(0)\n-        buf.seek(0)\n-        self.assertEqual(im.format, \"JPEG\")\n-        self.assertEqual(converted_buf.read(), buf.read())\n+        self.assertEqual(converted_buf, buf)\n \n         # check that thumbnail keep image ratio\n         thumbnail, buf = self.pipeline.convert_image(converted, buf, size=(10, 25))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#6039b66f42fe2c6e7708febb70939952cedaedd0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 587 | Contributors (this commit): 11 | Commits (past 90d): 5 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -87,14 +87,14 @@ class ImagesPipelineTestCase(unittest.TestCase):\n         self.assertEqual(converted_buf, buf)\n \n         # check that thumbnail keep image ratio\n-        thumbnail, buf = self.pipeline.convert_image(converted, buf, size=(10, 25))\n+        thumbnail, _ = self.pipeline.convert_image(converted, converted_buf, size=(10, 25))\n         self.assertEqual(thumbnail.mode, 'RGB')\n         self.assertEqual(thumbnail.size, (10, 10))\n \n         # transparency case: RGBA and PNG\n         COLOUR = (0, 127, 255, 50)\n         im, buf = _create_image('PNG', 'RGBA', SIZE, COLOUR)\n-        converted, buf = self.pipeline.convert_image(im, buf)\n+        converted, _ = self.pipeline.convert_image(im, buf)\n         self.assertEqual(converted.mode, 'RGB')\n         self.assertEqual(converted.getcolors(), [(10000, (205, 230, 255))])\n \n@@ -102,7 +102,7 @@ class ImagesPipelineTestCase(unittest.TestCase):\n         COLOUR = (0, 127, 255, 50)\n         im, buf = _create_image('PNG', 'RGBA', SIZE, COLOUR)\n         im = im.convert('P')\n-        converted, buf = self.pipeline.convert_image(im, buf)\n+        converted, _ = self.pipeline.convert_image(im, buf)\n         self.assertEqual(converted.mode, 'RGB')\n         self.assertEqual(converted.getcolors(), [(10000, (205, 230, 255))])\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#29739989478bb1b10467b036df91326071b1ffbc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 10/10 | Churn Δ: 9 | Churn Cumulative: 144 | Contributors (this commit): 4 | Commits (past 90d): 1 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3,7 +3,7 @@ import os\n import unittest\n \n from scrapy.item import Item, Field\n-from scrapy.utils.misc import arg_to_iter, create_instance, load_object, walk_modules\n+from scrapy.utils.misc import arg_to_iter, create_instance, load_object, walk_modules, set_environ\n \n from tests import mock\n \n@@ -130,5 +130,12 @@ class UtilsMiscTestCase(unittest.TestCase):\n         with self.assertRaises(ValueError):\n             create_instance(m, None, None)\n \n+    def test_set_environ(self):\n+        assert os.environ.get('some_test_environ') is None\n+        with set_environ(some_test_environ='test_value'):\n+            assert os.environ.get('some_test_environ') == 'test_value'\n+        assert os.environ.get('some_test_environ') is None\n+\n+\n if __name__ == \"__main__\":\n     unittest.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#6d52708579be05c29c58d6ccc63486f761466d18", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 150 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -136,6 +136,12 @@ class UtilsMiscTestCase(unittest.TestCase):\n             assert os.environ.get('some_test_environ') == 'test_value'\n         assert os.environ.get('some_test_environ') is None\n \n+        os.environ['some_test_environ'] = 'test'\n+        assert os.environ.get('some_test_environ') == 'test'\n+        with set_environ(some_test_environ='test_value'):\n+            assert os.environ.get('some_test_environ') == 'test_value'\n+        assert os.environ.get('some_test_environ') == 'test'\n+\n \n if __name__ == \"__main__\":\n     unittest.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#2a6bcdb413da0a4202fe905279d46d581368769d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 40 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 8 | Methods Changed: 6 | Complexity Δ (Sum/Max): 8/8 | Churn Δ: 47 | Churn Cumulative: 869 | Contributors (this commit): 13 | Commits (past 90d): 12 | Contributors (cumulative): 20 | DMM Complexity: 0.06060606060606061\n\nDIFF:\n@@ -127,15 +127,41 @@ class ImagesPipeline(FilesPipeline):\n             raise ImageException(\"Image too small (%dx%d < %dx%d)\" %\n                                  (width, height, self.min_width, self.min_height))\n         \n-        image, buf = self.convert_image(orig_image, BytesIO(response.body))\n+        def _is_convert_image_overriden():\n+            import inspect\n+            if six.PY2:\n+                convert_image_signature = inspect.getargspec(self.convert_image)\n+            elif six.PY3:\n+                convert_image_signature = inspect.getfullargspec(self.convert_image)\n+            if 'response_body' not in convert_image_signature.args:\n+                return True\n+            return False\n+\n+        def _warn():\n+            from scrapy.exceptions import ScrapyDeprecationWarning\n+            import warnings\n+            warnings.warn('ImagesPipeline.convert_image() method overriden in a incompatible way, '\n+                          'overriden method does not accept response_body attribute.',\n+                          category=ScrapyDeprecationWarning, stacklevel=1)\n+\n+        convert_image_overriden = _is_convert_image_overriden()\n+        if convert_image_overriden:\n+            _warn()\n+            image, buf = self.convert_image(orig_image)\n+        else:\n+            image, buf = self.convert_image(orig_image, response_body=BytesIO(response.body))\n         yield path, image, buf\n \n         for thumb_id, size in six.iteritems(self.thumbs):\n             thumb_path = self.thumb_path(request, thumb_id, response=response, info=info)\n-            thumb_image, thumb_buf = self.convert_image(image, buf, size)\n+            if convert_image_overriden:\n+                _warn()\n+                thumb_image, thumb_buf = self.convert_image(image, size)\n+            else:\n+                thumb_image, thumb_buf = self.convert_image(image, size, buf)\n             yield thumb_path, thumb_image, thumb_buf\n \n-    def convert_image(self, image, response_body, size=None):\n+    def convert_image(self, image, size=None, response_body=None):\n         if image.format == 'PNG' and image.mode == 'RGBA':\n             background = Image.new('RGBA', image.size, (255, 255, 255))\n             background.paste(image, image)\n@@ -151,6 +177,13 @@ class ImagesPipeline(FilesPipeline):\n         if size:\n             image = image.copy()\n             image.thumbnail(size, Image.ANTIALIAS)\n+        else: \n+            if not response_body:\n+                from scrapy.exceptions import ScrapyDeprecationWarning\n+                import warnings\n+                warnings.warn('ImagesPipeline.convert_image() method called in a incompatible way, '\n+                              'method called without response_body attribute.',\n+                              category=ScrapyDeprecationWarning, stacklevel=1)\n             elif image.format == 'JPEG':\n                 return image, response_body\n                 \n\n@@ -80,21 +80,21 @@ class ImagesPipelineTestCase(unittest.TestCase):\n         # straigh forward case: RGB and JPEG\n         COLOUR = (0, 127, 255)\n         im, buf = _create_image('JPEG', 'RGB', SIZE, COLOUR)\n-        converted, converted_buf = self.pipeline.convert_image(im, buf)\n+        converted, converted_buf = self.pipeline.convert_image(im, response_body=buf)\n         self.assertEqual(converted.mode, 'RGB')\n         self.assertEqual(converted.getcolors(), [(10000, COLOUR)])\n         # check that we don't convert JPEGs again\n         self.assertEqual(converted_buf, buf)\n \n         # check that thumbnail keep image ratio\n-        thumbnail, _ = self.pipeline.convert_image(converted, converted_buf, size=(10, 25))\n+        thumbnail, _ = self.pipeline.convert_image(converted, size=(10, 25), response_body=converted_buf)\n         self.assertEqual(thumbnail.mode, 'RGB')\n         self.assertEqual(thumbnail.size, (10, 10))\n \n         # transparency case: RGBA and PNG\n         COLOUR = (0, 127, 255, 50)\n         im, buf = _create_image('PNG', 'RGBA', SIZE, COLOUR)\n-        converted, _ = self.pipeline.convert_image(im, buf)\n+        converted, _ = self.pipeline.convert_image(im, response_body=buf)\n         self.assertEqual(converted.mode, 'RGB')\n         self.assertEqual(converted.getcolors(), [(10000, (205, 230, 255))])\n \n@@ -102,7 +102,7 @@ class ImagesPipelineTestCase(unittest.TestCase):\n         COLOUR = (0, 127, 255, 50)\n         im, buf = _create_image('PNG', 'RGBA', SIZE, COLOUR)\n         im = im.convert('P')\n-        converted, _ = self.pipeline.convert_image(im, buf)\n+        converted, _ = self.pipeline.convert_image(im, response_body=buf)\n         self.assertEqual(converted.mode, 'RGB')\n         self.assertEqual(converted.getcolors(), [(10000, (205, 230, 255))])\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
