{"custom_id": "keras#cbbe8eb53001ccffe9f02d08ecdaf22997879d19", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 182/182 | Churn Δ: 1 | Churn Cumulative: 1671 | Contributors (this commit): 7 | Commits (past 90d): 9 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -636,7 +636,6 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n                 # Lift variable creation to init scope to avoid environment\n                 # issues.\n                 self.build(trainable_variables)\n-            grads_and_vars = list(zip(grads, trainable_variables))\n             grads_and_vars = optimizer_utils.filter_empty_gradients(\n                 grads_and_vars\n             )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e8aeef54887354b1bc7e818dd98e88b288b53856", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 10 | Files Changed: 4 | Hunks: 8 | Methods Changed: 1 | Complexity Δ (Sum/Max): 62/29 | Churn Δ: 20 | Churn Cumulative: 3089 | Contributors (this commit): 15 | Commits (past 90d): 22 | Contributors (cumulative): 28 | DMM Complexity: None\n\nDIFF:\n@@ -197,14 +197,14 @@ def deserialize(config, custom_objects=None, use_legacy_format=False, **kwargs):\n def convert_to_legacy_optimizer(optimizer):\n     \"\"\"Convert experimental optimizer to legacy optimizer.\n \n-    This function takes in a `tf.keras.optimizers.experimental.Optimizer`\n+    This function takes in a `keras.optimizers.Optimizer`\n     instance and converts it to the corresponding\n-    `tf.keras.optimizers.legacy.Optimizer` instance.\n-    For example, `tf.keras.optimizers.experimental.Adam(...)` to\n-    `tf.keras.optimizers.legacy.Adam(...)`.\n+    `keras.optimizers.legacy.Optimizer` instance.\n+    For example, `keras.optimizers.Adam(...)` to\n+    `keras.optimizers.legacy.Adam(...)`.\n \n     Args:\n-        optimizer: An instance of `tf.keras.optimizers.experimental.Optimizer`.\n+        optimizer: An instance of `keras.optimizers.Optimizer`.\n     \"\"\"\n     # loss_scale_optimizer has a direct dependency of optimizer, import here\n     # rather than top to avoid the cyclic dependency.\n\n@@ -901,7 +901,7 @@ class Optimizer(_BaseOptimizer):\n \n     ```python\n     # Create an optimizer with the desired parameters.\n-    opt = tf.keras.optimizers.experimental.SGD(learning_rate=0.1)\n+    opt = keras.optimizers.SGD(learning_rate=0.1)\n     var1, var2 = tf.Variable(1.0), tf.Variable(2.0)\n     # `loss` is a callable that takes no argument and returns the value\n     # to minimize.\n\n@@ -63,7 +63,7 @@ class RMSprop(optimizer.Optimizer):\n \n     Usage:\n \n-    >>> opt = tf.keras.optimizers.experimental.RMSprop(learning_rate=0.1)\n+    >>> opt = tf.keras.optimizers.RMSprop(learning_rate=0.1)\n     >>> var1 = tf.Variable(10.0)\n     >>> loss = lambda: (var1 ** 2) / 2.0  # d(loss) / d(var1) = var1\n     >>> opt.minimize(loss, [var1])\n\n@@ -55,7 +55,7 @@ class SGD(optimizer.Optimizer):\n \n     Args:\n       learning_rate: A `Tensor`, floating point value, or a schedule that is a\n-        `tf.keras.optimizers.schedules.LearningRateSchedule`, or a callable\n+        `keras.optimizers.schedules.LearningRateSchedule`, or a callable\n         that takes no arguments and returns the actual value to use. The\n         learning rate. Defaults to 0.001.\n       momentum: float hyperparameter >= 0 that accelerates gradient descent in\n@@ -67,7 +67,7 @@ class SGD(optimizer.Optimizer):\n \n     Usage:\n \n-    >>> opt = tf.keras.optimizers.experimental.SGD(learning_rate=0.1)\n+    >>> opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n     >>> var = tf.Variable(1.0)\n     >>> loss = lambda: (var ** 2)/2.0         # d(loss)/d(var1) = var1\n     >>> opt.minimize(loss, [var])\n@@ -75,7 +75,7 @@ class SGD(optimizer.Optimizer):\n     >>> var.numpy()\n     0.9\n \n-    >>> opt = tf.keras.optimizers.experimental.SGD(0.1, momentum=0.9)\n+    >>> opt = tf.keras.optimizers.SGD(0.1, momentum=0.9)\n     >>> var = tf.Variable(1.0)\n     >>> val0 = var.value()\n     >>> loss = lambda: (var ** 2)/2.0         # d(loss)/d(var1) = var1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9d94c40111f825edc2c5e3553d4d845e9cf59c90", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 20/11 | Churn Δ: 5 | Churn Cumulative: 587 | Contributors (this commit): 9 | Commits (past 90d): 9 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -67,7 +67,8 @@ class ReLU(Layer):\n     Args:\n         max_value: Float >= 0. Maximum activation value. None means unlimited.\n             Defaults to `None`.\n-      negative_slope: Float >= 0. Negative slope coefficient. Defaults to `0.`.\n+        negative_slope: Float >= 0. Negative slope coefficient.\n+            Defaults to `0.`.\n         threshold: Float >= 0. Threshold value for thresholded activation.\n             Defaults to `0.`.\n     \"\"\"\n\n@@ -77,7 +77,7 @@ class Softmax(Layer):\n \n \n     Returns:\n-      softmaxed output with the same shape as `inputs`.\n+        Softmaxed output with the same shape as `inputs`.\n     \"\"\"\n \n     def __init__(self, axis=-1, **kwargs):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4093239db456776b9829d3db9a557c2b6974237a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 28 | Files Changed: 4 | Hunks: 11 | Methods Changed: 1 | Complexity Δ (Sum/Max): 89/37 | Churn Δ: 58 | Churn Cumulative: 2971 | Contributors (this commit): 11 | Commits (past 90d): 9 | Contributors (cumulative): 30 | DMM Complexity: None\n\nDIFF:\n@@ -56,24 +56,24 @@ class AdditiveAttention(BaseDenseAttention):\n         inputs: List of the following tensors:\n             * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n             * value: Value `Tensor` of shape `[batch_size, Tv, dim]`.\n-        * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`. If not\n-          given, will use `value` for both `key` and `value`, which is the\n-          most common case.\n+            * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`.\n+                If not given, will use `value` for both `key` and `value`,\n+                which is the most common case.\n         mask: List of the following tensors:\n             * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`.\n                 If given, the output will be zero at the positions where\n                 `mask==False`.\n             * value_mask: A boolean mask `Tensor` of shape `[batch_size, Tv]`.\n-          If given, will apply the mask such that values at positions where\n-          `mask==False` do not contribute to the result.\n+                If given, will apply the mask such that values at positions\n+                where `mask==False` do not contribute to the result.\n         training: Python boolean indicating whether the layer should behave in\n             training mode (adding dropout) or in inference mode (no dropout).\n         return_attention_scores: bool, it `True`, returns the attention scores\n             (after masking and softmax) as an additional output argument.\n-      use_causal_mask: Boolean. Set to `True` for decoder self-attention. Adds a\n-        mask such that position `i` cannot attend to positions `j > i`. This\n-        prevents the flow of information from the future towards the past.\n-        Defaults to `False`.\n+        use_causal_mask: Boolean. Set to `True` for decoder self-attention. Adds\n+            a mask such that position `i` cannot attend to positions `j > i`.\n+            This prevents the flow of information from the future towards the\n+            past. Defaults to `False`.\n \n     Output:\n \n\n@@ -44,37 +44,38 @@ class Attention(BaseDenseAttention):\n          `return tf.matmul(distribution, value)`.\n \n     Args:\n-      use_scale: If `True`, will create a scalar variable to scale the attention\n-        scores.\n+        use_scale: If `True`, will create a scalar variable to scale the\n+            attention scores.\n         dropout: Float between 0 and 1. Fraction of the units to drop for the\n             attention scores. Defaults to 0.0.\n         score_mode: Function to use to compute attention scores, one of\n-        `{\"dot\", \"concat\"}`. `\"dot\"` refers to the dot product between the query\n-        and key vectors. `\"concat\"` refers to the hyperbolic tangent of the\n-        concatenation of the query and key vectors.\n+            `{\"dot\", \"concat\"}`. `\"dot\"` refers to the dot product between the\n+            query and key vectors. `\"concat\"` refers to the hyperbolic tangent\n+            of the concatenation of the query and key vectors.\n \n     Call Args:\n \n         inputs: List of the following tensors:\n             * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n             * value: Value `Tensor` of shape `[batch_size, Tv, dim]`.\n-        * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`. If not\n-          given, will use `value` for both `key` and `value`, which is the\n-          most common case.\n+            * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`. If\n+                not given, will use `value` for both `key` and `value`, which is\n+                the most common case.\n         mask: List of the following tensors:\n             * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`.\n                 If given, the output will be zero at the positions where\n                 `mask==False`.\n             * value_mask: A boolean mask `Tensor` of shape `[batch_size, Tv]`.\n-          If given, will apply the mask such that values at positions where\n-          `mask==False` do not contribute to the result.\n+                If given, will apply the mask such that values at positions\n+                 where `mask==False` do not contribute to the result.\n         return_attention_scores: bool, it `True`, returns the attention scores\n             (after masking and softmax) as an additional output argument.\n         training: Python boolean indicating whether the layer should behave in\n             training mode (adding dropout) or in inference mode (no dropout).\n-      use_causal_mask: Boolean. Set to `True` for decoder self-attention. Adds a\n-        mask such that position `i` cannot attend to positions `j > i`. This\n-        prevents the flow of information from the future towards the past.\n+        use_causal_mask: Boolean. Set to `True` for decoder self-attention. Adds\n+            a mask such that position `i` cannot attend to positions `j > i`.\n+            This prevents the flow of information from the future towards the\n+            past.\n             Defaults to `False`.\n \n     Output:\n\n@@ -46,9 +46,9 @@ class BaseDenseAttention(base_layer.BaseRandomLayer):\n         inputs: List of the following tensors:\n             * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n             * value: Value `Tensor` of shape `[batch_size, Tv, dim]`.\n-        * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`. If not\n-          given, will use `value` for both `key` and `value`, which is the most\n-          common case.\n+            * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`. If\n+                not given, will use `value` for both `key` and `value`, which is\n+                the most common case.\n         mask: List of the following tensors:\n             * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`. If\n                 given, the output will be zero at the positions where `mask==False`.\n@@ -107,8 +107,9 @@ class BaseDenseAttention(base_layer.BaseRandomLayer):\n         * Use `query` tensor of shape `[batch_size, Tq]` and `key` tensor of\n             shape `[batch_size, Tv]` to calculate the attention `scores`.\n         * Pass `scores` and `value` tensors to this method. The method applies\n-          `scores_mask`, calculates `attention_distribution = softmax(scores)`,\n-          then returns `matmul(attention_distribution, value).\n+            `scores_mask`, calculates\n+            `attention_distribution = softmax(scores)`, then returns\n+            `matmul(attention_distribution, value).\n         * Apply `query_mask` and return the result.\n \n         Args:\n\n@@ -1,4 +1,4 @@\n-# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n+\"\"# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#45112441b114b4e30e826035edb7f908f6b51727", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 22 | Churn Cumulative: 2058 | Contributors (this commit): 10 | Commits (past 90d): 6 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -50,11 +50,12 @@ class BaseDenseAttention(base_layer.BaseRandomLayer):\n                 not given, will use `value` for both `key` and `value`, which is\n                 the most common case.\n         mask: List of the following tensors:\n-            * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`. If\n-                given, the output will be zero at the positions where `mask==False`.\n-            * value_mask: A boolean mask `Tensor` of shape `[batch_size, Tv]`. If\n-                given, will apply the mask such that values at positions where\n-                `mask==False` do not contribute to the result.\n+            * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`.\n+                If given, the output will be zero at the positions where\n+                `mask==False`.\n+            * value_mask: A boolean mask `Tensor` of shape `[batch_size, Tv]`.\n+                If given, will apply the mask such that values at positions\n+                 where `mask==False` do not contribute to the result.\n         training: Python boolean indicating whether the layer should behave in\n             training mode (adding dropout) or in inference mode (no dropout).\n         return_attention_scores: bool, if `True`, returns the attention scores\n@@ -115,13 +116,14 @@ class BaseDenseAttention(base_layer.BaseRandomLayer):\n         Args:\n             scores: Scores float tensor of shape `[batch_size, Tq, Tv]`.\n             value: Value tensor of shape `[batch_size, Tv, dim]`.\n-            scores_mask: A boolean mask `Tensor` of shape `[batch_size, 1, Tv]` or\n-                `[batch_size, Tq, Tv]`. If given, scores at positions where\n+            scores_mask: A boolean mask `Tensor` of shape `[batch_size, 1, Tv]`\n+                or `[batch_size, Tq, Tv]`. If given, scores at positions where\n                 `scores_mask==False` do not contribute to the result. It must\n                 contain at least one `True` value in each line along the last\n                 dimension.\n-            training: Python boolean indicating whether the layer should behave in\n-                training mode (adding dropout) or in inference mode (no dropout).\n+            training: Python boolean indicating whether the layer should behave\n+                in training mode (adding dropout) or in inference mode\n+                (no dropout).\n \n         Returns:\n             Tensor of shape `[batch_size, Tq, dim]`.\n\n@@ -1,4 +1,4 @@\n-\"\"# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n+# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#de0886f0fb836ccc733012cf7e7eb8fb28dc1a27", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 5 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 390 | Contributors (this commit): 1 | Commits (past 90d): 9 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -1,7 +1,7 @@\n from keras_core import backend\n from keras_core.engine.layer import Layer\n from keras_core.backend import KerasTensor\n-from keras_core.engine.function import Function\n+from keras_core.operations.function import Function\n from keras_core import initializers\n from keras_core.operations import numpy as knp\n \n\n@@ -1,5 +1,5 @@\n from keras_core.backend import keras_tensor\n-from keras_core.engine import function\n+from keras_core.operations import function\n from keras_core.operations import numpy as knp\n from keras_core import testing\n from keras_core import backend\n\n@@ -1,4 +1,4 @@\n-from keras_core.engine.function import Function\n+from keras_core.operations.function import Function\n from keras_core.engine.model import Model\n from keras_core.engine.layer import Layer\n \n\n\n@@ -1,7 +1,7 @@\n from keras_core import backend\n from keras_core.engine.layer import Layer\n from keras_core.backend import KerasTensor\n-from keras_core.engine.function import Function\n+from keras_core.operations.function import Function\n from keras_core import initializers\n from keras_core.operations import numpy as knp\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#54d1d4e6d31402884c4d6ec6309a8231ab901366", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 7 | Files Changed: 9 | Hunks: 8 | Methods Changed: 0 | Complexity Δ (Sum/Max): 138/135 | Churn Δ: 16 | Churn Cumulative: 649 | Contributors (this commit): 1 | Commits (past 90d): 18 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -1,5 +1,5 @@\n from keras_core import backend\n-from keras_core.engine.layer import Layer\n+from keras_core.layers.layer import Layer\n from keras_core.backend import KerasTensor\n from keras_core.operations.function import Function\n from keras_core import initializers\n\n@@ -1,7 +1,7 @@\n from keras_core import operations as ops\n from keras_core import backend\n from keras_core.optimizers import SGD\n-from keras_core.engine.layer import Layer\n+from keras_core.layers.layer import Layer\n from keras_core import initializers\n import jax\n from jax import numpy as jnp\n\n@@ -1,5 +1,5 @@\n from keras_core.api_export import keras_core_export\n-from keras_core.engine.layer import Layer\n+from keras_core.layers.layer import Layer\n from keras_core.backend import Trainer\n \n \n\n\n@@ -20,7 +20,7 @@ from keras_core import backend\n from keras_core.engine.tracking import Tracker\n from keras_core.metrics.metric import Metric\n from keras_core import utils\n-from keras_core.engine import input_spec\n+from keras_core.layers import input_spec\n from tensorflow import nest\n from tensorflow import keras as tf_keras\n import numpy as np\n\n@@ -1,6 +1,6 @@\n from keras_core import testing\n from keras_core.engine import keras_tensor\n-from keras_core.engine.layer import Layer\n+from keras_core.layers.layer import Layer\n import numpy as np\n \n \n\n@@ -1,6 +1,6 @@\n from keras_core.operations.function import Function\n from keras_core.engine.model import Model\n-from keras_core.engine.layer import Layer\n+from keras_core.layers.layer import Layer\n \n \n class Functional(Function, Model):\n\n@@ -1,3 +1,5 @@\n+\n+\n class Sequential(Model):\n     def __init__(self, layers, trainable=True, name=None):\n         pass\n\n@@ -1,5 +1,5 @@\n from keras_core import backend\n-from keras_core.engine.layer import Layer\n+from keras_core.layers.layer import Layer\n from keras_core.backend import KerasTensor\n from keras_core.operations.function import Function\n from keras_core import initializers\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#701d4cf7bcc07e5a81c40f857b83bce6d5a4c9b7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 20 | Files Changed: 22 | Hunks: 16 | Methods Changed: 0 | Complexity Δ (Sum/Max): 98/56 | Churn Δ: 40 | Churn Cumulative: 1991 | Contributors (this commit): 1 | Commits (past 90d): 36 | Contributors (cumulative): 22 | DMM Complexity: None\n\nDIFF:\n@@ -3,7 +3,7 @@ import numpy as np\n from keras_core.backend.common import KerasVariable\n from keras_core.backend.common import standardize_dtype\n from keras_core.backend.keras_tensor import KerasTensor\n-from keras_core.engine.naming import auto_name\n+from keras_core.utils.naming import auto_name\n from keras_core.backend.common import in_stateless_scope\n from keras_core.backend.common import get_stateless_scope\n from keras_core.backend.common import StatelessScope\n\n@@ -1,4 +1,4 @@\n-from keras_core.engine.naming import auto_name\n+from keras_core.utils.naming import auto_name\n from tensorflow import nest\n \n \n\n@@ -3,7 +3,7 @@ from tensorflow.experimental import numpy as tfnp\n from keras_core.backend.common import KerasVariable\n from keras_core.backend.common import standardize_dtype\n from keras_core.backend.keras_tensor import KerasTensor\n-from keras_core.engine.naming import auto_name\n+from keras_core.utils.naming import auto_name\n from keras_core.backend.tensorflow.trainer import Trainer\n from keras_core.backend.common import in_stateless_scope\n from keras_core.backend.common import get_stateless_scope\n\n@@ -1,4 +1,4 @@\n-from keras_core.engine import trainer\n+from keras_core.trainers import trainer\n import tensorflow as tf\n \n \n\n\n@@ -14,10 +14,10 @@ And some more magic:\n - metric tracking\n - RNG seed tracking\n \"\"\"\n-from keras_core.engine.operation import Operation\n+from keras_core.operations.operation import Operation\n from keras_core.backend import KerasTensor\n from keras_core import backend\n-from keras_core.engine.tracking import Tracker\n+from keras_core.utils.tracking import Tracker\n from keras_core.metrics.metric import Metric\n from keras_core import utils\n from keras_core.layers import input_spec\n\n@@ -1,6 +1,6 @@\n from keras_core import operations as ops\n from keras_core import backend\n-from keras_core.engine.naming import auto_name\n+from keras_core.utils.naming import auto_name\n \n \n class Loss:\n\n@@ -1,6 +1,6 @@\n from keras_core import backend\n-from keras_core.engine.tracking import Tracker\n-from keras_core.engine.naming import auto_name\n+from keras_core.utils.tracking import Tracker\n+from keras_core.utils.naming import auto_name\n \n \n class Metric:\n\n@@ -1,5 +1,5 @@\n from keras_core.operations.function import Function\n-from keras_core.engine.model import Model\n+from keras_core.models.model import Model\n from keras_core.layers.layer import Layer\n \n \n\n\n@@ -1,6 +1,6 @@\n from keras_core.backend import KerasTensor\n-from keras_core.engine.operation import Operation\n-from keras_core.engine.naming import auto_name\n+from keras_core.operations.operation import Operation\n+from keras_core.utils.naming import auto_name\n from tensorflow import nest\n import collections\n \n\n\n@@ -1,7 +1,7 @@\n import collections\n from tensorflow import nest\n from keras_core.backend import KerasTensor\n-from keras_core.engine.symbolic_arguments import SymbolicArguments\n+from keras_core.operations.symbolic_arguments import SymbolicArguments\n \n \n class Node:\n\n@@ -20,8 +20,8 @@ ones\n from keras_core.backend import KerasTensor\n from keras_core.backend import any_symbolic_tensors\n from keras_core.backend import convert_to_tensor\n-from keras_core.engine.symbolic_arguments import SymbolicArguments\n-from keras_core.engine.operation import Operation\n+from keras_core.operations.symbolic_arguments import SymbolicArguments\n+from keras_core.operations.operation import Operation\n from keras_core import backend\n \n from tensorflow import nest\n\n@@ -1,6 +1,6 @@\n from keras_core.backend.keras_tensor import any_symbolic_tensors\n-from keras_core.engine.node import Node\n-from keras_core.engine.naming import auto_name\n+from keras_core.operations.node import Node\n+from keras_core.utils.naming import auto_name\n from keras_core import backend\n \n \n\n@@ -1,4 +1,4 @@\n-from keras_core.engine import operation\n+from keras_core.operations import operation\n from keras_core.engine import keras_tensor\n from keras_core.operations import numpy as knp\n from keras_core import backend\n\n\n@@ -1,9 +1,9 @@\n from keras_core import backend\n from keras_core import operations as ops\n-from keras_core.engine.tracking import Tracker\n+from keras_core.utils.tracking import Tracker\n from keras_core import initializers\n from keras_core.optimizers.schedules import learning_rate_schedule\n-from keras_core.engine.naming import auto_name\n+from keras_core.utils.naming import auto_name\n import re\n import warnings\n \n\n\n\n\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#377fcdb91e0ae4818a145c0340473f343b13fdfe", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 1 | Files Changed: 8 | Hunks: 15 | Methods Changed: 0 | Complexity Δ (Sum/Max): 57/57 | Churn Δ: 17 | Churn Cumulative: 1261 | Contributors (this commit): 1 | Commits (past 90d): 21 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -1,6 +1,8 @@\n import warnings\n+from keras_core.api_export import keras_core_export\n \n \n+@keras_core_export([\"keras_core.Initializer\", \"keras_core.initializers.Initializer\"])\n class Initializer:\n     \"\"\"Initializer base class: all Keras initializers inherit from this class.\n \n\n@@ -1,7 +1,9 @@\n from keras_core import backend\n from tensorflow import nest\n+from keras_core.api_export import keras_core_export\n \n \n+@keras_core_export([\"keras_core.InputSpec\", \"keras_core.layers.InputSpec\"])\n class InputSpec:\n     \"\"\"Specifies the rank, dtype and shape of every input to a layer.\n \n\n@@ -21,6 +21,7 @@ from keras_core.utils.tracking import Tracker\n from keras_core.metrics.metric import Metric\n from keras_core import utils\n from keras_core.layers import input_spec\n+from keras_core.api_export import keras_core_export\n from tensorflow import nest\n from tensorflow import keras as tf_keras\n import numpy as np\n@@ -29,6 +30,7 @@ import threading\n import collections\n \n \n+@keras_core_export([\"keras_core.Layer\", \"keras_core.layers.Layer\"])\n class Layer(Operation):\n     def __init__(self, trainable=True, dtype=None, name=None):\n         super().__init__(name=name)\n\n@@ -1,8 +1,10 @@\n from keras_core import operations as ops\n from keras_core import backend\n from keras_core.utils.naming import auto_name\n+from keras_core.api_export import keras_core_export\n \n \n+@keras_core_export([\"keras_core.Loss\", \"keras_core.losses.Loss\"])\n class Loss:\n     def __init__(self, name=None, reduction=\"sum_over_batch_size\"):\n         self.name = name or auto_name(self.__class__.__name__)\n\n@@ -1,8 +1,10 @@\n from keras_core import backend\n from keras_core.utils.tracking import Tracker\n from keras_core.utils.naming import auto_name\n+from keras_core.api_export import keras_core_export\n \n \n+@keras_core_export([\"keras_core.Metric\", \"keras_core.metrics.Metric\"])\n class Metric:\n     def __init__(self, dtype=None, name=None):\n         self.name = name or auto_name(self.__class__.__name__)\n\n@@ -1,5 +1,8 @@\n+from keras_core.api_export import keras_core_export\n+from keras_core.models.model import Model\n \n \n+@keras_core_export([\"keras_core.Sequential\", \"keras_core.models.Sequential\"])\n class Sequential(Model):\n     def __init__(self, layers, trainable=True, name=None):\n         pass\n\n@@ -4,10 +4,12 @@ from keras_core.utils.tracking import Tracker\n from keras_core import initializers\n from keras_core.optimizers.schedules import learning_rate_schedule\n from keras_core.utils.naming import auto_name\n+from keras_core.api_export import keras_core_export\n import re\n import warnings\n \n \n+@keras_core_export([\"keras_core.Optimizer\", \"keras_core.optimizers.Optimizer\"])\n class Optimizer:\n     # TODO: support jit_compile\n     def __init__(\n\n@@ -3,7 +3,7 @@ from keras_core import operations as ops\n from keras_core.api_export import keras_core_export\n \n \n-@keras_core_export(\"keras_core.regularizers.Regularizer\")\n+@keras_core_export([\"keras_core.Regularizer\", \"keras_core.regularizers.Regularizer\"])\n class Regularizer:\n     \"\"\"Regularizer base class.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#93f41ce9a54f363bd975c9b0bc3ac9f330b78b0d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 49 | Files Changed: 1 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 50 | Churn Cumulative: 247 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -83,22 +83,6 @@ class MyModel(Layer):\n         return self.dense2(x)\n \n \n-# class Optimizer:\n-#     @property\n-#     def variables(self):\n-#         return []\n-\n-#     def build(self, variables):\n-#         pass\n-\n-#     def stateless_apply_gradients(self, vars_and_grads, optimizer_variables):\n-#         new_values = []\n-#         for v, g in vars_and_grads:\n-#             new_v = v - g * 0.001\n-#             new_values.append(new_v)\n-#         return new_values, optimizer_variables\n-\n-\n def Dataset():\n     for _ in range(10):\n         yield (np.random.random((8, 4)), np.random.random((8, 2)))\n@@ -120,7 +104,7 @@ optimizer.build(model.trainable_variables)\n \n \n ################################\n-## Currently achievable workflow\n+## Currently operational workflow\n \n \n def compute_loss_and_updates(trainable_variables, non_trainable_variables, x, y):\n@@ -160,36 +144,4 @@ for variable, value in zip(model.trainable_variables, trainable_variables):\n for variable, value in zip(model.non_trainable_variables, non_trainable_variables):\n     variable.assign(value)\n \n-\n print(\"Updated values\")\n-\n-\n-# ####################\n-# ## Alternative workflow\n-\n-\n-# def compute_loss_and_updates(trainable_variables, non_trainable_variables, x, y):\n-#     y_pred, updates = model.stateless_call(\n-#         trainable_variables, non_trainable_variables, x\n-#     )\n-#     loss = loss_fn(y, y_pred)\n-#     return loss, updates\n-\n-\n-# grad_fn = jax.value_and_grad(compute_loss_and_updates, has_aux=True)\n-\n-\n-# @jax.jit\n-# def train_step(trainable_variables, non_trainable_variables, x, y):\n-#     (loss, updates), grads = grad_fn(trainable_variables, non_trainable_variables, x, y)\n-#     updates += optimizer.get_updates(zip(trainable_variables, grads))\n-#     return updates\n-\n-\n-# trainable_variables = model.trainable_variables\n-# non_trainable_variables = model.non_trainable_variables\n-\n-# for x, y in dataset:\n-#     updates = train_step(trainable_variables, non_trainable_variables, x, y)\n-#     for variable, value in updates:\n-#         variable.assign(value)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6ccb50ba47def1977c94b603447b10fd19a6fdd9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 98 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 4 | Complexity Δ (Sum/Max): 8/8 | Churn Δ: 98 | Churn Cumulative: 491 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -391,3 +391,101 @@ def compute_fans(shape):\n         fan_in = shape[-2] * receptive_field_size\n         fan_out = shape[-1] * receptive_field_size\n     return int(fan_in), int(fan_out)\n+\n+\n+class RandomNormal(Initializer):\n+    \"\"\"Random normal initializer.\n+\n+    Draws samples from a normal distribution for given parameters.\n+\n+    Examples:\n+\n+    >>> # Standalone usage:\n+    >>> initializer = RandomNormal(mean=0.0, stddev=1.0)\n+    >>> values = initializer(shape=(2, 2))\n+\n+    >>> # Usage in a Keras layer:\n+    >>> initializer = RandomNormal(mean=0.0, stddev=1.0)\n+    >>> layer = Dense(3, kernel_initializer=initializer)\n+\n+    Args:\n+        mean: A python scalar or a scalar keras tensor. Mean of the random values to\n+            generate.\n+        stddev: A python scalar or a scalar keras tensor. Standard deviation of the\n+           random values to generate.\n+        seed: A Python integer or instance of\n+            `keras_core.backend.RandomSeedGenerator`.\n+            Used to make the behavior of the initializer\n+            deterministic. Note that an initializer seeded with an integer\n+            or None (unseeded) will produce the same random values\n+            across multiple calls. To get different random values\n+            across multiple calls, use as seed an instance\n+            of `keras_core.backend.RandomSeedGenerator`.\n+    \"\"\"\n+\n+    def __init__(self, mean=0.0, stddev=1.0, seed=None):\n+        self.mean = mean\n+        self.stddev = stddev\n+        self.seed = seed or random.make_default_seed()\n+        super().__init__()\n+\n+    def __call__(self, shape, dtype=None, **kwargs):\n+        return random.normal(\n+            shape=shape,\n+            mean=self.mean,\n+            stddev=self.stddev,\n+            seed=self.seed,\n+            dtype=dtype\n+        )\n+\n+    def get_config(self):\n+        return {\"mean\": self.mean, \"stddev\":self.stddev, \"seed\":self.seed}\n+\n+\n+class RandomUniform(Initializer):\n+    \"\"\"Random uniform initializer.\n+\n+    Draws samples from a uniform distribution for given parameters.\n+\n+    Examples:\n+\n+    >>> # Standalone usage:\n+    >>> initializer = RandomNormal(mean=0.0, stddev=1.0)\n+    >>> values = initializer(shape=(2, 2))\n+\n+    >>> # Usage in a Keras layer:\n+    >>> initializer = RandomNormal(mean=0.0, stddev=1.0)\n+    >>> layer = Dense(3, kernel_initializer=initializer)\n+\n+    Args:\n+        minval: A python scalar or a scalar keras tensor. Lower bound of the range of\n+            random values to generate (inclusive).\n+        maxval: A python scalar or a scalar keras tensor. Upper bound of the range of\n+            random values to generate (exclusive).\n+        seed: A Python integer or instance of\n+            `keras_core.backend.RandomSeedGenerator`.\n+            Used to make the behavior of the initializer\n+            deterministic. Note that an initializer seeded with an integer\n+            or None (unseeded) will produce the same random values\n+            across multiple calls. To get different random values\n+            across multiple calls, use as seed an instance\n+            of `keras_core.backend.RandomSeedGenerator`.\n+    \"\"\"\n+\n+    def __init__(self, minval=0.0, maxval=1.0, seed=None):\n+        self.minval = minval\n+        self.maxval = maxval\n+        self.seed = seed or random.make_default_seed()\n+        super().__init__()\n+\n+    def __call__(self, shape, dtype=None, **kwargs):\n+        return random.uniform(\n+            shape=shape,\n+            minval=self.minval,\n+            maxval=self.maxval,\n+            seed=self.seed,\n+            dtype=dtype\n+        )\n+\n+    def get_config(self):\n+        return {\"minval\": self.minval, \"maxval\":self.maxval, \"seed\":self.seed}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#de47e8f778ad6b339aeeac37b4e53414eb8d49af", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 3 | Complexity Δ (Sum/Max): 48/48 | Churn Δ: 2 | Churn Cumulative: 794 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -339,7 +339,7 @@ class ExactEvaluationTest(tf.test.TestCase, parameterized.TestCase):\n         metric_name = \"custom_acc\" if custom_metric else \"accuracy\"\n         expected_results = {metric_name: expected_acc}\n \n-        def kill_and_revive_in_thread(wait_secs=2):\n+        def kill_and_revive_in_thread(wait_secs=0.1):\n             def _kill_and_revive_fn():\n                 time.sleep(wait_secs)\n                 logging.info(\"Killing 2 workers\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3c119a6928ec413ba6004228ae1da29c7706d199", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 495 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -450,11 +450,11 @@ class RandomUniform(Initializer):\n     Examples:\n \n     >>> # Standalone usage:\n-    >>> initializer = RandomNormal(mean=0.0, stddev=1.0)\n+    >>> initializer = RandomUniform(minval=0.0, maxval=1.0)\n     >>> values = initializer(shape=(2, 2))\n \n     >>> # Usage in a Keras layer:\n-    >>> initializer = RandomNormal(mean=0.0, stddev=1.0)\n+    >>> initializer = RandomUniform(minval=0.0, maxval=1.0)\n     >>> layer = Dense(3, kernel_initializer=initializer)\n \n     Args:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bcb0e8bc686df15dbbc905503ec9fc337bbabbb9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 355 | Lines Deleted: 303 | Files Changed: 3 | Hunks: 54 | Methods Changed: 26 | Complexity Δ (Sum/Max): 287/176 | Churn Δ: 658 | Churn Cumulative: 7823 | Contributors (this commit): 43 | Commits (past 90d): 12 | Contributors (cumulative): 56 | DMM Complexity: 0.0\n\nDIFF:\n@@ -25,6 +25,7 @@ import tensorflow.compat.v2 as tf\n \n from keras import initializers\n from keras.utils import io_utils\n+from keras.utils import text_rendering\n \n # isort: off\n from tensorflow.python.util.tf_export import keras_export\n@@ -249,7 +250,7 @@ def print_dtensor_variable_summary(model, print_fn, line_length):\n \n def readable_memory_size(weight_memory_size):\n     \"\"\"Convert the weight memory size (Bytes) to a readable string.\"\"\"\n-    units = [\"Byte\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\n+    units = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\n     scale = 1024\n     for unit in units:\n         if weight_memory_size / scale < 1:\n@@ -387,83 +388,36 @@ def print_summary(\n                     break\n \n     if sequential_like:\n-        line_length = line_length or 65\n+        line_length = line_length or 84\n         positions = positions or [0.45, 0.85, 1.0]\n-        if positions[-1] <= 1:\n-            positions = [int(line_length * p) for p in positions]\n         # header names for the different log elements\n-        to_display = [\"Layer (type)\", \"Output Shape\", \"Param #\"]\n+        header = [\"Layer (type)\", \"Output Shape\", \"Param #\"]\n     else:\n-        line_length = line_length or 98\n+        line_length = line_length or 100\n         positions = positions or [0.3, 0.6, 0.70, 1.0]\n-        if positions[-1] <= 1:\n-            positions = [int(line_length * p) for p in positions]\n         # header names for the different log elements\n-        to_display = [\"Layer (type)\", \"Output Shape\", \"Param #\", \"Connected to\"]\n+        header = [\"Layer (type)\", \"Output Shape\", \"Param #\", \"Connected to\"]\n         relevant_nodes = []\n         for v in model._nodes_by_depth.values():\n             relevant_nodes += v\n \n     if show_trainable:\n-        line_length += 11\n-        positions.append(line_length)\n-        to_display.append(\"Trainable\")\n+        line_length += 8\n+        positions = [p * 0.86 for p in positions] + [1.0]\n+        header.append(\"Trainable\")\n \n     layer_range = get_layer_index_bound_by_layer_name(model, layer_range)\n \n-    def print_row(fields, positions, nested_level=0):\n-        left_to_print = [str(x) for x in fields]\n-        while any(left_to_print):\n-            line = \"\"\n-            for col in range(len(left_to_print)):\n-                if col > 0:\n-                    start_pos = positions[col - 1]\n-                else:\n-                    start_pos = 0\n-                end_pos = positions[col]\n-                # Leave room for 2 spaces to delineate columns\n-                # we don't need any if we are printing the last column\n-                space = 2 if col != len(positions) - 1 else 0\n-                cutoff = end_pos - start_pos - space\n-                # Except for last col, offset by one to align the start of col\n-                if col != len(positions) - 1:\n-                    cutoff -= 1\n-                if col == 0:\n-                    cutoff -= nested_level\n-                fit_into_line = left_to_print[col][:cutoff]\n-                # For nicer formatting we line-break on seeing end of\n-                # tuple/dict etc.\n-                line_break_conditions = (\"),\", \"},\", \"],\", \"',\")\n-                candidate_cutoffs = [\n-                    fit_into_line.find(x) + len(x)\n-                    for x in line_break_conditions\n-                    if fit_into_line.find(x) >= 0\n-                ]\n-                if candidate_cutoffs:\n-                    cutoff = min(candidate_cutoffs)\n-                    fit_into_line = fit_into_line[:cutoff]\n+    print_fn(text_rendering.highlight_msg(f' Model: \"{model.name}\"'))\n+    rows = []\n \n-                if col == 0:\n-                    line += \"|\" * nested_level + \" \"\n-                line += fit_into_line\n-                line += \" \" * space if space else \"\"\n-                left_to_print[col] = left_to_print[col][cutoff:]\n+    def format_shape(shape):\n+        shape = tuple(shape)\n+        if len(shape) == 1 and isinstance(shape[0], tuple):\n+            shape = shape[0]\n+        return str(shape)\n \n-                # Pad out to the next position\n-                # Make space for nested_level for last column\n-                if nested_level and col == len(positions) - 1:\n-                    line += \" \" * (positions[col] - len(line) - nested_level)\n-                else:\n-                    line += \" \" * (positions[col] - len(line))\n-            line += \"|\" * nested_level\n-            print_fn(line)\n-\n-    print_fn(f'Model: \"{model.name}\"')\n-    print_fn(\"_\" * line_length)\n-    print_row(to_display, positions)\n-    print_fn(\"=\" * line_length)\n-\n-    def print_layer_summary(layer, nested_level=0):\n+    def print_layer_summary(layer, prefix=\"\"):\n         \"\"\"Prints a summary for a single layer.\n \n         Args:\n@@ -472,28 +426,27 @@ def print_summary(\n               (e.g. 0 for a top-level layer, 1 for a nested layer).\n         \"\"\"\n         try:\n-            output_shape = layer.output_shape\n+            output_shape = format_shape(layer.output_shape)\n         except AttributeError:\n             output_shape = \"multiple\"\n         except RuntimeError:  # output_shape unknown in Eager mode.\n             output_shape = \"?\"\n-        name = layer.name\n+        name = prefix + layer.name\n         cls_name = layer.__class__.__name__\n-        if not layer.built and not getattr(layer, \"_is_graph_network\", False):\n+        if not layer.built:\n             # If a subclassed model has a layer that is not called in\n             # Model.call, the layer will not be built and we cannot call\n             # layer.count_params().\n             params = \"0 (unused)\"\n         else:\n             params = layer.count_params()\n-        fields = [name + \" (\" + cls_name + \")\", output_shape, params]\n+        fields = [name + \" (\" + cls_name + \")\", output_shape, str(params)]\n \n         if show_trainable:\n             fields.append(\"Y\" if layer.trainable else \"N\")\n+        rows.append(fields)\n \n-        print_row(fields, positions, nested_level)\n-\n-    def print_layer_summary_with_connections(layer, nested_level=0):\n+    def print_layer_summary_with_connections(layer, prefix=\"\"):\n         \"\"\"Prints a summary for a single layer (including its connections).\n \n         Args:\n@@ -502,7 +455,7 @@ def print_summary(\n               (e.g. 0 for a top-level layer, 1 for a nested layer).\n         \"\"\"\n         try:\n-            output_shape = layer.output_shape\n+            output_shape = format_shape(layer.output_shape)\n         except AttributeError:\n             output_shape = \"multiple\"\n         connections = []\n@@ -510,68 +463,57 @@ def print_summary(\n             if relevant_nodes and node not in relevant_nodes:\n                 # node is not part of the current network\n                 continue\n-\n-            for (\n-                inbound_layer,\n-                node_index,\n-                tensor_index,\n-                _,\n-            ) in node.iterate_inbound():\n+            for kt in node.keras_inputs:\n+                keras_history = kt._keras_history\n+                inbound_layer = keras_history.layer\n+                node_index = keras_history.node_index\n+                tensor_index = keras_history.tensor_index\n                 connections.append(\n                     f\"{inbound_layer.name}[{node_index}][{tensor_index}]\"\n                 )\n-\n-        name = layer.name\n+        name = prefix + layer.name\n         cls_name = layer.__class__.__name__\n         fields = [\n             name + \" (\" + cls_name + \")\",\n             output_shape,\n-            layer.count_params(),\n+            str(layer.count_params()),\n             connections,\n         ]\n-\n         if show_trainable:\n             fields.append(\"Y\" if layer.trainable else \"N\")\n+        rows.append(fields)\n \n-        print_row(fields, positions, nested_level)\n-\n-    def print_layer(layer, nested_level=0, is_nested_last=False):\n-        if sequential_like:\n-            print_layer_summary(layer, nested_level)\n+    def print_layer(layer, nested_level=0):\n+        if nested_level:\n+            prefix = \"   \" * nested_level + \"└\" + \" \"\n         else:\n-            print_layer_summary_with_connections(layer, nested_level)\n+            prefix = \"\"\n+        if sequential_like:\n+            print_layer_summary(layer, prefix=prefix)\n+        else:\n+            print_layer_summary_with_connections(layer, prefix=prefix)\n \n         if expand_nested and hasattr(layer, \"layers\") and layer.layers:\n-            print_fn(\n-                \"|\" * (nested_level + 1)\n-                + \"¯\" * (line_length - 2 * nested_level - 2)\n-                + \"|\" * (nested_level + 1)\n-            )\n-\n-            nested_layer = layer.layers\n-            is_nested_last = False\n-            for i in range(len(nested_layer)):\n-                if i == len(nested_layer) - 1:\n-                    is_nested_last = True\n-                print_layer(nested_layer[i], nested_level + 1, is_nested_last)\n-\n-            print_fn(\n-                \"|\" * nested_level\n-                + \"¯\" * (line_length - 2 * nested_level)\n-                + \"|\" * nested_level\n-            )\n-\n-        if not is_nested_last:\n-            print_fn(\n-                \"|\" * nested_level\n-                + \" \" * (line_length - 2 * nested_level)\n-                + \"|\" * nested_level\n-            )\n+            nested_layers = layer.layers\n+            nested_level += 1\n+            for i in range(len(nested_layers)):\n+                print_layer(nested_layers[i], nested_level=nested_level)\n \n     for layer in model.layers[layer_range[0] : layer_range[1]]:\n         print_layer(layer)\n-    print_fn(\"=\" * line_length)\n \n+    # Render summary as a table.\n+    table = text_rendering.TextTable(\n+        header=header,\n+        rows=rows,\n+        positions=positions,\n+        # Left align layer name, center-align everything else\n+        alignments=[\"left\"] + [\"center\" for _ in range(len(header) - 1)],\n+        max_line_length=line_length,\n+    )\n+    print_fn(table.make())\n+\n+    # After the table, append information about parameter count and size.\n     if hasattr(model, \"_collected_trainable_weights\"):\n         trainable_count = count_params(model._collected_trainable_weights)\n         trainable_memory_size = weight_memory_size(\n@@ -587,19 +529,23 @@ def print_summary(\n     total_memory_size = trainable_memory_size + non_trainable_memory_size\n \n     print_fn(\n+        text_rendering.highlight_msg(\n             f\" Total params: {trainable_count + non_trainable_count} \"\n             f\"({readable_memory_size(total_memory_size)})\"\n         )\n+    )\n     print_fn(\n+        text_rendering.highlight_msg(\n             f\" Trainable params: {trainable_count} \"\n             f\"({readable_memory_size(trainable_memory_size)})\"\n         )\n+    )\n     print_fn(\n+        text_rendering.highlight_msg(\n             f\" Non-trainable params: {non_trainable_count} \"\n             f\"({readable_memory_size(non_trainable_memory_size)})\"\n         )\n-    print_fn(\"_\" * line_length)\n-\n+    )\n     print_dtensor_variable_summary(model, print_fn, line_length)\n \n \n\n@@ -93,7 +93,7 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n             writer.close()\n             with open(fpath, \"r\") as reader:\n                 lines = reader.readlines()\n-            self.assertEqual(len(lines), 15)\n+            self.assertEqual(len(lines), 13)\n         except ImportError:\n             pass\n \n@@ -112,10 +112,16 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n         model = keras.Sequential(\n             [\n                 keras.Input(shape),\n-                keras.layers.Conv2D(4, 3, name=\"Really-Long-name-test\"),\n-                keras.layers.Conv2D(4, 3, name=\"Another-long-name-test\"),\n+                keras.layers.Conv2D(\n+                    4, 3, name=\"Really-really-really-really-Long-name-test\"\n+                ),\n+                keras.layers.Conv2D(\n+                    4, 3, name=\"Another-really-really-really-long-name-test\"\n+                ),\n                 keras.layers.Flatten(),\n-                keras.layers.Dense(2, name=\"long-name-test-output\"),\n+                keras.layers.Dense(\n+                    2, name=\"Really-really-really-long-name-test-output\"\n+                ),\n             ]\n         )\n         file_name = \"sequential.txt\"\n@@ -130,34 +136,33 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n         layer_utils.print_summary(model, print_fn=print_to_file)\n         self.assertTrue(tf.io.gfile.exists(fpath))\n         writer.close()\n+        ref_str = \"\"\" Model: \"sequential\"\n+┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n+┃           Layer (type)           ┃         Output Shape         ┃  Param #   ┃\n+┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n+│ Really-really-really-really-Lon  │       (None, 6, 6, 4)        │    112     │\n+│ g-name-test (Conv2D)             │                              │            │\n+├──────────────────────────────────┼──────────────────────────────┼────────────┤\n+│ Another-really-really-really-lo  │       (None, 4, 4, 4)        │    148     │\n+│ ng-name-test (Conv2D)            │                              │            │\n+├──────────────────────────────────┼──────────────────────────────┼────────────┤\n+│ flatten (Flatten)                │          (None, 64)          │     0      │\n+├──────────────────────────────────┼──────────────────────────────┼────────────┤\n+│ Really-really-really-long-name-  │          (None, 2)           │    130     │\n+│ test-output (Dense)              │                              │            │\n+└──────────────────────────────────┴──────────────────────────────┴────────────┘\n+ Total params: 390 (1.52 KB)\n+ Trainable params: 390 (1.52 KB)\n+ Non-trainable params: 0 (0.00 B)\\n\"\"\"\n+        self._check_summary_string(ref_str, fpath)\n+\n+    def _check_summary_string(self, ref_str, fpath):\n         reader = open(fpath, \"r\")\n-        lines = reader.readlines()\n+        seen_str = reader.read()\n+        seen_str = seen_str.replace(\"\\x1b[1m\", \"\")\n+        seen_str = seen_str.replace(\"\\x1b[0m\", \"\")\n         reader.close()\n-        check_str = (\n-            'Model: \"sequential\"\\n'\n-            \"_________________________________________________________________\\n\"  # noqa: E501\n-            \" Layer (type)                Output Shape              Param #   \\n\"  # noqa: E501\n-            \"=================================================================\\n\"  # noqa: E501\n-            \" Really-Long-name-test (Con  (None, 6, 6, 4)           112       \\n\"  # noqa: E501\n-            \" v2D)                                                            \\n\"  # noqa: E501\n-            \"                                                                 \\n\"  # noqa: E501\n-            \" Another-long-name-test (Co  (None, 4, 4, 4)           148       \\n\"  # noqa: E501\n-            \" nv2D)                                                           \\n\"  # noqa: E501\n-            \"                                                                 \\n\"  # noqa: E501\n-            \" flatten (Flatten)           (None, 64)                0         \\n\"  # noqa: E501\n-            \"                                                                 \\n\"  # noqa: E501\n-            \" long-name-test-output (Den  (None, 2)                 130       \\n\"  # noqa: E501\n-            \" se)                                                             \\n\"  # noqa: E501\n-            \"                                                                 \\n\"  # noqa: E501\n-            \"=================================================================\\n\"  # noqa: E501\n-            \"Total params: 390 (1.52 KB)\\n\"\n-            \"Trainable params: 390 (1.52 KB)\\n\"\n-            \"Non-trainable params: 0 (0.00 Byte)\\n\"\n-            \"_________________________________________________________________\\n\"  # noqa: E501\n-        )\n-        fin_str = \"\".join(lines)\n-        self.assertIn(fin_str, check_str)\n-        self.assertEqual(len(lines), 20)\n+        self.assertEqual(ref_str, seen_str)\n \n     def test_print_summary_expand_nested(self):\n         shape = (None, None, 3)\n@@ -184,49 +189,34 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n         def print_to_file(text):\n             print(text, file=writer)\n \n-        try:\n         layer_utils.print_summary(\n             model, print_fn=print_to_file, expand_nested=True\n         )\n         self.assertTrue(tf.io.gfile.exists(fpath))\n         writer.close()\n-            reader = open(fpath, \"r\")\n-            lines = reader.readlines()\n-            reader.close()\n-            check_str = (\n-                'Model: \"model_2\"\\n'\n-                \"_________________________________________________________________\\n\"  # noqa: E501\n-                \" Layer (type)                Output Shape              Param #   \\n\"  # noqa: E501\n-                \"=================================================================\\n\"  # noqa: E501\n-                \" input_3 (InputLayer)        [(None, None, None, 3)]   0         \\n\"  # noqa: E501\n-                \"                                                                 \\n\"  # noqa: E501\n-                \" model_1 (Functional)        (None, None, None, 3)     24        \\n\"  # noqa: E501\n-                \"|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n\"  # noqa: E501\n-                \"| input_1 (InputLayer)       [(None, None, None, 3)]   0        |\\n\"  # noqa: E501\n-                \"|                                                               |\\n\"  # noqa: E501\n-                \"| model (Functional)         (None, None, None, 3)     24       |\\n\"  # noqa: E501\n-                \"||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\\n\"  # noqa: E501\n-                \"|| input_2 (InputLayer)      [(None, None, None, 3)]   0       ||\\n\"  # noqa: E501\n-                \"||                                                             ||\\n\"  # noqa: E501\n-                \"|| conv2d (Conv2D)           (None, None, None, 3)     12      ||\\n\"  # noqa: E501\n-                \"||                                                             ||\\n\"  # noqa: E501\n-                \"|| batch_normalization (Bat  (None, None, None, 3)     12      ||\\n\"  # noqa: E501\n-                \"|| chNormalization)                                            ||\\n\"  # noqa: E501\n-                \"|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n\"  # noqa: E501\n-                \"¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\\n\"  # noqa: E501\n-                \"=================================================================\\n\"  # noqa: E501\n-                \"Total params: 24 (96.00 Byte)\\n\"\n-                \"Trainable params: 18 (72.00 Byte)\\n\"\n-                \"Non-trainable params: 6 (24.00 Byte)\\n\"\n-                \"_________________________________________________________________\\n\"  # noqa: E501\n-            )\n-\n-            fin_str = \"\".join(lines)\n-\n-            self.assertIn(fin_str, check_str)\n-            self.assertEqual(len(lines), 25)\n-        except ImportError:\n-            pass\n+        ref_str = \"\"\" Model: \"model_2\"\n+┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n+┃           Layer (type)           ┃         Output Shape         ┃  Param #   ┃\n+┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n+│ input_3 (InputLayer)             │    (None, None, None, 3)     │     0      │\n+├──────────────────────────────────┼──────────────────────────────┼────────────┤\n+│ model_1 (Functional)             │    (None, None, None, 3)     │     24     │\n+├──────────────────────────────────┼──────────────────────────────┼────────────┤\n+│    └ input_1 (InputLayer)        │    (None, None, None, 3)     │     0      │\n+├──────────────────────────────────┼──────────────────────────────┼────────────┤\n+│    └ model (Functional)          │    (None, None, None, 3)     │     24     │\n+├──────────────────────────────────┼──────────────────────────────┼────────────┤\n+│       └ input_2 (InputLayer)     │    (None, None, None, 3)     │     0      │\n+├──────────────────────────────────┼──────────────────────────────┼────────────┤\n+│       └ conv2d (Conv2D)          │    (None, None, None, 3)     │     12     │\n+├──────────────────────────────────┼──────────────────────────────┼────────────┤\n+│       └ batch_normalization      │    (None, None, None, 3)     │     12     │\n+│ (BatchNormalization)             │                              │            │\n+└──────────────────────────────────┴──────────────────────────────┴────────────┘\n+ Total params: 24 (96.00 B)\n+ Trainable params: 18 (72.00 B)\n+ Non-trainable params: 6 (24.00 B)\\n\"\"\"\n+        self._check_summary_string(ref_str, fpath)\n \n     def test_summary_subclass_model_expand_nested(self):\n         class Sequential(keras.Model):\n@@ -294,12 +284,7 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n             writer.close()\n             with open(fpath, \"r\") as reader:\n                 lines = reader.readlines()\n-            # The output content are slightly different for the input shapes\n-            # between v1 and v2.\n-            if tf.__internal__.tf2.enabled():\n-                self.assertEqual(len(lines), 39)\n-            else:\n-                self.assertEqual(len(lines), 40)\n+            self.assertEqual(len(lines), 37)\n         except ImportError:\n             pass\n \n@@ -323,39 +308,25 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n         def print_to_file(text):\n             print(text, file=writer)\n \n-        try:\n         layer_utils.print_summary(\n             model, print_fn=print_to_file, show_trainable=True\n         )\n         self.assertTrue(tf.io.gfile.exists(fpath))\n         writer.close()\n-            with open(fpath, \"r\") as reader:\n-                lines = reader.readlines()\n-            check_str = (\n-                'Model: \"trainable\"\\n'\n-                \"____________________________________________________________________________\\n\"  # noqa: E501\n-                \" Layer (type)                Output Shape              Param #   Trainable  \\n\"  # noqa: E501\n-                \"============================================================================\\n\"  # noqa: E501\n-                \" conv (Conv2D)               (None, 2, 3, 2)           62        N          \\n\"  # noqa: E501\n-                \"                                                                            \\n\"  # noqa: E501\n-                \" flat (Flatten)              (None, 12)                0         Y          \\n\"  # noqa: E501\n-                \"                                                                            \\n\"  # noqa: E501\n-                \" dense (Dense)               (None, 5)                 65        Y          \\n\"  # noqa: E501\n-                \"                                                                            \\n\"  # noqa: E501\n-                \"============================================================================\\n\"  # noqa: E501\n-                \"Total params: 127 (508.00 Byte)\\n\"\n-                \"Trainable params: 65 (260.00 Byte)\\n\"\n-                \"Non-trainable params: 62 (248.00 Byte)\\n\"\n-                \"____________________________________________________________________________\\n\"  # noqa: E501\n-                \"____________________________________________________________________________\\n\"  # noqa: E501\n-            )\n-\n-            fin_str = \"\".join(lines)\n-\n-            self.assertIn(fin_str, check_str)\n-            self.assertEqual(len(lines), 15)\n-        except ImportError:\n-            pass\n+        ref_str = \"\"\" Model: \"trainable\"\n+┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┓\n+┃         Layer (type)        ┃       Output Shape       ┃ Param #  ┃ Trainable ┃\n+┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━┩\n+│ conv (Conv2D)               │     (None, 2, 3, 2)      │    62    │     N     │\n+├─────────────────────────────┼──────────────────────────┼──────────┼───────────┤\n+│ flat (Flatten)              │        (None, 12)        │    0     │     Y     │\n+├─────────────────────────────┼──────────────────────────┼──────────┼───────────┤\n+│ dense (Dense)               │        (None, 5)         │    65    │     Y     │\n+└─────────────────────────────┴──────────────────────────┴──────────┴───────────┘\n+ Total params: 127 (508.00 B)\n+ Trainable params: 65 (260.00 B)\n+ Non-trainable params: 62 (248.00 B)\\n\"\"\"  # noqa: E501\n+        self._check_summary_string(ref_str, fpath)\n \n     def test_print_summary_expand_nested_show_trainable(self):\n         shape = (None, None, 3)\n@@ -384,7 +355,6 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n         def print_to_file(text):\n             print(text, file=writer)\n \n-        try:\n         layer_utils.print_summary(\n             model,\n             print_fn=print_to_file,\n@@ -393,42 +363,30 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n         )\n         self.assertTrue(tf.io.gfile.exists(fpath))\n         writer.close()\n-            with open(fpath, \"r\") as reader:\n-                lines = reader.readlines()\n-            check_str = (\n-                'Model: \"model_2\"\\n'\n-                \"____________________________________________________________________________\\n\"  # noqa: E501\n-                \" Layer (type)                Output Shape              Param #   Trainable  \\n\"  # noqa: E501\n-                \"============================================================================\\n\"  # noqa: E501\n-                \" input3 (InputLayer)         [(None, None, None, 3)]   0         Y          \\n\"  # noqa: E501\n-                \"                                                                            \\n\"  # noqa: E501\n-                \" model_1 (Functional)        (None, None, None, 3)     24        Y          \\n\"  # noqa: E501\n-                \"|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n\"  # noqa: E501\n-                \"| input1 (InputLayer)        [(None, None, None, 3)]   0         Y         |\\n\"  # noqa: E501\n-                \"|                                                                          |\\n\"  # noqa: E501\n-                \"| model (Functional)         (None, None, None, 3)     24        Y         |\\n\"  # noqa: E501\n-                \"||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\\n\"  # noqa: E501\n-                \"|| input2 (InputLayer)       [(None, None, None, 3)]   0         Y        ||\\n\"  # noqa: E501\n-                \"||                                                                        ||\\n\"  # noqa: E501\n-                \"|| conv2d (Conv2D)           (None, None, None, 3)     12        N        ||\\n\"  # noqa: E501\n-                \"||                                                                        ||\\n\"  # noqa: E501\n-                \"|| batch_normalization (Bat  (None, None, None, 3)     12        Y        ||\\n\"  # noqa: E501\n-                \"|| chNormalization)                                                       ||\\n\"  # noqa: E501\n-                \"|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n\"  # noqa: E501\n-                \"¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\\n\"  # noqa: E501\n-                \"============================================================================\\n\"  # noqa: E501\n-                \"Total params: 24 (96.00 Byte)\\n\"\n-                \"Trainable params: 6 (24.00 Byte)\\n\"\n-                \"Non-trainable params: 18 (72.00 Byte)\\n\"\n-                \"____________________________________________________________________________\\n\"  # noqa: E501\n-            )\n-\n-            fin_str = \"\".join(lines)\n-\n-            self.assertIn(fin_str, check_str)\n-            self.assertEqual(len(lines), 25)\n-        except ImportError:\n-            pass\n+        ref_str = \"\"\" Model: \"model_2\"\n+┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┓\n+┃         Layer (type)        ┃       Output Shape       ┃ Param #  ┃ Trainable ┃\n+┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━┩\n+│ input3 (InputLayer)         │  (None, None, None, 3)   │    0     │     Y     │\n+├─────────────────────────────┼──────────────────────────┼──────────┼───────────┤\n+│ model_1 (Functional)        │  (None, None, None, 3)   │    24    │     Y     │\n+├─────────────────────────────┼──────────────────────────┼──────────┼───────────┤\n+│    └ input1 (InputLayer)    │  (None, None, None, 3)   │    0     │     Y     │\n+├─────────────────────────────┼──────────────────────────┼──────────┼───────────┤\n+│    └ model (Functional)     │  (None, None, None, 3)   │    24    │     Y     │\n+├─────────────────────────────┼──────────────────────────┼──────────┼───────────┤\n+│       └ input2              │  (None, None, None, 3)   │    0     │     Y     │\n+│ (InputLayer)                │                          │          │           │\n+├─────────────────────────────┼──────────────────────────┼──────────┼───────────┤\n+│       └ conv2d (Conv2D)     │  (None, None, None, 3)   │    12    │     N     │\n+├─────────────────────────────┼──────────────────────────┼──────────┼───────────┤\n+│       └ batch_normalizatio  │  (None, None, None, 3)   │    12    │     Y     │\n+│ n (BatchNormalization)      │                          │          │           │\n+└─────────────────────────────┴──────────────────────────┴──────────┴───────────┘\n+ Total params: 24 (96.00 B)\n+ Trainable params: 6 (24.00 B)\n+ Non-trainable params: 18 (72.00 B)\\n\"\"\"  # noqa: E501\n+        self._check_summary_string(ref_str, fpath)\n \n     def test_print_summary_layer_range(self):\n         model = keras.Sequential()\n@@ -460,9 +418,7 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n             writer.close()\n             with open(fpath, \"r\") as reader:\n                 lines = reader.readlines()\n-            # The expected lenght with no layer filter is 15\n-            # we filtered out 2 lines by excluding the layer 'dense'\n-            self.assertEqual(len(lines), 15 - 2)\n+            self.assertEqual(len(lines), 11)\n         except ImportError:\n             pass\n \n@@ -491,57 +447,35 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n         def print_to_file(text):\n             print(text, file=writer)\n \n-        try:\n         layer_utils.print_summary(\n             model,\n             print_fn=print_to_file,\n             expand_nested=True,\n             layer_range=[\"1st_inner\", \"1st_inner\"],\n         )\n-            layer_utils.print_summary(\n-                model,\n-                expand_nested=True,\n-                layer_range=[\"1st_inner\", \"1st_inner\"],\n-            )\n         self.assertTrue(tf.io.gfile.exists(fpath))\n         writer.close()\n-            with open(fpath, \"r\") as reader:\n-                lines = reader.readlines()\n-            check_str = (\n-                'Model: \"model\"\\n'\n-                \"_________________________________________________________________\\n\"  # noqa: E501\n-                \" Layer (type)                Output Shape              Param #   \\n\"  # noqa: E501\n-                \"=================================================================\\n\"  # noqa: E501\n-                \" 1st_inner (Functional)      (None, None, None, 3)     24        \\n\"  # noqa: E501\n-                \"|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n\"  # noqa: E501\n-                \"| input_1 (InputLayer)       [(None, None, None, 3)]   0        |\\n\"  # noqa: E501\n-                \"|                                                               |\\n\"  # noqa: E501\n-                \"| 2nd_inner (Functional)     (None, None, None, 3)     24       |\\n\"  # noqa: E501\n-                \"||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\\n\"  # noqa: E501\n-                \"|| input_2 (InputLayer)      [(None, None, None, 3)]   0       ||\\n\"  # noqa: E501\n-                \"||                                                             ||\\n\"  # noqa: E501\n-                \"|| conv2d (Conv2D)           (None, None, None, 3)     12      ||\\n\"  # noqa: E501\n-                \"||                                                             ||\\n\"  # noqa: E501\n-                \"|| batch_normalization (Bat  (None, None, None, 3)     12      ||\\n\"  # noqa: E501\n-                \"|| chNormalization)                                            ||\\n\"  # noqa: E501\n-                \"|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n\"  # noqa: E501\n-                \"¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\\n\"  # noqa: E501\n-                \"=================================================================\\n\"  # noqa: E501\n-                \"Total params: 24 (96.00 Byte)\\n\"\n-                \"Trainable params: 18 (72.00 Byte)\\n\"\n-                \"Non-trainable params: 6 (24.00 Byte)\\n\"\n-                \"_________________________________________________________________\\n\"  # noqa: E501\n-            )\n-\n-            check_lines = check_str.split(\"\\n\")[\n-                :-1\n-            ]  # Removing final empty string which is not a line\n-\n-            fin_str = \"\".join(lines)\n-            self.assertIn(fin_str, check_str)\n-            self.assertEqual(len(lines), len(check_lines))\n-        except ImportError:\n-            pass\n+        ref_str = \"\"\" Model: \"model\"\n+┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n+┃           Layer (type)           ┃         Output Shape         ┃  Param #   ┃\n+┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n+│ 1st_inner (Functional)           │    (None, None, None, 3)     │     24     │\n+├──────────────────────────────────┼──────────────────────────────┼────────────┤\n+│    └ input_1 (InputLayer)        │    (None, None, None, 3)     │     0      │\n+├──────────────────────────────────┼──────────────────────────────┼────────────┤\n+│    └ 2nd_inner (Functional)      │    (None, None, None, 3)     │     24     │\n+├──────────────────────────────────┼──────────────────────────────┼────────────┤\n+│       └ input_2 (InputLayer)     │    (None, None, None, 3)     │     0      │\n+├──────────────────────────────────┼──────────────────────────────┼────────────┤\n+│       └ conv2d (Conv2D)          │    (None, None, None, 3)     │     12     │\n+├──────────────────────────────────┼──────────────────────────────┼────────────┤\n+│       └ batch_normalization      │    (None, None, None, 3)     │     12     │\n+│ (BatchNormalization)             │                              │            │\n+└──────────────────────────────────┴──────────────────────────────┴────────────┘\n+ Total params: 24 (96.00 B)\n+ Trainable params: 18 (72.00 B)\n+ Non-trainable params: 6 (24.00 B)\\n\"\"\"\n+        self._check_summary_string(ref_str, fpath)\n \n     def test_weight_memory_size(self):\n         v1 = tf.Variable(tf.zeros(shape=(1, 2), dtype=tf.float32))\n@@ -555,8 +489,8 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n         self.assertEqual(weight_memory_size, expected_memory_size)\n \n     @parameterized.parameters(\n-        (0, \"0.00 Byte\"),\n-        (1000, \"1000.00 Byte\"),\n+        (0, \"0.00 B\"),\n+        (1000, \"1000.00 B\"),\n         (1024, \"1.00 KB\"),\n         (1024 * 2 - 1, \"2.00 KB\"),\n         (1024 * 2 + 1, \"2.00 KB\"),\n\n@@ -0,0 +1,172 @@\n+# Copyright 2023 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+import shutil\n+\n+\n+class TextTable:\n+    def __init__(\n+        self, header, rows, positions, alignments=None, max_line_length=80\n+    ):\n+        if len(header) != len(positions):\n+            raise ValueError(\"header and positions should be the same length.\")\n+        if not all(p <= 1.0 for p in positions):\n+            raise ValueError(\"All positions should be <= 1.\")\n+        self.alignments = alignments or [\"center\" for _ in header]\n+        if len(self.alignments) != len(header):\n+            raise ValueError(\"header and alignments should be the same length.\")\n+        last_p = 0.0\n+        for p in positions:\n+            if p <= last_p:\n+                raise ValueError(\n+                    \"All consecutive positions should be greater than the last.\"\n+                )\n+            last_p = p\n+        self.header = header\n+        self.rows = rows\n+\n+        # Compute columns widths\n+        line_length = min(\n+            max_line_length, shutil.get_terminal_size().columns - 4\n+        )\n+        column_widths = []\n+        current = 0\n+        for pos in positions:\n+            width = int(pos * line_length) - current\n+            if width < 4:\n+                raise ValueError(\"Insufficient console width to print summary.\")\n+            column_widths.append(width)\n+            current += width\n+        self.column_widths = column_widths\n+\n+    def make_separator(self, left, mid, right, horizontal):\n+        line = mid.join(horizontal * width for width in self.column_widths)\n+        return f\"{left}{line}{right}\"\n+\n+    @staticmethod\n+    def maybe_pad(field, alignment):\n+        if alignment == \"left\":\n+            return \" \" + field\n+        if alignment == \"right\":\n+            return field + \" \"\n+        return field\n+\n+    def print_row(\n+        self,\n+        fields,\n+        vertical_separator=\"│\",\n+        alignments=None,\n+        highlight=False,\n+    ):\n+        alignments = alignments or [\"center\" for _ in fields]\n+        lines = []\n+        line_break_chars_post = (\")\", \"}\", \"]\")\n+        line_break_chars_pre = (\"(\", \"{\", \"[\")\n+        for field, width, alignment in zip(\n+            fields, self.column_widths, alignments\n+        ):\n+            field = self.maybe_pad(str(field), alignment)\n+            buffered_width = width - 1\n+            if len(field) < buffered_width and \"\\n\" not in field:\n+                lines.append([field])\n+                continue\n+            subfields = []\n+            while len(field) >= buffered_width or \"\\n\" in field:\n+                if \"\\n\" in field[:buffered_width]:\n+                    # priority: break on line break\n+                    cutoff = field.find(\"\\n\")\n+                    subfield = field[:cutoff]\n+                    field = field[cutoff + 1 :]\n+                    field = self.maybe_pad(field, alignment)\n+                    subfields.append(subfield)\n+                    continue\n+                # secondary: break on certain characters\n+                candidate_cutoffs_post = [\n+                    field.find(x) + len(x)\n+                    for x in line_break_chars_post\n+                    if 0 < field.find(x) < buffered_width - len(x)\n+                ]\n+                candidate_cutoffs_pre = [\n+                    field.find(x)\n+                    for x in line_break_chars_pre\n+                    if 0 < field.find(x) < buffered_width\n+                ]\n+                cutoffs = candidate_cutoffs_post + candidate_cutoffs_pre\n+                if cutoffs:\n+                    cutoff = max(cutoffs)\n+                else:\n+                    cutoff = buffered_width - 1\n+                subfield = field[:cutoff]\n+                field = field[cutoff:]\n+                field = self.maybe_pad(field, alignment)\n+                subfields.append(subfield)\n+            if field:\n+                subfields.append(field)\n+            lines.append(subfields)\n+\n+        max_subfield_count = max(len(subs) for subs in lines)\n+        rendered_lines = []\n+        for i in range(max_subfield_count):\n+            fields = []\n+            for subfields in lines:\n+                if len(subfields) < i + 1:\n+                    field = \"\"\n+                else:\n+                    field = subfields[i]\n+                fields.append(field)\n+            aligned_fields = [\n+                self.align_field(field, width, alignment)\n+                for field, width, alignment in zip(\n+                    fields, self.column_widths, alignments\n+                )\n+            ]\n+            if highlight:\n+                aligned_fields = [\n+                    highlight_msg(field) for field in aligned_fields\n+                ]\n+            line = vertical_separator.join(aligned_fields)\n+            line = f\"{vertical_separator}{line}{vertical_separator}\"\n+            rendered_lines.append(line)\n+        return \"\\n\".join(rendered_lines)\n+\n+    @staticmethod\n+    def align_field(field, width, alignment):\n+        if alignment == \"center\":\n+            return field.center(width)\n+        if alignment == \"left\":\n+            return field.ljust(width)\n+        if alignment == \"right\":\n+            return field.rjust(width)\n+\n+    def make(self):\n+        lines = []\n+        # Print header\n+        lines.append(self.make_separator(*\"┏┳┓━\"))\n+        lines.append(\n+            self.print_row(self.header, vertical_separator=\"┃\", highlight=True)\n+        )\n+        lines.append(self.make_separator(*\"┡╇┩━\"))\n+\n+        # Print rows\n+        for i, row in enumerate(self.rows):\n+            lines.append(self.print_row(row, alignments=self.alignments))\n+            if i < len(self.rows) - 1:\n+                lines.append(self.make_separator(*\"├┼┤─\"))\n+\n+        lines.append(self.make_separator(*\"└┴┘─\"))\n+        return \"\\n\".join(lines)\n+\n+\n+def highlight_msg(msg):\n+    return f\"\\x1b[1m{msg}\\x1b[0m\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
