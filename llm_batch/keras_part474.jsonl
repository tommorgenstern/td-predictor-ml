{"custom_id": "keras#ce5497519b6638502146f49fce75d09d431eb9d2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 3 | Methods Changed: 5 | Complexity Δ (Sum/Max): -8/0 | Churn Δ: 30 | Churn Cumulative: 1913 | Contributors (this commit): 31 | Commits (past 90d): 14 | Contributors (cumulative): 40 | DMM Complexity: 1.0\n\nDIFF:\n@@ -272,7 +272,7 @@ def model_to_dot(\n         if show_shapes:\n \n             def format_shape(shape):\n-                return str(shape).replace(str(None), \"None\")\n+                return str(shape).replace(str(None), \"None\").replace(\"{\", \"/{\").replace(\"}\", \"/}\")\n \n             try:\n                 outputlabels = format_shape(layer.output_shape)\n\n@@ -229,15 +229,27 @@ class ModelToDotFormatTest(tf.test.TestCase, parameterized.TestCase):\n         except ImportError:\n             pass\n \n-    def test_model_with_tf_op(self):\n-        # Test fix for a bug in which inputs to a TFOp layer past the 1st one\n-        # were not connected in the Keras model plot.\n-        a = keras.Input((2,))\n-        b = keras.Input((2,))\n-        model = keras.Model(inputs=[a, b], outputs=a + b)\n+    def test_model_with_brackets_in_shape(self):\n+        # Test fix for a bug in which plotting the model shapes fails if\n+        # any labels contain brackets\n+        class DictLayer(keras.layers.Layer):\n+            def call(self, inputs) -> tf.Tensor:\n+                tensor_input, dict_input = inputs\n+                return tf.concat(list(dict_input.values()), axis=1)\n+        inputs = {\n+            \"a\": keras.Input(name=\"a\", shape=(1), dtype=tf.float32),\n+            \"b\": keras.Input(name=\"b\", shape=(1), dtype=tf.float32)\n+        }\n+        outputs=DictLayer()((inputs[\"a\"], inputs))\n+        model = keras.Model(\n+            inputs=inputs,\n+            outputs=outputs,\n+        )\n         try:\n-            dot = vis_utils.model_to_dot(model)\n-            self.assertLen(dot.get_edges(), 2)  # This model has 2 edges.\n+            vis_utils.plot_model(model,\n+                                 show_shapes=True,\n+                                 show_dtype=True,\n+                                 show_layer_names=True)\n         except ImportError:\n             pass\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e1a6941e442047878f3a17bf6029d509dbdc56c8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 19 | Churn Cumulative: 11309 | Contributors (this commit): 31 | Commits (past 90d): 24 | Contributors (cumulative): 40 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3610,7 +3610,9 @@ class BaseRandomLayer(Layer):\n     \"\"\"A layer handle the random number creation and savemodel behavior.\"\"\"\n \n     @tf.__internal__.tracking.no_automatic_dependency_tracking\n-    def __init__(self, seed=None, force_generator=False, **kwargs):\n+    def __init__(\n+        self, seed=None, force_generator=False, rng_type=None, **kwargs\n+    ):\n         \"\"\"Initialize the BaseRandomLayer.\n \n         Note that the constructor is annotated with\n@@ -3628,12 +3630,16 @@ class BaseRandomLayer(Layer):\n           seed: optional integer, used to create RandomGenerator.\n           force_generator: boolean, default to False, whether to force the\n             RandomGenerator to use the code branch of tf.random.Generator.\n+          rng_type: string, the rng type that will be passed to backend\n+            RandomGenerator. Default to `None`, which will allow RandomGenerator\n+            to choose types by itself. Valid values are \"stateful\", \"stateless\",\n+            \"legacy_stateful\".\n           **kwargs: other keyword arguments that will be passed to the parent\n             *class\n         \"\"\"\n         super().__init__(**kwargs)\n         self._random_generator = backend.RandomGenerator(\n-            seed, force_generator=force_generator\n+            seed, force_generator=force_generator, rng_type=rng_type\n         )\n         # Eagerly init the generator to avoid any issue like b/206821407\n         self._random_generator._maybe_init()\n\n@@ -332,8 +332,15 @@ class Dropout(keras_layers.Dropout, base.Layer):\n     def __init__(\n         self, rate=0.5, noise_shape=None, seed=None, name=None, **kwargs\n     ):\n+        # Force the rng type to be legacy stateful since the new stateful code\n+        # path is not supported by legacy layer.\n         super().__init__(\n-            rate=rate, noise_shape=noise_shape, seed=seed, name=name, **kwargs\n+            rate=rate,\n+            noise_shape=noise_shape,\n+            seed=seed,\n+            name=name,\n+            rng_type=\"legacy_stateful\",\n+            **kwargs\n         )\n \n     def call(self, inputs, training=False):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cc28c7d3976d5ad12d7fae23ef4546ed7b7490d3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 837 | Contributors (this commit): 6 | Commits (past 90d): 8 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -138,8 +138,7 @@ class TimeDistributedTest(test_combinations.TestCase):\n \n     def test_TimeDistributed_learning_phase(self):\n         with self.cached_session():\n-            # test layers that need learning_phase to be set\n-            np.random.seed(1234)\n+            keras.utils.set_random_seed(0)\n             x = keras.layers.Input(shape=(3, 2))\n             y = keras.layers.TimeDistributed(keras.layers.Dropout(0.999))(\n                 x, training=True\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1589a843bac4390c8377db05cbd6ae650b6210cc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 5721 | Contributors (this commit): 26 | Commits (past 90d): 10 | Contributors (cumulative): 26 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2071,8 +2071,6 @@ def sparse_categorical_crossentropy(\n     Returns:\n       Sparse categorical crossentropy loss value.\n     \"\"\"\n-    y_pred = tf.convert_to_tensor(y_pred)\n-\n     return backend.sparse_categorical_crossentropy(\n         y_true,\n         y_pred,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9e5d76417cd9d75c5792aa7b32e2183f12110b97", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 707 | Contributors (this commit): 6 | Commits (past 90d): 7 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -35,12 +35,12 @@ except ImportError:\n \n if pil_image is not None:\n     _PIL_INTERPOLATION_METHODS = {\n-        \"nearest\": pil_image.NEAREST,\n-        \"bilinear\": pil_image.BILINEAR,\n-        \"bicubic\": pil_image.BICUBIC,\n-        \"hamming\": pil_image.HAMMING,\n-        \"box\": pil_image.BOX,\n-        \"lanczos\": pil_image.LANCZOS,\n+        \"nearest\": pil_image.Resampling.NEAREST,\n+        \"bilinear\": pil_image.Resampling.BILINEAR,\n+        \"bicubic\": pil_image.Resampling.BICUBIC,\n+        \"hamming\": pil_image.Resampling.HAMMING,\n+        \"box\": pil_image.Resampling.BOX,\n+        \"lanczos\": pil_image.Resampling.LANCZOS,\n     }\n \n ResizeMethod = tf.image.ResizeMethod\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#70f7fb6789e1a7e030737a46847b24b892965e4e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 76 | Lines Deleted: 83 | Files Changed: 6 | Hunks: 48 | Methods Changed: 30 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 159 | Churn Cumulative: 30344 | Contributors (this commit): 38 | Commits (past 90d): 67 | Contributors (cumulative): 82 | DMM Complexity: None\n\nDIFF:\n@@ -5545,7 +5545,7 @@ def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n @tf.__internal__.dispatch.add_dispatch_support\n @doc_controls.do_not_generate_docs\n def sparse_categorical_crossentropy(\n-    target, output, from_logits=False, axis=-1, ignore_index=None\n+    target, output, from_logits=False, axis=-1, ignore_class=None\n ):\n     \"\"\"Categorical crossentropy with integer targets.\n \n@@ -5559,14 +5559,11 @@ def sparse_categorical_crossentropy(\n         axis: Int specifying the channels axis. `axis=-1` corresponds to data\n             format `channels_last`, and `axis=1` corresponds to data format\n             `channels_first`.\n-        ignore_index: Optional integer, the id of a label that will not be\n-            included in the entropy equation nor in gradient computation. This\n-            is useful in segmentation problems containing the *void* label\n-            (commonly -1 or 255) in its annotated segmentation maps.\n-            By default, all label ids are considered. If `ignore_index` is not\n-            `None` and the output is a tensor with `rank>=3`, then the valid\n-            entries will be averaged over the axes `range(1, output_rank-1)`,\n-            resulting in an output of shape `[batch]`.\n+        ignore_class: Optional integer. The ID of a class to be ignored\n+            during loss computation. This is useful, for example, in\n+            segmentation problems featuring a \"void\" class (commonly -1\n+            or 255) in segmentation maps.\n+            By default (`ignore_class=None`), all classes are considered.\n \n     Returns:\n         Output tensor.\n@@ -5620,8 +5617,8 @@ def sparse_categorical_crossentropy(\n         target = flatten(target)\n         output = tf.reshape(output, [-1, output_shape[-1]])\n \n-    if ignore_index is not None:\n-        valid_mask = tf.not_equal(target, ignore_index)\n+    if ignore_class is not None:\n+        valid_mask = tf.not_equal(target, ignore_class)\n         target = target[valid_mask]\n         output = output[valid_mask]\n \n@@ -5635,7 +5632,7 @@ def sparse_categorical_crossentropy(\n             labels=target, logits=output\n         )\n \n-    if ignore_index is not None:\n+    if ignore_class is not None:\n         res_shape = cast(output_shape[:-1], \"int64\")\n         valid_mask = tf.reshape(valid_mask, res_shape)\n \n\n@@ -1972,7 +1972,7 @@ class BackendCrossEntropyLossesTest(tf.test.TestCase, parameterized.TestCase):\n     @test_combinations.generate(\n         test_combinations.combine(mode=[\"graph\", \"eager\"])\n     )\n-    def test_sparse_categorical_crossentropy_loss_with_ignore_index(self):\n+    def test_sparse_categorical_crossentropy_loss_with_ignore_class(self):\n         t = backend.constant([255, 1, 2, 2])\n         p = backend.softmax(\n             backend.constant(\n@@ -1984,7 +1984,7 @@ class BackendCrossEntropyLossesTest(tf.test.TestCase, parameterized.TestCase):\n                 ]\n             )\n         )\n-        result = backend.sparse_categorical_crossentropy(t, p, ignore_index=255)\n+        result = backend.sparse_categorical_crossentropy(t, p, ignore_class=255)\n         self.assertArrayNear(\n             self.evaluate(result),\n             [0.0, 0.07428224, 0.13980183, 0.11967831],\n@@ -2001,7 +2001,7 @@ class BackendCrossEntropyLossesTest(tf.test.TestCase, parameterized.TestCase):\n             ]\n         )\n         result = backend.sparse_categorical_crossentropy(\n-            t, p, ignore_index=-1, from_logits=True\n+            t, p, ignore_class=-1, from_logits=True\n         )\n         self.assertArrayNear(\n             self.evaluate(result),\n@@ -2012,7 +2012,7 @@ class BackendCrossEntropyLossesTest(tf.test.TestCase, parameterized.TestCase):\n     @test_combinations.generate(\n         test_combinations.combine(mode=[\"graph\", \"eager\"])\n     )\n-    def test_sparse_cce_loss_with_ignore_index_for_segmentation(self):\n+    def test_sparse_cce_loss_with_ignore_class_for_segmentation(self):\n         t = backend.constant(\n             [\n                 [[0, 2], [-1, -1]],\n@@ -2032,7 +2032,7 @@ class BackendCrossEntropyLossesTest(tf.test.TestCase, parameterized.TestCase):\n             ]\n         )\n \n-        result = backend.sparse_categorical_crossentropy(t, p, ignore_index=-1)\n+        result = backend.sparse_categorical_crossentropy(t, p, ignore_class=-1)\n         self.assertArrayNear(\n             self.evaluate(result), [2.3841855e-07, 3.4657377e-01], 1e-3\n         )\n\n@@ -2025,7 +2025,7 @@ def _ragged_tensor_categorical_crossentropy(\n )\n @tf.__internal__.dispatch.add_dispatch_support\n def sparse_categorical_crossentropy(\n-    y_true, y_pred, from_logits=False, axis=-1, ignore_index=None\n+    y_true, y_pred, from_logits=False, axis=-1, ignore_class=None\n ):\n     \"\"\"Computes the sparse categorical crossentropy loss.\n \n@@ -2047,7 +2047,7 @@ def sparse_categorical_crossentropy(\n                   [[[1.0, 0.0, 0.0], [0.0, 0.5, 0.5]],\n                    [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]]]\n     >>> loss = tf.keras.losses.sparse_categorical_crossentropy(\n-    ...   y_true, y_pred, ignore_index=-1)\n+    ...   y_true, y_pred, ignore_class=-1)\n     >>> assert loss.shape == (2,)\n     >>> loss.numpy()\n     array([2.3841855e-07, 3.4657377e-01], dtype=float32)\n@@ -2059,14 +2059,10 @@ def sparse_categorical_crossentropy(\n         default, we assume that `y_pred` encodes a probability distribution.\n       axis: Defaults to -1. The dimension along which the entropy is\n         computed.\n-      ignore_index: Optional integer, the id of a label that will not be\n-        included in the entropy equation nor in gradient computation. This\n-        is useful in segmentation problems containing the *void* label\n-        (commonly -1 or 255) in its annotated segmentation maps.\n-        By default, all label ids are considered. If `ignore_index` is not\n-        `None` and the output is a tensor with `rank>=3`, then the valid\n-        entries will be averaged over the axes `range(1, output_rank-1)`,\n-        resulting in an output of shape `[batch]`.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        loss computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n \n     Returns:\n       Sparse categorical crossentropy loss value.\n@@ -2075,14 +2071,14 @@ def sparse_categorical_crossentropy(\n         y_true,\n         y_pred,\n         from_logits=from_logits,\n-        ignore_index=ignore_index,\n+        ignore_class=ignore_class,\n         axis=axis,\n     )\n \n \n @dispatch.dispatch_for_types(sparse_categorical_crossentropy, tf.RaggedTensor)\n def _ragged_tensor_sparse_categorical_crossentropy(\n-    y_true, y_pred, from_logits=False, axis=-1, ignore_index=None\n+    y_true, y_pred, from_logits=False, axis=-1, ignore_class=None\n ):\n     \"\"\"Implements support for handling RaggedTensors.\n \n@@ -2099,7 +2095,7 @@ def _ragged_tensor_sparse_categorical_crossentropy(\n     fn = functools.partial(\n         sparse_categorical_crossentropy,\n         from_logits=from_logits,\n-        ignore_index=ignore_index,\n+        ignore_class=ignore_class,\n         axis=axis,\n     )\n     return _ragged_tensor_apply_loss(fn, y_true, y_pred, y_pred_extra_dim=True)\n\n@@ -164,8 +164,8 @@ class KerasLossesTest(tf.test.TestCase, parameterized.TestCase):\n     @test_combinations.generate(\n         test_combinations.combine(mode=[\"graph\", \"eager\"])\n     )\n-    def test_sparse_categorical_crossentropy_loss_with_ignore_index(self):\n-        ignore_index = 255\n+    def test_sparse_categorical_crossentropy_loss_with_ignore_class(self):\n+        ignore_class = 255\n         target = backend.variable(np.random.randint(0, 1, (5, 1)))\n         logits = backend.variable(np.random.random((5, 1)))\n         softmax_output = backend.softmax(logits)\n@@ -174,14 +174,14 @@ class KerasLossesTest(tf.test.TestCase, parameterized.TestCase):\n             tf.constant([0, 1, 0, 1, 1], target.dtype), (5, 1)\n         )\n         target.assign(\n-            target * valid_entries + (1 - valid_entries) * ignore_index\n+            target * valid_entries + (1 - valid_entries) * ignore_class\n         )\n \n         output_from_logit = losses.sparse_categorical_crossentropy(\n-            target, logits, ignore_index=ignore_index, from_logits=True\n+            target, logits, ignore_class=ignore_class, from_logits=True\n         )\n         output_from_softmax = losses.sparse_categorical_crossentropy(\n-            target, softmax_output, ignore_index=ignore_index\n+            target, softmax_output, ignore_class=ignore_class\n         )\n         np.testing.assert_allclose(\n             backend.eval(output_from_logit),\n\n@@ -2646,10 +2646,10 @@ class _IoUBase(base_metric.Metric):\n         `(num_classes, num_classes)` will be allocated.\n       name: (Optional) string name of the metric instance.\n       dtype: (Optional) data type of the metric result.\n-      ignore_index: Optional integer, the id of a label that will not be\n-        included in the metric computation. This is useful in segmentation\n-        problems containing the *void* label (commonly -1 or 255) in its\n-        annotated segmentation maps. By default, all label ids are considered.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        metric computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n       sparse_labels: Wether labels are encoded using natural numbers or\n         probability distribution vectors. If `False`, the `tf.argmax` function\n         will be used to determine each sample's most likely associated label.\n@@ -2665,14 +2665,14 @@ class _IoUBase(base_metric.Metric):\n         num_classes: int,\n         name: Optional[str] = None,\n         dtype: Optional[Union[str, tf.dtypes.DType]] = None,\n-        ignore_index: Optional[int] = None,\n+        ignore_class: Optional[int] = None,\n         sparse_labels: bool = True,\n         sparse_preds: bool = True,\n         axis: int = -1,\n     ):\n         super().__init__(name=name, dtype=dtype)\n         self.num_classes = num_classes\n-        self.ignore_index = ignore_index\n+        self.ignore_class = ignore_class\n         self.sparse_labels = sparse_labels\n         self.sparse_preds = sparse_preds\n         self.axis = axis\n@@ -2713,8 +2713,8 @@ class _IoUBase(base_metric.Metric):\n         if y_true.shape.ndims > 1:\n             y_true = tf.reshape(y_true, [-1])\n \n-        if self.ignore_index is not None:\n-            valid_mask = tf.not_equal(y_true, self.ignore_index)\n+        if self.ignore_class is not None:\n+            valid_mask = tf.not_equal(y_true, self.ignore_class)\n             y_true = y_true[valid_mask]\n             y_pred = y_pred[valid_mask]\n \n@@ -2774,10 +2774,10 @@ class IoU(_IoUBase):\n         single id value should be provided.\n       name: (Optional) string name of the metric instance.\n       dtype: (Optional) data type of the metric result.\n-      ignore_index: Optional integer, the id of a label that will not be\n-        included in the metric computation. This is useful in segmentation\n-        problems containing the *void* label (commonly -1 or 255) in its\n-        annotated segmentation maps. By default, all label ids are considered.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        metric computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n       sparse_labels: Wether labels are encoded using natural numbers or\n         probability distribution vectors. If `False`, the `tf.argmax` function\n         will be used to determine each sample's most likely associated label.\n@@ -2826,7 +2826,7 @@ class IoU(_IoUBase):\n         target_class_ids: Union[List[int], Tuple[int, ...]],\n         name: Optional[str] = None,\n         dtype: Optional[Union[str, tf.dtypes.DType]] = None,\n-        ignore_index: Optional[int] = None,\n+        ignore_class: Optional[int] = None,\n         sparse_labels: bool = True,\n         sparse_preds: bool = True,\n         axis: int = -1,\n@@ -2834,7 +2834,7 @@ class IoU(_IoUBase):\n         super().__init__(\n             name=name,\n             num_classes=num_classes,\n-            ignore_index=ignore_index,\n+            ignore_class=ignore_class,\n             sparse_labels=sparse_labels,\n             sparse_preds=sparse_preds,\n             axis=axis,\n@@ -2883,7 +2883,7 @@ class IoU(_IoUBase):\n         config = {\n             \"num_classes\": self.num_classes,\n             \"target_class_ids\": self.target_class_ids,\n-            \"ignore_index\": self.ignore_index,\n+            \"ignore_class\": self.ignore_class,\n             \"sparse_labels\": self.sparse_labels,\n             \"sparse_preds\": self.sparse_preds,\n             \"axis\": self.axis,\n@@ -3042,10 +3042,10 @@ class MeanIoU(IoU):\n         [num_classes, num_classes] will be allocated.\n       name: (Optional) string name of the metric instance.\n       dtype: (Optional) data type of the metric result.\n-      ignore_index: Optional integer, the id of a label that will not be\n-        included in the metric computation. This is useful in segmentation\n-        problems containing the *void* label (commonly -1 or 255) in its\n-        annotated segmentation maps. By default, all label ids are considered.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        metric computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n       sparse_labels: Wether labels are encoded using natural numbers or\n         probability distribution vectors. If `False`, the `tf.argmax` function\n         will be used to determine each sample's most likely associated label.\n@@ -3088,7 +3088,7 @@ class MeanIoU(IoU):\n         num_classes: int,\n         name: Optional[str] = None,\n         dtype: Optional[Union[str, tf.dtypes.DType]] = None,\n-        ignore_index: Optional[int] = None,\n+        ignore_class: Optional[int] = None,\n         sparse_labels: bool = True,\n         sparse_preds: bool = True,\n         axis: int = -1,\n@@ -3100,7 +3100,7 @@ class MeanIoU(IoU):\n             target_class_ids=target_class_ids,\n             axis=axis,\n             dtype=dtype,\n-            ignore_index=ignore_index,\n+            ignore_class=ignore_class,\n             sparse_labels=sparse_labels,\n             sparse_preds=sparse_preds,\n         )\n@@ -3110,7 +3110,7 @@ class MeanIoU(IoU):\n             \"num_classes\": self.num_classes,\n             \"name\": self.name,\n             \"dtype\": self._dtype,\n-            \"ignore_index\": self.ignore_index,\n+            \"ignore_class\": self.ignore_class,\n             \"sparse_labels\": self.sparse_labels,\n             \"sparse_preds\": self.sparse_preds,\n             \"axis\": self.axis,\n@@ -3161,10 +3161,10 @@ class OneHotIoU(IoU):\n         single id value should be provided.\n       name: (Optional) string name of the metric instance.\n       dtype: (Optional) data type of the metric result.\n-      ignore_index: Optional integer, the id of a label that will not be\n-        included in the metric computation. This is useful in segmentation\n-        problems containing the *void* label (commonly -1 or 255) in its\n-        annotated segmentation maps. By default, all label ids are considered.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        metric computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n       sparse_preds: Wether predictions are encoded using natural numbers or\n         probability distribution vectors. If `False`, the `tf.argmax` function\n         will be used to determine each sample's most likely associated label.\n@@ -3206,7 +3206,7 @@ class OneHotIoU(IoU):\n         target_class_ids: Union[List[int], Tuple[int, ...]],\n         name=None,\n         dtype=None,\n-        ignore_index: Optional[int] = None,\n+        ignore_class: Optional[int] = None,\n         sparse_preds: bool = False,\n         axis: int = -1,\n     ):\n@@ -3215,7 +3215,7 @@ class OneHotIoU(IoU):\n             target_class_ids=target_class_ids,\n             name=name,\n             dtype=dtype,\n-            ignore_index=ignore_index,\n+            ignore_class=ignore_class,\n             sparse_labels=False,\n             sparse_preds=sparse_preds,\n             axis=axis,\n@@ -3227,7 +3227,7 @@ class OneHotIoU(IoU):\n             \"target_class_ids\": self.target_class_ids,\n             \"name\": self.name,\n             \"dtype\": self._dtype,\n-            \"ignore_index\": self.ignore_index,\n+            \"ignore_class\": self.ignore_class,\n             \"sparse_preds\": self.sparse_preds,\n             \"axis\": self.axis,\n         }\n@@ -3275,10 +3275,10 @@ class OneHotMeanIoU(MeanIoU):\n         allocated to accumulate predictions from which the metric is calculated.\n       name: (Optional) string name of the metric instance.\n       dtype: (Optional) data type of the metric result.\n-      ignore_index: Optional integer, the id of a label that will not be\n-        included in the metric computation. This is useful in segmentation\n-        problems containing the *void* label (commonly -1 or 255) in its\n-        annotated segmentation maps. By default, all label ids are considered.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        metric computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n       sparse_preds: Wether predictions are encoded using natural numbers or\n         probability distribution vectors. If `False`, the `tf.argmax` function\n         will be used to determine each sample's most likely associated label.\n@@ -3319,7 +3319,7 @@ class OneHotMeanIoU(MeanIoU):\n         num_classes: int,\n         name: str = None,\n         dtype: Optional[Union[str, tf.dtypes.DType]] = None,\n-        ignore_index: Optional[int] = None,\n+        ignore_class: Optional[int] = None,\n         sparse_preds: bool = False,\n         axis: int = -1,\n     ):\n@@ -3328,7 +3328,7 @@ class OneHotMeanIoU(MeanIoU):\n             axis=axis,\n             name=name,\n             dtype=dtype,\n-            ignore_index=ignore_index,\n+            ignore_class=ignore_class,\n             sparse_labels=False,\n             sparse_preds=sparse_preds,\n         )\n@@ -3338,7 +3338,7 @@ class OneHotMeanIoU(MeanIoU):\n             \"num_classes\": self.num_classes,\n             \"name\": self.name,\n             \"dtype\": self._dtype,\n-            \"ignore_index\": self.ignore_index,\n+            \"ignore_class\": self.ignore_class,\n             \"sparse_preds\": self.sparse_preds,\n             \"axis\": self.axis,\n         }\n@@ -3493,10 +3493,10 @@ class SparseCategoricalCrossentropy(base_metric.MeanMetricWrapper):\n       dtype: (Optional) data type of the metric result.\n       from_logits: (Optional) Whether output is expected to be a logits tensor.\n         By default, we consider that output encodes a probability distribution.\n-      ignore_index: Optional integer, the id of a label that will not be\n-        included in the metric computation. This is useful in segmentation\n-        problems containing the *void* label (commonly -1 or 255) in its\n-        annotated segmentation maps. By default, all label ids are considered.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        metric computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n       axis: (Optional) Defaults to -1. The dimension along which entropy is\n         computed.\n \n@@ -3541,7 +3541,7 @@ class SparseCategoricalCrossentropy(base_metric.MeanMetricWrapper):\n         name: str = \"sparse_categorical_crossentropy\",\n         dtype: Optional[Union[str, tf.dtypes.DType]] = None,\n         from_logits: bool = False,\n-        ignore_index: Optional[int] = None,\n+        ignore_class: Optional[int] = None,\n         axis: int = -1,\n     ):\n         super().__init__(\n@@ -3549,7 +3549,7 @@ class SparseCategoricalCrossentropy(base_metric.MeanMetricWrapper):\n             name,\n             dtype=dtype,\n             from_logits=from_logits,\n-            ignore_index=ignore_index,\n+            ignore_class=ignore_class,\n             axis=axis,\n         )\n \n\n@@ -1282,11 +1282,11 @@ class MeanIoUTest(tf.test.TestCase):\n         expected_result = (1 / (2 + 2 - 1) + 1 / (2 + 2 - 1)) / 2\n         self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n \n-    def test_unweighted_ignore_index_255(self):\n+    def test_unweighted_ignore_class_255(self):\n         y_pred = [0, 1, 1, 1]\n         y_true = [0, 1, 2, 255]\n \n-        m_obj = metrics.MeanIoU(num_classes=3, ignore_index=255)\n+        m_obj = metrics.MeanIoU(num_classes=3, ignore_class=255)\n         self.evaluate(tf.compat.v1.variables_initializer(m_obj.variables))\n \n         result = m_obj(y_true, y_pred)\n@@ -1301,11 +1301,11 @@ class MeanIoUTest(tf.test.TestCase):\n         ) / 3\n         self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n \n-    def test_unweighted_ignore_index_1(self):\n+    def test_unweighted_ignore_class_1(self):\n         y_pred = [0, 1, 1, 1]\n         y_true = [0, 1, 2, -1]\n \n-        m_obj = metrics.MeanIoU(num_classes=3, ignore_index=-1)\n+        m_obj = metrics.MeanIoU(num_classes=3, ignore_class=-1)\n         self.evaluate(tf.compat.v1.variables_initializer(m_obj.variables))\n \n         result = m_obj(y_true, y_pred)\n@@ -1340,12 +1340,12 @@ class MeanIoUTest(tf.test.TestCase):\n         ) / 2\n         self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n \n-    def test_weighted_ignore_index_1(self):\n+    def test_weighted_ignore_class_1(self):\n         y_pred = tf.constant([0, 1, 0, 1], dtype=tf.float32)\n         y_true = tf.constant([0, 0, 1, -1])\n         sample_weight = tf.constant([0.2, 0.3, 0.4, 0.1])\n \n-        m_obj = metrics.MeanIoU(num_classes=2, ignore_index=-1)\n+        m_obj = metrics.MeanIoU(num_classes=2, ignore_class=-1)\n         self.evaluate(tf.compat.v1.variables_initializer(m_obj.variables))\n \n         result = m_obj(y_true, y_pred, sample_weight=sample_weight)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#efdb4531164a12431b7c69038d5329ac4107ee05", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1800 | Contributors (this commit): 7 | Commits (past 90d): 9 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -977,6 +977,7 @@ def decode_predictions(preds, top=5):\n decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__\n \n ResNetRS50.__doc__ = BASE_DOCSTRING.format(name=\"ResNetRS50\")\n+ResNetRS101.__doc__ = BASE_DOCSTRING.format(name=\"ResNetRS101\")\n ResNetRS152.__doc__ = BASE_DOCSTRING.format(name=\"ResNetRS152\")\n ResNetRS200.__doc__ = BASE_DOCSTRING.format(name=\"ResNetRS200\")\n ResNetRS270.__doc__ = BASE_DOCSTRING.format(name=\"ResNetRS270\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d18db421eaabdf6a7dc099968e0c9664433e120a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 0 | Files Changed: 6 | Hunks: 10 | Methods Changed: 6 | Complexity Δ (Sum/Max): 18/4 | Churn Δ: 20 | Churn Cumulative: 629 | Contributors (this commit): 4 | Commits (past 90d): 31 | Contributors (cumulative): 24 | DMM Complexity: 0.0\n\nDIFF:\n@@ -82,6 +82,8 @@ class GlobalAveragePooling1D(GlobalPooling1D):\n \n     def call(self, inputs, mask=None):\n         steps_axis = 1 if self.data_format == \"channels_last\" else 2\n+        if inputs.shape[steps_axis] == 0 :\n+            raise ValueError(\"Reducing axis cannot be of 0 dimension\")\n         if mask is not None:\n             mask = tf.cast(mask, inputs[0].dtype)\n             mask = tf.expand_dims(\n\n@@ -72,8 +72,12 @@ class GlobalAveragePooling2D(GlobalPooling2D):\n \n     def call(self, inputs):\n         if self.data_format == \"channels_last\":\n+            if [inputs.shape[i] == 0 for i in [1, 2]]:\n+                raise ValueError(\"Reducing axis cannot be of 0 dimension\")\n             return backend.mean(inputs, axis=[1, 2], keepdims=self.keepdims)\n         else:\n+            if [inputs.shape[i] == 0 for i in [2, 3]]:\n+                raise ValueError(\"Reducing axis cannot be of 0 dimension\")\n             return backend.mean(inputs, axis=[2, 3], keepdims=self.keepdims)\n \n \n\n@@ -66,8 +66,12 @@ class GlobalAveragePooling3D(GlobalPooling3D):\n \n     def call(self, inputs):\n         if self.data_format == \"channels_last\":\n+            if [inputs.shape[i] == 0 for i in [1, 2, 3]]:\n+                raise ValueError(\"Reducing axis cannot be of 0 dimension\")\n             return backend.mean(inputs, axis=[1, 2, 3], keepdims=self.keepdims)\n         else:\n+            if [inputs.shape[i] == 0 for i in [2, 3, 4]]:\n+                raise ValueError(\"Reducing axis cannot be of 0 dimension\")\n             return backend.mean(inputs, axis=[2, 3, 4], keepdims=self.keepdims)\n \n \n\n@@ -80,6 +80,8 @@ class GlobalMaxPooling1D(GlobalPooling1D):\n \n     def call(self, inputs):\n         steps_axis = 1 if self.data_format == \"channels_last\" else 2\n+        if inputs.shape[steps_axis] == 0 :\n+            raise ValueError(\"Reducing axis cannot be of 0 dimension\")\n         return backend.max(inputs, axis=steps_axis, keepdims=self.keepdims)\n \n \n\n@@ -70,8 +70,12 @@ class GlobalMaxPooling2D(GlobalPooling2D):\n \n     def call(self, inputs):\n         if self.data_format == \"channels_last\":\n+            if [inputs.shape[i] == 0 for i in [1, 2]]:\n+                raise ValueError(\"Reducing axis cannot be of 0 dimension\")\n             return backend.max(inputs, axis=[1, 2], keepdims=self.keepdims)\n         else:\n+            if [inputs.shape[i] == 0 for i in [2, 3]]:\n+                raise ValueError(\"Reducing axis cannot be of 0 dimension\")\n             return backend.max(inputs, axis=[2, 3], keepdims=self.keepdims)\n \n \n\n@@ -64,8 +64,12 @@ class GlobalMaxPooling3D(GlobalPooling3D):\n \n     def call(self, inputs):\n         if self.data_format == \"channels_last\":\n+            if [inputs.shape[i] == 0 for i in [1, 2, 3]]:\n+                raise ValueError(\"Reducing axis cannot be of 0 dimension\")\n             return backend.max(inputs, axis=[1, 2, 3], keepdims=self.keepdims)\n         else:\n+            if [inputs.shape[i] == 0 for i in [2, 3, 4]]:\n+                raise ValueError(\"Reducing axis cannot be of 0 dimension\")\n             return backend.max(inputs, axis=[2, 3, 4], keepdims=self.keepdims)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#459878f40fe664f8abfe6861cbad7ae500d725d5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 22 | Lines Deleted: 3 | Files Changed: 5 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 25 | Churn Cumulative: 21150 | Contributors (this commit): 132 | Commits (past 90d): 51 | Contributors (cumulative): 152 | DMM Complexity: 1.0\n\nDIFF:\n@@ -127,7 +127,7 @@ class OptimizersTest(test_util.DTensorBaseTest):\n \n         grads = tf.ones_like(variable_init_value)\n         optimizer.apply_gradients(zip([grads], [model_variable]))\n-        optimizer_variables = optimizer.variables\n+        optimizer_variables = optimizer.variables()\n \n         self.assertEqual(self.evaluate(optimizer.iterations), 1)\n \n\n@@ -3168,6 +3168,10 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         self._assert_weights_created()\n         weights = []\n         for layer in self._self_tracked_trackables:\n+            if isinstance(layer, optimizer_experimental.Optimizer):\n+                # Optimizer has to use variables() method.\n+                weights += layer.variables()\n+            else:\n                 weights += layer.variables\n         weights += self._trainable_weights + self._non_trainable_weights\n         return weights\n\n@@ -592,6 +592,21 @@ class _BaseOptimizer(tf.Module):\n                 )\n         return cls(**config)\n \n+    @doc_controls.do_not_generate_docs\n+    def variables(self):\n+        \"\"\"Returns variables of this Optimizer.\n+\n+        We override the `variable` property method of `tf.Module` for the\n+        sake of backward compatibility with `optimizer_v2.Optimizer`'s\n+        `variable()` method.\n+        \"\"\"\n+        return tuple(\n+            self._flatten(\n+                predicate=lambda obj: isinstance(obj, tf.Variable),\n+                expand_composites=True,\n+            )\n+        )\n+\n \n base_optimizer_keyword_args = \"\"\"name: String. The name to use\n         for momentum accumulator weights created by\n\n@@ -86,7 +86,7 @@ class OptimizerPssTest(tf.test.TestCase, parameterized.TestCase):\n         return dataset_fn\n \n     def _verify_accumulators_updated(self, optimizer):\n-        variables = optimizer.variables\n+        variables = optimizer.variables()\n         for var in variables:\n             if \"iteration\" not in var.name and \"learning_rate\" not in var.name:\n                 # Find a variable not iteration or learning_rate, and verify its\n\n@@ -176,7 +176,7 @@ class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n         optimizer = adam_new.Adam()\n         grads = tf.convert_to_tensor([[1.0, 2.0], [3.0, 4.0]])\n         optimizer.apply_gradients(zip([grads], [x]))\n-        optimizer_variables = optimizer.variables\n+        optimizer_variables = optimizer.variables()\n         all_names = [var._shared_name for var in optimizer_variables]\n         self.assertLen(optimizer_variables, 4)\n         self.assertCountEqual(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#24b987268defb86129676f565132750adb30e10a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 20 | Churn Cumulative: 727 | Contributors (this commit): 6 | Commits (past 90d): 8 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -29,18 +29,24 @@ from tensorflow.python.util.tf_export import keras_export\n \n try:\n     from PIL import Image as pil_image\n+\n+    try:\n+        pil_image_resampling = pil_image.Resampling\n+    except AttributeError:\n+        pil_image_resampling = pil_image\n except ImportError:\n     pil_image = None\n+    pil_image_resampling = None\n \n \n-if pil_image is not None:\n+if pil_image_resampling is not None:\n     _PIL_INTERPOLATION_METHODS = {\n-        \"nearest\": pil_image.Resampling.NEAREST,\n-        \"bilinear\": pil_image.Resampling.BILINEAR,\n-        \"bicubic\": pil_image.Resampling.BICUBIC,\n-        \"hamming\": pil_image.Resampling.HAMMING,\n-        \"box\": pil_image.Resampling.BOX,\n-        \"lanczos\": pil_image.Resampling.LANCZOS,\n+        \"nearest\": pil_image_resampling.NEAREST,\n+        \"bilinear\": pil_image_resampling.BILINEAR,\n+        \"bicubic\": pil_image_resampling.BICUBIC,\n+        \"hamming\": pil_image_resampling.HAMMING,\n+        \"box\": pil_image_resampling.BOX,\n+        \"lanczos\": pil_image_resampling.LANCZOS,\n     }\n \n ResizeMethod = tf.image.ResizeMethod\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#558592f71e3210cfe3d01b0eb0d1e0622d04a6b5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 15 | Churn Cumulative: 9199 | Contributors (this commit): 108 | Commits (past 90d): 20 | Contributors (cumulative): 108 | DMM Complexity: 1.0\n\nDIFF:\n@@ -611,6 +611,14 @@ class CallbackList:\n                 )\n         # pylint: enable=protected-access\n \n+    def make_logs(self, model, logs, outputs, mode, prefix=''):\n+        \"\"\"Computes logs for sending to `on_batch_end` methods.\"\"\"\n+        if not self.callbacks:\n+            return logs\n+\n+        return make_logs(model, logs, outputs, mode, prefix=prefix)\n+\n+\n \n @keras_export(\"keras.callbacks.Callback\")\n class Callback:\n@@ -904,13 +912,6 @@ class Callback:\n               method but that may change in the future.\n         \"\"\"\n \n-    def make_logs(self, model, logs, outputs, mode, prefix=''):\n-        \"\"\"Computes logs for sending to `on_batch_end` methods.\"\"\"\n-        if not self.callbacks:\n-            return logs\n-\n-        return make_logs(model, logs, outputs, mode, prefix=prefix)\n-\n         def _implements_train_batch_hooks(self):\n         \"\"\"Determines if this Callback should be called for each train batch.\"\"\"\n         return (\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e641f8a210a38890e0a7164f57a8860f8e83083c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 5745 | Contributors (this commit): 27 | Commits (past 90d): 12 | Contributors (cumulative): 27 | DMM Complexity: None\n\nDIFF:\n@@ -102,7 +102,7 @@ class Loss:\n     def _set_name_scope(self):\n         \"\"\"Creates a valid `name_scope` name.\"\"\"\n         if self.name is None:\n-            self._name_scope = self.__class__.__name__\n+            self._name_scope = self.__class__.__name__.strip(\"_\")\n         elif self.name == \"<lambda>\":\n             self._name_scope = \"lambda\"\n         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0a98948b63023f493a0704f1d175b1a71170c069", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 4 | Methods Changed: 5 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 23 | Churn Cumulative: 5939 | Contributors (this commit): 18 | Commits (past 90d): 26 | Contributors (cumulative): 37 | DMM Complexity: 0.7368421052631579\n\nDIFF:\n@@ -50,6 +50,7 @@ class LayerSavedModelSaver(base_serialization.SavedModelSaver):\n             stateful=self.obj.stateful,\n             must_restore_from_config=self.obj._must_restore_from_config,\n             preserve_input_structure_in_config=self.obj._preserve_input_structure_in_config,  # noqa: E501\n+            autocast=self.obj._autocast,\n         )\n \n         metadata.update(get_serialized(self.obj))\n\n@@ -624,6 +624,8 @@ class KerasObjectLoader:\n             obj._set_dtype_policy(metadata[\"dtype\"])\n         if metadata.get(\"stateful\") is not None:\n             obj.stateful = metadata[\"stateful\"]\n+        if metadata.get(\"autocast\") is not None:\n+            obj._autocast = metadata[\"autocast\"]\n         # Restore model save spec for subclassed models. (layers do not store a\n         # SaveSpec)\n         if isinstance(obj, training_lib.Model):\n@@ -1187,6 +1189,8 @@ class RevivedLayer:\n                 revived_obj._is_feature_layer = metadata[\"_is_feature_layer\"]\n             if metadata.get(\"stateful\") is not None:\n                 revived_obj.stateful = metadata[\"stateful\"]\n+            if metadata.get(\"autocast\") is not None:\n+                revived_obj._autocast = metadata[\"autocast\"]\n             if metadata.get(\"preserve_input_structure_in_config\") is not None:\n                 revived_obj._preserve_input_structure_in_config = metadata[\n                     \"preserve_input_structure_in_config\"\n\n@@ -1108,6 +1108,24 @@ class TestSavedModelFormatAllModes(test_combinations.TestCase):\n         assert_loaded_model(keras_load.load(saved_model_dir))\n         assert_loaded_model(tf.saved_model.load(saved_model_dir))\n \n+    @parameterized.named_parameters([(\"true\", True), (\"false\", False)])\n+    def test_save_layer_autocast(self, autocast):\n+        class CustomLayer(keras.layers.Layer):\n+            def __init__(self):\n+                super().__init__(autocast=autocast)\n+\n+        x = tf.constant(3, dtype=tf.float64)\n+\n+        x_in = keras.Input(tensor=x)\n+        output = CustomLayer()(x_in)\n+        model = keras.Model(inputs=x_in, outputs=output)\n+\n+        saved_model_dir = self._save_model_dir()\n+        model.save(saved_model_dir, save_format=\"tf\")\n+        loaded = keras_load.load(saved_model_dir)\n+        self.assertEqual(autocast, loaded.layers[-1]._autocast)\n+        self.assertEqual(self.evaluate(model(x)), self.evaluate(loaded(x)))\n+\n \n class TestSavedModelFormat(tf.test.TestCase):\n     def _save_model_dir(self, dirname=\"saved_model\"):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#77fc9756dac7fa84e3e421a37491bc4dfabb495d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 5 | Files Changed: 3 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 11758 | Contributors (this commit): 108 | Commits (past 90d): 36 | Contributors (cumulative): 120 | DMM Complexity: 0.0\n\nDIFF:\n@@ -611,7 +611,7 @@ class CallbackList:\n                 )\n         # pylint: enable=protected-access\n \n-    def make_logs(self, model, logs, outputs, mode, prefix=''):\n+    def make_logs(self, model, logs, outputs, mode, prefix=\"\"):\n         \"\"\"Computes logs for sending to `on_batch_end` methods.\"\"\"\n         if not self.callbacks:\n             return logs\n@@ -619,7 +619,6 @@ class CallbackList:\n         return make_logs(model, logs, outputs, mode, prefix=prefix)\n \n \n-\n @keras_export(\"keras.callbacks.Callback\")\n class Callback:\n     \"\"\"Abstract base class used to build new callbacks.\n\n@@ -363,7 +363,9 @@ def model_iteration(\n                 aggregator.aggregate(batch_outs)\n \n                 # Callbacks batch end.\n-                batch_logs = callbacks.make_logs(model, batch_logs, batch_outs, mode)\n+                batch_logs = callbacks.make_logs(\n+                    model, batch_logs, batch_outs, mode\n+                )\n                 callbacks._call_batch_hook(mode, \"end\", step, batch_logs)\n                 step += 1\n \n@@ -426,7 +428,9 @@ def model_iteration(\n                 aggregator.aggregate(batch_outs, batch_start, batch_end)\n \n                 # Callbacks batch end.\n-                batch_logs = callbacks.make_logs(model, batch_logs, batch_outs, mode)\n+                batch_logs = callbacks.make_logs(\n+                    model, batch_logs, batch_outs, mode\n+                )\n                 callbacks._call_batch_hook(mode, \"end\", batch_index, batch_logs)\n \n                 if callbacks.model.stop_training:\n\n@@ -306,7 +306,9 @@ def model_iteration(\n             aggregator.aggregate(batch_outs)\n \n             # Callbacks batch end.\n-            batch_logs = callbacks.make_logs(model, batch_logs, batch_outs, mode)\n+            batch_logs = callbacks.make_logs(\n+                model, batch_logs, batch_outs, mode\n+            )\n             callbacks._call_batch_hook(mode, \"end\", step, batch_logs)\n             step += 1\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
