{"custom_id": "keras#a3697d097d55ae00e8f174517b86928df360ea2a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 595 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 19 | Complexity Δ (Sum/Max): 59/55 | Churn Δ: 595 | Churn Cumulative: 595 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 0.6035502958579881\n\nDIFF:\n@@ -0,0 +1,517 @@\n+from .. import backend as K\n+from .. import activations, initializations, regularizers\n+\n+import numpy as np\n+from ..engine import Layer, InputSpec\n+from ..utils.np_utils import conv_output_length\n+\n+\n+class RecurrentConv2D(Layer):\n+    '''Abstract base class for recurrent layers.\n+    Do not use in a model -- it's not a functional layer!\n+\n+    All recurrent layers (GRU, LSTM, SimpleRNN) also\n+    follow the specifications of this class and accept\n+    the keyword arguments listed below.\n+\n+    # Input shape\n+        5D tensor with shape `(nb_samples, timesteps, channels,rows,cols)`.\n+\n+    # Output shape\n+        - if `return_sequences`: 5D tensor with shape\n+            `(nb_samples, timesteps, channels,rows,cols)`.\n+        - else, 2D tensor with shape `(nb_samples, channels,rows,cols)`.\n+\n+    # Arguments\n+        weights: list of numpy arrays to set as initial weights.\n+            The list should have 3 elements, of shapes:\n+            `[(input_dim, nb_filter), (nb_filter, nb_filter), (nb_filter,)]`.\n+        return_sequences: Boolean. Whether to return the last output\n+            in the output sequence, or the full sequence.\n+        go_backwards: Boolean (default False).\n+            If True, rocess the input sequence backwards.\n+        stateful: Boolean (default False). If True, the last state\n+            for each sample at index i in a batch will be used as initial\n+            state for the sample of index i in the following batch.\n+        nb_filter: Number of convolution filters to use.\n+        nb_row: Number of rows in the convolution kernel.\n+        nb_col: Number of columns in the convolution kernel.\n+            is required when using this layer as the first layer in a model.\n+        input_shape: input_shape\n+\n+    # Masking\n+        This layer supports masking for input data with a variable number\n+        of timesteps. To introduce masks to your data,\n+        use an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n+        set to `True`.\n+        **Note:** for the time being, masking is only supported with Theano.\n+\n+    # TensorFlow warning\n+        For the time being, when using the TensorFlow backend,\n+        the number of timesteps used must be specified in your model.\n+        Make sure to pass an `input_length` int argument to your\n+        recurrent layer (if it comes first in your model),\n+        or to pass a complete `input_shape` argument to the first layer\n+        in your model otherwise.\n+\n+\n+    # Note on using statefulness in RNNs\n+        You can set RNN layers to be 'stateful', which means that the states\n+        computed for the samples in one batch will be reused as initial states\n+        for the samples in the next batch.\n+        This assumes a one-to-one mapping between\n+        samples in different successive batches.\n+\n+        To enable statefulness:\n+            - specify `stateful=True` in the layer constructor.\n+            - specify a fixed batch size for your model, by passing\n+                a `batch_input_size=(...)` to the first layer in your model.\n+                This is the expected shape of your inputs *including the batch\n+                size*.\n+                It should be a tuple of integers, e.g. `(32, 10, 100)`.\n+\n+        To reset the states of your model, call `.reset_states()` on either\n+        a specific layer, or on your entire model.\n+    '''\n+\n+    def __init__(self, weights=None,\n+                 return_sequences=False, go_backwards=False, stateful=False,\n+                 nb_row=None, nb_col=None, nb_filter=None,\n+                 dim_ordering=None,\n+                 input_dim=None, input_length=None, **kwargs):\n+        self.return_sequences = return_sequences\n+        self.initial_weights = weights\n+        self.go_backwards = go_backwards\n+        self.stateful = stateful\n+\n+        self.nb_row = nb_row\n+        self.nb_col = nb_col\n+        self.nb_filter = nb_filter\n+        self.dim_ordering = dim_ordering\n+        self.input_spec = [InputSpec(ndim=5)]\n+\n+        self.input_dim = input_dim\n+        self.input_length = input_length\n+        #if self.input_dim:\n+        #    kwargs['input_shape'] = (self.input_length, self.input_dim)\n+\n+        super(RecurrentConv2D, self).__init__(**kwargs)\n+\n+    def compute_mask(self, input,mask):\n+        if self.return_sequences:\n+            return mask\n+        else:\n+            return None\n+\n+    def get_output_shape_for(self,input_shape):\n+\n+        if self.dim_ordering == 'th':\n+            rows = input_shape[2+1]\n+            cols = input_shape[3+1]\n+        elif self.dim_ordering == 'tf':\n+            rows = input_shape[1+1]\n+            cols = input_shape[2+1]\n+        else:\n+            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+\n+        rows = conv_output_length(rows, self.nb_row,\n+                                  self.border_mode, self.subsample[0])\n+        cols = conv_output_length(cols, self.nb_col,\n+                                  self.border_mode, self.subsample[1])\n+\n+        if self.return_sequences:\n+            if self.dim_ordering == 'th':\n+                return (input_shape[0], input_shape[1],\n+                        self.nb_filter, rows, cols)\n+            elif self.dim_ordering == 'tf':\n+                return (input_shape[0], input_shape[1],\n+                        rows, cols, self.nb_filter)\n+            else:\n+                raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+        else:\n+            if self.dim_ordering == 'th':\n+                return (input_shape[0], self.nb_filter, rows, cols)\n+            elif self.dim_ordering == 'tf':\n+                return (input_shape[0], rows, cols, self.nb_filter)\n+            else:\n+                raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+\n+    def step(self, x, states):\n+        raise NotImplementedError\n+\n+    def get_constants(self, X, train=False):\n+        return None\n+\n+    def get_initial_states(self, X):\n+        # (samples, timesteps, row, col, filter)\n+        initial_state = K.zeros_like(X)\n+        # (samples,row, col, filter)\n+        initial_state = K.sum(initial_state, axis=1)\n+        # initial_state = initial_state[::,]\n+        initial_state = self.conv_step(initial_state, K.zeros(self.W_shape),\n+                                       border_mode=self.border_mode)\n+\n+        initial_states = [initial_state for _ in range(2)]\n+        return initial_states\n+        \n+    def preprocess_input(self, x):\n+        return x\n+    def call(self, x,mask=None):\n+\n+       \n+\n+        assert K.ndim(x) == 5\n+        input_shape = self.input_spec[0].shape\n+       \n+        if K._BACKEND == 'tensorflow':\n+            if not input_shape[1]:\n+                raise Exception('When using TensorFlow, you should define ' +\n+                                'explicitely the number of timesteps of ' +\n+                                'your sequences. Make sure the first layer ' +\n+                                'has a \"batch_input_shape\" argument ' +\n+                                'including the samples axis.')\n+\n+        if self.stateful:\n+            initial_states = self.states\n+        else:\n+            initial_states = self.get_initial_states(x)\n+\n+        constants = self.get_constants(x)\n+        preprocessed_input = self.preprocess_input(x)\n+\n+\n+        last_output, outputs, states = K.rnn(self.step, preprocessed_input,\n+                                             initial_states,\n+                                             go_backwards=self.go_backwards,\n+                                             mask=mask,\n+                                             constants=constants,\n+                                             input_length=input_shape[1])\n+        if self.stateful:\n+            self.updates = []\n+            for i in range(len(states)):\n+                self.updates.append((self.states[i], states[i]))\n+\n+        if self.return_sequences:\n+            return outputs\n+        else:\n+            return last_output\n+\n+    def get_config(self):\n+        config = {\"name\": self.__class__.__name__,\n+                  \"return_sequences\": self.return_sequences,\n+                  \"go_backwards\": self.go_backwards,\n+                  \"stateful\": self.stateful}\n+        if self.stateful:\n+            config['batch_input_shape'] = self.input_shape\n+        else:\n+            config['input_dim'] = self.input_dim\n+            config['input_length'] = self.input_length\n+\n+        base_config = super(RecurrentConv2D, self).get_config()\n+        return dict(list(base_config.items()) + list(config.items()))\n+\n+\n+class LSTMConv2D(RecurrentConv2D):\n+    '''\n+    # Input shape\n+            5D tensor with shape:\n+            `(samples,time, channels, rows, cols)` if dim_ordering='th'\n+            or 5D tensor with shape:\n+            `(samples,time, rows, cols, channels)` if dim_ordering='tf'.\n+\n+     # Output shape\n+        if return_sequences=False\n+\n+            4D tensor with shape:\n+            `(samples, nb_filter, o_row, o_col)` if dim_ordering='th'\n+            or 4D tensor with shape:\n+            `(samples, o_row, o_col, nb_filter)` if dim_ordering='tf'.\n+        if return_sequences=True\n+            5D tensor with shape:\n+            `(samples, time,nb_filter, o_row, o_col)` if dim_ordering='th'\n+            or 5D tensor with shape:\n+            `(samples, time, o_row, o_col, nb_filter)` if dim_ordering='tf'.\n+\n+        where o_row and o_col depend on the shape of the filter and\n+        the border_mode\n+\n+        # Arguments\n+            nb_filter: Number of convolution filters to use.\n+            nb_row: Number of rows in the convolution kernel.\n+            nb_col: Number of columns in the convolution kernel.\n+            border_mode: 'valid' or 'same'.\n+            sub_sample: tuple of length 2. Factor by which to subsample output.\n+            Also called strides elsewhere.\n+            dim_ordering: \"tf\" if the feature are at the last dimension or \"th\"\n+            stateful : has not been checked yet.\n+\n+\n+            init: weight initialization function.\n+                Can be the name of an existing function (str),\n+                or a Theano function\n+                (see: [initializations](../initializations.md)).\n+            inner_init: initialization function of the inner cells.\n+            forget_bias_init: initialization function for the bias of the\n+            forget gate.\n+                [Jozefowicz et al.]\n+                (http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n+                recommend initializing with ones.\n+            activation: activation function.\n+                Can be the name of an existing function (str),\n+                or a Theano function (see: [activations](../activations.md)).\n+            inner_activation: activation function for the inner cells.\n+\n+    # References\n+        - [Convolutional LSTM Network: A Machine Learning Approach for\n+        Precipitation Nowcasting](http://arxiv.org/pdf/1506.04214v1.pdf)\n+        The current implementation does not include the feedback loop on the\n+        cells output\n+    '''\n+    def __init__(self, nb_filter, nb_row, nb_col,\n+                 init='glorot_uniform', inner_init='orthogonal',\n+                 forget_bias_init='one', activation='tanh',\n+                 inner_activation='hard_sigmoid', dim_ordering=\"tf\",\n+                 border_mode=\"valid\", sub_sample=(1, 1),\n+                 W_regularizer=None, U_regularizer=None, b_regularizer=None,\n+                 dropout_W=0., dropout_U=0., **kwargs):\n+        self.nb_filter = nb_filter\n+        self.nb_row = nb_row\n+        self.nb_col = nb_col\n+        self.init = initializations.get(init)\n+        self.inner_init = initializations.get(inner_init)\n+        self.forget_bias_init = initializations.get(forget_bias_init)\n+        self.activation = activations.get(activation)\n+        self.inner_activation = activations.get(inner_activation)\n+        self.border_mode = border_mode\n+        self.subsample = sub_sample\n+\n+        assert dim_ordering in {'tf', \"th\"}, 'dim_ordering must be in {tf,\"th}'\n+        \n+        if dim_ordering == \"th\":\n+            print \"Warning, unlike convolution3D the time must be the first dimention\"\n+        self.dim_ordering = dim_ordering\n+\n+        kwargs[\"nb_filter\"] = nb_filter\n+        kwargs[\"nb_row\"] = nb_row\n+        kwargs[\"nb_col\"] = nb_col\n+        kwargs[\"dim_ordering\"] = dim_ordering\n+\n+        self.W_regularizer = regularizers.get(W_regularizer)\n+        self.U_regularizer = regularizers.get(U_regularizer)\n+        self.b_regularizer = regularizers.get(b_regularizer)\n+        self.dropout_W, self.dropout_U = dropout_W, dropout_U\n+        if self.dropout_W or self.dropout_U:\n+            self.uses_learning_phase = True\n+\n+        super(LSTMConv2D, self).__init__(**kwargs)\n+\n+    def build(self, input_shape):\n+        self.input_spec = [InputSpec(shape=input_shape)]\n+        \n+\n+        if self.dim_ordering == 'th':\n+            stack_size = input_shape[1+1]\n+            self.W_shape = (self.nb_filter, stack_size,\n+                            self.nb_row, self.nb_col)\n+        elif self.dim_ordering == 'tf':\n+            stack_size = input_shape[3+1]\n+            self.W_shape = (self.nb_row, self.nb_col,\n+                            stack_size, self.nb_filter)\n+        else:\n+            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+\n+        if self.dim_ordering == 'th':\n+            self.W_shape1 = (self.nb_filter, self.nb_filter,\n+                             self.nb_row, self.nb_col)\n+        elif self.dim_ordering == 'tf':\n+            self.W_shape1 = (self.nb_row, self.nb_col,\n+                             self.nb_filter, self.nb_filter)\n+        else:\n+            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+\n+        if self.stateful:\n+            self.reset_states()\n+        else:\n+            # initial states: 2 all-zero tensor of shape (nb_filter)\n+            self.states = [None, None, None, None]\n+\n+        self.W_i = self.init(self.W_shape)\n+        self.U_i = self.inner_init(self.W_shape1)\n+        self.b_i = K.zeros((self.nb_filter,))\n+\n+        self.W_f = self.init(self.W_shape)\n+        self.U_f = self.inner_init(self.W_shape1)\n+        self.b_f = self.forget_bias_init((self.nb_filter,))\n+\n+        self.W_c = self.init(self.W_shape)\n+        self.U_c = self.inner_init(self.W_shape1)\n+        self.b_c = K.zeros((self.nb_filter))\n+\n+        self.W_o = self.init(self.W_shape)\n+        self.U_o = self.inner_init(self.W_shape1)\n+        self.b_o = K.zeros((self.nb_filter,))\n+\n+        self.trainable_weights = [self.W_i, self.U_i, self.b_i,\n+                                  self.W_c, self.U_c, self.b_c,\n+                                  self.W_f, self.U_f, self.b_f,\n+                                  self.W_o, self.U_o, self.b_o]\n+                                  \n+ \n+        self.W = K.concatenate([self.W_i, self.W_f, self.W_c, self.W_o])\n+        self.U = K.concatenate([self.U_i, self.U_f, self.U_c, self.U_o])\n+        self.b = K.concatenate([self.b_i, self.b_f, self.b_c, self.b_o])\n+\n+        self.regularizers = []\n+        if self.W_regularizer:\n+            self.W_regularizer.set_param(self.W)\n+            self.regularizers.append(self.W_regularizer)\n+        if self.U_regularizer:\n+            self.U_regularizer.set_param(self.U)\n+            self.regularizers.append(self.U_regularizer)\n+        if self.b_regularizer:\n+            self.b_regularizer.set_param(self.b)\n+            self.regularizers.append(self.b_regularizer)\n+\n+        if self.initial_weights is not None:\n+            self.set_weights(self.initial_weights)\n+            del self.initial_weights\n+\n+    def reset_states(self):\n+        assert self.stateful, 'Layer must be stateful.'\n+        input_shape = self.input_spec[0].shape\n+        if not input_shape[0]:\n+            raise Exception('If a RNN is stateful, a complete ' +\n+                            'input_shape must be provided ' +\n+                            '(including batch size).')\n+\n+        if self.return_sequences:\n+            out_row, out_col, out_filter = self.output_shape[2:]\n+        else:\n+            out_row, out_col, out_filter = self.output_shape[1:]\n+\n+        if hasattr(self, 'states'):\n+            K.set_value(self.states[0],\n+                        np.zeros((input_shape[0],\n+                                  out_row, out_col, out_filter)))\n+            K.set_value(self.states[1],\n+                        np.zeros((input_shape[0],\n+                                  out_row, out_col, out_filter)))\n+        else:\n+            self.states = [K.zeros((input_shape[0],\n+                                    out_row, out_col, out_filter)),\n+                           K.zeros((input_shape[0],\n+                                    out_row, out_col, out_filter))]\n+\n+    def conv_step(self, x, W, b=None, border_mode=\"valid\"):\n+        input_shape = self.input_spec[0].shape\n+\n+        conv_out = K.conv2d(x, W, strides=self.subsample,\n+                            border_mode=border_mode,\n+                            dim_ordering=self.dim_ordering,\n+                            image_shape=(input_shape[0],\n+                                         input_shape[2],\n+                                         input_shape[3],\n+                                         input_shape[4]),\n+                            filter_shape=self.W_shape)\n+        if b:\n+            if self.dim_ordering == 'th':\n+                conv_out = conv_out + K.reshape(b, (1, self.nb_filter, 1, 1))\n+            elif self.dim_ordering == 'tf':\n+                conv_out = conv_out + K.reshape(b, (1, 1, 1, self.nb_filter))\n+            else:\n+                raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+\n+        return conv_out\n+\n+    def conv_step_hidden(self, x, W, border_mode=\"valid\"):\n+        # This new function was defined because the\n+        # image shape must be hardcoded\n+        input_shape = self.input_spec[0].shape\n+        output_shape = self.get_output_shape_for(input_shape)\n+        if self.return_sequences:\n+            out_row, out_col, out_filter = output_shape[2:]\n+        else:\n+            out_row, out_col, out_filter = output_shape[1:]\n+\n+        conv_out = K.conv2d(x, W, strides=(1, 1),\n+                            border_mode=border_mode,\n+                            dim_ordering=self.dim_ordering,\n+                            image_shape=(input_shape[0],\n+                                         out_row, out_col,\n+                                         out_filter),\n+                            filter_shape=self.W_shape1)\n+\n+        return conv_out\n+\n+    def step(self, x, states):\n+        assert len(states) == 4\n+        h_tm1 = states[0]\n+        c_tm1 = states[1]\n+        B_W = states[2]\n+        B_U = states[3]\n+\n+        x_i = self.conv_step(x * B_W[0], self.W_i, self.b_i,\n+                             border_mode=self.border_mode)\n+        x_f = self.conv_step(x * B_W[1], self.W_f, self.b_f,\n+                             border_mode=self.border_mode)\n+        x_c = self.conv_step(x * B_W[2], self.W_c, self.b_c,\n+                             border_mode=self.border_mode)\n+        x_o = self.conv_step(x * B_W[3], self.W_o, self.b_o,\n+                             border_mode=self.border_mode)\n+\n+        # U : from nb_filter to nb_filter\n+        # Same because must be stable in the ouptut space\n+        h_i = self.conv_step_hidden(h_tm1, self.U_i * B_U[0],\n+                                    border_mode=\"same\")\n+        h_f = self.conv_step_hidden(h_tm1, self.U_f * B_U[1],\n+                                    border_mode=\"same\")\n+        h_c = self.conv_step_hidden(h_tm1, self.U_c * B_U[2],\n+                                    border_mode=\"same\")\n+        h_o = self.conv_step_hidden(h_tm1, self.U_o * B_U[3],\n+                                    border_mode=\"same\")\n+\n+        i = self.inner_activation(x_i + h_i)\n+        f = self.inner_activation(x_f + h_f)\n+        c = f * c_tm1 + i * self.activation(x_c + h_c)\n+        o = self.inner_activation(x_o + h_o)\n+        h = o * self.activation(c)\n+\n+        return h, [h, c]\n+\n+\n+    def get_constants(self, x):\n+        constants = []\n+        if 0 < self.dropout_U < 1:\n+            ones = K.ones_like(K.reshape(x[:, 0, 0], (-1, 1)))\n+            ones = K.concatenate([ones] * self.output_dim, 1)\n+            B_U = [K.in_train_phase(K.dropout(ones, self.dropout_U), ones) for _ in range(4)]\n+            constants.append(B_U)\n+        else:\n+            constants.append([K.cast_to_floatx(1.) for _ in range(4)])\n+\n+        if 0 < self.dropout_W < 1:\n+            input_shape = self.input_spec[0].shape\n+            input_dim = input_shape[-1]\n+            ones = K.ones_like(K.reshape(x[:, 0, 0], (-1, 1)))\n+            ones = K.concatenate([ones] * input_dim, 1)\n+            B_W = [K.in_train_phase(K.dropout(ones, self.dropout_W), ones) for _ in range(4)]\n+            constants.append(B_W)\n+        else:\n+            constants.append([K.cast_to_floatx(1.) for _ in range(4)])\n+        return constants        \n+        \n+\n+    def get_config(self):\n+        config = {\"name\": self.__class__.__name__,\n+                  \"nb_filter\": self.nb_filter,\n+                  'nb_row': self.nb_row,\n+                  'nb_col': self.nb_col,\n+                  \"init\": self.init.__name__,\n+                  \"inner_init\": self.inner_init.__name__,\n+                  \"forget_bias_init\": self.forget_bias_init.__name__,\n+                  \"activation\": self.activation.__name__,\n+                  'dim_ordering': self.dim_ordering,\n+                  'border_mode': self.border_mode,\n+                  \"inner_activation\": self.inner_activation.__name__}\n+        base_config = super(LSTMConv2D, self).get_config()\n+        return dict(list(base_config.items()) + list(config.items()))\n\\ No newline at end of file\n\n@@ -0,0 +1,78 @@\n+import pytest\n+import numpy as np\n+from numpy.testing import assert_allclose\n+\n+from keras import backend as K\n+from keras.models import Sequential\n+from keras.layers.recurrent_convolutional import LSTMConv2D\n+\n+\n+def test_shape2():\n+    # With return_sequences = True\n+    input_shape = [10, 30, 30, 3]\n+    batch = 5\n+    nfilter = 20\n+    input_a = np.zeros([batch]+input_shape)\n+    gt_shape = (batch, input_shape[0], input_shape[1], input_shape[2], nfilter)\n+    gt = np.zeros(gt_shape)\n+    seq = Sequential()\n+    seq.add(LSTMConv2D(nb_filter=20, nb_row=4, nb_col=4,\n+                       input_shape=input_shape, border_mode=\"same\",\n+                       return_sequences=True))\n+    seq.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n+    assert seq.predict(input_a).shape == gt_shape\n+    #seq.fit(input_a, gt, nb_epoch=1)\n+\n+\n+def test_shape_th_return_sequences():\n+    input_shape = [10, 3, 30, 30]\n+    batch = 5\n+    nfilter = 20\n+    input_a = np.zeros([batch]+input_shape)\n+    gt_shape = (batch, input_shape[0], nfilter, input_shape[2], input_shape[3])\n+    gt = np.zeros(gt_shape)\n+    seq = Sequential()\n+    seq.add(LSTMConv2D(nb_filter=nfilter, nb_row=4, nb_col=4,\n+                       dim_ordering=\"th\", input_shape=input_shape,\n+            border_mode=\"same\", return_sequences=True))\n+\n+    seq.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n+    assert seq.predict(input_a).shape == gt_shape\n+\n+    #seq.fit(input_a, gt, nb_epoch=1)\n+\n+\n+def test_shape_th():\n+    input_shape = [10, 3, 30, 30]\n+    batch = 5\n+    nfilter = 20\n+    input_a = np.zeros([batch]+input_shape)\n+    gt_shape = (batch, nfilter, input_shape[2], input_shape[3])\n+    gt = np.zeros(gt_shape)\n+    seq = Sequential()\n+    seq.add(LSTMConv2D(nb_filter=nfilter, nb_row=4, nb_col=4,\n+                       dim_ordering=\"th\", input_shape=input_shape,\n+            border_mode=\"same\", return_sequences=False))\n+    seq.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n+    assert seq.predict(input_a).shape == gt_shape\n+    #seq.fit(input_a, gt, nb_epoch=1)\n+\n+\n+def test_shape():\n+    input_shape = [10, 30, 30, 3]\n+    batch = 5\n+    nfilter = 20\n+    input_a = np.zeros([batch]+input_shape)\n+    gt_shape = (batch, input_shape[1], input_shape[2], nfilter)\n+    gt = np.zeros(gt_shape)\n+    seq = Sequential()\n+    seq.add(LSTMConv2D(nb_filter=nfilter, nb_row=4, nb_col=4,\n+                       input_shape=input_shape,\n+                       border_mode=\"same\", return_sequences=False))\n+    seq.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n+    assert seq.predict(input_a).shape == gt_shape\n+    #seq.fit(input_a, gt, nb_epoch=1)\n+\n+\n+if __name__ == '__main__':\n+    pytest.main([__file__])\n\\ No newline at end of file\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3bf8964355ea0675b7809bf6b0586999c9cc31fe", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 224 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -12,6 +12,8 @@ from keras import backend as K\n from keras import objectives\n from keras.datasets import mnist\n \n+K.set_image_dim_ordering('th') # this is a Theano oriented example\n+\n # input image dimensions\n img_rows, img_cols, img_chns = 28, 28, 1\n # number of convolutional filters to use\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8fab33c245208f9c39f55292af9773574d891a16", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 33 | Lines Deleted: 18 | Files Changed: 1 | Hunks: 16 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 51 | Churn Cumulative: 275 | Contributors (this commit): 4 | Commits (past 90d): 5 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -1,4 +1,5 @@\n-'''This script demonstrates how to build a variational autoencoder with Keras and deconvolution layers.\n+'''This script demonstrates how to build a variational autoencoder\n+with Keras and deconvolution layers.\n \n Reference: \"Auto-Encoding Variational Bayes\" https://arxiv.org/abs/1312.6114\n '''\n@@ -6,14 +7,12 @@ import numpy as np\n import matplotlib.pyplot as plt\n \n from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n-from keras.layers import Convolution2D, Deconvolution2D, MaxPooling2D\n+from keras.layers import Convolution2D, Deconvolution2D\n from keras.models import Model\n from keras import backend as K\n from keras import objectives\n from keras.datasets import mnist\n \n-K.set_image_dim_ordering('th') # this is a Theano oriented example\n-\n # input image dimensions\n img_rows, img_cols, img_chns = 28, 28, 1\n # number of convolutional filters to use\n@@ -22,14 +21,16 @@ nb_filters = 64\n nb_conv = 3\n \n batch_size = 100\n-original_dim = (img_chns, img_rows, img_cols)\n+if K.image_dim_ordering() == 'th':\n+    original_img_size = (img_chns, img_rows, img_cols)\n+else:\n+    original_img_size = (img_rows, img_cols, img_chns)\n latent_dim = 2\n intermediate_dim = 128\n epsilon_std = 0.01\n nb_epoch = 5\n \n-\n-x = Input(batch_shape=(batch_size,) + original_dim)\n+x = Input(batch_shape=(batch_size,) + original_img_size)\n conv_1 = Convolution2D(img_chns, 2, 2, border_mode='same', activation='relu')(x)\n conv_2 = Convolution2D(nb_filters, 2, 2,\n                        border_mode='same', activation='relu',\n@@ -60,23 +61,35 @@ z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n # we instantiate these layers separately so as to reuse them later\n decoder_hid = Dense(intermediate_dim, activation='relu')\n decoder_upsample = Dense(nb_filters * 14 * 14, activation='relu')\n-decoder_reshape = Reshape((nb_filters, 14, 14))\n+\n+if K.image_dim_ordering() == 'th':\n+    output_shape = (batch_size, nb_filters, 14, 14)\n+else:\n+    output_shape = (batch_size, 14, 14, nb_filters)\n+\n+decoder_reshape = Reshape(output_shape[1:])\n decoder_deconv_1 = Deconvolution2D(nb_filters, nb_conv, nb_conv,\n-                                   (batch_size, nb_filters, 14, 14),\n+                                   output_shape,\n                                    border_mode='same',\n                                    subsample=(1, 1),\n                                    activation='relu')\n decoder_deconv_2 = Deconvolution2D(nb_filters, nb_conv, nb_conv,\n-                                   (batch_size, nb_filters, 14, 14),\n+                                   output_shape,\n                                    border_mode='same',\n                                    subsample=(1, 1),\n                                    activation='relu')\n+if K.image_dim_ordering() == 'th':\n+    output_shape = (batch_size, nb_filters, 29, 29)\n+else:\n+    output_shape = (batch_size, 29, 29, nb_filters)\n decoder_deconv_3_upsamp = Deconvolution2D(nb_filters, 2, 2,\n-                                          (batch_size, nb_filters, 29, 29),\n+                                          output_shape,\n                                           border_mode='valid',\n                                           subsample=(2, 2),\n                                           activation='relu')\n-decoder_mean_squash = Convolution2D(img_chns, 2, 2, border_mode='valid', activation='sigmoid')\n+decoder_mean_squash = Convolution2D(img_chns, 2, 2,\n+                                    border_mode='valid',\n+                                    activation='sigmoid')\n \n hid_decoded = decoder_hid(z)\n up_decoded = decoder_upsample(hid_decoded)\n@@ -87,7 +100,8 @@ x_decoded_relu = decoder_deconv_3_upsamp(deconv_2_decoded)\n x_decoded_mean_squash = decoder_mean_squash(x_decoded_relu)\n \n def vae_loss(x, x_decoded_mean):\n-    # NOTE: binary_crossentropy expects a batch_size by dim for x and x_decoded_mean, so we MUST flatten these!\n+    # NOTE: binary_crossentropy expects a batch_size by dim\n+    # for x and x_decoded_mean, so we MUST flatten these!\n     x = K.flatten(x)\n     x_decoded_mean = K.flatten(x_decoded_mean)\n     xent_loss = img_rows * img_cols * objectives.binary_crossentropy(x, x_decoded_mean)\n@@ -99,12 +113,14 @@ vae.compile(optimizer='rmsprop', loss=vae_loss)\n vae.summary()\n \n # train the VAE on MNIST digits\n-(x_train, y_train), (x_test, y_test) = mnist.load_data()\n+(x_train, _), (x_test, y_test) = mnist.load_data()\n \n-x_train = x_train.astype('float32')[:, None, :, :] / 255.\n-x_test = x_test.astype('float32')[:, None, :, :] / 255.\n+x_train = x_train.astype('float32') / 255.\n+x_train = x_train.reshape((x_train.shape[0],) + original_img_size)\n+x_test = x_test.astype('float32') / 255.\n+x_test = x_test.reshape((x_test.shape[0],) + original_img_size)\n \n-print(x_train.shape)\n+print('x_train.shape:', x_train.shape)\n \n vae.fit(x_train, x_train,\n         shuffle=True,\n@@ -112,7 +128,6 @@ vae.fit(x_train, x_train,\n         batch_size=batch_size,\n         validation_data=(x_test, x_test))\n \n-\n # build a model to project inputs on the latent space\n encoder = Model(x, z_mean)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ffff5e99aadcab226bb35245ed5eb146ce2b7bc6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 18 | Churn Cumulative: 667 | Contributors (this commit): 13 | Commits (past 90d): 2 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -87,16 +87,28 @@ def print_summary(layers, relevant_nodes=None, line_length=100, positions=[.33,\n                 fields = ['', '', '', connections[i]]\n                 print_row(fields, positions)\n \n-    total_params = 0\n     for i in range(len(layers)):\n         print_layer_summary(layers[i])\n         if i == len(layers) - 1:\n             print('=' * line_length)\n         else:\n             print('_' * line_length)\n-        total_params += layers[i].count_params()\n \n-    print('Total params: %s' % total_params)\n+    def count_total_params(layers, layer_set=None):\n+        if layer_set is None:\n+            layer_set = set()\n+        total_params = 0\n+        for layer in layers:\n+            if layer in layer_set:\n+                continue\n+            layer_set.add(layer)\n+            if type(layer) in (Model, Sequential):\n+                total_params += count_total_params(layer.layers, layer_set)\n+            else:\n+                total_params += layer.count_params()\n+        return total_params\n+\n+    print('Total params: %s' % count_total_params(layers))\n     print('_' * line_length)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5f58a6d2cae6e6e0b50e6e9495dcc31dab054e80", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 23 | Files Changed: 4 | Hunks: 19 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 46 | Churn Cumulative: 3284 | Contributors (this commit): 38 | Commits (past 90d): 66 | Contributors (cumulative): 45 | DMM Complexity: 1.0\n\nDIFF:\n@@ -25,6 +25,8 @@ def librosa_exists():\n \n \n def preprocess_input(audio_path, dim_ordering='default'):\n+    '''Reads an audio file and outputs a Mel-spectrogram.\n+    '''\n     if dim_ordering == 'default':\n         dim_ordering = K.image_dim_ordering()\n     assert dim_ordering in {'tf', 'th'}\n@@ -32,8 +34,8 @@ def preprocess_input(audio_path, dim_ordering='default'):\n     if librosa_exists():\n         import librosa\n     else:\n-        raise RuntimeError('librosa is required to process audio files\\n' +\n-                           'In short, $ pip install librosa\\nor visit ' +\n+        raise RuntimeError('Librosa is required to process audio files.\\n' +\n+                           'Install it via `pip install librosa` \\nor visit ' +\n                            'http://librosa.github.io/librosa/ for details.')\n \n     # mel-spectrogram parameters\n@@ -61,14 +63,15 @@ def preprocess_input(audio_path, dim_ordering='default'):\n               ref_power=1.0)\n \n     if dim_ordering == 'th':\n-        x = x[np.newaxis, :]\n+        x = np.expand_dims(x, axis=0)\n     elif dim_ordering == 'tf':\n-        x = x[:, np.newaxis]\n+        x = np.expand_dims(x, axis=3)\n     return x\n \n \n def decode_predictions(preds, top_n=5):\n-    '''\n+    '''Decode the output of a music tagger model.\n+\n     # Arguments\n         preds: 2-dimensional numpy array\n         top_n: integer in [0, 50], number of items to show\n\n@@ -19,10 +19,11 @@ from ..layers.normalization import BatchNormalization\n from ..layers.advanced_activations import ELU\n from ..layers.recurrent import GRU\n from ..utils.data_utils import get_file\n+from ..utils.layer_utils import convert_all_kernels_in_model\n from .audio_conv_utils import decode_predictions, preprocess_input\n \n-TH_WEIGHTS_PATH = 'https://github.com/keunwoochoi/music-auto_tagging-keras/raw/master/data/music_tagger_crnn_weights_theano.h5'\n-TF_WEIGHTS_PATH = 'https://github.com/keunwoochoi/music-auto_tagging-keras/raw/master/data/music_tagger_crnn_weights_tensorflow.h5'\n+TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.3/music_tagger_crnn_weights_tf_kernels_th_dim_ordering.h5'\n+TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.3/music_tagger_crnn_weights_tf_kernels_tf_dim_ordering.h5'\n \n \n def MusicTaggerCRNN(weights='msd', input_tensor=None,\n@@ -95,28 +96,24 @@ def MusicTaggerCRNN(weights='msd', input_tensor=None,\n     x = BatchNormalization(axis=channel_axis, mode=0, name='bn1')(x)\n     x = ELU()(x)\n     x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool1')(x)\n-    x = Dropout(0.5, name='dropout1')(x)\n \n     # Conv block 2\n     x = Convolution2D(128, 3, 3, border_mode='same', name='conv2')(x)\n     x = BatchNormalization(axis=channel_axis, mode=0, name='bn2')(x)\n     x = ELU()(x)\n     x = MaxPooling2D(pool_size=(3, 3), strides=(3, 3), name='pool2')(x)\n-    x = Dropout(0.5, name='dropout2')(x)\n \n     # Conv block 3\n     x = Convolution2D(128, 3, 3, border_mode='same', name='conv3')(x)\n     x = BatchNormalization(axis=channel_axis, mode=0, name='bn3')(x)\n     x = ELU()(x)\n     x = MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool3')(x)\n-    x = Dropout(0.5, name='dropout3')(x)\n \n     # Conv block 4\n     x = Convolution2D(128, 3, 3, border_mode='same', name='conv4')(x)\n     x = BatchNormalization(axis=channel_axis, mode=0, name='bn4')(x)\n     x = ELU()(x)\n     x = MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool4')(x)\n-    x = Dropout(0.5, name='dropout4')(x)\n \n     # reshaping\n     if K.image_dim_ordering() == 'th':\n@@ -126,7 +123,6 @@ def MusicTaggerCRNN(weights='msd', input_tensor=None,\n     # GRU block 1, 2, output\n     x = GRU(32, return_sequences=True, name='gru1')(x)\n     x = GRU(32, return_sequences=False, name='gru2')(x)\n-    x = Dropout(0.3)(x)\n \n     if include_top:\n         x = Dense(50, activation='sigmoid', name='output')(x)\n@@ -138,17 +134,14 @@ def MusicTaggerCRNN(weights='msd', input_tensor=None,\n     else:\n         # Load weights\n         if K.image_dim_ordering() == 'tf':\n-            raise RuntimeError('Please set `image_dim_ordering` to \"th\".'\n-                               'You can set it at `~/.keras/keras.json`.')\n-\n-        if K._BACKEND == 'theano':\n-            weights_path = get_file('music_tagger_crnn_weights_theano.h5',\n-                                    TH_WEIGHTS_PATH,\n-                                    cache_subdir='models')\n-        else:\n-            weights_path = get_file('music_tagger_crnn_weights_tensorflow.h5',\n+            weights_path = get_file('music_tagger_crnn_weights_tf_kernels_tf_dim_ordering.h5',\n                                     TF_WEIGHTS_PATH,\n                                     cache_subdir='models')\n-\n+        else:\n+            weights_path = get_file('music_tagger_crnn_weights_tf_kernels_th_dim_ordering.h5',\n+                                    TH_WEIGHTS_PATH,\n+                                    cache_subdir='models')\n         model.load_weights(weights_path, by_name=True)\n+        if K.backend() == 'theano':\n+            convert_all_kernels_in_model(model)\n         return model\n\n@@ -1361,6 +1361,7 @@ def elu(x, alpha=1.):\n     else:\n         return tf.select(x > 0, res, alpha*res)\n \n+\n def softmax(x):\n     '''Softmax of a tensor.\n     '''\n\n@@ -3,6 +3,7 @@ import numpy as np\n import scipy as sp\n from six.moves import range\n from six.moves import zip\n+from .. import backend as K\n \n \n def to_categorical(y, nb_classes=None):\n@@ -52,12 +53,14 @@ def categorical_probas_to_classes(p):\n     return np.argmax(p, axis=1)\n \n \n-def convert_kernel(kernel, dim_ordering='th'):\n+def convert_kernel(kernel, dim_ordering='default'):\n     '''Converts a kernel matrix (Numpy array)\n     from Theano format to TensorFlow format\n     (or reciprocally, since the transformation\n     is its own inverse).\n     '''\n+    if dim_ordering == 'default':\n+        dim_ordering = K.image_dim_ordering()\n     new_kernel = np.copy(kernel)\n     if kernel.ndim == 4:\n         # conv 2d\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6ee5d61c9145dd46a80ee1429a19b88bd9eec10a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 31 | Churn Cumulative: 1044 | Contributors (this commit): 9 | Commits (past 90d): 13 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -83,6 +83,7 @@ from keras import backend\n from keras import constraints\n from keras import activations\n from keras import regularizers\n+from keras.utils import io_utils\n \n \n EXCLUDE = {\n@@ -237,6 +238,12 @@ PAGES = [\n         'page': 'backend.md',\n         'all_module_functions': [backend],\n     },\n+    {\n+        'page': 'io_utils.md',\n+        'classes': [\n+            io_utils.HDF5Matrix\n+        ],\n+    },\n ]\n \n ROOT = 'http://keras.io/'\n\n@@ -6,6 +6,30 @@ from collections import defaultdict\n \n \n class HDF5Matrix():\n+    '''Representation of HDF5 dataset which can be used instead of a\n+    Numpy array.\n+\n+    # Example\n+\n+    ```python\n+        X_data = HDF5Matrix('input/file.hdf5', 'data')\n+        model.predict(X_data)\n+    ```\n+\n+    Providing start and end allows use of a slice of the dataset.\n+\n+    Optionally, a normalizer function (or lambda) can be given. This will\n+    be called on every slice of data retrieved.\n+\n+    # Arguments\n+        datapath: string, path to a HDF5 file\n+        dataset: string, name of the HDF5 dataset in the file specified\n+            in datapath\n+        start: int, start of desired slice of the specified dataset\n+        end: int, end of desired slice of the specified dataset\n+        normalizer: function to be called on data when retrieved\n+\n+    '''\n     refs = defaultdict(int)\n \n     def __init__(self, datapath, dataset, start, end, normalizer=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d864512631668fbfb75fe7a454c85577cfbe3278", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1081 | Contributors (this commit): 18 | Commits (past 90d): 17 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -529,7 +529,7 @@ class TestBackend(object):\n \n                 kernel_val = np.random.random(kernel_shape) - 0.5\n \n-                kernel_th = KTH.variable(convert_kernel(kernel_val))\n+                kernel_th = KTH.variable(convert_kernel(kernel_val, dim_ordering='th'))\n                 kernel_tf = KTF.variable(kernel_val)\n \n                 zth = KTH.eval(KTH.conv2d(xth, kernel_th, dim_ordering='th'))\n@@ -573,7 +573,7 @@ class TestBackend(object):\n \n                 kernel_val = np.random.random(kernel_shape) - 0.5\n \n-                kernel_th = KTH.variable(convert_kernel(kernel_val))\n+                kernel_th = KTH.variable(convert_kernel(kernel_val, dim_ordering='th'))\n                 kernel_tf = KTF.variable(kernel_val)\n \n                 zth = KTH.eval(KTH.conv3d(xth, kernel_th, dim_ordering='th'))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c455a19f8e303b5ab1530fe98808808a30c77647", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 9 | Churn Cumulative: 143 | Contributors (this commit): 4 | Commits (past 90d): 5 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -32,7 +32,7 @@ class HDF5Matrix():\n     '''\n     refs = defaultdict(int)\n \n-    def __init__(self, datapath, dataset, start, end, normalizer=None):\n+    def __init__(self, datapath, dataset, start=0, end=None, normalizer=None):\n         import h5py\n \n         if datapath not in list(self.refs.keys()):\n@@ -40,9 +40,12 @@ class HDF5Matrix():\n             self.refs[datapath] = f\n         else:\n             f = self.refs[datapath]\n-        self.start = start\n-        self.end = end\n         self.data = f[dataset]\n+        self.start = start\n+        if end is None:\n+            self.end = self.data.shape[0]\n+        else:\n+            self.end = end\n         self.normalizer = normalizer\n \n     def __len__(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9194052a94921ab2e1b4deacb4a43748d0456245", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 739 | Contributors (this commit): 17 | Commits (past 90d): 9 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -58,7 +58,7 @@ class BatchNormalization(Layer):\n         Same shape as input.\n \n     # References\n-        - [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](http://jmlr.org/proceedings/papers/v37/ioffe15.html)\n+        - [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](http://jmlr.org/proceedings/papers/v37/ioffe15.pdf)\n     '''\n     def __init__(self, epsilon=1e-5, mode=0, axis=-1, momentum=0.99,\n                  weights=None, beta_init='zero', gamma_init='one',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b5dddeb4191395b3260214a874e887df6dfec895", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 144 | Lines Deleted: 11 | Files Changed: 2 | Hunks: 12 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 155 | Churn Cumulative: 672 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -0,0 +1,136 @@\n+from keras.models import Sequential\n+from keras.layers.convolutional import Convolution3D\n+from keras.layers.recurrent_convolutional import LSTMConv2D\n+from keras.layers.normalization import BatchNormalization\n+import numpy as np\n+from pylab import *\n+\n+# We create a layer whose take movies as input\n+# of shape (time, width, height, channel) and that return a movie\n+# with identical shape.\n+\n+seq = Sequential()\n+seq.add(LSTMConv2D(nb_filter=40, nb_row=3, nb_col=3,\n+                   input_shape=(None, 40, 40, 1),\n+                   border_mode=\"same\", return_sequences=True))\n+seq.add(BatchNormalization())\n+\n+seq.add(LSTMConv2D(nb_filter=40, nb_row=3, nb_col=3,\n+                   border_mode=\"same\", return_sequences=True))\n+seq.add(BatchNormalization())\n+\n+seq.add(LSTMConv2D(nb_filter=40, nb_row=3, nb_col=3,\n+                   border_mode=\"same\", return_sequences=True))\n+seq.add(BatchNormalization())\n+\n+seq.add(LSTMConv2D(nb_filter=40, nb_row=3, nb_col=3,\n+                   border_mode=\"same\", return_sequences=True))\n+seq.add(BatchNormalization())\n+\n+seq.add(Convolution3D(nb_filter=1, kernel_dim1=1, kernel_dim2=3,\n+                      kernel_dim3=3, activation='sigmoid',\n+                      border_mode=\"same\", dim_ordering=\"tf\"))\n+\n+seq.compile(loss=\"binary_crossentropy\", optimizer=\"adadelta\")\n+\n+\n+# Generating artificial data:\n+# We are going to create a movie with\n+# square of size one or two by two pixels moving linearly\n+# trought time. For convenience we first create\n+# a movie with bigger width and height, and at the end\n+# we cut it to 40x40\n+\n+time = 15\n+row = 80\n+col = 80\n+filters = 1\n+training = 1200\n+train = np.zeros((training, time, row, col, 1), dtype=np.float)\n+gt = np.zeros((training, time, row, col, 1), dtype=np.float)\n+\n+for i in range(training):\n+\n+    # add from 3 to 7 moving squares\n+    n = np.random.randint(3, 8)\n+\n+    for j in range(n):\n+        # Initial position\n+        xstart = np.random.randint(20, 60)\n+        ystart = np.random.randint(20, 60)\n+        # Direction of motion\n+        directionx = np.random.randint(0, 3) - 1\n+        directiony = np.random.randint(0, 3) - 1\n+\n+        # Size of the square\n+        w = np.random.randint(2, 4)\n+\n+        for t in range(time):\n+            x_shift = xstart + directionx * t\n+            y_shift = ystart + directiony * t\n+            train[i, t, x_shift - w: x_shift + w,\n+                  y_shift - w: y_shift + w, 0] += 1\n+\n+            # Make it more robust by adding noise.\n+            # The idea is that if during predict time,\n+            # the value of the pixel is not exactly one,\n+            # we need to train the network to be robust and stille\n+            # consider it is a pixel belonging to a square.\n+            if np.random.randint(0, 2):\n+                noise_f = (-1)**np.random.randint(0, 2)\n+                train[i, t, x_shift - w - 1: x_shift + w + 1,\n+                      y_shift - w - 1: y_shift + w + 1, 0] += noise_f * 0.1\n+\n+            # Shitf the ground truth by 1\n+            x_shift = xstart + directionx * (t + 1)\n+            y_shift = ystart + directiony * (t + 1)\n+            gt[i, t, x_shift - w: x_shift + w,\n+               y_shift - w: y_shift + w, 0] += 1\n+\n+# Cut to a forty's sized window\n+train = train[::, ::, 20:60, 20:60, ::]\n+gt = gt[::, ::, 20:60, 20:60, ::]\n+train[train >= 1] = 1\n+gt[gt >= 1] = 1\n+\n+# Train the network\n+seq.fit(train[:1000], gt[:1000], batch_size=10,\n+        nb_epoch=300, validation_split=0.05)\n+\n+# Testing the network on one movie\n+# feed it with the first 7 positions and then\n+# predict the new positions\n+which = 1004\n+track = train[which][:7, ::, ::, ::]\n+\n+for j in range(16):\n+    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n+    new = new_pos[::, -1, ::, ::, ::]\n+    track = np.concatenate((track, new), axis=0)\n+\n+\n+# And then compare the predictions\n+# to the ground truth\n+track2 = train[which][::, ::, ::, ::]\n+for i in range(15):\n+    fig = figure(figsize=(10, 5))\n+\n+    ax = fig.add_subplot(121)\n+\n+    if i >= 7:\n+        ax.text(1, 3, \"Predictions !\", fontsize=20, color=\"w\")\n+    else:\n+        ax.text(1, 3, \"Inital trajectory\", fontsize=20)\n+\n+    toplot = track[i, ::, ::, 0]\n+\n+    imshow(toplot)\n+    ax = fig.add_subplot(122)\n+    text(1, 3, \"Ground truth\", fontsize=20)\n+\n+    toplot = track2[i, ::, ::, 0]\n+    if i >= 2:\n+        toplot = gt[which][i - 1, ::, ::, 0]\n+\n+    imshow(toplot)\n+    savefig(\"%i_animate.png\" % (i + 1))\n\n@@ -156,10 +156,9 @@ class RecurrentConv2D(Layer):\n \n     def preprocess_input(self, x):\n         return x\n+\n     def call(self, x, mask=None):\n \n-       \n-\n         assert K.ndim(x) == 5\n         input_shape = self.input_spec[0].shape\n \n@@ -179,7 +178,6 @@ class RecurrentConv2D(Layer):\n         constants = self.get_constants(x)\n         preprocessed_input = self.preprocess_input(x)\n \n-\n         last_output, outputs, states = K.rnn(self.step, preprocessed_input,\n                                              initial_states,\n                                              go_backwards=self.go_backwards,\n@@ -288,7 +286,8 @@ class LSTMConv2D(RecurrentConv2D):\n         assert dim_ordering in {'tf', \"th\"}, 'dim_ordering must be in {tf,\"th}'\n \n         if dim_ordering == \"th\":\n-            print \"Warning, unlike convolution3D the time must be the first dimention\"\n+            print(\"Warning, unlike convolution3D the time must be the \" +\\\n+                  \"first dimention\")\n         self.dim_ordering = dim_ordering\n \n         kwargs[\"nb_filter\"] = nb_filter\n@@ -308,7 +307,6 @@ class LSTMConv2D(RecurrentConv2D):\n     def build(self, input_shape):\n         self.input_spec = [InputSpec(shape=input_shape)]\n \n-\n         if self.dim_ordering == 'th':\n             stack_size = input_shape[1+1]\n             self.W_shape = (self.nb_filter, stack_size,\n@@ -345,7 +343,7 @@ class LSTMConv2D(RecurrentConv2D):\n \n         self.W_c = self.init(self.W_shape)\n         self.U_c = self.inner_init(self.W_shape1)\n-        self.b_c = K.zeros((self.nb_filter))\n+        self.b_c = K.zeros((self.nb_filter,))\n \n         self.W_o = self.init(self.W_shape)\n         self.U_o = self.inner_init(self.W_shape1)\n@@ -356,7 +354,6 @@ class LSTMConv2D(RecurrentConv2D):\n                                   self.W_f, self.U_f, self.b_f,\n                                   self.W_o, self.U_o, self.b_o]\n \n- \n         self.W = K.concatenate([self.W_i, self.W_f, self.W_c, self.W_o])\n         self.U = K.concatenate([self.U_i, self.U_f, self.U_c, self.U_o])\n         self.b = K.concatenate([self.b_i, self.b_f, self.b_c, self.b_o])\n@@ -478,13 +475,13 @@ class LSTMConv2D(RecurrentConv2D):\n \n         return h, [h, c]\n \n-\n     def get_constants(self, x):\n         constants = []\n         if 0 < self.dropout_U < 1:\n             ones = K.ones_like(K.reshape(x[:, 0, 0], (-1, 1)))\n             ones = K.concatenate([ones] * self.output_dim, 1)\n-            B_U = [K.in_train_phase(K.dropout(ones, self.dropout_U), ones) for _ in range(4)]\n+            B_U = [K.in_train_phase(K.dropout(ones, self.dropout_U), ones)\n+                   for _ in range(4)]\n             constants.append(B_U)\n         else:\n             constants.append([K.cast_to_floatx(1.) for _ in range(4)])\n@@ -494,13 +491,13 @@ class LSTMConv2D(RecurrentConv2D):\n             input_dim = input_shape[-1]\n             ones = K.ones_like(K.reshape(x[:, 0, 0], (-1, 1)))\n             ones = K.concatenate([ones] * input_dim, 1)\n-            B_W = [K.in_train_phase(K.dropout(ones, self.dropout_W), ones) for _ in range(4)]\n+            B_W = [K.in_train_phase(K.dropout(ones, self.dropout_W), ones)\n+                   for _ in range(4)]\n             constants.append(B_W)\n         else:\n             constants.append([K.cast_to_floatx(1.) for _ in range(4)])\n         return constants\n \n-\n     def get_config(self):\n         config = {\"name\": self.__class__.__name__,\n                   \"nb_filter\": self.nb_filter,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
