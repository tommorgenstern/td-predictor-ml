{"custom_id": "keras#2209914d5d1514e000ae0fded355273d7cedced4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 27 | Files Changed: 2 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 31 | Churn Cumulative: 6912 | Contributors (this commit): 18 | Commits (past 90d): 9 | Contributors (cumulative): 27 | DMM Complexity: 0.3888888888888889\n\nDIFF:\n@@ -26,9 +26,6 @@ from keras.optimizers.optimizer_v2 import utils as optimizer_utils\n from keras.saving.legacy import serialization\n \n # isort: off\n-from tensorflow.python.keras.optimizer_v2 import (\n-    optimizer_v2 as legacy_optimizer,\n-)\n from tensorflow.python.platform import tf_logging\n from tensorflow.python.util.tf_export import keras_export\n \n@@ -345,13 +342,6 @@ class LossScaleOptimizerMetaclass(type):\n             \"`tf.keras.optimizers.experimental.Optimizer`, but got: \"\n             f\"{inner_optimizer}.\"\n         )\n-        if isinstance(inner_optimizer, legacy_optimizer.OptimizerV2):\n-            msg += (\n-                ' Please make sure \"inner_optimizer\" is not an instance of '\n-                \"`tensorflow.python.keras.optimizers`, which is \"\n-                \"the legacy keras code and will be removed in future release. \"\n-                \"Please use the tf.keras public API instead.\"\n-            )\n         raise TypeError(msg)\n \n \n@@ -624,13 +614,6 @@ class LossScaleOptimizer(\n                 \"`tf.keras.optimizers.Optimizer`, but got: %s. \"\n                 % inner_optimizer\n             )\n-            if isinstance(inner_optimizer, legacy_optimizer.OptimizerV2):\n-                msg += (\n-                    'Please make sure \"inner_optimizer\" is not an instance of '\n-                    \"`tensorflow.python.keras.optimizers`, which is \"\n-                    \"the legacy keras code and will be removed in future \"\n-                    \"release. Please use the tf.keras public API instead.\"\n-                )\n             raise TypeError(msg)\n         if not isinstance(dynamic, bool):\n             # Catch errors if a user incorrectly passes a string or float to the\n\n@@ -38,9 +38,6 @@ from keras.testing_infra import test_combinations\n from tensorflow.python.framework import (\n     test_util as tf_test_utils,\n )\n-from tensorflow.python.keras.optimizer_v2 import (\n-    gradient_descent as legacy_sgd,\n-)\n from tensorflow.python.platform import tf_logging\n \n # If called outside any strategy.scope() calls, this will return the default\n@@ -1284,6 +1281,10 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n                 \"before\",\n                 mock_warn.call_args_list[0][0][0],\n             )\n+\n+    @test_combinations.generate(opt_combinations_only())\n+    def testScalingNoWarning(self, opt_cls):\n+        var = tf.Variable(1.0)\n         lso = create_lso(create_sgd(opt_cls))\n         with mock.patch.object(tf_logging, \"warning\") as mock_warn:\n             lso.get_scaled_loss(tf.constant(1.0))\n@@ -1320,13 +1321,6 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n         ):\n             loss_scale_optimizer.BaseLossScaleOptimizer(1)\n \n-    def testErrorWhenWrappingLegacyKerasOptimizers(self):\n-        sgd = legacy_sgd.SGD()\n-        with self.assertRaisesRegex(\n-            TypeError, \"not an instance of `tensorflow.python.keras.optimizers`\"\n-        ):\n-            loss_scale_optimizer.BaseLossScaleOptimizer(sgd)\n-\n     def testErrorWhenV3LsoWrapsV2Optimizer(self):\n         sgd = gradient_descent.SGD()\n         with self.assertRaisesRegex(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b52e3d2fb5ca0f2ca2ccf1be0653a094ef36fbf4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 130 | Contributors (this commit): 8 | Commits (past 90d): 4 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -98,7 +98,7 @@ class SGD(optimizer_v2.OptimizerV2):\n \n     Reference:\n         - For `nesterov=True`, See [Sutskever et al., 2013](\n-          http://jmlr.org/proceedings/papers/v28/sutskever13.pdf).\n+          https://github.com/mlresearch/v28/blob/gh-pages/sutskever13.pdf).\n     \"\"\"\n \n     _HAS_AGGREGATE_GRAD = True\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#330eb89a9a94e2621cfa03e813e3d252e91ee15a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 129 | Contributors (this commit): 7 | Commits (past 90d): 6 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -97,7 +97,6 @@ class SGD(optimizer.Optimizer):\n         learning_rate=0.01,\n         momentum=0.0,\n         nesterov=False,\n-        amsgrad=False,\n         weight_decay=None,\n         clipnorm=None,\n         clipvalue=None,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#62832d0b5c319b2202170fe580e3471f157b1575", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 7 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 38 | Churn Cumulative: 2365 | Contributors (this commit): 5 | Commits (past 90d): 15 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -52,14 +52,36 @@ _SAVING_V3_ENABLED.value = False\n \n ATTR_SKIPLIST = frozenset(\n     {\n-        \"__dict__\",\n-        \"_self_tracked_trackables\",\n-        \"_layer_call_argspecs\",\n-        \"_self_unconditional_dependency_names\",\n+        \"_callable_losses\",\n+        \"_captured_weight_regularizer\",\n+        \"_checkpoint_dependencies\",\n+        \"_deferred_dependencies\",\n+        \"_eager_losses\",\n+        \"_inbound_nodes\",\n+        \"_inbound_nodes_value\",\n         \"_output_layers\",\n         \"_input_layers\",\n+        \"_keras_api_names\",\n+        \"_keras_api_names_v1\",\n+        \"_name_based_restores\",\n+        \"_non_trainable_weights\",\n+        \"_outbound_nodes\",\n+        \"_outbound_nodes_value\",\n+        \"_saved_model_arg_spec\",\n+        \"_self_name_based_restores\",\n+        \"_self_saveable_object_factories\",\n+        \"_self_tracked_trackables\",\n+        \"_self_unconditional_checkpoint_dependencies\",\n+        \"_self_unconditional_deferred_dependencies\",\n+        \"_self_unconditional_dependency_names\",\n+        \"_tf_api_names\",\n+        \"_tf_api_names_v1\",\n         \"_trainable_weights\",\n         \"_non_trainable_weights\",\n+        \"_unconditional_checkpoint_dependencies\",\n+        \"_unconditional_dependency_names\",\n+        \"_updates\",\n+        \"inbound_nodes\",\n         \"submodules\",\n         \"weights\",\n         \"non_trainable_weights\",\n@@ -311,7 +333,7 @@ def _save_state(\n \n     # Recursively save state of children trackables (layers, optimizers, etc.)\n     for child_attr in dir(trackable):\n-        if child_attr in ATTR_SKIPLIST:\n+        if child_attr.startswith(\"__\") or child_attr in ATTR_SKIPLIST:\n             continue\n         try:\n             child_obj = getattr(trackable, child_attr)\n@@ -326,7 +348,7 @@ def _save_state(\n                 inner_path=tf.io.gfile.join(inner_path, child_attr),\n                 visited_trackables=visited_trackables,\n             )\n-        elif isinstance(child_obj, (list, dict, tuple)):\n+        elif isinstance(child_obj, (list, dict, tuple, set)):\n             _save_container_state(\n                 child_obj,\n                 weights_store,\n@@ -351,7 +373,7 @@ def _load_state(\n \n     # Recursively load states for Keras trackables such as layers/optimizers.\n     for child_attr in dir(trackable):\n-        if child_attr in ATTR_SKIPLIST:\n+        if child_attr.startswith(\"__\") or child_attr in ATTR_SKIPLIST:\n             continue\n         try:\n             child_obj = getattr(trackable, child_attr)\n@@ -366,7 +388,7 @@ def _load_state(\n                 inner_path=tf.io.gfile.join(inner_path, child_attr),\n                 visited_trackables=visited_trackables,\n             )\n-        elif isinstance(child_obj, (list, dict, tuple)):\n+        elif isinstance(child_obj, (list, dict, tuple, set)):\n             _load_container_state(\n                 child_obj,\n                 weights_store,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f2b3ef620d3eb412fdb0a07f2f23933351351eab", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 9485 | Contributors (this commit): 115 | Commits (past 90d): 13 | Contributors (cumulative): 115 | DMM Complexity: None\n\nDIFF:\n@@ -2354,7 +2354,8 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n           same applies for `'epoch'`. If using an integer, let's say `1000`, the\n           callback will write the metrics and losses to TensorBoard every 1000\n           batches. Note that writing too frequently to TensorBoard can slow down\n-          your training.\n+          your training. May not work when doing distributed training, as\n+          currently only a subset of `tf.distribute.Strategy`s are supported.\n         profile_batch: Profile the batch(es) to sample compute characteristics.\n           profile_batch must be a non-negative integer or a tuple of integers.\n           A pair of positive integers signify a range of batches to profile.\n@@ -2775,8 +2776,9 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n                 step=self._train_step,\n             )\n \n-        # `logs` is a `RemoteValue` when using asynchronous strategies, for now\n-        # we just disable `update_freq` entirely in those cases.\n+        # `logs` is a `tf.distribute.experimental.coordinator.RemoteValue` when\n+        # using asynchronous strategies, for now we just disable `update_freq`\n+        # entirely in those cases.\n         if isinstance(logs, dict):\n             for name, value in logs.items():\n                 tf.summary.scalar(\"batch_\" + name, value, step=self._train_step)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#aba9edd22d64e76518848054f22589128378cee8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2095 | Lines Deleted: 1 | Files Changed: 18 | Hunks: 17 | Methods Changed: 122 | Complexity Δ (Sum/Max): 190/28 | Churn Δ: 2096 | Churn Cumulative: 2360 | Contributors (this commit): 7 | Commits (past 90d): 20 | Contributors (cumulative): 24 | DMM Complexity: 0.8493589743589743\n\nDIFF:\n@@ -0,0 +1,101 @@\n+\"\"\"Test Model.fit across a diverse range of models.\"\"\"\n+\n+import tensorflow.compat.v2 as tf\n+from absl.testing import parameterized\n+\n+from keras.integration_test.models import bert\n+from keras.integration_test.models import dcgan\n+from keras.integration_test.models import edge_case_model\n+from keras.integration_test.models import efficientnet_v2\n+from keras.integration_test.models import input_spec\n+from keras.integration_test.models import low_level_model\n+from keras.integration_test.models import mini_unet\n+from keras.integration_test.models import mini_xception\n+from keras.integration_test.models import retinanet\n+from keras.integration_test.models import structured_data_classification\n+from keras.integration_test.models import text_classification\n+from keras.integration_test.models import timeseries_forecasting\n+from keras.integration_test.models import vae\n+from keras.testing_infra import test_combinations\n+from keras.testing_infra import test_utils\n+\n+# from keras.integration_test.models import ctc_speech_rnn\n+# from keras.integration_test.models import translation\n+\n+\n+def get_dataset(data_specs, batch_size):\n+    values = tf.nest.map_structure(input_spec.spec_to_value, data_specs)\n+    dataset = (\n+        tf.data.Dataset.from_tensor_slices(values)\n+        .prefetch(batch_size * 2)\n+        .batch(batch_size)\n+    )\n+    return dataset\n+\n+\n+@test_utils.run_v2_only\n+class FitTest(test_combinations.TestCase):\n+    @parameterized.named_parameters(\n+        (\"bert\", bert),\n+        # (\"ctc_speech_rnn\", ctc_speech_rnn),  # Buggy?\n+        (\"dcgan\", dcgan),\n+        (\"edge_case_model\", edge_case_model),\n+        (\"efficientnet_v2\", efficientnet_v2),\n+        (\"low_level_model\", low_level_model),\n+        (\"mini_unet\", mini_unet),\n+        (\"mini_xception\", mini_xception),\n+        (\"retinanet\", retinanet),\n+        (\"structured_data_classification\", structured_data_classification),\n+        (\"text_classification\", text_classification),\n+        (\"timeseries_forecasting\", timeseries_forecasting),\n+        # (\"translation\", translation),  # Buggy?\n+        (\"vae\", vae),\n+    )\n+    def test_fit_on_all_models_with_sync_preprocessing(self, module):\n+        batch_size = 4\n+        data_specs = module.get_data_spec(batch_size * 3)\n+        dataset = get_dataset(data_specs, batch_size)\n+\n+        model = module.get_model(\n+            build=True,\n+            compile=True,\n+            jit_compile=False,\n+            include_preprocessing=True,\n+        )\n+        model.fit(dataset, epochs=1)\n+\n+    @parameterized.named_parameters(\n+        (\"bert\", bert),\n+        # (\"ctc_speech_rnn\", ctc_speech_rnn),  # Buggy?\n+        (\"dcgan\", dcgan),\n+        (\"edge_case_model\", edge_case_model),\n+        (\"efficientnet_v2\", efficientnet_v2),\n+        (\"low_level_model\", low_level_model),\n+        # (\"mini_unet\", mini_unet),  # Not XLA compatible b/c of UpSampling2D\n+        (\"mini_xception\", mini_xception),\n+        # (\"retinanet\", retinanet),  # Not XLA compatible b/c of UpSampling2D\n+        (\"structured_data_classification\", structured_data_classification),\n+        (\"text_classification\", text_classification),\n+        (\"timeseries_forecasting\", timeseries_forecasting),\n+        # (\"translation\", translation),  # Buggy?\n+        (\"vae\", vae),\n+    )\n+    def test_fit_on_all_models_with_async_preprocessing_and_xla(self, module):\n+        batch_size = 4\n+        data_specs = module.get_data_spec(batch_size * 3)\n+        dataset = get_dataset(data_specs, batch_size)\n+        preprocessor = module.get_input_preprocessor()\n+        if preprocessor is not None:\n+            dataset = dataset.map(lambda x, y: (preprocessor(x), y))\n+\n+        model = module.get_model(\n+            build=True,\n+            compile=True,\n+            jit_compile=True,\n+            include_preprocessing=False,\n+        )\n+        model.fit(dataset, epochs=1)\n+\n+\n+if __name__ == \"__main__\":\n+    tf.test.main()\n\n\n@@ -0,0 +1,150 @@\n+\"\"\"Bert model.\n+\n+Adapted from https://keras.io/examples/nlp/masked_language_modeling/\n+\"\"\"\n+import numpy as np\n+import tensorflow as tf\n+from tensorflow import keras\n+\n+from keras.integration_test.models.input_spec import InputSpec\n+\n+SEQUENCE_LENGTH = 16\n+VOCAB_SIZE = 1000\n+EMBED_DIM = 64\n+NUM_HEAD = 2\n+FF_DIM = 32\n+NUM_LAYERS = 2\n+\n+\n+def get_data_spec(batch_size):\n+    return (\n+        InputSpec((batch_size,), dtype=\"string\"),\n+        InputSpec((batch_size, SEQUENCE_LENGTH, VOCAB_SIZE)),\n+    )\n+\n+\n+def get_input_preprocessor():\n+    input_vectorizer = keras.layers.TextVectorization(\n+        max_tokens=VOCAB_SIZE,\n+        output_mode=\"int\",\n+        output_sequence_length=SEQUENCE_LENGTH,\n+    )\n+    text_ds = tf.data.Dataset.from_tensor_slices(\n+        [\n+            \"Lorem ipsum dolor sit amet\",\n+            \"consectetur adipiscing elit\",\n+            \"sed do eiusmod tempor incididunt ut\",\n+            \"labore et dolore magna aliqua.\",\n+            \"Ut enim ad minim veniam\",\n+            \"quis nostrud exercitation ullamco\",\n+            \"laboris nisi ut aliquip ex ea commodo consequat.\",\n+        ]\n+    )\n+    input_vectorizer.adapt(text_ds)\n+    return input_vectorizer\n+\n+\n+def bert_module(query, key, value, i):\n+    attention_output = keras.layers.MultiHeadAttention(\n+        num_heads=NUM_HEAD,\n+        key_dim=EMBED_DIM // NUM_HEAD,\n+    )(query, key, value)\n+    attention_output = keras.layers.Dropout(0.1)(attention_output)\n+    attention_output = keras.layers.LayerNormalization(epsilon=1e-6)(\n+        query + attention_output\n+    )\n+\n+    ffn = keras.Sequential(\n+        [\n+            keras.layers.Dense(FF_DIM, activation=\"relu\"),\n+            keras.layers.Dense(EMBED_DIM),\n+        ],\n+    )\n+    ffn_output = ffn(attention_output)\n+    ffn_output = keras.layers.Dropout(0.1)(ffn_output)\n+    sequence_output = keras.layers.LayerNormalization(epsilon=1e-6)(\n+        attention_output + ffn_output\n+    )\n+    return sequence_output\n+\n+\n+def get_pos_encoding_matrix(max_len, d_emb):\n+    pos_enc = np.array(\n+        [\n+            [pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)]\n+            if pos != 0\n+            else np.zeros(d_emb)\n+            for pos in range(max_len)\n+        ]\n+    )\n+    pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2])\n+    pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2])\n+    return pos_enc\n+\n+\n+loss_fn = keras.losses.CategoricalCrossentropy()\n+loss_tracker = keras.metrics.Mean(name=\"loss\")\n+\n+\n+class MaskedLanguageModel(keras.Model):\n+    def train_step(self, inputs):\n+        if len(inputs) == 3:\n+            features, labels, sample_weight = inputs\n+        else:\n+            features, labels = inputs\n+            sample_weight = None\n+\n+        with tf.GradientTape() as tape:\n+            predictions = self(features, training=True)\n+            loss = loss_fn(labels, predictions, sample_weight=sample_weight)\n+\n+        trainable_vars = self.trainable_variables\n+        gradients = tape.gradient(loss, trainable_vars)\n+        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n+        loss_tracker.update_state(loss, sample_weight=sample_weight)\n+        return {\"loss\": loss_tracker.result()}\n+\n+    @property\n+    def metrics(self):\n+        return [loss_tracker]\n+\n+\n+def get_model(\n+    build=False, compile=False, jit_compile=False, include_preprocessing=True\n+):\n+    if include_preprocessing:\n+        inputs = keras.layers.Input((), dtype=\"string\")\n+        x = get_input_preprocessor()(inputs)\n+    else:\n+        inputs = keras.layers.Input((SEQUENCE_LENGTH,), dtype=tf.int64)\n+        x = inputs\n+    word_embeddings = keras.layers.Embedding(VOCAB_SIZE, EMBED_DIM)(x)\n+    position_embeddings = keras.layers.Embedding(\n+        input_dim=SEQUENCE_LENGTH,\n+        output_dim=EMBED_DIM,\n+        weights=[get_pos_encoding_matrix(SEQUENCE_LENGTH, EMBED_DIM)],\n+        trainable=False,\n+    )(tf.range(start=0, limit=SEQUENCE_LENGTH, delta=1))\n+    embeddings = word_embeddings + position_embeddings\n+\n+    encoder_output = embeddings\n+    for i in range(NUM_LAYERS):\n+        encoder_output = bert_module(\n+            encoder_output, encoder_output, encoder_output, i\n+        )\n+\n+    mlm_output = keras.layers.Dense(\n+        VOCAB_SIZE, name=\"mlm_cls\", activation=\"softmax\"\n+    )(encoder_output)\n+    model = MaskedLanguageModel(inputs, mlm_output)\n+\n+    if compile:\n+        optimizer = keras.optimizers.Adam()\n+        model.compile(optimizer=optimizer, jit_compile=jit_compile)\n+    return model\n+\n+\n+def get_custom_objects():\n+    return {\n+        \"MaskedLanguageModel\": MaskedLanguageModel,\n+    }\n\n@@ -0,0 +1,100 @@\n+import tensorflow as tf\n+from tensorflow import keras\n+\n+from keras.integration_test.models.input_spec import InputSpec\n+\n+TIMESTEPS = 64\n+INPUT_DIM = 50\n+OUTPUT_DIM = 40\n+NUM_RNN_LAYERS = 2\n+RNN_UNITS = 32\n+\n+\n+def get_input_preprocessor():\n+    return None\n+\n+\n+def get_data_spec(batch_size):\n+    return (\n+        InputSpec((batch_size, TIMESTEPS, INPUT_DIM)),\n+        InputSpec((batch_size, 1), dtype=\"int64\", range=[0, OUTPUT_DIM]),\n+    )\n+\n+\n+def ctc_loss(y_true, y_pred):\n+    batch_length = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n+    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n+    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n+\n+    input_length = input_length * tf.ones(\n+        shape=(batch_length, 1), dtype=\"int64\"\n+    )\n+    label_length = label_length * tf.ones(\n+        shape=(batch_length, 1), dtype=\"int64\"\n+    )\n+\n+    return keras.backend.ctc_batch_cost(\n+        y_true, y_pred, input_length, label_length\n+    )\n+\n+\n+def get_model(\n+    build=False, compile=False, jit_compile=False, include_preprocessing=True\n+):\n+    input_spectrogram = keras.layers.Input((None, INPUT_DIM), name=\"input\")\n+    x = keras.layers.Reshape((-1, INPUT_DIM, 1), name=\"expand_dim\")(\n+        input_spectrogram\n+    )\n+    x = keras.layers.Conv2D(\n+        filters=32,\n+        kernel_size=[11, 41],\n+        strides=[2, 2],\n+        padding=\"same\",\n+        use_bias=False,\n+        name=\"conv_1\",\n+    )(x)\n+    x = keras.layers.BatchNormalization(name=\"conv_1_bn\")(x)\n+    x = keras.layers.ReLU(name=\"conv_1_relu\")(x)\n+    x = keras.layers.Conv2D(\n+        filters=32,\n+        kernel_size=[11, 21],\n+        strides=[1, 2],\n+        padding=\"same\",\n+        use_bias=False,\n+        name=\"conv_2\",\n+    )(x)\n+    x = keras.layers.BatchNormalization(name=\"conv_2_bn\")(x)\n+    x = keras.layers.ReLU(name=\"conv_2_relu\")(x)\n+    x = keras.layers.Reshape((-1, x.shape[-2] * x.shape[-1]))(x)\n+    for i in range(1, NUM_RNN_LAYERS + 1):\n+        recurrent = keras.layers.GRU(\n+            units=RNN_UNITS,\n+            activation=\"tanh\",\n+            recurrent_activation=\"sigmoid\",\n+            use_bias=True,\n+            return_sequences=True,\n+            reset_after=True,\n+            name=f\"gru_{i}\",\n+        )\n+        x = keras.layers.Bidirectional(\n+            recurrent, name=f\"bidirectional_{i}\", merge_mode=\"concat\"\n+        )(x)\n+        if i < NUM_RNN_LAYERS:\n+            x = keras.layers.Dropout(rate=0.5)(x)\n+    x = keras.layers.Dense(units=RNN_UNITS * 2, name=\"dense_1\")(x)\n+    x = keras.layers.ReLU(name=\"dense_1_relu\")(x)\n+    x = keras.layers.Dropout(rate=0.5)(x)\n+    output = keras.layers.Dense(units=OUTPUT_DIM + 1, activation=\"softmax\")(x)\n+    model = keras.Model(input_spectrogram, output, name=\"DeepSpeech_2\")\n+\n+    if compile:\n+        model.compile(\n+            optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n+            loss=ctc_loss,\n+            jit_compile=jit_compile,\n+        )\n+    return model\n+\n+\n+def get_custom_objects():\n+    return {\"ctc_loss\": ctc_loss}\n\n@@ -0,0 +1,136 @@\n+import tensorflow as tf\n+from tensorflow import keras\n+\n+from keras.integration_test.models.input_spec import InputSpec\n+\n+IMG_SIZE = (64, 64)\n+LATENT_DIM = 128\n+\n+\n+def get_data_spec(batch_size):\n+    return InputSpec((batch_size,) + IMG_SIZE + (3,))\n+\n+\n+def get_input_preprocessor():\n+    return None\n+\n+\n+class GAN(keras.Model):\n+    def __init__(self, discriminator, generator, latent_dim):\n+        super(GAN, self).__init__()\n+        self.discriminator = discriminator\n+        self.generator = generator\n+        self.latent_dim = latent_dim\n+\n+    def compile(self, d_optimizer, g_optimizer, loss_fn, jit_compile=False):\n+        super(GAN, self).compile(jit_compile=jit_compile)\n+        self.d_optimizer = d_optimizer\n+        self.g_optimizer = g_optimizer\n+        self.loss_fn = loss_fn\n+        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n+        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n+\n+    @property\n+    def metrics(self):\n+        return [self.d_loss_metric, self.g_loss_metric]\n+\n+    def train_step(self, real_images):\n+        batch_size = tf.shape(real_images)[0]\n+        random_latent_vectors = tf.random.normal(\n+            shape=(batch_size, self.latent_dim)\n+        )\n+        generated_images = self.generator(random_latent_vectors)\n+        combined_images = tf.concat([generated_images, real_images], axis=0)\n+        labels = tf.concat(\n+            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n+        )\n+        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n+\n+        with tf.GradientTape() as tape:\n+            predictions = self.discriminator(combined_images)\n+            d_loss = self.loss_fn(labels, predictions)\n+        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n+        self.d_optimizer.apply_gradients(\n+            zip(grads, self.discriminator.trainable_weights)\n+        )\n+\n+        random_latent_vectors = tf.random.normal(\n+            shape=(batch_size, self.latent_dim)\n+        )\n+        misleading_labels = tf.zeros((batch_size, 1))\n+\n+        with tf.GradientTape() as tape:\n+            predictions = self.discriminator(\n+                self.generator(random_latent_vectors)\n+            )\n+            g_loss = self.loss_fn(misleading_labels, predictions)\n+        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n+        self.g_optimizer.apply_gradients(\n+            zip(grads, self.generator.trainable_weights)\n+        )\n+        self.d_loss_metric.update_state(d_loss)\n+        self.g_loss_metric.update_state(g_loss)\n+        return {\n+            \"d_loss\": self.d_loss_metric.result(),\n+            \"g_loss\": self.g_loss_metric.result(),\n+        }\n+\n+\n+def get_model(\n+    build=False, compile=False, jit_compile=False, include_preprocessing=True\n+):\n+    discriminator = keras.Sequential(\n+        [\n+            keras.Input(shape=IMG_SIZE + (3,)),\n+            keras.layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n+            keras.layers.LeakyReLU(alpha=0.2),\n+            keras.layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n+            keras.layers.LeakyReLU(alpha=0.2),\n+            keras.layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n+            keras.layers.LeakyReLU(alpha=0.2),\n+            keras.layers.Flatten(),\n+            keras.layers.Dropout(0.2),\n+            keras.layers.Dense(1, activation=\"sigmoid\"),\n+        ],\n+        name=\"discriminator\",\n+    )\n+\n+    generator = keras.Sequential(\n+        [\n+            keras.Input(shape=(LATENT_DIM,)),\n+            keras.layers.Dense(8 * 8 * 128),\n+            keras.layers.Reshape((8, 8, 128)),\n+            keras.layers.Conv2DTranspose(\n+                128, kernel_size=4, strides=2, padding=\"same\"\n+            ),\n+            keras.layers.LeakyReLU(alpha=0.2),\n+            keras.layers.Conv2DTranspose(\n+                256, kernel_size=4, strides=2, padding=\"same\"\n+            ),\n+            keras.layers.LeakyReLU(alpha=0.2),\n+            keras.layers.Conv2DTranspose(\n+                512, kernel_size=4, strides=2, padding=\"same\"\n+            ),\n+            keras.layers.LeakyReLU(alpha=0.2),\n+            keras.layers.Conv2D(\n+                3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"\n+            ),\n+        ],\n+        name=\"generator\",\n+    )\n+\n+    gan = GAN(\n+        discriminator=discriminator, generator=generator, latent_dim=LATENT_DIM\n+    )\n+    if compile:\n+        gan.compile(\n+            d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n+            g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n+            loss_fn=keras.losses.BinaryCrossentropy(),\n+            jit_compile=jit_compile,\n+        )\n+    return gan\n+\n+\n+def get_custom_objects():\n+    return {\"GAN\": GAN}\n\n@@ -0,0 +1,151 @@\n+\"\"\"Model that incorporates a set of edge case development patterns.\n+\"\"\"\n+\n+import tensorflow as tf\n+from tensorflow import keras\n+\n+from keras.integration_test.models.input_spec import InputSpec\n+\n+INPUT_DIM = 32\n+NUM_CLASSES = 5\n+\n+\n+def get_data_spec(batch_size):\n+    return (\n+        InputSpec((batch_size, INPUT_DIM)),\n+        InputSpec((batch_size, NUM_CLASSES)),\n+    )\n+\n+\n+def get_input_preprocessor():\n+    return None\n+\n+\n+class LinearA(keras.layers.Layer):\n+    \"\"\"Standard custom layer with 2 call() inputs.\"\"\"\n+\n+    def __init__(self, units=32, input_dim=32):\n+        super().__init__()\n+        self.w = self.add_weight(\n+            shape=(input_dim, units),\n+            initializer=\"random_normal\",\n+            trainable=True,\n+        )\n+        self.b = self.add_weight(\n+            shape=(units,), initializer=\"zeros\", trainable=True\n+        )\n+\n+    def call(self, inputs_1, inputs_2):\n+        return (\n+            tf.matmul(inputs_1, self.w) + tf.matmul(inputs_2, self.w) + self.b\n+        )\n+\n+\n+class LinearB(keras.layers.Layer):\n+    \"\"\"Layer that tracks weights in a dict attribute.\"\"\"\n+\n+    def __init__(self, units=32, input_dim=32):\n+        super().__init__()\n+        w_init = tf.random_normal_initializer()\n+        b_init = tf.zeros_initializer()\n+        self.state = {\n+            \"kernel\": tf.Variable(\n+                initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n+                trainable=True,\n+            )\n+        }\n+        self.state[\"bias\"] = tf.Variable(\n+            initial_value=b_init(shape=(units,), dtype=\"float32\"),\n+            trainable=True,\n+        )\n+\n+    def call(self, inputs):\n+        return tf.matmul(inputs, self.state[\"kernel\"]) + self.state[\"bias\"]\n+\n+\n+class LinearC(keras.layers.Layer):\n+    \"\"\"Layer that creates weights in call().\"\"\"\n+\n+    def __init__(self, units=32, input_dim=32):\n+        super().__init__()\n+        self._custom_built = False\n+        self.units = units\n+        self.input_dim = input_dim\n+\n+    def call(self, inputs):\n+        if not self._custom_built:\n+            self.w = self.add_weight(\n+                shape=(self.input_dim, self.units),\n+                initializer=\"random_normal\",\n+                trainable=True,\n+            )\n+            self.b = self.add_weight(\n+                shape=(self.units,), initializer=\"zeros\", trainable=True\n+            )\n+            self._custom_built = True\n+        return tf.matmul(inputs, self.w) + self.b\n+\n+\n+class BatchNorm(keras.layers.Layer):\n+    \"\"\"Layer with different training/test behavior and non-trainable updates.\"\"\"\n+\n+    def __init__(self, scale=True, center=True, epsilon=1e-6, momentum=0.9):\n+        super().__init__()\n+        self.scale = scale\n+        self.center = center\n+        self.epsilon = epsilon\n+        self.momentum = momentum\n+\n+    def build(self, input_shape):\n+        self.var = self.add_weight(\n+            shape=[input_shape[1]], initializer=\"ones\", trainable=False\n+        )\n+        self.mean = self.add_weight(\n+            shape=[input_shape[1]], initializer=\"zeros\", trainable=False\n+        )\n+        self.gamma = self.add_weight(shape=[input_shape[1]], initializer=\"ones\")\n+        self.beta = self.add_weight(shape=[input_shape[1]], initializer=\"zeros\")\n+\n+    def call(self, inputs, training=False):\n+        if training:\n+            mean, var = tf.nn.moments(inputs, axes=[0])\n+            outputs = (inputs - mean) / (var + self.epsilon)\n+            self.var.assign(self.var * self.momentum + var * 0.1)\n+            self.mean.assign(self.mean * self.momentum + mean * 0.1)\n+        else:\n+            outputs = (inputs - self.mean) / (self.var + self.epsilon)\n+        if self.scale:\n+            outputs *= self.gamma\n+        if self.center:\n+            outputs += self.beta\n+        return outputs\n+\n+\n+class FunctionalSubclassModel(keras.Model):\n+    def __init__(self):\n+        inputs = keras.Input((INPUT_DIM,))\n+        x = inputs\n+        x = LinearA(32, INPUT_DIM)(x, x)\n+        x = LinearB(32, 32)(x)\n+        x = LinearC(32, 32)(x)\n+        x = BatchNorm()(x)\n+        outputs = keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n+        super().__init__(inputs, outputs)\n+\n+\n+def get_model(\n+    build=False, compile=False, jit_compile=False, include_preprocessing=True\n+):\n+    model = FunctionalSubclassModel()\n+    if compile:\n+        model.compile(\"rmsprop\", \"mse\", jit_compile=jit_compile)\n+    return model\n+\n+\n+def get_custom_objects():\n+    return {\n+        \"LinearA\": LinearA,\n+        \"LinearB\": LinearB,\n+        \"LinearC\": LinearC,\n+        \"BatchNorm\": BatchNorm,\n+    }\n\n@@ -0,0 +1,311 @@\n+\"\"\"Image classification with EfficientNetV2 architecture.\n+\n+Adapted from the EfficientNetV2 Keras Application.\n+\"\"\"\n+import math\n+\n+from tensorflow import keras\n+\n+from keras.integration_test.models.input_spec import InputSpec\n+\n+IMG_SIZE = (96, 96)\n+NUM_CLASSES = 5\n+\n+\n+def get_data_spec(batch_size):\n+    return (\n+        InputSpec((batch_size,) + IMG_SIZE + (3,)),\n+        InputSpec((batch_size, NUM_CLASSES)),\n+    )\n+\n+\n+def get_input_preprocessor():\n+    return keras.layers.Rescaling(scale=1.0 / 128.0, offset=-1)\n+\n+\n+def round_filters(filters, width_coefficient, min_depth, depth_divisor):\n+    filters *= width_coefficient\n+    minimum_depth = min_depth or depth_divisor\n+    new_filters = max(\n+        minimum_depth,\n+        int(filters + depth_divisor / 2) // depth_divisor * depth_divisor,\n+    )\n+    return int(new_filters)\n+\n+\n+def MBConvBlock(\n+    input_filters: int,\n+    output_filters: int,\n+    expand_ratio=1,\n+    kernel_size=3,\n+    strides=1,\n+    se_ratio=0.0,\n+    activation=\"swish\",\n+    survival_probability: float = 0.8,\n+):\n+    def apply(inputs):\n+        filters = input_filters * expand_ratio\n+        if expand_ratio != 1:\n+            x = keras.layers.Conv2D(\n+                filters=filters,\n+                kernel_size=1,\n+                strides=1,\n+                padding=\"same\",\n+                data_format=\"channels_last\",\n+                use_bias=False,\n+            )(inputs)\n+            x = keras.layers.BatchNormalization()(x)\n+            x = keras.layers.Activation(activation)(x)\n+        else:\n+            x = inputs\n+\n+        x = keras.layers.DepthwiseConv2D(\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=\"same\",\n+            data_format=\"channels_last\",\n+            use_bias=False,\n+        )(x)\n+        x = keras.layers.BatchNormalization()(x)\n+        x = keras.layers.Activation(activation)(x)\n+\n+        if 0 < se_ratio <= 1:\n+            filters_se = max(1, int(input_filters * se_ratio))\n+            se = keras.layers.GlobalAveragePooling2D()(x)\n+            se = keras.layers.Reshape((1, 1, filters))(se)\n+            se = keras.layers.Conv2D(\n+                filters_se,\n+                1,\n+                padding=\"same\",\n+                activation=activation,\n+            )(se)\n+            se = keras.layers.Conv2D(\n+                filters,\n+                1,\n+                padding=\"same\",\n+                activation=\"sigmoid\",\n+            )(se)\n+            x = keras.layers.multiply([x, se])\n+            x = keras.layers.Conv2D(\n+                filters=output_filters,\n+                kernel_size=1,\n+                strides=1,\n+                padding=\"same\",\n+                data_format=\"channels_last\",\n+                use_bias=False,\n+            )(x)\n+            x = keras.layers.BatchNormalization()(x)\n+\n+            if strides == 1 and input_filters == output_filters:\n+                if survival_probability:\n+                    x = keras.layers.Dropout(\n+                        survival_probability,\n+                        noise_shape=(None, 1, 1, 1),\n+                    )(x)\n+                x = keras.layers.add([x, inputs])\n+        return x\n+\n+    return apply\n+\n+\n+def FusedMBConvBlock(\n+    input_filters: int,\n+    output_filters: int,\n+    expand_ratio=1,\n+    kernel_size=3,\n+    strides=1,\n+    se_ratio=0.0,\n+    activation=\"swish\",\n+    survival_probability: float = 0.8,\n+):\n+    def apply(inputs):\n+        filters = input_filters * expand_ratio\n+        if expand_ratio != 1:\n+            x = keras.layers.Conv2D(\n+                filters,\n+                kernel_size=kernel_size,\n+                strides=strides,\n+                data_format=\"channels_last\",\n+                padding=\"same\",\n+                use_bias=False,\n+            )(inputs)\n+            x = keras.layers.BatchNormalization()(x)\n+            x = keras.layers.Activation(activation)(x)\n+        else:\n+            x = inputs\n+\n+        if 0 < se_ratio <= 1:\n+            filters_se = max(1, int(input_filters * se_ratio))\n+            se = keras.layers.GlobalAveragePooling2D()(x)\n+            se = keras.layers.Reshape((1, 1, filters))(se)\n+            se = keras.layers.Conv2D(\n+                filters_se,\n+                1,\n+                padding=\"same\",\n+                activation=activation,\n+            )(se)\n+            se = keras.layers.Conv2D(\n+                filters,\n+                1,\n+                padding=\"same\",\n+                activation=\"sigmoid\",\n+            )(se)\n+            x = keras.layers.multiply([x, se])\n+\n+        x = keras.layers.Conv2D(\n+            output_filters,\n+            kernel_size=1 if expand_ratio != 1 else kernel_size,\n+            strides=1 if expand_ratio != 1 else strides,\n+            padding=\"same\",\n+            use_bias=False,\n+        )(x)\n+        x = keras.layers.BatchNormalization()(x)\n+\n+        if expand_ratio == 1:\n+            x = keras.layers.Activation(activation)(x)\n+\n+        if strides == 1 and input_filters == output_filters:\n+            if survival_probability:\n+                x = keras.layers.Dropout(\n+                    survival_probability,\n+                    noise_shape=(None, 1, 1, 1),\n+                )(x)\n+            x = keras.layers.add([x, inputs])\n+\n+        return x\n+\n+    return apply\n+\n+\n+def get_model(\n+    build=False, compile=False, jit_compile=False, include_preprocessing=True\n+):\n+    width_coefficient = 1.0\n+    depth_coefficient = 1.0\n+    dropout_rate = 0.2\n+    drop_connect_rate = 0.2\n+    depth_divisor = 8\n+    min_depth = 8\n+    activation = \"swish\"\n+    blocks_args = [\n+        {\n+            \"kernel_size\": 3,\n+            \"num_repeat\": 2,\n+            \"input_filters\": 24,\n+            \"output_filters\": 24,\n+            \"expand_ratio\": 1,\n+            \"se_ratio\": 0.0,\n+            \"strides\": 1,\n+            \"conv_type\": 1,\n+        },\n+        {\n+            \"kernel_size\": 3,\n+            \"num_repeat\": 4,\n+            \"input_filters\": 24,\n+            \"output_filters\": 48,\n+            \"expand_ratio\": 4,\n+            \"se_ratio\": 0.0,\n+            \"strides\": 2,\n+            \"conv_type\": 1,\n+        },\n+        {\n+            \"conv_type\": 1,\n+            \"expand_ratio\": 4,\n+            \"input_filters\": 48,\n+            \"kernel_size\": 3,\n+            \"num_repeat\": 4,\n+            \"output_filters\": 64,\n+            \"se_ratio\": 0,\n+            \"strides\": 2,\n+        },\n+        {\n+            \"conv_type\": 0,\n+            \"expand_ratio\": 4,\n+            \"input_filters\": 64,\n+            \"kernel_size\": 3,\n+            \"num_repeat\": 6,\n+            \"output_filters\": 128,\n+            \"se_ratio\": 0.25,\n+            \"strides\": 2,\n+        },\n+    ]\n+\n+    inputs = keras.layers.Input(shape=IMG_SIZE + (3,))\n+    if include_preprocessing:\n+        x = get_input_preprocessor()(inputs)\n+    else:\n+        x = inputs\n+\n+    stem_filters = round_filters(\n+        filters=blocks_args[0][\"input_filters\"],\n+        width_coefficient=width_coefficient,\n+        min_depth=min_depth,\n+        depth_divisor=depth_divisor,\n+    )\n+    x = keras.layers.Conv2D(\n+        filters=stem_filters,\n+        kernel_size=3,\n+        strides=2,\n+        padding=\"same\",\n+        use_bias=False,\n+    )(x)\n+    x = keras.layers.BatchNormalization()(x)\n+    x = keras.layers.Activation(activation, name=\"stem_activation\")(x)\n+\n+    b = 0\n+    blocks = float(sum(args[\"num_repeat\"] for args in blocks_args))\n+    for _, args in enumerate(blocks_args):\n+        args[\"input_filters\"] = round_filters(\n+            filters=args[\"input_filters\"],\n+            width_coefficient=width_coefficient,\n+            min_depth=min_depth,\n+            depth_divisor=depth_divisor,\n+        )\n+        args[\"output_filters\"] = round_filters(\n+            filters=args[\"output_filters\"],\n+            width_coefficient=width_coefficient,\n+            min_depth=min_depth,\n+            depth_divisor=depth_divisor,\n+        )\n+        block = {0: MBConvBlock, 1: FusedMBConvBlock}[args.pop(\"conv_type\")]\n+        repeats = int(math.ceil(depth_coefficient * args.pop(\"num_repeat\")))\n+        for j in range(repeats):\n+            if j > 0:\n+                args[\"strides\"] = 1\n+                args[\"input_filters\"] = args[\"output_filters\"]\n+\n+            x = block(\n+                activation=activation,\n+                survival_probability=drop_connect_rate * b / blocks,\n+                **args,\n+            )(x)\n+            b += 1\n+\n+    top_filters = round_filters(\n+        filters=1280,\n+        width_coefficient=width_coefficient,\n+        min_depth=min_depth,\n+        depth_divisor=depth_divisor,\n+    )\n+    x = keras.layers.Conv2D(\n+        filters=top_filters,\n+        kernel_size=1,\n+        strides=1,\n+        padding=\"same\",\n+        data_format=\"channels_last\",\n+        use_bias=False,\n+    )(x)\n+    x = keras.layers.BatchNormalization()(x)\n+    x = keras.layers.Activation(activation=activation, name=\"top_activation\")(x)\n+    x = keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n+    x = keras.layers.Dropout(dropout_rate, name=\"top_dropout\")(x)\n+    x = keras.layers.Dense(\n+        NUM_CLASSES,\n+        activation=\"softmax\",\n+    )(x)\n+    model = keras.Model(inputs, x)\n+    if compile:\n+        model.compile(\n+            \"adam\", loss=\"categorical_crossentropy\", jit_compile=jit_compile\n+        )\n+    return model\n\n@@ -0,0 +1,24 @@\n+\"\"\"Class to specify an input's shape/dtype/value range.\n+\"\"\"\n+\n+import tensorflow as tf\n+\n+\n+class InputSpec:\n+    def __init__(self, shape, dtype=\"float32\", range=None):\n+        self.shape = shape\n+        self.dtype = dtype\n+        self.range = range\n+\n+\n+def spec_to_value(spec):\n+    shape = spec.shape\n+    dtype = spec.dtype\n+    rg = spec.range or [0, 1]\n+    if dtype == \"string\":\n+        return tf.constant(\n+            [\"some string\" for _ in range(shape[0])], dtype=\"string\"\n+        )\n+    return tf.random.stateless_uniform(\n+        shape, seed=[123, 1], minval=rg[0], maxval=rg[1], dtype=dtype\n+    )\n\n@@ -0,0 +1,156 @@\n+\"\"\"Model where almost everything is implemented from scratch.\n+\n+- Custom layers\n+- Custom model subclass\n+- Custom train_step and test_step\n+- Custom compile()\n+- Custom learning rate schedule\n+- Custom metrics\n+\"\"\"\n+\n+import tensorflow as tf\n+from tensorflow import keras\n+\n+from keras.integration_test.models.input_spec import InputSpec\n+\n+INPUT_DIM = 32\n+NUM_CLASSES = 5\n+\n+\n+def get_data_spec(batch_size):\n+    return (\n+        InputSpec((batch_size, INPUT_DIM)),\n+        InputSpec((batch_size, NUM_CLASSES)),\n+    )\n+\n+\n+def get_input_preprocessor():\n+    return None\n+\n+\n+class Linear(keras.layers.Layer):\n+    def __init__(self, units=32):\n+        super().__init__()\n+        self.units = units\n+\n+    def build(self, input_shape):\n+        self.w = self.add_weight(\n+            shape=(input_shape[-1], self.units),\n+            initializer=\"random_normal\",\n+            trainable=True,\n+        )\n+        self.b = self.add_weight(\n+            shape=(self.units,), initializer=\"random_normal\", trainable=True\n+        )\n+\n+    def call(self, inputs):\n+        return tf.matmul(inputs, self.w) + self.b\n+\n+\n+class BinaryTruePositives(tf.keras.metrics.Metric):\n+    def __init__(self, name=\"binary_true_positives\", **kwargs):\n+        super().__init__(name=name, **kwargs)\n+        self.true_positives = self.add_weight(name=\"tp\", initializer=\"zeros\")\n+\n+    def update_state(self, y_true, y_pred, sample_weight=None):\n+        y_true = tf.cast(y_true, tf.bool)\n+        y_pred = tf.cast(y_pred, tf.bool)\n+\n+        values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))\n+        values = tf.cast(values, self.dtype)\n+        if sample_weight is not None:\n+            sample_weight = tf.cast(sample_weight, self.dtype)\n+            values = tf.multiply(values, sample_weight)\n+        self.true_positives.assign_add(tf.reduce_sum(values))\n+\n+    def result(self):\n+        return self.true_positives\n+\n+    def reset_states(self):\n+        self.true_positives.assign(0)\n+\n+\n+class CustomModel(keras.Model):\n+    def __init__(self):\n+        super().__init__()\n+        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n+        self.btp_metric = BinaryTruePositives(name=\"mae\")\n+\n+        self.linear_1 = Linear(32)\n+        self.linear_2 = Linear(NUM_CLASSES)\n+\n+    def call(self, inputs, training=False):\n+        x = self.linear_1(inputs)\n+        x = self.linear_2(x)\n+        return x\n+\n+    def compile(self, optimizer, loss, jit_compile=False):\n+        self.optimizer = optimizer\n+        self.loss = loss\n+        self.jit_compile = jit_compile\n+        self._is_compiled = True\n+\n+    def train_step(self, data):\n+        x, y = data\n+        with tf.GradientTape() as tape:\n+            y_pred = self(x, training=True)\n+            loss = keras.losses.mean_squared_error(y, y_pred)\n+\n+        trainable_vars = self.trainable_variables\n+        gradients = tape.gradient(loss, trainable_vars)\n+        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n+        self.loss_tracker.update_state(loss)\n+        self.btp_metric.update_state(y, y_pred)\n+        return {\n+            \"loss\": self.loss_tracker.result(),\n+            \"btp\": self.btp_metric.result(),\n+        }\n+\n+    def test_step(self, data):\n+        x, y = data\n+        y_pred = self(x, training=True)\n+        loss = keras.losses.mean_squared_error(y, y_pred)\n+        self.loss_tracker.update_state(loss)\n+        self.btp_metric.update_state(y, y_pred)\n+        return {\n+            \"loss\": self.loss_tracker.result(),\n+            \"btp\": self.btp_metric.result(),\n+        }\n+\n+    @property\n+    def metrics(self):\n+        return [self.loss_tracker, self.btp_metric]\n+\n+\n+class CustomLRSchedule(keras.optimizers.schedules.LearningRateSchedule):\n+    def __init__(self, initial_learning_rate):\n+        self.initial_learning_rate = initial_learning_rate\n+\n+    def __call__(self, step):\n+        return self.initial_learning_rate / tf.cast(step + 1, \"float32\")\n+\n+\n+def custom_loss(y_true, y_pred):\n+    return keras.losses.mse(y_true, y_pred)\n+\n+\n+def get_model(\n+    build=False, compile=False, jit_compile=False, include_preprocessing=True\n+):\n+    model = CustomModel()\n+    if compile:\n+        model.compile(\n+            optimizer=keras.optimizers.Adam(CustomLRSchedule(0.1)),\n+            loss=custom_loss,\n+            jit_compile=jit_compile,\n+        )\n+    return model\n+\n+\n+def get_custom_objects():\n+    return {\n+        \"Linear\": Linear,\n+        \"CustomLRSchedule\": CustomLRSchedule,\n+        \"CustomModel\": CustomModel,\n+        \"BinaryTruePositives\": BinaryTruePositives,\n+    }\n\n@@ -0,0 +1,80 @@\n+\"\"\"Segmentation model.\n+\n+Adapted from https://keras.io/examples/vision/oxford_pets_image_segmentation/\n+\"\"\"\n+from tensorflow import keras\n+\n+from keras.integration_test.models.input_spec import InputSpec\n+\n+IMG_SIZE = (224, 224)\n+NUM_CLASSES = 5\n+\n+\n+def get_data_spec(batch_size):\n+    return (\n+        InputSpec((batch_size,) + IMG_SIZE + (3,)),\n+        InputSpec((batch_size,) + IMG_SIZE + (NUM_CLASSES,)),\n+    )\n+\n+\n+def get_input_preprocessor():\n+    return None\n+\n+\n+def get_model(\n+    build=False, compile=False, jit_compile=False, include_preprocessing=True\n+):\n+    inputs = keras.Input(shape=IMG_SIZE + (3,))\n+    x = keras.layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n+    x = keras.layers.BatchNormalization()(x)\n+    x = keras.layers.Activation(\"relu\")(x)\n+\n+    previous_block_activation = x\n+    for filters in [64, 128, 256]:\n+        x = keras.layers.Activation(\"relu\")(x)\n+        x = keras.layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n+        x = keras.layers.BatchNormalization()(x)\n+\n+        x = keras.layers.Activation(\"relu\")(x)\n+        x = keras.layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n+        x = keras.layers.BatchNormalization()(x)\n+\n+        x = keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n+\n+        residual = keras.layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n+            previous_block_activation\n+        )\n+        x = keras.layers.add([x, residual])\n+        previous_block_activation = x\n+\n+    for filters in [256, 128, 64, 32]:\n+        x = keras.layers.Activation(\"relu\")(x)\n+        x = keras.layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n+        x = keras.layers.BatchNormalization()(x)\n+\n+        x = keras.layers.Activation(\"relu\")(x)\n+        x = keras.layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n+        x = keras.layers.BatchNormalization()(x)\n+\n+        x = keras.layers.UpSampling2D(2)(x)\n+\n+        residual = keras.layers.UpSampling2D(2)(previous_block_activation)\n+        residual = keras.layers.Conv2D(filters, 1, padding=\"same\")(residual)\n+        x = keras.layers.add([x, residual])\n+        previous_block_activation = x\n+\n+    outputs = keras.layers.Conv2D(\n+        NUM_CLASSES, 3, activation=\"softmax\", padding=\"same\"\n+    )(x)\n+    model = keras.Model(inputs, outputs)\n+    if compile:\n+        model.compile(\n+            optimizer=\"rmsprop\",\n+            loss=\"categorical_crossentropy\",\n+            jit_compile=jit_compile,\n+        )\n+    return model\n+\n+\n+def get_custom_objects():\n+    return None\n\n@@ -0,0 +1,84 @@\n+\"\"\"Mini-Xception classification model.\n+\n+Adapted from https://keras.io/examples/vision/image_classification_from_scratch/\n+\"\"\"\n+from tensorflow import keras\n+\n+from keras.integration_test.models.input_spec import InputSpec\n+\n+IMG_SIZE = (120, 120)\n+\n+\n+def get_data_spec(batch_size):\n+    return (\n+        InputSpec((batch_size,) + IMG_SIZE + (3,)),\n+        InputSpec((batch_size, 1), dtype=\"int32\", range=[0, 2]),\n+    )\n+\n+\n+def get_input_preprocessor():\n+    return keras.Sequential(\n+        [\n+            keras.layers.RandomFlip(),\n+            keras.layers.RandomRotation(0.2),\n+            keras.layers.RandomZoom(0.2),\n+            keras.layers.Rescaling(1.0 / 255),\n+        ]\n+    )\n+\n+\n+def get_model(\n+    build=False, compile=False, jit_compile=False, include_preprocessing=True\n+):\n+    inputs = keras.Input(shape=IMG_SIZE + (3,))\n+\n+    if include_preprocessing:\n+        x = get_input_preprocessor()(inputs)\n+    else:\n+        x = inputs\n+\n+    x = keras.layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n+    x = keras.layers.BatchNormalization()(x)\n+    x = keras.layers.Activation(\"relu\")(x)\n+\n+    x = keras.layers.Conv2D(64, 3, padding=\"same\")(x)\n+    x = keras.layers.BatchNormalization()(x)\n+    x = keras.layers.Activation(\"relu\")(x)\n+\n+    previous_block_activation = x\n+\n+    for size in [128, 256, 512, 728]:\n+        x = keras.layers.Activation(\"relu\")(x)\n+        x = keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n+        x = keras.layers.BatchNormalization()(x)\n+        x = keras.layers.Activation(\"relu\")(x)\n+        x = keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n+        x = keras.layers.BatchNormalization()(x)\n+        x = keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n+\n+        residual = keras.layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n+            previous_block_activation\n+        )\n+        x = keras.layers.add([x, residual])\n+        previous_block_activation = x\n+\n+    x = keras.layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n+    x = keras.layers.BatchNormalization()(x)\n+    x = keras.layers.Activation(\"relu\")(x)\n+\n+    x = keras.layers.GlobalAveragePooling2D()(x)\n+    x = keras.layers.Dropout(0.5)(x)\n+    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n+    model = keras.Model(inputs, outputs)\n+    if compile:\n+        model.compile(\n+            optimizer=\"adam\",\n+            loss=\"binary_crossentropy\",\n+            metrics=[\"accuracy\"],\n+            jit_compile=jit_compile,\n+        )\n+    return model\n+\n+\n+def get_custom_objects():\n+    return None\n\n@@ -0,0 +1,226 @@\n+\"\"\"RetinaNet object detection model.\n+\n+Adapted from https://keras.io/examples/vision/retinanet/\n+\"\"\"\n+import tensorflow as tf\n+from tensorflow import keras\n+\n+from keras.integration_test.models.input_spec import InputSpec\n+\n+NUM_CLASSES = 10\n+IMG_SIZE = (224, 224)\n+\n+\n+def get_data_spec(batch_size):\n+    return (\n+        InputSpec((batch_size,) + IMG_SIZE + (3,)),\n+        InputSpec((batch_size, 9441, 5)),\n+    )\n+\n+\n+def get_input_preprocessor():\n+    return None\n+\n+\n+def get_backbone():\n+    backbone = keras.applications.ResNet50(\n+        include_top=False,\n+        input_shape=[None, None, 3],\n+        weights=None,\n+    )\n+    c3_output, c4_output, c5_output = [\n+        backbone.get_layer(layer_name).output\n+        for layer_name in [\n+            \"conv3_block4_out\",\n+            \"conv4_block6_out\",\n+            \"conv5_block3_out\",\n+        ]\n+    ]\n+    return keras.Model(\n+        inputs=[backbone.inputs], outputs=[c3_output, c4_output, c5_output]\n+    )\n+\n+\n+class FeaturePyramid(keras.layers.Layer):\n+    def __init__(self, backbone=None, **kwargs):\n+        super().__init__(name=\"FeaturePyramid\", **kwargs)\n+        self.backbone = backbone if backbone else get_backbone()\n+        self.conv_c3_1x1 = keras.layers.Conv2D(256, 1, 1, \"same\")\n+        self.conv_c4_1x1 = keras.layers.Conv2D(256, 1, 1, \"same\")\n+        self.conv_c5_1x1 = keras.layers.Conv2D(256, 1, 1, \"same\")\n+        self.conv_c3_3x3 = keras.layers.Conv2D(256, 3, 1, \"same\")\n+        self.conv_c4_3x3 = keras.layers.Conv2D(256, 3, 1, \"same\")\n+        self.conv_c5_3x3 = keras.layers.Conv2D(256, 3, 1, \"same\")\n+        self.conv_c6_3x3 = keras.layers.Conv2D(256, 3, 2, \"same\")\n+        self.conv_c7_3x3 = keras.layers.Conv2D(256, 3, 2, \"same\")\n+        self.upsample_2x = keras.layers.UpSampling2D(2)\n+\n+    def call(self, images, training=False):\n+        c3_output, c4_output, c5_output = self.backbone(\n+            images, training=training\n+        )\n+        p3_output = self.conv_c3_1x1(c3_output)\n+        p4_output = self.conv_c4_1x1(c4_output)\n+        p5_output = self.conv_c5_1x1(c5_output)\n+        p4_output = p4_output + self.upsample_2x(p5_output)\n+        p3_output = p3_output + self.upsample_2x(p4_output)\n+        p3_output = self.conv_c3_3x3(p3_output)\n+        p4_output = self.conv_c4_3x3(p4_output)\n+        p5_output = self.conv_c5_3x3(p5_output)\n+        p6_output = self.conv_c6_3x3(c5_output)\n+        p7_output = self.conv_c7_3x3(tf.nn.relu(p6_output))\n+        return p3_output, p4_output, p5_output, p6_output, p7_output\n+\n+\n+def build_head(output_filters, bias_init):\n+    head = keras.Sequential([keras.Input(shape=[None, None, 256])])\n+    kernel_init = tf.initializers.RandomNormal(0.0, 0.01)\n+    for _ in range(4):\n+        head.add(\n+            keras.layers.Conv2D(\n+                256, 3, padding=\"same\", kernel_initializer=kernel_init\n+            )\n+        )\n+        head.add(keras.layers.ReLU())\n+    head.add(\n+        keras.layers.Conv2D(\n+            output_filters,\n+            3,\n+            1,\n+            padding=\"same\",\n+            kernel_initializer=kernel_init,\n+            bias_initializer=bias_init,\n+        )\n+    )\n+    return head\n+\n+\n+class RetinaNet(keras.Model):\n+    def __init__(self, num_classes, backbone=None, **kwargs):\n+        super().__init__(name=\"RetinaNet\", **kwargs)\n+        self.fpn = FeaturePyramid(backbone)\n+        self.num_classes = num_classes\n+\n+        prior_probability = keras.initializers.Constant(\n+            -tf.math.log((1 - 0.01) / 0.01)\n+        )\n+        self.cls_head = build_head(9 * num_classes, prior_probability)\n+        self.box_head = build_head(9 * 4, \"zeros\")\n+\n+    def call(self, image, training=False):\n+        features = self.fpn(image, training=training)\n+        N = tf.shape(image)[0]\n+        cls_outputs = []\n+        box_outputs = []\n+        for feature in features:\n+            box_outputs.append(tf.reshape(self.box_head(feature), [N, -1, 4]))\n+            cls_outputs.append(\n+                tf.reshape(self.cls_head(feature), [N, -1, self.num_classes])\n+            )\n+        cls_outputs = tf.concat(cls_outputs, axis=1)\n+        box_outputs = tf.concat(box_outputs, axis=1)\n+        return tf.concat([box_outputs, cls_outputs], axis=-1)\n+\n+\n+class RetinaNetBoxLoss(keras.losses.Loss):\n+    def __init__(self, delta):\n+        super().__init__(reduction=\"none\", name=\"RetinaNetBoxLoss\")\n+        self._delta = delta\n+\n+    def call(self, y_true, y_pred):\n+        difference = y_true - y_pred\n+        absolute_difference = tf.abs(difference)\n+        squared_difference = difference**2\n+        loss = tf.where(\n+            tf.less(absolute_difference, self._delta),\n+            0.5 * squared_difference,\n+            absolute_difference - 0.5,\n+        )\n+        return tf.reduce_sum(loss, axis=-1)\n+\n+\n+class RetinaNetClassificationLoss(keras.losses.Loss):\n+    def __init__(self, alpha, gamma):\n+        super().__init__(reduction=\"none\", name=\"RetinaNetClassificationLoss\")\n+        self._alpha = alpha\n+        self._gamma = gamma\n+\n+    def call(self, y_true, y_pred):\n+        cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(\n+            labels=y_true, logits=y_pred\n+        )\n+        probs = tf.nn.sigmoid(y_pred)\n+        alpha = tf.where(\n+            tf.equal(y_true, 1.0), self._alpha, (1.0 - self._alpha)\n+        )\n+        pt = tf.where(tf.equal(y_true, 1.0), probs, 1 - probs)\n+        loss = alpha * tf.pow(1.0 - pt, self._gamma) * cross_entropy\n+        return tf.reduce_sum(loss, axis=-1)\n+\n+\n+class RetinaNetLoss(keras.losses.Loss):\n+    def __init__(self, num_classes=80, alpha=0.25, gamma=2.0, delta=1.0):\n+        super().__init__(reduction=\"auto\", name=\"RetinaNetLoss\")\n+        self._clf_loss = RetinaNetClassificationLoss(alpha, gamma)\n+        self._box_loss = RetinaNetBoxLoss(delta)\n+        self._num_classes = num_classes\n+\n+    def call(self, y_true, y_pred):\n+        y_pred = tf.cast(y_pred, dtype=tf.float32)\n+        box_labels = y_true[:, :, :4]\n+        box_predictions = y_pred[:, :, :4]\n+        cls_labels = tf.one_hot(\n+            tf.cast(y_true[:, :, 4], dtype=tf.int32),\n+            depth=self._num_classes,\n+            dtype=tf.float32,\n+        )\n+        cls_predictions = y_pred[:, :, 4:]\n+        positive_mask = tf.cast(\n+            tf.greater(y_true[:, :, 4], -1.0), dtype=tf.float32\n+        )\n+        ignore_mask = tf.cast(tf.equal(y_true[:, :, 4], -2.0), dtype=tf.float32)\n+        clf_loss = self._clf_loss(cls_labels, cls_predictions)\n+        box_loss = self._box_loss(box_labels, box_predictions)\n+        clf_loss = tf.where(tf.equal(ignore_mask, 1.0), 0.0, clf_loss)\n+        box_loss = tf.where(tf.equal(positive_mask, 1.0), box_loss, 0.0)\n+        normalizer = tf.reduce_sum(positive_mask, axis=-1)\n+        clf_loss = tf.math.divide_no_nan(\n+            tf.reduce_sum(clf_loss, axis=-1), normalizer\n+        )\n+        box_loss = tf.math.divide_no_nan(\n+            tf.reduce_sum(box_loss, axis=-1), normalizer\n+        )\n+        loss = clf_loss + box_loss\n+        return loss\n+\n+\n+def get_model(\n+    build=False, compile=False, jit_compile=False, include_preprocessing=True\n+):\n+    resnet50_backbone = get_backbone()\n+    loss_fn = RetinaNetLoss(NUM_CLASSES)\n+    model = RetinaNet(NUM_CLASSES, resnet50_backbone)\n+\n+    if compile:\n+        learning_rates = [2.5e-06, 0.000625, 0.00125, 0.0025, 0.00025, 2.5e-05]\n+        learning_rate_boundaries = [125, 250, 500, 240000, 360000]\n+        learning_rate_fn = keras.optimizers.schedules.PiecewiseConstantDecay(\n+            boundaries=learning_rate_boundaries, values=learning_rates\n+        )\n+        optimizer = keras.optimizers.SGD(\n+            learning_rate=learning_rate_fn, momentum=0.9\n+        )\n+        model.compile(\n+            loss=loss_fn, optimizer=optimizer, jit_compile=jit_compile\n+        )\n+    return model\n+\n+\n+def get_custom_objects():\n+    return {\n+        \"RetinaNetLoss\": RetinaNetLoss,\n+        \"RetinaNetClassificationLoss\": RetinaNetClassificationLoss,\n+        \"RetinaNetBoxLoss\": RetinaNetBoxLoss,\n+        \"RetinaNet\": RetinaNet,\n+        \"FeaturePyramid\": FeaturePyramid,\n+    }\n\n@@ -0,0 +1,103 @@\n+import tensorflow as tf\n+from tensorflow import keras\n+\n+from keras.integration_test.models.input_spec import InputSpec\n+\n+\n+def get_data_spec(batch_size):\n+    return (\n+        {\n+            \"num_cat_feat\": InputSpec(\n+                (batch_size,), dtype=\"int32\", range=[0, 5]\n+            ),\n+            \"string_cat_feat\": InputSpec((batch_size,), dtype=\"string\"),\n+            \"num_feat\": InputSpec((batch_size,)),\n+        },\n+        InputSpec((batch_size, 1), dtype=\"int32\", range=[0, 2]),\n+    )\n+\n+\n+def get_input_preprocessor():\n+    dataset = tf.data.Dataset.from_tensor_slices(\n+        {\n+            \"num_cat_feat\": [0, 1, 2, 3, 4, 5],\n+            \"string_cat_feat\": [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\"],\n+            \"num_feat\": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n+        }\n+    ).batch(3)\n+\n+    num_cat_feat = keras.Input(shape=(1,), name=\"num_cat_feat\", dtype=\"int64\")\n+    string_cat_feat = keras.Input(\n+        shape=(1,), name=\"string_cat_feat\", dtype=\"string\"\n+    )\n+    num_feat = keras.Input(shape=(1,), name=\"num_feat\", dtype=\"float32\")\n+\n+    all_inputs = [\n+        num_cat_feat,\n+        string_cat_feat,\n+        num_feat,\n+    ]\n+\n+    all_features = keras.layers.concatenate(\n+        [\n+            encode_categorical_feature(\n+                num_cat_feat, \"num_cat_feat\", dataset, False\n+            ),\n+            encode_categorical_feature(\n+                string_cat_feat, \"string_cat_feat\", dataset, True\n+            ),\n+            encode_numerical_feature(num_feat, \"num_feat\", dataset),\n+        ]\n+    )\n+    preprocessor = keras.Model(all_inputs, all_features)\n+    return preprocessor\n+\n+\n+def encode_numerical_feature(feature, name, dataset):\n+    normalizer = keras.layers.Normalization()\n+    feature_ds = dataset.map(lambda x: x[name])\n+    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n+    normalizer.adapt(feature_ds)\n+    encoded_feature = normalizer(feature)\n+    return encoded_feature\n+\n+\n+def encode_categorical_feature(feature, name, dataset, is_string):\n+    lookup_class = (\n+        keras.layers.StringLookup if is_string else keras.layers.IntegerLookup\n+    )\n+    lookup = lookup_class(output_mode=\"binary\")\n+    feature_ds = dataset.map(lambda x: x[name])\n+    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n+    lookup.adapt(feature_ds)\n+    encoded_feature = lookup(feature)\n+    return encoded_feature\n+\n+\n+def get_model(\n+    build=False, compile=False, jit_compile=False, include_preprocessing=True\n+):\n+    preprocessor = get_input_preprocessor()\n+    if include_preprocessing:\n+        all_inputs = preprocessor.inputs\n+        all_features = preprocessor.outputs[0]\n+    else:\n+        all_inputs = keras.Input(shape=preprocessor.outputs[0].shape)\n+        all_features = all_inputs\n+    x = keras.layers.Dense(32, activation=\"relu\")(all_features)\n+    x = keras.layers.Dropout(0.5)(x)\n+    output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n+    model = keras.Model(all_inputs, output)\n+\n+    if compile:\n+        model.compile(\n+            \"adam\",\n+            \"binary_crossentropy\",\n+            metrics=[\"accuracy\"],\n+            jit_compile=jit_compile,\n+        )\n+    return model\n+\n+\n+def get_custom_objects():\n+    return None\n\n@@ -0,0 +1,91 @@\n+\"\"\"Text classification model.\n+\n+Adapted from https://keras.io/examples/nlp/text_classification_from_scratch/\n+\"\"\"\n+import re\n+import string\n+\n+import tensorflow as tf\n+from tensorflow import keras\n+\n+from keras.integration_test.models.input_spec import InputSpec\n+\n+MAX_FEATURES = 1000\n+EMBEDDING_DIM = 64\n+SEQUENCE_LENGTH = 32\n+\n+\n+def get_data_spec(batch_size):\n+    return (\n+        InputSpec((batch_size,), dtype=\"string\"),\n+        InputSpec((batch_size, 1), dtype=\"int32\", range=[0, 2]),\n+    )\n+\n+\n+def custom_standardization(input_data):\n+    lowercase = tf.strings.lower(input_data)\n+    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n+    return tf.strings.regex_replace(\n+        stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\"\n+    )\n+\n+\n+def get_input_preprocessor():\n+    input_vectorizer = keras.layers.TextVectorization(\n+        standardize=custom_standardization,\n+        max_tokens=MAX_FEATURES,\n+        output_mode=\"int\",\n+        output_sequence_length=SEQUENCE_LENGTH,\n+    )\n+    text_ds = tf.data.Dataset.from_tensor_slices(\n+        [\n+            \"Lorem ipsum dolor sit amet\",\n+            \"consectetur adipiscing elit\",\n+            \"sed do eiusmod tempor incididunt ut\",\n+            \"labore et dolore magna aliqua.\",\n+            \"Ut enim ad minim veniam\",\n+            \"quis nostrud exercitation ullamco\",\n+            \"laboris nisi ut aliquip ex ea commodo consequat.\",\n+        ]\n+    )\n+    input_vectorizer.adapt(text_ds)\n+    return input_vectorizer\n+\n+\n+def get_model(\n+    build=False, compile=False, jit_compile=False, include_preprocessing=True\n+):\n+    if include_preprocessing:\n+        inputs = keras.Input(shape=(), dtype=\"string\")\n+        x = get_input_preprocessor()(inputs)\n+    else:\n+        inputs = keras.Input(shape=(None,), dtype=\"int64\")\n+        x = inputs\n+    x = keras.layers.Embedding(MAX_FEATURES, EMBEDDING_DIM)(x)\n+    x = keras.layers.Dropout(0.5)(x)\n+    x = keras.layers.Conv1D(\n+        128, 7, padding=\"valid\", activation=\"relu\", strides=3\n+    )(x)\n+    x = keras.layers.Conv1D(\n+        128, 7, padding=\"valid\", activation=\"relu\", strides=3\n+    )(x)\n+    x = keras.layers.GlobalMaxPooling1D()(x)\n+    x = keras.layers.Dense(128, activation=\"relu\")(x)\n+    x = keras.layers.Dropout(0.5)(x)\n+    predictions = keras.layers.Dense(\n+        1, activation=\"sigmoid\", name=\"predictions\"\n+    )(x)\n+    model = keras.Model(inputs, predictions)\n+\n+    if compile:\n+        model.compile(\n+            loss=\"binary_crossentropy\",\n+            optimizer=\"adam\",\n+            metrics=[\"accuracy\"],\n+            jit_compile=jit_compile,\n+        )\n+    return model\n+\n+\n+def get_custom_objects():\n+    return {\"custom_standardization\": custom_standardization}\n\n@@ -0,0 +1,39 @@\n+from tensorflow import keras\n+\n+from keras.integration_test.models.input_spec import InputSpec\n+\n+TIMESTEPS = 32\n+\n+\n+def get_data_spec(batch_size):\n+    return (\n+        InputSpec((batch_size, TIMESTEPS, 1)),\n+        InputSpec((batch_size, 1)),\n+    )\n+\n+\n+def get_input_preprocessor():\n+    return None\n+\n+\n+def get_model(\n+    build=False, compile=False, jit_compile=False, include_preprocessing=True\n+):\n+    model = keras.Sequential(\n+        [\n+            keras.layers.LSTM(32, return_sequences=True),\n+            keras.layers.LSTM(32),\n+            keras.layers.Dense(1),\n+        ]\n+    )\n+    if compile:\n+        model.compile(\n+            optimizer=keras.optimizers.Adam(),\n+            loss=\"mse\",\n+            jit_compile=jit_compile,\n+        )\n+    return model\n+\n+\n+def get_custom_objects():\n+    return None\n\n@@ -0,0 +1,225 @@\n+\"\"\"Machine translation model.\n+\n+Adapted from\n+https://keras.io/examples/nlp/neural_machine_translation_with_transformer/\n+\"\"\"\n+import tensorflow as tf\n+from tensorflow import keras\n+\n+from keras.integration_test.models.input_spec import InputSpec\n+\n+VOCAB_SIZE = 1500\n+SEQUENCE_LENGTH = 20\n+\n+\n+def get_data_spec(batch_size):\n+    return (\n+        (\n+            InputSpec((batch_size,), dtype=\"string\"),\n+            InputSpec((batch_size,), dtype=\"string\"),\n+        ),\n+        InputSpec(\n+            (batch_size, SEQUENCE_LENGTH), dtype=\"int64\", range=[0, VOCAB_SIZE]\n+        ),\n+    )\n+\n+\n+def get_input_preprocessor():\n+    encoder_input_vectorizer = keras.layers.TextVectorization(\n+        max_tokens=VOCAB_SIZE,\n+        output_mode=\"int\",\n+        output_sequence_length=SEQUENCE_LENGTH,\n+    )\n+    decoder_input_vectorizer = keras.layers.TextVectorization(\n+        max_tokens=VOCAB_SIZE,\n+        output_mode=\"int\",\n+        output_sequence_length=SEQUENCE_LENGTH,\n+    )\n+    text_ds = tf.data.Dataset.from_tensor_slices(\n+        [\n+            \"Lorem ipsum dolor sit amet\",\n+            \"consectetur adipiscing elit\",\n+            \"sed do eiusmod tempor incididunt ut\",\n+            \"labore et dolore magna aliqua.\",\n+            \"Ut enim ad minim veniam\",\n+            \"quis nostrud exercitation ullamco\",\n+            \"laboris nisi ut aliquip ex ea commodo consequat.\",\n+        ]\n+    )\n+    encoder_input_vectorizer.adapt(text_ds)\n+    decoder_input_vectorizer.adapt(text_ds)\n+    return lambda x: (\n+        encoder_input_vectorizer(x[0]),\n+        decoder_input_vectorizer(x[1]),\n+    )\n+\n+\n+class TransformerEncoder(keras.layers.Layer):\n+    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n+        super().__init__(**kwargs)\n+        self.embed_dim = embed_dim\n+        self.dense_dim = dense_dim\n+        self.num_heads = num_heads\n+        self.attention = keras.layers.MultiHeadAttention(\n+            num_heads=num_heads, key_dim=embed_dim\n+        )\n+        self.dense_proj = keras.Sequential(\n+            [\n+                keras.layers.Dense(dense_dim, activation=\"relu\"),\n+                keras.layers.Dense(embed_dim),\n+            ]\n+        )\n+        self.layernorm_1 = keras.layers.LayerNormalization()\n+        self.layernorm_2 = keras.layers.LayerNormalization()\n+        self.supports_masking = True\n+\n+    def call(self, inputs, mask=None):\n+        if mask is not None:\n+            padding_mask = tf.cast(\n+                mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\"\n+            )\n+        attention_output = self.attention(\n+            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n+        )\n+        proj_input = self.layernorm_1(inputs + attention_output)\n+        proj_output = self.dense_proj(proj_input)\n+        return self.layernorm_2(proj_input + proj_output)\n+\n+\n+class PositionalEmbedding(keras.layers.Layer):\n+    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n+        super().__init__(**kwargs)\n+        self.token_embeddings = keras.layers.Embedding(\n+            input_dim=vocab_size, output_dim=embed_dim\n+        )\n+        self.position_embeddings = keras.layers.Embedding(\n+            input_dim=sequence_length, output_dim=embed_dim\n+        )\n+        self.sequence_length = sequence_length\n+        self.vocab_size = vocab_size\n+        self.embed_dim = embed_dim\n+\n+    def call(self, inputs):\n+        length = tf.shape(inputs)[-1]\n+        positions = tf.range(start=0, limit=length, delta=1)\n+        embedded_tokens = self.token_embeddings(inputs)\n+        embedded_positions = self.position_embeddings(positions)\n+        return embedded_tokens + embedded_positions\n+\n+    def compute_mask(self, inputs, mask=None):\n+        return tf.math.not_equal(inputs, 0)\n+\n+\n+class TransformerDecoder(keras.layers.Layer):\n+    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n+        super().__init__(**kwargs)\n+        self.embed_dim = embed_dim\n+        self.latent_dim = latent_dim\n+        self.num_heads = num_heads\n+        self.attention_1 = keras.layers.MultiHeadAttention(\n+            num_heads=num_heads, key_dim=embed_dim\n+        )\n+        self.attention_2 = keras.layers.MultiHeadAttention(\n+            num_heads=num_heads, key_dim=embed_dim\n+        )\n+        self.dense_proj = keras.Sequential(\n+            [\n+                keras.layers.Dense(latent_dim, activation=\"relu\"),\n+                keras.layers.Dense(embed_dim),\n+            ]\n+        )\n+        self.layernorm_1 = keras.layers.LayerNormalization()\n+        self.layernorm_2 = keras.layers.LayerNormalization()\n+        self.layernorm_3 = keras.layers.LayerNormalization()\n+        self.supports_masking = True\n+\n+    def call(self, inputs, encoder_outputs, mask=None):\n+        causal_mask = self.get_causal_attention_mask(inputs)\n+        if mask is not None:\n+            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n+            padding_mask = tf.minimum(padding_mask, causal_mask)\n+\n+        attention_output_1 = self.attention_1(\n+            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n+        )\n+        out_1 = self.layernorm_1(inputs + attention_output_1)\n+\n+        attention_output_2 = self.attention_2(\n+            query=out_1,\n+            value=encoder_outputs,\n+            key=encoder_outputs,\n+            attention_mask=padding_mask,\n+        )\n+        out_2 = self.layernorm_2(out_1 + attention_output_2)\n+\n+        proj_output = self.dense_proj(out_2)\n+        return self.layernorm_3(out_2 + proj_output)\n+\n+    def get_causal_attention_mask(self, inputs):\n+        input_shape = tf.shape(inputs)\n+        batch_size, sequence_length = input_shape[0], input_shape[1]\n+        i = tf.range(sequence_length)[:, tf.newaxis]\n+        j = tf.range(sequence_length)\n+        mask = tf.cast(i >= j, dtype=\"int32\")\n+        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n+        mult = tf.concat(\n+            [\n+                tf.expand_dims(batch_size, -1),\n+                tf.constant([1, 1], dtype=tf.int32),\n+            ],\n+            axis=0,\n+        )\n+        return tf.tile(mask, mult)\n+\n+\n+def get_model(\n+    build=False, compile=False, jit_compile=False, include_preprocessing=True\n+):\n+    embed_dim = 256\n+    latent_dim = 256\n+    num_heads = 2\n+\n+    if include_preprocessing:\n+        encoder_inputs = keras.Input(shape=(), dtype=\"string\")\n+        decoder_inputs = keras.Input(shape=(), dtype=\"string\")\n+        encoder_x, decoder_x = get_input_preprocessor()(\n+            (encoder_inputs, decoder_inputs)\n+        )\n+    else:\n+        encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\")\n+        decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\")\n+        encoder_x = encoder_inputs\n+        decoder_x = decoder_inputs\n+\n+    x = PositionalEmbedding(SEQUENCE_LENGTH, VOCAB_SIZE, embed_dim)(encoder_x)\n+    encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n+\n+    encoded_seq_inputs = keras.Input(shape=(None, embed_dim))\n+    x = PositionalEmbedding(SEQUENCE_LENGTH, VOCAB_SIZE, embed_dim)(decoder_x)\n+    x = TransformerDecoder(embed_dim, latent_dim, num_heads)(\n+        x, encoded_seq_inputs\n+    )\n+    x = keras.layers.Dropout(0.5)(x)\n+    decoder_outputs = keras.layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n+    decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n+\n+    decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n+    model = keras.Model(\n+        [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n+    )\n+    if compile:\n+        model.compile(\n+            \"rmsprop\",\n+            loss=\"sparse_categorical_crossentropy\",\n+            metrics=[\"accuracy\"],\n+            jit_compile=jit_compile,\n+        )\n+    return model\n+\n+\n+def get_custom_objects():\n+    return {\n+        \"TransformerEncoder\": TransformerEncoder,\n+        \"TransformerDecoder\": TransformerDecoder,\n+        \"PositionalEmbedding\": PositionalEmbedding,\n+    }\n\n@@ -0,0 +1,118 @@\n+\"\"\"Variable autoencoder.\n+\n+Adapted from https://keras.io/examples/generative/vae/\n+\"\"\"\n+\n+import tensorflow as tf\n+from tensorflow import keras\n+\n+from keras.integration_test.models.input_spec import InputSpec\n+\n+IMG_SIZE = (28, 28)\n+LATENT_DIM = 64\n+\n+\n+def get_input_preprocessor():\n+    return None\n+\n+\n+class Sampling(keras.layers.Layer):\n+    def call(self, inputs):\n+        z_mean, z_log_var = inputs\n+        batch = tf.shape(z_mean)[0]\n+        dim = tf.shape(z_mean)[1]\n+        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n+        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n+\n+\n+class VAE(keras.Model):\n+    def __init__(self, encoder, decoder, **kwargs):\n+        super(VAE, self).__init__(**kwargs)\n+        self.encoder = encoder\n+        self.decoder = decoder\n+        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n+        self.reconstruction_loss_tracker = keras.metrics.Mean(\n+            name=\"reconstruction_loss\"\n+        )\n+        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n+\n+    @property\n+    def metrics(self):\n+        return [\n+            self.total_loss_tracker,\n+            self.reconstruction_loss_tracker,\n+            self.kl_loss_tracker,\n+        ]\n+\n+    def train_step(self, data):\n+        with tf.GradientTape() as tape:\n+            z_mean, z_log_var, z = self.encoder(data)\n+            reconstruction = self.decoder(z)\n+            reconstruction_loss = tf.reduce_mean(\n+                tf.reduce_sum(\n+                    keras.losses.binary_crossentropy(data, reconstruction),\n+                    axis=(1, 2),\n+                )\n+            )\n+            kl_loss = -0.5 * (\n+                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n+            )\n+            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n+            total_loss = reconstruction_loss + kl_loss\n+        grads = tape.gradient(total_loss, self.trainable_weights)\n+        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n+        self.total_loss_tracker.update_state(total_loss)\n+        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n+        self.kl_loss_tracker.update_state(kl_loss)\n+        return {\n+            \"loss\": self.total_loss_tracker.result(),\n+            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n+            \"kl_loss\": self.kl_loss_tracker.result(),\n+        }\n+\n+\n+def get_data_spec(batch_size):\n+    return InputSpec((batch_size,) + IMG_SIZE + (1,))\n+\n+\n+def get_model(\n+    build=False, compile=False, jit_compile=False, include_preprocessing=True\n+):\n+    encoder_inputs = keras.Input(shape=IMG_SIZE + (1,))\n+    x = keras.layers.Conv2D(\n+        32, 3, activation=\"relu\", strides=2, padding=\"same\"\n+    )(encoder_inputs)\n+    x = keras.layers.Conv2D(\n+        64, 3, activation=\"relu\", strides=2, padding=\"same\"\n+    )(x)\n+    x = keras.layers.Flatten()(x)\n+    x = keras.layers.Dense(16, activation=\"relu\")(x)\n+    z_mean = keras.layers.Dense(LATENT_DIM, name=\"z_mean\")(x)\n+    z_log_var = keras.layers.Dense(LATENT_DIM, name=\"z_log_var\")(x)\n+    z = Sampling()([z_mean, z_log_var])\n+    encoder = keras.Model(\n+        encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\"\n+    )\n+\n+    latent_inputs = keras.Input(shape=(LATENT_DIM,))\n+    x = keras.layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n+    x = keras.layers.Reshape((7, 7, 64))(x)\n+    x = keras.layers.Conv2DTranspose(\n+        64, 3, activation=\"relu\", strides=2, padding=\"same\"\n+    )(x)\n+    x = keras.layers.Conv2DTranspose(\n+        32, 3, activation=\"relu\", strides=2, padding=\"same\"\n+    )(x)\n+    decoder_outputs = keras.layers.Conv2DTranspose(\n+        1, 3, activation=\"sigmoid\", padding=\"same\"\n+    )(x)\n+    decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n+\n+    vae = VAE(encoder, decoder)\n+    if compile:\n+        vae.compile(optimizer=keras.optimizers.Adam(), jit_compile=jit_compile)\n+    return vae\n+\n+\n+def get_custom_objects():\n+    return {\"VAE\": VAE, \"Sampling\": Sampling}\n\n@@ -36,7 +36,6 @@ PIP_EXCLUDED_FILES = frozenset(\n PIP_EXCLUDED_DIRS = frozenset(\n     [\n         \"keras/benchmarks\",\n-        \"keras/integration_tests\",\n         \"keras/tests\",\n     ]\n )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
