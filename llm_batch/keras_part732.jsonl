{"custom_id": "keras#b502307cb2c1a387f29651f99f271f5bf589afb7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 732 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,7 +1,5 @@\n \"\"\"Library for exporting inference-only Keras models/layers.\"\"\"\n \n-from jax.experimental import jax2tf\n-\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers import Layer\n@@ -441,6 +439,8 @@ class ExportArchive:\n                         self._tf_trackable._misc_assets.append(trackable)\n \n     def _convert_jax2tf_function(self, fn, input_signature):\n+        from jax.experimental import jax2tf\n+\n         shapes = []\n         for spec in input_signature:\n             shapes.append(self._spec_to_poly_shape(spec))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e3d0b8b2ce2af87989a26f156a1b6859ff458ec3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 63 | Lines Deleted: 10 | Files Changed: 3 | Hunks: 13 | Methods Changed: 8 | Complexity Δ (Sum/Max): 10/7 | Churn Δ: 73 | Churn Cumulative: 5188 | Contributors (this commit): 23 | Commits (past 90d): 76 | Contributors (cumulative): 43 | DMM Complexity: 1.0\n\nDIFF:\n@@ -514,10 +514,13 @@ class Layer(BackendLayer, Operation):\n \n     @property\n     def variables(self):\n-        \"\"\"List of all layer state, including metric variables and random seeds.\n+        \"\"\"List of all layer state, including random seeds.\n \n         This extends `layer.weights` to include all state used by the layer\n-        including state for metrics and `SeedGenerator`s.\n+        including `SeedGenerator`s.\n+\n+        Note that metrics variables are not included here, use\n+        `metrics_variables` to visit all the metric variables.\n         \"\"\"\n         # Return all `Variables` associate with the layer including metrics\n         # and random seeds. Also deduplicate them.\n@@ -527,8 +530,6 @@ class Layer(BackendLayer, Operation):\n             if id(v) not in seen_ids:\n                 variables.append(v)\n                 seen_ids.add(id(v))\n-        for m in self._metrics:\n-            variables.extend(m.variables)\n         for sg in self._seed_generators:\n             variables.append(sg.state)\n         for layer in self._layers:\n@@ -602,6 +603,17 @@ class Layer(BackendLayer, Operation):\n             return self.weights\n         return [v for v in self.weights if not v.trainable]\n \n+    @property\n+    def metrics_variables(self):\n+        \"\"\"List of all metric variables.\"\"\"\n+        vars = []\n+        for metric in self._metrics:\n+            vars.extend(metric.variables)\n+        for layer in self._layers:\n+            for metric in layer._metrics:\n+                vars.extend(metric.variables)\n+        return vars\n+\n     def get_weights(self):\n         \"\"\"Return the values of `layer.weights` as a list of NumPy arrays.\"\"\"\n         return [v.numpy() for v in self.weights]\n\n@@ -3,6 +3,7 @@ import pytest\n \n from keras_core import backend\n from keras_core import layers\n+from keras_core import metrics\n from keras_core import models\n from keras_core import ops\n from keras_core import testing\n@@ -214,6 +215,45 @@ class LayerTest(testing.TestCase):\n         self.assertLen(layer.inner_layer.weights, 8)\n         self.assertLen(layer.weights, 8)\n \n+    def test_metric_tracking(self):\n+        class LayerWithMetric(layers.Layer):\n+            def __init__(self, units):\n+                super().__init__()\n+                self.dense = layers.Dense(units)\n+                self.metric = metrics.MeanSquaredError(name=\"my_metric\")\n+\n+            def build(self, input_shape):\n+                self.dense.build(input_shape)\n+\n+            def call(self, x):\n+                return self.dense(x)\n+\n+        class NestedLayerWithMetric(layers.Layer):\n+            def __init__(self, units):\n+                super().__init__()\n+                self.layer_with_metric = LayerWithMetric(units)\n+                self.metric = metrics.MeanSquaredError(name=\"my_metric\")\n+\n+            def build(self, input_shape):\n+                self.layer_with_metric.build(input_shape)\n+\n+            def call(self, x):\n+                return self.layer_with_metric(x)\n+\n+        layer = LayerWithMetric(3)\n+        layer.build((1, 3))\n+\n+        self.assertLen(layer.metrics_variables, 2)\n+        self.assertLen(layer.trainable_variables, 2)\n+        self.assertLen(layer.non_trainable_variables, 0)\n+\n+        layer = NestedLayerWithMetric(3)\n+        layer.build((1, 3))\n+\n+        self.assertLen(layer.metrics_variables, 4)\n+        self.assertLen(layer.trainable_variables, 2)\n+        self.assertLen(layer.non_trainable_variables, 0)\n+\n     def test_build_on_call(self):\n         class LayerWithUnbuiltState(layers.Layer):\n             def __init__(self, units):\n\n@@ -29,7 +29,7 @@ else:\n \n \n # A model is just a layer mixed in with a Trainer.\n-class ExampleModel(layers.Dense, Trainer):\n+class ExampleModel(Trainer, layers.Dense):\n     def __init__(self, units):\n         layers.Dense.__init__(\n             self,\n@@ -40,7 +40,7 @@ class ExampleModel(layers.Dense, Trainer):\n         Trainer.__init__(self)\n \n \n-class StructModel(layers.Layer, Trainer):\n+class StructModel(Trainer, layers.Layer):\n     def __init__(self, units):\n         layers.Layer.__init__(self)\n         Trainer.__init__(self)\n@@ -62,7 +62,7 @@ class StructModel(layers.Layer, Trainer):\n         }\n \n \n-class ListModel(layers.Layer, Trainer):\n+class ListModel(Trainer, layers.Layer):\n     def __init__(self, units):\n         layers.Layer.__init__(self)\n         Trainer.__init__(self)\n@@ -82,7 +82,7 @@ class ListModel(layers.Layer, Trainer):\n         return self.dense_1(x[0]) + self.dense_2(x[1])\n \n \n-class TrainingTestingLayer(layers.Layer, Trainer):\n+class TrainingTestingLayer(Trainer, layers.Layer):\n     def __init__(self, **kwargs):\n         layers.Layer.__init__(self, **kwargs)\n         Trainer.__init__(self)\n@@ -96,7 +96,7 @@ class TrainingTestingLayer(layers.Layer, Trainer):\n class TestTrainer(testing.TestCase, parameterized.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_metric_tracking(self):\n-        class ModelWithMetric(layers.Dense, Trainer):\n+        class ModelWithMetric(Trainer, layers.Dense):\n             def __init__(self, units):\n                 layers.Dense.__init__(\n                     self,\n@@ -132,6 +132,7 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n \n         # And those weights are tracked at the model level\n         self.assertEqual(len(model.metrics_variables), 6)\n+        self.assertLen(model.non_trainable_variables, 0)\n \n         # Models with only weighted_metrics should have the same 3 metrics\n         model_weighted = ModelWithMetric(units=3)\n@@ -361,7 +362,7 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n         reason=\"half precision unsupported on torch CPU.\",\n     )\n     def test_loss_scaling_prevents_underflow(self):\n-        class DeepModel(layers.Layer, Trainer):\n+        class DeepModel(Trainer, layers.Layer):\n             def __init__(self):\n                 layers.Layer.__init__(self, dtype=\"mixed_float16\")\n                 Trainer.__init__(self)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1956e732459ec9801f39235c79be8fb01b0059f7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 7 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 28 | Churn Cumulative: 2623 | Contributors (this commit): 10 | Commits (past 90d): 22 | Contributors (cumulative): 10 | DMM Complexity: 0.16666666666666666\n\nDIFF:\n@@ -1,3 +1,5 @@\n+from functools import partial\n+\n import jax\n import numpy as np\n import tree\n@@ -237,8 +239,11 @@ class JAXTrainer(base_trainer.Trainer):\n             train_step = one_train_step\n \n         if not self.run_eagerly and self.jit_compile:\n-\n-            @jax.jit\n+            # Note that we mark the state and data to be donated to jax,\n+            # so that jax will reuse the memory buffer for outputs.\n+            # This will reduce the memory usage of the training function by\n+            # half.\n+            @partial(jax.jit, donate_argnames=\"state\")\n             def compiled_train_step(state, data):\n                 return train_step(state, data)\n \n@@ -266,8 +271,11 @@ class JAXTrainer(base_trainer.Trainer):\n             test_step = one_test_step\n \n         if not self.run_eagerly and self.jit_compile:\n-\n-            @jax.jit\n+            # Note that we mark the state and data to be donated to jax,\n+            # so that jax will reuse the memory buffer for outputs.\n+            # This will reduce the memory usage of the training function by\n+            # half.\n+            @partial(jax.jit, donate_argnames=\"state\")\n             def compiled_test_step(state, data):\n                 return test_step(state, data)\n \n@@ -578,15 +586,18 @@ class JAXTrainer(base_trainer.Trainer):\n             )\n             data = self._distribute_data(data)\n             logs, state = self.test_function(state, data)\n-            # Note that trainable variables are not returned since they're\n-            # immutable here.\n-            _, non_trainable_variables, metrics_variables = state\n+            (\n+                trainable_variables,\n+                non_trainable_variables,\n+                metrics_variables,\n+            ) = state\n \n             # Setting _jax_state enables callbacks to force a state sync\n             # if they need to.\n             self._jax_state = {\n                 # I wouldn't recommend modifying non-trainable model state\n                 # during evaluate(), but it's allowed.\n+                \"trainable_variables\": trainable_variables,\n                 \"non_trainable_variables\": non_trainable_variables,\n                 \"metrics_variables\": metrics_variables,\n             }\n@@ -764,8 +775,9 @@ class JAXTrainer(base_trainer.Trainer):\n         logs, state = self.test_function(state, [data])\n \n         # State sync\n-        _, non_trainable_variables, metrics_variables = state\n+        trainable_variables, non_trainable_variables, metrics_variables = state\n         self._jax_state = {\n+            \"trainable_variables\": trainable_variables,\n             \"non_trainable_variables\": non_trainable_variables,\n             \"metrics_variables\": metrics_variables,\n         }\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#459d16b6180ff695a95e342a0b9562508e09359f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 22 | Files Changed: 1 | Hunks: 8 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 31 | Churn Cumulative: 649 | Contributors (this commit): 4 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,6 +1,6 @@\n import numpy as np\n \n-from keras_core import backend\n+from keras_core import backend, ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.utils import argument_validation\n@@ -17,13 +17,9 @@ class Discretization(Layer):\n     contiguous ranges and output an integer index indicating which range each\n     element was placed in.\n \n-    **Note:** This layer uses TensorFlow internally. It cannot\n-    be used as part of the compiled computation graph of a model with\n-    any backend other than TensorFlow.\n-    It can however be used with any backend when running eagerly.\n-    It can also always be used as part of an input preprocessing pipeline\n-    with any backend (outside the model itself), which is how we recommend\n-    to use this layer.\n+    This layer can also always be used as part of an input preprocessing\n+    pipeline with any backend (outside the model itself), which is how we\n+    recommend to use this layer.\n \n     **Note:** This layer is safe to use inside a `tf.data` pipeline\n     (independently of which backend you're using).\n@@ -78,14 +74,14 @@ class Discretization(Layer):\n \n     Examples:\n \n-    Bucketize float values based on provided buckets.\n+    Digitize float values based on provided buckets.\n     >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n     >>> layer = Discretization(bin_boundaries=[0., 1., 2.])\n     >>> layer(input)\n     array([[0, 2, 3, 1],\n            [1, 3, 2, 1]])\n \n-    Bucketize float values based on a number of buckets to compute.\n+    Digitize float values based on a number of buckets to compute.\n     >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n     >>> layer = Discretization(num_bins=4, epsilon=0.01)\n     >>> layer.adapt(input)\n@@ -241,20 +237,15 @@ class Discretization(Layer):\n         if not isinstance(\n             inputs,\n             (\n-                tf.Tensor,\n-                tf.SparseTensor,\n-                tf.RaggedTensor,\n                 np.ndarray,\n                 backend.KerasTensor,\n             ),\n         ):\n-            inputs = tf.convert_to_tensor(\n-                backend.convert_to_numpy(inputs), dtype=self.input_dtype\n+            inputs = backend.convert_to_tensor(\n+                inputs, dtype=self.input_dtype\n             )\n \n-        from keras_core.backend.tensorflow.numpy import digitize\n-\n-        indices = digitize(inputs, self.bin_boundaries)\n+        indices = ops.digitize(inputs, self.bin_boundaries)\n \n         outputs = tf_utils.encode_categorical_inputs(\n             indices,\n@@ -370,7 +361,3 @@ def compress_summary(summary, epsilon):\n     )\n     summary = np.stack((new_bins, new_weights))\n     return summary.astype(\"float32\")\n-\n-\n-def bucketize(inputs, boundaries):\n-    return tf.raw_ops.Bucketize(input=inputs, boundaries=boundaries)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#faf8bc2ae37950c09c7b42a6e2a5d0699e0609cf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 53 | Lines Deleted: 15 | Files Changed: 2 | Hunks: 12 | Methods Changed: 2 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 68 | Churn Cumulative: 2048 | Contributors (this commit): 5 | Commits (past 90d): 13 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,5 +1,5 @@\n import warnings\n-\n+from keras_core import ops\n \n def _convert_conv_tranpose_padding_args_from_keras_to_jax(\n     kernel_size, stride, dilation_rate, padding, output_padding\n@@ -255,3 +255,46 @@ def compute_conv_transpose_output_shape(\n     else:\n         output_shape = [input_shape[0], filters] + output_shape\n     return output_shape\n+\n+\n+def encode_categorical_inputs(\n+    inputs,\n+    output_mode,\n+    depth,\n+    dtype=\"float32\",\n+    sparse=False,\n+    count_weights=None,\n+):\n+    \"\"\"Encodes categoical inputs according to output_mode.\"\"\"\n+    if output_mode == \"int\":\n+        return ops.identity(ops.cast(inputs, dtype))\n+\n+    original_shape = inputs.shape\n+    # In all cases, we should uprank scalar input to a single sample.\n+    if len(ops.shape(inputs)) == 0:\n+        inputs = ops.expand_dims(inputs, -1)\n+    # One hot will unprank only if the final output dimension is not already 1.\n+    if output_mode == \"one_hot\":\n+        if ops.shape(inputs)[-1] != 1:\n+            inputs = ops.expand_dims(inputs, -1)\n+\n+    if len(ops.shape(inputs)) > 2:\n+        raise ValueError(\n+            \"When output_mode is not `'int'`, maximum supported output rank \"\n+            f\"is 2. Received output_mode {output_mode} and input shape \"\n+            f\"{original_shape}, \"\n+            f\"which would result in output rank {inputs.shape.rank}.\"\n+        )\n+\n+    binary_output = output_mode in (\"multi_hot\", \"one_hot\")\n+    bincounts = ops.bincount(\n+        inputs,\n+        weights=count_weights,\n+        minlength=depth,\n+    )\n+    if binary_output:\n+      one_hot_input = ops.one_hot(inputs, depth)\n+      bincounts = ops.where(ops.any(one_hot_input, axis =-2), 1, 0)\n+    bincounts = ops.cast(bincounts, dtype)\n+\n+    return bincounts\n\n@@ -1,26 +1,24 @@\n import numpy as np\n \n-from keras_core import backend, ops\n+from keras_core import backend\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n-from keras_core.layers.layer import Layer\n from keras_core.utils import argument_validation\n from keras_core.utils import backend_utils\n from keras_core.utils import tf_utils\n from keras_core.utils.module_utils import tensorflow as tf\n+from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras_core.backend.common.backend_utils import encode_categorical_inputs\n \n \n @keras_core_export(\"keras_core.layers.Discretization\")\n-class Discretization(Layer):\n+class Discretization(TFDataLayer):\n     \"\"\"A preprocessing layer which buckets continuous features by ranges.\n \n     This layer will place each element of its input data into one of several\n     contiguous ranges and output an integer index indicating which range each\n     element was placed in.\n \n-    This layer can also always be used as part of an input preprocessing\n-    pipeline with any backend (outside the model itself), which is how we\n-    recommend to use this layer.\n-\n     **Note:** This layer is safe to use inside a `tf.data` pipeline\n     (independently of which backend you're using).\n \n@@ -74,14 +72,14 @@ class Discretization(Layer):\n \n     Examples:\n \n-    Digitize float values based on provided buckets.\n+    Discretize float values based on provided buckets.\n     >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n     >>> layer = Discretization(bin_boundaries=[0., 1., 2.])\n     >>> layer(input)\n     array([[0, 2, 3, 1],\n            [1, 3, 2, 1]])\n \n-    Digitize float values based on a number of buckets to compute.\n+    Discretize float values based on a number of buckets to compute.\n     >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n     >>> layer = Discretization(num_bins=4, epsilon=0.01)\n     >>> layer.adapt(input)\n@@ -241,17 +239,14 @@ class Discretization(Layer):\n                 backend.KerasTensor,\n             ),\n         ):\n-            inputs = backend.convert_to_tensor(\n-                inputs, dtype=self.input_dtype\n-            )\n+          self._convert_input_args = True\n \n         indices = ops.digitize(inputs, self.bin_boundaries)\n \n-        outputs = tf_utils.encode_categorical_inputs(\n+        outputs = encode_categorical_inputs(\n             indices,\n             output_mode=self.output_mode,\n             depth=len(self.bin_boundaries) + 1,\n-            sparse=self.sparse,\n             dtype=self.compute_dtype,\n         )\n         if (\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3c44da563bda5e8778e130a1dded86e2c264d26d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 2055 | Contributors (this commit): 5 | Commits (past 90d): 15 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -1,6 +1,8 @@\n import warnings\n+\n from keras_core import ops\n \n+\n def _convert_conv_tranpose_padding_args_from_keras_to_jax(\n     kernel_size, stride, dilation_rate, padding, output_padding\n ):\n\n@@ -3,12 +3,11 @@ import numpy as np\n from keras_core import backend\n from keras_core import ops\n from keras_core.api_export import keras_core_export\n+from keras_core.backend.common.backend_utils import encode_categorical_inputs\n+from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n from keras_core.utils import argument_validation\n from keras_core.utils import backend_utils\n-from keras_core.utils import tf_utils\n from keras_core.utils.module_utils import tensorflow as tf\n-from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n-from keras_core.backend.common.backend_utils import encode_categorical_inputs\n \n \n @keras_core_export(\"keras_core.layers.Discretization\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#264dde629a9542e7584c5b550954559e124b590a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 313 | Lines Deleted: 54 | Files Changed: 3 | Hunks: 16 | Methods Changed: 4 | Complexity Δ (Sum/Max): -5/1 | Churn Δ: 367 | Churn Cumulative: 2422 | Contributors (this commit): 6 | Commits (past 90d): 18 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,285 @@\n+\"\"\"\n+Title: Fine-tuning a pre-trained TorchVision Model\n+Author: [Ayush Thakur](https://twitter.com/ayushthakur0), [Soumik Rakshit](https://twitter.com/soumikRakshit96)\n+Date created: 2023/09/18\n+Last modified: 2023/09/18\n+Description: Fine-tuning a pre-trained Torch model from TorchVision for image\n+classification using Keras.\n+\"\"\"\n+\"\"\"\n+## Introduction\n+\n+[TorchVision](https://pytorch.org/vision/stable/index.html) is a library part of the\n+[PyTorch](http://pytorch.org/) project that consists of popular datasets, model\n+architectures, and common image transformations for computer vision. This example\n+demonstrates how we can perform transfer learning for image classification using a\n+pre-trained backbone model from TorchVision on the [Imagenette\n+dataset](https://github.com/fastai/imagenette) using KerasCore. We will also demonstrate\n+the compatibility of KerasCore with an input system consisting of [Torch Datasets and\n+Dataloaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html).\n+\n+### References:\n+\n+- [Customizing what happens in `fit()` with\n+PyTorch](https://keras.io/keras_core/guides/custom_train_step_in_torch/)\n+- [PyTorch Datasets and\n+Dataloaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n+- [Transfer learning for Computer Vision using\n+PyTorch](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n+- [Fine-tuning a TorchVision Model using Keras\n+](https://wandb.ai/ml-colabs/keras-torch/reports/Fine-tuning-a-TorchVision-Model-using-Keras--Vmlldzo1NDE5NDE1)\n+\n+## Setup\n+\"\"\"\n+\n+import os\n+\n+os.environ[\"KERAS_BACKEND\"] = \"torch\"\n+\n+import numpy as np\n+import matplotlib.pyplot as plt\n+\n+import torch\n+import torch.nn as nn\n+import torch.nn.functional as F\n+\n+import torchvision\n+from torchvision import datasets, models, transforms\n+\n+import keras_core as keras\n+from keras_core.layers import TorchModuleWrapper\n+\n+\"\"\"\n+## Define the Hyperparameters\n+\"\"\"\n+\n+batch_size = 32\n+image_size = 224\n+initial_learning_rate = 1e-3\n+num_epochs = 5\n+\n+\"\"\"\n+## Creating the Torch Datasets and Dataloaders\n+\n+In this example, we would train an image classification model on the [Imagenette\n+dataset](https://github.com/fastai/imagenette). Imagenette is a subset of 10 easily\n+classified classes from [Imagenet](https://www.image-net.org/) (tench, English springer,\n+cassette player, chain saw, church, French horn, garbage truck, gas pump, golf ball,\n+parachute).\n+\"\"\"\n+\n+# Fetch the imagenette dataset\n+data_dir = keras.utils.get_file(\n+    fname=\"imagenette2-320.tgz\",\n+    origin=\"https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz\",\n+    extract=True,\n+)\n+data_dir = data_dir.replace(\".tgz\", \"\")\n+\n+\"\"\"\n+Next, we define pre-processing and augmentation transforms from TorchVision for the train\n+and validation sets.\n+\"\"\"\n+\n+data_transforms = {\n+    \"train\": transforms.Compose(\n+        [\n+            transforms.RandomResizedCrop(image_size),\n+            transforms.RandomHorizontalFlip(),\n+            transforms.ToTensor(),\n+            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n+        ]\n+    ),\n+    \"val\": transforms.Compose(\n+        [\n+            transforms.Resize(256),\n+            transforms.CenterCrop(image_size),\n+            transforms.ToTensor(),\n+            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n+        ]\n+    ),\n+}\n+\n+\"\"\"\n+Finally, we will use TorchVision and the\n+[`torch.utils.data`](https://pytorch.org/docs/stable/data.html) packages for creating the\n+dataloaders for trainig and validation.\n+\"\"\"\n+\n+# Define the train and validation datasets\n+image_datasets = {\n+    x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n+    for x in [\"train\", \"val\"]\n+}\n+\n+# Define the torch dataloaders corresponding to the train and validation dataset\n+dataloaders = {\n+    x: torch.utils.data.DataLoader(\n+        image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4\n+    )\n+    for x in [\"train\", \"val\"]\n+}\n+dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\"]}\n+class_names = image_datasets[\"train\"].classes\n+\n+# Specify the global device\n+device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n+\n+\"\"\"\n+Let us visualize a few samples from the training dataloader.\n+\"\"\"\n+\n+plt.figure(figsize=(10, 10))\n+sample_images, sample_labels = next(iter(dataloaders[\"train\"]))\n+sample_images = sample_images.numpy()\n+sample_labels = sample_labels.numpy()\n+for idx in range(9):\n+    ax = plt.subplot(3, 3, idx + 1)\n+    image = sample_images[idx].transpose((1, 2, 0))\n+    mean = np.array([0.485, 0.456, 0.406])\n+    std = np.array([0.229, 0.224, 0.225])\n+    image = std * image + mean\n+    image = np.clip(image, 0, 1)\n+    plt.imshow(image)\n+    plt.title(\"Ground Truth Label: \" + class_names[int(sample_labels[idx])])\n+    plt.axis(\"off\")\n+\n+\"\"\"\n+## The Image Classification Model\n+\"\"\"\n+\n+\"\"\"\n+We typically define a model in PyTorch using\n+[`torch.nn.Module`s](https://pytorch.org/docs/stable/notes/modules.html) which act as the\n+building blocks of stateful computation. Let us define the ResNet18 model from the\n+TorchVision package as a `torch.nn.Module` pre-trained on the [Imagenet1K\n+dataset](https://huggingface.co/datasets/imagenet-1k).\n+\"\"\"\n+\n+# Define the pre-trained resnet18 module from TorchVision\n+resnet_18 = models.resnet18(weights=\"IMAGENET1K_V1\")\n+\n+# We set the classification head of the pre-trained ResNet18\n+# module to an identity module\n+resnet_18.fc = nn.Identity()\n+\n+\"\"\"\n+Even though Keras supports PyTorch as a backend, it does not mean that we can nest torch\n+modules inside a [`keras_core.Model`](https://keras.io/keras_core/api/models/), because\n+trainable variables inside a Keras Model is tracked exclusively via [Keras\n+Layers](https://keras.io/keras_core/api/layers/).\n+\n+KerasCore provides us with a feature called `TorchModuleWrapper` which enables us to do\n+exactly this. The `TorchModuleWrapper` is a Keras Layer that accepts a torch module and\n+tracks its trainable variables, essentially converting the torch module into a Keras\n+Layer. This enables us to put any torch modules inside a Keras Model and train them with\n+a single `model.fit()`!\n+\"\"\"\n+\n+# We set the trainable ResNet18 backbone to be a Keras Layer\n+# using `TorchModuleWrapper`\n+backbone = TorchModuleWrapper(resnet_18)\n+\n+# We set this to `False` if you want to freeze the backbone\n+backbone.trainable = True\n+\n+\"\"\"\n+Now, we will build a Keras functional model with the backbone layer.\n+\"\"\"\n+\n+inputs = keras.Input(shape=(3, image_size, image_size))\n+x = backbone(inputs)\n+x = keras.layers.Dropout(0.5)(x)\n+x = keras.layers.Dense(len(class_names))(x)\n+outputs = keras.activations.softmax(x, axis=1)\n+model = keras.Model(inputs, outputs, name=\"ResNet18_Classifier\")\n+\n+model.summary()\n+\n+# Create exponential decay learning rate scheduler\n+decay_steps = num_epochs * len(dataloaders[\"train\"]) // batch_size\n+lr_scheduler = keras.optimizers.schedules.ExponentialDecay(\n+    initial_learning_rate=initial_learning_rate,\n+    decay_steps=decay_steps,\n+    decay_rate=0.1,\n+)\n+\n+# Compile the model\n+model.compile(\n+    loss=\"sparse_categorical_crossentropy\",\n+    optimizer=keras.optimizers.Adam(lr_scheduler),\n+    metrics=[\"accuracy\"],\n+)\n+\n+# Define the backend-agnostic WandB callbacks for KerasCore\n+callbacks = [\n+    # Save best model checkpoints\n+    keras.callbacks.ModelCheckpoint(\n+        filepath=\"model.weights.h5\",\n+        monitor=\"val_loss\",\n+        save_best_only=True,\n+        save_weights_only=True,\n+    )\n+]\n+\n+# Train the model by calling model.fit\n+history = model.fit(\n+    dataloaders[\"train\"],\n+    validation_data=dataloaders[\"val\"],\n+    epochs=num_epochs,\n+    callbacks=callbacks,\n+)\n+\n+\n+def plot_history(item):\n+    plt.plot(history.history[item], label=item)\n+    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n+    plt.xlabel(\"Epochs\")\n+    plt.ylabel(item)\n+    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n+    plt.legend()\n+    plt.grid()\n+    plt.show()\n+\n+\n+plot_history(\"loss\")\n+plot_history(\"accuracy\")\n+\n+\"\"\"\n+## Evaluation and Inference\n+\n+Now, we let us load the best model weights checkpoint and evaluate the model.\n+\"\"\"\n+\n+model.load_weights(\"model.weights.h5\")\n+_, val_accuracy = model.evaluate(dataloaders[\"val\"])\n+print(\"Best Validation Accuracy:\", val_accuracy)\n+\n+\"\"\"\n+Finally, let us visualize the some predictions of the model\n+\"\"\"\n+\n+plt.figure(figsize=(10, 10))\n+sample_images, sample_labels = next(iter(dataloaders[\"train\"]))\n+\n+# We perform inference and detach the predicted probabilities from the Torch\n+# computation graph with a tensor that does not require gradient computation.\n+sample_pred_probas = model(sample_images.to(\"cuda\")).detach()\n+sample_pred_logits = keras.ops.argmax(sample_pred_probas, axis=1)\n+sample_pred_logits = sample_pred_logits.to(\"cpu\").numpy()\n+\n+sample_images = sample_images.numpy()\n+sample_labels = sample_labels.numpy()\n+\n+for idx in range(9):\n+    ax = plt.subplot(3, 3, idx + 1)\n+    image = sample_images[idx].transpose((1, 2, 0))\n+    mean = np.array([0.485, 0.456, 0.406])\n+    std = np.array([0.229, 0.224, 0.225])\n+    image = std * image + mean\n+    image = np.clip(image, 0, 1)\n+    plt.imshow(image)\n+    title = \"Ground Truth Label: \" + class_names[int(sample_labels[idx])]\n+    title += \"\\nPredicted Label: \" + class_names[int(sample_pred_logits[idx])]\n+    plt.title(title)\n+    plt.axis(\"off\")\n\n@@ -1,7 +1,5 @@\n import warnings\n \n-from keras_core import ops\n-\n \n def _convert_conv_tranpose_padding_args_from_keras_to_jax(\n     kernel_size, stride, dilation_rate, padding, output_padding\n@@ -257,46 +255,3 @@ def compute_conv_transpose_output_shape(\n     else:\n         output_shape = [input_shape[0], filters] + output_shape\n     return output_shape\n-\n-\n-def encode_categorical_inputs(\n-    inputs,\n-    output_mode,\n-    depth,\n-    dtype=\"float32\",\n-    sparse=False,\n-    count_weights=None,\n-):\n-    \"\"\"Encodes categoical inputs according to output_mode.\"\"\"\n-    if output_mode == \"int\":\n-        return ops.identity(ops.cast(inputs, dtype))\n-\n-    original_shape = inputs.shape\n-    # In all cases, we should uprank scalar input to a single sample.\n-    if len(ops.shape(inputs)) == 0:\n-        inputs = ops.expand_dims(inputs, -1)\n-    # One hot will unprank only if the final output dimension is not already 1.\n-    if output_mode == \"one_hot\":\n-        if ops.shape(inputs)[-1] != 1:\n-            inputs = ops.expand_dims(inputs, -1)\n-\n-    if len(ops.shape(inputs)) > 2:\n-        raise ValueError(\n-            \"When output_mode is not `'int'`, maximum supported output rank \"\n-            f\"is 2. Received output_mode {output_mode} and input shape \"\n-            f\"{original_shape}, \"\n-            f\"which would result in output rank {inputs.shape.rank}.\"\n-        )\n-\n-    binary_output = output_mode in (\"multi_hot\", \"one_hot\")\n-    bincounts = ops.bincount(\n-        inputs,\n-        weights=count_weights,\n-        minlength=depth,\n-    )\n-    if binary_output:\n-        one_hot_input = ops.one_hot(inputs, depth)\n-        bincounts = ops.where(ops.any(one_hot_input, axis=-2), 1, 0)\n-    bincounts = ops.cast(bincounts, dtype)\n-\n-    return bincounts\n\n@@ -1,23 +1,30 @@\n import numpy as np\n \n from keras_core import backend\n-from keras_core import ops\n from keras_core.api_export import keras_core_export\n-from keras_core.backend.common.backend_utils import encode_categorical_inputs\n-from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n+from keras_core.layers.layer import Layer\n from keras_core.utils import argument_validation\n from keras_core.utils import backend_utils\n+from keras_core.utils import tf_utils\n from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.Discretization\")\n-class Discretization(TFDataLayer):\n+class Discretization(Layer):\n     \"\"\"A preprocessing layer which buckets continuous features by ranges.\n \n     This layer will place each element of its input data into one of several\n     contiguous ranges and output an integer index indicating which range each\n     element was placed in.\n \n+    **Note:** This layer uses TensorFlow internally. It cannot\n+    be used as part of the compiled computation graph of a model with\n+    any backend other than TensorFlow.\n+    It can however be used with any backend when running eagerly.\n+    It can also always be used as part of an input preprocessing pipeline\n+    with any backend (outside the model itself), which is how we recommend\n+    to use this layer.\n+\n     **Note:** This layer is safe to use inside a `tf.data` pipeline\n     (independently of which backend you're using).\n \n@@ -71,14 +78,14 @@ class Discretization(TFDataLayer):\n \n     Examples:\n \n-    Discretize float values based on provided buckets.\n+    Bucketize float values based on provided buckets.\n     >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n     >>> layer = Discretization(bin_boundaries=[0., 1., 2.])\n     >>> layer(input)\n     array([[0, 2, 3, 1],\n            [1, 3, 2, 1]])\n \n-    Discretize float values based on a number of buckets to compute.\n+    Bucketize float values based on a number of buckets to compute.\n     >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n     >>> layer = Discretization(num_bins=4, epsilon=0.01)\n     >>> layer.adapt(input)\n@@ -234,18 +241,26 @@ class Discretization(TFDataLayer):\n         if not isinstance(\n             inputs,\n             (\n+                tf.Tensor,\n+                tf.SparseTensor,\n+                tf.RaggedTensor,\n                 np.ndarray,\n                 backend.KerasTensor,\n             ),\n         ):\n-            self._convert_input_args = True\n+            inputs = tf.convert_to_tensor(\n+                backend.convert_to_numpy(inputs), dtype=self.input_dtype\n+            )\n \n-        indices = ops.digitize(inputs, self.bin_boundaries)\n+        from keras_core.backend.tensorflow.numpy import digitize\n \n-        outputs = encode_categorical_inputs(\n+        indices = digitize(inputs, self.bin_boundaries)\n+\n+        outputs = tf_utils.encode_categorical_inputs(\n             indices,\n             output_mode=self.output_mode,\n             depth=len(self.bin_boundaries) + 1,\n+            sparse=self.sparse,\n             dtype=self.compute_dtype,\n         )\n         if (\n@@ -355,3 +370,7 @@ def compress_summary(summary, epsilon):\n     )\n     summary = np.stack((new_bins, new_weights))\n     return summary.astype(\"float32\")\n+\n+\n+def bucketize(inputs, boundaries):\n+    return tf.raw_ops.Bucketize(input=inputs, boundaries=boundaries)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#536a8167bfdeba3f2254f422d35c1ae57ef7ba45", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 54 | Lines Deleted: 314 | Files Changed: 4 | Hunks: 16 | Methods Changed: 5 | Complexity Δ (Sum/Max): 5/7 | Churn Δ: 368 | Churn Cumulative: 3626 | Contributors (this commit): 14 | Commits (past 90d): 39 | Contributors (cumulative): 23 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,285 +0,0 @@\n-\"\"\"\n-Title: Fine-tuning a pre-trained TorchVision Model\n-Author: [Ayush Thakur](https://twitter.com/ayushthakur0), [Soumik Rakshit](https://twitter.com/soumikRakshit96)\n-Date created: 2023/09/18\n-Last modified: 2023/09/18\n-Description: Fine-tuning a pre-trained Torch model from TorchVision for image\n-classification using Keras.\n-\"\"\"\n-\"\"\"\n-## Introduction\n-\n-[TorchVision](https://pytorch.org/vision/stable/index.html) is a library part of the\n-[PyTorch](http://pytorch.org/) project that consists of popular datasets, model\n-architectures, and common image transformations for computer vision. This example\n-demonstrates how we can perform transfer learning for image classification using a\n-pre-trained backbone model from TorchVision on the [Imagenette\n-dataset](https://github.com/fastai/imagenette) using KerasCore. We will also demonstrate\n-the compatibility of KerasCore with an input system consisting of [Torch Datasets and\n-Dataloaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html).\n-\n-### References:\n-\n-- [Customizing what happens in `fit()` with\n-PyTorch](https://keras.io/keras_core/guides/custom_train_step_in_torch/)\n-- [PyTorch Datasets and\n-Dataloaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n-- [Transfer learning for Computer Vision using\n-PyTorch](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n-- [Fine-tuning a TorchVision Model using Keras\n-](https://wandb.ai/ml-colabs/keras-torch/reports/Fine-tuning-a-TorchVision-Model-using-Keras--Vmlldzo1NDE5NDE1)\n-\n-## Setup\n-\"\"\"\n-\n-import os\n-\n-os.environ[\"KERAS_BACKEND\"] = \"torch\"\n-\n-import numpy as np\n-import matplotlib.pyplot as plt\n-\n-import torch\n-import torch.nn as nn\n-import torch.nn.functional as F\n-\n-import torchvision\n-from torchvision import datasets, models, transforms\n-\n-import keras_core as keras\n-from keras_core.layers import TorchModuleWrapper\n-\n-\"\"\"\n-## Define the Hyperparameters\n-\"\"\"\n-\n-batch_size = 32\n-image_size = 224\n-initial_learning_rate = 1e-3\n-num_epochs = 5\n-\n-\"\"\"\n-## Creating the Torch Datasets and Dataloaders\n-\n-In this example, we would train an image classification model on the [Imagenette\n-dataset](https://github.com/fastai/imagenette). Imagenette is a subset of 10 easily\n-classified classes from [Imagenet](https://www.image-net.org/) (tench, English springer,\n-cassette player, chain saw, church, French horn, garbage truck, gas pump, golf ball,\n-parachute).\n-\"\"\"\n-\n-# Fetch the imagenette dataset\n-data_dir = keras.utils.get_file(\n-    fname=\"imagenette2-320.tgz\",\n-    origin=\"https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz\",\n-    extract=True,\n-)\n-data_dir = data_dir.replace(\".tgz\", \"\")\n-\n-\"\"\"\n-Next, we define pre-processing and augmentation transforms from TorchVision for the train\n-and validation sets.\n-\"\"\"\n-\n-data_transforms = {\n-    \"train\": transforms.Compose(\n-        [\n-            transforms.RandomResizedCrop(image_size),\n-            transforms.RandomHorizontalFlip(),\n-            transforms.ToTensor(),\n-            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n-        ]\n-    ),\n-    \"val\": transforms.Compose(\n-        [\n-            transforms.Resize(256),\n-            transforms.CenterCrop(image_size),\n-            transforms.ToTensor(),\n-            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n-        ]\n-    ),\n-}\n-\n-\"\"\"\n-Finally, we will use TorchVision and the\n-[`torch.utils.data`](https://pytorch.org/docs/stable/data.html) packages for creating the\n-dataloaders for trainig and validation.\n-\"\"\"\n-\n-# Define the train and validation datasets\n-image_datasets = {\n-    x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n-    for x in [\"train\", \"val\"]\n-}\n-\n-# Define the torch dataloaders corresponding to the train and validation dataset\n-dataloaders = {\n-    x: torch.utils.data.DataLoader(\n-        image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4\n-    )\n-    for x in [\"train\", \"val\"]\n-}\n-dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\"]}\n-class_names = image_datasets[\"train\"].classes\n-\n-# Specify the global device\n-device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n-\n-\"\"\"\n-Let us visualize a few samples from the training dataloader.\n-\"\"\"\n-\n-plt.figure(figsize=(10, 10))\n-sample_images, sample_labels = next(iter(dataloaders[\"train\"]))\n-sample_images = sample_images.numpy()\n-sample_labels = sample_labels.numpy()\n-for idx in range(9):\n-    ax = plt.subplot(3, 3, idx + 1)\n-    image = sample_images[idx].transpose((1, 2, 0))\n-    mean = np.array([0.485, 0.456, 0.406])\n-    std = np.array([0.229, 0.224, 0.225])\n-    image = std * image + mean\n-    image = np.clip(image, 0, 1)\n-    plt.imshow(image)\n-    plt.title(\"Ground Truth Label: \" + class_names[int(sample_labels[idx])])\n-    plt.axis(\"off\")\n-\n-\"\"\"\n-## The Image Classification Model\n-\"\"\"\n-\n-\"\"\"\n-We typically define a model in PyTorch using\n-[`torch.nn.Module`s](https://pytorch.org/docs/stable/notes/modules.html) which act as the\n-building blocks of stateful computation. Let us define the ResNet18 model from the\n-TorchVision package as a `torch.nn.Module` pre-trained on the [Imagenet1K\n-dataset](https://huggingface.co/datasets/imagenet-1k).\n-\"\"\"\n-\n-# Define the pre-trained resnet18 module from TorchVision\n-resnet_18 = models.resnet18(weights=\"IMAGENET1K_V1\")\n-\n-# We set the classification head of the pre-trained ResNet18\n-# module to an identity module\n-resnet_18.fc = nn.Identity()\n-\n-\"\"\"\n-Even though Keras supports PyTorch as a backend, it does not mean that we can nest torch\n-modules inside a [`keras_core.Model`](https://keras.io/keras_core/api/models/), because\n-trainable variables inside a Keras Model is tracked exclusively via [Keras\n-Layers](https://keras.io/keras_core/api/layers/).\n-\n-KerasCore provides us with a feature called `TorchModuleWrapper` which enables us to do\n-exactly this. The `TorchModuleWrapper` is a Keras Layer that accepts a torch module and\n-tracks its trainable variables, essentially converting the torch module into a Keras\n-Layer. This enables us to put any torch modules inside a Keras Model and train them with\n-a single `model.fit()`!\n-\"\"\"\n-\n-# We set the trainable ResNet18 backbone to be a Keras Layer\n-# using `TorchModuleWrapper`\n-backbone = TorchModuleWrapper(resnet_18)\n-\n-# We set this to `False` if you want to freeze the backbone\n-backbone.trainable = True\n-\n-\"\"\"\n-Now, we will build a Keras functional model with the backbone layer.\n-\"\"\"\n-\n-inputs = keras.Input(shape=(3, image_size, image_size))\n-x = backbone(inputs)\n-x = keras.layers.Dropout(0.5)(x)\n-x = keras.layers.Dense(len(class_names))(x)\n-outputs = keras.activations.softmax(x, axis=1)\n-model = keras.Model(inputs, outputs, name=\"ResNet18_Classifier\")\n-\n-model.summary()\n-\n-# Create exponential decay learning rate scheduler\n-decay_steps = num_epochs * len(dataloaders[\"train\"]) // batch_size\n-lr_scheduler = keras.optimizers.schedules.ExponentialDecay(\n-    initial_learning_rate=initial_learning_rate,\n-    decay_steps=decay_steps,\n-    decay_rate=0.1,\n-)\n-\n-# Compile the model\n-model.compile(\n-    loss=\"sparse_categorical_crossentropy\",\n-    optimizer=keras.optimizers.Adam(lr_scheduler),\n-    metrics=[\"accuracy\"],\n-)\n-\n-# Define the backend-agnostic WandB callbacks for KerasCore\n-callbacks = [\n-    # Save best model checkpoints\n-    keras.callbacks.ModelCheckpoint(\n-        filepath=\"model.weights.h5\",\n-        monitor=\"val_loss\",\n-        save_best_only=True,\n-        save_weights_only=True,\n-    )\n-]\n-\n-# Train the model by calling model.fit\n-history = model.fit(\n-    dataloaders[\"train\"],\n-    validation_data=dataloaders[\"val\"],\n-    epochs=num_epochs,\n-    callbacks=callbacks,\n-)\n-\n-\n-def plot_history(item):\n-    plt.plot(history.history[item], label=item)\n-    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n-    plt.xlabel(\"Epochs\")\n-    plt.ylabel(item)\n-    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n-    plt.legend()\n-    plt.grid()\n-    plt.show()\n-\n-\n-plot_history(\"loss\")\n-plot_history(\"accuracy\")\n-\n-\"\"\"\n-## Evaluation and Inference\n-\n-Now, we let us load the best model weights checkpoint and evaluate the model.\n-\"\"\"\n-\n-model.load_weights(\"model.weights.h5\")\n-_, val_accuracy = model.evaluate(dataloaders[\"val\"])\n-print(\"Best Validation Accuracy:\", val_accuracy)\n-\n-\"\"\"\n-Finally, let us visualize the some predictions of the model\n-\"\"\"\n-\n-plt.figure(figsize=(10, 10))\n-sample_images, sample_labels = next(iter(dataloaders[\"train\"]))\n-\n-# We perform inference and detach the predicted probabilities from the Torch\n-# computation graph with a tensor that does not require gradient computation.\n-sample_pred_probas = model(sample_images.to(\"cuda\")).detach()\n-sample_pred_logits = keras.ops.argmax(sample_pred_probas, axis=1)\n-sample_pred_logits = sample_pred_logits.to(\"cpu\").numpy()\n-\n-sample_images = sample_images.numpy()\n-sample_labels = sample_labels.numpy()\n-\n-for idx in range(9):\n-    ax = plt.subplot(3, 3, idx + 1)\n-    image = sample_images[idx].transpose((1, 2, 0))\n-    mean = np.array([0.485, 0.456, 0.406])\n-    std = np.array([0.229, 0.224, 0.225])\n-    image = std * image + mean\n-    image = np.clip(image, 0, 1)\n-    plt.imshow(image)\n-    title = \"Ground Truth Label: \" + class_names[int(sample_labels[idx])]\n-    title += \"\\nPredicted Label: \" + class_names[int(sample_pred_logits[idx])]\n-    plt.title(title)\n-    plt.axis(\"off\")\n\n@@ -255,3 +255,47 @@ def compute_conv_transpose_output_shape(\n     else:\n         output_shape = [input_shape[0], filters] + output_shape\n     return output_shape\n+\n+\n+def encode_categorical_inputs(\n+    inputs,\n+    output_mode,\n+    depth,\n+    dtype=\"float32\",\n+    sparse=False,\n+    count_weights=None,\n+):\n+    from keras_core import ops\n+    \"\"\"Encodes categoical inputs according to output_mode.\"\"\"\n+    if output_mode == \"int\":\n+        return ops.identity(ops.cast(inputs, dtype))\n+\n+    original_shape = inputs.shape\n+    # In all cases, we should uprank scalar input to a single sample.\n+    if len(ops.shape(inputs)) == 0:\n+        inputs = ops.expand_dims(inputs, -1)\n+    # One hot will unprank only if the final output dimension is not already 1.\n+    if output_mode == \"one_hot\":\n+        if ops.shape(inputs)[-1] != 1:\n+            inputs = ops.expand_dims(inputs, -1)\n+\n+    if len(ops.shape(inputs)) > 2:\n+        raise ValueError(\n+            \"When output_mode is not `'int'`, maximum supported output rank \"\n+            f\"is 2. Received output_mode {output_mode} and input shape \"\n+            f\"{original_shape}, \"\n+            f\"which would result in output rank {inputs.shape.rank}.\"\n+        )\n+\n+    binary_output = output_mode in (\"multi_hot\", \"one_hot\")\n+    bincounts = ops.bincount(\n+        inputs,\n+        weights=count_weights,\n+        minlength=depth,\n+    )\n+    if binary_output:\n+        one_hot_input = ops.one_hot(inputs, depth)\n+        bincounts = ops.where(ops.any(one_hot_input, axis=-2), 1, 0)\n+    bincounts = ops.cast(bincounts, dtype)\n+\n+    return bincounts\n\n@@ -330,7 +330,7 @@ def hstack(xs):\n \n \n def identity(n, dtype=\"float32\"):\n-    return tfnp.identity(n, dtype=dtype)\n+    return tf.identity(n)\n \n \n def imag(x):\n\n@@ -1,30 +1,23 @@\n import numpy as np\n \n from keras_core import backend\n+from keras_core import ops\n from keras_core.api_export import keras_core_export\n-from keras_core.layers.layer import Layer\n+from keras_core.backend.common.backend_utils import encode_categorical_inputs\n+from keras_core.layers.preprocessing.tf_data_layer import TFDataLayer\n from keras_core.utils import argument_validation\n from keras_core.utils import backend_utils\n-from keras_core.utils import tf_utils\n from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.Discretization\")\n-class Discretization(Layer):\n+class Discretization(TFDataLayer):\n     \"\"\"A preprocessing layer which buckets continuous features by ranges.\n \n     This layer will place each element of its input data into one of several\n     contiguous ranges and output an integer index indicating which range each\n     element was placed in.\n \n-    **Note:** This layer uses TensorFlow internally. It cannot\n-    be used as part of the compiled computation graph of a model with\n-    any backend other than TensorFlow.\n-    It can however be used with any backend when running eagerly.\n-    It can also always be used as part of an input preprocessing pipeline\n-    with any backend (outside the model itself), which is how we recommend\n-    to use this layer.\n-\n     **Note:** This layer is safe to use inside a `tf.data` pipeline\n     (independently of which backend you're using).\n \n@@ -78,14 +71,14 @@ class Discretization(Layer):\n \n     Examples:\n \n-    Bucketize float values based on provided buckets.\n+    Discretize float values based on provided buckets.\n     >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n     >>> layer = Discretization(bin_boundaries=[0., 1., 2.])\n     >>> layer(input)\n     array([[0, 2, 3, 1],\n            [1, 3, 2, 1]])\n \n-    Bucketize float values based on a number of buckets to compute.\n+    Discretize float values based on a number of buckets to compute.\n     >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n     >>> layer = Discretization(num_bins=4, epsilon=0.01)\n     >>> layer.adapt(input)\n@@ -241,26 +234,18 @@ class Discretization(Layer):\n         if not isinstance(\n             inputs,\n             (\n-                tf.Tensor,\n-                tf.SparseTensor,\n-                tf.RaggedTensor,\n                 np.ndarray,\n                 backend.KerasTensor,\n             ),\n         ):\n-            inputs = tf.convert_to_tensor(\n-                backend.convert_to_numpy(inputs), dtype=self.input_dtype\n-            )\n+            self._convert_input_args = True\n \n-        from keras_core.backend.tensorflow.numpy import digitize\n+        indices = ops.digitize(inputs, self.bin_boundaries)\n \n-        indices = digitize(inputs, self.bin_boundaries)\n-\n-        outputs = tf_utils.encode_categorical_inputs(\n+        outputs = encode_categorical_inputs(\n             indices,\n             output_mode=self.output_mode,\n             depth=len(self.bin_boundaries) + 1,\n-            sparse=self.sparse,\n             dtype=self.compute_dtype,\n         )\n         if (\n@@ -370,7 +355,3 @@ def compress_summary(summary, epsilon):\n     )\n     summary = np.stack((new_bins, new_weights))\n     return summary.astype(\"float32\")\n-\n-\n-def bucketize(inputs, boundaries):\n-    return tf.raw_ops.Bucketize(input=inputs, boundaries=boundaries)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
