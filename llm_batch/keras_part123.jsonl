{"custom_id": "keras#058e54061bdedbe9cc56a5a3ec18797ae1e612c0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 19 | Churn Cumulative: 586 | Contributors (this commit): 15 | Commits (past 90d): 9 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -34,30 +34,30 @@ def top_k_categorical_accuracy(y_true, y_pred, k=5):\n \n \n def mean_squared_error(y_true, y_pred):\n-    '''Calculates the mean squared error (mse) rate between predicted and target\n-    values\n+    '''Calculates the mean squared error (mse) rate\n+    between predicted and target values\n     '''\n     return K.mean(K.square(y_pred - y_true))\n \n \n def mean_absolute_error(y_true, y_pred):\n-    '''Calculates the mean absolute error (mae) rate between predicted and target\n-    values\n+    '''Calculates the mean absolute error (mae) rate\n+    between predicted and target values\n     '''\n     return K.mean(K.abs(y_pred - y_true))\n \n \n def mean_absolute_percentage_error(y_true, y_pred):\n-    '''Calculates the mean absolute percentage error (mape) rate between predicted\n-    and target values\n+    '''Calculates the mean absolute percentage error (mape) rate\n+    between predicted and target values\n     '''\n     diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true), K.epsilon(), np.inf))\n     return 100. * K.mean(diff)\n \n \n def mean_squared_logarithmic_error(y_true, y_pred):\n-    '''Calculates the mean squared logarithmic error (msle) rate between predicted\n-    and target values\n+    '''Calculates the mean squared logarithmic error (msle) rate\n+    between predicted and target values\n     '''\n     first_log = K.log(K.clip(y_pred, K.epsilon(), np.inf) + 1.)\n     second_log = K.log(K.clip(y_true, K.epsilon(), np.inf) + 1.)\n\n@@ -1,6 +1,7 @@\n from __future__ import absolute_import\n import numpy as np\n from . import backend as K\n+from .utils.generic_utils import get_from_module\n \n \n def mean_squared_error(y_true, y_pred):\n@@ -72,6 +73,6 @@ msle = MSLE = mean_squared_logarithmic_error\n kld = KLD = kullback_leibler_divergence\n cosine = cosine_proximity\n \n-from .utils.generic_utils import get_from_module\n+\n def get(identifier):\n     return get_from_module(identifier, globals(), 'objective')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#61c21ef9eef30cd18a1f6f2a0253cb05eb46fca0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 70 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -44,7 +44,7 @@ def decode_predictions(preds, top=5):\n         CLASS_INDEX = json.load(open(fpath))\n     results = []\n     for pred in preds:\n-        top_indices = np.argpartition(pred, -top)[-top:][::-1]\n+        top_indices = pred.argsort()[-top:][::-1]\n         result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n         results.append(result)\n     return results\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#531147c8774af745d823d13227da4c2a3fa51118", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 162 | Lines Deleted: 154 | Files Changed: 5 | Hunks: 17 | Methods Changed: 2 | Complexity Δ (Sum/Max): 68/55 | Churn Δ: 316 | Churn Cumulative: 475 | Contributors (this commit): 3 | Commits (past 90d): 8 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,143 @@\n+\"\"\" This script demonstrate the use of convolutional LSTM network\n+This network is used to predict the next frame of an artificialy\n+generated movie which contain moving squares.\n+\"\"\"\n+from keras.models import Sequential\n+from keras.layers.convolutional import Convolution3D\n+from keras.layers.convolutional_recurrent import ConvLSTM2D\n+from keras.layers.normalization import BatchNormalization\n+import numpy as np\n+import pylab as plt\n+\n+# We create a layer which take as input movies of shape\n+# (n_frames, width, height, channel) and that returns a movie\n+# of identical shape.\n+\n+seq = Sequential()\n+seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,\n+                   input_shape=(None, 40, 40, 1),\n+                   border_mode='same', return_sequences=True))\n+seq.add(BatchNormalization())\n+\n+seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,\n+                   border_mode='same', return_sequences=True))\n+seq.add(BatchNormalization())\n+\n+seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,\n+                   border_mode='same', return_sequences=True))\n+seq.add(BatchNormalization())\n+\n+seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,\n+                   border_mode='same', return_sequences=True))\n+seq.add(BatchNormalization())\n+\n+seq.add(Convolution3D(nb_filter=1, kernel_dim1=1, kernel_dim2=3,\n+                      kernel_dim3=3, activation='sigmoid',\n+                      border_mode='same', dim_ordering='tf'))\n+\n+seq.compile(loss='binary_crossentropy', optimizer='adadelta')\n+\n+\n+# Generating artificial data:\n+# Generate movies with 3 to 7 moving squares inside.\n+# The squares are of shape one by one or two by two pixels and\n+# they move linearly trought time.\n+# For convenience we first create movies with bigger width and height, (80x80)\n+# and at the end we select a 40x40 window\n+\n+def generate_movies(n_samples=1200, n_frames=15):\n+    row = 80\n+    col = 80\n+    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n+    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),\n+                              dtype=np.float)\n+\n+    for i in range(n_samples):\n+\n+        # add from 3 to 7 moving squares\n+        n = np.random.randint(3, 8)\n+\n+        for j in range(n):\n+            # Initial position\n+            xstart = np.random.randint(20, 60)\n+            ystart = np.random.randint(20, 60)\n+            # Direction of motion\n+            directionx = np.random.randint(0, 3) - 1\n+            directiony = np.random.randint(0, 3) - 1\n+\n+            # Size of the square\n+            w = np.random.randint(2, 4)\n+\n+            for t in range(n_frames):\n+                x_shift = xstart + directionx * t\n+                y_shift = ystart + directiony * t\n+                noisy_movies[i, t, x_shift - w: x_shift + w,\n+                             y_shift - w: y_shift + w, 0] += 1\n+\n+                # Make it more robust by adding noise.\n+                # The idea is that if during predict time,\n+                # the value of the pixel is not exactly one,\n+                # we need to train the network to be robust and stille\n+                # consider it is a pixel belonging to a square.\n+                if np.random.randint(0, 2):\n+                    noise_f = (-1)**np.random.randint(0, 2)\n+                    noisy_movies[i, t,\n+                                 x_shift - w - 1: x_shift + w + 1,\n+                                 y_shift - w - 1: y_shift + w + 1,\n+                                 0] += noise_f * 0.1\n+\n+                # Shitf the ground truth by 1\n+                x_shift = xstart + directionx * (t + 1)\n+                y_shift = ystart + directiony * (t + 1)\n+                shifted_movies[i, t, x_shift - w: x_shift + w,\n+                               y_shift - w: y_shift + w, 0] += 1\n+\n+    # Cut to a forty's sized window\n+    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n+    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n+    noisy_movies[noisy_movies >= 1] = 1\n+    shifted_movies[shifted_movies >= 1] = 1\n+    return noisy_movies, shifted_movies\n+\n+# Train the network\n+noisy_movies, shifted_movies = generate_movies(n_samples=1200)\n+seq.fit(noisy_movies[:1000], shifted_movies[:1000], batch_size=10,\n+        nb_epoch=300, validation_split=0.05)\n+\n+# Testing the network on one movie\n+# feed it with the first 7 positions and then\n+# predict the new positions\n+which = 1004\n+track = noisy_movies[which][:7, ::, ::, ::]\n+\n+for j in range(16):\n+    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n+    new = new_pos[::, -1, ::, ::, ::]\n+    track = np.concatenate((track, new), axis=0)\n+\n+\n+# And then compare the predictions\n+# to the ground truth\n+track2 = noisy_movies[which][::, ::, ::, ::]\n+for i in range(15):\n+    fig = plt.figure(figsize=(10, 5))\n+\n+    ax = fig.add_subplot(121)\n+\n+    if i >= 7:\n+        ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n+    else:\n+        ax.text(1, 3, 'Inital trajectory', fontsize=20)\n+\n+    toplot = track[i, ::, ::, 0]\n+\n+    plt.imshow(toplot)\n+    ax = fig.add_subplot(122)\n+    plt.text(1, 3, 'Ground truth', fontsize=20)\n+\n+    toplot = track2[i, ::, ::, 0]\n+    if i >= 2:\n+        toplot = shifted_movies[which][i - 1, ::, ::, 0]\n+\n+    plt.imshow(toplot)\n+    plt.savefig('%i_animate.png' % (i + 1))\n\n@@ -1,136 +0,0 @@\n-from keras.models import Sequential\n-from keras.layers.convolutional import Convolution3D\n-from keras.layers.recurrent_convolutional import ConvLSTM2D\n-from keras.layers.normalization import BatchNormalization\n-import numpy as np\n-from pylab import *\n-\n-# We create a layer whose take movies as input\n-# of shape (time, width, height, channel) and that return a movie\n-# with identical shape.\n-\n-seq = Sequential()\n-seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,\n-                   input_shape=(None, 40, 40, 1),\n-                   border_mode=\"same\", return_sequences=True))\n-seq.add(BatchNormalization())\n-\n-seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,\n-                   border_mode=\"same\", return_sequences=True))\n-seq.add(BatchNormalization())\n-\n-seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,\n-                   border_mode=\"same\", return_sequences=True))\n-seq.add(BatchNormalization())\n-\n-seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,\n-                   border_mode=\"same\", return_sequences=True))\n-seq.add(BatchNormalization())\n-\n-seq.add(Convolution3D(nb_filter=1, kernel_dim1=1, kernel_dim2=3,\n-                      kernel_dim3=3, activation='sigmoid',\n-                      border_mode=\"same\", dim_ordering=\"tf\"))\n-\n-seq.compile(loss=\"binary_crossentropy\", optimizer=\"adadelta\")\n-\n-\n-# Generating artificial data:\n-# We are going to create a movie with\n-# square of size one or two by two pixels moving linearly\n-# trought time. For convenience we first create\n-# a movie with bigger width and height, and at the end\n-# we cut it to 40x40\n-\n-time = 15\n-row = 80\n-col = 80\n-filters = 1\n-training = 1200\n-train = np.zeros((training, time, row, col, 1), dtype=np.float)\n-gt = np.zeros((training, time, row, col, 1), dtype=np.float)\n-\n-for i in range(training):\n-\n-    # add from 3 to 7 moving squares\n-    n = np.random.randint(3, 8)\n-\n-    for j in range(n):\n-        # Initial position\n-        xstart = np.random.randint(20, 60)\n-        ystart = np.random.randint(20, 60)\n-        # Direction of motion\n-        directionx = np.random.randint(0, 3) - 1\n-        directiony = np.random.randint(0, 3) - 1\n-\n-        # Size of the square\n-        w = np.random.randint(2, 4)\n-\n-        for t in range(time):\n-            x_shift = xstart + directionx * t\n-            y_shift = ystart + directiony * t\n-            train[i, t, x_shift - w: x_shift + w,\n-                  y_shift - w: y_shift + w, 0] += 1\n-\n-            # Make it more robust by adding noise.\n-            # The idea is that if during predict time,\n-            # the value of the pixel is not exactly one,\n-            # we need to train the network to be robust and stille\n-            # consider it is a pixel belonging to a square.\n-            if np.random.randint(0, 2):\n-                noise_f = (-1)**np.random.randint(0, 2)\n-                train[i, t, x_shift - w - 1: x_shift + w + 1,\n-                      y_shift - w - 1: y_shift + w + 1, 0] += noise_f * 0.1\n-\n-            # Shitf the ground truth by 1\n-            x_shift = xstart + directionx * (t + 1)\n-            y_shift = ystart + directiony * (t + 1)\n-            gt[i, t, x_shift - w: x_shift + w,\n-               y_shift - w: y_shift + w, 0] += 1\n-\n-# Cut to a forty's sized window\n-train = train[::, ::, 20:60, 20:60, ::]\n-gt = gt[::, ::, 20:60, 20:60, ::]\n-train[train >= 1] = 1\n-gt[gt >= 1] = 1\n-\n-# Train the network\n-seq.fit(train[:1000], gt[:1000], batch_size=10,\n-        nb_epoch=300, validation_split=0.05)\n-\n-# Testing the network on one movie\n-# feed it with the first 7 positions and then\n-# predict the new positions\n-which = 1004\n-track = train[which][:7, ::, ::, ::]\n-\n-for j in range(16):\n-    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n-    new = new_pos[::, -1, ::, ::, ::]\n-    track = np.concatenate((track, new), axis=0)\n-\n-\n-# And then compare the predictions\n-# to the ground truth\n-track2 = train[which][::, ::, ::, ::]\n-for i in range(15):\n-    fig = figure(figsize=(10, 5))\n-\n-    ax = fig.add_subplot(121)\n-\n-    if i >= 7:\n-        ax.text(1, 3, \"Predictions !\", fontsize=20, color=\"w\")\n-    else:\n-        ax.text(1, 3, \"Inital trajectory\", fontsize=20)\n-\n-    toplot = track[i, ::, ::, 0]\n-\n-    imshow(toplot)\n-    ax = fig.add_subplot(122)\n-    text(1, 3, \"Ground truth\", fontsize=20)\n-\n-    toplot = track2[i, ::, ::, 0]\n-    if i >= 2:\n-        toplot = gt[which][i - 1, ::, ::, 0]\n-\n-    imshow(toplot)\n-    savefig(\"%i_animate.png\" % (i + 1))\n\n@@ -10,4 +10,4 @@ from .embeddings import *\n from .noise import *\n from .advanced_activations import *\n from .wrappers import *\n-from .recurrent_convolutional import *\n+from .convolutional_recurrent import *\n\n@@ -8,10 +8,10 @@ import warnings\n \n \n class ConvRecurrent2D(Layer):\n-    '''Abstract base class for recurrent layers.\n+    '''Abstract base class for convolutionnal recurrent layers.\n     Do not use in a model -- it's not a functional layer!\n \n-    All recurrent layers (GRU, LSTM, SimpleRNN) also\n+    ConvLSTM2D\n     follow the specifications of this class and accept\n     the keyword arguments listed below.\n \n@@ -21,7 +21,7 @@ class ConvRecurrent2D(Layer):\n     # Output shape\n         - if `return_sequences`: 5D tensor with shape\n             `(nb_samples, timesteps, channels, rows, cols)`.\n-        - else, 2D tensor with shape `(nb_samples, channels,rows,cols)`.\n+        - else, 4D tensor with shape `(nb_samples, channels, rows, cols)`.\n \n     # Arguments\n         weights: list of numpy arrays to set as initial weights.\n@@ -200,7 +200,8 @@ class ConvRecurrent2D(Layer):\n \n \n class ConvLSTM2D(ConvRecurrent2D):\n-    '''\n+    '''Convolutional LSTM.\n+\n     # Input shape\n         - if dim_ordering='th'\n             5D tensor with shape:\n@@ -213,17 +214,17 @@ class ConvLSTM2D(ConvRecurrent2D):\n         - if `return_sequences`\n              - if dim_ordering='th'\n                 5D tensor with shape:\n-                `(samples, time, nb_filter, o_row, o_col)`\n+                `(samples, time, nb_filter, output_row, output_col)`\n              - if dim_ordering='tf'\n                 5D tensor with shape:\n-                `(samples, time, o_row, o_col, nb_filter)`\n+                `(samples, time, output_row, output_col, nb_filter)`\n         - else\n             - if dim_ordering ='th'\n                 4D tensor with shape:\n-                `(samples, nb_filter, o_row, o_col)`\n+                `(samples, nb_filter, output_row, output_col)`\n             - if dim_ordering='tf'\n                 4D tensor with shape:\n-                `(samples, o_row, o_col, nb_filter)`\n+                `(samples, output_row, output_col, nb_filter)`\n \n         where o_row and o_col depend on the shape of the filter and\n         the border_mode\n\n@@ -4,7 +4,7 @@ from numpy.testing import assert_allclose\n \n from keras import backend as K\n from keras.models import Sequential\n-from keras.layers import recurrent_convolutional\n+from keras.layers import convolutional_recurrent\n from keras.utils.test_utils import layer_test\n from keras import regularizers\n \n@@ -15,10 +15,10 @@ def test_recurrent_convolutional():\n     nb_col = 4\n     nb_filter = 20\n     nb_samples = 5\n-    input_channel = 3\n-    input_nb_row = 30\n-    input_nb_col = 30\n-    sequence_len = 10\n+    input_channel = 2\n+    input_nb_row = 10\n+    input_nb_col = 10\n+    sequence_len = 2\n     for dim_ordering in ['th', 'tf']:\n \n         if dim_ordering == 'th':\n@@ -32,7 +32,7 @@ def test_recurrent_convolutional():\n \n         for return_sequences in [True, False]:\n             # test for ouptput shape:\n-            output = layer_test(recurrent_convolutional.ConvLSTM2D,\n+            output = layer_test(convolutional_recurrent.ConvLSTM2D,\n                                 kwargs={'dim_ordering': dim_ordering,\n                                         'return_sequences': return_sequences,\n                                         'nb_filter': nb_filter,\n@@ -67,7 +67,7 @@ def test_recurrent_convolutional():\n                       'stateful': True,\n                       'batch_input_shape': input.shape,\n                       'border_mode': \"same\"}\n-            layer = recurrent_convolutional.ConvLSTM2D(**kwargs)\n+            layer = convolutional_recurrent.ConvLSTM2D(**kwargs)\n \n             model.add(layer)\n             model.compile(optimizer='sgd', loss='mse')\n@@ -110,13 +110,13 @@ def test_recurrent_convolutional():\n                       'b_regularizer': 'l2',\n                       'border_mode': \"same\"}\n \n-            layer = recurrent_convolutional.ConvLSTM2D(**kwargs)\n+            layer = convolutional_recurrent.ConvLSTM2D(**kwargs)\n             layer.set_input(K.variable(np.ones(input.shape)),\n                             shape=input.shape)\n             K.eval(layer.output)\n \n             # check dropout\n-            layer_test(recurrent_convolutional.ConvLSTM2D,\n+            layer_test(convolutional_recurrent.ConvLSTM2D,\n                        kwargs={'dim_ordering': dim_ordering,\n                                'return_sequences': return_sequences,\n                                'nb_filter': nb_filter,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4840e435f755078ad2cf72a49f97effbbf6487be", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 22 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 24 | Churn Cumulative: 4391 | Contributors (this commit): 28 | Commits (past 90d): 5 | Contributors (cumulative): 28 | DMM Complexity: 0.0\n\nDIFF:\n@@ -199,6 +199,18 @@ class Recurrent(Layer):\n         # note that the .build() method of subclasses MUST define\n         # self.input_spec with a complete input shape.\n         input_shape = self.input_spec[0].shape\n+        if self.unroll and input_shape[1] is None:\n+            raise ValueError('Cannot unroll a RNN if the '\n+                             'time dimension is undefined. \\n'\n+                             '- If using a Sequential model, '\n+                             'specify the time dimension by passing '\n+                             'an `input_shape` or `batch_input_shape` '\n+                             'argument to your first layer. If your '\n+                             'first layer is an Embedding, you can '\n+                             'also use the `input_length` argument.\\n'\n+                             '- If using the functional API, specify '\n+                             'the time dimension by passing a `shape` '\n+                             'or `batch_shape` argument to your Input layer.')\n         if self.stateful:\n             initial_states = self.states\n         else:\n@@ -318,8 +330,16 @@ class SimpleRNN(Recurrent):\n         assert self.stateful, 'Layer must be stateful.'\n         input_shape = self.input_spec[0].shape\n         if not input_shape[0]:\n-            raise Exception('If a RNN is stateful, a complete ' +\n-                            'input_shape must be provided (including batch size).')\n+            raise Exception('If a RNN is stateful, it needs to know '\n+                            'its batch size. Specify the batch size '\n+                            'of your input tensors: \\n'\n+                            '- If using a Sequential model, '\n+                            'specify the batch size by passing '\n+                            'a `batch_input_shape` '\n+                            'argument to your first layer.\\n'\n+                            '- If using the functional API, specify '\n+                            'the time dimension by passing a '\n+                            '`batch_shape` argument to your Input layer.')\n         if hasattr(self, 'states'):\n             K.set_value(self.states[0],\n                         np.zeros((input_shape[0], self.output_dim)))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a9b6bef0624c67d6df1618ca63d8e8141b0df4d0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 76 | Lines Deleted: 117 | Files Changed: 3 | Hunks: 18 | Methods Changed: 7 | Complexity Δ (Sum/Max): -15/0 | Churn Δ: 193 | Churn Cumulative: 4261 | Contributors (this commit): 43 | Commits (past 90d): 43 | Contributors (cumulative): 50 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,6 +1,8 @@\n import tensorflow as tf\n \n from tensorflow.python.training import moving_averages\n+from tensorflow.python.ops import tensor_array_ops\n+from tensorflow.python.ops import control_flow_ops\n try:\n     from tensorflow.python.ops import ctc_ops as ctc\n except ImportError:\n@@ -1168,6 +1170,13 @@ def rnn(step_function, inputs, initial_states,\n     axes = [1, 0] + list(range(2, ndim))\n     inputs = tf.transpose(inputs, (axes))\n \n+    if mask is not None:\n+        if mask.dtype != tf.bool:\n+            mask = tf.cast(mask, tf.bool)\n+        if len(mask.get_shape()) == ndim - 1:\n+            mask = expand_dims(mask)\n+        mask = tf.transpose(mask, axes)\n+\n     if constants is None:\n         constants = []\n \n@@ -1184,13 +1193,7 @@ def rnn(step_function, inputs, initial_states,\n             input_list.reverse()\n \n         if mask is not None:\n-            # Transpose not supported by bool tensor types, hence round-trip to uint8.\n-            mask = tf.cast(mask, tf.uint8)\n-            if len(mask.get_shape()) == ndim - 1:\n-                mask = expand_dims(mask)\n-            mask = tf.cast(tf.transpose(mask, axes), tf.bool)\n             mask_list = tf.unpack(mask)\n-\n             if go_backwards:\n                 mask_list.reverse()\n \n@@ -1234,26 +1237,25 @@ def rnn(step_function, inputs, initial_states,\n             outputs = tf.pack(successive_outputs)\n \n     else:\n-        from tensorflow.python.ops.rnn import _dynamic_rnn_loop\n-\n         if go_backwards:\n             inputs = tf.reverse(inputs, [True] + [False] * (ndim - 1))\n \n-        states = initial_states\n-        nb_states = len(states)\n-        if nb_states == 0:\n-            # use dummy state, otherwise _dynamic_rnn_loop breaks\n-            state = inputs[:, 0, :]\n-            state_size = state.get_shape()[-1]\n-        else:\n-            state_size = int(states[0].get_shape()[-1])\n-            if nb_states == 1:\n-                state = states[0]\n-            else:\n-                state = tf.concat(1, states)\n+        states = tuple(initial_states)\n+\n+        time_steps = tf.shape(inputs)[0]\n+        output_ta = tensor_array_ops.TensorArray(\n+            dtype=inputs.dtype,\n+            size=time_steps,\n+            tensor_array_name='output_ta')\n+        input_ta = tensor_array_ops.TensorArray(\n+            dtype=inputs.dtype,\n+            size=time_steps,\n+            tensor_array_name='input_ta')\n+        input_ta = input_ta.unpack(inputs)\n+        time = tf.constant(0, dtype='int32', name='time')\n \n         if mask is not None:\n-            if len(initial_states) == 0:\n+            if len(states) == 0:\n                 raise ValueError('No initial states provided! '\n                                  'When using masking in an RNN, you should '\n                                  'provide initial states '\n@@ -1263,84 +1265,44 @@ def rnn(step_function, inputs, initial_states,\n             if go_backwards:\n                 mask = tf.reverse(mask, [True] + [False] * (ndim - 2))\n \n-            # Transpose not supported by bool tensor types, hence round-trip to uint8.\n-            mask = tf.cast(mask, tf.uint8)\n-            if len(mask.get_shape()) == ndim - 1:\n-                mask = expand_dims(mask)\n-            mask = tf.transpose(mask, axes)\n-            inputs = tf.concat(2, [tf.cast(mask, inputs.dtype), inputs])\n+            mask_ta = tensor_array_ops.TensorArray(\n+                dtype=tf.bool,\n+                size=time_steps,\n+                tensor_array_name='mask_ta')\n+            mask_ta = mask_ta.unpack(mask)\n \n-            def _step(input, state):\n-                if nb_states > 1:\n-                    states = []\n-                    for i in range(nb_states):\n-                        states.append(state[:, i * state_size: (i + 1) * state_size])\n+            def _step(time, output_ta_t, *states):\n+                current_input = input_ta.read(time)\n+                mask_t = mask_ta.read(time)\n+                output, new_states = step_function(current_input,\n+                                                   tuple(states) +\n+                                                   tuple(constants))\n+                tiled_mask_t = tf.tile(mask_t, tf.pack([1, tf.shape(output)[1]]))\n+                output = tf.select(tiled_mask_t, output, states[0])\n+                new_states = [tf.select(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\n+                output_ta_t = output_ta_t.write(time, output)\n+                return (time + 1, output_ta_t) + tuple(new_states)\n         else:\n-                    states = [state]\n-                mask_t = tf.cast(input[:, 0], tf.bool)\n-                input = input[:, 1:]\n-                output, new_states = step_function(input, states + constants)\n+            def _step(time, output_ta_t, *states):\n+                current_input = input_ta.read(time)\n+                output, new_states = step_function(current_input,\n+                                                   tuple(states) +\n+                                                   tuple(constants))\n+                output_ta_t = output_ta_t.write(time, output)\n+                return (time + 1, output_ta_t) + tuple(new_states)\n \n-                output = tf.select(mask_t, output, states[0])\n-                new_states = [tf.select(mask_t, new_states[i], states[i]) for i in range(len(states))]\n-\n-                if len(new_states) == 1:\n-                    new_state = new_states[0]\n-                else:\n-                    new_state = tf.concat(1, new_states)\n-\n-                return output, new_state\n-        else:\n-            def _step(input, state):\n-                if nb_states > 1:\n-                    states = []\n-                    for i in range(nb_states):\n-                        states.append(state[:, i * state_size: (i + 1) * state_size])\n-                elif nb_states == 1:\n-                    states = [state]\n-                else:\n-                    states = []\n-                output, new_states = step_function(input, states + constants)\n-\n-                if len(new_states) > 1:\n-                    new_state = tf.concat(1, new_states)\n-                elif len(new_states) == 1:\n-                    new_state = new_states[0]\n-                else:\n-                    # return dummy state, otherwise _dynamic_rnn_loop breaks\n-                    new_state = state\n-                return output, new_state\n-\n-        _step.state_size = state_size * nb_states\n-        # recover output size by calling _step on the first input\n-        slice_begin = tf.pack([0] * ndim)\n-        slice_size = tf.pack([1] + [-1] * (ndim - 1))\n-        first_input = tf.slice(inputs, slice_begin, slice_size)\n-        first_input = tf.squeeze(first_input, [0])\n-        _step.output_size = int(_step(first_input, state)[0].get_shape()[-1])\n-\n-        (outputs, final_state) = _dynamic_rnn_loop(\n-            _step,\n-            inputs,\n-            state,\n+        final_outputs = control_flow_ops.while_loop(\n+            cond=lambda time, *_: time < time_steps,\n+            body=_step,\n+            loop_vars=(time, output_ta) + states,\n             parallel_iterations=32,\n-            swap_memory=True,\n-            sequence_length=None)\n+            swap_memory=True)\n+        last_time = final_outputs[0]\n+        output_ta = final_outputs[1]\n+        new_states = final_outputs[2:]\n \n-        if nb_states > 1:\n-            new_states = []\n-            for i in range(nb_states):\n-                new_states.append(final_state[:, i * state_size: (i + 1) * state_size])\n-        elif nb_states == 1:\n-            new_states = [final_state]\n-        else:\n-            new_states = []\n-\n-        # all this circus is to recover the last vector in the sequence.\n-        slice_begin = tf.pack([tf.shape(outputs)[0] - 1] + [0] * (ndim - 1))\n-        slice_size = tf.pack([1] + [-1] * (ndim - 1))\n-        last_output = tf.slice(outputs, slice_begin, slice_size)\n-        last_output = tf.squeeze(last_output, [0])\n+        outputs = output_ta.pack()\n+        last_output = output_ta.read(last_time - 1)\n \n     axes = [1, 0] + list(range(2, len(outputs.get_shape())))\n     outputs = tf.transpose(outputs, axes)\n@@ -1348,7 +1310,8 @@ def rnn(step_function, inputs, initial_states,\n \n \n def _cond(condition, then_lambda, else_lambda):\n-    '''Backwards compatible interface to tf.cond prior to public introduction.'''\n+    '''Backwards compatible interface to tf.cond prior to public introduction.\n+    '''\n     try:\n         cond_fn = tf.cond\n     except AttributeError:\n@@ -1358,7 +1321,8 @@ def _cond(condition, then_lambda, else_lambda):\n \n \n def switch(condition, then_expression, else_expression):\n-    '''Switches between two operations depending on a scalar value (int or bool).\n+    '''Switches between two operations\n+    depending on a scalar value (int or bool).\n     Note that both `then_expression` and `else_expression`\n     should be symbolic tensors of the *same shape*.\n \n\n@@ -112,23 +112,11 @@ class TimeDistributed(Wrapper):\n             def step(x, states):\n                 output = self.layer.call(x)\n                 return output, []\n-            input_length = input_shape[1]\n-            if K.backend() == 'tensorflow' and len(input_shape) > 3:\n-                if input_length is None:\n-                    raise Exception('When using TensorFlow, you should define '\n-                                    'explicitly the number of timesteps of '\n-                                    'your sequences.\\n'\n-                                    'If your first layer is an Embedding, '\n-                                    'make sure to pass it an \"input_length\" '\n-                                    'argument. Otherwise, make sure '\n-                                    'the first layer has '\n-                                    'an \"input_shape\" or \"batch_input_shape\" '\n-                                    'argument, including the time axis.')\n-                unroll = True\n-            else:\n-                unroll = False\n-            last_output, outputs, states = K.rnn(step, X,\n-                                                 initial_states=[], input_length=input_length, unroll=unroll)\n+\n+            _, outputs, _ = K.rnn(step, X,\n+                                  initial_states=[],\n+                                  input_length=input_shape[1],\n+                                  unroll=False)\n             y = outputs\n         else:\n             # no batch size specified, therefore the layer will be able\n\n@@ -140,13 +140,20 @@ def test_masking_layer():\n     https://github.com/fchollet/keras/issues/1567\n \n     '''\n-    model = Sequential()\n-    model.add(Masking(input_shape=(3, 4)))\n-    model.add(recurrent.LSTM(output_dim=5, return_sequences=True))\n-    model.compile(loss='categorical_crossentropy', optimizer='adam')\n     I = np.random.random((6, 3, 4))\n     V = np.abs(np.random.random((6, 3, 5)))\n     V /= V.sum(axis=-1, keepdims=True)\n+\n+    model = Sequential()\n+    model.add(Masking(input_shape=(3, 4)))\n+    model.add(recurrent.LSTM(output_dim=5, return_sequences=True, unroll=False))\n+    model.compile(loss='categorical_crossentropy', optimizer='adam')\n+    model.fit(I, V, nb_epoch=1, batch_size=100, verbose=1)\n+\n+    model = Sequential()\n+    model.add(Masking(input_shape=(3, 4)))\n+    model.add(recurrent.LSTM(output_dim=5, return_sequences=True, unroll=True))\n+    model.compile(loss='categorical_crossentropy', optimizer='adam')\n     model.fit(I, V, nb_epoch=1, batch_size=100, verbose=1)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#71494ffdbc8193ece7a82496ec7835f195fb8309", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 434 | Contributors (this commit): 8 | Commits (past 90d): 6 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -16,7 +16,7 @@ original_dim = 784\n latent_dim = 2\n intermediate_dim = 256\n nb_epoch = 50\n-epsilon_std = 0.01\n+epsilon_std = 1.0\n \n x = Input(batch_shape=(batch_size, original_dim))\n h = Dense(intermediate_dim, activation='relu')(x)\n\n@@ -27,7 +27,7 @@ else:\n     original_img_size = (img_rows, img_cols, img_chns)\n latent_dim = 2\n intermediate_dim = 128\n-epsilon_std = 0.01\n+epsilon_std = 1.0\n nb_epoch = 5\n \n x = Input(batch_shape=(batch_size,) + original_img_size)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#49386e8da49f0c63c467c28456c995ad24cc99fb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 18 | Churn Cumulative: 5529 | Contributors (this commit): 59 | Commits (past 90d): 45 | Contributors (cumulative): 67 | DMM Complexity: 1.0\n\nDIFF:\n@@ -176,9 +176,9 @@ def variable(value, dtype=_FLOATX, name=None):\n         indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),\n                                   np.expand_dims(sparse_coo.col, 1)), 1)\n         # SparseTensor doesn't need initialization\n-        return tf.SparseTensor(indices=indices,\n-                               values=sparse_coo.data,\n-                               shape=sparse_coo.shape)\n+        v = tf.SparseTensor(indices=indices, values=sparse_coo.data, shape=sparse_coo.shape)\n+        v._dims = len(sparse_coo.shape)\n+        return v\n     v = tf.Variable(value, dtype=_convert_string_dtype(dtype), name=name)\n     return v\n \n@@ -214,9 +214,8 @@ def placeholder(shape=None, ndim=None, dtype=_FLOATX, sparse=False, name=None):\n         if ndim:\n             shape = tuple([None for _ in range(ndim)])\n     if sparse:\n-        tf_shape = tf.constant(np.array(list([0 for _ in range(len(shape))]),\n-                                        dtype=np.int64))\n-        x = tf.sparse_placeholder(dtype, shape=tf_shape, name=name)\n+        x = tf.sparse_placeholder(dtype, name=name)\n+        x._dims = len(shape)\n     else:\n         x = tf.placeholder(dtype, shape=shape, name=name)\n     x._keras_shape = shape\n@@ -243,7 +242,7 @@ def ndim(x):\n     '''Returns the number of axes in a tensor, as an integer.\n     '''\n     if is_sparse(x):\n-        return int(x.shape.get_shape()[0])\n+        return x._dims\n \n     dims = x.get_shape()._dims\n     if dims is not None:\n\n@@ -610,7 +610,10 @@ class Model(Container):\n         for i in range(len(self.outputs)):\n             shape = self.internal_output_shapes[i]\n             name = self.output_names[i]\n-            self.targets.append(K.placeholder(ndim=len(shape), name=name + '_target'))\n+            self.targets.append(K.placeholder(ndim=len(shape),\n+                                name=name + '_target',\n+                                sparse=K.is_sparse(self.outputs[i]),\n+                                dtype=K.dtype(self.outputs[i])))\n \n         # prepare metrics\n         self.metrics = metrics\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#650c2c8cf9d711d35ab0ca7d1653ef53cbedaab3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 38 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 4 | Methods Changed: 9 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 46 | Churn Cumulative: 1561 | Contributors (this commit): 17 | Commits (past 90d): 9 | Contributors (cumulative): 17 | DMM Complexity: 1.0\n\nDIFF:\n@@ -19,6 +19,7 @@ def optimizer_from_config(config, custom_objects={}):\n         'adam': Adam,\n         'adamax': Adamax,\n         'nadam': Nadam,\n+        'tfoptimizer': TFOptimizer,\n     }\n     class_name = config['class_name']\n     if class_name in custom_objects:\n@@ -53,14 +54,6 @@ class Optimizer(object):\n         self.updates = []\n         self.weights = []\n \n-    def get_state(self):\n-        return [K.get_value(u[0]) for u in self.updates]\n-\n-    def set_state(self, value_list):\n-        assert len(self.updates) == len(value_list)\n-        for u, v in zip(self.updates, value_list):\n-            K.set_value(u[0], v)\n-\n     def get_updates(self, params, constraints, loss):\n         raise NotImplementedError\n \n@@ -570,6 +563,37 @@ class Nadam(Optimizer):\n         return dict(list(base_config.items()) + list(config.items()))\n \n \n+class TFOptimizer(Optimizer):\n+\n+    def __init__(self, optimizer):\n+        self.optimizer = optimizer\n+        self.iterations = K.variable(0.)\n+        self.updates = []\n+\n+    def get_updates(self, params, constraints, loss):\n+        if constraints:\n+            raise ValueError('TF optimizers do not support '\n+                             'weights constraints. Either remove '\n+                             'all weights constraints in your model, '\n+                             'or use a Keras optimizer.')\n+        grads = self.optimizer.compute_gradients(loss, params)\n+        self.updates.append(K.update_add(self.iterations, 1))\n+        opt_update = self.optimizer.apply_gradients(\n+            grads, global_step=self.iterations)\n+        self.updates.append(opt_update)\n+        return self.updates\n+\n+    @property\n+    def weights(self):\n+        raise NotImplementedError\n+\n+    def get_config(self):\n+        raise NotImplementedError\n+\n+    def from_config(self, config):\n+        raise NotImplementedError\n+\n+\n # aliases\n sgd = SGD\n rmsprop = RMSprop\n@@ -581,5 +605,11 @@ nadam = Nadam\n \n \n def get(identifier, kwargs=None):\n+    if K.backend() == 'tensorflow':\n+        # Wrap TF optimizer instances\n+        import tensorflow as tf\n+        if isinstance(identifier, tf.train.Optimizer):\n+            return TFOptimizer(identifier)\n+    # Instantiate a Keras optimizer\n     return get_from_module(identifier, globals(), 'optimizer',\n                            instantiate=True, kwargs=kwargs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2b51317be82d4420169d2cc79dc4443028417911", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 84 | Lines Deleted: 32 | Files Changed: 2 | Hunks: 22 | Methods Changed: 20 | Complexity Δ (Sum/Max): 6/3 | Churn Δ: 116 | Churn Cumulative: 455 | Contributors (this commit): 6 | Commits (past 90d): 15 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -5,14 +5,14 @@ from .utils.generic_utils import get_from_module\n \n def binary_accuracy(y_true, y_pred):\n     '''Calculates the mean accuracy rate across all predictions for binary\n-    classification problems\n+    classification problems.\n     '''\n     return K.mean(K.equal(y_true, K.round(y_pred)))\n \n \n def categorical_accuracy(y_true, y_pred):\n     '''Calculates the mean accuracy rate across all predictions for\n-    multiclass classification problems\n+    multiclass classification problems.\n     '''\n     return K.mean(K.equal(K.argmax(y_true, axis=-1),\n                   K.argmax(y_pred, axis=-1)))\n@@ -20,7 +20,7 @@ def categorical_accuracy(y_true, y_pred):\n \n def sparse_categorical_accuracy(y_true, y_pred):\n     '''Same as categorical_accuracy, but useful when the predictions are for\n-    sparse targets\n+    sparse targets.\n     '''\n     return K.mean(K.equal(K.max(y_true, axis=-1),\n                           K.cast(K.argmax(y_pred, axis=-1), K.floatx())))\n@@ -28,28 +28,28 @@ def sparse_categorical_accuracy(y_true, y_pred):\n \n def top_k_categorical_accuracy(y_true, y_pred, k=5):\n     '''Calculates the top-k categorical accuracy rate, i.e. success when the\n-    target class is within the top-k predictions provided\n+    target class is within the top-k predictions provided.\n     '''\n     return K.mean(K.in_top_k(y_pred, K.argmax(y_true, axis=-1), k))\n \n \n def mean_squared_error(y_true, y_pred):\n     '''Calculates the mean squared error (mse) rate\n-    between predicted and target values\n+    between predicted and target values.\n     '''\n     return K.mean(K.square(y_pred - y_true))\n \n \n def mean_absolute_error(y_true, y_pred):\n     '''Calculates the mean absolute error (mae) rate\n-    between predicted and target values\n+    between predicted and target values.\n     '''\n     return K.mean(K.abs(y_pred - y_true))\n \n \n def mean_absolute_percentage_error(y_true, y_pred):\n     '''Calculates the mean absolute percentage error (mape) rate\n-    between predicted and target values\n+    between predicted and target values.\n     '''\n     diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true), K.epsilon(), np.inf))\n     return 100. * K.mean(diff)\n@@ -57,7 +57,7 @@ def mean_absolute_percentage_error(y_true, y_pred):\n \n def mean_squared_logarithmic_error(y_true, y_pred):\n     '''Calculates the mean squared logarithmic error (msle) rate\n-    between predicted and target values\n+    between predicted and target values.\n     '''\n     first_log = K.log(K.clip(y_pred, K.epsilon(), np.inf) + 1.)\n     second_log = K.log(K.clip(y_true, K.epsilon(), np.inf) + 1.)\n@@ -66,13 +66,13 @@ def mean_squared_logarithmic_error(y_true, y_pred):\n \n def hinge(y_true, y_pred):\n     '''Calculates the hinge loss, which is defined as\n-    `max(1 - y_true * y_pred, 0)`\n+    `max(1 - y_true * y_pred, 0)`.\n     '''\n     return K.mean(K.maximum(1. - y_true * y_pred, 0.))\n \n \n def squared_hinge(y_true, y_pred):\n-    '''Calculates the squared value of the hinge loss\n+    '''Calculates the squared value of the hinge loss.\n     '''\n     return K.mean(K.square(K.maximum(1. - y_true * y_pred, 0.)))\n \n@@ -104,7 +104,7 @@ def binary_crossentropy(y_true, y_pred):\n \n def kullback_leibler_divergence(y_true, y_pred):\n     '''Calculates the Kullback-Leibler (KL) divergence between prediction\n-    and target values\n+    and target values.\n     '''\n     y_true = K.clip(y_true, K.epsilon(), 1)\n     y_pred = K.clip(y_pred, K.epsilon(), 1)\n@@ -148,11 +148,31 @@ def matthews_correlation(y_true, y_pred):\n     return numerator / (denominator + K.epsilon())\n \n \n-def fbeta_score(y_true, y_pred, beta=1):\n-    '''Computes the F score, the weighted harmonic mean of precision and recall.\n+def precision(y_true, y_pred):\n+    '''Calculates the precision, a metric for multi-label classification of\n+    how many selected items are relevant.\n+    '''\n+    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n+    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n+    precision = true_positives / (predicted_positives + K.epsilon())\n+    return precision\n \n-    This is useful for multi-label classification where input samples can be\n-    tagged with a set of labels. By only using accuracy (precision) a model\n+\n+def recall(y_true, y_pred):\n+    '''Calculates the recall, a metric for multi-label classification of\n+    how many relevant items are selected.\n+    '''\n+    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n+    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n+    recall = true_positives / (possible_positives + K.epsilon())\n+    return recall\n+\n+\n+def fbeta_score(y_true, y_pred, beta):\n+    '''Calculates the F score, the weighted harmonic mean of precision and recall.\n+\n+    This is useful for multi-label classification, where input samples can be\n+    classified as sets of labels. By only using accuracy (precision) a model\n     would achieve a perfect score by simply assigning every class to every\n     input. In order to avoid this, a metric should penalize incorrect class\n     assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n@@ -162,30 +182,25 @@ def fbeta_score(y_true, y_pred, beta=1):\n     With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n     correct classes becomes more important, and with beta > 1 the metric is\n     instead weighted towards penalizing incorrect class assignments.\n-\n     '''\n     if beta < 0:\n         raise ValueError('The lowest choosable beta is zero (only precision).')\n         \n-    # Count positive samples.\n-    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n-    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n-    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n-\n-    # If there are no true samples, fix the F score at 0.\n-    if c3 == 0:\n+    # If there are no true positives, fix the F score at 0 like sklearn.\n+    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n         return 0\n \n-    # How many selected items are relevant?\n-    precision = c1 / c2\n+    p = precision(y_true, y_pred)\n+    r = recall(y_true, y_pred)\n+    bb = beta ** 2\n+    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n+    return fbeta_score\n \n-    # How many relevant items are selected?\n-    recall = c1 / c3\n \n-    # Weight precision and recall together as a single scalar.\n-    beta2 = beta ** 2\n-    f_score = (1 + beta2) * (precision * recall) / (beta2 * precision + recall)\n-    return f_score\n+def fmeasure(y_true, y_pred):\n+    '''Calculates the f-measure, the harmonic mean of precision and recall.\n+    '''\n+    return fbeta_score(y_true, y_pred, beta=1)\n \n \n # aliases\n@@ -194,6 +209,7 @@ mae = MAE = mean_absolute_error\n mape = MAPE = mean_absolute_percentage_error\n msle = MSLE = mean_squared_logarithmic_error\n cosine = cosine_proximity\n+fscore = f1score = fmeasure\n \n \n def get(identifier):\n\n@@ -46,14 +46,50 @@ def test_matthews_correlation():\n     assert expected - epsilon <= actual <= expected + epsilon\n \n \n+def test_precision():\n+    y_true = K.variable(np.array([0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0]))\n+    y_pred = K.variable(np.array([1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0]))\n+\n+    # Calculated using sklearn.metrics.precision_score\n+    expected = 0.40000000000000002\n+\n+    actual = K.eval(metrics.precision(y_true, y_pred))\n+    epsilon = 1e-05\n+    assert expected - epsilon <= actual <= expected + epsilon\n+\n+\n+def test_recall():\n+    y_true = K.variable(np.array([0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0]))\n+    y_pred = K.variable(np.array([1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0]))\n+\n+    # Calculated using sklearn.metrics.recall_score\n+    expected = 0.2857142857142857\n+\n+    actual = K.eval(metrics.recall(y_true, y_pred))\n+    epsilon = 1e-05\n+    assert expected - epsilon <= actual <= expected + epsilon\n+\n+\n def test_fbeta_score():\n     y_true = K.variable(np.array([0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0]))\n     y_pred = K.variable(np.array([1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0]))\n \n+    # Calculated using sklearn.metrics.fbeta_score\n+    expected = 0.30303030303030304\n+\n+    actual = K.eval(metrics.fbeta_score(y_true, y_pred, beta=2))\n+    epsilon = 1e-05\n+    assert expected - epsilon <= actual <= expected + epsilon\n+\n+\n+def test_fmeasure():\n+    y_true = K.variable(np.array([0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0]))\n+    y_pred = K.variable(np.array([1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0]))\n+\n     # Calculated using sklearn.metrics.f1_score\n     expected = 0.33333333333333331\n \n-    actual = K.eval(metrics.fbeta_score(y_true, y_pred))\n+    actual = K.eval(metrics.fmeasure(y_true, y_pred))\n     epsilon = 1e-05\n     assert expected - epsilon <= actual <= expected + epsilon\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
