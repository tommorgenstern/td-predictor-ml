{"custom_id": "keras#5986893dbaaa3c3ce1f07958ad5d3ec894ad20a9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 5 | Churn Cumulative: 1812 | Contributors (this commit): 9 | Commits (past 90d): 2 | Contributors (cumulative): 9 | DMM Complexity: 0.0\n\nDIFF:\n@@ -474,10 +474,7 @@ def _get_type_spec(dataset):\n \n def is_batched(tf_dataset):\n     \"\"\" \"Check if the `tf.data.Dataset` is batched.\"\"\"\n-    try:\n-        return tf_dataset.__class__.__name__ == \"BatchDataset\"\n-    except AttributeError:\n-        return False\n+    return hasattr(tf_dataset, \"_batch_size\")\n \n \n def get_batch_size(tf_dataset):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3f9a34ce26c05982df38b02cdfa9ba60b933377c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 4245 | Contributors (this commit): 15 | Commits (past 90d): 4 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -739,7 +739,7 @@ class Layer(base_layer.Layer):\n             inputs = tf.nest.map_structure(_convert_non_tensor, inputs)\n             input_list = tf.nest.flatten(inputs)\n \n-        # Handle `mask` propagation from the previous layer to the current layer. Masks\n+        # Handle `mask` propagation from previous layer to current layer. Masks\n         # can be propagated explicitly via the `mask` argument, or implicitly\n         # via setting the `_keras_mask` attribute on the inputs to a Layer.\n         # Masks passed explicitly take priority.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#069b8d3bc15dbb13b6311fee52c91d6a78985bfb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 14 | Churn Cumulative: 422 | Contributors (this commit): 9 | Commits (past 90d): 1 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -185,6 +185,20 @@ class KerasTensorTest(test_combinations.TestCase):\n             self.assertEqual(kt.type_spec.shape.as_list(), expected_shape)\n         self.assertTrue(kt.type_spec.is_compatible_with(spec))\n \n+    @parameterized.parameters(\n+        [\n+            (layers.Input(shape=[3, 4], batch_size=7), tf.reshape),\n+            (layers.Input(shape=[3, 4], ragged=True, batch_size=7), tf.reshape),\n+            (\n+                layers.Input(shape=[3, 4], sparse=True, batch_size=7),\n+                tf.sparse.reshape,\n+            ),\n+        ]\n+    )\n+    def test_reshape(self, inp, reshape_op):\n+        out = reshape_op(inp, shape=[7, 4, 3])\n+        self.assertEqual(out.type_spec.shape.as_list(), [7, 4, 3])\n+\n     def test_set_shape_error(self):\n         spec = CustomTypeSpec([3, None], tf.int32)\n         kt = keras_tensor.KerasTensor(spec)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b3f12f1acc0a599e9aa61349c7e1b4e3afcdd932", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 8 | Methods Changed: 7 | Complexity Δ (Sum/Max): 52/50 | Churn Δ: 36 | Churn Cumulative: 684 | Contributors (this commit): 2 | Commits (past 90d): 15 | Contributors (cumulative): 3 | DMM Complexity: 0.3076923076923077\n\nDIFF:\n@@ -21,6 +21,7 @@ import numpy as np\n import tensorflow.compat.v2 as tf\n \n from keras.saving import object_registration\n+from keras.utils import generic_utils\n \n # isort: off\n from tensorflow.python.util import tf_export\n@@ -83,6 +84,13 @@ def serialize_keras_object(obj):\n             return obj.item()\n     if isinstance(obj, tf.DType):\n         return obj.name\n+    if isinstance(obj, types.FunctionType) and obj.__name__ == \"<lambda>\":\n+        return {\n+            \"class_name\": \"__lambda__\",\n+            \"config\": {\n+                \"value\": generic_utils.func_dump(obj),\n+            },\n+        }\n \n     # This gets the `keras.*` exported name, such as \"keras.optimizers.Adam\".\n     keras_api_name = tf_export.get_canonical_name_for_symbol(\n@@ -122,13 +130,6 @@ def _get_class_or_fn_config(obj):\n     \"\"\"Return the object's config depending on its type.\"\"\"\n     # Functions / lambdas:\n     if isinstance(obj, types.FunctionType):\n-        if getattr(obj, \"__name__\") == \"<lambda>\":\n-            raise TypeError(\n-                \"`lambda` objects cannot be serialized. \"\n-                \"Make sure there are no `lambda` objects being \"\n-                \"returned by a `get_config()` method. \"\n-                f\"Received the following: {obj}\"\n-            )\n         return obj.__name__\n     # All classes:\n     if hasattr(obj, \"get_config\"):\n@@ -278,6 +279,8 @@ def deserialize_keras_object(config, custom_objects=None):\n         return np.array(inner_config[\"value\"], dtype=inner_config[\"dtype\"])\n     if config[\"class_name\"] == \"__bytes__\":\n         return inner_config[\"value\"].encode(\"utf-8\")\n+    if config[\"class_name\"] == \"__lambda__\":\n+        return generic_utils.func_load(inner_config[\"value\"])\n     # TODO(fchollet): support for TypeSpec, CompositeTensor, tf.Dtype\n     # TODO(fchollet): consider special-casing tuples (which are currently\n     # deserialized as lists).\n\n@@ -132,7 +132,7 @@ class SerializationLibTest(tf.test.TestCase, parameterized.TestCase):\n         # Test inside layer\n         dense = keras.layers.Dense(1, activation=custom_fn)\n         dense.build((None, 2))\n-        serialized, new_dense, reserialized = self.roundtrip(\n+        _, new_dense, _ = self.roundtrip(\n             dense, custom_objects={\"custom_fn\": custom_fn}\n         )\n         x = tf.random.normal((2, 2))\n@@ -146,7 +146,7 @@ class SerializationLibTest(tf.test.TestCase, parameterized.TestCase):\n         layer = CustomLayer(factor=2)\n         x = tf.random.normal((2, 2))\n         y1 = layer(x)\n-        serialized, new_layer, reserialized = self.roundtrip(\n+        _, new_layer, _ = self.roundtrip(\n             layer, custom_objects={\"CustomLayer\": CustomLayer}\n         )\n         y2 = new_layer(x)\n@@ -155,7 +155,7 @@ class SerializationLibTest(tf.test.TestCase, parameterized.TestCase):\n         layer = NestedCustomLayer(factor=2)\n         x = tf.random.normal((2, 2))\n         y1 = layer(x)\n-        serialized, new_layer, reserialized = self.roundtrip(\n+        _, new_layer, _ = self.roundtrip(\n             layer,\n             custom_objects={\n                 \"NestedCustomLayer\": NestedCustomLayer,\n@@ -167,6 +167,19 @@ class SerializationLibTest(tf.test.TestCase, parameterized.TestCase):\n         y2 = new_layer(x)\n         self.assertAllClose(y1, y2, atol=1e-5)\n \n+    def test_lambda_fn(self):\n+        obj = {\"activation\": lambda x: x**2}\n+        _, new_obj, _ = self.roundtrip(obj)\n+        self.assertEqual(obj[\"activation\"](3), new_obj[\"activation\"](3))\n+\n+    def test_lambda_layer(self):\n+        lmbda = keras.layers.Lambda(lambda x: x**2)\n+        _, new_lmbda, _ = self.roundtrip(lmbda)\n+        x = tf.random.normal((2, 2))\n+        y1 = lmbda(x)\n+        y2 = new_lmbda(x)\n+        self.assertAllClose(y1, y2, atol=1e-5)\n+\n     def test_shared_object(self):\n         input_1 = keras.Input((2,))\n         input_2 = keras.Input((2,))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#63e8a9abf3cf5c8c985491e1882ed092eebfc138", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 112 | Lines Deleted: 6 | Files Changed: 4 | Hunks: 12 | Methods Changed: 17 | Complexity Δ (Sum/Max): 20/12 | Churn Δ: 118 | Churn Cumulative: 3784 | Contributors (this commit): 7 | Commits (past 90d): 37 | Contributors (cumulative): 11 | DMM Complexity: 0.8690476190476191\n\nDIFF:\n@@ -31,6 +31,7 @@ import keras\n from keras import losses\n from keras.engine import base_layer\n from keras.optimizers import optimizer\n+from keras.saving.experimental.serialization_lib import ObjectSharingScope\n from keras.saving.experimental.serialization_lib import deserialize_keras_object\n from keras.saving.experimental.serialization_lib import serialize_keras_object\n from keras.utils import generic_utils\n@@ -141,6 +142,7 @@ def save_model(model, filepath, weights_format=\"h5\"):\n     saving_v3_enabled_value = getattr(_SAVING_V3_ENABLED, \"value\", False)\n     _SAVING_V3_ENABLED.value = True\n \n+    with ObjectSharingScope():\n         serialized_model_dict = serialize_keras_object(model)\n     config_json = json.dumps(serialized_model_dict)\n     metadata_json = json.dumps(\n@@ -230,6 +232,7 @@ def load_model(filepath, custom_objects=None, compile=True):\n                 # Disable compilation\n                 config_dict[\"config\"][\"compile_config\"] = None\n             # Construct the model from the configuration file in the archive.\n+            with ObjectSharingScope():\n                 model = deserialize_keras_object(config_dict, custom_objects)\n \n             all_filenames = zf.namelist()\n\n@@ -15,6 +15,7 @@\n \"\"\"Object config serialization and deserialization logic.\"\"\"\n \n import importlib\n+import threading\n import types\n \n import numpy as np\n@@ -27,6 +28,47 @@ from keras.utils import generic_utils\n from tensorflow.python.util import tf_export\n \n PLAIN_TYPES = (str, int, float, bool)\n+SHARED_OBJECTS = threading.local()\n+\n+\n+class ObjectSharingScope:\n+    \"\"\"Scope to enable detection and reuse of previously seen objects.\"\"\"\n+\n+    def __enter__(self):\n+        SHARED_OBJECTS.enabled = True\n+        SHARED_OBJECTS.id_to_obj_map = {}\n+        SHARED_OBJECTS.id_to_config_map = {}\n+\n+    def __exit__(self, *args, **kwargs):\n+        SHARED_OBJECTS.enabled = False\n+        SHARED_OBJECTS.id_to_obj_map = {}\n+        SHARED_OBJECTS.id_to_config_map = {}\n+\n+\n+def get_shared_object(obj_id):\n+    \"\"\"Retrieve an object previously seen during deserialization.\"\"\"\n+    if getattr(SHARED_OBJECTS, \"enabled\", False):\n+        return SHARED_OBJECTS.id_to_obj_map.get(obj_id, None)\n+\n+\n+def record_object_after_serialization(obj, config):\n+    \"\"\"Call after serializing an object, to keep track of its config.\"\"\"\n+    if not getattr(SHARED_OBJECTS, \"enabled\", False):\n+        return  # Not in a sharing scope\n+    obj_id = int(id(obj))\n+    if obj_id not in SHARED_OBJECTS.id_to_config_map:\n+        SHARED_OBJECTS.id_to_config_map[obj_id] = config\n+    else:\n+        config[\"shared_object_id\"] = obj_id\n+        prev_config = SHARED_OBJECTS.id_to_config_map[obj_id]\n+        prev_config[\"shared_object_id\"] = obj_id\n+\n+\n+def record_object_after_deserialization(obj, obj_id):\n+    \"\"\"Call after deserializing an object, to keep track of it in the future.\"\"\"\n+    if not getattr(SHARED_OBJECTS, \"enabled\", False):\n+        return  # Not in a sharing scope\n+    SHARED_OBJECTS.id_to_obj_map[obj_id] = obj\n \n \n def serialize_keras_object(obj):\n@@ -118,12 +160,14 @@ def serialize_keras_object(obj):\n         module = \".\".join(parts[:-1])\n         class_name = parts[-1]\n         registered_name = None\n-    return {\n+    config = {\n         \"module\": module,\n         \"class_name\": class_name,\n         \"config\": _get_class_or_fn_config(obj),\n         \"registered_name\": registered_name,\n     }\n+    record_object_after_serialization(obj, config)\n+    return config\n \n \n def _get_class_or_fn_config(obj):\n@@ -300,7 +344,13 @@ def deserialize_keras_object(config, custom_objects=None):\n             custom_objects=custom_objects,\n         )\n \n-    # All classes:\n+    # Below, handling of all classes.\n+    # First, is it a shared object?\n+    if \"shared_object_id\" in config:\n+        obj = get_shared_object(config[\"shared_object_id\"])\n+        if obj is not None:\n+            return obj\n+\n     cls = _retrieve_class_or_fn(\n         class_name,\n         registered_name,\n@@ -318,7 +368,10 @@ def deserialize_keras_object(config, custom_objects=None):\n     # Instantiate the class from its config inside a custom object scope\n     # so that we can catch any custom objects that the config refers to.\n     with object_registration.custom_object_scope(custom_objects):\n-        return cls.from_config(inner_config)\n+        obj = cls.from_config(inner_config)\n+    if \"shared_object_id\" in config:\n+        record_object_after_deserialization(obj, config[\"shared_object_id\"])\n+    return obj\n \n \n def _retrieve_class_or_fn(\n\n@@ -180,7 +180,7 @@ class SerializationLibTest(tf.test.TestCase, parameterized.TestCase):\n         y2 = new_lmbda(x)\n         self.assertAllClose(y1, y2, atol=1e-5)\n \n-    def test_shared_object(self):\n+    def shared_inner_layer(self):\n         input_1 = keras.Input((2,))\n         input_2 = keras.Input((2,))\n         shared_layer = keras.layers.Dense(1)\n@@ -195,6 +195,56 @@ class SerializationLibTest(tf.test.TestCase, parameterized.TestCase):\n         self.assertIs(model.layers[2], model.layers[3].layer)\n         self.assertIs(new_model.layers[2], new_model.layers[3].layer)\n \n+    def test_shared_object(self):\n+        class MyLayer(keras.layers.Layer):\n+            def __init__(self, activation, **kwargs):\n+                super().__init__(**kwargs)\n+                if isinstance(activation, dict):\n+                    self.activation = (\n+                        serialization_lib.deserialize_keras_object(activation)\n+                    )\n+                else:\n+                    self.activation = activation\n+\n+            def call(self, x):\n+                return self.activation(x)\n+\n+            def get_config(self):\n+                config = super().get_config()\n+                config[\"activation\"] = self.activation\n+                return config\n+\n+        class SharedActivation:\n+            def __call__(self, x):\n+                return x**2\n+\n+            def get_config(self):\n+                return {}\n+\n+            @classmethod\n+            def from_config(cls, config):\n+                return cls()\n+\n+        shared_act = SharedActivation()\n+        layer_1 = MyLayer(activation=shared_act)\n+        layer_2 = MyLayer(activation=shared_act)\n+        layers = [layer_1, layer_2]\n+\n+        with serialization_lib.ObjectSharingScope():\n+            serialized, new_layers, reserialized = self.roundtrip(\n+                layers,\n+                custom_objects={\n+                    \"MyLayer\": MyLayer,\n+                    \"SharedActivation\": SharedActivation,\n+                },\n+            )\n+        self.assertIn(\"shared_object_id\", serialized[0][\"config\"][\"activation\"])\n+        obj_id = serialized[0][\"config\"][\"activation\"]\n+        self.assertIn(\"shared_object_id\", serialized[1][\"config\"][\"activation\"])\n+        self.assertEqual(obj_id, serialized[1][\"config\"][\"activation\"])\n+        self.assertIs(layers[0].activation, layers[1].activation)\n+        self.assertIs(new_layers[0].activation, new_layers[1].activation)\n+\n \n @test_utils.run_v2_only\n class BackwardsCompatibilityTest(tf.test.TestCase, parameterized.TestCase):\n\n@@ -353,8 +353,8 @@ def serialize_keras_object(instance):\n     if hasattr(instance, \"__name__\"):\n         return object_registration.get_registered_name(instance)\n     raise ValueError(\n-        f\"Cannot serialize {instance} since it doesn't implement \"\n-        \"`get_config()`, and also doesn\\t have `__name__`\"\n+        f\"Cannot serialize {instance} because it doesn't implement \"\n+        \"`get_config()`.\"\n     )\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d9209d62c63cfa816d32f471321b3c3abec72a93", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 60 | Lines Deleted: 54 | Files Changed: 6 | Hunks: 18 | Methods Changed: 14 | Complexity Δ (Sum/Max): 3/6 | Churn Δ: 114 | Churn Cumulative: 39735 | Contributors (this commit): 159 | Commits (past 90d): 105 | Contributors (cumulative): 208 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2273,6 +2273,25 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         )\n         return self.add_weight(*args, **kwargs)\n \n+    def get_build_config(self):\n+        if self._build_input_shape is not None:\n+\n+            def convert_tensorshapes(x):\n+                if isinstance(x, tf.TensorShape):\n+                    return tuple(x.as_list())\n+                return x\n+\n+            return {\n+                \"input_shape\": tf.nest.map_structure(\n+                    convert_tensorshapes, self._build_input_shape\n+                )\n+            }\n+\n+    def build_from_config(self, config):\n+        input_shape = config[\"input_shape\"]\n+        if input_shape is not None:\n+            self.build(input_shape)\n+\n     ############################################################################\n     # Methods & attributes below are all private and only used by the framework.\n     ############################################################################\n@@ -3324,7 +3343,6 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n                 output.append(w)\n                 # Track the Variable's identity to avoid __eq__ issues.\n                 seen_ids.add(id(w))\n-\n         return output\n \n     # SavedModel properties. Please see keras/saving/saved_model for details.\n\n@@ -25,7 +25,6 @@ from keras.engine import functional\n from keras.engine import input_layer\n from keras.engine import training\n from keras.engine import training_utils\n-from keras.saving.experimental import saving_lib\n from keras.saving.legacy import serialization\n from keras.saving.legacy.saved_model import model_serialization\n from keras.utils import generic_utils\n@@ -471,7 +470,6 @@ class Sequential(functional.Functional):\n             layer_configs = config[\"layers\"]\n         else:\n             name = None\n-            build_input_shape = None\n             layer_configs = config\n         model = cls(name=name)\n         for layer_config in layer_configs:\n@@ -480,13 +478,6 @@ class Sequential(functional.Functional):\n             )\n             model.add(layer)\n \n-        if saving_lib.saving_v3_enabled():\n-            compile_config = config.get(\"compile_config\", None)\n-            if compile_config is not None:\n-                model._compile_from_config(\n-                    compile_config, base_class=Sequential\n-                )\n-\n         if (\n             not model.inputs\n             and build_input_shape\n\n@@ -3020,18 +3020,10 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                 config.pop(key, None)\n         else:\n             config = {}\n-        if saving_lib.saving_v3_enabled():\n-            if self._is_compiled and hasattr(self, \"_compile_config\"):\n-                config[\"compile_config\"] = self._compile_config.serialize()\n-            if self.built:\n-                config[\"build_input_shape\"] = self._build_input_shape\n         return config\n \n     @classmethod\n     def from_config(cls, config, custom_objects=None):\n-        compile_config = config.pop(\"compile_config\", None)\n-        build_input_shape = config.pop(\"build_input_shape\", None)\n-\n         # `from_config` assumes `cls` is either `Functional` or a child class of\n         # `Functional`. In the case that `cls` is meant to behave like a child\n         # class of `Functional` but only inherits from the `Model` class, we\n@@ -3074,13 +3066,6 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                         f\"instance of {cls.__name__} from the config. \\n\\n\"\n                         f\"Error encountered during deserialization:\\n{e}\"\n                     )\n-\n-            if saving_lib.saving_v3_enabled():\n-                if build_input_shape:\n-                    model.build(build_input_shape)\n-                if compile_config is not None:\n-                    model._compile_from_config(compile_config, base_class=Model)\n-\n             return model\n \n     def to_json(self, **kwargs):\n@@ -3366,6 +3351,26 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                 result[object_path] = descendant\n         return result\n \n+    def get_compile_config(self):\n+        if self._is_compiled and hasattr(self, \"_compile_config\"):\n+            return self._compile_config.serialize()\n+\n+    def compile_from_config(self, config):\n+        has_overridden_compile = self.__class__.compile != Model.compile\n+        if has_overridden_compile:\n+            logging.warning(\n+                \"`compile()` was not called as part of model loading \"\n+                \"because the model's `compile()` method is custom. \"\n+                \"All subclassed Models that have `compile()` \"\n+                \"overridden should also override \"\n+                \"`get_compile_config()` and `compile_from_config(config)`. \"\n+                \"Alternatively, you can \"\n+                \"call `compile()` manually after loading.\"\n+            )\n+            return\n+        config = saving_lib.deserialize_keras_object(config)\n+        self.compile(**config)\n+\n     @tf.__internal__.tracking.no_automatic_dependency_tracking\n     def _set_save_spec(self, inputs, args=None, kwargs=None):\n         \"\"\"Defines the save spec so that serialization can trace `call()`.\n@@ -3693,27 +3698,6 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                 f\"type {type(validation_freq)}.\"\n             )\n \n-    def _compile_from_config(self, compile_config, base_class):\n-        has_overridden_compile = self.__class__.compile != base_class.compile\n-        has_overridden_from_config = (\n-            self.__class__.from_config.__func__.__qualname__\n-            != base_class.from_config.__func__.__qualname__\n-        )\n-\n-        if not has_overridden_compile:\n-            compile_config = saving_lib.deserialize_keras_object(compile_config)\n-            self.compile(**compile_config)\n-        else:\n-            if not has_overridden_from_config:\n-                logging.warning(\n-                    \"`compile()` was not called as part of model loading \"\n-                    \"because the model's `compile()` method is custom. \"\n-                    \"All subclassed Models that have `compile()` \"\n-                    \"overridden should also override `from_config()` in \"\n-                    \"order to call `compile()`. Alternatively, you can \"\n-                    \"call `compile()` manually after loading.\"\n-                )\n-\n     ######################################################################\n     # Functions below exist only as v1 / v2 compatibility shims.\n     ######################################################################\n\n@@ -230,7 +230,7 @@ def load_model(filepath, custom_objects=None, compile=True):\n             config_dict = json.loads(config_json)\n             if not compile:\n                 # Disable compilation\n-                config_dict[\"config\"][\"compile_config\"] = None\n+                config_dict[\"compile_config\"] = None\n             # Construct the model from the configuration file in the archive.\n             with ObjectSharingScope():\n                 model = deserialize_keras_object(config_dict, custom_objects)\n\n@@ -356,18 +356,18 @@ class SavingV3Test(tf.test.TestCase, parameterized.TestCase):\n             config_dict[\"registered_name\"], \"my_custom_package>CustomModelX\"\n         )\n         self.assertEqual(\n-            config_dict[\"config\"][\"compile_config\"][\"optimizer\"][\"config\"][\n+            config_dict[\"compile_config\"][\"optimizer\"][\"config\"][\n                 \"is_legacy_optimizer\"\n             ],\n             False,\n         )\n         self.assertEqual(\n-            config_dict[\"config\"][\"compile_config\"][\"optimizer\"][\"class_name\"],\n+            config_dict[\"compile_config\"][\"optimizer\"][\"class_name\"],\n             \"Adam\",\n         )\n-        self.assertLen(config_dict[\"config\"][\"compile_config\"][\"loss\"], 4)\n+        self.assertLen(config_dict[\"compile_config\"][\"loss\"], 4)\n         self.assertEqual(\n-            config_dict[\"config\"][\"compile_config\"][\"loss\"][0],\n+            config_dict[\"compile_config\"][\"loss\"][0],\n             \"mse\",\n         )\n \n\n@@ -166,6 +166,10 @@ def serialize_keras_object(obj):\n         \"config\": _get_class_or_fn_config(obj),\n         \"registered_name\": registered_name,\n     }\n+    if hasattr(obj, \"get_build_config\"):\n+        config[\"build_config\"] = obj.get_build_config()\n+    if hasattr(obj, \"get_compile_config\"):\n+        config[\"compile_config\"] = obj.get_compile_config()\n     record_object_after_serialization(obj, config)\n     return config\n \n@@ -368,10 +372,19 @@ def deserialize_keras_object(config, custom_objects=None):\n     # Instantiate the class from its config inside a custom object scope\n     # so that we can catch any custom objects that the config refers to.\n     with object_registration.custom_object_scope(custom_objects):\n-        obj = cls.from_config(inner_config)\n+        instance = cls.from_config(inner_config)\n+        build_config = config.get(\"build_config\", None)\n+        if build_config:\n+            instance.build_from_config(build_config)\n+        compile_config = config.get(\"compile_config\", None)\n+        if compile_config:\n+            instance.compile_from_config(compile_config)\n+\n     if \"shared_object_id\" in config:\n-        record_object_after_deserialization(obj, config[\"shared_object_id\"])\n-    return obj\n+        record_object_after_deserialization(\n+            instance, config[\"shared_object_id\"]\n+        )\n+    return instance\n \n \n def _retrieve_class_or_fn(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f752a15a7633a09e6b9c1ffe86f2032249570d2d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 10903 | Contributors (this commit): 23 | Commits (past 90d): 14 | Contributors (cumulative): 29 | DMM Complexity: None\n\nDIFF:\n@@ -1817,7 +1817,7 @@ def identity(x, name=None):\n # tf.random.Generator to generate random numbers.\n # The legacy behavior is to use TF's legacy stateful RNG ops like\n # tf.random.uniform.\n-_USE_GENERATOR_FOR_RNG = True\n+_USE_GENERATOR_FOR_RNG = False\n \n # The global generator to create the seed when initializing the\n # tf.random.Genrator used by RandomGenerator. When tf.random.Generator becomes\n\n@@ -44,7 +44,7 @@ class Dropout(base_layer.BaseRandomLayer):\n     `trainable` does not affect the layer's behavior, as Dropout does\n     not have any variables/weights that can be frozen during training.)\n \n-    >>> tf.keras.utils.set_random_seed(0)\n+    >>> tf.random.set_seed(0)\n     >>> layer = tf.keras.layers.Dropout(.2, input_shape=(2,))\n     >>> data = np.arange(10).reshape(5, 2).astype(np.float32)\n     >>> print(data)\n@@ -57,7 +57,7 @@ class Dropout(base_layer.BaseRandomLayer):\n     >>> print(outputs)\n     tf.Tensor(\n     [[ 0.    1.25]\n-     [ 0.    3.75]\n+     [ 2.5   3.75]\n      [ 5.    6.25]\n      [ 7.5   8.75]\n      [10.    0.  ]], shape=(5, 2), dtype=float32)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5c1364e3a6ba90a7d1fe928b2e9957373b7e2799", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 8 | Files Changed: 5 | Hunks: 9 | Methods Changed: 0 | Complexity Δ (Sum/Max): 97/66 | Churn Δ: 16 | Churn Cumulative: 8592 | Contributors (this commit): 48 | Commits (past 90d): 29 | Contributors (cumulative): 58 | DMM Complexity: None\n\nDIFF:\n@@ -31,9 +31,9 @@ import keras\n from keras import losses\n from keras.engine import base_layer\n from keras.optimizers import optimizer\n-from keras.saving.experimental.serialization_lib import ObjectSharingScope\n-from keras.saving.experimental.serialization_lib import deserialize_keras_object\n-from keras.saving.experimental.serialization_lib import serialize_keras_object\n+from keras.saving.serialization_lib import ObjectSharingScope\n+from keras.saving.serialization_lib import deserialize_keras_object\n+from keras.saving.serialization_lib import serialize_keras_object\n from keras.utils import generic_utils\n from keras.utils import io_utils\n \n\n@@ -24,7 +24,6 @@ from keras.utils import tf_contextlib\n from keras.utils import tf_inspect\n \n # isort: off\n-from tensorflow.python.util.tf_export import keras_export\n \n # Flag that determines whether to skip the NotImplementedError when calling\n # get_config in custom models and layers. This is only enabled when saving to\n@@ -282,7 +281,6 @@ class CustomMaskWarning(Warning):\n     pass\n \n \n-@keras_export(\"keras.utils.serialize_keras_object\")\n def serialize_keras_object(instance):\n     \"\"\"Serialize a Keras object into a JSON-compatible representation.\n \n@@ -437,7 +435,6 @@ def class_and_config_for_serialized_keras_object(\n     return (cls, cls_config)\n \n \n-@keras_export(\"keras.utils.deserialize_keras_object\")\n def deserialize_keras_object(\n     identifier,\n     module_objects=None,\n\n@@ -26,6 +26,7 @@ from keras.utils import generic_utils\n \n # isort: off\n from tensorflow.python.util import tf_export\n+from tensorflow.python.util.tf_export import keras_export\n \n PLAIN_TYPES = (str, int, float, bool)\n SHARED_OBJECTS = threading.local()\n@@ -71,6 +72,7 @@ def record_object_after_deserialization(obj, obj_id):\n     SHARED_OBJECTS.id_to_obj_map[obj_id] = obj\n \n \n+@keras_export(\"keras.utils.serialize_keras_object\")\n def serialize_keras_object(obj):\n     \"\"\"Retrieve the config dict by serializing the Keras object.\n \n@@ -200,6 +202,7 @@ def serialize_dict(obj):\n     return {key: serialize_keras_object(value) for key, value in obj.items()}\n \n \n+@keras_export(\"keras.utils.deserialize_keras_object\")\n def deserialize_keras_object(config, custom_objects=None):\n     \"\"\"Retrieve the object by deserializing the config dict.\n \n\n@@ -21,7 +21,7 @@ import tensorflow.compat.v2 as tf\n from absl.testing import parameterized\n \n import keras\n-from keras.saving.experimental import serialization_lib\n+from keras.saving import serialization_lib\n from keras.saving.legacy import serialization\n from keras.testing_infra import test_utils\n \n\n@@ -27,7 +27,7 @@ import types as python_types\n import numpy as np\n import tensorflow.compat.v2 as tf\n \n-from keras.saving.experimental import serialization_lib\n+from keras.saving import serialization_lib\n from keras.utils import io_utils\n from keras.utils import tf_inspect\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f9688c69e29ded7809af1213909787d69a112e59", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 7 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -128,6 +128,8 @@ def serialize_keras_object(obj):\n             return obj.item()\n     if isinstance(obj, tf.DType):\n         return obj.name\n+    if isinstance(obj, tf.compat.v1.Dimension):\n+        return obj.value\n     if isinstance(obj, types.FunctionType) and obj.__name__ == \"<lambda>\":\n         return {\n             \"class_name\": \"__lambda__\",\n@@ -332,7 +334,7 @@ def deserialize_keras_object(config, custom_objects=None):\n         return inner_config[\"value\"].encode(\"utf-8\")\n     if config[\"class_name\"] == \"__lambda__\":\n         return generic_utils.func_load(inner_config[\"value\"])\n-    # TODO(fchollet): support for TypeSpec, CompositeTensor, tf.Dtype\n+    # TODO(fchollet): support for TypeSpec, CompositeTensor/RaggedTensor\n     # TODO(fchollet): consider special-casing tuples (which are currently\n     # deserialized as lists).\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5b4639ea7b3cdcc3da56443b2523dfb9f1b42a41", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 11 | Files Changed: 5 | Hunks: 11 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 20 | Churn Cumulative: 9421 | Contributors (this commit): 48 | Commits (past 90d): 50 | Contributors (cumulative): 62 | DMM Complexity: 1.0\n\nDIFF:\n@@ -31,9 +31,9 @@ import keras\n from keras import losses\n from keras.engine import base_layer\n from keras.optimizers import optimizer\n-from keras.saving.serialization_lib import ObjectSharingScope\n-from keras.saving.serialization_lib import deserialize_keras_object\n-from keras.saving.serialization_lib import serialize_keras_object\n+from keras.saving.experimental.serialization_lib import ObjectSharingScope\n+from keras.saving.experimental.serialization_lib import deserialize_keras_object\n+from keras.saving.experimental.serialization_lib import serialize_keras_object\n from keras.utils import generic_utils\n from keras.utils import io_utils\n \n\n@@ -26,7 +26,6 @@ from keras.utils import generic_utils\n \n # isort: off\n from tensorflow.python.util import tf_export\n-from tensorflow.python.util.tf_export import keras_export\n \n PLAIN_TYPES = (str, int, float, bool)\n SHARED_OBJECTS = threading.local()\n@@ -72,7 +71,6 @@ def record_object_after_deserialization(obj, obj_id):\n     SHARED_OBJECTS.id_to_obj_map[obj_id] = obj\n \n \n-@keras_export(\"keras.utils.serialize_keras_object\")\n def serialize_keras_object(obj):\n     \"\"\"Retrieve the config dict by serializing the Keras object.\n \n@@ -128,8 +126,6 @@ def serialize_keras_object(obj):\n             return obj.item()\n     if isinstance(obj, tf.DType):\n         return obj.name\n-    if isinstance(obj, tf.compat.v1.Dimension):\n-        return obj.value\n     if isinstance(obj, types.FunctionType) and obj.__name__ == \"<lambda>\":\n         return {\n             \"class_name\": \"__lambda__\",\n@@ -204,7 +200,6 @@ def serialize_dict(obj):\n     return {key: serialize_keras_object(value) for key, value in obj.items()}\n \n \n-@keras_export(\"keras.utils.deserialize_keras_object\")\n def deserialize_keras_object(config, custom_objects=None):\n     \"\"\"Retrieve the object by deserializing the config dict.\n \n@@ -334,7 +329,7 @@ def deserialize_keras_object(config, custom_objects=None):\n         return inner_config[\"value\"].encode(\"utf-8\")\n     if config[\"class_name\"] == \"__lambda__\":\n         return generic_utils.func_load(inner_config[\"value\"])\n-    # TODO(fchollet): support for TypeSpec, CompositeTensor/RaggedTensor\n+    # TODO(fchollet): support for TypeSpec, CompositeTensor, tf.Dtype\n     # TODO(fchollet): consider special-casing tuples (which are currently\n     # deserialized as lists).\n \n\n@@ -21,7 +21,7 @@ import tensorflow.compat.v2 as tf\n from absl.testing import parameterized\n \n import keras\n-from keras.saving import serialization_lib\n+from keras.saving.experimental import serialization_lib\n from keras.saving.legacy import serialization\n from keras.testing_infra import test_utils\n \n\n@@ -24,6 +24,7 @@ from keras.utils import tf_contextlib\n from keras.utils import tf_inspect\n \n # isort: off\n+from tensorflow.python.util.tf_export import keras_export\n \n # Flag that determines whether to skip the NotImplementedError when calling\n # get_config in custom models and layers. This is only enabled when saving to\n@@ -281,6 +282,7 @@ class CustomMaskWarning(Warning):\n     pass\n \n \n+@keras_export(\"keras.utils.serialize_keras_object\")\n def serialize_keras_object(instance):\n     \"\"\"Serialize a Keras object into a JSON-compatible representation.\n \n@@ -435,6 +437,7 @@ def class_and_config_for_serialized_keras_object(\n     return (cls, cls_config)\n \n \n+@keras_export(\"keras.utils.deserialize_keras_object\")\n def deserialize_keras_object(\n     identifier,\n     module_objects=None,\n\n@@ -27,7 +27,7 @@ import types as python_types\n import numpy as np\n import tensorflow.compat.v2 as tf\n \n-from keras.saving import serialization_lib\n+from keras.saving.experimental import serialization_lib\n from keras.utils import io_utils\n from keras.utils import tf_inspect\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c457f769cca3c8e090a33f2e80bbc13c07ad5ae4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 4026 | Contributors (this commit): 14 | Commits (past 90d): 4 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -429,7 +429,7 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n             \"vocabulary_dtype\": self.vocabulary_dtype,\n             \"idf_weights\": utils.listify_tensors(self.input_idf_weights),\n             \"vocabulary\": utils.listify_tensors(self.input_vocabulary),\n-            \"vocabulary_size\": self.vocabulary_size(),\n+            \"vocabulary_size\": self._frozen_vocab_size,\n         }\n         base_config = super().get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#356eaa8a7b035dcac2a565f9dde38201334f1c0c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 36 | Churn Cumulative: 36 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,36 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\r\n+#\r\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n+# you may not use this file except in compliance with the License.\r\n+# You may obtain a copy of the License at\r\n+#\r\n+#     http://www.apache.org/licenses/LICENSE-2.0\r\n+#\r\n+# Unless required by applicable law or agreed to in writing, software\r\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n+# See the License for the specific language governing permissions and\r\n+# limitations under the License.\r\n+# ==============================================================================\r\n+\"\"\"Contains the Identity layer.\"\"\"\r\n+\r\n+from keras.engine.base_layer import Layer\r\n+\r\n+# isort: off\r\n+from tensorflow.python.util.tf_export import keras_export\r\n+\r\n+\r\n+@keras_export(\"keras.layers.Identity\")\r\n+class Identity(Layer):\r\n+    \"\"\"Identity layer.\r\n+\r\n+    This layer should be used as a placeholder when no operation is to be\r\n+    performed. The layer is argument insensitive, and returns its `inputs`\r\n+    argument as output.\r\n+\r\n+    Args:\r\n+        name: Optional name for the layer instance.\r\n+    \"\"\"\r\n+\r\n+    def call(self, inputs):\r\n+        return inputs\r\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8e5f2292ac5541d7bef5de9d8f56c25ce36ada2b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 5 | Files Changed: 4 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): -67/0 | Churn Δ: 10 | Churn Cumulative: 8044 | Contributors (this commit): 48 | Commits (past 90d): 34 | Contributors (cumulative): 57 | DMM Complexity: None\n\nDIFF:\n@@ -31,9 +31,9 @@ import keras\n from keras import losses\n from keras.engine import base_layer\n from keras.optimizers import optimizer\n-from keras.saving.experimental.serialization_lib import ObjectSharingScope\n-from keras.saving.experimental.serialization_lib import deserialize_keras_object\n-from keras.saving.experimental.serialization_lib import serialize_keras_object\n+from keras.saving.serialization_lib import ObjectSharingScope\n+from keras.saving.serialization_lib import deserialize_keras_object\n+from keras.saving.serialization_lib import serialize_keras_object\n from keras.utils import generic_utils\n from keras.utils import io_utils\n \n\n\n@@ -21,7 +21,7 @@ import tensorflow.compat.v2 as tf\n from absl.testing import parameterized\n \n import keras\n-from keras.saving.experimental import serialization_lib\n+from keras.saving import serialization_lib\n from keras.saving.legacy import serialization\n from keras.testing_infra import test_utils\n \n\n@@ -27,7 +27,7 @@ import types as python_types\n import numpy as np\n import tensorflow.compat.v2 as tf\n \n-from keras.saving.experimental import serialization_lib\n+from keras.saving import serialization_lib\n from keras.utils import io_utils\n from keras.utils import tf_inspect\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#40074aec8ecf6a81cf91dc7fa2f837928a40840f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 4027 | Contributors (this commit): 14 | Commits (past 90d): 5 | Contributors (cumulative): 14 | DMM Complexity: 0.0\n\nDIFF:\n@@ -668,6 +668,7 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n             # compute a new vocabulary.\n             if self.output_mode == TF_IDF:\n                 self.idf_weights_const = self.idf_weights.value()\n+            self._record_vocabulary_size()\n             return\n \n         # Remove special tokens from our counts.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7a5e2ccd9435ba040806aeb5289618da31481c42", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 197 | Lines Deleted: 63 | Files Changed: 10 | Hunks: 43 | Methods Changed: 21 | Complexity Δ (Sum/Max): 26/10 | Churn Δ: 260 | Churn Cumulative: 43978 | Contributors (this commit): 159 | Commits (past 90d): 73 | Contributors (cumulative): 232 | DMM Complexity: 0.0\n\nDIFF:\n@@ -812,7 +812,13 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         # In this case the subclass doesn't implement get_config():\n         # Let's see if we can autogenerate it.\n         if getattr(self, \"_auto_get_config\", False):\n+            xtra_args = set(config.keys())\n             config.update(self._auto_config.config)\n+            # Remove args non explicitly supported\n+            argspec = tf_inspect.getfullargspec(self.__init__)\n+            if argspec.varkw != \"kwargs\":\n+                for key in xtra_args - xtra_args.intersection(argspec.args[1:]):\n+                    config.pop(key, None)\n             return config\n         else:\n             raise NotImplementedError(\n@@ -857,7 +863,13 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         Returns:\n             A layer instance.\n         \"\"\"\n+        try:\n             return cls(**config)\n+        except Exception as e:\n+            raise TypeError(\n+                f\"Error when deserializing class '{cls.__name__}' using \"\n+                f\"config={config}.\\n\\nException encountered: {e}\"\n+            )\n \n     def compute_output_shape(self, input_shape):\n         \"\"\"Computes the output shape of the layer.\n\n@@ -33,9 +33,11 @@ from keras.engine import input_spec\n from keras.engine import node as node_module\n from keras.engine import training as training_lib\n from keras.engine import training_utils\n+from keras.saving.experimental import saving_lib\n from keras.saving.legacy import serialization\n from keras.saving.legacy.saved_model import json_utils\n from keras.saving.legacy.saved_model import network_serialization\n+from keras.saving.legacy.saved_model import utils as saved_model_utils\n from keras.utils import generic_utils\n from keras.utils import tf_inspect\n from keras.utils import tf_utils\n@@ -761,11 +763,43 @@ class Functional(training_lib.Model):\n \n         return tensor\n \n+    @generic_utils.default\n     def get_config(self):\n-        # Continue adding configs into what the super class has added.\n+        if saved_model_utils.in_tf_saved_model_scope():\n+            # SavedModel special case: need to preserve legacy (potentially\n+            # incorrect) behavior.\n             config = super().get_config()\n             return copy.deepcopy(get_network_config(self, config=config))\n \n+        # Prepare base arguments\n+        config = {\n+            \"name\": self.name,\n+            \"trainable\": self.trainable,\n+        }\n+        # Check whether the class has a constructor compatible with a Functional\n+        # model or if it has a custom constructor.\n+        if has_functional_like_constructor(self.__class__):\n+            # Only return a Functional config if the constructor is the same\n+            # as that of a Functional model. This excludes subclassed Functional\n+            # models with a custom __init__.\n+            config = copy.deepcopy(get_network_config(self, config=config))\n+        else:\n+            # Try to autogenerate config\n+            xtra_args = set(config.keys())\n+            if getattr(self, \"_auto_get_config\", False):\n+                config.update(self._auto_config.config)\n+            # Remove args non explicitly supported\n+            argspec = tf_inspect.getfullargspec(self.__init__)\n+            if argspec.varkw != \"kwargs\":\n+                for key in xtra_args - xtra_args.intersection(argspec.args[1:]):\n+                    config.pop(key, None)\n+\n+        # Add compile config\n+        if saving_lib.saving_v3_enabled():\n+            if self._is_compiled and hasattr(self, \"_compile_config\"):\n+                config[\"compile_config\"] = self._compile_config.serialize()\n+        return config\n+\n     def get_weight_paths(self):\n         result = {}\n         for layer in self.layers:\n@@ -1647,3 +1681,13 @@ class ModuleWrapper(base_layer.Layer):\n         if \"mask\" in kwargs and not self._expects_mask_arg:\n             kwargs.pop(\"mask\")\n         return getattr(self._module, self._method_name)(*args, **kwargs)\n+\n+\n+def has_functional_like_constructor(cls):\n+    init_args = tf_inspect.getfullargspec(cls.__init__).args[1:]\n+    functional_init_args = tf_inspect.getfullargspec(Functional.__init__).args[\n+        1:\n+    ]\n+    if init_args == functional_init_args:\n+        return True\n+    return False\n\n@@ -3003,7 +3003,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         # otherwise default to empty dict\n         if generic_utils.is_default(self.get_config):\n             try:\n-                config = super().get_config()\n+                config = base_layer.Layer.get_config(self)\n             except NotImplementedError:\n                 config = {}\n                 logging.warning(\n@@ -3012,12 +3012,6 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                     \"subclassed Model for proper saving and loading. \"\n                     \"Defaulting to empty config.\"\n                 )\n-            # `super.get_config` adds additional keys, keep them if they\n-            # are explicitly specified in `__init__`\n-            init_args = tf_inspect.getfullargspec(self.__init__).args[1:]\n-            xtra_args = set([\"name\", \"trainable\", \"dtype\", \"batch_input_shape\"])\n-            for key in xtra_args - xtra_args.intersection(init_args):\n-                config.pop(key, None)\n         else:\n             config = {}\n         return config\n@@ -3031,13 +3025,27 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         from keras.engine import functional\n \n         with serialization.SharedObjectLoadingScope():\n-            functional_model_keys = [\n+            functional_config_keys = [\n                 \"name\",\n                 \"layers\",\n                 \"input_layers\",\n                 \"output_layers\",\n             ]\n-            if all(key in config for key in functional_model_keys):\n+            is_functional_config = all(\n+                key in config for key in functional_config_keys\n+            )\n+            argspec = tf_inspect.getfullargspec(cls.__init__)\n+            functional_init_args = tf_inspect.getfullargspec(\n+                functional.Functional.__init__\n+            ).args[1:]\n+            revivable_as_functional = (\n+                cls in {functional.Functional, Model}\n+                or argspec.args[1:] == functional_init_args\n+                or (argspec.varargs == \"args\" and argspec.varkw == \"kwargs\")\n+            )\n+            if is_functional_config and revivable_as_functional:\n+                # Revive Functional model\n+                # (but not Functional subclasses with a custom __init__)\n                 inputs, outputs, layers = functional.reconstruct_from_config(\n                     config, custom_objects\n                 )\n@@ -3047,7 +3055,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                 functional.connect_ancillary_layers(model, layers)\n \n             else:\n-                # The config does not contain all the information necessary to\n+                # Either the model has a custom __init__, or the config\n+                # does not contain all the information necessary to\n                 # revive a Functional model. This happens when the user creates\n                 # subclassed models where `get_config()` is returning\n                 # insufficient information to be considered a Functional model.\n@@ -3058,13 +3067,16 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                 except TypeError as e:\n                     raise TypeError(\n                         \"Unable to revive model from config. When overriding \"\n-                        \"the `get_config()`, make sure that the returned \"\n-                        \"config contains all items used as arguments in the \"\n-                        f\"constructor to {cls}, which is the default behavior. \"\n+                        \"the `get_config()` method, make sure that the \"\n+                        \"returned config contains all items used as arguments \"\n+                        f\"in the  constructor to {cls}, \"\n+                        \"which is the default behavior. \"\n                         \"You can override this default behavior by defining a \"\n-                        \"`from_config` method to specify how to create an \"\n+                        \"`from_config(cls, config)` class method to specify \"\n+                        \"how to create an \"\n                         f\"instance of {cls.__name__} from the config.\\n\\n\"\n-                        f\"Error encountered during deserialization:\\n{e}\"\n+                        f\"Received config={config}\\n\\n\"\n+                        f\"Error encountered during deserialization: {e}\"\n                     )\n             return model\n \n\n@@ -1035,7 +1035,9 @@ class TrainingTest(test_combinations.TestCase):\n \n         model = MyModel(10, extra=1)\n         config = model.get_config()\n-        self.assertLen(config, 2)\n+        # config = {'name': 'my_model', 'trainable': True, 'dtype': 'float32',\n+        # 'extra': 1, 'units': 10}\n+        self.assertLen(config, 5)\n         self.assertEqual(config[\"units\"], 10)\n         self.assertEqual(config[\"extra\"], 1)\n         model = model.from_config(config)\n\n@@ -159,6 +159,9 @@ def _clone_functional_model(model, input_tensors=None, layer_fn=_clone_layer):\n         ValueError: in case of invalid `model` argument value or `layer_fn`\n         argument value.\n     \"\"\"\n+    if layer_fn is None:\n+        layer_fn = _clone_layer\n+\n     if not isinstance(model, Model):\n         raise ValueError(\n             \"Expected `model` argument \"\n@@ -218,11 +221,22 @@ def _clone_functional_model(model, input_tensors=None, layer_fn=_clone_layer):\n         model_configs, created_layers=created_layers\n     )\n     metrics_names = model.metrics_names\n-    model = Model(input_tensors, output_tensors, name=model.name)\n+    if functional.has_functional_like_constructor(model.__class__):\n+        new_model = model.__class__(\n+            input_tensors, output_tensors, name=model.name\n+        )\n+    else:\n+        # This may be incorrect: the new model will end up having a different\n+        # class than the original. However various existing models rely\n+        # on this behavior, so we keep it.\n+        new_model = Model(input_tensors, output_tensors, name=model.name)\n+\n     # Layers not directly tied to outputs of the Model, such as loss layers\n     # created in `add_loss` and `add_metric`.\n     ancillary_layers = [\n-        layer for layer in created_layers.values() if layer not in model.layers\n+        layer\n+        for layer in created_layers.values()\n+        if layer not in new_model.layers\n     ]\n     # TODO(b/162887610): This may need to adjust the inbound node index if the\n     # created layers had already been used to define other models.\n@@ -236,9 +250,9 @@ def _clone_functional_model(model, input_tensors=None, layer_fn=_clone_layer):\n             ]\n         )\n         _insert_ancillary_layers(\n-            model, ancillary_layers, metrics_names, new_nodes\n+            new_model, ancillary_layers, metrics_names, new_nodes\n         )\n-    return model\n+    return new_model\n \n \n def _clone_layers_and_model_config(model, input_layers, layer_fn):\n@@ -334,6 +348,9 @@ def _clone_sequential_model(model, input_tensors=None, layer_fn=_clone_layer):\n         ValueError: in case of invalid `model` argument value or `layer_fn`\n         argument value.\n     \"\"\"\n+    if layer_fn is None:\n+        layer_fn = _clone_layer\n+\n     if not isinstance(model, Sequential):\n         raise ValueError(\n             \"Expected `model` argument \"\n@@ -495,18 +512,37 @@ def clone_model(model, input_tensors=None, clone_function=None):\n     ```\n     \"\"\"\n     with serialization.DisableSharedObjectScope():\n-        if clone_function is None:\n-            clone_function = _clone_layer\n-\n         if isinstance(model, Sequential):\n             return _clone_sequential_model(\n                 model, input_tensors=input_tensors, layer_fn=clone_function\n             )\n-        else:\n+        if isinstance(model, functional.Functional):\n+            # If the get_config() method is the same as a regular Functional\n+            # model, we're safe to use _clone_functional_model (which relies\n+            # on a Functional constructor). In the case where the get_config\n+            # is custom, this may not necessarily work, but if clone_function\n+            # or input_tensors are passed, we attempt it anyway\n+            # in order to preserve backwards compatibility.\n+            if generic_utils.is_default(model.get_config) or (\n+                clone_function or input_tensors\n+            ):\n                 return _clone_functional_model(\n                     model, input_tensors=input_tensors, layer_fn=clone_function\n                 )\n \n+        # Case of a custom model class\n+        if clone_function or input_tensors:\n+            raise ValueError(\n+                \"Arguments clone_function and input_tensors \"\n+                \"are only supported for Sequential models \"\n+                \"or Functional models. Received model of \"\n+                f\"type '{model.__class__.__name__}', with \"\n+                f\"clone_function={clone_function} and \"\n+                f\"input_tensors={input_tensors}\"\n+            )\n+        # Note that a custom object scope may be required in this case.\n+        return model.__class__.from_config(model.get_config())\n+\n \n # \"Clone\" a subclassed model by resetting all of the attributes.\n def _in_place_subclassed_model_reset(model):\n\n@@ -584,6 +584,7 @@ class KerasObjectLoader:\n         if not serialization.validate_config(config):\n             return None\n \n+        try:\n             try:\n                 obj = layers_module.deserialize(\n                     serialization.serialize_keras_class_and_config(\n@@ -592,23 +593,26 @@ class KerasObjectLoader:\n                 )\n             except (TypeError, KeyError) as e:\n                 # A name conflict has occurred. The `class_name` is in the Keras\n-            # native framework; however, the value in the framework is different\n-            # from the user's class definition which confuses the\n+                # native framework; however, the value in the framework is\n+                # different from the user's class definition which confuses the\n                 # KerasObjectLoader.\n                 builtin_layer = layers_module.get_builtin_layer(class_name)\n                 if builtin_layer:\n                     raise RuntimeError(\n-                    f\"Unable to restore object of class '{class_name}' likely \"\n-                    \"due to name conflict with built-in Keras class \"\n-                    f\"'{builtin_layer}'. To override the built-in Keras \"\n-                    \"definition of the object, decorate your class with \"\n-                    \"`@keras.utils.register_keras_serializable` and include \"\n-                    \"that file in your program, or pass your class in a \"\n-                    \"`keras.utils.CustomObjectScope` that wraps this load call.\"\n+                        f\"Unable to restore object of class '{class_name}'. \"\n+                        \"One of several possible causes could be \"\n+                        \"a missing custom object. \"\n+                        \"Decorate your custom object with \"\n+                        \"`@keras.utils.register_keras_serializable` and \"\n+                        \"include that file in your program, \"\n+                        \"or pass your class in a \"\n+                        \"`keras.utils.CustomObjectScope` \"\n+                        \"that wraps this load call. \"\n+                        f\"\\n\\nException: {e}\"\n                     ) from e\n                 else:\n                     raise\n-        except ValueError as e:\n+        except Exception as e:\n             if must_restore_from_config:\n                 raise e\n             else:\n\n@@ -397,7 +397,7 @@ class TestModelRevive(ReviveTestBase):\n     def test_functional_subclass_wrong_config(self):\n         model = FunctionalSubclassModelWrongConfig(32)\n         model.save(self.path, save_format=\"tf\")\n-        with self.assertRaisesRegex(TypeError, \"Unable to revive model\"):\n+        with self.assertRaisesRegex(TypeError, \"required positional arguments\"):\n             keras_load.load(self.path, compile=False)\n \n     def test_load_compiled_metrics(self):\n@@ -435,18 +435,6 @@ class TestModelRevive(ReviveTestBase):\n             revived._get_save_spec(dynamic_batch=False),\n         )\n \n-    def test_load_model_with_name_conflict_raises_error(self):\n-        class LinearModel(SubclassedModelWithConfig):\n-            pass\n-\n-        model = LinearModel(2, 3)\n-        model(np.random.random((5, 10)).astype(np.float32))\n-        model.save(self.path, save_format=\"tf\")\n-        with self.assertRaisesRegex(\n-            RuntimeError, \"Unable to restore object of class 'LinearModel'\"\n-        ):\n-            keras_load.load(self.path, compile=True)\n-\n     def test_load_model_with_name_conflict_registered_works(self):\n         model = WideDeepModel(2, 3)\n         model(np.random.random((5, 10)).astype(np.float32))\n\n@@ -1171,16 +1171,6 @@ class TestSavedModelFormat(tf.test.TestCase):\n         self.assertAllEqual([[1.0]], self.evaluate(loaded.layer(inp)))\n         self.assertIsInstance(loaded.layer, CustomLayer)\n \n-        # If the symbol is no longer available, loading should raise an error.\n-        del CustomLayer\n-        with object_registration.custom_object_scope({\"Model\": Model}):\n-            with self.assertRaisesRegex(\n-                NameError,\n-                \"free variable 'CustomLayer' referenced \"\n-                \"before assignment in enclosing scope\",\n-            ):\n-                loaded = keras_load.load(saved_model_dir)\n-\n     def test_save_without_tracing(self):\n         class DoNotTrace(keras.layers.Layer):\n             def __init__(self):\n\n@@ -228,19 +228,23 @@ class SaveOptionsContext(threading.local):\n     def __init__(self):\n         super().__init__()\n         self.save_traces = True\n+        self.in_tf_saved_model_scope = False\n \n \n _save_options_context = SaveOptionsContext()\n \n \n @tf_contextlib.contextmanager\n-def keras_option_scope(save_traces):\n-    previous_value = _save_options_context.save_traces\n+def keras_option_scope(save_traces, in_tf_saved_model_scope=True):\n+    save_traces_previous_value = _save_options_context.save_traces\n+    in_scope_previous_value = _save_options_context.in_tf_saved_model_scope\n     try:\n         _save_options_context.save_traces = save_traces\n+        _save_options_context.in_tf_saved_model_scope = in_tf_saved_model_scope\n         yield\n     finally:\n-        _save_options_context.save_traces = previous_value\n+        _save_options_context.save_traces = save_traces_previous_value\n+        _save_options_context.in_tf_saved_model_scope = in_scope_previous_value\n \n \n def should_save_traces():\n@@ -249,6 +253,10 @@ def should_save_traces():\n     return _save_options_context.save_traces\n \n \n+def in_tf_saved_model_scope():\n+    return _save_options_context.in_tf_saved_model_scope\n+\n+\n @tf_contextlib.contextmanager\n def no_automatic_dependency_tracking_scope(obj):\n     \"\"\"Context that disables automatic dependency tracking when assigning attrs.\n\n@@ -22,7 +22,7 @@ from absl.testing import parameterized\n \n import keras\n from keras.saving import serialization_lib\n-from keras.saving.legacy import serialization\n+from keras.saving.legacy import serialization as legacy_serialization\n from keras.testing_infra import test_utils\n \n \n@@ -195,6 +195,44 @@ class SerializationLibTest(tf.test.TestCase, parameterized.TestCase):\n         self.assertIs(model.layers[2], model.layers[3].layer)\n         self.assertIs(new_model.layers[2], new_model.layers[3].layer)\n \n+    def test_functional_subclass(self):\n+        class PlainFunctionalSubclass(keras.Model):\n+            pass\n+\n+        inputs = keras.Input((2,))\n+        outputs = keras.layers.Dense(1)(inputs)\n+        model = PlainFunctionalSubclass(inputs, outputs)\n+        x = tf.random.normal((2, 2))\n+        y1 = model(x)\n+        _, new_model, _ = self.roundtrip(\n+            model,\n+            custom_objects={\"PlainFunctionalSubclass\": PlainFunctionalSubclass},\n+        )\n+        new_model.set_weights(model.get_weights())\n+        y2 = new_model(x)\n+        self.assertAllClose(y1, y2, atol=1e-5)\n+        self.assertIsInstance(new_model, PlainFunctionalSubclass)\n+\n+        class FunctionalSubclassWCustomInit(keras.Model):\n+            def __init__(self, num_units=1, **kwargs):\n+                inputs = keras.Input((2,))\n+                outputs = keras.layers.Dense(num_units)(inputs)\n+                super().__init__(inputs, outputs)\n+\n+        model = FunctionalSubclassWCustomInit(num_units=2)\n+        x = tf.random.normal((2, 2))\n+        y1 = model(x)\n+        _, new_model, _ = self.roundtrip(\n+            model,\n+            custom_objects={\n+                \"FunctionalSubclassWCustomInit\": FunctionalSubclassWCustomInit\n+            },\n+        )\n+        new_model.set_weights(model.get_weights())\n+        y2 = new_model(x)\n+        self.assertAllClose(y1, y2, atol=1e-5)\n+        self.assertIsInstance(new_model, FunctionalSubclassWCustomInit)\n+\n     def test_shared_object(self):\n         class MyLayer(keras.layers.Layer):\n             def __init__(self, activation, **kwargs):\n@@ -249,7 +287,7 @@ class SerializationLibTest(tf.test.TestCase, parameterized.TestCase):\n @test_utils.run_v2_only\n class BackwardsCompatibilityTest(tf.test.TestCase, parameterized.TestCase):\n     def assert_old_format_can_be_deserialized(self, obj, custom_objects=None):\n-        old_config = serialization.serialize_keras_object(obj)\n+        old_config = legacy_serialization.serialize_keras_object(obj)\n         revived = serialization_lib.deserialize_keras_object(\n             old_config, custom_objects=custom_objects\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
