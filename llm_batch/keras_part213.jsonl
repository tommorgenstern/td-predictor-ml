{"custom_id": "keras#b5612acd748b90dc5853cd11f357536a20dba1ec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1302 | Contributors (this commit): 18 | Commits (past 90d): 10 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -369,7 +369,7 @@ def get_class_signature(cls):\n \n \n def post_process_signature(signature):\n-    parts = signature.split('.')\n+    parts = re.split('\\.(?!\\d)', signature)\n     if len(parts) >= 4:\n         if parts[1] == 'layers':\n             signature = 'keras.layers.' + '.'.join(parts[3:])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#91ad52244a7d4670b9569f46c857020eda1d0dc7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 2775 | Contributors (this commit): 13 | Commits (past 90d): 20 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -460,10 +460,6 @@ def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n             stddev, seed=seed), dtype=dtype)\n \n \n-def zeros_like(x, dtype=None, name=None):\n-    return x * 0\n-\n-\n def dtype(x):\n     return _convert_dtype_string(x.dtype)\n \n@@ -488,7 +484,11 @@ def eye(size, dtype=None, name=None):\n     return variable(np.eye(size), dtype, name)\n \n \n-def ones_like(x, name=None):\n+def zeros_like(x, dtype=None, name=None):\n+    return x * 0\n+\n+\n+def ones_like(x, dtype=None, name=None):\n     return zeros_like(x) + 1\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e35b455c3a8b12e26d03502346e7156281fd2d7d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 1964 | Contributors (this commit): 15 | Commits (past 90d): 6 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -378,8 +378,7 @@ class Concatenate(_Merge):\n         for input_i, mask_i in zip(inputs, mask):\n             if mask_i is None:\n                 # Input is unmasked. Append all 1s to masks,\n-                # but cast it to bool first\n-                masks.append(K.cast(K.ones_like(input_i), 'bool'))\n+                masks.append(K.ones_like(input_i, dtype='bool'))\n             elif K.ndim(mask_i) < K.ndim(input_i):\n                 # Mask is smaller than the input, expand it\n                 masks.append(K.expand_dims(mask_i))\n\n@@ -300,8 +300,7 @@ class Merge(Layer):\n             for input_i, mask_i in zip(inputs, mask):\n                 if mask_i is None:\n                     # Input is unmasked. Append all 1s to masks,\n-                    # but cast it to bool first\n-                    masks.append(K.cast(K.ones_like(input_i), 'bool'))\n+                    masks.append(K.ones_like(input_i, dtype='bool'))\n                 elif K.ndim(mask_i) < K.ndim(input_i):\n                     # Mask is smaller than the input, expand it\n                     masks.append(K.expand_dims(mask_i))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e87384eddf463e4cf4a7f4f3e881634fafc480ee", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 8952 | Contributors (this commit): 92 | Commits (past 90d): 29 | Contributors (cumulative): 92 | DMM Complexity: 1.0\n\nDIFF:\n@@ -725,7 +725,10 @@ def eye(size, dtype=None, name=None):\n     ```\n \n     \"\"\"\n-    return variable(np.eye(size), dtype, name)\n+    if dtype is None:\n+        dtype = floatx()\n+    tf_dtype = tf.as_dtype(dtype)\n+    return variable(tf.eye(size, dtype=tf_dtype), dtype, name)\n \n \n def zeros_like(x, dtype=None, name=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3b15ee6954b688b9490fd885d628939fd35f76ca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 6 | Files Changed: 3 | Hunks: 7 | Methods Changed: 6 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 16 | Churn Cumulative: 17136 | Contributors (this commit): 116 | Commits (past 90d): 67 | Contributors (cumulative): 184 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2131,8 +2131,10 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n     return _postprocess_conv2d_output(x, data_format)\n \n \n-def identity(x):\n-    return C.alias(x, name=('%s_alias' % (x.name)))\n+def identity(x, name=None):\n+    if name is None:\n+        name = '%s_alias' % x.name\n+    return C.alias(x, name=name)\n \n \n def _preprocess_conv2d_input(x, data_format):\n\n@@ -781,16 +781,17 @@ def ones_like(x, dtype=None, name=None):\n     return tf.ones_like(x, dtype=dtype, name=name)\n \n \n-def identity(x):\n+def identity(x, name=None):\n     \"\"\"Returns a tensor with the same content as the input tensor.\n \n     # Arguments\n         x: The input tensor.\n+        name: String, name for the variable to create.\n \n     # Returns\n         A tensor of the same shape, type and content.\n     \"\"\"\n-    return tf.identity(x)\n+    return tf.identity(x, name)\n \n \n def random_uniform_variable(shape, low, high, dtype=None,\n\n@@ -321,16 +321,17 @@ def zeros_like(x, dtype=None, name=None):\n     return T.zeros_like(x, dtype=dtype)\n \n \n-def identity(x):\n+def identity(x, name=None):\n     \"\"\"Returns a tensor with the same content as the input tensor.\n \n     # Arguments\n         x: The input tensor.\n+        name: String, name for the variable to create.\n \n     # Returns\n         A tensor of the same shape, type and content.\n     \"\"\"\n-    return x.copy()\n+    return x.copy(name=name)\n \n \n def random_uniform_variable(shape, low, high, dtype=None, name=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5b7cbb731bba20f77b341a203aecebbb9acc6e49", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 1072 | Contributors (this commit): 11 | Commits (past 90d): 9 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -315,6 +315,7 @@ class Sequence(object):\n         from skimage.io import imread\n         from skimage.transform import resize\n         import numpy as np\n+        import math\n \n         # Here, `x_set` is list of path to the images\n         # and `y_set` are the associated classes.\n@@ -326,7 +327,7 @@ class Sequence(object):\n                 self.batch_size = batch_size\n \n             def __len__(self):\n-                return len(self.x) // self.batch_size\n+                return math.ceil(len(self.x) / self.batch_size)\n \n             def __getitem__(self, idx):\n                 batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3077f277daa5f71a3d51f5217d367e08ab09a550", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 5 | Churn Cumulative: 8962 | Contributors (this commit): 92 | Commits (past 90d): 31 | Contributors (cumulative): 92 | DMM Complexity: 0.0\n\nDIFF:\n@@ -279,10 +279,7 @@ def _to_tensor(x, dtype):\n     # Returns\n         A tensor.\n     \"\"\"\n-    x = tf.convert_to_tensor(x)\n-    if x.dtype != dtype:\n-        x = tf.cast(x, dtype)\n-    return x\n+    return tf.convert_to_tensor(x, dtype=dtype)\n \n \n def is_sparse(tensor):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#13876a1548e1183c4cc534226151891f9644642a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2634 | Contributors (this commit): 43 | Commits (past 90d): 14 | Contributors (cumulative): 43 | DMM Complexity: None\n\nDIFF:\n@@ -1104,7 +1104,7 @@ class DirectoryIterator(Iterator):\n                 img = array_to_img(batch_x[i], self.data_format, scale=True)\n                 fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n                                                                   index=j,\n-                                                                  hash=np.random.randint(1e4),\n+                                                                  hash=np.random.randint(1e7),\n                                                                   format=self.save_format)\n                 img.save(os.path.join(self.save_to_dir, fname))\n         # build batch of labels\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b1d298a1260d620e3fff873d19d7ca22d832e88e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 59 | Lines Deleted: 20 | Files Changed: 2 | Hunks: 7 | Methods Changed: 4 | Complexity Δ (Sum/Max): 13/13 | Churn Δ: 79 | Churn Cumulative: 2226 | Contributors (this commit): 36 | Commits (past 90d): 20 | Contributors (cumulative): 40 | DMM Complexity: 0.0\n\nDIFF:\n@@ -406,31 +406,70 @@ def code_snippet(snippet):\n     return result\n \n \n-def process_class_docstring(docstring):\n+def count_leading_spaces(s):\n+    ws = re.search('\\S', s)\n+    if ws:\n+        return ws.start()\n+    else:\n+        return 0\n+\n+\n+def process_docstring(docstring):\n+    # First, extract code blocks and process them.\n+    code_blocks = []\n+    if '```' in docstring:\n+        tmp = docstring[:]\n+        while '```' in tmp:\n+            tmp = tmp[tmp.find('```'):]\n+            index = tmp[3:].find('```') + 6\n+            snippet = tmp[:index]\n+            # Place marker in docstring for later reinjection.\n+            docstring = docstring.replace(\n+                snippet, '$CODE_BLOCK_%d' % len(code_blocks))\n+            snippet_lines = snippet.split('\\n')\n+            # Remove leading spaces.\n+            num_leading_spaces = snippet_lines[-1].find('`')\n+            snippet_lines = ([snippet_lines[0]] +\n+                             [line[num_leading_spaces:]\n+                             for line in snippet_lines[1:]])\n+            # Most code snippets have 3 or 4 more leading spaces\n+            # on inner lines, but not all. Remove them.\n+            inner_lines = snippet_lines[1:-1]\n+            leading_spaces = None\n+            for line in inner_lines:\n+                if not line or line[0] == '\\n':\n+                    continue\n+                spaces = count_leading_spaces(line)\n+                if leading_spaces is None:\n+                    leading_spaces = spaces\n+                if spaces < leading_spaces:\n+                    leading_spaces = spaces\n+            if leading_spaces:\n+                snippet_lines = ([snippet_lines[0]] +\n+                                 [line[leading_spaces:]\n+                                  for line in snippet_lines[1:-1]] +\n+                                 [snippet_lines[-1]])\n+            snippet = '\\n'.join(snippet_lines)\n+            code_blocks.append(snippet)\n+            tmp = tmp[index:]\n+\n+    # Format docstring section titles.\n     docstring = re.sub(r'\\n(\\s+)# (.*)\\n',\n                        r'\\n\\1__\\2__\\n\\n',\n                        docstring)\n+    # Format docstring lists.\n     docstring = re.sub(r'    ([^\\s\\\\\\(]+):(.*)\\n',\n                        r'    - __\\1__:\\2\\n',\n                        docstring)\n \n-    docstring = docstring.replace('    ' * 5, '\\t\\t')\n-    docstring = docstring.replace('    ' * 3, '\\t')\n-    docstring = docstring.replace('    ', '')\n-    return docstring\n+    # Strip all leading spaces.\n+    lines = docstring.split('\\n')\n+    docstring = '\\n'.join([line.lstrip(' ') for line in lines])\n \n-\n-def process_function_docstring(docstring):\n-    docstring = re.sub(r'\\n(\\s+)# (.*)\\n',\n-                       r'\\n\\1__\\2__\\n\\n',\n-                       docstring)\n-    docstring = re.sub(r'    ([^\\s\\\\\\(]+):(.*)\\n',\n-                       r'    - __\\1__:\\2\\n',\n-                       docstring)\n-\n-    docstring = docstring.replace('    ' * 6, '\\t\\t')\n-    docstring = docstring.replace('    ' * 4, '\\t')\n-    docstring = docstring.replace('    ', '')\n+    # Reinject code blocks.\n+    for i, code_block in enumerate(code_blocks):\n+        docstring = docstring.replace(\n+            '$CODE_BLOCK_%d' % i, code_block)\n     return docstring\n \n print('Cleaning up existing sources directory.')\n@@ -483,7 +522,7 @@ for page_data in PAGES:\n         subblocks.append(code_snippet(signature))\n         docstring = cls.__doc__\n         if docstring:\n-            subblocks.append(process_class_docstring(docstring))\n+            subblocks.append(process_docstring(docstring))\n         blocks.append('\\n'.join(subblocks))\n \n     functions = page_data.get('functions', [])\n@@ -509,7 +548,7 @@ for page_data in PAGES:\n         subblocks.append(code_snippet(signature))\n         docstring = function.__doc__\n         if docstring:\n-            subblocks.append(process_function_docstring(docstring))\n+            subblocks.append(process_docstring(docstring))\n         blocks.append('\\n\\n'.join(subblocks))\n \n     if not blocks:\n\n@@ -24,7 +24,7 @@ class CustomObjectScope(object):\n \n     # Example\n \n-    Consider a custom object `MyObject`\n+    Consider a custom object `MyObject` (e.g. a class):\n \n     ```python\n         with CustomObjectScope({'MyObject':MyObject}):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7d63ae6f7861d01f8feb1d0ab5df9b5f04d80658", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 194 | Contributors (this commit): 5 | Commits (past 90d): 2 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -13,7 +13,7 @@ def load_data():\n         Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n     \"\"\"\n     dirname = 'cifar-10-batches-py'\n-    origin = 'http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n+    origin = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n     path = get_file(dirname, origin=origin, untar=True)\n \n     num_train_samples = 50000\n\n@@ -22,7 +22,7 @@ def load_data(label_mode='fine'):\n         raise ValueError('`label_mode` must be one of `\"fine\"`, `\"coarse\"`.')\n \n     dirname = 'cifar-100-python'\n-    origin = 'http://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz'\n+    origin = 'https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz'\n     path = get_file(dirname, origin=origin, untar=True)\n \n     fpath = os.path.join(path, 'train')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d368dc870bfd8fdd4ca0ff82bd5b61aa549291c5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 902 | Contributors (this commit): 14 | Commits (past 90d): 7 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -14,7 +14,7 @@ from keras.preprocessing.image import ImageDataGenerator\n from keras.models import Sequential\n from keras.layers import Dense, Dropout, Activation, Flatten\n from keras.layers import Conv2D, MaxPooling2D\n-\n+import numpy as np\n import os\n \n batch_size = 32\n@@ -100,7 +100,7 @@ else:\n     # Fit the model on the batches generated by datagen.flow().\n     model.fit_generator(datagen.flow(x_train, y_train,\n                                      batch_size=batch_size),\n-                        steps_per_epoch=x_train.shape[0] // batch_size,\n+                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),\n                         epochs=epochs,\n                         validation_data=(x_test, y_test),\n                         workers=4)\n\n@@ -181,7 +181,7 @@ else:\n \n     # Fit the model on the batches generated by datagen.flow().\n     model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n-                        steps_per_epoch=x_train.shape[0] // batch_size,\n+                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),\n                         validation_data=(x_test, y_test),\n                         epochs=epochs, verbose=1, workers=4,\n                         callbacks=callbacks)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#159bb1aac17a8de0f96997d35703b8f26926a848", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 19 | Churn Cumulative: 9627 | Contributors (this commit): 49 | Commits (past 90d): 13 | Contributors (cumulative): 58 | DMM Complexity: 0.5\n\nDIFF:\n@@ -1803,10 +1803,15 @@ class LSTMCell(Layer):\n                 inputs_f = inputs\n                 inputs_c = inputs\n                 inputs_o = inputs\n-            x_i = K.dot(inputs_i, self.kernel_i) + self.bias_i\n-            x_f = K.dot(inputs_f, self.kernel_f) + self.bias_f\n-            x_c = K.dot(inputs_c, self.kernel_c) + self.bias_c\n-            x_o = K.dot(inputs_o, self.kernel_o) + self.bias_o\n+            x_i = K.dot(inputs_i, self.kernel_i)\n+            x_f = K.dot(inputs_f, self.kernel_f)\n+            x_c = K.dot(inputs_c, self.kernel_c)\n+            x_o = K.dot(inputs_o, self.kernel_o)\n+            if self.use_bias:\n+                x_i = K.bias_add(x_i, self.bias_i)\n+                x_f = K.bias_add(x_f, self.bias_f)\n+                x_c = K.bias_add(x_c, self.bias_c)\n+                x_o = K.bias_add(x_o, self.bias_o)\n \n             if 0 < self.recurrent_dropout < 1.:\n                 h_tm1_i = h_tm1 * rec_dp_mask[0]\n\n@@ -183,6 +183,12 @@ def test_implementation_mode(layer_class):\n                            'dropout': 0.1,\n                            'recurrent_dropout': 0.1},\n                    input_shape=(num_samples, timesteps, embedding_dim))\n+        # Without bias\n+        layer_test(layer_class,\n+                   kwargs={'units': units,\n+                           'implementation': mode,\n+                           'use_bias': False},\n+                   input_shape=(num_samples, timesteps, embedding_dim))\n \n \n @rnn_test\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7230b002163e9204ab7aa930f8e76980cfdd445f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 113 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 113 | Churn Cumulative: 113 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,113 @@\n+'''MNIST classification with TensorFlow's Dataset API.\n+\n+Introduced in TensorFlow 1.3, the Dataset API is now the\n+standard method for loading data into TensorFlow models.\n+A Dataset is a sequence of elements, which are themselves\n+composed of tf.Tensor components. For more details, see:\n+https://www.tensorflow.org/programmers_guide/datasets\n+\n+To use this with Keras, we make a dataset out of elements\n+of the form (input batch, output batch). From there, we\n+create a one-shot iterator and a graph node corresponding\n+to its get_next() method. Its components are then provided\n+to the network's Input layer and the Model.compile() method,\n+respectively.\n+\n+Note that from TensorFlow 1.4, tf.contrib.data is deprecated\n+and tf.data is preferred. See the release notes for details.\n+\n+This example is intended to closely follow the\n+mnist_tfrecord.py example.\n+'''\n+from __future__ import division\n+\n+import numpy as np\n+import os\n+import tempfile\n+\n+import keras\n+from keras import backend as K\n+from keras import layers\n+from keras.datasets import mnist\n+\n+import tensorflow as tf\n+from tensorflow.contrib.data import Dataset\n+\n+\n+if K.backend() != 'tensorflow':\n+    raise RuntimeError('This example can only run with the TensorFlow backend,'\n+                       ' because it requires the Datset API, which is not'\n+                       ' supported on other platforms.')\n+\n+\n+def cnn_layers(inputs):\n+    x = layers.Conv2D(32, (3, 3),\n+                      activation='relu', padding='valid')(inputs)\n+    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n+    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n+    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n+    x = layers.Flatten()(x)\n+    x = layers.Dense(512, activation='relu')(x)\n+    x = layers.Dropout(0.5)(x)\n+    predictions = layers.Dense(classes,\n+                               activation='softmax',\n+                               name='x_train_out')(x)\n+    return predictions\n+\n+\n+batch_size = 128\n+buffer_size = 10000\n+steps_per_epoch = np.ceil(60000 / 128).astype('int')  # = 469\n+epochs = 5\n+classes = 10\n+\n+(x_train, y_train), (x_test, y_test) = mnist.load_data()\n+x_train = x_train.astype(np.float32) / 255\n+x_train = np.expand_dims(x_train, -1)\n+y_train = tf.one_hot(y_train, classes)\n+\n+# Create the dataset and its associated one-shot iterator.\n+dataset = Dataset.from_tensor_slices((x_train, y_train))\n+dataset = dataset.repeat()\n+dataset = dataset.shuffle(buffer_size)\n+dataset = dataset.batch(batch_size)\n+iterator = dataset.make_one_shot_iterator()\n+\n+# Model creation using tensors from the get_next() graph node.\n+inputs, targets = iterator.get_next()\n+model_input = layers.Input(tensor=inputs)\n+model_output = cnn_layers(model_input)\n+train_model = keras.models.Model(inputs=model_input, outputs=model_output)\n+\n+train_model.compile(optimizer=keras.optimizers.RMSprop(lr=2e-3, decay=1e-5),\n+                    loss='categorical_crossentropy',\n+                    metrics=['accuracy'],\n+                    target_tensors=[targets])\n+train_model.summary()\n+\n+train_model.fit(epochs=epochs,\n+                steps_per_epoch=steps_per_epoch)\n+\n+# Save the model weights.\n+weight_path = os.path.join(tempfile.gettempdir(), 'saved_wt.h5')\n+train_model.save_weights(weight_path)\n+\n+# Clean up the TF session.\n+K.clear_session()\n+\n+# Second session to test loading trained model without tensors.\n+x_test = x_test.astype(np.float32)\n+x_test = np.expand_dims(x_test, -1)\n+\n+x_test_inp = layers.Input(shape=x_test.shape[1:])\n+test_out = cnn_layers(x_test_inp)\n+test_model = keras.models.Model(inputs=x_test_inp, outputs=test_out)\n+\n+test_model.load_weights(weight_path)\n+test_model.compile(optimizer='rmsprop',\n+                   loss='sparse_categorical_crossentropy',\n+                   metrics=['accuracy'])\n+test_model.summary()\n+\n+loss, acc = test_model.evaluate(x_test, y_test, classes)\n+print('\\nTest accuracy: {0}'.format(acc))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#de17ff3b2aded0e94a9a747a61d4614d56ff80ef", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 44 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -2,15 +2,15 @@ from ..utils.data_utils import get_file\n import numpy as np\n \n \n-def load_data(path='boston_housing.npz', seed=113, test_split=0.2):\n+def load_data(path='boston_housing.npz', test_split=0.2, seed=113):\n     \"\"\"Loads the Boston Housing dataset.\n \n     # Arguments\n         path: path where to cache the dataset locally\n             (relative to ~/.keras/datasets).\n+        test_split: fraction of the data to reserve as test set.\n         seed: Random seed for shuffling the data\n             before computing the test split.\n-        test_split: fraction of the data to reserve as test set.\n \n     # Returns\n         Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ee4b0bcc2cbac3c79c9b0b2c30036d189654bed4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 14 | Files Changed: 3 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 30 | Churn Cumulative: 823 | Contributors (this commit): 12 | Commits (past 90d): 6 | Contributors (cumulative): 22 | DMM Complexity: 0.5\n\nDIFF:\n@@ -25,9 +25,10 @@ def load_data(path='boston_housing.npz', test_split=0.2, seed=113):\n     f.close()\n \n     np.random.seed(seed)\n-    np.random.shuffle(x)\n-    np.random.seed(seed)\n-    np.random.shuffle(y)\n+    indices = np.arange(len(x))\n+    np.random.shuffle(indices)\n+    x = x[indices]\n+    y = y[indices]\n \n     x_train = np.array(x[:int(len(x) * (1 - test_split))])\n     y_train = np.array(y[:int(len(x) * (1 - test_split))])\n\n@@ -55,15 +55,15 @@ def load_data(path='imdb.npz', num_words=None, skip_top=0,\n         x_train, labels_train = f['x_train'], f['y_train']\n         x_test, labels_test = f['x_test'], f['y_test']\n \n-    np.random.seed(seed)\n-    np.random.shuffle(x_train)\n-    np.random.seed(seed)\n-    np.random.shuffle(labels_train)\n+    indices = np.arange(len(x_train))\n+    np.random.shuffle(indices)\n+    x_train = x_train[indices]\n+    labels_train = labels_train[indices]\n \n-    np.random.seed(seed * 2)\n-    np.random.shuffle(x_test)\n-    np.random.seed(seed * 2)\n-    np.random.shuffle(labels_test)\n+    indices = np.arange(len(x_test))\n+    np.random.shuffle(indices)\n+    x_test = x_test[indices]\n+    labels_test = labels_test[indices]\n \n     xs = np.concatenate([x_train, x_test])\n     labels = np.concatenate([labels_train, labels_test])\n\n@@ -53,9 +53,10 @@ def load_data(path='reuters.npz', num_words=None, skip_top=0,\n         xs, labels = f['x'], f['y']\n \n     np.random.seed(seed)\n-    np.random.shuffle(xs)\n-    np.random.seed(seed)\n-    np.random.shuffle(labels)\n+    indices = np.arange(len(xs))\n+    np.random.shuffle(indices)\n+    xs = xs[indices]\n+    labels = labels[indices]\n \n     if start_char is not None:\n         xs = [[start_char] + [w + index_from for w in x] for x in xs]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#abccbbac42a8f5b37673b12215b04da421f1e4ce", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 1 | Churn Cumulative: 1073 | Contributors (this commit): 12 | Commits (past 90d): 10 | Contributors (cumulative): 12 | DMM Complexity: 0.0\n\nDIFF:\n@@ -57,6 +57,7 @@ if sys.version_info[0] == 2:\n                 chunk = response.read(chunk_size)\n                 count += 1\n                 if not chunk:\n+                    if reporthook:\n                         reporthook(count, total_size, total_size)\n                     break\n                 if reporthook:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#09e0044882f9311d5ea227e130209636defabfa7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 11 | Churn Cumulative: 858 | Contributors (this commit): 22 | Commits (past 90d): 10 | Contributors (cumulative): 22 | DMM Complexity: 0.0\n\nDIFF:\n@@ -326,9 +326,8 @@ class Progbar(object):\n                 time_per_unit = (now - self.start) / current\n             else:\n                 time_per_unit = 0\n-            if self.target is not None and current <= self.target:\n+            if self.target is not None and current < self.target:\n                 eta = time_per_unit * (self.target - current)\n-\n                 if eta > 3600:\n                     eta_format = '%d:%02d:%02d' % (eta // 3600, (eta % 3600) // 60, eta % 60)\n                 elif eta > 60:\n@@ -337,6 +336,14 @@ class Progbar(object):\n                     eta_format = '%ds' % eta\n \n                 info = ' - ETA: %s' % eta_format\n+            else:\n+                if time_per_unit >= 1:\n+                    info += ' %.0fs/step' % time_per_unit\n+                elif time_per_unit >= 1e-3:\n+                    info += ' %.0fms/step' % (time_per_unit * 1e3)\n+                else:\n+                    info += ' %.0fus/step' % (time_per_unit * 1e6)\n+\n             for k in self.unique_values:\n                 info += ' - %s:' % k\n                 if isinstance(self.sum_values[k], list):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a3d41bb88640d034947c68cb75d2e89c54706ec8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 11 | Churn Cumulative: 1084 | Contributors (this commit): 12 | Commits (past 90d): 11 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -53,16 +53,15 @@ if sys.version_info[0] == 2:\n             if content_type is not None:\n                 total_size = int(content_type.strip())\n             count = 0\n-            while 1:\n+            while True:\n                 chunk = response.read(chunk_size)\n                 count += 1\n-                if not chunk:\n-                    if reporthook:\n-                        reporthook(count, total_size, total_size)\n-                    break\n-                if reporthook:\n+                if reporthook is not None:\n                     reporthook(count, chunk_size, total_size)\n+                if chunk:\n                     yield chunk\n+                else:\n+                    break\n \n         response = urlopen(url, data)\n         with open(filename, 'wb') as fd:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e5f2fb7852b505893e863a0c0fc0598a73e52372", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 50 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 50 | Churn Cumulative: 8665 | Contributors (this commit): 52 | Commits (past 90d): 15 | Contributors (cumulative): 55 | DMM Complexity: 0.6206896551724138\n\nDIFF:\n@@ -3027,6 +3027,27 @@ def preprocess_weights_for_loading(layer, weights,\n             weights[0] = np.transpose(weights[0], (3, 2, 0, 1))\n             if layer.__class__.__name__ == 'ConvLSTM2D':\n                 weights[1] = np.transpose(weights[1], (3, 2, 0, 1))\n+\n+    # convert the weights of CuDNNLSTM so that they could be loaded into LSTM\n+    if layer.__class__.__name__ == 'LSTM':\n+        # determine if we're loading a CuDNNLSTM layer from the number of bias weights:\n+        # CuDNNLSTM has (units * 8) weights; while LSTM has (units * 4)\n+        units = weights[1].shape[0]\n+        bias = weights[2]\n+        if len(bias) == units * 8:\n+            # reshape the kernels\n+            kernels = np.split(weights[0], 4, axis=1)\n+            kernels = [kernel.reshape(-1).reshape(kernel.shape, order='F') for kernel in kernels]\n+            weights[0] = np.concatenate(kernels, axis=1)\n+\n+            # transpose the recurrent kernels\n+            recurrent_kernels = np.split(weights[1], 4, axis=1)\n+            recurrent_kernels = [kernel.T for kernel in recurrent_kernels]\n+            weights[1] = np.concatenate(recurrent_kernels, axis=1)\n+\n+            # split the bias into half and merge\n+            weights[2] = bias[:units * 4] + bias[units * 4:]\n+\n     return weights\n \n \n\n@@ -348,5 +348,34 @@ def test_statefulness():\n         assert(out4.max() != out5.max())\n \n \n+@keras_test\n+@pytest.mark.skipif((keras.backend.backend() != 'tensorflow'),\n+                    reason='Requires TensorFlow backend')\n+@pytest.mark.skipif(not keras.backend.tensorflow_backend._get_available_gpus(),\n+                    reason='Requires GPU')\n+def test_load_weights_into_noncudnn_lstm():\n+    input_size = 10\n+    timesteps = 6\n+    units = 2\n+    num_samples = 32\n+\n+    input_shape = (timesteps, input_size)\n+    rnn_layer = keras.layers.LSTM(units, input_shape=input_shape,\n+                                  recurrent_activation='sigmoid')\n+    cudnn_rnn_layer = keras.layers.CuDNNLSTM(units, input_shape=input_shape)\n+\n+    model = keras.models.Sequential([rnn_layer])\n+    cudnn_model = keras.models.Sequential([cudnn_rnn_layer])\n+\n+    weights = cudnn_rnn_layer.get_weights()\n+    weights = keras.engine.topology.preprocess_weights_for_loading(rnn_layer, weights)\n+    rnn_layer.set_weights(weights)\n+\n+    inputs = np.random.random((num_samples, timesteps, input_size))\n+    out = model.predict(inputs)\n+    cudnn_out = cudnn_model.predict(inputs)\n+    assert_allclose(out, cudnn_out, atol=1e-4)\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3fe52549783a745417cbe8552f8307161d7b8c77", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 861 | Contributors (this commit): 23 | Commits (past 90d): 11 | Contributors (cumulative): 23 | DMM Complexity: 1.0\n\nDIFF:\n@@ -267,6 +267,7 @@ class Progbar(object):\n         self.total_width = 0\n         self.seen_so_far = 0\n         self.verbose = verbose \n+        self.is_jupyter = 'ipykernel' in sys.modules\n \n     def update(self, current, values=None, force=False):\n         \"\"\"Updates the progress bar.\n@@ -296,7 +297,7 @@ class Progbar(object):\n                 return\n \n             prev_total_width = self.total_width\n-            if sys.stdout.isatty():\n+            if sys.stdout.isatty() or self.is_jupyter:\n                 sys.stdout.write('\\b' * prev_total_width)\n                 sys.stdout.write('\\r')\n             else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7fc5466f95e2f9e19c8ab7602286f642a136091b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 872 | Contributors (this commit): 23 | Commits (past 90d): 12 | Contributors (cumulative): 23 | DMM Complexity: 0.3333333333333333\n\nDIFF:\n@@ -267,7 +267,8 @@ class Progbar(object):\n         self.total_width = 0\n         self.seen_so_far = 0\n         self.verbose = verbose\n-        self.is_jupyter = 'ipykernel' in sys.modules\n+        self._dynamic_display = (sys.stdout.isatty() or\n+                                 'ipykernel' in sys.modules)\n \n     def update(self, current, values=None, force=False):\n         \"\"\"Updates the progress bar.\n@@ -297,7 +298,7 @@ class Progbar(object):\n                 return\n \n             prev_total_width = self.total_width\n-            if sys.stdout.isatty() or self.is_jupyter:\n+            if self._dynamic_display:\n                 sys.stdout.write('\\b' * prev_total_width)\n                 sys.stdout.write('\\r')\n             else:\n@@ -348,7 +349,8 @@ class Progbar(object):\n             for k in self.unique_values:\n                 info += ' - %s:' % k\n                 if isinstance(self.sum_values[k], list):\n-                    avg = np.mean(self.sum_values[k][0] / max(1, self.sum_values[k][1]))\n+                    avg = np.mean(\n+                        self.sum_values[k][0] / max(1, self.sum_values[k][1]))\n                     if abs(avg) > 1e-3:\n                         info += ' %.4f' % avg\n                     else:\n@@ -370,7 +372,8 @@ class Progbar(object):\n             if self.target is None or current >= self.target:\n                 for k in self.unique_values:\n                     info += ' - %s:' % k\n-                    avg = np.mean(self.sum_values[k][0] / max(1, self.sum_values[k][1]))\n+                    avg = np.mean(\n+                        self.sum_values[k][0] / max(1, self.sum_values[k][1]))\n                     if avg > 1e-3:\n                         info += ' %.4f' % avg\n                     else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bfa7dca200c1bc2b0dae2d312930d03de6768bc4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 20 | Churn Cumulative: 2993 | Contributors (this commit): 17 | Commits (past 90d): 11 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -856,27 +856,27 @@ class TestBackend(object):\n         mean = 0.\n         std = 1.\n         for k in BACKENDS:\n-            rand = k.eval(k.random_normal((1000, 1000), mean=mean, stddev=std))\n-            assert rand.shape == (1000, 1000)\n-            assert np.abs(np.mean(rand) - mean) < 0.01\n-            assert np.abs(np.std(rand) - std) < 0.01\n+            rand = k.eval(k.random_normal((200, 100), mean=mean, stddev=std))\n+            assert rand.shape == (200, 100)\n+            assert np.abs(np.mean(rand) - mean) < 0.015\n+            assert np.abs(np.std(rand) - std) < 0.015\n \n     def test_random_uniform(self):\n         min_val = -1.\n         max_val = 1.\n         for k in BACKENDS:\n-            rand = k.eval(k.random_uniform((1000, 1000), min_val, max_val))\n-            assert rand.shape == (1000, 1000)\n-            assert np.abs(np.mean(rand)) < 0.01\n+            rand = k.eval(k.random_uniform((200, 100), min_val, max_val))\n+            assert rand.shape == (200, 100)\n+            assert np.abs(np.mean(rand)) < 0.015\n             assert np.max(rand) <= max_val\n             assert np.min(rand) >= min_val\n \n     def test_random_binomial(self):\n         p = 0.5\n         for k in BACKENDS:\n-            rand = k.eval(k.random_binomial((1000, 1000), p))\n-            assert rand.shape == (1000, 1000)\n-            assert np.abs(np.mean(rand) - p) < 0.01\n+            rand = k.eval(k.random_binomial((200, 100), p))\n+            assert rand.shape == (200, 100)\n+            assert np.abs(np.mean(rand) - p) < 0.015\n             assert np.max(rand) == 1\n             assert np.min(rand) == 0\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c25e06f05a245ebf127ed3856eea19a7c73a9ab9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 387 | Contributors (this commit): 15 | Commits (past 90d): 9 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -17,7 +17,10 @@ from . import models\n from . import losses\r\n from . import optimizers\r\n from . import regularizers\r\n-# Importable from root because it's technically not a layer\r\n-from .layers import Input\r\n \r\n-__version__ = '2.0.8'\r\n+# Also importable from root\r\n+from .layers import Input\r\n+from .models import Model\r\n+from .models import Sequential\r\n+\r\n+__version__ = '2.0.9'\r\n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='2.0.8',\n+      version='2.0.9',\n       description='Deep Learning for Python',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/fchollet/keras',\n-      download_url='https://github.com/fchollet/keras/tarball/2.0.8',\n+      download_url='https://github.com/fchollet/keras/tarball/2.0.9',\n       license='MIT',\n       install_requires=['numpy>=1.9.1',\n                         'scipy>=0.14',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7a5e391c34eb99bcdccac67d6a917787fc118fd6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 419 | Contributors (this commit): 4 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -67,9 +67,10 @@ def conv2d_bn(x,\n         x: input tensor.\n         filters: filters in `Conv2D`.\n         kernel_size: kernel size as in `Conv2D`.\n+        strides: strides in `Conv2D`.\n         padding: padding mode in `Conv2D`.\n         activation: activation in `Conv2D`.\n-        strides: strides in `Conv2D`.\n+        use_bias: whether to use a bias in `Conv2D`.\n         name: name of the ops; will become `name + '_ac'` for the activation\n             and `name + '_bn'` for the batch norm layer.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1a2c2971776783627b002e410d83b7cb6b59f7c3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 503 | Contributors (this commit): 8 | Commits (past 90d): 5 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -149,8 +149,6 @@ if __name__ == '__main__':\n \n     # build the generator\n     generator = build_generator(latent_size)\n-    generator.compile(optimizer=Adam(lr=adam_lr, beta_1=adam_beta_1),\n-                      loss='binary_crossentropy')\n \n     latent = Input(shape=(latent_size, ))\n     image_class = Input(shape=(1,), dtype='int32')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#612f5307b962fb140106efcc50932c292630fda3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 137 | Lines Deleted: 22 | Files Changed: 4 | Hunks: 37 | Methods Changed: 28 | Complexity Δ (Sum/Max): 21/10 | Churn Δ: 159 | Churn Cumulative: 8264 | Contributors (this commit): 75 | Commits (past 90d): 49 | Contributors (cumulative): 100 | DMM Complexity: 0.7142857142857143\n\nDIFF:\n@@ -1901,7 +1901,7 @@ class Model(Container):\n                 to yield from `generator` before declaring one epoch\n                 finished and starting the next epoch. It should typically\n                 be equal to the number of unique samples of your dataset\n-                divided by the batch size.\n+                divided by the batch size. Not used if using `Sequence`.\n             epochs: Integer, total number of iterations on the data.\n             verbose: Verbosity mode, 0, 1, or 2.\n             callbacks: List of callbacks to be called during training.\n@@ -2023,6 +2023,8 @@ class Model(Container):\n                             ' and multiple workers may duplicate your data.'\n                             ' Please consider using the`keras.utils.Sequence'\n                             ' class.'))\n+        if is_sequence:\n+            steps_per_epoch = len(generator)\n         enqueuer = None\n \n         try:\n@@ -2144,6 +2146,7 @@ class Model(Container):\n                     when using multiprocessing.\n             steps: Total number of steps (batches of samples)\n                 to yield from `generator` before stopping.\n+                Not used if using Sequence.\n             max_queue_size: maximum size for the generator queue\n             workers: maximum number of processes to spin up\n                 when using process based threading\n@@ -2178,6 +2181,8 @@ class Model(Container):\n                             ' and multiple workers may duplicate your data.'\n                             ' Please consider using the`keras.utils.Sequence'\n                             ' class.'))\n+        if is_sequence:\n+            steps = len(generator)\n         enqueuer = None\n \n         try:\n@@ -2256,6 +2261,7 @@ class Model(Container):\n                     when using multiprocessing.\n             steps: Total number of steps (batches of samples)\n                 to yield from `generator` before stopping.\n+                Not used if using Sequence.\n             max_queue_size: Maximum size for the generator queue.\n             workers: Maximum number of processes to spin up\n                 when using process based threading\n@@ -2287,6 +2293,8 @@ class Model(Container):\n                             ' and multiple workers may duplicate your data.'\n                             ' Please consider using the`keras.utils.Sequence'\n                             ' class.'))\n+        if is_sequence:\n+            steps = len(generator)\n         enqueuer = None\n \n         try:\n\n@@ -366,17 +366,28 @@ class Sequence(object):\n         pass\n \n \n-def get_index(ds, i):\n-    \"\"\"Quick fix for Python2, otherwise, it cannot be pickled.\n+# Global variables to be shared across processes\n+_SHARED_SEQUENCES = {}\n+# We use a Value to provide unique id to different processes.\n+_SEQUENCE_COUNTER = multiprocessing.Value('i', 0)\n+\n+\n+def get_index(uid, i):\n+    \"\"\"Get the value from the Sequence `uid` at index `i`.\n+\n+    To allow multiple Sequences to be used at the same time, we use `uid` to\n+    get a specific one. A single Sequence would cause the validation to\n+    overwrite the training Sequence.\n \n     # Arguments\n-        ds: a Sequence object\n+        uid: int, Sequence identifier\n         i: index\n \n     # Returns\n         The value at index `i`.\n     \"\"\"\n-    return ds[i]\n+    global _SHARED_SEQUENCES\n+    return _SHARED_SEQUENCES[uid][i]\n \n \n class SequenceEnqueuer(object):\n@@ -454,7 +465,13 @@ class OrderedEnqueuer(SequenceEnqueuer):\n     def __init__(self, sequence,\n                  use_multiprocessing=False,\n                  shuffle=False):\n+        global _SEQUENCE_COUNTER\n         self.sequence = sequence\n+\n+        # Doing Multiprocessing.Value += x is not process-safe.\n+        with _SEQUENCE_COUNTER.get_lock():\n+            self.uid = _SEQUENCE_COUNTER.value\n+            _SEQUENCE_COUNTER.value += 1\n         self.use_multiprocessing = use_multiprocessing\n         self.shuffle = shuffle\n         self.workers = 0\n@@ -478,15 +495,24 @@ class OrderedEnqueuer(SequenceEnqueuer):\n             self.executor = multiprocessing.Pool(workers)\n         else:\n             self.executor = ThreadPool(workers)\n+        self.workers = workers\n         self.queue = queue.Queue(max_queue_size)\n         self.stop_signal = threading.Event()\n         self.run_thread = threading.Thread(target=self._run)\n         self.run_thread.daemon = True\n         self.run_thread.start()\n \n+    def _wait_queue(self):\n+        \"\"\"Wait for the queue to be empty.\"\"\"\n+        while True:\n+            time.sleep(0.1)\n+            if self.queue.unfinished_tasks == 0 or self.stop_signal.is_set():\n+                return\n+\n     def _run(self):\n         \"\"\"Function to submit request to the executor and queue the `Future` objects.\"\"\"\n         sequence = list(range(len(self.sequence)))\n+        self._send_sequence()  # Share the initial sequence\n         while True:\n             if self.shuffle:\n                 random.shuffle(sequence)\n@@ -494,10 +520,18 @@ class OrderedEnqueuer(SequenceEnqueuer):\n                 if self.stop_signal.is_set():\n                     return\n                 self.queue.put(\n-                    self.executor.apply_async(get_index,\n-                                              (self.sequence, i)), block=True)\n+                    self.executor.apply_async(get_index, (self.uid, i)), block=True)\n+\n+            # Done with the current epoch, waiting for the final batches\n+            self._wait_queue()\n+\n+            if self.stop_signal.is_set():\n+                # We're done\n+                return\n+\n             # Call the internal on epoch end.\n             self.sequence.on_epoch_end()\n+            self._send_sequence()  # Update the pool\n \n     def get(self):\n         \"\"\"Creates a generator to extract data from the queue.\n@@ -511,12 +545,24 @@ class OrderedEnqueuer(SequenceEnqueuer):\n         try:\n             while self.is_running():\n                 inputs = self.queue.get(block=True).get()\n+                self.queue.task_done()\n                 if inputs is not None:\n                     yield inputs\n         except Exception as e:\n             self.stop()\n             raise StopIteration(e)\n \n+    def _send_sequence(self):\n+        \"\"\"Send current Sequence to all workers.\"\"\"\n+        global _SHARED_SEQUENCES\n+        _SHARED_SEQUENCES[self.uid] = self.sequence  # For new processes that may spawn\n+\n+        self._close_pool()\n+        if self.use_multiprocessing:\n+            self.executor = multiprocessing.Pool(self.workers)\n+        else:\n+            self.executor = ThreadPool(self.workers)\n+\n     def stop(self, timeout=None):\n         \"\"\"Stops running threads and wait for them to exit, if necessary.\n \n@@ -525,14 +571,19 @@ class OrderedEnqueuer(SequenceEnqueuer):\n         # Arguments\n             timeout: maximum time to wait on `thread.join()`\n         \"\"\"\n+        global _SHARED_SEQUENCES\n         self.stop_signal.set()\n         with self.queue.mutex:\n             self.queue.queue.clear()\n             self.queue.unfinished_tasks = 0\n             self.queue.not_full.notify()\n+        self._close_pool()\n+        self.run_thread.join(timeout)\n+        _SHARED_SEQUENCES[self.uid] = None\n+\n+    def _close_pool(self):\n         self.executor.close()\n         self.executor.join()\n-        self.run_thread.join(timeout)\n \n \n class GeneratorEnqueuer(SequenceEnqueuer):\n\n@@ -392,9 +392,9 @@ def test_model_methods():\n     model.compile(optimizer, loss, metrics=[], loss_weights=loss_weights,\n                   sample_weight_mode=None)\n     trained_epochs = []\n-    out = model.fit_generator(generator=RandomSequence(3), steps_per_epoch=4, epochs=5,\n+    out = model.fit_generator(generator=RandomSequence(3), steps_per_epoch=12, epochs=5,\n                               initial_epoch=0, validation_data=RandomSequence(4),\n-                              validation_steps=3, callbacks=[tracker_cb])\n+                              validation_steps=12, callbacks=[tracker_cb])\n     assert trained_epochs == [0, 1, 2, 3, 4]\n \n \n\n@@ -12,9 +12,9 @@ import pytest\n from six.moves.urllib.parse import urljoin\n from six.moves.urllib.request import pathname2url\n \n-from keras.utils import Sequence\n from keras.utils import GeneratorEnqueuer\n from keras.utils import OrderedEnqueuer\n+from keras.utils import Sequence\n from keras.utils.data_utils import _hash_file\n from keras.utils.data_utils import get_file\n from keras.utils.data_utils import validate_file\n@@ -111,18 +111,19 @@ def threadsafe_generator(f):\n     return g\n \n \n-class TestSequence(Sequence):\n-    def __init__(self, shape):\n+class DummySequence(Sequence):\n+    def __init__(self, shape, value=1.0):\n         self.shape = shape\n+        self.inner = value\n \n     def __getitem__(self, item):\n-        return np.ones(self.shape, dtype=np.uint8) * item\n+        return np.ones(self.shape, dtype=np.uint32) * item * self.inner\n \n     def __len__(self):\n         return 100\n \n     def on_epoch_end(self):\n-        pass\n+        self.inner *= 5.0\n \n \n class FaultSequence(Sequence):\n@@ -149,7 +150,7 @@ def create_generator_from_sequence_pcs(ds):\n \n def test_generator_enqueuer_threads():\n     enqueuer = GeneratorEnqueuer(create_generator_from_sequence_threads(\n-        TestSequence([3, 200, 200, 3])), use_multiprocessing=False)\n+        DummySequence([3, 200, 200, 3])), use_multiprocessing=False)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n     acc = []\n@@ -166,7 +167,7 @@ def test_generator_enqueuer_threads():\n \n def test_generator_enqueuer_processes():\n     enqueuer = GeneratorEnqueuer(create_generator_from_sequence_pcs(\n-        TestSequence([3, 200, 200, 3])), use_multiprocessing=True)\n+        DummySequence([3, 200, 200, 3])), use_multiprocessing=True)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n     acc = []\n@@ -195,7 +196,7 @@ def test_generator_enqueuer_fail_processes():\n \n \n def test_ordered_enqueuer_threads():\n-    enqueuer = OrderedEnqueuer(TestSequence([3, 200, 200, 3]), use_multiprocessing=False)\n+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]), use_multiprocessing=False)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n     acc = []\n@@ -206,7 +207,7 @@ def test_ordered_enqueuer_threads():\n \n \n def test_ordered_enqueuer_threads_not_ordered():\n-    enqueuer = OrderedEnqueuer(TestSequence([3, 200, 200, 3]),\n+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]),\n                                use_multiprocessing=False,\n                                shuffle=True)\n     enqueuer.start(3, 10)\n@@ -219,7 +220,7 @@ def test_ordered_enqueuer_threads_not_ordered():\n \n \n def test_ordered_enqueuer_processes():\n-    enqueuer = OrderedEnqueuer(TestSequence([3, 200, 200, 3]), use_multiprocessing=True)\n+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]), use_multiprocessing=True)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n     acc = []\n@@ -237,6 +238,61 @@ def test_ordered_enqueuer_fail_threads():\n         next(gen_output)\n \n \n+def test_on_epoch_end_processes():\n+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]), use_multiprocessing=True)\n+    enqueuer.start(3, 10)\n+    gen_output = enqueuer.get()\n+    acc = []\n+    for i in range(200):\n+        acc.append(next(gen_output)[0, 0, 0, 0])\n+    assert acc[100:] == list([k * 5 for k in range(100)]), \"Order was not keep in GeneratorEnqueuer with processes\"\n+    enqueuer.stop()\n+\n+\n+def test_context_switch():\n+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]), use_multiprocessing=True)\n+    enqueuer2 = OrderedEnqueuer(DummySequence([3, 200, 200, 3], value=15), use_multiprocessing=True)\n+    enqueuer.start(3, 10)\n+    enqueuer2.start(3, 10)\n+    gen_output = enqueuer.get()\n+    gen_output2 = enqueuer2.get()\n+    acc = []\n+    for i in range(100):\n+        acc.append(next(gen_output)[0, 0, 0, 0])\n+    assert acc[-1] == 99\n+    # One epoch is completed so enqueuer will switch the Sequence\n+\n+    acc = []\n+    for i in range(100):\n+        acc.append(next(gen_output2)[0, 0, 0, 0])\n+    assert acc[-1] == 99 * 15\n+    # One epoch has been completed so enqueuer2 will switch\n+\n+    # Be sure that both Sequence were updated\n+    assert next(gen_output)[0, 0, 0, 0] == 0\n+    assert next(gen_output)[0, 0, 0, 0] == 5\n+    assert next(gen_output2)[0, 0, 0, 0] == 0\n+    assert next(gen_output2)[0, 0, 0, 0] == 15 * 5\n+\n+    # Tear down everything\n+    enqueuer.stop()\n+    enqueuer2.stop()\n+\n+\n+def test_on_epoch_end_threads():\n+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]), use_multiprocessing=False)\n+    enqueuer.start(3, 10)\n+    gen_output = enqueuer.get()\n+    acc = []\n+    for i in range(100):\n+        acc.append(next(gen_output)[0, 0, 0, 0])\n+    acc = []\n+    for i in range(100):\n+        acc.append(next(gen_output)[0, 0, 0, 0])\n+    assert acc == list([k * 5 for k in range(100)]), \"Order was not keep in GeneratorEnqueuer with processes\"\n+    enqueuer.stop()\n+\n+\n def test_ordered_enqueuer_fail_processes():\n     enqueuer = OrderedEnqueuer(FaultSequence(), use_multiprocessing=True)\n     enqueuer.start(3, 10)\n@@ -258,7 +314,7 @@ def create_finite_generator_from_sequence_pcs(ds):\n \n def test_finite_generator_enqueuer_threads():\n     enqueuer = GeneratorEnqueuer(create_finite_generator_from_sequence_threads(\n-        TestSequence([3, 200, 200, 3])), use_multiprocessing=False)\n+        DummySequence([3, 200, 200, 3])), use_multiprocessing=False)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n     acc = []\n@@ -270,7 +326,7 @@ def test_finite_generator_enqueuer_threads():\n \n def test_finite_generator_enqueuer_processes():\n     enqueuer = GeneratorEnqueuer(create_finite_generator_from_sequence_pcs(\n-        TestSequence([3, 200, 200, 3])), use_multiprocessing=True)\n+        DummySequence([3, 200, 200, 3])), use_multiprocessing=True)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n     acc = []\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
