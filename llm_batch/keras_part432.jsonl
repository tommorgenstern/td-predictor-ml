{"custom_id": "keras#25e53c1654b0aeeb8bf4ea00dcc2f9743420a9d9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 29 | Lines Deleted: 13 | Files Changed: 2 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 42 | Churn Cumulative: 7973 | Contributors (this commit): 14 | Commits (past 90d): 7 | Contributors (cumulative): 15 | DMM Complexity: 0.0\n\nDIFF:\n@@ -3389,7 +3389,7 @@ def resize_images(x, height_factor, width_factor, data_format,\n       height_factor: Positive integer.\n       width_factor: Positive integer.\n       data_format: One of `\"channels_first\"`, `\"channels_last\"`.\n-      interpolation: A string, one of `nearest` or `bilinear`.\n+      interpolation: A string any of `tf.image.ResizeMethod`.\n \n   Returns:\n       A tensor.\n@@ -3415,15 +3415,21 @@ def resize_images(x, height_factor, width_factor, data_format,\n \n   if data_format == 'channels_first':\n     x = permute_dimensions(x, [0, 2, 3, 1])\n-  if interpolation == 'nearest':\n-    x = tf.image.resize(\n-        x, new_shape, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n-  elif interpolation == 'bilinear':\n-    x = tf.image.resize(x, new_shape,\n-                                   method=tf.image.ResizeMethod.BILINEAR)\n+  interpolations = {\n+    'area': tf.image.ResizeMethod.AREA,\n+    'bicubic': tf.image.ResizeMethod.BICUBIC,\n+    'bilinear': tf.image.ResizeMethod.BILINEAR,\n+    'gaussian': tf.image.ResizeMethod.GAUSSIAN,\n+    'lanczos3': tf.image.ResizeMethod.LANCZOS3,\n+    'lanczos5': tf.image.ResizeMethod.LANCZOS5,\n+    'mitchellcubic': tf.image.ResizeMethod.MITCHELLCUBIC,\n+    'nearest': tf.image.ResizeMethod.NEAREST_NEIGHBOR,\n+  }\n+  if interpolation in interpolations:\n+    x = tf.image.resize(x, new_shape, method=interpolations[interpolation])\n   else:\n-    raise ValueError('interpolation should be one '\n-                     'of \"nearest\" or \"bilinear\".')\n+    raise ValueError('interpolation should be '\n+                     'from `tf.image.ResizeMethod`.')\n   if data_format == 'channels_first':\n     x = permute_dimensions(x, [0, 3, 1, 2])\n \n\n@@ -65,7 +65,7 @@ class UpSampling2D(Layer):\n       It defaults to the `image_data_format` value found in your\n       Keras config file at `~/.keras/keras.json`.\n       If you never set it, then it will be \"channels_last\".\n-    interpolation: A string, one of `nearest` or `bilinear`.\n+    interpolation: A string any of `tf.image.ResizeMethod`.\n \n   Input shape:\n     4D tensor with shape:\n@@ -90,9 +90,19 @@ class UpSampling2D(Layer):\n     super(UpSampling2D, self).__init__(**kwargs)\n     self.data_format = conv_utils.normalize_data_format(data_format)\n     self.size = conv_utils.normalize_tuple(size, 2, 'size')\n-    if interpolation not in {'nearest', 'bilinear'}:\n-      raise ValueError('`interpolation` argument should be one of `\"nearest\"` '\n-                       f'or `\"bilinear\"`. Received: \"{interpolation}\".')\n+    interpolations = {\n+      'area': tf.image.ResizeMethod.AREA,\n+      'bicubic': tf.image.ResizeMethod.BICUBIC,\n+      'bilinear': tf.image.ResizeMethod.BILINEAR,\n+      'gaussian': tf.image.ResizeMethod.GAUSSIAN,\n+      'lanczos3': tf.image.ResizeMethod.LANCZOS3,\n+      'lanczos5': tf.image.ResizeMethod.LANCZOS5,\n+      'mitchellcubic': tf.image.ResizeMethod.MITCHELLCUBIC,\n+      'nearest': tf.image.ResizeMethod.NEAREST_NEIGHBOR,\n+    }\n+    if interpolation not in interpolations:\n+      raise ValueError('`interpolation` argument should be from `tf.image.ResizeMethod`. '\n+                       f'Received: \"{interpolation}\".')\n     self.interpolation = interpolation\n     self.input_spec = InputSpec(ndim=4)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b295e003d1d3deba7d4e456b8de44ddb46e3e4ac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 1771 | Contributors (this commit): 24 | Commits (past 90d): 3 | Contributors (cumulative): 24 | DMM Complexity: None\n\nDIFF:\n@@ -12,7 +12,14 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-\"\"\"Utilities for preprocessing sequence data.\"\"\"\n+\"\"\"Utilities for preprocessing sequence data.\n+\n+Warning: `tf.keras.preprocessing.sequence` APIs are not recommended for new\n+code. Prefer `tf.keras.utils.timeseries_dataset_from_array` and\n+the `tf.data` APIs which provide a much more flexible mechanisms for dealing\n+with sequences. See the [tf.data guide](https://www.tensorflow.org/guide/data)\n+for more details.\n+\"\"\"\n # pylint: disable=invalid-name\n # pylint: disable=g-classes-have-attributes\n # pylint: disable=g-direct-tensorflow-import\n@@ -49,6 +56,12 @@ def _remove_long_seq(maxlen, seq, label):\n class TimeseriesGenerator(data_utils.Sequence):\n   \"\"\"Utility class for generating batches of temporal data.\n \n+  Warning: `tf.keras.preprocessing.sequence.TimeseriesGenerator` does not\n+  operate on tensors and is not recommended for new code. Prefer using a\n+  `tf.data.Dataset` which provides a more efficient and flexible mechanism for\n+  batching, shuffling, and windowing input. See the\n+  [tf.data guide](https://www.tensorflow.org/guide/data) for more details.\n+\n   This class takes in a sequence of data-points gathered at\n   equal intervals, along with time series parameters such as\n   stride, length of history, etc., to produce batches for\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#255b3f645d42464d4f8c80e97200d4dacc513616", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 101 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -12,7 +12,21 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-\"\"\"Provides keras data preprocessing utils to pre-process tf.data.Datasets before they are fed to the model.\"\"\"\n+\"\"\"Utilities to preprocess data before training.\n+\n+Warning: `tf.keras.preprocessing` APIs do not operate on tensors and are\n+not recommended for new code. Prefer loading data with either\n+`tf.keras.utils.text_dataset_from_directory` or\n+`tf.keras.utils.image_dataset_from_directory`, and then transforming the output\n+`tf.data.Dataset` with preprocessing layers. These approaches will offer\n+better performance and intergration with the broader Tensorflow ecosystem. For\n+more information, see the tutorials for [loading text](\n+https://www.tensorflow.org/tutorials/load_data/text), [loading images](\n+https://www.tensorflow.org/tutorials/load_data/images), and [augmenting images](\n+https://www.tensorflow.org/tutorials/images/data_augmentation), as well as the\n+[preprocessing layer guide](\n+https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\"\"\"\n from keras import backend\n from keras.preprocessing import image\n from keras.preprocessing import sequence\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5c11e767a7312a80f70fa5100b7df8b4e391c4e2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 357 | Contributors (this commit): 10 | Commits (past 90d): 3 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -79,7 +79,7 @@ def image_dataset_from_directory(directory,\n         image files found in the directory. Labels should be sorted according\n         to the alphanumeric order of the image file paths\n         (obtained via `os.walk(directory)` in Python).\n-    label_mode:\n+    label_mode: String describing the encoding of `labels`. Options are:\n         - 'int': means that the labels are encoded as integers\n             (e.g. for `sparse_categorical_crossentropy` loss).\n         - 'categorical' means that the labels are\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3073e00912838454359079a35f1638ccf06e855f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 564 | Contributors (this commit): 10 | Commits (past 90d): 5 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -203,7 +203,7 @@ def labels_to_dataset(labels, label_mode, num_classes):\n \n   Args:\n     labels: list/tuple of labels to be converted into a tf.data.Dataset.\n-    label_mode:\n+    label_mode: String describing the encoding of `labels`. Options are:\n     - 'binary' indicates that the labels (there can be only 2) are encoded as\n       `float32` scalars with values 0 or 1 (e.g. for `binary_crossentropy`).\n     - 'categorical' means that the labels are mapped into a categorical vector.\n\n@@ -68,7 +68,7 @@ def text_dataset_from_directory(directory,\n         text files found in the directory. Labels should be sorted according\n         to the alphanumeric order of the text file paths\n         (obtained via `os.walk(directory)` in Python).\n-    label_mode:\n+    label_mode: String describing the encoding of `labels`. Options are:\n         - 'int': means that the labels are encoded as integers\n             (e.g. for `sparse_categorical_crossentropy` loss).\n         - 'categorical' means that the labels are\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f98f87dd7bfac6f34e35896ce9ed9650dc61e3ec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 1416 | Contributors (this commit): 5 | Commits (past 90d): 14 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -61,6 +61,11 @@ class LayersTest(test_util.DTensorBaseTest):\n       # ('conv3dtranspose', layers.Conv3DTranspose,\n       #  {'filters': 4, 'kernel_size': (3, 3, 3)},\n       #  {'kernel': 5, 'bias': 1}, [10, 28, 28, 28, 3]),\n+      ('batch_norm', layers.BatchNormalization, {'fused': False},\n+       {'beta': 1, 'gamma': 1, 'moving_mean': 1, 'moving_variance': 1},\n+       [10, 28, 28, 3]),\n+      ('layer_norm', layers.LayerNormalization, {'dtype': tf.float64},\n+       {'beta': 1, 'gamma': 1}, [10, 28, 28, 3])\n   )\n   def test_layer(self, layer_cls, init_args, variable_settings, input_shape,\n                  input_dtype=np.float32):\n\n@@ -19,6 +19,7 @@ from keras import backend\n from keras import constraints\n from keras import initializers\n from keras import regularizers\n+from keras.dtensor import utils\n from keras.engine.base_layer import Layer\n from keras.engine.input_spec import InputSpec\n from keras.utils import control_flow_util\n@@ -1215,6 +1216,7 @@ class BatchNormalization(BatchNormalizationBase):\n   \"\"\"\n   _USE_V2_BEHAVIOR = True\n \n+  @utils.allow_initializer_layout\n   def __init__(self,\n                axis=-1,\n                momentum=0.99,\n\n@@ -20,6 +20,7 @@ import tensorflow.compat.v2 as tf\n from keras import constraints\n from keras import initializers\n from keras import regularizers\n+from keras.dtensor import utils\n from keras.engine.base_layer import Layer\n from keras.utils import tf_utils\n \n@@ -149,6 +150,7 @@ class LayerNormalization(Layer):\n     - [Lei Ba et al., 2016](https://arxiv.org/abs/1607.06450).\n   \"\"\"\n \n+  @utils.allow_initializer_layout\n   def __init__(self,\n                axis=-1,\n                epsilon=1e-3,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#895cf2090c665fac2a50549932acd55cd2dc3856", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 6 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 7989 | Contributors (this commit): 14 | Commits (past 90d): 9 | Contributors (cumulative): 15 | DMM Complexity: 0.0\n\nDIFF:\n@@ -3389,7 +3389,8 @@ def resize_images(x, height_factor, width_factor, data_format,\n       height_factor: Positive integer.\n       width_factor: Positive integer.\n       data_format: One of `\"channels_first\"`, `\"channels_last\"`.\n-      interpolation: A string any of `tf.image.ResizeMethod`.\n+      interpolation: A string, one of `area`, `bicubic`, `bilinear`,\n+        `gaussian`, `lanczos3`, `lanczos5`, `mitchellcubic`, `nearest`.\n \n   Returns:\n       A tensor.\n@@ -3425,11 +3426,12 @@ def resize_images(x, height_factor, width_factor, data_format,\n     'mitchellcubic': tf.image.ResizeMethod.MITCHELLCUBIC,\n     'nearest': tf.image.ResizeMethod.NEAREST_NEIGHBOR,\n   }\n+  interploations_list = '`' + '`, `'.join(interpolations.keys()) + '`'\n   if interpolation in interpolations:\n     x = tf.image.resize(x, new_shape, method=interpolations[interpolation])\n   else:\n-    raise ValueError('interpolation should be '\n-                     'from `tf.image.ResizeMethod`.')\n+    raise ValueError('`interpolation` argument should be one of: '\n+                     f'{interploations_list}. Received: \"{interpolation}\".')\n   if data_format == 'channels_first':\n     x = permute_dimensions(x, [0, 3, 1, 2])\n \n\n@@ -65,7 +65,8 @@ class UpSampling2D(Layer):\n       It defaults to the `image_data_format` value found in your\n       Keras config file at `~/.keras/keras.json`.\n       If you never set it, then it will be \"channels_last\".\n-    interpolation: A string any of `tf.image.ResizeMethod`.\n+    interpolation: A string, one of `area`, `bicubic`, `bilinear`, `gaussian`,\n+      `lanczos3`, `lanczos5`, `mitchellcubic`, `nearest`.\n \n   Input shape:\n     4D tensor with shape:\n@@ -100,9 +101,10 @@ class UpSampling2D(Layer):\n       'mitchellcubic': tf.image.ResizeMethod.MITCHELLCUBIC,\n       'nearest': tf.image.ResizeMethod.NEAREST_NEIGHBOR,\n     }\n+    interploations_list = '`' + '`, `'.join(interpolations.keys()) + '`'\n     if interpolation not in interpolations:\n-      raise ValueError('`interpolation` argument should be from `tf.image.ResizeMethod`. '\n-                       f'Received: \"{interpolation}\".')\n+      raise ValueError('`interpolation` argument should be one of: '\n+                       f'{interploations_list}. Received: \"{interpolation}\".')\n     self.interpolation = interpolation\n     self.input_spec = InputSpec(ndim=4)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ffc5551010d9966cd20f9b8db2d7aa61ef6192aa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 1457 | Contributors (this commit): 1 | Commits (past 90d): 9 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -156,8 +156,7 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n         se_ratio: Squeeze and Excitation layer ratio.\n         dropout_rate: dropout rate before final classifier layer.\n         drop_connect_rate: dropout rate at skip connections.\n-        include_top: whether to include the fully-connected layer at the top of\n-        the network.\n+        include_top: whether to include the fully-connected layer at the top of the network.\n         block_args: list of dicts, parameters to construct block modules.\n         model_name: name of the model.\n         pooling: optional pooling mode for feature extraction when `include_top`\n@@ -533,8 +532,7 @@ def ResNetRS(\n         se_ratio: Squeeze and Excitation layer ratio.\n         dropout_rate: dropout rate before final classifier layer.\n         drop_connect_rate: dropout rate at skip connections.\n-        include_top: whether to include the fully-connected layer at the top of\n-        the network.\n+        include_top: whether to include the fully-connected layer at the top of the network.\n         block_args: list of dicts, parameters to construct block modules.\n         model_name: name of the model.\n         pooling: optional pooling mode for feature extraction when `include_top`\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8e9d1c54552ca7350ff092544d265b1bf6f1eecf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 4682 | Contributors (this commit): 22 | Commits (past 90d): 5 | Contributors (cumulative): 22 | DMM Complexity: None\n\nDIFF:\n@@ -29,7 +29,6 @@ from tensorflow.python.ops.ragged import ragged_util\n from tensorflow.python.util import dispatch\n from tensorflow.python.util.tf_export import keras_export\n from tensorflow.tools.docs import doc_controls\n-from tensorflow.python.ops import check_ops\n \n \n @keras_export('keras.losses.Loss')\n@@ -1774,8 +1773,7 @@ def categorical_crossentropy(y_true,\n   Returns:\n     Categorical crossentropy loss value.\n   \"\"\"\n-  #axis assert\n-  check_ops.assert_integer_v2(int(axis), message=('`axis` must be of type `int`.'))\n+  axis = int(axis)\n   y_pred = tf.convert_to_tensor(y_pred)\n   y_true = tf.cast(y_true, y_pred.dtype)\n   label_smoothing = tf.convert_to_tensor(label_smoothing, dtype=y_pred.dtype)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c028047ce6782d20c2d59882ed59145af7ad0667", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 99 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 10 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 100 | Churn Cumulative: 11224 | Contributors (this commit): 65 | Commits (past 90d): 2 | Contributors (cumulative): 65 | DMM Complexity: None\n\nDIFF:\n@@ -16,7 +16,18 @@\n # pylint: disable=g-import-not-at-top\n # pylint: disable=g-classes-have-attributes\n # pylint: disable=g-direct-tensorflow-import\n-\"\"\"Set of tools for real-time data augmentation on image data.\"\"\"\n+\"\"\"Utilies for image preprocessing and augmentation.\n+\n+Warning: `tf.keras.preprocessing.image` APIs do not operate on tensors and are\n+not recommended for new code. Prefer loading data with\n+`tf.keras.utils.image_dataset_from_directory`, and then transforming the output\n+`tf.data.Dataset` with preprocessing layers. For more information, see the\n+tutorials for [loading images](\n+https://www.tensorflow.org/tutorials/load_data/images) and [augmenting images](\n+https://www.tensorflow.org/tutorials/images/data_augmentation), as well as the\n+[preprocessing layer guide](\n+https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\"\"\"\n \n import collections\n import io\n@@ -62,6 +73,13 @@ if pil_image is not None:\n def smart_resize(x, size, interpolation='bilinear'):\n   \"\"\"Resize images to a target size without aspect ratio distortion.\n \n+  Warning: `tf.keras.preprocessing.image.smart_resize` is not recommended for\n+  new code. Prefer `tf.keras.layers.Resizing`, which provides the same\n+  functionality as a preprocessing layer and adds `tf.RaggedTensor` support. See\n+  the [preprocessing layer guide](\n+  https://www.tensorflow.org/guide/keras/preprocessing_layers)\n+  for an overview of preprocessing layers.\n+\n   TensorFlow image datasets typically yield images that have each a different\n   size. However, these images need to be batched before they can be\n   processed by Keras layers. To be batched, images need to share the same height\n@@ -435,6 +453,17 @@ def load_img(path,\n class Iterator(data_utils.Sequence):\n   \"\"\"Base class for image data iterators.\n \n+  Warning: `tf.keras.preprocessing.image.Iterator` is not recommended for\n+  new code. Prefer loading images with\n+  `tf.keras.utils.image_dataset_from_directory` and transforming the output\n+  `tf.data.Dataset` with preprocessing layers. For more information, see the\n+  tutorials for [loading images](\n+  https://www.tensorflow.org/tutorials/load_data/images) and\n+  [augmenting images](\n+  https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n+  the [preprocessing layer guide](\n+  https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   Every `Iterator` must implement the `_get_batches_of_transformed_samples`\n   method.\n \n@@ -775,6 +804,17 @@ class BatchFromFilesMixin():\n class DirectoryIterator(BatchFromFilesMixin, Iterator):\n   \"\"\"Iterator capable of reading images from a directory on disk.\n \n+  Warning: `tf.keras.preprocessing.image.DirectoryIterator` is not recommended\n+  for new code. Prefer loading images with\n+  `tf.keras.utils.image_dataset_from_directory` and transforming the output\n+  `tf.data.Dataset` with preprocessing layers. For more information, see the\n+  tutorials for [loading images](\n+  https://www.tensorflow.org/tutorials/load_data/images) and\n+  [augmenting images](\n+  https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n+  the [preprocessing layer guide](\n+  https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   Args:\n       directory: Path to the directory to read images from. Each subdirectory in\n         this directory will be considered to contain images from one class, or\n@@ -916,6 +956,17 @@ class DirectoryIterator(BatchFromFilesMixin, Iterator):\n class NumpyArrayIterator(Iterator):\n   \"\"\"Iterator yielding data from a Numpy array.\n \n+  Warning: `tf.keras.preprocessing.image.NumpyArrayIterator` is not recommended\n+  for new code. Prefer loading images with\n+  `tf.keras.utils.image_dataset_from_directory` and transforming the output\n+  `tf.data.Dataset` with preprocessing layers. For more information, see the\n+  tutorials for [loading images](\n+  https://www.tensorflow.org/tutorials/load_data/images) and\n+  [augmenting images](\n+  https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n+  the [preprocessing layer guide](\n+  https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   Args:\n       x: Numpy array of input data or tuple. If tuple, the second elements is\n         either another numpy array or a list of numpy arrays, each of which gets\n@@ -1363,6 +1414,17 @@ def flip_axis(x, axis):\n class ImageDataGenerator():\n   \"\"\"Generate batches of tensor image data with real-time data augmentation.\n \n+  Warning: `tf.keras.preprocessing.image.ImageDataGenerator` is not recommended\n+  for new code. Prefer loading images with\n+  `tf.keras.utils.image_dataset_from_directory` and transforming the output\n+  `tf.data.Dataset` with preprocessing layers. For more information, see the\n+  tutorials for [loading images](\n+  https://www.tensorflow.org/tutorials/load_data/images) and\n+  [augmenting images](\n+  https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n+  the [preprocessing layer guide](\n+  https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n    The data will be looped over (in batches).\n \n   Args:\n@@ -2258,6 +2320,15 @@ def random_rotation(x, rg, row_axis=1, col_axis=2, channel_axis=0,\n                     fill_mode='nearest', cval=0., interpolation_order=1):\n   \"\"\"Performs a random rotation of a Numpy image tensor.\n \n+  Warning: `tf.keras.preprocessing.image.random_rotation` does not operate on\n+  tensors and is not recommended for new code. Prefer\n+  `tf.keras.layers.RandomRotation` which provides equivalent functionality as a\n+  preprocessing layer. For more information, see the tutorial for\n+  [augmenting images](\n+  https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n+  the [preprocessing layer guide](\n+  https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   Args:\n       x: Input tensor. Must be 3D.\n       rg: Rotation range, in degrees.\n@@ -2292,6 +2363,15 @@ def random_shift(x, wrg, hrg, row_axis=1, col_axis=2, channel_axis=0,\n                  fill_mode='nearest', cval=0., interpolation_order=1):\n   \"\"\"Performs a random spatial shift of a Numpy image tensor.\n \n+  Warning: `tf.keras.preprocessing.image.random_shift` does not operate on\n+  tensors and is not recommended for new code. Prefer\n+  `tf.keras.layers.RandomTranslation` which provides equivalent functionality as\n+  a preprocessing layer. For more information, see the tutorial for\n+  [augmenting images](\n+  https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n+  the [preprocessing layer guide](\n+  https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   Args:\n       x: Input tensor. Must be 3D.\n       wrg: Width shift range, as a float fraction of the width.\n@@ -2365,6 +2445,15 @@ def random_zoom(x, zoom_range, row_axis=1, col_axis=2, channel_axis=0,\n                 fill_mode='nearest', cval=0., interpolation_order=1):\n   \"\"\"Performs a random spatial zoom of a Numpy image tensor.\n \n+  Warning: `tf.keras.preprocessing.image.random_zoom` does not operate on\n+  tensors and is not recommended for new code. Prefer\n+  `tf.keras.layers.RandomZoom` which provides equivalent functionality as\n+  a preprocessing layer. For more information, see the tutorial for\n+  [augmenting images](\n+  https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n+  the [preprocessing layer guide](\n+  https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   Args:\n       x: Input tensor. Must be 3D.\n       zoom_range: Tuple of floats; zoom range for width and height.\n@@ -2477,6 +2566,15 @@ def apply_brightness_shift(x, brightness, scale=True):\n def random_brightness(x, brightness_range, scale=True):\n   \"\"\"Performs a random brightness shift.\n \n+  Warning: `tf.keras.preprocessing.image.random_brightness` does not operate on\n+  tensors and is not recommended for new code. Prefer\n+  `tf.keras.layers.RandomBrightness` which provides equivalent functionality as\n+  a preprocessing layer. For more information, see the tutorial for\n+  [augmenting images](\n+  https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n+  the [preprocessing layer guide](\n+  https://www.tensorflow.org/guide/keras/preprocessing_layers).\n+\n   Args:\n       x: Input tensor. Must be 3D.\n       brightness_range: Tuple of floats; brightness range.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5a767d922921d4d11a00611fd067f35c7c1a1627", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 39 | Contributors (this commit): 1 | Commits (past 90d): 4 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -19,13 +19,8 @@ _DTENSOR_API_ENABLED = False\n \n # Conditional import the dtensor API, since it is currently broken in OSS.\n if _DTENSOR_API_ENABLED:\n-  try:\n   # pylint: disable=g-direct-tensorflow-import, g-import-not-at-top\n   from tensorflow.dtensor import python as dtensor_api\n-  except ImportError:\n-    # TODO(b/222341036): Remove this conditional import after dtensor have a\n-    # trimmed target that can be used by Keras.\n-    dtensor_api = None\n else:\n   # Leave it with a placeholder, so that the import line from other python file\n   # will not break.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bd9768c799be6691734501afde664e5e0dc4b53e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 24 | Files Changed: 11 | Hunks: 28 | Methods Changed: 9 | Complexity Δ (Sum/Max): 117/42 | Churn Δ: 48 | Churn Cumulative: 13066 | Contributors (this commit): 79 | Commits (past 90d): 20 | Contributors (cumulative): 102 | DMM Complexity: None\n\nDIFF:\n@@ -31,5 +31,4 @@ from keras import backend\n from keras.preprocessing import image\n from keras.preprocessing import sequence\n from keras.preprocessing import text\n-from keras.preprocessing import timeseries\n from keras.utils import all_utils as utils\n\n@@ -38,7 +38,6 @@ import threading\n import warnings\n \n from keras import backend\n-from keras.preprocessing.image_dataset import image_dataset_from_directory  # pylint: disable=unused-import\n from keras.utils import data_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n\n@@ -32,7 +32,6 @@ import hashlib\n import json\n import warnings\n \n-from keras.preprocessing.text_dataset import text_dataset_from_directory  # pylint: disable=unused-import\n import numpy as np\n from tensorflow.python.util.tf_export import keras_export\n \n\n@@ -30,9 +30,12 @@ from keras.utils.generic_utils import deserialize_keras_object\n from keras.utils.generic_utils import get_custom_objects\n from keras.utils.generic_utils import Progbar\n from keras.utils.generic_utils import serialize_keras_object\n+from keras.utils.image_dataset import image_dataset_from_directory\n from keras.utils.layer_utils import get_source_inputs\n from keras.utils.np_utils import normalize\n from keras.utils.np_utils import to_categorical\n+from keras.utils.text_dataset import text_dataset_from_directory\n from keras.utils.tf_utils import set_random_seed\n+from keras.utils.timeseries_dataset import timeseries_dataset_from_array\n from keras.utils.vis_utils import model_to_dot\n from keras.utils.vis_utils import plot_model\n\n\n@@ -19,8 +19,8 @@ import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras.layers.preprocessing import image_preprocessing\n-from keras.preprocessing import dataset_utils\n from keras.preprocessing import image as keras_image_ops\n+from keras.utils import dataset_utils\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -23,7 +23,7 @@ import numpy as np\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n from keras.preprocessing import image as image_preproc\n-from keras.preprocessing import image_dataset\n+from keras.utils import image_dataset\n \n try:\n   import PIL  # pylint:disable=g-import-not-at-top\n\n@@ -17,7 +17,7 @@\n import tensorflow.compat.v2 as tf\n \n import numpy as np\n-from keras.preprocessing import dataset_utils\n+from keras.utils import dataset_utils\n from tensorflow.python.util.tf_export import keras_export\n \n \n\n@@ -22,7 +22,7 @@ import shutil\n import string\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n-from keras.preprocessing import text_dataset\n+from keras.utils import text_dataset\n \n \n @test_utils.run_v2_only\n\n\n@@ -12,13 +12,13 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-\"\"\"Tests for timeseries.\"\"\"\n+\"\"\"Tests for timeseries_dataset.\"\"\"\n \n import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras.testing_infra import test_utils\n-from keras.preprocessing import timeseries\n+from keras.utils import timeseries_dataset\n \n \n @test_utils.run_v2_only\n@@ -28,7 +28,7 @@ class TimeseriesDatasetTest(tf.test.TestCase):\n     # Test ordering, targets, sequence length, batch size\n     data = np.arange(100)\n     targets = data * 2\n-    dataset = timeseries.timeseries_dataset_from_array(\n+    dataset = timeseries_dataset.timeseries_dataset_from_array(\n         data, targets, sequence_length=9, batch_size=5)\n     # Expect 19 batches\n     for i, batch in enumerate(dataset):\n@@ -50,7 +50,7 @@ class TimeseriesDatasetTest(tf.test.TestCase):\n     data = np.arange(10)\n     offset = 3\n     targets = data[offset:]\n-    dataset = timeseries.timeseries_dataset_from_array(\n+    dataset = timeseries_dataset.timeseries_dataset_from_array(\n         data, targets, sequence_length=offset, batch_size=1)\n     i = 0\n     for batch in dataset:\n@@ -65,7 +65,7 @@ class TimeseriesDatasetTest(tf.test.TestCase):\n \n   def test_no_targets(self):\n     data = np.arange(50)\n-    dataset = timeseries.timeseries_dataset_from_array(\n+    dataset = timeseries_dataset.timeseries_dataset_from_array(\n         data, None, sequence_length=10, batch_size=5)\n     # Expect 9 batches\n     i = None\n@@ -83,7 +83,7 @@ class TimeseriesDatasetTest(tf.test.TestCase):\n     # Test cross-epoch random order and seed determinism\n     data = np.arange(10)\n     targets = data * 2\n-    dataset = timeseries.timeseries_dataset_from_array(\n+    dataset = timeseries_dataset.timeseries_dataset_from_array(\n         data, targets, sequence_length=5, batch_size=1, shuffle=True, seed=123)\n     first_seq = None\n     for x, y in dataset.take(1):\n@@ -94,7 +94,7 @@ class TimeseriesDatasetTest(tf.test.TestCase):\n     for x, _ in dataset.take(1):\n       self.assertNotAllClose(x, first_seq)\n     # Check determism with same seed\n-    dataset = timeseries.timeseries_dataset_from_array(\n+    dataset = timeseries_dataset.timeseries_dataset_from_array(\n         data, targets, sequence_length=5, batch_size=1, shuffle=True, seed=123)\n     for x, _ in dataset.take(1):\n       self.assertAllClose(x, first_seq)\n@@ -102,7 +102,7 @@ class TimeseriesDatasetTest(tf.test.TestCase):\n   def test_sampling_rate(self):\n     data = np.arange(100)\n     targets = data * 2\n-    dataset = timeseries.timeseries_dataset_from_array(\n+    dataset = timeseries_dataset.timeseries_dataset_from_array(\n         data, targets, sequence_length=9, batch_size=5, sampling_rate=2)\n     for i, batch in enumerate(dataset):\n       self.assertLen(batch, 2)\n@@ -123,7 +123,7 @@ class TimeseriesDatasetTest(tf.test.TestCase):\n   def test_sequence_stride(self):\n     data = np.arange(100)\n     targets = data * 2\n-    dataset = timeseries.timeseries_dataset_from_array(\n+    dataset = timeseries_dataset.timeseries_dataset_from_array(\n         data, targets, sequence_length=9, batch_size=5, sequence_stride=3)\n     for i, batch in enumerate(dataset):\n       self.assertLen(batch, 2)\n@@ -144,7 +144,7 @@ class TimeseriesDatasetTest(tf.test.TestCase):\n \n   def test_start_and_end_index(self):\n     data = np.arange(100)\n-    dataset = timeseries.timeseries_dataset_from_array(\n+    dataset = timeseries_dataset.timeseries_dataset_from_array(\n         data, None,\n         sequence_length=9, batch_size=5, sequence_stride=3, sampling_rate=2,\n         start_index=10, end_index=90)\n@@ -155,31 +155,31 @@ class TimeseriesDatasetTest(tf.test.TestCase):\n   def test_errors(self):\n     # bad start index\n     with self.assertRaisesRegex(ValueError, '`start_index` must be '):\n-      _ = timeseries.timeseries_dataset_from_array(\n+      _ = timeseries_dataset.timeseries_dataset_from_array(\n           np.arange(10), None, 3, start_index=-1)\n     with self.assertRaisesRegex(ValueError, '`start_index` must be '):\n-      _ = timeseries.timeseries_dataset_from_array(\n+      _ = timeseries_dataset.timeseries_dataset_from_array(\n           np.arange(10), None, 3, start_index=11)\n     # bad end index\n     with self.assertRaisesRegex(ValueError, '`end_index` must be '):\n-      _ = timeseries.timeseries_dataset_from_array(\n+      _ = timeseries_dataset.timeseries_dataset_from_array(\n           np.arange(10), None, 3, end_index=-1)\n     with self.assertRaisesRegex(ValueError, '`end_index` must be '):\n-      _ = timeseries.timeseries_dataset_from_array(\n+      _ = timeseries_dataset.timeseries_dataset_from_array(\n           np.arange(10), None, 3, end_index=11)\n     # bad sampling_rate\n     with self.assertRaisesRegex(ValueError, '`sampling_rate` must be '):\n-      _ = timeseries.timeseries_dataset_from_array(\n+      _ = timeseries_dataset.timeseries_dataset_from_array(\n           np.arange(10), None, 3, sampling_rate=0)\n     # bad sequence stride\n     with self.assertRaisesRegex(ValueError, '`sequence_stride` must be '):\n-      _ = timeseries.timeseries_dataset_from_array(\n+      _ = timeseries_dataset.timeseries_dataset_from_array(\n           np.arange(10), None, 3, sequence_stride=0)\n \n   def test_not_batched(self):\n     data = np.arange(100)\n \n-    dataset = timeseries.timeseries_dataset_from_array(\n+    dataset = timeseries_dataset.timeseries_dataset_from_array(\n         data, None, sequence_length=9, batch_size=None, shuffle=True)\n     sample = next(iter(dataset))\n     self.assertEqual(len(sample.shape), 1)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bb3c71ea2d21b204a779ebd9746a058eab3f80b1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 11 | Churn Cumulative: 18912 | Contributors (this commit): 130 | Commits (past 90d): 31 | Contributors (cumulative): 136 | DMM Complexity: 0.8333333333333334\n\nDIFF:\n@@ -1133,6 +1133,7 @@ class DataHandler:\n     \"\"\"\n \n     self._initial_epoch = initial_epoch\n+    self._initial_step = 0\n     self._epochs = epochs\n     self._insufficient_data = False\n     self._model = model\n@@ -1237,7 +1238,7 @@ class DataHandler:\n \n   def steps(self):\n     \"\"\"Yields steps for the current epoch.\"\"\"\n-    self._current_step = 0\n+    self._current_step = self._initial_step\n     # `self._inferred_steps` can be changed by `catch_stop_iteration`.\n     while (self._inferred_steps is None or\n            self._current_step < self._inferred_steps):\n\n@@ -1397,6 +1397,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         self.reset_metrics()\n         callbacks.on_epoch_begin(epoch)\n         with data_handler.catch_stop_iteration():\n+          data_handler._initial_step = self._maybe_load_initial_step_from_ckpt()  # pylint: disable=protected-access\n           for step in data_handler.steps():\n             with tf.profiler.experimental.Trace(\n                 'train',\n@@ -3141,8 +3142,15 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     if self._training_state is not None:\n       return self._training_state.maybe_load_initial_epoch_from_ckpt(\n           initial_epoch, mode=ModeKeys.TRAIN)\n+\n     return initial_epoch\n \n+  def _maybe_load_initial_step_from_ckpt(self):\n+    if getattr(self, '_callback_step', 0) > 0:\n+      return self._callback_step.numpy() + 1\n+\n+    return 0\n+\n   def _assert_compile_was_called(self):\n     # Checks whether `compile` has been called. If it has been called,\n     # then the optimizer is set. This is different from whether the\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5718c203cb8b815130230a92dee24412e98ee9af", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 4686 | Contributors (this commit): 22 | Commits (past 90d): 6 | Contributors (cumulative): 22 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1773,7 +1773,9 @@ def categorical_crossentropy(y_true,\n   Returns:\n     Categorical crossentropy loss value.\n   \"\"\"\n-  axis = int(axis)\n+  if isinstance(axis, bool):\n+    raise ValueError(\n+      '`axis` must be of type `int`.')\n   y_pred = tf.convert_to_tensor(y_pred)\n   y_true = tf.cast(y_true, y_pred.dtype)\n   label_smoothing = tf.convert_to_tensor(label_smoothing, dtype=y_pred.dtype)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0523fc3e6bfc5aa86bbc214247061c8cc3ea2ccd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 16887 | Contributors (this commit): 125 | Commits (past 90d): 31 | Contributors (cumulative): 125 | DMM Complexity: None\n\nDIFF:\n@@ -1861,7 +1861,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n \n     if not self.run_eagerly:\n       predict_function = tf.function(\n-          predict_function, experimental_relax_shapes=True)\n+          predict_function, experimental_relax_shapes=False)\n     self.predict_function = predict_function\n \n     return self.predict_function\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b67f90fa06176f6e0da23681f53dad9df7e88949", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 38 | Lines Deleted: 12 | Files Changed: 8 | Hunks: 12 | Methods Changed: 9 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 50 | Churn Cumulative: 1011 | Contributors (this commit): 4 | Commits (past 90d): 18 | Contributors (cumulative): 18 | DMM Complexity: 1.0\n\nDIFF:\n@@ -62,7 +62,7 @@ def add(inputs, **kwargs):\n   \"\"\"Functional interface to the `tf.keras.layers.Add` layer.\n \n   Args:\n-      inputs: A list of input tensors (at least 2) with the same shape.\n+      inputs: A list of input tensors with the same shape.\n       **kwargs: Standard layer keyword arguments.\n \n   Returns:\n\n@@ -80,7 +80,7 @@ def average(inputs, **kwargs):\n   >>> model = tf.keras.models.Model(inputs=[input1, input2], outputs=out)\n \n   Args:\n-      inputs: A list of input tensors (at least 2).\n+      inputs: A list of input tensors.\n       **kwargs: Standard layer keyword arguments.\n \n   Returns:\n\n@@ -83,9 +83,9 @@ class _Merge(Layer):\n       raise ValueError(\n           'A merge layer should be called on a list of inputs. '\n           f'Received: input_shape={input_shape} (not a list of shapes)')\n-    if len(input_shape) < 2:\n+    if len(input_shape) < 1:\n       raise ValueError('A merge layer should be called '\n-                       'on a list of at least 2 inputs. '\n+                       'on a list of at least 1 input. '\n                        f'Got {len(input_shape)} inputs. '\n                        f'Full input_shape received: {input_shape}')\n     batch_sizes = {s[0] for s in input_shape if s} - {None}\n\n@@ -207,7 +207,7 @@ def concatenate(inputs, axis=-1, **kwargs):\n         [25, 26, 27, 28, 29]]])>\n \n   Args:\n-      inputs: A list of input tensors (at least 2).\n+      inputs: A list of input tensors.\n       axis: Concatenation axis.\n       **kwargs: Standard layer keyword arguments.\n \n\n@@ -70,7 +70,7 @@ def maximum(inputs, **kwargs):\n   ```\n \n   Args:\n-      inputs: A list of input tensors (at least 2) of same shape.\n+      inputs: A list of input tensors of same shape.\n       **kwargs: Standard layer keyword arguments.\n \n   Returns:\n\n@@ -19,6 +19,7 @@ import keras\n from keras import backend\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n+from keras.utils import tf_inspect\n import numpy as np\n import tensorflow.compat.v2 as tf\n \n@@ -271,6 +272,35 @@ class MergingLayersTest(test_combinations.TestCase):\n     out = layer()([x1, x2])\n     self.assertEqual(out.shape, ())\n \n+  @parameterized.named_parameters(\n+      *test_utils.generate_combinations_with_testcase_name(\n+          layer=[keras.layers.Add, keras.layers.add,\n+                 keras.layers.Average, keras.layers.average,\n+                 keras.layers.Concatenate, keras.layers.concatenate,\n+                 keras.layers.Maximum, keras.layers.maximum,\n+                 keras.layers.Minimum, keras.layers.minimum,\n+                 keras.layers.Multiply, keras.layers.multiply]))\n+  def test_single_element(self, layer):\n+    # Instantiate the Layer subclasses\n+    if tf_inspect.isclass(layer) and issubclass(layer, keras.layers.Layer):\n+      layer = layer()\n+\n+    # Processing a single element list should behave as identity.\n+    i1 = keras.layers.Input(shape=(4, 5))\n+    o = layer([i1])\n+    self.assertListEqual(o.shape.as_list(), [None, 4, 5])\n+    model = keras.models.Model(i1, o)\n+    model.run_eagerly = test_utils.should_run_eagerly()\n+\n+    x1 = np.random.random((2, 4, 5))\n+    out = model.predict(x1)\n+    self.assertEqual(out.shape, (2, 4, 5))\n+    self.assertAllClose(out, x1)\n+\n+    # A single element must be passed as a list, not by itself.\n+    with self.assertRaises(ValueError):\n+      layer(i1)\n+\n \n @test_combinations.generate(test_combinations.combine(mode=['graph', 'eager']))\n class MergingLayersTestNoExecution(tf.test.TestCase):\n@@ -280,12 +310,8 @@ class MergingLayersTestNoExecution(tf.test.TestCase):\n     i2 = keras.layers.Input(shape=(4, 6))\n     with self.assertRaises(ValueError):\n       keras.layers.add([i1, i2])\n-    with self.assertRaises(ValueError):\n-      keras.layers.add([i1])\n     with self.assertRaises(ValueError):\n       keras.layers.add(i1)\n-    with self.assertRaises(ValueError):\n-      keras.layers.add([i1])\n \n   def test_concatenate_errors(self):\n     i1 = keras.layers.Input(shape=(4, 5))\n\n@@ -56,7 +56,7 @@ def minimum(inputs, **kwargs):\n   \"\"\"Functional interface to the `Minimum` layer.\n \n   Args:\n-      inputs: A list of input tensors (at least 2).\n+      inputs: A list of input tensors.\n       **kwargs: Standard layer keyword arguments.\n \n   Returns:\n\n@@ -72,7 +72,7 @@ def multiply(inputs, **kwargs):\n   >>> model = tf.keras.models.Model(inputs=[input1, input2], outputs=out)\n \n   Args:\n-      inputs: A list of input tensors (at least 2).\n+      inputs: A list of input tensors.\n       **kwargs: Standard layer keyword arguments.\n \n   Returns:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#802ef25756089cc55dd49c0b47377a76edf8958c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 58 | Lines Deleted: 16 | Files Changed: 18 | Hunks: 27 | Methods Changed: 0 | Complexity Δ (Sum/Max): 92/46 | Churn Δ: 74 | Churn Cumulative: 12233 | Contributors (this commit): 110 | Commits (past 90d): 76 | Contributors (cumulative): 150 | DMM Complexity: None\n\nDIFF:\n@@ -29,7 +29,7 @@ import time\n from keras import backend\n from keras.distribute import distributed_file_utils\n from keras.distribute import worker_training_state\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.utils import generic_utils\n from keras.utils import io_utils\n from keras.utils import tf_utils\n\n@@ -34,8 +34,8 @@ from keras.callbacks import BackupAndRestoreExperimental\n from keras.engine import sequential\n from keras.layers import Activation\n from keras.layers import Dense\n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers.optimizer_v2 import gradient_descent\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n from keras.utils import io_utils\n\n@@ -15,13 +15,13 @@\n \"\"\"DTensor specific Keras optimizers.\"\"\"\n \n from keras.dtensor import dtensor_api as dtensor\n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers.optimizer_experimental import adadelta\n from keras.optimizers.optimizer_experimental import adagrad\n from keras.optimizers.optimizer_experimental import adam\n from keras.optimizers.optimizer_experimental import optimizer as optimizer_lib\n from keras.optimizers.optimizer_experimental import rmsprop\n from keras.optimizers.optimizer_experimental import sgd\n+from keras.optimizers.schedules import learning_rate_schedule\n \n import tensorflow.compat.v2 as tf\n \n\n@@ -13,6 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n # pylint: disable=invalid-name\n+# pylint: disable=g-bad-import-order\n \"\"\"Built-in optimizer classes.\n \n For more examples see the base class `tf.keras.optimizers.Optimizer`.\n@@ -20,6 +21,18 @@ For more examples see the base class `tf.keras.optimizers.Optimizer`.\n \n import tensorflow.compat.v2 as tf\n \n+# Symbols to be accessed under keras.optimizers. To be replaced with\n+# optimizers v2022 when they graduate out of experimental.\n+from keras.optimizers.optimizer_v2.gradient_descent import SGD\n+from keras.optimizers.optimizer_v2.rmsprop import RMSprop\n+from keras.optimizers.optimizer_v2.adam import Adam\n+from keras.optimizers.optimizer_v2.adadelta import Adadelta\n+from keras.optimizers.optimizer_v2.adagrad import Adagrad\n+from keras.optimizers.optimizer_v2.adamax import Adamax\n+from keras.optimizers.optimizer_v2.nadam import Nadam\n+from keras.optimizers.optimizer_v2.ftrl import Ftrl\n+\n+# Imports needed for deserialization.\n from keras import backend\n from keras.optimizers.optimizer_experimental import optimizer as optimizer_experimental\n from keras.optimizers.optimizer_experimental import adadelta as adadelta_experimental\n\n@@ -13,3 +13,12 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Legacy optimizer package.\"\"\"\n+\n+from keras.optimizers.legacy.adadelta import Adadelta\n+from keras.optimizers.legacy.adagrad import Adagrad\n+from keras.optimizers.legacy.adam import Adam\n+from keras.optimizers.legacy.adamax import Adamax\n+from keras.optimizers.legacy.ftrl import Ftrl\n+from keras.optimizers.legacy.nadam import Nadam\n+from keras.optimizers.legacy.rmsprop import RMSprop\n+from keras.optimizers.legacy.sgd import SGD\n\n@@ -17,7 +17,7 @@\n import tensorflow.compat.v2 as tf\n \n import functools\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n from tensorflow.python.util.tf_export import tf_export\n \n \n\n@@ -22,8 +22,8 @@ from absl import logging\n \n from keras import backend\n from keras import initializers\n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers.optimizer_v2 import utils as optimizer_utils\n+from keras.optimizers.schedules import learning_rate_schedule\n import tensorflow.compat.v2 as tf\n # pylint: disable=g-direct-tensorflow-import\n from tensorflow.python.util.tf_export import keras_export\n\n@@ -9,7 +9,6 @@ import re\n from absl import logging\n from absl.testing import parameterized\n import keras\n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers.optimizer_experimental import adadelta as adadelta_new\n from keras.optimizers.optimizer_experimental import adagrad as adagrad_new\n from keras.optimizers.optimizer_experimental import adam as adam_new\n@@ -25,6 +24,7 @@ from keras.optimizers.optimizer_v2 import adam as adam_old\n from keras.optimizers.optimizer_v2 import ftrl as ftrl_old\n from keras.optimizers.optimizer_v2 import gradient_descent as sgd_old\n from keras.optimizers.optimizer_v2 import rmsprop as rmsprop_old\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.utils import losses_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n\n@@ -22,7 +22,7 @@ from absl.testing import parameterized\n import numpy as np\n from keras.testing_infra import test_combinations\n from keras.optimizers.optimizer_v2 import adagrad\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n \n _DATA_TYPES = [\n     tf.half, tf.float32, tf.float64, tf.complex64,\n\n@@ -21,7 +21,7 @@ import numpy as np\n from keras.testing_infra import test_combinations\n from keras.optimizers import optimizer_v1\n from keras.optimizers.optimizer_v2 import adam\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n \n \n def adam_update_numpy(param,\n\n@@ -20,7 +20,7 @@ from absl.testing import parameterized\n import numpy as np\n from keras.testing_infra import test_combinations\n from keras.optimizers.optimizer_v2 import gradient_descent\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n \n \n class GradientDescentOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n\n@@ -16,7 +16,7 @@\n \n import tensorflow.compat.v2 as tf\n from keras import backend_config\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n \n\n@@ -23,8 +23,8 @@ import warnings\n from keras import backend\n from keras import initializers\n from keras.engine import base_layer_utils\n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers.optimizer_v2 import utils as optimizer_utils\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.utils import generic_utils\n from keras.utils import layer_utils\n from keras.utils import tf_inspect\n\n@@ -26,7 +26,6 @@ from keras.engine import sequential\n from keras.engine import training\n from keras.layers import core\n from keras.layers import regularization\n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers import optimizer_v1\n from keras.optimizers.optimizer_v2 import adadelta\n from keras.optimizers.optimizer_v2 import adagrad\n@@ -37,6 +36,7 @@ from keras.optimizers.optimizer_v2 import gradient_descent\n from keras.optimizers.optimizer_v2 import nadam\n from keras.optimizers.optimizer_v2 import optimizer_v2\n from keras.optimizers.optimizer_v2 import rmsprop\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n from keras.utils import np_utils\n\n@@ -25,7 +25,7 @@ import numpy as np\n from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.optimizers.optimizer_v2 import rmsprop\n \n _DATA_TYPES = [\n\n@@ -0,0 +1,20 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Learning rate schedule API.\"\"\"\n+\n+from keras.optimizers.schedules.learning_rate_schedules import ExponentialDecay\n+from keras.optimizers.schedules.learning_rate_schedules import InverseTimeDecay\n+from keras.optimizers.schedules.learning_rate_schedules import PiecewiseConstantDecay\n+from keras.optimizers.schedules.learning_rate_schedules import PolynomialDecay\n\n@@ -12,7 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-\"\"\"Various learning rate decay functions.\"\"\"\n+\"\"\"Various learning rate schedule functions.\"\"\"\n \n import tensorflow.compat.v2 as tf\n \n\n@@ -12,14 +12,14 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-\"\"\"Functional test for learning rate decay.\"\"\"\n+\"\"\"Tests for learning rate schedule API.\"\"\"\n \n import math\n \n from absl.testing import parameterized\n \n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers.optimizer_v2 import gradient_descent\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.testing_infra import test_combinations\n import numpy as np\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
