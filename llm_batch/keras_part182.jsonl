{"custom_id": "keras#90cf7b9ed25046e64acd35d1a9ea26187cb08176", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 68 | Lines Deleted: 17 | Files Changed: 1 | Hunks: 7 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 85 | Churn Cumulative: 9728 | Contributors (this commit): 41 | Commits (past 90d): 43 | Contributors (cumulative): 41 | DMM Complexity: 0.058823529411764705\n\nDIFF:\n@@ -1232,7 +1232,10 @@ class ZeroPadding1D(Layer):\n         self.input_spec = InputSpec(ndim=3)\n \n     def compute_output_shape(self, input_shape):\n-        length = input_shape[1] + self.padding[0] + self.padding[1] if input_shape[1] is not None else None\n+        if input_shape[1] is not None:\n+            length = input_shape[1] + self.padding[0] + self.padding[1]\n+        else:\n+            length = None\n         return (input_shape[0],\n                 length,\n                 input_shape[2])\n@@ -1318,15 +1321,27 @@ class ZeroPadding2D(Layer):\n \n     def compute_output_shape(self, input_shape):\n         if self.data_format == 'channels_first':\n-            rows = input_shape[2] + self.padding[0][0] + self.padding[0][1] if input_shape[2] is not None else None\n-            cols = input_shape[3] + self.padding[1][0] + self.padding[1][1] if input_shape[3] is not None else None\n+            if input_shape[2] is not None:\n+                rows = input_shape[2] + self.padding[0][0] + self.padding[0][1]\n+            else:\n+                rows = None\n+            if input_shape[3] is not None:\n+                cols = input_shape[3] + self.padding[1][0] + self.padding[1][1]\n+            else:\n+                cols = None\n             return (input_shape[0],\n                     input_shape[1],\n                     rows,\n                     cols)\n         elif self.data_format == 'channels_last':\n-            rows = input_shape[1] + self.padding[0][0] + self.padding[0][1] if input_shape[1] is not None else None\n-            cols = input_shape[2] + self.padding[1][0] + self.padding[1][1] if input_shape[2] is not None else None\n+            if input_shape[1] is not None:\n+                rows = input_shape[1] + self.padding[0][0] + self.padding[0][1]\n+            else:\n+                rows = None\n+            if input_shape[2] is not None:\n+                cols = input_shape[2] + self.padding[1][0] + self.padding[1][1]\n+            else:\n+                cols = None\n             return (input_shape[0],\n                     rows,\n                     cols,\n@@ -1414,18 +1429,36 @@ class ZeroPadding3D(Layer):\n \n     def compute_output_shape(self, input_shape):\n         if self.data_format == 'channels_first':\n-            dim1 = input_shape[2] + 2 * self.padding[0][0] if input_shape[2] is not None else None\n-            dim2 = input_shape[3] + 2 * self.padding[1][0] if input_shape[3] is not None else None\n-            dim3 = input_shape[4] + 2 * self.padding[2][0] if input_shape[4] is not None else None\n+            if input_shape[2] is not None:\n+                dim1 = input_shape[2] + 2 * self.padding[0][0]\n+            else:\n+                dim1 = None\n+            if input_shape[3] is not None:\n+                dim2 = input_shape[3] + 2 * self.padding[1][0]\n+            else:\n+                dim2 = None\n+            if input_shape[4] is not None:\n+                dim3 = input_shape[4] + 2 * self.padding[2][0]\n+            else:\n+                dim3 = None\n             return (input_shape[0],\n                     input_shape[1],\n                     dim1,\n                     dim2,\n                     dim3)\n         elif self.data_format == 'channels_last':\n-            dim1 = input_shape[1] + 2 * self.padding[0][1] if input_shape[1] is not None else None\n-            dim2 = input_shape[2] + 2 * self.padding[1][1] if input_shape[2] is not None else None\n-            dim3 = input_shape[3] + 2 * self.padding[2][1] if input_shape[3] is not None else None\n+            if input_shape[1] is not None:\n+                dim1 = input_shape[1] + 2 * self.padding[0][1]\n+            else:\n+                dim1 = None\n+            if input_shape[2] is not None:\n+                dim2 = input_shape[2] + 2 * self.padding[1][1]\n+            else:\n+                dim2 = None\n+            if input_shape[3] is not None:\n+                dim3 = input_shape[3] + 2 * self.padding[2][1]\n+            else:\n+                dim3 = None\n             return (input_shape[0],\n                     dim1,\n                     dim2,\n@@ -1705,18 +1738,36 @@ class Cropping3D(Layer):\n \n     def compute_output_shape(self, input_shape):\n         if self.data_format == 'channels_first':\n-            dim1 = input_shape[2] - self.cropping[0][0] - self.cropping[0][1] if input_shape[2] is not None else None\n-            dim2 = input_shape[3] - self.cropping[1][0] - self.cropping[1][1] if input_shape[3] is not None else None\n-            dim3 = input_shape[4] - self.cropping[2][0] - self.cropping[2][1] if input_shape[4] is not None else None\n+            if input_shape[2] is not None:\n+                dim1 = input_shape[2] - self.cropping[0][0] - self.cropping[0][1]\n+            else:\n+                dim1 = None\n+            if input_shape[3] is not None:\n+                dim2 = input_shape[3] - self.cropping[1][0] - self.cropping[1][1]\n+            else:\n+                dim2 = None\n+            if input_shape[4] is not None:\n+                dim3 = input_shape[4] - self.cropping[2][0] - self.cropping[2][1]\n+            else:\n+                dim3 = None\n             return (input_shape[0],\n                     input_shape[1],\n                     dim1,\n                     dim2,\n                     dim3)\n         elif self.data_format == 'channels_last':\n-            dim1 = input_shape[1] - self.cropping[0][0] - self.cropping[0][1] if input_shape[1] is not None else None\n-            dim2 = input_shape[2] - self.cropping[1][0] - self.cropping[1][1] if input_shape[2] is not None else None\n-            dim3 = input_shape[3] - self.cropping[2][0] - self.cropping[2][1] if input_shape[3] is not None else None\n+            if input_shape[1] is not None:\n+                dim1 = input_shape[1] - self.cropping[0][0] - self.cropping[0][1]\n+            else:\n+                dim1 = None\n+            if input_shape[2] is not None:\n+                dim2 = input_shape[2] - self.cropping[1][0] - self.cropping[1][1]\n+            else:\n+                dim2 = None\n+            if input_shape[3] is not None:\n+                dim3 = input_shape[3] - self.cropping[2][0] - self.cropping[2][1]\n+            else:\n+                dim3 = None\n             return (input_shape[0],\n                     dim1,\n                     dim2,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#938788bd0188c8030d38f00bee06068eaf81f6f5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 4613 | Contributors (this commit): 41 | Commits (past 90d): 44 | Contributors (cumulative): 43 | DMM Complexity: 0.0\n\nDIFF:\n@@ -939,7 +939,8 @@ class Model(Container):\n                     # (because of class mode duality)\n                     output_shape = self.internal_output_shapes[i]\n                     acc_fn = None\n-                    if output_shape[-1] == 1 or self.loss_functions[i] == losses.binary_crossentropy:\n+                    if (output_shape[-1] == 1 or\n+                       self.loss_functions[i] == losses.binary_crossentropy):\n                         # case: binary accuracy\n                         acc_fn = metrics_module.binary_accuracy\n                     elif self.loss_functions[i] == losses.sparse_categorical_crossentropy:\n\n@@ -58,7 +58,7 @@ else:\n \n \n def _extract_archive(file_path, path='.', archive_format='auto'):\n-    \"\"\"Extracts an archive if it matches the tar, tar.gz, tar.bz, or zip formats\n+    \"\"\"Extracts an archive if it matches tar, tar.gz, tar.bz, or zip formats.\n \n     # Arguments\n         file_path: path to the archive file\n@@ -69,7 +69,7 @@ def _extract_archive(file_path, path='.', archive_format='auto'):\n             The default 'auto' is ['tar', 'zip'].\n             None or an empty list will return no matches found.\n \n-    # Return:\n+    # Returns\n         True if a match was found and an archive extraction was completed,\n         False otherwise.\n     \"\"\"\n@@ -93,7 +93,7 @@ def _extract_archive(file_path, path='.', archive_format='auto'):\n                 try:\n                     archive.extractall(path)\n                 except (tarfile.TarError, RuntimeError,\n-                        KeyboardInterrupt) as e:\n+                        KeyboardInterrupt):\n                     if os.path.exists(path):\n                         if os.path.isfile(path):\n                             os.remove(path)\n@@ -104,9 +104,12 @@ def _extract_archive(file_path, path='.', archive_format='auto'):\n     return False\n \n \n-def get_file(fname, origin, untar=False,\n-             md5_hash=None, cache_subdir='datasets',\n+def get_file(fname,\n+             origin,\n+             untar=False,\n+             md5_hash=None,\n              file_hash=None,\n+             cache_subdir='datasets',\n              hash_algorithm='auto',\n              extract=False,\n              archive_format='auto',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#edaa1d479dc27c30898bd00c09caf7c8a1ae1ed4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 7675 | Contributors (this commit): 32 | Commits (past 90d): 54 | Contributors (cumulative): 32 | DMM Complexity: 0.0\n\nDIFF:\n@@ -543,6 +543,7 @@ class Layer(object):\n \n             # Handle mask propagation.\n             previous_mask = _collect_previous_mask(inputs)\n+            user_kwargs = copy.copy(kwargs)\n             if not _is_all_none(previous_mask):\n                 # The previous layer generated a mask.\n                 if 'mask' in inspect.getargspec(self.call).args:\n@@ -574,7 +575,7 @@ class Layer(object):\n             self._add_inbound_node(input_tensors=inputs, output_tensors=output,\n                                    input_masks=previous_mask, output_masks=output_mask,\n                                    input_shapes=input_shape, output_shapes=output_shape,\n-                                   arguments=kwargs)\n+                                   arguments=user_kwargs)\n \n             # Apply activity regularizer if any:\n             if hasattr(self, 'activity_regularizer') and self.activity_regularizer is not None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3838f554891b6ea0031a02e4f3953bb7d8b78543", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 58 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 14/14 | Churn Δ: 59 | Churn Cumulative: 2533 | Contributors (this commit): 42 | Commits (past 90d): 17 | Contributors (cumulative): 42 | DMM Complexity: 0.17142857142857143\n\nDIFF:\n@@ -22,6 +22,7 @@ except ImportError:\n \n if K.backend() == 'tensorflow':\n     import tensorflow as tf\n+    from tensorflow.contrib.tensorboard.plugins import projector\n \n \n class CallbackList(object):\n@@ -590,12 +591,24 @@ class TensorBoard(Callback):\n             write_graph is set to True.\n         write_images: whether to write model weights to visualize as\n             image in Tensorboard.\n+        embeddings_freq: frequency (in epochs) at which selected embedding\n+            layers will be saved.\n+        embeddings_layer_names: a list of names of layers to keep eye on. If\n+            None or empty list all the embedding layer will be watched.\n+        embeddings_metadata: a dictionary which maps layer name to a file name\n+            in which metadata for this embedding layer is saved. See the\n+            [details](https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional)\n+            about metadata files format. In case if the same metadata file is\n+            used for all embedding layers, string can be passed.\n     \"\"\"\n \n     def __init__(self, log_dir='./logs',\n                  histogram_freq=0,\n                  write_graph=True,\n-                 write_images=False):\n+                 write_images=False,\n+                 embeddings_freq=0,\n+                 embeddings_layer_names=None,\n+                 embeddings_metadata={}):\n         super(TensorBoard, self).__init__()\n         if K.backend() != 'tensorflow':\n             raise RuntimeError('TensorBoard callback only works '\n@@ -605,6 +618,9 @@ class TensorBoard(Callback):\n         self.merged = None\n         self.write_graph = write_graph\n         self.write_images = write_images\n+        self.embeddings_freq = embeddings_freq\n+        self.embeddings_layer_names = embeddings_layer_names\n+        self.embeddings_metadata = embeddings_metadata\n \n     def set_model(self, model):\n         self.model = model\n@@ -635,6 +651,42 @@ class TensorBoard(Callback):\n         else:\n             self.writer = tf.summary.FileWriter(self.log_dir)\n \n+        if self.embeddings_freq:\n+            self.saver = tf.train.Saver()\n+\n+            embeddings_layer_names = self.embeddings_layer_names\n+\n+            if not embeddings_layer_names:\n+                embeddings_layer_names = [layer.name for layer in self.model.layers\n+                                          if type(layer).__name__ == 'Embedding']\n+\n+            embeddings = {layer.name: layer.weights[0]\n+                          for layer in self.model.layers\n+                          if layer.name in embeddings_layer_names}\n+\n+            embeddings_metadata = {}\n+\n+            if not isinstance(self.embeddings_metadata, str):\n+                embeddings_metadata = self.embeddings_metadata\n+            else:\n+                embeddings_metadata = {layer_name: self.embeddings_metadata\n+                                       for layer_name in embeddings.keys()}\n+\n+            config = projector.ProjectorConfig()\n+            self.embeddings_logs = []\n+\n+            for layer_name, tensor in embeddings.items():\n+                embedding = config.embeddings.add()\n+                embedding.tensor_name = tensor.name\n+\n+                self.embeddings_logs.append(os.path.join(self.log_dir,\n+                                                         layer_name + '.ckpt'))\n+\n+                if layer_name in embeddings_metadata:\n+                    embedding.metadata_path = embeddings_metadata[layer_name]\n+\n+            projector.visualize_embeddings(self.writer, config)\n+\n     def on_epoch_end(self, epoch, logs=None):\n         logs = logs or {}\n \n@@ -654,6 +706,11 @@ class TensorBoard(Callback):\n                 summary_str = result[0]\n                 self.writer.add_summary(summary_str, epoch)\n \n+        if self.embeddings_freq and self.embeddings_logs:\n+            if epoch % self.embeddings_freq == 0:\n+                for log in self.embeddings_logs:\n+                    self.saver.save(self.sess, log, epoch)\n+\n         for name, value in logs.items():\n             if name in ['batch', 'size']:\n                 continue\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d660bd15c5630cf20d05a7367262a25af2b00ef5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 7464 | Contributors (this commit): 69 | Commits (past 90d): 58 | Contributors (cumulative): 69 | DMM Complexity: 1.0\n\nDIFF:\n@@ -151,6 +151,7 @@ def get_session():\n             _SESSION = tf.Session(config=config)\n         session = _SESSION\n     if not _MANUAL_VAR_INIT:\n+        with session.graph.as_default():\n             _initialize_variables()\n     return session\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#466bb39aa113a09844d6677516497242e6a5f4fb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 98 | Lines Deleted: 23 | Files Changed: 4 | Hunks: 17 | Methods Changed: 17 | Complexity Δ (Sum/Max): 17/13 | Churn Δ: 121 | Churn Cumulative: 9852 | Contributors (this commit): 39 | Commits (past 90d): 85 | Contributors (cumulative): 46 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1029,7 +1029,7 @@ class Layer(object):\n                 (e.g. L2 weight regularization, which only depends\n                 on the layer's weights variables, not on any inputs tensors).\n         \"\"\"\n-        if losses is None:\n+        if losses is None or losses == []:\n             return\n         # Update self.losses\n         losses = _to_list(losses)\n@@ -1046,6 +1046,8 @@ class Layer(object):\n         # Update self._per_input_updates\n         if not hasattr(self, '_per_input_losses'):\n             self._per_input_losses = {}\n+        if inputs == []:\n+            inputs = None\n         if inputs is not None:\n             inputs_hash = _object_list_uid(inputs)\n         else:\n@@ -1069,7 +1071,7 @@ class Layer(object):\n                 the updates as conditional on these inputs.\n                 If None is passed, the updates are assumed unconditional.\n         \"\"\"\n-        if updates is None:\n+        if updates is None or updates == []:\n             return\n         # Update self.updates\n         updates = _to_list(updates)\n@@ -1086,6 +1088,8 @@ class Layer(object):\n         # Update self._per_input_updates\n         if not hasattr(self, '_per_input_updates'):\n             self._per_input_updates = {}\n+        if inputs == []:\n+            inputs = None\n         if inputs is not None:\n             inputs_hash = _object_list_uid(inputs)\n         else:\n@@ -1800,9 +1804,6 @@ class Container(Layer):\n         updates = []\n         for layer in self.layers:\n             if hasattr(layer, 'updates'):\n-                if len(layer.inbound_nodes) == 1:\n-                    updates += layer.updates\n-                else:\n                 # Collect updates that are dependent on inputs\n                 # that are part of the model.\n                 for node_index, node in enumerate(layer.inbound_nodes):\n@@ -1831,9 +1832,6 @@ class Container(Layer):\n         # Retrieve losses for all internal layers.\n         for layer in self.layers:\n             if hasattr(layer, 'losses'):\n-                if len(layer.inbound_nodes) == 1:\n-                    losses += layer.losses\n-                else:\n                 # Collect losses that are dependent on inputs\n                 # that are part of the model.\n                 for node_index, node in enumerate(layer.inbound_nodes):\n@@ -1845,8 +1843,7 @@ class Container(Layer):\n                 # Collect unconditional losses.\n                 losses += layer.get_losses_for(None)\n         # Add any potential unconditional model-level loss.\n-        if hasattr(self, '_per_input_losses'):\n-            losses += self._per_input_losses.get(None, [])\n+        losses += self.get_losses_for(None)\n         return losses\n \n     @property\n@@ -2129,6 +2126,7 @@ class Container(Layer):\n                 for x in reference_input_tensors:\n                     if str(id(x)) in tensor_map:\n                         computed_data.append(tensor_map[str(id(x))])\n+\n                 if len(computed_data) == len(reference_input_tensors):\n                     # call layer\n                     with K.name_scope(layer.name):\n@@ -2156,16 +2154,20 @@ class Container(Layer):\n                             output_masks = _to_list(layer.compute_mask(computed_tensors,\n                                                                        computed_masks))\n \n+                        # Apply activity regularizer if any:\n+                        if hasattr(layer, 'activity_regularizer') and layer.activity_regularizer is not None:\n+                            regularization_losses = [layer.activity_regularizer(x) for x in computed_tensors]\n+                            layer.add_loss(regularization_losses, computed_tensors)\n+\n                     # Update model updates and losses:\n-                    layer_inputs = [x[0] for x in computed_data]\n                     # Keep track of updates that depend on the inputs\n                     # (e.g. BN updates).\n-                    self.add_update(layer.get_updates_for(layer_inputs), inputs)\n+                    self.add_update(layer.get_updates_for(computed_tensors), inputs)\n                     # Keep track of unconditional updates (e.g. a counter).\n                     self.add_update(layer.get_updates_for(None), None)\n                     # Keep track of losses that depend on the inputs\n                     # (e.g. activity regularizers).\n-                    self.add_loss(layer.get_losses_for(layer_inputs), inputs)\n+                    self.add_loss(layer.get_losses_for(computed_tensors), inputs)\n                     # Keep track of unconditional losses\n                     # (e.g. weight regularizers).\n                     self.add_loss(layer.get_losses_for(None), None)\n\n@@ -24,18 +24,53 @@ class Wrapper(Layer):\n         super(Wrapper, self).__init__(**kwargs)\n \n     def build(self, input_shape=None):\n-        # Assumes that self.layer is already set.\n-        # Should be called at the end of .build() in the children classes.\n-        self.trainable_weights = getattr(self.layer, 'trainable_weights', [])\n-        self.non_trainable_weights = getattr(self.layer, 'non_trainable_weights', [])\n-        self.updates = getattr(self.layer, 'updates', [])\n-        self.losses = getattr(self.layer, 'losses', [])\n-        self.constraints = getattr(self.layer, 'constraints', {})\n         self.built = True\n \n+    @property\n+    def activity_regularizer(self):\n+        if hasattr(self.layer, 'activity_regularizer'):\n+            return self.layer.activity_regularizer\n+        else:\n+            return None\n+\n+    @property\n+    def trainable_weights(self):\n+        return self.layer.trainable_weights\n+\n+    @property\n+    def non_trainable_weights(self):\n+        return self.layer.non_trainable_weights\n+\n+    @property\n+    def updates(self):\n+        if hasattr(self.layer, 'updates'):\n+            return self.layer.updates\n+        return []\n+\n+    def get_updates_for(self, inputs=None):\n+        if inputs is None:\n+            updates = self.layer.get_updates_for(None)\n+            return updates + super(Wrapper, self).get_updates_for(None)\n+        return super(Wrapper, self).get_updates_for(inputs)\n+\n+    @property\n+    def losses(self):\n+        if hasattr(self.layer, 'losses'):\n+            return self.layer.losses\n+        return []\n+\n+    def get_losses_for(self, inputs=None):\n+        if inputs is None:\n+            losses = self.layer.get_losses_for(None)\n+            return losses + super(Wrapper, self).get_losses_for(None)\n+        return super(Wrapper, self).get_losses_for(inputs)\n+\n+    @property\n+    def constraints(self):\n+        return self.layer.constraints\n+\n     def get_weights(self):\n-        weights = self.layer.get_weights()\n-        return weights\n+        return self.layer.get_weights()\n \n     def set_weights(self, weights):\n         self.layer.set_weights(weights)\n\n@@ -489,5 +489,32 @@ def test_recursion():\n         Dense(2)(x)\n \n \n+@keras_test\n+def test_recursion_with_bn_and_loss():\n+    model1 = Sequential([\n+        layers.Dense(5, input_dim=5, activity_regularizer='l1'),\n+        layers.BatchNormalization(),\n+        layers.Dense(5),\n+    ])\n+\n+    print('NEW MODEL')\n+    inputs = layers.Input(shape=(5,))\n+    outputs = model1(inputs)\n+    model2 = Model(inputs=inputs, outputs=outputs)\n+\n+    assert len(model1.updates) == 2\n+    assert len(model2.updates) == 2\n+    assert len(model1.losses) == 1\n+    assert len(model2.losses) == 1, model2.layers[1]._per_input_losses\n+\n+    model1.compile(optimizer='sgd', loss='categorical_crossentropy')\n+    model2.compile(optimizer='sgd', loss='categorical_crossentropy')\n+\n+    x = np.ones((3, 5))\n+    y = np.ones((3, 5))\n+    model1.fit(x, y, verbose=0, epochs=1)\n+    model2.fit(x, y, verbose=0, epochs=1)\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n@@ -90,7 +90,18 @@ def test_TimeDistributed():\n @keras_test\n def test_regularizers():\n     model = Sequential()\n-    model.add(wrappers.TimeDistributed(core.Dense(2, kernel_regularizer='l1'), input_shape=(3, 4)))\n+    model.add(wrappers.TimeDistributed(\n+        core.Dense(2, kernel_regularizer='l1'), input_shape=(3, 4)))\n+    model.add(core.Activation('relu'))\n+    model.compile(optimizer='rmsprop', loss='mse')\n+    assert len(model.layers[0].layer.losses) == 1\n+    assert len(model.layers[0].losses) == 1\n+    assert len(model.layers[0].get_losses_for(None)) == 1\n+    assert len(model.losses) == 1\n+\n+    model = Sequential()\n+    model.add(wrappers.TimeDistributed(\n+        core.Dense(2, activity_regularizer='l1'), input_shape=(3, 4)))\n     model.add(core.Activation('relu'))\n     model.compile(optimizer='rmsprop', loss='mse')\n     assert len(model.losses) == 1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#debbd4740547ab06c38e0dfa8a1852402fc0eb2c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 9 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 19 | Churn Cumulative: 177 | Contributors (this commit): 8 | Commits (past 90d): 6 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -12,20 +12,22 @@ from .common import image_data_format\n from .common import set_image_data_format\n from .common import is_keras_tensor\n \n+# Obtain Keras base dir path: either ~/.keras or /tmp.\n _keras_base_dir = os.path.expanduser('~')\n if not os.access(_keras_base_dir, os.W_OK):\n     _keras_base_dir = '/tmp'\n-\n _keras_dir = os.path.join(_keras_base_dir, '.keras')\n-if not os.path.exists(_keras_dir):\n-    os.makedirs(_keras_dir)\n \n # Default backend: TensorFlow.\n _BACKEND = 'tensorflow'\n \n+# Attempt to read Keras config file.\n _config_path = os.path.expanduser(os.path.join(_keras_dir, 'keras.json'))\n if os.path.exists(_config_path):\n+    try:\n         _config = json.load(open(_config_path))\n+    except ValueError:\n+        _config = {}\n     _floatx = _config.get('floatx', floatx())\n     assert _floatx in {'float16', 'float32', 'float64'}\n     _epsilon = _config.get('epsilon', epsilon())\n@@ -41,7 +43,13 @@ if os.path.exists(_config_path):\n     set_image_data_format(_image_data_format)\n     _BACKEND = _backend\n \n-# save config file\n+# Save config file, if possible.\n+if os.access(_keras_base_dir, os.W_OK):\n+    if not os.path.exists(_keras_dir):\n+        try:\n+            os.makedirs(_keras_dir)\n+        except OSError:\n+            pass\n     if not os.path.exists(_config_path):\n         _config = {'floatx': floatx(),\n                    'epsilon': epsilon(),\n@@ -50,12 +58,13 @@ if not os.path.exists(_config_path):\n         with open(_config_path, 'w') as f:\n             f.write(json.dumps(_config, indent=4))\n \n+# Set backend based on KERAS_BACKEND flag, if applicable.\n if 'KERAS_BACKEND' in os.environ:\n     _backend = os.environ['KERAS_BACKEND']\n     assert _backend in {'theano', 'tensorflow'}\n     _BACKEND = _backend\n \n-# import backend\n+# Import backend functions.\n if _BACKEND == 'theano':\n     sys.stderr.write('Using Theano backend.\\n')\n     from .theano_backend import *\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#98ec9fc9720a1879fcb186b247c189863dbc7b0b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 487 | Contributors (this commit): 11 | Commits (past 90d): 7 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -54,9 +54,12 @@ model.add(Dropout(0.5))\n model.add(Dense(num_classes))\n model.add(Activation('softmax'))\n \n+# initiate RMSprop optimizer\n+opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n+\n # Let's train the model using RMSprop\n model.compile(loss='categorical_crossentropy',\n-              optimizer='rmsprop',\n+              optimizer=opt,\n               metrics=['accuracy'])\n \n x_train = x_train.astype('float32')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#75b69a5615304ac4381d2311c1028a1523ffb791", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 765 | Contributors (this commit): 16 | Commits (past 90d): 10 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -31,8 +31,8 @@ class Embedding(Layer):\n     ```\n \n     # Arguments\n-      input_dim: int > 0. Size of the vocabulary, ie.\n-          1 + maximum integer index occurring in the input data.\n+      input_dim: int > 0. Size of the vocabulary,\n+          i.e. maximum integer index + 1.\n       output_dim: int >= 0. Dimension of the dense embedding.\n       embeddings_initializer: Initializer for the `embeddings` matrix\n           (see [initializers](../initializers.md)).\n@@ -49,7 +49,8 @@ class Embedding(Layer):\n           If this is `True` then all subsequent layers\n           in the model need to support masking or an exception will be raised.\n           If mask_zero is set to True, as a consequence, index 0 cannot be\n-          used in the vocabulary (input_dim should equal `|vocabulary| + 2`).\n+          used in the vocabulary (input_dim should equal size of\n+          vocabulary + 1).\n       input_length: Length of input sequences, when it is constant.\n           This argument is required if you are going to connect\n           `Flatten` then `Dense` layers upstream\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8fde4fe305df814bc6a5fd8f1c07a167c834a468", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 720 | Contributors (this commit): 4 | Commits (past 90d): 11 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -157,7 +157,10 @@ def InceptionV3(include_top=True,\n     if input_tensor is None:\n         img_input = Input(shape=input_shape)\n     else:\n+        if not K.is_keras_tensor(input_tensor):\n             img_input = Input(tensor=input_tensor, shape=input_shape)\n+        else:\n+            img_input = input_tensor\n \n     if K.image_data_format() == 'channels_first':\n         channel_axis = 1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#65a215646c653ab808170c8b8c10de2945262613", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 69 | Lines Deleted: 13 | Files Changed: 3 | Hunks: 7 | Methods Changed: 3 | Complexity Δ (Sum/Max): 8/4 | Churn Δ: 82 | Churn Cumulative: 12512 | Contributors (this commit): 89 | Commits (past 90d): 116 | Contributors (cumulative): 139 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2730,13 +2730,14 @@ def in_top_k(predictions, targets, k):\n     \"\"\"Returns whether the `targets` are in the top `k` `predictions`.\n \n     # Arguments\n-        predictions: A tensor of shape `batch_size` x classes and type `float32`.\n-        targets: A tensor of shape batch_size and type `int32` or `int64`.\n+        predictions: A tensor of shape `(batch_size, classes)` and type `float32`.\n+        targets: A 1D tensor of length `batch_size` and type `int32` or `int64`.\n         k: An `int`, number of top elements to consider.\n \n     # Returns\n-        A tensor of shape `batch_size` and type `bool`. `output_i` is `True` if\n-        `targets_i` is within top-k values of `predictions_i`\n+        A 1D tensor of length `batch_size` and type `bool`.\n+        `output[i]` is `True` if `predictions[i, targets[i]]` is within top-`k`\n+        values of `predictions[i]`.\n     \"\"\"\n     return tf.nn.in_top_k(predictions, targets, k)\n \n\n@@ -1494,20 +1494,35 @@ def l2_normalize(x, axis):\n \n \n def in_top_k(predictions, targets, k):\n-    \"\"\"Returns whether the `targets` are in the top `k` `predictions`\n+    \"\"\"Returns whether the `targets` are in the top `k` `predictions`.\n \n     # Arguments\n-        predictions: A tensor of shape batch_size x classess and type float32.\n-        targets: A tensor of shape batch_size and type int32 or int64.\n-        k: An int, number of top elements to consider.\n+        predictions: A tensor of shape `(batch_size, classes)` and type `float32`.\n+        targets: A 1D tensor of length `batch_size` and type `int32` or `int64`.\n+        k: An `int`, number of top elements to consider.\n \n     # Returns\n-        A tensor of shape batch_size and type int. output_i is 1 if\n-        targets_i is within top-k values of predictions_i\n+        A 1D tensor of length `batch_size` and type `bool`.\n+        `output[i]` is `True` if `predictions[i, targets[i]]` is within top-`k`\n+        values of `predictions[i]`.\n     \"\"\"\n-    predictions_top_k = T.argsort(predictions)[:, -k:]\n-    result, _ = theano.map(lambda prediction, target: any(equal(prediction, target)), sequences=[predictions_top_k, targets])\n-    return result\n+    # handle k < 1 and k >= predictions.shape[1] cases to match TF behavior\n+    if k < 1:\n+        # dtype='bool' is only available since Theano 0.9.0\n+        try:\n+            return T.zeros_like(targets, dtype='bool')\n+        except TypeError:\n+            return T.zeros_like(targets, dtype='int8')\n+\n+    if k >= int_shape(predictions)[1]:\n+        try:\n+            return T.ones_like(targets, dtype='bool')\n+        except TypeError:\n+            return T.ones_like(targets, dtype='int8')\n+\n+    predictions_k = T.sort(predictions)[:, -k]\n+    targets_values = predictions[T.arange(targets.shape[0]), targets]\n+    return T.ge(targets_values, predictions_k)\n \n \n # CONVOLUTIONS\n\n@@ -618,6 +618,46 @@ class TestBackend(object):\n         check_single_tensor_operation('l2_normalize', (4, 3), axis=-1)\n         check_single_tensor_operation('l2_normalize', (4, 3), axis=1)\n \n+    def test_in_top_k(self):\n+        batch_size = 20\n+        num_classes = 10\n+\n+        # Random prediction test case\n+        predictions = np.random.random((batch_size, num_classes)).astype('float32')\n+        targets = np.random.randint(num_classes, size=batch_size, dtype='int32')\n+\n+        predictions_th = KTH.variable(predictions, dtype='float32')\n+        targets_th = KTH.variable(targets, dtype='int32')\n+        predictions_tf = KTF.variable(predictions, dtype='float32')\n+        targets_tf = KTF.variable(targets, dtype='int32')\n+\n+        for k in range(1, num_classes + 1):\n+            res_th = KTH.eval(KTH.in_top_k(predictions_th, targets_th, k))\n+            res_tf = KTF.eval(KTF.in_top_k(predictions_tf, targets_tf, k))\n+\n+            assert res_th.shape == res_tf.shape\n+            assert_allclose(res_th, res_tf, atol=1e-05)\n+\n+        # Identical prediction test case:\n+        # randomly set half of the predictions to an identical value\n+        num_identical = num_classes // 2\n+        for i in range(batch_size):\n+            idx_identical = np.random.choice(num_classes, size=num_identical, replace=False)\n+            predictions[i, idx_identical] = predictions[i, 0]\n+        targets = np.zeros(batch_size, dtype='int32')\n+\n+        predictions_th = KTH.variable(predictions, dtype='float32')\n+        targets_th = KTH.variable(targets, dtype='int32')\n+        predictions_tf = KTF.variable(predictions, dtype='float32')\n+        targets_tf = KTF.variable(targets, dtype='int32')\n+\n+        for k in range(1, num_classes + 1):\n+            res_th = KTH.eval(KTH.in_top_k(predictions_th, targets_th, k))\n+            res_tf = KTF.eval(KTF.in_top_k(predictions_tf, targets_tf, k))\n+\n+            assert res_th.shape == res_tf.shape\n+            assert_allclose(res_th, res_tf, atol=1e-05)\n+\n     def test_conv2d(self):\n         # TF kernel shape: (rows, cols, input_depth, depth)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1fe9ed7b55f2ad42b4e697f2e0a471f0ff71b210", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 29 | Files Changed: 2 | Hunks: 10 | Methods Changed: 11 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 60 | Churn Cumulative: 8546 | Contributors (this commit): 34 | Commits (past 90d): 67 | Contributors (cumulative): 38 | DMM Complexity: 1.0\n\nDIFF:\n@@ -252,7 +252,11 @@ class Layer(object):\n         self._trainable_weights = []\n         self._non_trainable_weights = []\n         self._constraints = {}  # dict {tensor: constraint instance}\n-        self.built = False\n+        self._losses = []\n+        self._updates = []\n+        self._per_input_losses = {}\n+        self._per_input_updates = {}\n+        self._built = False\n \n         # These lists will be filled via successive calls\n         # to self._add_inbound_node().\n@@ -308,6 +312,22 @@ class Layer(object):\n         else:\n             self._initial_weights = None\n \n+    @property\n+    def losses(self):\n+        return self._losses\n+\n+    @property\n+    def updates(self):\n+        return self._updates\n+\n+    @property\n+    def built(self):\n+        return self._built\n+\n+    @built.setter\n+    def built(self, value):\n+        self._built = value\n+\n     @property\n     def constraints(self):\n         return self._constraints\n@@ -1033,19 +1053,9 @@ class Layer(object):\n             return\n         # Update self.losses\n         losses = _to_list(losses)\n-        if not hasattr(self, 'losses'):\n-            self.losses = []\n-        try:\n-            self.losses += losses\n-        except AttributeError:\n-            # In case self.losses isn't settable\n-            # (i.e. it's a getter method).\n-            # In that case the `losses` property is\n-            # auto-computed and shouldn't be set.\n-            pass\n+        if hasattr(self, '_losses'):\n+            self._losses += losses\n         # Update self._per_input_updates\n-        if not hasattr(self, '_per_input_losses'):\n-            self._per_input_losses = {}\n         if inputs == []:\n             inputs = None\n         if inputs is not None:\n@@ -1075,19 +1085,9 @@ class Layer(object):\n             return\n         # Update self.updates\n         updates = _to_list(updates)\n-        if not hasattr(self, 'updates'):\n-            self.updates = []\n-        try:\n-            self.updates += updates\n-        except AttributeError:\n-            # In case self.updates isn't settable\n-            # (i.e. it's a getter method).\n-            # In that case the `updates` property is\n-            # auto-computed and shouldn't be set.\n-            pass\n+        if hasattr(self, '_updates'):\n+            self._updates += updates\n         # Update self._per_input_updates\n-        if not hasattr(self, '_per_input_updates'):\n-            self._per_input_updates = {}\n         if inputs == []:\n             inputs = None\n         if inputs is not None:\n@@ -1101,8 +1101,6 @@ class Layer(object):\n         self._per_input_updates[inputs_hash] += updates\n \n     def get_updates_for(self, inputs):\n-        if not hasattr(self, '_per_input_updates'):\n-            return []\n         if inputs is not None:\n             inputs_hash = _object_list_uid(inputs)\n         else:\n@@ -1112,8 +1110,6 @@ class Layer(object):\n         return []\n \n     def get_losses_for(self, inputs):\n-        if not hasattr(self, '_per_input_losses'):\n-            return []\n         if inputs is not None:\n             inputs_hash = _object_list_uid(inputs)\n         else:\n@@ -1450,6 +1446,8 @@ class Container(Layer):\n \n         self.supports_masking = False\n         self.trainable = True\n+        self._per_input_losses = {}\n+        self._per_input_updates = {}\n \n         # Container-specific properties.\n         if isinstance(inputs, (list, tuple)):\n\n@@ -76,6 +76,10 @@ class Merge(Layer):\n         self._output_mask = output_mask\n         self.arguments = arguments if arguments else {}\n         self._initial_weights = None\n+        self._updates = []\n+        self._losses = []\n+        self._per_input_updates = {}\n+        self._per_input_losses = {}\n \n         # Layer parameters.\n         self.inbound_nodes = []\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a8e7b19b7965bbf5bc478aec25c5d6ea39dcb100", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 2537 | Contributors (this commit): 42 | Commits (past 90d): 18 | Contributors (cumulative): 42 | DMM Complexity: None\n\nDIFF:\n@@ -608,7 +608,7 @@ class TensorBoard(Callback):\n                  write_images=False,\n                  embeddings_freq=0,\n                  embeddings_layer_names=None,\n-                 embeddings_metadata={}):\n+                 embeddings_metadata=None):\n         super(TensorBoard, self).__init__()\n         if K.backend() != 'tensorflow':\n             raise RuntimeError('TensorBoard callback only works '\n@@ -620,7 +620,7 @@ class TensorBoard(Callback):\n         self.write_images = write_images\n         self.embeddings_freq = embeddings_freq\n         self.embeddings_layer_names = embeddings_layer_names\n-        self.embeddings_metadata = embeddings_metadata\n+        self.embeddings_metadata = embeddings_metadata or {}\n \n     def set_model(self, model):\n         self.model = model\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#76c553e68f8f64ab49c255b4b0c1336c5243ac46", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 810 | Contributors (this commit): 10 | Commits (past 90d): 19 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -107,13 +107,18 @@ class TimeDistributed(Wrapper):\n         model = Sequential()\n         model.add(TimeDistributed(Dense(8), input_shape=(10, 16)))\n         # now model.output_shape == (None, 10, 8)\n+    ```\n \n-        # subsequent layers: no need for input_shape\n+    The output will then have shape `(32, 10, 8)`.\n+\n+    In subsequent layers, there is no need for the `input_shape`:\n+\n+    ```python\n         model.add(TimeDistributed(Dense(32)))\n         # now model.output_shape == (None, 10, 32)\n     ```\n \n-    The output will then have shape `(32, 10, 8)`.\n+    The output will then have shape `(32, 10, 32)`.\n \n     `TimeDistributed` can be used with arbitrary layers, not just `Dense`,\n     for instance with a `Conv2D` layer:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6b3459ae4dc0d7af2927917b85e43f98b2c2db6a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 204 | Contributors (this commit): 9 | Commits (past 90d): 10 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -16,6 +16,7 @@ setup(name='Keras',\n           'visualize': ['pydot-ng'],\n           'tests': ['pytest',\n                     'pytest-pep8',\n-                    'pytest-xdist'],\n+                    'pytest-xdist',\n+                    'pytest-cov'],\n       },\n       packages=find_packages())\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#28b731a3d11f75b3c2a24c580c49b3625e3e6998", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 502 | Contributors (this commit): 5 | Commits (past 90d): 11 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -149,7 +149,7 @@ def ResNet50(include_top=True, weights='imagenet',\n         input_shape: optional shape tuple, only to be specified\n             if `include_top` is False (otherwise the input shape\n             has to be `(224, 224, 3)` (with `channels_last` data format)\n-            or `(3, 224, 244)` (with `channels_first` data format).\n+            or `(3, 224, 224)` (with `channels_first` data format).\n             It should have exactly 3 inputs channels,\n             and width and height should be no smaller than 197.\n             E.g. `(200, 200, 3)` would be one valid value.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#362bfdd65126e62addc459122e19a2523dcafa2f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 4 | Churn Cumulative: 615 | Contributors (this commit): 15 | Commits (past 90d): 16 | Contributors (cumulative): 15 | DMM Complexity: 0.0\n\nDIFF:\n@@ -161,10 +161,6 @@ def deserialize_keras_object(identifier, module_objects=None,\n                          printable_module_name + ': ' + identifier)\n \n \n-def make_tuple(*args):\n-    return args\n-\n-\n def func_dump(func):\n     \"\"\"Serializes a user defined function.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0fb0c22f3998c7c92f47837b8cd54009a3a19f75", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 313 | Contributors (this commit): 11 | Commits (past 90d): 20 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -18,4 +18,4 @@ from . import losses\n from . import optimizers\r\n from . import regularizers\r\n \r\n-__version__ = '2.0.2'\r\n+__version__ = '2.0.3'\r\n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='2.0.2',\n+      version='2.0.3',\n       description='Deep Learning for Python',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/fchollet/keras',\n-      download_url='https://github.com/fchollet/keras/tarball/2.0.2',\n+      download_url='https://github.com/fchollet/keras/tarball/2.0.3',\n       license='MIT',\n       install_requires=['theano', 'pyyaml', 'six'],\n       extras_require={\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
