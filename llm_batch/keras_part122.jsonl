{"custom_id": "keras#80fbbc3a6a2a30f391bad2aa85e7558c50ca0709", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1239 | Contributors (this commit): 18 | Commits (past 90d): 6 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -411,7 +411,7 @@ class ImageDataGenerator(object):\n \n         if self.zca_whitening:\n             flatX = np.reshape(X, (X.shape[0], X.shape[1] * X.shape[2] * X.shape[3]))\n-            sigma = np.dot(flatX.T, flatX) / flatX.shape[1]\n+            sigma = np.dot(flatX.T, flatX) / flatX.shape[0]\n             U, S, V = linalg.svd(sigma)\n             self.principal_components = np.dot(np.dot(U, np.diag(1. / np.sqrt(S + 10e-7))), U.T)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a89dabe0cd732fcb45b775e3a5c0c07f8c9621e0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 10084 | Contributors (this commit): 68 | Commits (past 90d): 21 | Contributors (cumulative): 77 | DMM Complexity: None\n\nDIFF:\n@@ -1025,7 +1025,7 @@ class Model(Container):\n                 on this data at the end of each epoch.\n             validation_data: data on which to evaluate the loss and any model metrics\n                 at the end of each epoch. The model will not be trained on this data.\n-                This could be a tuple (x_val, y_val) or a tuple (val_x, val_y, val_sample_weights).\n+                This could be a tuple (x_val, y_val) or a tuple (x_val, y_val, val_sample_weights).\n             shuffle: boolean, whether to shuffle the training data before each epoch.\n             class_weight: optional dictionary mapping class indices (integers) to\n                 a weight (float) to apply to the model's loss for the samples\n\n@@ -573,7 +573,8 @@ class Sequential(Model):\n                 See [callbacks](/callbacks).\n             validation_split: float (0. < x < 1).\n                 Fraction of the data to use as held-out validation data.\n-            validation_data: tuple (X, y) to be used as held-out\n+            validation_data: tuple (x_val, y_val) or tuple\n+                (x_val, y_val, val_sample_weights) to be used as held-out\n                 validation data. Will override validation_split.\n             shuffle: boolean or str (for 'batch').\n                 Whether to shuffle the samples at each epoch.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bef888c2d817042ee9663e4039619e0b91a04a35", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 14 | Churn Cumulative: 1912 | Contributors (this commit): 29 | Commits (past 90d): 10 | Contributors (cumulative): 29 | DMM Complexity: 0.0\n\nDIFF:\n@@ -314,6 +314,10 @@ class EarlyStopping(Callback):\n \n     # Arguments\n         monitor: quantity to be monitored.\n+        min_delta: minimum change in the monitored quantity\n+            to qualify as an improvement, i.e. an absolute\n+            change of less than min_delta, will count as no\n+            improvement.\n         patience: number of epochs with no improvement\n             after which training will be stopped.\n         verbose: verbosity mode.\n@@ -325,12 +329,13 @@ class EarlyStopping(Callback):\n             mode, the direction is automatically inferred\n             from the name of the monitored quantity.\n     '''\n-    def __init__(self, monitor='val_loss', patience=0, verbose=0, mode='auto'):\n+    def __init__(self, monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto'):\n         super(EarlyStopping, self).__init__()\n \n         self.monitor = monitor\n         self.patience = patience\n         self.verbose = verbose\n+        self.min_delta = min_delta\n         self.wait = 0\n \n         if mode not in ['auto', 'min', 'max']:\n@@ -349,6 +354,11 @@ class EarlyStopping(Callback):\n             else:\n                 self.monitor_op = np.less\n \n+        if self.monitor_op == np.greater:\n+            self.min_delta *= 1\n+        else:\n+            self.min_delta *= -1\n+\n     def on_train_begin(self, logs={}):\n         self.wait = 0       # Allow instances to be re-used\n         self.best = np.Inf if self.monitor_op == np.less else -np.Inf\n@@ -359,7 +369,7 @@ class EarlyStopping(Callback):\n             warnings.warn('Early stopping requires %s available!' %\n                           (self.monitor), RuntimeWarning)\n \n-        if self.monitor_op(current, self.best):\n+        if self.monitor_op(current - self.min_delta, self.best):\n             self.best = current\n             self.wait = 0\n         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#556399cc48e8043c4bf2c25dbe7e8794b12f2b89", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 59 | Lines Deleted: 5 | Files Changed: 4 | Hunks: 8 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 64 | Churn Cumulative: 1913 | Contributors (this commit): 26 | Commits (past 90d): 19 | Contributors (cumulative): 33 | DMM Complexity: None\n\nDIFF:\n@@ -85,7 +85,10 @@ from keras import backend\n from keras import constraints\n from keras import activations\n from keras import regularizers\n+from keras.utils import data_utils\n from keras.utils import io_utils\n+from keras.utils import layer_utils\n+from keras.utils import np_utils\n \n \n EXCLUDE = {\n@@ -244,11 +247,27 @@ PAGES = [\n         'all_module_functions': [backend],\n     },\n     {\n-        'page': 'io_utils.md',\n+        'page': 'utils/data_utils.md',\n+        'functions': [\n+            data_utils.get_file,\n+        ]\n+    },\n+    {\n+        'page': 'utils/io_utils.md',\n         'classes': [\n             io_utils.HDF5Matrix\n         ],\n     },\n+    {\n+        'page': 'utils/layer_utils.md',\n+        'functions': [\n+            layer_utils.layer_from_config,\n+        ]\n+    },\n+    {\n+        'page': 'utils/np_utils.md',\n+        'all_module_functions': [np_utils]\n+    },\n ]\n \n ROOT = 'http://keras.io/'\n\n@@ -40,6 +40,20 @@ else:\n \n def get_file(fname, origin, untar=False,\n              md5_hash=None, cache_subdir='datasets'):\n+    '''Downloads a file from a URL if it not already in the cache.\n+\n+    Passing the MD5 hash will verify the file after download as well as if it is already present in the cache.\n+\n+    # Arguments\n+        fname: name of the file\n+        origin: original URL of the file\n+        untar: boolean, whether the file should be decompressed\n+        md5_hash: MD5 hash of the file for verification\n+        cache_subdir: directory being used as the cache\n+\n+    # Returns\n+        Path to the downloaded file\n+    '''\n     datadir_base = os.path.expanduser(os.path.join('~', '.keras'))\n     if not os.access(datadir_base, os.W_OK):\n         datadir_base = os.path.join('/tmp', '.keras')\n@@ -110,6 +124,15 @@ def get_file(fname, origin, untar=False,\n \n \n def validate_file(fpath, md5_hash):\n+    '''Validates a file against a MD5 hash\n+\n+    # Arguments\n+        fpath: path to the file being validated\n+        md5_hash: the MD5 hash being validated against\n+\n+    # Returns\n+        Whether the file is valid\n+    '''\n     hasher = hashlib.md5()\n     with open(fpath, 'rb') as f:\n         buf = f.read()\n\n@@ -37,8 +37,14 @@ def layer_from_config(config, custom_objects={}):\n \n \n def print_summary(layers, relevant_nodes=None, line_length=100, positions=[.33, .55, .67, 1.]):\n-    # line_length: total length of printed lines\n-    # positions: relative or absolute positions of log elements in each line\n+    '''Prints a summary of a layer\n+\n+    # Arguments\n+        layers: list of layers to print summaries of\n+        relevant_nodes: list of relevant nodes\n+        line_length: total length of printed lines\n+        positions: relative or absolute positions of log elements in each line\n+    '''\n     if positions[-1] <= 1:\n         positions = [int(line_length * p) for p in positions]\n     # header names for the different log elements\n\n@@ -7,8 +7,14 @@ from .. import backend as K\n \n \n def to_categorical(y, nb_classes=None):\n-    '''Convert class vector (integers from 0 to nb_classes)\n-    to binary class matrix, for use with categorical_crossentropy.\n+    '''Convert class vector (integers from 0 to nb_classes) to binary class matrix, for use with categorical_crossentropy.\n+\n+    # Arguments\n+        y: class vector to be converted into a matrix\n+        nb_classes: total number of classes\n+\n+    # Returns\n+        A binary matrix representation of the input.\n     '''\n     if not nb_classes:\n         nb_classes = np.max(y)+1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9c7020f7e71ed60e2358e9aae190b9eec2ad1cc5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 6 | Churn Cumulative: 7904 | Contributors (this commit): 52 | Commits (past 90d): 10 | Contributors (cumulative): 52 | DMM Complexity: 0.0\n\nDIFF:\n@@ -8,7 +8,7 @@ import numpy as np\n from . import backend as K\n from .utils.io_utils import ask_to_proceed_with_overwrite\n from .engine.training import Model\n-from .engine.topology import get_source_inputs, Node\n+from .engine.topology import get_source_inputs, Node, Layer\n from .optimizers import optimizer_from_config\n from .legacy.models import Graph\n \n@@ -260,6 +260,10 @@ class Sequential(Model):\n         # Arguments\n             layer: layer instance.\n         '''\n+        if not isinstance(layer, Layer):\n+            raise ValueError('The added layer must be '\n+                             'an instance of class Layer. '\n+                             'Found: ' + str(layer))\n         if not self.outputs:\n             # first layer in model: check that it is an input layer\n             if len(layer.inbound_nodes) == 0:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#40fd4154093d5c65b6718083911d5bf761d1adec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 146 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -1,6 +1,6 @@\n from keras.models import Sequential\n from keras.layers.convolutional import Convolution3D\n-from keras.layers.recurrent_convolutional import LSTMConv2D\n+from keras.layers.recurrent_convolutional import ConvLSTM2D\n from keras.layers.normalization import BatchNormalization\n import numpy as np\n from pylab import *\n@@ -10,20 +10,20 @@ from pylab import *\n # with identical shape.\n \n seq = Sequential()\n-seq.add(LSTMConv2D(nb_filter=40, nb_row=3, nb_col=3,\n+seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,\n                    input_shape=(None, 40, 40, 1),\n                    border_mode=\"same\", return_sequences=True))\n seq.add(BatchNormalization())\n \n-seq.add(LSTMConv2D(nb_filter=40, nb_row=3, nb_col=3,\n+seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,\n                    border_mode=\"same\", return_sequences=True))\n seq.add(BatchNormalization())\n \n-seq.add(LSTMConv2D(nb_filter=40, nb_row=3, nb_col=3,\n+seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,\n                    border_mode=\"same\", return_sequences=True))\n seq.add(BatchNormalization())\n \n-seq.add(LSTMConv2D(nb_filter=40, nb_row=3, nb_col=3,\n+seq.add(ConvLSTM2D(nb_filter=40, nb_row=3, nb_col=3,\n                    border_mode=\"same\", return_sequences=True))\n seq.add(BatchNormalization())\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6fd2d43bfeb1195e68693a66e767464835e40abf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 17 | Churn Cumulative: 2682 | Contributors (this commit): 42 | Commits (past 90d): 22 | Contributors (cumulative): 42 | DMM Complexity: 0.0\n\nDIFF:\n@@ -437,10 +437,25 @@ def batch_normalization(x, mean, var, beta, gamma, epsilon=0.0001):\n     use_cudnn = ndim < 5 and (dev.startswith('cuda') or dev.startswith('gpu'))\n     if use_cudnn:\n         try:\n-            return theano.sandbox.cuda.dnn.dnn_batch_normalization_test(x, gamma, beta, mean, var,\n+            axis = mean.broadcastable.index(False)\n+            if axis != 1:\n+                shuffle_pattern = list(range(ndim))\n+                shuffle_pattern[1] = shuffle_pattern[axis]\n+                shuffle_pattern[axis] = 1\n+                x = x.dimshuffle(shuffle_pattern)\n+                mean = mean.dimshuffle(shuffle_pattern)\n+                var = var.dimshuffle(shuffle_pattern)\n+                beta = beta.dimshuffle(shuffle_pattern)\n+                gamma = gamma.dimshuffle(shuffle_pattern)\n+            normed = theano.sandbox.cuda.dnn.dnn_batch_normalization_test(x, gamma, beta, mean, var,\n                                                                           'spatial', epsilon)\n+            if axis != 1:\n+                normed = normed.dimshuffle(shuffle_pattern)\n+            return normed\n         except AttributeError:\n             pass\n+        except ValueError:\n+            pass\n     return T.nnet.bn.batch_normalization(x, gamma, beta, mean, sqrt(var + epsilon),\n                                          mode='high_mem')\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fee03bd5a6c436a69bb479c272acb8fe29f1c588", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 15 | Files Changed: 2 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 18 | Churn Cumulative: 617 | Contributors (this commit): 8 | Commits (past 90d): 4 | Contributors (cumulative): 11 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,7 +1,7 @@\n import numpy as np\n from numpy.testing import assert_allclose\n import inspect\n-import functools\n+import six\n \n from ..engine import Model, Input\n from ..models import Sequential, model_from_json\n@@ -112,7 +112,7 @@ def layer_test(layer_cls, kwargs={}, input_shape=None, input_dtype=None,\n def keras_test(func):\n     '''Clean up after tensorflow tests.\n     '''\n-    @functools.wraps(func)\n+    @six.wraps(func)\n     def wrapper(*args, **kwargs):\n         output = func(*args, **kwargs)\n         if K._BACKEND == 'tensorflow':\n\n@@ -1,5 +1,4 @@\n import pytest\n-import sys\n import numpy as np\n from numpy.testing import assert_allclose\n \n@@ -21,18 +20,7 @@ def rnn_test(f):\n     All the recurrent layers share the same interface,\n     so we can run through them with a single function.\n     \"\"\"\n-    kf = keras_test(f)\n-\n-    def wrapped(layer_class):\n-        return kf(layer_class)\n-\n-    # functools doesnt propagate arguments info for pytest correctly in 2.7\n-    # and wrapped doesnt work with pytest in 3.4\n-    if sys.version_info >= (3, 0):\n-        f = kf\n-    else:\n-        f = wrapped\n-\n+    f = keras_test(f)\n     return pytest.mark.parametrize(\"layer_class\", [\n         recurrent.SimpleRNN,\n         recurrent.GRU,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c6d2ccd453bc71144ba891abc6876772144985c4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 240 | Contributors (this commit): 9 | Commits (past 90d): 9 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -15,4 +15,4 @@ from . import objectives\n from . import optimizers\r\n from . import regularizers\r\n \r\n-__version__ = '1.1.0'\r\n+__version__ = '1.1.1'\r\n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='1.1.0',\n+      version='1.1.1',\n       description='Deep Learning for Python',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/fchollet/keras',\n-      download_url='https://github.com/fchollet/keras/tarball/1.1.0',\n+      download_url='https://github.com/fchollet/keras/tarball/1.1.1',\n       license='MIT',\n       install_requires=['theano', 'pyyaml', 'six'],\n       extras_require={\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bc6880fa348eda885dfad305088b395510d74300", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 24 | Files Changed: 4 | Hunks: 28 | Methods Changed: 12 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 58 | Churn Cumulative: 9472 | Contributors (this commit): 63 | Commits (past 90d): 55 | Contributors (cumulative): 93 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1182,6 +1182,8 @@ def _preprocess_border_mode(border_mode):\n         th_border_mode = 'half'\n     elif border_mode == 'valid':\n         th_border_mode = 'valid'\n+    elif border_mode == 'full':\n+        th_border_mode = 'full'\n     else:\n         raise Exception('Border mode not supported: ' + str(border_mode))\n     return th_border_mode\n\n@@ -47,7 +47,7 @@ class Convolution1D(Layer):\n             If you don't specify anything, no activation is applied\n             (ie. \"linear\" activation: a(x) = x).\n         weights: list of numpy arrays to set as initial weights.\n-        border_mode: 'valid' or 'same'.\n+        border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)\n         subsample_length: factor by which to subsample output.\n         W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n             (eg. L1 or L2 regularization), applied to the main weights matrix.\n@@ -83,13 +83,12 @@ class Convolution1D(Layer):\n                  W_constraint=None, b_constraint=None,\n                  bias=True, input_dim=None, input_length=None, **kwargs):\n \n-        if border_mode not in {'valid', 'same'}:\n+        if border_mode not in {'valid', 'same', 'full'}:\n             raise Exception('Invalid border mode for Convolution1D:', border_mode)\n         self.nb_filter = nb_filter\n         self.filter_length = filter_length\n         self.init = initializations.get(init, dim_ordering='th')\n         self.activation = activations.get(activation)\n-        assert border_mode in {'valid', 'same'}, 'border_mode must be in {valid, same}'\n         self.border_mode = border_mode\n         self.subsample_length = subsample_length\n \n@@ -218,7 +217,7 @@ class AtrousConvolution1D(Convolution1D):\n             If you don't specify anything, no activation is applied\n             (ie. \"linear\" activation: a(x) = x).\n         weights: list of numpy arrays to set as initial weights.\n-        border_mode: 'valid' or 'same'.\n+        border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)\n         subsample_length: factor by which to subsample output.\n         atrous_rate: Factor for kernel dilation. Also called filter_dilation\n             elsewhere.\n@@ -256,7 +255,7 @@ class AtrousConvolution1D(Convolution1D):\n                  W_constraint=None, b_constraint=None,\n                  bias=True, **kwargs):\n \n-        if border_mode not in {'valid', 'same'}:\n+        if border_mode not in {'valid', 'same', 'full'}:\n             raise Exception('Invalid border mode for AtrousConv1D:', border_mode)\n \n         self.atrous_rate = int(atrous_rate)\n@@ -331,7 +330,7 @@ class Convolution2D(Layer):\n             If you don't specify anything, no activation is applied\n             (ie. \"linear\" activation: a(x) = x).\n         weights: list of numpy arrays to set as initial weights.\n-        border_mode: 'valid' or 'same'.\n+        border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)\n         subsample: tuple of length 2. Factor by which to subsample output.\n             Also called strides elsewhere.\n         W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n@@ -373,14 +372,13 @@ class Convolution2D(Layer):\n                  bias=True, **kwargs):\n         if dim_ordering == 'default':\n             dim_ordering = K.image_dim_ordering()\n-        if border_mode not in {'valid', 'same'}:\n+        if border_mode not in {'valid', 'same', 'full'}:\n             raise Exception('Invalid border mode for Convolution2D:', border_mode)\n         self.nb_filter = nb_filter\n         self.nb_row = nb_row\n         self.nb_col = nb_col\n         self.init = initializations.get(init, dim_ordering=dim_ordering)\n         self.activation = activations.get(activation)\n-        assert border_mode in {'valid', 'same'}, 'border_mode must be in {valid, same}'\n         self.border_mode = border_mode\n         self.subsample = tuple(subsample)\n         assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n@@ -570,7 +568,7 @@ class Deconvolution2D(Convolution2D):\n             If you don't specify anything, no activation is applied\n             (ie. \"linear\" activation: a(x) = x).\n         weights: list of numpy arrays to set as initial weights.\n-        border_mode: 'valid' or 'same'.\n+        border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)\n         subsample: tuple of length 2. Factor by which to oversample output.\n             Also called strides elsewhere.\n         W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n@@ -617,7 +615,7 @@ class Deconvolution2D(Convolution2D):\n                  bias=True, **kwargs):\n         if dim_ordering == 'default':\n             dim_ordering = K.image_dim_ordering()\n-        if border_mode not in {'valid', 'same'}:\n+        if border_mode not in {'valid', 'same', 'full'}:\n             raise Exception('Invalid border mode for Deconvolution2D:', border_mode)\n \n         self.output_shape_ = output_shape\n@@ -703,7 +701,7 @@ class AtrousConvolution2D(Convolution2D):\n             If you don't specify anything, no activation is applied\n             (ie. \"linear\" activation: a(x) = x).\n         weights: list of numpy arrays to set as initial weights.\n-        border_mode: 'valid' or 'same'.\n+        border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)\n         subsample: tuple of length 2. Factor by which to subsample output.\n             Also called strides elsewhere.\n         atrous_rate: tuple of length 2. Factor for kernel dilation.\n@@ -751,7 +749,7 @@ class AtrousConvolution2D(Convolution2D):\n         if dim_ordering == 'default':\n             dim_ordering = K.image_dim_ordering()\n \n-        if border_mode not in {'valid', 'same'}:\n+        if border_mode not in {'valid', 'same', 'full'}:\n             raise Exception('Invalid border mode for AtrousConv2D:', border_mode)\n \n         self.atrous_rate = tuple(atrous_rate)\n@@ -1068,7 +1066,7 @@ class Convolution3D(Layer):\n             If you don't specify anything, no activation is applied\n             (ie. \"linear\" activation: a(x) = x).\n         weights: list of Numpy arrays to set as initial weights.\n-        border_mode: 'valid' or 'same'.\n+        border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)\n         subsample: tuple of length 3. Factor by which to subsample output.\n             Also called strides elsewhere.\n             Note: 'subsample' is implemented by slicing the output of conv3d with strides=(1,1,1).\n@@ -1112,7 +1110,7 @@ class Convolution3D(Layer):\n         if dim_ordering == 'default':\n             dim_ordering = K.image_dim_ordering()\n \n-        if border_mode not in {'valid', 'same'}:\n+        if border_mode not in {'valid', 'same', 'full'}:\n             raise Exception('Invalid border mode for Convolution3D:', border_mode)\n         self.nb_filter = nb_filter\n         self.kernel_dim1 = kernel_dim1\n@@ -1120,7 +1118,6 @@ class Convolution3D(Layer):\n         self.kernel_dim3 = kernel_dim3\n         self.init = initializations.get(init, dim_ordering=dim_ordering)\n         self.activation = activations.get(activation)\n-        assert border_mode in {'valid', 'same'}, 'border_mode must be in {valid, same}'\n         self.border_mode = border_mode\n         self.subsample = tuple(subsample)\n         assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n\n@@ -122,21 +122,25 @@ def convert_kernel(kernel, dim_ordering='default'):\n def conv_output_length(input_length, filter_size, border_mode, stride, dilation=1):\n     if input_length is None:\n         return None\n-    assert border_mode in {'same', 'valid'}\n+    assert border_mode in {'same', 'valid', 'full'}\n     dilated_filter_size = filter_size + (filter_size - 1) * (dilation - 1)\n     if border_mode == 'same':\n         output_length = input_length\n     elif border_mode == 'valid':\n         output_length = input_length - dilated_filter_size + 1\n+    elif border_mode == 'full':\n+        output_length = input_length + dilated_filter_size - 1\n     return (output_length + stride - 1) // stride\n \n \n def conv_input_length(output_length, filter_size, border_mode, stride):\n     if output_length is None:\n         return None\n-    assert border_mode in {'same', 'valid'}\n+    assert border_mode in {'same', 'valid', 'full'}\n     if border_mode == 'same':\n         pad = filter_size // 2\n     elif border_mode == 'valid':\n         pad = 0\n+    elif border_mode == 'full':\n+        pad = filter_size - 1\n     return (output_length - 1) * stride - 2 * pad + filter_size\n\n@@ -8,6 +8,13 @@ from keras import backend as K\n from keras.layers import convolutional, pooling\n \n \n+# TensorFlow does not support full convolution.\n+if K._BACKEND == 'theano':\n+    _convolution_border_modes = ['valid', 'same', 'full']\n+else:\n+    _convolution_border_modes = ['valid', 'same']\n+\n+\n @keras_test\n def test_convolution_1d():\n     nb_samples = 2\n@@ -16,7 +23,7 @@ def test_convolution_1d():\n     filter_length = 3\n     nb_filter = 3\n \n-    for border_mode in ['valid', 'same']:\n+    for border_mode in _convolution_border_modes:\n         for subsample_length in [1, 2]:\n             if border_mode == 'same' and subsample_length != 1:\n                 continue\n@@ -47,7 +54,7 @@ def test_atrous_conv_1d():\n     filter_length = 3\n     nb_filter = 3\n \n-    for border_mode in ['valid', 'same']:\n+    for border_mode in _convolution_border_modes:\n         for subsample_length in [1, 2]:\n             for atrous_rate in [1, 2]:\n                 if border_mode == 'same' and subsample_length != 1:\n@@ -101,7 +108,7 @@ def test_convolution_2d():\n     nb_row = 10\n     nb_col = 6\n \n-    for border_mode in ['valid', 'same']:\n+    for border_mode in _convolution_border_modes:\n         for subsample in [(1, 1), (2, 2)]:\n             if border_mode == 'same' and subsample != (1, 1):\n                 continue\n@@ -134,7 +141,7 @@ def test_deconvolution_2d():\n     nb_row = 10\n     nb_col = 6\n \n-    for border_mode in ['valid', 'same']:\n+    for border_mode in _convolution_border_modes:\n         for subsample in [(1, 1), (2, 2)]:\n             if border_mode == 'same' and subsample != (1, 1):\n                 continue\n@@ -175,7 +182,7 @@ def test_atrous_conv_2d():\n     nb_row = 10\n     nb_col = 6\n \n-    for border_mode in ['valid', 'same']:\n+    for border_mode in _convolution_border_modes:\n         for subsample in [(1, 1), (2, 2)]:\n             for atrous_rate in [(1, 1), (2, 2)]:\n                 if border_mode == 'same' and subsample != (1, 1):\n@@ -214,7 +221,7 @@ def test_separable_conv_2d():\n     nb_row = 10\n     nb_col = 6\n \n-    for border_mode in ['valid', 'same']:\n+    for border_mode in _convolution_border_modes:\n         for subsample in [(1, 1), (2, 2)]:\n             for multiplier in [1, 2]:\n                 if border_mode == 'same' and subsample != (1, 1):\n@@ -322,7 +329,7 @@ def test_convolution_3d():\n     input_len_dim2 = 11\n     input_len_dim3 = 12\n \n-    for border_mode in ['same', 'valid']:\n+    for border_mode in _convolution_border_modes:\n         for subsample in [(1, 1, 1), (2, 2, 2)]:\n             if border_mode == 'same' and subsample != (1, 1, 1):\n                 continue\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7d143370d8ee6ceb4b72790c6b859ce9ce6880d5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 5221 | Contributors (this commit): 29 | Commits (past 90d): 17 | Contributors (cumulative): 29 | DMM Complexity: None\n\nDIFF:\n@@ -663,7 +663,7 @@ class Deconvolution2D(Convolution2D):\n         return output\n \n     def get_config(self):\n-        config = {'output_shape': self.output_shape}\n+        config = {'output_shape': self.output_shape_}\n         base_config = super(Deconvolution2D, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#114b82a212ed2b2590d45550c41c3384ffa0d53e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 70 | Lines Deleted: 45 | Files Changed: 1 | Hunks: 29 | Methods Changed: 13 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 115 | Churn Cumulative: 3051 | Contributors (this commit): 39 | Commits (past 90d): 30 | Contributors (cumulative): 39 | DMM Complexity: 1.0\n\nDIFF:\n@@ -15,22 +15,36 @@ py_all = all\n \n # INTERNAL UTILS\n \n+# This is the default internal TF session used by Keras.\n+# It can be set manually via `set_session(sess)`.\n _SESSION = None\n-_LEARNING_PHASE = tf.placeholder(dtype='uint8', name='keras_learning_phase')  # 0 = test, 1 = train\n+# This dictionary holds a mapping {graph: learning_phase}.\n+# A learning phase is a bool tensor used to run Keras models in\n+# either train mode (learning_phase == 1) or test mode (learning_phase == 0).\n+_GRAPH_LEARNING_PHASES = {}\n+# This boolean flag can be set to True to leave variable initialization\n+# up to the user.\n+# Change its value via `manual_variable_initialization(value)`.\n _MANUAL_VAR_INIT = False\n \n \n def clear_session():\n+    '''Destroys the current TF graph and creates a new one.\n+\n+    Useful to avoid clutter from old models / layers.\n+    '''\n     global _SESSION\n-    global _LEARNING_PHASE\n+    global _GRAPH_LEARNING_PHASES\n     tf.reset_default_graph()\n     reset_uids()\n     _SESSION = None\n-    _LEARNING_PHASE = tf.placeholder(dtype='uint8', name='keras_learning_phase')\n+    phase = tf.placeholder(dtype='bool', name='keras_learning_phase')\n+    _GRAPH_LEARNING_PHASES[tf.get_default_graph()] = phase\n \n \n def manual_variable_initialization(value):\n-    '''Whether variables should be initialized\n+    '''Returns a boolean:\n+    whether variables should be initialized\n     as they are instantiated (default), or if\n     the user should handle the initialization\n     (e.g. via tf.initialize_all_variables()).\n@@ -42,19 +56,26 @@ def manual_variable_initialization(value):\n def learning_phase():\n     '''Returns the learning phase flag.\n \n-    The learning phase flag is an integer tensor (0 = test, 1 = train)\n+    The learning phase flag is a bool tensor (0 = test, 1 = train)\n     to be passed as input to any Keras function\n     that uses a different behavior at train time and test time.\n     '''\n-    return _LEARNING_PHASE\n+    graph = tf.get_default_graph()\n+    if graph not in _GRAPH_LEARNING_PHASES:\n+        phase = tf.placeholder(dtype='bool', name='keras_learning_phase')\n+        _GRAPH_LEARNING_PHASES[graph] = phase\n+    return _GRAPH_LEARNING_PHASES[graph]\n \n \n def set_learning_phase(value):\n-    global _LEARNING_PHASE\n+    '''Sets the learning phase to a fixed value,\n+    either 0 or 1 (integers).\n+    '''\n+    global _GRAPH_LEARNING_PHASES\n     if value not in {0, 1}:\n         raise ValueError('Expected learning phase to be '\n                          '0 or 1.')\n-    _LEARNING_PHASE = value\n+    _GRAPH_LEARNING_PHASES[tf.get_default_graph()] = value\n \n \n def get_session():\n@@ -72,15 +93,20 @@ def get_session():\n     '''\n     global _SESSION\n     if tf.get_default_session() is not None:\n-        return tf.get_default_session()\n+        session = tf.get_default_session()\n+    else:\n         if _SESSION is None:\n             if not os.environ.get('OMP_NUM_THREADS'):\n-            _SESSION = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n+                config = tf.ConfigProto(allow_soft_placement=True)\n             else:\n                 nb_thread = int(os.environ.get('OMP_NUM_THREADS'))\n-            _SESSION = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=nb_thread,\n-                                                        allow_soft_placement=True))\n-    return _SESSION\n+                config = tf.ConfigProto(intra_op_parallelism_threads=nb_thread,\n+                                        allow_soft_placement=True)\n+            _SESSION = tf.Session(config=config)\n+        session = _SESSION\n+    if not _MANUAL_VAR_INIT:\n+        _initialize_variables()\n+    return session\n \n \n def set_session(session):\n@@ -149,25 +175,21 @@ def variable(value, dtype=_FLOATX, name=None):\n         return tf.SparseTensor(indices=indices, values=sparse_coo.data, shape=sparse_coo.shape)\n \n     v = tf.Variable(value, dtype=_convert_string_dtype(dtype), name=name)\n-    if _MANUAL_VAR_INIT:\n-        return v\n-    if tf.get_default_graph() is get_session().graph:\n-        try:\n-            get_session().run(v.initializer)\n-        except tf.errors.InvalidArgumentError:\n-            warnings.warn('Could not automatically initialize variable, '\n-                          'make sure you do it manually (e.g. via '\n-                          '`tf.initialize_all_variables()`).')\n-    else:\n-        warnings.warn('The default TensorFlow graph is not the graph '\n-                      'associated with the TensorFlow session currently '\n-                      'registered with Keras, and as such Keras '\n-                      'was not able to automatically initialize a variable. '\n-                      'You should consider registering the proper session '\n-                      'with Keras via `K.set_session(sess)`.')\n     return v\n \n \n+def _initialize_variables():\n+    variables = tf.all_variables()\n+    uninitialized_variables = []\n+    for v in variables:\n+        if not hasattr(v, '_keras_initialized') or not v._keras_initialized:\n+            uninitialized_variables.append(v)\n+            v._keras_initialized = True\n+    if uninitialized_variables:\n+        sess = get_session()\n+        sess.run(tf.initialize_variables(uninitialized_variables))\n+\n+\n def placeholder(shape=None, ndim=None, dtype=_FLOATX, sparse=False, name=None):\n     '''Instantiates a placeholder.\n \n@@ -1321,8 +1343,11 @@ def switch(condition, then_expression, else_expression):\n         else_expression: TensorFlow operation.\n     '''\n     x_shape = copy.copy(then_expression.get_shape())\n-    x = _cond(tf.cast(condition, 'bool'),\n-              lambda: then_expression, lambda: else_expression)\n+    if condition.dtype != tf.bool:\n+        condition = tf.cast(condition, 'bool')\n+    x = _cond(condition,\n+              lambda: then_expression,\n+              lambda: else_expression)\n     x.set_shape(x_shape)\n     return x\n \n@@ -1331,15 +1356,13 @@ def in_train_phase(x, alt):\n     '''Selects `x` in train phase, and `alt` otherwise.\n     Note that `alt` should have the *same shape* as `x`.\n     '''\n-    if _LEARNING_PHASE is 1:\n+    if learning_phase() is 1:\n         return x\n-    elif _LEARNING_PHASE is 0:\n+    elif learning_phase() is 0:\n         return alt\n-    # else: assume learning phase is a placeholder.\n-    x_shape = copy.copy(x.get_shape())\n-    x = _cond(tf.cast(_LEARNING_PHASE, 'bool'), lambda: x, lambda: alt)\n+    # else: assume learning phase is a placeholder tensor.\n+    x = switch(learning_phase(), x, alt)\n     x._uses_learning_phase = True\n-    x.set_shape(x_shape)\n     return x\n \n \n@@ -1347,14 +1370,13 @@ def in_test_phase(x, alt):\n     '''Selects `x` in test phase, and `alt` otherwise.\n     Note that `alt` should have the *same shape* as `x`.\n     '''\n-    if _LEARNING_PHASE is 1:\n+    if learning_phase() is 1:\n         return alt\n-    elif _LEARNING_PHASE is 0:\n+    elif learning_phase() is 0:\n         return x\n-    x_shape = copy.copy(x.get_shape())\n-    x = _cond(tf.cast(_LEARNING_PHASE, 'bool'), lambda: alt, lambda: x)\n+    # else: assume learning phase is a placeholder tensor.\n+    x = switch(learning_phase(), alt, x)\n     x._uses_learning_phase = True\n-    x.set_shape(x_shape)\n     return x\n \n \n@@ -1381,12 +1403,12 @@ def relu(x, alpha=0., max_value=None):\n \n \n def elu(x, alpha=1.):\n-    \"\"\" Exponential linear unit\n+    '''Exponential linear unit.\n \n     # Arguments\n         x: Tensor to compute the activation function for.\n         alpha: scalar\n-    \"\"\"\n+    '''\n     res = tf.nn.elu(x)\n     if alpha == 1:\n         return res\n@@ -1407,6 +1429,8 @@ def softplus(x):\n \n \n def softsign(x):\n+    '''Softsign of a tensor.\n+    '''\n     return tf.nn.softsign(x)\n \n \n@@ -1516,8 +1540,9 @@ def l2_normalize(x, axis):\n         axis = axis % len(x.get_shape())\n     return tf.nn.l2_normalize(x, dim=axis)\n \n+\n def in_top_k(predictions, targets, k):\n-    '''Says whether the `targets` are in the top `k` `predictions`\n+    '''Returns whether the `targets` are in the top `k` `predictions`\n \n     # Arguments\n         predictions: A tensor of shape batch_size x classess and type float32.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9bf55395f14e5ba02a937825dff08484ee5b5006", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 643 | Contributors (this commit): 5 | Commits (past 90d): 6 | Contributors (cumulative): 5 | DMM Complexity: 0.0\n\nDIFF:\n@@ -34,14 +34,12 @@ class _Pooling1D(Layer):\n         raise NotImplementedError\n \n     def call(self, x, mask=None):\n-        x = K.expand_dims(x, -1)   # add dummy last dimension\n-        x = K.permute_dimensions(x, (0, 2, 1, 3))\n+        x = K.expand_dims(x, 2)   # add dummy last dimension\n         output = self._pooling_function(inputs=x, pool_size=self.pool_size,\n                                         strides=self.st,\n                                         border_mode=self.border_mode,\n-                                        dim_ordering='th')\n-        output = K.permute_dimensions(output, (0, 2, 1, 3))\n-        return K.squeeze(output, 3)  # remove dummy last dimension\n+                                        dim_ordering='tf')\n+        return K.squeeze(output, 2)  # remove dummy last dimension\n \n     def get_config(self):\n         config = {'stride': self.stride,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#32be731194a2ff3f82a0689bb758fbdd44e10a69", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 170 | Lines Deleted: 52 | Files Changed: 2 | Hunks: 74 | Methods Changed: 44 | Complexity Δ (Sum/Max): 17/10 | Churn Δ: 222 | Churn Cumulative: 5957 | Contributors (this commit): 56 | Commits (past 90d): 53 | Contributors (cumulative): 81 | DMM Complexity: 0.98\n\nDIFF:\n@@ -10,7 +10,7 @@ import numpy as np\n import os\n import copy\n import warnings\n-from .common import _FLOATX, _EPSILON, _IMAGE_DIM_ORDERING, reset_uids\n+from .common import _FLOATX, _EPSILON, image_dim_ordering, reset_uids\n py_all = all\n \n # INTERNAL UTILS\n@@ -62,7 +62,8 @@ def learning_phase():\n     '''\n     graph = tf.get_default_graph()\n     if graph not in _GRAPH_LEARNING_PHASES:\n-        phase = tf.placeholder(dtype='bool', name='keras_learning_phase')\n+        phase = tf.placeholder(dtype='bool',\n+                               name='keras_learning_phase')\n         _GRAPH_LEARNING_PHASES[graph] = phase\n     return _GRAPH_LEARNING_PHASES[graph]\n \n@@ -170,10 +171,12 @@ def variable(value, dtype=_FLOATX, name=None):\n     '''\n     if hasattr(value, 'tocoo'):\n         sparse_coo = value.tocoo()\n-        indices = np.concatenate((np.expand_dims(sparse_coo.row, 1), np.expand_dims(sparse_coo.col, 1)), 1)\n+        indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),\n+                                  np.expand_dims(sparse_coo.col, 1)), 1)\n         # SparseTensor doesn't need initialization\n-        return tf.SparseTensor(indices=indices, values=sparse_coo.data, shape=sparse_coo.shape)\n-\n+        return tf.SparseTensor(indices=indices,\n+                               values=sparse_coo.data,\n+                               shape=sparse_coo.shape)\n     v = tf.Variable(value, dtype=_convert_string_dtype(dtype), name=name)\n     return v\n \n@@ -209,7 +212,8 @@ def placeholder(shape=None, ndim=None, dtype=_FLOATX, sparse=False, name=None):\n         if ndim:\n             shape = tuple([None for _ in range(ndim)])\n     if sparse:\n-        tf_shape = tf.constant(np.array(list([0 for _ in range(len(shape))]), dtype=np.int64))\n+        tf_shape = tf.constant(np.array(list([0 for _ in range(len(shape))]),\n+                                        dtype=np.int64))\n         x = tf.sparse_placeholder(dtype, shape=tf_shape, name=name)\n     else:\n         x = tf.placeholder(dtype, shape=shape, name=name)\n@@ -263,7 +267,8 @@ def zeros(shape, dtype=_FLOATX, name=None):\n     '''\n     shape = tuple(map(int, shape))\n     tf_dtype = _convert_string_dtype(dtype)\n-    return variable(tf.constant_initializer(0., dtype=tf_dtype)(shape), dtype, name)\n+    return variable(tf.constant_initializer(0., dtype=tf_dtype)(shape),\n+                    dtype, name)\n \n \n def ones(shape, dtype=_FLOATX, name=None):\n@@ -271,7 +276,8 @@ def ones(shape, dtype=_FLOATX, name=None):\n     '''\n     shape = tuple(map(int, shape))\n     tf_dtype = _convert_string_dtype(dtype)\n-    return variable(tf.constant_initializer(1., dtype=tf_dtype)(shape), dtype, name)\n+    return variable(tf.constant_initializer(1., dtype=tf_dtype)(shape),\n+                    dtype, name)\n \n \n def eye(size, dtype=_FLOATX, name=None):\n@@ -876,10 +882,15 @@ def asymmetric_temporal_padding(x, left_pad=1, right_pad=1):\n     return tf.pad(x, pattern)\n \n \n-def spatial_2d_padding(x, padding=(1, 1), dim_ordering=_IMAGE_DIM_ORDERING):\n+def spatial_2d_padding(x, padding=(1, 1), dim_ordering='default'):\n     '''Pads the 2nd and 3rd dimensions of a 4D tensor\n     with \"padding[0]\" and \"padding[1]\" (resp.) zeros left and right.\n     '''\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n+    if dim_ordering not in {'th', 'tf'}:\n+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+\n     if dim_ordering == 'th':\n         pattern = [[0, 0], [0, 0],\n                    [padding[0], padding[0]], [padding[1], padding[1]]]\n@@ -890,10 +901,18 @@ def spatial_2d_padding(x, padding=(1, 1), dim_ordering=_IMAGE_DIM_ORDERING):\n     return tf.pad(x, pattern)\n \n \n-def asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1, left_pad=1, right_pad=1, dim_ordering=_IMAGE_DIM_ORDERING):\n+def asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1,\n+                                  left_pad=1, right_pad=1,\n+                                  dim_ordering='default'):\n     '''Pad the rows and columns of a 4D tensor\n-    with \"top_pad\", \"bottom_pad\", \"left_pad\", \"right_pad\"  (resp.) zeros rows on top, bottom; cols on left, right.\n+    with \"top_pad\", \"bottom_pad\", \"left_pad\", \"right_pad\" (resp.) zeros\n+    rows on top, bottom; cols on left, right.\n     '''\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n+    if dim_ordering not in {'th', 'tf'}:\n+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+\n     if dim_ordering == 'th':\n         pattern = [[0, 0],\n                    [0, 0],\n@@ -907,13 +926,18 @@ def asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1, left_pad=1, right_\n     return tf.pad(x, pattern)\n \n \n-def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering=_IMAGE_DIM_ORDERING):\n+def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='default'):\n     '''Pads 5D tensor with zeros for the depth, height, width dimension with\n     \"padding[0]\", \"padding[1]\" and \"padding[2]\" (resp.) zeros left and right\n \n     For 'tf' dim_ordering, the 2nd, 3rd and 4th dimension will be padded.\n     For 'th' dim_ordering, the 3rd, 4th and 5th dimension will be padded.\n     '''\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n+    if dim_ordering not in {'th', 'tf'}:\n+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+\n     if dim_ordering == 'th':\n         pattern = [\n             [0, 0],\n@@ -1055,7 +1079,8 @@ class Function(object):\n         for tensor, value in zip(self.inputs, inputs):\n             if is_sparse(tensor):\n                 sparse_coo = value.tocoo()\n-                indices = np.concatenate((np.expand_dims(sparse_coo.row, 1), np.expand_dims(sparse_coo.col, 1)), 1)\n+                indices = np.concatenate((np.expand_dims(sparse_coo.row, 1),\n+                                          np.expand_dims(sparse_coo.col, 1)), 1)\n                 value = (indices, sparse_coo.data, sparse_coo.shape)\n             feed_dict[tensor] = value\n         session = get_session()\n@@ -1073,8 +1098,8 @@ def function(inputs, outputs, updates=[], **kwargs):\n     '''\n     if len(kwargs) > 0:\n         msg = [\n-            \"Expected no kwargs, you passed %s\" % len(kwargs),\n-            \"kwargs passed to function are ignored with Tensorflow backend\"\n+            'Expected no kwargs, you passed %s' % len(kwargs),\n+            'kwargs passed to function are ignored with Tensorflow backend'\n         ]\n         warnings.warn('\\n'.join(msg))\n     return Function(inputs, outputs, updates=updates)\n@@ -1640,8 +1665,29 @@ def _postprocess_conv3d_output(x, dim_ordering):\n     return x\n \n \n+def conv1d(x, kernel, stride=1, border_mode='valid',\n+           image_shape=None, filter_shape=None):\n+    '''1D convolution.\n+\n+    # Arguments\n+        kernel: kernel tensor.\n+        strides: stride integer.\n+        border_mode: string, \"same\" or \"valid\".\n+    '''\n+    # pre-process dtype\n+    if _FLOATX == 'float64':\n+        x = tf.cast(x, 'float32')\n+        kernel = tf.cast(kernel, 'float32')\n+    padding = _preprocess_border_mode(border_mode)\n+    x = tf.nn.conv1d(x, kernel, stride, padding=padding)\n+    # post-process dtype\n+    if _FLOATX == 'float64':\n+        x = tf.cast(x, 'float64')\n+    return x\n+\n+\n def conv2d(x, kernel, strides=(1, 1), border_mode='valid',\n-           dim_ordering=_IMAGE_DIM_ORDERING,\n+           dim_ordering='default',\n            image_shape=None, filter_shape=None, filter_dilation=(1, 1)):\n     '''2D convolution.\n \n@@ -1653,8 +1699,10 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid',\n             Whether to use Theano or TensorFlow dimension ordering\n             for inputs/kernels/ouputs.\n     '''\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n     if dim_ordering not in {'th', 'tf'}:\n-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))\n+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n \n     x = _preprocess_conv2d_input(x, dim_ordering)\n     kernel = _preprocess_conv2d_kernel(kernel, dim_ordering)\n@@ -1671,7 +1719,7 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid',\n \n def deconv2d(x, kernel, output_shape, strides=(1, 1),\n              border_mode='valid',\n-             dim_ordering=_IMAGE_DIM_ORDERING,\n+             dim_ordering='default',\n              image_shape=None, filter_shape=None):\n     '''2D deconvolution (i.e. transposed convolution).\n \n@@ -1685,8 +1733,10 @@ def deconv2d(x, kernel, output_shape, strides=(1, 1),\n             Whether to use Theano or TensorFlow dimension ordering\n             for inputs/kernels/ouputs.\n     '''\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n     if dim_ordering not in {'th', 'tf'}:\n-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))\n+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n \n     x = _preprocess_conv2d_input(x, dim_ordering)\n     output_shape = _preprocess_deconv_output_shape(output_shape, dim_ordering)\n@@ -1702,10 +1752,12 @@ def deconv2d(x, kernel, output_shape, strides=(1, 1),\n \n def atrous_conv2d(x, kernel, rate=1,\n                   border_mode='valid',\n-                  dim_ordering=_IMAGE_DIM_ORDERING,\n+                  dim_ordering='default',\n                   image_shape=None, filter_shape=None):\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n     if dim_ordering not in {'th', 'tf'}:\n-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))\n+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n     if rate == 1:\n         return conv2d(x, kernel, strides=(1, 1), border_mode=border_mode,\n                       dim_ordering=dim_ordering)\n@@ -1719,9 +1771,11 @@ def atrous_conv2d(x, kernel, rate=1,\n \n \n def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n-                     border_mode='valid', dim_ordering=_IMAGE_DIM_ORDERING):\n+                     border_mode='valid', dim_ordering='default'):\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n     if dim_ordering not in {'th', 'tf'}:\n-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))\n+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n \n     x = _preprocess_conv2d_input(x, dim_ordering)\n     depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel,\n@@ -1737,7 +1791,7 @@ def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n \n \n def conv3d(x, kernel, strides=(1, 1, 1),\n-           border_mode='valid', dim_ordering=_IMAGE_DIM_ORDERING,\n+           border_mode='valid', dim_ordering='default',\n            volume_shape=None, filter_shape=None):\n     '''3D convolution.\n \n@@ -1749,8 +1803,10 @@ def conv3d(x, kernel, strides=(1, 1, 1),\n             Whether to use Theano or TensorFlow dimension ordering\n             for inputs/kernels/ouputs.\n     '''\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n     if dim_ordering not in {'th', 'tf'}:\n-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))\n+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n \n     x = _preprocess_conv3d_input(x, dim_ordering)\n     kernel = _preprocess_conv3d_kernel(kernel, dim_ordering)\n@@ -1762,7 +1818,7 @@ def conv3d(x, kernel, strides=(1, 1, 1),\n \n \n def pool2d(x, pool_size, strides=(1, 1),\n-           border_mode='valid', dim_ordering=_IMAGE_DIM_ORDERING,\n+           border_mode='valid', dim_ordering='default',\n            pool_mode='max'):\n     '''2D Pooling.\n \n@@ -1773,8 +1829,10 @@ def pool2d(x, pool_size, strides=(1, 1),\n         dim_ordering: one of \"th\", \"tf\".\n         pool_mode: one of \"max\", \"avg\".\n     '''\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n     if dim_ordering not in {'th', 'tf'}:\n-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))\n+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n \n     padding = _preprocess_border_mode(border_mode)\n     strides = (1,) + strides + (1,)\n@@ -1793,7 +1851,7 @@ def pool2d(x, pool_size, strides=(1, 1),\n \n \n def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n-           dim_ordering=_IMAGE_DIM_ORDERING, pool_mode='max'):\n+           dim_ordering='default', pool_mode='max'):\n     '''3D Pooling.\n \n     # Arguments\n@@ -1803,8 +1861,10 @@ def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n         dim_ordering: one of \"th\", \"tf\".\n         pool_mode: one of \"max\", \"avg\".\n     '''\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n     if dim_ordering not in {'th', 'tf'}:\n-        raise Exception('Unknown dim_ordering ' + str(dim_ordering))\n+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n \n     padding = _preprocess_border_mode(border_mode)\n     strides = (1,) + strides + (1,)\n\n@@ -14,7 +14,7 @@ except ImportError:\n     from theano.sandbox.softsign import softsign as T_softsign\n import inspect\n import numpy as np\n-from .common import _FLOATX, _EPSILON, _IMAGE_DIM_ORDERING\n+from .common import _FLOATX, _EPSILON, image_dim_ordering\n py_all = all\n \n \n@@ -35,6 +35,7 @@ def set_learning_phase(value):\n                          '0 or 1.')\n     _LEARNING_PHASE = value\n \n+\n # VARIABLE MANIPULATION\n \n \n@@ -88,7 +89,7 @@ def placeholder(shape=None, ndim=None, dtype=_FLOATX, sparse=False, name=None):\n \n \n def shape(x):\n-    '''Return the shape of a tensor.\n+    '''Returns the shape of a tensor.\n \n     Warning: type returned will be different for\n     Theano backend (Theano tensor type) and TF backend (TF TensorShape).\n@@ -105,25 +106,25 @@ def dtype(x):\n \n \n def eval(x):\n-    '''Run a graph.\n+    '''Returns the value of a tensor.\n     '''\n     return to_dense(x).eval()\n \n \n def zeros(shape, dtype=_FLOATX, name=None):\n-    '''Instantiate an all-zeros variable.\n+    '''Instantiates an all-zeros variable.\n     '''\n     return variable(np.zeros(shape), dtype, name)\n \n \n def ones(shape, dtype=_FLOATX, name=None):\n-    '''Instantiate an all-ones variable.\n+    '''Instantiates an all-ones variable.\n     '''\n     return variable(np.ones(shape), dtype, name)\n \n \n def eye(size, dtype=_FLOATX, name=None):\n-    '''Instantiate an identity matrix.\n+    '''Instantiates an identity matrix.\n     '''\n     return variable(np.eye(size), dtype, name)\n \n@@ -147,7 +148,7 @@ def random_normal_variable(shape, mean, scale, dtype=_FLOATX, name=None):\n \n \n def count_params(x):\n-    '''Return number of scalars in a tensor.\n+    '''Returns the number of scalars in a tensor.\n \n     Return: numpy integer.\n     '''\n@@ -393,7 +394,7 @@ def cos(x):\n \n def normalize_batch_in_training(x, gamma, beta,\n                                 reduction_axes, epsilon=0.0001):\n-    '''Compute mean and std for batch then apply batch_normalization on batch.\n+    '''Computes mean and std for batch then apply batch_normalization on batch.\n     '''\n     dev = theano.config.device\n     use_cudnn = ndim(x) < 5 and reduction_axes == [0, 2, 3] and (dev.startswith('cuda') or dev.startswith('gpu'))\n@@ -616,10 +617,15 @@ def asymmetric_temporal_padding(x, left_pad=1, right_pad=1):\n     return T.set_subtensor(output[:, left_pad:x.shape[1] + left_pad, :], x)\n \n \n-def spatial_2d_padding(x, padding=(1, 1), dim_ordering=_IMAGE_DIM_ORDERING):\n+def spatial_2d_padding(x, padding=(1, 1), dim_ordering='default'):\n     '''Pad the 2nd and 3rd dimensions of a 4D tensor\n     with \"padding[0]\" and \"padding[1]\" (resp.) zeros left and right.\n     '''\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n+    if dim_ordering not in {'th', 'tf'}:\n+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+\n     input_shape = x.shape\n     if dim_ordering == 'th':\n         output_shape = (input_shape[0],\n@@ -647,10 +653,18 @@ def spatial_2d_padding(x, padding=(1, 1), dim_ordering=_IMAGE_DIM_ORDERING):\n     return T.set_subtensor(output[indices], x)\n \n \n-def asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1, left_pad=1, right_pad=1, dim_ordering=_IMAGE_DIM_ORDERING):\n+def asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1,\n+                                  left_pad=1, right_pad=1,\n+                                  dim_ordering='default'):\n     '''Pad the rows and columns of a 4D tensor\n-    with \"top_pad\", \"bottom_pad\", \"left_pad\", \"right_pad\"  (resp.) zeros rows on top, bottom; cols on left, right.\n+    with \"top_pad\", \"bottom_pad\", \"left_pad\", \"right_pad\" (resp.) zeros\n+    rows on top, bottom; cols on left, right.\n     '''\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n+    if dim_ordering not in {'th', 'tf'}:\n+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+\n     input_shape = x.shape\n     if dim_ordering == 'th':\n         output_shape = (input_shape[0],\n@@ -679,10 +693,15 @@ def asymmetric_spatial_2d_padding(x, top_pad=1, bottom_pad=1, left_pad=1, right_\n     return T.set_subtensor(output[indices], x)\n \n \n-def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering=_IMAGE_DIM_ORDERING):\n+def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='default'):\n     '''Pad the 2nd, 3rd and 4th dimensions of a 5D tensor\n     with \"padding[0]\", \"padding[1]\" and \"padding[2]\" (resp.) zeros left and right.\n     '''\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n+    if dim_ordering not in {'th', 'tf'}:\n+        raise ValueError('Unknown dim_ordering ' + str(dim_ordering))\n+\n     input_shape = x.shape\n     if dim_ordering == 'th':\n         output_shape = (input_shape[0],\n@@ -1119,7 +1138,7 @@ def l2_normalize(x, axis):\n \n \n def in_top_k(predictions, targets, k):\n-    '''Says whether the `targets` are in the top `k` `predictions`\n+    '''Returns whether the `targets` are in the top `k` `predictions`\n \n     # Arguments\n         predictions: A tensor of shape batch_size x classess and type float32.\n@@ -1277,8 +1296,20 @@ def _postprocess_conv3d_output(conv_out, x, border_mode, np_kernel, strides, dim\n     return conv_out\n \n \n+def conv1d(x, kernel, stride=1, border_mode='valid',\n+           image_shape=None, filter_shape=None):\n+    '''1D convolution.\n+\n+    # Arguments\n+        kernel: kernel tensor.\n+        strides: stride integer.\n+        border_mode: string, \"same\" or \"valid\".\n+    '''\n+    raise NotImplementedError\n+\n+\n def conv2d(x, kernel, strides=(1, 1), border_mode='valid',\n-           dim_ordering=_IMAGE_DIM_ORDERING, image_shape=None,\n+           dim_ordering='default', image_shape=None,\n            filter_shape=None, filter_dilation=(1, 1)):\n     '''2D convolution.\n \n@@ -1290,6 +1321,8 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid',\n             Whether to use Theano or TensorFlow dimension ordering\n         in inputs/kernels/ouputs.\n     '''\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n     if dim_ordering not in {'th', 'tf'}:\n         raise Exception('Unknown dim_ordering ' + str(dim_ordering))\n \n@@ -1322,7 +1355,7 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid',\n \n def deconv2d(x, kernel, output_shape, strides=(1, 1),\n              border_mode='valid',\n-             dim_ordering=_IMAGE_DIM_ORDERING,\n+             dim_ordering='default',\n              image_shape=None, filter_shape=None):\n     '''2D deconvolution (transposed convolution).\n \n@@ -1336,6 +1369,8 @@ def deconv2d(x, kernel, output_shape, strides=(1, 1),\n         in inputs/kernels/ouputs.\n     '''\n     flip_filters = False\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n     if dim_ordering not in {'th', 'tf'}:\n         raise Exception('Unknown dim_ordering ' + str(dim_ordering))\n \n@@ -1360,18 +1395,18 @@ def deconv2d(x, kernel, output_shape, strides=(1, 1),\n \n def atrous_conv2d(x, kernel, rate=1,\n                   border_mode='valid',\n-                  dim_ordering=_IMAGE_DIM_ORDERING,\n+                  dim_ordering='default',\n                   image_shape=None, filter_shape=None):\n     raise NotImplementedError\n \n \n def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n-                     border_mode='valid', dim_ordering=_IMAGE_DIM_ORDERING):\n+                     border_mode='valid', dim_ordering='default'):\n     raise NotImplementedError\n \n \n def conv3d(x, kernel, strides=(1, 1, 1),\n-           border_mode='valid', dim_ordering=_IMAGE_DIM_ORDERING,\n+           border_mode='valid', dim_ordering='default',\n            volume_shape=None, filter_shape=None,\n            filter_dilation=(1, 1, 1)):\n     '''3D convolution.\n@@ -1384,6 +1419,8 @@ def conv3d(x, kernel, strides=(1, 1, 1),\n             Whether to use Theano or TensorFlow dimension ordering\n         in inputs/kernels/ouputs.\n     '''\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n     if dim_ordering not in {'th', 'tf'}:\n         raise Exception('Unknown dim_ordering ' + str(dim_ordering))\n \n@@ -1417,12 +1454,14 @@ def conv3d(x, kernel, strides=(1, 1, 1),\n \n # TODO: remove this function when theano without AbstractConv3d is deprecated\n def _old_theano_conv3d(x, kernel, strides=(1, 1, 1),\n-                       border_mode='valid', dim_ordering=_IMAGE_DIM_ORDERING,\n+                       border_mode='valid', dim_ordering='default',\n                        volume_shape=None, filter_shape=None):\n     '''\n     Run on cuDNN if available.\n     border_mode: string, \"same\" or \"valid\".\n     '''\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n     if dim_ordering not in {'th', 'tf'}:\n         raise Exception('Unknown dim_ordering ' + str(dim_ordering))\n \n@@ -1479,7 +1518,12 @@ def _old_theano_conv3d(x, kernel, strides=(1, 1, 1),\n \n \n def pool2d(x, pool_size, strides=(1, 1), border_mode='valid',\n-           dim_ordering=_IMAGE_DIM_ORDERING, pool_mode='max'):\n+           dim_ordering='default', pool_mode='max'):\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n+    if dim_ordering not in {'th', 'tf'}:\n+        raise Exception('Unknown dim_ordering ' + str(dim_ordering))\n+\n     if border_mode == 'same':\n         w_pad = pool_size[0] - 2 if pool_size[0] % 2 == 1 else pool_size[0] - 1\n         h_pad = pool_size[1] - 2 if pool_size[1] % 2 == 1 else pool_size[1] - 1\n@@ -1522,7 +1566,12 @@ def pool2d(x, pool_size, strides=(1, 1), border_mode='valid',\n \n \n def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n-           dim_ordering=_IMAGE_DIM_ORDERING, pool_mode='max'):\n+           dim_ordering='default', pool_mode='max'):\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n+    if dim_ordering not in {'th', 'tf'}:\n+        raise Exception('Unknown dim_ordering ' + str(dim_ordering))\n+\n     # TODO: remove this if statement when Theano without pool_3d is deprecated\n     #       (pool_3d was introduced after 0.9.0dev3)\n     if not hasattr(T.signal.pool, 'pool_3d'):\n@@ -1576,7 +1625,12 @@ def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n # TODO: remove this function when Theano without pool_3d is deprecated\n #       (pool_3d was introduced after 0.9.0dev3)\n def _old_theano_pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n-                       dim_ordering=_IMAGE_DIM_ORDERING, pool_mode='max'):\n+                       dim_ordering='default', pool_mode='max'):\n+    if dim_ordering == 'default':\n+        dim_ordering = image_dim_ordering()\n+    if dim_ordering not in {'th', 'tf'}:\n+        raise Exception('Unknown dim_ordering ' + str(dim_ordering))\n+\n     if border_mode == 'same':\n         # TODO: add implementation for border_mode=\"same\"\n         raise Exception('border_mode=\"same\" not supported with Theano.')\n@@ -1667,11 +1721,13 @@ def ctc_interleave_blanks(Y):\n     Y_ = T.set_subtensor(Y_[T.arange(Y.shape[0]) * 2 + 1], Y)\n     return Y_\n \n+\n def ctc_create_skip_idxs(Y):\n     skip_idxs = T.arange((Y.shape[0] - 3) // 2) * 2 + 1\n     non_repeats = T.neq(Y[skip_idxs], Y[skip_idxs + 2])\n     return skip_idxs[non_repeats.nonzero()]\n \n+\n def ctc_update_log_p(skip_idxs, zeros, active, log_p_curr, log_p_prev):\n     active_skip_idxs = skip_idxs[(skip_idxs < active).nonzero()]\n     active_next = T.cast(T.minimum(\n@@ -1697,11 +1753,11 @@ def ctc_update_log_p(skip_idxs, zeros, active, log_p_curr, log_p_prev):\n     )\n     return active_next, log_p_next\n \n+\n def ctc_path_probs(predict, Y, alpha=1e-4):\n     smoothed_predict = (1 - alpha) * predict[:, Y] + alpha * np.float32(1.) / Y.shape[0]\n     L = T.log(smoothed_predict)\n     zeros = T.zeros_like(L[0])\n-    base = T.set_subtensor(zeros[:1], np.float32(1))\n     log_first = zeros\n \n     f_skip_idxs = ctc_create_skip_idxs(Y)\n@@ -1720,12 +1776,14 @@ def ctc_path_probs(predict, Y, alpha=1e-4):\n     log_probs = log_f_probs + log_b_probs[::-1, ::-1] - L\n     return log_probs, mask\n \n+\n def ctc_cost(predict, Y):\n     log_probs, mask = ctc_path_probs(predict, ctc_interleave_blanks(Y))\n     common_factor = T.max(log_probs)\n     total_log_prob = T.log(T.sum(T.exp(log_probs - common_factor)[mask.nonzero()])) + common_factor\n     return -total_log_prob\n \n+\n # batchifies original CTC code\n def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n     '''Runs CTC loss algorithm on each batch element.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
