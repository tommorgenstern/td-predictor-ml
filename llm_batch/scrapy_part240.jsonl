{"custom_id": "scrapy#df7e0a4315f9db2c74fa9e9a0654f44277da2e55", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 518 | Contributors (this commit): 38 | Commits (past 90d): 1 | Contributors (cumulative): 38 | DMM Complexity: None\n\nDIFF:\n@@ -270,7 +270,7 @@ TEMPLATES_DIR = abspath(join(dirname(__file__), '..', 'templates'))\n \n URLLENGTH_LIMIT = 2083\n \n-USER_AGENT = 'Scrapy/%s (+http://scrapy.org)' % import_module('scrapy').__version__\n+USER_AGENT = 'Scrapy/%s (+https://scrapy.org)' % import_module('scrapy').__version__\n \n TELNETCONSOLE_ENABLED = 1\n TELNETCONSOLE_PORT = [6023, 6073]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#846fd83512bb45335195b060d76b46060b4b6e3d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 62 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 7 | Methods Changed: 8 | Complexity Δ (Sum/Max): 7/5 | Churn Δ: 62 | Churn Cumulative: 827 | Contributors (this commit): 11 | Commits (past 90d): 2 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,4 +1,5 @@\n from __future__ import print_function\n+import json\n import logging\n \n from w3lib.url import is_url\n@@ -48,6 +49,8 @@ class Command(ScrapyCommand):\n             help=\"use CrawlSpider rules to discover the callback\")\n         parser.add_option(\"-c\", \"--callback\", dest=\"callback\",\n             help=\"use this callback for parsing, instead looking for a callback\")\n+        parser.add_option(\"-m\", \"--meta\", dest=\"meta\",\n+            help=\"inject extra meta into the Request, it must be a valid raw json string\")\n         parser.add_option(\"-d\", \"--depth\", dest=\"depth\", type=\"int\", default=1,\n             help=\"maximum depth for parsing requests [default: %default]\")\n         parser.add_option(\"-v\", \"--verbose\", dest=\"verbose\", action=\"store_true\",\n@@ -204,6 +207,10 @@ class Command(ScrapyCommand):\n                     req.callback = callback\n                 return requests\n \n+        #update request meta if any extra meta was passed through the --meta/-m opts.\n+        if opts.meta:\n+            request.meta.update(opts.meta)\n+\n         request.meta['_depth'] = 1\n         request.meta['_callback'] = request.callback\n         request.callback = callback\n@@ -211,11 +218,27 @@ class Command(ScrapyCommand):\n \n     def process_options(self, args, opts):\n         ScrapyCommand.process_options(self, args, opts)\n+\n+        self.process_spider_arguments(opts)\n+        self.process_request_meta(opts)\n+\n+    def process_spider_arguments(self, opts):\n+\n         try:\n             opts.spargs = arglist_to_dict(opts.spargs)\n         except ValueError:\n             raise UsageError(\"Invalid -a value, use -a NAME=VALUE\", print_help=False)\n \n+    def process_request_meta(self, opts):\n+\n+        if opts.meta:\n+            try:\n+                opts.meta = json.loads(opts.meta)\n+            except ValueError:\n+                raise UsageError(\"Invalid -m/--meta value, pass a valid json string to -m or --meta. \" \\\n+                                \"Example: --meta='{\\\"foo\\\" : \\\"bar\\\"}'\", print_help=False)\n+\n+\n     def run(self, args, opts):\n         # parse arguments\n         if not len(args) == 1 or not is_url(args[0]):\n\n@@ -29,6 +29,21 @@ class MySpider(scrapy.Spider):\n             self.logger.debug('It Works!')\n         return [scrapy.Item(), dict(foo='bar')]\n \n+    def parse_request_with_meta(self, response):\n+        foo = response.meta.get('foo', 'bar')\n+\n+        if foo == 'bar':\n+            self.logger.debug('It Does Not Work :(')\n+        else:\n+            self.logger.debug('It Works!')\n+\n+    def parse_request_without_meta(self, response):\n+        foo = response.meta.get('foo', 'bar')\n+\n+        if foo == 'bar':\n+            self.logger.debug('It Works!')\n+        else:\n+            self.logger.debug('It Does Not Work :(')\n \n class MyGoodCrawlSpider(CrawlSpider):\n     name = 'goodcrawl{0}'\n@@ -84,6 +99,30 @@ ITEM_PIPELINES = {'%s.pipelines.MyPipeline': 1}\n                                            self.url('/html')])\n         self.assertIn(\"DEBUG: It Works!\", to_native_str(stderr))\n \n+    @defer.inlineCallbacks\n+    def test_request_with_meta(self):\n+        raw_json_string = '{\"foo\" : \"baz\"}'\n+        _, _, stderr = yield self.execute(['--spider', self.spider_name,\n+                                           '--meta', raw_json_string,\n+                                           '-c', 'parse_request_with_meta',\n+                                           self.url('/html')])\n+        self.assertIn(\"DEBUG: It Works!\", to_native_str(stderr))\n+\n+        _, _, stderr = yield self.execute(['--spider', self.spider_name,\n+                                           '-m', raw_json_string,\n+                                           '-c', 'parse_request_with_meta',\n+                                           self.url('/html')])\n+        self.assertIn(\"DEBUG: It Works!\", to_native_str(stderr))\n+\n+\n+    @defer.inlineCallbacks\n+    def test_request_without_meta(self):\n+        _, _, stderr = yield self.execute(['--spider', self.spider_name,\n+                                          '-c', 'parse_request_without_meta',\n+                                           self.url('/html')])\n+        self.assertIn(\"DEBUG: It Works!\", to_native_str(stderr))\n+\n+\n     @defer.inlineCallbacks\n     def test_pipelines(self):\n         _, _, stderr = yield self.execute(['--spider', self.spider_name,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#62a626102877de4998538717f34e61d2f7d2622c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 4 | Churn Cumulative: 5 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -52,6 +52,10 @@ class OffsiteMiddleware(object):\n         allowed_domains = getattr(spider, 'allowed_domains', None)\n         if not allowed_domains:\n             return re.compile('') # allow all by default\n+        for domainIndex in range(0, len(allowed_domains)):\n+            url_pattern = re.compile(\"^https?://.*$\")\n+            if url_pattern.match(allowed_domains[domainIndex]):\n+                logger.warn(\"allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains.\" % allowed_domains[domainIndex])\n         regex = r'^(.*\\.)?(%s)$' % '|'.join(re.escape(d) for d in allowed_domains if d is not None)\n         return re.compile(regex)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#5441cc18e43cba6b8196ece49d6b454badb246f0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 59 | Contributors (this commit): 6 | Commits (past 90d): 1 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -1,4 +1,5 @@\n-import sys, os\n+import sys\n+import os\n \n from scrapy.commands import ScrapyCommand\n from scrapy.exceptions import UsageError\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#91ff194d1e9477d2196817ea1dc8beb220c3e058", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 11 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -52,10 +52,10 @@ class OffsiteMiddleware(object):\n         allowed_domains = getattr(spider, 'allowed_domains', None)\n         if not allowed_domains:\n             return re.compile('') # allow all by default\n-        for domainIndex in range(0, len(allowed_domains)):\n+        for domain in allowed_domains:\n             url_pattern = re.compile(\"^https?://.*$\")\n-            if url_pattern.match(allowed_domains[domainIndex]):\n-                logger.warn(\"allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains.\" % allowed_domains[domainIndex])\n+            if url_pattern.match(domain):\n+                logger.warn(\"allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains.\" % domain)\n         regex = r'^(.*\\.)?(%s)$' % '|'.join(re.escape(d) for d in allowed_domains if d is not None)\n         return re.compile(regex)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#8ec3b476b03d6b8424f6dfc556758392e7a5a61f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 14 | Churn Cumulative: 62 | Contributors (this commit): 7 | Commits (past 90d): 4 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -6,6 +6,7 @@ See documentation in docs/topics/spider-middleware.rst\n \n import re\n import logging\n+import warnings\n \n from scrapy import signals\n from scrapy.http import Request\n@@ -55,7 +56,7 @@ class OffsiteMiddleware(object):\n         for domain in allowed_domains:\n             url_pattern = re.compile(\"^https?://.*$\")\n             if url_pattern.match(domain):\n-                logger.warn(\"allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains.\" % domain)\n+                warnings.warn(\"allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains.\" % domain, Warning)\n         regex = r'^(.*\\.)?(%s)$' % '|'.join(re.escape(d) for d in allowed_domains if d is not None)\n         return re.compile(regex)\n \n\n@@ -6,6 +6,7 @@ from scrapy.http import Response, Request\n from scrapy.spiders import Spider\n from scrapy.spidermiddlewares.offsite import OffsiteMiddleware\n from scrapy.utils.test import get_crawler\n+import warnings\n \n class TestOffsiteMiddleware(TestCase):\n \n@@ -68,3 +69,13 @@ class TestOffsiteMiddleware4(TestOffsiteMiddleware3):\n       reqs = [Request('http://scrapytest.org/1')]\n       out = list(self.mw.process_spider_output(res, reqs, self.spider))\n       self.assertEqual(out, reqs)\n+\n+\n+class TestOffsiteMiddleware5(TestOffsiteMiddleware4):\n+    \n+    def test_get_host_regex(self):\n+        self.spider.allowed_domains = ['http://scrapytest.org', 'scrapy.org', 'scrapy.test.org']\n+        with warnings.catch_warnings(record=True) as w:\n+            warnings.simplefilter(\"always\")\n+            self.mw.get_host_regex(self.spider)\n+            assert \"allowed_domains accepts only domains, not URLs.\" in str(w[-1].message)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#454d5e57333e9f33c8d684e4e21f8f7e9493f310", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 72 | Contributors (this commit): 7 | Commits (past 90d): 6 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -56,10 +56,15 @@ class OffsiteMiddleware(object):\n         for domain in allowed_domains:\n             url_pattern = re.compile(\"^https?://.*$\")\n             if url_pattern.match(domain):\n-                warnings.warn(\"allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains.\" % domain, Warning)\n+                warnings.warn(\"allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains.\" % domain, URLWarning)\n+                \n         regex = r'^(.*\\.)?(%s)$' % '|'.join(re.escape(d) for d in allowed_domains if d is not None)\n         return re.compile(regex)\n \n     def spider_opened(self, spider):\n         self.host_regex = self.get_host_regex(spider)\n         self.domains_seen = set()\n+\n+\n+class URLWarning(Warning):\n+    pass\n\\ No newline at end of file\n\n@@ -5,6 +5,7 @@ from six.moves.urllib.parse import urlparse\n from scrapy.http import Response, Request\n from scrapy.spiders import Spider\n from scrapy.spidermiddlewares.offsite import OffsiteMiddleware\n+from scrapy.spidermiddlewares.offsite import URLWarning\n from scrapy.utils.test import get_crawler\n import warnings\n \n@@ -78,4 +79,4 @@ class TestOffsiteMiddleware5(TestOffsiteMiddleware4):\n         with warnings.catch_warnings(record=True) as w:\n             warnings.simplefilter(\"always\")\n             self.mw.get_host_regex(self.spider)\n-            assert \"allowed_domains accepts only domains, not URLs.\" in str(w[-1].message)\n+            assert issubclass(w[-1].category, URLWarning)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#22c68baf990f15d249f38c481f24a984977be3e5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 23 | Contributors (this commit): 4 | Commits (past 90d): 5 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -53,8 +53,8 @@ class OffsiteMiddleware(object):\n         allowed_domains = getattr(spider, 'allowed_domains', None)\n         if not allowed_domains:\n             return re.compile('') # allow all by default\n-        for domain in allowed_domains:\n         url_pattern = re.compile(\"^https?://.*$\")\n+        for domain in allowed_domains:\n             if url_pattern.match(domain):\n                 warnings.warn(\"allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains.\" % domain, URLWarning)\n                 \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#44623687ab8936c5696f68f74e438a2891880c82", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 454 | Contributors (this commit): 15 | Commits (past 90d): 2 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -53,7 +53,6 @@ setup(\n         'Programming Language :: Python :: 2',\n         'Programming Language :: Python :: 2.7',\n         'Programming Language :: Python :: 3',\n-        'Programming Language :: Python :: 3.3',\n         'Programming Language :: Python :: 3.4',\n         'Programming Language :: Python :: 3.5',\n         'Programming Language :: Python :: 3.6',\n@@ -61,6 +60,7 @@ setup(\n         'Topic :: Software Development :: Libraries :: Application Frameworks',\n         'Topic :: Software Development :: Libraries :: Python Modules',\n     ],\n+    python_requires='>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*',\n     install_requires=[\n         'Twisted>=13.1.0',\n         'w3lib>=1.17.0',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#1058169f0e3a8646dbd20f9b4c0b599ed9f6d08e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 456 | Contributors (this commit): 15 | Commits (past 90d): 3 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -56,6 +56,8 @@ setup(\n         'Programming Language :: Python :: 3.4',\n         'Programming Language :: Python :: 3.5',\n         'Programming Language :: Python :: 3.6',\n+        'Programming Language :: Python :: Implementation :: CPython',\n+        'Programming Language :: Python :: Implementation :: PyPy',\n         'Topic :: Internet :: WWW/HTTP',\n         'Topic :: Software Development :: Libraries :: Application Frameworks',\n         'Topic :: Software Development :: Libraries :: Python Modules',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#041308afe7c40de7088f75b0e0c312ecd5de428a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 237 | Contributors (this commit): 6 | Commits (past 90d): 1 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -219,9 +219,12 @@ class UtilsPythonTestCase(unittest.TestCase):\n             self.assertEqual(get_func_args(\" \".join), [])\n             self.assertEqual(get_func_args(operator.itemgetter(2)), [])\n         else:\n-            self.assertEqual(get_func_args(six.text_type.split), ['sep', 'maxsplit'])\n-            self.assertEqual(get_func_args(\" \".join), ['list'])\n-            self.assertEqual(get_func_args(operator.itemgetter(2)), ['obj'])\n+            stripself = not six.PY2  # PyPy3 exposes them as methods\n+            self.assertEqual(\n+                get_func_args(six.text_type.split, stripself), ['sep', 'maxsplit'])\n+            self.assertEqual(get_func_args(\" \".join, stripself), ['list'])\n+            self.assertEqual(\n+                get_func_args(operator.itemgetter(2), stripself), ['obj'])\n \n \n     def test_without_none_values(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#61c0b1478284b02a4fcfd2cc4931587c348c5d3a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 2 | Churn Cumulative: 1593 | Contributors (this commit): 18 | Commits (past 90d): 5 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -379,7 +379,7 @@ class ScrapyAgent(object):\n                            {'size': expected_size, 'warnsize': warnsize, 'request': request})\n \n         def _cancel(_):\n-            # Abort connection inmediately.\n+            # Abort connection immediately.\n             txresponse._transport._producer.abortConnection()\n \n         d = defer.Deferred(_cancel)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#1d1581266c3df99ebf870d6c3e10ac09f2ee3673", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 187 | Contributors (this commit): 11 | Commits (past 90d): 2 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -11,7 +11,7 @@ def defer_fail(_failure):\n     \"\"\"Same as twisted.internet.defer.fail but delay calling errback until\n     next reactor loop\n \n-    It delays by 100ms so reactor has a chance to go trough readers and writers\n+    It delays by 100ms so reactor has a chance to go through readers and writers\n     before attending pending delayed calls, so do not set delay to zero.\n     \"\"\"\n     d = defer.Deferred()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#ba15b63ed696dbbd6aa6082c035754a15ca8e03c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 562 | Contributors (this commit): 7 | Commits (past 90d): 1 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -272,7 +272,10 @@ class TextResponseTest(BaseResponseTest):\n                                  headers={\"Content-type\": [\"text/html; charset=utf-8\"]},\n                                  body=b\"\\xef\\xbb\\xbfWORD\\xe3\\xab\")\n         self.assertEqual(r6.encoding, 'utf-8')\n-        self.assertEqual(r6.text, u'WORD\\ufffd\\ufffd')\n+        self.assertIn(r6.text, {\n+            u'WORD\\ufffd\\ufffd',  # w3lib < 1.19.0\n+            u'WORD\\ufffd',        # w3lib >= 1.19.0\n+        })\n \n     def test_bom_is_removed_from_body(self):\n         # Inferring encoding from body also cache decoded body as sideeffect,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c1916626c1b5c06f1b3c89cd29db1b7b5bc9996c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 35 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -1,17 +1,18 @@\n \n from __future__ import absolute_import\n+import signal\n \n from twisted.internet import reactor\n \n-import signal\n \n signal_names = {}\n for signame in dir(signal):\n-    if signame.startswith(\"SIG\"):\n+    if signame.startswith('SIG') and not signame.startswith('SIG_'):\n         signum = getattr(signal, signame)\n         if isinstance(signum, int):\n             signal_names[signum] = signame\n \n+\n def install_shutdown_handlers(function, override_sigint=True):\n     \"\"\"Install the given function as a signal handler for all common shutdown\n     signals (such as SIGINT, SIGTERM, etc). If override_sigint is ``False`` the\n@@ -24,5 +25,5 @@ def install_shutdown_handlers(function, override_sigint=True):\n             override_sigint:\n         signal.signal(signal.SIGINT, function)\n     # Catch Ctrl-Break in windows\n-    if hasattr(signal, \"SIGBREAK\"):\n+    if hasattr(signal, 'SIGBREAK'):\n         signal.signal(signal.SIGBREAK, function)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#6f264ab190882d9bfb375688a7e44d03716242ba", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 15 | Churn Cumulative: 106 | Contributors (this commit): 5 | Commits (past 90d): 1 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -41,10 +41,12 @@ class RobotsTxtMiddleware(object):\n         return d\n \n     def process_request_2(self, rp, request, spider):\n-        if rp is not None and not rp.can_fetch(\n-                 to_native_str(self._useragent), request.url):\n+        if rp is None:\n+            return\n+        if not rp.can_fetch(to_native_str(self._useragent), request.url):\n             logger.debug(\"Forbidden by robots.txt: %(request)s\",\n                          {'request': request}, extra={'spider': spider})\n+            self.crawler.stats.inc_value('robotstxt/forbidden')\n             raise IgnoreRequest()\n \n     def robot_parser(self, request, spider):\n@@ -63,6 +65,7 @@ class RobotsTxtMiddleware(object):\n             dfd.addCallback(self._parse_robots, netloc)\n             dfd.addErrback(self._logerror, robotsreq, spider)\n             dfd.addErrback(self._robots_error, netloc)\n+            self.crawler.stats.inc_value('robotstxt/request_count')\n \n         if isinstance(self._parsers[netloc], Deferred):\n             d = Deferred()\n@@ -83,6 +86,9 @@ class RobotsTxtMiddleware(object):\n         return failure\n \n     def _parse_robots(self, response, netloc):\n+        self.crawler.stats.inc_value('robotstxt/response_count')\n+        self.crawler.stats.inc_value(\n+            'robotstxt/response_status_count/{}'.format(response.status))\n         rp = robotparser.RobotFileParser(response.url)\n         body = ''\n         if hasattr(response, 'text'):\n@@ -95,7 +101,7 @@ class RobotsTxtMiddleware(object):\n                 # but keep the lookup cached (in self._parsers)\n                 # Running rp.parse() will set rp state from\n                 # 'disallow all' to 'allow any'.\n-                pass\n+                self.crawler.stats.inc_value('robotstxt/unicode_error_count')\n         # stdlib's robotparser expects native 'str' ;\n         # with unicode input, non-ASCII encoded bytes decoding fails in Python2\n         rp.parse(to_native_str(body).splitlines())\n@@ -105,6 +111,9 @@ class RobotsTxtMiddleware(object):\n         rp_dfd.callback(rp)\n \n     def _robots_error(self, failure, netloc):\n+        if failure.type is not IgnoreRequest:\n+            key = 'robotstxt/exception_count/{}'.format(failure.type)\n+            self.crawler.stats.inc_value(key)\n         rp_dfd = self._parsers[netloc]\n         self._parsers[netloc] = None\n         rp_dfd.callback(None)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#4d5e5378bd2ccea2879102614536410d9338b3f1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 2 | Churn Cumulative: 108 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -45,7 +45,7 @@ class RobotsTxtMiddleware(object):\n                  to_native_str(self._useragent), request.url):\n             logger.debug(\"Forbidden by robots.txt: %(request)s\",\n                          {'request': request}, extra={'spider': spider})\n-            raise IgnoreRequest()\n+            raise IgnoreRequest(\"Forbidden by robots.txt\")\n \n     def robot_parser(self, request, spider):\n         url = urlparse_cached(request)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#0c374c00fb7c8d24a60bec8a94f7cbb06accb980", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 92 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -55,7 +55,7 @@ class TelnetConsole(protocol.ServerFactory):\n     def start_listening(self):\n         self.port = listen_tcp(self.portrange, self.host, self)\n         h = self.port.getHost()\n-        logger.debug(\"Telnet console listening on %(host)s:%(port)d\",\n+        logger.info(\"Telnet console listening on %(host)s:%(port)d\",\n                     {'host': h.host, 'port': h.port},\n                     extra={'crawler': self.crawler})\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#a56540877c2c24d3ba787cc43ca1f81d91b386fd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 7 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 16 | Churn Cumulative: 72 | Contributors (this commit): 5 | Commits (past 90d): 2 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -25,9 +25,10 @@ def _serializable_queue(queue_class, serialize, deserialize):\n def _pickle_serialize(obj):\n     try:\n         return pickle.dumps(obj, protocol=2)\n-    # Python>=3.5 raises AttributeError here while\n-    # Python<=3.4 raises pickle.PicklingError\n-    except (pickle.PicklingError, AttributeError) as e:\n+    # Python<=3.4 raises pickle.PicklingError here while\n+    # Python>=3.5 raises AttributeError and\n+    # Python>=3.6 raises TypeError\n+    except (pickle.PicklingError, AttributeError, TypeError) as e:\n         raise ValueError(str(e))\n \n PickleFifoDiskQueue = _serializable_queue(queue.FifoDiskQueue, \\\n\n@@ -1,3 +1,4 @@\n+from sys import version_info\n import pickle\n \n from queuelib.tests import test_queue as t\n@@ -5,6 +6,7 @@ from scrapy.squeues import MarshalFifoDiskQueue, MarshalLifoDiskQueue, PickleFif\n from scrapy.item import Item, Field\n from scrapy.http import Request\n from scrapy.loader import ItemLoader\n+from scrapy.selector import Selector\n \n class TestItem(Item):\n     name = Field()\n@@ -17,20 +19,23 @@ class TestLoader(ItemLoader):\n     name_out = staticmethod(_test_procesor)\n \n def nonserializable_object_test(self):\n+    q = self.queue()\n     try:\n         pickle.dumps(lambda x: x)\n     except Exception:\n         # Trigger Twisted bug #7989\n         import twisted.persisted.styles  # NOQA\n-        q = self.queue()\n         self.assertRaises(ValueError, q.push, lambda x: x)\n     else:\n         # Use a different unpickleable object\n         class A(object): pass\n         a = A()\n         a.__reduce__ = a.__reduce_ex__ = None\n-        q = self.queue()\n         self.assertRaises(ValueError, q.push, a)\n+    if version_info.major == 3 and version_info.minor >= 6:\n+        # Selectors should fail (lxml.html.HtmlElement objects can't be pickled)\n+        sel = Selector(text='<html><body><p>some text</p></body></html>')\n+        self.assertRaises(ValueError, q.push, sel)\n \n class MarshalFifoDiskQueueTest(t.FifoDiskQueueTest):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#e4558cb27e8eeec8432a06124acf8c2569784ccc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 2 | Churn Cumulative: 63 | Contributors (this commit): 5 | Commits (past 90d): 2 | Contributors (cumulative): 5 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,4 +1,3 @@\n-from sys import version_info\n import pickle\n \n from queuelib.tests import test_queue as t\n@@ -32,7 +31,6 @@ def nonserializable_object_test(self):\n         a = A()\n         a.__reduce__ = a.__reduce_ex__ = None\n         self.assertRaises(ValueError, q.push, a)\n-    if version_info.major == 3 and version_info.minor >= 6:\n     # Selectors should fail (lxml.html.HtmlElement objects can't be pickled)\n     sel = Selector(text='<html><body><p>some text</p></body></html>')\n     self.assertRaises(ValueError, q.push, sel)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#0d87e77afeb506c69f4717744917b95234a86650", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 458 | Contributors (this commit): 16 | Commits (past 90d): 3 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -71,7 +71,7 @@ setup(\n         'pyOpenSSL',\n         'cssselect>=0.9',\n         'six>=1.5.2',\n-        'parsel>=1.1',\n+        'parsel>=1.4',\n         'PyDispatcher>=2.0.5',\n         'service_identity',\n     ],\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#6edd4114c4e715a3a0c440af455fff089a099620", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 13 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -26,7 +26,7 @@ def _pickle_serialize(obj):\n     try:\n         return pickle.dumps(obj, protocol=2)\n     # Python <= 3.4 raises pickle.PicklingError here while\n-    # Python>=3.5 raises AttributeError and\n+    # 3.5 <= Python < 3.6 raises AttributeError and\n     # Python >= 3.6 raises TypeError\n     except (pickle.PicklingError, AttributeError, TypeError) as e:\n         raise ValueError(str(e))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#dc0304fde1b29b4973fabf9d189eb5c4084bf899", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 6 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 294 | Contributors (this commit): 10 | Commits (past 90d): 2 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -1,6 +1,6 @@\n from docutils.parsers.rst.roles import set_classes\n from docutils import nodes\n-from sphinx.util.compat import Directive\n+from docutils.parsers.rst import Directive\n from sphinx.util.nodes import make_refnode\n from operator import itemgetter\n \n@@ -110,24 +110,28 @@ def setup(app):\n     app.connect('doctree-read', collect_scrapy_settings_refs)\n     app.connect('doctree-resolved', replace_settingslist_nodes)\n \n+\n def source_role(name, rawtext, text, lineno, inliner, options={}, content=[]):\n     ref = 'https://github.com/scrapy/scrapy/blob/master/' + text\n     set_classes(options)\n     node = nodes.reference(rawtext, text, refuri=ref, **options)\n     return [node], []\n \n+\n def issue_role(name, rawtext, text, lineno, inliner, options={}, content=[]):\n     ref = 'https://github.com/scrapy/scrapy/issues/' + text\n     set_classes(options)\n     node = nodes.reference(rawtext, 'issue ' + text, refuri=ref, **options)\n     return [node], []\n \n+\n def commit_role(name, rawtext, text, lineno, inliner, options={}, content=[]):\n     ref = 'https://github.com/scrapy/scrapy/commit/' + text\n     set_classes(options)\n     node = nodes.reference(rawtext, 'commit ' + text, refuri=ref, **options)\n     return [node], []\n \n+\n def rev_role(name, rawtext, text, lineno, inliner, options={}, content=[]):\n     ref = 'http://hg.scrapy.org/scrapy/changeset/' + text\n     set_classes(options)\n\n@@ -144,10 +144,6 @@ html_static_path = ['_static']\n # using the given strftime format.\n html_last_updated_fmt = '%b %d, %Y'\n \n-# If true, SmartyPants will be used to convert quotes and dashes to\n-# typographically correct entities.\n-html_use_smartypants = True\n-\n # Custom sidebar templates, maps document names to template names.\n #html_sidebars = {}\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#acd2b8d43b5ebec7ffd364b6f335427041a0b98d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 6 | Churn Cumulative: 854 | Contributors (this commit): 10 | Commits (past 90d): 3 | Contributors (cumulative): 16 | DMM Complexity: 1.0\n\nDIFF:\n@@ -120,6 +120,8 @@ class Response(object_ref):\n         \"\"\"\n         if isinstance(url, Link):\n             url = url.url\n+        elif url is None:\n+            raise ValueError(\"url can't be None\")\n         url = self.urljoin(url)\n         return Request(url, callback,\n                        method=method,\n\n@@ -155,6 +155,10 @@ class BaseResponseTest(unittest.TestCase):\n         self._assert_followed_url(Link('http://example.com/foo'),\n                                   'http://example.com/foo')\n \n+    def test_follow_None_url(self):\n+        r = self.response_class(\"http://example.com\")\n+        self.assertRaises(ValueError, r.follow, None)\n+\n     def test_follow_whitespace_url(self):\n         self._assert_followed_url('foo ',\n                                   'http://example.com/foo%20')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#4c05441450bc1f8438239af0310ab76777a2dacf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 15 | Churn Cumulative: 515 | Contributors (this commit): 8 | Commits (past 90d): 2 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -41,7 +41,8 @@ IGNORED_EXTENSIONS = [\n \n _re_type = type(re.compile(\"\", 0))\n _matches = lambda url, regexs: any(r.search(url) for r in regexs)\n-_is_valid_url = lambda url: url.split('://', 1)[0] in {'http', 'https', 'file'}\n+_is_valid_url = lambda url: url.split('://', 1)[0] in {'http', 'https', \\\n+                                                       'file', 'ftp'}\n \n \n class FilteringLinkExtractor(object):\n\n@@ -451,6 +451,17 @@ class Base:\n                 Link(url='http://example.org/item3.html', text=u'Item 3', nofollow=False),\n             ])\n \n+        def test_ftp_links(self):\n+            body = b\"\"\"\n+            <html><body>\n+            <div><a href=\"ftp://www.external.com/\">An Item</a></div>\n+            </body></html>\"\"\"\n+            response = HtmlResponse(\"http://www.example.com/index.html\", body=body, encoding='utf8')\n+            lx = self.extractor_cls()\n+            self.assertEqual(lx.extract_links(response), [\n+                Link(url='ftp://www.external.com/', text=u'An Item', fragment='', nofollow=False),\n+            ])\n+\n \n class LxmlLinkExtractorTestCase(Base.LinkExtractorTestCase):\n     extractor_cls = LxmlLinkExtractor\n@@ -471,4 +482,3 @@ class LxmlLinkExtractorTestCase(Base.LinkExtractorTestCase):\n     @pytest.mark.xfail\n     def test_restrict_xpaths_with_html_entities(self):\n         super(LxmlLinkExtractorTestCase, self).test_restrict_xpaths_with_html_entities()\n-\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#d5b7ebcfdcfd40d29990712b587893fcc6e84ce8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 12 | Churn Cumulative: 1434 | Contributors (this commit): 24 | Commits (past 90d): 2 | Contributors (cumulative): 33 | DMM Complexity: 0.8181818181818182\n\nDIFF:\n@@ -172,6 +172,8 @@ def _get_clickable(clickdata, form):\n         el for el in form.xpath(\n              'descendant::*[(self::input or self::button)'\n              ' and re:test(@type, \"^submit$\", \"i\")]'\n+             '|descendant::*[(self::input or self::button)'\n+             ' and re:test(@type, \"^image$\", \"i\")]'\n              '|descendant::button[not(@type)]',\n              namespaces={\"re\": \"http://exslt.org/regular-expressions\"})\n         ]\n\n@@ -533,6 +533,16 @@ class FormRequestTest(RequestTest):\n         fs = _qs(req)\n         self.assertEqual(fs, {b'i1': [b'i1v']})\n     \n+    def test_from_response_clickdata_does_not_ignore_image(self):\n+        response = _buildresponse(\n+            \"\"\"<form>\n+            <input type=\"text\" name=\"i1\" value=\"i1v\">\n+            <input id=\"image\" name=\"i2\" type=\"image\" value=\"i2v\" alt=\"Login\" src=\"http://my.image.org/1.jpg\">\n+            </form>\"\"\")\n+        req = self.request_class.from_response(response, dont_click=True)\n+        fs = _qs(req)\n+        self.assertEqual(fs, {b'i1': [b'i1v'], b'i2': [b'i2v']})\n+\n     def test_from_response_dont_submit_reset_as_input(self):\n         response = _buildresponse(\n             \"\"\"<form>\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#65744c2199fc6a5bccfa11eec40a867c1401aee9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 20 | Churn Cumulative: 667 | Contributors (this commit): 12 | Commits (past 90d): 2 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -533,16 +533,6 @@ class FormRequestTest(RequestTest):\n         fs = _qs(req)\n         self.assertEqual(fs, {b'i1': [b'i1v']})\n \n-    def test_from_response_clickdata_does_not_ignore_image(self):\n-        response = _buildresponse(\n-            \"\"\"<form>\n-            <input type=\"text\" name=\"i1\" value=\"i1v\">\n-            <input id=\"image\" name=\"i2\" type=\"image\" value=\"i2v\" alt=\"Login\" src=\"http://my.image.org/1.jpg\">\n-            </form>\"\"\")\n-        req = self.request_class.from_response(response, dont_click=True)\n-        fs = _qs(req)\n-        self.assertEqual(fs, {b'i1': [b'i1v'], b'i2': [b'i2v']})\n-\n     def test_from_response_dont_submit_reset_as_input(self):\n         response = _buildresponse(\n             \"\"\"<form>\n@@ -555,6 +545,16 @@ class FormRequestTest(RequestTest):\n         fs = _qs(req)\n         self.assertEqual(fs, {b'i1': [b'i1v'], b'i2': [b'i2v']})\n     \n+    def test_from_response_clickdata_does_not_ignore_image(self):\n+        response = _buildresponse(\n+            \"\"\"<form>\n+            <input type=\"text\" name=\"i1\" value=\"i1v\">\n+            <input id=\"image\" name=\"i2\" type=\"image\" value=\"i2v\" alt=\"Login\" src=\"http://my.image.org/1.jpg\">\n+            </form>\"\"\")\n+        req = self.request_class.from_response(response)\n+        fs = _qs(req)\n+        self.assertEqual(fs, {b'i1': [b'i1v'], b'i2': [b'i2v']})\n+\n     def test_from_response_multiple_clickdata(self):\n         response = _buildresponse(\n             \"\"\"<form action=\"get.php\" method=\"GET\">\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#13a74d77e2e4d1719bf984d99ca2ae6874752e41", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 114 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -40,6 +40,7 @@ if twisted_version >= (14, 0, 0):\n     from twisted.internet._sslverify import (ClientTLSOptions,\n                                              verifyHostname,\n                                              VerificationError)\n+    from service_identity.exceptions import CertificateError\n \n     if twisted_version < (17, 0, 0):\n         from twisted.internet._sslverify import _maybeSetHostNameIndication\n@@ -65,7 +66,7 @@ if twisted_version >= (14, 0, 0):\n             elif where & SSL_CB_HANDSHAKE_DONE:\n                 try:\n                     verifyHostname(connection, self._hostnameASCII)\n-                except VerificationError as e:\n+                except (CertificateError, VerificationError) as e:\n                     logger.warning(\n                         'Remote certificate is not valid for hostname \"{}\"; {}'.format(\n                             self._hostnameASCII, e))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#e487100987496474de4d2b5fc509ff47d01cd0b6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 9 | Churn Cumulative: 1059 | Contributors (this commit): 14 | Commits (past 90d): 1 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -505,6 +505,15 @@ class Https11InvalidDNSId(Https11TestCase):\n         super(Https11InvalidDNSId, self).setUp()\n         self.host = '127.0.0.1'\n \n+class Https11InvalidDNSPattern(Https11TestCase):\n+    \"\"\"Connect to HTTPS hosts where the certificate are issued to an ip instead of a domain.\"\"\"\n+\n+    keyfile = 'keys/localhost.ip.key'\n+    certfile = 'keys/localhost.ip.crt'\n+\n+    def setUp(self):\n+        super(Https11InvalidDNSPattern, self).setUp()\n+\n \n class Http11MockServerTestCase(unittest.TestCase):\n     \"\"\"HTTP 1.1 test case with MockServer\"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#6a7cdf9a6c4162cf4dd91721d28974c80e0f68cd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 64 | Contributors (this commit): 7 | Commits (past 90d): 2 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -28,7 +28,7 @@ IGNORED_EXTENSIONS = [\n \n     # video\n     '3gp', 'asf', 'asx', 'avi', 'mov', 'mp4', 'mpg', 'qt', 'rm', 'swf', 'wmv',\n-    'm4a', 'm4v',\n+    'm4a', 'm4v', 'flv',\n \n     # office suites\n     'xls', 'xlsx', 'ppt', 'pptx', 'pps', 'doc', 'docx', 'odt', 'ods', 'odg',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#2c58da19a6f85f4532d80d3a941cede8f9d0bab8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 128 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -63,8 +63,9 @@ if twisted_version >= (14, 0, 0):\n         (for genuinely invalid certificates or bugs in verification code).\n \n         Same as Twisted's private _sslverify.ClientTLSOptions,\n-        except that VerificationError and ValueError exceptions are caught,\n-        so that the connection is not closed, only logging warnings.\n+        except that VerificationError, CertificateError and ValueError\n+        exceptions are caught, so that the connection is not closed, only\n+        logging warnings.\n         \"\"\"\n \n         def _identityVerifyingInfoCallback(self, connection, where, ret):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
