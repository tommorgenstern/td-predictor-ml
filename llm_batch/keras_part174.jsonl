{"custom_id": "keras#81aa60a7cf934d86bc669ed820dcd696256bfac4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 15 | Files Changed: 1 | Hunks: 10 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 30 | Churn Cumulative: 360 | Contributors (this commit): 6 | Commits (past 90d): 14 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -199,47 +199,47 @@ def test_gaussiandropout_legacy_interface():\n \n @keras_test\n def test_maxpooling2d_legacy_interface():\n-    old_layer = keras.layers.MaxPool2D(pool_size=2, border_mode='valid', name='maxpool2d')\n+    old_layer = keras.layers.MaxPooling2D(pool_size=(2, 2), border_mode='valid', name='maxpool2d')\n     new_layer = keras.layers.MaxPool2D(pool_size=2, padding='valid', name='maxpool2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n-    old_layer = keras.layers.MaxPool2D(2, 2, 'valid', name='maxpool2d')\n+    old_layer = keras.layers.MaxPooling2D((2, 2), 2, 'valid', name='maxpool2d')\n     new_layer = keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid', name='maxpool2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n-    old_layer = keras.layers.MaxPool2D(2, padding='valid', dim_ordering='tf', name='maxpool2d')\n+    old_layer = keras.layers.MaxPooling2D((2, 2), padding='valid', dim_ordering='tf', name='maxpool2d')\n     new_layer = keras.layers.MaxPool2D(pool_size=2, padding='valid', data_format='channels_last', name='maxpool2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n-    old_layer = keras.layers.MaxPool2D(2, padding='valid', dim_ordering='th', name='maxpool2d')\n+    old_layer = keras.layers.MaxPooling2D((2, 2), padding='valid', dim_ordering='th', name='maxpool2d')\n     new_layer = keras.layers.MaxPool2D(pool_size=2, padding='valid', data_format='channels_first', name='maxpool2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n-    old_layer = keras.layers.MaxPool2D(2, padding='valid', dim_ordering='default', name='maxpool2d')\n+    old_layer = keras.layers.MaxPooling2D((2, 2), padding='valid', dim_ordering='default', name='maxpool2d')\n     new_layer = keras.layers.MaxPool2D(pool_size=2, padding='valid', name='maxpool2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n \n @keras_test\n def test_avgpooling2d_legacy_interface():\n-    old_layer = keras.layers.MaxPooling2D(pool_size=(2, 2), border_mode='valid', name='avgpooling2d')\n-    new_layer = keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid', name='avgpooling2d')\n+    old_layer = keras.layers.AveragePooling2D(pool_size=(2, 2), border_mode='valid', name='avgpooling2d')\n+    new_layer = keras.layers.AvgPool2D(pool_size=(2, 2), padding='valid', name='avgpooling2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n-    old_layer = keras.layers.MaxPooling2D((2, 2), (2, 2), 'valid', name='avgpooling2d')\n-    new_layer = keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid', name='avgpooling2d')\n+    old_layer = keras.layers.AveragePooling2D((2, 2), (2, 2), 'valid', name='avgpooling2d')\n+    new_layer = keras.layers.AvgPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid', name='avgpooling2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n-    old_layer = keras.layers.AveragePooling2D(2, padding='valid', dim_ordering='tf', name='avgpooling2d')\n-    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', data_format='channels_last', name='avgpooling2d')\n+    old_layer = keras.layers.AveragePooling2D((2, 2), padding='valid', dim_ordering='tf', name='avgpooling2d')\n+    new_layer = keras.layers.AvgPool2D(pool_size=2, padding='valid', data_format='channels_last', name='avgpooling2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n-    old_layer = keras.layers.AveragePooling2D(2, padding='valid', dim_ordering='th', name='avgpooling2d')\n-    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', data_format='channels_first', name='avgpooling2d')\n+    old_layer = keras.layers.AveragePooling2D((2, 2), padding='valid', dim_ordering='th', name='avgpooling2d')\n+    new_layer = keras.layers.AvgPool2D(pool_size=2, padding='valid', data_format='channels_first', name='avgpooling2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n-    old_layer = keras.layers.AveragePooling2D(2, padding='valid', dim_ordering='default', name='avgpooling2d')\n-    new_layer = keras.layers.AveragePooling2D(pool_size=2, padding='valid', name='avgpooling2d')\n+    old_layer = keras.layers.AveragePooling2D((2, 2), padding='valid', dim_ordering='default', name='avgpooling2d')\n+    new_layer = keras.layers.AvgPool2D(pool_size=2, padding='valid', name='avgpooling2d')\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fd9acf6d7338d75b4433e714ffdda72295630173", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 38 | Churn Cumulative: 7459 | Contributors (this commit): 62 | Commits (past 90d): 67 | Contributors (cumulative): 64 | DMM Complexity: 0.9583333333333334\n\nDIFF:\n@@ -2255,8 +2255,9 @@ def rnn(step_function, inputs, initial_states,\n         states = tuple(initial_states)\n \n         time_steps = tf.shape(inputs)[0]\n+        outputs, _ = step_function(inputs[0], initial_states + constants)\n         output_ta = tensor_array_ops.TensorArray(\n-            dtype=inputs.dtype,\n+            dtype=outputs.dtype,\n             size=time_steps,\n             tensor_array_name='output_ta')\n         input_ta = tensor_array_ops.TensorArray(\n\n@@ -3,7 +3,7 @@ import numpy as np\n from numpy.testing import assert_allclose\n from keras.utils.test_utils import keras_test\n from keras.layers import wrappers, Input\n-from keras.layers import core, convolutional, recurrent\n+from keras.layers import core, convolutional, recurrent, embeddings\n from keras.models import Sequential, Model, model_from_json\n \n \n@@ -19,6 +19,39 @@ def test_TimeDistributed():\n     # test config\n     model.get_config()\n \n+    # test when specifying a batch_input_shape\n+    test_input = np.random.random((1, 3, 4))\n+    test_output = model.predict(test_input)\n+    weights = model.layers[0].get_weights()\n+\n+    reference = Sequential()\n+    reference.add(wrappers.TimeDistributed(core.Dense(2), batch_input_shape=(1, 3, 4)))\n+    reference.add(core.Activation('relu'))\n+    reference.compile(optimizer='rmsprop', loss='mse')\n+    reference.layers[0].set_weights(weights)\n+\n+    reference_output = reference.predict(test_input)\n+    assert_allclose(test_output, reference_output, atol=1e-05)\n+\n+    # test with Embedding\n+    model = Sequential()\n+    model.add(wrappers.TimeDistributed(embeddings.Embedding(5, 6), batch_input_shape=(10, 3, 4), dtype='int32'))\n+    model.compile(optimizer='rmsprop', loss='mse')\n+    model.fit(np.random.randint(5, size=(10, 3, 4), dtype='int32'), np.random.random((10, 3, 4, 6)), epochs=1, batch_size=10)\n+\n+    # compare to not using batch_input_shape\n+    test_input = np.random.randint(5, size=(10, 3, 4), dtype='int32')\n+    test_output = model.predict(test_input)\n+    weights = model.layers[0].get_weights()\n+\n+    reference = Sequential()\n+    reference.add(wrappers.TimeDistributed(embeddings.Embedding(5, 6), input_shape=(3, 4), dtype='int32'))\n+    reference.compile(optimizer='rmsprop', loss='mse')\n+    reference.layers[0].set_weights(weights)\n+\n+    reference_output = reference.predict(test_input)\n+    assert_allclose(test_output, reference_output, atol=1e-05)\n+\n     # test with Conv2D\n     model = Sequential()\n     model.add(wrappers.TimeDistributed(convolutional.Conv2D(5, (2, 2), padding='same'), input_shape=(2, 4, 4, 3)))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d12d1715539153cf05574910edb0f760bdbb1cbd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1136 | Contributors (this commit): 20 | Commits (past 90d): 12 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -181,8 +181,8 @@ class BatchNormalization(Layer):\n                         epsilon=self.epsilon)\n \n         # Pick the normalized form corresponding to the training phase.\n-        return K.in_train_phase(normed,\n-                                normalize_in_training,\n+        return K.in_train_phase(normalize_in_training,\n+                                normed,\n                                 training=training)\n \n     def get_config(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e723c3baf1eebb976d07635288f8e47878fc6629", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 124 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 6 | Methods Changed: 6 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 124 | Churn Cumulative: 2613 | Contributors (this commit): 11 | Commits (past 90d): 51 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -369,6 +369,7 @@ class MaxPooling3D(_Pooling3D):\n             `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`\n     \"\"\"\n \n+    @interfaces.legacy_pooling3d_support\n     def __init__(self, pool_size=(2, 2, 2), strides=None, padding='valid',\n                  data_format=None, **kwargs):\n         super(MaxPooling3D, self).__init__(pool_size, strides, padding,\n@@ -418,6 +419,7 @@ class AveragePooling3D(_Pooling3D):\n             `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`\n     \"\"\"\n \n+    @interfaces.legacy_pooling3d_support\n     def __init__(self, pool_size=(2, 2, 2), strides=None, padding='valid',\n                  data_format=None, **kwargs):\n         super(AveragePooling3D, self).__init__(pool_size, strides, padding,\n@@ -480,6 +482,7 @@ class _GlobalPooling2D(Layer):\n     \"\"\"Abstract class for different global pooling 2D layers.\n     \"\"\"\n \n+    @interfaces.legacy_global_pooling_support\n     def __init__(self, data_format=None, **kwargs):\n         super(_GlobalPooling2D, self).__init__(**kwargs)\n         self.data_format = conv_utils.normalize_data_format(data_format)\n@@ -574,6 +577,7 @@ class _GlobalPooling3D(Layer):\n     \"\"\"Abstract class for different global pooling 3D layers.\n     \"\"\"\n \n+    @interfaces.legacy_global_pooling_support\n     def __init__(self, data_format=None, **kwargs):\n         super(_GlobalPooling3D, self).__init__(**kwargs)\n         self.data_format = conv_utils.normalize_data_format(data_format)\n\n@@ -141,3 +141,17 @@ legacy_pooling2d_support = generate_legacy_interface(\n     value_conversions={'dim_ordering': {'tf': 'channels_last',\n                                         'th': 'channels_first',\n                                         'default': None}})\n+\n+legacy_pooling3d_support = generate_legacy_interface(\n+    allowed_positional_args=['pool_size', 'strides', 'padding'],\n+    conversions=[('border_mode', 'padding'),\n+                 ('dim_ordering', 'data_format')],\n+    value_conversions={'dim_ordering': {'tf': 'channels_last',\n+                                        'th': 'channels_first',\n+                                        'default': None}})\n+\n+legacy_global_pooling_support = generate_legacy_interface(\n+    conversions=[('dim_ordering', 'data_format')],\n+    value_conversions={'dim_ordering': {'tf': 'channels_last',\n+                                        'th': 'channels_first',\n+                                        'default': None}})\n\n@@ -243,5 +243,111 @@ def test_avgpooling2d_legacy_interface():\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n \n+@keras_test\n+def test_maxpooling3d_legacy_interface():\n+    old_layer = keras.layers.MaxPooling3D(pool_size=(2, 2, 2), border_mode='valid', name='maxpool3d')\n+    new_layer = keras.layers.MaxPool3D(pool_size=(2, 2, 2), padding='valid', name='maxpool3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.MaxPooling3D((2, 2, 2), (2, 2, 2), 'valid', name='maxpool3d')\n+    new_layer = keras.layers.MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid', name='maxpool3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.MaxPooling3D((2, 2, 2), padding='valid', dim_ordering='tf', name='maxpool3d')\n+    new_layer = keras.layers.MaxPool3D(pool_size=(2, 2, 2), padding='valid', data_format='channels_last', name='maxpool3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.MaxPooling3D((2, 2, 2), padding='valid', dim_ordering='th', name='maxpool3d')\n+    new_layer = keras.layers.MaxPool3D(pool_size=(2, 2, 2), padding='valid', data_format='channels_first', name='maxpool3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.MaxPooling3D((2, 2, 2), padding='valid', dim_ordering='default', name='maxpool3d')\n+    new_layer = keras.layers.MaxPool3D(pool_size=(2, 2, 2), padding='valid', name='maxpool3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n+@keras_test\n+def test_avgpooling3d_legacy_interface():\n+    old_layer = keras.layers.AveragePooling3D(pool_size=(2, 2, 2), border_mode='valid', name='avgpooling3d')\n+    new_layer = keras.layers.AvgPool3D(pool_size=(2, 2, 2), padding='valid', name='avgpooling3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.AveragePooling3D((2, 2, 2), (2, 2, 2), 'valid', name='avgpooling3d')\n+    new_layer = keras.layers.AvgPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid', name='avgpooling3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.AveragePooling3D((2, 2, 2), padding='valid', dim_ordering='tf', name='avgpooling3d')\n+    new_layer = keras.layers.AvgPool3D(pool_size=(2, 2, 2), padding='valid', data_format='channels_last', name='avgpooling3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.AveragePooling3D((2, 2, 2), padding='valid', dim_ordering='th', name='avgpooling3d')\n+    new_layer = keras.layers.AvgPool3D(pool_size=(2, 2, 2), padding='valid', data_format='channels_first', name='avgpooling3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.AveragePooling3D((2, 2, 2), padding='valid', dim_ordering='default', name='avgpooling3d')\n+    new_layer = keras.layers.AvgPool3D(pool_size=(2, 2, 2), padding='valid', name='avgpooling3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n+@keras_test\n+def test_global_maxpooling2d_legacy_interface():\n+    old_layer = keras.layers.GlobalMaxPooling2D(dim_ordering='tf', name='global_maxpool2d')\n+    new_layer = keras.layers.GlobalMaxPool2D(data_format='channels_last', name='global_maxpool2d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.GlobalMaxPooling2D(dim_ordering='th', name='global_maxpool2d')\n+    new_layer = keras.layers.GlobalMaxPool2D(data_format='channels_first', name='global_maxpool2d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.GlobalMaxPooling2D(dim_ordering='default', name='global_maxpool2d')\n+    new_layer = keras.layers.GlobalMaxPool2D(name='global_maxpool2d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n+@keras_test\n+def test_global_avgpooling2d_legacy_interface():\n+    old_layer = keras.layers.GlobalAveragePooling2D(dim_ordering='tf', name='global_avgpool2d')\n+    new_layer = keras.layers.GlobalAvgPool2D(data_format='channels_last', name='global_avgpool2d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.GlobalAveragePooling2D(dim_ordering='th', name='global_avgpool2d')\n+    new_layer = keras.layers.GlobalAvgPool2D(data_format='channels_first', name='global_avgpool2d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.GlobalAveragePooling2D(dim_ordering='default', name='global_avgpool2d')\n+    new_layer = keras.layers.GlobalAvgPool2D(name='global_avgpool2d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n+@keras_test\n+def test_global_maxpooling3d_legacy_interface():\n+    old_layer = keras.layers.GlobalMaxPooling3D(dim_ordering='tf', name='global_maxpool3d')\n+    new_layer = keras.layers.GlobalMaxPool3D(data_format='channels_last', name='global_maxpool3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.GlobalMaxPooling3D(dim_ordering='th', name='global_maxpool3d')\n+    new_layer = keras.layers.GlobalMaxPool3D(data_format='channels_first', name='global_maxpool3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.GlobalMaxPooling3D(dim_ordering='default', name='global_maxpool3d')\n+    new_layer = keras.layers.GlobalMaxPool3D(name='global_maxpool3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n+@keras_test\n+def test_global_avgpooling3d_legacy_interface():\n+    old_layer = keras.layers.GlobalAveragePooling3D(dim_ordering='tf', name='global_avgpool3d')\n+    new_layer = keras.layers.GlobalAvgPool3D(data_format='channels_last', name='global_avgpool3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.GlobalAveragePooling3D(dim_ordering='th', name='global_avgpool3d')\n+    new_layer = keras.layers.GlobalAvgPool3D(data_format='channels_first', name='global_avgpool3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.GlobalAveragePooling3D(dim_ordering='default', name='global_avgpool3d')\n+    new_layer = keras.layers.GlobalAvgPool3D(name='global_avgpool3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7f1cdbfef6753fcb9c50d86f530791bfe706dc35", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 40 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 40 | Churn Cumulative: 1829 | Contributors (this commit): 19 | Commits (past 90d): 47 | Contributors (cumulative): 27 | DMM Complexity: 1.0\n\nDIFF:\n@@ -5,6 +5,7 @@ from .. import initializers\n from .. import regularizers\n from .. import constraints\n from ..engine import Layer\n+from ..legacy import interfaces\n \n \n class Embedding(Layer):\n@@ -64,6 +65,7 @@ class Embedding(Layer):\n         - [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)\n     \"\"\"\n \n+    @interfaces.legacy_embedding_support\n     def __init__(self, input_dim, output_dim,\n                  embeddings_initializer='uniform',\n                  embeddings_regularizer=None,\n\n@@ -87,6 +87,23 @@ legacy_dropout_support = generate_legacy_interface(\n     allowed_positional_args=['rate', 'noise_shape', 'seed'],\n     conversions=[('p', 'rate')])\n \n+\n+def embedding_kwargs_preprocessor(args, kwargs):\n+    converted = []\n+    if 'dropout' in kwargs:\n+        kwargs.pop('dropout')\n+        warnings.warn('The `dropout` argument is no longer support in `Embedding`. '\n+                      'You can apply a `keras.layers.SpatialDropout1D` layer '\n+                      'right after the `Embedding` layer to get the same behavior.')\n+    return args, kwargs, converted\n+\n+legacy_embedding_support = generate_legacy_interface(\n+    allowed_positional_args=['input_dim', 'output_dim'],\n+    conversions=[('init', 'embeddings_initializer'),\n+                 ('W_regularizer', 'embeddings_regularizer'),\n+                 ('W_constraint', 'embeddings_constraint')],\n+    preprocessor=embedding_kwargs_preprocessor)\n+\n legacy_pooling1d_support = generate_legacy_interface(\n     allowed_positional_args=['pool_size', 'strides', 'padding'],\n     conversions=[('pool_length', 'pool_size'),\n\n@@ -37,6 +37,27 @@ def test_dropout_legacy_interface():\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_2.get_config())\n \n \n+@keras_test\n+def test_embedding_legacy_interface():\n+    old_layer = keras.layers.Embedding(4, 2, name='d')\n+    new_layer = keras.layers.Embedding(output_dim=2, input_dim=4, name='d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.Embedding(input_dim=4, output_dim=2, name='d',\n+                                       init='normal',\n+                                       W_regularizer='l1',\n+                                       W_constraint='max_norm')\n+    new_layer = keras.layers.Embedding(input_dim=4, output_dim=2, name='d',\n+                                       embeddings_initializer='normal',\n+                                       embeddings_regularizer='l1',\n+                                       embeddings_constraint='max_norm')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.Embedding(1, 1, dropout=0.0, name='d')\n+    new_layer = keras.layers.Embedding(1, 1, name='d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n @keras_test\n def test_maxpooling1d_legacy_interface():\n     old_layer = keras.layers.MaxPool1D(pool_length=2,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#da21c15180d12a74a7c744c1f851a94c8b931a63", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 87 | Lines Deleted: 41 | Files Changed: 2 | Hunks: 17 | Methods Changed: 9 | Complexity Δ (Sum/Max): 13/8 | Churn Δ: 128 | Churn Cumulative: 6653 | Contributors (this commit): 34 | Commits (past 90d): 28 | Contributors (cumulative): 36 | DMM Complexity: 1.0\n\nDIFF:\n@@ -222,32 +222,13 @@ class Recurrent(Layer):\n     def preprocess_input(self, inputs, training=None):\n         return inputs\n \n-    def __call__(self, inputs, **kwargs):\n-        with K.name_scope(self.name):\n-            # Handle laying building (weight creating, input spec locking,\n-            # state spec locking)\n-            if not self.built:\n-                # Raise exceptions in case the input is not compatible\n-                # with the input_spec specified in the layer constructor.\n-                self.assert_input_compatibility(inputs)\n-\n-                if hasattr(inputs, '_keras_shape'):\n-                    input_shape = inputs._keras_shape\n-                elif hasattr(K, 'int_shape'):\n-                    input_shape = K.int_shape(inputs)\n-                else:\n-                    raise ValueError('You tried to call layer \"' + self.name +\n-                                        '\". This layer has no information'\n-                                        ' about its expected input shape, '\n-                                        'and thus cannot be built. '\n-                                        'You can build it manually via: '\n-                                        '`layer.build(batch_input_shape)`')\n-                self.build(input_shape)\n-                self.built = True\n-\n-        # If initial_state is specified, add it to the inputs and temporarily\n-        # modify the input spec to include the state\n-        if 'initial_state' in kwargs:\n+    def __call__(self, inputs, initial_state=None, **kwargs):\n+        # If `initial_state` is specified,\n+        # and if it a Keras tensor,\n+        # then add it to the inputs and temporarily\n+        # modify the input spec to include the state.\n+        if initial_state is not None:\n+            if hasattr(initial_state, '_keras_history'):\n                 # Compute the full input spec, including state\n                 input_spec = self.input_spec\n                 state_spec = self.state_spec\n@@ -256,10 +237,9 @@ class Recurrent(Layer):\n                 self.input_spec = [input_spec] + state_spec\n \n                 # Compute the full inputs, including state\n-            initial_state = kwargs.pop('initial_state')\n-            if not isinstance(initial_state, list):\n+                if not isinstance(initial_state, (list, tuple)):\n                     initial_state = [initial_state]\n-            inputs = [inputs] + initial_state\n+                inputs = [inputs] + list(initial_state)\n \n                 # Perform the call\n                 output = super(Recurrent, self).__call__(inputs, **kwargs)\n@@ -267,13 +247,19 @@ class Recurrent(Layer):\n                 # Restore original input spec\n                 self.input_spec = input_spec\n                 return output\n-\n+            else:\n+                kwargs['initial_state'] = initial_state\n         return super(Recurrent, self).__call__(inputs, **kwargs)\n \n-    def call(self, inputs, mask=None, training=None):\n-        # input shape: (nbias_samples, time (padded with zeros), input_dim)\n+    def call(self, inputs, mask=None, initial_state=None, training=None):\n+        # input shape: `(samples, time (padded with zeros), input_dim)`\n         # note that the .build() method of subclasses MUST define\n         # self.input_spec and self.state_spec with complete input shapes.\n+        if initial_state is not None:\n+            if not isinstance(initial_state, (list, tuple)):\n+                initial_states = [initial_state]\n+            else:\n+                initial_states = list(initial_state)\n         if isinstance(inputs, list):\n             initial_states = inputs[1:]\n             inputs = inputs[0]\n@@ -281,6 +267,11 @@ class Recurrent(Layer):\n             initial_states = self.states\n         else:\n             initial_states = self.get_initial_states(inputs)\n+\n+        if len(initial_states) != len(self.states):\n+            raise ValueError('Layer has ' + str(len(self.states)) +\n+                             ' but was passed ' + str(len(initial_states)) +\n+                             ' initial states.')\n         input_shape = K.int_shape(inputs)\n         if self.unroll and input_shape[1] is None:\n             raise ValueError('Cannot unroll a RNN if the '\n@@ -320,9 +311,12 @@ class Recurrent(Layer):\n         else:\n             return last_output\n \n-    def reset_states(self):\n+    def reset_states(self, states_value=None):\n         if not self.stateful:\n             raise AttributeError('Layer must be stateful.')\n+        if not self.input_spec:\n+            raise RuntimeError('Layer has never been called '\n+                               'and thus has no states.')\n         batch_size = self.input_spec.shape[0]\n         if not batch_size:\n             raise ValueError('If a RNN is stateful, it needs to know '\n@@ -335,12 +329,31 @@ class Recurrent(Layer):\n                              '- If using the functional API, specify '\n                              'the time dimension by passing a '\n                              '`batch_shape` argument to your Input layer.')\n-        if self.states[0] is not None:\n-            for state in self.states:\n-                K.set_value(state, np.zeros((batch_size, self.units)))\n-        else:\n+        if states_value is not None:\n+            if not isinstance(states_value, (list, tuple)):\n+                states_value = [states_value]\n+            if len(states_value) != len(self.states):\n+                raise ValueError('The layer has ' + str(len(self.states)) +\n+                                 ' states, but the `states_value` '\n+                                 'argument passed '\n+                                 'only has ' + str(len(states_value)) +\n+                                 ' entries')\n+        if self.states[0] is None:\n             self.states = [K.zeros((batch_size, self.units))\n                            for _ in self.states]\n+            if not states_value:\n+                return\n+        for i, state in enumerate(self.states):\n+            if states_value:\n+                value = states_value[i]\n+                if value.shape != (batch_size, self.units):\n+                    raise ValueError(\n+                        'Expected state #' + str(i) +\n+                        ' to have shape ' + str((batch_size, self.units)) +\n+                        ' but got array with shape ' + str(value.shape))\n+            else:\n+                value = np.zeros((batch_size, self.units))\n+            K.set_value(state, value)\n \n     def get_config(self):\n         config = {'return_sequences': self.return_sequences,\n\n@@ -167,11 +167,14 @@ def test_from_config(layer_class):\n         l2 = layer_class.from_config(l1.get_config())\n         assert l1.get_config() == l2.get_config()\n \n+\n @rnn_test\n-def test_specify_state(layer_class):\n-    states = 2 if layer_class is recurrent.LSTM else 1\n+def test_specify_initial_state(layer_class):\n+    num_states = 2 if layer_class is recurrent.LSTM else 1\n+\n+    # Test with Keras tensor\n     inputs = Input((timesteps, embedding_dim))\n-    initial_state = [Input((units,)) for _ in range(states)]\n+    initial_state = [Input((units,)) for _ in range(num_states)]\n     layer = layer_class(units)\n     output = layer(inputs, initial_state=initial_state)\n     model = Model([inputs] + initial_state, output)\n@@ -179,11 +182,41 @@ def test_specify_state(layer_class):\n \n     inputs = np.random.random((num_samples, timesteps, embedding_dim))\n     initial_states = [np.random.random((num_samples, units))\n-                      for _ in range(states)]\n+                      for _ in range(num_states)]\n     targets = np.random.random((num_samples, units))\n     model.fit([inputs] + initial_states, targets)\n \n+    # Test with non-Keras tensor\n+    inputs = Input((timesteps, embedding_dim))\n+    initial_state = [K.random_normal_variable((units,), 0, 1) for _ in range(num_states)]\n+    layer = layer_class(units)\n+    output = layer(inputs, initial_state=initial_state)\n+    model = Model([inputs], output)\n+    model.compile(loss='categorical_crossentropy', optimizer='adam')\n \n+    inputs = np.random.random((num_samples, timesteps, embedding_dim))\n+    targets = np.random.random((num_samples, units))\n+    model.fit(inputs, targets)\n+\n+\n+@rnn_test\n+def test_reset_states_with_values(layer_class):\n+    num_states = 2 if layer_class is recurrent.LSTM else 1\n+\n+    layer = layer_class(units, stateful=True)\n+    layer.build((num_samples, timesteps, embedding_dim))\n+    layer.reset_states()\n+    assert len(layer.states) == num_states\n+    assert layer.states[0] is not None\n+    np.testing.assert_allclose(K.eval(layer.states[0]),\n+                               np.zeros(K.int_shape(layer.states[0])),\n+                               atol=1e-4)\n+    state_shapes = [K.int_shape(state) for state in layer.states]\n+    values = [np.ones(shape) for shape in state_shapes]\n+    layer.reset_states(values)\n+    np.testing.assert_allclose(K.eval(layer.states[0]),\n+                               np.ones(K.int_shape(layer.states[0])),\n+                               atol=1e-4)\n \n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4cf4aa1efe30c3ed0e985ba2d0ae5fa9ed3cec07", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 45 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 45 | Churn Cumulative: 10699 | Contributors (this commit): 39 | Commits (past 90d): 76 | Contributors (cumulative): 47 | DMM Complexity: 1.0\n\nDIFF:\n@@ -9,6 +9,7 @@ from .. import constraints\n from ..engine import Layer\n from ..engine import InputSpec\n from ..utils import conv_utils\n+from ..legacy import interfaces\n \n # imports for backwards namespace compatibility\n from .pooling import AveragePooling1D\n@@ -1035,6 +1036,7 @@ class UpSampling1D(Layer):\n         3D tensor with shape: `(batch, upsampled_steps, features)`.\n     \"\"\"\n \n+    @interfaces.legacy_upsampling1d_support\n     def __init__(self, size=2, **kwargs):\n         super(UpSampling1D, self).__init__(**kwargs)\n         self.size = int(size)\n@@ -1089,6 +1091,7 @@ class UpSampling2D(Layer):\n             `(batch, channels, upsampled_rows, upsampled_cols)`\n     \"\"\"\n \n+    @interfaces.legacy_upsampling2d_support\n     def __init__(self, size=(2, 2), data_format=None, **kwargs):\n         super(UpSampling2D, self).__init__(**kwargs)\n         self.data_format = conv_utils.normalize_data_format(data_format)\n@@ -1157,6 +1160,7 @@ class UpSampling3D(Layer):\n             `(batch, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)`\n     \"\"\"\n \n+    @interfaces.legacy_upsampling3d_support\n     def __init__(self, size=(2, 2, 2), data_format=None, **kwargs):\n         self.data_format = conv_utils.normalize_data_format(data_format)\n         self.size = conv_utils.normalize_tuple(size, 3, 'size')\n\n@@ -172,3 +172,21 @@ legacy_global_pooling_support = generate_legacy_interface(\n     value_conversions={'dim_ordering': {'tf': 'channels_last',\n                                         'th': 'channels_first',\n                                         'default': None}})\n+\n+legacy_upsampling1d_support = generate_legacy_interface(\n+    allowed_positional_args=['size'],\n+    conversions=[('length', 'size')])\n+\n+legacy_upsampling2d_support = generate_legacy_interface(\n+    allowed_positional_args=['size'],\n+    conversions=[('dim_ordering', 'data_format')],\n+    value_conversions={'dim_ordering': {'tf': 'channels_last',\n+                                        'th': 'channels_first',\n+                                        'default': None}})\n+\n+legacy_upsampling3d_support = generate_legacy_interface(\n+    allowed_positional_args=['size'],\n+    conversions=[('dim_ordering', 'data_format')],\n+    value_conversions={'dim_ordering': {'tf': 'channels_last',\n+                                        'th': 'channels_first',\n+                                        'default': None}})\n\n@@ -370,5 +370,28 @@ def test_global_avgpooling3d_legacy_interface():\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n \n+@keras_test\n+def test_upsampling1d_legacy_interface():\n+    old_layer = keras.layers.UpSampling1D(length=3, name='us1d')\n+    new_layer_1 = keras.layers.UpSampling1D(size=3, name='us1d')\n+    new_layer_2 = keras.layers.UpSampling1D(3, name='us1d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_1.get_config())\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_2.get_config())\n+\n+\n+@keras_test\n+def test_upsampling2d_legacy_interface():\n+    old_layer = keras.layers.UpSampling2D((2, 2), dim_ordering='tf', name='us2d')\n+    new_layer = keras.layers.UpSampling2D((2, 2), data_format='channels_last', name='us2d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n+@keras_test\n+def test_upsampling3d_legacy_interface():\n+    old_layer = keras.layers.UpSampling3D((2, 2, 2), dim_ordering='tf', name='us3d')\n+    new_layer = keras.layers.UpSampling3D((2, 2, 2), data_format='channels_last', name='us3d')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0c7b9d57c1049869dd3e8d69f32752e74aa738be", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 418 | Contributors (this commit): 7 | Commits (past 90d): 10 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -148,6 +148,12 @@ unit_norm = UnitNorm\n min_max_norm = MinMaxNorm\n \n \n+# Legacy aliases.\n+maxnorm = max_norm\n+nonneg = non_neg\n+unitnorm = unit_norm\n+\n+\n def serialize(constraint):\n     return serialize_keras_object(constraint)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#109b11016a87c2606b3e738d085fe0281ef3cbbe", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 87 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 7 | Methods Changed: 4 | Complexity Δ (Sum/Max): 14/13 | Churn Δ: 90 | Churn Cumulative: 10789 | Contributors (this commit): 39 | Commits (past 90d): 79 | Contributors (cumulative): 47 | DMM Complexity: 0.5535714285714286\n\nDIFF:\n@@ -19,6 +19,8 @@ from .pooling import MaxPooling1D\n from .pooling import MaxPooling2D\n from .pooling import MaxPooling3D\n \n+from ..legacy import interfaces\n+\n \n class _Conv(Layer):\n     \"\"\"Abstract nD convolution layer (private, used as implementation base).\n@@ -414,6 +416,7 @@ class Conv2D(_Conv):\n         `rows` and `cols` values might have changed due to padding.\n     \"\"\"\n \n+    @interfaces.legacy_conv2d_support\n     def __init__(self, filters,\n                  kernel_size,\n                  strides=(1, 1),\n\n@@ -190,3 +190,47 @@ legacy_upsampling3d_support = generate_legacy_interface(\n     value_conversions={'dim_ordering': {'tf': 'channels_last',\n                                         'th': 'channels_first',\n                                         'default': None}})\n+\n+\n+def conv2d_args_preprocessor(args, kwargs):\n+    if len(args) > 4:\n+        raise TypeError('Layer can receive at most 3 positional arguments.')\n+    if len(args) == 4:\n+        if isinstance(args[2], int) and isinstance(args[3], int):\n+            new_keywords = ['padding', 'strides', 'data_format']\n+            for kwd in new_keywords:\n+                if kwd in kwargs:\n+                    raise ValueError(\n+                        'It seems that you are using the Keras 2 '\n+                        'and you are passing both `kernel_size` and `strides` '\n+                        'as integer positional arguments. For safety reasons, '\n+                        'this is disallowed. Pass `strides` as a keyword arugment '\n+                        'instead.')\n+            kernel_size = (args[2], args[3])\n+            args = [args[0], args[1], kernel_size]\n+    elif len(args) == 3 and isinstance(args[2], int):\n+        if 'nb_col' in kwargs:\n+            kernel_size = (args[2], kwargs.pop('nb_col'))\n+            args = [args[0], args[1], kernel_size]\n+    elif len(args) == 2:\n+        if 'nb_row' in kwargs and 'nb_col' in kwargs:\n+            kernel_size = (kwargs.pop('nb_row'), kwargs.pop('nb_col'))\n+            args = [args[0], args[1], kernel_size]\n+    return args, kwargs, [('kernel_size', 'nb_row/nb_col')]\n+\n+legacy_conv2d_support = generate_legacy_interface(\n+    allowed_positional_args=['filters', 'kernel_size'],\n+    conversions=[('nb_filters', 'filters'),\n+                 ('subsample', 'strides'),\n+                 ('border_mode', 'padding'),\n+                 ('dim_ordering', 'data_format'),\n+                 ('init', 'kernel_initializer'),\n+                 ('W_regularizer', 'kernel_regularizer'),\n+                 ('b_regularizer', 'bias_regularizer'),\n+                 ('W_constraint', 'kernel_constraint'),\n+                 ('b_constraint', 'bias_constraint'),\n+                 ('bias', 'use_bias')],\n+    value_conversions={'dim_ordering': {'tf': 'channels_last',\n+                                        'th': 'channels_first',\n+                                        'default': None}},\n+    preprocessor=conv2d_args_preprocessor)\n\n@@ -12,7 +12,7 @@ def test_dense_legacy_interface():\n \n     old_layer = keras.layers.Dense(2, bias=False, init='normal',\n                                    W_regularizer='l1',\n-                                   W_constraint='max_norm', name='d')\n+                                   W_constraint='maxnorm', name='d')\n     new_layer = keras.layers.Dense(2, use_bias=False,\n                                    kernel_initializer='normal',\n                                    kernel_regularizer='l1',\n@@ -21,7 +21,7 @@ def test_dense_legacy_interface():\n \n     old_layer = keras.layers.Dense(2, bias=True,\n                                    b_regularizer='l1',\n-                                   b_constraint='max_norm', name='d')\n+                                   b_constraint='maxnorm', name='d')\n     new_layer = keras.layers.Dense(2, use_bias=True,\n                                    bias_regularizer='l1',\n                                    bias_constraint='max_norm', name='d')\n@@ -46,7 +46,7 @@ def test_embedding_legacy_interface():\n     old_layer = keras.layers.Embedding(input_dim=4, output_dim=2, name='d',\n                                        init='normal',\n                                        W_regularizer='l1',\n-                                       W_constraint='max_norm')\n+                                       W_constraint='maxnorm')\n     new_layer = keras.layers.Embedding(input_dim=4, output_dim=2, name='d',\n                                        embeddings_initializer='normal',\n                                        embeddings_regularizer='l1',\n@@ -393,5 +393,42 @@ def test_upsampling3d_legacy_interface():\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n \n+@keras_test\n+def test_conv2d_legacy_interface():\n+    old_layer = keras.layers.Convolution2D(5, 3, 3, name='conv')\n+    new_layer = keras.layers.Conv2D(5, (3, 3), name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.Convolution2D(5, 3, nb_col=3, name='conv')\n+    new_layer = keras.layers.Conv2D(5, (3, 3), name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.Convolution2D(5, nb_row=3, nb_col=3, name='conv')\n+    new_layer = keras.layers.Conv2D(5, (3, 3), name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.Convolution2D(5, 3, 3,\n+                                           init='normal',\n+                                           subsample=(2, 2),\n+                                           border_mode='valid',\n+                                           dim_ordering='th',\n+                                           W_regularizer='l1',\n+                                           b_regularizer='l2',\n+                                           W_constraint='maxnorm',\n+                                           b_constraint='unitnorm',\n+                                           name='conv')\n+    new_layer = keras.layers.Conv2D(5, (3, 3),\n+                                    kernel_initializer='normal',\n+                                    strides=(2, 2),\n+                                    padding='valid',\n+                                    kernel_regularizer='l1',\n+                                    bias_regularizer='l2',\n+                                    kernel_constraint='max_norm',\n+                                    bias_constraint='unit_norm',\n+                                    data_format='channels_first',\n+                                    name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d51fc7659ecd616a40504f836e51fef9472e0ef3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 13 | Files Changed: 2 | Hunks: 9 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 26 | Churn Cumulative: 669 | Contributors (this commit): 11 | Commits (past 90d): 11 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -27,7 +27,7 @@ Five digits inverted:\n \n from __future__ import print_function\n from keras.models import Sequential\n-from keras.layers import Activation, TimeDistributed, Dense, RepeatVector, recurrent\n+from keras import layers\n import numpy as np\n from six.moves import range\n \n@@ -141,7 +141,7 @@ print(x_val.shape)\n print(y_val.shape)\n \n # Try replacing GRU, or SimpleRNN.\n-RNN = recurrent.LSTM\n+RNN = layers.LSTM\n HIDDEN_SIZE = 128\n BATCH_SIZE = 128\n LAYERS = 1\n@@ -155,7 +155,7 @@ model.add(RNN(HIDDEN_SIZE, input_shape=(MAxLEN, len(chars))))\n # As the decoder RNN's input, repeatedly provide with the last hidden state of\n # RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n # length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n-model.add(RepeatVector(DIGITS + 1))\n+model.add(layers.RepeatVector(DIGITS + 1))\n # The decoder RNN could be multiple layers stacked or a single layer.\n for _ in range(LAYERS):\n     # By setting return_sequences to True, return not only the last output but\n@@ -166,8 +166,8 @@ for _ in range(LAYERS):\n \n # Apply a dense layer to the every temporal slice of an input. For each of step\n # of the output sequence, decide which character should be chosen.\n-model.add(TimeDistributed(Dense(len(chars))))\n-model.add(Activation('softmax'))\n+model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n+model.add(layers.Activation('softmax'))\n model.compile(loss='categorical_crossentropy',\n               optimizer='adam',\n               metrics=['accuracy'])\n\n@@ -13,12 +13,12 @@ backend (`K`), our code can run both on TensorFlow and Theano.\n from __future__ import print_function\n import keras\n from keras.models import Sequential\n-from keras.layers import Dense, Dropout, Layer, Activation\n+from keras import layers\n from keras.datasets import mnist\n from keras import backend as K\n \n \n-class Antirectifier(Layer):\n+class Antirectifier(layers.Layer):\n     '''This is the combination of a sample-wise\n     L2 normalization with the concatenation of the\n     positive part of the input with the negative part\n@@ -82,14 +82,14 @@ y_test = keras.utils.to_categorical(y_test, num_classes)\n \n # build the model\n model = Sequential()\n-model.add(Dense(256, input_shape=(784,)))\n+model.add(layers.Dense(256, input_shape=(784,)))\n model.add(Antirectifier())\n-model.add(Dropout(0.1))\n-model.add(Dense(256))\n+model.add(layers.Dropout(0.1))\n+model.add(layers.Dense(256))\n model.add(Antirectifier())\n-model.add(Dropout(0.1))\n-model.add(Dense(10))\n-model.add(Activation('softmax'))\n+model.add(layers.Dropout(0.1))\n+model.add(layers.Dense(10))\n+model.add(layers.Activation('softmax'))\n \n # compile the model\n model.compile(loss='categorical_crossentropy',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#16feb385e5a84c8298b909fb7a8719ca9a99d105", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 227 | Lines Deleted: 4 | Files Changed: 4 | Hunks: 9 | Methods Changed: 8 | Complexity Δ (Sum/Max): 28/25 | Churn Δ: 231 | Churn Cumulative: 17435 | Contributors (this commit): 61 | Commits (past 90d): 106 | Contributors (cumulative): 81 | DMM Complexity: 0.7697368421052632\n\nDIFF:\n@@ -293,6 +293,7 @@ class Conv1D(_Conv):\n         `steps` value might have changed due to padding or strides.\n     \"\"\"\n \n+    @interfaces.legacy_conv1d_support\n     def __init__(self, filters,\n                  kernel_size,\n                  strides=1,\n@@ -541,6 +542,7 @@ class Conv3D(_Conv):\n         `new_conv_dim1`, `new_conv_dim2` and `new_conv_dim3` values might have changed due to padding.\n     \"\"\"\n \n+    @interfaces.legacy_conv3d_support\n     def __init__(self, filters,\n                  kernel_size,\n                  strides=(1, 1, 1),\n@@ -886,6 +888,7 @@ class SeparableConv2D(Conv2D):\n         `rows` and `cols` values might have changed due to padding.\n     \"\"\"\n \n+    @interfaces.legacy_separable_conv2d_support\n     def __init__(self, filters,\n                  kernel_size,\n                  strides=(1, 1),\n\n@@ -270,7 +270,8 @@ class Recurrent(Layer):\n \n         if len(initial_states) != len(self.states):\n             raise ValueError('Layer has ' + str(len(self.states)) +\n-                             ' but was passed ' + str(len(initial_states)) +\n+                             ' states but was passed ' +\n+                             str(len(initial_states)) +\n                              ' initial states.')\n         input_shape = K.int_shape(inputs)\n         if self.unroll and input_shape[1] is None:\n\n@@ -192,6 +192,31 @@ legacy_upsampling3d_support = generate_legacy_interface(\n                                         'default': None}})\n \n \n+def conv1d_args_preprocessor(args, kwargs):\n+    if 'input_dim' in kwargs:\n+        if 'input_length' in kwargs:\n+            length = kwargs.pop('input_length')\n+        else:\n+            length = None\n+        input_shape = (length, kwargs.pop('input_dim'))\n+        kwargs['input_shape'] = input_shape\n+    return args, kwargs, [('input_shape', 'input_dim')]\n+\n+legacy_conv1d_support = generate_legacy_interface(\n+    allowed_positional_args=['filters', 'kernel_size'],\n+    conversions=[('nb_filter', 'filters'),\n+                 ('filter_length', 'kernel_size'),\n+                 ('subsample_length', 'strides'),\n+                 ('border_mode', 'padding'),\n+                 ('init', 'kernel_initializer'),\n+                 ('W_regularizer', 'kernel_regularizer'),\n+                 ('b_regularizer', 'bias_regularizer'),\n+                 ('W_constraint', 'kernel_constraint'),\n+                 ('b_constraint', 'bias_constraint'),\n+                 ('bias', 'use_bias')],\n+    preprocessor=conv1d_args_preprocessor)\n+\n+\n def conv2d_args_preprocessor(args, kwargs):\n     if len(args) > 4:\n         raise TypeError('Layer can receive at most 3 positional arguments.')\n@@ -204,8 +229,8 @@ def conv2d_args_preprocessor(args, kwargs):\n                         'It seems that you are using the Keras 2 '\n                         'and you are passing both `kernel_size` and `strides` '\n                         'as integer positional arguments. For safety reasons, '\n-                        'this is disallowed. Pass `strides` as a keyword arugment '\n-                        'instead.')\n+                        'this is disallowed. Pass `strides` '\n+                        'as a keyword argument instead.')\n             kernel_size = (args[2], args[3])\n             args = [args[0], args[1], kernel_size]\n     elif len(args) == 3 and isinstance(args[2], int):\n@@ -220,7 +245,7 @@ def conv2d_args_preprocessor(args, kwargs):\n \n legacy_conv2d_support = generate_legacy_interface(\n     allowed_positional_args=['filters', 'kernel_size'],\n-    conversions=[('nb_filters', 'filters'),\n+    conversions=[('nb_filter', 'filters'),\n                  ('subsample', 'strides'),\n                  ('border_mode', 'padding'),\n                  ('dim_ordering', 'data_format'),\n@@ -234,3 +259,78 @@ legacy_conv2d_support = generate_legacy_interface(\n                                         'th': 'channels_first',\n                                         'default': None}},\n     preprocessor=conv2d_args_preprocessor)\n+\n+\n+def separable_conv2d_args_preprocessor(args, kwargs):\n+    if 'init' in kwargs:\n+        init = kwargs.pop('init')\n+        kwargs['depthwise_initializer'] = init\n+        kwargs['pointwise_initializer'] = init\n+    return conv2d_args_preprocessor(args, kwargs)\n+\n+legacy_separable_conv2d_support = generate_legacy_interface(\n+    allowed_positional_args=['filters', 'kernel_size'],\n+    conversions=[('nb_filter', 'filters'),\n+                 ('subsample', 'strides'),\n+                 ('border_mode', 'padding'),\n+                 ('dim_ordering', 'data_format'),\n+                 ('b_regularizer', 'bias_regularizer'),\n+                 ('b_constraint', 'bias_constraint'),\n+                 ('bias', 'use_bias')],\n+    value_conversions={'dim_ordering': {'tf': 'channels_last',\n+                                        'th': 'channels_first',\n+                                        'default': None}},\n+    preprocessor=separable_conv2d_args_preprocessor)\n+\n+\n+def conv3d_args_preprocessor(args, kwargs):\n+    if len(args) > 5:\n+        raise TypeError('Layer can receive at most 4 positional arguments.')\n+    if len(args) == 5:\n+        if isinstance(args[2], int) and isinstance(args[3], int) and isinstance(args[4], int):\n+            kernel_size = (args[2], args[3], args[4])\n+            args = [args[0], args[1], kernel_size]\n+    elif len(args) == 4 and isinstance(args[3], int):\n+        if isinstance(args[2], int) and isinstance(args[3], int):\n+            new_keywords = ['padding', 'strides', 'data_format']\n+            for kwd in new_keywords:\n+                if kwd in kwargs:\n+                    raise ValueError(\n+                        'It seems that you are using the Keras 2 '\n+                        'and you are passing both `kernel_size` and `strides` '\n+                        'as integer positional arguments. For safety reasons, '\n+                        'this is disallowed. Pass `strides` '\n+                        'as a keyword argument instead.')\n+        if 'kernel_dim3' in kwargs:\n+            kernel_size = (args[2], args[3], kwargs.pop('kernel_dim3'))\n+            args = [args[0], args[1], kernel_size]\n+    elif len(args) == 3:\n+        if 'kernel_dim2' in kwargs and 'kernel_dim3' in kwargs:\n+            kernel_size = (args[2],\n+                           kwargs.pop('kernel_dim2'),\n+                           kwargs.pop('kernel_dim3'))\n+            args = [args[0], args[1], kernel_size]\n+    elif len(args) == 2:\n+        if 'kernel_dim1' in kwargs and 'kernel_dim2' in kwargs and 'kernel_dim3' in kwargs:\n+            kernel_size = (kwargs.pop('kernel_dim1'),\n+                           kwargs.pop('kernel_dim2'),\n+                           kwargs.pop('kernel_dim3'))\n+            args = [args[0], args[1], kernel_size]\n+    return args, kwargs, [('kernel_size', 'kernel_dim*')]\n+\n+legacy_conv3d_support = generate_legacy_interface(\n+    allowed_positional_args=['filters', 'kernel_size'],\n+    conversions=[('nb_filter', 'filters'),\n+                 ('subsample', 'strides'),\n+                 ('border_mode', 'padding'),\n+                 ('dim_ordering', 'data_format'),\n+                 ('init', 'kernel_initializer'),\n+                 ('W_regularizer', 'kernel_regularizer'),\n+                 ('b_regularizer', 'bias_regularizer'),\n+                 ('W_constraint', 'kernel_constraint'),\n+                 ('b_constraint', 'bias_constraint'),\n+                 ('bias', 'use_bias')],\n+    value_conversions={'dim_ordering': {'tf': 'channels_last',\n+                                        'th': 'channels_first',\n+                                        'default': None}},\n+    preprocessor=conv3d_args_preprocessor)\n\n@@ -430,5 +430,124 @@ def test_conv2d_legacy_interface():\n     assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n \n \n+@keras_test\n+def test_conv1d_legacy_interface():\n+    old_layer = keras.layers.Convolution1D(5,\n+                                           filter_length=3,\n+                                           input_dim=3,\n+                                           input_length=4,\n+                                           name='conv')\n+    new_layer = keras.layers.Conv1D(5, 3, name='conv', input_shape=(4, 3))\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.Convolution1D(5, 3,\n+                                           init='normal',\n+                                           subsample_length=2,\n+                                           border_mode='valid',\n+                                           W_regularizer='l1',\n+                                           b_regularizer='l2',\n+                                           W_constraint='maxnorm',\n+                                           b_constraint='unitnorm',\n+                                           name='conv')\n+    new_layer = keras.layers.Conv1D(5, 3,\n+                                    kernel_initializer='normal',\n+                                    strides=2,\n+                                    padding='valid',\n+                                    kernel_regularizer='l1',\n+                                    bias_regularizer='l2',\n+                                    kernel_constraint='max_norm',\n+                                    bias_constraint='unit_norm',\n+                                    name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n+@keras_test\n+def test_separable_conv2d_legacy_interface():\n+    old_layer = keras.layers.SeparableConv2D(5, 3, 3, name='conv')\n+    new_layer = keras.layers.SeparableConv2D(5, (3, 3), name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.SeparableConv2D(5, 3, nb_col=3, name='conv')\n+    new_layer = keras.layers.SeparableConv2D(5, (3, 3), name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.SeparableConv2D(5, nb_row=3, nb_col=3, name='conv')\n+    new_layer = keras.layers.SeparableConv2D(5, (3, 3), name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.SeparableConv2D(5, 3, 3,\n+                                             init='normal',\n+                                             subsample=(2, 2),\n+                                             border_mode='valid',\n+                                             dim_ordering='th',\n+                                             depthwise_regularizer='l1',\n+                                             b_regularizer='l2',\n+                                             depthwise_constraint='maxnorm',\n+                                             b_constraint='unitnorm',\n+                                             name='conv')\n+    new_layer = keras.layers.SeparableConv2D(5, (3, 3),\n+                                             depthwise_initializer='normal',\n+                                             pointwise_initializer='normal',\n+                                             strides=(2, 2),\n+                                             padding='valid',\n+                                             depthwise_regularizer='l1',\n+                                             bias_regularizer='l2',\n+                                             depthwise_constraint='max_norm',\n+                                             bias_constraint='unit_norm',\n+                                             data_format='channels_first',\n+                                             name='conv')\n+    old_config = json.dumps(old_layer.get_config())\n+    new_config = json.dumps(new_layer.get_config())\n+    assert old_config == new_config\n+\n+\n+@keras_test\n+def test_conv3d_legacy_interface():\n+    old_layer = keras.layers.Convolution3D(5, 3, 3, 4, name='conv')\n+    new_layer = keras.layers.Conv3D(5, (3, 3, 4), name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.Convolution3D(5, 3, 3, kernel_dim3=4, name='conv')\n+    new_layer = keras.layers.Conv3D(5, (3, 3, 4), name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.Convolution3D(5, 3,\n+                                           kernel_dim2=3,\n+                                           kernel_dim3=4,\n+                                           name='conv')\n+    new_layer = keras.layers.Conv3D(5, (3, 3, 4), name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.Convolution3D(5,\n+                                           kernel_dim1=3,\n+                                           kernel_dim2=3,\n+                                           kernel_dim3=4,\n+                                           name='conv')\n+    new_layer = keras.layers.Conv3D(5, (3, 3, 4), name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+    old_layer = keras.layers.Convolution3D(5, 3, 3, 4,\n+                                           init='normal',\n+                                           subsample=(2, 2, 2),\n+                                           border_mode='valid',\n+                                           dim_ordering='th',\n+                                           W_regularizer='l1',\n+                                           b_regularizer='l2',\n+                                           W_constraint='maxnorm',\n+                                           b_constraint='unitnorm',\n+                                           name='conv')\n+    new_layer = keras.layers.Conv3D(5, (3, 3, 4),\n+                                    kernel_initializer='normal',\n+                                    strides=(2, 2, 2),\n+                                    padding='valid',\n+                                    kernel_regularizer='l1',\n+                                    bias_regularizer='l2',\n+                                    kernel_constraint='max_norm',\n+                                    bias_constraint='unit_norm',\n+                                    data_format='channels_first',\n+                                    name='conv')\n+    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
