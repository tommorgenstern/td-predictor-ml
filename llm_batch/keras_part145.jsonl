{"custom_id": "keras#590a5a5382dc47af188b0c7f34bed3b4ef6d394e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 5649 | Contributors (this commit): 53 | Commits (past 90d): 40 | Contributors (cumulative): 53 | DMM Complexity: 1.0\n\nDIFF:\n@@ -10,7 +10,6 @@ except ImportError:\n \n import numpy as np\n import os\n-import copy\n import warnings\n from .common import floatx, _EPSILON, image_dim_ordering, reset_uids\n py_all = all\n@@ -1250,6 +1249,8 @@ def clip(x, min_value, max_value):\n     \"\"\"\n     if max_value is not None and max_value < min_value:\n         max_value = min_value\n+    if max_value is None:\n+        max_value = np.inf\n     min_value = _to_tensor(min_value, x.dtype.base_dtype)\n     max_value = _to_tensor(max_value, x.dtype.base_dtype)\n     return tf.clip_by_value(x, min_value, max_value)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#538d368396f041826dea063c77cac6e0ace4ad58", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 3455 | Contributors (this commit): 49 | Commits (past 90d): 32 | Contributors (cumulative): 49 | DMM Complexity: 1.0\n\nDIFF:\n@@ -403,6 +403,8 @@ def pow(x, a):\n def clip(x, min_value, max_value):\n     if max_value is not None and max_value < min_value:\n         max_value = min_value\n+    if max_value is None:\n+        max_value = np.inf\n     return T.clip(x, min_value, max_value)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cfa1f7c3bc4d459b7684ed55d8257bbf67e1be23", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 29 | Files Changed: 4 | Hunks: 19 | Methods Changed: 11 | Complexity Δ (Sum/Max): 0/1 | Churn Δ: 59 | Churn Cumulative: 1641 | Contributors (this commit): 33 | Commits (past 90d): 31 | Contributors (cumulative): 40 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,6 +1,7 @@\n # -*- coding: utf-8 -*-\n-\"\"\"These preprocessing utilities would greatly benefit\n-from a fast Cython rewrite.\n+\"\"\"Utilities for text input preprocessing.\n+\n+May benefit from a fast Cython rewrite.\n \"\"\"\n from __future__ import absolute_import\n from __future__ import division\n@@ -17,14 +18,9 @@ else:\n     maketrans = str.maketrans\n \n \n-def base_filter():\n-    f = string.punctuation\n-    f = f.replace(\"'\", '')\n-    f += '\\t\\n'\n-    return f\n-\n-\n-def text_to_word_sequence(text, filters=base_filter(), lower=True, split=\" \"):\n+def text_to_word_sequence(text,\n+                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n+                          lower=True, split=\" \"):\n     \"\"\"Converts a text to a sequence of word indices.\n \n     # Arguments\n@@ -40,7 +36,7 @@ def text_to_word_sequence(text, filters=base_filter(), lower=True, split=\" \"):\n         text = text.lower()\n     text = text.translate(maketrans(filters, split * len(filters)))\n     seq = text.split(split)\n-    return [_f for _f in seq if _f]\n+    return [i for i in seq if i]\n \n \n def one_hot(text, n, filters=base_filter(), lower=True, split=\" \"):\n@@ -78,8 +74,11 @@ class Tokenizer(object):\n     `0` is a reserved index that won't be assigned to any word.\n     \"\"\"\n \n-    def __init__(self, nb_words=None, filters=base_filter(),\n-                 lower=True, split=' ', char_level=False):\n+    def __init__(self, nb_words=None,\n+                 filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n+                 lower=True,\n+                 split=' ',\n+                 char_level=False):\n         self.word_counts = {}\n         self.word_docs = {}\n         self.filters = filters\n@@ -165,6 +164,7 @@ class Tokenizer(object):\n \n     def texts_to_sequences_generator(self, texts):\n         \"\"\"Transforms each text in texts in a sequence of integers.\n+\n         Only top \"nb_words\" most frequent words will be taken into account.\n         Only words known by the tokenizer will be taken into account.\n \n@@ -191,8 +191,7 @@ class Tokenizer(object):\n             yield vect\n \n     def texts_to_matrix(self, texts, mode='binary'):\n-        \"\"\"Convert a list of texts to a Numpy matrix,\n-        according to some vectorization mode.\n+        \"\"\"Convert a list of texts to a Numpy matrix.\n \n         # Arguments\n             texts: list of strings.\n@@ -205,8 +204,7 @@ class Tokenizer(object):\n         return self.sequences_to_matrix(sequences, mode=mode)\n \n     def sequences_to_matrix(self, sequences, mode='binary'):\n-        \"\"\"Converts a list of sequences into a Numpy matrix,\n-        according to some vectorization mode.\n+        \"\"\"Converts a list of sequences into a Numpy matrix.\n \n         # Arguments\n             sequences: list of sequences\n@@ -229,7 +227,7 @@ class Tokenizer(object):\n             raise ValueError('Fit the Tokenizer on some data '\n                              'before using tfidf mode.')\n \n-        X = np.zeros((len(sequences), nb_words))\n+        x = np.zeros((len(sequences), nb_words))\n         for i, seq in enumerate(sequences):\n             if not seq:\n                 continue\n@@ -243,17 +241,18 @@ class Tokenizer(object):\n                     counts[j] += 1\n             for j, c in list(counts.items()):\n                 if mode == 'count':\n-                    X[i][j] = c\n+                    x[i][j] = c\n                 elif mode == 'freq':\n-                    X[i][j] = c / len(seq)\n+                    x[i][j] = c / len(seq)\n                 elif mode == 'binary':\n-                    X[i][j] = 1\n+                    x[i][j] = 1\n                 elif mode == 'tfidf':\n                     # Use weighting scheme 2 in\n                     # https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n                     tf = 1 + np.log(c)\n-                    idf = np.log(1 + self.document_count / (1 + self.index_docs.get(j, 0)))\n-                    X[i][j] = tf * idf\n+                    idf = np.log(1 + self.document_count /\n+                                 (1 + self.index_docs.get(j, 0)))\n+                    x[i][j] = tf * idf\n                 else:\n                     raise ValueError('Unknown vectorization mode:', mode)\n-        return X\n+        return x\n\n@@ -17,7 +17,7 @@ except ImportError:\n     tables = None\n \n \n-class HDF5Matrix():\n+class HDF5Matrix(object):\n     \"\"\"Representation of HDF5 dataset to be used instead of a Numpy array.\n \n     # Example\n\n@@ -44,15 +44,17 @@ def layer_from_config(config, custom_objects=None):\n \n \n def print_summary(layers, relevant_nodes=None,\n-                  line_length=100, positions=[.33, .55, .67, 1.]):\n+                  line_length=100, positions=None):\n     \"\"\"Prints a summary of a layer.\n \n     # Arguments\n         layers: list of layers to print summaries of\n         relevant_nodes: list of relevant nodes\n         line_length: total length of printed lines\n-        positions: relative or absolute positions of log elements in each line\n+        positions: relative or absolute positions of log elements in each line.\n+            If not provided, defaults to `[.33, .55, .67, 1.]`.\n     \"\"\"\n+    positions = positions or [.33, .55, .67, 1.]\n     if positions[-1] <= 1:\n         positions = [int(line_length * p) for p in positions]\n     # header names for the different log elements\n\n@@ -71,7 +71,7 @@ def convert_kernel(kernel, dim_ordering=None):\n     Also works reciprocally, since the transformation is its own inverse.\n \n     # Arguments\n-        kerne: Numpy array (4D or 5D).\n+        kernel: Numpy array (4D or 5D).\n         dim_ordering: the data format.\n \n     # Returns\n@@ -85,7 +85,7 @@ def convert_kernel(kernel, dim_ordering=None):\n     if not 4 <= kernel.ndim <= 5:\n         raise ValueError('Invalid kernel shape:', kernel.shape)\n \n-    slices = [slice(None, None, -1) for i in range(kernel.ndim)]\n+    slices = [slice(None, None, -1) for _ in range(kernel.ndim)]\n     no_flip = (slice(None, None), slice(None, None))\n     if dim_ordering == 'th':  # (out_depth, input_depth, ...)\n         slices[:2] = no_flip\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4973fe3069b594f1cc808cc18bf473ff21ab7956", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 383 | Contributors (this commit): 7 | Commits (past 90d): 6 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -39,7 +39,10 @@ def text_to_word_sequence(text,\n     return [i for i in seq if i]\n \n \n-def one_hot(text, n, filters=base_filter(), lower=True, split=\" \"):\n+def one_hot(text, n,\n+            filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n+            lower=True,\n+            split=' '):\n     seq = text_to_word_sequence(text,\n                                 filters=filters,\n                                 lower=lower,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6e03136116c6cfd58a912e575c1980eeb7cd6809", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 39 | Lines Deleted: 11 | Files Changed: 2 | Hunks: 16 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 50 | Churn Cumulative: 715 | Contributors (this commit): 17 | Commits (past 90d): 9 | Contributors (cumulative): 18 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,5 +1,6 @@\n-from __future__ import absolute_import\n # -*- coding: utf-8 -*-\n+from __future__ import absolute_import\n+\n import numpy as np\n import random\n from six.moves import range\n@@ -7,8 +8,7 @@ from six.moves import range\n \n def pad_sequences(sequences, maxlen=None, dtype='int32',\n                   padding='pre', truncating='pre', value=0.):\n-    \"\"\"Pads each sequence to the same length:\n-    the length of the longest sequence.\n+    \"\"\"Pads each sequence to the same length (length of the longest sequence).\n \n     If maxlen is provided, any sequence longer\n     than maxlen is truncated to maxlen.\n@@ -28,6 +28,10 @@ def pad_sequences(sequences, maxlen=None, dtype='int32',\n \n     # Returns\n         x: numpy array with dimensions (number_of_sequences, maxlen)\n+\n+    # Raises\n+        ValueError, in case of invalid values for `truncating`, `padding`,\n+            or in case of invalid shape for a `sequences` entry.\n     \"\"\"\n     lengths = [len(s) for s in sequences]\n \n@@ -39,13 +43,13 @@ def pad_sequences(sequences, maxlen=None, dtype='int32',\n     # checking for consistency in the main loop below.\n     sample_shape = tuple()\n     for s in sequences:\n-        if len(s) > 0:\n+        if s:\n             sample_shape = np.asarray(s).shape[1:]\n             break\n \n     x = (np.ones((nb_samples, maxlen) + sample_shape) * value).astype(dtype)\n     for idx, s in enumerate(sequences):\n-        if len(s) == 0:\n+        if not s:\n             continue  # empty list was found\n         if truncating == 'pre':\n             trunc = s[-maxlen:]\n@@ -70,7 +74,9 @@ def pad_sequences(sequences, maxlen=None, dtype='int32',\n \n \n def make_sampling_table(size, sampling_factor=1e-5):\n-    \"\"\"This generates an array where the ith element\n+    \"\"\"Generates a word rank-based probabilistic sampling table.\n+\n+    This generates an array where the ith element\n     is the probability that a word of rank i would be sampled,\n     according to the sampling distribution used in word2vec.\n \n@@ -84,6 +90,11 @@ def make_sampling_table(size, sampling_factor=1e-5):\n \n     # Arguments\n         size: int, number of possible words to sample.\n+        sample_factor: the sampling factor in the word2vec formula.\n+\n+    # Returns\n+        A 1D Numpy array of length `size` where the ith entry\n+        is the probability that a word of rank i should be sampled.\n     \"\"\"\n     gamma = 0.577\n     rank = np.array(list(range(size)))\n@@ -97,12 +108,20 @@ def make_sampling_table(size, sampling_factor=1e-5):\n def skipgrams(sequence, vocabulary_size,\n               window_size=4, negative_samples=1., shuffle=True,\n               categorical=False, sampling_table=None):\n-    \"\"\"Take a sequence (list of indexes of words),\n+    \"\"\"Generates skipgram word pairs.\n+\n+    Takes a sequence (list of indexes of words),\n     returns couples of [word_index, other_word index] and labels (1s or 0s),\n     where label = 1 if 'other_word' belongs to the context of 'word',\n     and label=0 if 'other_word' is randomly sampled\n \n     # Arguments\n+        sequence: a word sequence (sentence), encoded as a list\n+            of word indices (integers). If using a `sampling_table`,\n+            word indices are expected to match the rank\n+            of the words in a reference dataset (e.g. 10 would encode\n+            the 10-th most frequently occuring token).\n+            Note that index 0 is expected to be a non-word and will be skipped.\n         vocabulary_size: int. maximum possible word index + 1\n         window_size: int. actually half-window.\n             The window of a word wi will be [i-window_size, i+window_size+1]\n@@ -111,12 +130,16 @@ def skipgrams(sequence, vocabulary_size,\n         categorical: bool. if False, labels will be\n             integers (eg. [0, 1, 1 .. ]),\n             if True labels will be categorical eg. [[1,0],[0,1],[0,1] .. ]\n+        shuffle: whether to shuffle the word couples before returning them.\n+        categorical: whether to use categorical encoding for the labels.\n+        sampling_table: 1D array of size `vocabulary_size` where the entry i\n+            encodes the probabibily to sample a word of rank i.\n \n     # Returns\n         couples, labels: where `couples` are int pairs and\n             `labels` are either 0 or 1.\n \n-    # Notes\n+    # Note\n         By convention, index 0 in the vocabulary is\n         a non-word and will be skipped.\n     \"\"\"\n@@ -147,7 +170,8 @@ def skipgrams(sequence, vocabulary_size,\n         words = [c[0] for c in couples]\n         random.shuffle(words)\n \n-        couples += [[words[i % len(words)], random.randint(1, vocabulary_size - 1)] for i in range(nb_negative_samples)]\n+        couples += [[words[i % len(words)],\n+                    random.randint(1, vocabulary_size - 1)] for i in range(nb_negative_samples)]\n         if categorical:\n             labels += [[1, 0]] * nb_negative_samples\n         else:\n\n@@ -198,7 +198,7 @@ class Tokenizer(object):\n \n         # Arguments\n             texts: list of strings.\n-            modes: one of \"binary\", \"count\", \"tfidf\", \"freq\".\n+            mode: one of \"binary\", \"count\", \"tfidf\", \"freq\".\n \n         # Returns\n             A Numpy matrix.\n@@ -212,10 +212,14 @@ class Tokenizer(object):\n         # Arguments\n             sequences: list of sequences\n                 (a sequence is a list of integer word indices).\n-            modes: one of \"binary\", \"count\", \"tfidf\", \"freq\"\n+            mode: one of \"binary\", \"count\", \"tfidf\", \"freq\"\n \n         # Returns\n             A Numpy matrix.\n+\n+        # Raises\n+            ValueError: In case of invalid `mode` argument,\n+                or if the Tokenizer requires to be fit to sample data.\n         \"\"\"\n         if not self.nb_words:\n             if self.word_index:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e5529d98fe770019f45b6b5efe7efa88d0dccc4c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 132 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 20/20 | Churn Δ: 132 | Churn Cumulative: 7591 | Contributors (this commit): 39 | Commits (past 90d): 25 | Contributors (cumulative): 50 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1789,11 +1789,41 @@ class Cropping2D(Layer):\n \n     def call(self, x, mask=None):\n         if self.dim_ordering == 'th':\n+            if self.cropping[0][1] == self.cropping[1][1] == 0:\n+                return x[:,\n+                         :,\n+                         self.cropping[0][0]:,\n+                         self.cropping[1][0]:]\n+            elif self.cropping[0][1] == 0:\n+                return x[:,\n+                         :,\n+                         self.cropping[0][0]:,\n+                         self.cropping[1][0]:-self.cropping[1][1]]\n+            elif self.cropping[1][1] == 0:\n+                return x[:,\n+                         :,\n+                         self.cropping[0][0]:-self.cropping[0][1],\n+                         self.cropping[1][0]:]\n             return x[:,\n                      :,\n                      self.cropping[0][0]:-self.cropping[0][1],\n                      self.cropping[1][0]:-self.cropping[1][1]]\n         elif self.dim_ordering == 'tf':\n+            if self.cropping[0][1] == self.cropping[1][1] == 0:\n+                return x[:,\n+                         self.cropping[0][0]:,\n+                         self.cropping[1][0]:,\n+                         :]\n+            elif self.cropping[0][1] == 0:\n+                return x[:,\n+                         self.cropping[0][0]:,\n+                         self.cropping[1][0]:-self.cropping[1][1],\n+                         :]\n+            elif self.cropping[1][1] == 0:\n+                return x[:,\n+                         self.cropping[0][0]:-self.cropping[0][1],\n+                         self.cropping[1][0]:,\n+                         :]\n             return x[:,\n                      self.cropping[0][0]:-self.cropping[0][1],\n                      self.cropping[1][0]:-self.cropping[1][1],\n@@ -1876,12 +1906,96 @@ class Cropping3D(Layer):\n \n     def call(self, x, mask=None):\n         if self.dim_ordering == 'th':\n+            if self.cropping[0][1] == self.cropping[1][1] == self.cropping[2][1] == 0:\n+                return x[:,\n+                         :,\n+                         self.cropping[0][0]:,\n+                         self.cropping[1][0]:,\n+                         self.cropping[2][0]:]\n+            elif self.cropping[0][1] == self.cropping[1][1] == 0:\n+                return x[:,\n+                         :,\n+                         self.cropping[0][0]:,\n+                         self.cropping[1][0]:,\n+                         self.cropping[2][0]:-self.cropping[2][1]]\n+            elif self.cropping[1][1] == self.cropping[2][1] == 0:\n+                return x[:,\n+                         :,\n+                         self.cropping[0][0]:-self.cropping[0][1],\n+                         self.cropping[1][0]:,\n+                         self.cropping[2][0]:]\n+            elif self.cropping[0][1] == self.cropping[2][1] == 0:\n+                return x[:,\n+                         :,\n+                         self.cropping[0][0]:,\n+                         self.cropping[1][0]:-self.cropping[1][1],\n+                         self.cropping[2][0]:]\n+            elif self.cropping[0][1] == 0:\n+                return x[:,\n+                         :,\n+                         self.cropping[0][0]:,\n+                         self.cropping[1][0]:-self.cropping[1][1],\n+                         self.cropping[2][0]:-self.cropping[2][1]]\n+            elif self.cropping[1][1] == 0:\n+                return x[:,\n+                         :,\n+                         self.cropping[0][0]:-self.cropping[0][1],\n+                         self.cropping[1][0]:,\n+                         self.cropping[2][0]:-self.cropping[2][1]]\n+            elif self.cropping[2][1] == 0:\n+                return x[:,\n+                         :,\n+                         self.cropping[0][0]:-self.cropping[0][1],\n+                         self.cropping[1][0]:-self.cropping[1][1],\n+                         self.cropping[2][0]:]\n             return x[:,\n                      :,\n                      self.cropping[0][0]:-self.cropping[0][1],\n                      self.cropping[1][0]:-self.cropping[1][1],\n                      self.cropping[2][0]:-self.cropping[2][1]]\n         elif self.dim_ordering == 'tf':\n+            if self.cropping[0][1] == self.cropping[1][1] == self.cropping[2][1] == 0:\n+                return x[:,\n+                         self.cropping[0][0]:,\n+                         self.cropping[1][0]:,\n+                         self.cropping[2][0]:,\n+                         :]\n+            elif self.cropping[0][1] == self.cropping[1][1] == 0:\n+                return x[:,\n+                         self.cropping[0][0]:,\n+                         self.cropping[1][0]:,\n+                         self.cropping[2][0]:-self.cropping[2][1],\n+                         :]\n+            elif self.cropping[1][1] == self.cropping[2][1] == 0:\n+                return x[:,\n+                         self.cropping[0][0]:-self.cropping[0][1],\n+                         self.cropping[1][0]:,\n+                         self.cropping[2][0]:,\n+                         :]\n+            elif self.cropping[0][1] == self.cropping[2][1] == 0:\n+                return x[:,\n+                         self.cropping[0][0]:,\n+                         self.cropping[1][0]:-self.cropping[1][1],\n+                         self.cropping[2][0]:,\n+                         :]\n+            elif self.cropping[0][1] == 0:\n+                return x[:,\n+                         self.cropping[0][0]:,\n+                         self.cropping[1][0]:-self.cropping[1][1],\n+                         self.cropping[2][0]:-self.cropping[2][1],\n+                         :]\n+            elif self.cropping[1][1] == 0:\n+                return x[:,\n+                         self.cropping[0][0]:-self.cropping[0][1],\n+                         self.cropping[1][0]:,\n+                         self.cropping[2][0]:-self.cropping[2][1],\n+                         :]\n+            elif self.cropping[2][1] == 0:\n+                return x[:,\n+                         self.cropping[0][0]:-self.cropping[0][1],\n+                         self.cropping[1][0]:-self.cropping[1][1],\n+                         self.cropping[2][0]:,\n+                         :]\n             return x[:,\n                      self.cropping[0][0]:-self.cropping[0][1],\n                      self.cropping[1][0]:-self.cropping[1][1],\n\n@@ -666,6 +666,15 @@ def test_cropping_2d():\n                              cropping[1][0]: -cropping[1][1],\n                              :]\n     assert_allclose(np_output, expected_out)\n+    # another correctness test (no cropping)\n+    cropping = ((0, 0), (0, 0))\n+    layer = convolutional.Cropping2D(cropping=cropping,\n+                                     dim_ordering=dim_ordering)\n+    layer.build(input.shape)\n+    output = layer(K.variable(input))\n+    np_output = K.eval(output)\n+    # compare with input\n+    assert_allclose(np_output, input)\n \n \n def test_cropping_3d():\n@@ -709,6 +718,15 @@ def test_cropping_3d():\n                              cropping[2][0]: -cropping[2][1],\n                              :]\n     assert_allclose(np_output, expected_out)\n+    # another correctness test (no cropping)\n+    cropping = ((0, 0), (0, 0), (0, 0))\n+    layer = convolutional.Cropping3D(cropping=cropping,\n+                                     dim_ordering=dim_ordering)\n+    layer.build(input.shape)\n+    output = layer(K.variable(input))\n+    np_output = K.eval(output)\n+    # compare with input\n+    assert_allclose(np_output, input)\n \n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#429e253fb696c78029824ed73b28ade047b92cd3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 6 | Methods Changed: 12 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 297 | Contributors (this commit): 8 | Commits (past 90d): 6 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -29,11 +29,11 @@ def get_fans(shape, dim_ordering='th'):\n     return fan_in, fan_out\n \n \n-def uniform(shape, scale=0.05, name=None):\n+def uniform(shape, scale=0.05, name=None, dim_ordering='th'):\n     return K.random_uniform_variable(shape, -scale, scale, name=name)\n \n \n-def normal(shape, scale=0.05, name=None):\n+def normal(shape, scale=0.05, name=None, dim_ordering='th'):\n     return K.random_normal_variable(shape, 0.0, scale, name=name)\n \n \n@@ -85,7 +85,7 @@ def he_uniform(shape, name=None, dim_ordering='th'):\n     return uniform(shape, s, name=name)\n \n \n-def orthogonal(shape, scale=1.1, name=None):\n+def orthogonal(shape, scale=1.1, name=None, dim_ordering='th'):\n     \"\"\"Orthogonal initializer.\n \n     # References\n@@ -100,7 +100,7 @@ def orthogonal(shape, scale=1.1, name=None):\n     return K.variable(scale * q[:shape[0], :shape[1]], name=name)\n \n \n-def identity(shape, scale=1, name=None):\n+def identity(shape, scale=1, name=None, dim_ordering='th'):\n     if len(shape) != 2 or shape[0] != shape[1]:\n         raise ValueError('Identity matrix initialization can only be used '\n                          'for 2D square matrices.')\n@@ -108,11 +108,11 @@ def identity(shape, scale=1, name=None):\n         return K.variable(scale * np.identity(shape[0]), name=name)\n \n \n-def zero(shape, name=None):\n+def zero(shape, name=None, dim_ordering='th'):\n     return K.zeros(shape, name=name)\n \n \n-def one(shape, name=None):\n+def one(shape, name=None, dim_ordering='th'):\n     return K.ones(shape, name=name)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c6bf7558b2121c3f2f280a0d15ee4354994e0c86", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 5651 | Contributors (this commit): 54 | Commits (past 90d): 41 | Contributors (cumulative): 54 | DMM Complexity: None\n\nDIFF:\n@@ -2468,7 +2468,7 @@ def _preprocess_deconv_output_shape(x, shape, dim_ordering):\n         shape = (shape[0], shape[2], shape[3], shape[1])\n \n     if shape[0] is None:\n-        shape = (tf.shape(x)[0], ) + shape[1:]\n+        shape = (tf.shape(x)[0], ) + tuple(shape[1:])\n     return shape\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5d976573751fa744a4b9b4648a699dbd2ce42a6b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 337 | Contributors (this commit): 11 | Commits (past 90d): 3 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -30,7 +30,7 @@ def pad_sequences(sequences, maxlen=None, dtype='int32',\n         x: numpy array with dimensions (number_of_sequences, maxlen)\n \n     # Raises\n-        ValueError, in case of invalid values for `truncating`, `padding`,\n+        ValueError: in case of invalid values for `truncating` or `padding`,\n             or in case of invalid shape for a `sequences` entry.\n     \"\"\"\n     lengths = [len(s) for s in sequences]\n@@ -43,14 +43,14 @@ def pad_sequences(sequences, maxlen=None, dtype='int32',\n     # checking for consistency in the main loop below.\n     sample_shape = tuple()\n     for s in sequences:\n-        if s:\n+        if len(s) > 0:\n             sample_shape = np.asarray(s).shape[1:]\n             break\n \n     x = (np.ones((nb_samples, maxlen) + sample_shape) * value).astype(dtype)\n     for idx, s in enumerate(sequences):\n-        if not s:\n-            continue  # empty list was found\n+        if not len(s):\n+            continue  # empty list/array was found\n         if truncating == 'pre':\n             trunc = s[-maxlen:]\n         elif truncating == 'post':\n@@ -90,7 +90,7 @@ def make_sampling_table(size, sampling_factor=1e-5):\n \n     # Arguments\n         size: int, number of possible words to sample.\n-        sample_factor: the sampling factor in the word2vec formula.\n+        sampling_factor: the sampling factor in the word2vec formula.\n \n     # Returns\n         A 1D Numpy array of length `size` where the ith entry\n@@ -127,11 +127,10 @@ def skipgrams(sequence, vocabulary_size,\n             The window of a word wi will be [i-window_size, i+window_size+1]\n         negative_samples: float >= 0. 0 for no negative (=random) samples.\n             1 for same number as positive samples. etc.\n+        shuffle: whether to shuffle the word couples before returning them.\n         categorical: bool. if False, labels will be\n             integers (eg. [0, 1, 1 .. ]),\n             if True labels will be categorical eg. [[1,0],[0,1],[0,1] .. ]\n-        shuffle: whether to shuffle the word couples before returning them.\n-        categorical: whether to use categorical encoding for the labels.\n         sampling_table: 1D array of size `vocabulary_size` where the entry i\n             encodes the probabibily to sample a word of rank i.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0edecdd09e84f9cfd83e4a5775c6d6f46e7b60ff", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 312 | Contributors (this commit): 12 | Commits (past 90d): 11 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -2,7 +2,6 @@\n from __future__ import absolute_import\n \n import numpy as np\n-import scipy as sp\n from six.moves import range\n from six.moves import zip\n from .. import backend as K\n@@ -38,9 +37,9 @@ def normalize(a, axis=-1, order=2):\n \n def binary_logloss(p, y):\n     epsilon = 1e-15\n-    p = sp.maximum(epsilon, p)\n-    p = sp.minimum(1 - epsilon, p)\n-    res = sum(y * sp.log(p) + sp.subtract(1, y) * sp.log(sp.subtract(1, p)))\n+    p = np.maximum(epsilon, p)\n+    p = np.minimum(1 - epsilon, p)\n+    res = sum(y * np.log(p) + np.subtract(1, y) * np.log(np.subtract(1, p)))\n     res *= -1.0 / len(y)\n     return res\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#68bde67d0a73825f9de15bb2a1eef01aaf405fa0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 18 | Churn Cumulative: 204 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -15,10 +15,24 @@ from six.moves.urllib.error import HTTPError\n from ..utils.generic_utils import Progbar\n \n \n-# Under Python 2, 'urlretrieve' relies on FancyURLopener from legacy\n-# urllib module, known to have issues with proxy management\n if sys.version_info[0] == 2:\n     def urlretrieve(url, filename, reporthook=None, data=None):\n+        \"\"\"Replacement for `urlretrive` for Python 2.\n+\n+        Under Python 2, `urlretrieve` relies on `FancyURLopener` from legacy\n+        `urllib` module, known to have issues with proxy management.\n+\n+        # Arguments\n+            url: url to retrieve.\n+            filename: where to store the retrieved data locally.\n+            reporthook: a hook function that will be called once\n+                on establishment of the network connection and once\n+                after each block read thereafter.\n+                The hook will be passed three arguments;\n+                a count of blocks transferred so far,\n+                a block size in bytes, and the total size of the file.\n+            data: `data` argument passed to `urlopen`.\n+        \"\"\"\n         def chunk_read(response, chunk_size=8192, reporthook=None):\n             total_size = response.info().get('Content-Length').strip()\n             total_size = int(total_size)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#887576b1139b5f21dfa4656410ebdbf986bc6fb3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 259 | Lines Deleted: 119 | Files Changed: 1 | Hunks: 86 | Methods Changed: 30 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 378 | Churn Cumulative: 1790 | Contributors (this commit): 21 | Commits (past 90d): 9 | Contributors (cumulative): 21 | DMM Complexity: 0.21428571428571427\n\nDIFF:\n@@ -16,23 +16,63 @@ import warnings\n \n from .. import backend as K\n \n+try:\n+    from PIL import Image as pil_image\n+except ImportError:\n+    pil_image = None\n \n-def random_rotation(x, rg, row_index=1, col_index=2, channel_index=0,\n+\n+def random_rotation(x, rg, row_axis=1, col_axis=2, channel_axis=0,\n                     fill_mode='nearest', cval=0.):\n+    \"\"\"Performs a random rotation of a Numpy image tensor.\n+\n+    # Arguments\n+        x: Input tensor. Must be 3D.\n+        rg: Rotation range, in degrees.\n+        row_axis: Index of axis for rows in the input tensor.\n+        col_axis: Index of axis for columns in the input tensor.\n+        channel_axis: Index of axis for channels in the input tensor.\n+        fill_mode: Points outside the boundaries of the input\n+            are filled according to the given mode\n+            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n+        cval: Value used for points outside the boundaries\n+            of the input if `mode='constant'`.\n+\n+    # Returns\n+        Rotated Numpy image tensor.\n+    \"\"\"\n     theta = np.pi / 180 * np.random.uniform(-rg, rg)\n     rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n                                 [np.sin(theta), np.cos(theta), 0],\n                                 [0, 0, 1]])\n \n-    h, w = x.shape[row_index], x.shape[col_index]\n+    h, w = x.shape[row_axis], x.shape[col_axis]\n     transform_matrix = transform_matrix_offset_center(rotation_matrix, h, w)\n-    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\n+    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n     return x\n \n \n-def random_shift(x, wrg, hrg, row_index=1, col_index=2, channel_index=0,\n+def random_shift(x, wrg, hrg, row_axis=1, col_axis=2, channel_axis=0,\n                  fill_mode='nearest', cval=0.):\n-    h, w = x.shape[row_index], x.shape[col_index]\n+    \"\"\"Performs a random spatial shift of a Numpy image tensor.\n+\n+    # Arguments\n+        x: Input tensor. Must be 3D.\n+        wrg: Width shift range, as a float fraction of the width.\n+        hrg: Height shift range, as a float fraction of the height.\n+        row_axis: Index of axis for rows in the input tensor.\n+        col_axis: Index of axis for columns in the input tensor.\n+        channel_axis: Index of axis for channels in the input tensor.\n+        fill_mode: Points outside the boundaries of the input\n+            are filled according to the given mode\n+            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n+        cval: Value used for points outside the boundaries\n+            of the input if `mode='constant'`.\n+\n+    # Returns\n+        Shifted Numpy image tensor.\n+    \"\"\"\n+    h, w = x.shape[row_axis], x.shape[col_axis]\n     tx = np.random.uniform(-hrg, hrg) * h\n     ty = np.random.uniform(-wrg, wrg) * w\n     translation_matrix = np.array([[1, 0, tx],\n@@ -40,25 +80,62 @@ def random_shift(x, wrg, hrg, row_index=1, col_index=2, channel_index=0,\n                                    [0, 0, 1]])\n \n     transform_matrix = translation_matrix  # no need to do offset\n-    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\n+    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n     return x\n \n \n-def random_shear(x, intensity, row_index=1, col_index=2, channel_index=0,\n+def random_shear(x, intensity, row_axis=1, col_axis=2, channel_axis=0,\n                  fill_mode='nearest', cval=0.):\n+    \"\"\"Performs a random spatial shear of a Numpy image tensor.\n+\n+    # Arguments\n+        x: Input tensor. Must be 3D.\n+        intensity: Transformation intensity.\n+        row_axis: Index of axis for rows in the input tensor.\n+        col_axis: Index of axis for columns in the input tensor.\n+        channel_axis: Index of axis for channels in the input tensor.\n+        fill_mode: Points outside the boundaries of the input\n+            are filled according to the given mode\n+            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n+        cval: Value used for points outside the boundaries\n+            of the input if `mode='constant'`.\n+\n+    # Returns\n+        Sheared Numpy image tensor.\n+    \"\"\"\n     shear = np.random.uniform(-intensity, intensity)\n     shear_matrix = np.array([[1, -np.sin(shear), 0],\n                              [0, np.cos(shear), 0],\n                              [0, 0, 1]])\n \n-    h, w = x.shape[row_index], x.shape[col_index]\n+    h, w = x.shape[row_axis], x.shape[col_axis]\n     transform_matrix = transform_matrix_offset_center(shear_matrix, h, w)\n-    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\n+    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n     return x\n \n \n-def random_zoom(x, zoom_range, row_index=1, col_index=2, channel_index=0,\n+def random_zoom(x, zoom_range, row_axis=1, col_axis=2, channel_axis=0,\n                 fill_mode='nearest', cval=0.):\n+    \"\"\"Performs a random spatial zoom of a Numpy image tensor.\n+\n+    # Arguments\n+        x: Input tensor. Must be 3D.\n+        zoom_range: Tuple of floats; zoom range for width and height.\n+        row_axis: Index of axis for rows in the input tensor.\n+        col_axis: Index of axis for columns in the input tensor.\n+        channel_axis: Index of axis for channels in the input tensor.\n+        fill_mode: Points outside the boundaries of the input\n+            are filled according to the given mode\n+            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n+        cval: Value used for points outside the boundaries\n+            of the input if `mode='constant'`.\n+\n+    # Returns\n+        Zoomed Numpy image tensor.\n+\n+    # Raises\n+        ValueError: if `zoom_range` isn't a tuple.\n+    \"\"\"\n     if len(zoom_range) != 2:\n         raise ValueError('zoom_range should be a tuple or list of two floats. '\n                          'Received arg: ', zoom_range)\n@@ -71,24 +148,19 @@ def random_zoom(x, zoom_range, row_index=1, col_index=2, channel_index=0,\n                             [0, zy, 0],\n                             [0, 0, 1]])\n \n-    h, w = x.shape[row_index], x.shape[col_index]\n+    h, w = x.shape[row_axis], x.shape[col_axis]\n     transform_matrix = transform_matrix_offset_center(zoom_matrix, h, w)\n-    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\n+    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n     return x\n \n \n-def random_barrel_transform(x, intensity):\n-    # TODO\n-    pass\n-\n-\n-def random_channel_shift(x, intensity, channel_index=0):\n-    x = np.rollaxis(x, channel_index, 0)\n+def random_channel_shift(x, intensity, channel_axis=0):\n+    x = np.rollaxis(x, channel_axis, 0)\n     min_x, max_x = np.min(x), np.max(x)\n     channel_images = [np.clip(x_channel + np.random.uniform(-intensity, intensity), min_x, max_x)\n                       for x_channel in x]\n     x = np.stack(channel_images, axis=0)\n-    x = np.rollaxis(x, 0, channel_index + 1)\n+    x = np.rollaxis(x, 0, channel_axis + 1)\n     return x\n \n \n@@ -101,14 +173,14 @@ def transform_matrix_offset_center(matrix, x, y):\n     return transform_matrix\n \n \n-def apply_transform(x, transform_matrix, channel_index=0, fill_mode='nearest', cval=0.):\n-    x = np.rollaxis(x, channel_index, 0)\n+def apply_transform(x, transform_matrix, channel_axis=0, fill_mode='nearest', cval=0.):\n+    x = np.rollaxis(x, channel_axis, 0)\n     final_affine_matrix = transform_matrix[:2, :2]\n     final_offset = transform_matrix[:2, 2]\n     channel_images = [ndi.interpolation.affine_transform(x_channel, final_affine_matrix,\n                                                          final_offset, order=0, mode=fill_mode, cval=cval) for x_channel in x]\n     x = np.stack(channel_images, axis=0)\n-    x = np.rollaxis(x, 0, channel_index + 1)\n+    x = np.rollaxis(x, 0, channel_axis + 1)\n     return x\n \n \n@@ -120,7 +192,24 @@ def flip_axis(x, axis):\n \n \n def array_to_img(x, dim_ordering='default', scale=True):\n-    from PIL import Image\n+    \"\"\"Converts a 3D Numpy array to a PIL Image instance.\n+\n+    # Arguments\n+        x: Input Numpy array.\n+        dim_ordering: Image data format.\n+        scale: Whether to rescale image values\n+            to be within [0, 255].\n+\n+    # Returns\n+        A PIL Image instance.\n+\n+    # Raises\n+        ImportError: if PIL is not available.\n+        ValueError: if invalid `x` or `dim_ordering` is passed.\n+    \"\"\"\n+    if pil_image is None:\n+        raise ImportError('Could not import PIL.Image. '\n+                          'The use of `array_to_img` requires PIL.')\n     x = np.asarray(x)\n     if x.ndim != 3:\n         raise ValueError('Expected image array to have rank 3 (single image). '\n@@ -144,15 +233,27 @@ def array_to_img(x, dim_ordering='default', scale=True):\n         x *= 255\n     if x.shape[2] == 3:\n         # RGB\n-        return Image.fromarray(x.astype('uint8'), 'RGB')\n+        return pil_image.fromarray(x.astype('uint8'), 'RGB')\n     elif x.shape[2] == 1:\n         # grayscale\n-        return Image.fromarray(x[:, :, 0].astype('uint8'), 'L')\n+        return pil_image.fromarray(x[:, :, 0].astype('uint8'), 'L')\n     else:\n         raise ValueError('Unsupported channel number: ', x.shape[2])\n \n \n def img_to_array(img, dim_ordering='default'):\n+    \"\"\"Converts a PIL Image instance to a Numpy array.\n+\n+    # Arguments\n+        img: PIL Image instance.\n+        dim_ordering: Image data format.\n+\n+    # Returns\n+        A 3D Numpy array (float32).\n+\n+    # Raises\n+        ValueError: if invalid `img` or `dim_ordering` is passed.\n+    \"\"\"\n     if dim_ordering == 'default':\n         dim_ordering = K.image_dim_ordering()\n     if dim_ordering not in {'th', 'tf'}:\n@@ -175,16 +276,24 @@ def img_to_array(img, dim_ordering='default'):\n \n \n def load_img(path, grayscale=False, target_size=None):\n-    \"\"\"Load an image into PIL format.\n+    \"\"\"Loads an image into PIL format.\n \n     # Arguments\n-        path: path to image file\n-        grayscale: boolean\n-        target_size: None (default to original size)\n-            or (img_height, img_width)\n+        path: Path to image file\n+        grayscale: Boolean, whether to load the image as grayscale.\n+        target_size: Either `None` (default to original size)\n+            or tuple of ints `(img_height, img_width)`.\n+\n+    # Returns\n+        A PIL Image instance.\n+\n+    # Raises\n+        ImportError: if PIL is not available.\n     \"\"\"\n-    from PIL import Image\n-    img = Image.open(path)\n+    if pil_image is None:\n+        raise ImportError('Could not import PIL.Image. '\n+                          'The use of `array_to_img` requires PIL.')\n+    img = pil_image.open(path)\n     if grayscale:\n         img = img.convert('L')\n     else:  # Ensure 3 channel even when loaded image is grayscale\n@@ -201,8 +310,7 @@ def list_pictures(directory, ext='jpg|jpeg|bmp|png'):\n \n \n class ImageDataGenerator(object):\n-    \"\"\"Generate minibatches with\n-    real-time data augmentation.\n+    \"\"\"Generate minibatches of image data with real-time data augmentation.\n \n     # Arguments\n         featurewise_center: set input mean to 0 over the dataset.\n@@ -230,13 +338,14 @@ class ImageDataGenerator(object):\n             (before applying any other transformation).\n         preprocessing_function: function that will be implied on each input.\n             The function will run before any other modification on it.\n-            The function should take one argument: one image (Numpy tensor with rank 3),\n+            The function should take one argument:\n+            one image (Numpy tensor with rank 3),\n             and should output a Numpy tensor with the same shape.\n         dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n             (the depth) is at index 1, in 'tf' mode it is at index 3.\n             It defaults to the `image_dim_ordering` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"th\".\n+            If you never set it, then it will be \"tf\".\n     \"\"\"\n \n     def __init__(self,\n@@ -260,10 +369,21 @@ class ImageDataGenerator(object):\n                  dim_ordering='default'):\n         if dim_ordering == 'default':\n             dim_ordering = K.image_dim_ordering()\n-        self.__dict__.update(locals())\n-        self.mean = None\n-        self.std = None\n-        self.principal_components = None\n+        self.featurewise_center = featurewise_center\n+        self.samplewise_center = samplewise_center\n+        self.featurewise_std_normalization = featurewise_std_normalization\n+        self.samplewise_std_normalization = samplewise_std_normalization\n+        self.zca_whitening = zca_whitening\n+        self.rotation_range = rotation_range\n+        self.width_shift_range = width_shift_range\n+        self.height_shift_range = height_shift_range\n+        self.shear_range = shear_range\n+        self.zoom_range = zoom_range\n+        self.channel_shift_range = channel_shift_range\n+        self.fill_mode = fill_mode\n+        self.cval = cval\n+        self.horizontal_flip = horizontal_flip\n+        self.vertical_flip = vertical_flip\n         self.rescale = rescale\n         self.preprocessing_function = preprocessing_function\n \n@@ -273,13 +393,17 @@ class ImageDataGenerator(object):\n                              'Received arg: ', dim_ordering)\n         self.dim_ordering = dim_ordering\n         if dim_ordering == 'th':\n-            self.channel_index = 1\n-            self.row_index = 2\n-            self.col_index = 3\n+            self.channel_axis = 1\n+            self.row_axis = 2\n+            self.col_axis = 3\n         if dim_ordering == 'tf':\n-            self.channel_index = 3\n-            self.row_index = 1\n-            self.col_index = 2\n+            self.channel_axis = 3\n+            self.row_axis = 1\n+            self.col_axis = 2\n+\n+        self.mean = None\n+        self.std = None\n+        self.principal_components = None\n \n         if np.isscalar(zoom_range):\n             self.zoom_range = [1 - zoom_range, 1 + zoom_range]\n@@ -294,15 +418,21 @@ class ImageDataGenerator(object):\n              save_to_dir=None, save_prefix='', save_format='jpeg'):\n         return NumpyArrayIterator(\n             X, y, self,\n-            batch_size=batch_size, shuffle=shuffle, seed=seed,\n+            batch_size=batch_size,\n+            shuffle=shuffle,\n+            seed=seed,\n             dim_ordering=self.dim_ordering,\n-            save_to_dir=save_to_dir, save_prefix=save_prefix, save_format=save_format)\n+            save_to_dir=save_to_dir,\n+            save_prefix=save_prefix,\n+            save_format=save_format)\n \n     def flow_from_directory(self, directory,\n                             target_size=(256, 256), color_mode='rgb',\n                             classes=None, class_mode='categorical',\n                             batch_size=32, shuffle=True, seed=None,\n-                            save_to_dir=None, save_prefix='', save_format='jpeg',\n+                            save_to_dir=None,\n+                            save_prefix='',\n+                            save_format='jpeg',\n                             follow_links=False):\n         return DirectoryIterator(\n             directory, self,\n@@ -310,7 +440,9 @@ class ImageDataGenerator(object):\n             classes=classes, class_mode=class_mode,\n             dim_ordering=self.dim_ordering,\n             batch_size=batch_size, shuffle=shuffle, seed=seed,\n-            save_to_dir=save_to_dir, save_prefix=save_prefix, save_format=save_format,\n+            save_to_dir=save_to_dir,\n+            save_prefix=save_prefix,\n+            save_format=save_format,\n             follow_links=follow_links)\n \n     def standardize(self, x):\n@@ -319,11 +451,11 @@ class ImageDataGenerator(object):\n         if self.rescale:\n             x *= self.rescale\n         # x is a single image, so it doesn't have image number at index 0\n-        img_channel_index = self.channel_index - 1\n+        img_channel_axis = self.channel_axis - 1\n         if self.samplewise_center:\n-            x -= np.mean(x, axis=img_channel_index, keepdims=True)\n+            x -= np.mean(x, axis=img_channel_axis, keepdims=True)\n         if self.samplewise_std_normalization:\n-            x /= (np.std(x, axis=img_channel_index, keepdims=True) + 1e-7)\n+            x /= (np.std(x, axis=img_channel_axis, keepdims=True) + 1e-7)\n \n         if self.featurewise_center:\n             if self.mean is not None:\n@@ -355,11 +487,12 @@ class ImageDataGenerator(object):\n \n     def random_transform(self, x):\n         # x is a single image, so it doesn't have image number at index 0\n-        img_row_index = self.row_index - 1\n-        img_col_index = self.col_index - 1\n-        img_channel_index = self.channel_index - 1\n+        img_row_axis = self.row_axis - 1\n+        img_col_axis = self.col_axis - 1\n+        img_channel_axis = self.channel_axis - 1\n \n-        # use composition of homographies to generate final transform that needs to be applied\n+        # use composition of homographies\n+        # to generate final transform that needs to be applied\n         if self.rotation_range:\n             theta = np.pi / 180 * np.random.uniform(-self.rotation_range, self.rotation_range)\n         else:\n@@ -368,12 +501,12 @@ class ImageDataGenerator(object):\n                                     [np.sin(theta), np.cos(theta), 0],\n                                     [0, 0, 1]])\n         if self.height_shift_range:\n-            tx = np.random.uniform(-self.height_shift_range, self.height_shift_range) * x.shape[img_row_index]\n+            tx = np.random.uniform(-self.height_shift_range, self.height_shift_range) * x.shape[img_row_axis]\n         else:\n             tx = 0\n \n         if self.width_shift_range:\n-            ty = np.random.uniform(-self.width_shift_range, self.width_shift_range) * x.shape[img_col_index]\n+            ty = np.random.uniform(-self.width_shift_range, self.width_shift_range) * x.shape[img_col_axis]\n         else:\n             ty = 0\n \n@@ -396,29 +529,30 @@ class ImageDataGenerator(object):\n                                 [0, zy, 0],\n                                 [0, 0, 1]])\n \n-        transform_matrix = np.dot(np.dot(np.dot(rotation_matrix, translation_matrix), shear_matrix), zoom_matrix)\n+        transform_matrix = np.dot(np.dot(np.dot(rotation_matrix,\n+                                                translation_matrix),\n+                                         shear_matrix),\n+                                  zoom_matrix)\n \n-        h, w = x.shape[img_row_index], x.shape[img_col_index]\n+        h, w = x.shape[img_row_axis], x.shape[img_col_axis]\n         transform_matrix = transform_matrix_offset_center(transform_matrix, h, w)\n-        x = apply_transform(x, transform_matrix, img_channel_index,\n+        x = apply_transform(x, transform_matrix, img_channel_axis,\n                             fill_mode=self.fill_mode, cval=self.cval)\n         if self.channel_shift_range != 0:\n-            x = random_channel_shift(x, self.channel_shift_range, img_channel_index)\n-\n+            x = random_channel_shift(x,\n+                                     self.channel_shift_range,\n+                                     img_channel_axis)\n         if self.horizontal_flip:\n             if np.random.random() < 0.5:\n-                x = flip_axis(x, img_col_index)\n+                x = flip_axis(x, img_col_axis)\n \n         if self.vertical_flip:\n             if np.random.random() < 0.5:\n-                x = flip_axis(x, img_row_index)\n+                x = flip_axis(x, img_row_axis)\n \n-        # TODO:\n-        # channel-wise normalization\n-        # barrel/fisheye\n         return x\n \n-    def fit(self, X,\n+    def fit(self, x,\n             augment=False,\n             rounds=1,\n             seed=None):\n@@ -426,7 +560,7 @@ class ImageDataGenerator(object):\n         and zca_whitening.\n \n         # Arguments\n-            X: Numpy array, the data to fit on. Should have rank 4.\n+            x: Numpy array, the data to fit on. Should have rank 4.\n                 In case of grayscale data,\n                 the channels axis should have value 1, and in case\n                 of RGB data, it should have value 3.\n@@ -434,83 +568,86 @@ class ImageDataGenerator(object):\n             rounds: If `augment`,\n                 how many augmentation passes to do over the data\n             seed: random seed.\n+\n+        # Raises\n+            ValueError: in case of invalid input `x`.\n         \"\"\"\n-        X = np.asarray(X)\n-        if X.ndim != 4:\n+        x = np.asarray(x)\n+        if x.ndim != 4:\n             raise ValueError('Input to `.fit()` should have rank 4. '\n-                             'Got array with shape: ' + str(X.shape))\n-        if X.shape[self.channel_index] not in {1, 3, 4}:\n+                             'Got array with shape: ' + str(x.shape))\n+        if x.shape[self.channel_axis] not in {1, 3, 4}:\n             raise ValueError(\n                 'Expected input to be images (as Numpy array) '\n                 'following the dimension ordering convention \"' + self.dim_ordering + '\" '\n-                '(channels on axis ' + str(self.channel_index) + '), i.e. expected '\n-                'either 1, 3 or 4 channels on axis ' + str(self.channel_index) + '. '\n-                'However, it was passed an array with shape ' + str(X.shape) +\n-                ' (' + str(X.shape[self.channel_index]) + ' channels).')\n+                '(channels on axis ' + str(self.channel_axis) + '), i.e. expected '\n+                'either 1, 3 or 4 channels on axis ' + str(self.channel_axis) + '. '\n+                'However, it was passed an array with shape ' + str(x.shape) +\n+                ' (' + str(x.shape[self.channel_axis]) + ' channels).')\n \n         if seed is not None:\n             np.random.seed(seed)\n \n-        X = np.copy(X)\n+        x = np.copy(x)\n         if augment:\n-            aX = np.zeros(tuple([rounds * X.shape[0]] + list(X.shape)[1:]))\n+            ax = np.zeros(tuple([rounds * x.shape[0]] + list(x.shape)[1:]))\n             for r in range(rounds):\n-                for i in range(X.shape[0]):\n-                    aX[i + r * X.shape[0]] = self.random_transform(X[i])\n-            X = aX\n+                for i in range(x.shape[0]):\n+                    ax[i + r * x.shape[0]] = self.random_transform(x[i])\n+            x = ax\n \n         if self.featurewise_center:\n-            self.mean = np.mean(X, axis=(0, self.row_index, self.col_index))\n+            self.mean = np.mean(x, axis=(0, self.row_axis, self.col_axis))\n             broadcast_shape = [1, 1, 1]\n-            broadcast_shape[self.channel_index - 1] = X.shape[self.channel_index]\n+            broadcast_shape[self.channel_axis - 1] = x.shape[self.channel_axis]\n             self.mean = np.reshape(self.mean, broadcast_shape)\n-            X -= self.mean\n+            x -= self.mean\n \n         if self.featurewise_std_normalization:\n-            self.std = np.std(X, axis=(0, self.row_index, self.col_index))\n+            self.std = np.std(x, axis=(0, self.row_axis, self.col_axis))\n             broadcast_shape = [1, 1, 1]\n-            broadcast_shape[self.channel_index - 1] = X.shape[self.channel_index]\n+            broadcast_shape[self.channel_axis - 1] = x.shape[self.channel_axis]\n             self.std = np.reshape(self.std, broadcast_shape)\n-            X /= (self.std + K.epsilon())\n+            x /= (self.std + K.epsilon())\n \n         if self.zca_whitening:\n-            flatX = np.reshape(X, (X.shape[0], X.shape[1] * X.shape[2] * X.shape[3]))\n-            sigma = np.dot(flatX.T, flatX) / flatX.shape[0]\n-            U, S, V = linalg.svd(sigma)\n-            self.principal_components = np.dot(np.dot(U, np.diag(1. / np.sqrt(S + 10e-7))), U.T)\n+            flat_x = np.reshape(x, (x.shape[0], x.shape[1] * x.shape[2] * x.shape[3]))\n+            sigma = np.dot(flat_x.T, flat_x) / flat_x.shape[0]\n+            u, s, v = linalg.svd(sigma)\n+            self.principal_components = np.dot(np.dot(u, np.diag(1. / np.sqrt(s + 10e-7))), u.T)\n \n \n class Iterator(object):\n \n-    def __init__(self, N, batch_size, shuffle, seed):\n-        self.N = N\n+    def __init__(self, n, batch_size, shuffle, seed):\n+        self.n = n\n         self.batch_size = batch_size\n         self.shuffle = shuffle\n         self.batch_index = 0\n         self.total_batches_seen = 0\n         self.lock = threading.Lock()\n-        self.index_generator = self._flow_index(N, batch_size, shuffle, seed)\n+        self.index_generator = self._flow_index(n, batch_size, shuffle, seed)\n \n     def reset(self):\n         self.batch_index = 0\n \n-    def _flow_index(self, N, batch_size=32, shuffle=False, seed=None):\n+    def _flow_index(self, n, batch_size=32, shuffle=False, seed=None):\n         # ensure self.batch_index is 0\n         self.reset()\n         while 1:\n             if seed is not None:\n                 np.random.seed(seed + self.total_batches_seen)\n             if self.batch_index == 0:\n-                index_array = np.arange(N)\n+                index_array = np.arange(n)\n                 if shuffle:\n-                    index_array = np.random.permutation(N)\n+                    index_array = np.random.permutation(n)\n \n-            current_index = (self.batch_index * batch_size) % N\n-            if N >= current_index + batch_size:\n+            current_index = (self.batch_index * batch_size) % n\n+            if n >= current_index + batch_size:\n                 current_batch_size = batch_size\n                 self.batch_index += 1\n             else:\n-                current_batch_size = N - current_index\n+                current_batch_size = n - current_index\n                 self.batch_index = 0\n             self.total_batches_seen += 1\n             yield (index_array[current_index: current_index + current_batch_size],\n@@ -527,29 +664,30 @@ class Iterator(object):\n \n class NumpyArrayIterator(Iterator):\n \n-    def __init__(self, X, y, image_data_generator,\n+    def __init__(self, x, y, image_data_generator,\n                  batch_size=32, shuffle=False, seed=None,\n                  dim_ordering='default',\n                  save_to_dir=None, save_prefix='', save_format='jpeg'):\n-        if y is not None and len(X) != len(y):\n+        if y is not None and len(x) != len(y):\n             raise ValueError('X (images tensor) and y (labels) '\n                              'should have the same length. '\n-                             'Found: X.shape = %s, y.shape = %s' % (np.asarray(X).shape, np.asarray(y).shape))\n+                             'Found: X.shape = %s, y.shape = %s' %\n+                             (np.asarray(x).shape, np.asarray(y).shape))\n         if dim_ordering == 'default':\n             dim_ordering = K.image_dim_ordering()\n-        self.X = np.asarray(X)\n-        if self.X.ndim != 4:\n+        self.x = np.asarray(x)\n+        if self.x.ndim != 4:\n             raise ValueError('Input data in `NumpyArrayIterator` '\n                              'should have rank 4. You passed an array '\n-                             'with shape', self.X.shape)\n+                             'with shape', self.x.shape)\n         channels_axis = 3 if dim_ordering == 'tf' else 1\n-        if self.X.shape[channels_axis] not in {1, 3, 4}:\n+        if self.x.shape[channels_axis] not in {1, 3, 4}:\n             raise ValueError('NumpyArrayIterator is set to use the '\n                              'dimension ordering convention \"' + dim_ordering + '\" '\n                              '(channels on axis ' + str(channels_axis) + '), i.e. expected '\n                              'either 1, 3 or 4 channels on axis ' + str(channels_axis) + '. '\n-                             'However, it was passed an array with shape ' + str(self.X.shape) +\n-                             ' (' + str(self.X.shape[channels_axis]) + ' channels).')\n+                             'However, it was passed an array with shape ' + str(self.x.shape) +\n+                             ' (' + str(self.x.shape[channels_axis]) + ' channels).')\n         if y is not None:\n             self.y = np.asarray(y)\n         else:\n@@ -559,7 +697,7 @@ class NumpyArrayIterator(Iterator):\n         self.save_to_dir = save_to_dir\n         self.save_prefix = save_prefix\n         self.save_format = save_format\n-        super(NumpyArrayIterator, self).__init__(X.shape[0], batch_size, shuffle, seed)\n+        super(NumpyArrayIterator, self).__init__(x.shape[0], batch_size, shuffle, seed)\n \n     def next(self):\n         # for python 2.x.\n@@ -568,10 +706,11 @@ class NumpyArrayIterator(Iterator):\n         # see http://anandology.com/blog/using-iterators-and-generators/\n         with self.lock:\n             index_array, current_index, current_batch_size = next(self.index_generator)\n-        # The transformation of images is not under thread lock so it can be done in parallel\n-        batch_x = np.zeros(tuple([current_batch_size] + list(self.X.shape)[1:]))\n+        # The transformation of images is not under thread lock\n+        # so it can be done in parallel\n+        batch_x = np.zeros(tuple([current_batch_size] + list(self.x.shape)[1:]))\n         for i, j in enumerate(index_array):\n-            x = self.X[j]\n+            x = self.x[j]\n             x = self.image_data_generator.random_transform(x.astype('float32'))\n             x = self.image_data_generator.standardize(x)\n             batch_x[i] = x\n@@ -663,7 +802,7 @@ class DirectoryIterator(Iterator):\n         i = 0\n         for subdir in classes:\n             subpath = os.path.join(directory, subdir)\n-            for root, dirs, files in _recursive_list(subpath):\n+            for root, _, files in _recursive_list(subpath):\n                 for fname in files:\n                     is_valid = False\n                     for extension in white_list_formats:\n@@ -681,7 +820,8 @@ class DirectoryIterator(Iterator):\n     def next(self):\n         with self.lock:\n             index_array, current_index, current_batch_size = next(self.index_generator)\n-        # The transformation of images is not under thread lock so it can be done in parallel\n+        # The transformation of images is not under thread lock\n+        # so it can be done in parallel\n         batch_x = np.zeros((current_batch_size,) + self.image_shape)\n         grayscale = self.color_mode == 'grayscale'\n         # build batch of image data\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
