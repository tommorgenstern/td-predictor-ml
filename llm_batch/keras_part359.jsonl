{"custom_id": "keras#c3370abc94e0d2699a3f40d7330920292b259071", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 7 | Methods Changed: 5 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 30 | Churn Cumulative: 9115 | Contributors (this commit): 18 | Commits (past 90d): 23 | Contributors (cumulative): 24 | DMM Complexity: 0.7777777777777778\n\nDIFF:\n@@ -337,7 +337,8 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n             (isinstance(trainable, (tf.Tensor, tf.Variable)) and\n              trainable.dtype is tf.bool)):\n       raise TypeError(\n-          f'Expected trainable argument to be a boolean, but got: {trainable}')\n+          'Expected `trainable` argument to be a boolean, '\n+          f'but got: {trainable}')\n     self._trainable = trainable\n     # A stateful layer is a layer whose updates are run during inference too,\n     # for instance stateful RNNs.\n@@ -409,6 +410,9 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     # Whether the `call` method can be used to build a TF graph without issues.\n     # This attribute has no effect if the model is created using the Functional\n     # API. Instead, `model.dynamic` is determined based on the internal layers.\n+    if not isinstance(dynamic, bool):\n+      raise TypeError(\n+          f'Expected `dynamic` argument to be a boolean, but got: {dynamic}')\n     self._dynamic = dynamic\n \n     # Manage input shape information if passed.\n@@ -2448,13 +2452,16 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     return name_scope\n \n   def _init_set_name(self, name, zero_based=True):\n-    if not name:\n+    if name is None:\n       self._name = backend.unique_object_name(\n           generic_utils.to_snake_case(self.__class__.__name__),\n           zero_based=zero_based)\n-    else:\n+    elif isinstance(name, str):\n       backend.observe_object_name(name)\n       self._name = name\n+    else:\n+      raise TypeError(\n+          f'Expected `name` argument to be a string, but got: {name}')\n \n   def _get_existing_metric(self, name=None):\n     match = [m for m in self._metrics if m.name == name]\n\n@@ -468,10 +468,23 @@ class BaseLayerTest(keras_parameterized.TestCase):\n     base_layer.Layer(trainable=True)\n     base_layer.Layer(trainable=tf.constant(True))\n     base_layer.Layer(trainable=tf.Variable(tf.constant(True)))\n-    with self.assertRaisesRegex(TypeError,\n-                                'Expected trainable argument to be a boolean'):\n+    with self.assertRaisesRegex(\n+        TypeError, 'Expected `trainable` argument to be a boolean'):\n       base_layer.Layer(trainable=0)\n \n+  def test_exception_if_dynamic_not_boolean(self):\n+    base_layer.Layer(dynamic=True)\n+    with self.assertRaisesRegex(TypeError,\n+                                'Expected `dynamic` argument to be a boolean'):\n+      base_layer.Layer(dynamic=0)\n+\n+  def test_exception_if_name_not_string_or_none(self):\n+    base_layer.Layer(name=None)\n+    base_layer.Layer(name='layer_name')\n+    with self.assertRaisesRegex(TypeError,\n+                                'Expected `name` argument to be a string'):\n+      base_layer.Layer(name=0)\n+\n   @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n   def test_layer_names(self):\n     inputs = input_layer.Input(shape=[2])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#32febb6cdebe166fc70ad72f2da37607c13bb11a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 54 | Files Changed: 4 | Hunks: 12 | Methods Changed: 4 | Complexity Δ (Sum/Max): -5/0 | Churn Δ: 71 | Churn Cumulative: 20094 | Contributors (this commit): 107 | Commits (past 90d): 42 | Contributors (cumulative): 119 | DMM Complexity: 0.0\n\nDIFF:\n@@ -48,7 +48,7 @@ class Functional(training_lib.Model):\n   than with subclassed `Model`s, specifically:\n \n   - Model cloning (`keras.models.clone`)\n-  - Serialization (`model.get_config()/from_config`, `model.to_json()/to_yaml()`\n+  - Serialization (`model.get_config()/from_config`, `model.to_json()`\n   - Whole-model saving (`model.save()`)\n \n   A `Functional` model can be instantiated by passing two arguments to\n\n@@ -36,11 +36,6 @@ from keras.utils import layer_utils\n from keras.utils import tf_utils\n from tensorflow.python.training.tracking.util import Checkpoint\n \n-try:\n-  import yaml  # pylint:disable=g-import-not-at-top\n-except ImportError:\n-  yaml = None\n-\n \n class NetworkConstructionTest(keras_parameterized.TestCase):\n \n@@ -616,10 +611,6 @@ class NetworkConstructionTest(keras_parameterized.TestCase):\n       json_str = model.to_json()\n       models.model_from_json(json_str)\n \n-      if yaml is not None:\n-        yaml_str = model.to_yaml()\n-        models.model_from_yaml(yaml_str)\n-\n   @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n   def test_invalid_graphs(self):\n     a = layers.Input(shape=(32,), name='input_a')\n@@ -1341,10 +1332,6 @@ class NetworkConstructionTest(keras_parameterized.TestCase):\n     json_str = model.to_json()\n     models.model_from_json(json_str)\n \n-    if yaml is not None:\n-      yaml_str = model.to_yaml()\n-      models.model_from_yaml(yaml_str)\n-\n   def test_subclassed_error_if_init_not_called(self):\n \n     class MyNetwork(training_lib.Model):\n\n@@ -59,11 +59,6 @@ try:\n   import h5py\n except ImportError:\n   h5py = None\n-\n-try:\n-  import yaml\n-except ImportError:\n-  yaml = None\n # pylint: enable=g-import-not-at-top\n \n \n@@ -2421,6 +2416,9 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n   def to_yaml(self, **kwargs):\n     \"\"\"Returns a yaml string containing the network configuration.\n \n+    Note: Since TF 2.6, this method is no longer supported and will raise a\n+    RuntimeError.\n+\n     To load a network from a yaml save file, use\n     `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n \n@@ -2436,12 +2434,12 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         A YAML string.\n \n     Raises:\n-        ImportError: if the `yaml` module is not found.\n+        RuntimeError: announces that the method poses a security risk\n     \"\"\"\n-    if yaml is None:\n-      raise ImportError(\n-          'Requires yaml module installed (`pip install pyyaml`).')\n-    return yaml.dump(self._updated_config(), **kwargs)\n+    raise RuntimeError(\n+        'Method `model.to_yaml()` has been removed due to security risk of '\n+        'arbitrary code execution. Please use `model.to_json()` instead.'\n+    )\n \n   def reset_states(self):\n     for layer in self.layers:\n\n@@ -18,13 +18,6 @@\n from keras.saving.saved_model import json_utils\n from tensorflow.python.util.tf_export import keras_export\n \n-# pylint: disable=g-import-not-at-top\n-try:\n-  import yaml\n-except ImportError:\n-  yaml = None\n-# pylint: enable=g-import-not-at-top\n-\n \n @keras_export('keras.models.model_from_config')\n def model_from_config(config, custom_objects=None):\n@@ -63,17 +56,8 @@ def model_from_config(config, custom_objects=None):\n def model_from_yaml(yaml_string, custom_objects=None):\n   \"\"\"Parses a yaml model configuration file and returns a model instance.\n \n-  Usage:\n-\n-  >>> model = tf.keras.Sequential([\n-  ...     tf.keras.layers.Dense(5, input_shape=(3,)),\n-  ...     tf.keras.layers.Softmax()])\n-  >>> try:\n-  ...   import yaml\n-  ...   config = model.to_yaml()\n-  ...   loaded_model = tf.keras.models.model_from_yaml(config)\n-  ... except ImportError:\n-  ...   pass\n+  Note: Since TF 2.6, this method is no longer supported and will raise a\n+  RuntimeError.\n \n   Args:\n       yaml_string: YAML string or open file encoding a model configuration.\n@@ -85,19 +69,13 @@ def model_from_yaml(yaml_string, custom_objects=None):\n       A Keras model instance (uncompiled).\n \n   Raises:\n-      ImportError: if yaml module is not found.\n+      RuntimeError: announces that the method poses a security risk\n   \"\"\"\n-  if yaml is None:\n-    raise ImportError('Requires yaml module installed (`pip install pyyaml`).')\n-  # The method unsafe_load only exists in PyYAML 5.x+, so which branch of the\n-  # try block is covered by tests depends on the installed version of PyYAML.\n-  try:\n-    # PyYAML 5.x+\n-    config = yaml.unsafe_load(yaml_string)\n-  except AttributeError:\n-    config = yaml.load(yaml_string)\n-  from keras.layers import deserialize  # pylint: disable=g-import-not-at-top\n-  return deserialize(config, custom_objects=custom_objects)\n+  raise RuntimeError(\n+      'Method `model_from_yaml()` has been removed due to security risk of '\n+      'arbitrary code execution. Please use `Model.to_json()` and '\n+      '`model_from_json()` instead.'\n+  )\n \n \n @keras_export('keras.models.model_from_json')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d9abcd788e5419560c4d8bd47b22ec387fe5c9c2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 4 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 23 | Churn Cumulative: 3118 | Contributors (this commit): 7 | Commits (past 90d): 19 | Contributors (cumulative): 11 | DMM Complexity: 0.8125\n\nDIFF:\n@@ -803,8 +803,15 @@ class GeneratorDataAdapter(DataAdapter):\n     # Need to build the Model on concrete input shapes.\n     if model is not None and not model.built:\n       concrete_x, _, _ = unpack_x_y_sample_weight(peek)\n+      try:\n         model.distribute_strategy.run(\n             lambda x: model(x, training=False), args=(concrete_x,))\n+      except NotImplementedError:\n+        # The above call may fail if the model is a container-like class that\n+        # does not implement its own forward pass (e.g. a GAN or VAE where the\n+        # forward pass is handled by subcomponents).\n+        # Such a model does not need to be built.\n+        pass\n \n     self._first_batch_size = int(tf.nest.flatten(peek)[0].shape[0])\n \n\n@@ -725,6 +725,22 @@ class GeneratorDataAdapterTest(DataAdapterTestBase):\n     for i, data in enumerate(adapter.get_dataset()):\n       self.assertEqual(i, data[0].numpy().flatten())\n \n+  def test_model_without_forward_pass(self):\n+\n+    class MyModel(keras.Model):\n+\n+      def train_step(self, data):\n+        return {'loss': 0.}\n+\n+      def test_step(self, data):\n+        return {'loss': 0.}\n+\n+    model = MyModel()\n+    model.compile('rmsprop')\n+    model.fit(self.generator_input, steps_per_epoch=5)\n+    out = model.evaluate(self.generator_input, steps=5)\n+    self.assertEqual(out, 0)\n+\n \n class KerasSequenceAdapterTest(DataAdapterTestBase):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e66bfdd14709fe0b39ee834194130d46c87c77eb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 26 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 26 | Churn Cumulative: 19038 | Contributors (this commit): 77 | Commits (past 90d): 12 | Contributors (cumulative): 77 | DMM Complexity: 1.0\n\nDIFF:\n@@ -16,7 +16,6 @@\n # pylint: disable=g-bad-import-order\n import tensorflow.compat.v2 as tf\n \n-import functools\n from keras import activations\n from keras import backend\n from keras import constraints\n@@ -216,31 +215,6 @@ class Conv(Layer):\n     channel_axis = self._get_channel_axis()\n     self.input_spec = InputSpec(min_ndim=self.rank + 2,\n                                 axes={channel_axis: input_channel})\n-\n-    # This code is kept for backwards compat, but can be removed after fixing\n-    # the tests listed in b/192260878\n-\n-    # Convert Keras formats to TF native formats.\n-    if self.padding == 'causal':\n-      tf_padding = 'VALID'  # Causal padding handled in `call`.\n-    elif isinstance(self.padding, str):\n-      tf_padding = self.padding.upper()\n-    else:\n-      tf_padding = self.padding\n-    tf_dilations = list(self.dilation_rate)\n-    tf_strides = list(self.strides)\n-\n-    tf_op_name = self.__class__.__name__\n-    if tf_op_name == 'Conv1D':\n-      tf_op_name = 'conv1d'  # Backwards compat.\n-\n-    self._convolution_op = functools.partial(\n-        tf.nn.convolution,\n-        strides=tf_strides,\n-        padding=tf_padding,\n-        dilations=tf_dilations,\n-        data_format=self._tf_data_format,\n-        name=tf_op_name)\n     self.built = True\n \n   def convolution_op(self, inputs, kernel):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2559e1576375357dfd12ce81ca6c8af113c6ad3e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 8 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 28 | Churn Cumulative: 858 | Contributors (this commit): 7 | Commits (past 90d): 2 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -42,15 +42,15 @@ class InputLayer(base_layer.Layer):\n   or create a placeholder tensor (pass arguments `input_shape`, and\n   optionally, `dtype`).\n \n-  It is generally recommend to use the functional layer API via `Input`,\n+  It is generally recommend to use the Keras Functional model via `Input`,\n   (which creates an `InputLayer`) without directly using `InputLayer`.\n \n-  When using InputLayer with Keras Sequential model, it can be skipped by\n-  moving the input_shape parameter to the first layer after the InputLayer.\n+  When using `InputLayer` with the Keras Sequential model, it can be skipped by\n+  moving the `input_shape` parameter to the first layer after the `InputLayer`.\n \n-  This class can create placeholders for tf.Tensors, tf.SparseTensors, and\n-  tf.RaggedTensors by choosing 'sparse=True' or 'ragged=True'. Note that\n-  'sparse' and 'ragged' can't be configured to True at same time.\n+  This class can create placeholders for `tf.Tensors`, `tf.SparseTensors`, and\n+  `tf.RaggedTensors` by choosing `sparse=True` or `ragged=True`. Note that\n+  `sparse` and `ragged` can't be configured to `True` at the same time.\n   Usage:\n \n   ```python\n@@ -74,22 +74,22 @@ class InputLayer(base_layer.Layer):\n   Args:\n       input_shape: Shape tuple (not including the batch axis), or `TensorShape`\n         instance (not including the batch axis).\n-      batch_size: Optional input batch size (integer or None).\n+      batch_size: Optional input batch size (integer or `None`).\n       dtype: Optional datatype of the input. When not provided, the Keras\n-          default float type will be used.\n+          default `float` type will be used.\n       input_tensor: Optional tensor to use as layer input. If set, the layer\n           will use the `tf.TypeSpec` of this tensor rather\n           than creating a new placeholder tensor.\n       sparse: Boolean, whether the placeholder created is meant to be sparse.\n-          Default to False.\n+          Default to `False`.\n       ragged: Boolean, whether the placeholder created is meant to be ragged.\n-          In this case, values of 'None' in the 'shape' argument represent\n-          ragged dimensions. For more information about RaggedTensors, see\n-          [this guide](https://www.tensorflow.org/guide/ragged_tensors).\n-          Default to False.\n+          In this case, values of `None` in the `shape` argument represent\n+          ragged dimensions. For more information about `tf.RaggedTensor`, see\n+          [this guide](https://www.tensorflow.org/guide/ragged_tensor).\n+          Default to `False`.\n       type_spec: A `tf.TypeSpec` object to create Input from. This `tf.TypeSpec`\n           represents the entire batch. When provided, all other args except\n-          name must be None.\n+          name must be `None`.\n       name: Optional name of the layer (string).\n   \"\"\"\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d4dc8979d5de574eb2b840a0fbe57cfd5a997ecf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 41 | Lines Deleted: 15 | Files Changed: 2 | Hunks: 9 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/1 | Churn Δ: 56 | Churn Cumulative: 4313 | Contributors (this commit): 5 | Commits (past 90d): 12 | Contributors (cumulative): 10 | DMM Complexity: 0.6428571428571429\n\nDIFF:\n@@ -1138,13 +1138,7 @@ def reconstruct_from_config(config, custom_objects=None, created_layers=None):\n   # It acts as a queue that maintains any unprocessed\n   # layer call until it becomes possible to process it\n   # (i.e. until the input tensors to the call all exist).\n-  unprocessed_nodes = {}\n-\n-  def add_unprocessed_node(layer, node_data):\n-    if layer not in unprocessed_nodes:\n-      unprocessed_nodes[layer] = [node_data]\n-    else:\n-      unprocessed_nodes[layer].append(node_data)\n+  unprocessed_nodes = collections.defaultdict(list)\n \n   def get_node_index(layer, config_node_index):\n     \"\"\"Returns node index in layer (might differ from config_node_index).\"\"\"\n@@ -1189,6 +1183,10 @@ def reconstruct_from_config(config, custom_objects=None, created_layers=None):\n         layer: layer instance.\n         node_data: Nested structure of `ListWrapper`.\n \n+    Returns:\n+        Whether the node was processed (i.e. the layer was called on the inputs\n+        specified by the node data)\n+\n     Raises:\n         ValueError: In case of improperly formatted `node_data`.\n     \"\"\"\n@@ -1206,8 +1204,7 @@ def reconstruct_from_config(config, custom_objects=None, created_layers=None):\n           kwargs = _deserialize_keras_tensors(kwargs, created_layers)\n         except IndexError:\n           # Happens if keras tensors in kwargs are still unprocessed\n-          add_unprocessed_node(layer, node_data)\n-          return\n+          return False\n       else:\n         raise ValueError('Improperly formatted model config.')\n \n@@ -1216,8 +1213,7 @@ def reconstruct_from_config(config, custom_objects=None, created_layers=None):\n         inbound_node_index = get_node_index(inbound_layer, inbound_node_index)\n \n         if inbound_node_index is None:\n-          add_unprocessed_node(layer, node_data)\n-          return\n+          return False\n         inbound_node = inbound_layer._inbound_nodes[inbound_node_index]\n         input_tensors.append(\n             tf.nest.flatten(inbound_node.outputs)[inbound_tensor_index])\n@@ -1234,9 +1230,11 @@ def reconstruct_from_config(config, custom_objects=None, created_layers=None):\n       output_tensors = layer(input_tensors, **kwargs)\n \n       # Update node index map.\n-      output_index = tf.nest.flatten(output_tensors)[0]._keras_history.node_index\n+      output_index = (tf.nest.flatten(output_tensors)[0].\n+                      _keras_history.node_index)\n       node_index_map[(layer.name, node_count_by_layer[layer])] = output_index\n       node_count_by_layer[layer] += 1\n+    return True\n \n   def process_layer(layer_data):\n     \"\"\"Deserializes a layer, then call it on appropriate inputs.\n@@ -1269,7 +1267,7 @@ def reconstruct_from_config(config, custom_objects=None, created_layers=None):\n       # on the fly because the inbound node may not yet exist,\n       # in case of layer shared at different topological depths\n       # (e.g. a model such as A(B(A(B(x)))))\n-      add_unprocessed_node(layer, node_data)\n+      unprocessed_nodes[layer].append(node_data)\n \n   # First, we create all layers and enqueue nodes to be processed\n   for layer_data in config['layers']:\n@@ -1282,8 +1280,16 @@ def reconstruct_from_config(config, custom_objects=None, created_layers=None):\n     for layer_data in config['layers']:\n       layer = created_layers[layer_data['name']]\n       if layer in unprocessed_nodes:\n-        for node_data in unprocessed_nodes.pop(layer):\n-          process_node(layer, node_data)\n+        layer_nodes = unprocessed_nodes.pop(layer)\n+        while layer_nodes:\n+          node_data = layer_nodes[0]\n+          if process_node(layer, node_data):\n+            layer_nodes.pop(0)\n+          else:\n+            # If a node can't be processed, stop processing the nodes of\n+            # the current layer to maintain node ordering.\n+            unprocessed_nodes[layer] = layer_nodes\n+            break\n \n   input_tensors = []\n   output_tensors = []\n\n@@ -807,6 +807,26 @@ class NetworkConstructionTest(keras_parameterized.TestCase):\n     output_val_2 = m2.predict(x_val)\n     self.assertAllClose(output_val, output_val_2, atol=1e-6)\n \n+  def test_layer_sharing_maintains_node_order(self):\n+    # See https://github.com/keras-team/keras/issues/14838.\n+    inp = input_layer_lib.Input(shape=[5], name='main_input')\n+\n+    zeros = layers.Lambda(tf.zeros_like, name='generate_zeros')(inp)\n+    ones = layers.Lambda(tf.ones_like, name='generate_ones')(inp)\n+\n+    shared_layer = layers.Layer(name='shared')\n+\n+    ones_result = shared_layer(ones)\n+    zeros_result = shared_layer(zeros)\n+    zeros_result = layers.Layer(name='blank')(zeros_result)\n+\n+    m = training_lib.Model(\n+        inputs=[inp], outputs=[zeros_result, ones_result])\n+    m2 = models.Model.from_config(m.get_config())\n+    self.assertAllClose(\n+        m2.predict_on_batch(tf.zeros([1, 5])),\n+        m.predict_on_batch(tf.zeros([1, 5])))\n+\n   @combinations.generate(combinations.keras_mode_combinations())\n   def test_explicit_training_argument(self):\n     a = layers.Input(shape=(2,))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7d4c5572fa3a9fc2542a1314d06c555f67575cb0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 104 | Lines Deleted: 19 | Files Changed: 2 | Hunks: 16 | Methods Changed: 10 | Complexity Δ (Sum/Max): 14/14 | Churn Δ: 123 | Churn Cumulative: 9572 | Contributors (this commit): 24 | Commits (past 90d): 16 | Contributors (cumulative): 27 | DMM Complexity: 0.9565217391304348\n\nDIFF:\n@@ -72,7 +72,7 @@ def all_combinations():\n           combinations.mirrored_strategy_with_gpu_and_cpu,\n           combinations.mirrored_strategy_with_two_gpus\n       ],\n-      mode=[\"graph\"])\n+      mode=[\"graph\", \"eager\"])\n \n \n def tpu_combinations():\n@@ -187,6 +187,78 @@ class KerasMetricsTest(tf.test.TestCase, parameterized.TestCase):\n     self.assertEqual(layer.sum_var.read_value().numpy(),\n                      1.0 * distribution.num_replicas_in_sync)\n \n+  @combinations.generate(all_combinations())\n+  def test_precision(self, distribution):\n+    # True positive is 2, false positive 1, precision is 2/3 = 0.6666667\n+    label_prediction = ([0, 1, 1, 1], [1, 0, 1, 1])\n+    with distribution.scope():\n+      precision = metrics.Precision()\n+      self.evaluate([v.initializer for v in precision.variables])\n+      updates = distribution.run(precision, args=label_prediction)\n+      self.evaluate(updates)\n+    self.assertAllClose(precision.result(), 0.6666667)\n+\n+  @combinations.generate(all_combinations())\n+  def test_recall(self, distribution):\n+    # True positive is 2, false negative 1, precision is 2/3 = 0.6666667\n+    label_prediction = ([0, 1, 1, 1], [1, 0, 1, 1])\n+    with distribution.scope():\n+      recall = metrics.Recall()\n+      self.evaluate([v.initializer for v in recall.variables])\n+      updates = distribution.run(recall, args=label_prediction)\n+      self.evaluate(updates)\n+    self.assertAllClose(recall.result(), 0.6666667)\n+\n+  @combinations.generate(all_combinations())\n+  def test_SensitivityAtSpecificity(self, distribution):\n+    label_prediction = ([0, 0, 0, 1, 1], [0, 0.3, 0.8, 0.3, 0.8])\n+    with distribution.scope():\n+      metric = metrics.SensitivityAtSpecificity(0.5)\n+      self.evaluate([v.initializer for v in metric.variables])\n+      updates = distribution.run(metric, args=label_prediction)\n+      self.evaluate(updates)\n+    self.assertAllClose(metric.result(), 0.5)\n+\n+  @combinations.generate(all_combinations())\n+  def test_SpecificityAtSensitivity(self, distribution):\n+    label_prediction = ([0, 0, 0, 1, 1], [0, 0.3, 0.8, 0.3, 0.8])\n+    with distribution.scope():\n+      metric = metrics.SpecificityAtSensitivity(0.5)\n+      self.evaluate([v.initializer for v in metric.variables])\n+      updates = distribution.run(metric, args=label_prediction)\n+      self.evaluate(updates)\n+    self.assertAllClose(metric.result(), 0.66666667)\n+\n+  @combinations.generate(all_combinations())\n+  def test_PrecisionAtRecall(self, distribution):\n+    label_prediction = ([0, 0, 0, 1, 1], [0, 0.3, 0.8, 0.3, 0.8])\n+    with distribution.scope():\n+      metric = metrics.PrecisionAtRecall(0.5)\n+      self.evaluate([v.initializer for v in metric.variables])\n+      updates = distribution.run(metric, args=label_prediction)\n+      self.evaluate(updates)\n+    self.assertAllClose(metric.result(), 0.5)\n+\n+  @combinations.generate(all_combinations())\n+  def test_RecallAtPrecision(self, distribution):\n+    label_prediction = ([0, 0, 1, 1], [0, 0.5, 0.3, 0.9])\n+    with distribution.scope():\n+      metric = metrics.RecallAtPrecision(0.8)\n+      self.evaluate([v.initializer for v in metric.variables])\n+      updates = distribution.run(metric, args=label_prediction)\n+      self.evaluate(updates)\n+    self.assertAllClose(metric.result(), 0.5)\n+\n+  @combinations.generate(all_combinations())\n+  def test_auc(self, distribution):\n+    label_prediction = ([0, 0, 1, 1], [0, 0.5, 0.3, 0.9])\n+    with distribution.scope():\n+      metric = metrics.AUC(num_thresholds=3)\n+      self.evaluate([v.initializer for v in metric.variables])\n+      updates = distribution.run(metric, args=label_prediction)\n+      self.evaluate(updates)\n+    self.assertAllClose(metric.result(), 0.75)\n+\n \n if __name__ == \"__main__\":\n   tf.__internal__.distribute.multi_process_runner.test_main()\n\n@@ -1368,8 +1368,9 @@ class Precision(Metric):\n         sample_weight=sample_weight)\n \n   def result(self):\n-    result = tf.math.divide_no_nan(self.true_positives,\n-                                 self.true_positives + self.false_positives)\n+    result = tf.math.divide_no_nan(\n+        self.true_positives,\n+        tf.math.add(self.true_positives, self.false_positives))\n     return result[0] if len(self.thresholds) == 1 else result\n \n   def reset_state(self):\n@@ -1497,8 +1498,9 @@ class Recall(Metric):\n         sample_weight=sample_weight)\n \n   def result(self):\n-    result = tf.math.divide_no_nan(self.true_positives,\n-                                 self.true_positives + self.false_negatives)\n+    result = tf.math.divide_no_nan(\n+        self.true_positives,\n+        tf.math.add(self.true_positives, self.false_negatives))\n     return result[0] if len(self.thresholds) == 1 else result\n \n   def reset_state(self):\n@@ -1707,9 +1709,11 @@ class SensitivityAtSpecificity(SensitivitySpecificityBase):\n \n   def result(self):\n     specificities = tf.math.divide_no_nan(\n-        self.true_negatives, self.true_negatives + self.false_positives)\n+        self.true_negatives,\n+        tf.math.add(self.true_negatives, self.false_positives))\n     sensitivities = tf.math.divide_no_nan(\n-        self.true_positives, self.true_positives + self.false_negatives)\n+        self.true_positives,\n+        tf.math.add(self.true_positives, self.false_negatives))\n     return self._find_max_under_constraint(\n         specificities, sensitivities, tf.greater_equal)\n \n@@ -1801,9 +1805,11 @@ class SpecificityAtSensitivity(SensitivitySpecificityBase):\n \n   def result(self):\n     sensitivities = tf.math.divide_no_nan(\n-        self.true_positives, self.true_positives + self.false_negatives)\n+        self.true_positives,\n+        tf.math.add(self.true_positives, self.false_negatives))\n     specificities = tf.math.divide_no_nan(\n-        self.true_negatives, self.true_negatives + self.false_positives)\n+        self.true_negatives,\n+        tf.math.add(self.true_negatives, self.false_positives))\n     return self._find_max_under_constraint(\n         sensitivities, specificities, tf.greater_equal)\n \n@@ -1887,9 +1893,11 @@ class PrecisionAtRecall(SensitivitySpecificityBase):\n \n   def result(self):\n     recalls = tf.math.divide_no_nan(\n-        self.true_positives, self.true_positives + self.false_negatives)\n+        self.true_positives,\n+        tf.math.add(self.true_positives, self.false_negatives))\n     precisions = tf.math.divide_no_nan(\n-        self.true_positives, self.true_positives + self.false_positives)\n+        self.true_positives,\n+        tf.math.add(self.true_positives, self.false_positives))\n     return self._find_max_under_constraint(\n         recalls, precisions, tf.greater_equal)\n \n@@ -1973,9 +1981,11 @@ class RecallAtPrecision(SensitivitySpecificityBase):\n \n   def result(self):\n     precisions = tf.math.divide_no_nan(\n-        self.true_positives, self.true_positives + self.false_positives)\n+        self.true_positives,\n+        tf.math.add(self.true_positives, self.false_positives))\n     recalls = tf.math.divide_no_nan(\n-        self.true_positives, self.true_positives + self.false_negatives)\n+        self.true_positives,\n+        tf.math.add(self.true_positives, self.false_negatives))\n     return self._find_max_under_constraint(\n         precisions, recalls, tf.greater_equal)\n \n@@ -2353,7 +2363,7 @@ class AUC(Metric):\n     \"\"\"\n     dtp = self.true_positives[:self.num_thresholds -\n                               1] - self.true_positives[1:]\n-    p = self.true_positives + self.false_positives\n+    p = tf.math.add(self.true_positives, self.false_positives)\n     dp = p[:self.num_thresholds - 1] - p[1:]\n     prec_slope = tf.math.divide_no_nan(\n         dtp, tf.maximum(dp, 0), name='prec_slope')\n@@ -2396,16 +2406,19 @@ class AUC(Metric):\n       return self.interpolate_pr_auc()\n \n     # Set `x` and `y` values for the curves based on `curve` config.\n-    recall = tf.math.divide_no_nan(self.true_positives,\n-                                 self.true_positives + self.false_negatives)\n+    recall = tf.math.divide_no_nan(\n+        self.true_positives,\n+        tf.math.add(self.true_positives, self.false_negatives))\n     if self.curve == metrics_utils.AUCCurve.ROC:\n-      fp_rate = tf.math.divide_no_nan(self.false_positives,\n-                                    self.false_positives + self.true_negatives)\n+      fp_rate = tf.math.divide_no_nan(\n+          self.false_positives,\n+          tf.math.add(self.false_positives, self.true_negatives))\n       x = fp_rate\n       y = recall\n     else:  # curve == 'PR'.\n       precision = tf.math.divide_no_nan(\n-          self.true_positives, self.true_positives + self.false_positives)\n+          self.true_positives,\n+          tf.math.add(self.true_positives, self.false_positives))\n       x = recall\n       y = precision\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7b72c7edcc43783b5a5f889d443ae2df30f29800", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 37 | Lines Deleted: 37 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 74 | Churn Cumulative: 3365 | Contributors (this commit): 11 | Commits (past 90d): 8 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -46,44 +46,44 @@ class Sequential(functional.Functional):\n \n   Examples:\n \n-  >>> # Optionally, the first layer can receive an `input_shape` argument:\n-  >>> model = tf.keras.Sequential()\n-  >>> model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n-  >>> # Afterwards, we do automatic shape inference:\n-  >>> model.add(tf.keras.layers.Dense(4))\n-\n-  >>> # This is identical to the following:\n-  >>> model = tf.keras.Sequential()\n-  >>> model.add(tf.keras.Input(shape=(16,)))\n-  >>> model.add(tf.keras.layers.Dense(8))\n-\n-  >>> # Note that you can also omit the `input_shape` argument.\n-  >>> # In that case the model doesn't have any weights until the first call\n-  >>> # to a training/evaluation method (since it isn't yet built):\n-  >>> model = tf.keras.Sequential()\n-  >>> model.add(tf.keras.layers.Dense(8))\n-  >>> model.add(tf.keras.layers.Dense(4))\n-  >>> # model.weights not created yet\n-\n-  >>> # Whereas if you specify the input shape, the model gets built\n-  >>> # continuously as you are adding layers:\n-  >>> model = tf.keras.Sequential()\n-  >>> model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n-  >>> model.add(tf.keras.layers.Dense(4))\n-  >>> len(model.weights)\n-  4\n-\n-  >>> # When using the delayed-build pattern (no input shape specified), you can\n-  >>> # choose to manually build your model by calling\n-  >>> # `build(batch_input_shape)`:\n-  >>> model = tf.keras.Sequential()\n-  >>> model.add(tf.keras.layers.Dense(8))\n-  >>> model.add(tf.keras.layers.Dense(4))\n-  >>> model.build((None, 16))\n-  >>> len(model.weights)\n-  4\n-\n   ```python\n+  # Optionally, the first layer can receive an `input_shape` argument:\n+  model = tf.keras.Sequential()\n+  model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n+  # Afterwards, we do automatic shape inference:\n+  model.add(tf.keras.layers.Dense(4))\n+\n+  # This is identical to the following:\n+  model = tf.keras.Sequential()\n+  model.add(tf.keras.Input(shape=(16,)))\n+  model.add(tf.keras.layers.Dense(8))\n+\n+  # Note that you can also omit the `input_shape` argument.\n+  # In that case the model doesn't have any weights until the first call\n+  # to a training/evaluation method (since it isn't yet built):\n+  model = tf.keras.Sequential()\n+  model.add(tf.keras.layers.Dense(8))\n+  model.add(tf.keras.layers.Dense(4))\n+  # model.weights not created yet\n+\n+  # Whereas if you specify the input shape, the model gets built\n+  # continuously as you are adding layers:\n+  model = tf.keras.Sequential()\n+  model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n+  model.add(tf.keras.layers.Dense(4))\n+  len(model.weights)\n+  4\n+\n+  # When using the delayed-build pattern (no input shape specified), you can\n+  # choose to manually build your model by calling\n+  # `build(batch_input_shape)`:\n+  model = tf.keras.Sequential()\n+  model.add(tf.keras.layers.Dense(8))\n+  model.add(tf.keras.layers.Dense(4))\n+  model.build((None, 16))\n+  len(model.weights)\n+  4\n+\n   # Note that when using the delayed-build pattern (no input shape specified),\n   # the model gets built the first time you call `fit`, `eval`, or `predict`,\n   # or the first time you call the model on some input data.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a92e154baefd11ca6451fd3d921a0eebe0653276", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 27 | Files Changed: 1 | Hunks: 14 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 51 | Churn Cumulative: 655 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -74,14 +74,13 @@ MACs stands for Multiply Adds\n       https://arxiv.org/abs/1801.04381) (CVPR 2018)\n \"\"\"\n \n-import tensorflow.compat.v2 as tf\n-\n from keras import backend\n from keras.applications import imagenet_utils\n from keras.engine import training\n from keras.layers import VersionAwareLayers\n from keras.utils import data_utils\n from keras.utils import layer_utils\n+import tensorflow.compat.v2 as tf\n from tensorflow.python.platform import tf_logging as logging\n from tensorflow.python.util.tf_export import keras_export\n \n@@ -142,26 +141,23 @@ def MobileNetV2(input_shape=None,\n       input_shape will be used if they match, if the shapes\n       do not match then we will throw an error.\n       E.g. `(160, 160, 3)` would be one valid value.\n-    alpha: Float between 0 and 1. controls the width of the network.\n-      This is known as the width multiplier in the MobileNetV2 paper,\n-      but the name is kept for consistency with `applications.MobileNetV1`\n-      model in Keras.\n+    alpha: Float, larger than zero, controls the width of the network. This is\n+      known as the width multiplier in the MobileNetV2 paper, but the name is\n+      kept for consistency with `applications.MobileNetV1` model in Keras.\n       - If `alpha` < 1.0, proportionally decreases the number\n           of filters in each layer.\n       - If `alpha` > 1.0, proportionally increases the number\n           of filters in each layer.\n       - If `alpha` = 1.0, default number of filters from the paper\n           are used at each layer.\n-    include_top: Boolean, whether to include the fully-connected\n-      layer at the top of the network. Defaults to `True`.\n-    weights: String, one of `None` (random initialization),\n-      'imagenet' (pre-training on ImageNet),\n-      or the path to the weights file to be loaded.\n-    input_tensor: Optional Keras tensor (i.e. output of\n-      `layers.Input()`)\n+    include_top: Boolean, whether to include the fully-connected layer at the\n+      top of the network. Defaults to `True`.\n+    weights: String, one of `None` (random initialization), 'imagenet'\n+      (pre-training on ImageNet), or the path to the weights file to be loaded.\n+    input_tensor: Optional Keras tensor (i.e. output of `layers.Input()`)\n       to use as image input for the model.\n-    pooling: String, optional pooling mode for feature extraction\n-      when `include_top` is `False`.\n+    pooling: String, optional pooling mode for feature extraction when\n+      `include_top` is `False`.\n       - `None` means that the output of the model\n           will be the 4D tensor output of the\n           last convolutional block.\n@@ -172,9 +168,9 @@ def MobileNetV2(input_shape=None,\n           2D tensor.\n       - `max` means that global max pooling will\n           be applied.\n-    classes: Integer, optional number of classes to classify images\n-      into, only to be specified if `include_top` is True, and\n-      if no `weights` argument is specified.\n+    classes: Optional integer number of classes to classify images into, only to\n+      be specified if `include_top` is True, and if no `weights` argument is\n+      specified.\n     classifier_activation: A `str` or callable. The activation function to use\n       on the \"top\" layer. Ignored unless `include_top=True`. Set\n       `classifier_activation=None` to return the logits of the \"top\" layer.\n@@ -229,7 +225,7 @@ def MobileNetV2(input_shape=None,\n       raise ValueError('input_tensor specified: ', input_tensor,\n                        'is not a keras tensor')\n \n-  # If input_shape is None, infer shape from input_tensor\n+  # If input_shape is None, infer shape from input_tensor.\n   if input_shape is None and input_tensor is not None:\n \n     try:\n@@ -257,7 +253,7 @@ def MobileNetV2(input_shape=None,\n   elif input_shape is None:\n     default_size = 224\n \n-  # If input_shape is not None, assume default size\n+  # If input_shape is not None, assume default size.\n   else:\n     if backend.image_data_format() == 'channels_first':\n       rows = input_shape[1]\n@@ -364,8 +360,8 @@ def MobileNetV2(input_shape=None,\n       x, filters=320, alpha=alpha, stride=1, expansion=6, block_id=16)\n \n   # no alpha applied to last conv as stated in the paper:\n-  # if the width multiplier is greater than 1 we\n-  # increase the number of output channels\n+  # if the width multiplier is greater than 1 we increase the number of output\n+  # channels.\n   if alpha > 1.0:\n     last_block_filters = _make_divisible(1280 * alpha, 8)\n   else:\n@@ -391,8 +387,8 @@ def MobileNetV2(input_shape=None,\n     elif pooling == 'max':\n       x = layers.GlobalMaxPooling2D()(x)\n \n-  # Ensure that the model takes into account\n-  # any potential predecessors of `input_tensor`.\n+  # Ensure that the model takes into account any potential predecessors of\n+  # `input_tensor`.\n   if input_tensor is not None:\n     inputs = layer_utils.get_source_inputs(input_tensor)\n   else:\n@@ -428,12 +424,13 @@ def _inverted_res_block(inputs, expansion, stride, alpha, filters, block_id):\n \n   in_channels = backend.int_shape(inputs)[channel_axis]\n   pointwise_conv_filters = int(filters * alpha)\n+  # Ensure the number of filters on the last 1x1 convolution is divisible by 8.\n   pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\n   x = inputs\n   prefix = 'block_{}_'.format(block_id)\n \n   if block_id:\n-    # Expand\n+    # Expand with a pointwise 1x1 convolution.\n     x = layers.Conv2D(\n         expansion * in_channels,\n         kernel_size=1,\n@@ -452,7 +449,7 @@ def _inverted_res_block(inputs, expansion, stride, alpha, filters, block_id):\n   else:\n     prefix = 'expanded_conv_'\n \n-  # Depthwise\n+  # Depthwise 3x3 convolution.\n   if stride == 2:\n     x = layers.ZeroPadding2D(\n         padding=imagenet_utils.correct_pad(x, 3),\n@@ -474,7 +471,7 @@ def _inverted_res_block(inputs, expansion, stride, alpha, filters, block_id):\n \n   x = layers.ReLU(6., name=prefix + 'depthwise_relu')(x)\n \n-  # Project\n+  # Project wiht a pointwise 1x1 convolution.\n   x = layers.Conv2D(\n       pointwise_filters,\n       kernel_size=1,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c09e753f26afc7ec85a5213df5c2ea52a4e63da2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 3369 | Contributors (this commit): 11 | Commits (past 90d): 9 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -72,7 +72,7 @@ class Sequential(functional.Functional):\n   model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n   model.add(tf.keras.layers.Dense(4))\n   len(model.weights)\n-  4\n+  # Returns \"4\"\n \n   # When using the delayed-build pattern (no input shape specified), you can\n   # choose to manually build your model by calling\n@@ -82,7 +82,7 @@ class Sequential(functional.Functional):\n   model.add(tf.keras.layers.Dense(4))\n   model.build((None, 16))\n   len(model.weights)\n-  4\n+  # Returns \"4\"\n \n   # Note that when using the delayed-build pattern (no input shape specified),\n   # the model gets built the first time you call `fit`, `eval`, or `predict`,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#45e4287fa37f077399abb2552286a69712d168ee", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 39 | Lines Deleted: 28 | Files Changed: 1 | Hunks: 20 | Methods Changed: 12 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 67 | Churn Cumulative: 7190 | Contributors (this commit): 94 | Commits (past 90d): 8 | Contributors (cumulative): 94 | DMM Complexity: 0.36363636363636365\n\nDIFF:\n@@ -294,7 +294,8 @@ class CallbackList:\n     elif hook == 'end':\n       self._call_batch_end_hook(mode, batch, logs)\n     else:\n-      raise ValueError('Unrecognized hook: {}'.format(hook))\n+      raise ValueError(\n+          f'Unrecognized hook: {hook}. Expected values are [\"begin\", \"end\"]')\n \n   def _call_batch_begin_hook(self, mode, batch, logs):\n     \"\"\"Helper function for `on_*_batch_begin` methods.\"\"\"\n@@ -562,9 +563,10 @@ class CallbackList:\n             cb._implements_predict_batch_hooks()):\n           unsupported_callbacks.append(cb)\n       if unsupported_callbacks:\n-        raise ValueError('Batch-level `Callback`s are not supported with '\n+        raise ValueError(\n+            'Batch-level `Callback`s are not supported with '\n             '`ParameterServerStrategy`. Found unsupported '\n-                         'callbacks: {}'.format(unsupported_callbacks))\n+            f'callbacks: {unsupported_callbacks}')\n     # pylint: enable=protected-access\n \n \n@@ -971,7 +973,9 @@ class ProgbarLogger(Callback):\n     elif count_mode == 'steps':\n       self.use_steps = True\n     else:\n-      raise ValueError('Unknown `count_mode`: ' + str(count_mode))\n+      raise ValueError(\n+          f'Unknown `count_mode`: {count_mode}. '\n+          'Expected values are [\"samples\", \"steps\"]')\n     # Defaults to all Model's metrics except for loss.\n     self.stateful_metrics = set(stateful_metrics) if stateful_metrics else set()\n \n@@ -1280,14 +1284,16 @@ class ModelCheckpoint(Callback):\n           options, tf.train.CheckpointOptions):\n         self._options = options or tf.train.CheckpointOptions()\n       else:\n-        raise TypeError('If save_weights_only is True, then `options` must be '\n-                        'either None or a tf.train.CheckpointOptions')\n+        raise TypeError(\n+            'If save_weights_only is True, then `options` must be '\n+            f'either None or a tf.train.CheckpointOptions. Got {options}.')\n     else:\n       if options is None or isinstance(options, tf.saved_model.SaveOptions):\n         self._options = options or tf.saved_model.SaveOptions()\n       else:\n-        raise TypeError('If save_weights_only is False, then `options` must be'\n-                        'either None or a tf.saved_model.SaveOptions')\n+        raise TypeError(\n+            'If save_weights_only is False, then `options` must be '\n+            f'either None or a tf.saved_model.SaveOptions. Got {options}.')\n \n     # Deprecated field `load_weights_on_restart` is for loading the checkpoint\n     # file from `filepath` at the start of `model.fit()`\n@@ -1329,7 +1335,9 @@ class ModelCheckpoint(Callback):\n         self.best = np.Inf\n \n     if self.save_freq != 'epoch' and not isinstance(self.save_freq, int):\n-      raise ValueError('Unrecognized save_freq: {}'.format(self.save_freq))\n+      raise ValueError(\n+          f'Unrecognized save_freq: {self.save_freq}. '\n+          'Expected save_freq are \"epoch\" or integer')\n \n     # Only the chief worker writes model checkpoints, but all workers\n     # restore checkpoint at on_train_begin().\n@@ -1347,8 +1355,8 @@ class ModelCheckpoint(Callback):\n           # name matching the pattern.\n           self.model.load_weights(filepath_to_load)\n         except (IOError, ValueError) as e:\n-          raise ValueError('Error loading file from {}. Reason: {}'.format(\n-              filepath_to_load, e))\n+          raise ValueError(\n+              f'Error loading file from {filepath_to_load}. Reason: {e}')\n \n   def _implements_train_batch_hooks(self):\n     # Only call batch hooks when saving on batch\n@@ -1437,13 +1445,13 @@ class ModelCheckpoint(Callback):\n       except IsADirectoryError as e:  # h5py 3.x\n         raise IOError('Please specify a non-directory filepath for '\n                       'ModelCheckpoint. Filepath used is an existing '\n-                      'directory: {}'.format(filepath))\n+                      f'directory: {filepath}')\n       except IOError as e:  # h5py 2.x\n         # `e.errno` appears to be `None` so checking the content of `e.args[0]`.\n         if 'is a directory' in str(e.args[0]).lower():\n           raise IOError('Please specify a non-directory filepath for '\n                         'ModelCheckpoint. Filepath used is an existing '\n-                        'directory: {}'.format(filepath))\n+                        f'directory: f{filepath}')\n         # Re-throw the error for any other causes.\n         raise e\n \n@@ -1460,8 +1468,9 @@ class ModelCheckpoint(Callback):\n         file_path = self.filepath.format(\n             epoch=epoch + 1, batch=batch + 1, **logs)\n     except KeyError as e:\n-      raise KeyError('Failed to format this callback filepath: \"{}\". '\n-                     'Reason: {}'.format(self.filepath, e))\n+      raise KeyError(\n+          f'Failed to format this callback filepath: \"{self.filepath}\". '\n+          f'Reason: {e}')\n     self._write_filepath = distributed_file_utils.write_filepath(\n         file_path, self.model.distribute_strategy)\n     return self._write_filepath\n@@ -1665,10 +1674,9 @@ class BackupAndRestore(Callback):\n     if self.model._distribution_strategy and not isinstance(\n         self.model.distribute_strategy, self._supported_strategies):\n       raise NotImplementedError(\n-          '%s is not supported yet. '\n+          f'{type(self.model.distribute_strategy)} is not supported yet. '\n           'Currently BackupAndRestore callback only supports empty strategy, '\n-          'MirroredStrategy, MultiWorkerMirroredStrategy and TPUStrategy.' %\n-          type(self.model.distribute_strategy).__name__)\n+          'MirroredStrategy, MultiWorkerMirroredStrategy and TPUStrategy.')\n     self.model._training_state = (\n         worker_training_state.WorkerTrainingState(self.model, self.backup_dir))\n     self._training_state = self.model._training_state\n@@ -1950,9 +1958,10 @@ class LearningRateScheduler(Callback):\n       lr = self.schedule(epoch)\n     if not isinstance(lr, (tf.Tensor, float, np.float32, np.float64)):\n       raise ValueError('The output of the \"schedule\" function '\n-                       'should be float.')\n+                       f'should be float. Got: {lr}')\n     if isinstance(lr, tf.Tensor) and not lr.dtype.is_floating:\n-      raise ValueError('The dtype of Tensor should be float')\n+      raise ValueError(\n+          f'The dtype of `lr` Tensor should be float. Got: {lr.dtype}')\n     backend.set_value(self.model.optimizer.lr, backend.get_value(lr))\n     if self.verbose > 0:\n       print('\\nEpoch %05d: LearningRateScheduler setting learning '\n@@ -2193,14 +2202,15 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n                       '2.0. Instead, all `Embedding` variables will be '\n                       'visualized.')\n \n-    unrecognized_kwargs = set(kwargs.keys()) - {\n-        'write_grads', 'embeddings_layer_names', 'embeddings_data', 'batch_size'\n-    }\n+    supported_kwargs = {'write_grads', 'embeddings_layer_names',\n+                        'embeddings_data', 'batch_size'}\n+    unrecognized_kwargs = set(kwargs.keys()) - supported_kwargs\n \n     # Only allow kwargs that were supported in V1.\n     if unrecognized_kwargs:\n-      raise ValueError('Unrecognized arguments in `TensorBoard` '\n-                       'Callback: ' + str(unrecognized_kwargs))\n+      raise ValueError(\n+          'Unrecognized arguments in `TensorBoard` Callback: '\n+          f'{unrecognized_kwargs}. Supported kwargs are: {supported_kwargs}')\n \n   def set_model(self, model):\n     \"\"\"Sets Keras model and writes graph if specified.\"\"\"\n@@ -2291,7 +2301,7 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n                                                    str):\n       raise ValueError('Unrecognized `Embedding` layer names passed to '\n                        '`keras.callbacks.TensorBoard` `embeddings_metadata` '\n-                       'argument: ' + str(self.embeddings_metadata.keys()))\n+                       f'argument: {self.embeddings_metadata.keys()}')\n \n     config_pbtxt = text_format.MessageToString(config)\n     path = os.path.join(self._log_write_dir, 'projector_config.pbtxt')\n@@ -2345,7 +2355,7 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n     profile_batch_error_message = (\n         'profile_batch must be a non-negative integer or 2-tuple of positive '\n         'integers. A pair of positive integers signifies a range of batches '\n-        'to profile. Found: {}'.format(profile_batch))\n+        f'to profile. Found: {profile_batch}')\n \n     # Support legacy way of specifying \"start,stop\" or \"start\" as str.\n     if isinstance(profile_batch, str):\n@@ -2629,7 +2639,8 @@ class ReduceLROnPlateau(Callback):\n \n     self.monitor = monitor\n     if factor >= 1.0:\n-      raise ValueError('ReduceLROnPlateau ' 'does not support a factor >= 1.0.')\n+      raise ValueError(\n+          f'ReduceLROnPlateau does not support a factor >= 1.0. Got {factor}')\n     if 'epsilon' in kwargs:\n       min_delta = kwargs.pop('epsilon')\n       logging.warning('`epsilon` argument is deprecated and '\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
