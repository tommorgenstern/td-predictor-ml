{"custom_id": "keras#8950981b787b8e40824f2c100b6daab0be9872a9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 7 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 367 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -123,11 +123,12 @@ def inject_argument_info_in_traceback(fn, object_name=None):\n           message = e.args[0]\n         else:\n           message = ''\n+        display_name = f'{object_name if object_name else fn.__name__}'\n         message = (\n-            'Exception encountered when calling '\n-            f'{object_name if object_name else fn.__name__}.\\n\\n'\n+            f'Exception encountered when calling {display_name}.\\n\\n'\n             f'{message}\\n\\n'\n-            f'Call arguments received:\\n{arguments_context}')\n+            f'Call arguments received by {display_name}:\\n'\n+            f'{arguments_context}')\n \n         # Reraise exception, with added context\n         if isinstance(e, tf.errors.OpError):\n\n@@ -31,7 +31,7 @@ class TracebackUtilsTest(tf.test.TestCase):\n     self.assertIn('Original message', str(e.exception))\n     self.assertIn('Exception encountered when calling ObjName',\n                   str(e.exception))\n-    self.assertIn('Call arguments received:', str(e.exception))\n+    self.assertIn('Call arguments received', str(e.exception))\n     self.assertIn('arg_1=1', str(e.exception))\n     self.assertIn('arg_2=2', str(e.exception))\n     self.assertIn('keyword_arg_1=3', str(e.exception))\n@@ -49,7 +49,7 @@ class TracebackUtilsTest(tf.test.TestCase):\n \n     with self.assertRaises(ValueError) as e:\n       traceback_utils.inject_argument_info_in_traceback(error_fn)()\n-    self.assertEqual(str(e.exception).count('Call arguments received:'), 0)\n+    self.assertEqual(str(e.exception).count('Call arguments received'), 0)\n \n   def test_info_injection_unbindable(self):\n     def error_fn(arg_1, keyword_arg_1=1):\n@@ -69,7 +69,7 @@ class TracebackUtilsTest(tf.test.TestCase):\n     with self.assertRaises(ValueError) as e:\n       traceback_utils.inject_argument_info_in_traceback(\n           outer_fn)(1)\n-    self.assertEqual(str(e.exception).count('Call arguments received:'), 1)\n+    self.assertEqual(str(e.exception).count('Call arguments received'), 1)\n \n   def test_info_injection_tf_op_error(self):\n     def error_fn(arg_1, keyword_arg_1=1):\n@@ -90,7 +90,7 @@ class LayerCallInfoInjectionTest(tf.test.TestCase):\n       fn()\n     except Exception as e:  # pylint: disable=broad-except\n       # Info should be injected exactly once.\n-      self.assertEqual(str(e).count('Call arguments received:'), 1)  # pylint: disable=g-assert-in-except\n+      self.assertEqual(str(e).count('Call arguments received'), 1)  # pylint: disable=g-assert-in-except\n \n   def test_custom_layer_call_nested(self):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f427e16d9e4a440b5e7e839001255f7cd87127f5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 97 | Lines Deleted: 15 | Files Changed: 8 | Hunks: 29 | Methods Changed: 17 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 112 | Churn Cumulative: 10729 | Contributors (this commit): 39 | Commits (past 90d): 32 | Contributors (cumulative): 63 | DMM Complexity: 1.0\n\nDIFF:\n@@ -40,6 +40,7 @@ from keras.layers import Activation\n from keras.layers import Dense\n from keras.optimizer_v2 import gradient_descent\n from keras.optimizer_v2 import learning_rate_schedule\n+from keras.utils import io_utils\n from keras.utils import np_utils\n from tensorflow.python.platform import tf_logging as logging\n \n@@ -274,6 +275,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(10)\n     expected_log = r'(.*- loss:.*- my_acc:.*)+'\n \n+    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(dataset, epochs=2, steps_per_epoch=10)\n       self.assertRegex(printed.contents(), expected_log)\n@@ -302,6 +304,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     # There are 7 ones in total in `y_train` after two batches.\n     expected_log = r'(.*- loss:.*- my_acc:.*- add_all_ones: 7.0000)+'\n \n+    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model = self._get_model(\n           input_shape=(8,), additional_metrics=[AddAllOnes()])\n@@ -488,6 +491,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(10)\n     expected_log = r'(.*- loss:.*- my_acc:.*)+'\n \n+    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(dataset, epochs=2, steps_per_epoch=10)\n       self.assertRegex(printed.contents(), expected_log)\n@@ -503,6 +507,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     val_dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(10)\n     expected_log = r'(.*5/5.*- loss:.*- my_acc:.*- val_loss:.*- val_my_acc:.*)+'\n \n+    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(training_dataset, epochs=2, validation_data=val_dataset)\n       self.assertRegex(printed.contents(), expected_log)\n@@ -518,6 +523,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n         r'(?s).*1/2.*8/8.*- loss:.*- my_acc:.*- val_loss:.*- val_my_acc:'\n         r'.*2/2.*8/8.*- loss:.*- my_acc:.*- val_loss:.*- val_my_acc:.*')\n \n+    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(x, y, batch_size=10, epochs=2, validation_split=0.2)\n       self.assertRegex(printed.contents(), expected_log)\n@@ -548,6 +554,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n         r'(?s).*1/2.*20/20.*- loss:.*- my_acc:.*- val_loss:.*- val_my_acc:'\n         r'.*2/2.*20/20.*- loss:.*- my_acc:.*- val_loss:.*- val_my_acc:.*')\n \n+    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(\n           x=training, validation_data=validation, epochs=2, steps_per_epoch=20)\n@@ -576,6 +583,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n           output_shapes=([2], [])) \\\n       .batch(2)\n \n+    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(x=training, validation_data=validation)\n \n@@ -1496,6 +1504,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n           keras.callbacks.LearningRateScheduler(\n               lambda x: 1. / (1. + x), verbose=1)\n       ]\n+      io_utils.enable_interactive_logging()\n       with self.captureWritesToStream(sys.stdout) as printed:\n         model.fit(\n             x_train,\n\n@@ -27,6 +27,7 @@ from tensorflow.python.framework import test_util\n from keras import keras_parameterized\n from keras import testing_utils\n from keras.layers import core\n+from keras.utils import io_utils\n \n \n @keras_parameterized.run_with_all_model_types\n@@ -76,6 +77,7 @@ class PrintTrainingInfoTest(keras_parameterized.TestCase,\n         ([1.], [1.])).repeat(50).batch(10)\n \n     mock_stdout = io.StringIO()\n+    io_utils.enable_interactive_logging()\n     with tf.compat.v1.test.mock.patch.object(sys, \"stdout\", mock_stdout):\n       model.fit(dataset, epochs=2, validation_data=val_dataset)\n \n\n@@ -26,6 +26,7 @@ from keras import callbacks\n from keras import keras_parameterized\n from keras import metrics as metrics_module\n from keras import testing_utils\n+from keras.utils import io_utils\n from tensorflow.python.platform import tf_logging as logging\n \n \n@@ -419,6 +420,7 @@ class TestTrainingWithDataset(keras_parameterized.TestCase):\n         tf.data.experimental.UNKNOWN_CARDINALITY)\n \n     batch_counter = BatchCounterCallback()\n+    io_utils.enable_interactive_logging()\n     with CaptureStdout() as capture:\n       history = model.fit(\n           dataset,\n\n@@ -35,6 +35,7 @@ from keras.engine import sequential\n from keras.engine import training as training_module\n from keras.engine import training_utils_v1\n from keras.utils import data_utils\n+from keras.utils import io_utils\n from keras.utils import np_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n@@ -1059,6 +1060,7 @@ class TrainingTest(keras_parameterized.TestCase):\n         RMSPropOptimizer(learning_rate=0.001),\n         loss='binary_crossentropy',\n         run_eagerly=testing_utils.should_run_eagerly())\n+    io_utils.enable_interactive_logging()\n     with tf.compat.v1.test.mock.patch.object(sys, 'stdout', mock_stdout):\n       model.fit(\n           np.ones((10, 10), 'float32'), np.ones((10, 1), 'float32'), epochs=10)\n\n@@ -19,23 +19,64 @@ import os\n import sys\n import threading\n \n-import absl\n+from absl import logging\n+from keras.utils import keras_logging\n+# pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.util.tf_export import keras_export\n+# pylint: enable=g-direct-tensorflow-import\n \n-ABSL_LOGGING = threading.local()\n-ABSL_LOGGING.enable = False\n+INTERACTIVE_LOGGING = threading.local()\n+INTERACTIVE_LOGGING.enable = keras_logging.INTERACTIVE_LOGGING_DEFAULT\n+\n+\n+@keras_export('keras.utils.enable_interactive_logging')\n+def enable_interactive_logging():\n+  \"\"\"Turn on interactive logging.\n+\n+  When interactive logging is enabled, Keras displays logs via stdout.\n+  This provides the best experience when using Keras in an interactive\n+  environment such as a shell or a notebook.\n+  \"\"\"\n+  INTERACTIVE_LOGGING.enable = True\n+\n+\n+@keras_export('keras.utils.disable_interactive_logging')\n+def disable_interactive_logging():\n+  \"\"\"Turn off interactive logging.\n+\n+  When interactive logging is disabled, Keras sends logs to `absl.logging`.\n+  This is the best option when using Keras in a non-interactive\n+  way, such as running a training or inference job on a server.\n+  \"\"\"\n+  INTERACTIVE_LOGGING.enable = False\n+\n+\n+@keras_export('keras.utils.is_interactive_logging_enabled')\n+def is_interactive_logging_enabled():\n+  \"\"\"Check if interactive logging is enabled.\n+\n+  To switch between writing logs to stdout and `absl.logging`, you may use\n+  `keras.utils.enable_interactive_logging()` and\n+  `keras.utils.disable_interactie_logging()`.\n+\n+  Returns:\n+    Boolean (True if interactive logging is enabled and False otherwise).\n+  \"\"\"\n+  return INTERACTIVE_LOGGING.enable\n \n \n def print_msg(message, line_break=True):\n   \"\"\"Print the message to absl logging or stdout.\"\"\"\n-  # Use `getattr` in case `ABSL_LOGGING` does not have the `enable` attribute.\n-  if getattr(ABSL_LOGGING, 'enable', False):\n-    absl.logging.info(message)\n-  else:\n+  # Use `getattr` in case `INTERACTIVE_LOGGING`\n+  # does not have the `enable` attribute.\n+  if INTERACTIVE_LOGGING.enable:\n     if line_break:\n       sys.stdout.write(message + '\\n')\n     else:\n       sys.stdout.write(message)\n     sys.stdout.flush()\n+  else:\n+    logging.info(message)\n \n \n def path_to_string(path):\n\n@@ -14,15 +14,13 @@\n # ==============================================================================\n \"\"\"Tests for io_utils.\"\"\"\n \n-import sys\n-\n-import tensorflow.compat.v2 as tf\n-\n import builtins\n from pathlib import Path\n+import sys\n \n from keras import keras_parameterized\n from keras.utils import io_utils\n+import tensorflow.compat.v2 as tf\n \n \n class TestIOUtils(keras_parameterized.TestCase):\n@@ -60,19 +58,26 @@ class TestIOUtils(keras_parameterized.TestCase):\n     self.assertIs(io_utils.path_to_string(dummy), dummy)\n \n   def test_print_msg(self):\n-    enabled = io_utils.ABSL_LOGGING.enable\n+    enabled = io_utils.is_interactive_logging_enabled()\n+\n+    io_utils.disable_interactive_logging()\n+    self.assertFalse(io_utils.is_interactive_logging_enabled())\n \n-    io_utils.ABSL_LOGGING.enable = True\n     with self.assertLogs(level='INFO') as logged:\n       io_utils.print_msg('Testing Message')\n     self.assertIn('Testing Message', logged.output[0])\n \n-    io_utils.ABSL_LOGGING.enable = False\n+    io_utils.enable_interactive_logging()\n+    self.assertTrue(io_utils.is_interactive_logging_enabled())\n+\n     with self.captureWritesToStream(sys.stdout) as printed:\n       io_utils.print_msg('Testing Message')\n     self.assertEqual('Testing Message\\n', printed.contents())\n \n-    io_utils.ABSL_LOGGING.enable = enabled\n+    if enabled:\n+      io_utils.enable_interactive_logging()\n+    else:\n+      io_utils.disable_interactive_logging()\n \n if __name__ == '__main__':\n   tf.test.main()\n\n@@ -0,0 +1,19 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Flags for logging control.\"\"\"\n+\n+# LINT.IfChange(external_interactive_logging)\n+INTERACTIVE_LOGGING_DEFAULT = True\n+# LINT.ThenChange(../../utils/keras_logging.py:internal_interactive_logging)\n\n@@ -28,6 +28,7 @@ import time\n import timeit\n \n import numpy as np\n+from keras.utils import io_utils\n from keras.utils import layer_utils\n \n \n@@ -81,6 +82,7 @@ class LayerUtilsTest(tf.test.TestCase):\n   def test_print_summary_without_print_fn(self):\n     model = keras.Sequential([\n         keras.layers.Dense(5, input_shape=(10,), name='dense')])\n+    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       layer_utils.print_summary(model)\n     self.assertIn('dense (Dense)', printed.contents())\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6f170814ccc0a242fe12751a9fa8433d75076085", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 20 | Churn Cumulative: 2025 | Contributors (this commit): 4 | Commits (past 90d): 41 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -27,6 +27,7 @@ from keras.optimizer_v2 import utils as optimizer_utils\n import tensorflow.compat.v2 as tf\n # pylint: disable=g-direct-tensorflow-import\n from tensorflow.python.util.tf_export import keras_export\n+from tensorflow.tools.docs import doc_controls\n \n \n class _BaseOptimizer(tf.Module):\n@@ -210,6 +211,20 @@ class _BaseOptimizer(tf.Module):\n                       \"the optimizer with a float `learning_rate` argument.\")\n     self._learning_rate.assign(learning_rate)\n \n+  @property\n+  @doc_controls.do_not_generate_docs\n+  def lr(self):\n+    \"\"\"Alias of `learning_rate()`.\n+\n+    `lr()` is heavily called in workflows using `optimizer_v2.OptimizerV2`,\n+    so we keep it for backward compabitliy.\n+    \"\"\"\n+    return self.learning_rate\n+\n+  @lr.setter\n+  def lr(self, learning_rate):\n+    self.learning_rate = learning_rate\n+\n   def _build_learning_rate(self, learning_rate):\n     if isinstance(learning_rate, learning_rate_schedule.LearningRateSchedule):\n       # Create a variable to hold the current learning rate.\n\n@@ -130,6 +130,9 @@ class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n     self.assertEqual(self.evaluate(optimizer.learning_rate), 1.0)\n     optimizer.learning_rate = 2.0\n     self.assertEqual(self.evaluate(optimizer.learning_rate), 2.0)\n+    # Test the legacy setter.\n+    optimizer.lr = 3.0\n+    self.assertEqual(self.evaluate(optimizer.learning_rate), 3.0)\n \n     lr_schedule = learning_rate_schedule.ExponentialDecay(\n         initial_learning_rate=1e-2, decay_steps=10000, decay_rate=0.9)\n@@ -137,6 +140,8 @@ class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n     self.assertIsInstance(optimizer._learning_rate,\n                           learning_rate_schedule.ExponentialDecay)\n     self.assertEqual(optimizer.learning_rate, 0.01)\n+    # Test the legacy property.\n+    self.assertEqual(optimizer.lr, 0.01)\n \n     x = tf.Variable([1.0, 2.0], dtype=tf.float32)\n     grads = tf.convert_to_tensor([1.0, 2.0])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ecc0bb91f2df38761120dd0cf090a2cc33fa3e28", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 55 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 8 | Methods Changed: 5 | Complexity Δ (Sum/Max): 11/11 | Churn Δ: 57 | Churn Cumulative: 748 | Contributors (this commit): 8 | Commits (past 90d): 5 | Contributors (cumulative): 8 | DMM Complexity: 0.2558139534883721\n\nDIFF:\n@@ -242,6 +242,8 @@ class Attention(BaseDenseAttention):\n       Defaults to `False`.\n     dropout: Float between 0 and 1. Fraction of the units to drop for the\n       attention scores. Defaults to 0.0.\n+    score: One of {'dot', 'concat'}. 'dot' refers to dot multiplication\n+      of query and key. 'concat' refers to hyperbolic tangent of query and key.\n \n   Call Args:\n \n@@ -319,9 +321,14 @@ class Attention(BaseDenseAttention):\n   ```\n   \"\"\"\n \n-  def __init__(self, use_scale=False, **kwargs):\n+  def __init__(self, use_scale=False, score='dot', **kwargs):\n     super(Attention, self).__init__(**kwargs)\n     self.use_scale = use_scale\n+    self.score_type= score\n+    if self.score_type not in ['dot', 'concat']:\n+      logging.warning(f'Score type {self.score_type} is unknown, '\n+                      'fallback to score_type dot.')\n+      self.score_type= 'dot'\n \n   def build(self, input_shape):\n     \"\"\"Creates scale variable if use_scale==True.\"\"\"\n@@ -336,16 +343,27 @@ class Attention(BaseDenseAttention):\n       self.scale = None\n     super(Attention, self).build(input_shape)\n \n-  def _calculate_scores(self, query, key):\n+  def _calculate_scores(self, query, key, score_type):\n     \"\"\"Calculates attention scores as a query-key dot product.\n \n     Args:\n       query: Query tensor of shape `[batch_size, Tq, dim]`.\n       key: Key tensor of shape `[batch_size, Tv, dim]`.\n+      score: One of {'dot', 'concat'}.\n     Returns:\n       Tensor of shape `[batch_size, Tq, Tv]`.\n     \"\"\"\n+    if score_type == 'dot':\n       scores = tf.matmul(query, key, transpose_b=True)\n+    elif score_type == 'concat':\n+      # Reshape tensors to enable broadcasting.\n+      # Reshape into [batch_size, Tq, 1, dim].\n+      q_reshaped = tf.expand_dims(query, axis=-2)\n+      # Reshape into [batch_size, 1, Tv, dim].\n+      k_reshaped = tf.expand_dims(key, axis=-3)\n+      scores = tf.reduce_sum(\n+         tf.tanh(q_reshaped + k_reshaped), axis=-1)\n+\n     if self.scale is not None:\n       scores *= self.scale\n     return scores\n@@ -355,6 +373,41 @@ class Attention(BaseDenseAttention):\n     base_config = super(Attention, self).get_config()\n     return dict(list(base_config.items()) + list(config.items()))\n   \n+  def call(self,\n+           inputs,\n+           mask=None,\n+           training=None,\n+           return_attention_scores=False):\n+    self._validate_call_args(inputs=inputs, mask=mask)\n+    q = inputs[0]\n+    v = inputs[1]\n+    k = inputs[2] if len(inputs) > 2 else v\n+    q_mask = mask[0] if mask else None\n+    v_mask = mask[1] if mask else None\n+    scores = self._calculate_scores(\n+        query=q, key=k, score_type= self.score_type)\n+    if v_mask is not None:\n+      # Mask of shape [batch_size, 1, Tv].\n+      v_mask = tf.expand_dims(v_mask, axis=-2)\n+    if self.causal:\n+      scores_shape = tf.shape(scores)\n+      causal_mask_shape = tf.concat(\n+          [tf.ones_like(scores_shape[:-2]), scores_shape[-2:]],\n+          axis=0)\n+      causal_mask = _lower_triangular_mask(causal_mask_shape)\n+    else:\n+      causal_mask = None\n+    scores_mask = _merge_masks(v_mask, causal_mask)\n+    result, attention_scores = self._apply_scores(\n+        scores=scores, value=v, scores_mask=scores_mask, training=training)\n+    if q_mask is not None:\n+      # Mask of shape [batch_size, Tq, 1].\n+      q_mask = tf.expand_dims(q_mask, axis=-1)\n+      result *= tf.cast(q_mask, dtype=result.dtype)\n+    if return_attention_scores:\n+      return result, attention_scores\n+    return result\n+\n \n @keras_export('keras.layers.AdditiveAttention')\n class AdditiveAttention(BaseDenseAttention):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d74fae551f3017da8a47831ac67dfbc6e3b96a8c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 73 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 73 | Churn Cumulative: 891 | Contributors (this commit): 4 | Commits (past 90d): 1 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -204,6 +204,29 @@ class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n                         dtype=np.float32)\n     self.assertAllClose(expected, actual)\n  \n+  def test_calculate_scores_multi_dim_concat(self):\n+    # Query tensor of shape [1, 2, 4]\n+    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n+    # Key tensor of shape [1, 3, 4]\n+    k = np.array(\n+        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n+        dtype=np.float32)\n+    attention_layer = dense_attention.Attention()\n+    attention_layer.build(input_shape=([1, 2, 4], [1, 3, 4]))\n+    actual = attention_layer._calculate_scores(query=q, key=k, score_type='concat')\n+\n+    # pylint:disable=line-too-long\n+    # expected000 = tanh(1.+1.5) + tanh(1.1+1.6) + tanh(1.2+1.7) + tanh(1.3+1.8) = 3.96753427840\n+    # expected001 = tanh(1.+2.5) + tanh(1.1+2.6) + tanh(1.2+2.7) + tanh(1.3+2.8) = 3.99558784825\n+    # expected002 = tanh(1.+3.5) + tanh(1.1+3.6) + tanh(1.2+3.7) + tanh(1.3+3.8) = 3.99940254147\n+    # expected010 = tanh(2.+1.5) + tanh(2.1+1.6) + tanh(2.2+1.7) + tanh(2.3+1.8) = 3.99558784825\n+    # expected011 = tanh(2.+2.5) + tanh(2.1+2.6) + tanh(2.2+2.7) + tanh(2.3+2.8) = 3.99940254147\n+    # expected012 = tanh(2.+3.5) + tanh(2.1+3.6) + tanh(2.2+3.7) + tanh(2.3+3.8) = 3.99991913657\n+    expected = np.array([[[3.96753427840, 3.99558784825, 3.99940254147],\n+                          [3.99558784825, 3.99940254147, 3.99991913657]]],\n+                        dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n   def test_calculate_scores_one_dim_batch_size_two(self):\n     # Query tensor of shape [2, 1, 1]\n     q = np.array([[[1.1]], [[2.1]]], dtype=np.float32)\n@@ -235,6 +258,22 @@ class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n     expected = np.array([[[-3.52]]], dtype=np.float32)\n     self.assertAllClose(expected, actual)\n    \n+  def test_calculate_scores_one_dim_with_scale_concat(self):\n+    \"\"\"Tests that scores are multiplied by scale.\"\"\"\n+    # Query tensor of shape [1, 1, 1]\n+    q = np.array([[[1.1]]], dtype=np.float32)\n+    # Key tensor of shape [1, 1, 1]\n+    k = np.array([[[1.6]]], dtype=np.float32)\n+    attention_layer = dense_attention.Attention(use_scale=True)\n+    attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\n+    attention_layer.scale = 2.\n+    actual = attention_layer._calculate_scores(query=q, key=k)\n+\n+    # Expected tensor of shape [1, 1, 1].\n+    # expected000 = 2 * tanh(1.1+1.6) = 1.982014907\n+    expected = np.array([[[1.98201491]]], dtype=np.float32)\n+    self.assertAllClose(expected, actual)\n+\n   def test_shape(self):\n     # Query tensor of shape [1, 2, 4]\n     q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n@@ -250,6 +289,21 @@ class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n     expected_shape = [1, 2, 4]\n     self.assertAllEqual(expected_shape, tf.shape(actual))\n   \n+  def test_shape_concat(self):\n+    # Query tensor of shape [1, 2, 4]\n+    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n+    # Value tensor of shape [1, 3, 4]\n+    v = np.array(\n+        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n+        dtype=np.float32)\n+    # Value mask tensor of shape [1, 3]\n+    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n+    attention_layer = dense_attention.Attention(score='concat')\n+    actual = attention_layer([q, v], mask=[None, v_mask])\n+\n+    expected_shape = [1, 2, 4]\n+    self.assertAllEqual(expected_shape, tf.shape(actual))\n+\n   def test_shape_with_key(self):\n     # Query tensor of shape [1, 2, 4]\n     q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n@@ -269,6 +323,25 @@ class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n     expected_shape = [1, 2, 4]\n     self.assertAllEqual(expected_shape, tf.shape(actual))\n    \n+  def test_shape_with_key_concat(self):\n+    # Query tensor of shape [1, 2, 4]\n+    q = np.array([[[1., 1.1, 1.2, 1.3], [2., 2.1, 2.2, 2.3]]], dtype=np.float32)\n+    # Value tensor of shape [1, 3, 4]\n+    v = np.array(\n+        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n+        dtype=np.float32)\n+    # Key tensor of shape [1, 3, 4]\n+    k = np.array(\n+        [[[1.5, 1.6, 1.7, 1.8], [2.5, 2.6, 2.7, 2.8], [3.5, 3.6, 3.7, 3.8]]],\n+        dtype=np.float32)\n+    # Value mask tensor of shape [1, 3]\n+    v_mask = np.array([[True, True, False]], dtype=np.bool_)\n+    attention_layer = dense_attention.Attention(score='concat')\n+    actual = attention_layer([q, v, k], mask=[None, v_mask])\n+\n+    expected_shape = [1, 2, 4]\n+    self.assertAllEqual(expected_shape, tf.shape(actual))\n+\n   def test_multi_dim(self):\n     # Query tensor of shape [1, 1, 1]\n     q = np.array([[[1.1]]], dtype=np.float32)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ed22329789f0db71bec940a90616f3c04008c5c9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 1281 | Contributors (this commit): 23 | Commits (past 90d): 8 | Contributors (cumulative): 23 | DMM Complexity: 1.0\n\nDIFF:\n@@ -62,14 +62,15 @@ def is_interactive_logging_enabled():\n   Returns:\n     Boolean (True if interactive logging is enabled and False otherwise).\n   \"\"\"\n-  return INTERACTIVE_LOGGING.enable\n+  # Use `getattr` in case `INTERACTIVE_LOGGING`\n+  # does not have the `enable` attribute.\n+  return getattr(INTERACTIVE_LOGGING, 'enable',\n+                 keras_logging.INTERACTIVE_LOGGING_DEFAULT)\n \n \n def print_msg(message, line_break=True):\n   \"\"\"Print the message to absl logging or stdout.\"\"\"\n-  # Use `getattr` in case `INTERACTIVE_LOGGING`\n-  # does not have the `enable` attribute.\n-  if INTERACTIVE_LOGGING.enable:\n+  if is_interactive_logging_enabled():\n     if line_break:\n       sys.stdout.write(message + '\\n')\n     else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#02ea53588d8961f355db30ee80bb5e6282f21880", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 182 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -17,6 +17,7 @@ import gc\n \n import tensorflow.compat.v2 as tf\n \n+from tensorflow.python.framework import test_util  # pylint: disable=g-direct-tensorflow-import\n from tensorflow.python.platform import test as test_lib\n \n layers = tf.keras.layers\n@@ -138,6 +139,7 @@ def _train_with_recompute(n_steps):\n   return losses\n \n \n+@test_util.with_eager_op_as_function\n class GradientCheckpointTest(tf.test.TestCase):\n \n   def test_raises_oom_exception(self):\n@@ -147,6 +149,8 @@ class GradientCheckpointTest(tf.test.TestCase):\n       _train_no_recompute(1)\n     self.assertIsInstance(context.exception, tf.errors.ResourceExhaustedError)\n \n+  @test_util.disable_xla(\n+      'xla does not support searching for memory-limited solvers.')\n   def test_does_not_raise_oom_exception(self):\n     if not _limit_gpu_memory():\n       self.skipTest('No virtual GPUs found')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4ba7f0979050dbfaaee1deae1d390129c3db0e32", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 1290 | Contributors (this commit): 24 | Commits (past 90d): 9 | Contributors (cumulative): 24 | DMM Complexity: 0.0\n\nDIFF:\n@@ -62,15 +62,14 @@ def is_interactive_logging_enabled():\n   Returns:\n     Boolean (True if interactive logging is enabled and False otherwise).\n   \"\"\"\n-  # Use `getattr` in case `INTERACTIVE_LOGGING`\n-  # does not have the `enable` attribute.\n-  return getattr(INTERACTIVE_LOGGING, 'enable',\n-                 keras_logging.INTERACTIVE_LOGGING_DEFAULT)\n+  return INTERACTIVE_LOGGING.enable\n \n \n def print_msg(message, line_break=True):\n   \"\"\"Print the message to absl logging or stdout.\"\"\"\n-  if is_interactive_logging_enabled():\n+  # Use `getattr` in case `INTERACTIVE_LOGGING`\n+  # does not have the `enable` attribute.\n+  if INTERACTIVE_LOGGING.enable:\n     if line_break:\n       sys.stdout.write(message + '\\n')\n     else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#48247a7752e3160062bc9d08fa1cb8affad02e63", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 97 | Files Changed: 8 | Hunks: 29 | Methods Changed: 17 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 112 | Churn Cumulative: 10859 | Contributors (this commit): 40 | Commits (past 90d): 42 | Contributors (cumulative): 71 | DMM Complexity: 0.0\n\nDIFF:\n@@ -40,7 +40,6 @@ from keras.layers import Activation\n from keras.layers import Dense\n from keras.optimizer_v2 import gradient_descent\n from keras.optimizer_v2 import learning_rate_schedule\n-from keras.utils import io_utils\n from keras.utils import np_utils\n from tensorflow.python.platform import tf_logging as logging\n \n@@ -275,7 +274,6 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(10)\n     expected_log = r'(.*- loss:.*- my_acc:.*)+'\n \n-    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(dataset, epochs=2, steps_per_epoch=10)\n       self.assertRegex(printed.contents(), expected_log)\n@@ -304,7 +302,6 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     # There are 7 ones in total in `y_train` after two batches.\n     expected_log = r'(.*- loss:.*- my_acc:.*- add_all_ones: 7.0000)+'\n \n-    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model = self._get_model(\n           input_shape=(8,), additional_metrics=[AddAllOnes()])\n@@ -491,7 +488,6 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(10)\n     expected_log = r'(.*- loss:.*- my_acc:.*)+'\n \n-    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(dataset, epochs=2, steps_per_epoch=10)\n       self.assertRegex(printed.contents(), expected_log)\n@@ -507,7 +503,6 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     val_dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(10)\n     expected_log = r'(.*5/5.*- loss:.*- my_acc:.*- val_loss:.*- val_my_acc:.*)+'\n \n-    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(training_dataset, epochs=2, validation_data=val_dataset)\n       self.assertRegex(printed.contents(), expected_log)\n@@ -523,7 +518,6 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n         r'(?s).*1/2.*8/8.*- loss:.*- my_acc:.*- val_loss:.*- val_my_acc:'\n         r'.*2/2.*8/8.*- loss:.*- my_acc:.*- val_loss:.*- val_my_acc:.*')\n \n-    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(x, y, batch_size=10, epochs=2, validation_split=0.2)\n       self.assertRegex(printed.contents(), expected_log)\n@@ -554,7 +548,6 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n         r'(?s).*1/2.*20/20.*- loss:.*- my_acc:.*- val_loss:.*- val_my_acc:'\n         r'.*2/2.*20/20.*- loss:.*- my_acc:.*- val_loss:.*- val_my_acc:.*')\n \n-    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(\n           x=training, validation_data=validation, epochs=2, steps_per_epoch=20)\n@@ -583,7 +576,6 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n           output_shapes=([2], [])) \\\n       .batch(2)\n \n-    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(x=training, validation_data=validation)\n \n@@ -1504,7 +1496,6 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n           keras.callbacks.LearningRateScheduler(\n               lambda x: 1. / (1. + x), verbose=1)\n       ]\n-      io_utils.enable_interactive_logging()\n       with self.captureWritesToStream(sys.stdout) as printed:\n         model.fit(\n             x_train,\n\n@@ -27,7 +27,6 @@ from tensorflow.python.framework import test_util\n from keras import keras_parameterized\n from keras import testing_utils\n from keras.layers import core\n-from keras.utils import io_utils\n \n \n @keras_parameterized.run_with_all_model_types\n@@ -77,7 +76,6 @@ class PrintTrainingInfoTest(keras_parameterized.TestCase,\n         ([1.], [1.])).repeat(50).batch(10)\n \n     mock_stdout = io.StringIO()\n-    io_utils.enable_interactive_logging()\n     with tf.compat.v1.test.mock.patch.object(sys, \"stdout\", mock_stdout):\n       model.fit(dataset, epochs=2, validation_data=val_dataset)\n \n\n@@ -26,7 +26,6 @@ from keras import callbacks\n from keras import keras_parameterized\n from keras import metrics as metrics_module\n from keras import testing_utils\n-from keras.utils import io_utils\n from tensorflow.python.platform import tf_logging as logging\n \n \n@@ -420,7 +419,6 @@ class TestTrainingWithDataset(keras_parameterized.TestCase):\n         tf.data.experimental.UNKNOWN_CARDINALITY)\n \n     batch_counter = BatchCounterCallback()\n-    io_utils.enable_interactive_logging()\n     with CaptureStdout() as capture:\n       history = model.fit(\n           dataset,\n\n@@ -35,7 +35,6 @@ from keras.engine import sequential\n from keras.engine import training as training_module\n from keras.engine import training_utils_v1\n from keras.utils import data_utils\n-from keras.utils import io_utils\n from keras.utils import np_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n@@ -1060,7 +1059,6 @@ class TrainingTest(keras_parameterized.TestCase):\n         RMSPropOptimizer(learning_rate=0.001),\n         loss='binary_crossentropy',\n         run_eagerly=testing_utils.should_run_eagerly())\n-    io_utils.enable_interactive_logging()\n     with tf.compat.v1.test.mock.patch.object(sys, 'stdout', mock_stdout):\n       model.fit(\n           np.ones((10, 10), 'float32'), np.ones((10, 1), 'float32'), epochs=10)\n\n@@ -19,64 +19,23 @@ import os\n import sys\n import threading\n \n-from absl import logging\n-from keras.utils import keras_logging\n-# pylint: disable=g-direct-tensorflow-import\n-from tensorflow.python.util.tf_export import keras_export\n-# pylint: enable=g-direct-tensorflow-import\n+import absl\n \n-INTERACTIVE_LOGGING = threading.local()\n-INTERACTIVE_LOGGING.enable = keras_logging.INTERACTIVE_LOGGING_DEFAULT\n-\n-\n-@keras_export('keras.utils.enable_interactive_logging')\n-def enable_interactive_logging():\n-  \"\"\"Turn on interactive logging.\n-\n-  When interactive logging is enabled, Keras displays logs via stdout.\n-  This provides the best experience when using Keras in an interactive\n-  environment such as a shell or a notebook.\n-  \"\"\"\n-  INTERACTIVE_LOGGING.enable = True\n-\n-\n-@keras_export('keras.utils.disable_interactive_logging')\n-def disable_interactive_logging():\n-  \"\"\"Turn off interactive logging.\n-\n-  When interactive logging is disabled, Keras sends logs to `absl.logging`.\n-  This is the best option when using Keras in a non-interactive\n-  way, such as running a training or inference job on a server.\n-  \"\"\"\n-  INTERACTIVE_LOGGING.enable = False\n-\n-\n-@keras_export('keras.utils.is_interactive_logging_enabled')\n-def is_interactive_logging_enabled():\n-  \"\"\"Check if interactive logging is enabled.\n-\n-  To switch between writing logs to stdout and `absl.logging`, you may use\n-  `keras.utils.enable_interactive_logging()` and\n-  `keras.utils.disable_interactie_logging()`.\n-\n-  Returns:\n-    Boolean (True if interactive logging is enabled and False otherwise).\n-  \"\"\"\n-  return INTERACTIVE_LOGGING.enable\n+ABSL_LOGGING = threading.local()\n+ABSL_LOGGING.enable = False\n \n \n def print_msg(message, line_break=True):\n   \"\"\"Print the message to absl logging or stdout.\"\"\"\n-  # Use `getattr` in case `INTERACTIVE_LOGGING`\n-  # does not have the `enable` attribute.\n-  if INTERACTIVE_LOGGING.enable:\n+  # Use `getattr` in case `ABSL_LOGGING` does not have the `enable` attribute.\n+  if getattr(ABSL_LOGGING, 'enable', False):\n+    absl.logging.info(message)\n+  else:\n     if line_break:\n       sys.stdout.write(message + '\\n')\n     else:\n       sys.stdout.write(message)\n     sys.stdout.flush()\n-  else:\n-    logging.info(message)\n \n \n def path_to_string(path):\n\n@@ -14,13 +14,15 @@\n # ==============================================================================\n \"\"\"Tests for io_utils.\"\"\"\n \n+import sys\n+\n+import tensorflow.compat.v2 as tf\n+\n import builtins\n from pathlib import Path\n-import sys\n \n from keras import keras_parameterized\n from keras.utils import io_utils\n-import tensorflow.compat.v2 as tf\n \n \n class TestIOUtils(keras_parameterized.TestCase):\n@@ -58,26 +60,19 @@ class TestIOUtils(keras_parameterized.TestCase):\n     self.assertIs(io_utils.path_to_string(dummy), dummy)\n \n   def test_print_msg(self):\n-    enabled = io_utils.is_interactive_logging_enabled()\n-\n-    io_utils.disable_interactive_logging()\n-    self.assertFalse(io_utils.is_interactive_logging_enabled())\n+    enabled = io_utils.ABSL_LOGGING.enable\n \n+    io_utils.ABSL_LOGGING.enable = True\n     with self.assertLogs(level='INFO') as logged:\n       io_utils.print_msg('Testing Message')\n     self.assertIn('Testing Message', logged.output[0])\n \n-    io_utils.enable_interactive_logging()\n-    self.assertTrue(io_utils.is_interactive_logging_enabled())\n-\n+    io_utils.ABSL_LOGGING.enable = False\n     with self.captureWritesToStream(sys.stdout) as printed:\n       io_utils.print_msg('Testing Message')\n     self.assertEqual('Testing Message\\n', printed.contents())\n \n-    if enabled:\n-      io_utils.enable_interactive_logging()\n-    else:\n-      io_utils.disable_interactive_logging()\n+    io_utils.ABSL_LOGGING.enable = enabled\n \n if __name__ == '__main__':\n   tf.test.main()\n\n@@ -1,19 +0,0 @@\n-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-# ==============================================================================\n-\"\"\"Flags for logging control.\"\"\"\n-\n-# LINT.IfChange(external_interactive_logging)\n-INTERACTIVE_LOGGING_DEFAULT = True\n-# LINT.ThenChange(../../utils/keras_logging.py:internal_interactive_logging)\n\n@@ -28,7 +28,6 @@ import time\n import timeit\n \n import numpy as np\n-from keras.utils import io_utils\n from keras.utils import layer_utils\n \n \n@@ -82,7 +81,6 @@ class LayerUtilsTest(tf.test.TestCase):\n   def test_print_summary_without_print_fn(self):\n     model = keras.Sequential([\n         keras.layers.Dense(5, input_shape=(10,), name='dense')])\n-    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       layer_utils.print_summary(model)\n     self.assertIn('dense (Dense)', printed.contents())\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b8e66ada45846972a73d730df176c19440186933", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 1763 | Contributors (this commit): 12 | Commits (past 90d): 6 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -1102,8 +1102,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n     >>> m.compile(opt, loss='mse')\n     >>> data = np.arange(100).reshape(5, 20)\n     >>> labels = np.zeros(5)\n-    >>> print('Training'); results = m.fit(data, labels)\n-    Training ...\n+    >>> results = m.fit(data, labels)  # Training.\n     >>> len(opt.get_weights())\n     3\n \n@@ -1133,8 +1132,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n     >>> m.compile(opt, loss='mse')\n     >>> data = np.arange(100).reshape(5, 20)\n     >>> labels = np.zeros(5)\n-    >>> print('Training'); results = m.fit(data, labels)\n-    Training ...\n+    >>> results = m.fit(data, labels)  # Training.\n     >>> new_weights = [np.array(10), np.ones([20, 10]), np.zeros([10])]\n     >>> opt.set_weights(new_weights)\n     >>> opt.iterations\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#83ac90078cec41abeac5370ff03d120f0e99a089", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 546 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -327,8 +327,8 @@ class TestGeneratorMethods(keras_parameterized.TestCase):\n         'I think juice is great',\n         'unknown is the best language since slicedbread',\n         'a a a a a a a',\n-        'matmul'\n-        'Yaks are also quite nice',\n+        'matmul',\n+        'Yaks are also quite nice'\n     ]\n     y = [1, 0, 0, 1, 1]\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2c66f3761d7689464ca8e9e741b7d3de0a7553b9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 5 | Files Changed: 3 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 25 | Churn Cumulative: 29745 | Contributors (this commit): 90 | Commits (past 90d): 12 | Contributors (cumulative): 102 | DMM Complexity: 1.0\n\nDIFF:\n@@ -5721,7 +5721,12 @@ def conv2d_transpose(x,\n                                          padding=padding,\n                                          data_format=tf_data_format)\n   else:\n-    assert dilation_rate[0] == dilation_rate[1]\n+    if dilation_rate[0] != dilation_rate[1]:\n+      raise ValueError(\n+          'Expected the 2 dimensions of the `dilation_rate` argument '\n+          'to be equal to each other. '\n+          f'Received: dilation_rate={dilation_rate}'\n+      )\n     x = tf.nn.atrous_conv2d_transpose(\n         x,\n         kernel,\n\n@@ -1087,6 +1087,17 @@ class BackendNNOpsTest(tf.test.TestCase, parameterized.TestCase):\n     self.assertEqual(\n         tuple(y.shape.as_list()), (batch_size,) + input_size + (filters,))\n \n+    # Test dilation_rate error\n+    with self.assertRaisesRegex(\n+        ValueError,\n+        'Expected the 2 dimensions'):\n+      y = backend.conv2d_transpose(\n+          x,\n+          k, (batch_size,) + input_size + (filters,),\n+          padding='same',\n+          data_format='channels_last',\n+          dilation_rate=(1, 2))\n+\n     # Test batch size of None in output_shape\n     y = backend.conv2d_transpose(\n         x,\n\n@@ -1153,10 +1153,9 @@ class Conv2DTranspose(Conv2D):\n       It defaults to the `image_data_format` value found in your\n       Keras config file at `~/.keras/keras.json`.\n       If you never set it, then it will be \"channels_last\".\n-    dilation_rate: an integer or tuple/list of 2 integers, specifying\n-      the dilation rate to use for dilated convolution.\n-      Can be a single integer to specify the same value for\n-      all spatial dimensions.\n+    dilation_rate: an integer, specifying the dilation rate for all spatial\n+      dimensions for dilated convolution. Specifying different dilation rates\n+      for different dimensions is not supported.\n       Currently, specifying any `dilation_rate` value != 1 is\n       incompatible with specifying any stride value != 1.\n     activation: Activation function to use.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c16045d9ba36f257b278732e35519656f00eceeb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 4671 | Contributors (this commit): 20 | Commits (past 90d): 5 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -44,9 +44,7 @@ class Loss:\n   class MeanSquaredError(Loss):\n \n     def call(self, y_true, y_pred):\n-      y_pred = tf.convert_to_tensor_v2(y_pred)\n-      y_true = tf.cast(y_true, y_pred.dtype)\n-      return tf.reduce_mean(math_ops.square(y_pred - y_true), axis=-1)\n+      return tf.reduce_mean(tf.math.square(y_pred - y_true), axis=-1)\n   ```\n \n   When used with `tf.distribute.Strategy`, outside of built-in training loops\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#08f582808b406cd01aa61ff28db9de8cf6af0aaa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 98 | Lines Deleted: 15 | Files Changed: 8 | Hunks: 29 | Methods Changed: 17 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 113 | Churn Cumulative: 10972 | Contributors (this commit): 40 | Commits (past 90d): 50 | Contributors (cumulative): 71 | DMM Complexity: 1.0\n\nDIFF:\n@@ -40,6 +40,7 @@ from keras.layers import Activation\n from keras.layers import Dense\n from keras.optimizer_v2 import gradient_descent\n from keras.optimizer_v2 import learning_rate_schedule\n+from keras.utils import io_utils\n from keras.utils import np_utils\n from tensorflow.python.platform import tf_logging as logging\n \n@@ -274,6 +275,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(10)\n     expected_log = r'(.*- loss:.*- my_acc:.*)+'\n \n+    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(dataset, epochs=2, steps_per_epoch=10)\n       self.assertRegex(printed.contents(), expected_log)\n@@ -302,6 +304,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     # There are 7 ones in total in `y_train` after two batches.\n     expected_log = r'(.*- loss:.*- my_acc:.*- add_all_ones: 7.0000)+'\n \n+    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model = self._get_model(\n           input_shape=(8,), additional_metrics=[AddAllOnes()])\n@@ -488,6 +491,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(10)\n     expected_log = r'(.*- loss:.*- my_acc:.*)+'\n \n+    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(dataset, epochs=2, steps_per_epoch=10)\n       self.assertRegex(printed.contents(), expected_log)\n@@ -503,6 +507,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     val_dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(10)\n     expected_log = r'(.*5/5.*- loss:.*- my_acc:.*- val_loss:.*- val_my_acc:.*)+'\n \n+    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(training_dataset, epochs=2, validation_data=val_dataset)\n       self.assertRegex(printed.contents(), expected_log)\n@@ -518,6 +523,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n         r'(?s).*1/2.*8/8.*- loss:.*- my_acc:.*- val_loss:.*- val_my_acc:'\n         r'.*2/2.*8/8.*- loss:.*- my_acc:.*- val_loss:.*- val_my_acc:.*')\n \n+    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(x, y, batch_size=10, epochs=2, validation_split=0.2)\n       self.assertRegex(printed.contents(), expected_log)\n@@ -548,6 +554,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n         r'(?s).*1/2.*20/20.*- loss:.*- my_acc:.*- val_loss:.*- val_my_acc:'\n         r'.*2/2.*20/20.*- loss:.*- my_acc:.*- val_loss:.*- val_my_acc:.*')\n \n+    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(\n           x=training, validation_data=validation, epochs=2, steps_per_epoch=20)\n@@ -576,6 +583,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n           output_shapes=([2], [])) \\\n       .batch(2)\n \n+    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       model.fit(x=training, validation_data=validation)\n \n@@ -1496,6 +1504,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n           keras.callbacks.LearningRateScheduler(\n               lambda x: 1. / (1. + x), verbose=1)\n       ]\n+      io_utils.enable_interactive_logging()\n       with self.captureWritesToStream(sys.stdout) as printed:\n         model.fit(\n             x_train,\n\n@@ -27,6 +27,7 @@ from tensorflow.python.framework import test_util\n from keras import keras_parameterized\n from keras import testing_utils\n from keras.layers import core\n+from keras.utils import io_utils\n \n \n @keras_parameterized.run_with_all_model_types\n@@ -76,6 +77,7 @@ class PrintTrainingInfoTest(keras_parameterized.TestCase,\n         ([1.], [1.])).repeat(50).batch(10)\n \n     mock_stdout = io.StringIO()\n+    io_utils.enable_interactive_logging()\n     with tf.compat.v1.test.mock.patch.object(sys, \"stdout\", mock_stdout):\n       model.fit(dataset, epochs=2, validation_data=val_dataset)\n \n\n@@ -26,6 +26,7 @@ from keras import callbacks\n from keras import keras_parameterized\n from keras import metrics as metrics_module\n from keras import testing_utils\n+from keras.utils import io_utils\n from tensorflow.python.platform import tf_logging as logging\n \n \n@@ -419,6 +420,7 @@ class TestTrainingWithDataset(keras_parameterized.TestCase):\n         tf.data.experimental.UNKNOWN_CARDINALITY)\n \n     batch_counter = BatchCounterCallback()\n+    io_utils.enable_interactive_logging()\n     with CaptureStdout() as capture:\n       history = model.fit(\n           dataset,\n\n@@ -35,6 +35,7 @@ from keras.engine import sequential\n from keras.engine import training as training_module\n from keras.engine import training_utils_v1\n from keras.utils import data_utils\n+from keras.utils import io_utils\n from keras.utils import np_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n@@ -1059,6 +1060,7 @@ class TrainingTest(keras_parameterized.TestCase):\n         RMSPropOptimizer(learning_rate=0.001),\n         loss='binary_crossentropy',\n         run_eagerly=testing_utils.should_run_eagerly())\n+    io_utils.enable_interactive_logging()\n     with tf.compat.v1.test.mock.patch.object(sys, 'stdout', mock_stdout):\n       model.fit(\n           np.ones((10, 10), 'float32'), np.ones((10, 1), 'float32'), epochs=10)\n\n@@ -19,23 +19,65 @@ import os\n import sys\n import threading\n \n-import absl\n+from absl import logging\n+from keras.utils import keras_logging\n+# pylint: disable=g-direct-tensorflow-import\n+from tensorflow.python.util.tf_export import keras_export\n+# pylint: enable=g-direct-tensorflow-import\n \n-ABSL_LOGGING = threading.local()\n-ABSL_LOGGING.enable = False\n+INTERACTIVE_LOGGING = threading.local()\n+INTERACTIVE_LOGGING.enable = keras_logging.INTERACTIVE_LOGGING_DEFAULT\n+\n+\n+@keras_export('keras.utils.enable_interactive_logging')\n+def enable_interactive_logging():\n+  \"\"\"Turn on interactive logging.\n+\n+  When interactive logging is enabled, Keras displays logs via stdout.\n+  This provides the best experience when using Keras in an interactive\n+  environment such as a shell or a notebook.\n+  \"\"\"\n+  INTERACTIVE_LOGGING.enable = True\n+\n+\n+@keras_export('keras.utils.disable_interactive_logging')\n+def disable_interactive_logging():\n+  \"\"\"Turn off interactive logging.\n+\n+  When interactive logging is disabled, Keras sends logs to `absl.logging`.\n+  This is the best option when using Keras in a non-interactive\n+  way, such as running a training or inference job on a server.\n+  \"\"\"\n+  INTERACTIVE_LOGGING.enable = False\n+\n+\n+@keras_export('keras.utils.is_interactive_logging_enabled')\n+def is_interactive_logging_enabled():\n+  \"\"\"Check if interactive logging is enabled.\n+\n+  To switch between writing logs to stdout and `absl.logging`, you may use\n+  `keras.utils.enable_interactive_logging()` and\n+  `keras.utils.disable_interactie_logging()`.\n+\n+  Returns:\n+    Boolean (True if interactive logging is enabled and False otherwise).\n+  \"\"\"\n+  # Use `getattr` in case `INTERACTIVE_LOGGING`\n+  # does not have the `enable` attribute.\n+  return getattr(INTERACTIVE_LOGGING, 'enable',\n+                 keras_logging.INTERACTIVE_LOGGING_DEFAULT)\n \n \n def print_msg(message, line_break=True):\n   \"\"\"Print the message to absl logging or stdout.\"\"\"\n-  # Use `getattr` in case `ABSL_LOGGING` does not have the `enable` attribute.\n-  if getattr(ABSL_LOGGING, 'enable', False):\n-    absl.logging.info(message)\n-  else:\n+  if is_interactive_logging_enabled():\n     if line_break:\n       sys.stdout.write(message + '\\n')\n     else:\n       sys.stdout.write(message)\n     sys.stdout.flush()\n+  else:\n+    logging.info(message)\n \n \n def path_to_string(path):\n\n@@ -14,15 +14,13 @@\n # ==============================================================================\n \"\"\"Tests for io_utils.\"\"\"\n \n-import sys\n-\n-import tensorflow.compat.v2 as tf\n-\n import builtins\n from pathlib import Path\n+import sys\n \n from keras import keras_parameterized\n from keras.utils import io_utils\n+import tensorflow.compat.v2 as tf\n \n \n class TestIOUtils(keras_parameterized.TestCase):\n@@ -60,19 +58,26 @@ class TestIOUtils(keras_parameterized.TestCase):\n     self.assertIs(io_utils.path_to_string(dummy), dummy)\n \n   def test_print_msg(self):\n-    enabled = io_utils.ABSL_LOGGING.enable\n+    enabled = io_utils.is_interactive_logging_enabled()\n+\n+    io_utils.disable_interactive_logging()\n+    self.assertFalse(io_utils.is_interactive_logging_enabled())\n \n-    io_utils.ABSL_LOGGING.enable = True\n     with self.assertLogs(level='INFO') as logged:\n       io_utils.print_msg('Testing Message')\n     self.assertIn('Testing Message', logged.output[0])\n \n-    io_utils.ABSL_LOGGING.enable = False\n+    io_utils.enable_interactive_logging()\n+    self.assertTrue(io_utils.is_interactive_logging_enabled())\n+\n     with self.captureWritesToStream(sys.stdout) as printed:\n       io_utils.print_msg('Testing Message')\n     self.assertEqual('Testing Message\\n', printed.contents())\n \n-    io_utils.ABSL_LOGGING.enable = enabled\n+    if enabled:\n+      io_utils.enable_interactive_logging()\n+    else:\n+      io_utils.disable_interactive_logging()\n \n if __name__ == '__main__':\n   tf.test.main()\n\n@@ -0,0 +1,19 @@\n+# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Flags for logging control.\"\"\"\n+\n+# LINT.IfChange(external_interactive_logging)\n+INTERACTIVE_LOGGING_DEFAULT = True\n+# LINT.ThenChange(../../utils/keras_logging.py:internal_interactive_logging)\n\n@@ -28,6 +28,7 @@ import time\n import timeit\n \n import numpy as np\n+from keras.utils import io_utils\n from keras.utils import layer_utils\n \n \n@@ -81,6 +82,7 @@ class LayerUtilsTest(tf.test.TestCase):\n   def test_print_summary_without_print_fn(self):\n     model = keras.Sequential([\n         keras.layers.Dense(5, input_shape=(10,), name='dense')])\n+    io_utils.enable_interactive_logging()\n     with self.captureWritesToStream(sys.stdout) as printed:\n       layer_utils.print_summary(model)\n     self.assertIn('dense (Dense)', printed.contents())\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
