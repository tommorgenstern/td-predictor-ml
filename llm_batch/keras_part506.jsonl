{"custom_id": "keras#ed99e34f279a2d2d6a44af87ee64f8fc98c7e8b9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 46 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 4 | Methods Changed: 9 | Complexity Δ (Sum/Max): 11/9 | Churn Δ: 46 | Churn Cumulative: 2061 | Contributors (this commit): 14 | Commits (past 90d): 6 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -38,6 +38,34 @@ def numpy_text(tensor, is_repr=False):\n     return text\n \n \n+class AutoCastVariableSpec(tf.types.experimental.TraceType):\n+    \"\"\"TraceType for AutoCastVariableSpec for tracing with tf.function.\n+\n+    This class implements the Type for AutoCastVariable used in tracing.\n+    \"\"\"\n+\n+    def __init__(self, value):\n+        self._value = value\n+\n+    def is_subtype_of(self, other) -> bool:\n+        \"\"\"If the other spec is the same as `self`, return True.\"\"\"\n+        return self == other\n+\n+    def most_specific_common_supertype(self, others):\n+        \"\"\"`self` is the common supertype if all input types match it.\"\"\"\n+        return self if all(self == other for other in others) else None\n+\n+    def placeholder_value(self, placeholder_context=None):\n+        \"\"\"Use the AutoCastVariable value itself as a placeholder.\"\"\"\n+        return self._value\n+\n+    def __hash__(self) -> int:\n+        return hash(id(self._value))\n+\n+    def __eq__(self, other) -> bool:\n+        return self is other\n+\n+\n class AutoCastVariable(tf.Variable, tf.__internal__.types.Tensor):\n     \"\"\"Variable that casts itself to a different dtype in applicable contexts.\n \n@@ -363,6 +391,9 @@ class AutoCastVariable(tf.Variable, tf.__internal__.types.Tensor):\n     def get_shape(self):\n         return self._variable.get_shape()\n \n+    def __tf_tracing_type__(self, context):\n+        return AutoCastVariableSpec(self)\n+\n     def _gather_saveables_for_checkpoint(self):\n         # By delegating this method to the wrapped variable, checkpoints with\n         # AutoCastVariables are identical to checkpoints with normal variables.\n\n@@ -21,6 +21,7 @@ import numpy as np\n import tensorflow.compat.v2 as tf\n from absl.testing import parameterized\n \n+from keras.layers import Dense\n from keras.mixed_precision import autocast_variable\n from keras.optimizers.legacy import adadelta\n from keras.optimizers.legacy import adagrad\n@@ -113,6 +114,20 @@ class AutoCastVariableTest(tf.test.TestCase, parameterized.TestCase):\n             self.assertEqual(x.sparse_read([0]).dtype, tf.float16)\n             self.assertEqual(x.gather_nd([0]).dtype, tf.float16)\n \n+    def test_tf_function_with_variable_and_autocast_variable(self):\n+        ones = tf.ones((2, 2))\n+        layer1 = Dense(2, dtype=\"float32\")\n+        layer2 = Dense(2, dtype=\"mixed_float16\")\n+        layer1(ones)\n+        layer2(ones)\n+\n+        @tf.function\n+        def f(x):\n+            return x + 1\n+\n+        self.assertEqual(f(layer1.kernel).dtype, tf.dtypes.float32)\n+        self.assertEqual(f(layer2.kernel).dtype, tf.dtypes.float32)\n+\n     @tf.__internal__.distribute.combinations.generate(maybe_distribute)\n     def test_read_nested_scopes(self, distribution):\n         with distribution.scope():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#db9058bd91a0927b1b11fa6e78fdab86eb7a3565", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 11 | Files Changed: 5 | Hunks: 13 | Methods Changed: 9 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 38 | Churn Cumulative: 9085 | Contributors (this commit): 21 | Commits (past 90d): 14 | Contributors (cumulative): 51 | DMM Complexity: 1.0\n\nDIFF:\n@@ -23,7 +23,9 @@ Reference:\n \n import tensorflow.compat.v2 as tf\n \n+import keras\n from keras import backend\n+from keras import layers as keras_layers\n from keras.applications import imagenet_utils\n from keras.engine import training\n from keras.layers import VersionAwareLayers\n@@ -319,6 +321,21 @@ def conv2d_bn(\n     return x\n \n \n+@keras.utils.register_keras_serializable()\n+class CustomScaleLayer(keras_layers.Layer):\n+    def __init__(self, scale, **kwargs):\n+        super().__init__(**kwargs)\n+        self.scale = scale\n+\n+    def get_config(self):\n+        config = super().get_config()\n+        config.update({\"scale\": self.scale})\n+        return config\n+\n+    def call(self, inputs):\n+        return inputs[0] + inputs[1] * self.scale\n+\n+\n def inception_resnet_block(x, scale, block_type, block_idx, activation=\"relu\"):\n     \"\"\"Adds an Inception-ResNet block.\n \n@@ -395,12 +412,7 @@ def inception_resnet_block(x, scale, block_type, block_idx, activation=\"relu\"):\n         name=block_name + \"_conv\",\n     )\n \n-    x = layers.Lambda(\n-        lambda inputs, scale: inputs[0] + inputs[1] * scale,\n-        output_shape=backend.int_shape(x)[1:],\n-        arguments={\"scale\": scale},\n-        name=block_name,\n-    )([x, up])\n+    x = CustomScaleLayer(scale)([x, up])\n     if activation is not None:\n         x = layers.Activation(activation, name=block_name + \"_ac\")(x)\n     return x\n\n@@ -897,13 +897,10 @@ class NetworkConstructionTest(test_combinations.TestCase):\n         # See https://github.com/keras-team/keras/issues/14838.\n         inp = input_layer_lib.Input(shape=[5], name=\"main_input\")\n \n-        zeros = layers.Lambda(tf.zeros_like, name=\"generate_zeros\")(inp)\n-        ones = layers.Lambda(tf.ones_like, name=\"generate_ones\")(inp)\n-\n         shared_layer = layers.Layer(name=\"shared\")\n \n-        ones_result = shared_layer(ones)\n-        zeros_result = shared_layer(zeros)\n+        ones_result = shared_layer(tf.ones_like(inp))\n+        zeros_result = shared_layer(tf.zeros_like(inp))\n         zeros_result = layers.Layer(name=\"blank\")(zeros_result)\n \n         m = training_lib.Model(\n\n@@ -21,6 +21,7 @@ from keras.engine import functional\n from keras.engine import input_layer as input_layer_lib\n from keras.layers import core\n from keras.saving.legacy import model_config\n+from keras.saving.serialization_lib import SafeModeScope\n from keras.testing_infra import test_combinations\n \n # isort: off\n@@ -406,6 +407,7 @@ class InputLayerTest(test_combinations.TestCase):\n             self.assertAllEqual(model(two_tensors), lambda_fn(two_tensors))\n \n             # Test serialization / deserialization\n+            with SafeModeScope(safe_mode=False):\n                 model = functional.Functional.from_config(model.get_config())\n                 self.assertAllEqual(model(two_tensors), lambda_fn(two_tensors))\n                 model = model_config.model_from_json(model.to_json())\n\n@@ -24,6 +24,7 @@ import keras\n from keras import initializers\n from keras.layers import core\n from keras.mixed_precision import policy\n+from keras.saving.serialization_lib import SafeModeScope\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n \n@@ -156,6 +157,7 @@ class LambdaLayerTest(test_combinations.TestCase):\n \n         ld = keras.layers.Lambda(f)\n         config = ld.get_config()\n+        with SafeModeScope(safe_mode=False):\n             ld = keras.layers.deserialize(\n                 {\"class_name\": \"Lambda\", \"config\": config}\n             )\n@@ -248,6 +250,7 @@ class LambdaLayerTest(test_combinations.TestCase):\n         layer(keras.backend.variable(np.ones((1, 1))))\n         config = layer.get_config()\n \n+        with SafeModeScope(safe_mode=False):\n             layer = keras.layers.deserialize(\n                 {\"class_name\": \"Lambda\", \"config\": config}\n             )\n\n@@ -45,6 +45,7 @@ from keras.optimizers import sgd\n from keras.optimizers.legacy import gradient_descent\n from keras.saving import object_registration\n from keras.saving.legacy import save\n+from keras.saving.serialization_lib import SafeModeScope\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n \n@@ -511,6 +512,7 @@ class KerasModelTest(test_combinations.TestCase):\n                 model = models.Model(inputs=x, outputs=y)\n                 if get_config:\n                     config = model.get_config()\n+                    with SafeModeScope(safe_mode=False):\n                         model = model.__class__.from_config(\n                             config,\n                             custom_objects={\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c2e007e3e7b18bcef8fe7dc059d2c3d2ed7dbdf4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 290 | Contributors (this commit): 7 | Commits (past 90d): 2 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -209,7 +209,7 @@ def timeseries_dataset_from_array(\n \n     # Determine the lowest dtype to store start positions (to lower memory\n     # usage).\n-    num_seqs = end_index - start_index - (sequence_length * sampling_rate) + 1\n+    num_seqs = end_index - start_index - ((sequence_length-1) * sampling_rate)\n     if targets is not None:\n         num_seqs = min(num_seqs, len(targets))\n     if num_seqs < 2147483647:\n\n@@ -130,8 +130,8 @@ class TimeseriesDatasetTest(tf.test.TestCase):\n             if i < 16:\n                 self.assertEqual(inputs.shape, (5, 9))\n             if i == 16:\n-                # Last batch: size 3\n-                self.assertEqual(inputs.shape, (3, 9))\n+                # Last batch: size 4\n+                self.assertEqual(inputs.shape, (4, 9))\n             # Check target values\n             self.assertAllClose(inputs[:, 0] * 2, targets)\n             for j in range(min(5, len(inputs))):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#50542a234850ebf6128f9c61673fc4cae596ff01", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 979 | Contributors (this commit): 11 | Commits (past 90d): 5 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -59,6 +59,9 @@ class AutoCastVariableSpec(tf.types.experimental.TraceType):\n         \"\"\"Use the AutoCastVariable value itself as a placeholder.\"\"\"\n         return self._value\n \n+    def _to_tensors(self, value):\n+        return []\n+\n     def __hash__(self) -> int:\n         return hash(id(self._value))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#57b2e83ef632d77453f8273ee2e1999176b166a2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 156 | Contributors (this commit): 7 | Commits (past 90d): 2 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -84,7 +84,7 @@ def timeseries_dataset_from_array(\n \n     Example 1:\n \n-    Consider indices `[0, 1, ... 99]`.\n+    Consider indices `[0, 1, ... 98]`.\n     With `sequence_length=10,  sampling_rate=2, sequence_stride=3`,\n     `shuffle=False`, the dataset will yield batches of sequences\n     composed of the following indices:\n@@ -97,9 +97,9 @@ def timeseries_dataset_from_array(\n     Last sequence:   [78 80 82 84 86 88 90 92 94 96]\n     ```\n \n-    In this case the last 3 data points are discarded since no full sequence\n+    In this case the last 2 data points are discarded since no full sequence\n     can be generated to include them (the next sequence would have started\n-    at index 81, and thus its last step would have gone over 99).\n+    at index 81, and thus its last step would have gone over 98).\n \n     Example 2: Temporal regression.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#665ca5c574f49d5ae31c2ed57629259f7c848e34", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 1842 | Contributors (this commit): 11 | Commits (past 90d): 6 | Contributors (cumulative): 11 | DMM Complexity: 0.6666666666666666\n\nDIFF:\n@@ -496,10 +496,13 @@ def index_directory(\n     seed=None,\n     follow_links=False,\n ):\n-    \"\"\"Make list of all files in the subdirs of `directory`, with their labels.\n+    \"\"\"Make list of all files in `directory`, with their labels.\n \n     Args:\n-      directory: The target directory (string).\n+      directory: Directory where the data is located.\n+          If `labels` is \"inferred\", it should contain\n+          subdirectories, each containing files for a class.\n+          Otherwise, the directory structure is ignored.\n       labels: Either \"inferred\"\n           (labels are generated from the directory structure),\n           None (no labels),\n@@ -524,8 +527,8 @@ def index_directory(\n         class_names: names of the classes corresponding to these labels, in\n           order.\n     \"\"\"\n-    if labels is None:\n-        # in the no-label case, index from the parent directory down.\n+    if labels != \"inferred\":\n+        # in the explicit/no-label cases, index from the parent directory down.\n         subdirs = [\"\"]\n         class_names = subdirs\n     else:\n@@ -572,6 +575,7 @@ def index_directory(\n                 f\"{len(labels)} while we found {len(filenames)} files \"\n                 f\"in directory {directory}.\"\n             )\n+        class_names = sorted(set(labels))\n     else:\n         i = 0\n         labels = np.zeros((len(filenames),), dtype=\"int32\")\n@@ -641,7 +645,9 @@ def index_subdirectory(directory, class_indices, follow_links, formats):\n     return filenames, labels\n \n \n-def get_training_or_validation_split(samples, labels, validation_split, subset):\n+def get_training_or_validation_split(\n+    samples, labels, validation_split, subset\n+):\n     \"\"\"Potentially restict samples & labels to a training or validation split.\n \n     Args:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#981cb8da38f0338ef8c1834e4e34d1f2efda04dc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1846 | Contributors (this commit): 11 | Commits (past 90d): 7 | Contributors (cumulative): 11 | DMM Complexity: 0.0\n\nDIFF:\n@@ -645,9 +645,7 @@ def index_subdirectory(directory, class_indices, follow_links, formats):\n     return filenames, labels\n \n \n-def get_training_or_validation_split(\n-    samples, labels, validation_split, subset\n-):\n+def get_training_or_validation_split(samples, labels, validation_split, subset):\n     \"\"\"Potentially restict samples & labels to a training or validation split.\n \n     Args:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d3d523d35a11479bc455981e5e7f792119a7bbd2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 158 | Contributors (this commit): 7 | Commits (past 90d): 3 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -209,7 +209,7 @@ def timeseries_dataset_from_array(\n \n     # Determine the lowest dtype to store start positions (to lower memory\n     # usage).\n-    num_seqs = end_index - start_index - ((sequence_length - 1) * sampling_rate)\n+    num_seqs = end_index - start_index - (sequence_length - 1) * sampling_rate\n     if targets is not None:\n         num_seqs = min(num_seqs, len(targets))\n     if num_seqs < 2147483647:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bfb5ce634f588539be347ebffb46da42b46518a5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 29 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 31 | Churn Cumulative: 651 | Contributors (this commit): 3 | Commits (past 90d): 6 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -277,7 +277,10 @@ def skip_failed_serialization():\n         _SKIP_FAILED_SERIALIZATION = prev\n \n \n-@keras_export(\"keras.utils.serialize_keras_object\")\n+@keras_export(\n+    \"keras.utils.serialize_keras_object\",\n+    \"keras.utils.legacy.serialize_keras_object\",\n+)\n def serialize_keras_object(instance):\n     \"\"\"Serialize a Keras object into a JSON-compatible representation.\n \n@@ -417,7 +420,10 @@ def class_and_config_for_serialized_keras_object(\n     return (cls, cls_config)\n \n \n-@keras_export(\"keras.utils.deserialize_keras_object\")\n+@keras_export(\n+    \"keras.utils.deserialize_keras_object\",\n+    \"keras.utils.legacy.deserialize_keras_object\",\n+)\n def deserialize_keras_object(\n     identifier,\n     module_objects=None,\n\n@@ -0,0 +1,21 @@\n+# Copyright 2023 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Legacy public Keras utilities.\"\"\"\n+\n+# isort: off\n+\n+# Serialization related\n+from keras.saving.legacy.serialization import deserialize_keras_object\n+from keras.saving.legacy.serialization import serialize_keras_object\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#04a23bcf32f4a4957cf7db191619f1979c65fe5c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 37 | Lines Deleted: 25 | Files Changed: 6 | Hunks: 16 | Methods Changed: 9 | Complexity Δ (Sum/Max): 0/2 | Churn Δ: 62 | Churn Cumulative: 34470 | Contributors (this commit): 230 | Commits (past 90d): 31 | Contributors (cumulative): 298 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1745,7 +1745,7 @@ class BackupAndRestore(Callback):\n \n     Note that the user is responsible to bring jobs back after the interruption.\n     This callback is important for the backup and restore mechanism for fault\n-    tolerance purpose, and the model to be restored from an previous checkpoint\n+    tolerance purpose, and the model to be restored from a previous checkpoint\n     is expected to be the same as the one used to back up. If user changes\n     arguments passed to compile or fit, the checkpoint saved for fault tolerance\n     can become invalid.\n@@ -2353,7 +2353,7 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n         write_images: whether to write model weights to visualize as image in\n           TensorBoard.\n         write_steps_per_second: whether to log the training steps per second\n-          into Tensorboard. This supports both epoch and batch frequency\n+          into TensorBoard. This supports both epoch and batch frequency\n           logging.\n         update_freq: `'batch'` or `'epoch'` or integer. When using `'epoch'`,\n           writes the losses and metrics to TensorBoard after every epoch.\n\n@@ -171,8 +171,10 @@ def _on_gcp():\n         return False\n \n \n-def support_on_demand_checkpoint_callback():\n-    if _on_gcp() and not tf.config.list_physical_devices(\"TPU\"):\n+def support_on_demand_checkpoint_callback(strategy):\n+    if _on_gcp() and isinstance(\n+        strategy, tf.distribute.MultiWorkerMirroredStrategy\n+    ):\n         return True\n \n     return False\n\n@@ -14,6 +14,8 @@\n # ==============================================================================\n \"\"\"Utilities related to distributed training.\"\"\"\n \n+import contextlib\n+\n import tensorflow.compat.v2 as tf\n from absl import flags\n \n@@ -126,3 +128,15 @@ def get_strategy():\n             f\"It should be one of {accepted_strats}\"\n         )\n     return strategy\n+\n+\n+def maybe_preemption_handler_scope(model):\n+\n+    if getattr(model, \"_preemption_handler\", None):\n+        preemption_checkpoint_scope = (\n+            model._preemption_handler._watch_error_scope()\n+        )\n+    else:\n+        preemption_checkpoint_scope = contextlib.nullcontext()\n+\n+    return preemption_checkpoint_scope\n\n@@ -31,15 +31,6 @@ from keras.distribute.distributed_file_utils import (\n MAX_CHECKPOINT_TO_KEEP = 1\n \n \n-def _should_enable_save_before_preemption(save_before_preemption_arg, strategy):\n-    # TODO(wxinyi): expand support to TPU.\n-    return (\n-        save_before_preemption_arg\n-        and isinstance(strategy, tf.distribute.MultiWorkerMirroredStrategy)\n-        and support_on_demand_checkpoint_callback()\n-    )\n-\n-\n class WorkerTrainingState:\n     \"\"\"Training state management class.\n \n@@ -61,12 +52,11 @@ class WorkerTrainingState:\n         save_freq=\"epoch\",\n         save_before_preemption_arg=None,\n     ):\n-        self._enable_save_before_preemption = (\n-            _should_enable_save_before_preemption(\n-                save_before_preemption_arg, model.distribute_strategy\n-            )\n+        self._enable_save_before_preemption = save_before_preemption_arg and (\n+            support_on_demand_checkpoint_callback(model.distribute_strategy)\n         )\n         self._model = model\n+\n         self._save_freq = save_freq\n         # The batch and epoch at which the checkpoint is saved. Used for\n         # fault-tolerance. GPU device only has int64 dtype registered\n@@ -130,13 +120,14 @@ class WorkerTrainingState:\n         if self._enable_save_before_preemption:\n             self.preemption_handler = (\n                 tf.distribute.experimental.PreemptionCheckpointHandler(\n-                    self._model.distribute_strategy.extended._cluster_resolver,\n+                    self._model.distribute_strategy.cluster_resolver,\n                     self.write_checkpoint_manager,\n                 )\n             )\n             self.preemption_handler._read_checkpoint_manager = (\n                 self.read_checkpoint_manager\n             )\n+            self._model._preemption_handler = self.preemption_handler\n \n     def back_up(self, epoch, batch=0):\n         \"\"\"Back up the current state of training into a checkpoint file.\n@@ -155,7 +146,7 @@ class WorkerTrainingState:\n     def backup_if_preempted(self):\n         if self._enable_save_before_preemption:\n             self.preemption_handler._run_counter += 1\n-            self.preemption_handler._checkpoint_if_preempted()\n+            self.preemption_handler._check_preemption_and_maybe_checkpoint()\n \n     def restore(self):\n         \"\"\"Restore the training state from the backed up checkpoint file.\n\n@@ -25,6 +25,7 @@ import numpy as np\n import tensorflow.compat.v2 as tf\n \n from keras import backend\n+from keras.distribute import distributed_training_utils\n from keras.engine import training_utils\n from keras.utils import data_utils\n from keras.utils import dataset_creator\n@@ -1338,6 +1339,9 @@ class DataHandler:\n     @contextlib.contextmanager\n     def catch_stop_iteration(self):\n         \"\"\"Catches errors when an iterator runs out of data.\"\"\"\n+        with distributed_training_utils.maybe_preemption_handler_scope(\n+            self._model\n+        ):\n             try:\n                 yield\n                 self.sync()\n@@ -1349,10 +1353,10 @@ class DataHandler:\n                     total_epochs = self._epochs - self._initial_epoch\n                     logging.warning(\n                         \"Your input ran out of data; interrupting training. \"\n-                    \"Make sure that your dataset or generator can generate at \"\n-                    \"least `steps_per_epoch * epochs` batches (in this case, \"\n-                    \"{} batches). You may need to use the repeat() function \"\n-                    \"when building your dataset.\".format(\n+                        \"Make sure that your dataset or generator can generate \"\n+                        \"at least `steps_per_epoch * epochs` batches (in this \"\n+                        \"case, {} batches). You may need to use the repeat() \"\n+                        \"function when building your dataset.\".format(\n                             total_epochs * self._inferred_steps\n                         )\n                     )\n\n@@ -957,7 +957,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     def jit_compile(self, value):\n         # Function remains cached with previous jit_compile settings\n         if self._jit_compile == value:\n-            # Avoid reseting compiler cache if possible if the value is the same\n+            # Avoid resetting compiler cache if possible if the value is the\n+            # same\n             return\n         # Check if TensorFlow is compiled with XLA before setting the value\n         if value and not tf_utils.can_jit_compile(warn=True):\n@@ -3297,7 +3298,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     def get_weight_paths(self):\n         \"\"\"Retrieve all the variables and their paths for the model.\n \n-        The variable path (string) is a stable key to indentify a `tf.Variable`\n+        The variable path (string) is a stable key to identify a `tf.Variable`\n         instance owned by the model. It can be used to specify variable-specific\n         configurations (e.g. DTensor, quantization) from a global view.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#68856d6c68d863b2bb0fc5267a932533c709305a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 19 | Churn Cumulative: 16038 | Contributors (this commit): 122 | Commits (past 90d): 13 | Contributors (cumulative): 141 | DMM Complexity: 0.9333333333333333\n\nDIFF:\n@@ -2083,6 +2083,7 @@ class EarlyStopping(Callback):\n                 current, self.baseline\n             ):\n                 self.wait = 0\n+            return\n \n         # Only check after the first epoch.\n         if self.wait >= self.patience and epoch > 0:\n\n@@ -1787,6 +1787,24 @@ class KerasCallbacksTest(test_combinations.TestCase):\n                     verbose=0,\n                 )\n \n+    def test_EarlyStopping_patience(self):\n+        cases = [0, 1, 2, 3]\n+        losses = [10.0, 9.0, 8.0, 9.0, 8.9, 8.8, 8.7, 8.6, 8.5]\n+\n+        for patience in cases:\n+            stopper = keras.callbacks.EarlyStopping(\n+                monitor=\"loss\", patience=patience\n+            )\n+            stopper.model = keras.models.Sequential()\n+            stopper.on_train_begin()\n+\n+            for epoch, loss in enumerate(losses):\n+                stopper.on_epoch_end(epoch=epoch, logs={\"loss\": loss})\n+                if stopper.model.stop_training:\n+                    break\n+\n+            self.assertEqual(stopper.stopped_epoch, max(patience, 1) + 2)\n+\n     def test_EarlyStopping_reuse(self):\n         with self.cached_session():\n             np.random.seed(1337)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#305ee50994491d8cac35a385c96de11592a5c0b8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1471 | Contributors (this commit): 34 | Commits (past 90d): 1 | Contributors (cumulative): 34 | DMM Complexity: 0.0\n\nDIFF:\n@@ -212,6 +212,7 @@ def model_to_dot(\n                     rankdir,\n                     expand_nested,\n                     subgraph=True,\n+                    show_layer_activations=show_layer_activations,\n                     show_trainable=show_trainable,\n                 )\n                 # sub_w : submodel_wrapper\n@@ -233,6 +234,7 @@ def model_to_dot(\n                 rankdir,\n                 expand_nested,\n                 subgraph=True,\n+                show_layer_activations=show_layer_activations,\n                 show_trainable=show_trainable,\n             )\n             # sub_n : submodel_not_wrapper\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ce6b3645e5f3fe0c258acf804359e4666f22fad7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 323 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -26,6 +26,7 @@ from keras.saving.legacy import serialization\n from keras.saving.legacy.saved_model import load as saved_model_load\n from keras.saving.legacy.saved_model import load_context\n from keras.saving.legacy.saved_model import save as saved_model_save\n+from keras.saving.legacy.saved_model.utils import keras_option_scope\n from keras.utils import io_utils\n from keras.utils import traceback_utils\n \n@@ -161,6 +162,9 @@ def save_model(\n         )\n     else:\n         with serialization.SharedObjectSavingScope():\n+            with keras_option_scope(\n+                save_traces=save_traces, in_tf_saved_model_scope=True\n+            ):\n                 saved_model_save.save(\n                     model,\n                     filepath,\n@@ -216,6 +220,9 @@ def load_model(filepath, custom_objects=None, compile=True, options=None):\n     \"\"\"\n     with serialization.SharedObjectLoadingScope():\n         with object_registration.CustomObjectScope(custom_objects or {}):\n+            with keras_option_scope(\n+                save_traces=False, in_tf_saved_model_scope=True\n+            ):\n                 with load_context.load_context(options):\n                     filepath_str = io_utils.path_to_string(filepath)\n                     if isinstance(filepath_str, str):\n@@ -231,8 +238,8 @@ def load_model(filepath, custom_objects=None, compile=True, options=None):\n                         else:\n                             if h5py is None:\n                                 raise ImportError(\n-                                \"Filepath looks like a hdf5 file but h5py is \"\n-                                \"not available.\"\n+                                    \"Filepath looks like a hdf5 file but h5py\"\n+                                    \"is not available.\"\n                                     f\" filepath={filepath_str}\"\n                                 )\n                             return hdf5_format.load_model_from_hdf5(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b46c1a40ae2fa44300cb9aeb26f65d2b229940bc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 67 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 9/5 | Churn Δ: 67 | Churn Cumulative: 912 | Contributors (this commit): 24 | Commits (past 90d): 2 | Contributors (cumulative): 29 | DMM Complexity: 1.0\n\nDIFF:\n@@ -91,3 +91,47 @@ def normalize(x, axis=-1, order=2):\n     l2 = np.atleast_1d(np.linalg.norm(x, order, axis))\n     l2[l2 == 0] = 1\n     return x / np.expand_dims(l2, axis)\n+\n+\n+@keras_export(\"keras.utils.to_ordinal\")\n+def to_ordinal(y, num_classes=None, dtype=\"float32\"):\n+    \"\"\"Converts a class vector (integers) to an ordinal class matrix for ordinal\n+        regression/classification\n+\n+    Args:\n+        y: Array-like with class values to be converted into a matrix\n+            (integers from 0 to `num_classes - 1`).\n+        num_classes: Total number of classes. If `None`, this would be inferred\n+          as `max(y) + 1`.\n+        dtype: The data type expected by the input. Default: `'float32'`.\n+\n+    Returns:\n+        A ordinal regression matrix representation of the input. The class axis\n+        is placed last.\n+\n+    Example:\n+\n+    >>> a = tf.keras.utils.to_ordinal([0, 1, 2, 3], num_classes=4)\n+    >>> a = tf.constant(a, shape=[4, 3])\n+    >>> print(a)\n+    tf.Tensor(\n+      [[0. 0. 0.]\n+       [1. 0. 0.]\n+       [1. 1. 0.]\n+       [1. 1. 1.]], shape=(4, 3), dtype=float32)\n+    \"\"\"\n+    y = np.array(y, dtype=\"int\")\n+    input_shape = y.shape\n+    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n+        input_shape = tuple(input_shape[:-1])\n+    y = y.ravel()\n+    if not num_classes:\n+        num_classes = np.max(y) + 1\n+    n = y.shape[0]\n+    range_values = np.arange(num_classes - 1)\n+    range_values = np.tile(np.expand_dims(range_values, 0), [n, 1])\n+    ordinal = np.zeros((n, num_classes - 1), dtype=dtype)\n+    ordinal[range_values < np.expand_dims(y, -1)] = 1\n+    output_shape = input_shape + (num_classes - 1,)\n+    ordinal = np.reshape(ordinal, output_shape)\n+    return ordinal\n\n@@ -48,6 +48,29 @@ class TestNPUtils(tf.test.TestCase):\n                 np.all(np.argmax(one_hot, -1).reshape(label.shape) == label)\n             )\n \n+    def test_to_ordinal(self):\n+        num_classes = 5\n+        shapes = [(1,), (3,), (4, 3), (5, 4, 3), (3, 1), (3, 2, 1)]\n+        expected_shapes = [\n+            (1, num_classes - 1),\n+            (3, num_classes - 1),\n+            (4, 3, num_classes - 1),\n+            (5, 4, 3, num_classes - 1),\n+            (3, num_classes - 1),\n+            (3, 2, num_classes - 1),\n+        ]\n+        labels = [np.random.randint(0, num_classes, shape) for shape in shapes]\n+        ordinal_matrix = [np_utils.to_ordinal(label, num_classes) for label in labels]\n+        for label, ordinal, expected_shape in zip(\n+            labels, ordinal_matrix, expected_shapes\n+        ):\n+            # Check shape\n+            self.assertEqual(ordinal.shape, expected_shape)\n+            # Make sure all the values are either 0 or 1\n+            self.assertTrue(np.all(np.logical_or(ordinal == 0, ordinal == 1)))\n+            # Get original labels back from ordinal matrix\n+            self.assertTrue(np.all(np.sum(np.cumprod(ordinal, -1), -1) == label))\n+\n \n if __name__ == \"__main__\":\n     tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6fac129d25ef09946a7f87d183ee469f801ac871", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 237 | Contributors (this commit): 17 | Commits (past 90d): 2 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -58,6 +58,7 @@ from keras.utils.layer_utils import get_source_inputs\n # Deprecated\n from keras.utils.np_utils import normalize\n from keras.utils.np_utils import to_categorical\n+from keras.utils.np_utils import to_ordinal\n from keras.utils.data_utils import pad_sequences\n \n # Evaluation related\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6501e8ad844dbe2214c13269546b05c899778eb6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 4065 | Contributors (this commit): 10 | Commits (past 90d): 3 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -1803,9 +1803,9 @@ class CategoricalCrossentropyTest(tf.test.TestCase):\n             warnings.simplefilter(\"always\")\n             cce_obj = losses.CategoricalCrossentropy()\n             cce_obj(tf.constant([[1.0], [0.0]]), tf.constant([[1.0], [1.0]]))\n-            self.assertIsInstance(w[-1].category, SyntaxWarning)\n+            self.assertIs(w[-1].category, SyntaxWarning)\n             self.assertIn(\n-                \"Expected the tensor's shape passed..*\", w[-1].message\n+                \"Expected the tensor's shape passed\", str(w[-1].message)\n             )\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0352c362ba2bdbb40aab19031c819f4434f6ee2d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 10215 | Contributors (this commit): 33 | Commits (past 90d): 14 | Contributors (cumulative): 42 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1962,11 +1962,12 @@ def categorical_crossentropy(\n \n     if y_pred.shape[-1] == 1:\n         warnings.warn(\n-            \"Expected the tensor's shape passed to 'categorical_crossentropy' \"\n-            \"to be (batch_size, n_classes), \"\n-            f\"where n_classes > 1. Received: y_pred.shape={y_pred.shape}. \"\n+            \"In loss categorical_crossentropy, expected \"\n+            \"y_pred.shape to be (batch_size, num_classes) \"\n+            f\"with num_classes > 1. Received: y_pred.shape={y_pred.shape}. \"\n             \"Consider using 'binary_crossentropy' if you only have 2 classes.\",\n             SyntaxWarning,\n+            stacklevel=2,\n         )\n \n     def _smooth_labels():\n\n@@ -1805,7 +1805,8 @@ class CategoricalCrossentropyTest(tf.test.TestCase):\n             cce_obj(tf.constant([[1.0], [0.0]]), tf.constant([[1.0], [1.0]]))\n             self.assertIs(w[-1].category, SyntaxWarning)\n             self.assertIn(\n-                \"Expected the tensor's shape passed\", str(w[-1].message)\n+                \"In loss categorical_crossentropy, expected \",\n+                str(w[-1].message),\n             )\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#aae74da4b878f1cc001c761c644176ed26d32230", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 120 | Contributors (this commit): 5 | Commits (past 90d): 2 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -60,7 +60,9 @@ class TestNPUtils(tf.test.TestCase):\n             (3, 2, num_classes - 1),\n         ]\n         labels = [np.random.randint(0, num_classes, shape) for shape in shapes]\n-        ordinal_matrix = [np_utils.to_ordinal(label, num_classes) for label in labels]\n+        ordinal_matrix = [\n+            np_utils.to_ordinal(label, num_classes) for label in labels\n+        ]\n         for label, ordinal, expected_shape in zip(\n             labels, ordinal_matrix, expected_shapes\n         ):\n@@ -69,7 +71,9 @@ class TestNPUtils(tf.test.TestCase):\n             # Make sure all the values are either 0 or 1\n             self.assertTrue(np.all(np.logical_or(ordinal == 0, ordinal == 1)))\n             # Get original labels back from ordinal matrix\n-            self.assertTrue(np.all(np.sum(np.cumprod(ordinal, -1), -1) == label))\n+            self.assertTrue(\n+                np.all(np.sum(np.cumprod(ordinal, -1), -1) == label)\n+            )\n \n \n if __name__ == \"__main__\":\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#808ef77548fceac684a0bbce6e848a2ceff614b5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 17 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 34 | Churn Cumulative: 834 | Contributors (this commit): 24 | Commits (past 90d): 2 | Contributors (cumulative): 24 | DMM Complexity: None\n\nDIFF:\n@@ -76,23 +76,6 @@ def to_categorical(y, num_classes=None, dtype=\"float32\"):\n     return categorical\n \n \n-@keras_export(\"keras.utils.normalize\")\n-def normalize(x, axis=-1, order=2):\n-    \"\"\"Normalizes a Numpy array.\n-\n-    Args:\n-        x: Numpy array to normalize.\n-        axis: axis along which to normalize.\n-        order: Normalization order (e.g. `order=2` for L2 norm).\n-\n-    Returns:\n-        A normalized copy of the array.\n-    \"\"\"\n-    l2 = np.atleast_1d(np.linalg.norm(x, order, axis))\n-    l2[l2 == 0] = 1\n-    return x / np.expand_dims(l2, axis)\n-\n-\n @keras_export(\"keras.utils.to_ordinal\")\n def to_ordinal(y, num_classes=None, dtype=\"float32\"):\n     \"\"\"Converts a class vector (integers) to an ordinal class matrix for ordinal\n@@ -135,3 +118,20 @@ def to_ordinal(y, num_classes=None, dtype=\"float32\"):\n     output_shape = input_shape + (num_classes - 1,)\n     ordinal = np.reshape(ordinal, output_shape)\n     return ordinal\n+\n+\n+@keras_export(\"keras.utils.normalize\")\n+def normalize(x, axis=-1, order=2):\n+    \"\"\"Normalizes a Numpy array.\n+\n+    Args:\n+        x: Numpy array to normalize.\n+        axis: axis along which to normalize.\n+        order: Normalization order (e.g. `order=2` for L2 norm).\n+\n+    Returns:\n+        A normalized copy of the array.\n+    \"\"\"\n+    l2 = np.atleast_1d(np.linalg.norm(x, order, axis))\n+    l2[l2 == 0] = 1\n+    return x / np.expand_dims(l2, axis)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#416fa79283c1b499c1ad299d2394608034f1a423", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 122 | Contributors (this commit): 5 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -72,7 +72,7 @@ class TestNPUtils(tf.test.TestCase):\n             self.assertTrue(np.all(np.logical_or(ordinal == 0, ordinal == 1)))\n             # Get original labels back from ordinal matrix\n             self.assertTrue(\n-                np.all(np.sum(np.cumprod(ordinal, -1), -1) == label)\n+                ordinal.cumprod(-1).sum(-1).reshape(label.shape) == label\n             )\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#633d7c99ecf9ea3fcaa23eb25f7503582669da8b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 124 | Contributors (this commit): 5 | Commits (past 90d): 4 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -72,8 +72,10 @@ class TestNPUtils(tf.test.TestCase):\n             self.assertTrue(np.all(np.logical_or(ordinal == 0, ordinal == 1)))\n             # Get original labels back from ordinal matrix\n             self.assertTrue(\n+                np.all(\n                     ordinal.cumprod(-1).sum(-1).reshape(label.shape) == label\n                 )\n+            )\n \n \n if __name__ == \"__main__\":\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fa3cc1373d67e2d61c9dfd9bf65286aae9b4c3b7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 576 | Contributors (this commit): 13 | Commits (past 90d): 2 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -187,8 +187,8 @@ class MultiHeadAttention(Layer):\n       dropout: Dropout probability.\n       use_bias: Boolean, whether the dense layers use bias vectors/matrices.\n       output_shape: The expected shape of an output tensor, besides the batch\n-        and sequence dims. If not specified, projects back to the key feature\n-        dim.\n+        and sequence dims. If not specified, projects back to the query feature\n+        dim(the query input last dimension).\n       attention_axes: axes over which the attention is applied. `None` means\n         attention over all axes, but batch, heads, and features.\n       kernel_initializer: Initializer for dense layer kernels.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1d158c53c90100bf91004cf7feb98b71534202a2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 578 | Contributors (this commit): 13 | Commits (past 90d): 3 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -188,7 +188,7 @@ class MultiHeadAttention(Layer):\n       use_bias: Boolean, whether the dense layers use bias vectors/matrices.\n       output_shape: The expected shape of an output tensor, besides the batch\n         and sequence dims. If not specified, projects back to the query feature\n-        dim(the query input last dimension).\n+        dim(the query input's last dimension).\n       attention_axes: axes over which the attention is applied. `None` means\n         attention over all axes, but batch, heads, and features.\n       kernel_initializer: Initializer for dense layer kernels.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4fafa2e26cb6a12fffcf8bd8b918038dc2336255", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 10 | Churn Cumulative: 10864 | Contributors (this commit): 24 | Commits (past 90d): 7 | Contributors (cumulative): 24 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2153,13 +2153,21 @@ class RandomGenerator(tf.__internal__.tracking.AutoTrackable):\n \n     def dropout(self, inputs, rate, noise_shape=None):\n         self._maybe_init()\n-        if self._rng_type in [self.RNG_STATEFUL, self.RNG_STATELESS]:\n+        if self._rng_type == self.RNG_STATEFUL:\n+            return tf.nn.experimental.general_dropout(\n+                inputs,\n+                rate=rate,\n+                noise_shape=noise_shape,\n+                uniform_sampler=self._generator.uniform,\n+            )\n+        elif self._rng_type == self.RNG_STATELESS:\n             return tf.nn.experimental.stateless_dropout(\n                 inputs,\n                 rate=rate,\n                 noise_shape=noise_shape,\n                 seed=self.make_seed_for_stateless_op(),\n             )\n+        else:\n             return tf.nn.dropout(\n                 inputs,\n                 rate=rate,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
