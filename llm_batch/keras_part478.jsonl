{"custom_id": "keras#06521777bdf4419e5e6197e5815ba6a40d4a197f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 408 | Contributors (this commit): 9 | Commits (past 90d): 7 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -180,7 +180,7 @@ class ApplicationsTest(tf.test.TestCase, parameterized.TestCase):\n     def test_application_notop_custom_input_shape(self, app, last_dim):\n         output_shape = _get_output_shape(\n             lambda: app(\n-                weights=None, include_top=False, input_shape=(224, 224, 3)\n+                weights='imagenet', include_top=False, input_shape=(224, 224, 3)\n             )\n         )\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e79ea90f63a3b72664c11826d0917b80ee2240c0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 410 | Contributors (this commit): 9 | Commits (past 90d): 8 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -180,7 +180,7 @@ class ApplicationsTest(tf.test.TestCase, parameterized.TestCase):\n     def test_application_notop_custom_input_shape(self, app, last_dim):\n         output_shape = _get_output_shape(\n             lambda: app(\n-                weights='imagenet', include_top=False, input_shape=(224, 224, 3)\n+                weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3)\n             )\n         )\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4e892602be5291569ecf245d463201e839a7c9e9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 3142 | Contributors (this commit): 17 | Commits (past 90d): 24 | Contributors (cumulative): 27 | DMM Complexity: None\n\nDIFF:\n@@ -123,8 +123,8 @@ class StringLookup(index_lookup.IndexLookup):\n       sparse: Boolean. Only applicable when `output_mode` is `\"multi_hot\"`,\n         `\"count\"`, or `\"tf_idf\"`. If True, returns a `SparseTensor` instead of a\n         dense `Tensor`. Defaults to False.\n-      encoding: Optional. A string representing the encoding to use. Defaults to\n-        `\"utf-8\"`.\n+      encoding: Optional. The text encoding to use to interpret the input\n+        strings. Defaults to `\"utf-8\"`.\n \n     Examples:\n \n\n@@ -174,8 +174,8 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n       sparse: Boolean. Only applicable to `\"multi_hot\"`, `\"count\"`, and\n         `\"tf_idf\"` output modes. If True, returns a `SparseTensor` instead of a\n         dense `Tensor`. Defaults to False.\n-      encoding: Optional. A string representing the encoding to use. Defaults to\n-        `\"utf-8\"`.\n+      encoding: Optional. The text encoding to use to interpret the input\n+        strings. Defaults to `\"utf-8\"`.\n \n     Example:\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a496f9239dae9c6e4ef35688dde1450d5130b087", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 42 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 6 | Complexity Δ (Sum/Max): 15/5 | Churn Δ: 42 | Churn Cumulative: 249 | Contributors (this commit): 4 | Commits (past 90d): 15 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -31,6 +31,20 @@ class GlobalPooling1D(Layer):\n         self.data_format = conv_utils.normalize_data_format(data_format)\n         self.keepdims = keepdims\n     \n+    def _validate_reduction_axis(self, input_shape, axes):\n+        for axis in axes:\n+          if input_shape[axis] == 0:\n+              raise ValueError(\n+                  f\"Incorrect input shape {input_shape} \"\n+                  f\"with dimension 0 at reduction axis {axis}.\")\n+    \n+    def build(self, input_shape):\n+        input_shape = tf.TensorShape(input_shape).as_list()\n+        if self.data_format == 'channels_last':\n+            self._validate_reduction_axis(input_shape, [1])\n+        else:\n+            self._validate_reduction_axis(input_shape, [2])\n+\n     def compute_output_shape(self, input_shape):\n         input_shape = tf.TensorShape(input_shape).as_list()\n         if self.data_format == \"channels_first\":\n\n@@ -31,6 +31,20 @@ class GlobalPooling2D(Layer):\n         self.input_spec = InputSpec(ndim=4)\n         self.keepdims = keepdims\n     \n+    def _validate_reduction_axis(self, input_shape, axes):\n+        for axis in axes:\n+          if input_shape[axis] == 0:\n+              raise ValueError(\n+                  f\"Incorrect input shape {input_shape} \"\n+                  f\"with dimension 0 at reduction axis {axis}.\")\n+    \n+    def build(self, input_shape):\n+        input_shape = tf.TensorShape(input_shape).as_list()\n+        if self.data_format == 'channels_last':\n+            self._validate_reduction_axis(input_shape, [1, 2])\n+        else:\n+            self._validate_reduction_axis(input_shape, [2, 3])\n+\n     def compute_output_shape(self, input_shape):\n         input_shape = tf.TensorShape(input_shape).as_list()\n         if self.data_format == \"channels_last\":\n\n@@ -31,6 +31,20 @@ class GlobalPooling3D(Layer):\n         self.input_spec = InputSpec(ndim=5)\n         self.keepdims = keepdims\n     \n+    def _validate_reduction_axis(self, input_shape, axes):\n+        for axis in axes:\n+          if input_shape[axis] == 0:\n+              raise ValueError(\n+                  f\"Incorrect input shape {input_shape} \"\n+                  f\"with dimension 0 at reduction axis {axis}.\")\n+    \n+    def build(self, input_shape):\n+        input_shape = tf.TensorShape(input_shape).as_list()\n+        if self.data_format == 'channels_last':\n+            self._validate_reduction_axis(input_shape, [1, 2, 3])\n+        else:\n+            self._validate_reduction_axis(input_shape, [2, 3, 4])\n+\n     def compute_output_shape(self, input_shape):\n         input_shape = tf.TensorShape(input_shape).as_list()\n         if self.data_format == \"channels_last\":\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3c6250fc248701f24b353ea9e650a314c41f5476", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 6 | Files Changed: 3 | Hunks: 6 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 264 | Contributors (this commit): 4 | Commits (past 90d): 18 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -36,11 +36,12 @@ class GlobalPooling1D(Layer):\n             if input_shape[axis] == 0:\n                 raise ValueError(\n                     f\"Incorrect input shape {input_shape} \"\n-                  f\"with dimension 0 at reduction axis {axis}.\")\n+                    f\"with dimension 0 at reduction axis {axis}.\"\n+                )\n \n     def build(self, input_shape):\n         input_shape = tf.TensorShape(input_shape).as_list()\n-        if self.data_format == 'channels_last':\n+        if self.data_format == \"channels_last\":\n             self._validate_reduction_axis(input_shape, [1])\n         else:\n             self._validate_reduction_axis(input_shape, [2])\n\n@@ -36,11 +36,12 @@ class GlobalPooling2D(Layer):\n             if input_shape[axis] == 0:\n                 raise ValueError(\n                     f\"Incorrect input shape {input_shape} \"\n-                  f\"with dimension 0 at reduction axis {axis}.\")\n+                    f\"with dimension 0 at reduction axis {axis}.\"\n+                )\n \n     def build(self, input_shape):\n         input_shape = tf.TensorShape(input_shape).as_list()\n-        if self.data_format == 'channels_last':\n+        if self.data_format == \"channels_last\":\n             self._validate_reduction_axis(input_shape, [1, 2])\n         else:\n             self._validate_reduction_axis(input_shape, [2, 3])\n\n@@ -36,11 +36,12 @@ class GlobalPooling3D(Layer):\n             if input_shape[axis] == 0:\n                 raise ValueError(\n                     f\"Incorrect input shape {input_shape} \"\n-                  f\"with dimension 0 at reduction axis {axis}.\")\n+                    f\"with dimension 0 at reduction axis {axis}.\"\n+                )\n \n     def build(self, input_shape):\n         input_shape = tf.TensorShape(input_shape).as_list()\n-        if self.data_format == 'channels_last':\n+        if self.data_format == \"channels_last\":\n             self._validate_reduction_axis(input_shape, [1, 2, 3])\n         else:\n             self._validate_reduction_axis(input_shape, [2, 3, 4])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7fdbf98bb6fb1ed6810d8589ee053abdd64d274c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 33 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 37 | Churn Cumulative: 269 | Contributors (this commit): 9 | Commits (past 90d): 7 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -105,7 +105,7 @@ def serialize(optimizer):\n \n \n @keras_export(\"keras.optimizers.deserialize\")\n-def deserialize(config, custom_objects=None):\n+def deserialize(config, custom_objects=None, **kwargs):\n     \"\"\"Inverse of the `serialize` function.\n \n     Args:\n@@ -123,6 +123,32 @@ def deserialize(config, custom_objects=None):\n         loss_scale_optimizer,\n     )\n \n+    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", True)\n+    if (\n+        tf.__internal__.tf2.enabled()\n+        and tf.executing_eagerly()\n+        and not use_legacy_optimizer\n+    ):\n+        all_classes = {\n+            \"adadelta\": adadelta_experimental.Adadelta,\n+            \"adagrad\": adagrad_experimental.Adagrad,\n+            \"adam\": adam_experimental.Adam,\n+            \"adamax\": adamax_experimental.Adamax,\n+            \"experimentaladadelta\": adadelta_experimental.Adadelta,\n+            \"experimentaladagrad\": adagrad_experimental.Adagrad,\n+            \"experimentaladam\": adam_experimental.Adam,\n+            \"experimentalsgd\": sgd_experimental.SGD,\n+            \"nadam\": nadam_experimental.Nadam,\n+            \"rmsprop\": rmsprop_experimental.RMSprop,\n+            \"sgd\": sgd_experimental.SGD,\n+            \"ftrl\": ftrl_experimental.Ftrl,\n+            \"lossscaleoptimizer\": loss_scale_optimizer.LossScaleOptimizerV3,\n+            \"lossscaleoptimizerv3\": loss_scale_optimizer.LossScaleOptimizerV3,\n+            # LossScaleOptimizerV1 was an old version of LSO that was removed.\n+            # Deserializing it turns it into a LossScaleOptimizer\n+            \"lossscaleoptimizerv1\": loss_scale_optimizer.LossScaleOptimizer,\n+        }\n+    else:\n         all_classes = {\n             \"adadelta\": adadelta_v2.Adadelta,\n             \"adagrad\": adagrad_v2.Adagrad,\n@@ -155,7 +181,7 @@ def deserialize(config, custom_objects=None):\n \n \n @keras_export(\"keras.optimizers.get\")\n-def get(identifier):\n+def get(identifier, **kwargs):\n     \"\"\"Retrieves a Keras Optimizer instance.\n \n     Args:\n@@ -172,6 +198,7 @@ def get(identifier):\n     Raises:\n         ValueError: If `identifier` cannot be interpreted.\n     \"\"\"\n+    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", True)\n     if isinstance(\n         identifier,\n         (\n@@ -187,10 +214,12 @@ def get(identifier):\n         backend.track_tf_optimizer(opt)\n         return opt\n     elif isinstance(identifier, dict):\n-        return deserialize(identifier)\n+        return deserialize(\n+            identifier, use_legacy_optimizer=use_legacy_optimizer\n+        )\n     elif isinstance(identifier, str):\n         config = {\"class_name\": str(identifier), \"config\": {}}\n-        return deserialize(config)\n+        return deserialize(config, use_legacy_optimizer=use_legacy_optimizer)\n     else:\n         raise ValueError(\n             f\"Could not interpret optimizer identifier: {identifier}\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d85e3ddac4c982dec760325eac718138b1ccde8a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 10 | Churn Cumulative: 1196 | Contributors (this commit): 7 | Commits (past 90d): 24 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -297,6 +297,11 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n \n     @learning_rate.setter\n     def learning_rate(self, learning_rate):\n+        if isinstance(\n+            learning_rate, learning_rate_schedule.LearningRateSchedule\n+        ):\n+            self._learning_rate = learning_rate\n+        else:\n             if isinstance(\n                 self._learning_rate, learning_rate_schedule.LearningRateSchedule\n             ):\n\n@@ -215,6 +215,11 @@ class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n         self.assertTrue(\n             optimizer.learning_rate < 0.01 and optimizer.learning_rate > 0.00999\n         )\n+        # Check it does not throw error to set `learning_rate` by a\n+        # LearningRateScheduler instance.\n+        optimizer.learning_rate = learning_rate_schedule.ExponentialDecay(\n+            initial_learning_rate=1e-2, decay_steps=10000, decay_rate=0.9\n+        )\n         with self.assertRaisesRegex(\n             TypeError, \"This optimizer was created with*\"\n         ):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5be6742aedc47c23555b642b599f50323b85c61e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 6 | Churn Cumulative: 19745 | Contributors (this commit): 132 | Commits (past 90d): 27 | Contributors (cumulative): 132 | DMM Complexity: None\n\nDIFF:\n@@ -934,6 +934,12 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         \"\"\"Settable attribute indicating how the model should reduce\n         loss and metric values from replicas.\n \n+        By default, tf.distribute takes care of proper synchronization\n+        so that \"first\" is sufficient. If you implement a custom `train_step`\n+        as described in [distributed training guide](\n+            https://www.tensorflow.org/guide/distributed_training#use_tfdistributestrategy_with_custom_training_loops)\n+        you should set this property to `\"sum\"`.\n+\n         Default: 'first', which will get the value from the first replica.\n         \"\"\"\n         return self._distribute_reduction_method or \"first\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#88859985f40a9cfb91762d7cfb76c2fc59565f63", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 19746 | Contributors (this commit): 132 | Commits (past 90d): 28 | Contributors (cumulative): 132 | DMM Complexity: None\n\nDIFF:\n@@ -939,6 +939,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         as described in [distributed training guide](\n             https://www.tensorflow.org/guide/distributed_training#use_tfdistributestrategy_with_custom_training_loops)\n         you should set this property to `\"sum\"`.\n+        This doesn't affect TPU training, where `\"first\"` should be used.\n \n         Default: 'first', which will get the value from the first replica.\n         \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7a00caa84b3779fa4c70380d42f012a5f447e247", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 226 | Contributors (this commit): 6 | Commits (past 90d): 7 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -63,7 +63,8 @@ class DTensorBaseTest(tf.test.TestCase, parameterized.TestCase):\n             mesh = device_type_mesh_map.get(device_type, None)\n             if mesh is None:\n                 raise ValueError(\n-                    f\"Requires a {device_type} mesh to run test on {device_type}.\"\n+                    dt = device_type\n+                    f\"Requires a {dt} mesh to run test on {dt}.\"\n                 )\n             return mesh\n \n@@ -140,7 +141,8 @@ def reset_logical_devices(device_type, count):\n         )\n     else:\n         raise ValueError(\n-            f\"resetting logical device for non-supported device type : {device_type}\"\n+            dt = device_type\n+            f\"resetting logical device for non-supported device type: {dt}\"\n         )\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#61964244052edac595ebb898b97e1fb1f5ae5c23", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 10775 | Contributors (this commit): 19 | Commits (past 90d): 27 | Contributors (cumulative): 24 | DMM Complexity: None\n\nDIFF:\n@@ -1815,7 +1815,7 @@ def identity(x, name=None):\n # tf.random.Generator to generate random numbers.\n # The legacy behavior is to use TF's legacy stateful RNG ops like\n # tf.random.uniform.\n-_USE_GENERATOR_FOR_RNG = False\n+_USE_GENERATOR_FOR_RNG = True\n \n # The global generator to create the seed when initializing the\n # tf.random.Genrator used by RandomGenerator. When tf.random.Generator becomes\n\n@@ -43,7 +43,7 @@ class Dropout(base_layer.BaseRandomLayer):\n     `trainable` does not affect the layer's behavior, as Dropout does\n     not have any variables/weights that can be frozen during training.)\n \n-    >>> tf.random.set_seed(0)\n+    >>> tf.keras.utils.set_random_seed(0)\n     >>> layer = tf.keras.layers.Dropout(.2, input_shape=(2,))\n     >>> data = np.arange(10).reshape(5, 2).astype(np.float32)\n     >>> print(data)\n@@ -56,7 +56,7 @@ class Dropout(base_layer.BaseRandomLayer):\n     >>> print(outputs)\n     tf.Tensor(\n     [[ 0.    1.25]\n-     [ 2.5   3.75]\n+     [ 0.    3.75]\n      [ 5.    6.25]\n      [ 7.5   8.75]\n      [10.    0.  ]], shape=(5, 2), dtype=float32)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#26ea823bdc75f8d77ef1d23b327d5c62647e5ce4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 230 | Contributors (this commit): 6 | Commits (past 90d): 8 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -62,8 +62,8 @@ class DTensorBaseTest(tf.test.TestCase, parameterized.TestCase):\n         def get_mesh(device_type):\n             mesh = device_type_mesh_map.get(device_type, None)\n             if mesh is None:\n-                raise ValueError(\n                 dt = device_type\n+                raise ValueError(\n                     f\"Requires a {dt} mesh to run test on {dt}.\"\n                 )\n             return mesh\n@@ -140,8 +140,8 @@ def reset_logical_devices(device_type, count):\n             * count,\n         )\n     else:\n-        raise ValueError(\n         dt = device_type\n+        raise ValueError(\n             f\"resetting logical device for non-supported device type: {dt}\"\n         )\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#472e33e27cbade8658f90b0ba0378722dbf7e7c6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 37 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 5 | Methods Changed: 6 | Complexity Δ (Sum/Max): 7/5 | Churn Δ: 41 | Churn Cumulative: 28147 | Contributors (this commit): 135 | Commits (past 90d): 43 | Contributors (cumulative): 151 | DMM Complexity: 1.0\n\nDIFF:\n@@ -943,7 +943,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n \n         Default: 'first', which will get the value from the first replica.\n         \"\"\"\n-        return self._distribute_reduction_method or \"first\"\n+        return self._distribute_reduction_method or \"auto\"\n \n     @distribute_reduction_method.setter\n     def distribute_reduction_method(self, value):\n@@ -3764,7 +3764,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         return saving_lib.save(self, dirpath)\n \n \n-def reduce_per_replica(values, strategy, reduction=\"first\"):\n+def reduce_per_replica(values, strategy, reduction=\"auto\"):\n     \"\"\"Attempt to reduce the structure `values` to single values.\n \n     Given `values` (a `tf.Tensor` or a `PerReplica` structure),\n@@ -3807,6 +3807,9 @@ def reduce_per_replica(values, strategy, reduction=\"first\"):\n       ValueError: if the reduction method is not supported.\n     \"\"\"\n \n+    if reduction == \"auto\":\n+        reduction = \"first\" if _is_tpu_multi_host(strategy) else \"sum\"\n+\n     def _reduce(v):\n         \"\"\"Reduce a single `PerReplica` object.\"\"\"\n         if reduction == \"concat\" and _collective_all_reduce_multi_worker(\n\n@@ -146,7 +146,38 @@ class TrainingTest(test_combinations.TestCase):\n         model.predict(x)\n \n     @test_combinations.run_all_keras_modes(always_skip_v1=True)\n-    def test_distribution_reduction_method_sum(self):\n+    def test_distribution_reduction_method_sum_default_train_step(self):\n+\n+        strategy = tf.distribute.MirroredStrategy(\n+            [\"/cpu:1\", \"/cpu:2\", \"/cpu:3\", \"/cpu:4\"]\n+        )\n+        BATCH_SIZE = 10\n+\n+        # A model that always outputs `1`:\n+        with strategy.scope():\n+            inputs = layers_module.Input(shape=(1,), name=\"my_input\")\n+            outputs = layers_module.Dense(\n+                units=1, kernel_initializer=\"zeros\", bias_initializer=\"ones\"\n+            )(inputs)\n+            model = training_module.Model(inputs, outputs)\n+\n+        model.trainable = False\n+        model.compile(optimizer=\"sgd\", loss=\"mean_absolute_error\")\n+\n+        # Data points are always equal to `2`:\n+        x, y = 2 * np.ones((40, 1)), 2 * np.ones((40, 1))\n+\n+        # For every output x_i = 1, every target y_i = 2,\n+        #   loss_i     = |1-2| = 1; and\n+        #   loss_total = sum([1, 1, ..., 1]) / BATCH_SIZE = 1.0\n+        history = model.fit(x, y, epochs=1, batch_size=BATCH_SIZE)\n+        self.assertAllClose(history.history[\"loss\"][-1], 1.0)\n+\n+        eval_output = model.evaluate(x, y, batch_size=BATCH_SIZE)\n+        self.assertAllClose(eval_output, 1.0)\n+\n+    @test_combinations.run_all_keras_modes(always_skip_v1=True)\n+    def test_distribution_reduction_method_sum_custom_train_step(self):\n \n         strategy = tf.distribute.MirroredStrategy(\n             [\"/cpu:1\", \"/cpu:2\", \"/cpu:3\", \"/cpu:4\"]\n@@ -183,7 +214,6 @@ class TrainingTest(test_combinations.TestCase):\n             outputs = layers_module.Dense(1)(inputs)\n             model = MyModel(inputs, outputs)\n \n-        model.distribute_reduction_method = \"sum\"\n         model.compile()\n \n         x, y = np.ones((40, 1)), np.ones((40, 1))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c55e5b5f0357e1548a9a2647321bdc9b2cc34639", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 3105 | Contributors (this commit): 14 | Commits (past 90d): 7 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -26,12 +26,12 @@ Only the NASNet-A models, and their respective weights, which are suited\n for ImageNet 2012 are provided.\n \n The below table describes the performance on ImageNet 2012:\n---------------------------------------------------------------------------------\n+---------------------------------------------------------------------------\n+\n Architecture         | Top-1 Acc | Top-5 Acc |  Multiply-Adds |  Params (M)\n---------------------------------------------------------------------------------\n-|   NASNet-A (4 @ 1056)  |   74.0 %  |   91.6 %  |       564 M    |     5.3    |\n-|   NASNet-A (6 @ 4032)  |   82.7 %  |   96.2 %  |      23.8 B    |    88.9    |\n---------------------------------------------------------------------------------\n+---------------------|-----------|-----------|----------------|------------\n+NASNet-A (4 @ 1056)  |   74.0 %  |   91.6 %  |       564 M    |     5.3    \n+NASNet-A (6 @ 4032)  |   82.7 %  |   96.2 %  |      23.8 B    |    88.9  \n \n Reference:\n   - [Learning Transferable Architectures for Scalable Image Recognition](\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2e4ccdabab8419996c39bcc83315a04645a966bc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 1028 | Contributors (this commit): 10 | Commits (past 90d): 6 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -43,9 +43,11 @@ are provided (224, 192, 160, 128, and 96).\n The following table describes the performance of\n MobileNet on various input sizes:\n ------------------------------------------------------------------------\n+\n MACs stands for Multiply Adds\n+\n  Classification Checkpoint|MACs (M)|Parameters (M)|Top 1 Accuracy|Top 5 Accuracy\n---------------------------|------------|---------------|---------|----|---------\n+--------------------------|------------|---------------|---------|------------\n | [mobilenet_v2_1.4_224]  | 582 | 6.06 |          75.0 | 92.5 |\n | [mobilenet_v2_1.3_224]  | 509 | 5.34 |          74.4 | 92.1 |\n | [mobilenet_v2_1.0_224]  | 300 | 3.47 |          71.8 | 91.0 |\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#24c27de74747fba5aac278bd9916854b618c649b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 2410 | Contributors (this commit): 17 | Commits (past 90d): 5 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -38,23 +38,22 @@ The following table describes the size and accuracy of the 100% MobileNet\n on size 224 x 224:\n ----------------------------------------------------------------------------\n Width Multiplier (alpha) | ImageNet Acc |  Multiply-Adds (M) |  Params (M)\n-----------------------------------------------------------------------------\n+-------------------------|---------------|-------------------|--------------\n |   1.0 MobileNet-224    |    70.6 %     |        529        |     4.2     |\n |   0.75 MobileNet-224   |    68.4 %     |        325        |     2.6     |\n |   0.50 MobileNet-224   |    63.7 %     |        149        |     1.3     |\n |   0.25 MobileNet-224   |    50.6 %     |        41         |     0.5     |\n-----------------------------------------------------------------------------\n \n The following table describes the performance of\n the 100 % MobileNet on various input sizes:\n ------------------------------------------------------------------------\n Resolution      | ImageNet Acc | Multiply-Adds (M) | Params (M)\n-------------------------------------------------------------------------\n+----------------------|---------------|-------------------|----------------\n |  1.0 MobileNet-224  |    70.6 %    |        569        |     4.2     |\n |  1.0 MobileNet-192  |    69.1 %    |        418        |     4.2     |\n |  1.0 MobileNet-160  |    67.2 %    |        290        |     4.2     |\n |  1.0 MobileNet-128  |    64.4 %    |        186        |     4.2     |\n-------------------------------------------------------------------------\n+\n Reference:\n   - [MobileNets: Efficient Convolutional Neural Networks\n      for Mobile Vision Applications](\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e3b551408539fe8b3fb343c8d7b1209e628704c2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 3106 | Contributors (this commit): 14 | Commits (past 90d): 8 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -27,7 +27,6 @@ for ImageNet 2012 are provided.\n \n The below table describes the performance on ImageNet 2012:\n ---------------------------------------------------------------------------\n-\n Architecture         | Top-1 Acc | Top-5 Acc |  Multiply-Adds |  Params (M)\n ---------------------|-----------|-----------|----------------|------------\n NASNet-A (4 @ 1056)  |   74.0 %  |   91.6 %  |       564 M    |     5.3    \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2707b23790ab4d99d48934d651eb9e18f2fc7d7a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1030 | Contributors (this commit): 10 | Commits (past 90d): 7 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -43,9 +43,7 @@ are provided (224, 192, 160, 128, and 96).\n The following table describes the performance of\n MobileNet on various input sizes:\n ------------------------------------------------------------------------\n-\n MACs stands for Multiply Adds\n-\n Classification Checkpoint|MACs (M)|Parameters (M)|Top 1 Accuracy|Top 5 Accuracy\n --------------------------|------------|---------------|---------|------------\n | [mobilenet_v2_1.4_224]  | 582 | 6.06 |          75.0 | 92.5 |\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#33e9160548e2297b09a7f5eb8c5aebaced3677be", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 12 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 19770 | Contributors (this commit): 132 | Commits (past 90d): 30 | Contributors (cumulative): 132 | DMM Complexity: 1.0\n\nDIFF:\n@@ -934,14 +934,9 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         \"\"\"Settable attribute indicating how the model should reduce\n         loss and metric values from replicas.\n \n-        By default, tf.distribute takes care of proper synchronization\n-        so that \"first\" is sufficient. If you implement a custom `train_step`\n-        as described in [distributed training guide](\n-            https://www.tensorflow.org/guide/distributed_training#use_tfdistributestrategy_with_custom_training_loops)\n-        you should set this property to `\"sum\"`.\n-        This doesn't affect TPU training, where `\"first\"` should be used.\n-\n-        Default: 'first', which will get the value from the first replica.\n+        Default: `\"auto\"`. This should be good for all cases.\n+        It boils down to using `\"sum\"` or `\"first\"` conditioned on\n+        whether TPU is used.\n         \"\"\"\n         return self._distribute_reduction_method or \"auto\"\n \n@@ -3827,13 +3822,11 @@ def reduce_per_replica(values, strategy, reduction=\"auto\"):\n                 return concat(strategy.experimental_local_results(v))\n         elif reduction == \"sum\":\n             values = strategy.experimental_local_results(v)\n-            # TODO remove me before finalizing PR\n-            tf.print(\"reduce-sum\", tf.stack(values))\n             return tf.reduce_sum(values)\n         else:\n             raise ValueError(\n-                '`reduction` must be \"first\", \"concat\", or \"sum\". Received: '\n-                f\"reduction={reduction}.\"\n+                '`reduction` must be \"first\", \"concat\", \"sum\", or \"auto\". '\n+                f\"Received: reduction={reduction}.\"\n             )\n \n     return tf.nest.map_structure(_reduce, values)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#371514a8af71999975c8b45dda925f75f5b85eae", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 234 | Contributors (this commit): 6 | Commits (past 90d): 9 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -63,9 +63,7 @@ class DTensorBaseTest(tf.test.TestCase, parameterized.TestCase):\n             mesh = device_type_mesh_map.get(device_type, None)\n             if mesh is None:\n                 dt = device_type\n-                raise ValueError(\n-                    f\"Requires a {dt} mesh to run test on {dt}.\"\n-                )\n+                raise ValueError(f\"Requires a {dt} mesh to run test on {dt}.\")\n             return mesh\n \n         mesh = None\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#015a0bcb255c1ed808455e1a9dd35e8eafe2fc39", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 2857 | Contributors (this commit): 19 | Commits (past 90d): 14 | Contributors (cumulative): 19 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1439,6 +1439,11 @@ class DataHandler:\n         if adapter_steps is not None:\n             return adapter_steps\n \n+        # tf.distribute's `PerWorkerDataset` does not inherit from\n+        # `tf.data.Dataset` and in those cases we give up on inferring steps.\n+        if not isinstance(dataset, tf.data.Dataset):\n+            return None\n+\n         size = tf.data.experimental.cardinality(dataset)\n         if size == tf.data.experimental.INFINITE_CARDINALITY and steps is None:\n             raise ValueError(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3e31a224db02ca79aa4d63c6eecc7d4a19c38768", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 5 | Files Changed: 9 | Hunks: 14 | Methods Changed: 13 | Complexity Δ (Sum/Max): 6/1 | Churn Δ: 36 | Churn Cumulative: 8011 | Contributors (this commit): 20 | Commits (past 90d): 84 | Contributors (cumulative): 72 | DMM Complexity: 0.0\n\nDIFF:\n@@ -929,7 +929,9 @@ class LossScaleOptimizer(\n                 )\n             config[\"inner_optimizer\"] = config.pop(\"optimizer\")\n         inner_optimizer = optimizers.deserialize(\n-            config[\"inner_optimizer\"], custom_objects=custom_objects\n+            config[\"inner_optimizer\"],\n+            custom_objects=custom_objects,\n+            use_legacy_optimizer=True,\n         )\n         del config[\"inner_optimizer\"]\n         return cls(inner_optimizer, **config)\n@@ -1366,7 +1368,9 @@ class LossScaleOptimizerV3(\n     def from_config(cls, config, custom_objects=None):\n         config = config.copy()  # Make a copy, since we mutate config\n         inner_optimizer = optimizers.deserialize(\n-            config[\"inner_optimizer\"], custom_objects=custom_objects\n+            config[\"inner_optimizer\"],\n+            custom_objects=custom_objects,\n+            use_legacy_optimizer=False,\n         )\n         del config[\"inner_optimizer\"]\n         return cls(inner_optimizer, **config)\n\n@@ -91,7 +91,8 @@ def serialize(optimizer):\n     `Optimizer` instance again.\n \n     >>> tf.keras.optimizers.serialize(tf.keras.optimizers.SGD())\n-    {'class_name': 'SGD', 'config': {'name': 'SGD', 'learning_rate': 0.01,\n+    {'class_name': 'SGD', 'config': {'name': 'SGD', 'is_legacy_optimizer': True,\n+                                     'learning_rate': 0.01,\n                                      'decay': 0.0, 'momentum': 0.0,\n                                      'nesterov': False}}\n \n@@ -124,6 +125,11 @@ def deserialize(config, custom_objects=None, **kwargs):\n     )\n \n     use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", True)\n+    if \"is_legacy_optimizer\" in config[\"config\"]:\n+        # If the optimizer to deserialize has `is_legacy_optimizer`, use it to\n+        # override `use_legacy_optimizer`. This happens when loading a saved\n+        # optimizer.\n+        use_legacy_optimizer = config[\"config\"][\"is_legacy_optimizer\"]\n     if (\n         tf.__internal__.tf2.enabled()\n         and tf.executing_eagerly()\n\n@@ -619,6 +619,7 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n             \"ema_momentum\": self.ema_momentum,\n             \"ema_overwrite_frequency\": self.ema_overwrite_frequency,\n             \"jit_compile\": self.jit_compile,\n+            \"is_legacy_optimizer\": False,\n         }\n         return config\n \n@@ -640,6 +641,8 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n                 config[\"learning_rate\"] = learning_rate_schedule.deserialize(\n                     config[\"learning_rate\"]\n                 )\n+        if \"is_legacy_optimizer\" in config:\n+            del config[\"is_legacy_optimizer\"]\n         return cls(**config)\n \n     @doc_controls.do_not_generate_docs\n\n@@ -297,6 +297,7 @@ class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n             \"use_ema\": True,\n             \"ema_momentum\": 0.5,\n             \"ema_overwrite_frequency\": 50,\n+            \"is_legacy_optimizer\": False,\n         }\n         self.assertDictContainsSubset(expected_config, config)\n         restored_optimizer = adam_new.Adam.from_config(config)\n\n@@ -148,7 +148,7 @@ class Optimizer:\n         return backend.batch_get_value(self.weights)\n \n     def get_config(self):\n-        config = {}\n+        config = {\"is_legacy_optimizer\": True}\n         if hasattr(self, \"clipnorm\"):\n             config[\"clipnorm\"] = self.clipnorm\n         if hasattr(self, \"clipvalue\"):\n@@ -157,6 +157,8 @@ class Optimizer:\n \n     @classmethod\n     def from_config(cls, config):\n+        if \"is_legacy_optimizer\" in config:\n+            del config[\"is_legacy_optimizer\"]\n         return cls(**config)\n \n \n\n@@ -132,6 +132,8 @@ class Adagrad(optimizer_v2.OptimizerV2):\n             config[\"initial_accumulator_value\"] = 0.1\n         if \"lr\" in config:\n             config[\"learning_rate\"] = config.pop(\"lr\")\n+        if \"is_legacy_optimizer\" in config:\n+            del config[\"is_legacy_optimizer\"]\n         return cls(**config)\n \n     def _resource_apply_dense(self, grad, var, apply_state=None):\n\n@@ -1182,7 +1182,10 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n         Returns:\n             Python dictionary.\n         \"\"\"\n-        config = {\"name\": self._name}\n+        config = {\n+            \"name\": self._name,\n+            \"is_legacy_optimizer\": True,\n+        }\n         if self.clipnorm is not None:\n             config[\"clipnorm\"] = self.clipnorm\n         if self.clipvalue is not None:\n@@ -1215,6 +1218,8 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n                 config[\"learning_rate\"] = learning_rate_schedule.deserialize(\n                     config[\"learning_rate\"], custom_objects=custom_objects\n                 )\n+        if \"is_legacy_optimizer\" in config:\n+            del config[\"is_legacy_optimizer\"]\n         return cls(**config)\n \n     def _serialize_hyperparameter(self, hyperparameter_name):\n\n@@ -304,6 +304,7 @@ class OptimizerTest(tf.test.TestCase, parameterized.TestCase):\n         with test_utils.use_gpu():\n             opt = gradient_descent.SGD(learning_rate=1.0)\n             config = opt.get_config()\n+            self.assertEqual(config[\"is_legacy_optimizer\"], True)\n             opt2 = gradient_descent.SGD.from_config(config)\n             lr = opt._get_hyper(\"learning_rate\")\n             lr2 = opt2._get_hyper(\"learning_rate\")\n\n@@ -92,6 +92,8 @@ class KerasOptimizersTest(test_combinations.TestCase):\n             new_config[\"config\"].pop(\"momentum\", None)\n         if \"centered\" not in config[\"config\"]:\n             new_config[\"config\"].pop(\"centered\", None)\n+        if \"is_legacy_optimizer\" not in config[\"config\"]:\n+            new_config[\"config\"].pop(\"is_legacy_optimizer\", None)\n         self.assertDictEqual(config, new_config)\n \n         # Test constraints.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a2ad3ef9cbc960ed2809e9ecc1417dd649f6cded", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 31 | Files Changed: 9 | Hunks: 14 | Methods Changed: 13 | Complexity Δ (Sum/Max): -6/0 | Churn Δ: 36 | Churn Cumulative: 8047 | Contributors (this commit): 20 | Commits (past 90d): 93 | Contributors (cumulative): 72 | DMM Complexity: 1.0\n\nDIFF:\n@@ -929,9 +929,7 @@ class LossScaleOptimizer(\n                 )\n             config[\"inner_optimizer\"] = config.pop(\"optimizer\")\n         inner_optimizer = optimizers.deserialize(\n-            config[\"inner_optimizer\"],\n-            custom_objects=custom_objects,\n-            use_legacy_optimizer=True,\n+            config[\"inner_optimizer\"], custom_objects=custom_objects\n         )\n         del config[\"inner_optimizer\"]\n         return cls(inner_optimizer, **config)\n@@ -1368,9 +1366,7 @@ class LossScaleOptimizerV3(\n     def from_config(cls, config, custom_objects=None):\n         config = config.copy()  # Make a copy, since we mutate config\n         inner_optimizer = optimizers.deserialize(\n-            config[\"inner_optimizer\"],\n-            custom_objects=custom_objects,\n-            use_legacy_optimizer=False,\n+            config[\"inner_optimizer\"], custom_objects=custom_objects\n         )\n         del config[\"inner_optimizer\"]\n         return cls(inner_optimizer, **config)\n\n@@ -91,8 +91,7 @@ def serialize(optimizer):\n     `Optimizer` instance again.\n \n     >>> tf.keras.optimizers.serialize(tf.keras.optimizers.SGD())\n-    {'class_name': 'SGD', 'config': {'name': 'SGD', 'is_legacy_optimizer': True,\n-                                     'learning_rate': 0.01,\n+    {'class_name': 'SGD', 'config': {'name': 'SGD', 'learning_rate': 0.01,\n                                      'decay': 0.0, 'momentum': 0.0,\n                                      'nesterov': False}}\n \n@@ -125,11 +124,6 @@ def deserialize(config, custom_objects=None, **kwargs):\n     )\n \n     use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", True)\n-    if \"is_legacy_optimizer\" in config[\"config\"]:\n-        # If the optimizer to deserialize has `is_legacy_optimizer`, use it to\n-        # override `use_legacy_optimizer`. This happens when loading a saved\n-        # optimizer.\n-        use_legacy_optimizer = config[\"config\"][\"is_legacy_optimizer\"]\n     if (\n         tf.__internal__.tf2.enabled()\n         and tf.executing_eagerly()\n\n@@ -619,7 +619,6 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n             \"ema_momentum\": self.ema_momentum,\n             \"ema_overwrite_frequency\": self.ema_overwrite_frequency,\n             \"jit_compile\": self.jit_compile,\n-            \"is_legacy_optimizer\": False,\n         }\n         return config\n \n@@ -641,8 +640,6 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n                 config[\"learning_rate\"] = learning_rate_schedule.deserialize(\n                     config[\"learning_rate\"]\n                 )\n-        if \"is_legacy_optimizer\" in config:\n-            del config[\"is_legacy_optimizer\"]\n         return cls(**config)\n \n     @doc_controls.do_not_generate_docs\n\n@@ -297,7 +297,6 @@ class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n             \"use_ema\": True,\n             \"ema_momentum\": 0.5,\n             \"ema_overwrite_frequency\": 50,\n-            \"is_legacy_optimizer\": False,\n         }\n         self.assertDictContainsSubset(expected_config, config)\n         restored_optimizer = adam_new.Adam.from_config(config)\n\n@@ -148,7 +148,7 @@ class Optimizer:\n         return backend.batch_get_value(self.weights)\n \n     def get_config(self):\n-        config = {\"is_legacy_optimizer\": True}\n+        config = {}\n         if hasattr(self, \"clipnorm\"):\n             config[\"clipnorm\"] = self.clipnorm\n         if hasattr(self, \"clipvalue\"):\n@@ -157,8 +157,6 @@ class Optimizer:\n \n     @classmethod\n     def from_config(cls, config):\n-        if \"is_legacy_optimizer\" in config:\n-            del config[\"is_legacy_optimizer\"]\n         return cls(**config)\n \n \n\n@@ -132,8 +132,6 @@ class Adagrad(optimizer_v2.OptimizerV2):\n             config[\"initial_accumulator_value\"] = 0.1\n         if \"lr\" in config:\n             config[\"learning_rate\"] = config.pop(\"lr\")\n-        if \"is_legacy_optimizer\" in config:\n-            del config[\"is_legacy_optimizer\"]\n         return cls(**config)\n \n     def _resource_apply_dense(self, grad, var, apply_state=None):\n\n@@ -1182,10 +1182,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n         Returns:\n             Python dictionary.\n         \"\"\"\n-        config = {\n-            \"name\": self._name,\n-            \"is_legacy_optimizer\": True,\n-        }\n+        config = {\"name\": self._name}\n         if self.clipnorm is not None:\n             config[\"clipnorm\"] = self.clipnorm\n         if self.clipvalue is not None:\n@@ -1218,8 +1215,6 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n                 config[\"learning_rate\"] = learning_rate_schedule.deserialize(\n                     config[\"learning_rate\"], custom_objects=custom_objects\n                 )\n-        if \"is_legacy_optimizer\" in config:\n-            del config[\"is_legacy_optimizer\"]\n         return cls(**config)\n \n     def _serialize_hyperparameter(self, hyperparameter_name):\n\n@@ -304,7 +304,6 @@ class OptimizerTest(tf.test.TestCase, parameterized.TestCase):\n         with test_utils.use_gpu():\n             opt = gradient_descent.SGD(learning_rate=1.0)\n             config = opt.get_config()\n-            self.assertEqual(config[\"is_legacy_optimizer\"], True)\n             opt2 = gradient_descent.SGD.from_config(config)\n             lr = opt._get_hyper(\"learning_rate\")\n             lr2 = opt2._get_hyper(\"learning_rate\")\n\n@@ -92,8 +92,6 @@ class KerasOptimizersTest(test_combinations.TestCase):\n             new_config[\"config\"].pop(\"momentum\", None)\n         if \"centered\" not in config[\"config\"]:\n             new_config[\"config\"].pop(\"centered\", None)\n-        if \"is_legacy_optimizer\" not in config[\"config\"]:\n-            new_config[\"config\"].pop(\"is_legacy_optimizer\", None)\n         self.assertDictEqual(config, new_config)\n \n         # Test constraints.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
