{"custom_id": "keras#a0201b66fc18f192dad2a18b045abb430409159e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 92 | Lines Deleted: 40 | Files Changed: 2 | Hunks: 34 | Methods Changed: 12 | Complexity Δ (Sum/Max): 12/6 | Churn Δ: 132 | Churn Cumulative: 1252 | Contributors (this commit): 3 | Commits (past 90d): 12 | Contributors (cumulative): 5 | DMM Complexity: 0.4222222222222222\n\nDIFF:\n@@ -5,6 +5,7 @@ from keras_core.utils import dtype_utils\n from keras_core.utils import text_rendering\n import math\n import re\n+import string\n \n \n def count_params(weights):\n@@ -120,12 +121,12 @@ def print_summary(\n                     break\n \n     if sequential_like:\n-        line_length = line_length or 65\n+        line_length = line_length or 84\n         positions = positions or [0.45, 0.85, 1.0]\n         # header names for the different log elements\n         header = [\"Layer (type)\", \"Output Shape\", \"Param #\"]\n     else:\n-        line_length = line_length or 98\n+        line_length = line_length or 100\n         positions = positions or [0.3, 0.6, 0.70, 1.0]\n         # header names for the different log elements\n         header = [\"Layer (type)\", \"Output Shape\", \"Param #\", \"Connected to\"]\n@@ -134,15 +135,21 @@ def print_summary(\n             relevant_nodes += v\n \n     if show_trainable:\n-        line_length += 11\n-        positions.append(line_length)\n+        line_length += 8\n+        positions = [p * 0.86 for p in positions] + [1.0]\n         header.append(\"Trainable\")\n \n     layer_range = get_layer_index_bound_by_layer_name(model, layer_range)\n \n-    print_fn(f'Model: \"{model.name}\"')\n+    print_fn(text_rendering.highlight_msg(f' Model: \"{model.name}\"'))\n     rows = []\n \n+    def format_shape(shape):\n+        shape = tuple(shape)\n+        if len(shape) == 1 and isinstance(shape[0], tuple):\n+            shape = shape[0]\n+        return str(shape)\n+\n     def print_layer_summary(layer, prefix=\"\"):\n         \"\"\"Prints a summary for a single layer.\n \n@@ -152,7 +159,7 @@ def print_summary(\n               (e.g. 0 for a top-level layer, 1 for a nested layer).\n         \"\"\"\n         try:\n-            output_shape = layer.output_shape\n+            output_shape = format_shape(layer.output_shape)\n         except AttributeError:\n             output_shape = \"multiple\"\n         except RuntimeError:  # output_shape unknown in Eager mode.\n@@ -166,7 +173,7 @@ def print_summary(\n             params = \"0 (unused)\"\n         else:\n             params = layer.count_params()\n-        fields = [name + \" (\" + cls_name + \")\", output_shape, params]\n+        fields = [name + \" (\" + cls_name + \")\", output_shape, str(params)]\n \n         if show_trainable:\n             fields.append(\"Y\" if layer.trainable else \"N\")\n@@ -181,7 +188,7 @@ def print_summary(\n               (e.g. 0 for a top-level layer, 1 for a nested layer).\n         \"\"\"\n         try:\n-            output_shape = layer.output_shape\n+            output_shape = format_shape(layer.output_shape)\n         except AttributeError:\n             output_shape = \"multiple\"\n         connections = []\n@@ -202,7 +209,7 @@ def print_summary(\n         fields = [\n             name + \" (\" + cls_name + \")\",\n             output_shape,\n-            layer.count_params(),\n+            str(layer.count_params()),\n             connections,\n         ]\n         if show_trainable:\n@@ -210,12 +217,14 @@ def print_summary(\n         rows.append(fields)\n \n     def print_layer(layer, nested_level=0):\n-        if sequential_like:\n-            print_layer_summary(layer, prefix=\">>>\" * nested_level + \" \")\n+        if nested_level:\n+            prefix = \"   \" * nested_level + \"└\" + \" \"\n         else:\n-            print_layer_summary_with_connections(\n-                layer, prefix=\">>>\" * nested_level + \" \"\n-            )\n+            prefix = \"\"\n+        if sequential_like:\n+            print_layer_summary(layer, prefix=prefix)\n+        else:\n+            print_layer_summary_with_connections(layer, prefix=prefix)\n \n         if expand_nested and hasattr(layer, \"layers\") and layer.layers:\n             nested_layers = layer.layers\n@@ -227,14 +236,21 @@ def print_summary(\n         print_layer(layer)\n \n     # Render summary as a table.\n-    table = text_rendering.Table(\n+    table = text_rendering.TextTable(\n         header=header,\n         rows=rows,\n         positions=positions,\n         # Left align layer name, center-align everything else\n         alignments=[\"left\"] + [\"center\" for _ in range(len(header) - 1)],\n+        max_line_length=line_length,\n     )\n-    print_fn(table.make())\n+    try:\n+        table_str = table.make()\n+        print_fn(table_str)\n+    except UnicodeEncodeError:\n+        printable = set(string.printable)\n+        table_str = filter(lambda x: x in printable, table_str)\n+        print_fn(table_str)\n \n     # After the table, append information about parameter count and size.\n     if hasattr(model, \"_collected_trainable_weights\"):\n@@ -252,17 +268,23 @@ def print_summary(\n     total_memory_size = trainable_memory_size + non_trainable_memory_size\n \n     print_fn(\n+        text_rendering.highlight_msg(\n             f\" Total params: {trainable_count + non_trainable_count} \"\n             f\"({readable_memory_size(total_memory_size)})\"\n         )\n+    )\n     print_fn(\n+        text_rendering.highlight_msg(\n             f\" Trainable params: {trainable_count} \"\n             f\"({readable_memory_size(trainable_memory_size)})\"\n         )\n+    )\n     print_fn(\n+        text_rendering.highlight_msg(\n             f\" Non-trainable params: {non_trainable_count} \"\n             f\"({readable_memory_size(non_trainable_memory_size)})\"\n         )\n+    )\n \n \n def get_layer_index_bound_by_layer_name(model, layer_range=None):\n\n@@ -1,7 +1,7 @@\n import shutil\n \n \n-class Table:\n+class TextTable:\n     def __init__(\n         self, header, rows, positions, alignments=None, max_line_length=80\n     ):\n@@ -40,44 +40,63 @@ class Table:\n         line = mid.join(horizontal * width for width in self.column_widths)\n         return f\"{left}{line}{right}\"\n \n+    @staticmethod\n+    def format_field(field):\n+        field = str(field)\n+        field = field.replace(\"\\n\", \" \")\n+        return field\n+    \n+    @staticmethod\n+    def maybe_pad(field, alignment):\n+        if alignment == \"left\":\n+            return \" \" + field\n+        if alignment == \"right\":\n+            return field + \" \"\n+        return field\n+\n     def print_row(\n         self,\n         fields,\n         vertical_separator=\"│\",\n         alignments=None,\n+        highlight=False,\n     ):\n         alignments = alignments or [\"center\" for _ in fields]\n         lines = []\n-        line_break_conditions = (\"),\", \"},\", \"],\", \"',\", \") \")\n-        for field, width in zip(fields, self.column_widths):\n+        line_break_chars_post = (\")\", \"}\", \"]\")\n+        line_break_chars_pre = (\"(\", \"{\", \"[\")\n+        for field, width, alignment in zip(\n+            fields, self.column_widths, alignments\n+        ):\n+            field = self.format_field(field)\n             buffered_width = width - 1\n-            if len(field) < buffered_width and not \"\\n\" in field:\n-                lines.append([field])\n+            if len(field) < buffered_width:\n+                lines.append([self.maybe_pad(field, alignment)])\n                 continue\n             subfields = []\n-            while len(field) >= buffered_width or \"\\n\" in field:\n-                if \"\\n\" in field[:buffered_width]:\n-                    # priority: break on line break\n-                    cutoff = field.find(\"\\n\")\n-                    subfield = field[:cutoff]\n-                    field = field[cutoff + 1 :]\n-                    subfields.append(subfield)\n-                    continue\n-                # secondary: break on certain characters\n-                candidate_cutoffs = [\n-                    field.find(x) + len(x)\n-                    for x in line_break_conditions\n+            while len(field) >= buffered_width:\n+                # Break on certain characters\n+                candidate_cutoffs_pre = [\n+                    field.find(x)\n+                    for x in line_break_chars_pre\n                     if 0 < field.find(x) < buffered_width\n                 ]\n-                if candidate_cutoffs:\n-                    cutoff = min(buffered_width - 1, *candidate_cutoffs)\n+                candidate_cutoffs_post = [\n+                    field.find(x) + len(x)\n+                    for x in line_break_chars_post\n+                    if 0 < field.find(x) + len(x) < buffered_width\n+                ]\n+                cutoffs = candidate_cutoffs_pre + candidate_cutoffs_post\n+                if cutoffs:\n+                    cutoff = max(cutoffs)\n                 else:\n                     cutoff = buffered_width - 1\n                 subfield = field[:cutoff]\n                 field = field[cutoff:]\n-                subfields.append(subfield)\n+                \n+                subfields.append(self.maybe_pad(subfield, alignment))\n             if field:\n-                subfields.append(field)\n+                subfields.append(self.maybe_pad(field, alignment))\n             lines.append(subfields)\n \n         max_subfield_count = max(len(subs) for subs in lines)\n@@ -90,12 +109,17 @@ class Table:\n                 else:\n                     field = subfields[i]\n                 fields.append(field)\n-            line = vertical_separator.join(\n+            aligned_fields = [\n                 self.align_field(field, width, alignment)\n                 for field, width, alignment in zip(\n                     fields, self.column_widths, alignments\n                 )\n-            )\n+            ]\n+            if highlight:\n+                aligned_fields = [\n+                    highlight_msg(field) for field in aligned_fields\n+                ]\n+            line = vertical_separator.join(aligned_fields)\n             line = f\"{vertical_separator}{line}{vertical_separator}\"\n             rendered_lines.append(line)\n         return \"\\n\".join(rendered_lines)\n@@ -113,7 +137,9 @@ class Table:\n         lines = []\n         # Print header\n         lines.append(self.make_separator(*\"┏┳┓━\"))\n-        lines.append(self.print_row(self.header, vertical_separator=\"┃\"))\n+        lines.append(\n+            self.print_row(self.header, vertical_separator=\"┃\", highlight=True)\n+        )\n         lines.append(self.make_separator(*\"┡╇┩━\"))\n \n         # Print rows\n@@ -124,3 +150,7 @@ class Table:\n \n         lines.append(self.make_separator(*\"└┴┘─\"))\n         return \"\\n\".join(lines)\n+\n+\n+def highlight_msg(msg):\n+    return f\"\\x1b[1m{msg}\\x1b[0m\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#21d8cc8b77c5edff069448dc4ac6e3fd8e4dce8e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 9 | Files Changed: 4 | Hunks: 6 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 20 | Churn Cumulative: 1219 | Contributors (this commit): 3 | Commits (past 90d): 21 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -1,7 +1,8 @@\n-from keras_core import testing\n-from keras_core import initializers\n import numpy as np\n \n+from keras_core import initializers\n+from keras_core import testing\n+\n \n class InitializersTest(testing.TestCase):\n     def test_random_normal(self):\n\n@@ -1,8 +1,7 @@\n from keras_core import backend\n-from keras_core.utils.naming import auto_name\n-from keras_core.utils import dtype_utils\n from keras_core import operations as ops\n from keras_core.api_export import keras_core_export\n+from keras_core.utils import dtype_utils\n from keras_core.utils.naming import auto_name\n \n \n\n\n@@ -1,12 +1,14 @@\n-from tensorflow import nest\n-from keras_core import backend\n-from keras_core.utils import io_utils\n-from keras_core.utils import dtype_utils\n-from keras_core.utils import text_rendering\n import math\n import re\n import string\n \n+from tensorflow import nest\n+\n+from keras_core import backend\n+from keras_core.utils import dtype_utils\n+from keras_core.utils import io_utils\n+from keras_core.utils import text_rendering\n+\n \n def count_params(weights):\n     shapes = [v.shape for v in weights]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4fd0029ad7b9b6b7a6e0d69ca7550c8af38f17c2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 75 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 7 | Methods Changed: 5 | Complexity Δ (Sum/Max): 6/5 | Churn Δ: 78 | Churn Cumulative: 376 | Contributors (this commit): 3 | Commits (past 90d): 15 | Contributors (cumulative): 4 | DMM Complexity: 0.6428571428571429\n\nDIFF:\n@@ -2,6 +2,7 @@ import warnings\n \n from tensorflow import nest\n \n+from keras_core import backend\n from keras_core import operations as ops\n from keras_core.layers.layer import Layer\n from keras_core.models.model import Model\n@@ -32,6 +33,19 @@ class Functional(Function, Model):\n         skip_init = kwargs.pop(\"skip_init\", False)\n         if skip_init:\n             return\n+        if isinstance(inputs, dict):\n+            for k, v in inputs.items():\n+                if not isinstance(v, backend.KerasTensor):\n+                    raise ValueError(\n+                        \"When providing an input dict, all values in the dict \"\n+                        f\"must be KerasTensors. Received: inputs={inputs} including \"\n+                        f\"invalid value {v} of type {type(v)}\")\n+                if k != v.name:\n+                    raise ValueError(\n+                        \"When providing an input dict, all keys in the dict \"\n+                        \"must match the names of the corresponding tensors. \"\n+                        f\"Received key '{k}' mapping to value {v} which has name '{v.name}'. \"\n+                        f\"Change the tensor name to '{k}' (via `Input(..., name='{k}')`)\")\n         super().__init__(inputs, outputs, name=name, **kwargs)\n         self._layers = self.layers\n         self.built = True\n@@ -60,6 +74,9 @@ class Functional(Function, Model):\n     def compute_output_spec(self, inputs, training=False, mask=None):\n         return super().compute_output_spec(inputs)\n     \n+    def _assert_input_compatibility(self, *args):\n+        return super(Model, self)._assert_input_compatibility(*args)\n+\n     def _flatten_to_reference_inputs(self, inputs):\n         if isinstance(inputs, dict):\n             ref_inputs = self._inputs_struct\n\n@@ -2,7 +2,6 @@ import numpy as np\n \n from keras_core import backend\n from keras_core import layers\n-from keras_core import operations as ops\n from keras_core import testing\n from keras_core.layers.core.input_layer import Input\n from keras_core.models.functional import Functional\n@@ -51,6 +50,33 @@ class FunctionalTest(testing.TestCase):\n         self.assertEqual(out_val[0].shape, (2, 4))\n         self.assertEqual(out_val[1].shape, (2, 5))\n \n+    def test_basic_flow_dict_io(self):\n+        input_a = Input(shape=(3,), batch_size=2, name=\"a\")\n+        input_b = Input(shape=(3,), batch_size=2, name=\"b\")\n+        x = input_a + input_b\n+        x = layers.Dense(5)(x)\n+        outputs = layers.Dense(4)(x)\n+\n+        with self.assertRaisesRegex(ValueError, \"all values in the dict must be KerasTensors\"):\n+            model = Functional({\"aa\": [input_a], \"bb\": input_b}, outputs)\n+\n+        with self.assertRaisesRegex(ValueError, \"all keys in the dict must match the names\"):\n+            model = Functional({\"aa\": input_a, \"bb\": input_b}, outputs)\n+\n+        model = Functional({\"a\": input_a, \"b\": input_b}, outputs)\n+\n+        # Eager call\n+        in_val = {\"a\": np.random.random((2, 3)), \"b\": np.random.random((2, 3))}\n+        out_val = model(in_val)\n+        self.assertEqual(out_val.shape, (2, 4))\n+\n+        # Symbolic call\n+        input_a_2 = Input(shape=(3,), batch_size=2)\n+        input_b_2 = Input(shape=(3,), batch_size=2)\n+        in_val = {\"a\": input_a_2, \"b\": input_b_2}\n+        out_val = model(in_val)\n+        self.assertEqual(out_val.shape, (2, 4))\n+\n     def test_layer_getters(self):\n         # Test mixing ops and layers\n         input_a = Input(shape=(3,), batch_size=2, name=\"input_a\")\n@@ -87,10 +113,39 @@ class FunctionalTest(testing.TestCase):\n         pass\n \n     def test_passing_inputs_by_name(self):\n-        pass\n+        input_a = Input(shape=(3,), batch_size=2, name=\"input_a\")\n+        input_b = Input(shape=(3,), batch_size=2, name=\"input_b\")\n+        x = input_a + input_b\n+        x = layers.Dense(5)(x)\n+        outputs = layers.Dense(4)(x)\n+        model = Functional([input_a, input_b], outputs)\n+\n+        # Eager call\n+        in_val = {\"input_a\": np.random.random((2, 3)), \"input_b\": np.random.random((2, 3))}\n+        out_val = model(in_val)\n+        self.assertEqual(out_val.shape, (2, 4))\n+\n+        # Symbolic call\n+        input_a_2 = Input(shape=(3,), batch_size=2, name=\"input_a_2\")\n+        input_b_2 = Input(shape=(3,), batch_size=2, name=\"input_b_2\")\n+        in_val = {\"input_a\": input_a_2, \"input_b\": input_b_2}\n+        out_val = model(in_val)\n+        self.assertEqual(out_val.shape, (2, 4))\n \n     def test_rank_standardization(self):\n-        pass\n+        # Downranking\n+        inputs = Input(shape=(3,), batch_size=2)\n+        outputs = layers.Dense(3)(inputs)\n+        model = Functional(inputs, outputs)\n+        out_val = model(np.random.random((2, 3, 1)))\n+        self.assertEqual(out_val.shape, (2, 3))\n+\n+        # Upranking\n+        inputs = Input(shape=(3, 1), batch_size=2)\n+        outputs = layers.Dense(3)(inputs)\n+        model = Functional(inputs, outputs)\n+        out_val = model(np.random.random((2, 3)))\n+        self.assertEqual(out_val.shape, (2, 3, 3))\n \n     def test_serialization(self):\n         # TODO\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c1ca10160fcb49798bb063ef2a8311de489ebabe", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 5 | Files Changed: 4 | Hunks: 7 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 21 | Churn Cumulative: 456 | Contributors (this commit): 3 | Commits (past 90d): 27 | Contributors (cumulative): 8 | DMM Complexity: 0.7777777777777778\n\nDIFF:\n@@ -39,13 +39,15 @@ class Functional(Function, Model):\n                     raise ValueError(\n                         \"When providing an input dict, all values in the dict \"\n                         f\"must be KerasTensors. Received: inputs={inputs} including \"\n-                        f\"invalid value {v} of type {type(v)}\")\n+                        f\"invalid value {v} of type {type(v)}\"\n+                    )\n                 if k != v.name:\n                     raise ValueError(\n                         \"When providing an input dict, all keys in the dict \"\n                         \"must match the names of the corresponding tensors. \"\n                         f\"Received key '{k}' mapping to value {v} which has name '{v.name}'. \"\n-                        f\"Change the tensor name to '{k}' (via `Input(..., name='{k}')`)\")\n+                        f\"Change the tensor name to '{k}' (via `Input(..., name='{k}')`)\"\n+                    )\n         super().__init__(inputs, outputs, name=name, **kwargs)\n         self._layers = self.layers\n         self.built = True\n\n@@ -57,10 +57,14 @@ class FunctionalTest(testing.TestCase):\n         x = layers.Dense(5)(x)\n         outputs = layers.Dense(4)(x)\n \n-        with self.assertRaisesRegex(ValueError, \"all values in the dict must be KerasTensors\"):\n+        with self.assertRaisesRegex(\n+            ValueError, \"all values in the dict must be KerasTensors\"\n+        ):\n             model = Functional({\"aa\": [input_a], \"bb\": input_b}, outputs)\n \n-        with self.assertRaisesRegex(ValueError, \"all keys in the dict must match the names\"):\n+        with self.assertRaisesRegex(\n+            ValueError, \"all keys in the dict must match the names\"\n+        ):\n             model = Functional({\"aa\": input_a, \"bb\": input_b}, outputs)\n \n         model = Functional({\"a\": input_a, \"b\": input_b}, outputs)\n@@ -121,7 +125,10 @@ class FunctionalTest(testing.TestCase):\n         model = Functional([input_a, input_b], outputs)\n \n         # Eager call\n-        in_val = {\"input_a\": np.random.random((2, 3)), \"input_b\": np.random.random((2, 3))}\n+        in_val = {\n+            \"input_a\": np.random.random((2, 3)),\n+            \"input_b\": np.random.random((2, 3)),\n+        }\n         out_val = model(in_val)\n         self.assertEqual(out_val.shape, (2, 4))\n \n\n@@ -37,6 +37,7 @@ class Node:\n         call_kwargs: The keyword arguments the operation was called with.\n         outputs: The output tensors of the `op.__call__()` call.\n     \"\"\"\n+\n     def __init__(\n         self, operation, call_args=None, call_kwargs=None, outputs=None\n     ):\n\n@@ -20,6 +20,7 @@ def no_automatic_dependency_tracking(fn):\n     def wrapper(*args, **kwargs):\n         with DotNotTrackScope():\n             return fn(*args, **kwargs)\n+\n     return wrapper\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4d040659070a50586ddf7be9acb5a402f64788f9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 279 | Lines Deleted: 17 | Files Changed: 6 | Hunks: 18 | Methods Changed: 29 | Complexity Δ (Sum/Max): 46/34 | Churn Δ: 296 | Churn Cumulative: 689 | Contributors (this commit): 3 | Commits (past 90d): 35 | Contributors (cumulative): 10 | DMM Complexity: 0.5767195767195767\n\nDIFF:\n@@ -1,4 +1,6 @@\n from keras_core.layers.core.dense import Dense\n+from keras_core.layers.core.input_layer import Input\n+from keras_core.layers.core.input_layer import InputLayer\n from keras_core.layers.layer import Layer\n \n # from keras_core.layers.regularization.dropout import Dropout\n\n@@ -5,13 +5,33 @@ from keras_core.operations.node import Node\n \n class InputLayer(Layer):\n     def __init__(\n-        self, shape, batch_size=None, dtype=None, input_tensor=None, name=None\n+        self,\n+        shape=None,\n+        batch_size=None,\n+        dtype=None,\n+        batch_shape=None,\n+        input_tensor=None,\n+        name=None,\n     ):\n         # TODO: support for sparse, ragged.\n         super().__init__(name=name)\n-        self.shape = backend.standardize_shape(shape)\n+        if shape is not None and batch_shape is not None:\n+            raise ValueError(\n+                \"You cannot pass both `shape` and `batch_shape` at the same time.\"\n+            )\n+        if batch_size is not None and batch_shape is not None:\n+            raise ValueError(\n+                \"You cannot pass both `batch_size` and `batch_shape` at the same time.\"\n+            )\n+        if shape is None and batch_shape is None:\n+            raise ValueError(\"You must pass a `shape` argument.\")\n+\n+        if shape:\n+            shape = backend.standardize_shape(shape)\n+            batch_shape = (batch_size,) + shape\n+        self.batch_shape = batch_shape\n         self._dtype = backend.standardize_dtype(dtype)\n-        self.batch_size = batch_size\n+\n         if input_tensor is not None:\n             if not isinstance(input_tensor, backend.KerasTensor):\n                 raise ValueError(\n@@ -20,7 +40,7 @@ class InputLayer(Layer):\n                 )\n         else:\n             input_tensor = backend.KerasTensor(\n-                shape=(batch_size,) + shape, dtype=dtype, name=name\n+                shape=batch_shape, dtype=dtype, name=name\n             )\n         self._input_tensor = input_tensor\n         Node(operation=self, call_args=(), call_kwargs={}, outputs=input_tensor)\n@@ -35,15 +55,18 @@ class InputLayer(Layer):\n \n     def get_config(self):\n         return {\n-            \"shape\": self.shape,\n-            \"batch_size\": self.batch_size,\n+            \"batch_shape\": self.batch_shape,\n             \"dtype\": self.dtype,\n             \"name\": self.name,\n         }\n \n \n-def Input(shape=None, batch_size=None, dtype=None, name=None):\n+def Input(shape=None, batch_size=None, dtype=None, batch_shape=None, name=None):\n     layer = InputLayer(\n-        shape=shape, batch_size=batch_size, dtype=dtype, name=name\n+        shape=shape,\n+        batch_size=batch_size,\n+        dtype=dtype,\n+        batch_shape=batch_shape,\n+        name=name,\n     )\n     return layer.output\n\n@@ -55,6 +55,9 @@ class Layer(Operation):\n         self._non_trainable_variables = []\n         self._supports_masking = not utils.is_default(self.compute_mask)\n         self._build_shapes_dict = None\n+        self._call_signature_parameters = [\n+            p.name for p in inspect.signature(self.call).parameters.values()\n+        ]\n \n         self._tracker = Tracker(\n             {\n@@ -503,9 +506,10 @@ class Layer(Operation):\n             )\n \n     def _call_has_training_arg(self):\n-        return \"training\" in [\n-            p.name for p in inspect.signature(self.call).parameters.values()\n-        ]\n+        return \"training\" in self._call_signature_parameters\n+\n+    def _call_has_mask_arg(self):\n+        return \"mask\" in self._call_signature_parameters\n \n     def _get_call_context(self):\n         \"\"\"Returns currently active `CallContext`.\"\"\"\n\n@@ -60,7 +60,7 @@ class Functional(Function, Model):\n                 layers.append(operation)\n         return layers\n \n-    def call(self, inputs, training=False, mask=None):\n+    def call(self, inputs, training=None, mask=None):\n         # Add support for traning, masking\n         inputs = self._standardize_inputs(inputs)\n         if mask is None:\n@@ -73,7 +73,8 @@ class Functional(Function, Model):\n             inputs, operation_fn=lambda op: operation_fn(op, training=training)\n         )\n \n-    def compute_output_spec(self, inputs, training=False, mask=None):\n+    def compute_output_spec(self, inputs, training=None, mask=None):\n+        # From Function\n         return super().compute_output_spec(inputs)\n \n     def _assert_input_compatibility(self, *args):\n\n@@ -1,11 +1,145 @@\n+from tensorflow import nest\n+\n+from keras_core import backend\n from keras_core.api_export import keras_core_export\n+from keras_core.layers.core.input_layer import InputLayer\n+from keras_core.models.functional import Functional\n from keras_core.models.model import Model\n+from keras_core.utils import tracking\n \n \n @keras_core_export([\"keras_core.Sequential\", \"keras_core.models.Sequential\"])\n class Sequential(Model):\n-    def __init__(self, layers, trainable=True, name=None):\n-        pass\n+    @tracking.no_automatic_dependency_tracking\n+    def __init__(self, layers=None, trainable=True, name=None):\n+        super().__init__(trainable=trainable, name=name)\n+        self._functional = None\n+        self._layers = []\n+        if layers:\n+            for layer in layers:\n+                self.add(layer)\n \n-    def call(self, inputs):\n-        pass\n+    def add(self, layer):\n+        # If we are passed a Keras tensor created by keras.Input(), we\n+        # extract the input layer from its keras history and use that.\n+        if hasattr(layer, \"_keras_history\"):\n+            origin_layer = layer._keras_history[0]\n+            if isinstance(origin_layer, InputLayer):\n+                layer = origin_layer\n+        if not self._is_layer_name_unique(layer):\n+            raise ValueError(\n+                \"All layers added to a Sequential model \"\n+                f\"should have unique names. Name '{layer.name}' is already \"\n+                \"the name of a layer in this model. Update the `name` argument \"\n+                \"to pass a unique name.\"\n+            )\n+        if (\n+            isinstance(layer, InputLayer)\n+            and self._layers\n+            and isinstance(self._layers[0], InputLayer)\n+        ):\n+            raise ValueError(\n+                f\"Sequential model '{self.name}' has already been configured to \"\n+                f\"use input shape {self._layers[0].batch_input_shape}. You cannot add \"\n+                f\"a different Input layer to it.\"\n+            )\n+\n+        self._layers.append(layer)\n+        self.built = False\n+        self._functional = None\n+\n+    def pop(self):\n+        layer = self._layers.pop()\n+        self.built = False\n+        self._functional = None\n+        return layer\n+\n+    def build(self, input_shape=None):\n+        if not self._layers:\n+            raise ValueError(\n+                f\"Sequential model {self.name} cannot be built because it has no layers. \"\n+                \"Call `model.add(layer)`.\"\n+            )\n+        if isinstance(self._layers[0], InputLayer):\n+            if self._layers[0].batch_shape != input_shape:\n+                raise ValueError(\n+                    f\"Sequential model '{self.name}' has already been configured to \"\n+                    f\"use input shape {self._layers[0].batch_shape}. You cannot build it \"\n+                    f\"with input_shape {input_shape}\"\n+                )\n+        else:\n+            self._layers = [InputLayer(batch_shape=input_shape)] + self._layers\n+\n+        # Build functional model\n+        inputs = self._layers[0].output\n+        x = inputs\n+        for layer in self._layers[1:]:\n+            x = layer(x)\n+        outputs = x\n+        self._functional = Functional(inputs=inputs, outputs=outputs)\n+        self.built = True\n+\n+    def call(self, inputs, training=None, mask=None):\n+        if self._functional:\n+            return self._functional(inputs, training=training, mask=mask)\n+        # Else, check if we can build a Functional model\n+        if isinstance(inputs, backend.KerasTensor) or backend.is_tensor(inputs):\n+            self.build(inputs.shape)\n+            return self._functional(inputs, training=training, mask=mask)\n+\n+        # No functional model can be built -- Just apply the layer sequence.\n+        # This typically happens if `inputs` is a nested struct.\n+        for layer in self.layers:\n+            # During each iteration, `inputs` are the inputs to `layer`, and\n+            # `outputs` are the outputs of `layer` applied to `inputs`. At the\n+            # end of each iteration `inputs` is set to `outputs` to prepare for\n+            # the next layer.\n+            kwargs = {}\n+            if layer._call_has_mask_arg:\n+                kwargs[\"mask\"] = mask\n+            if layer._call_has_training_arg:\n+                kwargs[\"training\"] = training\n+            outputs = layer(inputs, **kwargs)\n+            inputs = outputs\n+\n+            def _get_mask_from_keras_tensor(kt):\n+                return getattr(kt, \"_keras_mask\", None)\n+\n+            mask = nest.map_structure(_get_mask_from_keras_tensor, outputs)\n+        return outputs\n+\n+    @property\n+    def layers(self):\n+        # Historically, `sequential.layers` only returns layers that were added\n+        # via `add`, and omits the auto-generated `InputLayer` that comes at the\n+        # bottom of the stack.\n+        layers = self._layers\n+        if layers and isinstance(layers[0], InputLayer):\n+            return layers[1:]\n+        return layers[:]\n+\n+    def compute_output_spec(self, inputs, training=None, mask=None):\n+        if self._functional:\n+            return self._functional.compute_output_spec(\n+                inputs, training=training, mask=mask\n+            )\n+        # Direct application\n+        for layer in self.layers:\n+            outputs = layer.compute_output_spec(\n+                inputs, training=training\n+            )  # Ignore mask\n+            inputs = outputs\n+        return outputs\n+\n+    def _is_layer_name_unique(self, layer):\n+        for ref_layer in self._layers:\n+            if layer.name == ref_layer.name and ref_layer is not layer:\n+                return False\n+        return True\n+\n+    def get_config(self):\n+        raise NotImplementedError\n+\n+    @classmethod\n+    def from_config(cls, config):\n+        raise NotImplementedError\n\n@@ -0,0 +1,98 @@\n+import numpy as np\n+\n+from keras_core import backend\n+from keras_core import layers\n+from keras_core import testing\n+from keras_core.layers.core.input_layer import Input\n+from keras_core.models.functional import Functional\n+from keras_core.models.sequential import Sequential\n+\n+\n+class SequentialTest(testing.TestCase):\n+    def test_basic_flow_with_input(self):\n+        model = Sequential(name=\"seq\")\n+        model.add(Input(shape=(2,), batch_size=3))\n+        model.add(layers.Dense(4))\n+        model.add(layers.Dense(5))\n+\n+        self.assertEqual(len(model.layers), 2)\n+\n+        # Test eager call\n+        x = np.random.random((3, 2))\n+        y = model(x)\n+        self.assertTrue(model.built)\n+        self.assertEqual(type(model._functional), Functional)\n+        self.assertEqual(y.shape, (3, 5))\n+\n+        # Test symbolic call\n+        x = backend.KerasTensor((3, 2))\n+        y = model(x)\n+        self.assertEqual(y.shape, (3, 5))\n+\n+        # Test `layers` constructor arg\n+        model = Sequential(\n+            layers=[\n+                Input(shape=(2,), batch_size=3),\n+                layers.Dense(4),\n+                layers.Dense(5),\n+            ]\n+        )\n+        x = np.random.random((3, 2))\n+        y = model(x)\n+        self.assertEqual(y.shape, (3, 5))\n+\n+        # Test pop\n+        model.pop()\n+        self.assertFalse(model.built)\n+        self.assertEqual(model._functional, None)\n+        x = np.random.random((3, 2))\n+        y = model(x)\n+        self.assertTrue(model.built)\n+        self.assertEqual(type(model._functional), Functional)\n+        self.assertEqual(y.shape, (3, 4))\n+\n+    def test_basic_flow_deferred(self):\n+        model = Sequential(name=\"seq\")\n+        model.add(layers.Dense(4))\n+        model.add(layers.Dense(5))\n+\n+        self.assertEqual(len(model.layers), 2)\n+\n+        # Test eager call\n+        x = np.random.random((3, 2))\n+        y = model(x)\n+        self.assertTrue(model.built)\n+        self.assertEqual(type(model._functional), Functional)\n+        self.assertEqual(y.shape, (3, 5))\n+\n+        # Test symbolic call\n+        x = backend.KerasTensor((3, 2))\n+        y = model(x)\n+        self.assertEqual(y.shape, (3, 5))\n+\n+        # Test `layers` constructor arg\n+        model = Sequential(\n+            layers=[\n+                layers.Dense(4),\n+                layers.Dense(5),\n+            ]\n+        )\n+        x = np.random.random((3, 2))\n+        y = model(x)\n+        self.assertEqual(y.shape, (3, 5))\n+\n+        # Test pop\n+        model.pop()\n+        self.assertFalse(model.built)\n+        self.assertEqual(model._functional, None)\n+        x = np.random.random((3, 2))\n+        y = model(x)\n+        self.assertTrue(model.built)\n+        self.assertEqual(type(model._functional), Functional)\n+        self.assertEqual(y.shape, (3, 4))\n+\n+    def test_dict_inputs(self):\n+        pass\n+\n+    def test_serialization(self):\n+        pass\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8b8e0bc15f80994150a8cb5e71716c08e8a0e50c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 32 | Churn Cumulative: 283 | Contributors (this commit): 1 | Commits (past 90d): 7 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -40,7 +40,7 @@ class Sequential(Model):\n         ):\n             raise ValueError(\n                 f\"Sequential model '{self.name}' has already been configured to \"\n-                f\"use input shape {self._layers[0].batch_input_shape}. You cannot add \"\n+                f\"use input shape {self._layers[0].batch_shape}. You cannot add \"\n                 f\"a different Input layer to it.\"\n             )\n \n\n@@ -94,5 +94,35 @@ class SequentialTest(testing.TestCase):\n     def test_dict_inputs(self):\n         pass\n \n+    def test_errors(self):\n+        # Trying to pass 2 Inputs\n+        model = Sequential()\n+        model.add(Input(shape=(2,), batch_size=3))\n+        with self.assertRaisesRegex(ValueError, \"already been configured\"):\n+            model.add(Input(shape=(2,), batch_size=3))\n+        with self.assertRaisesRegex(ValueError, \"already been configured\"):\n+            model.add(layers.InputLayer(shape=(2,), batch_size=3))\n+\n+        # Same name 2x\n+        model = Sequential()\n+        model.add(layers.Dense(2, name=\"dense\"))\n+        with self.assertRaisesRegex(ValueError, \"should have unique names\"):\n+            model.add(layers.Dense(2, name=\"dense\"))\n+\n+        # No layers\n+        model = Sequential()\n+        x = np.random.random((3, 2))\n+        with self.assertRaisesRegex(ValueError, \"no layers\"):\n+            model(x)\n+\n+        # Build conflict\n+        model = Sequential()\n+        model.add(Input(shape=(2,), batch_size=3))\n+        model.add(layers.Dense(2))\n+        with self.assertRaisesRegex(ValueError, \"already been configured\"):\n+            model.build((3, 4))\n+        # But this works\n+        model.build((3, 2))\n+\n     def test_serialization(self):\n         pass\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f4445f1135a6c2366587895d65efeff78b53b214", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 72 | Lines Deleted: 68 | Files Changed: 9 | Hunks: 43 | Methods Changed: 9 | Complexity Δ (Sum/Max): 503/82 | Churn Δ: 140 | Churn Cumulative: 27277 | Contributors (this commit): 51 | Commits (past 90d): 40 | Contributors (cumulative): 117 | DMM Complexity: None\n\nDIFF:\n@@ -124,7 +124,7 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n \n   Args:\n     include_top: Whether to include the fully-connected\n-      layer at the top of the network. Defaults to True.\n+      layer at the top of the network. Defaults to `True`.\n     weights: One of `None` (random initialization),\n       `\"imagenet\"` (pre-training on ImageNet-1k), or the path to the weights\n       file to be loaded. Defaults to `\"imagenet\"`.\n@@ -135,7 +135,7 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n       if `include_top` is False.\n       It should have exactly 3 inputs channels.\n     pooling: Optional pooling mode for feature extraction\n-      when `include_top` is `False`. Defaults to None.\n+      when `include_top` is `False`.\n       - `None` means that the output of the model will be\n         the 4D tensor output of the last convolutional layer.\n       - `avg` means that global average pooling\n@@ -144,16 +144,16 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n         the output of the model will be a 2D tensor.\n       - `max` means that global max pooling will\n         be applied.\n+      Defaults to `None`.\n     classes: Optional number of classes to classify images\n       into, only to be specified if `include_top` is True, and\n-      if no `weights` argument is specified. Defaults to 1000 (number of\n-      ImageNet classes).\n+      if no `weights` argument is specified. 1000 is how many\n+      ImageNet classes there are. Defaults to `1000`.\n     classifier_activation: A `str` or callable. The activation function to use\n       on the \"top\" layer. Ignored unless `include_top=True`. Set\n       `classifier_activation=None` to return the logits of the \"top\" layer.\n-      Defaults to `\"softmax\"`.\n       When loading pretrained weights, `classifier_activation` can only\n-      be `None` or `\"softmax\"`.\n+      be `None` or `\"softmax\"`. Defaults to `\"softmax\"`.\n \n   Returns:\n     A `keras.Model` instance.\n@@ -754,10 +754,10 @@ def preprocess_input(x, data_format=None):\n \n     Args:\n       x: A floating point `numpy.array` or a `tf.Tensor`.\n-      data_format: Optional data format of the image tensor/array. Defaults to\n-        None, in which case the global setting\n-        `tf.keras.backend.image_data_format()` is used (unless you changed it,\n-        it defaults to \"channels_last\").{mode}\n+      data_format: Optional data format of the image tensor/array. `None` means\n+        the global setting `tf.keras.backend.image_data_format()` is used\n+        (unless you changed it, it uses \"channels_last\").{mode}.\n+        Defaults to `None`.\n \n     Returns:\n       Unchanged `numpy.array` or `tf.Tensor`.\n\n@@ -192,7 +192,7 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n \n   Args:\n     include_top: Whether to include the fully-connected\n-        layer at the top of the network. Defaults to True.\n+        layer at the top of the network. Defaults to `True`.\n     weights: One of `None` (random initialization),\n           'imagenet' (pre-training on ImageNet),\n           or the path to the weights file to be loaded. Defaults to 'imagenet'.\n@@ -203,7 +203,7 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n         if `include_top` is False.\n         It should have exactly 3 inputs channels.\n     pooling: Optional pooling mode for feature extraction\n-        when `include_top` is `False`. Defaults to None.\n+        when `include_top` is `False`. Defaults to `None`.\n         - `None` means that the output of the model will be\n             the 4D tensor output of the\n             last convolutional layer.\n@@ -215,8 +215,8 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n             be applied.\n     classes: Optional number of classes to classify images\n         into, only to be specified if `include_top` is True, and\n-        if no `weights` argument is specified. Defaults to 1000 (number of\n-        ImageNet classes).\n+        if no `weights` argument is specified. 1000 is how many\n+        ImageNet classes there are. Defaults to `1000`.\n     classifier_activation: A `str` or callable. The activation function to use\n         on the \"top\" layer. Ignored unless `include_top=True`. Set\n         `classifier_activation=None` to return the logits of the \"top\" layer.\n@@ -852,10 +852,10 @@ def preprocess_input(x, data_format=None):\n \n     Args:\n       x: A floating point `numpy.array` or a `tf.Tensor`.\n-      data_format: Optional data format of the image tensor/array. Defaults to\n-        None, in which case the global setting\n-        `tf.keras.backend.image_data_format()` is used (unless you changed it,\n-        it defaults to \"channels_last\").{mode}\n+      data_format: Optional data format of the image tensor/array. `None` means\n+        the global setting `tf.keras.backend.image_data_format()` is used\n+        (unless you changed it, it uses \"channels_last\").{mode}.\n+        Defaults to `None`.\n \n     Returns:\n       Unchanged `numpy.array` or `tf.Tensor`.\n\n@@ -574,7 +574,7 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n \n   Args:\n     include_top: Boolean, whether to include the fully-connected\n-      layer at the top of the network. Defaults to True.\n+      layer at the top of the network. Defaults to `True`.\n     weights: One of `None` (random initialization),\n       `\"imagenet\"` (pre-training on ImageNet),\n       or the path to the weights file to be loaded. Defaults to `\"imagenet\"`.\n@@ -585,7 +585,7 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n       if `include_top` is False.\n       It should have exactly 3 inputs channels.\n     pooling: Optional pooling mode for feature extraction\n-      when `include_top` is `False`. Defaults to None.\n+      when `include_top` is `False`.\n       - `None` means that the output of the model will be\n           the 4D tensor output of the\n           last convolutional layer.\n@@ -595,16 +595,17 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n           the output of the model will be a 2D tensor.\n       - `\"max\"` means that global max pooling will\n           be applied.\n+      Defaults to `None`.\n     classes: Optional number of classes to classify images\n       into, only to be specified if `include_top` is True, and\n-      if no `weights` argument is specified. Defaults to 1000 (number of\n-      ImageNet classes).\n+      if no `weights` argument is specified. 1000 is how many\n+      ImageNet classes there are. Defaults to `1000`.\n     classifier_activation: A string or callable. The activation function to use\n       on the `\"top\"` layer. Ignored unless `include_top=True`. Set\n       `classifier_activation=None` to return the logits of the \"top\" layer.\n-      Defaults to `\"softmax\"`.\n       When loading pretrained weights, `classifier_activation` can only\n       be `None` or `\"softmax\"`.\n+      Defaults to `\"softmax\"`.\n \n   Returns:\n     A `keras.Model` instance.\n@@ -1342,10 +1343,10 @@ def preprocess_input(x, data_format=None):\n \n     Args:\n       x: A floating point `numpy.array` or a `tf.Tensor`.\n-      data_format: Optional data format of the image tensor/array. Defaults to\n-        None, in which case the global setting\n-        `tf.keras.backend.image_data_format()` is used (unless you changed it,\n-        it defaults to \"channels_last\").{mode}\n+      data_format: Optional data format of the image tensor/array. `None` means\n+        the global setting `tf.keras.backend.image_data_format()` is used\n+        (unless you changed it, it uses \"channels_last\").{mode}.\n+        Defaults to `None`.\n \n     Returns:\n       Unchanged `numpy.array` or `tf.Tensor`.\n\n@@ -56,10 +56,10 @@ PREPROCESS_INPUT_DOC = \"\"\"\n       The preprocessed data are written over the input data\n       if the data types are compatible. To avoid this\n       behaviour, `numpy.copy(x)` can be used.\n-    data_format: Optional data format of the image tensor/array. Defaults to\n-      None, in which case the global setting\n-      `tf.keras.backend.image_data_format()` is used (unless you changed it,\n-      it defaults to \"channels_last\").{mode}\n+    data_format: Optional data format of the image tensor/array. None, means\n+      the global setting `tf.keras.backend.image_data_format()` is used\n+      (unless you changed it, it uses \"channels_last\").{mode}\n+      Defaults to `None`.\n \n   Returns:\n       Preprocessed `numpy.array` or a `tf.Tensor` with type `float32`.\n@@ -70,7 +70,7 @@ PREPROCESS_INPUT_DOC = \"\"\"\n   \"\"\"\n \n PREPROCESS_INPUT_MODE_DOC = \"\"\"\n-    mode: One of \"caffe\", \"tf\" or \"torch\". Defaults to \"caffe\".\n+    mode: One of \"caffe\", \"tf\" or \"torch\".\n       - caffe: will convert the images from RGB to BGR,\n           then will zero-center each color channel with\n           respect to the ImageNet dataset,\n@@ -80,6 +80,7 @@ PREPROCESS_INPUT_MODE_DOC = \"\"\"\n       - torch: will scale pixels between 0 and 1 and then\n           will normalize each channel with respect to the\n           ImageNet dataset.\n+      Defaults to \"caffe\".\n   \"\"\"\n \n PREPROCESS_INPUT_DEFAULT_ERROR_DOC = \"\"\"\n\n@@ -82,13 +82,13 @@ def InceptionV3(\n \n     Args:\n       include_top: Boolean, whether to include the fully-connected\n-        layer at the top, as the last layer of the network. Default to `True`.\n+        layer at the top, as the last layer of the network. Defaults to `True`.\n       weights: One of `None` (random initialization),\n         `imagenet` (pre-training on ImageNet),\n-        or the path to the weights file to be loaded. Default to `imagenet`.\n+        or the path to the weights file to be loaded. Defaults to `imagenet`.\n       input_tensor: Optional Keras tensor (i.e. output of `layers.Input()`)\n         to use as image input for the model. `input_tensor` is useful for\n-        sharing inputs between multiple different networks. Default to None.\n+        sharing inputs between multiple different networks. Defaults to `None`.\n       input_shape: Optional shape tuple, only to be specified\n         if `include_top` is False (otherwise the input shape\n         has to be `(299, 299, 3)` (with `channels_last` data format)\n@@ -108,7 +108,7 @@ def InceptionV3(\n         - `max` means that global max pooling will be applied.\n       classes: optional number of classes to classify images\n         into, only to be specified if `include_top` is True, and\n-        if no `weights` argument is specified. Default to 1000.\n+        if no `weights` argument is specified. Defaults to 1000.\n       classifier_activation: A `str` or callable. The activation function to use\n         on the \"top\" layer. Ignored unless `include_top=True`. Set\n         `classifier_activation=None` to return the logits of the \"top\" layer.\n\n@@ -124,25 +124,26 @@ def MobileNet(\n         `channels_last` data format) or (3, 224, 224) (with `channels_first`\n         data format). It should have exactly 3 inputs channels, and width and\n         height should be no smaller than 32. E.g. `(200, 200, 3)` would be one\n-        valid value. Default to `None`.\n+        valid value. Defaults to `None`.\n         `input_shape` will be ignored if the `input_tensor` is provided.\n       alpha: Controls the width of the network. This is known as the width\n         multiplier in the MobileNet paper. - If `alpha` < 1.0, proportionally\n         decreases the number of filters in each layer. - If `alpha` > 1.0,\n         proportionally increases the number of filters in each layer. - If\n         `alpha` = 1, default number of filters from the paper are used at each\n-        layer. Default to 1.0.\n+        layer. Defaults to `1.0`.\n       depth_multiplier: Depth multiplier for depthwise convolution. This is\n-        called the resolution multiplier in the MobileNet paper. Default to 1.0.\n-      dropout: Dropout rate. Default to 0.001.\n+        called the resolution multiplier in the MobileNet paper.\n+        Defaults to `1.0`.\n+      dropout: Dropout rate. Defaults to `0.001`.\n       include_top: Boolean, whether to include the fully-connected layer at the\n-        top of the network. Default to `True`.\n+        top of the network. Defaults to `True`.\n       weights: One of `None` (random initialization), 'imagenet' (pre-training\n-        on ImageNet), or the path to the weights file to be loaded. Default to\n+        on ImageNet), or the path to the weights file to be loaded. Defaults to\n         `imagenet`.\n       input_tensor: Optional Keras tensor (i.e. output of `layers.Input()`) to\n         use as image input for the model. `input_tensor` is useful for sharing\n-        inputs between multiple different networks. Default to None.\n+        inputs between multiple different networks. Defaults to `None`.\n       pooling: Optional pooling mode for feature extraction when `include_top`\n         is `False`.\n         - `None` (default) means that the output of the model will be\n@@ -154,7 +155,7 @@ def MobileNet(\n         - `max` means that global max pooling will be applied.\n       classes: Optional number of classes to classify images into, only to be\n         specified if `include_top` is True, and if no `weights` argument is\n-        specified. Defaults to 1000.\n+        specified. Defaults to `1000`.\n       classifier_activation: A `str` or callable. The activation function to use\n         on the \"top\" layer. Ignored unless `include_top=True`. Set\n         `classifier_activation=None` to return the logits of the \"top\" layer.\n\n@@ -679,10 +679,10 @@ def preprocess_input(x, data_format=None):\n \n     Args:\n       x: A floating point `numpy.array` or a `tf.Tensor`.\n-      data_format: Optional data format of the image tensor/array. Defaults to\n-        None, in which case the global setting\n-        `tf.keras.backend.image_data_format()` is used (unless you changed it,\n-        it defaults to \"channels_last\").{mode}\n+      data_format: Optional data format of the image tensor/array. `None` means\n+        the global setting `tf.keras.backend.image_data_format()` is used\n+        (unless you changed it, it uses \"channels_last\").\n+        Defaults to `None`.\n \n     Returns:\n       Unchanged `numpy.array` or `tf.Tensor`.\n\n@@ -342,7 +342,7 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n \n   Args:\n     include_top: Whether to include the fully-connected\n-        layer at the top of the network. Defaults to True.\n+        layer at the top of the network. Defaults to `True`.\n     weights: One of `None` (random initialization),\n           `\"imagenet\"` (pre-training on ImageNet), or the path to the weights\n           file to be loaded. Defaults to `\"imagenet\"`.\n@@ -353,7 +353,7 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n         if `include_top` is False.\n         It should have exactly 3 inputs channels.\n     pooling: Optional pooling mode for feature extraction\n-        when `include_top` is `False`. Defaults to None.\n+        when `include_top` is `False`.\n         - `None` means that the output of the model will be\n             the 4D tensor output of the\n             last convolutional layer.\n@@ -363,16 +363,16 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n             the output of the model will be a 2D tensor.\n         - `max` means that global max pooling will\n             be applied.\n+        Defaults to `None`.\n     classes: Optional number of classes to classify images\n         into, only to be specified if `include_top` is True, and\n-        if no `weights` argument is specified. Defaults to 1000 (number of\n-        ImageNet classes).\n+        if no `weights` argument is specified. 1000 is how many\n+        ImageNet classes there are. Defaults to `1000`.\n     classifier_activation: A `str` or callable. The activation function to use\n         on the \"top\" layer. Ignored unless `include_top=True`. Set\n         `classifier_activation=None` to return the logits of the \"top\" layer.\n-        Defaults to `\"softmax\"`.\n         When loading pretrained weights, `classifier_activation` can only\n-        be `None` or `\"softmax\"`.\n+        be `None` or `\"softmax\"`. Defaults to `\"softmax\"`.\n \n   Returns:\n     A `keras.Model` instance.\n@@ -1819,10 +1819,10 @@ def preprocess_input(x, data_format=None):\n \n     Args:\n       x: A floating point `numpy.array` or a `tf.Tensor`.\n-      data_format: Optional data format of the image tensor/array. Defaults to\n-        None, in which case the global setting\n-        `tf.keras.backend.image_data_format()` is used (unless you changed it,\n-        it defaults to \"channels_last\").{mode}\n+      data_format: Optional data format of the image tensor/array. `None` means\n+        the global setting `tf.keras.backend.image_data_format()` is used\n+        (unless you changed it, it uses \"channels_last\").{mode}.\n+        Defaults to `None`.\n \n     Returns:\n       Unchanged `numpy.array` or `tf.Tensor`.\n\n@@ -196,9 +196,9 @@ BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n             `classifier_activation=None` to return the logits of the \"top\"\n             layer.\n         include_preprocessing: Boolean, whether to include the preprocessing\n-            layer (`Rescaling`) at the bottom of the network. Defaults to\n-            `True`.  Note: Input image is normalized by ImageNet mean and\n-            standard deviation.\n+            layer (`Rescaling`) at the bottom of the network. Note: Input image\n+            is normalized by ImageNet mean and standard deviation.\n+            Defaults to `True`.\n \n     Returns:\n         A `keras.Model` instance.\n@@ -582,9 +582,10 @@ def ResNetRS(\n           use on the \"top\" layer. Ignored unless `include_top=True`. Set\n           `classifier_activation=None` to return the logits of the \"top\" layer.\n         include_preprocessing: Boolean, whether to include the preprocessing\n-          layer (`Rescaling`) at the bottom of the network. Defaults to `True`.\n-          Note- Input image is normalized by ImageNet mean and standard\n-          deviation.\n+          layer (`Rescaling`) at the bottom of the network. Note - Input image\n+          is normalized by ImageNet mean and standard deviation.\n+          Defaults to `True`.\n+\n \n     Returns:\n         A `tf.keras.Model` instance.\n@@ -958,10 +959,10 @@ def preprocess_input(x, data_format=None):\n \n     Args:\n       x: A floating point `numpy.array` or a `tf.Tensor`.\n-      data_format: Optional data format of the image tensor/array. Defaults to\n-        None, in which case the global setting\n-        `tf.keras.backend.image_data_format()` is used (unless you changed it,\n-        it defaults to \"channels_last\").{mode}\n+      data_format: Optional data format of the image tensor/array. `None` means\n+        the global setting `tf.keras.backend.image_data_format()` is used\n+        (unless you changed it, it uses \"channels_last\").{mode}.\n+        Defaults to `None`.\n \n     Returns:\n       Unchanged `numpy.array` or `tf.Tensor`.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
