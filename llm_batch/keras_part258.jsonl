{"custom_id": "keras#1fc585adb57f20a2acf69f0cd08b731259b8d2f8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 104 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 8 | Methods Changed: 19 | Complexity Δ (Sum/Max): 21/18 | Churn Δ: 105 | Churn Cumulative: 4765 | Contributors (this commit): 80 | Commits (past 90d): 8 | Contributors (cumulative): 105 | DMM Complexity: 0.6578947368421053\n\nDIFF:\n@@ -477,6 +477,10 @@ class EarlyStopping(Callback):\n         baseline: Baseline value for the monitored quantity to reach.\n             Training will stop if the model doesn't show improvement\n             over the baseline.\n+        restore_best_weights: whether to restore model weights from\n+            the epoch with the best value of the monitored quantity.\n+            If False, the model weights obtained at the last step of\n+            training are used.\n     \"\"\"\n \n     def __init__(self,\n@@ -485,7 +489,8 @@ class EarlyStopping(Callback):\n                  patience=0,\n                  verbose=0,\n                  mode='auto',\n-                 baseline=None):\n+                 baseline=None,\n+                 restore_best_weights=False):\n         super(EarlyStopping, self).__init__()\n \n         self.monitor = monitor\n@@ -495,6 +500,8 @@ class EarlyStopping(Callback):\n         self.min_delta = min_delta\n         self.wait = 0\n         self.stopped_epoch = 0\n+        self.restore_best_weights = restore_best_weights\n+        self.best_weights = None\n \n         if mode not in ['auto', 'min', 'max']:\n             warnings.warn('EarlyStopping mode %s is unknown, '\n@@ -538,11 +545,17 @@ class EarlyStopping(Callback):\n         if self.monitor_op(current - self.min_delta, self.best):\n             self.best = current\n             self.wait = 0\n+            if self.restore_best_weights:\n+                self.best_weights = self.model.get_weights()\n         else:\n             self.wait += 1\n             if self.wait >= self.patience:\n                 self.stopped_epoch = epoch\n                 self.model.stop_training = True\n+                if self.restore_best_weights:\n+                    if self.verbose > 0:\n+                        print(\"Restoring model weights from the end of the best epoch\")\n+                    self.model.set_weights(self.best_weights)\n \n     def on_train_end(self, logs=None):\n         if self.stopped_epoch > 0 and self.verbose > 0:\n\n@@ -267,6 +267,12 @@ def test_EarlyStopping_patience():\n         def __init__(self):\n             self.stop_training = False\n \n+        def get_weights(self):\n+            return []\n+\n+        def set_weights(self, weights):\n+            pass\n+\n     early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=2)\n     early_stop.model = DummyModel()\n \n@@ -292,6 +298,12 @@ def test_EarlyStopping_baseline():\n         def __init__(self):\n             self.stop_training = False\n \n+        def get_weights(self):\n+            return []\n+\n+        def set_weights(self, weights):\n+            pass\n+\n     def baseline_tester(acc_levels):\n         early_stop = callbacks.EarlyStopping(monitor='val_acc', baseline=0.75, patience=2)\n         early_stop.model = DummyModel()\n@@ -315,6 +327,84 @@ def test_EarlyStopping_baseline():\n     assert baseline_not_met == 2\n \n \n+@keras_test\n+def test_EarlyStopping_final_weights():\n+    class DummyModel(object):\n+        def __init__(self):\n+            self.stop_training = False\n+            self.weights = -1\n+\n+        def get_weights(self):\n+            return self.weights\n+\n+        def set_weights(self, weights):\n+            self.weights = weights\n+\n+        def set_weight_to_epoch(self, epoch):\n+            self.weights = epoch\n+\n+    early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=2)\n+    early_stop.model = DummyModel()\n+\n+    losses = [0.2, 0.15, 0.1, 0.11, 0.12]\n+\n+    epochs_trained = 0\n+    early_stop.on_train_begin()\n+\n+    for epoch in range(len(losses)):\n+        epochs_trained += 1\n+        early_stop.model.set_weight_to_epoch(epoch=epoch)\n+        early_stop.on_epoch_end(epoch, logs={'val_loss': losses[epoch]})\n+\n+        if early_stop.model.stop_training:\n+            break\n+\n+    # The best configuration is in the epoch 2 (loss = 0.1000),\n+    # so with patience=2 we need to end up at epoch 4\n+    assert early_stop.model.get_weights() == 4\n+\n+\n+@keras_test\n+def test_EarlyStopping_final_weights_when_restoring_model_weights():\n+    class DummyModel(object):\n+        def __init__(self):\n+            self.stop_training = False\n+            self.weights = -1\n+\n+        def get_weights(self):\n+            return self.weights\n+\n+        def set_weights(self, weights):\n+            self.weights = weights\n+\n+        def set_weight_to_epoch(self, epoch):\n+            self.weights = epoch\n+\n+    early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=2,\n+                                         restore_best_weights=True)\n+    early_stop.model = DummyModel()\n+\n+    losses = [0.2, 0.15, 0.1, 0.11, 0.12]\n+\n+    # The best configuration is in the epoch 2 (loss = 0.1000).\n+\n+    epochs_trained = 0\n+    early_stop.on_train_begin()\n+\n+    for epoch in range(len(losses)):\n+        epochs_trained += 1\n+        early_stop.model.set_weight_to_epoch(epoch=epoch)\n+        early_stop.on_epoch_end(epoch, logs={'val_loss': losses[epoch]})\n+\n+        if early_stop.model.stop_training:\n+            break\n+\n+    # The best configuration is in epoch 2 (loss = 0.1000),\n+    # and while patience = 2, we're restoring the best weights,\n+    # so we end up at the epoch with the best weights, i.e. epoch 2\n+    assert early_stop.model.get_weights() == 2\n+\n+\n @keras_test\n def test_LearningRateScheduler():\n     np.random.seed(1337)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7386841194d139ee8d1de2749fa64f86150f9c2f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 1602 | Contributors (this commit): 14 | Commits (past 90d): 4 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -19,6 +19,11 @@ from keras.utils import Sequence\n from keras.utils.data_utils import _hash_file\n from keras.utils.data_utils import get_file\n from keras.utils.data_utils import validate_file\n+from keras import backend as K\n+\n+pytestmark = pytest.mark.skipif(\n+    K.backend() == 'tensorflow',\n+    reason='Temporarily disabled until the use_multiprocessing problem is solved')\n \n if sys.version_info < (3,):\n     def next(x):\n\n@@ -9,6 +9,10 @@ from keras.utils.test_utils import keras_test\n from keras.utils import Sequence\n from keras import backend as K\n \n+pytestmark = pytest.mark.skipif(\n+    K.backend() == 'tensorflow',\n+    reason='Temporarily disabled until the use_multiprocessing problem is solved')\n+\n STEPS_PER_EPOCH = 100\n STEPS = 100\n WORKERS = 4 if K.backend() != 'tensorflow' else 2\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#213170d20241c918ff42078e2de3e9a908244093", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 37 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 7/6 | Churn Δ: 38 | Churn Cumulative: 431 | Contributors (this commit): 6 | Commits (past 90d): 5 | Contributors (cumulative): 9 | DMM Complexity: 0.5517241379310345\n\nDIFF:\n@@ -231,10 +231,25 @@ def multi_gpu_model(model, gpus=None, cpu_merge=True, cpu_relocation=False):\n                 for o in range(len(outputs)):\n                     all_outputs[o].append(outputs[o])\n \n+    # Deduplicate output names to handle Siamese networks.\n+    occurrences = {}\n+    for n in model.output_names:\n+        if n not in occurrences:\n+            occurrences[n] = 1\n+        else:\n+            occurrences[n] += 1\n+    conflict_counter = {n: 0 for n, count in occurrences.items() if count > 1}\n+    output_names = []\n+    for n in model.output_names:\n+        if n in conflict_counter:\n+            conflict_counter[n] += 1\n+            n += '_%d' % conflict_counter[n]\n+        output_names.append(n)\n+\n     # Merge outputs under expected scope.\n     with tf.device('/cpu:0' if cpu_merge else '/gpu:%d' % target_gpu_ids[0]):\n         merged = []\n-        for name, outputs in zip(model.output_names, all_outputs):\n+        for name, outputs in zip(output_names, all_outputs):\n             merged.append(concatenate(outputs,\n                                       axis=0, name=name))\n         return Model(model.inputs, merged)\n\n@@ -286,5 +286,26 @@ def test_multi_gpu_with_multi_input_layers():\n     parallel_model.train_on_batch(x, y)\n \n \n+@keras_test\n+def test_multi_gpu_with_siamese():\n+    input_shape = (3,)\n+    nested_model = keras.models.Sequential([\n+        keras.layers.Dense(32, input_shape=input_shape),\n+        keras.layers.Dense(1)\n+    ], name='nested')\n+\n+    input1 = keras.Input(input_shape)\n+    input2 = keras.Input(input_shape)\n+    score1 = nested_model(input1)\n+    score2 = nested_model(input2)\n+    score_sum = keras.layers.Add(name='add')([score1, score2])\n+\n+    siamese = keras.models.Model(inputs=[input1, input2],\n+                                 outputs=[score_sum, score1, score2],\n+                                 name='siamese')\n+    parallel_siamese = multi_gpu_model(siamese, 2)\n+    assert parallel_siamese.output_names == ['add', 'nested_1', 'nested_2']\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c8e3b601cd8bf3062d416a5ef74c4a97be611923", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 263 | Contributors (this commit): 6 | Commits (past 90d): 3 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -6,10 +6,10 @@ and 79% after 15 epochs, and overfitting after 20 epochs\n \n With Data Augmentation:\n It gets to 75% validation accuracy in 10 epochs,\n-and 79% after 15 epochs, and 83% after 30 epcohs.\n-In my test, highest validation accuracy is 83.79% after 50 epcohs.\n+and 79% after 15 epochs, and 83% after 30 epochs.\n+In my test, highest validation accuracy is 83.79% after 50 epochs.\n \n-This is a fast Implement, just 20s/epcoh with a gtx 1070 gpu.\n+This is a fast Implement, just 20s/epoch with a gtx 1070 gpu.\n \"\"\"\n \n from __future__ import print_function\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a36ed703e4723ba5af948eb0988bf44a56747452", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 60 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 10 | Methods Changed: 4 | Complexity Δ (Sum/Max): 12/10 | Churn Δ: 70 | Churn Cumulative: 10603 | Contributors (this commit): 98 | Commits (past 90d): 15 | Contributors (cumulative): 116 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1177,14 +1177,30 @@ def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n     y = T.set_subtensor(output[indices], x)\n     if hasattr(x, '_keras_shape'):\n         if data_format == 'channels_first':\n+            if x._keras_shape[2] is not None:\n+                h = x._keras_shape[2] + top_pad + bottom_pad\n+            else:\n+                h = None\n+            if x._keras_shape[3] is not None:\n+                w = x._keras_shape[3] + left_pad + right_pad\n+            else:\n+                w = None\n             output_keras_shape = (x._keras_shape[0],\n                                   x._keras_shape[1],\n-                                  x._keras_shape[2] + top_pad + bottom_pad,\n-                                  x._keras_shape[3] + left_pad + right_pad)\n+                                  h,\n+                                  w)\n         else:\n+            if x._keras_shape[1] is not None:\n+                h = x._keras_shape[1] + top_pad + bottom_pad\n+            else:\n+                h = None\n+            if x._keras_shape[2] is not None:\n+                w = x._keras_shape[2] + left_pad + right_pad\n+            else:\n+                w = None\n             output_keras_shape = (x._keras_shape[0],\n-                                  x._keras_shape[1] + top_pad + bottom_pad,\n-                                  x._keras_shape[2] + left_pad + right_pad,\n+                                  h,\n+                                  w,\n                                   x._keras_shape[3])\n         y._keras_shape = output_keras_shape\n     return y\n@@ -1225,16 +1241,40 @@ def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n     y = T.set_subtensor(output[indices], x)\n     if hasattr(x, '_keras_shape'):\n         if data_format == 'channels_first':\n+            if x._keras_shape[2] is not None:\n+                h = x._keras_shape[2] + padding[0][0] + padding[0][1]\n+            else:\n+                h = None\n+            if x._keras_shape[3] is not None:\n+                w = x._keras_shape[3] + padding[1][0] + padding[1][1]\n+            else:\n+                w = None\n+            if x._keras_shape[4] is not None:\n+                d = x._keras_shape[4] + padding[2][0] + padding[2][1]\n+            else:\n+                d = None\n             output_keras_shape = (x._keras_shape[0],\n                                   x._keras_shape[1],\n-                                  x._keras_shape[2] + padding[0][0] + padding[0][1],\n-                                  x._keras_shape[3] + padding[1][0] + padding[1][1],\n-                                  x._keras_shape[4] + padding[2][0] + padding[2][1])\n+                                  h,\n+                                  w,\n+                                  d)\n         else:\n+            if x._keras_shape[1] is not None:\n+                h = x._keras_shape[1] + padding[0][0] + padding[0][1]\n+            else:\n+                h = None\n+            if x._keras_shape[2] is not None:\n+                w = x._keras_shape[2] + padding[1][0] + padding[1][1]\n+            else:\n+                w = None\n+            if x._keras_shape[3] is not None:\n+                d = x._keras_shape[3] + padding[2][0] + padding[2][1]\n+            else:\n+                d = None\n             output_keras_shape = (x._keras_shape[0],\n-                                  x._keras_shape[1] + padding[0][0] + padding[0][1],\n-                                  x._keras_shape[2] + padding[1][0] + padding[1][1],\n-                                  x._keras_shape[3] + padding[2][0] + padding[2][1],\n+                                  h,\n+                                  w,\n+                                  d,\n                                   x._keras_shape[4])\n         y._keras_shape = output_keras_shape\n     return y\n\n@@ -1351,6 +1351,11 @@ class TestBackend(object):\n                 x_shape = (1,) + shape + (3,)\n             check_single_tensor_operation('spatial_2d_padding', x_shape, BACKENDS,\n                                           padding=padding, data_format=data_format)\n+            # Check handling of dynamic shapes.\n+            for k in BACKENDS:\n+                x = k.placeholder(shape=(1, None, None, 1))\n+                y = k.spatial_2d_padding(x, padding=padding, data_format='channels_last')\n+                assert k.int_shape(y) == (1, None, None, 1)\n \n         # Test invalid use cases\n         xval = np.random.random(x_shape)\n@@ -1369,6 +1374,11 @@ class TestBackend(object):\n                 x_shape = (1,) + shape + (3,)\n             check_single_tensor_operation('spatial_3d_padding', x_shape, BACKENDS,\n                                           padding=padding, data_format=data_format)\n+            # Check handling of dynamic shapes.\n+            for k in BACKENDS:\n+                x = k.placeholder(shape=(1, None, None, None, 1))\n+                y = k.spatial_3d_padding(x, padding=padding, data_format='channels_last')\n+                assert k.int_shape(y) == (1, None, None, None, 1)\n \n         # Test invalid use cases\n         xval = np.random.random(x_shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#907e8035656b0597a7a2f3cc1bf237a8cbf48821", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 33 | Files Changed: 1 | Hunks: 22 | Methods Changed: 12 | Complexity Δ (Sum/Max): -12/0 | Churn Δ: 54 | Churn Cumulative: 4462 | Contributors (this commit): 28 | Commits (past 90d): 6 | Contributors (cumulative): 28 | DMM Complexity: 1.0\n\nDIFF:\n@@ -879,9 +879,8 @@ class TestBackend(object):\n         '''\n         Check if K.logsumexp works properly for values close to one.\n         '''\n-        for k in BACKENDS:\n-            x = k.variable(x_np)\n-            assert_allclose(k.eval(k.logsumexp(x, axis=axis, keepdims=keepdims)),\n+        x = K.variable(x_np)\n+        assert_allclose(K.eval(K.logsumexp(x, axis=axis, keepdims=keepdims)),\n                         np.log(np.sum(np.exp(x_np), axis=axis, keepdims=keepdims)),\n                         rtol=1e-5)\n \n@@ -936,9 +935,8 @@ class TestBackend(object):\n             assert np.abs(z_list[i].mean() - z_list[i + 1].mean()) < 0.05\n \n         # Test invalid use cases\n-        for k in BACKENDS:\n         with pytest.raises(ValueError):\n-                z = k.dropout(k.variable(val), level=-0.5)\n+            z = K.dropout(K.variable(val), level=-0.5)\n \n     def test_nn_operations(self):\n         check_single_tensor_operation('relu', (4, 2), BACKENDS, alpha=0.1, max_value=0.5)\n@@ -1176,46 +1174,43 @@ class TestBackend(object):\n \n     def test_random_normal(self):\n         # test standard normal as well as a normal with a different set of parameters\n-        for k in BACKENDS:\n         for mean, std in [(0., 1.), (-10., 5.)]:\n-                rand = k.eval(k.random_normal((300, 200), mean=mean, stddev=std, seed=1337))\n+            rand = K.eval(K.random_normal((300, 200), mean=mean, stddev=std, seed=1337))\n             assert rand.shape == (300, 200)\n             assert np.abs(np.mean(rand) - mean) < std * 0.015\n             assert np.abs(np.std(rand) - std) < std * 0.015\n \n             # test that random_normal also generates different values when used within a function\n-                r = k.random_normal((1,), mean=mean, stddev=std, seed=1337)\n-                samples = [k.eval(r) for _ in range(60000)]\n+            r = K.random_normal((1,), mean=mean, stddev=std, seed=1337)\n+            samples = [K.eval(r) for _ in range(60000)]\n             assert np.abs(np.mean(samples) - mean) < std * 0.015\n             assert np.abs(np.std(samples) - std) < std * 0.015\n \n     def test_random_uniform(self):\n         min_val = -1.\n         max_val = 1.\n-        for k in BACKENDS:\n-            rand = k.eval(k.random_uniform((200, 100), min_val, max_val))\n+        rand = K.eval(K.random_uniform((200, 100), min_val, max_val))\n         assert rand.shape == (200, 100)\n         assert np.abs(np.mean(rand)) < 0.015\n         assert max_val - 0.015 < np.max(rand) <= max_val\n         assert min_val + 0.015 > np.min(rand) >= min_val\n \n-            r = k.random_uniform((1,), minval=min_val, maxval=max_val)\n-            samples = [k.eval(r) for _ in range(20000)]\n+        r = K.random_uniform((1,), minval=min_val, maxval=max_val)\n+        samples = [K.eval(r) for _ in range(20000)]\n         assert np.abs(np.mean(samples)) < 0.015\n         assert max_val - 0.015 < np.max(samples) <= max_val\n         assert min_val + 0.015 > np.min(samples) >= min_val\n \n     def test_random_binomial(self):\n         p = 0.5\n-        for k in BACKENDS:\n-            rand = k.eval(k.random_binomial((200, 100), p))\n+        rand = K.eval(K.random_binomial((200, 100), p))\n         assert rand.shape == (200, 100)\n         assert np.abs(np.mean(rand) - p) < 0.015\n         assert np.max(rand) == 1\n         assert np.min(rand) == 0\n \n-            r = k.random_binomial((1,), p)\n-            samples = [k.eval(r) for _ in range(20000)]\n+        r = K.random_binomial((1,), p)\n+        samples = [K.eval(r) for _ in range(20000)]\n         assert np.abs(np.mean(samples) - p) < 0.015\n         assert np.max(samples) == 1\n         assert np.min(samples) == 0\n@@ -1225,8 +1220,7 @@ class TestBackend(object):\n         std = 1.\n         min_val = -2.\n         max_val = 2.\n-        for k in BACKENDS:\n-            rand = k.eval(k.truncated_normal((300, 200), mean=mean, stddev=std, seed=1337))\n+        rand = K.eval(K.truncated_normal((300, 200), mean=mean, stddev=std, seed=1337))\n         assert rand.shape == (300, 200)\n         assert np.abs(np.mean(rand) - mean) < 0.015\n         assert np.max(rand) <= max_val\n@@ -1309,9 +1303,8 @@ class TestBackend(object):\n \n         # Test invalid use cases\n         xval = np.random.random(x_shape)\n-        for k in BACKENDS:\n         with pytest.raises(ValueError):\n-                k.resize_images(k.variable(xval), 2, 2,\n+            K.resize_images(K.variable(xval), 2, 2,\n                             data_format='channels_middle')\n \n     def test_resize_volumes(self):\n@@ -1330,9 +1323,8 @@ class TestBackend(object):\n \n         # Test invalid use cases\n         xval = np.random.random(x_shape)\n-        for k in BACKENDS:\n         with pytest.raises(ValueError):\n-                k.resize_volumes(k.variable(xval), 2, 2, 2,\n+            K.resize_volumes(K.variable(xval), 2, 2, 2,\n                              data_format='channels_middle')\n \n     def test_temporal_padding(self):\n@@ -1359,9 +1351,8 @@ class TestBackend(object):\n \n         # Test invalid use cases\n         xval = np.random.random(x_shape)\n-        for k in BACKENDS:\n         with pytest.raises(ValueError):\n-                k.spatial_2d_padding(k.variable(xval), padding=padding,\n+            K.spatial_2d_padding(K.variable(xval), padding=padding,\n                                  data_format='channels_middle')\n \n     def test_spatial_3d_padding(self):\n@@ -1382,9 +1373,8 @@ class TestBackend(object):\n \n         # Test invalid use cases\n         xval = np.random.random(x_shape)\n-        for k in BACKENDS:\n         with pytest.raises(ValueError):\n-                k.spatial_3d_padding(k.variable(xval), padding=padding,\n+            K.spatial_3d_padding(K.variable(xval), padding=padding,\n                                  data_format='channels_middle')\n \n     def test_bias_add(self):\n@@ -1408,11 +1398,10 @@ class TestBackend(object):\n                                        data_format=data_format)\n \n         # Test invalid use cases\n-        for k in BACKENDS:\n-            x = k.variable(np.random.random(x_shape))\n-            b = k.variable(np.random.random(bias_shape))\n+        x = K.variable(np.random.random(x_shape))\n+        b = K.variable(np.random.random(bias_shape))\n         with pytest.raises(ValueError):\n-                k.bias_add(x, b, data_format='channels_middle')\n+            K.bias_add(x, b, data_format='channels_middle')\n \n     def test_batchnorm(self):\n         shape = (2, 3)\n@@ -1620,8 +1609,7 @@ class TestBackend(object):\n         batch_size = 30\n         indices = np.random.randint(0, num_classes, size=(batch_size, input_length))\n         oh = np.eye(num_classes)[indices]\n-        for k in BACKENDS:\n-            koh = k.eval(k.one_hot(k.variable(indices, dtype='int32'), num_classes))\n+        koh = K.eval(K.one_hot(K.variable(indices, dtype='int32'), num_classes))\n         assert np.all(koh == oh)\n \n     def test_sparse_dot(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bca4cc4df563a1d72b91460bc29cb18e91d14057", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 85 | Lines Deleted: 58 | Files Changed: 4 | Hunks: 41 | Methods Changed: 17 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 143 | Churn Cumulative: 5039 | Contributors (this commit): 34 | Commits (past 90d): 10 | Contributors (cumulative): 44 | DMM Complexity: 0.65\n\nDIFF:\n@@ -107,7 +107,11 @@ def pool(x, pool_size, strides, padding, data_format, pool_mode):\n         for (k, k1) in zip(range(pool_size[0]), range(-pool_size[0], 0)):\n             for (l, l1) in zip(range(pool_size[1]), range(-pool_size[1], 0)):\n                 for (m, m1) in zip(range(pool_size[2]), range(-pool_size[2], 0)):\n-                    y.append(x[:, :, k:k1:strides[0], l:l1:strides[1], m:m1:strides[2]])\n+                    y.append(x[:,\n+                               :,\n+                               k:k1:strides[0],\n+                               l:l1:strides[1],\n+                               m:m1:strides[2]])\n     y = np.stack(y, axis=-1)\n     if pool_mode == 'avg':\n         y = np.mean(np.ma.masked_invalid(y), axis=-1).data\n\n@@ -13,7 +13,8 @@ from keras.initializers import Constant\n \n \n skipif_no_tf_gpu = pytest.mark.skipif(\n-    (K.backend() != 'tensorflow') or (not K.tensorflow_backend._get_available_gpus()),\n+    (K.backend() != 'tensorflow' or\n+     not K.tensorflow_backend._get_available_gpus()),\n     reason='Requires TensorFlow backend and a GPU')\n \n \n@@ -284,13 +285,15 @@ def test_multi_input_layer():\n \n     model = Model(inputs=[a, b], outputs=[c, d], name='model')\n     assert len(model.layers) == 6\n-    assert model.compute_output_shape([(None, 32), (None, 32)]) == [(None, 64), (None, 5)]\n+    expected_shapes = [(None, 64), (None, 5)]\n+    assert model.compute_output_shape([(None, 32), (None, 32)]) == expected_shapes\n     assert model.compute_mask([a, b], [None, None]) == [None, None]\n-    assert model.compute_output_shape([(None, 32), (None, 32)]) == [(None, 64), (None, 5)]\n+    assert model.compute_output_shape([(None, 32), (None, 32)]) == expected_shapes\n \n     # we don't check names of first 2 layers (inputs) because\n     # ordering of same-level layers is not fixed\n-    assert [l.name for l in model.layers][2:] == ['dense_1', 'merge', 'dense_2', 'dense_3']\n+    expected_names = ['dense_1', 'merge', 'dense_2', 'dense_3']\n+    assert [l.name for l in model.layers][2:] == expected_names\n     assert [l.name for l in model._input_layers] == ['input_a', 'input_b']\n     assert [l.name for l in model._output_layers] == ['dense_2', 'dense_3']\n \n@@ -309,7 +312,7 @@ def test_multi_input_layer():\n     recreated_model = model_from_json(json_config)\n     recreated_model.compile('rmsprop', 'mse')\n \n-    assert [l.name for l in recreated_model.layers][2:] == ['dense_1', 'merge', 'dense_2', 'dense_3']\n+    assert [l.name for l in recreated_model.layers][2:] == expected_names\n     assert [l.name for l in recreated_model._input_layers] == ['input_a', 'input_b']\n     assert [l.name for l in recreated_model._output_layers] == ['dense_2', 'dense_3']\n \n@@ -356,9 +359,10 @@ def test_recursion():\n \n     # we don't check names of first 2 layers (inputs) because\n     # ordering of same-level layers is not fixed\n+    expected_shapes = [(10, 7), (10, 64)]\n     assert [layer.name for layer in final_model.layers][2:] == ['model', 'dense_4']\n     assert model.compute_mask([e, f], [None, None]) == [None, None]\n-    assert final_model.compute_output_shape([(10, 32), (10, 32)]) == [(10, 7), (10, 64)]\n+    assert final_model.compute_output_shape([(10, 32), (10, 32)]) == expected_shapes\n \n     # run recursive model\n     fn = K.function(final_model.inputs, final_model.outputs)\n@@ -501,7 +505,8 @@ def test_recursion():\n \n @keras_test\n def test_load_layers():\n-    from keras.layers import ConvLSTM2D, TimeDistributed, Bidirectional, Conv2D, Input\n+    from keras.layers import ConvLSTM2D, TimeDistributed\n+    from keras.layers import Bidirectional, Conv2D, Input\n     from keras.models import Model\n \n     if K.backend() == 'tensorflow' or K.backend() == 'cntk':\n@@ -509,13 +514,14 @@ def test_load_layers():\n     else:\n         inputs = Input(shape=(10, 1, 20, 20))\n     td_conv = TimeDistributed(Conv2D(15, (5, 5)))(inputs)\n-    bi_convlstm2d = Bidirectional(ConvLSTM2D(10, (3, 3)), merge_mode='concat')(td_conv)\n-    model = Model(inputs=inputs, outputs=bi_convlstm2d)\n+    bi_conv = Bidirectional(ConvLSTM2D(10, (3, 3)), merge_mode='concat')(td_conv)\n+    model = Model(inputs=inputs, outputs=bi_conv)\n \n     weight_value_tuples = []\n \n     # TimeDistributed Conv2D layer\n-    # use 'channels_first' data format to check that the function is being called correctly for Conv2D\n+    # use 'channels_first' data format to check that\n+    # the function is being called correctly for Conv2D\n     # old: (filters, stack_size, kernel_rows, kernel_cols)\n     # new: (kernel_rows, kernel_cols, stack_size, filters)\n     weight_tensor_td_conv_old = list()\n@@ -532,34 +538,35 @@ def test_load_layers():\n     weight_value_tuples += zip(symbolic_weights, weight_tensor_td_conv_new)\n \n     # Bidirectional ConvLSTM2D layer\n-    # old ConvLSTM2D took a list of 12 weight tensors, returns a list of 3 concatenated larger tensors.\n-    weight_tensor_bi_convlstm_old = []\n+    # old ConvLSTM2D took a list of 12 weight tensors,\n+    # returns a list of 3 concatenated larger tensors.\n+    weights_bi_conv_old = []\n     for j in range(2):  # bidirectional\n         for i in range(4):\n-            weight_tensor_bi_convlstm_old.append(np.zeros((3, 3, 15, 10)))  # kernel\n-            weight_tensor_bi_convlstm_old.append(np.zeros((3, 3, 10, 10)))  # recurrent kernel\n-            weight_tensor_bi_convlstm_old.append(np.zeros((10,)))  # bias\n+            weights_bi_conv_old.append(np.zeros((3, 3, 15, 10)))  # kernel\n+            weights_bi_conv_old.append(np.zeros((3, 3, 10, 10)))  # recurrent kernel\n+            weights_bi_conv_old.append(np.zeros((10,)))  # bias\n \n     bi_convlstm_layer = model.layers[2]\n-    weight_tensor_bi_convlstm_new = saving.preprocess_weights_for_loading(\n+    weights_bi_conv_new = saving.preprocess_weights_for_loading(\n         bi_convlstm_layer,\n-        weight_tensor_bi_convlstm_old,\n+        weights_bi_conv_old,\n         original_keras_version='1')\n \n     symbolic_weights = bi_convlstm_layer.weights\n-    assert (len(symbolic_weights) == len(weight_tensor_bi_convlstm_new))\n-    weight_value_tuples += zip(symbolic_weights, weight_tensor_bi_convlstm_new)\n+    assert (len(symbolic_weights) == len(weights_bi_conv_new))\n+    weight_value_tuples += zip(symbolic_weights, weights_bi_conv_new)\n \n     K.batch_set_value(weight_value_tuples)\n \n     assert np.all(K.eval(model.layers[1].weights[0]) == weight_tensor_td_conv_new[0])\n     assert np.all(K.eval(model.layers[1].weights[1]) == weight_tensor_td_conv_new[1])\n-    assert np.all(K.eval(model.layers[2].weights[0]) == weight_tensor_bi_convlstm_new[0])\n-    assert np.all(K.eval(model.layers[2].weights[1]) == weight_tensor_bi_convlstm_new[1])\n-    assert np.all(K.eval(model.layers[2].weights[2]) == weight_tensor_bi_convlstm_new[2])\n-    assert np.all(K.eval(model.layers[2].weights[3]) == weight_tensor_bi_convlstm_new[3])\n-    assert np.all(K.eval(model.layers[2].weights[4]) == weight_tensor_bi_convlstm_new[4])\n-    assert np.all(K.eval(model.layers[2].weights[5]) == weight_tensor_bi_convlstm_new[5])\n+    assert np.all(K.eval(model.layers[2].weights[0]) == weights_bi_conv_new[0])\n+    assert np.all(K.eval(model.layers[2].weights[1]) == weights_bi_conv_new[1])\n+    assert np.all(K.eval(model.layers[2].weights[2]) == weights_bi_conv_new[2])\n+    assert np.all(K.eval(model.layers[2].weights[3]) == weights_bi_conv_new[3])\n+    assert np.all(K.eval(model.layers[2].weights[4]) == weights_bi_conv_new[4])\n+    assert np.all(K.eval(model.layers[2].weights[5]) == weights_bi_conv_new[5])\n \n \n def convert_weights(layer, weights):\n@@ -613,17 +620,17 @@ def test_preprocess_weights_for_loading_for_model(layer):\n \n \n @keras_test\n-@pytest.mark.parametrize('layer_class,layer_args', [\n+@pytest.mark.parametrize('layer_class,args', [\n     (layers.GRU, {'units': 2, 'input_shape': [3, 5]}),\n     (layers.GRU, {'units': 2, 'input_shape': [3, 5], 'reset_after': True}),\n     (layers.LSTM, {'units': 2, 'input_shape': [3, 5]}),\n ])\n-def test_preprocess_weights_for_loading_rnn_should_be_idempotent(layer_class, layer_args):\n+def test_preprocess_weights_for_loading_rnn_should_be_idempotent(layer_class, args):\n     \"\"\"\n     Loading weights from a RNN class to itself should not convert the weights.\n     \"\"\"\n     # layer can be instantiated only for supported backends\n-    layer = layer_class(**layer_args)\n+    layer = layer_class(**args)\n     # A model is needed to initialize weights.\n     _ = Sequential([layer])\n     weights1 = layer.get_weights()\n@@ -632,13 +639,14 @@ def test_preprocess_weights_for_loading_rnn_should_be_idempotent(layer_class, la\n \n \n @keras_test\n-@pytest.mark.parametrize('layer_class,layer_args', [\n+@pytest.mark.parametrize('layer_class,args', [\n     (layers.CuDNNGRU, {'units': 2, 'input_shape': [3, 5]}),\n     (layers.CuDNNLSTM, {'units': 2, 'input_shape': [3, 5]}),\n ])\n @skipif_no_tf_gpu\n-def test_preprocess_weights_for_loading_cudnn_rnn_should_be_idempotent(layer_class, layer_args):\n-    test_preprocess_weights_for_loading_rnn_should_be_idempotent(layer_class, layer_args)\n+def test_preprocess_weights_for_loading_cudnn_rnn_should_be_idempotent(layer_class,\n+                                                                       args):\n+    test_preprocess_weights_for_loading_rnn_should_be_idempotent(layer_class, args)\n \n \n @keras_test\n@@ -693,10 +701,11 @@ def test_activity_regularization_with_model_composition():\n \n @keras_test\n def test_shared_layer_depth_is_correct():\n-    # Basic outline here: we have a shared embedding layer, and two inputs that go through\n-    # different depths of computation in the graph before the final output.  We need the computed\n-    # depth of the input layers to be the same, because they both pass through the embedding layer\n-    # before anything else happens.  That's what we're testing.\n+    # Basic outline here: we have a shared embedding layer, and two inputs that\n+    # go through different depths of computation in the graph before\n+    # the final output.  We need the computed depth of the input layers to be\n+    # the same, because they both pass through the embedding layer before anything\n+    # else happens.  That's what we're testing.\n     from keras.layers import Embedding, Input, Dense, Concatenate\n     from keras.models import Model\n     input1 = Input(shape=(10,), name='input1')\n@@ -772,28 +781,29 @@ def test_layer_sharing_at_heterogeneous_depth_with_concat():\n @keras_test\n def test_multi_output_mask():\n     \"\"\"Fixes #7589\"\"\"\n-    class ArbitraryMultiOutputLayer(Layer):\n+    class TestMultiOutputLayer(Layer):\n         def __init__(self, **kwargs):\n-            super(ArbitraryMultiOutputLayer, self).__init__(**kwargs)\n+            super(TestMultiOutputLayer, self).__init__(**kwargs)\n \n         def call(self, inputs, **kwargs):\n             return [K.abs(inputs), K.abs(inputs)]\n \n         def compute_output_shape(self, input_shape):\n-            out_shape = super(ArbitraryMultiOutputLayer, self).compute_output_shape(input_shape)\n+            out_shape = super(TestMultiOutputLayer, self).compute_output_shape(\n+                input_shape)\n             return [out_shape, out_shape]\n \n-    class ArbitraryMultiInputLayer(Layer):\n+    class TestMultiInputLayer(Layer):\n         def __init__(self, **kwargs):\n-            super(ArbitraryMultiInputLayer, self).__init__(**kwargs)\n+            super(TestMultiInputLayer, self).__init__(**kwargs)\n \n         def call(self, inputs, **kwargs):\n             negative, positive = inputs\n             return negative + positive\n \n     input_layer = Input(shape=(16, 16, 3))\n-    x, y = ArbitraryMultiOutputLayer()(input_layer)\n-    z = ArbitraryMultiInputLayer()([x, y])\n+    x, y = TestMultiOutputLayer()(input_layer)\n+    z = TestMultiInputLayer()([x, y])\n     _ = Model(inputs=input_layer, outputs=z)\n     assert K.int_shape(z)[1:] == (16, 16, 3)\n \n@@ -801,7 +811,8 @@ def test_multi_output_mask():\n @keras_test\n def test_constant_initializer_with_numpy():\n     model = Sequential()\n-    model.add(Dense(2, input_shape=(3,), kernel_initializer=Constant(np.ones((3, 2)))))\n+    model.add(Dense(2, input_shape=(3,),\n+                    kernel_initializer=Constant(np.ones((3, 2)))))\n     model.add(Dense(3))\n     model.compile(loss='mse', optimizer='sgd', metrics=['acc'])\n \n\n@@ -392,7 +392,8 @@ def test_model_methods():\n \n     # the rank of weight arrays should be 1.\n     with pytest.raises(ValueError):\n-        out = model.train_on_batch([input_a_np, input_b_np],\n+        out = model.train_on_batch(\n+            [input_a_np, input_b_np],\n             [output_a_np, output_b_np],\n             sample_weight=[None, np.random.random((10, 20, 30))])\n \n@@ -557,7 +558,8 @@ def test_warnings():\n                                   steps_per_epoch=4,\n                                   use_multiprocessing=True,\n                                   workers=2)\n-    assert all(['Sequence' not in str(w_.message) for w_ in w]), 'A warning was raised for Sequence.'\n+    assert all(['Sequence' not in str(w_.message) for w_ in w]), (\n+        'A warning was raised for Sequence.')\n \n \n @keras_test\n@@ -576,7 +578,8 @@ def test_sparse_inputs_targets():\n     model.evaluate(test_inputs, test_outputs, batch_size=2)\n \n \n-@pytest.mark.skipif(K.backend() != 'tensorflow', reason='sparse operations supported only by TensorFlow')\n+@pytest.mark.skipif(K.backend() != 'tensorflow',\n+                    reason='sparse operations supported only by TensorFlow')\n @keras_test\n def test_sparse_placeholder_fit():\n     test_inputs = [sparse.random(6, 3, density=0.25).tocsr() for _ in range(2)]\n@@ -657,7 +660,8 @@ def test_check_bad_shape():\n     assert 'targets to have the same shape' in str(exc)\n \n \n-@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TensorFlow backend')\n+@pytest.mark.skipif(K.backend() != 'tensorflow',\n+                    reason='Requires TensorFlow backend')\n @keras_test\n def test_model_with_input_feed_tensor():\n     \"\"\"We test building a model with a TF variable as input.\n@@ -1053,12 +1057,16 @@ def test_target_tensors():\n     model.train_on_batch(input_val, None)\n \n     # multi-output, not enough target tensors when `target_tensors` is not a dict\n-    with pytest.raises(ValueError, match='When passing a list as `target_tensors`, it should have one entry per model '\n-                                         'output. The model has \\d outputs, but you passed target_tensors='):\n+    with pytest.raises(ValueError,\n+                       match='When passing a list as `target_tensors`, it should '\n+                             'have one entry per model output. The model has \\d '\n+                             'outputs, but you passed target_tensors='):\n         model.compile(optimizer='rmsprop', loss='mse',\n                       target_tensors=[target_a])\n-    with pytest.raises(ValueError, match='The model has \\d outputs, but you passed a single tensor as '\n-                                         '`target_tensors`. Expected a list or a dict of tensors.'):\n+    with pytest.raises(ValueError,\n+                       match='The model has \\d outputs, but you passed a single '\n+                             'tensor as `target_tensors`. Expected a list or '\n+                             'a dict of tensors.'):\n         model.compile(optimizer='rmsprop', loss='mse',\n                       target_tensors=target_a)\n \n@@ -1131,7 +1139,8 @@ def test_model_custom_target_tensors():\n                              [output_a_np, output_b_np])\n \n \n-@pytest.mark.skipif(sys.version_info < (3,), reason='Cannot catch warnings in python 2')\n+@pytest.mark.skipif(sys.version_info < (3,),\n+                    reason='Cannot catch warnings in python 2')\n @keras_test\n def test_trainable_weights_count_consistency():\n     \"\"\"Tests the trainable weights consistency check of Model.\n@@ -1157,19 +1166,22 @@ def test_trainable_weights_count_consistency():\n     with pytest.warns(UserWarning) as w:\n         model2.summary()\n     warning_raised = any(['Discrepancy' in str(w_.message) for w_ in w])\n-    assert warning_raised, 'No warning raised when trainable is modified without .compile.'\n+    assert warning_raised, (\n+        'No warning raised when trainable is modified without .compile.')\n \n     # And on .fit()\n     with pytest.warns(UserWarning) as w:\n         model2.fit(x=np.zeros((5, 3)), y=np.zeros((5, 1)))\n     warning_raised = any(['Discrepancy' in str(w_.message) for w_ in w])\n-    assert warning_raised, 'No warning raised when trainable is modified without .compile.'\n+    assert warning_raised, (\n+        'No warning raised when trainable is modified without .compile.')\n \n     # And shouldn't warn if we recompile\n     model2.compile(optimizer='adam', loss='mse')\n     with pytest.warns(None) as w:\n         model2.summary()\n-    assert len(w) == 0, \"Warning raised even when .compile() is called after modifying .trainable\"\n+    assert len(w) == 0, (\n+        'Warning raised even when .compile() is called after modifying .trainable')\n \n \n @keras_test\n\n@@ -9,8 +9,8 @@ import time\n \n \n skipif_no_tf_gpu = pytest.mark.skipif(\n-    ((K.backend() != 'tensorflow') or\n-     (not K.tensorflow_backend._get_available_gpus())),\n+    (K.backend() != 'tensorflow' or\n+     not K.tensorflow_backend._get_available_gpus()),\n     reason='Requires TensorFlow backend and a GPU')\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#529daf169e3b26889eca968430a6a7080f1ab7de", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 12/12 | Churn Δ: 4 | Churn Cumulative: 4466 | Contributors (this commit): 28 | Commits (past 90d): 7 | Contributors (cumulative): 28 | DMM Complexity: None\n\nDIFF:\n@@ -1352,7 +1352,7 @@ class TestBackend(object):\n             check_single_tensor_operation('spatial_2d_padding', x_shape, BACKENDS,\n                                           padding=padding, data_format=data_format)\n             # Check handling of dynamic shapes.\n-            for k in BACKENDS:\n+            for k in [KTF, KTH]:\n                 x = k.placeholder(shape=(1, None, None, 1))\n                 y = k.spatial_2d_padding(x, padding=padding, data_format='channels_last')\n                 assert k.int_shape(y) == (1, None, None, 1)\n@@ -1375,7 +1375,7 @@ class TestBackend(object):\n             check_single_tensor_operation('spatial_3d_padding', x_shape, BACKENDS,\n                                           padding=padding, data_format=data_format)\n             # Check handling of dynamic shapes.\n-            for k in BACKENDS:\n+            for k in [KTF, KTH]:\n                 x = k.placeholder(shape=(1, None, None, None, 1))\n                 y = k.spatial_3d_padding(x, padding=padding, data_format='channels_last')\n                 assert k.int_shape(y) == (1, None, None, None, 1)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8c6f8d8c797c1b8576063cc973e6b9f729ec7612", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 7 | Files Changed: 3 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 38 | Churn Cumulative: 1747 | Contributors (this commit): 18 | Commits (past 90d): 3 | Contributors (cumulative): 25 | DMM Complexity: 1.0\n\nDIFF:\n@@ -266,7 +266,9 @@ class Orthogonal(Initializer):\n class Identity(Initializer):\n     \"\"\"Initializer that generates the identity matrix.\n \n-    Only use for square 2D matrices.\n+    Only use for 2D matrices.\n+    If the long side of the matrix is a multiple of the short side,\n+    multiple identity matrices are concatenated along the long side.\n \n     # Arguments\n         gain: Multiplicative factor to apply to the identity matrix.\n@@ -276,11 +278,21 @@ class Identity(Initializer):\n         self.gain = gain\n \n     def __call__(self, shape, dtype=None):\n-        if len(shape) != 2 or shape[0] != shape[1]:\n-            raise ValueError('Identity matrix initializer can only be used '\n-                             'for 2D square matrices.')\n-        else:\n+        if len(shape) != 2:\n+            raise ValueError(\n+                'Identity matrix initializer can only be used for 2D matrices.')\n+\n+        if max(shape) % min(shape) != 0:\n+            raise ValueError('Long side should be multiple of short side.')\n+\n+        if shape[0] == shape[1]:\n             return self.gain * np.identity(shape[0])\n+        elif shape[0] > shape[1]:\n+            return self.gain * np.concatenate(\n+                [np.identity(shape[1])] * (shape[0] // shape[1]), axis=0)\n+        else:\n+            return self.gain * np.concatenate(\n+                [np.identity(shape[0])] * (shape[1] // shape[0]), axis=1)\n \n     def get_config(self):\n         return {\n\n@@ -104,9 +104,10 @@ def test_orthogonal(tensor_shape):\n             target_mean=0.)\n \n \n-@pytest.mark.parametrize('tensor_shape', [(100, 100), (1, 2, 3, 4)], ids=['FC', 'CONV'])\n+@pytest.mark.parametrize('tensor_shape', [(100, 100), (10, 20), (30, 80), (1, 2, 3, 4)],\n+                         ids=['FC', 'RNN', 'RNN_INVALID', 'CONV'])\n def test_identity(tensor_shape):\n-    if len(tensor_shape) > 2:\n+    if len(tensor_shape) > 2 or max(tensor_shape) % min(tensor_shape) != 0:\n         with pytest.raises(ValueError):\n             _runner(initializers.identity(), tensor_shape,\n                     target_mean=1. / tensor_shape[0], target_max=1.)\n\n@@ -896,5 +896,16 @@ def test_rnn_cell_with_constants_layer_passing_initial_state():\n     assert_allclose(y_np, y_np_3, atol=1e-4)\n \n \n+@rnn_test\n+def test_rnn_cell_identity_initializer(layer_class):\n+    inputs = Input(shape=(timesteps, embedding_dim))\n+    layer = layer_class(units, recurrent_initializer='identity')\n+    layer(inputs)\n+    recurrent_kernel = layer.get_weights()[1]\n+    num_kernels = recurrent_kernel.shape[1] // recurrent_kernel.shape[0]\n+    assert np.array_equal(recurrent_kernel,\n+                          np.concatenate([np.identity(units)] * num_kernels, axis=1))\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6746bda3dcda273580fef2d911c6cc333c8a626c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 10 | Methods Changed: 4 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 13 | Churn Cumulative: 2660 | Contributors (this commit): 27 | Commits (past 90d): 12 | Contributors (cumulative): 29 | DMM Complexity: 1.0\n\nDIFF:\n@@ -111,7 +111,7 @@ def fit_generator(model,\n                 if isinstance(val_data, Sequence):\n                     val_enqueuer = OrderedEnqueuer(val_data,\n                                                    use_multiprocessing=use_multiprocessing)\n-                    validation_steps = len(val_data)\n+                    validation_steps = validation_steps or len(val_data)\n                 else:\n                     val_enqueuer = GeneratorEnqueuer(val_data,\n                                                      use_multiprocessing=use_multiprocessing)\n\n@@ -23,11 +23,13 @@ class RandomSequence(Sequence):\n     def __init__(self, batch_size, sequence_length=12):\n         self.batch_size = batch_size\n         self.sequence_length = sequence_length\n+        self.logs = []  # It will work for use_multiprocessing=False\n \n     def __len__(self):\n         return self.sequence_length\n \n     def __getitem__(self, idx):\n+        self.logs.append(idx)\n         return ([np.random.random((self.batch_size, 3)),\n                  np.random.random((self.batch_size, 3))],\n                 [np.random.random((self.batch_size, 4)),\n@@ -411,26 +413,31 @@ def test_model_methods():\n                   sample_weight_mode=None)\n     trained_epochs = []\n     trained_batches = []\n+    val_seq = RandomSequence(4)\n     out = model.fit_generator(generator=RandomSequence(3),\n                               steps_per_epoch=3,\n                               epochs=5,\n                               initial_epoch=0,\n-                              validation_data=RandomSequence(4),\n+                              validation_data=val_seq,\n                               validation_steps=3,\n+                              max_queue_size=1,\n                               callbacks=[tracker_cb])\n     assert trained_epochs == [0, 1, 2, 3, 4]\n     assert trained_batches == list(range(3)) * 5\n+    assert len(val_seq.logs) <= 4 * 5\n \n     # steps_per_epoch will be equal to len of sequence if it's unspecified\n     trained_epochs = []\n     trained_batches = []\n+    val_seq = RandomSequence(4)\n     out = model.fit_generator(generator=RandomSequence(3),\n                               epochs=5,\n                               initial_epoch=0,\n-                              validation_data=RandomSequence(4),\n+                              validation_data=val_seq,\n                               callbacks=[tracker_cb])\n     assert trained_epochs == [0, 1, 2, 3, 4]\n     assert trained_batches == list(range(12)) * 5\n+    assert len(val_seq.logs) == 12 * 5\n \n     # fit_generator will throw an exception\n     # if steps is unspecified for regular generator\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
