{"custom_id": "keras#272bb901dd207a57656286284cee1aa8c28061cb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 133 | Lines Deleted: 0 | Files Changed: 8 | Hunks: 10 | Methods Changed: 9 | Complexity Δ (Sum/Max): 18/11 | Churn Δ: 133 | Churn Cumulative: 1997 | Contributors (this commit): 16 | Commits (past 90d): 52 | Contributors (cumulative): 70 | DMM Complexity: 0.6385542168674698\n\nDIFF:\n@@ -47,6 +47,7 @@ from keras.src.ops.math import erfinv\n from keras.src.ops.math import extract_sequences\n from keras.src.ops.math import fft\n from keras.src.ops.math import fft2\n+from keras.src.ops.math import ifft2\n from keras.src.ops.math import in_top_k\n from keras.src.ops.math import irfft\n from keras.src.ops.math import istft\n\n@@ -47,6 +47,7 @@ from keras.src.ops.math import erfinv\n from keras.src.ops.math import extract_sequences\n from keras.src.ops.math import fft\n from keras.src.ops.math import fft2\n+from keras.src.ops.math import ifft2\n from keras.src.ops.math import in_top_k\n from keras.src.ops.math import irfft\n from keras.src.ops.math import istft\n\n@@ -123,6 +123,12 @@ def fft2(x):\n     return jnp.real(complex_output), jnp.imag(complex_output)\n \n \n+def ifft2(x):\n+    complex_input = _get_complex_tensor_from_tuple(x)\n+    complex_output = jnp.fft.ifft2(complex_input)\n+    return jnp.real(complex_output), jnp.imag(complex_output)\n+\n+\n def rfft(x, fft_length=None):\n     complex_output = jnp.fft.rfft(x, n=fft_length, axis=-1, norm=\"backward\")\n     return jnp.real(complex_output), jnp.imag(complex_output)\n\n@@ -144,6 +144,12 @@ def fft2(x):\n     return np.array(real), np.array(imag)\n \n \n+def ifft2(x):\n+    complex_input = _get_complex_tensor_from_tuple(x)\n+    complex_output = np.fft.ifft2(complex_input)\n+    return np.real(complex_output), np.imag(complex_output)\n+\n+\n def rfft(x, fft_length=None):\n     complex_output = np.fft.rfft(x, n=fft_length, axis=-1, norm=\"backward\")\n     # numpy always outputs complex128, so we need to recast the dtype\n\n@@ -113,6 +113,15 @@ def fft2(x):\n     return tf.math.real(complex_output), tf.math.imag(complex_output)\n \n \n+def ifft2(x):\n+    real, imag = x\n+    h = cast(tf.shape(real)[-2], \"float32\")\n+    w = cast(tf.shape(real)[-1], \"float32\")\n+    real_conj, imag_conj = real, -imag\n+    fft_real, fft_imag = fft2((real_conj, imag_conj))\n+    return fft_real / (h * w), -fft_imag / (h * w)\n+\n+\n def rfft(x, fft_length=None):\n     if fft_length is not None:\n         fft_length = [fft_length]\n\n@@ -203,6 +203,12 @@ def fft2(x):\n     return complex_output.real, complex_output.imag\n \n \n+def ifft2(x):\n+    complex_input = _get_complex_tensor_from_tuple(x)\n+    complex_output = torch.fft.ifft2(complex_input)\n+    return complex_output.real, complex_output.imag\n+\n+\n def rfft(x, fft_length=None):\n     x = convert_to_tensor(x)\n     complex_output = torch.fft.rfft(x, n=fft_length, dim=-1, norm=\"backward\")\n\n@@ -473,6 +473,81 @@ def fft2(x):\n     return backend.math.fft2(x)\n \n \n+class IFFT2(Operation):\n+    def __init__(self):\n+        super().__init__()\n+        self.axes = (-2, -1)\n+\n+    def compute_output_spec(self, x):\n+        if not isinstance(x, (tuple, list)) or len(x) != 2:\n+            raise ValueError(\n+                \"Input `x` should be a tuple of two tensors - real and \"\n+                f\"imaginary. Received: x={x}\"\n+            )\n+\n+        real, imag = x\n+        # Both real and imaginary parts should have the same shape.\n+        if real.shape != imag.shape:\n+            raise ValueError(\n+                \"Input `x` should be a tuple of two tensors - real and \"\n+                \"imaginary. Both the real and imaginary parts should have the \"\n+                f\"same shape. Received: x[0].shape = {real.shape}, \"\n+                f\"x[1].shape = {imag.shape}\"\n+            )\n+        # We are calculating 2D IFFT. Hence, rank >= 2.\n+        if len(real.shape) < 2:\n+            raise ValueError(\n+                f\"Input should have rank >= 2. \"\n+                f\"Received: input.shape = {real.shape}\"\n+            )\n+\n+        # The axes along which we are calculating IFFT should be fully-defined.\n+        m = real.shape[self.axes[0]]\n+        n = real.shape[self.axes[1]]\n+        if m is None or n is None:\n+            raise ValueError(\n+                f\"Input should have its {self.axes} axes fully-defined. \"\n+                f\"Received: input.shape = {real.shape}\"\n+            )\n+\n+        return (\n+            KerasTensor(shape=real.shape, dtype=real.dtype),\n+            KerasTensor(shape=imag.shape, dtype=imag.dtype),\n+        )\n+\n+    def call(self, x):\n+        return backend.math.ifft2(x)\n+\n+\n+@keras_export(\"keras.ops.ifft2\")\n+def ifft2(x):\n+    \"\"\"Computes the 2D Inverse Fast Fourier Transform along the last two axes of\n+        input.\n+\n+    Args:\n+        x: Tuple of the real and imaginary parts of the input tensor. Both\n+            tensors in the tuple should be of floating type.\n+\n+    Returns:\n+        A tuple containing two tensors - the real and imaginary parts of the\n+        output.\n+\n+    Example:\n+\n+    >>> x = (\n+    ...     keras.ops.convert_to_tensor([[1., 2.], [2., 1.]]),\n+    ...     keras.ops.convert_to_tensor([[0., 1.], [1., 0.]]),\n+    ... )\n+    >>> ifft2(x)\n+    (array([[ 6.,  0.],\n+        [ 0., -2.]], dtype=float32), array([[ 2.,  0.],\n+        [ 0., -2.]], dtype=float32))\n+    \"\"\"\n+    if any_symbolic_tensors(x):\n+        return IFFT2().symbolic_call(x)\n+    return backend.math.ifft2(x)\n+\n+\n class RFFT(Operation):\n     def __init__(self, fft_length=None):\n         super().__init__()\n\n@@ -218,6 +218,15 @@ class MathOpsDynamicShapeTest(testing.TestCase):\n         self.assertEqual(real_output.shape, ref_shape)\n         self.assertEqual(imag_output.shape, ref_shape)\n \n+    def test_ifft2(self):\n+        real = KerasTensor((None, 4, 3), dtype=\"float32\")\n+        imag = KerasTensor((None, 4, 3), dtype=\"float32\")\n+        real_output, imag_output = kmath.ifft2((real, imag))\n+        ref = np.fft.ifft2(np.ones((2, 4, 3)))\n+        ref_shape = (None,) + ref.shape[1:]\n+        self.assertEqual(real_output.shape, ref_shape)\n+        self.assertEqual(imag_output.shape, ref_shape)\n+\n     @parameterized.parameters([(None,), (1,), (5,)])\n     def test_rfft(self, fft_length):\n         x = KerasTensor((None, 4, 3), dtype=\"float32\")\n@@ -354,6 +363,14 @@ class MathOpsStaticShapeTest(testing.TestCase):\n         self.assertEqual(real_output.shape, ref.shape)\n         self.assertEqual(imag_output.shape, ref.shape)\n \n+    def test_ifft2(self):\n+        real = KerasTensor((2, 4, 3), dtype=\"float32\")\n+        imag = KerasTensor((2, 4, 3), dtype=\"float32\")\n+        real_output, imag_output = kmath.ifft2((real, imag))\n+        ref = np.fft.ifft2(np.ones((2, 4, 3)))\n+        self.assertEqual(real_output.shape, ref.shape)\n+        self.assertEqual(imag_output.shape, ref.shape)\n+\n     def test_rfft(self):\n         x = KerasTensor((2, 4, 3), dtype=\"float32\")\n         real_output, imag_output = kmath.rfft(x)\n@@ -715,6 +732,18 @@ class MathOpsCorrectnessTest(testing.TestCase):\n         self.assertAllClose(real_ref, real_output)\n         self.assertAllClose(imag_ref, imag_output)\n \n+    def test_ifft2(self):\n+        real = np.random.random((2, 4, 3)).astype(np.float32)\n+        imag = np.random.random((2, 4, 3)).astype(np.float32)\n+        complex_arr = real + 1j * imag\n+\n+        real_output, imag_output = kmath.ifft2((real, imag))\n+        ref = np.fft.ifft2(complex_arr)\n+        real_ref = np.real(ref)\n+        imag_ref = np.imag(ref)\n+        self.assertAllClose(real_ref, real_output)\n+        self.assertAllClose(imag_ref, imag_output)\n+\n     @parameterized.parameters([(None,), (3,), (15,)])\n     def test_rfft(self, n):\n         # Test 1D.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1a01cbddae6b5ac266537a3027010a0e38353bd5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 75 | Lines Deleted: 14 | Files Changed: 5 | Hunks: 16 | Methods Changed: 12 | Complexity Δ (Sum/Max): 17/6 | Churn Δ: 89 | Churn Cumulative: 164 | Contributors (this commit): 7 | Commits (past 90d): 9 | Contributors (cumulative): 14 | DMM Complexity: 0.0\n\nDIFF:\n@@ -7,6 +7,7 @@ from keras.src.backend.jax import math\n from keras.src.backend.jax import nn\n from keras.src.backend.jax import numpy\n from keras.src.backend.jax import random\n+from keras.src.backend.jax import tensorboard\n from keras.src.backend.jax.core import IS_THREAD_SAFE\n from keras.src.backend.jax.core import SUPPORTS_SPARSE_TENSORS\n from keras.src.backend.jax.core import Variable\n\n@@ -0,0 +1,23 @@\n+from keras.src.utils.module_utils import jax\n+\n+\n+def start_trace(logdir):\n+    if logdir:\n+        jax.profiler.start_trace(logdir)\n+\n+\n+def stop_trace(save):\n+    if save:\n+        jax.profiler.stop_trace()\n+\n+\n+def start_batch_trace(batch):\n+    batch_trace_context = jax.profiler.TraceAnnotation(\n+        f\"Profiled batch {batch}\"\n+    )\n+    batch_trace_context.__enter__()\n+    return batch_trace_context\n+\n+\n+def stop_batch_trace(batch_trace_context):\n+    batch_trace_context.__exit__(None, None, None)\n\n@@ -1,4 +1,4 @@\n-import tensorflow as tf\n+from keras.src.utils.module_utils import tensorflow as tf\n \n \n def start_trace(logdir):\n@@ -7,3 +7,15 @@ def start_trace(logdir):\n \n def stop_trace(save):\n     tf.profiler.experimental.stop(save=save)\n+\n+\n+def start_batch_trace(batch):\n+    batch_trace_context = tf.profiler.experimental.Trace(\n+        \"Profiled batch\", step_num=batch\n+    )\n+    batch_trace_context.__enter__()\n+    return batch_trace_context\n+\n+\n+def stop_batch_trace(batch_trace_context):\n+    batch_trace_context.__exit__(None, None, None)\n\n@@ -76,8 +76,7 @@ class TensorBoard(Callback):\n             [TensorBoard Scalars tutorial](\n                 https://www.tensorflow.org/tensorboard/scalars_and_keras#batch-level_logging)\n             for more details.\n-        profile_batch: (Not supported at this time)\n-            Profile the batch(es) to sample compute characteristics.\n+        profile_batch: Profile the batch(es) to sample compute characteristics.\n             profile_batch must be a non-negative integer or a tuple of integers.\n             A pair of positive integers signify a range of batches to profile.\n             By default, profiling is disabled.\n@@ -176,14 +175,23 @@ class TensorBoard(Callback):\n         self.update_freq = 1 if update_freq == \"batch\" else update_freq\n         self.embeddings_freq = embeddings_freq\n         self.embeddings_metadata = embeddings_metadata\n-        if profile_batch and backend.backend() != \"tensorflow\":\n-            # TODO: profiling not available in JAX/torch\n+        if profile_batch:\n+            if backend.backend() not in (\"jax\", \"tensorflow\"):\n+                # TODO: profiling not available in torch, numpy\n                 raise ValueError(\n                     \"Profiling is not yet available with the \"\n                     f\"{backend.backend()} backend. Please open a PR \"\n                     \"if you'd like to add this feature. Received: \"\n                     f\"profile_batch={profile_batch} (must be 0)\"\n                 )\n+            elif backend.backend() == \"jax\":\n+                if sys.version_info[1] < 12:\n+                    warnings.warn(\n+                        \"Profiling with the \"\n+                        f\"{backend.backend()} backend requires python >= 3.12.\"\n+                    )\n+                    profile_batch = 0\n+\n         self._init_profile_batch(profile_batch)\n         self._global_train_batch = 0\n         self._previous_epoch_iterations = 0\n@@ -384,6 +392,8 @@ class TensorBoard(Callback):\n         # We track the status here to make sure callbacks do not interfere with\n         # each other. The callback will only stop the profiler it started.\n         self._profiler_started = False\n+        self._batch_trace_context = None\n+\n         if self._start_batch > 0:\n             # Warm up and improve the profiling accuracy.\n             self._start_profiler(logdir=\"\")\n@@ -437,6 +447,10 @@ class TensorBoard(Callback):\n \n         if self._global_train_batch == self._start_batch:\n             self._start_trace()\n+        if self._profiler_started:\n+            self._batch_trace_context = backend.tensorboard.start_batch_trace(\n+                batch\n+            )\n \n     def on_train_batch_end(self, batch, logs=None):\n         if self._should_write_train_graph:\n@@ -460,7 +474,11 @@ class TensorBoard(Callback):\n         if not self._should_trace:\n             return\n \n-        if self._is_tracing and self._global_train_batch >= self._stop_batch:\n+        if self._is_tracing:\n+            if self._profiler_started and self._batch_trace_context is not None:\n+                backend.tensorboard.stop_batch_trace(self._batch_trace_context)\n+                self._batch_trace_context = None\n+            if self._global_train_batch >= self._stop_batch:\n                 self._stop_trace()\n \n     def on_epoch_begin(self, epoch, logs=None):\n@@ -483,7 +501,7 @@ class TensorBoard(Callback):\n \n     def _start_trace(self):\n         self.summary.trace_on(graph=True, profiler=False)\n-        self._start_profiler(logdir=self.log_dir)\n+        self._start_profiler(logdir=self._train_dir)\n         self._is_tracing = True\n \n     def _stop_trace(self, batch=None):\n\n@@ -1,6 +1,7 @@\n import collections\n import os\n import random\n+import sys\n \n import numpy as np\n import pytest\n@@ -736,14 +737,10 @@ class TestTensorBoardV2(testing.TestCase):\n         pass\n \n     @pytest.mark.skipif(\n-        backend.backend() != \"tensorflow\",\n-        reason=\"The profiling test can only run with TF backend.\",\n+        backend.backend() not in (\"jax\", \"tensorflow\"),\n+        reason=\"The profiling test can only run with TF and JAX backends.\",\n     )\n     def test_TensorBoard_auto_trace(self):\n-        # TODO: Waiting for implementation for torch/jax for profiling ops\n-        # if backend.backend() == \"jax\":\n-        #       return\n-        # TODO: Debug profiling for JAX\n         logdir, train_dir, validation_dir = self._get_log_dirs()\n         model = models.Sequential(\n             [\n@@ -753,6 +750,16 @@ class TestTensorBoardV2(testing.TestCase):\n             ]\n         )\n         x, y = np.ones((10, 10, 10, 1)), np.ones((10, 1))\n+        if backend.backend() == \"jax\" and sys.version_info[1] < 12:\n+            with pytest.warns(match=\"backend requires python >= 3.12\"):\n+                callbacks.TensorBoard(\n+                    logdir, histogram_freq=1, profile_batch=1, write_graph=False\n+                )\n+            self.skipTest(\n+                \"Profiling with JAX and python < 3.12 \"\n+                \"raises segmentation fault.\"\n+            )\n+\n         tb_cbk = callbacks.TensorBoard(\n             logdir, histogram_freq=1, profile_batch=1, write_graph=False\n         )\n@@ -773,5 +780,5 @@ class TestTensorBoardV2(testing.TestCase):\n                 _ObservedSummary(logdir=train_dir, tag=\"batch_1\"),\n             },\n         )\n-        self.assertEqual(1, self._count_xplane_file(logdir=logdir))\n+        self.assertEqual(1, self._count_xplane_file(logdir=train_dir))\n         pass\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b91cfe517f722a817da55422e102245b1aaab3c1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 200 | Lines Deleted: 8 | Files Changed: 4 | Hunks: 11 | Methods Changed: 16 | Complexity Δ (Sum/Max): 25/25 | Churn Δ: 208 | Churn Cumulative: 2172 | Contributors (this commit): 10 | Commits (past 90d): 21 | Contributors (cumulative): 21 | DMM Complexity: 0.5483870967741935\n\nDIFF:\n@@ -193,6 +193,7 @@ class PyDatasetAdapter(DataAdapter):\n         self.enqueuer = None\n         self.shuffle = shuffle\n         self._output_signature = None\n+        self._within_epoch = False\n \n         workers = self.py_dataset.workers\n         use_multiprocessing = self.py_dataset.use_multiprocessing\n@@ -314,6 +315,12 @@ class PyDatasetAdapter(DataAdapter):\n         return data_adapter_utils.get_torch_dataloader(self._get_iterator())\n \n     def on_epoch_begin(self):\n+        if self._within_epoch:\n+            raise ValueError(\n+                \"`on_epoch_begin` was called twice without `on_epoch_end` \"\n+                \"having been called.\"\n+            )\n+        self._within_epoch = True\n         if self.enqueuer:\n             self.enqueuer.start()\n         self.py_dataset.on_epoch_begin()\n@@ -322,6 +329,7 @@ class PyDatasetAdapter(DataAdapter):\n         if self.enqueuer:\n             self.enqueuer.stop()\n         self.py_dataset.on_epoch_end()\n+        self._within_epoch = False\n \n     @property\n     def num_batches(self):\n@@ -460,7 +468,7 @@ class PyDatasetEnqueuer:\n                 return\n             self.running = True\n             self.run_thread = threading.Thread(target=self._run)\n-            self.run_thread.name = f\"Worker_{self.uid}\"  # TODO remove\n+            self.run_thread.name = f\"Worker_{self.uid}\"\n             self.run_thread.daemon = True\n             self.run_thread.start()\n \n@@ -644,11 +652,7 @@ class OrderedEnqueuer(PyDatasetEnqueuer):\n                 if inputs is not None:\n                     yield inputs\n             except queue.Empty:\n-                warnings.warn(\n-                    \"Generator ran out of batches before reaching `num_batches`\"\n-                )\n-                self.stop()\n-                return\n+                pass\n             except Exception as e:\n                 self.stop(drain_queue_and_join=True)\n                 raise e\n\n@@ -143,12 +143,17 @@ class PyDatasetAdapterTest(testing.TestCase):\n     ):\n         if use_multiprocessing and shuffle:\n             pytest.skip(\"Starting processes is slow, test fewer variants\")\n-        if testing.tensorflow_uses_gpu():\n-            pytest.skip(\"This test is flaky with TF on GPU\")\n \n         set_random_seed(1337)\n         x = np.random.random((64, 4)).astype(\"float32\")\n         y = np.array([[i, i] for i in range(64)], dtype=\"float32\")\n+        CPU_DEVICES = {\n+            \"tensorflow\": \"CPU:0\",\n+            \"jax\": \"cpu:0\",\n+            \"torch\": \"cpu\",\n+            \"numpy\": \"cpu\",\n+        }\n+        with backend.device(CPU_DEVICES[backend.backend()]):\n             if dataset_type == \"tf\":\n                 x, y = tf.constant(x), tf.constant(y)\n             elif dataset_type == \"jax\":\n\n@@ -91,6 +91,7 @@ class EpochIterator:\n         self._num_batches = self.data_adapter.num_batches\n         self._steps_seen = 0\n         self._epoch_iterator = None\n+        self.data_adapter.on_epoch_end()\n \n     def _enumerate_iterator(self):\n         self.data_adapter.on_epoch_begin()\n\n@@ -18,6 +18,7 @@ from keras.src.backend.common.symbolic_scope import in_symbolic_scope\n from keras.src.callbacks.callback import Callback\n from keras.src.optimizers.rmsprop import RMSprop\n from keras.src.testing.test_utils import named_product\n+from keras.src.trainers.data_adapters import py_dataset_adapter\n \n if backend.backend() == \"jax\":\n     from keras.src.backend.jax.trainer import JAXTrainer as Trainer\n@@ -141,6 +142,82 @@ class TrainingTestingLayer(Trainer, layers.Layer):\n         return x * 0\n \n \n+class TestPyDataset(py_dataset_adapter.PyDataset):\n+    def __init__(self, infinite=False, **kwargs):\n+        super().__init__(**kwargs)\n+        self.infinite = infinite\n+\n+    @property\n+    def num_batches(self):\n+        return None if self.infinite else 20\n+\n+    def __getitem__(self, idx):\n+        CPU_DEVICES = {\n+            \"tensorflow\": \"CPU:0\",\n+            \"jax\": \"cpu:0\",\n+            \"torch\": \"cpu\",\n+        }\n+        with backend.device(CPU_DEVICES[backend.backend()]):\n+            return ops.ones((5, 4)), ops.zeros((5, 3))\n+\n+\n+def create_dataset(dataset_type, dataset_kwargs):\n+    if dataset_type == \"np_array\":\n+        return np.ones((100, 4)), np.zeros((100, 3))\n+    elif dataset_type == \"native_array\":\n+        return ops.ones((100, 4)), ops.zeros((100, 3))\n+    elif dataset_type == \"py_dataset\":\n+        return TestPyDataset(**dataset_kwargs), None\n+    elif dataset_type == \"tf_dataset\":\n+        import tensorflow as tf\n+\n+        dataset = tf.data.Dataset.from_tensor_slices(\n+            (tf.ones((100, 4)), tf.zeros((100, 3)))\n+        ).batch(5)\n+        if dataset_kwargs.get(\"infinite\", False):\n+            dataset = dataset.repeat()\n+        return dataset, None\n+    elif dataset_type == \"torch_dataloader\":\n+        import torch\n+\n+        class TestIterableDataset(torch.utils.data.IterableDataset):\n+            def __iter__(self):\n+                for _ in range(20):\n+                    yield torch.ones((5, 4)), torch.zeros((5, 3))\n+\n+        class TestIterableDatasetWithLen(TestIterableDataset):\n+            def __len__(self):\n+                return 20\n+\n+        if dataset_kwargs.get(\"iterable\", False):\n+            if dataset_kwargs.get(\"has_len\", False):\n+                dataset = TestIterableDatasetWithLen()\n+            else:\n+                dataset = TestIterableDataset()\n+            return torch.utils.data.DataLoader(dataset), None\n+        else:\n+            dataset = torch.utils.data.TensorDataset(\n+                torch.ones((100, 4)), torch.zeros((100, 3))\n+            )\n+            return torch.utils.data.DataLoader(dataset, batch_size=5), None\n+    elif dataset_type == \"generator\":\n+\n+        def generate_finite():\n+            for _ in range(20):\n+                yield ops.ones((5, 4)), ops.zeros((5, 3))\n+\n+        def generate_infinite():\n+            while True:\n+                yield ops.ones((5, 4)), ops.zeros((5, 3))\n+\n+        if dataset_kwargs.get(\"infinite\", False):\n+            return generate_infinite(), None\n+        else:\n+            return generate_finite(), None\n+    else:\n+        raise ValueError(f\"Invalid dataset type {dataset_type}\")\n+\n+\n def sparse_generator(generator_type):\n     if generator_type == \"scipy\":\n         import scipy\n@@ -397,6 +474,111 @@ class TestTrainer(testing.TestCase):\n             atol=1.0,  # TODO: results vary across backends\n         )\n \n+    @parameterized.named_parameters(\n+        [\n+            {\n+                \"testcase_name\": \"np_array\",\n+                \"dataset_type\": \"np_array\",\n+                \"fit_kwargs\": {\"batch_size\": 5},\n+            },\n+            {\n+                \"testcase_name\": \"native_array\",\n+                \"dataset_type\": \"native_array\",\n+                \"fit_kwargs\": {\"batch_size\": 5},\n+            },\n+            {\n+                \"testcase_name\": \"py_dataset\",\n+                \"dataset_type\": \"py_dataset\",\n+            },\n+            {\n+                \"testcase_name\": \"py_dataset_infinite\",\n+                \"dataset_type\": \"py_dataset\",\n+                \"dataset_kwargs\": {\"infinite\": True},\n+                \"fit_kwargs\": {\"steps_per_epoch\": 20},\n+            },\n+            {\n+                \"testcase_name\": \"py_dataset_multithreading\",\n+                \"dataset_type\": \"py_dataset\",\n+                \"dataset_kwargs\": {\"workers\": 2},\n+            },\n+            {\n+                \"testcase_name\": \"py_dataset_multithreading_infinite\",\n+                \"dataset_type\": \"py_dataset\",\n+                \"dataset_kwargs\": {\"infinite\": True, \"workers\": 2},\n+                \"fit_kwargs\": {\"steps_per_epoch\": 20},\n+            },\n+            {\n+                \"testcase_name\": \"py_dataset_multiprocessing\",\n+                \"dataset_type\": \"py_dataset\",\n+                \"dataset_kwargs\": {\"workers\": 2, \"use_multiprocessing\": True},\n+            },\n+            {\n+                \"testcase_name\": \"py_dataset_multiprocessing_infinite\",\n+                \"dataset_type\": \"py_dataset\",\n+                \"dataset_kwargs\": {\n+                    \"infinite\": True,\n+                    \"workers\": 2,\n+                    \"use_multiprocessing\": True,\n+                },\n+                \"fit_kwargs\": {\"steps_per_epoch\": 20},\n+            },\n+            {\n+                \"testcase_name\": \"tf_dataset\",\n+                \"dataset_type\": \"tf_dataset\",\n+            },\n+            {\n+                \"testcase_name\": \"tf_dataset_infinite\",\n+                \"dataset_type\": \"tf_dataset\",\n+                \"dataset_kwargs\": {\"infinite\": True},\n+                \"fit_kwargs\": {\"steps_per_epoch\": 20},\n+            },\n+            {\n+                \"testcase_name\": \"torch_dataloader_tensor\",\n+                \"dataset_type\": \"torch_dataloader\",\n+            },\n+            {\n+                \"testcase_name\": \"torch_dataloader_iterable\",\n+                \"dataset_type\": \"torch_dataloader\",\n+                \"dataset_kwargs\": {\"iterable\": True, \"has_len\": False},\n+            },\n+            {\n+                \"testcase_name\": \"torch_dataloader_iterable_with_len\",\n+                \"dataset_type\": \"torch_dataloader\",\n+                \"dataset_kwargs\": {\"iterable\": True, \"has_len\": True},\n+            },\n+            {\n+                \"testcase_name\": \"generator\",\n+                \"dataset_type\": \"generator\",\n+            },\n+            {\n+                \"testcase_name\": \"generator_infinite\",\n+                \"dataset_type\": \"generator\",\n+                \"dataset_kwargs\": {\"infinite\": True},\n+                \"fit_kwargs\": {\"steps_per_epoch\": 20},\n+            },\n+        ]\n+    )\n+    @pytest.mark.requires_trainable_backend\n+    def test_fit_with_data_adapter(\n+        self, dataset_type, dataset_kwargs={}, fit_kwargs={}\n+    ):\n+        if (\n+            dataset_kwargs.get(\"use_multiprocessing\", False)\n+            and backend.backend() == \"jax\"\n+        ):\n+            pytest.skip(\"Multiprocessing not supported with JAX backend\")\n+\n+        model = ExampleModel(units=3)\n+        optimizer = optimizers.Adagrad()\n+        model.compile(\n+            optimizer=optimizer,\n+            loss=losses.MeanSquaredError(),\n+            metrics=[metrics.MeanSquaredError()],\n+            jit_compile=True,\n+        )\n+        x, y = create_dataset(dataset_type, dataset_kwargs)\n+        model.fit(x, y, epochs=3, **fit_kwargs)\n+\n     @parameterized.named_parameters(\n         [\n             (\"eager\", True, False, False),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fe8407620aa9b1aa1ea21c36fe3c44db1b66883e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 128 | Lines Deleted: 105 | Files Changed: 1 | Hunks: 25 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 233 | Churn Cumulative: 558 | Contributors (this commit): 8 | Commits (past 90d): 13 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -533,29 +533,34 @@ class Trainer:\n         \"\"\"Trains the model for a fixed number of epochs (dataset iterations).\n \n         Args:\n-            x: Input data. It could be:\n+            x: Input data. It can be:\n                 - A NumPy array (or array-like), or a list of arrays\n                 (in case the model has multiple inputs).\n-                - A tensor, or a list of tensors\n+                - A backend-native tensor, or a list of tensors\n                 (in case the model has multiple inputs).\n                 - A dict mapping input names to the corresponding array/tensors,\n                 if the model has named inputs.\n-                - A `tf.data.Dataset`. Should return a tuple\n-                of either `(inputs, targets)` or\n+                - A `keras.utils.PyDataset` returning `(inputs, targets)` or\n                 `(inputs, targets, sample_weights)`.\n-                - A `keras.utils.PyDataset` returning `(inputs,\n-                targets)` or `(inputs, targets, sample_weights)`.\n-            y: Target data. Like the input data `x`,\n-                it could be either NumPy array(s) or backend-native tensor(s).\n-                If `x` is a dataset, generator,\n-                or `keras.utils.PyDataset` instance, `y` should\n-                not be specified (since targets will be obtained from `x`).\n+                - A `tf.data.Dataset` yielding `(inputs, targets)` or\n+                `(inputs, targets, sample_weights)`.\n+                - A `torch.utils.data.DataLoader` yielding `(inputs, targets)`\n+                or `(inputs, targets, sample_weights)`.\n+                - A Python generator function yielding `(inputs, targets)` or\n+                `(inputs, targets, sample_weights)`.\n+            y: Target data. Like the input data `x`, it can be either NumPy\n+                array(s) or backend-native tensor(s). If `x` is a\n+                `keras.utils.PyDataset`, `tf.data.Dataset`,\n+                `torch.utils.data.DataLoader` or a Python generator function,\n+                `y` should not be specified since targets will be obtained from\n+                `x`.\n             batch_size: Integer or `None`.\n                 Number of samples per gradient update.\n                 If unspecified, `batch_size` will default to 32.\n-                Do not specify the `batch_size` if your data is in the\n-                form of datasets, generators, or `keras.utils.PyDataset`\n-                instances (since they generate batches).\n+                Do not specify the `batch_size` if your input data `x` is a\n+                `keras.utils.PyDataset`, `tf.data.Dataset`,\n+                `torch.utils.data.DataLoader` or Python generator function\n+                since they generate batches.\n             epochs: Integer. Number of epochs to train the model.\n                 An epoch is an iteration over the entire `x` and `y`\n                 data provided\n@@ -584,13 +589,12 @@ class Trainer:\n             validation_split: Float between 0 and 1.\n                 Fraction of the training data to be used as validation data.\n                 The model will set apart this fraction of the training data,\n-                will not train on it, and will evaluate\n-                the loss and any model metrics\n-                on this data at the end of each epoch.\n-                The validation data is selected from the last samples\n-                in the `x` and `y` data provided, before shuffling. This\n-                argument is not supported when `x` is a dataset, generator or\n-                `keras.utils.PyDataset` instance.\n+                will not train on it, and will evaluate the loss and any model\n+                metrics on this data at the end of each epoch. The validation\n+                data is selected from the last samples in the `x` and `y` data\n+                provided, before shuffling.\n+                This argument is only supported when `x` and `y` are made of\n+                NumPy arrays or tensors.\n                 If both `validation_data` and `validation_split` are provided,\n                 `validation_data` will override `validation_split`.\n             validation_data: Data on which to evaluate\n@@ -600,16 +604,18 @@ class Trainer:\n                 `validation_split` or `validation_data` is not affected by\n                 regularization layers like noise and dropout.\n                 `validation_data` will override `validation_split`.\n-                It could be:\n+                It can be:\n                 - A tuple `(x_val, y_val)` of NumPy arrays or tensors.\n                 - A tuple `(x_val, y_val, val_sample_weights)` of NumPy\n                 arrays.\n-                - A `tf.data.Dataset`.\n-                - A Python generator or `keras.utils.PyDataset` returning\n-                `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n-            shuffle: Boolean, whether to shuffle the training data\n-                before each epoch. This argument is\n-                ignored when `x` is a generator or a `tf.data.Dataset`.\n+                - A `keras.utils.PyDataset`, a `tf.data.Dataset`, a\n+                `torch.utils.data.DataLoader` yielding `(inputs, targets)` or a\n+                Python generator function yielding `(x_val, y_val)` or\n+                `(inputs, targets, sample_weights)`.\n+            shuffle: Boolean, whether to shuffle the training data before each\n+                epoch. This argument is ignored when `x` is a\n+                `keras.utils.PyDataset`, `tf.data.Dataset`,\n+                `torch.utils.data.DataLoader` or Python generator function.\n             class_weight: Optional dictionary mapping class indices (integers)\n                 to a weight (float) value, used for weighting the loss function\n                 (during training only).\n@@ -619,18 +625,18 @@ class Trainer:\n                 and targets have a rank of 2 or greater, either `y` must be\n                 one-hot encoded, or an explicit final dimension of `1` must\n                 be included for sparse class labels.\n-            sample_weight: Optional NumPy array of weights for\n+            sample_weight: Optional NumPy array or tensor of weights for\n                 the training samples, used for weighting the loss function\n                 (during training only). You can either pass a flat (1D)\n-                NumPy array with the same length as the input samples\n-                (1:1 mapping between weights and samples),\n-                or in the case of temporal data,\n-                you can pass a 2D array with shape\n-                `(samples, sequence_length)`,\n-                to apply a different weight to every timestep of every sample.\n-                This argument is not supported when `x` is a dataset, generator,\n-                or `keras.utils.PyDataset` instance, instead provide the\n-                sample_weights as the third element of `x`.\n+                NumPy array or tensor with the same length as the input samples\n+                (1:1 mapping between weights and samples), or in the case of\n+                temporal data, you can pass a 2D NumPy array or tensor with\n+                shape `(samples, sequence_length)` to apply a different weight\n+                to every timestep of every sample.\n+                This argument is not supported when `x` is a\n+                `keras.utils.PyDataset`, `tf.data.Dataset`,\n+                `torch.utils.data.DataLoader` or Python generator function.\n+                Instead, provide `sample_weights` as the third element of `x`.\n                 Note that sample weighting does not apply to metrics specified\n                 via the `metrics` argument in `compile()`. To apply sample\n                 weighting to your metrics, you can specify them via the\n@@ -639,35 +645,35 @@ class Trainer:\n                 Epoch at which to start training\n                 (useful for resuming a previous training run).\n             steps_per_epoch: Integer or `None`.\n-                Total number of steps (batches of samples)\n-                before declaring one epoch finished and starting the\n-                next epoch. When training with input tensors such as\n-                backend-native tensors, the default `None` is equal to\n-                the number of samples in your dataset divided by\n-                the batch size, or 1 if that cannot be determined. If `x` is a\n-                `tf.data.Dataset`, and `steps_per_epoch`\n-                is `None`, the epoch will run until the input dataset is\n-                exhausted.  When passing an infinitely repeating dataset, you\n-                must specify the `steps_per_epoch` argument. If\n-                `steps_per_epoch=-1` the training will run indefinitely with an\n-                infinitely repeating dataset.\n-            validation_steps: Only relevant if `validation_data` is provided.\n-                Total number of steps (batches of\n-                samples) to draw before stopping when performing validation\n-                at the end of every epoch. If `validation_steps` is `None`,\n-                validation will run until the `validation_data` dataset is\n-                exhausted. In the case of an infinitely repeated dataset, it\n-                will run into an infinite loop. If `validation_steps` is\n-                specified and only part of the dataset will be consumed, the\n-                evaluation will start from the beginning of the dataset at each\n-                epoch. This ensures that the same validation samples are used\n-                every time.\n+                Total number of steps (batches of samples) before declaring one\n+                epoch finished and starting the next epoch. When training with\n+                input tensors or NumPy arrays, the default `None` means that the\n+                value used is the number of samples in your dataset divided by\n+                the batch size, or 1 if that cannot be determined.\n+                If `x` is a `keras.utils.PyDataset`, `tf.data.Dataset`,\n+                `torch.utils.data.DataLoader` or Python generator function, the\n+                epoch will run until the input dataset is exhausted. When\n+                passing an infinitely repeating dataset, you must specify the\n+                `steps_per_epoch` argument, otherwise the training will run\n+                indefinitely.\n+            validation_steps: Integer or `None`.\n+                Only relevant if `validation_data` is provided.\n+                Total number of steps (batches of samples) to draw before\n+                stopping when performing validation at the end of every epoch.\n+                If `validation_steps` is `None`, validation will run until the\n+                `validation_data` dataset is exhausted. In the case of an\n+                infinitely repeating dataset, it will run indefinitely. If\n+                `validation_steps` is specified and only part of the dataset\n+                is consumed, the evaluation will start from the beginning of the\n+                dataset at each epoch. This ensures that the same validation\n+                samples are used every time.\n             validation_batch_size: Integer or `None`.\n                 Number of samples per validation batch.\n                 If unspecified, will default to `batch_size`.\n-                Do not specify the `validation_batch_size` if your data is in\n-                the form of datasets or `keras.utils.PyDataset`\n-                instances (since they generate batches).\n+                Do not specify the `validation_batch_size` if your data is a\n+                `keras.utils.PyDataset`, `tf.data.Dataset`,\n+                `torch.utils.data.DataLoader` or Python generator function\n+                since they generate batches.\n             validation_freq: Only relevant if validation data is provided.\n                 Specifies how many training epochs to run\n                 before a new validation run is performed,\n@@ -724,28 +730,34 @@ class Trainer:\n         Computation is done in batches (see the `batch_size` arg.)\n \n         Args:\n-            x: Input data. It could be:\n+            x: Input data. It can be:\n                 - A NumPy array (or array-like), or a list of arrays\n                 (in case the model has multiple inputs).\n-                - A tensor, or a list of tensors\n+                - A backend-native tensor, or a list of tensors\n                 (in case the model has multiple inputs).\n                 - A dict mapping input names to the corresponding array/tensors,\n                 if the model has named inputs.\n-                - A `tf.data.Dataset`. Should return a tuple\n-                    of either `(inputs, targets)` or\n+                - A `keras.utils.PyDataset` returning `(inputs, targets)` or\n                 `(inputs, targets, sample_weights)`.\n-                - A generator or `keras.utils.PyDataset` returning\n-                    `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n-            y: Target data. Like the input data `x`, it could be either NumPy\n-                array(s) or backend-native tensor(s).\n-                If `x` is a `tf.data.Dataset` or `keras.utils.PyDataset`\n-                instance, `y` should not be specified\n-                (since targets will be obtained from the iterator/dataset).\n-            batch_size: Integer or `None`. Number of samples per batch of\n-                computation. If unspecified, `batch_size` will default to 32. Do\n-                not specify the `batch_size` if your data is in the form of a\n-                dataset, generators, or `keras.utils.PyDataset` instances\n-                (since they generate batches).\n+                - A `tf.data.Dataset` yielding `(inputs, targets)` or\n+                `(inputs, targets, sample_weights)`.\n+                - A `torch.utils.data.DataLoader` yielding `(inputs, targets)`\n+                or `(inputs, targets, sample_weights)`.\n+                - A Python generator function yielding `(inputs, targets)` or\n+                `(inputs, targets, sample_weights)`.\n+            y: Target data. Like the input data `x`, it can be either NumPy\n+                array(s) or backend-native tensor(s). If `x` is a\n+                `keras.utils.PyDataset`, `tf.data.Dataset`,\n+                `torch.utils.data.DataLoader` or a Python generator function,\n+                `y` should not be specified since targets will be obtained from\n+                `x`.\n+            batch_size: Integer or `None`.\n+                Number of samples per batch of computation.\n+                If unspecified, `batch_size` will default to 32.\n+                Do not specify the `batch_size` if your input data `x` is a\n+                `keras.utils.PyDataset`, `tf.data.Dataset`,\n+                `torch.utils.data.DataLoader` or Python generator function\n+                since they generate batches.\n             verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n                 0 = silent, 1 = progress bar, 2 = single line.\n                 `\"auto\"` becomes 1 for most cases.\n@@ -753,20 +765,27 @@ class Trainer:\n                 particularly useful when logged to a file, so `verbose=2` is\n                 recommended when not running interactively\n                 (e.g. in a production environment). Defaults to `\"auto\"`.\n-            sample_weight: Optional NumPy array of weights for the test samples,\n-                used for weighting the loss function. You can either pass a flat\n-                (1D) NumPy array with the same length as the input samples\n+            sample_weight: Optional NumPy array or tensor of weights for\n+                the training samples, used for weighting the loss function\n+                (during training only). You can either pass a flat (1D)\n+                NumPy array or tensor with the same length as the input samples\n                 (1:1 mapping between weights and samples), or in the case of\n-                temporal data, you can pass a 2D array with shape `(samples,\n-                sequence_length)`, to apply a different weight to every\n-                timestep of every sample. This argument is not supported when\n-                `x` is a dataset, instead pass sample weights as the third\n-                element of `x`.\n-            steps: Integer or `None`. Total number of steps (batches of samples)\n-                before declaring the evaluation round finished. Ignored with the\n-                default value of `None`. If `x` is a `tf.data.Dataset` and\n-                `steps` is `None`, evaluation will run until the dataset\n-                is exhausted.\n+                temporal data, you can pass a 2D NumPy array or tensor with\n+                shape `(samples, sequence_length)` to apply a different weight\n+                to every timestep of every sample.\n+                This argument is not supported when `x` is a\n+                `keras.utils.PyDataset`, `tf.data.Dataset`,\n+                `torch.utils.data.DataLoader` or Python generator function.\n+                Instead, provide `sample_weights` as the third element of `x`.\n+                Note that sample weighting does not apply to metrics specified\n+                via the `metrics` argument in `compile()`. To apply sample\n+                weighting to your metrics, you can specify them via the\n+                `weighted_metrics` in `compile()` instead.\n+            steps: Integer or `None`.\n+                Total number of steps (batches of samples) to draw before\n+                declaring the evaluation round finished. If `steps` is `None`,\n+                it will run until `x` is exhausted. In the case of an infinitely\n+                repeating dataset, it will run indefinitely.\n             callbacks: List of `keras.callbacks.Callback` instances.\n                 List of callbacks to apply during evaluation.\n             return_dict: If `True`, loss and metric results are returned as a\n@@ -803,30 +822,34 @@ class Trainer:\n         `predict()` and `__call__()`.\n \n         Args:\n-            x: Input samples. It could be:\n+            x: Input data. It can be:\n                 - A NumPy array (or array-like), or a list of arrays\n                 (in case the model has multiple inputs).\n-                - A tensor, or a list of tensors\n+                - A backend-native tensor, or a list of tensors\n                 (in case the model has multiple inputs).\n+                - A dict mapping input names to the corresponding array/tensors,\n+                if the model has named inputs.\n+                - A `keras.utils.PyDataset`.\n                 - A `tf.data.Dataset`.\n-                - A `keras.utils.PyDataset` instance.\n+                - A `torch.utils.data.DataLoader`.\n+                - A Python generator function.\n             batch_size: Integer or `None`.\n-                Number of samples per batch.\n+                Number of samples per batch of computation.\n                 If unspecified, `batch_size` will default to 32.\n-                Do not specify the `batch_size` if your data is in the\n-                form of dataset, generators, or `keras.utils.PyDataset`\n-                instances (since they generate batches).\n+                Do not specify the `batch_size` if your input data `x` is a\n+                `keras.utils.PyDataset`, `tf.data.Dataset`,\n+                `torch.utils.data.DataLoader` or Python generator function\n+                since they generate batches.\n             verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n                 0 = silent, 1 = progress bar, 2 = single line.\n                 `\"auto\"` becomes 1 for most cases. Note that the progress bar\n                 is not particularly useful when logged to a file,\n                 so `verbose=2` is recommended when not running interactively\n                 (e.g. in a production environment). Defaults to `\"auto\"`.\n-            steps: Total number of steps (batches of samples)\n-                before declaring the prediction round finished.\n-                Ignored with the default value of `None`.\n-                If `x` is a `tf.data.Dataset` and `steps` is `None`,\n-                `predict()` will run until the input dataset is exhausted.\n+            steps: Total number of steps (batches of samples) to draw before\n+                declaring the prediction round finished. If `steps` is `None`,\n+                it will run until `x` is exhausted. In the case of an infinitely\n+                repeating dataset, it will run indefinitely.\n             callbacks: List of `keras.callbacks.Callback` instances.\n                 List of callbacks to apply during prediction.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4e71b2ee3da8888a701b86255d7229bef6aa3167", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 489 | Contributors (this commit): 9 | Commits (past 90d): 16 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -214,8 +214,12 @@ class Functional(Function, Model):\n \n     def _maybe_warn_inputs_struct_mismatch(self, inputs):\n         try:\n+            # We first normalize to tuples before performing the check to\n+            # suppress warnings when encountering mismatched tuples and lists.\n             tree.assert_same_structure(\n-                inputs, self._inputs_struct, check_types=False\n+                tree.lists_to_tuples(inputs),\n+                tree.lists_to_tuples(self._inputs_struct),\n+                check_types=False,\n             )\n         except:\n             model_inputs_struct = tree.map_structure(\n\n@@ -1,4 +1,5 @@\n import os\n+import warnings\n \n import numpy as np\n import pytest\n@@ -503,13 +504,19 @@ class FunctionalTest(testing.TestCase):\n         model = Model({\"i1\": i1, \"i2\": i2}, outputs)\n \n         with pytest.warns() as record:\n-            model([np.ones((2, 2)), np.zeros((2, 2))])\n+            model.predict([np.ones((2, 2)), np.zeros((2, 2))], verbose=0)\n         self.assertLen(record, 1)\n         self.assertStartsWith(\n             str(record[0].message),\n             r\"The structure of `inputs` doesn't match the expected structure:\",\n         )\n \n+        # No warning for mismatched tuples and lists.\n+        model = Model([i1, i2], outputs)\n+        with warnings.catch_warnings(record=True) as warning_logs:\n+            model.predict((np.ones((2, 2)), np.zeros((2, 2))), verbose=0)\n+            self.assertLen(warning_logs, 0)\n+\n     def test_for_functional_in_sequential(self):\n         # Test for a v3.4.1 regression.\n         if backend.image_data_format() == \"channels_first\":\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
