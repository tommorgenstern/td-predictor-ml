{"custom_id": "keras#136766fc9e3b7804699b3dc68c8460bcd428eb34", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 231 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): 12/12 | Churn Δ: 231 | Churn Cumulative: 1223 | Contributors (this commit): 12 | Commits (past 90d): 40 | Contributors (cumulative): 18 | DMM Complexity: 1.0\n\nDIFF:\n@@ -35,6 +35,7 @@ from keras.optimizers.legacy import sgd as sgd_legacy\n from keras.optimizers.optimizer_experimental import (\n     adadelta as adadelta_experimental,\n )\n+from keras.optimizers.optimizer_experimental import adafactor\n from keras.optimizers.optimizer_experimental import (\n     adagrad as adagrad_experimental,\n )\n\n@@ -0,0 +1,225 @@\n+# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Adagrad optimizer implementation.\"\"\"\n+\n+import tensorflow.compat.v2 as tf\n+\n+from keras.optimizers.optimizer_experimental import optimizer\n+from keras.optimizers.schedules import learning_rate_schedule\n+from keras.saving.object_registration import register_keras_serializable\n+\n+# isort: off\n+from tensorflow.python.util.tf_export import keras_export\n+\n+\n+@register_keras_serializable()\n+@keras_export(\"keras.optimizers.experimental.Adafactor\", v1=[])\n+class Adafactor(optimizer.Optimizer):\n+    \"\"\"Optimizer that implements the Adafactor algorithm.\n+\n+    Adafactor is commonly used in NLP tasks, and has the advantage\n+    of taking less memory because it only saves partial information of previous\n+    gradients.\n+\n+    The default argument setup is based on the original paper (see reference).\n+    When gradients are of dimension > 2, Adafactor optimizer will delete the\n+    last 2 dimensions separately in its accumulator variables.\n+\n+    Args:\n+      learning_rate: Initial value for the learning rate:\n+        either a floating point value,\n+        or a `tf.keras.optimizers.schedules.LearningRateSchedule` instance.\n+        Defaults to 0.001.\n+      beta_2_decay: float, defaults to -0.8. The decay rate of `beta_2`.\n+      epsilon_1: float, defaults to 1e-30. A small offset to keep demoninator\n+        away from 0.\n+      epsilon_2: float, defaults to 1e-3. A small offset to avoid learning\n+        rate becoming too small by time.\n+      clip_threshold: float, defaults to 1.0. Clipping threshold. This is a part\n+        of Adafactor algorithm, independent from `clipnorm`, `clipvalue` and\n+        `global_clipnorm`.\n+      relative_step: bool, defaults to True. If `learning_rate` is a\n+        constant and `relative_step=True`, learning rate will be adjusted\n+        based on current iterations. This is a default learning rate decay\n+        in Adafactor.\n+      {{base_optimizer_keyword_args}}\n+\n+    Reference:\n+      - [Shazeer, Noam et al., 2018](https://arxiv.org/abs/1804.04235).\n+\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        learning_rate=0.001,\n+        beta_2_decay=-0.8,\n+        epsilon_1=1e-30,\n+        epsilon_2=1e-3,\n+        clip_threshold=1.0,\n+        relative_step=True,\n+        clipnorm=None,\n+        clipvalue=None,\n+        global_clipnorm=None,\n+        use_ema=False,\n+        ema_momentum=0.99,\n+        ema_overwrite_frequency=None,\n+        jit_compile=True,\n+        name=\"Adafactor\",\n+        **kwargs,\n+    ):\n+        super().__init__(\n+            name=name,\n+            clipnorm=clipnorm,\n+            clipvalue=clipvalue,\n+            global_clipnorm=global_clipnorm,\n+            use_ema=use_ema,\n+            ema_momentum=ema_momentum,\n+            ema_overwrite_frequency=ema_overwrite_frequency,\n+            jit_compile=jit_compile,\n+            **kwargs,\n+        )\n+        self._learning_rate = self._build_learning_rate(learning_rate)\n+        self.beta_2_decay = beta_2_decay\n+        self.epsilon_1 = epsilon_1\n+        self.epsilon_2 = epsilon_2\n+        self.clip_threshold = clip_threshold\n+        self.relative_step = relative_step\n+\n+    def build(self, var_list):\n+        \"\"\"Initialize optimizer variables.\n+\n+        Adam optimizer has 3 types of variables: momentums, velocities and\n+        velocity_hat (only set when amsgrad is applied),\n+\n+        Args:\n+          var_list: list of model variables to build Adam variables on.\n+        \"\"\"\n+        super().build(var_list)\n+        if hasattr(self, \"_built\") and self._built:\n+            return\n+        self._built = True\n+        self._r = []\n+        self._c = []\n+        self._v = []\n+        for var in var_list:\n+            if len(var.shape) < 2:\n+                # Don't factor if variable is of dimension < 2, but we still\n+                # need to create dummy variables as placeholder.\n+                self._r.append(tf.Variable(0, name=f\"r/{var._shared_name}\"))\n+                self._c.append(tf.Variable(0, name=f\"r/{var._shared_name}\"))\n+            else:\n+                # Always factor the last 2 dimenstions.\n+                r_shape = var.shape[:-1]\n+                c_shape = var.shape[:-2] + var.shape[-1]\n+                self._r.append(\n+                    self.add_variable(\n+                        shape=r_shape,\n+                        dtype=var.dtype,\n+                        name=f\"r/{var._shared_name}\",\n+                    )\n+                )\n+                self._c.append(\n+                    self.add_variable(\n+                        shape=c_shape,\n+                        dtype=var.dtype,\n+                        name=f\"c/{var._shared_name}\",\n+                    )\n+                )\n+            self._v.append(\n+                self.add_variable_from_reference(\n+                    model_variable=var, variable_name=\"v\"\n+                )\n+            )\n+\n+    def _rms(self, x):\n+        return tf.sqrt(tf.reduce_mean(tf.square(x)))\n+\n+    def update_step(self, gradient, variable):\n+        \"\"\"Update step given gradient and the associated model variable.\"\"\"\n+\n+        lr = tf.cast(self.learning_rate, variable.dtype)\n+        epsilon_2 = tf.cast(self.epsilon_2, variable.dtype)\n+        one = tf.cast(1.0, variable.dtype)\n+        local_step = tf.cast(self.iterations + 1, variable.dtype)\n+        if (\n+            not isinstance(\n+                self._learning_rate, learning_rate_schedule.LearningRateSchedule\n+            )\n+            and self.relative_step\n+        ):\n+            # If `relative_step=True` and learning rate is a constant, we\n+            # apply the relative step algorithm.\n+            lr = tf.minimum(lr, tf.math.rsqrt(local_step))\n+\n+        var_key = self._var_key(variable)\n+        r = self._r[self._index_dict[var_key]]\n+        c = self._c[self._index_dict[var_key]]\n+        v = self._v[self._index_dict[var_key]]\n+\n+        rho_t = tf.minimum(lr, tf.math.rsqrt(local_step))\n+        alpha_t = tf.maximum(epsilon_2, self._rms(variable)) * rho_t\n+        regulated_grad_square = tf.square(gradient) + self.epsilon_1\n+        beta_2_t = 1 - tf.pow(local_step, self.beta_2_decay)\n+\n+        if len(variable.shape) >= 2:\n+            # `r` deletes the last dimension of gradient, so it is of shape\n+            # `gradient.shape[:-1]`.\n+            r.assign(\n+                beta_2_t * r\n+                + (1 - beta_2_t)\n+                * tf.reduce_mean(regulated_grad_square, axis=-1)\n+            )\n+            # `c` deletes the second last dimension of gradient, so it is of\n+            # shape `gradient.shape[:-2] + gradient.shape[-1]`.\n+            c.assign(\n+                beta_2_t * c\n+                + (1 - beta_2_t)\n+                * tf.reduce_mean(regulated_grad_square, axis=-2)\n+            )\n+            v.assign(\n+                tf.expand_dims(\n+                    r / tf.reduce_mean(r, axis=-1, keepdims=True), axis=-1\n+                )\n+                * tf.expand_dims(c, -2)\n+            )\n+        else:\n+            v.assign(beta_2_t * v + (1 - beta_2_t) * regulated_grad_square)\n+\n+        # `convert_to_tensor` unifies the handling of sparse and dense grads.\n+        u_t = tf.convert_to_tensor(gradient) * tf.math.rsqrt(v)\n+        u_t_hat = u_t / tf.maximum(one, (self._rms(u_t) / self.clip_threshold))\n+        variable.assign_add(-alpha_t * u_t_hat)\n+\n+    def get_config(self):\n+        config = super().get_config()\n+\n+        config.update(\n+            {\n+                \"learning_rate\": self._serialize_hyperparameter(\n+                    self._learning_rate\n+                ),\n+                \"beta_2_decay\": self.beta_2_decay,\n+                \"epsilon_1\": self.epsilon_1,\n+                \"epsilon_2\": self.epsilon_2,\n+                \"clip_threshold\": self.clip_threshold,\n+                \"relative_step\": self.relative_step,\n+            }\n+        )\n+        return config\n+\n+\n+Adafactor.__doc__ = Adafactor.__doc__.replace(\n+    \"{{base_optimizer_keyword_args}}\", optimizer.base_optimizer_keyword_args\n+)\n\n@@ -13,6 +13,7 @@ from absl.testing import parameterized\n \n import keras\n from keras.optimizers.optimizer_experimental import adadelta as adadelta_new\n+from keras.optimizers.optimizer_experimental import adafactor as adafactor_new\n from keras.optimizers.optimizer_experimental import adagrad as adagrad_new\n from keras.optimizers.optimizer_experimental import adam as adam_new\n from keras.optimizers.optimizer_experimental import adamax as adamax_new\n@@ -53,6 +54,9 @@ adadelta_new_fn = tf.__internal__.test.combinations.NamedObject(\n adagrad_new_fn = tf.__internal__.test.combinations.NamedObject(\n     \"experimentaladagrad\", lambda: adagrad_new.Adagrad(0.002)\n )\n+adafactor_new_fn = tf.__internal__.test.combinations.NamedObject(\n+    \"adafactor\", lambda: adafactor_new.Adafactor(0.002)\n+)\n adam_new_fn = tf.__internal__.test.combinations.NamedObject(\n     \"experimentaladam\", lambda: adam_new.Adam(0.002)\n )\n@@ -79,6 +83,7 @@ sgd_new_fn = tf.__internal__.test.combinations.NamedObject(\n OPTIMIZER_FN = [\n     adadelta_new_fn,\n     adagrad_new_fn,\n+    adafactor_new_fn,\n     adam_new_fn,\n     adamax_new_fn,\n     adamw_new_fn,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d3ddd2838781acc0c64fbb8d746e3c744597bc13", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 306 | Contributors (this commit): 10 | Commits (past 90d): 1 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -101,7 +101,7 @@ def _limit_gpu_memory():\n             gpus[0],\n             [\n                 tf.config.experimental.VirtualDeviceConfiguration(\n-                    memory_limit=1024\n+                    memory_limit=2048\n                 )\n             ],\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f3035dce9cad07564d0a55398c5310d9ede69c44", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 20 | Files Changed: 2 | Hunks: 10 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 46 | Churn Cumulative: 885 | Contributors (this commit): 7 | Commits (past 90d): 31 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -524,19 +524,22 @@ class OptimizerRegressionTest(tf.test.TestCase, parameterized.TestCase):\n         x1 = tf.Variable(np.ones([10]), dtype=tf.float64)\n         x2 = tf.Variable(np.ones([10]), dtype=tf.float64)\n         grads = tf.convert_to_tensor(np.arange(0.1, 1.1, 0.1))\n+        first_grads = tf.constant([0.01] * 10, dtype=tf.float64)\n         sparse_grads = tf.IndexedSlices(\n             tf.convert_to_tensor([0, 0.2, 0.4, 0.8, 0.8], dtype=tf.float64),\n             tf.convert_to_tensor([0, 2, 4, 6, 6]),\n             dense_shape=tf.convert_to_tensor([len(grads)]),\n         )\n \n+        old_optimizer.apply_gradients(zip([first_grads], [x1]))\n+        new_optimizer.apply_gradients(zip([first_grads], [x2]))\n         for _ in range(5):\n-            self.assertAllClose(x1, x2)\n+            self.assertAllClose(x1, x2, rtol=5e-4, atol=5e-4)\n             old_optimizer.apply_gradients(zip([grads], [x1]))\n             new_optimizer.apply_gradients(zip([grads], [x2]))\n \n         for _ in range(5):\n-            self.assertAllClose(x1, x2)\n+            self.assertAllClose(x1, x2, rtol=5e-4, atol=5e-4)\n             old_optimizer.apply_gradients(zip([sparse_grads], [x1]))\n             new_optimizer.apply_gradients(zip([sparse_grads], [x2]))\n \n@@ -557,7 +560,10 @@ class OptimizerRegressionTest(tf.test.TestCase, parameterized.TestCase):\n         self._compare_numerical(ftrl_old.Ftrl(), ftrl_new.Ftrl())\n \n     def testRMSprop(self):\n-        self._compare_numerical(rmsprop_old.RMSprop(), rmsprop_new.RMSprop())\n+        self._compare_numerical(\n+            rmsprop_old.RMSprop(centered=True),\n+            rmsprop_new.RMSprop(centered=True),\n+        )\n \n     @parameterized.product(nesterov=[True, False])\n     def testSgd(self, nesterov):\n\n@@ -161,35 +161,35 @@ class RMSprop(optimizer.Optimizer):\n                         gradient.values * (1 - rho), gradient.indices\n                     )\n                 )\n-                velocity.assign_add(-tf.square(average_grad))\n-            velocity_value = tf.gather(velocity, gradient.indices)\n-            transformed_grad = tf.IndexedSlices(\n-                gradient.values / (tf.sqrt(velocity_value) + self.epsilon),\n+                denominator = velocity - tf.square(average_grad) + self.epsilon\n+            else:\n+                denominator = velocity + self.epsilon\n+            denominator_slices = tf.gather(denominator, gradient.indices)\n+            increment = tf.IndexedSlices(\n+                lr * gradient.values * tf.math.rsqrt(denominator_slices),\n                 gradient.indices,\n             )\n \n             if self.momentum > 0:\n                 momentum.assign(self.momentum * momentum)\n-                momentum.scatter_add(transformed_grad)\n-                variable.assign_add(-lr * momentum)\n+                momentum.scatter_add(increment)\n+                variable.assign_add(-momentum)\n             else:\n-                variable.scatter_add(\n-                    tf.IndexedSlices(\n-                        -lr * transformed_grad.values, transformed_grad.indices\n-                    )\n-                )\n+                variable.scatter_add(-increment)\n         else:\n             # Dense gradients.\n             velocity.assign(rho * velocity + (1 - rho) * tf.square(gradient))\n             if self.centered:\n                 average_grad.assign(rho * average_grad + (1 - rho) * gradient)\n-                velocity.assign_add(-tf.square(average_grad))\n-            transformed_grad = gradient / (tf.sqrt(velocity) + self.epsilon)\n-            if self.momentum > 0:\n-                momentum.assign(self.momentum * momentum + transformed_grad)\n-                variable.assign_add(-lr * momentum)\n+                denominator = velocity - tf.square(average_grad) + self.epsilon\n             else:\n-                variable.assign_add(-lr * transformed_grad)\n+                denominator = velocity + self.epsilon\n+            increment = lr * gradient * tf.math.rsqrt(denominator)\n+            if self.momentum > 0:\n+                momentum.assign(self.momentum * momentum + increment)\n+                variable.assign_add(-momentum)\n+            else:\n+                variable.assign_add(-increment)\n \n     def get_config(self):\n         config = super().get_config()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2eda0600e24c48363a8eb07ad2c3f39436430df7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1097 | Contributors (this commit): 8 | Commits (past 90d): 29 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -473,8 +473,8 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n         \"\"\"\n         if initial_value is None:\n             if shape is None:\n-                initial_value = tf.zeros(\n-                    shape=model_variable.shape, dtype=model_variable.dtype\n+                initial_value = tf.zeros_like(\n+                    model_variable, dtype=model_variable.dtype\n                 )\n             else:\n                 initial_value = tf.zeros(shape, dtype=model_variable.dtype)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#38b618ad90d669c85cccee521ad73cc0630cf750", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 171 | Lines Deleted: 64 | Files Changed: 13 | Hunks: 42 | Methods Changed: 24 | Complexity Δ (Sum/Max): 13/22 | Churn Δ: 235 | Churn Cumulative: 4842 | Contributors (this commit): 16 | Commits (past 90d): 101 | Contributors (cumulative): 77 | DMM Complexity: 0.9753086419753086\n\nDIFF:\n@@ -212,6 +212,7 @@ def convert_to_legacy_optimizer(optimizer):\n     config = optimizer.get_config()\n     # Remove fields that only exist in experimental optimizer.\n     keys_to_remove = [\n+        \"weight_decay\",\n         \"use_ema\",\n         \"ema_momentum\",\n         \"ema_overwrite_frequency\",\n\n@@ -64,6 +64,7 @@ class Adadelta(optimizer.Optimizer):\n         learning_rate=0.001,\n         rho=0.95,\n         epsilon=1e-7,\n+        weight_decay=None,\n         clipnorm=None,\n         clipvalue=None,\n         global_clipnorm=None,\n@@ -75,6 +76,7 @@ class Adadelta(optimizer.Optimizer):\n         **kwargs\n     ):\n         super().__init__(\n+            weight_decay=weight_decay,\n             clipnorm=clipnorm,\n             clipvalue=clipvalue,\n             global_clipnorm=global_clipnorm,\n\n@@ -69,6 +69,7 @@ class Adafactor(optimizer.Optimizer):\n         epsilon_2=1e-3,\n         clip_threshold=1.0,\n         relative_step=True,\n+        weight_decay=None,\n         clipnorm=None,\n         clipvalue=None,\n         global_clipnorm=None,\n@@ -81,6 +82,7 @@ class Adafactor(optimizer.Optimizer):\n     ):\n         super().__init__(\n             name=name,\n+            weight_decay=weight_decay,\n             clipnorm=clipnorm,\n             clipvalue=clipvalue,\n             global_clipnorm=global_clipnorm,\n\n@@ -58,6 +58,7 @@ class Adagrad(optimizer.Optimizer):\n         learning_rate=0.001,\n         initial_accumulator_value=0.1,\n         epsilon=1e-7,\n+        weight_decay=None,\n         clipnorm=None,\n         clipvalue=None,\n         global_clipnorm=None,\n@@ -69,6 +70,7 @@ class Adagrad(optimizer.Optimizer):\n         **kwargs\n     ):\n         super().__init__(\n+            weight_decay=weight_decay,\n             clipnorm=clipnorm,\n             clipvalue=clipvalue,\n             global_clipnorm=global_clipnorm,\n\n@@ -88,6 +88,7 @@ class Adam(optimizer.Optimizer):\n         beta_2=0.999,\n         epsilon=1e-7,\n         amsgrad=False,\n+        weight_decay=None,\n         clipnorm=None,\n         clipvalue=None,\n         global_clipnorm=None,\n@@ -100,6 +101,7 @@ class Adam(optimizer.Optimizer):\n     ):\n         super().__init__(\n             name=name,\n+            weight_decay=weight_decay,\n             clipnorm=clipnorm,\n             clipvalue=clipvalue,\n             global_clipnorm=global_clipnorm,\n\n@@ -76,6 +76,7 @@ class Adamax(optimizer.Optimizer):\n         beta_1=0.9,\n         beta_2=0.999,\n         epsilon=1e-7,\n+        weight_decay=None,\n         clipnorm=None,\n         clipvalue=None,\n         global_clipnorm=None,\n@@ -88,6 +89,7 @@ class Adamax(optimizer.Optimizer):\n     ):\n         super().__init__(\n             name=name,\n+            weight_decay=weight_decay,\n             clipnorm=clipnorm,\n             clipvalue=clipvalue,\n             global_clipnorm=global_clipnorm,\n\n@@ -14,7 +14,6 @@\n # ==============================================================================\n \"\"\"AdamW optimizer implementation.\"\"\"\n \n-import re\n \n import tensorflow.compat.v2 as tf\n \n@@ -166,20 +165,6 @@ class AdamW(optimizer.Optimizer):\n                     )\n                 )\n \n-    def _use_weight_decay(self, variable):\n-        exclude_from_weight_decay = getattr(\n-            self, \"_exclude_from_weight_decay\", []\n-        )\n-        exclude_from_weight_decay_names = getattr(\n-            self, \"_exclude_from_weight_decay_names\", []\n-        )\n-        if variable in exclude_from_weight_decay:\n-            return False\n-        for name in exclude_from_weight_decay_names:\n-            if re.search(name, variable.name) is not None:\n-                return False\n-        return True\n-\n     def update_step(self, gradient, variable):\n         \"\"\"Update step given gradient and the associated model variable.\"\"\"\n         beta_1_power = None\n@@ -195,11 +180,6 @@ class AdamW(optimizer.Optimizer):\n \n         alpha = lr * tf.sqrt(1 - beta_2_power) / (1 - beta_1_power)\n \n-        # Apply step weight decay\n-        if self._use_weight_decay(variable):\n-            wd = tf.cast(self.weight_decay, variable.dtype)\n-            variable.assign_sub(variable * wd * lr)\n-\n         if isinstance(gradient, tf.IndexedSlices):\n             # Sparse gradients.\n             m.assign_add(-m * (1 - self.beta_1))\n@@ -247,30 +227,6 @@ class AdamW(optimizer.Optimizer):\n         )\n         return config\n \n-    def exclude_from_weight_decay(self, var_list=None, var_names=None):\n-        \"\"\"Exclude variables from weight decays.\n-\n-        This method must be called before the optimizer's `build` method is\n-        called. You can set specific variables to exclude out, or set a list of\n-        strings as the anchor words, if any of which appear in a variable's\n-        name, then the variable is excluded.\n-\n-        Args:\n-            var_list: A list of `tf.Variable`s to exclude from weight decay.\n-            var_names: A list of strings. If any string in `var_names` appear\n-                in the model variable's name, then this model variable is\n-                excluded from weight decay. For example, `var_names=['bias']`\n-                excludes all bias variables from weight decay.\n-        \"\"\"\n-        if hasattr(self, \"_built\") and self._built:\n-            raise ValueError(\n-                \"`exclude_from_weight_decay()` can only be configued before \"\n-                \"the optimizer is built.\"\n-            )\n-\n-        self._exclude_from_weight_decay = var_list or []\n-        self._exclude_from_weight_decay_names = var_names or []\n-\n \n AdamW.__doc__ = AdamW.__doc__.replace(\n     \"{{base_optimizer_keyword_args}}\", optimizer.base_optimizer_keyword_args\n\n@@ -103,6 +103,7 @@ class Ftrl(optimizer.Optimizer):\n         l2_regularization_strength=0.0,\n         l2_shrinkage_regularization_strength=0.0,\n         beta=0.0,\n+        weight_decay=None,\n         clipnorm=None,\n         clipvalue=None,\n         global_clipnorm=None,\n@@ -115,6 +116,7 @@ class Ftrl(optimizer.Optimizer):\n     ):\n         super().__init__(\n             name=name,\n+            weight_decay=weight_decay,\n             clipnorm=clipnorm,\n             clipvalue=clipvalue,\n             global_clipnorm=global_clipnorm,\n\n@@ -59,6 +59,7 @@ class Nadam(optimizer.Optimizer):\n         beta_1=0.9,\n         beta_2=0.999,\n         epsilon=1e-7,\n+        weight_decay=None,\n         clipnorm=None,\n         clipvalue=None,\n         global_clipnorm=None,\n@@ -71,6 +72,7 @@ class Nadam(optimizer.Optimizer):\n     ):\n         super().__init__(\n             name=name,\n+            weight_decay=weight_decay,\n             clipnorm=clipnorm,\n             clipvalue=clipvalue,\n             global_clipnorm=global_clipnorm,\n\n@@ -18,6 +18,7 @@ This is under development, and subject to interface/implementation changes.\n \"\"\"\n \n import abc\n+import re\n \n import tensorflow.compat.v2 as tf\n from absl import logging\n@@ -41,6 +42,7 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n     def __init__(\n         self,\n         name,\n+        weight_decay=None,\n         clipnorm=None,\n         clipvalue=None,\n         global_clipnorm=None,\n@@ -51,6 +53,7 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n         **kwargs,\n     ):\n         self.name = name\n+        self.weight_decay = weight_decay\n         self.clipnorm = clipnorm\n         self.global_clipnorm = global_clipnorm\n         self.clipvalue = clipvalue\n@@ -511,20 +514,7 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n         grads_and_vars = self.compute_gradients(loss, var_list, tape)\n         self.apply_gradients(grads_and_vars)\n \n-    def apply_gradients(self, grads_and_vars, name=None):\n-        \"\"\"Apply gradients to variables.\n-\n-        Args:\n-          grads_and_vars: List of `(gradient, variable)` pairs.\n-          name: string, defaults to None. The name of the namescope to\n-            use when creating variables. If None, `self.name` will be used.\n-\n-        Returns:\n-          A `tf.Variable`, representing the current iteration.\n-\n-        Raises:\n-          TypeError: If `grads_and_vars` is malformed.\n-        \"\"\"\n+    def _compute_current_learning_rate(self):\n         if isinstance(\n             self._learning_rate, learning_rate_schedule.LearningRateSchedule\n         ):\n@@ -544,6 +534,67 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n                     dtype=current_learning_rate.dtype,\n                     trainable=False,\n                 )\n+\n+    def exclude_from_weight_decay(self, var_list=None, var_names=None):\n+        \"\"\"Exclude variables from weight decay.\n+\n+        This method must be called before the optimizer's `build` method is\n+        called. You can set specific variables to exclude out, or set a list of\n+        strings as the anchor words, if any of which appear in a variable's\n+        name, then the variable is excluded.\n+\n+        Args:\n+            var_list: A list of `tf.Variable`s to exclude from weight decay.\n+            var_names: A list of strings. If any string in `var_names` appear\n+                in the model variable's name, then this model variable is\n+                excluded from weight decay. For example, `var_names=['bias']`\n+                excludes all bias variables from weight decay.\n+        \"\"\"\n+        if hasattr(self, \"_built\") and self._built:\n+            raise ValueError(\n+                \"`exclude_from_weight_decay()` can only be configued before \"\n+                \"the optimizer is built.\"\n+            )\n+\n+        if var_list:\n+            self._exclude_from_weight_decay = [\n+                self._var_key(variable) for variable in var_list\n+            ]\n+        else:\n+            self._exclude_from_weight_decay = []\n+        self._exclude_from_weight_decay_names = var_names or []\n+\n+    def _use_weight_decay(self, variable):\n+        exclude_from_weight_decay = getattr(\n+            self, \"_exclude_from_weight_decay\", []\n+        )\n+        exclude_from_weight_decay_names = getattr(\n+            self, \"_exclude_from_weight_decay_names\", []\n+        )\n+        variable_id = self._var_key(variable)\n+        for exclude_id in exclude_from_weight_decay:\n+            if variable_id == exclude_id:\n+                return False\n+        for name in exclude_from_weight_decay_names:\n+            if re.search(name, variable.name) is not None:\n+                return False\n+        return True\n+\n+    def apply_gradients(self, grads_and_vars, name=None):\n+        \"\"\"Apply gradients to variables.\n+\n+        Args:\n+          grads_and_vars: List of `(gradient, variable)` pairs.\n+          name: string, defaults to None. The name of the namescope to\n+            use when creating variables. If None, `self.name` will be used.\n+\n+        Returns:\n+          A `tf.Variable`, representing the current iteration.\n+\n+        Raises:\n+          TypeError: If `grads_and_vars` is malformed.\n+        \"\"\"\n+        self._compute_current_learning_rate()\n         grads_and_vars = list(grads_and_vars)\n         if len(grads_and_vars) == 0:\n             # It is possible that the grad is empty. In this case,\n@@ -566,6 +617,7 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n \n         grads = self._clip_gradients(grads)\n         grads = self._deduplicate_sparse_grad(grads)\n+        self._apply_weight_decay(trainable_variables)\n         grads_and_vars = list(zip(grads, trainable_variables))\n         iteration = self._internal_apply_gradients(grads_and_vars)\n \n@@ -575,6 +627,15 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n                 variable.assign(variable.constraint(variable))\n         return iteration\n \n+    def _apply_weight_decay(self, variables):\n+        if self.weight_decay is None:\n+            return\n+        for variable in variables:\n+            if self._use_weight_decay(variable):\n+                lr = tf.cast(self.learning_rate, variable.dtype)\n+                wd = tf.cast(self.weight_decay, variable.dtype)\n+                variable.assign_sub(variable * wd * lr)\n+\n     def _internal_apply_gradients(self, grads_and_vars):\n         \"\"\"Helper function of apply gradients.\n \n@@ -663,6 +724,7 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n         \"\"\"\n         config = {\n             \"name\": self.name,\n+            \"weight_decay\": self.weight_decay,\n             \"clipnorm\": self.clipnorm,\n             \"global_clipnorm\": self.global_clipnorm,\n             \"clipvalue\": self.clipvalue,\n@@ -758,6 +820,7 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n base_optimizer_keyword_args = \"\"\"name: String. The name to use\n         for momentum accumulator weights created by\n         the optimizer.\n+      weight_decay: Float, defaults to None. If set, weight decay is applied.\n       clipnorm: Float. If set, the gradient of each weight is individually\n         clipped so that its norm is no higher than this value.\n       clipvalue: Float. If set, the gradient of each weight is clipped to be no\n@@ -870,11 +933,26 @@ class Optimizer(_BaseOptimizer):\n     [2.0, 2.0]\n     >>> opt.apply_gradients(zip(grads, [var1, var2]))\n     >>> # Without clipping, we should get [0, 0], but as gradients are clipped\n-    >>> # to\n-    >>> # have max value 1, we get [1.0, 1.0].\n+    >>> # to have max value 1, we get [1.0, 1.0].\n     >>> print([var1.numpy(), var2.numpy()])\n     [1.0, 1.0]\n \n+    ### Using weight decay.\n+\n+    Weight decay in certain scenarios can boost the model's performance. Keras\n+    has built-in support for weight decay in all optimizers. Users can apply\n+    weight decay by setting `weight_decay` argument.\n+\n+    >>> opt = tf.keras.optimizers.experimental.SGD(1, weight_decay=0.004)\n+    >>> grads, var1, var2 = tf.zeros(()), tf.Variable(2.0), tf.Variable(2.0)\n+    >>> # You can exclude variables from weight decay, in this case we\n+    >>> # exclude `var2`.\n+    >>> opt.exclude_from_weight_decay(var_list=[var2])\n+    >>> opt.apply_gradients(zip([grads, grads], [var1, var2]))\n+    >>> print([var1.numpy(), var2.numpy()])\n+    [1.992, 2.0]\n+\n+\n     ### Using exponential moving average.\n \n     Empirically it has been found that using the exponential moving average\n@@ -963,6 +1041,7 @@ class Optimizer(_BaseOptimizer):\n     def __init__(\n         self,\n         name,\n+        weight_decay=0,\n         clipnorm=None,\n         clipvalue=None,\n         global_clipnorm=None,\n@@ -976,6 +1055,7 @@ class Optimizer(_BaseOptimizer):\n \n         super().__init__(\n             name,\n+            weight_decay,\n             clipnorm,\n             clipvalue,\n             global_clipnorm,\n@@ -1054,6 +1134,29 @@ class Optimizer(_BaseOptimizer):\n             grads_and_vars = self.aggregate_gradients(grads_and_vars)\n         return super().apply_gradients(grads_and_vars, name=name)\n \n+    def _apply_weight_decay(self, variables):\n+        # Apply weight decay in distributed setup.\n+        if self.weight_decay is None:\n+            return\n+\n+        def distributed_apply_weight_decay(distribution, variables, **kwargs):\n+            def weight_decay_fn(variable):\n+                if self._use_weight_decay(variable):\n+                    lr = tf.cast(self.learning_rate, variable.dtype)\n+                    wd = tf.cast(self.weight_decay, variable.dtype)\n+                    variable.assign_sub(variable * wd * lr)\n+\n+            for variable in variables:\n+                distribution.extended.update(\n+                    variable, weight_decay_fn, group=False\n+                )\n+\n+        tf.__internal__.distribute.interim.maybe_merge_call(\n+            distributed_apply_weight_decay,\n+            self._distribution_strategy,\n+            variables,\n+        )\n+\n     def _internal_apply_gradients(self, grads_and_vars):\n         return tf.__internal__.distribute.interim.maybe_merge_call(\n             self._distributed_apply_gradients_fn,\n\n@@ -77,7 +77,9 @@ rmsprop_new_fn = tf.__internal__.test.combinations.NamedObject(\n )\n sgd_new_fn = tf.__internal__.test.combinations.NamedObject(\n     \"experimentalsgdaverage\",\n-    lambda: sgd_new.SGD(0.002, use_ema=True, ema_overwrite_frequency=1),\n+    lambda: sgd_new.SGD(\n+        0.002, weight_decay=0.004, use_ema=True, ema_overwrite_frequency=1\n+    ),\n )\n \n OPTIMIZER_FN = [\n@@ -167,13 +169,34 @@ class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n \n         optimizer_2 = adamw_new.AdamW(learning_rate=1, weight_decay=0.004)\n         optimizer_2.exclude_from_weight_decay(var_names=[\"exclude\"])\n-        optimizer_2.apply_gradients(zip([grads], [var2]))\n+        optimizer_2.apply_gradients(zip([grads, grads], [var1, var2]))\n \n         optimizer_3 = adamw_new.AdamW(learning_rate=1, weight_decay=0.004)\n         optimizer_3.exclude_from_weight_decay(var_list=[var3])\n-        optimizer_3.apply_gradients(zip([grads], [var3]))\n+        optimizer_3.apply_gradients(zip([grads, grads], [var1, var3]))\n \n-        self.assertEqual(var1, 1.992)\n+        self.assertEqual(var1, 1.9760959)\n+        self.assertEqual(var2, 2.0)\n+        self.assertEqual(var3, 2.0)\n+\n+        grads, var1, var2, var3 = (\n+            tf.zeros(()),\n+            tf.Variable(2.0),\n+            tf.Variable(2.0, name=\"exclude\"),\n+            tf.Variable(2.0),\n+        )\n+        optimizer_1 = sgd_new.SGD(learning_rate=1, weight_decay=0.004)\n+        optimizer_1.apply_gradients(zip([grads], [var1]))\n+\n+        optimizer_2 = sgd_new.SGD(learning_rate=1, weight_decay=0.004)\n+        optimizer_2.exclude_from_weight_decay(var_names=[\"exclude\"])\n+        optimizer_2.apply_gradients(zip([grads, grads], [var1, var2]))\n+\n+        optimizer_3 = sgd_new.SGD(learning_rate=1, weight_decay=0.004)\n+        optimizer_3.exclude_from_weight_decay(var_list=[var3])\n+        optimizer_3.apply_gradients(zip([grads, grads], [var1, var3]))\n+\n+        self.assertEqual(var1, 1.9760959)\n         self.assertEqual(var2, 2.0)\n         self.assertEqual(var3, 2.0)\n \n@@ -571,6 +594,12 @@ class OptimizerRegressionTest(tf.test.TestCase, parameterized.TestCase):\n             sgd_old.SGD(nesterov=nesterov), sgd_new.SGD(nesterov=nesterov)\n         )\n \n+    def testWeightDecay(self):\n+        self._compare_numerical(\n+            adam_new.Adam(learning_rate=1, weight_decay=0.5, epsilon=0),\n+            adamw_new.AdamW(learning_rate=1, weight_decay=0.5, epsilon=0),\n+        )\n+\n \n class DistributedTrainingTest(tf.test.TestCase, parameterized.TestCase):\n     @ds_combinations.generate(\n\n@@ -78,6 +78,7 @@ class RMSprop(optimizer.Optimizer):\n         momentum=0.0,\n         epsilon=1e-7,\n         centered=False,\n+        weight_decay=None,\n         clipnorm=None,\n         clipvalue=None,\n         global_clipnorm=None,\n@@ -89,6 +90,7 @@ class RMSprop(optimizer.Optimizer):\n         **kwargs\n     ):\n         super().__init__(\n+            weight_decay=weight_decay,\n             clipnorm=clipnorm,\n             clipvalue=clipvalue,\n             global_clipnorm=global_clipnorm,\n\n@@ -96,6 +96,7 @@ class SGD(optimizer.Optimizer):\n         momentum=0.0,\n         nesterov=False,\n         amsgrad=False,\n+        weight_decay=None,\n         clipnorm=None,\n         clipvalue=None,\n         global_clipnorm=None,\n@@ -108,6 +109,7 @@ class SGD(optimizer.Optimizer):\n     ):\n         super().__init__(\n             name=name,\n+            weight_decay=weight_decay,\n             clipnorm=clipnorm,\n             clipvalue=clipvalue,\n             global_clipnorm=global_clipnorm,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#298df74408252899a129067802bc2bd4cd40d164", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1390 | Contributors (this commit): 12 | Commits (past 90d): 3 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -247,7 +247,7 @@ class NormalizationTest(\n         inv_norm.adapt(input_data)\n         output = norm(input_data)\n         output2 = inv_norm(output)\n-        self.assertListEqual(output2.shape.as_list(), [4])\n+        self.assertListEqual(output2.shape.as_list(), [4, 1])\n         self.assertAllClose(input_data, output2)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#609d4550a692fc1a4fe6b22442ed04ed4ec24c2d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 9 | Churn Cumulative: 1241 | Contributors (this commit): 8 | Commits (past 90d): 31 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -476,9 +476,18 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n         \"\"\"\n         if initial_value is None:\n             if shape is None:\n+                if model_variable.shape.rank is None:\n+                    # When the rank is None, we cannot get a concrete\n+                    # `model_variable.shape`, we use dynamic shape.\n                     initial_value = tf.zeros_like(\n                         model_variable, dtype=model_variable.dtype\n                     )\n+                else:\n+                    # We cannot always use `zeros_like`, because some cases\n+                    # the shape exists while values don't.\n+                    initial_value = tf.zeros(\n+                        model_variable.shape, dtype=model_variable.dtype\n+                    )\n             else:\n                 initial_value = tf.zeros(shape, dtype=model_variable.dtype)\n         variable = tf.Variable(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7bda68243d677dafb75eca1af770874a2af71fa7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 76 | Lines Deleted: 56 | Files Changed: 3 | Hunks: 26 | Methods Changed: 9 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 132 | Churn Cumulative: 21514 | Contributors (this commit): 137 | Commits (past 90d): 43 | Contributors (cumulative): 153 | DMM Complexity: 0.6\n\nDIFF:\n@@ -241,42 +241,48 @@ class KerasMultiWorkerTestIndependentWorker(\n     def test_distribution_reduction_method_auto_default_train_step(\n         self, strategy\n     ):\n-        batch_size = 32\n-        epochs = 2\n-        steps = 2\n+        BATCH = 4\n+        EPOCHS = 1\n+        STEPS = 2\n+\n+        # Dataset's targets are [0, 1, 2, 3, 4, 5, 6, 7]:\n         train_ds, _ = multi_worker_testing_utils.mnist_synthetic_dataset(\n-            batch_size, steps\n+            BATCH, STEPS, target_values=\"increasing\"\n         )\n \n-        # A model that always outputs `sum(inputs*1) + 1 = 28**2 + 1 = 785`\n+        # A model that always outputs `sum(inputs*0) + 1 = 1`\n         with strategy.scope():\n             inputs = keras.Input(shape=(28, 28, 1))\n             x = keras.layers.Flatten()(inputs)\n             x = keras.layers.Dense(\n-                1, kernel_initializer=\"ones\", bias_initializer=\"ones\"\n+                1, kernel_initializer=\"zeros\", bias_initializer=\"ones\"\n             )(x)\n             model = keras.Model(inputs=inputs, outputs=x)\n-            # model.distribute_reduction_method = 'auto'\n             model.trainable = False\n+            # model.distribute_reduction_method = 'auto'\n+\n             model.compile(\n-                loss=keras.losses.mean_absolute_error,\n+                loss=keras.losses.MeanAbsoluteError(\n+                    reduction=keras.losses.losses_utils.ReductionV2.NONE\n+                ),\n                 optimizer=multi_worker_testing_utils.gradient_descent.SGD(\n                     learning_rate=0.001\n                 ),\n                 metrics=[\"mse\"],\n             )\n \n-        # For every output x_i = 785, every target y_i = 1,\n-        #   loss_i     = |785-1| = 784; and\n-        #   loss_total = sum([784, 784, ..., 784]) / (BATCH_SIZE*steps) = 784\n-        orig_loss, _ = model.evaluate(train_ds, steps=steps)\n-        self.assertEqual(784, orig_loss)\n+        # For every output x_i = 1, and increasing target values in [0, 8):\n+        #   loss_i = |i-1|\n+        #   loss   = (|0-1| + |1-1| + |2-1| + ... |7-1|) / (BATCH*STEPS)\n+        #          = (1+0+1+2+3+4+5+6) / 8 = 2.75\n+        orig_loss, _ = model.evaluate(train_ds, steps=STEPS)\n+        self.assertEqual(2.75, orig_loss)\n \n-        history = model.fit(train_ds, epochs=epochs, steps_per_epoch=steps)\n-        self.assertAllClose(history.history[\"loss\"], [784] * epochs)\n+        history = model.fit(train_ds, epochs=EPOCHS, steps_per_epoch=STEPS)\n+        self.assertAllClose(history.history[\"loss\"], [2.75] * EPOCHS)\n \n-        trained_loss, _ = model.evaluate(train_ds, steps=steps)\n-        self.assertEqual(784, trained_loss)\n+        trained_loss, _ = model.evaluate(train_ds, steps=STEPS)\n+        self.assertEqual(2.75, trained_loss)\n \n     @tf.__internal__.distribute.combinations.generate(\n         tf.__internal__.test.combinations.combine(\n@@ -290,37 +296,31 @@ class KerasMultiWorkerTestIndependentWorker(\n     def test_distribution_reduction_method_auto_custom_train_step(\n         self, strategy\n     ):\n-        batch_size = 32\n-        steps = 2\n-        epochs = 2\n+        BATCH = 4\n+        EPOCHS = 1\n+        STEPS = 2\n+\n+        # Dataset's targets are [0, 1, 2, 3]:\n         train_ds, _ = multi_worker_testing_utils.mnist_synthetic_dataset(\n-            batch_size, steps\n+            BATCH, STEPS, target_values=\"increasing\"\n         )\n \n         class MyModel(keras.Model):\n-            @staticmethod\n-            def reduce_loss(loss_value, global_batch_size):\n-                REDUCTION_AXES = range(1, loss_value.shape.rank)\n-                loss_value = tf.reduce_mean(loss_value, axis=REDUCTION_AXES)\n-                return tf.nn.compute_average_loss(\n-                    loss_value, global_batch_size=batch_size\n-                )\n-\n             def train_step(self, data):\n-                loss_value = 3 * tf.ones_like(data[0])\n-                return {\n-                    \"loss\": MyModel.reduce_loss(\n-                        loss_value, global_batch_size=batch_size\n+                _, y = data\n+                loss_value = tf.cast(y, tf.float32)\n+                loss_value = tf.nn.compute_average_loss(\n+                    loss_value, global_batch_size=BATCH\n                 )\n-                }\n+                return {\"loss\": loss_value}\n \n             def test_step(self, data):\n-                loss_value = 5 * tf.ones_like(data[0])\n-                return {\n-                    \"metric\": MyModel.reduce_loss(\n-                        loss_value, global_batch_size=batch_size\n+                _, y = data\n+                loss_value = tf.cast(y, tf.float32)\n+                loss_value = tf.nn.compute_average_loss(\n+                    loss_value, global_batch_size=BATCH\n                 )\n-                }\n+                return {\"loss\": loss_value}\n \n         with strategy.scope():\n             inputs = keras.Input(shape=(28, 28, 1))\n@@ -330,26 +330,27 @@ class KerasMultiWorkerTestIndependentWorker(\n             )(x)\n             model = MyModel(inputs=inputs, outputs=x)\n             # model.distribute_reduction_method = 'auto'\n+\n             model.compile(\n-                loss=keras.losses.mean_absolute_error,\n                 optimizer=multi_worker_testing_utils.gradient_descent.SGD(\n                     learning_rate=0.001\n                 ),\n             )\n \n-        # For 2 mirrored workers,\n-        # train_loss_i_replica_r = (3+3+3+3)/batch = 6/8;\n-        # test_loss_i_replica_r  = (5+5+5+5)/batch = 5/8\n-        # =>\n-        # train_loss_i = sum([12/8, 12/8]) = 3\n-        # train_loss   = sum([3, 3, ...])/(batch*steps) = 12/4 = 3\n-        history = model.fit(train_ds, epochs=epochs, steps_per_epoch=steps)\n-        self.assertAllClose(history.history[\"loss\"], [3.0] * epochs)\n+        # For epochs=1 steps=2 replicas=2 batch=4, and increasing target vals,\n+        #   loss_e0_s0_r0 = [0+1]/BATCH =  1/4\n+        #   loss_e0_s0_r1 = [2+3]/BATCH =  5/4\n+        #   loss_e0_s0    = 1/4 + 5/4   = 1.5\n+        #   loss_e0_s1_r0 = [4+5]/BATCH =  9/4\n+        #   loss_e0_s2_r1 = [6+7]/BATCH = 13/4\n+        #   loss_e0_s1    = 9/4 + 13/4   = 5.5\n+        #\n+        #   loss_e0       = last([1.5, 5.5])\n+        history = model.fit(train_ds, epochs=EPOCHS, steps_per_epoch=STEPS)\n+        self.assertAllClose([5.5], history.history[\"loss\"])\n \n-        # test_loss_i = sum([20/8, 20/8]) = 5\n-        # test_loss   = sum([5, 5, 5, 5])/(batch*steps) = 20/4 = 5\n-        eval_output = model.evaluate(train_ds, steps=steps)\n-        self.assertAllClose(eval_output, 5.0)\n+        eval_output = model.evaluate(train_ds, steps=STEPS)\n+        self.assertAllClose(5.5, eval_output)\n \n \n class KPLMultiWorkerTest(tf.test.TestCase, parameterized.TestCase):\n\n@@ -45,13 +45,27 @@ ASSIGNED_PORTS = set()\n lock = threading.Lock()\n \n \n-def mnist_synthetic_dataset(batch_size, steps_per_epoch):\n+def mnist_synthetic_dataset(\n+    batch_size, steps_per_epoch, target_values=\"constant\"\n+):\n     \"\"\"Generate synthetic MNIST dataset for testing.\"\"\"\n     # train dataset\n     x_train = tf.ones(\n         [batch_size * steps_per_epoch, 28, 28, 1], dtype=tf.float32\n     )\n+    if target_values == \"constant\":\n         y_train = tf.ones([batch_size * steps_per_epoch, 1], dtype=tf.int32)\n+    elif target_values == \"increasing\":\n+        y_train = tf.reshape(\n+            tf.range(batch_size * steps_per_epoch, dtype=tf.int32), (-1, 1)\n+        )\n+    else:\n+        raise ValueError(\n+            'Unknown value for `target_values` \"'\n+            + str(target_values)\n+            + '\". Valid options are \"constant\" and \"increasing\".'\n+        )\n+\n     train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n     train_ds = train_ds.repeat()\n     # train_ds = train_ds.shuffle(100)\n\n@@ -3879,10 +3879,15 @@ def reduce_per_replica(values, strategy, reduction):\n \n     def _reduce(v):\n         \"\"\"Reduce a single `PerReplica` object.\"\"\"\n-        if reduction == \"concat\" and _collective_all_reduce_multi_worker(\n-            strategy\n-        ):\n+        if reduction in (\n+            \"concat\",\n+            \"sum\",\n+        ) and _collective_all_reduce_multi_worker(strategy):\n+            if reduction == \"concat\":\n                 return _multi_worker_concat(v, strategy)\n+            else:\n+                return strategy.reduce(\"SUM\", v, axis=None)\n+\n         if not _is_per_replica_instance(v):\n             return v\n         elif reduction == \"first\":\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
