{"custom_id": "keras#9cfc0d17ea703e48f60a96e70c871c9faf89e5f5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 195 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 6 | Methods Changed: 6 | Complexity Δ (Sum/Max): -9/0 | Churn Δ: 200 | Churn Cumulative: 2616 | Contributors (this commit): 23 | Commits (past 90d): 26 | Contributors (cumulative): 32 | DMM Complexity: 1.0\n\nDIFF:\n@@ -17,6 +17,7 @@ from .losses import mean_squared_logarithmic_error\n from .losses import hinge\n from .losses import logcosh\n from .losses import squared_hinge\n+from .losses import categorical_hinge\n from .losses import categorical_crossentropy\n from .losses import sparse_categorical_crossentropy\n from .losses import binary_crossentropy\n@@ -261,7 +262,7 @@ class Mean(Reduce):\n     Usage:\n \n     ```python\n-    m = tf.keras.metrics.Mean()\n+    m = keras.metrics.Mean()\n     m.update_state([1, 3, 5, 7])\n     m.result()\n     ```\n@@ -350,6 +351,91 @@ class MeanSquaredError(MeanMetricWrapper):\n             mean_squared_error, name, dtype=dtype)\n \n \n+class Hinge(MeanMetricWrapper):\n+    \"\"\"Computes the hinge metric between `y_true` and `y_pred`.\n+\n+    `y_true` values are expected to be -1 or 1. If binary (0 or 1) labels are\n+    provided we will convert them to -1 or 1.\n+    For example, if `y_true` is [-1., 1., 1.], and `y_pred` is [0.6, -0.7, -0.5]\n+    the hinge metric value is 1.6.\n+\n+    Usage:\n+\n+    ```python\n+    m = keras.metrics.Hinge()\n+    m.update_state([-1., 1., 1.], [0.6, -0.7, -0.5])\n+    # result = max(0, 1-y_true * y_pred) = [1.6 + 1.7 + 1.5] / 3\n+    # Final result: 1.6\n+    ```\n+\n+    Usage with the `compile` API:\n+\n+    ```python\n+    model = keras.Model(inputs, outputs)\n+    model.compile('sgd', metrics=[keras.metrics.Hinge()])\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, name='hinge', dtype=None):\n+        super(Hinge, self).__init__(hinge, name, dtype=dtype)\n+\n+\n+class SquaredHinge(MeanMetricWrapper):\n+    \"\"\"Computes the squared hinge metric between `y_true` and `y_pred`.\n+\n+    `y_true` values are expected to be -1 or 1. If binary (0 or 1) labels are\n+    provided we will convert them to -1 or 1.\n+    For example, if `y_true` is [-1., 1., 1.], and `y_pred` is [0.6, -0.7, -0.5]\n+    the squared hinge metric value is 2.6.\n+\n+    Usage:\n+\n+    ```python\n+    m = keras.metrics.SquaredHinge()\n+    m.update_state([-1., 1., 1.], [0.6, -0.7, -0.5])\n+    # result = max(0, 1-y_true * y_pred) = [1.6^2 + 1.7^2 + 1.5^2] / 3\n+    # Final result: 2.6\n+    ```\n+\n+    Usage with the `compile` API:\n+\n+    ```python\n+    model = keras.Model(inputs, outputs)\n+    model.compile('sgd', metrics=[keras.metrics.SquaredHinge()])\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, name='squared_hinge', dtype=None):\n+        super(SquaredHinge, self).__init__(squared_hinge, name, dtype=dtype)\n+\n+\n+class CategoricalHinge(MeanMetricWrapper):\n+    \"\"\"Computes the categorical hinge metric between `y_true` and `y_pred`.\n+\n+    For example, if `y_true` is [0., 1., 1.], and `y_pred` is [1., 0., 1.]\n+    the categorical hinge metric value is 1.0.\n+\n+    Usage:\n+\n+    ```python\n+    m = keras.metrics.CategoricalHinge()\n+    m.update_state([0., 1., 1.], [1., 0., 1.])\n+    # Final result: 1.0\n+    ```\n+\n+    Usage with the `compile` API:\n+\n+    ```python\n+    model = keras.Model(inputs, outputs)\n+    model.compile('sgd', metrics=[keras.metrics.CategoricalHinge()])\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, name='categorical_hinge', dtype=None):\n+        super(CategoricalHinge, self).__init__(\n+            categorical_hinge, name, dtype=dtype)\n+\n+\n def binary_accuracy(y_true, y_pred):\n     return K.mean(K.equal(y_true, K.round(y_pred)), axis=-1)\n \n\n@@ -191,16 +191,120 @@ class TestMeanSquaredErrorTest(object):\n \n     def test_unweighted(self):\n         mse_obj = metrics.MeanSquaredError()\n-        y_true = ((0, 1, 0, 1, 0), (0, 0, 1, 1, 1), (1, 1, 1, 1, 0), (0, 0, 0, 0, 1))\n-        y_pred = ((0, 0, 1, 1, 0), (1, 1, 1, 1, 1), (0, 1, 0, 1, 0), (1, 1, 1, 1, 1))\n+        y_true = ((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n+                  (1, 1, 1, 1, 0), (0, 0, 0, 0, 1))\n+        y_pred = ((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n+                  (0, 1, 0, 1, 0), (1, 1, 1, 1, 1))\n \n         result = mse_obj(y_true, y_pred)\n         np.isclose(0.5, K.eval(result), atol=1e-5)\n \n     def test_weighted(self):\n         mse_obj = metrics.MeanSquaredError()\n-        y_true = ((0, 1, 0, 1, 0), (0, 0, 1, 1, 1), (1, 1, 1, 1, 0), (0, 0, 0, 0, 1))\n-        y_pred = ((0, 0, 1, 1, 0), (1, 1, 1, 1, 1), (0, 1, 0, 1, 0), (1, 1, 1, 1, 1))\n+        y_true = ((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n+                  (1, 1, 1, 1, 0), (0, 0, 0, 0, 1))\n+        y_pred = ((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n+                  (0, 1, 0, 1, 0), (1, 1, 1, 1, 1))\n         sample_weight = (1., 1.5, 2., 2.5)\n         result = mse_obj(y_true, y_pred, sample_weight=sample_weight)\n         np.isclose(0.54285, K.eval(result), atol=1e-5)\n+\n+\n+class TestHinge(object):\n+\n+    def test_config(self):\n+        hinge_obj = metrics.Hinge(name='hinge', dtype='int32')\n+        assert hinge_obj.name == 'hinge'\n+        assert hinge_obj.dtype == 'int32'\n+\n+        # Check save and restore config\n+        hinge_obj2 = metrics.Hinge.from_config(hinge_obj.get_config())\n+        assert hinge_obj2.name == 'hinge'\n+        assert hinge_obj2.dtype == 'int32'\n+\n+    def test_unweighted(self):\n+        hinge_obj = metrics.Hinge()\n+        y_true = K.constant([[0, 1, 0, 1], [0, 0, 1, 1]])\n+        y_pred = K.constant([[-0.3, 0.2, -0.1, 1.6],\n+                             [-0.25, -1., 0.5, 0.6]])\n+\n+        result = hinge_obj(y_true, y_pred)\n+        assert np.allclose(0.506, K.eval(result), atol=1e-3)\n+\n+    def test_weighted(self):\n+        hinge_obj = metrics.Hinge()\n+        y_true = K.constant([[-1, 1, -1, 1], [-1, -1, 1, 1]])\n+        y_pred = K.constant([[-0.3, 0.2, -0.1, 1.6],\n+                             [-0.25, -1., 0.5, 0.6]])\n+        sample_weight = K.constant([1.5, 2.])\n+\n+        result = hinge_obj(y_true, y_pred, sample_weight=sample_weight)\n+        assert np.allclose(0.493, K.eval(result), atol=1e-3)\n+\n+\n+class TestSquaredHinge(object):\n+\n+    def test_config(self):\n+        sq_hinge_obj = metrics.SquaredHinge(name='sq_hinge', dtype='int32')\n+        assert sq_hinge_obj.name == 'sq_hinge'\n+        assert sq_hinge_obj.dtype == 'int32'\n+\n+        # Check save and restore config\n+        sq_hinge_obj2 = metrics.SquaredHinge.from_config(\n+            sq_hinge_obj.get_config())\n+        assert sq_hinge_obj2.name == 'sq_hinge'\n+        assert sq_hinge_obj2.dtype == 'int32'\n+\n+    def test_unweighted(self):\n+        sq_hinge_obj = metrics.SquaredHinge()\n+        y_true = K.constant([[0, 1, 0, 1], [0, 0, 1, 1]])\n+        y_pred = K.constant([[-0.3, 0.2, -0.1, 1.6],\n+                             [-0.25, -1., 0.5, 0.6]])\n+\n+        result = sq_hinge_obj(y_true, y_pred)\n+        assert np.allclose(0.364, K.eval(result), atol=1e-3)\n+\n+    def test_weighted(self):\n+        sq_hinge_obj = metrics.SquaredHinge()\n+        y_true = K.constant([[-1, 1, -1, 1], [-1, -1, 1, 1]])\n+        y_pred = K.constant([[-0.3, 0.2, -0.1, 1.6],\n+                             [-0.25, -1., 0.5, 0.6]])\n+        sample_weight = K.constant([1.5, 2.])\n+\n+        result = sq_hinge_obj(y_true, y_pred, sample_weight=sample_weight)\n+        assert np.allclose(0.347, K.eval(result), atol=1e-3)\n+\n+\n+class TestCategoricalHinge(object):\n+\n+    def test_config(self):\n+        cat_hinge_obj = metrics.CategoricalHinge(\n+            name='cat_hinge', dtype='int32')\n+        assert cat_hinge_obj.name == 'cat_hinge'\n+        assert cat_hinge_obj.dtype == 'int32'\n+\n+        # Check save and restore config\n+        cat_hinge_obj2 = metrics.CategoricalHinge.from_config(\n+            cat_hinge_obj.get_config())\n+        assert cat_hinge_obj2.name == 'cat_hinge'\n+        assert cat_hinge_obj2.dtype == 'int32'\n+\n+    def test_unweighted(self):\n+        cat_hinge_obj = metrics.CategoricalHinge()\n+        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n+                             (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n+        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n+                             (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n+\n+        result = cat_hinge_obj(y_true, y_pred)\n+        assert np.allclose(0.5, K.eval(result), atol=1e-5)\n+\n+    def test_weighted(self):\n+        cat_hinge_obj = metrics.CategoricalHinge()\n+        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n+                             (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n+        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n+                             (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n+        sample_weight = K.constant((1., 1.5, 2., 2.5))\n+        result = cat_hinge_obj(y_true, y_pred, sample_weight=sample_weight)\n+        assert np.allclose(0.5, K.eval(result), atol=1e-5)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#73106d57c7580223cf9af83a3d23e94888ef7a49", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 24 | Churn Cumulative: 855 | Contributors (this commit): 9 | Commits (past 90d): 8 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -633,10 +633,12 @@ def mean_squared_logarithmic_error(y_true, y_pred):\n \n \n def squared_hinge(y_true, y_pred):\n+    y_true = _maybe_convert_labels(y_true)\n     return K.mean(K.square(K.maximum(1. - y_true * y_pred, 0.)), axis=-1)\n \n \n def hinge(y_true, y_pred):\n+    y_true = _maybe_convert_labels(y_true)\n     return K.mean(K.maximum(1. - y_true * y_pred, 0.), axis=-1)\n \n \n@@ -722,6 +724,28 @@ def cosine_proximity(y_true, y_pred):\n     return -K.sum(y_true * y_pred, axis=-1)\n \n \n+def _maybe_convert_labels(y_true):\n+    \"\"\"Converts binary labels into -1/1.\"\"\"\n+    are_zeros = K.equal(y_true, 0)\n+    are_ones = K.equal(y_true, 1)\n+\n+    are_zeros = K.expand_dims(are_zeros, 0)\n+    are_ones = K.expand_dims(are_ones, 0)\n+\n+    are_different = K.concatenate([are_zeros, are_ones], axis=0)\n+    are_different = K.any(are_different, axis=0)\n+    is_binary = K.all(are_different)\n+\n+    def _convert_binary_labels():\n+        # Convert the binary labels to -1 or 1.\n+        return 2. * y_true - 1.\n+\n+    updated_y_true = K.switch(is_binary,\n+                              _convert_binary_labels,\n+                              lambda: y_true)\n+    return updated_y_true\n+\n+\n # Aliases.\n \n mse = MSE = mean_squared_error\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#680be2e1b782616982338da1bca5158259e94e78", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 643 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 15 | Complexity Δ (Sum/Max): 57/42 | Churn Δ: 643 | Churn Cumulative: 3259 | Contributors (this commit): 23 | Commits (past 90d): 28 | Contributors (cumulative): 32 | DMM Complexity: 1.0\n\nDIFF:\n@@ -618,6 +618,186 @@ class SparseTopKCategoricalAccuracy(MeanMetricWrapper):\n             sparse_top_k_categorical_accuracy, name, dtype=dtype, k=k)\n \n \n+class LogCoshError(MeanMetricWrapper):\n+    \"\"\"Computes the logarithm of the hyperbolic cosine of the prediction error.\n+\n+    `metric = log((exp(x) + exp(-x))/2)`, where x is the error (y_pred - y_true)\n+\n+    Usage with the compile API:\n+\n+    ```python\n+    model = keras.Model(inputs, outputs)\n+    model.compile('sgd', metrics=[keras.metrics.LogCoshError()])\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, name='logcosh', dtype=None):\n+        super(LogCoshError, self).__init__(logcosh, name, dtype=dtype)\n+\n+\n+class Poisson(MeanMetricWrapper):\n+    \"\"\"Computes the Poisson metric between `y_true` and `y_pred`.\n+\n+    `metric = y_pred - y_true * log(y_pred)`\n+\n+    Usage with the compile API:\n+\n+    ```python\n+    model = keras.Model(inputs, outputs)\n+    model.compile('sgd', metrics=[keras.metrics.Poisson()])\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, name='poisson', dtype=None):\n+        super(Poisson, self).__init__(poisson, name, dtype=dtype)\n+\n+\n+class KLDivergence(MeanMetricWrapper):\n+    \"\"\"Computes Kullback-Leibler divergence metric between `y_true` and `y_pred`.\n+\n+    `metric = y_true * log(y_true / y_pred)`\n+\n+    Usage with the compile API:\n+\n+    ```python\n+    model = keras.Model(inputs, outputs)\n+    model.compile('sgd', metrics=[keras.metrics.KLDivergence()])\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, name='kullback_leibler_divergence', dtype=None):\n+        super(KLDivergence, self).__init__(\n+            kullback_leibler_divergence, name, dtype=dtype)\n+\n+\n+class BinaryCrossentropy(MeanMetricWrapper):\n+    \"\"\"Computes the crossentropy metric between the labels and predictions.\n+\n+    This is the crossentropy metric class to be used when there are only two\n+    label classes (0 and 1).\n+\n+    Usage with the compile API:\n+\n+    ```python\n+    model = keras.Model(inputs, outputs)\n+    model.compile(\n+      'sgd',\n+      loss='mse',\n+      metrics=[keras.metrics.BinaryCrossentropy()])\n+    ```\n+\n+    # Arguments\n+        name: (Optional) string name of the metric instance.\n+        dtype: (Optional) data type of the metric result.\n+        from_logits: (Optional )Whether output is expected to be a logits tensor.\n+            By default, we consider that output encodes a probability distribution.\n+        label_smoothing: (Optional) Float in [0, 1]. When > 0, label values are\n+            smoothed, meaning the confidence on label values are relaxed.\n+            e.g. `label_smoothing=0.2` means that we will use a value of `0.1` for\n+            label `0` and `0.9` for label `1`\"\n+    \"\"\"\n+\n+    def __init__(self,\n+                 name='binary_crossentropy',\n+                 dtype=None,\n+                 from_logits=False,\n+                 label_smoothing=0):\n+        super(BinaryCrossentropy, self).__init__(\n+            binary_crossentropy,\n+            name,\n+            dtype=dtype,\n+            from_logits=from_logits,\n+            label_smoothing=label_smoothing)\n+\n+\n+class CategoricalCrossentropy(MeanMetricWrapper):\n+    \"\"\"Computes the crossentropy metric between the labels and predictions.\n+\n+    This is the crossentropy metric class to be used when there are multiple\n+    label classes (2 or more). Here we assume that labels are given as a `one_hot`\n+    representation. eg., When labels values are [2, 0, 1],\n+    `y_true` = [[0, 0, 1], [1, 0, 0], [0, 1, 0]].\n+\n+    Usage with the compile API:\n+\n+    ```python\n+    model = keras.Model(inputs, outputs)\n+    model.compile(\n+    'sgd',\n+    loss='mse',\n+    metrics=[keras.metrics.CategoricalCrossentropy()])\n+    ```\n+\n+    # Arguments\n+        name: (Optional) string name of the metric instance.\n+        dtype: (Optional) data type of the metric result.\n+        from_logits: (Optional ) Whether `y_pred` is expected to be a logits tensor.\n+            By default, we assume that `y_pred` encodes a probability distribution.\n+        label_smoothing: Float in [0, 1]. When > 0, label values are smoothed,\n+            meaning the confidence on label values are relaxed. e.g.\n+            `label_smoothing=0.2` means that we will use a value of `0.1` for label\n+            `0` and `0.9` for label `1`\"\n+    \"\"\"\n+\n+    def __init__(self,\n+                 name='categorical_crossentropy',\n+                 dtype=None,\n+                 from_logits=False,\n+                 label_smoothing=0):\n+        super(CategoricalCrossentropy, self).__init__(\n+            categorical_crossentropy,\n+            name,\n+            dtype=dtype,\n+            from_logits=from_logits,\n+            label_smoothing=label_smoothing)\n+\n+\n+class SparseCategoricalCrossentropy(MeanMetricWrapper):\n+    \"\"\"Computes the crossentropy metric between the labels and predictions.\n+\n+    Use this crossentropy metric when there are two or more label classes.\n+    We expect labels to be provided as integers. If you want to provide labels\n+    using `one-hot` representation, please use `CategoricalCrossentropy` metric.\n+    There should be `# classes` floating point values per feature for `y_pred`\n+    and a single floating point value per feature for `y_true`.\n+\n+    In the snippet below, there is a single floating point value per example for\n+    `y_true` and `# classes` floating pointing values per example for `y_pred`.\n+    The shape of `y_true` is `[batch_size]` and the shape of `y_pred` is\n+    `[batch_size, num_classes]`.\n+\n+    Usage with the compile API:\n+\n+    ```python\n+    model = keras.Model(inputs, outputs)\n+    model.compile(\n+    'sgd',\n+    loss='mse',\n+    metrics=[keras.metrics.SparseCategoricalCrossentropy()])\n+    ```\n+\n+    # Arguments\n+        name: (Optional) string name of the metric instance.\n+        dtype: (Optional) data type of the metric result.\n+        from_logits: (Optional ) Whether `y_pred` is expected to be a logits tensor.\n+            By default, we assume that `y_pred` encodes a probability distribution.\n+        axis: (Optional) Defaults to -1. The dimension along which the metric is\n+            computed.\n+    \"\"\"\n+\n+    def __init__(self,\n+                 name='sparse_categorical_crossentropy',\n+                 dtype=None,\n+                 from_logits=False,\n+                 axis=-1):\n+        super(SparseCategoricalCrossentropy, self).__init__(\n+            sparse_categorical_crossentropy,\n+            name,\n+            dtype=dtype,\n+            from_logits=from_logits,\n+            axis=axis)\n+\n+\n def accuracy(y_true, y_pred):\n     if not K.is_tensor(y_pred):\n         y_pred = K.constant(y_pred)\n\n@@ -519,3 +519,466 @@ class TestSparseTopKCategoricalAccuracy(object):\n         sample_weight = (1.0, 0.0, 1.0)\n         result = a_obj(y_true, y_pred, sample_weight=sample_weight)\n         assert np.allclose(1.0, K.eval(result), atol=1e-5)\n+\n+\n+class TestLogCoshError(object):\n+\n+    def setup(self):\n+        self.y_pred = np.asarray([1, 9, 2, -5, -2, 6]).reshape((2, 3))\n+        self.y_true = np.asarray([4, 8, 12, 8, 1, 3]).reshape((2, 3))\n+        self.batch_size = 6\n+        error = self.y_pred - self.y_true\n+        self.expected_results = np.log((np.exp(error) + np.exp(-error)) / 2)\n+\n+    def test_config(self):\n+        logcosh_obj = metrics.LogCoshError(name='logcosh', dtype='int32')\n+        assert logcosh_obj.name == 'logcosh'\n+        assert logcosh_obj.dtype == 'int32'\n+\n+    def test_unweighted(self):\n+        self.setup()\n+        logcosh_obj = metrics.LogCoshError()\n+\n+        result = logcosh_obj(self.y_true, self.y_pred)\n+        expected_result = np.sum(self.expected_results) / self.batch_size\n+        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n+\n+    def test_weighted(self):\n+        self.setup()\n+        logcosh_obj = metrics.LogCoshError()\n+        sample_weight = [[1.2], [3.4]]\n+        result = logcosh_obj(self.y_true, self.y_pred, sample_weight=sample_weight)\n+\n+        sample_weight = np.asarray([1.2, 1.2, 1.2, 3.4, 3.4, 3.4]).reshape((2, 3))\n+        expected_result = np.multiply(self.expected_results, sample_weight)\n+        expected_result = np.sum(expected_result) / np.sum(sample_weight)\n+        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n+\n+\n+class TestPoisson(object):\n+\n+    def setup(self):\n+        self.y_pred = np.asarray([1, 9, 2, 5, 2, 6]).reshape((2, 3))\n+        self.y_true = np.asarray([4, 8, 12, 8, 1, 3]).reshape((2, 3))\n+        self.batch_size = 6\n+        self.expected_results = self.y_pred - np.multiply(\n+            self.y_true, np.log(self.y_pred))\n+\n+    def test_config(self):\n+        poisson_obj = metrics.Poisson(name='poisson', dtype='int32')\n+        assert poisson_obj.name == 'poisson'\n+        assert poisson_obj.dtype == 'int32'\n+\n+        poisson_obj2 = metrics.Poisson.from_config(poisson_obj.get_config())\n+        assert poisson_obj2.name == 'poisson'\n+        assert poisson_obj2.dtype == 'int32'\n+\n+    def test_unweighted(self):\n+        self.setup()\n+        poisson_obj = metrics.Poisson()\n+\n+        result = poisson_obj(self.y_true, self.y_pred)\n+        expected_result = np.sum(self.expected_results) / self.batch_size\n+        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n+\n+    def test_weighted(self):\n+        self.setup()\n+        poisson_obj = metrics.Poisson()\n+        sample_weight = [[1.2], [3.4]]\n+\n+        result = poisson_obj(self.y_true, self.y_pred, sample_weight=sample_weight)\n+        sample_weight = np.asarray([1.2, 1.2, 1.2, 3.4, 3.4, 3.4]).reshape((2, 3))\n+        expected_result = np.multiply(self.expected_results, sample_weight)\n+        expected_result = np.sum(expected_result) / np.sum(sample_weight)\n+        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n+\n+\n+class TestKLDivergence(object):\n+\n+    def setup(self):\n+        self.y_pred = np.asarray([.4, .9, .12, .36, .3, .4]).reshape((2, 3))\n+        self.y_true = np.asarray([.5, .8, .12, .7, .43, .8]).reshape((2, 3))\n+        self.batch_size = 2\n+        self.expected_results = np.multiply(\n+            self.y_true, np.log(self.y_true / self.y_pred))\n+\n+    def test_config(self):\n+        k_obj = metrics.KLDivergence(name='kld', dtype='int32')\n+        assert k_obj.name == 'kld'\n+        assert k_obj.dtype == 'int32'\n+\n+        k_obj2 = metrics.KLDivergence.from_config(k_obj.get_config())\n+        assert k_obj2.name == 'kld'\n+        assert k_obj2.dtype == 'int32'\n+\n+    def test_unweighted(self):\n+        self.setup()\n+        k_obj = metrics.KLDivergence()\n+\n+        result = k_obj(self.y_true, self.y_pred)\n+        expected_result = np.sum(self.expected_results) / self.batch_size\n+        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n+\n+    def test_weighted(self):\n+        self.setup()\n+        k_obj = metrics.KLDivergence()\n+        sample_weight = [[1.2], [3.4]]\n+        result = k_obj(self.y_true, self.y_pred, sample_weight=sample_weight)\n+\n+        sample_weight = np.asarray([1.2, 1.2, 1.2, 3.4, 3.4, 3.4]).reshape((2, 3))\n+        expected_result = np.multiply(self.expected_results, sample_weight)\n+        expected_result = np.sum(expected_result) / (1.2 + 3.4)\n+        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n+\n+\n+class TestBinaryCrossentropy(object):\n+\n+    def test_config(self):\n+        bce_obj = metrics.BinaryCrossentropy(\n+            name='bce', dtype='int32', label_smoothing=0.2)\n+        assert bce_obj.name == 'bce'\n+        assert bce_obj.dtype == 'int32'\n+\n+        old_config = bce_obj.get_config()\n+        assert np.allclose(old_config['label_smoothing'], 0.2, atol=1e-3)\n+\n+    def test_unweighted(self):\n+        bce_obj = metrics.BinaryCrossentropy()\n+        y_true = np.asarray([1, 0, 1, 0]).reshape([2, 2])\n+        y_pred = np.asarray([1, 1, 1, 0], dtype=np.float32).reshape([2, 2])\n+        result = bce_obj(y_true, y_pred)\n+\n+        # EPSILON = 1e-7, y = y_true, y` = y_pred, Y_MAX = 0.9999999\n+        # y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON)\n+        # y` = [Y_MAX, Y_MAX, Y_MAX, EPSILON]\n+\n+        # Metric = -(y log(y` + EPSILON) + (1 - y) log(1 - y` + EPSILON))\n+        #        = [-log(Y_MAX + EPSILON), -log(1 - Y_MAX + EPSILON),\n+        #           -log(Y_MAX + EPSILON), -log(1)]\n+        #        = [(0 + 15.33) / 2, (0 + 0) / 2]\n+        # Reduced metric = 7.665 / 2\n+\n+        assert np.allclose(K.eval(result), 3.833, atol=1e-3)\n+\n+    def test_unweighted_with_logits(self):\n+        bce_obj = metrics.BinaryCrossentropy(from_logits=True)\n+\n+        y_true = [[1, 0, 1], [0, 1, 1]]\n+        y_pred = [[100.0, -100.0, 100.0], [100.0, 100.0, -100.0]]\n+        result = bce_obj(y_true, y_pred)\n+\n+        # Metric = max(x, 0) - x * z + log(1 + exp(-abs(x)))\n+        #              (where x = logits and z = y_true)\n+        #        = [((100 - 100 * 1 + log(1 + exp(-100))) +\n+        #            (0 + 100 * 0 + log(1 + exp(-100))) +\n+        #            (100 - 100 * 1 + log(1 + exp(-100))),\n+        #           ((100 - 100 * 0 + log(1 + exp(-100))) +\n+        #            (100 - 100 * 1 + log(1 + exp(-100))) +\n+        #            (0 + 100 * 1 + log(1 + exp(-100))))]\n+        #        = [(0 + 0 + 0) / 3, 200 / 3]\n+        # Reduced metric = (0 + 66.666) / 2\n+\n+        assert np.allclose(K.eval(result), 33.333, atol=1e-3)\n+\n+    def test_weighted(self):\n+        bce_obj = metrics.BinaryCrossentropy()\n+        y_true = np.asarray([1, 0, 1, 0]).reshape([2, 2])\n+        y_pred = np.asarray([1, 1, 1, 0], dtype=np.float32).reshape([2, 2])\n+        sample_weight = [1.5, 2.]\n+        result = bce_obj(y_true, y_pred, sample_weight=sample_weight)\n+\n+        # EPSILON = 1e-7, y = y_true, y` = y_pred, Y_MAX = 0.9999999\n+        # y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON)\n+        # y` = [Y_MAX, Y_MAX, Y_MAX, EPSILON]\n+\n+        # Metric = -(y log(y` + EPSILON) + (1 - y) log(1 - y` + EPSILON))\n+        #        = [-log(Y_MAX + EPSILON), -log(1 - Y_MAX + EPSILON),\n+        #           -log(Y_MAX + EPSILON), -log(1)]\n+        #        = [(0 + 15.33) / 2, (0 + 0) / 2]\n+        # Weighted metric = [7.665 * 1.5, 0]\n+        # Reduced metric = 7.665 * 1.5 / (1.5 + 2)\n+\n+        assert np.allclose(K.eval(result), 3.285, atol=1e-3)\n+\n+    def test_weighted_from_logits(self):\n+        bce_obj = metrics.BinaryCrossentropy(from_logits=True)\n+        y_true = [[1, 0, 1], [0, 1, 1]]\n+        y_pred = [[100.0, -100.0, 100.0], [100.0, 100.0, -100.0]]\n+        sample_weight = [2., 2.5]\n+        result = bce_obj(y_true, y_pred, sample_weight=sample_weight)\n+\n+        # Metric = max(x, 0) - x * z + log(1 + exp(-abs(x)))\n+        #              (where x = logits and z = y_true)\n+        #        = [(0 + 0 + 0) / 3, 200 / 3]\n+        # Weighted metric = [0, 66.666 * 2.5]\n+        # Reduced metric = 66.666 * 2.5 / (2 + 2.5)\n+\n+        assert np.allclose(K.eval(result), 37.037, atol=1e-3)\n+\n+    def test_label_smoothing(self):\n+        logits = ((100., -100., -100.))\n+        y_true = ((1, 0, 1))\n+        label_smoothing = 0.1\n+        # Metric: max(x, 0) - x * z + log(1 + exp(-abs(x)))\n+        #             (where x = logits and z = y_true)\n+        # Label smoothing: z' = z * (1 - L) + 0.5L\n+        # After label smoothing, label 1 becomes 1 - 0.5L\n+        #                        label 0 becomes 0.5L\n+        # Applying the above two fns to the given input:\n+        # (100 - 100 * (1 - 0.5 L)  + 0 +\n+        #  0   + 100 * (0.5 L)      + 0 +\n+        #  0   + 100 * (1 - 0.5 L)  + 0) * (1/3)\n+        #  = (100 + 50L) * 1/3\n+        bce_obj = metrics.BinaryCrossentropy(\n+            from_logits=True, label_smoothing=label_smoothing)\n+        result = bce_obj(y_true, logits)\n+        expected_value = (100.0 + 50.0 * label_smoothing) / 3.0\n+        assert np.allclose(expected_value, K.eval(result), atol=1e-3)\n+\n+\n+class TestCategoricalCrossentropy(object):\n+\n+    def test_config(self):\n+        cce_obj = metrics.CategoricalCrossentropy(\n+            name='cce', dtype='int32', label_smoothing=0.2)\n+        assert cce_obj.name == 'cce'\n+        assert cce_obj.dtype == 'int32'\n+\n+        old_config = cce_obj.get_config()\n+        assert np.allclose(old_config['label_smoothing'], 0.2, 1e-3)\n+\n+    def test_unweighted(self):\n+        cce_obj = metrics.CategoricalCrossentropy()\n+\n+        y_true = np.asarray([[0, 1, 0], [0, 0, 1]])\n+        y_pred = np.asarray([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n+        result = cce_obj(y_true, y_pred)\n+\n+        # EPSILON = 1e-7, y = y_true, y` = y_pred\n+        # y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON)\n+        # y` = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n+\n+        # Metric = -sum(y * log(y'), axis = -1)\n+        #        = -((log 0.95), (log 0.1))\n+        #        = [0.051, 2.302]\n+        # Reduced metric = (0.051 + 2.302) / 2\n+\n+        assert np.allclose(K.eval(result), 1.176, atol=1e-3)\n+\n+    def test_unweighted_from_logits(self):\n+        cce_obj = metrics.CategoricalCrossentropy(from_logits=True)\n+\n+        y_true = np.asarray([[0, 1, 0], [0, 0, 1]])\n+        logits = np.asarray([[1, 9, 0], [1, 8, 1]], dtype=np.float32)\n+        result = cce_obj(y_true, logits)\n+\n+        # softmax = exp(logits) / sum(exp(logits), axis=-1)\n+        # xent = -sum(labels * log(softmax), 1)\n+\n+        # exp(logits) = [[2.718, 8103.084, 1], [2.718, 2980.958, 2.718]]\n+        # sum(exp(logits), axis=-1) = [8106.802, 2986.394]\n+        # softmax = [[0.00033, 0.99954, 0.00012], [0.00091, 0.99817, 0.00091]]\n+        # log(softmax) = [[-8.00045, -0.00045, -9.00045],\n+        #                 [-7.00182, -0.00182, -7.00182]]\n+        # labels * log(softmax) = [[0, -0.00045, 0], [0, 0, -7.00182]]\n+        # xent = [0.00045, 7.00182]\n+        # Reduced xent = (0.00045 + 7.00182) / 2\n+\n+        assert np.allclose(K.eval(result), 3.5011, atol=1e-3)\n+\n+    def test_weighted(self):\n+        cce_obj = metrics.CategoricalCrossentropy()\n+\n+        y_true = np.asarray([[0, 1, 0], [0, 0, 1]])\n+        y_pred = np.asarray([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n+        sample_weight = [1.5, 2.]\n+        result = cce_obj(y_true, y_pred, sample_weight=sample_weight)\n+\n+        # EPSILON = 1e-7, y = y_true, y` = y_pred\n+        # y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON)\n+        # y` = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n+\n+        # Metric = -sum(y * log(y'), axis = -1)\n+        #        = -((log 0.95), (log 0.1))\n+        #        = [0.051, 2.302]\n+        # Weighted metric = [0.051 * 1.5, 2.302 * 2.]\n+        # Reduced metric = (0.051 * 1.5 + 2.302 * 2.) / 3.5\n+\n+        assert np.allclose(K.eval(result), 1.338, atol=1e-3)\n+\n+    def test_weighted_from_logits(self):\n+        cce_obj = metrics.CategoricalCrossentropy(from_logits=True)\n+\n+        y_true = np.asarray([[0, 1, 0], [0, 0, 1]])\n+        logits = np.asarray([[1, 9, 0], [1, 8, 1]], dtype=np.float32)\n+        sample_weight = [1.5, 2.]\n+        result = cce_obj(y_true, logits, sample_weight=sample_weight)\n+\n+        # softmax = exp(logits) / sum(exp(logits), axis=-1)\n+        # xent = -sum(labels * log(softmax), 1)\n+        # xent = [0.00045, 7.00182]\n+        # weighted xent = [0.000675, 14.00364]\n+        # Reduced xent = (0.000675 + 14.00364) / (1.5 + 2)\n+\n+        assert np.allclose(K.eval(result), 4.0012, atol=1e-3)\n+\n+    def test_label_smoothing(self):\n+        y_true = np.asarray([[0, 1, 0], [0, 0, 1]])\n+        logits = np.asarray([[1, 9, 0], [1, 8, 1]], dtype=np.float32)\n+        label_smoothing = 0.1\n+\n+        # Label smoothing: z' = z * (1 - L) + L/n,\n+        #     where L = label smoothing value and n = num classes\n+        # Label value 1 becomes: 1 - L + L/n\n+        # Label value 0 becomes: L/n\n+        # y_true with label_smoothing = [[0.0333, 0.9333, 0.0333],\n+        #                               [0.0333, 0.0333, 0.9333]]\n+\n+        # softmax = exp(logits) / sum(exp(logits), axis=-1)\n+        # xent = -sum(labels * log(softmax), 1)\n+        # log(softmax) = [[-8.00045, -0.00045, -9.00045],\n+        #                 [-7.00182, -0.00182, -7.00182]]\n+        # labels * log(softmax) = [[-0.26641, -0.00042, -0.29971],\n+        #                          [-0.23316, -0.00006, -6.53479]]\n+        # xent = [0.56654, 6.76801]\n+        # Reduced xent = (0.56654 + 6.76801) / 2\n+\n+        cce_obj = metrics.CategoricalCrossentropy(\n+            from_logits=True, label_smoothing=label_smoothing)\n+        loss = cce_obj(y_true, logits)\n+        assert np.allclose(K.eval(loss), 3.667, atol=1e-3)\n+\n+\n+class TestSparseCategoricalCrossentropy(object):\n+\n+    def test_config(self):\n+        scce_obj = metrics.SparseCategoricalCrossentropy(\n+            name='scce', dtype='int32')\n+        assert scce_obj.name == 'scce'\n+        assert scce_obj.dtype == 'int32'\n+\n+    def test_unweighted(self):\n+        scce_obj = metrics.SparseCategoricalCrossentropy()\n+\n+        y_true = np.asarray([1, 2])\n+        y_pred = np.asarray([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n+        result = scce_obj(y_true, y_pred)\n+\n+        # EPSILON = 1e-7, y = y_true, y` = y_pred\n+        # y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON)\n+        # y` = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n+        # logits = log(y`) =  [[-2.9957, -0.0513, -16.1181],\n+        #                      [-2.3026, -0.2231, -2.3026]]\n+\n+        # softmax = exp(logits) / sum(exp(logits), axis=-1)\n+        # y = one_hot(y) = [[0, 1, 0], [0, 0, 1]]\n+        # xent = -sum(y * log(softmax), 1)\n+\n+        # exp(logits) = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n+        # sum(exp(logits), axis=-1) = [1, 1]\n+        # softmax = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n+        # log(softmax) = [[-2.9957, -0.0513, -16.1181],\n+        #                 [-2.3026, -0.2231, -2.3026]]\n+        # y * log(softmax) = [[0, -0.0513, 0], [0, 0, -2.3026]]\n+        # xent = [0.0513, 2.3026]\n+        # Reduced xent = (0.0513 + 2.3026) / 2\n+\n+        assert np.allclose(K.eval(result), 1.176, atol=1e-3)\n+\n+    def test_unweighted_from_logits(self):\n+        scce_obj = metrics.SparseCategoricalCrossentropy(from_logits=True)\n+\n+        y_true = np.asarray([1, 2])\n+        logits = np.asarray([[1, 9, 0], [1, 8, 1]], dtype=np.float32)\n+        result = scce_obj(y_true, logits)\n+\n+        # softmax = exp(logits) / sum(exp(logits), axis=-1)\n+        # y_true = one_hot(y_true) = [[0, 1, 0], [0, 0, 1]]\n+        # xent = -sum(y_true * log(softmax), 1)\n+\n+        # exp(logits) = [[2.718, 8103.084, 1], [2.718, 2980.958, 2.718]]\n+        # sum(exp(logits), axis=-1) = [8106.802, 2986.394]\n+        # softmax = [[0.00033, 0.99954, 0.00012], [0.00091, 0.99817, 0.00091]]\n+        # log(softmax) = [[-8.00045, -0.00045, -9.00045],\n+        #                 [-7.00182, -0.00182, -7.00182]]\n+        # y_true * log(softmax) = [[0, -0.00045, 0], [0, 0, -7.00182]]\n+        # xent = [0.00045, 7.00182]\n+        # Reduced xent = (0.00045 + 7.00182) / 2\n+\n+        assert np.allclose(K.eval(result), 3.5011, atol=1e-3)\n+\n+    def test_weighted(self):\n+        scce_obj = metrics.SparseCategoricalCrossentropy()\n+\n+        y_true = np.asarray([1, 2])\n+        y_pred = np.asarray([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n+        sample_weight = [1.5, 2.]\n+        result = scce_obj(y_true, y_pred, sample_weight=sample_weight)\n+\n+        # EPSILON = 1e-7, y = y_true, y` = y_pred\n+        # y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON)\n+        # y` = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n+        # logits = log(y`) =  [[-2.9957, -0.0513, -16.1181],\n+        #                      [-2.3026, -0.2231, -2.3026]]\n+\n+        # softmax = exp(logits) / sum(exp(logits), axis=-1)\n+        # y = one_hot(y) = [[0, 1, 0], [0, 0, 1]]\n+        # xent = -sum(y * log(softmax), 1)\n+\n+        # exp(logits) = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n+        # sum(exp(logits), axis=-1) = [1, 1]\n+        # softmax = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n+        # log(softmax) = [[-2.9957, -0.0513, -16.1181],\n+        #                 [-2.3026, -0.2231, -2.3026]]\n+        # y * log(softmax) = [[0, -0.0513, 0], [0, 0, -2.3026]]\n+        # xent = [0.0513, 2.3026]\n+        # Weighted xent = [0.051 * 1.5, 2.302 * 2.]\n+        # Reduced xent = (0.051 * 1.5 + 2.302 * 2.) / 3.5\n+\n+        assert np.allclose(K.eval(result), 1.338, atol=1e-3)\n+\n+    def test_weighted_from_logits(self):\n+        scce_obj = metrics.SparseCategoricalCrossentropy(from_logits=True)\n+        y_true = np.asarray([1, 2])\n+        logits = np.asarray([[1, 9, 0], [1, 8, 1]], dtype=np.float32)\n+        sample_weight = [1.5, 2.]\n+        result = scce_obj(y_true, logits, sample_weight=sample_weight)\n+\n+        # softmax = exp(logits) / sum(exp(logits), axis=-1)\n+        # y_true = one_hot(y_true) = [[0, 1, 0], [0, 0, 1]]\n+        # xent = -sum(y_true * log(softmax), 1)\n+        # xent = [0.00045, 7.00182]\n+        # weighted xent = [0.000675, 14.00364]\n+        # Reduced xent = (0.000675 + 14.00364) / (1.5 + 2)\n+\n+        assert np.allclose(K.eval(result), 4.0012, atol=1e-3)\n+\n+    def test_axis(self):\n+        scce_obj = metrics.SparseCategoricalCrossentropy(axis=0)\n+\n+        y_true = np.asarray([1, 2])\n+        y_pred = np.asarray([[0.05, 0.1], [0.95, 0.8], [0, 0.1]])\n+        result = scce_obj(y_true, y_pred)\n+\n+        # EPSILON = 1e-7, y = y_true, y` = y_pred\n+        # y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON)\n+        # y` = [[0.05, 0.1], [0.95, 0.8], [EPSILON, 0.1]]\n+        # logits = log(y`) =  [[-2.9957, -2.3026],\n+        #                      [-0.0513, -0.2231],\n+        #                      [-16.1181, -2.3026]]\n+\n+        # softmax = exp(logits) / sum(exp(logits), axis=-1)\n+        # y = one_hot(y) = [[0, 0], [1, 0], [0, 1]]\n+        # xent = -sum(y * log(softmax), 1)\n+\n+        # exp(logits) = [[0.05, 0.1], [0.95, 0.8], [EPSILON, 0.1]]\n+        # sum(exp(logits)) = [1, 1]\n+        # softmax = [[0.05, 0.1], [0.95, 0.8], [EPSILON, 0.1]]\n+        # log(softmax) = [[-2.9957, -2.3026],\n+        #                 [-0.0513, -0.2231],\n+        #                 [-16.1181, -2.3026]]\n+        # y * log(softmax) = [[0, 0], [-0.0513, 0], [0, -2.3026]]\n+        # xent = [0.0513, 2.3026]\n+        # Reduced xent = (0.0513 + 2.3026) / 2\n+\n+        assert np.allclose(K.eval(result), 1.176, atol=1e-3)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#38e3831586d09c433155c5da684eaca4b63c46e7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 375 | Lines Deleted: 186 | Files Changed: 3 | Hunks: 21 | Methods Changed: 20 | Complexity Δ (Sum/Max): 29/21 | Churn Δ: 561 | Churn Cumulative: 4675 | Contributors (this commit): 28 | Commits (past 90d): 39 | Contributors (cumulative): 41 | DMM Complexity: 1.0\n\nDIFF:\n@@ -718,10 +718,10 @@ def poisson(y_true, y_pred):\n     return K.mean(y_pred - y_true * K.log(y_pred + K.epsilon()), axis=-1)\n \n \n-def cosine_proximity(y_true, y_pred):\n-    y_true = K.l2_normalize(y_true, axis=-1)\n-    y_pred = K.l2_normalize(y_pred, axis=-1)\n-    return -K.sum(y_true * y_pred, axis=-1)\n+def cosine_proximity(y_true, y_pred, axis=-1):\n+    y_true = K.l2_normalize(y_true, axis=axis)\n+    y_pred = K.l2_normalize(y_pred, axis=axis)\n+    return - K.sum(y_true * y_pred, axis=axis)\n \n \n def _maybe_convert_labels(y_true):\n@@ -753,7 +753,7 @@ mae = MAE = mean_absolute_error\n mape = MAPE = mean_absolute_percentage_error\n msle = MSLE = mean_squared_logarithmic_error\n kld = KLD = kullback_leibler_divergence\n-cosine = cosine_proximity\n+cosine = cosine_similarity = cosine_proximity\n \n \n def is_categorical_crossentropy(loss):\n\n@@ -24,6 +24,7 @@ from .losses import binary_crossentropy\n from .losses import kullback_leibler_divergence\n from .losses import poisson\n from .losses import cosine_proximity\n+from .losses import cosine_similarity\n from .utils import losses_utils\n from .utils import metrics_utils\n from .utils.generic_utils import deserialize_keras_object\n@@ -670,6 +671,150 @@ class KLDivergence(MeanMetricWrapper):\n             kullback_leibler_divergence, name, dtype=dtype)\n \n \n+class CosineSimilarity(MeanMetricWrapper):\n+    \"\"\"Computes the cosine similarity between the labels and predictions.\n+\n+    cosine similarity = (a . b) / ||a|| ||b||\n+    [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)\n+    For example, if `y_true` is [0, 1, 1], and `y_pred` is [1, 0, 1], the cosine\n+    similarity is 0.5.\n+\n+    This metric keeps the average cosine similarity between `predictions` and\n+    `labels` over a stream of data.\n+\n+    # Arguments\n+        name: (Optional) string name of the metric instance.\n+        dtype: (Optional) data type of the metric result.\n+        axis: (Optional) Defaults to -1. The dimension along which the cosine\n+        similarity is computed.\n+\n+    Usage with the `compile` API:\n+\n+    ```python\n+    model = keras.Model(inputs, outputs)\n+    model.compile(\n+      'sgd',\n+      loss='mse',\n+      metrics=[keras.metrics.CosineSimilarity(axis=1)])\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, name='cosine_similarity', dtype=None, axis=-1):\n+        super(CosineSimilarity, self).__init__(\n+            cosine_similarity, name, dtype=dtype, axis=axis)\n+\n+\n+class MeanAbsoluteError(MeanMetricWrapper):\n+    \"\"\"Computes the mean absolute error between the labels and predictions.\n+\n+    Usage with the `compile` API:\n+\n+    ```python\n+    model = keras.Model(inputs, outputs)\n+    model.compile('sgd', metrics=[keras.metrics.MeanAbsoluteError()])\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, name='mean_absolute_error', dtype=None):\n+        super(MeanAbsoluteError, self).__init__(\n+            mean_absolute_error, name, dtype=dtype)\n+\n+\n+class MeanAbsolutePercentageError(MeanMetricWrapper):\n+    \"\"\"Computes the mean absolute percentage error between `y_true` and `y_pred`.\n+\n+    For example, if `y_true` is [0., 0., 1., 1.], and `y_pred` is [1., 1., 1., 0.]\n+    the mean absolute percentage error is 5e+08.\n+\n+    Usage:\n+\n+    ```python\n+    m = keras.metrics.MeanAbsolutePercentageError()\n+    m.update_state([0., 0., 1., 1.], [1., 1., 1., 0.])\n+    # Final result: 5e+08\n+    ```\n+\n+    Usage with the `compile` API:\n+\n+    ```python\n+    model = keras.Model(inputs, outputs)\n+    model.compile('sgd', metrics=[keras.metrics.MeanAbsolutePercentageError()])\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, name='mean_absolute_percentage_error', dtype=None):\n+        super(MeanAbsolutePercentageError, self).__init__(\n+            mean_absolute_percentage_error, name, dtype=dtype)\n+\n+\n+class MeanSquaredError(MeanMetricWrapper):\n+    \"\"\"Computes the mean squared error between `y_true` and `y_pred`.\n+\n+    Usage with the `compile` API:\n+\n+    ```python\n+    model = keras.Model(inputs, outputs)\n+    model.compile('sgd', metrics=[keras.metrics.MeanSquaredError()])\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, name='mean_squared_error', dtype=None):\n+        super(MeanSquaredError, self).__init__(\n+            mean_squared_error, name, dtype=dtype)\n+\n+\n+class MeanSquaredLogarithmicError(MeanMetricWrapper):\n+    \"\"\"Computes the mean squared logarithmic error between `y_true` and `y_pred`.\n+\n+    Usage with the `compile` API:\n+\n+    ```python\n+    model = keras.Model(inputs, outputs)\n+    model.compile('sgd', metrics=[keras.metrics.MeanSquaredLogarithmicError()])\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, name='mean_squared_logarithmic_error', dtype=None):\n+        super(MeanSquaredLogarithmicError, self).__init__(\n+            mean_squared_logarithmic_error, name, dtype=dtype)\n+\n+\n+class RootMeanSquaredError(Mean):\n+    \"\"\"Computes root mean squared error metric between `y_true` and `y_pred`.\n+\n+    Usage with the `compile` API:\n+\n+    ```python\n+    model = keras.Model(inputs, outputs)\n+    model.compile('sgd', metrics=[keras.metrics.RootMeanSquaredError()])\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, name='root_mean_squared_error', dtype=None):\n+        super(RootMeanSquaredError, self).__init__(name, dtype=dtype)\n+\n+    def update_state(self, y_true, y_pred, sample_weight=None):\n+        \"\"\"Accumulates root mean squared error statistics.\n+\n+        # Arguments\n+            y_true: The ground truth values.\n+            y_pred: The predicted values.\n+            sample_weight: Optional weighting of each example. Defaults to 1.\n+                Can be a `Tensor` whose rank is either 0,\n+                or the same rank as `y_true`,\n+                and must be broadcastable to `y_true`.\n+\n+        # Returns\n+            List of update ops.\n+        \"\"\"\n+        error_sq = K.square(y_pred - y_true)\n+        return super(RootMeanSquaredError, self).update_state(\n+            error_sq, sample_weight=sample_weight)\n+\n+    def result(self):\n+        return K.sqrt(self.total / self.count)\n+\n+\n class BinaryCrossentropy(MeanMetricWrapper):\n     \"\"\"Computes the crossentropy metric between the labels and predictions.\n \n\n@@ -1,6 +1,7 @@\n \"\"\"Tests for Keras metrics classes.\"\"\"\n import pytest\n import numpy as np\n+import math\n \n from keras import metrics\n from keras import backend as K\n@@ -631,6 +632,230 @@ class TestKLDivergence(object):\n         assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n \n \n+class TestCosineSimilarity(object):\n+\n+    def l2_norm(self, x, axis):\n+        epsilon = 1e-12\n+        square_sum = np.sum(np.square(x), axis=axis, keepdims=True)\n+        x_inv_norm = 1 / np.sqrt(np.maximum(square_sum, epsilon))\n+        return np.multiply(x, x_inv_norm)\n+\n+    def setup(self, axis=1):\n+        self.np_y_true = np.asarray([[1, 9, 2], [-5, -2, 6]], dtype=np.float32)\n+        self.np_y_pred = np.asarray([[4, 8, 12], [8, 1, 3]], dtype=np.float32)\n+\n+        y_true = self.l2_norm(self.np_y_true, axis)\n+        y_pred = self.l2_norm(self.np_y_pred, axis)\n+        self.expected_loss = np.sum(np.multiply(y_true, y_pred), axis=(axis,))\n+\n+        self.y_true = K.constant(self.np_y_true)\n+        self.y_pred = K.constant(self.np_y_pred)\n+\n+    def test_config(self):\n+        cosine_obj = metrics.CosineSimilarity(\n+            axis=2, name='my_cos', dtype='int32')\n+        assert cosine_obj.name == 'my_cos'\n+        assert cosine_obj.dtype == 'int32'\n+\n+        # Check save and restore config\n+        cosine_obj2 = metrics.CosineSimilarity.from_config(cosine_obj.get_config())\n+        assert cosine_obj2.name == 'my_cos'\n+        assert cosine_obj2.dtype == 'int32'\n+\n+    def test_unweighted(self):\n+        self.setup()\n+        cosine_obj = metrics.CosineSimilarity()\n+        loss = cosine_obj(self.y_true, self.y_pred)\n+        expected_loss = np.mean(self.expected_loss)\n+        assert np.allclose(K.eval(loss), expected_loss, 3)\n+\n+    def test_weighted(self):\n+        self.setup()\n+        cosine_obj = metrics.CosineSimilarity()\n+        sample_weight = np.asarray([1.2, 3.4])\n+        loss = cosine_obj(\n+            self.y_true,\n+            self.y_pred,\n+            sample_weight=K.constant(sample_weight))\n+        expected_loss = np.sum(\n+            self.expected_loss * sample_weight) / np.sum(sample_weight)\n+        assert np.allclose(K.eval(loss), expected_loss, 3)\n+\n+    def test_axis(self):\n+        self.setup(axis=1)\n+        cosine_obj = metrics.CosineSimilarity(axis=1)\n+        loss = cosine_obj(self.y_true, self.y_pred)\n+        expected_loss = np.mean(self.expected_loss)\n+        assert np.allclose(K.eval(loss), expected_loss, 3)\n+\n+\n+class TestMeanAbsoluteError(object):\n+\n+    def test_config(self):\n+        mae_obj = metrics.MeanAbsoluteError(name='my_mae', dtype='int32')\n+        assert mae_obj.name == 'my_mae'\n+        assert mae_obj.dtype == 'int32'\n+\n+        # Check save and restore config\n+        mae_obj2 = metrics.MeanAbsoluteError.from_config(mae_obj.get_config())\n+        assert mae_obj2.name == 'my_mae'\n+        assert mae_obj2.dtype == 'int32'\n+\n+    def test_unweighted(self):\n+        mae_obj = metrics.MeanAbsoluteError()\n+        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n+                             (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n+        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n+                             (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n+\n+        result = mae_obj(y_true, y_pred)\n+        assert np.allclose(0.5, K.eval(result), atol=1e-5)\n+\n+    def test_weighted(self):\n+        mae_obj = metrics.MeanAbsoluteError()\n+        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n+                             (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n+        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n+                             (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n+        sample_weight = K.constant((1., 1.5, 2., 2.5))\n+        result = mae_obj(y_true, y_pred, sample_weight=sample_weight)\n+        assert np.allclose(0.54285, K.eval(result), atol=1e-5)\n+\n+\n+class TestMeanAbsolutePercentageError(object):\n+\n+    def test_config(self):\n+        mape_obj = metrics.MeanAbsolutePercentageError(\n+            name='my_mape', dtype='int32')\n+        assert mape_obj.name == 'my_mape'\n+        assert mape_obj.dtype == 'int32'\n+\n+        # Check save and restore config\n+        mape_obj2 = metrics.MeanAbsolutePercentageError.from_config(\n+            mape_obj.get_config())\n+        assert mape_obj2.name == 'my_mape'\n+        assert mape_obj2.dtype == 'int32'\n+\n+    def test_unweighted(self):\n+        mape_obj = metrics.MeanAbsolutePercentageError()\n+        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n+                            (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n+        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n+                            (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n+\n+        result = mape_obj(y_true, y_pred)\n+        assert np.allclose(35e7, K.eval(result), atol=1e-5)\n+\n+    def test_weighted(self):\n+        mape_obj = metrics.MeanAbsolutePercentageError()\n+        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n+                            (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n+        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n+                            (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n+        sample_weight = K.constant((1., 1.5, 2., 2.5))\n+        result = mape_obj(y_true, y_pred, sample_weight=sample_weight)\n+        assert np.allclose(40e7, K.eval(result), atol=1e-5)\n+\n+\n+class TestMeanSquaredError(object):\n+\n+    def test_config(self):\n+        mse_obj = metrics.MeanSquaredError(name='my_mse', dtype='int32')\n+        assert mse_obj.name == 'my_mse'\n+        assert mse_obj.dtype == 'int32'\n+\n+        # Check save and restore config\n+        mse_obj2 = metrics.MeanSquaredError.from_config(mse_obj.get_config())\n+        assert mse_obj2.name == 'my_mse'\n+        assert mse_obj2.dtype == 'int32'\n+\n+    def test_unweighted(self):\n+        mse_obj = metrics.MeanSquaredError()\n+        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n+                             (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n+        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n+                            (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n+\n+        result = mse_obj(y_true, y_pred)\n+        assert np.allclose(0.5, K.eval(result), atol=1e-5)\n+\n+    def test_weighted(self):\n+        mse_obj = metrics.MeanSquaredError()\n+        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n+                            (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n+        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n+                            (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n+        sample_weight = K.constant((1., 1.5, 2., 2.5))\n+        result = mse_obj(y_true, y_pred, sample_weight=sample_weight)\n+        assert np.allclose(0.54285, K.eval(result), atol=1e-5)\n+\n+\n+class TestMeanSquaredLogarithmicError(object):\n+\n+    def test_config(self):\n+        msle_obj = metrics.MeanSquaredLogarithmicError(\n+            name='my_msle', dtype='int32')\n+        assert msle_obj.name == 'my_msle'\n+        assert msle_obj.dtype == 'int32'\n+\n+        # Check save and restore config\n+        msle_obj2 = metrics.MeanSquaredLogarithmicError.from_config(\n+            msle_obj.get_config())\n+        assert msle_obj2.name == 'my_msle'\n+        assert msle_obj2.dtype == 'int32'\n+\n+    def test_unweighted(self):\n+        msle_obj = metrics.MeanSquaredLogarithmicError()\n+        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n+                            (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n+        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n+                            (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n+\n+        result = msle_obj(y_true, y_pred)\n+        assert np.allclose(0.24022, K.eval(result), atol=1e-5)\n+\n+    def test_weighted(self):\n+        msle_obj = metrics.MeanSquaredLogarithmicError()\n+        y_true = K.constant(((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n+                            (1, 1, 1, 1, 0), (0, 0, 0, 0, 1)))\n+        y_pred = K.constant(((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n+                            (0, 1, 0, 1, 0), (1, 1, 1, 1, 1)))\n+        sample_weight = K.constant((1., 1.5, 2., 2.5))\n+        result = msle_obj(y_true, y_pred, sample_weight=sample_weight)\n+        assert np.allclose(0.26082, K.eval(result), atol=1e-5)\n+\n+\n+class TestRootMeanSquaredError(object):\n+\n+    def test_config(self):\n+        rmse_obj = metrics.RootMeanSquaredError(name='rmse', dtype='int32')\n+        assert rmse_obj.name == 'rmse'\n+        assert rmse_obj.dtype == 'int32'\n+\n+        rmse_obj2 = metrics.RootMeanSquaredError.from_config(rmse_obj.get_config())\n+        assert rmse_obj2.name == 'rmse'\n+        assert rmse_obj2.dtype == 'int32'\n+\n+    def test_unweighted(self):\n+        rmse_obj = metrics.RootMeanSquaredError()\n+        y_true = K.constant((2, 4, 6))\n+        y_pred = K.constant((1, 3, 2))\n+\n+        update_op = rmse_obj(y_true, y_pred)\n+        K.eval(update_op)\n+        result = rmse_obj(y_true, y_pred)\n+        # error = [-1, -1, -4], square(error) = [1, 1, 16], mean = 18/3 = 6\n+        assert np.allclose(math.sqrt(6), K.eval(result), atol=1e-3)\n+\n+    def test_weighted(self):\n+        rmse_obj = metrics.RootMeanSquaredError()\n+        y_true = K.constant((2, 4, 6, 8))\n+        y_pred = K.constant((1, 3, 2, 3))\n+        sample_weight = K.constant((0, 1, 0, 1))\n+        result = rmse_obj(y_true, y_pred, sample_weight=sample_weight)\n+        assert np.allclose(math.sqrt(13), K.eval(result), atol=1e-3)\n+\n+\n class TestBinaryCrossentropy(object):\n \n     def test_config(self):\n@@ -648,16 +873,6 @@ class TestBinaryCrossentropy(object):\n         y_pred = np.asarray([1, 1, 1, 0], dtype=np.float32).reshape([2, 2])\n         result = bce_obj(y_true, y_pred)\n \n-        # EPSILON = 1e-7, y = y_true, y` = y_pred, Y_MAX = 0.9999999\n-        # y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON)\n-        # y` = [Y_MAX, Y_MAX, Y_MAX, EPSILON]\n-\n-        # Metric = -(y log(y` + EPSILON) + (1 - y) log(1 - y` + EPSILON))\n-        #        = [-log(Y_MAX + EPSILON), -log(1 - Y_MAX + EPSILON),\n-        #           -log(Y_MAX + EPSILON), -log(1)]\n-        #        = [(0 + 15.33) / 2, (0 + 0) / 2]\n-        # Reduced metric = 7.665 / 2\n-\n         assert np.allclose(K.eval(result), 3.833, atol=1e-3)\n \n     def test_unweighted_with_logits(self):\n@@ -667,17 +882,6 @@ class TestBinaryCrossentropy(object):\n         y_pred = [[100.0, -100.0, 100.0], [100.0, 100.0, -100.0]]\n         result = bce_obj(y_true, y_pred)\n \n-        # Metric = max(x, 0) - x * z + log(1 + exp(-abs(x)))\n-        #              (where x = logits and z = y_true)\n-        #        = [((100 - 100 * 1 + log(1 + exp(-100))) +\n-        #            (0 + 100 * 0 + log(1 + exp(-100))) +\n-        #            (100 - 100 * 1 + log(1 + exp(-100))),\n-        #           ((100 - 100 * 0 + log(1 + exp(-100))) +\n-        #            (100 - 100 * 1 + log(1 + exp(-100))) +\n-        #            (0 + 100 * 1 + log(1 + exp(-100))))]\n-        #        = [(0 + 0 + 0) / 3, 200 / 3]\n-        # Reduced metric = (0 + 66.666) / 2\n-\n         assert np.allclose(K.eval(result), 33.333, atol=1e-3)\n \n     def test_weighted(self):\n@@ -687,17 +891,6 @@ class TestBinaryCrossentropy(object):\n         sample_weight = [1.5, 2.]\n         result = bce_obj(y_true, y_pred, sample_weight=sample_weight)\n \n-        # EPSILON = 1e-7, y = y_true, y` = y_pred, Y_MAX = 0.9999999\n-        # y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON)\n-        # y` = [Y_MAX, Y_MAX, Y_MAX, EPSILON]\n-\n-        # Metric = -(y log(y` + EPSILON) + (1 - y) log(1 - y` + EPSILON))\n-        #        = [-log(Y_MAX + EPSILON), -log(1 - Y_MAX + EPSILON),\n-        #           -log(Y_MAX + EPSILON), -log(1)]\n-        #        = [(0 + 15.33) / 2, (0 + 0) / 2]\n-        # Weighted metric = [7.665 * 1.5, 0]\n-        # Reduced metric = 7.665 * 1.5 / (1.5 + 2)\n-\n         assert np.allclose(K.eval(result), 3.285, atol=1e-3)\n \n     def test_weighted_from_logits(self):\n@@ -707,28 +900,12 @@ class TestBinaryCrossentropy(object):\n         sample_weight = [2., 2.5]\n         result = bce_obj(y_true, y_pred, sample_weight=sample_weight)\n \n-        # Metric = max(x, 0) - x * z + log(1 + exp(-abs(x)))\n-        #              (where x = logits and z = y_true)\n-        #        = [(0 + 0 + 0) / 3, 200 / 3]\n-        # Weighted metric = [0, 66.666 * 2.5]\n-        # Reduced metric = 66.666 * 2.5 / (2 + 2.5)\n-\n         assert np.allclose(K.eval(result), 37.037, atol=1e-3)\n \n     def test_label_smoothing(self):\n         logits = ((100., -100., -100.))\n         y_true = ((1, 0, 1))\n         label_smoothing = 0.1\n-        # Metric: max(x, 0) - x * z + log(1 + exp(-abs(x)))\n-        #             (where x = logits and z = y_true)\n-        # Label smoothing: z' = z * (1 - L) + 0.5L\n-        # After label smoothing, label 1 becomes 1 - 0.5L\n-        #                        label 0 becomes 0.5L\n-        # Applying the above two fns to the given input:\n-        # (100 - 100 * (1 - 0.5 L)  + 0 +\n-        #  0   + 100 * (0.5 L)      + 0 +\n-        #  0   + 100 * (1 - 0.5 L)  + 0) * (1/3)\n-        #  = (100 + 50L) * 1/3\n         bce_obj = metrics.BinaryCrossentropy(\n             from_logits=True, label_smoothing=label_smoothing)\n         result = bce_obj(y_true, logits)\n@@ -754,15 +931,6 @@ class TestCategoricalCrossentropy(object):\n         y_pred = np.asarray([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n         result = cce_obj(y_true, y_pred)\n \n-        # EPSILON = 1e-7, y = y_true, y` = y_pred\n-        # y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON)\n-        # y` = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n-\n-        # Metric = -sum(y * log(y'), axis = -1)\n-        #        = -((log 0.95), (log 0.1))\n-        #        = [0.051, 2.302]\n-        # Reduced metric = (0.051 + 2.302) / 2\n-\n         assert np.allclose(K.eval(result), 1.176, atol=1e-3)\n \n     def test_unweighted_from_logits(self):\n@@ -772,18 +940,6 @@ class TestCategoricalCrossentropy(object):\n         logits = np.asarray([[1, 9, 0], [1, 8, 1]], dtype=np.float32)\n         result = cce_obj(y_true, logits)\n \n-        # softmax = exp(logits) / sum(exp(logits), axis=-1)\n-        # xent = -sum(labels * log(softmax), 1)\n-\n-        # exp(logits) = [[2.718, 8103.084, 1], [2.718, 2980.958, 2.718]]\n-        # sum(exp(logits), axis=-1) = [8106.802, 2986.394]\n-        # softmax = [[0.00033, 0.99954, 0.00012], [0.00091, 0.99817, 0.00091]]\n-        # log(softmax) = [[-8.00045, -0.00045, -9.00045],\n-        #                 [-7.00182, -0.00182, -7.00182]]\n-        # labels * log(softmax) = [[0, -0.00045, 0], [0, 0, -7.00182]]\n-        # xent = [0.00045, 7.00182]\n-        # Reduced xent = (0.00045 + 7.00182) / 2\n-\n         assert np.allclose(K.eval(result), 3.5011, atol=1e-3)\n \n     def test_weighted(self):\n@@ -794,16 +950,6 @@ class TestCategoricalCrossentropy(object):\n         sample_weight = [1.5, 2.]\n         result = cce_obj(y_true, y_pred, sample_weight=sample_weight)\n \n-        # EPSILON = 1e-7, y = y_true, y` = y_pred\n-        # y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON)\n-        # y` = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n-\n-        # Metric = -sum(y * log(y'), axis = -1)\n-        #        = -((log 0.95), (log 0.1))\n-        #        = [0.051, 2.302]\n-        # Weighted metric = [0.051 * 1.5, 2.302 * 2.]\n-        # Reduced metric = (0.051 * 1.5 + 2.302 * 2.) / 3.5\n-\n         assert np.allclose(K.eval(result), 1.338, atol=1e-3)\n \n     def test_weighted_from_logits(self):\n@@ -814,12 +960,6 @@ class TestCategoricalCrossentropy(object):\n         sample_weight = [1.5, 2.]\n         result = cce_obj(y_true, logits, sample_weight=sample_weight)\n \n-        # softmax = exp(logits) / sum(exp(logits), axis=-1)\n-        # xent = -sum(labels * log(softmax), 1)\n-        # xent = [0.00045, 7.00182]\n-        # weighted xent = [0.000675, 14.00364]\n-        # Reduced xent = (0.000675 + 14.00364) / (1.5 + 2)\n-\n         assert np.allclose(K.eval(result), 4.0012, atol=1e-3)\n \n     def test_label_smoothing(self):\n@@ -827,22 +967,6 @@ class TestCategoricalCrossentropy(object):\n         logits = np.asarray([[1, 9, 0], [1, 8, 1]], dtype=np.float32)\n         label_smoothing = 0.1\n \n-        # Label smoothing: z' = z * (1 - L) + L/n,\n-        #     where L = label smoothing value and n = num classes\n-        # Label value 1 becomes: 1 - L + L/n\n-        # Label value 0 becomes: L/n\n-        # y_true with label_smoothing = [[0.0333, 0.9333, 0.0333],\n-        #                               [0.0333, 0.0333, 0.9333]]\n-\n-        # softmax = exp(logits) / sum(exp(logits), axis=-1)\n-        # xent = -sum(labels * log(softmax), 1)\n-        # log(softmax) = [[-8.00045, -0.00045, -9.00045],\n-        #                 [-7.00182, -0.00182, -7.00182]]\n-        # labels * log(softmax) = [[-0.26641, -0.00042, -0.29971],\n-        #                          [-0.23316, -0.00006, -6.53479]]\n-        # xent = [0.56654, 6.76801]\n-        # Reduced xent = (0.56654 + 6.76801) / 2\n-\n         cce_obj = metrics.CategoricalCrossentropy(\n             from_logits=True, label_smoothing=label_smoothing)\n         loss = cce_obj(y_true, logits)\n@@ -864,25 +988,6 @@ class TestSparseCategoricalCrossentropy(object):\n         y_pred = np.asarray([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n         result = scce_obj(y_true, y_pred)\n \n-        # EPSILON = 1e-7, y = y_true, y` = y_pred\n-        # y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON)\n-        # y` = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n-        # logits = log(y`) =  [[-2.9957, -0.0513, -16.1181],\n-        #                      [-2.3026, -0.2231, -2.3026]]\n-\n-        # softmax = exp(logits) / sum(exp(logits), axis=-1)\n-        # y = one_hot(y) = [[0, 1, 0], [0, 0, 1]]\n-        # xent = -sum(y * log(softmax), 1)\n-\n-        # exp(logits) = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n-        # sum(exp(logits), axis=-1) = [1, 1]\n-        # softmax = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n-        # log(softmax) = [[-2.9957, -0.0513, -16.1181],\n-        #                 [-2.3026, -0.2231, -2.3026]]\n-        # y * log(softmax) = [[0, -0.0513, 0], [0, 0, -2.3026]]\n-        # xent = [0.0513, 2.3026]\n-        # Reduced xent = (0.0513 + 2.3026) / 2\n-\n         assert np.allclose(K.eval(result), 1.176, atol=1e-3)\n \n     def test_unweighted_from_logits(self):\n@@ -892,19 +997,6 @@ class TestSparseCategoricalCrossentropy(object):\n         logits = np.asarray([[1, 9, 0], [1, 8, 1]], dtype=np.float32)\n         result = scce_obj(y_true, logits)\n \n-        # softmax = exp(logits) / sum(exp(logits), axis=-1)\n-        # y_true = one_hot(y_true) = [[0, 1, 0], [0, 0, 1]]\n-        # xent = -sum(y_true * log(softmax), 1)\n-\n-        # exp(logits) = [[2.718, 8103.084, 1], [2.718, 2980.958, 2.718]]\n-        # sum(exp(logits), axis=-1) = [8106.802, 2986.394]\n-        # softmax = [[0.00033, 0.99954, 0.00012], [0.00091, 0.99817, 0.00091]]\n-        # log(softmax) = [[-8.00045, -0.00045, -9.00045],\n-        #                 [-7.00182, -0.00182, -7.00182]]\n-        # y_true * log(softmax) = [[0, -0.00045, 0], [0, 0, -7.00182]]\n-        # xent = [0.00045, 7.00182]\n-        # Reduced xent = (0.00045 + 7.00182) / 2\n-\n         assert np.allclose(K.eval(result), 3.5011, atol=1e-3)\n \n     def test_weighted(self):\n@@ -915,26 +1007,6 @@ class TestSparseCategoricalCrossentropy(object):\n         sample_weight = [1.5, 2.]\n         result = scce_obj(y_true, y_pred, sample_weight=sample_weight)\n \n-        # EPSILON = 1e-7, y = y_true, y` = y_pred\n-        # y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON)\n-        # y` = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n-        # logits = log(y`) =  [[-2.9957, -0.0513, -16.1181],\n-        #                      [-2.3026, -0.2231, -2.3026]]\n-\n-        # softmax = exp(logits) / sum(exp(logits), axis=-1)\n-        # y = one_hot(y) = [[0, 1, 0], [0, 0, 1]]\n-        # xent = -sum(y * log(softmax), 1)\n-\n-        # exp(logits) = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n-        # sum(exp(logits), axis=-1) = [1, 1]\n-        # softmax = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n-        # log(softmax) = [[-2.9957, -0.0513, -16.1181],\n-        #                 [-2.3026, -0.2231, -2.3026]]\n-        # y * log(softmax) = [[0, -0.0513, 0], [0, 0, -2.3026]]\n-        # xent = [0.0513, 2.3026]\n-        # Weighted xent = [0.051 * 1.5, 2.302 * 2.]\n-        # Reduced xent = (0.051 * 1.5 + 2.302 * 2.) / 3.5\n-\n         assert np.allclose(K.eval(result), 1.338, atol=1e-3)\n \n     def test_weighted_from_logits(self):\n@@ -944,13 +1016,6 @@ class TestSparseCategoricalCrossentropy(object):\n         sample_weight = [1.5, 2.]\n         result = scce_obj(y_true, logits, sample_weight=sample_weight)\n \n-        # softmax = exp(logits) / sum(exp(logits), axis=-1)\n-        # y_true = one_hot(y_true) = [[0, 1, 0], [0, 0, 1]]\n-        # xent = -sum(y_true * log(softmax), 1)\n-        # xent = [0.00045, 7.00182]\n-        # weighted xent = [0.000675, 14.00364]\n-        # Reduced xent = (0.000675 + 14.00364) / (1.5 + 2)\n-\n         assert np.allclose(K.eval(result), 4.0012, atol=1e-3)\n \n     def test_axis(self):\n@@ -960,25 +1025,4 @@ class TestSparseCategoricalCrossentropy(object):\n         y_pred = np.asarray([[0.05, 0.1], [0.95, 0.8], [0, 0.1]])\n         result = scce_obj(y_true, y_pred)\n \n-        # EPSILON = 1e-7, y = y_true, y` = y_pred\n-        # y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON)\n-        # y` = [[0.05, 0.1], [0.95, 0.8], [EPSILON, 0.1]]\n-        # logits = log(y`) =  [[-2.9957, -2.3026],\n-        #                      [-0.0513, -0.2231],\n-        #                      [-16.1181, -2.3026]]\n-\n-        # softmax = exp(logits) / sum(exp(logits), axis=-1)\n-        # y = one_hot(y) = [[0, 0], [1, 0], [0, 1]]\n-        # xent = -sum(y * log(softmax), 1)\n-\n-        # exp(logits) = [[0.05, 0.1], [0.95, 0.8], [EPSILON, 0.1]]\n-        # sum(exp(logits)) = [1, 1]\n-        # softmax = [[0.05, 0.1], [0.95, 0.8], [EPSILON, 0.1]]\n-        # log(softmax) = [[-2.9957, -2.3026],\n-        #                 [-0.0513, -0.2231],\n-        #                 [-16.1181, -2.3026]]\n-        # y * log(softmax) = [[0, 0], [-0.0513, 0], [0, -2.3026]]\n-        # xent = [0.0513, 2.3026]\n-        # Reduced xent = (0.0513 + 2.3026) / 2\n-\n         assert np.allclose(K.eval(result), 1.176, atol=1e-3)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
