{"custom_id": "keras#cb02df95b28716a2d506941babbc817953b79fce", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 23 | Files Changed: 2 | Hunks: 6 | Methods Changed: 6 | Complexity Δ (Sum/Max): 1/3 | Churn Δ: 46 | Churn Cumulative: 106 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -1,4 +1,6 @@\n-import h5py, numpy\n+from __future__ import absolute_import\n+import h5py\n+import numpy as np\n from collections import defaultdict\n \n class HDF5Matrix:\n@@ -6,7 +8,7 @@ class HDF5Matrix:\n     refs = defaultdict(int)\n \n     def __init__(self, datapath, dataset, start, end, normalizer=None):\n-        if datapath not in self.refs.keys():\n+        if datapath not in list(self.refs.keys()):\n             f = h5py.File(datapath)\n             self.refs[datapath] = f\n         else:\n@@ -30,14 +32,14 @@ class HDF5Matrix:\n                 idx = key+self.start\n             else:\n                 raise IndexError\n-        elif isinstance(key, numpy.ndarray):\n-            if numpy.max(key) + self.start < self.end:\n+        elif isinstance(key, np.ndarray):\n+            if np.max(key) + self.start < self.end:\n                 idx = (self.start + key).tolist()\n             else:\n                 raise IndexError\n         elif isinstance(key, list):\n             if max(key) + self.start < self.end:\n-                idx = map(lambda x: x + self.start, key)\n+                idx = [x + self.start for x in key]\n             else:\n                 raise IndexError\n         if self.normalizer is not None:\n@@ -50,3 +52,19 @@ class HDF5Matrix:\n         return tuple([self.end - self.start, self.data.shape[1]])\n \n \n+def save_array(array, name):\n+    import tables\n+    f = tables.open_file(name, 'w')\n+    atom = tables.Atom.from_dtype(array.dtype)\n+    ds = f.createCArray(f.root, 'data', atom, array.shape)\n+    ds[:] = array\n+    f.close()\n+\n+def load_array(name):\n+    import tables\n+    f = tables.open_file(name)\n+    array = f.root.data\n+    a=np.empty(shape=array.shape, dtype=array.dtype)\n+    a[:]=array[:]\n+    f.close()\n+    return a\n\n@@ -46,21 +46,3 @@ def probas_to_classes(y_pred):\n \n def categorical_probas_to_classes(p):\n     return np.argmax(p, axis=1)\n-\n-\n-def save_array(array, name):\n-    import tables\n-    f = tables.open_file(name, 'w')\n-    atom = tables.Atom.from_dtype(array.dtype)\n-    ds = f.createCArray(f.root, 'data', atom, array.shape)\n-    ds[:] = array\n-    f.close()\n-\n-def load_array(name):\n-    import tables\n-    f = tables.open_file(name)\n-    array = f.root.data\n-    a=np.empty(shape=array.shape, dtype=array.dtype)\n-    a[:]=array[:]\n-    f.close()\n-    return a\n\\ No newline at end of file\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5f25e2205ae61e5d7ce02d5ac14fb810561ea2c8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 167 | Contributors (this commit): 3 | Commits (past 90d): 6 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -53,7 +53,7 @@ model.add(Activation('relu'))\n model.add(MaxPooling2D(poolsize=(2, 2)))\n model.add(Dropout(0.25))\n \n-model.add(Flatten(64*8*8))\n+model.add(Flatten())\n model.add(Dense(64*8*8, 512, init='normal'))\n model.add(Activation('relu'))\n model.add(Dropout(0.5))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#03abbafe746917fd825039b70686284a2ae13cb7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 58 | Contributors (this commit): 3 | Commits (past 90d): 7 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -1,5 +1,8 @@\n #!/usr/bin/env python\n \n+try:\n+    from setuptools import setup\n+except ImportError:\n     from distutils.core import setup\n \n setup(name='Keras',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#731f0ab42b808b0f90d4c1e97fcd80dbc214191c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 11 | Methods Changed: 3 | Complexity Δ (Sum/Max): 10/10 | Churn Δ: 21 | Churn Cumulative: 273 | Contributors (this commit): 6 | Commits (past 90d): 11 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -121,6 +121,7 @@ class Sequential(object):\n                 np.random.shuffle(index_array)\n \n             batches = make_batches(len(X), batch_size)\n+            if verbose==1:\n                 progbar = Progbar(target=len(X))\n             for batch_index, (batch_start, batch_end) in enumerate(batches):\n                 if shuffle:\n@@ -138,7 +139,8 @@ class Sequential(object):\n                 # logging\n                 if verbose:\n                     is_last_batch = (batch_index == len(batches) - 1)\n-                    if not is_last_batch or not do_validation:\n+                    if (not is_last_batch or not do_validation):\n+                        if verbose==1:\n                             if show_accuracy:\n                                 progbar.update(batch_end, [('loss', loss), ('acc.', acc)])\n                             else:\n@@ -146,15 +148,21 @@ class Sequential(object):\n                     else:\n                         if show_accuracy:\n                             val_loss, val_acc = self.test(X_val, y_val, accuracy=True)\n+                            if verbose==1:\n                                 progbar.update(batch_end, [('loss', loss), ('acc.', acc), ('val. loss', val_loss), ('val. acc.', val_acc)])\n+                            if verbose==2:\n+                                print(\"loss: %.4f - acc.: %.4f - val. loss: %.4f - val. acc.: %.4f\" % (loss, acc, val_loss, val_acc))\n                         else:\n                             val_loss = self.test(X_val, y_val, accuracy=False)\n+                            if verbose==1:\n                                 progbar.update(batch_end, [('loss', loss), ('val. loss', val_loss)])\n+                            if verbose==2:\n+                                print(\"loss: %.4f - acc.: %.4f\" % (loss, acc))\n \n             \n     def predict_proba(self, X, batch_size=128, verbose=1):\n         batches = make_batches(len(X), batch_size)\n-        if verbose:\n+        if verbose==1:\n             progbar = Progbar(target=len(X))\n         for batch_index, (batch_start, batch_end) in enumerate(batches):\n             X_batch = X[batch_start:batch_end]\n@@ -165,8 +173,9 @@ class Sequential(object):\n                 preds = np.zeros(shape)\n             preds[batch_start:batch_end] = batch_preds\n \n-            if verbose:\n+            if verbose==1:\n                 progbar.update(batch_end)\n+\n         return preds\n \n \n@@ -199,10 +208,16 @@ class Sequential(object):\n             tot_score += loss\n \n             if verbose:\n+                if verbose==1:\n                     if show_accuracy:\n                         progbar.update(batch_end, [('loss', loss), ('acc.', acc)])\n                     else:\n                         progbar.update(batch_end, [('loss', loss)])\n+                if batch_index == len(batches) and verbose==2:\n+                    if show_accuracy:\n+                        print(\"loss: %.4f - acc.: %.4f\" % (loss, acc))\n+                    else:\n+                        print(\"loss: %.4f\")\n \n         if show_accuracy:\n             return tot_score/len(batches), tot_acc/len(batches)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#52bcd448f46a571bd66855531c47881c21d774fc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 6 | Methods Changed: 6 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 27 | Churn Cumulative: 54 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -5,6 +5,12 @@ import numpy as np\n \n from .utils.theano_utils import sharedX, shared_zeros\n \n+def get_fans(shape):\n+    fan_in = shape[0] if len(shape) == 2 else np.prod(shape[1:])\n+    fan_out = shape[1] if len(shape) == 2 else shape[0]\n+    return fan_in, fan_out\n+\n+\n def uniform(shape, scale=0.05):\n     return sharedX(np.random.uniform(low=-scale, high=scale, size=shape))\n \n@@ -15,27 +21,34 @@ def lecun_uniform(shape):\n     ''' Reference: LeCun 98, Efficient Backprop\n         http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf\n     '''\n-    m = 1\n-    for s in shape:\n-        m *= s\n-    scale = 1./np.sqrt(m)\n+    fan_in, fan_out = get_fans(shape)\n+    scale = 1./np.sqrt(fan_in)\n     return uniform(shape, scale)\n \n def glorot_normal(shape):\n     ''' Reference: Glorot & Bengio, AISTATS 2010\n     '''\n-    fan_in = shape[0] if len(shape) == 2 else np.prod(shape[1:])\n-    fan_out = shape[1] if len(shape) == 2 else shape[0]\n+    fan_in, fan_out = get_fans(shape)\n     s = np.sqrt(2. / (fan_in + fan_out))\n     return normal(shape, s)\n \n+def glorot_uniform(shape):\n+    fan_in, fan_out = get_fans(shape)\n+    s = np.sqrt(2. / (fan_in + fan_out))\n+    return uniform(shape, s)\n+    \n def he_normal(shape):\n     ''' Reference:  He et al., http://arxiv.org/abs/1502.01852\n     '''\n-    fan_in = shape[1] if len(shape) == 2 else np.prod(shape[1:])\n+    fan_in, fan_out = get_fans(shape)\n     s = np.sqrt(2. / fan_in)\n     return normal(shape, s)\n \n+def he_uniform(shape):\n+    fan_in, fan_out = get_fans(shape)\n+    s = np.sqrt(2. / fan_in)\n+    return uniform(shape, s)\n+\n def orthogonal(shape, scale=1.1):\n     ''' From Lasagne\n     '''\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#254b7cb1ad7322e423dd636d85e47b1261a0e962", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 275 | Contributors (this commit): 7 | Commits (past 90d): 12 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -157,7 +157,7 @@ class Sequential(object):\n                             if verbose==1:\n                                 progbar.update(batch_end, [('loss', loss), ('val. loss', val_loss)])\n                             if verbose==2:\n-                                print(\"loss: %.4f - acc.: %.4f\" % (loss, acc))\n+                                print(\"loss: %.4f - val. loss: %.4f\" % (loss, val_loss))\n \n             \n     def predict_proba(self, X, batch_size=128, verbose=1):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#70efc97ff4fe8b3a37f7fa11b45e98a3ca6633ae", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 59 | Contributors (this commit): 3 | Commits (past 90d): 6 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -156,8 +156,8 @@ class Adam(Optimizer):\n             m = theano.shared(p.get_value() * 0.) # zero init of moment\n             v = theano.shared(p.get_value() * 0.) # zero init of velocity\n \n-            m_t = ((1. - self.beta_1) * m) + (self.beta_1 * g)\n-            v_t = (self.beta_2 * v) + (1 - self.beta_2) * (g**2)\n+            m_t = (beta_1_t * m) + (1 - beta_1_t) * g\n+            v_t = (beta_2_t * v) + (1 - beta_2_t) * (g**2)\n \n             m_b_t = m_t / (1 - beta_1_t)\n             v_b_t = v_t / (1 - beta_2_t)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c224482190b8d4a057f9546753b8331e18a6d953", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 65 | Lines Deleted: 42 | Files Changed: 3 | Hunks: 21 | Methods Changed: 6 | Complexity Δ (Sum/Max): -1/4 | Churn Δ: 107 | Churn Cumulative: 492 | Contributors (this commit): 8 | Commits (past 90d): 22 | Contributors (cumulative): 10 | DMM Complexity: 0.16666666666666666\n\nDIFF:\n@@ -52,16 +52,20 @@ model.add(Dropout(0.5))\n model.add(Dense(256, nb_classes, init='normal'))\n model.add(Activation('softmax'))\n \n-\n model.compile(loss='categorical_crossentropy', optimizer='adam')\n-print(model.optimizer)\n \n-print(\"Training...\")\n-model.fit(X_train, Y_train, nb_epoch=5, batch_size=batch_size)\n-score = model.evaluate(X_test, Y_test, batch_size=batch_size)\n-print('Test score:', score)\n+# import cPickle\n+# model = cPickle.load(open('testsave.m.pkl'))\n \n-classes = model.predict_classes(X_test, batch_size=batch_size)\n+# print(\"Training...\")\n+# model.fit(X_train, Y_train, nb_epoch=1, batch_size=batch_size, verbose=2)\n+# score = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=2)\n+# print('Test score:', score)\n+\n+classes = model.predict_classes(X_test, batch_size=batch_size, verbose=2)\n acc = np_utils.accuracy(classes, y_test)\n print('Test accuracy:', acc)\n \n+model.save('testsave.m')\n+\n+\n\n@@ -117,12 +117,11 @@ class Sequential(object):\n         for epoch in range(nb_epoch):\n             if verbose:\n                 print('Epoch', epoch)\n+                progbar = Progbar(target=len(X), verbose=verbose)\n             if shuffle:\n                 np.random.shuffle(index_array)\n \n             batches = make_batches(len(X), batch_size)\n-            if verbose==1:\n-                progbar = Progbar(target=len(X))\n             for batch_index, (batch_start, batch_end) in enumerate(batches):\n                 if shuffle:\n                     batch_ids = index_array[batch_start:batch_end]\n@@ -133,31 +132,23 @@ class Sequential(object):\n \n                 if show_accuracy:\n                     loss, acc = self._train_with_acc(X_batch, y_batch)\n+                    log_values = [('loss', loss), ('acc.', acc)]\n                 else:\n                     loss = self._train(X_batch, y_batch)\n+                    log_values = [('loss', loss)]\n+\n+                # validation\n+                if do_validation and (batch_index == len(batches) - 1):\n+                    if show_accuracy:\n+                        val_loss, val_acc = self.test(X_val, y_val, accuracy=True)\n+                        log_values += [('val. loss', val_loss), ('val. acc.', val_acc)]\n+                    else:\n+                        val_loss = self.test(X_val, y_val)\n+                        log_values += [('val. loss', val_loss)]\n                 \n                 # logging\n                 if verbose:\n-                    is_last_batch = (batch_index == len(batches) - 1)\n-                    if (not is_last_batch or not do_validation):\n-                        if verbose==1:\n-                            if show_accuracy:\n-                                progbar.update(batch_end, [('loss', loss), ('acc.', acc)])\n-                            else:\n-                                progbar.update(batch_end, [('loss', loss)])\n-                    else:\n-                        if show_accuracy:\n-                            val_loss, val_acc = self.test(X_val, y_val, accuracy=True)\n-                            if verbose==1:\n-                                progbar.update(batch_end, [('loss', loss), ('acc.', acc), ('val. loss', val_loss), ('val. acc.', val_acc)])\n-                            if verbose==2:\n-                                print(\"loss: %.4f - acc.: %.4f - val. loss: %.4f - val. acc.: %.4f\" % (loss, acc, val_loss, val_acc))\n-                        else:\n-                            val_loss = self.test(X_val, y_val, accuracy=False)\n-                            if verbose==1:\n-                                progbar.update(batch_end, [('loss', loss), ('val. loss', val_loss)])\n-                            if verbose==2:\n-                                print(\"loss: %.4f - val. loss: %.4f\" % (loss, val_loss))\n+                    progbar.update(batch_end, log_values)\n \n             \n     def predict_proba(self, X, batch_size=128, verbose=1):\n@@ -195,7 +186,8 @@ class Sequential(object):\n         tot_score = 0.\n \n         batches = make_batches(len(X), batch_size)\n-        progbar = Progbar(target=len(X))\n+        if verbose:\n+            progbar = Progbar(target=len(X), verbose=verbose)\n         for batch_index, (batch_start, batch_end) in enumerate(batches):\n             X_batch = X[batch_start:batch_end]\n             y_batch = y[batch_start:batch_end]\n@@ -203,27 +195,44 @@ class Sequential(object):\n             if show_accuracy:\n                 loss, acc = self._test_with_acc(X_batch, y_batch)\n                 tot_acc += acc\n+                log_values = [('loss', loss), ('acc.', acc)]\n             else:\n                 loss = self._test(X_batch, y_batch)\n+                log_values = [('loss', loss)]\n             tot_score += loss\n \n+            # logging\n             if verbose:\n-                if verbose==1:\n-                    if show_accuracy:\n-                        progbar.update(batch_end, [('loss', loss), ('acc.', acc)])\n-                    else:\n-                        progbar.update(batch_end, [('loss', loss)])\n-                if batch_index == len(batches) and verbose==2:\n-                    if show_accuracy:\n-                        print(\"loss: %.4f - acc.: %.4f\" % (loss, acc))\n-                    else:\n-                        print(\"loss: %.4f\")\n+                progbar.update(batch_end, log_values)\n \n         if show_accuracy:\n             return tot_score/len(batches), tot_acc/len(batches)\n         else:\n             return tot_score/len(batches)\n \n+    def save(self, fpath):\n+        import cPickle\n+        import types\n+\n+        weights = []\n+        for l in self.layers:\n+            weights.append(l.get_weights())\n+            \n+            attributes = []\n+            for a in dir(l):\n+                if a[:2] != '__' and a not in ['params', 'previous_layer', 'input']:\n+                    if type(getattr(l, a)) != types.MethodType:\n+                        attributes.append((a, getattr(l, a)))\n+\n+        print('Pickle model...')\n+        cPickle.dump(self, open(fpath + '.pkl', 'w'))\n+        print('Pickle weights...')\n+        cPickle.dump(weights, open(fpath + '.h5', 'w'))\n+\n+        #save_weights_to_hdf5(fpath + '.h5', weights)\n+\n+\n+                \n \n \n \n\n@@ -18,7 +18,7 @@ def make_tuple(*args):\n     return args\n \n class Progbar(object):\n-    def __init__(self, target, width=30):\n+    def __init__(self, target, width=30, verbose=1):\n         '''\n             @param target: total number of steps expected\n         '''\n@@ -29,6 +29,7 @@ class Progbar(object):\n         self.start = time.time()\n         self.total_width = 0\n         self.seen_so_far = 0\n+        self.verbose = verbose\n \n     def update(self, current, values=[]):\n         '''\n@@ -44,6 +45,8 @@ class Progbar(object):\n                 self.sum_values[k][0] += v * (current-self.seen_so_far)\n                 self.sum_values[k][1] += (current-self.seen_so_far)\n \n+        now = time.time()\n+        if self.verbose == 1:\n             prev_total_width = self.total_width\n             sys.stdout.write(\"\\b\" * (self.total_width+1))\n \n@@ -61,7 +64,6 @@ class Progbar(object):\n             sys.stdout.write(bar)\n             self.total_width = len(bar)\n             \n-        now = time.time()\n             if current:\n                 time_per_unit = (now - self.start) / current\n             else:\n@@ -86,5 +88,13 @@ class Progbar(object):\n             if current >= self.target:\n                 sys.stdout.write(\"\\n\")\n \n+        if self.verbose == 2:\n+            if current >= self.target:\n+                info = '%ds' % (now - self.start)\n+                for k in self.unique_values:\n+                    info += ' - %s: %.4f' % (k, self.sum_values[k][0]/self.sum_values[k][1])\n+                sys.stdout.write(info + \"\\n\")\n+\n+\n     def add(self, n, values=[]):\n         self.update(self.seen_so_far+n, values)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4bb90a5bfd762269adeee772e233a733a6d318a9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 21 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -6/0 | Churn Δ: 21 | Churn Cumulative: 371 | Contributors (this commit): 7 | Commits (past 90d): 14 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -210,27 +210,6 @@ class Sequential(object):\n         else:\n             return tot_score/len(batches)\n \n-    def save(self, fpath):\n-        import cPickle\n-        import types\n-\n-        weights = []\n-        for l in self.layers:\n-            weights.append(l.get_weights())\n-            \n-            attributes = []\n-            for a in dir(l):\n-                if a[:2] != '__' and a not in ['params', 'previous_layer', 'input']:\n-                    if type(getattr(l, a)) != types.MethodType:\n-                        attributes.append((a, getattr(l, a)))\n-\n-        print('Pickle model...')\n-        cPickle.dump(self, open(fpath + '.pkl', 'w'))\n-        print('Pickle weights...')\n-        cPickle.dump(weights, open(fpath + '.h5', 'w'))\n-\n-        #save_weights_to_hdf5(fpath + '.h5', weights)\n-\n \n                 \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#06e1c3066e76b8a048913aaef7b994a77e8811b2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 19 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -1,7 +1,7 @@\n from __future__ import absolute_import\n from __future__ import print_function\n-import urllib, tarfile\n-import inspect, os\n+import tarfile, inspect, os\n+from six.moves.urllib.request import urlretrieve\n from ..utils.generic_utils import Progbar\n \n def get_file(fname, origin, untar=False):\n@@ -29,7 +29,7 @@ def get_file(fname, origin, untar=False):\n             else:\n                 progbar.update(count*block_size)\n \n-        urllib.urlretrieve(origin, fpath, dl_progress)\n+        urlretrieve(origin, fpath, dl_progress)\n         progbar = None\n \n     if untar:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#88e8403bfba298a0a0934d4899954f6488a937c0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 25 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -1,7 +1,7 @@\n from __future__ import absolute_import\n from __future__ import print_function\n-import urllib, tarfile\n-import inspect, os\n+import tarfile, inspect, os\n+from six.moves.urllib.request import urlretrieve\n from ..utils.generic_utils import Progbar\n \n def get_file(fname, origin, untar=False):\n@@ -29,7 +29,7 @@ def get_file(fname, origin, untar=False):\n             else:\n                 progbar.update(count*block_size)\n \n-        urllib.urlretrieve(origin, fpath, dl_progress)\n+        urlretrieve(origin, fpath, dl_progress)\n         progbar = None\n \n     if untar:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8e7e7552955168174eb652bc98b74aac96cf9dc3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 46 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 7 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 52 | Churn Cumulative: 451 | Contributors (this commit): 7 | Commits (past 90d): 17 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -211,16 +211,16 @@ class Sequential(object):\n             return tot_score/len(batches)\n \n \n-    def save(self, filepath):\n+    def save_weights(self, filepath):\n         # Save weights from all layers to HDF5\n         import h5py\n         # FIXME: fail if file exists, or add option to overwrite!\n         f = h5py.File(filepath, 'w')\n-        f.attrs['n_layers'] = len(self.layers)\n+        f.attrs['nb_layers'] = len(self.layers)\n         for k, l in enumerate(self.layers):\n             g = f.create_group('layer_{}'.format(k))\n             weights = l.get_weights()\n-            g.attrs['n_params'] = len(weights)\n+            g.attrs['nb_params'] = len(weights)\n             for n, param in enumerate(weights):\n                 param_name = 'param_{}'.format(n)\n                 param_dset = g.create_dataset(param_name, param.shape, dtype='float64')\n@@ -228,13 +228,13 @@ class Sequential(object):\n         f.flush()\n         f.close()\n \n-    def load(self, filepath):\n+    def load_weights(self, filepath):\n         # Loads weights from HDF5 file\n         import h5py\n         f = h5py.File(filepath)\n-        for k in range(f.attrs['n_layers']):\n+        for k in range(f.attrs['nb_layers']):\n             g = f['layer_{}'.format(k)]\n-            weights = [g['param_{}'.format(p)] for p in range(g.attrs['n_params'])]\n+            weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n             self.layers[k].set_weights(weights)\n         f.close()\n \n\n@@ -0,0 +1,40 @@\n+from keras.models import Sequential\n+from keras.layers.core import Dense, Dropout, Activation\n+from keras.optimizers import SGD\n+\n+import sys\n+sys.setrecursionlimit(10000) # to be able to pickle Theano compiled functions\n+\n+import pickle, numpy\n+\n+def create_model():\n+    model = Sequential()\n+    model.add(Dense(256, 2048, init='uniform', activation='relu'))\n+    model.add(Dropout(0.5))\n+    model.add(Dense(2048, 2048, init='uniform', activation='relu'))\n+    model.add(Dropout(0.5))\n+    model.add(Dense(2048, 2048, init='uniform', activation='relu'))\n+    model.add(Dropout(0.5))\n+    model.add(Dense(2048, 2048, init='uniform', activation='relu'))\n+    model.add(Dropout(0.5))\n+    model.add(Dense(2048, 256, init='uniform', activation='linear'))\n+    return model\n+\n+model = create_model()\n+sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n+model.compile(loss='mse', optimizer=sgd)\n+\n+pickle.dump(model, open('/tmp/model.pkl', 'wb'))\n+model.save_weights('/tmp/model_weights.hdf5')\n+\n+model_loaded = create_model()\n+model_loaded.load_weights('/tmp/model_weights.hdf5')\n+\n+for k in range(len(model.layers)):\n+    weights_orig = model.layers[k].get_weights()\n+    weights_loaded = model_loaded.layers[k].get_weights()\n+    for x, y in zip(weights_orig, weights_loaded):\n+        if numpy.any(x != y):\n+            raise ValueError('Loaded weights are different from pickled weights!')\n+\n+\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0c1184625dfd4928db44ea901e70ace3e4747e37", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 12 | Churn Cumulative: 53 | Contributors (this commit): 3 | Commits (past 90d): 11 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2,6 +2,7 @@\n from __future__ import absolute_import\n from .data_utils import get_file\n import random\n+import sys\n import numpy as np\n import six.moves.cPickle\n from six.moves import range\n@@ -17,7 +18,14 @@ def load_data(test_split=0.1, seed=113):\n     for i in range(1, 6):\n         fpath = path + '/data_batch_' + str(i)\n         f = open(fpath, 'rb')\n+        if sys.version_info < (3,):\n             d = six.moves.cPickle.load(f)\n+        else:\n+            d = six.moves.cPickle.load(f, encoding=\"bytes\")\n+            # decode utf8\n+            for k, v in d.items():\n+                del(d[k])\n+                d[k.decode(\"utf8\")] = v\n         f.close()\n         data = d[\"data\"]\n         labels = d[\"labels\"]\n@@ -40,4 +48,3 @@ def load_data(test_split=0.1, seed=113):\n     y_test = y[int(len(X)*(1-test_split)):]\n \n     return (X_train, y_train), (X_test, y_test)\n-\n\n@@ -41,6 +41,3 @@ def get_file(fname, origin, untar=False):\n         return untar_fpath\n \n     return fpath\n-\n-\n-\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e35f21b71057973bb9f13081d713d19727cbf52f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 83 | Contributors (this commit): 3 | Commits (past 90d): 8 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -1,5 +1,5 @@\n # -*- coding: utf-8 -*-\n-from __future__ import absolute_import\n+from __future__ import absolute_import, division\n \n import theano\n import theano.tensor as T\n@@ -94,7 +94,7 @@ class Flatten(Layer):\n \n     def output(self, train):\n         X = self.get_input(train)\n-        size = theano.tensor.prod(X.shape) / X.shape[0]\n+        size = theano.tensor.prod(X.shape) // X.shape[0]\n         nshape = (X.shape[0], size)\n         return theano.tensor.reshape(X, nshape)\n \n@@ -174,5 +174,3 @@ class TimeDistributedDense(Layer):\n                                 sequences = X.dimshuffle(1,0,2),\n                                 outputs_info=None)\n         return output.dimshuffle(1,0,2)\n-\n-\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e074a049205829feb52c7d90f2011519327e56f3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 145 | Lines Deleted: 6 | Files Changed: 8 | Hunks: 23 | Methods Changed: 8 | Complexity Δ (Sum/Max): 23/7 | Churn Δ: 151 | Churn Cumulative: 918 | Contributors (this commit): 9 | Commits (past 90d): 49 | Contributors (cumulative): 17 | DMM Complexity: 1.0\n\nDIFF:\n@@ -57,15 +57,20 @@ model.compile(loss='categorical_crossentropy', optimizer='adam')\n # import cPickle\n # model = cPickle.load(open('testsave.m.pkl'))\n \n-# print(\"Training...\")\n-# model.fit(X_train, Y_train, nb_epoch=1, batch_size=batch_size, verbose=2)\n-# score = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=2)\n-# print('Test score:', score)\n+for v in range(3):\n+    for sa in [True, False]:\n+        for vs in [0, 0.1]:\n+            print('='*40)\n+            print('v:%d, sa:%r, vs:%f' % (v, sa, vs))\n+            print(\"Training...\")\n+            model.fit(X_train, Y_train, nb_epoch=2, batch_size=batch_size, verbose=v, show_accuracy=sa, validation_split=vs)\n+            score = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=v, show_accuracy=sa)\n+            print('Test score:', score)\n \n-classes = model.predict_classes(X_test, batch_size=batch_size, verbose=2)\n+            classes = model.predict_classes(X_test, batch_size=batch_size, verbose=v)\n             acc = np_utils.accuracy(classes, y_test)\n             print('Test accuracy:', acc)\n \n-model.save('testsave.m')\n+# model.save('testsave.m')\n \n \n\n@@ -10,6 +10,10 @@ class LeakyReLU(Layer):\n         X = self.get_input(train)\n         return ((X + abs(X)) / 2.0) + self.alpha * ((X - abs(X)) / 2.0)\n \n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+            \"alpha\":self.alpha}\n+\n \n class PReLU(Layer):\n     '''\n@@ -26,3 +30,7 @@ class PReLU(Layer):\n         pos = ((X + abs(X)) / 2.0)\n         neg = self.alphas * ((X - abs(X)) / 2.0)\n         return pos + neg\n+\n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+            \"input_shape\":self.input_shape}\n\n@@ -25,6 +25,10 @@ class Convolution2D(Layer):\n         self.subsample = subsample\n         self.border_mode = border_mode\n         self.image_shape = image_shape\n+        self.nb_filter = nb_filter\n+        self.stack_size = stack_size\n+        self.nb_row = nb_row\n+        self.nb_col = nb_col\n \n         self.input = T.tensor4()\n         self.W_shape = (nb_filter, stack_size, nb_row, nb_col)\n@@ -44,6 +48,18 @@ class Convolution2D(Layer):\n         output = self.activation(conv_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n         return output\n \n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+            \"nb_filter\":self.nb_filter,\n+            \"stack_size\":self.stack_size,\n+            \"nb_row\":self.nb_row,\n+            \"nb_col\":self.nb_col,\n+            \"init\":self.init.__name__,\n+            \"activation\":self.activation.__name__,\n+            \"image_shape\":self.image_shape,\n+            \"border_mode\":self.border_mode,\n+            \"subsample\":self.subsample}\n+\n \n class MaxPooling2D(Layer):\n     def __init__(self, poolsize=(2, 2), ignore_border=True):\n@@ -57,6 +73,12 @@ class MaxPooling2D(Layer):\n         output = downsample.max_pool_2d(X, self.poolsize, ignore_border=self.ignore_border)\n         return output\n \n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+            \"poolsize\":self.poolsize,\n+            \"ignore_border\":self.ignore_border}\n+\n+\n \n # class ZeroPadding2D(Layer): TODO\n         \n\n@@ -35,6 +35,9 @@ class Layer(object):\n             weights.append(p.get_value())\n         return weights\n \n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__}\n+\n \n class Dropout(Layer):\n     '''\n@@ -54,6 +57,10 @@ class Dropout(Layer):\n                 X *= retain_prob\n         return X\n \n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+            \"p\":self.p}\n+\n \n class Activation(Layer):\n     '''\n@@ -67,6 +74,10 @@ class Activation(Layer):\n         X = self.get_input(train)\n         return self.activation(X)\n \n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+            \"activation\":self.activation.__name__}\n+\n \n class Reshape(Layer):\n     '''\n@@ -83,6 +94,10 @@ class Reshape(Layer):\n         nshape = make_tuple(X.shape[0], *self.dims)\n         return theano.tensor.reshape(X, nshape)\n \n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+            \"p\":self.p}\n+\n \n class Flatten(Layer):\n     '''\n@@ -116,6 +131,10 @@ class RepeatVector(Layer):\n         stacked = theano.tensor.stack(*tensors)\n         return stacked.dimshuffle((1,0,2))\n \n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+            \"n\":self.n}\n+\n \n class Dense(Layer):\n     '''\n@@ -141,6 +160,14 @@ class Dense(Layer):\n         output = self.activation(T.dot(X, self.W) + self.b)\n         return output\n \n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+            \"input_dim\":self.input_dim,\n+            \"output_dim\":self.output_dim,\n+            \"init\":self.init.__name__,\n+            \"activation\":self.activation.__name__}\n+\n+\n class TimeDistributedDense(Layer):\n     '''\n        Apply a same DenseLayer for each dimension[1] (shared_dimension) input\n@@ -174,3 +201,10 @@ class TimeDistributedDense(Layer):\n                                 sequences = X.dimshuffle(1,0,2),\n                                 outputs_info=None)\n         return output.dimshuffle(1,0,2)\n+\n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+            \"input_dim\":self.input_dim,\n+            \"output_dim\":self.output_dim,\n+            \"init\":self.init.__name__,\n+            \"activation\":self.activation.__name__}\n\n@@ -31,6 +31,12 @@ class Embedding(Layer):\n         out = self.W[X]\n         return out\n \n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+            \"input_dim\":self.input_dim,\n+            \"output_dim\":self.output_dim,\n+            \"init\":self.init.__name__}\n+\n \n class WordContextProduct(Layer):\n     '''\n@@ -84,3 +90,10 @@ class WordContextProduct(Layer):\n         dot = theano.tensor.reshape(dot, (X.shape[0], 1))\n         return self.activation(dot)\n \n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+            \"input_dim\":self.input_dim,\n+            \"proj_dim\":self.proj_dim,\n+            \"init\":self.init.__name__,\n+            \"activation\":self.activation.__name__}\n+\n\n@@ -25,3 +25,8 @@ class BatchNormalization(Layer):\n         X_normed = (X - X.mean(keepdims=True)) / (X.std(keepdims=True) + self.epsilon)\n         out = self.gamma * X_normed + self.beta\n         return out\n+\n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+            \"input_shape\":self.input_shape,\n+            \"epsilon\":self.epsilon}\n\\ No newline at end of file\n\n@@ -67,6 +67,16 @@ class SimpleRNN(Layer):\n             return outputs.dimshuffle((1,0,2))\n         return outputs[-1]\n \n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+            \"input_dim\":self.input_dim,\n+            \"output_dim\":self.output_dim,\n+            \"init\":self.init.__name__,\n+            \"inner_init\":self.inner_init.__name__,\n+            \"activation\":self.activation.__name__,\n+            \"truncate_gradient\":self.truncate_gradient,\n+            \"return_sequences\":self.return_sequences}\n+\n \n class SimpleDeepRNN(Layer):\n     '''\n@@ -127,6 +137,17 @@ class SimpleDeepRNN(Layer):\n             return outputs.dimshuffle((1,0,2))\n         return outputs[-1]\n \n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+            \"input_dim\":self.input_dim,\n+            \"output_dim\":self.output_dim,\n+            \"depth\":self.depth,\n+            \"init\":self.init.__name__,\n+            \"inner_init\":self.inner_init.__name__,\n+            \"activation\":self.activation.__name__,\n+            \"truncate_gradient\":self.truncate_gradient,\n+            \"return_sequences\":self.return_sequences}\n+\n \n \n class GRU(Layer):\n@@ -216,6 +237,16 @@ class GRU(Layer):\n             return outputs.dimshuffle((1,0,2))\n         return outputs[-1]\n \n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+            \"input_dim\":self.input_dim,\n+            \"output_dim\":self.output_dim,\n+            \"init\":self.init.__name__,\n+            \"inner_init\":self.inner_init.__name__,\n+            \"activation\":self.activation.__name__,\n+            \"truncate_gradient\":self.truncate_gradient,\n+            \"return_sequences\":self.return_sequences}\n+\n \n \n class LSTM(Layer):\n@@ -319,4 +350,14 @@ class LSTM(Layer):\n             return outputs.dimshuffle((1,0,2))\n         return outputs[-1]\n \n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+            \"input_dim\":self.input_dim,\n+            \"output_dim\":self.output_dim,\n+            \"init\":self.init.__name__,\n+            \"inner_init\":self.inner_init.__name__,\n+            \"activation\":self.activation.__name__,\n+            \"truncate_gradient\":self.truncate_gradient,\n+            \"return_sequences\":self.return_sequences}\n+        \n \n\n@@ -210,6 +210,17 @@ class Sequential(object):\n         else:\n             return tot_score/len(batches)\n \n+    def describe(self, verbose=1):\n+        layers = []\n+        for i, l in enumerate(self.layers):\n+            config = l.get_config()\n+            layers.append(config)\n+            if verbose:\n+                print('Layer %d: %s' % (i, config.get('name', '?')))\n+                for k, v in config.items():\n+                    if k != 'name':\n+                        print('... ' + k + ' = ' + str(v))\n+        return layers\n \n     def save_weights(self, filepath):\n         # Save weights from all layers to HDF5\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#83a01f4a46ee5de1e92b84024f3cc8a3fd6825cd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 424 | Contributors (this commit): 7 | Commits (past 90d): 18 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -236,6 +236,8 @@ class Sequential(object):\n                 param_name = 'param_{}'.format(n)\n                 param_dset = g.create_dataset(param_name, param.shape, dtype='float64')\n                 param_dset[:] = param\n+            for k, v in l.get_config().items():\n+                g.attrs[k] = v\n         f.flush()\n         f.close()\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4f89b0110f0328c4e2af3db4288a0388e78c5a65", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 19 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -48,7 +48,7 @@ class Progbar(object):\n         now = time.time()\n         if self.verbose == 1:\n             prev_total_width = self.total_width\n-            sys.stdout.write(\"\\b\" * (self.total_width+1))\n+            sys.stdout.write(\"\\r\")\n \n             bar = '%d/%d [' % (current, self.target)\n             prog = float(current)/self.target\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bc14d15094ba85b43c22fe7926ba31929c25a382", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 46 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 48 | Churn Cumulative: 84 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -10,9 +10,53 @@ from ..utils.theano_utils import shared_zeros\n from ..layers.core import Layer\n \n \n-# class Convolution1D(Layer): TODO\n+class Convolution1D(Layer):\n+    def __init__(self, nb_filter, stack_size, filter_length,\n+        init='uniform', activation='linear', weights=None,\n+        image_shape=None, border_mode='valid', subsample_length=1):\n+\n+        nb_row = 1\n+        nb_col = filter_length\n+        subsample=(1,subsample_length)\n+        self.init = initializations.get(init)\n+        self.activation = activations.get(activation)\n+        self.subsample = subsample\n+        self.border_mode = border_mode\n+        self.image_shape = image_shape\n+\n+        self.input = T.tensor4()\n+        self.W_shape = (nb_filter, stack_size, nb_row, nb_col)\n+        self.W = self.init(self.W_shape)\n+        self.b = shared_zeros((nb_filter,))\n+\n+        self.params = [self.W, self.b]\n+\n+        if weights is not None:\n+            self.set_weights(weights)\n+\n+    def output(self, train):\n+        X = self.get_input(train)\n+\n+        conv_out = theano.tensor.nnet.conv.conv2d(X, self.W,\n+            border_mode=self.border_mode, subsample=self.subsample, image_shape=self.image_shape)\n+        output = self.activation(conv_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n+        return output\n+\n+\n+class MaxPooling1D(Layer):\n+    def __init__(self, pool_length=2, ignore_border=True):\n+        poolsize=(1, pool_length)\n+        self.input = T.tensor4()\n+        self.poolsize = poolsize\n+        self.ignore_border = ignore_border\n+        self.params = []\n+\n+    def output(self, train):\n+        X = self.get_input(train)\n+        output = downsample.max_pool_2d(X, self.poolsize, ignore_border=self.ignore_border)\n+        return output\n+\n \n-# class MaxPooling1D(Layer): TODO\n \n \n class Convolution2D(Layer):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#43206aeb141b938305e7f45ee8d91fa31d51019d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 67 | Contributors (this commit): 1 | Commits (past 90d): 5 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -5,11 +5,16 @@\n '''\n from __future__ import absolute_import\n \n-import string\n+import string, sys\n import numpy as np\n from six.moves import range\n from six.moves import zip\n \n+if sys.version_info < (3,):\n+    maketrans = string.maketrans\n+else:\n+    maketrans = str.maketrans\n+\n def base_filter():\n     f = string.punctuation\n     f = f.replace(\"'\", '')\n@@ -21,7 +26,7 @@ def text_to_word_sequence(text, filters=base_filter(), lower=True, split=\" \"):\n     '''\n     if lower:\n         text = text.lower()\n-    text = text.translate(string.maketrans(filters, split*len(filters)))\n+    text = text.translate(maketrans(filters, split*len(filters)))\n     seq = text.split(split)\n     return [_f for _f in seq if _f]\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f143fac5244b8302f729bf35f73947bff3e376c2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 20 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -48,6 +48,7 @@ class Progbar(object):\n         now = time.time()\n         if self.verbose == 1:\n             prev_total_width = self.total_width\n+            sys.stdout.write(\"\\b\" * (self.total_width+1))\n             sys.stdout.write(\"\\r\")\n \n             bar = '%d/%d [' % (current, self.target)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f6d6de8922af4b4a157cfc9869bb5501a05966b1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 1 | Churn Cumulative: 425 | Contributors (this commit): 8 | Commits (past 90d): 19 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -237,6 +237,7 @@ class Sequential(object):\n                 param_dset = g.create_dataset(param_name, param.shape, dtype='float64')\n                 param_dset[:] = param\n             for k, v in l.get_config().items():\n+                if v is not None:\n                     g.attrs[k] = v\n         f.flush()\n         f.close()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
