{"custom_id": "keras#24ffc7cadb0e54a56d77527a0b9e47053dfebc97", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 3 | Churn Cumulative: 219 | Contributors (this commit): 7 | Commits (past 90d): 9 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -413,6 +413,9 @@ def associative_scan(f, elems, reverse=False, axis=0):\n         elems_flat = [torch.flip(elem, (axis,)) for elem in elems_flat]\n \n     def _combine(a_flat, b_flat):\n+        a_flat = [convert_to_tensor(a) for a in a_flat]\n+        b_flat = [convert_to_tensor(b) for b in b_flat]\n+\n         a = optree.tree_unflatten(tree, a_flat)\n         b = optree.tree_unflatten(tree, b_flat)\n         c = f(a, b)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#63919d01add02d8d44271941d664e895c5898b93", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 38 | Lines Deleted: 10 | Files Changed: 7 | Hunks: 15 | Methods Changed: 7 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 48 | Churn Cumulative: 1493 | Contributors (this commit): 5 | Commits (past 90d): 31 | Contributors (cumulative): 23 | DMM Complexity: 0.8947368421052632\n\nDIFF:\n@@ -188,9 +188,9 @@ def resize(\n         else:\n             height, width = shape[-2], shape[-1]\n         crop_height = int(float(width * target_height) / target_width)\n-        crop_height = min(height, crop_height)\n+        crop_height = max(min(height, crop_height), 1)\n         crop_width = int(float(height * target_width) / target_height)\n-        crop_width = min(width, crop_width)\n+        crop_width = max(min(width, crop_width), 1)\n         crop_box_hstart = int(float(height - crop_height) / 2)\n         crop_box_wstart = int(float(width - crop_width) / 2)\n         if data_format == \"channels_last\":\n\n@@ -184,9 +184,9 @@ def resize(\n         else:\n             height, width = shape[-2], shape[-1]\n         crop_height = int(float(width * target_height) / target_width)\n-        crop_height = min(height, crop_height)\n+        crop_height = max(min(height, crop_height), 1)\n         crop_width = int(float(height * target_width) / target_height)\n-        crop_width = min(width, crop_width)\n+        crop_width = max(min(width, crop_width), 1)\n         crop_box_hstart = int(float(height - crop_height) / 2)\n         crop_box_wstart = int(float(width - crop_width) / 2)\n         if data_format == \"channels_last\":\n\n@@ -151,13 +151,13 @@ def resize(\n             tf.cast(width * target_height, \"float32\") / target_width,\n             \"int32\",\n         )\n-        crop_height = tf.minimum(height, crop_height)\n+        crop_height = tf.maximum(tf.minimum(height, crop_height), 1)\n         crop_height = tf.cast(crop_height, \"int32\")\n         crop_width = tf.cast(\n             tf.cast(height * target_width, \"float32\") / target_height,\n             \"int32\",\n         )\n-        crop_width = tf.minimum(width, crop_width)\n+        crop_width = tf.maximum(tf.minimum(width, crop_width), 1)\n         crop_width = tf.cast(crop_width, \"int32\")\n \n         crop_box_hstart = tf.cast(\n\n@@ -193,9 +193,9 @@ def resize(\n         height, width = shape[-2], shape[-1]\n         target_height, target_width = size\n         crop_height = int(float(width * target_height) / target_width)\n-        crop_height = min(height, crop_height)\n+        crop_height = max(min(height, crop_height), 1)\n         crop_width = int(float(height * target_width) / target_height)\n-        crop_width = min(width, crop_width)\n+        crop_width = max(min(width, crop_width), 1)\n         crop_box_hstart = int(float(height - crop_height) / 2)\n         crop_box_wstart = int(float(width - crop_width) / 2)\n         if len(images.shape) == 4:\n\n@@ -194,3 +194,18 @@ class CenterCropTest(testing.TestCase, parameterized.TestCase):\n         )\n         self.assertEqual(tuple(output.shape), output_shape)\n         self.assertAllClose(ref_output, output)\n+\n+    @parameterized.parameters(\n+        [((5, 17), \"channels_last\"), ((5, 100), \"channels_last\")]\n+    )\n+    def test_image_stretch(self, size, data_format):\n+        img = np.random.rand(2, 11, 3, 9)\n+        out = layers.CenterCrop(\n+            size[0],\n+            size[1],\n+            data_format=data_format,\n+        )(img)\n+        ref_out = layers.Resizing(\n+            size[0], size[1], data_format=data_format, crop_to_aspect_ratio=True\n+        )(img)\n+        self.assertAllClose(ref_out, out)\n\n@@ -213,3 +213,13 @@ class ResizingTest(testing.TestCase, parameterized.TestCase):\n         for output in ds.take(1):\n             output = output.numpy()\n         self.assertEqual(tuple(output.shape), output_shape)\n+\n+    @parameterized.parameters(\n+        [((15, 10), \"channels_last\"), ((15, 100), \"channels_last\")]\n+    )\n+    def test_data_stretch(self, size, data_format):\n+        img = np.random.rand(1, 1, 4, 4)\n+        output = layers.Resizing(\n+            size[0], size[1], data_format=data_format, crop_to_aspect_ratio=True\n+        )(img)\n+        self.assertEqual(output.shape, (1, *size, 4))\n\n@@ -388,9 +388,9 @@ def smart_resize(\n     if isinstance(height, int) and isinstance(width, int):\n         # For JAX, we need to keep the slice indices as static integers\n         crop_height = int(float(width * target_height) / target_width)\n-        crop_height = min(height, crop_height)\n+        crop_height = max(min(height, crop_height), 1)\n         crop_width = int(float(height * target_width) / target_height)\n-        crop_width = min(width, crop_width)\n+        crop_width = max(min(width, crop_width), 1)\n         crop_box_hstart = int(float(height - crop_height) / 2)\n         crop_box_wstart = int(float(width - crop_width) / 2)\n     else:\n@@ -400,13 +400,16 @@ def smart_resize(\n             \"int32\",\n         )\n         crop_height = backend_module.numpy.minimum(height, crop_height)\n+        crop_height = backend_module.numpy.maximum(crop_height, 1)\n         crop_height = backend_module.cast(crop_height, \"int32\")\n+\n         crop_width = backend_module.cast(\n             backend_module.cast(height * target_width, \"float32\")\n             / target_height,\n             \"int32\",\n         )\n         crop_width = backend_module.numpy.minimum(width, crop_width)\n+        crop_width = backend_module.numpy.maximum(crop_width, 1)\n         crop_width = backend_module.cast(crop_width, \"int32\")\n \n         crop_box_hstart = backend_module.cast(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#38ef5f26244ab8042ad62ee2b52c5303f2539590", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 10 | Churn Cumulative: 109 | Contributors (this commit): 4 | Commits (past 90d): 6 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1001,12 +1001,6 @@ class Trainer:\n         optimizer_unbuilt = (\n             self.optimizer is not None and not self.optimizer.built\n         )\n-        if model_unbuilt or compile_metrics_unbuilt or optimizer_unbuilt:\n-            if data_batch is None:\n-                for _, data in iterator.enumerate_epoch():\n-                    data_batch = data[0]\n-                    break\n-\n         if model_unbuilt or compile_metrics_unbuilt:\n             # Create symbolic tensors matching an input batch.\n \n@@ -1017,6 +1011,10 @@ class Trainer:\n                     v.shape, backend.standardize_dtype(v.dtype)\n                 )\n \n+            if data_batch is None:\n+                for _, data in iterator.enumerate_epoch():\n+                    data_batch = data[0]\n+                    break\n             data_batch = tree.map_structure(to_symbolic_input, data_batch)\n             (\n                 x,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f81009b4d45504a9ae4a75965ee4d248821d4ea9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 15 | Churn Cumulative: 567 | Contributors (this commit): 8 | Commits (past 90d): 37 | Contributors (cumulative): 13 | DMM Complexity: 0.0\n\nDIFF:\n@@ -381,7 +381,8 @@ def ceil(x):\n         dtype = config.floatx()\n     else:\n         dtype = dtypes.result_type(x.dtype, float)\n-    return cast(jnp.ceil(x), dtype)\n+    x = cast(x, dtype)\n+    return jnp.ceil(x)\n \n \n def clip(x, x_min, x_max):\n@@ -558,7 +559,10 @@ def flip(x, axis=None):\n def floor(x):\n     x = convert_to_tensor(x)\n     if standardize_dtype(x.dtype) == \"int64\":\n-        x = cast(x, config.floatx())\n+        dtype = config.floatx()\n+    else:\n+        dtype = dtypes.result_type(x.dtype, float)\n+    x = cast(x, dtype)\n     return jnp.floor(x)\n \n \n\n@@ -12,6 +12,7 @@ import keras\n from keras.src import backend\n from keras.src import testing\n from keras.src.backend.common import dtypes\n+from keras.src.backend.common import is_int_dtype\n from keras.src.backend.common import standardize_dtype\n from keras.src.backend.common.keras_tensor import KerasTensor\n from keras.src.ops import numpy as knp\n@@ -5794,7 +5795,8 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n         x = knp.array(value, dtype=dtype)\n         x_jax = jnp.array(value, dtype=dtype)\n         expected_dtype = standardize_dtype(jnp.ceil(x_jax).dtype)\n-        if dtype == \"int64\":\n+        # Here, we follow Numpy's rule, not JAX's; ints are promoted to floats.\n+        if dtype == \"bool\" or is_int_dtype(dtype):\n             expected_dtype = backend.floatx()\n \n         self.assertEqual(standardize_dtype(knp.ceil(x).dtype), expected_dtype)\n@@ -6377,7 +6379,8 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n         x = knp.ones((1,), dtype=dtype)\n         x_jax = jnp.ones((1,), dtype=dtype)\n         expected_dtype = standardize_dtype(jnp.floor(x_jax).dtype)\n-        if dtype == \"int64\":\n+        # Here, we follow Numpy's rule, not JAX's; ints are promoted to floats.\n+        if dtype == \"bool\" or is_int_dtype(dtype):\n             expected_dtype = backend.floatx()\n \n         self.assertEqual(standardize_dtype(knp.floor(x).dtype), expected_dtype)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d910dcb827a744b88b5a5a7bdcf4e499722a031f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 65 | Lines Deleted: 20 | Files Changed: 2 | Hunks: 13 | Methods Changed: 8 | Complexity Δ (Sum/Max): 8/8 | Churn Δ: 85 | Churn Cumulative: 113 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -94,26 +94,18 @@ class TFLayer(KerasAutoTrackable):\n             inputs = self.input\n \n         if inputs is not None:\n-            input_signature = [\n+            input_signature = (\n                 tree.map_structure(\n-                    lambda x: tf.TensorSpec(x.shape, self.compute_dtype),\n-                    inputs,\n+                    lambda x: tf.TensorSpec(x.shape, x.dtype), inputs\n+                ),\n             )\n-            ]\n         else:\n-            shapes_dict = self._build_shapes_dict\n-            if len(shapes_dict) == 1:\n-                input_shape = tuple(shapes_dict.values())[0]\n-                input_signature = [\n-                    tf.TensorSpec(input_shape, self.compute_dtype)\n-                ]\n-            else:\n-                input_signature = [\n-                    tree.map_structure(\n-                        lambda x: tf.TensorSpec(x.shape, self.compute_dtype),\n-                        shapes_dict,\n+            input_signature = tuple(\n+                tree.map_shape_structure(\n+                    lambda s: tf.TensorSpec(s, self.input_dtype), value\n+                )\n+                for value in self._build_shapes_dict.values()\n             )\n-                ]\n \n         @tf.function(input_signature=input_signature)\n         def serving_default(inputs):\n\n@@ -5,14 +5,17 @@ import os\n import numpy as np\n import pytest\n import tensorflow as tf\n+from absl.testing import parameterized\n \n from keras.src import backend\n from keras.src import layers\n from keras.src import metrics\n from keras.src import models\n+from keras.src import ops\n from keras.src import optimizers\n from keras.src import testing\n from keras.src.saving import object_registration\n+from keras.src.testing.test_utils import named_product\n \n \n @object_registration.register_keras_serializable(package=\"my_package\")\n@@ -49,7 +52,7 @@ class CustomSignatureModel(models.Model):\n     backend.backend() != \"tensorflow\",\n     reason=\"The SavedModel test can only run with TF backend.\",\n )\n-class SavedModelTest(testing.TestCase):\n+class SavedModelTest(testing.TestCase, parameterized.TestCase):\n     def test_sequential(self):\n         model = models.Sequential([layers.Dense(1)])\n         model.compile(loss=\"mse\", optimizer=\"adam\")\n@@ -143,6 +146,52 @@ class SavedModelTest(testing.TestCase):\n             atol=1e-4,\n         )\n \n+    @parameterized.named_parameters(\n+        named_product(struct_type=[\"tuple\", \"array\", \"dict\"])\n+    )\n+    def test_model_with_input_structure(self, struct_type):\n+\n+        class TupleModel(models.Model):\n+\n+            def call(self, inputs):\n+                x, y = inputs\n+                return x + ops.mean(y, axis=1)\n+\n+        class ArrayModel(models.Model):\n+\n+            def call(self, inputs):\n+                x = inputs[0]\n+                y = inputs[1]\n+                return x + ops.mean(y, axis=1)\n+\n+        class DictModel(models.Model):\n+\n+            def call(self, inputs):\n+                x = inputs[\"x\"]\n+                y = inputs[\"y\"]\n+                return x + ops.mean(y, axis=1)\n+\n+        input_x = tf.constant([1.0])\n+        input_y = tf.constant([[1.0, 0.0, 2.0]])\n+        if struct_type == \"tuple\":\n+            model = TupleModel()\n+            inputs = (input_x, input_y)\n+        elif struct_type == \"array\":\n+            model = ArrayModel()\n+            inputs = [input_x, input_y]\n+        elif struct_type == \"dict\":\n+            model = DictModel()\n+            inputs = {\"x\": input_x, \"y\": input_y}\n+\n+        result = model(inputs)\n+        path = os.path.join(self.get_temp_dir(), \"my_keras_model\")\n+        tf.saved_model.save(model, path)\n+        restored_model = tf.saved_model.load(path)\n+        outputs = restored_model.signatures[\"serving_default\"](\n+            inputs=input_x, inputs_1=input_y\n+        )\n+        self.assertAllClose(result, outputs[\"output_0\"], rtol=1e-4, atol=1e-4)\n+\n     def test_multi_input_model(self):\n         input_1 = layers.Input(shape=(3,))\n         input_2 = layers.Input(shape=(5,))\n@@ -169,15 +218,19 @@ class SavedModelTest(testing.TestCase):\n     def test_multi_input_custom_model_and_layer(self):\n         @object_registration.register_keras_serializable(package=\"my_package\")\n         class CustomLayer(layers.Layer):\n-            def __call__(self, *input_list):\n+            def build(self, *input_shape):\n+                self.built = True\n+\n+            def call(self, *input_list):\n                 self.add_loss(input_list[-2] * 2)\n                 return sum(input_list)\n \n         @object_registration.register_keras_serializable(package=\"my_package\")\n         class CustomModel(models.Model):\n-            def build(self, input_shape):\n-                super().build(input_shape)\n+            def build(self, *input_shape):\n                 self.layer = CustomLayer()\n+                self.layer.build(*input_shape)\n+                self.built = True\n \n             @tf.function\n             def call(self, *inputs):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1b75407438d42f5242eaf8a99e3eeb3a66e361e7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 72 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -98,7 +98,7 @@ def initialize(job_addresses=None, num_processes=None, process_id=None):\n         ```python\n         os.environ[\n             \"KERAS_DISTRIBUTION_JOB_ADDRESSES\"] = \"10.0.0.1:1234,10.0.0.2:2345\"\n-        os.environ[\"KERAS_DISTRIBUTION_NUM_PROCESSES\"] = \"2\n+        os.environ[\"KERAS_DISTRIBUTION_NUM_PROCESSES\"] = \"2\"\n         os.environ[\"KERAS_DISTRIBUTION_PROCESS_ID\"] = \"0\"\n         keras.distribute.initialize()\n         ```\n@@ -107,7 +107,7 @@ def initialize(job_addresses=None, num_processes=None, process_id=None):\n         ```python\n         os.environ[\n             \"KERAS_DISTRIBUTION_JOB_ADDRESSES\"] = \"10.0.0.1:1234,10.0.0.2:2345\"\n-        os.environ[\"KERAS_DISTRIBUTION_NUM_PROCESSES\"] = \"2\n+        os.environ[\"KERAS_DISTRIBUTION_NUM_PROCESSES\"] = \"2\"\n         os.environ[\"KERAS_DISTRIBUTION_PROCESS_ID\"] = \"1\"\n         keras.distribute.initialize()\n         ```\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ca9519bf182650cd464d6825de451471b3243627", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 42 | Lines Deleted: 79 | Files Changed: 7 | Hunks: 25 | Methods Changed: 22 | Complexity Δ (Sum/Max): -1/1 | Churn Δ: 121 | Churn Cumulative: 1166 | Contributors (this commit): 6 | Commits (past 90d): 62 | Contributors (cumulative): 18 | DMM Complexity: 0.0\n\nDIFF:\n@@ -524,15 +524,12 @@ class Dense(Layer):\n             x = self.activation(x)\n         return x\n \n-    def quantize(self, mode):\n+    def quantize(self, mode, type_check=True):\n         import gc\n \n         # Prevent quantization of the subclasses\n-        if type(self) is not Dense:\n-            raise NotImplementedError(\n-                f\"Layer {self.__class__.__name__} does not have a `quantize()` \"\n-                \"method implemented.\"\n-            )\n+        if type_check and (type(self) is not Dense):\n+            raise self._quantize_not_implemented_error()\n         self._check_quantize_args(mode, self.compute_dtype)\n \n         self._tracker.unlock()\n\n@@ -408,6 +408,8 @@ class DenseTest(testing.TestCase, parameterized.TestCase):\n         with self.assertRaises(NotImplementedError):\n             layer.quantize(mode)\n \n+        layer.quantize(mode, type_check=False)  # No error\n+\n     @parameterized.named_parameters(\n         (\"int8\", \"int8\"),\n         (\"float8\", \"float8\"),\n@@ -422,12 +424,7 @@ class DenseTest(testing.TestCase, parameterized.TestCase):\n             ):\n                 layer.quantize(m)\n \n-    @parameterized.named_parameters(\n-        (\"int8\", \"int8_from_float32\"),\n-        (\"float8\", \"float8_from_float32\"),\n-    )\n-    def test_quantize_when_already_quantized_using_dtype_argument(self, mode):\n-        layer = layers.Dense(units=2, dtype=mode)\n+        layer = layers.Dense(units=2, dtype=f\"{mode}_from_float32\")\n         layer.build((None, 2))\n         for m in [\"int8\", \"float8\"]:\n             with self.assertRaisesRegex(\n@@ -479,18 +476,21 @@ class DenseTest(testing.TestCase, parameterized.TestCase):\n             layer.quantized_call(x)\n         self.assertEqual(layer.dtype_policy, original_dtype_policy)\n \n+    @parameterized.named_parameters(\n+        (\"int8\", \"int8_from_mixed_bfloat16\", 1, 2),\n+        (\"float8\", \"float8_from_mixed_bfloat16\", 8, 0),\n+    )\n     @pytest.mark.requires_trainable_backend\n-    def test_quantize_int8_dtype_argument(self):\n+    def test_quantize_dtype_argument(\n+        self, dtype, num_trainable_weights, num_non_trainable_weights\n+    ):\n         self.run_layer_test(\n             layers.Dense,\n-            init_kwargs={\n-                \"units\": 5,\n-                \"dtype\": \"int8_from_mixed_bfloat16\",\n-            },\n+            init_kwargs={\"units\": 5, \"dtype\": dtype},\n             input_shape=(2, 3, 4),\n             expected_output_shape=(2, 3, 5),\n-            expected_num_trainable_weights=1,\n-            expected_num_non_trainable_weights=2,\n+            expected_num_trainable_weights=num_trainable_weights,\n+            expected_num_non_trainable_weights=num_non_trainable_weights,\n             expected_num_seed_generators=0,\n             expected_num_losses=0,\n             supports_masking=True,\n@@ -577,23 +577,6 @@ class DenseTest(testing.TestCase, parameterized.TestCase):\n                 len(model.non_trainable_weights),\n             )\n \n-    @pytest.mark.requires_trainable_backend\n-    def test_quantize_float8_dtype_argument(self):\n-        self.run_layer_test(\n-            layers.Dense,\n-            init_kwargs={\n-                \"units\": 5,\n-                \"dtype\": \"float8_from_mixed_bfloat16\",\n-            },\n-            input_shape=(2, 3, 4),\n-            expected_output_shape=(2, 3, 5),\n-            expected_num_trainable_weights=8,\n-            expected_num_non_trainable_weights=0,\n-            expected_num_seed_generators=0,\n-            expected_num_losses=0,\n-            supports_masking=True,\n-        )\n-\n     @pytest.mark.requires_trainable_backend\n     def test_quantize_float8(self):\n         import ml_dtypes\n\n@@ -640,15 +640,12 @@ class EinsumDense(Layer):\n             x = self.activation(x)\n         return x\n \n-    def quantize(self, mode):\n+    def quantize(self, mode, type_check=True):\n         import gc\n \n         # Prevent quantization of the subclasses\n-        if type(self) is not EinsumDense:\n-            raise NotImplementedError(\n-                f\"Layer {self.__class__.__name__} does not have a `quantize()` \"\n-                \"method implemented.\"\n-            )\n+        if type_check and (type(self) is not EinsumDense):\n+            raise self._quantize_not_implemented_error()\n         self._check_quantize_args(mode, self.compute_dtype)\n \n         self._tracker.unlock()\n\n@@ -515,6 +515,8 @@ class EinsumDenseTest(testing.TestCase, parameterized.TestCase):\n         with self.assertRaises(NotImplementedError):\n             layer.quantize(mode)\n \n+        layer.quantize(mode, type_check=False)  # No error\n+\n     @parameterized.named_parameters(\n         (\"int8\", \"int8\"),\n         (\"float8\", \"float8\"),\n@@ -533,16 +535,11 @@ class EinsumDenseTest(testing.TestCase, parameterized.TestCase):\n             ):\n                 layer.quantize(m)\n \n-    @parameterized.named_parameters(\n-        (\"int8\", \"int8_from_float32\"),\n-        (\"float8\", \"float8_from_float32\"),\n-    )\n-    def test_quantize_when_already_quantized_using_dtype_argument(self, mode):\n         layer = layers.EinsumDense(\n             equation=\"ab,bcd->acd\",\n             output_shape=(8, 16),\n             bias_axes=\"d\",\n-            dtype=mode,\n+            dtype=f\"{mode}_from_float32\",\n         )\n         layer.build((None, 3))\n         for m in [\"int8\", \"float8\"]:\n@@ -603,20 +600,26 @@ class EinsumDenseTest(testing.TestCase, parameterized.TestCase):\n             layer.quantized_call(x)\n         self.assertEqual(layer.dtype_policy, original_dtype_policy)\n \n+    @parameterized.named_parameters(\n+        (\"int8\", \"int8_from_mixed_bfloat16\", 1, 2),\n+        (\"float8\", \"float8_from_mixed_bfloat16\", 8, 0),\n+    )\n     @pytest.mark.requires_trainable_backend\n-    def test_quantize_int8_dtype_argument(self):\n+    def test_quantize_dtype_argument(\n+        self, dtype, num_trainable_weights, num_non_trainable_weights\n+    ):\n         self.run_layer_test(\n             layers.EinsumDense,\n             init_kwargs={\n                 \"equation\": \"ab,bcd->acd\",\n                 \"output_shape\": (8, 32),\n                 \"bias_axes\": \"d\",\n-                \"dtype\": \"int8_from_mixed_bfloat16\",\n+                \"dtype\": dtype,\n             },\n             input_shape=(2, 3),\n             expected_output_shape=(2, 8, 32),\n-            expected_num_trainable_weights=1,\n-            expected_num_non_trainable_weights=2,\n+            expected_num_trainable_weights=num_trainable_weights,\n+            expected_num_non_trainable_weights=num_non_trainable_weights,\n             expected_num_seed_generators=0,\n             expected_num_losses=0,\n             supports_masking=False,\n@@ -705,25 +708,6 @@ class EinsumDenseTest(testing.TestCase, parameterized.TestCase):\n                 len(model.non_trainable_weights),\n             )\n \n-    @pytest.mark.requires_trainable_backend\n-    def test_quantize_float8_dtype_argument(self):\n-        self.run_layer_test(\n-            layers.EinsumDense,\n-            init_kwargs={\n-                \"equation\": \"ab,bcd->acd\",\n-                \"output_shape\": (8, 32),\n-                \"bias_axes\": \"d\",\n-                \"dtype\": \"float8_from_mixed_bfloat16\",\n-            },\n-            input_shape=(2, 3),\n-            expected_output_shape=(2, 8, 32),\n-            expected_num_trainable_weights=8,\n-            expected_num_non_trainable_weights=0,\n-            expected_num_seed_generators=0,\n-            expected_num_losses=0,\n-            supports_masking=False,\n-        )\n-\n     @pytest.mark.requires_trainable_backend\n     def test_quantize_float8(self):\n         import ml_dtypes\n\n@@ -344,15 +344,12 @@ class Embedding(Layer):\n             outputs = ops.add(outputs, lora_outputs)\n         return outputs\n \n-    def quantize(self, mode):\n+    def quantize(self, mode, type_check=True):\n         import gc\n \n         # Prevent quantization of the subclasses\n-        if type(self) is not Embedding:\n-            raise NotImplementedError(\n-                f\"Layer {self.__class__.__name__} does not have a `quantize()` \"\n-                \"method implemented.\"\n-            )\n+        if type_check and (type(self) is not Embedding):\n+            raise self._quantize_not_implemented_error()\n         self._check_quantize_args(mode, self.compute_dtype)\n \n         self._tracker.unlock()\n\n@@ -308,9 +308,12 @@ class EmbeddingTest(test_case.TestCase, parameterized.TestCase):\n             pass\n \n         layer = MyEmbedding(10, 16)\n+        layer.build()\n         with self.assertRaises(NotImplementedError):\n             layer.quantize(\"int8\")\n \n+        layer.quantize(\"int8\", type_check=False)  # No error\n+\n     def test_quantize_when_already_quantized(self):\n         layer = layers.Embedding(10, 16)\n         layer.build()\n@@ -320,7 +323,6 @@ class EmbeddingTest(test_case.TestCase, parameterized.TestCase):\n         ):\n             layer.quantize(\"int8\")\n \n-    def test_quantize_when_already_quantized_using_dtype_argument(self):\n         layer = layers.Embedding(10, 16, dtype=\"int8_from_float32\")\n         layer.build()\n         with self.assertRaisesRegex(\n\n@@ -1171,7 +1171,10 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n             layer._clear_losses()\n \n     def quantize(self, mode):\n-        raise NotImplementedError(\n+        raise self._quantize_not_implemented_error()\n+\n+    def _quantize_not_implemented_error(self):\n+        return NotImplementedError(\n             f\"Layer {self.__class__.__name__} does not have a `quantize()` \"\n             \"method implemented.\"\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#62838f9c409c009521bbef27da2ec762e821b981", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 130 | Lines Deleted: 0 | Files Changed: 8 | Hunks: 11 | Methods Changed: 9 | Complexity Δ (Sum/Max): 20/6 | Churn Δ: 130 | Churn Cumulative: 2634 | Contributors (this commit): 11 | Commits (past 90d): 133 | Contributors (cumulative): 56 | DMM Complexity: 1.0\n\nDIFF:\n@@ -199,6 +199,7 @@ from keras.src.ops.numpy import repeat\n from keras.src.ops.numpy import reshape\n from keras.src.ops.numpy import roll\n from keras.src.ops.numpy import round\n+from keras.src.ops.numpy import searchsorted\n from keras.src.ops.numpy import select\n from keras.src.ops.numpy import sign\n from keras.src.ops.numpy import sin\n\n@@ -199,6 +199,7 @@ from keras.src.ops.numpy import repeat\n from keras.src.ops.numpy import reshape\n from keras.src.ops.numpy import roll\n from keras.src.ops.numpy import round\n+from keras.src.ops.numpy import searchsorted\n from keras.src.ops.numpy import select\n from keras.src.ops.numpy import sign\n from keras.src.ops.numpy import sin\n\n@@ -878,6 +878,15 @@ def roll(x, shift, axis=None):\n     return jnp.roll(x, shift, axis=axis)\n \n \n+def searchsorted(sorted_sequence, values, side=\"left\"):\n+    if ndim(sorted_sequence) != 1:\n+        raise ValueError(\n+            \"searchsorted only supports 1-D sorted sequences. Use\"\n+            \"keras.ops.vectorized_map to extend to N-D sequences.\"\n+        )\n+    return jnp.searchsorted(sorted_sequence, values, side=side)\n+\n+\n @sparse.elementwise_unary(linear=False)\n def sign(x):\n     x = convert_to_tensor(x)\n\n@@ -789,6 +789,18 @@ def roll(x, shift, axis=None):\n     return np.roll(x, shift, axis=axis)\n \n \n+def searchsorted(sorted_sequence, values, side=\"left\"):\n+    if ndim(sorted_sequence) != 1:\n+        raise ValueError(\n+            \"searchsorted only supports 1-D sorted sequences. Use\"\n+            \"keras.ops.vectorized_map to extend to N-D sequences.\"\n+        )\n+    out_type = (\n+        \"int32\" if len(sorted_sequence) <= np.iinfo(np.int32).max else \"int64\"\n+    )\n+    return np.searchsorted(sorted_sequence, values, side=side).astype(out_type)\n+\n+\n def sign(x):\n     return np.sign(x)\n \n\n@@ -1800,6 +1800,20 @@ def roll(x, shift, axis=None):\n     return tf.reshape(x, original_shape)\n \n \n+def searchsorted(sorted_sequence, values, side=\"left\"):\n+    if ndim(sorted_sequence) != 1:\n+        raise ValueError(\n+            \"searchsorted only supports 1-D sorted sequences. Use\"\n+            \"keras.ops.vectorized_map to extend to N-D sequences.\"\n+        )\n+    out_type = (\n+        \"int32\" if len(sorted_sequence) <= np.iinfo(np.int32).max else \"int64\"\n+    )\n+    return tf.searchsorted(\n+        sorted_sequence, values, side=side, out_type=out_type\n+    )\n+\n+\n @sparse.elementwise_unary\n def sign(x):\n     x = convert_to_tensor(x)\n\n@@ -1,6 +1,7 @@\n import builtins\n import math\n \n+import numpy as np\n import torch\n \n from keras.src.backend import KerasTensor\n@@ -1194,6 +1195,18 @@ def roll(x, shift, axis=None):\n     return torch.roll(x, shift, dims=axis)\n \n \n+def searchsorted(sorted_sequence, values, side=\"left\"):\n+    if ndim(sorted_sequence) != 1:\n+        raise ValueError(\n+            \"searchsorted only supports 1-D sorted sequences. Use\"\n+            \"keras.ops.vectorized_map to extend to N-D sequences.\"\n+        )\n+    out_int32 = len(sorted_sequence) <= np.iinfo(np.int32).max\n+    return torch.searchsorted(\n+        sorted_sequence, values, side=side, out_int32=out_int32\n+    )\n+\n+\n def sign(x):\n     x = convert_to_tensor(x)\n     return torch.sign(x)\n\n@@ -4503,6 +4503,49 @@ def round(x, decimals=0):\n     return backend.numpy.round(x, decimals)\n \n \n+class SearchSorted(Operation):\n+    def call(self, sorted_sequence, values, side=\"left\"):\n+        sorted_sequence = backend.convert_to_tensor(sorted_sequence)\n+        values = backend.convert_to_tensor(values)\n+        return backend.numpy.searchsorted(sorted_sequence, values, side=side)\n+\n+    def compute_output_spec(self, sorted_sequence, values, side=\"left\"):\n+        if len(sorted_sequence.shape) != 1:\n+            raise ValueError(\n+                \"searchsorted only supports 1-D sorted sequences. Use\"\n+                \"keras.ops.vectorized_map to extend to N-D sequences.\"\n+            )\n+        out_type = (\n+            \"int32\"\n+            if sorted_sequence.shape[0] <= np.iinfo(np.int32).max\n+            else \"int64\"\n+        )\n+        return KerasTensor(values.shape, dtype=out_type)\n+\n+\n+@keras_export([\"keras.ops.searchsorted\"])\n+def searchsorted(sorted_sequence, values, side=\"left\"):\n+    \"\"\"Perform a binary search, returning indices for insertion of `values`\n+    into `sorted_sequence` that maintain the sorting order.\n+\n+    Args:\n+        sorted_sequence: 1-D input tensor, sorted along the innermost\n+            dimension.\n+        values: N-D tensor of query insertion values.\n+        side: 'left' or 'right', specifying the direction in which to insert\n+            for the equality case (tie-breaker).\n+\n+    Returns:\n+        Tensor of insertion indices of same shape as `values`.\n+    \"\"\"\n+    if any_symbolic_tensors((sorted_sequence, values)):\n+        return SearchSorted().symbolic_call(sorted_sequence, values, side=side)\n+\n+    sorted_sequence = backend.convert_to_tensor(sorted_sequence)\n+    values = backend.convert_to_tensor(values)\n+    return backend.numpy.searchsorted(sorted_sequence, values, side=side)\n+\n+\n class Sign(Operation):\n     def call(self, x):\n         return backend.numpy.sign(x)\n\n@@ -775,6 +775,12 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n             (2, 3, 1),\n         )\n \n+    def test_searchsorted(self):\n+        a = KerasTensor((3,))\n+        v = KerasTensor((2, 3))\n+\n+        self.assertEqual(knp.searchsorted(a, v).shape, v.shape)\n+\n     def test_take(self):\n         x = KerasTensor((2, 3))\n         self.assertEqual(knp.take(x, 1).shape, ())\n@@ -3967,6 +3973,13 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(knp.round(x, decimals=-1), np.round(x, decimals=-1))\n         self.assertAllClose(knp.Round(decimals=-1)(x), np.round(x, decimals=-1))\n \n+    def test_searchsorted(self):\n+        a = np.array([1, 2, 2, 3, 4, 5, 5])\n+        v = np.array([4, 3, 5, 1, 2])\n+        expected = np.searchsorted(a, v).astype(\"int32\")\n+        self.assertAllEqual(knp.searchsorted(a, v), expected)\n+        self.assertAllEqual(knp.SearchSorted()(a, v), expected)\n+\n     def test_sign(self):\n         x = np.array([[1, -2, 3], [-3, 2, -1]])\n         self.assertAllClose(knp.sign(x), np.sign(x))\n@@ -7364,6 +7377,30 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             expected_dtype,\n         )\n \n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n+    def test_searchsorted(self, dtype):\n+        import jax.numpy as jnp\n+\n+        if dtype == \"bool\":\n+            self.skipTest(\"searchsorted doesn't support bool dtype\")\n+\n+        a = knp.ones((3,), dtype=dtype)\n+        v = knp.ones((3,), dtype=dtype)\n+\n+        a_jax = jnp.ones((3,), dtype=dtype)\n+        v_jax = jnp.ones((3,), dtype=dtype)\n+\n+        expected_dtype = standardize_dtype(jnp.searchsorted(a_jax, v_jax).dtype)\n+\n+        self.assertEqual(\n+            standardize_dtype(knp.searchsorted(a, v).dtype), expected_dtype\n+        )\n+\n+        self.assertEqual(\n+            standardize_dtype(knp.SearchSorted().symbolic_call(a, v).dtype),\n+            expected_dtype,\n+        )\n+\n     @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_ravel(self, dtype):\n         import jax.numpy as jnp\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#08e5835a7161d480d1fb71490435a0d8f70ddc7c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 8 | Files Changed: 4 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 24 | Churn Cumulative: 1088 | Contributors (this commit): 7 | Commits (past 90d): 64 | Contributors (cumulative): 24 | DMM Complexity: 1.0\n\nDIFF:\n@@ -881,8 +881,10 @@ def roll(x, shift, axis=None):\n def searchsorted(sorted_sequence, values, side=\"left\"):\n     if ndim(sorted_sequence) != 1:\n         raise ValueError(\n-            \"searchsorted only supports 1-D sorted sequences. Use\"\n-            \"keras.ops.vectorized_map to extend to N-D sequences.\"\n+            \"`searchsorted` only supports 1-D sorted sequences. \"\n+            \"You can use `keras.ops.vectorized_map` \"\n+            \"to extend it to N-D sequences. Received: \"\n+            f\"sorted_sequence.shape={sorted_sequence.shape}\"\n         )\n     return jnp.searchsorted(sorted_sequence, values, side=side)\n \n\n@@ -792,8 +792,10 @@ def roll(x, shift, axis=None):\n def searchsorted(sorted_sequence, values, side=\"left\"):\n     if ndim(sorted_sequence) != 1:\n         raise ValueError(\n-            \"searchsorted only supports 1-D sorted sequences. Use\"\n-            \"keras.ops.vectorized_map to extend to N-D sequences.\"\n+            \"`searchsorted` only supports 1-D sorted sequences. \"\n+            \"You can use `keras.ops.vectorized_map` \"\n+            \"to extend it to N-D sequences. Received: \"\n+            f\"sorted_sequence.shape={sorted_sequence.shape}\"\n         )\n     out_type = (\n         \"int32\" if len(sorted_sequence) <= np.iinfo(np.int32).max else \"int64\"\n\n@@ -1803,8 +1803,10 @@ def roll(x, shift, axis=None):\n def searchsorted(sorted_sequence, values, side=\"left\"):\n     if ndim(sorted_sequence) != 1:\n         raise ValueError(\n-            \"searchsorted only supports 1-D sorted sequences. Use\"\n-            \"keras.ops.vectorized_map to extend to N-D sequences.\"\n+            \"`searchsorted` only supports 1-D sorted sequences. \"\n+            \"You can use `keras.ops.vectorized_map` \"\n+            \"to extend it to N-D sequences. Received: \"\n+            f\"sorted_sequence.shape={sorted_sequence.shape}\"\n         )\n     out_type = (\n         \"int32\" if len(sorted_sequence) <= np.iinfo(np.int32).max else \"int64\"\n\n@@ -1198,8 +1198,10 @@ def roll(x, shift, axis=None):\n def searchsorted(sorted_sequence, values, side=\"left\"):\n     if ndim(sorted_sequence) != 1:\n         raise ValueError(\n-            \"searchsorted only supports 1-D sorted sequences. Use\"\n-            \"keras.ops.vectorized_map to extend to N-D sequences.\"\n+            \"`searchsorted` only supports 1-D sorted sequences. \"\n+            \"You can use `keras.ops.vectorized_map` \"\n+            \"to extend it to N-D sequences. Received: \"\n+            f\"sorted_sequence.shape={sorted_sequence.shape}\"\n         )\n     out_int32 = len(sorted_sequence) <= np.iinfo(np.int32).max\n     return torch.searchsorted(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#53df6c0a7504a9dab6282072b77278522b712f7c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 194 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -144,6 +144,8 @@ class PyDatasetAdapterTest(testing.TestCase, parameterized.TestCase):\n     ):\n         if use_multiprocessing and (infinite or shuffle):\n             pytest.skip(\"Starting processes is slow, only test one variant\")\n+        if testing.tensorflow_uses_gpu():\n+            pytest.skip(\"This test is flaky with TF on GPU\")\n \n         set_random_seed(1337)\n         x = np.random.random((64, 4)).astype(\"float32\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0be3e78459c4c85766fe31ed31b0f98ab67c5de4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 20 | Churn Cumulative: 325 | Contributors (this commit): 4 | Commits (past 90d): 11 | Contributors (cumulative): 7 | DMM Complexity: 0.75\n\nDIFF:\n@@ -536,6 +536,10 @@ def functional_from_config(cls, config, custom_objects=None):\n \n     input_tensors = map_tensors(config[\"input_layers\"])\n     output_tensors = map_tensors(config[\"output_layers\"])\n+    if isinstance(input_tensors, list) and len(input_tensors) == 1:\n+        input_tensors = input_tensors[0]\n+    if isinstance(output_tensors, list) and len(output_tensors) == 1:\n+        output_tensors = output_tensors[0]\n \n     return cls(\n         inputs=input_tensors,\n\n@@ -4,6 +4,7 @@ import warnings\n import numpy as np\n import pytest\n \n+from keras.src import applications\n from keras.src import backend\n from keras.src import layers\n from keras.src import saving\n@@ -12,6 +13,7 @@ from keras.src.layers.core.input_layer import Input\n from keras.src.layers.input_spec import InputSpec\n from keras.src.models import Functional\n from keras.src.models import Model\n+from keras.src.models import Sequential\n \n \n class FunctionalTest(testing.TestCase):\n@@ -466,6 +468,20 @@ class FunctionalTest(testing.TestCase):\n         self.assertAllClose(out, np.ones((2, 2)))\n         # Note: it's not intended to work in symbolic mode (yet).\n \n+    def test_for_functional_in_sequential(self):\n+        # Test for a v3.4.1 regression.\n+        image_size = (100, 100)\n+        base_model = applications.mobilenet.MobileNet(\n+            include_top=False, weights=None\n+        )\n+        model = Sequential()\n+        model.add(layers.Input(shape=image_size + (3,)))\n+        model.add(base_model)\n+        model.add(layers.GlobalAveragePooling2D())\n+        model.add(layers.Dense(7, activation=\"softmax\"))\n+        config = model.get_config()\n+        model = Sequential.from_config(config)\n+\n     def test_add_loss(self):\n         # TODO\n         pass\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#48a260715357908fff11c06f2570bcd0119f79df", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 7 | Churn Cumulative: 141 | Contributors (this commit): 3 | Commits (past 90d): 6 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -470,12 +470,15 @@ class FunctionalTest(testing.TestCase):\n \n     def test_for_functional_in_sequential(self):\n         # Test for a v3.4.1 regression.\n-        image_size = (100, 100)\n+        if backend.image_data_format() == \"channels_first\":\n+            image_size = (3, 100, 100)\n+        else:\n+            image_size = (100, 100, 3)\n         base_model = applications.mobilenet.MobileNet(\n             include_top=False, weights=None\n         )\n         model = Sequential()\n-        model.add(layers.Input(shape=image_size + (3,)))\n+        model.add(layers.Input(shape=image_size))\n         model.add(base_model)\n         model.add(layers.GlobalAveragePooling2D())\n         model.add(layers.Dense(7, activation=\"softmax\"))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7ea0f1c22eac06e2a078b7d1831b042c4a4dc93a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 73 | Lines Deleted: 3 | Files Changed: 6 | Hunks: 12 | Methods Changed: 11 | Complexity Δ (Sum/Max): 12/9 | Churn Δ: 76 | Churn Cumulative: 1483 | Contributors (this commit): 5 | Commits (past 90d): 16 | Contributors (cumulative): 16 | DMM Complexity: 0.9387755102040817\n\nDIFF:\n@@ -592,6 +592,7 @@ A `PyDataset` must implement two methods:\n \n The method `__getitem__` should return a complete batch.\n If you want to modify your dataset between epochs, you may implement `on_epoch_end`.\n+You may also implement `on_epoch_begin` to be called at the start of each epoch.\n \n Here's a quick example:\n \"\"\"\n\n@@ -638,6 +638,7 @@ class TFEpochIterator(EpochIterator):\n         return self.data_adapter.get_tf_dataset()\n \n     def enumerate_epoch(self):\n+        self.data_adapter.on_epoch_begin()\n         if self.steps_per_epoch:\n             if not self._current_iterator:\n                 self._current_iterator = iter(self._distributed_dataset)\n\n@@ -87,6 +87,10 @@ class DataAdapter:\n         \"\"\"\n         raise NotImplementedError\n \n+    def on_epoch_begin(self):\n+        \"\"\"A hook called before each epoch.\"\"\"\n+        pass\n+\n     def on_epoch_end(self):\n         \"\"\"A hook called after each epoch.\"\"\"\n         pass\n\n@@ -21,7 +21,8 @@ class PyDataset:\n \n     Every `PyDataset` must implement the `__getitem__()` and the `__len__()`\n     methods. If you want to modify your dataset between epochs,\n-    you may additionally implement `on_epoch_end()`.\n+    you may additionally implement `on_epoch_end()`,\n+    or `on_epoch_begin` to be called at the start of each epoch.\n     The `__getitem__()` method should return a complete batch\n     (not a single sample), and the `__len__` method should return\n     the number of batches in the dataset (rather than the number of samples).\n@@ -170,6 +171,10 @@ class PyDataset:\n             \"@property\\ndef num_batches(self):\\n  return ...\"\n         )\n \n+    def on_epoch_begin(self):\n+        \"\"\"Method called at the beginning of every epoch.\"\"\"\n+        pass\n+\n     def on_epoch_end(self):\n         \"\"\"Method called at the end of every epoch.\"\"\"\n         pass\n@@ -299,6 +304,9 @@ class PyDatasetAdapter(DataAdapter):\n     def get_torch_dataloader(self):\n         return data_adapter_utils.get_torch_dataloader(self._get_iterator())\n \n+    def on_epoch_begin(self):\n+        self.py_dataset.on_epoch_begin()\n+\n     def on_epoch_end(self):\n         if self.enqueuer:\n             self.enqueuer.stop()\n@@ -558,8 +566,11 @@ class OrderedEnqueuer(PyDatasetEnqueuer):\n                         # We're done\n                         return\n \n-                # Call the internal on epoch end.\n+                # Call the internal on epoch end and epoch begin.\n                 self.py_dataset.on_epoch_end()\n+                # The first on_epoch_begin call was already made,\n+                # prior to the start of the Enqueuer.\n+                self.py_dataset.on_epoch_begin()\n                 self._send_py_dataset()  # Update the pool\n         except Exception as e:\n             self.queue.put(e)  # Report exception\n\n@@ -77,6 +77,7 @@ class EpochIterator:\n \n     def enumerate_epoch(self):\n         buffer = []\n+        self.data_adapter.on_epoch_begin()\n         if self.steps_per_epoch:\n             if self._current_iterator is None:\n                 self._current_iterator = iter(self._get_iterator())\n\n@@ -1,6 +1,7 @@\n import numpy as np\n import pytest\n import tensorflow as tf\n+from absl.testing import parameterized\n \n from keras.src import backend\n from keras.src import testing\n@@ -8,7 +9,7 @@ from keras.src.trainers import data_adapters\n from keras.src.trainers import epoch_iterator\n \n \n-class TestEpochIterator(testing.TestCase):\n+class TestEpochIterator(testing.TestCase, parameterized.TestCase):\n     def test_basic_flow(self):\n         x = np.random.random((100, 16))\n         y = np.random.random((100, 4))\n@@ -171,3 +172,54 @@ class TestEpochIterator(testing.TestCase):\n         x = \"unsupported_data\"\n         with self.assertRaisesRegex(ValueError, \"Unrecognized data type\"):\n             _ = epoch_iterator.EpochIterator(x=x)\n+\n+    @parameterized.named_parameters(\n+        [\n+            {\"testcase_name\": \"infinite\", \"infinite\": True},\n+            {\"testcase_name\": \"finite\", \"infinite\": False},\n+        ]\n+    )\n+    def test_epoch_callbacks(self, infinite):\n+        class TestPyDataset(data_adapters.py_dataset_adapter.PyDataset):\n+            def __init__(\n+                self,\n+                workers=1,\n+                use_multiprocessing=False,\n+                max_queue_size=10,\n+                infinite=False,\n+            ):\n+                super().__init__(workers, use_multiprocessing, max_queue_size)\n+                self.data = np.random.rand(64, 2)\n+                self.batch_size = 16\n+                self.infinite = infinite\n+\n+                # check that callbacks are called in the correct order\n+                self.tracker = []\n+\n+            @property\n+            def num_batches(self):\n+                if self.infinite:\n+                    return None\n+                return len(self.data) // self.batch_size\n+\n+            def on_epoch_begin(self):\n+                self.tracker.append(1)\n+\n+            def __getitem__(self, index):\n+                idx = index % 2\n+                return self.data[\n+                    idx * self.batch_size : (idx + 1) * self.batch_size\n+                ]\n+\n+            def on_epoch_end(self):\n+                self.tracker.append(2)\n+\n+        ds = TestPyDataset(infinite=infinite)\n+        epoch_iter = epoch_iterator.EpochIterator(x=ds, steps_per_epoch=10)\n+\n+        num_epochs = 5\n+        for epoch in range(num_epochs):\n+            for step, batch in epoch_iter.enumerate_epoch():\n+                pass\n+\n+        self.assertAllEqual(ds.tracker, [1, 2] * num_epochs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
