{"custom_id": "keras#dc95ceca57cbfada596a10a72f0cb30e1f2ed53b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 709 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 11 | Complexity Δ (Sum/Max): 52/46 | Churn Δ: 709 | Churn Cumulative: 1316 | Contributors (this commit): 8 | Commits (past 90d): 5 | Contributors (cumulative): 12 | DMM Complexity: 0.45768025078369906\n\nDIFF:\n@@ -5,3 +5,4 @@ from .inception_v3 import InceptionV3\n from .inception_resnet_v2 import InceptionResNetV2\n from .xception import Xception\n from .mobilenet import MobileNet\n+from .nasnet import NASNetMobile, NASNetLarge\n\n@@ -0,0 +1,656 @@\n+'''NASNet-A models for Keras\n+\n+NASNet refers to Neural Architecture Search Network, a family of models\n+that were designed automatically by learning the model architectures\n+directly on the dataset of interest.\n+\n+Here we consider NASNet-A, the highest performance model that was found\n+for the CIFAR-10 dataset, and then extended to ImageNet 2012 dataset,\n+obtaining state of the art performance on CIFAR-10 and ImageNet 2012.\n+Only the NASNet-A models, and their respective weights, which are suited\n+for ImageNet 2012 are provided.\n+\n+The below table describes the performance on ImageNet 2012:\n+--------------------------------------------------------------------------------\n+      Architecture       | Top-1 Acc | Top-5 Acc |  Multiply-Adds |  Params (M)\n+--------------------------------------------------------------------------------\n+|   NASNet-A (4 @ 1056)  |   74.0 %  |   91.6 %  |       564 M    |     5.3    |\n+|   NASNet-A (6 @ 4032)  |   82.7 %  |   96.2 %  |      23.8 B    |    88.9    |\n+--------------------------------------------------------------------------------\n+\n+Weights obtained from the official Tensorflow repository found at\n+https://github.com/tensorflow/models/tree/master/research/slim/nets/nasnet\n+\n+# References:\n+ - [Learning Transferable Architectures for Scalable Image Recognition]\n+    (https://arxiv.org/abs/1707.07012)\n+\n+Based on the following implementations:\n+ - [TF Slim Implementation]\n+   (https://github.com/tensorflow/models/blob/master/research/slim/nets/nasnet/nasnet.py)\n+ - [TensorNets implementation]\n+   (https://github.com/taehoonlee/tensornets/blob/master/tensornets/nasnets.py)\n+'''\n+from __future__ import print_function\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import os\n+import warnings\n+\n+from ..models import Model\n+from ..layers import Input\n+from ..layers import Activation\n+from ..layers import Dense\n+from ..layers import BatchNormalization\n+from ..layers import MaxPooling2D\n+from ..layers import AveragePooling2D\n+from ..layers import GlobalAveragePooling2D\n+from ..layers import GlobalMaxPooling2D\n+from ..layers import Conv2D\n+from ..layers import SeparableConv2D\n+from ..layers import ZeroPadding2D\n+from ..layers import Cropping2D\n+from ..layers import concatenate\n+from ..layers import add\n+from ..utils.data_utils import get_file\n+from ..engine.topology import get_source_inputs\n+from ..applications.imagenet_utils import _obtain_input_shape\n+from ..applications.inception_v3 import preprocess_input\n+from ..applications.imagenet_utils import decode_predictions\n+from .. import backend as K\n+\n+NASNET_MOBILE_WEIGHT_PATH = 'https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-mobile.h5'\n+NASNET_MOBILE_WEIGHT_PATH_NO_TOP = 'https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-mobile-no-top.h5'\n+NASNET_LARGE_WEIGHT_PATH = 'https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-large.h5'\n+NASNET_LARGE_WEIGHT_PATH_NO_TOP = 'https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-large-no-top.h5'\n+\n+\n+def NASNet(input_shape=None,\n+           penultimate_filters=4032,\n+           num_blocks=6,\n+           stem_block_filters=96,\n+           skip_reduction=True,\n+           filter_multiplier=2,\n+           include_top=True,\n+           weights=None,\n+           input_tensor=None,\n+           pooling=None,\n+           classes=1000,\n+           default_size=None):\n+    '''Instantiates a NASNet model.\n+\n+    Note that only TensorFlow is supported for now,\n+    therefore it only works with the data format\n+    `image_data_format='channels_last'` in your Keras config\n+    at `~/.keras/keras.json`.\n+\n+    # Arguments\n+        input_shape: optional shape tuple, only to be specified\n+            if `include_top` is False (otherwise the input shape\n+            has to be `(331, 331, 3)` for NASNetLarge or\n+            `(224, 224, 3)` for NASNetMobile\n+            It should have exactly 3 inputs channels,\n+            and width and height should be no smaller than 32.\n+            E.g. `(224, 224, 3)` would be one valid value.\n+        penultimate_filters: number of filters in the penultimate layer.\n+            NASNet models use the notation `NASNet (N @ P)`, where:\n+                -   N is the number of blocks\n+                -   P is the number of penultimate filters\n+        num_blocks: number of repeated blocks of the NASNet model.\n+            NASNet models use the notation `NASNet (N @ P)`, where:\n+                -   N is the number of blocks\n+                -   P is the number of penultimate filters\n+        stem_block_filters: number of filters in the initial stem block\n+        skip_reduction: Whether to skip the reduction step at the tail\n+            end of the network. Set to `False` for CIFAR models.\n+        filter_multiplier: controls the width of the network.\n+            - If `filter_multiplier` < 1.0, proportionally decreases the number\n+                of filters in each layer.\n+            - If `filter_multiplier` > 1.0, proportionally increases the number\n+                of filters in each layer.\n+            - If `filter_multiplier` = 1, default number of filters from the\n+                 paper are used at each layer.\n+        include_top: whether to include the fully-connected\n+            layer at the top of the network.\n+        weights: `None` (random initialization) or\n+            `imagenet` (ImageNet weights)\n+        input_tensor: optional Keras tensor (i.e. output of\n+            `layers.Input()`)\n+            to use as image input for the model.\n+        pooling: Optional pooling mode for feature extraction\n+            when `include_top` is `False`.\n+            - `None` means that the output of the model\n+                will be the 4D tensor output of the\n+                last convolutional layer.\n+            - `avg` means that global average pooling\n+                will be applied to the output of the\n+                last convolutional layer, and thus\n+                the output of the model will be a\n+                2D tensor.\n+            - `max` means that global max pooling will\n+                be applied.\n+        classes: optional number of classes to classify images\n+            into, only to be specified if `include_top` is True, and\n+            if no `weights` argument is specified.\n+        default_size: specifies the default image size of the model\n+\n+    # Returns\n+        A Keras model instance.\n+\n+    # Raises\n+        ValueError: in case of invalid argument for `weights`,\n+            invalid input shape or invalid `penultimate_filters` value.\n+        RuntimeError: If attempting to run this model with a\n+            backend that does not support separable convolutions.\n+    '''\n+    if K.backend() != 'tensorflow':\n+        raise RuntimeError('Only Tensorflow backend is currently supported, '\n+                           'as other backends do not support '\n+                           'separable convolution.')\n+\n+    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n+        raise ValueError('The `weights` argument should be either '\n+                         '`None` (random initialization), `imagenet` '\n+                         '(pre-training on ImageNet), '\n+                         'or the path to the weights file to be loaded.')\n+\n+    if weights == 'imagenet' and include_top and classes != 1000:\n+        raise ValueError('If using `weights` as ImageNet with `include_top` '\n+                         'as true, `classes` should be 1000')\n+\n+    if default_size is None:\n+        default_size = 331\n+\n+    # Determine proper input shape and default size.\n+    input_shape = _obtain_input_shape(input_shape,\n+                                      default_size=default_size,\n+                                      min_size=32,\n+                                      data_format=K.image_data_format(),\n+                                      require_flatten=include_top or weights,\n+                                      weights=weights)\n+\n+    if K.image_data_format() != 'channels_last':\n+        warnings.warn('The NASNet family of models is only available '\n+                      'for the input data format \"channels_last\" '\n+                      '(width, height, channels). '\n+                      'However your settings specify the default '\n+                      'data format \"channels_first\" (channels, width, height).'\n+                      ' You should set `image_data_format=\"channels_last\"` '\n+                      'in your Keras config located at ~/.keras/keras.json. '\n+                      'The model being returned right now will expect inputs '\n+                      'to follow the \"channels_last\" data format.')\n+        K.set_image_data_format('channels_last')\n+        old_data_format = 'channels_first'\n+    else:\n+        old_data_format = None\n+\n+    if input_tensor is None:\n+        img_input = Input(shape=input_shape)\n+    else:\n+        if not K.is_keras_tensor(input_tensor):\n+            img_input = Input(tensor=input_tensor, shape=input_shape)\n+        else:\n+            img_input = input_tensor\n+\n+    if penultimate_filters % 24 != 0:\n+        raise ValueError(\n+            'For NASNet-A models, the value of `penultimate_filters` '\n+            'needs to be divisible by 24. Current value: %d' %\n+            penultimate_filters)\n+\n+    channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n+    filters = penultimate_filters // 24\n+\n+    if not skip_reduction:\n+        x = Conv2D(stem_block_filters, (3, 3), strides=(2, 2), padding='valid',\n+                   use_bias=False, name='stem_conv1',\n+                   kernel_initializer='he_normal')(img_input)\n+    else:\n+        x = Conv2D(stem_block_filters, (3, 3), strides=(1, 1), padding='same',\n+                   use_bias=False, name='stem_conv1',\n+                   kernel_initializer='he_normal')(img_input)\n+\n+    x = BatchNormalization(axis=channel_dim, momentum=0.9997,\n+                           epsilon=1e-3, name='stem_bn1')(x)\n+\n+    p = None\n+    if not skip_reduction:  # imagenet / mobile mode\n+        x, p = _reduction_a_cell(x, p, filters // (filter_multiplier ** 2),\n+                                 block_id='stem_1')\n+        x, p = _reduction_a_cell(x, p, filters // filter_multiplier,\n+                                 block_id='stem_2')\n+\n+    for i in range(num_blocks):\n+        x, p = _normal_a_cell(x, p, filters, block_id='%d' % (i))\n+\n+    x, p0 = _reduction_a_cell(x, p, filters * filter_multiplier,\n+                              block_id='reduce_%d' % (num_blocks))\n+\n+    p = p0 if not skip_reduction else p\n+\n+    for i in range(num_blocks):\n+        x, p = _normal_a_cell(x, p, filters * filter_multiplier,\n+                              block_id='%d' % (num_blocks + i + 1))\n+\n+    x, p0 = _reduction_a_cell(x, p, filters * filter_multiplier ** 2,\n+                              block_id='reduce_%d' % (2 * num_blocks))\n+\n+    p = p0 if not skip_reduction else p\n+\n+    for i in range(num_blocks):\n+        x, p = _normal_a_cell(x, p, filters * filter_multiplier ** 2,\n+                              block_id='%d' % (2 * num_blocks + i + 1))\n+\n+    x = Activation('relu')(x)\n+\n+    if include_top:\n+        x = GlobalAveragePooling2D()(x)\n+        x = Dense(classes, activation='softmax', name='predictions')(x)\n+    else:\n+        if pooling == 'avg':\n+            x = GlobalAveragePooling2D()(x)\n+        elif pooling == 'max':\n+            x = GlobalMaxPooling2D()(x)\n+\n+    # Ensure that the model takes into account\n+    # any potential predecessors of `input_tensor`.\n+    if input_tensor is not None:\n+        inputs = get_source_inputs(input_tensor)\n+    else:\n+        inputs = img_input\n+\n+    model = Model(inputs, x, name='NASNet')\n+\n+    # load weights\n+    if weights == 'imagenet':\n+        if default_size == 224:  # mobile version\n+            if include_top:\n+                weight_path = NASNET_MOBILE_WEIGHT_PATH\n+                model_name = 'nasnet_mobile.h5'\n+            else:\n+                weight_path = NASNET_MOBILE_WEIGHT_PATH_NO_TOP\n+                model_name = 'nasnet_mobile_no_top.h5'\n+\n+            weights_file = get_file(model_name, weight_path,\n+                                    cache_subdir='models')\n+            model.load_weights(weights_file)\n+\n+        elif default_size == 331:  # large version\n+            if include_top:\n+                weight_path = NASNET_LARGE_WEIGHT_PATH\n+                model_name = 'nasnet_large.h5'\n+            else:\n+                weight_path = NASNET_LARGE_WEIGHT_PATH_NO_TOP\n+                model_name = 'nasnet_large_no_top.h5'\n+\n+            weights_file = get_file(model_name, weight_path,\n+                                    cache_subdir='models')\n+            model.load_weights(weights_file)\n+        else:\n+            raise ValueError(\n+                'ImageNet weights can only be loaded with NASNetLarge'\n+                ' or NASNetMobile')\n+    elif weights is not None:\n+        model.load_weights(weights)\n+\n+    if old_data_format:\n+        K.set_image_data_format(old_data_format)\n+\n+    return model\n+\n+\n+def NASNetLarge(input_shape=None,\n+                include_top=True,\n+                weights='imagenet',\n+                input_tensor=None,\n+                pooling=None,\n+                classes=1000):\n+    '''Instantiates a NASNet model in ImageNet mode.\n+\n+    Note that only TensorFlow is supported for now,\n+    therefore it only works with the data format\n+    `image_data_format='channels_last'` in your Keras config\n+    at `~/.keras/keras.json`.\n+\n+    # Arguments\n+        input_shape: optional shape tuple, only to be specified\n+            if `include_top` is False (otherwise the input shape\n+            has to be `(331, 331, 3)` for NASNetLarge.\n+            It should have exactly 3 inputs channels,\n+            and width and height should be no smaller than 32.\n+            E.g. `(224, 224, 3)` would be one valid value.\n+        include_top: whether to include the fully-connected\n+            layer at the top of the network.\n+        weights: `None` (random initialization) or\n+            `imagenet` (ImageNet weights)\n+        input_tensor: optional Keras tensor (i.e. output of\n+            `layers.Input()`)\n+            to use as image input for the model.\n+        pooling: Optional pooling mode for feature extraction\n+            when `include_top` is `False`.\n+            - `None` means that the output of the model\n+                will be the 4D tensor output of the\n+                last convolutional layer.\n+            - `avg` means that global average pooling\n+                will be applied to the output of the\n+                last convolutional layer, and thus\n+                the output of the model will be a\n+                2D tensor.\n+            - `max` means that global max pooling will\n+                be applied.\n+        classes: optional number of classes to classify images\n+            into, only to be specified if `include_top` is True, and\n+            if no `weights` argument is specified.\n+        default_size: specifies the default image size of the model\n+\n+    # Returns\n+        A Keras model instance.\n+\n+    # Raises\n+        ValueError: in case of invalid argument for `weights`,\n+            or invalid input shape.\n+        RuntimeError: If attempting to run this model with a\n+            backend that does not support separable convolutions.\n+    '''\n+    return NASNet(input_shape,\n+                  penultimate_filters=4032,\n+                  num_blocks=6,\n+                  stem_block_filters=96,\n+                  skip_reduction=False,\n+                  filter_multiplier=2,\n+                  include_top=include_top,\n+                  weights=weights,\n+                  input_tensor=input_tensor,\n+                  pooling=pooling,\n+                  classes=classes,\n+                  default_size=331)\n+\n+\n+def NASNetMobile(input_shape=None,\n+                 include_top=True,\n+                 weights='imagenet',\n+                 input_tensor=None,\n+                 pooling=None,\n+                 classes=1000):\n+    '''Instantiates a Mobile NASNet model in ImageNet mode.\n+\n+    Note that only TensorFlow is supported for now,\n+    therefore it only works with the data format\n+    `image_data_format='channels_last'` in your Keras config\n+    at `~/.keras/keras.json`.\n+\n+    # Arguments\n+        input_shape: optional shape tuple, only to be specified\n+            if `include_top` is False (otherwise the input shape\n+            has to be `(224, 224, 3)` for NASNetMobile\n+            It should have exactly 3 inputs channels,\n+            and width and height should be no smaller than 32.\n+            E.g. `(224, 224, 3)` would be one valid value.\n+        include_top: whether to include the fully-connected\n+            layer at the top of the network.\n+        weights: `None` (random initialization) or\n+            `imagenet` (ImageNet weights)\n+        input_tensor: optional Keras tensor (i.e. output of\n+            `layers.Input()`)\n+            to use as image input for the model.\n+        pooling: Optional pooling mode for feature extraction\n+            when `include_top` is `False`.\n+            - `None` means that the output of the model\n+                will be the 4D tensor output of the\n+                last convolutional layer.\n+            - `avg` means that global average pooling\n+                will be applied to the output of the\n+                last convolutional layer, and thus\n+                the output of the model will be a\n+                2D tensor.\n+            - `max` means that global max pooling will\n+                be applied.\n+        classes: optional number of classes to classify images\n+            into, only to be specified if `include_top` is True, and\n+            if no `weights` argument is specified.\n+        default_size: specifies the default image size of the model\n+\n+    # Returns\n+        A Keras model instance.\n+\n+    # Raises\n+        ValueError: in case of invalid argument for `weights`,\n+            or invalid input shape.\n+        RuntimeError: If attempting to run this model with a\n+            backend that does not support separable convolutions.\n+    '''\n+    return NASNet(input_shape,\n+                  penultimate_filters=1056,\n+                  num_blocks=4,\n+                  stem_block_filters=32,\n+                  skip_reduction=False,\n+                  filter_multiplier=2,\n+                  include_top=include_top,\n+                  weights=weights,\n+                  input_tensor=input_tensor,\n+                  pooling=pooling,\n+                  classes=classes,\n+                  default_size=224)\n+\n+\n+def _separable_conv_block(ip, filters, kernel_size=(3, 3), strides=(1, 1),\n+                          block_id=None):\n+    '''Adds 2 blocks of [relu-separable conv-batchnorm]\n+\n+    # Arguments:\n+        ip: input tensor\n+        filters: number of output filters per layer\n+        kernel_size: kernel size of separable convolutions\n+        strides: strided convolution for downsampling\n+        block_id: string block_id\n+\n+    # Returns:\n+        a Keras tensor\n+    '''\n+    channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n+\n+    with K.name_scope('separable_conv_block_%s' % block_id):\n+        x = Activation('relu')(ip)\n+        x = SeparableConv2D(filters, kernel_size, strides=strides,\n+                            name='separable_conv_1_%s' % block_id,\n+                            padding='same', use_bias=False,\n+                            kernel_initializer='he_normal')(x)\n+        x = BatchNormalization(axis=channel_dim, momentum=0.9997,\n+                               epsilon=1e-3,\n+                               name='separable_conv_1_bn_%s' % (block_id))(x)\n+        x = Activation('relu')(x)\n+        x = SeparableConv2D(filters, kernel_size,\n+                            name='separable_conv_2_%s' % block_id,\n+                            padding='same', use_bias=False,\n+                            kernel_initializer='he_normal')(x)\n+        x = BatchNormalization(axis=channel_dim, momentum=0.9997,\n+                               epsilon=1e-3,\n+                               name='separable_conv_2_bn_%s' % (block_id))(x)\n+    return x\n+\n+\n+def _adjust_block(p, ip, filters, block_id=None):\n+    '''\n+    Adjusts the input `previou path` to match the shape of the `input`\n+    or situations where the output number of filters needs to be changed\n+\n+    # Arguments:\n+        p: input tensor which needs to be modified\n+        ip: input tensor whose shape needs to be matched\n+        filters: number of output filters to be matched\n+        block_id: string block_id\n+\n+    # Returns:\n+        an adjusted Keras tensor\n+    '''\n+    channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n+    img_dim = 2 if K.image_data_format() == 'channels_first' else -2\n+\n+    ip_shape = K.int_shape(ip)\n+\n+    if p is not None:\n+        p_shape = K.int_shape(p)\n+\n+    with K.name_scope('adjust_block'):\n+        if p is None:\n+            p = ip\n+\n+        elif p_shape[img_dim] != ip_shape[img_dim]:\n+            with K.name_scope('adjust_reduction_block_%s' % block_id):\n+                p = Activation('relu', name='adjust_relu_1_%s' % block_id)(p)\n+\n+                p1 = AveragePooling2D((1, 1), strides=(2, 2), padding='valid',\n+                                      name='adjust_avg_pool_1_%s' % block_id)(p)\n+                p1 = Conv2D(filters // 2, (1, 1), padding='same',\n+                            use_bias=False, name='adjust_conv_1_%s' % block_id,\n+                            kernel_initializer='he_normal')(p1)\n+\n+                p2 = ZeroPadding2D(padding=((0, 1), (0, 1)))(p)\n+                p2 = Cropping2D(cropping=((1, 0), (1, 0)))(p2)\n+                p2 = AveragePooling2D((1, 1), strides=(2, 2), padding='valid',\n+                                      name='adjust_avg_pool_2_%s' % block_id)(\n+                    p2)\n+                p2 = Conv2D(filters // 2, (1, 1), padding='same',\n+                            use_bias=False, name='adjust_conv_2_%s' % block_id,\n+                            kernel_initializer='he_normal')(p2)\n+\n+                p = concatenate([p1, p2], axis=channel_dim)\n+                p = BatchNormalization(axis=channel_dim, momentum=0.9997,\n+                                       epsilon=1e-3,\n+                                       name='adjust_bn_%s' % block_id)(p)\n+\n+        elif p_shape[channel_dim] != filters:\n+            with K.name_scope('adjust_projection_block_%s' % block_id):\n+                p = Activation('relu')(p)\n+                p = Conv2D(filters, (1, 1), strides=(1, 1), padding='same',\n+                           name='adjust_conv_projection_%s' % block_id,\n+                           use_bias=False, kernel_initializer='he_normal')(p)\n+                p = BatchNormalization(axis=channel_dim, momentum=0.9997,\n+                                       epsilon=1e-3,\n+                                       name='adjust_bn_%s' % block_id)(p)\n+    return p\n+\n+\n+def _normal_a_cell(ip, p, filters, block_id=None):\n+    '''Adds a Normal cell for NASNet-A (Fig. 4 in the paper)\n+\n+    # Arguments:\n+        ip: input tensor `x`\n+        p: input tensor `p`\n+        filters: number of output filters\n+        block_id: string block_id\n+\n+    # Returns:\n+        a Keras tensor\n+    '''\n+    channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n+\n+    with K.name_scope('normal_A_block_%s' % block_id):\n+        p = _adjust_block(p, ip, filters, block_id)\n+\n+        h = Activation('relu')(ip)\n+        h = Conv2D(filters, (1, 1), strides=(1, 1), padding='same',\n+                   name='normal_conv_1_%s' % block_id,\n+                   use_bias=False, kernel_initializer='he_normal')(h)\n+        h = BatchNormalization(axis=channel_dim, momentum=0.9997,\n+                               epsilon=1e-3,\n+                               name='normal_bn_1_%s' % block_id)(h)\n+\n+        with K.name_scope('block_1'):\n+            x1_1 = _separable_conv_block(h, filters, kernel_size=(5, 5),\n+                                         block_id='normal_left1_%s' % block_id)\n+            x1_2 = _separable_conv_block(p, filters,\n+                                         block_id='normal_right1_%s' % block_id)\n+            x1 = add([x1_1, x1_2], name='normal_add_1_%s' % block_id)\n+\n+        with K.name_scope('block_2'):\n+            x2_1 = _separable_conv_block(p, filters, (5, 5),\n+                                         block_id='normal_left2_%s' % block_id)\n+            x2_2 = _separable_conv_block(p, filters, (3, 3),\n+                                         block_id='normal_right2_%s' % block_id)\n+            x2 = add([x2_1, x2_2], name='normal_add_2_%s' % block_id)\n+\n+        with K.name_scope('block_3'):\n+            x3 = AveragePooling2D((3, 3), strides=(1, 1), padding='same',\n+                                  name='normal_left3_%s' % (block_id))(h)\n+            x3 = add([x3, p], name='normal_add_3_%s' % block_id)\n+\n+        with K.name_scope('block_4'):\n+            x4_1 = AveragePooling2D((3, 3), strides=(1, 1), padding='same',\n+                                    name='normal_left4_%s' % (block_id))(p)\n+            x4_2 = AveragePooling2D((3, 3), strides=(1, 1), padding='same',\n+                                    name='normal_right4_%s' % (block_id))(p)\n+            x4 = add([x4_1, x4_2], name='normal_add_4_%s' % block_id)\n+\n+        with K.name_scope('block_5'):\n+            x5 = _separable_conv_block(h, filters,\n+                                       block_id='normal_left5_%s' % block_id)\n+            x5 = add([x5, h], name='normal_add_5_%s' % block_id)\n+\n+        x = concatenate([p, x1, x2, x3, x4, x5], axis=channel_dim,\n+                        name='normal_concat_%s' % block_id)\n+    return x, ip\n+\n+\n+def _reduction_a_cell(ip, p, filters, block_id=None):\n+    '''Adds a Reduction cell for NASNet-A (Fig. 4 in the paper)\n+\n+    # Arguments:\n+        ip: input tensor `x`\n+        p: input tensor `p`\n+        filters: number of output filters\n+        block_id: string block_id\n+\n+    # Returns:\n+        a Keras tensor\n+    '''\n+    channel_dim = 1 if K.image_data_format() == 'channels_first' else -1\n+\n+    with K.name_scope('reduction_A_block_%s' % block_id):\n+        p = _adjust_block(p, ip, filters, block_id)\n+\n+        h = Activation('relu')(ip)\n+        h = Conv2D(filters, (1, 1), strides=(1, 1), padding='same',\n+                   name='reduction_conv_1_%s' % block_id,\n+                   use_bias=False, kernel_initializer='he_normal')(h)\n+        h = BatchNormalization(axis=channel_dim, momentum=0.9997,\n+                               epsilon=1e-3,\n+                               name='reduction_bn_1_%s' % block_id)(h)\n+\n+        with K.name_scope('block_1'):\n+            x1_1 = _separable_conv_block(h, filters, (5, 5), strides=(2, 2),\n+                                         block_id='reduction_left1_%s' % block_id)\n+            x1_2 = _separable_conv_block(p, filters, (7, 7), strides=(2, 2),\n+                                         block_id='reduction_1_%s' % block_id)\n+            x1 = add([x1_1, x1_2], name='reduction_add_1_%s' % block_id)\n+\n+        with K.name_scope('block_2'):\n+            x2_1 = MaxPooling2D((3, 3), strides=(2, 2), padding='same',\n+                                name='reduction_left2_%s' % block_id)(h)\n+            x2_2 = _separable_conv_block(p, filters, (7, 7), strides=(2, 2),\n+                                         block_id='reduction_right2_%s' % block_id)\n+            x2 = add([x2_1, x2_2], name='reduction_add_2_%s' % block_id)\n+\n+        with K.name_scope('block_3'):\n+            x3_1 = AveragePooling2D((3, 3), strides=(2, 2), padding='same',\n+                                    name='reduction_left3_%s' % block_id)(h)\n+            x3_2 = _separable_conv_block(p, filters, (5, 5), strides=(2, 2),\n+                                         block_id='reduction_right3_%s' % block_id)\n+            x3 = add([x3_1, x3_2], name='reduction_add3_%s' % block_id)\n+\n+        with K.name_scope('block_4'):\n+            x4 = AveragePooling2D((3, 3), strides=(1, 1), padding='same',\n+                                  name='reduction_left4_%s' % block_id)(x1)\n+            x4 = add([x2, x4])\n+\n+        with K.name_scope('block_5'):\n+            x5_1 = _separable_conv_block(x1, filters, (3, 3),\n+                                         block_id='reduction_left4_%s' % block_id)\n+            x5_2 = MaxPooling2D((3, 3), strides=(2, 2), padding='same',\n+                                name='reduction_right5_%s' % block_id)(h)\n+            x5 = add([x5_1, x5_2], name='reduction_add4_%s' % block_id)\n+\n+        x = concatenate([x2, x3, x4, x5], axis=channel_dim,\n+                        name='reduction_concat_%s' % block_id)\n+        return x, ip\n\n@@ -310,6 +310,58 @@ def test_mobilenet_image_size():\n         model = applications.MobileNet(input_shape=invalid_image_shape, weights='imagenet', include_top=True)\n \n \n+@keras_test\n+@pytest.mark.skipif((K.backend() != 'tensorflow'),\n+                    reason='NASNets are supported only on TensorFlow')\n+def test_nasnet():\n+    model = applications.NASNetMobile(weights=None)\n+    assert model.output_shape == (None, 1000)\n+\n+    model = applications.NASNetLarge(weights=None)\n+    assert model.output_shape == (None, 1000)\n+\n+\n+@keras_test\n+@pytest.mark.skipif((K.backend() != 'tensorflow'),\n+                    reason='NASNets are supported only on TensorFlow')\n+def test_nasnet_no_top():\n+    model = applications.NASNetMobile(weights=None, include_top=False)\n+    assert model.output_shape == (None, None, None, 1056)\n+\n+    model = applications.NASNetLarge(weights=None, include_top=False)\n+    assert model.output_shape == (None, None, None, 4032)\n+\n+\n+@keras_test\n+@pytest.mark.skipif((K.backend() != 'tensorflow'),\n+                    reason='NASNets are supported only on TensorFlow')\n+def test_nasnet_pooling():\n+    model = applications.NASNetMobile(weights=None, include_top=False, pooling='avg')\n+    assert model.output_shape == (None, 1056)\n+\n+    model = applications.NASNetLarge(weights=None, include_top=False, pooling='avg')\n+    assert model.output_shape == (None, 4032)\n+\n+\n+@keras_test\n+@pytest.mark.skipif((K.backend() != 'tensorflow'),\n+                    reason='NASNets are supported only on TensorFlow')\n+def test_nasnet_variable_input_channels():\n+    input_shape = (1, None, None) if K.image_data_format() == 'channels_first' else (None, None, 1)\n+    model = applications.NASNetMobile(weights=None, include_top=False, input_shape=input_shape)\n+    assert model.output_shape == (None, None, None, 1056)\n+\n+    model = applications.NASNetLarge(weights=None, include_top=False, input_shape=input_shape)\n+    assert model.output_shape == (None, None, None, 4032)\n+\n+    input_shape = (4, None, None) if K.image_data_format() == 'channels_first' else (None, None, 4)\n+    model = applications.NASNetMobile(weights=None, include_top=False, input_shape=input_shape)\n+    assert model.output_shape == (None, None, None, 1056)\n+\n+    model = applications.NASNetLarge(weights=None, include_top=False, input_shape=input_shape)\n+    assert model.output_shape == (None, None, None, 4032)\n+\n+\n @pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TF backend')\n @keras_test\n def test_depthwise_conv_2d():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a18aed4f8fcb8e4d6b4433fb56754a4a73f9224a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 5 | Files Changed: 3 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 10330 | Contributors (this commit): 102 | Commits (past 90d): 39 | Contributors (cumulative): 109 | DMM Complexity: None\n\nDIFF:\n@@ -67,7 +67,7 @@ def build_generator(latent_size):\n                             activation='tanh',\n                             kernel_initializer='glorot_normal'))\n \n-    # this is the z space commonly refered to in GAN papers\n+    # this is the z space commonly referred to in GAN papers\n     latent = Input(shape=(latent_size, ))\n \n     # this will be our label\n@@ -183,10 +183,10 @@ if __name__ == '__main__':\n         progress_bar = Progbar(target=num_batches)\n \n         # we don't want the discriminator to also maximize the classification\n-        # accuracy of the auxilary classifier on generated images, so we\n+        # accuracy of the auxiliary classifier on generated images, so we\n         # don't train discriminator to produce class labels for generated\n         # images (see https://openreview.net/forum?id=rJXTf9Bxg).\n-        # To preserve sum of sample weights for the auxilary classifier,\n+        # To preserve sum of sample weights for the auxiliary classifier,\n         # we assign sample weight of 2 to the real images.\n         disc_sample_weight = [np.ones(2 * batch_size),\n                               np.concatenate((np.ones(batch_size) * 2,\n\n@@ -472,7 +472,7 @@ def _separable_conv_block(ip, filters, kernel_size=(3, 3), strides=(1, 1),\n \n def _adjust_block(p, ip, filters, block_id=None):\n     '''\n-    Adjusts the input `previou path` to match the shape of the `input`\n+    Adjusts the input `previous path` to match the shape of the `input`\n     or situations where the output number of filters needs to be changed\n \n     # Arguments:\n\n@@ -2300,7 +2300,7 @@ class Function(object):\n     \"\"\"Runs a computation graph.\n \n     It's possible to pass arguments to `tf.Session.run()` via `session_kwargs`.\n-    In particular additonal operations via `fetches` argument and additional\n+    In particular additional operations via `fetches` argument and additional\n     tensor substitutions via `feed_dict` arguments. Note that given\n     substitutions are merged with substitutions from `inputs`. Even though\n     `feed_dict` is passed once in the constructor (called in `model.compile()`)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#df523f10562f3570371fbf735ccbf4a28401c48d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 195 | Contributors (this commit): 13 | Commits (past 90d): 1 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -40,6 +40,10 @@ def selu(x):\n     # Arguments\n         x: A tensor or variable to compute the activation function for.\n     \n+    # Note\n+        - To be used together with the initialization \"lecun_normal\".\n+        - To be used together with the dropout variant \"AlphaDropout\".\n+\n     # References\n         - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n     \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f419af9f61160e8a1a52e5a42efd607648030ae9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 22 | Lines Deleted: 22 | Files Changed: 1 | Hunks: 15 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 44 | Churn Cumulative: 1354 | Contributors (this commit): 18 | Commits (past 90d): 3 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -115,10 +115,10 @@ class BaseWrapper(object):\n \n         # Arguments\n             x : array-like, shape `(n_samples, n_features)`\n-                Training samples where n_samples is the number of samples\n-                and n_features is the number of features.\n+                Training samples where `n_samples` is the number of samples\n+                and `n_features` is the number of features.\n             y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n-                True labels for X.\n+                True labels for `x`.\n             **kwargs: dictionary arguments\n                 Legal arguments are the arguments of `Sequential.fit`\n \n@@ -153,11 +153,11 @@ class BaseWrapper(object):\n \n         # Arguments\n             fn : arbitrary function\n-            override: dictionary, values to override sk_params\n+            override: dictionary, values to override `sk_params`\n \n         # Returns\n             res : dictionary containing variables\n-                in both sk_params and fn's arguments.\n+                in both `sk_params` and `fn`'s arguments.\n         \"\"\"\n         override = override or {}\n         res = {}\n@@ -177,10 +177,10 @@ class KerasClassifier(BaseWrapper):\n \n         # Arguments\n             x : array-like, shape `(n_samples, n_features)`\n-                Training samples where n_samples is the number of samples\n-                and n_features is the number of features.\n+                Training samples where `n_samples` is the number of samples\n+                and `n_features` is the number of features.\n             y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n-                True labels for X.\n+                True labels for `x`.\n             **kwargs: dictionary arguments\n                 Legal arguments are the arguments of `Sequential.fit`\n \n@@ -207,8 +207,8 @@ class KerasClassifier(BaseWrapper):\n \n         # Arguments\n             x: array-like, shape `(n_samples, n_features)`\n-                Test samples where n_samples is the number of samples\n-                and n_features is the number of features.\n+                Test samples where `n_samples` is the number of samples\n+                and `n_features` is the number of features.\n             **kwargs: dictionary arguments\n                 Legal arguments are the arguments\n                 of `Sequential.predict_classes`.\n@@ -226,8 +226,8 @@ class KerasClassifier(BaseWrapper):\n \n         # Arguments\n             x: array-like, shape `(n_samples, n_features)`\n-                Test samples where n_samples is the number of samples\n-                and n_features is the number of features.\n+                Test samples where `n_samples` is the number of samples\n+                and `n_features` is the number of features.\n             **kwargs: dictionary arguments\n                 Legal arguments are the arguments\n                 of `Sequential.predict_classes`.\n@@ -254,16 +254,16 @@ class KerasClassifier(BaseWrapper):\n \n         # Arguments\n             x: array-like, shape `(n_samples, n_features)`\n-                Test samples where n_samples is the number of samples\n-                and n_features is the number of features.\n+                Test samples where `n_samples` is the number of samples\n+                and `n_features` is the number of features.\n             y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n-                True labels for x.\n+                True labels for `x`.\n             **kwargs: dictionary arguments\n                 Legal arguments are the arguments of `Sequential.evaluate`.\n \n         # Returns\n             score: float\n-                Mean accuracy of predictions on X wrt. y.\n+                Mean accuracy of predictions on `x` wrt. `y`.\n \n         # Raises\n             ValueError: If the underlying model isn't configured to\n@@ -299,8 +299,8 @@ class KerasRegressor(BaseWrapper):\n \n         # Arguments\n             x: array-like, shape `(n_samples, n_features)`\n-                Test samples where n_samples is the number of samples\n-                and n_features is the number of features.\n+                Test samples where `n_samples` is the number of samples\n+                and `n_features` is the number of features.\n             **kwargs: dictionary arguments\n                 Legal arguments are the arguments of `Sequential.predict`.\n \n@@ -316,16 +316,16 @@ class KerasRegressor(BaseWrapper):\n \n         # Arguments\n             x: array-like, shape `(n_samples, n_features)`\n-                Test samples where n_samples is the number of samples\n-                and n_features is the number of features.\n+                Test samples where `n_samples` is the number of samples\n+                and `n_features` is the number of features.\n             y: array-like, shape `(n_samples,)`\n-                True labels for X.\n+                True labels for `x`.\n             **kwargs: dictionary arguments\n                 Legal arguments are the arguments of `Sequential.evaluate`.\n \n         # Returns\n             score: float\n-                Mean accuracy of predictions on X wrt. y.\n+                Mean accuracy of predictions on `x` wrt. `y`.\n         \"\"\"\n         kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n         loss = self.model.evaluate(x, y, **kwargs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#389738392b0e09af92eb51a396e4230779498ae6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 408 | Contributors (this commit): 8 | Commits (past 90d): 7 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -158,7 +158,7 @@ def test_generator_enqueuer_threads():\n         acc.append(int(next(gen_output)[0, 0, 0, 0]))\n \n     \"\"\"\n-     Not comparing the order since it is not guarantee.\n+     Not comparing the order since it is not guaranteed.\n      It may get ordered, but not a lot, one thread can take the GIL before he was supposed to.\n     \"\"\"\n     assert len(set(acc) - set(range(100))) == 0, \"Output is not the same\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#018af47bc87b6a48e64c2fc9cfacf595e0f36287", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 159 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 14 | Methods Changed: 10 | Complexity Δ (Sum/Max): 14/11 | Churn Δ: 169 | Churn Cumulative: 9375 | Contributors (this commit): 99 | Commits (past 90d): 26 | Contributors (cumulative): 101 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1684,9 +1684,9 @@ def cos(x):\n     return tf.cos(x)\n \n \n-def normalize_batch_in_training(x, gamma, beta,\n+def _regular_normalize_batch_in_training(x, gamma, beta,\n                                          reduction_axes, epsilon=1e-3):\n-    \"\"\"Computes mean and std for batch then apply batch_normalization on batch.\n+    \"\"\"Non-fused version of `normalize_batch_in_training`.\n \n     # Arguments\n         x: Input tensor or variable.\n@@ -1701,12 +1701,29 @@ def normalize_batch_in_training(x, gamma, beta,\n     \"\"\"\n     mean, var = tf.nn.moments(x, reduction_axes,\n                               shift=None, name=None, keep_dims=False)\n-    if sorted(reduction_axes) == list(range(ndim(x)))[:-1]:\n     normed = tf.nn.batch_normalization(x, mean, var,\n                                        beta, gamma,\n                                        epsilon)\n-    else:\n-        # need broadcasting\n+    return normed, mean, var\n+\n+\n+def _broadcast_normalize_batch_in_training(x, gamma, beta,\n+                                           reduction_axes, epsilon=1e-3):\n+    \"\"\"Non-fused, broadcast version of `normalize_batch_in_training`.\n+\n+    # Arguments\n+        x: Input tensor or variable.\n+        gamma: Tensor by which to scale the input.\n+        beta: Tensor with which to center the input.\n+        reduction_axes: iterable of integers,\n+            axes over which to normalize.\n+        epsilon: Fuzz factor.\n+\n+    # Returns\n+        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n+    \"\"\"\n+    mean, var = tf.nn.moments(x, reduction_axes,\n+                              shift=None, name=None, keep_dims=False)\n     target_shape = []\n     for axis in range(ndim(x)):\n         if axis in reduction_axes:\n@@ -1725,12 +1742,90 @@ def normalize_batch_in_training(x, gamma, beta,\n         broadcast_beta = None\n     else:\n         broadcast_beta = tf.reshape(beta, target_shape)\n-        normed = tf.nn.batch_normalization(x, broadcast_mean, broadcast_var,\n-                                           broadcast_beta, broadcast_gamma,\n+\n+    normed = tf.nn.batch_normalization(\n+        x,\n+        broadcast_mean,\n+        broadcast_var,\n+        broadcast_beta,\n+        broadcast_gamma,\n         epsilon)\n     return normed, mean, var\n \n \n+def _fused_normalize_batch_in_training(x, gamma, beta, reduction_axes,\n+                                       epsilon=1e-3):\n+    \"\"\"Fused version of `normalize_batch_in_training`.\n+\n+    # Arguments\n+        x: Input tensor or variable.\n+        gamma: Tensor by which to scale the input.\n+        beta: Tensor with which to center the input.\n+        reduction_axes: iterable of integers,\n+            axes over which to normalize.\n+        epsilon: Fuzz factor.\n+\n+    # Returns\n+        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n+    \"\"\"\n+    if list(reduction_axes) == [0, 1, 2]:\n+        normalization_axis = 3\n+        tf_data_format = 'NHWC'\n+    else:\n+        normalization_axis = 1\n+        tf_data_format = 'NCHW'\n+\n+    if gamma is None:\n+        gamma = tf.constant(1.0,\n+                            dtype=x.dtype,\n+                            shape=[x.get_shape()[normalization_axis]])\n+    if beta is None:\n+        beta = tf.constant(0.0,\n+                           dtype=x.dtype,\n+                           shape=[x.get_shape()[normalization_axis]])\n+\n+    return tf.nn.fused_batch_norm(\n+        x,\n+        gamma,\n+        beta,\n+        epsilon=epsilon,\n+        data_format=tf_data_format)\n+\n+\n+def normalize_batch_in_training(x, gamma, beta,\n+                                reduction_axes, epsilon=1e-3):\n+    \"\"\"Computes mean and std for batch then apply batch_normalization on batch.\n+\n+    # Arguments\n+        x: Input tensor or variable.\n+        gamma: Tensor by which to scale the input.\n+        beta: Tensor with which to center the input.\n+        reduction_axes: iterable of integers,\n+            axes over which to normalize.\n+        epsilon: Fuzz factor.\n+\n+    # Returns\n+        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n+    \"\"\"\n+    if ndim(x) == 4 and list(reduction_axes) in [[0, 1, 2], [0, 2, 3]]:\n+        if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:\n+            return _broadcast_normalize_batch_in_training(x, gamma, beta,\n+                                                          reduction_axes,\n+                                                          epsilon=epsilon)\n+        return _fused_normalize_batch_in_training(\n+            x, gamma, beta, reduction_axes,\n+            epsilon=epsilon)\n+    else:\n+        if sorted(reduction_axes) == list(range(ndim(x)))[:-1]:\n+            return _regular_normalize_batch_in_training(x, gamma, beta,\n+                                                        reduction_axes,\n+                                                        epsilon=epsilon)\n+        else:\n+            return _broadcast_normalize_batch_in_training(x, gamma, beta,\n+                                                          reduction_axes,\n+                                                          epsilon=epsilon)\n+\n+\n def batch_normalization(x, mean, var, beta, gamma, epsilon=1e-3):\n     \"\"\"Applies batch normalization on x given mean, var, beta and gamma.\n \n@@ -3573,6 +3668,10 @@ def bias_add(x, bias, data_format=None):\n     elif ndim(x) == 4:\n         if data_format == 'channels_first':\n             if len(bias_shape) == 1:\n+                if _has_nchw_support():\n+                    x = tf.nn.bias_add(x, bias,\n+                                       data_format='NCHW')\n+                else:\n                     x += reshape(bias, (1, bias_shape[0], 1, 1))\n             else:\n                 x += reshape(bias, (1, bias_shape[2]) + bias_shape[:2])\n\n@@ -3,6 +3,7 @@ import numpy as np\n from numpy.testing import assert_allclose\n \n from keras.layers import Input\n+from keras import regularizers\n from keras.utils.test_utils import layer_test, keras_test\n from keras.layers import normalization\n from keras.models import Sequential, Model\n@@ -16,23 +17,35 @@ input_shapes = [np.ones((10, 10)), np.ones((10, 10, 10))]\n \n @keras_test\n def test_basic_batchnorm():\n-    from keras import regularizers\n     layer_test(normalization.BatchNormalization,\n                kwargs={'momentum': 0.9,\n                        'epsilon': 0.1,\n                        'gamma_regularizer': regularizers.l2(0.01),\n                        'beta_regularizer': regularizers.l2(0.01)},\n                input_shape=(3, 4, 2))\n+    layer_test(normalization.BatchNormalization,\n+               kwargs={'momentum': 0.9,\n+                       'epsilon': 0.1,\n+                       'axis': 1},\n+               input_shape=(3, 4, 2))\n     layer_test(normalization.BatchNormalization,\n                kwargs={'gamma_initializer': 'ones',\n                        'beta_initializer': 'ones',\n                        'moving_mean_initializer': 'zeros',\n                        'moving_variance_initializer': 'ones'},\n-               input_shape=(3, 4, 2))\n+               input_shape=(3, 4, 2, 4))\n+    if K.backend() != 'theano':\n+        layer_test(normalization.BatchNormalization,\n+                   kwargs={'momentum': 0.9,\n+                           'epsilon': 0.1,\n+                           'axis': 1,\n+                           'scale': False,\n+                           'center': False},\n+                   input_shape=(3, 4, 2, 4))\n \n \n @keras_test\n-def test_batchnorm_correctness():\n+def test_batchnorm_correctness_1d():\n     model = Sequential()\n     norm = normalization.BatchNormalization(input_shape=(10,), momentum=0.8)\n     model.add(norm)\n@@ -49,6 +62,24 @@ def test_batchnorm_correctness():\n     assert_allclose(out.std(), 1.0, atol=1e-1)\n \n \n+@keras_test\n+def test_batchnorm_correctness_2d():\n+    model = Sequential()\n+    norm = normalization.BatchNormalization(axis=1, input_shape=(10, 6), momentum=0.8)\n+    model.add(norm)\n+    model.compile(loss='mse', optimizer='sgd')\n+\n+    # centered on 5.0, variance 10.0\n+    x = np.random.normal(loc=5.0, scale=10.0, size=(1000, 10, 6))\n+    model.fit(x, x, epochs=4, verbose=0)\n+    out = model.predict(x)\n+    out -= np.reshape(K.eval(norm.beta), (1, 10, 1))\n+    out /= np.reshape(K.eval(norm.gamma), (1, 10, 1))\n+\n+    assert_allclose(out.mean(axis=(0, 2)), 0.0, atol=1e-1)\n+    assert_allclose(out.std(axis=(0, 2)), 1.0, atol=1e-1)\n+\n+\n @keras_test\n def test_batchnorm_training_argument():\n     bn1 = normalization.BatchNormalization(input_shape=(10,))\n@@ -106,6 +137,25 @@ def test_batchnorm_convnet():\n     assert_allclose(np.std(out, axis=(0, 2, 3)), 1.0, atol=1e-1)\n \n \n+@keras_test\n+@pytest.mark.skipif((K.backend() == 'theano'),\n+                    reason='Bug with theano backend')\n+def test_batchnorm_convnet_no_center_no_scale():\n+    model = Sequential()\n+    norm = normalization.BatchNormalization(axis=-1, center=False, scale=False,\n+                                            input_shape=(3, 4, 4), momentum=0.8)\n+    model.add(norm)\n+    model.compile(loss='mse', optimizer='sgd')\n+\n+    # centered on 5.0, variance 10.0\n+    x = np.random.normal(loc=5.0, scale=10.0, size=(1000, 3, 4, 4))\n+    model.fit(x, x, epochs=4, verbose=0)\n+    out = model.predict(x)\n+\n+    assert_allclose(np.mean(out, axis=(0, 2, 3)), 0.0, atol=1e-1)\n+    assert_allclose(np.std(out, axis=(0, 2, 3)), 1.0, atol=1e-1)\n+\n+\n @keras_test\n def test_shared_batchnorm():\n     '''Test that a BN layer can be shared\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
