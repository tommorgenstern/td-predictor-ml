{"custom_id": "keras#ebad23cc1cf5071a58dc30470695aacc695fd045", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1432 | Contributors (this commit): 12 | Commits (past 90d): 3 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -170,7 +170,7 @@ class MultiHeadAttentionTest(testing.TestCase, parameterized.TestCase):\n         backend.backend() == \"numpy\",\n         reason=\"Numpy backend does not support masking.\",\n     )\n-    def test_query_mask_progagation(self):\n+    def test_query_mask_propagation(self):\n         \"\"\"Test automatic propagation of the query's mask.\"\"\"\n         layer = layers.MultiHeadAttention(num_heads=2, key_dim=2)\n         self.assertTrue(layer.supports_masking)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#41016ff7ad1a0f9a35ee3585199d33c2ad237533", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 5058 | Contributors (this commit): 17 | Commits (past 90d): 2 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -798,7 +798,7 @@ class IndexLookup(Layer):\n             self.idf_weights_const = self.idf_weights.value()\n \n     def save_assets(self, dir_path):\n-        if self.input_vocabulary:\n+        if self.input_vocabulary is not None:\n             # Vocab saved in config.\n             # TODO: consider unifying both paths.\n             return\n@@ -808,7 +808,7 @@ class IndexLookup(Layer):\n             f.write(\"\\n\".join([str(w) for w in vocabulary]))\n \n     def load_assets(self, dir_path):\n-        if self.input_vocabulary:\n+        if self.input_vocabulary is not None:\n             # Vocab saved in config.\n             # TODO: consider unifying both paths.\n             return\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cb5ee5599b58e6786cdf4eac40dca7bda44dd077", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 61 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 11 | Complexity Δ (Sum/Max): 11/11 | Churn Δ: 61 | Churn Cumulative: 125 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2,6 +2,7 @@ from absl.testing import parameterized\n \n from keras import backend\n from keras import ops\n+from keras.backend.common import dtypes\n from keras.backend.common.variables import ALLOWED_DTYPES\n from keras.backend.torch.core import to_torch_dtype\n from keras.testing import test_case\n@@ -62,3 +63,63 @@ class DtypesTest(test_case.TestCase, parameterized.TestCase):\n             ValueError, \"Invalid `dtypes`. At least one dtype is required.\"\n         ):\n             backend.result_type()\n+\n+    def test_respect_weak_type_for_bool(self):\n+        self.assertEqual(dtypes._respect_weak_type(\"bool\", True), \"bool\")\n+\n+    def test_respect_weak_type_for_int(self):\n+        self.assertEqual(dtypes._respect_weak_type(\"int32\", True), \"int\")\n+\n+    def test_respect_weak_type_for_float(self):\n+        self.assertEqual(dtypes._respect_weak_type(\"float32\", True), \"float\")\n+\n+    def test_resolve_weak_type_for_bfloat16(self):\n+        self.assertEqual(dtypes._resolve_weak_type(\"bfloat16\"), \"float32\")\n+\n+    def test_resolve_weak_type_for_bfloat16_with_precision(self):\n+        self.assertEqual(\n+            dtypes._resolve_weak_type(\"bfloat16\", precision=\"64\"), \"float64\"\n+        )\n+\n+    def test_invalid_dtype_for_keras_promotion(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"is not a valid dtype for Keras type promotion.\"\n+        ):\n+            dtypes._least_upper_bound(\"invalid_dtype\")\n+\n+    def test_resolve_weak_type_for_invalid_dtype(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"Invalid value for argument `dtype`. Expected one of\"\n+        ):\n+            dtypes._resolve_weak_type(\"invalid_dtype\")\n+\n+    def test_resolve_weak_type_for_invalid_precision(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"Invalid value for argument `precision`. Expected one of\",\n+        ):\n+            dtypes._resolve_weak_type(\"int32\", precision=\"invalid_precision\")\n+\n+    def test_cycle_detection_in_make_lattice_upper_bounds(self):\n+        original_lattice_function = dtypes._type_promotion_lattice\n+\n+        def mock_lattice():\n+            lattice = original_lattice_function()\n+            lattice[\"int32\"].append(\"float32\")\n+            lattice[\"float32\"].append(\"int32\")\n+            return lattice\n+\n+        dtypes._type_promotion_lattice = mock_lattice\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \"cycle detected in type promotion lattice for node\"\n+        ):\n+            dtypes._make_lattice_upper_bounds()\n+\n+        dtypes._type_promotion_lattice = original_lattice_function\n+\n+    def test_respect_weak_type_for_invalid_dtype(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"Invalid value for argument `dtype`. Expected one of\"\n+        ):\n+            dtypes._respect_weak_type(\"invalid_dtype\", True)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5f7bb3543553185d80d2d69eedf7f31a45dc7e11", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 22 | Churn Cumulative: 26 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -68,10 +68,10 @@ class Tracker:\n         if not is_tracking_enabled():\n             return attr\n \n-        for name, (is_attr_type, _) in self.config.items():\n+        for store_name, (is_attr_type, _) in self.config.items():\n             if is_attr_type(attr):\n-                if id(attr) not in self.stored_ids[name]:\n-                    self.add_to_store(name, attr)\n+                if id(attr) not in self.stored_ids[store_name]:\n+                    self.add_to_store(store_name, attr)\n                 return attr\n         if isinstance(attr, tuple):\n             wrapped_attr = []\n@@ -88,6 +88,12 @@ class Tracker:\n             return TrackedSet(attr, self)\n         return attr\n \n+    def untrack(self, value):\n+        for store_name in self.stored_ids.keys():\n+            if id(value) in self.stored_ids[store_name]:\n+                self.config[store_name][1].remove(value)\n+                self.stored_ids[store_name].remove(id(value))\n+\n     def lock(self, msg):\n         self.locked = True\n         self._lock_violation_msg = msg\n@@ -122,6 +128,11 @@ class TrackedList(list):\n             values = [self.tracker.track(v) for v in values]\n         super().extend(values)\n \n+    def remove(self, value):\n+        if self.tracker:\n+            self.tracker.untrack(value)\n+        super().remove(value)\n+\n \n class TrackedDict(dict):\n     # TODO: override item removal methods?\n@@ -159,3 +170,8 @@ class TrackedSet(set):\n         if self.tracker:\n             values = [self.tracker.track(v) for v in values]\n         super().update(values)\n+\n+    def remove(self, value):\n+        if self.tracker:\n+            self.tracker.untrack(value)\n+        super().remove(value)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#600d887975c34f0db84311db901e449e3bab865f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 35 | Lines Deleted: 18 | Files Changed: 4 | Hunks: 12 | Methods Changed: 6 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 53 | Churn Cumulative: 215 | Contributors (this commit): 4 | Commits (past 90d): 11 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -33,11 +33,12 @@ def test_model_fit():\n \n     model.summary()\n \n-    x = np.random.random((50000, 100))\n-    y = np.random.random((50000, 16))\n+    x = np.random.random((5000, 100))\n+    y = np.random.random((5000, 16))\n     batch_size = 32\n-    epochs = 5\n+    epochs = 2\n \n+    # Fit from numpy arrays:\n     with strategy.scope():\n         model.compile(\n             optimizer=optimizers.SGD(learning_rate=0.001, momentum=0.01),\n@@ -54,6 +55,16 @@ def test_model_fit():\n     print(\"History:\")\n     print(history.history)\n \n+    # Fit again from distributed dataset:\n+    with strategy.scope():\n+        dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size)\n+        dataset = strategy.experimental_distribute_dataset(dataset)\n+        history = model.fit(dataset, epochs=epochs)\n+\n+    print(\"History:\")\n+    print(history.history)\n+\n \n if __name__ == \"__main__\":\n+    keras.config.disable_traceback_filtering()\n     test_model_fit()\n\n@@ -622,26 +622,24 @@ class TFEpochIterator(EpochIterator):\n     def __init__(self, distribute_strategy=None, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n         self._distribute_strategy = distribute_strategy\n+        dataset = self.data_adapter.get_tf_dataset()\n+        if not isinstance(dataset, tf.distribute.DistributedDataset):\n+            dataset = self._distribute_strategy.experimental_distribute_dataset(\n+                dataset\n+            )\n+        self._distributed_dataset = dataset\n         self._steps_seen = 0\n \n     def enumerate_epoch(self):\n         if self.steps_per_epoch:\n             if not self._current_iterator:\n-                self._current_iterator = iter(\n-                    self._distribute_strategy.experimental_distribute_dataset(\n-                        self.data_adapter.get_tf_dataset()\n-                    )\n-                )\n+                self._current_iterator = iter(self._distributed_dataset)\n             for step in range(\n                 0, self.steps_per_epoch, self.steps_per_execution\n             ):\n                 yield step, self._current_iterator\n         else:\n-            iterator = iter(\n-                self._distribute_strategy.experimental_distribute_dataset(\n-                    self.data_adapter.get_tf_dataset()\n-                )\n-            )\n+            iterator = iter(self._distributed_dataset)\n             if self.num_batches:\n                 for step in range(\n                     0, self.num_batches, self.steps_per_execution\n\n@@ -108,10 +108,10 @@ def raise_unsupported_arg(arg_name, arg_description, input_type):\n def is_tf_dataset(x):\n     if hasattr(x, \"__class__\"):\n         for parent in x.__class__.__mro__:\n-            if (\n-                parent.__name__ == \"DatasetV2\"\n-                and \"tensorflow.python.types.data\" in str(parent.__module__)\n-            ):\n+            if parent.__name__ in (\n+                \"DatasetV2\",\n+                \"DistributedDataset\",\n+            ) and \"tensorflow.python.\" in str(parent.__module__):\n                 return True\n     return False\n \n\n@@ -10,7 +10,9 @@ class TFDatasetAdapter(DataAdapter):\n     def __init__(self, dataset, class_weight=None):\n         from keras.utils.module_utils import tensorflow as tf\n \n-        if not isinstance(dataset, tf.data.Dataset):\n+        if not isinstance(\n+            dataset, (tf.data.Dataset, tf.distribute.DistributedDataset)\n+        ):\n             raise ValueError(\n                 \"Expected argument `dataset` to be a tf.data.Dataset. \"\n                 f\"Received: {dataset}\"\n@@ -30,7 +32,13 @@ class TFDatasetAdapter(DataAdapter):\n \n     @property\n     def num_batches(self):\n+        cardinality = self._dataset.cardinality\n+        if callable(cardinality):\n+            # `dataset.cardinality` is normally expected to be a callable.\n             cardinality = int(self._dataset.cardinality())\n+        else:\n+            # However, in the case of `DistributedDataset`, it's a np.int64.\n+            cardinality = int(cardinality)\n         # Return None for Unknown and Infiite cardinality datasets\n         if cardinality < 0:\n             return None\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0409fb5aab7cf4d1c02c92350fc837f0c7415726", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 22 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -66,5 +66,4 @@ def test_model_fit():\n \n \n if __name__ == \"__main__\":\n-    keras.config.disable_traceback_filtering()\n     test_model_fit()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#36322e744ca99d9672677d5136055f622f586533", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 7 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 27 | Churn Cumulative: 1376 | Contributors (this commit): 7 | Commits (past 90d): 4 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -150,9 +150,9 @@ def batch_dot(x, y, axes=None):\n     # normalize both inputs to rank 3.\n     if x_ndim > 3:\n         # squash middle dimensions of x.\n-        x_shape = list(ops.shape(x))\n+        x_shape = ops.shape(x)\n         x_mid_dims = x_shape[1:-1]\n-        x_squashed_shape = ops.stack([x_shape[0], -1, x_shape[-1]])\n+        x_squashed_shape = (x_shape[0], -1, x_shape[-1])\n         x = ops.reshape(x, x_squashed_shape)\n         x_squashed = True\n     else:\n@@ -160,9 +160,9 @@ def batch_dot(x, y, axes=None):\n \n     if y_ndim > 3:\n         # squash trailing dimensions of y.\n-        y_shape = list(ops.shape(y))\n+        y_shape = ops.shape(y)\n         y_trail_dims = y_shape[2:]\n-        y_squashed_shape = ops.stack([y_shape[0], y_shape[1], -1])\n+        y_squashed_shape = (y_shape[0], y_shape[1], -1)\n         y = ops.reshape(y, y_squashed_shape)\n         y_squashed = True\n     else:\n@@ -175,13 +175,11 @@ def batch_dot(x, y, axes=None):\n     do_reshape = False\n \n     if x_squashed:\n-        output_shape = ops.concat(\n-            [output_shape[:1], x_mid_dims, output_shape[-1:]], 0\n-        )\n+        output_shape = output_shape[:1] + x_mid_dims + output_shape[-1:]\n         do_reshape = True\n \n     if y_squashed:\n-        output_shape = ops.concat([output_shape[:-1], y_trail_dims], 0)\n+        output_shape = output_shape[:-1] + y_trail_dims\n         do_reshape = True\n \n     if do_reshape:\n\n@@ -221,6 +221,19 @@ class MergingLayersTest(testing.TestCase, parameterized.TestCase):\n         ):\n             layers.Subtract()([input_1])\n \n+    def test_dot_higher_dim(self):\n+        a_shape = (1, 3, 2)\n+        b_shape = (1, 1, 2, 3)\n+        # Test symbolic call\n+        a = layers.Input(batch_shape=a_shape)\n+        b = layers.Input(batch_shape=b_shape)\n+        c = layers.Dot(axes=(-2, -1))([a, b])\n+        self.assertEqual(c.shape, (1, 2, 1, 2))\n+        a = np.random.random(a_shape)\n+        b = np.random.random(b_shape)\n+        c = layers.Dot(axes=(-2, -1))([a, b])\n+        self.assertEqual(backend.standardize_shape(c.shape), (1, 2, 1, 2))\n+\n     @parameterized.named_parameters(TEST_PARAMETERS)\n     @pytest.mark.skipif(\n         not backend.SUPPORTS_SPARSE_TENSORS,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#aad448efcbbced3ca6a06160ae59fd3c1e3ea9e8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 224 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -508,9 +508,9 @@ def softmax(x, axis=-1):\n             else:\n                 new_shape.append(original_shape[i])\n                 i += 1\n-        x = x.reshape(new_shape)\n+        x = backend.numpy.reshape(x, new_shape)\n         x = backend.nn.softmax(x, axis=-1)\n-        x = x.reshape(original_shape)\n+        x = backend.numpy.reshape(x, original_shape)\n         return x\n     else:\n         return backend.nn.softmax(x, axis=axis)\n@@ -573,9 +573,9 @@ def log_softmax(x, axis=-1):\n             else:\n                 new_shape.append(original_shape[i])\n                 i += 1\n-        x = x.reshape(new_shape)\n+        x = backend.numpy.reshape(x, new_shape)\n         x = backend.nn.log_softmax(x, axis=-1)\n-        x = x.reshape(original_shape)\n+        x = backend.numpy.reshape(x, original_shape)\n         return x\n     else:\n         return backend.nn.log_softmax(x, axis=axis)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6e051823313f44b32b655657da9250bee4ff5e92", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 715 | Lines Deleted: 538 | Files Changed: 4 | Hunks: 395 | Methods Changed: 147 | Complexity Δ (Sum/Max): 15/9 | Churn Δ: 1253 | Churn Cumulative: 2260 | Contributors (this commit): 5 | Commits (past 90d): 15 | Contributors (cumulative): 12 | DMM Complexity: 0.6296296296296297\n\nDIFF:\n@@ -6,6 +6,7 @@ from keras.backend.common import dtypes\n from keras.backend.common.variables import ALLOWED_DTYPES\n from keras.backend.torch.core import to_torch_dtype\n from keras.testing import test_case\n+from keras.testing.test_utils import named_product\n \n \n class DtypesTest(test_case.TestCase, parameterized.TestCase):\n@@ -13,11 +14,13 @@ class DtypesTest(test_case.TestCase, parameterized.TestCase):\n \n     if backend.backend() == \"torch\":\n         # TODO: torch doesn't support uint64.\n-        ALL_DTYPES = [\n-            str(to_torch_dtype(x)).split(\".\")[-1]\n-            for x in ALLOWED_DTYPES\n-            if x not in [\"string\", \"uint64\"]\n-        ] + [None]\n+        ALL_DTYPES = []\n+        for x in ALLOWED_DTYPES:\n+            if x not in [\"string\", \"uint64\"]:\n+                x = str(to_torch_dtype(x)).split(\".\")[-1]\n+                if x not in ALL_DTYPES:  # skip duplicates created by remapping\n+                    ALL_DTYPES.append(x)\n+        ALL_DTYPES += [None]\n     else:\n         ALL_DTYPES = [x for x in ALLOWED_DTYPES if x != \"string\"] + [None]\n \n@@ -32,7 +35,9 @@ class DtypesTest(test_case.TestCase, parameterized.TestCase):\n         self.jax_enable_x64.__exit__(None, None, None)\n         return super().tearDown()\n \n-    @parameterized.product(dtype1=ALL_DTYPES, dtype2=[bool, int, float])\n+    @parameterized.named_parameters(\n+        named_product(dtype1=ALL_DTYPES, dtype2=[bool, int, float])\n+    )\n     def test_result_type_with_python_scalar_types(self, dtype1, dtype2):\n         import jax.numpy as jnp\n \n@@ -40,7 +45,9 @@ class DtypesTest(test_case.TestCase, parameterized.TestCase):\n         expected = jnp.result_type(dtype1, dtype2).name\n         self.assertEqual(out, expected)\n \n-    @parameterized.product(dtype1=ALL_DTYPES, dtype2=ALL_DTYPES)\n+    @parameterized.named_parameters(\n+        named_product(dtype1=ALL_DTYPES, dtype2=ALL_DTYPES)\n+    )\n     def test_result_type_with_tensor(self, dtype1, dtype2):\n         import jax.numpy as jnp\n \n\n@@ -9,6 +9,7 @@ from keras.backend.common import standardize_dtype\n from keras.backend.common.keras_tensor import KerasTensor\n from keras.backend.common.variables import ALLOWED_DTYPES\n from keras.ops import numpy as knp\n+from keras.testing.test_utils import named_product\n \n # TODO: remove reliance on this (or alternatively, turn it on by default).\n np_config.enable_numpy_behavior()\n@@ -21,63 +22,63 @@ class NumpyTwoInputOpsDynamicShapeTest(testing.TestCase):\n         self.assertEqual(knp.add(x, y).shape, (2, 3))\n \n     def test_subtract(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.subtract(x, y).shape, (2, 3))\n \n     def test_multiply(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.multiply(x, y).shape, (2, 3))\n \n     def test_matmul(self):\n-        x = KerasTensor([None, 3, 4])\n-        y = KerasTensor([3, None, 4, 5])\n+        x = KerasTensor((None, 3, 4))\n+        y = KerasTensor((3, None, 4, 5))\n         self.assertEqual(knp.matmul(x, y).shape, (3, None, 3, 5))\n \n     def test_power(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.power(x, y).shape, (2, 3))\n \n     def test_divide(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.divide(x, y).shape, (2, 3))\n \n     def test_true_divide(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.true_divide(x, y).shape, (2, 3))\n \n     def test_append(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.append(x, y).shape, (None,))\n \n     def test_arctan2(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.arctan2(x, y).shape, (2, 3))\n \n     def test_cross(self):\n-        x1 = KerasTensor([2, 3, 3])\n-        x2 = KerasTensor([1, 3, 2])\n-        y = KerasTensor([None, 1, 2])\n+        x1 = KerasTensor((2, 3, 3))\n+        x2 = KerasTensor((1, 3, 2))\n+        y = KerasTensor((None, 1, 2))\n         self.assertEqual(knp.cross(x1, y).shape, (2, 3, 3))\n         self.assertEqual(knp.cross(x2, y).shape, (None, 3))\n \n     def test_einsum(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([3, 4])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((3, 4))\n         self.assertEqual(knp.einsum(\"ij,jk->ik\", x, y).shape, (None, 4))\n         self.assertEqual(knp.einsum(\"ij,jk->ikj\", x, y).shape, (None, 4, 3))\n         self.assertEqual(knp.einsum(\"ii\", x).shape, ())\n         self.assertEqual(knp.einsum(\",ij\", 5, x).shape, (None, 3))\n \n-        x = KerasTensor([None, 3, 4])\n-        y = KerasTensor([None, 4, 5])\n-        z = KerasTensor([1, 1, 1, 9])\n+        x = KerasTensor((None, 3, 4))\n+        y = KerasTensor((None, 4, 5))\n+        z = KerasTensor((1, 1, 1, 9))\n         self.assertEqual(knp.einsum(\"ijk,jkl->li\", x, y).shape, (5, None))\n         self.assertEqual(knp.einsum(\"ijk,jkl->lij\", x, y).shape, (5, None, 3))\n         self.assertEqual(\n@@ -95,112 +96,112 @@ class NumpyTwoInputOpsDynamicShapeTest(testing.TestCase):\n         )\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([None, 3])\n-            y = KerasTensor([3, 4])\n+            x = KerasTensor((None, 3))\n+            y = KerasTensor((3, 4))\n             knp.einsum(\"ijk,jk->ik\", x, y)\n \n     def test_full_like(self):\n-        x = KerasTensor([None, 3])\n-        self.assertEqual(knp.full_like(x, KerasTensor([1, 3])).shape, (None, 3))\n+        x = KerasTensor((None, 3))\n+        self.assertEqual(knp.full_like(x, KerasTensor((1, 3))).shape, (None, 3))\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.full_like(x, 2).shape, (None, 3, 3))\n \n     def test_greater(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.greater(x, y).shape, (2, 3))\n \n     def test_greater_equal(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.greater_equal(x, y).shape, (2, 3))\n \n     def test_isclose(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.isclose(x, y).shape, (2, 3))\n \n     def test_less(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.less(x, y).shape, (2, 3))\n \n     def test_less_equal(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.less_equal(x, y).shape, (2, 3))\n \n     def test_linspace(self):\n-        start = KerasTensor([None, 3, 4])\n-        stop = KerasTensor([2, 3, 4])\n+        start = KerasTensor((None, 3, 4))\n+        stop = KerasTensor((2, 3, 4))\n         self.assertEqual(\n             knp.linspace(start, stop, 10, axis=1).shape, (2, 10, 3, 4)\n         )\n \n-        start = KerasTensor([None, 3])\n+        start = KerasTensor((None, 3))\n         stop = 2\n         self.assertEqual(\n             knp.linspace(start, stop, 10, axis=1).shape, (None, 10, 3)\n         )\n \n     def test_logical_and(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.logical_and(x, y).shape, (2, 3))\n \n     def test_logical_or(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.logical_or(x, y).shape, (2, 3))\n \n     def test_logspace(self):\n-        start = KerasTensor([None, 3, 4])\n-        stop = KerasTensor([2, 3, 4])\n+        start = KerasTensor((None, 3, 4))\n+        stop = KerasTensor((2, 3, 4))\n         self.assertEqual(\n             knp.logspace(start, stop, 10, axis=1).shape, (2, 10, 3, 4)\n         )\n \n-        start = KerasTensor([None, 3])\n+        start = KerasTensor((None, 3))\n         stop = 2\n         self.assertEqual(\n             knp.logspace(start, stop, 10, axis=1).shape, (None, 10, 3)\n         )\n \n     def test_maximum(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.maximum(x, y).shape, (2, 3))\n \n     def test_minimum(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.minimum(x, y).shape, (2, 3))\n \n     def test_mod(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.mod(x, y).shape, (2, 3))\n \n     def test_not_equal(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.not_equal(x, y).shape, (2, 3))\n \n     def test_outer(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([2, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n         self.assertEqual(knp.outer(x, y).shape, (None, None))\n \n     def test_take(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.take(x, 1).shape, ())\n         self.assertEqual(knp.take(x, [1, 2]).shape, (2,))\n         self.assertEqual(\n             knp.take(x, [[1, 2], [1, 2]], axis=1).shape, (None, 2, 2)\n         )\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.take(x, 1, axis=1).shape, (None, 3))\n         self.assertEqual(knp.take(x, [1, 2]).shape, (2,))\n         self.assertEqual(\n@@ -211,43 +212,43 @@ class NumpyTwoInputOpsDynamicShapeTest(testing.TestCase):\n         self.assertEqual(knp.take(x, 1, axis=-2).shape, (None, 3))\n \n         # test with multi-dimensional indices\n-        x = KerasTensor([None, 3, None, 5])\n-        indices = KerasTensor([6, 7])\n+        x = KerasTensor((None, 3, None, 5))\n+        indices = KerasTensor((6, 7))\n         self.assertEqual(knp.take(x, indices, axis=2).shape, (None, 3, 6, 7, 5))\n \n     def test_take_along_axis(self):\n-        x = KerasTensor([None, 3])\n-        indices = KerasTensor([1, 3])\n+        x = KerasTensor((None, 3))\n+        indices = KerasTensor((1, 3))\n         self.assertEqual(knp.take_along_axis(x, indices, axis=0).shape, (1, 3))\n         self.assertEqual(\n             knp.take_along_axis(x, indices, axis=1).shape, (None, 3)\n         )\n \n-        x = KerasTensor([None, 3, 3])\n-        indices = KerasTensor([1, 3, None])\n+        x = KerasTensor((None, 3, 3))\n+        indices = KerasTensor((1, 3, None))\n         self.assertEqual(\n             knp.take_along_axis(x, indices, axis=1).shape, (None, 3, 3)\n         )\n \n     def test_tensordot(self):\n-        x = KerasTensor([None, 3, 4])\n-        y = KerasTensor([3, 4])\n+        x = KerasTensor((None, 3, 4))\n+        y = KerasTensor((3, 4))\n         self.assertEqual(knp.tensordot(x, y, axes=1).shape, (None, 3, 4))\n         self.assertEqual(knp.tensordot(x, y, axes=[[0, 1], [1, 0]]).shape, (4,))\n \n     def test_vdot(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((None, 3))\n         self.assertEqual(knp.vdot(x, y).shape, ())\n \n-        x = KerasTensor([None, 3, 3])\n-        y = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n+        y = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.vdot(x, y).shape, ())\n \n     def test_where(self):\n-        condition = KerasTensor([2, None, 1])\n-        x = KerasTensor([None, 1])\n-        y = KerasTensor([None, 3])\n+        condition = KerasTensor((2, None, 1))\n+        x = KerasTensor((None, 1))\n+        y = KerasTensor((None, 3))\n         self.assertEqual(knp.where(condition, x, y).shape, (2, None, 3))\n         self.assertEqual(knp.where(condition).shape, (2, None, 1))\n \n@@ -262,101 +263,101 @@ class NumpyTwoInputOpsDynamicShapeTest(testing.TestCase):\n         self.assertEqual(knp.logical_xor(x, y).shape, (2, 3))\n \n     def test_shape_equal_basic_equality(self):\n-        x = KerasTensor([3, 4]).shape\n-        y = KerasTensor([3, 4]).shape\n+        x = KerasTensor((3, 4)).shape\n+        y = KerasTensor((3, 4)).shape\n         self.assertTrue(knp.shape_equal(x, y))\n-        y = KerasTensor([3, 5]).shape\n+        y = KerasTensor((3, 5)).shape\n         self.assertFalse(knp.shape_equal(x, y))\n \n     def test_shape_equal_allow_none(self):\n-        x = KerasTensor([3, 4, None]).shape\n-        y = KerasTensor([3, 4, 5]).shape\n+        x = KerasTensor((3, 4, None)).shape\n+        y = KerasTensor((3, 4, 5)).shape\n         self.assertTrue(knp.shape_equal(x, y, allow_none=True))\n         self.assertFalse(knp.shape_equal(x, y, allow_none=False))\n \n     def test_shape_equal_different_shape_lengths(self):\n-        x = KerasTensor([3, 4]).shape\n-        y = KerasTensor([3, 4, 5]).shape\n+        x = KerasTensor((3, 4)).shape\n+        y = KerasTensor((3, 4, 5)).shape\n         self.assertFalse(knp.shape_equal(x, y))\n \n     def test_shape_equal_ignore_axes(self):\n-        x = KerasTensor([3, 4, 5]).shape\n-        y = KerasTensor([3, 6, 5]).shape\n+        x = KerasTensor((3, 4, 5)).shape\n+        y = KerasTensor((3, 6, 5)).shape\n         self.assertTrue(knp.shape_equal(x, y, axis=1))\n-        y = KerasTensor([3, 6, 7]).shape\n+        y = KerasTensor((3, 6, 7)).shape\n         self.assertTrue(knp.shape_equal(x, y, axis=(1, 2)))\n         self.assertFalse(knp.shape_equal(x, y, axis=1))\n \n     def test_shape_equal_only_none(self):\n-        x = KerasTensor([None, None]).shape\n-        y = KerasTensor([5, 6]).shape\n+        x = KerasTensor((None, None)).shape\n+        y = KerasTensor((5, 6)).shape\n         self.assertTrue(knp.shape_equal(x, y, allow_none=True))\n \n     def test_shape_equal_axis_as_list(self):\n-        x = KerasTensor([3, 4, 5]).shape\n-        y = KerasTensor([3, 6, 5]).shape\n+        x = KerasTensor((3, 4, 5)).shape\n+        y = KerasTensor((3, 6, 5)).shape\n         self.assertTrue(knp.shape_equal(x, y, axis=[1]))\n \n     def test_shape_non_equal_with_negative_axis(self):\n-        x = KerasTensor([3, 4, 5]).shape\n-        y = KerasTensor([3, 4, 6]).shape\n+        x = KerasTensor((3, 4, 5)).shape\n+        y = KerasTensor((3, 4, 6)).shape\n         self.assertFalse(knp.shape_equal(x, y, axis=-2))\n \n     def test_shape_equal_with_negative_axis(self):\n-        x = KerasTensor([3, 4, 5]).shape\n-        y = KerasTensor([3, 4, 5]).shape\n+        x = KerasTensor((3, 4, 5)).shape\n+        y = KerasTensor((3, 4, 5)).shape\n         self.assertTrue(knp.shape_equal(x, y, axis=-1))\n \n     def test_shape_equal_zeros(self):\n-        x = KerasTensor([0, 4]).shape\n-        y = KerasTensor([0, 4]).shape\n+        x = KerasTensor((0, 4)).shape\n+        y = KerasTensor((0, 4)).shape\n         self.assertTrue(knp.shape_equal(x, y))\n-        y = KerasTensor([0, 5]).shape\n+        y = KerasTensor((0, 5)).shape\n         self.assertFalse(knp.shape_equal(x, y))\n \n     def test_broadcast_shapes_conversion_to_list(self):\n-        shape1 = KerasTensor([1, 2]).shape\n-        shape2 = KerasTensor([3, 1]).shape\n+        shape1 = KerasTensor((1, 2)).shape\n+        shape2 = KerasTensor((3, 1)).shape\n         expected_output = [3, 2]\n         self.assertEqual(knp.broadcast_shapes(shape1, shape2), expected_output)\n \n     def test_broadcast_shapes_shape1_longer_than_shape2(self):\n-        shape1 = KerasTensor([5, 3, 2]).shape\n-        shape2 = KerasTensor([1, 3]).shape\n+        shape1 = KerasTensor((5, 3, 2)).shape\n+        shape2 = KerasTensor((1, 3)).shape\n         with self.assertRaisesRegex(ValueError, \"Cannot broadcast shape\"):\n             knp.broadcast_shapes(shape1, shape2)\n \n     def test_broadcast_shapes_shape2_longer_than_shape1(self):\n-        shape1 = KerasTensor([5, 3]).shape\n-        shape2 = KerasTensor([2, 5, 3]).shape\n+        shape1 = KerasTensor((5, 3)).shape\n+        shape2 = KerasTensor((2, 5, 3)).shape\n         expected_output = [2, 5, 3]\n         self.assertEqual(knp.broadcast_shapes(shape1, shape2), expected_output)\n \n     def test_broadcast_shapes_broadcasting_shape1_is_1(self):\n-        shape1 = KerasTensor([1, 3]).shape\n-        shape2 = KerasTensor([5, 1]).shape\n+        shape1 = KerasTensor((1, 3)).shape\n+        shape2 = KerasTensor((5, 1)).shape\n         expected_output = [5, 3]\n         self.assertEqual(knp.broadcast_shapes(shape1, shape2), expected_output)\n \n     def test_broadcast_shapes_broadcasting_shape1_is_none(self):\n-        shape1 = KerasTensor([None, 3]).shape\n-        shape2 = KerasTensor([5, 1]).shape\n+        shape1 = KerasTensor((None, 3)).shape\n+        shape2 = KerasTensor((5, 1)).shape\n         expected_output = [5, 3]\n         self.assertEqual(knp.broadcast_shapes(shape1, shape2), expected_output)\n \n-        shape1 = KerasTensor([None, 3]).shape\n-        shape2 = KerasTensor([5, 3]).shape\n+        shape1 = KerasTensor((None, 3)).shape\n+        shape2 = KerasTensor((5, 3)).shape\n         expected_output = [5, 3]\n         self.assertEqual(knp.broadcast_shapes(shape1, shape2), expected_output)\n \n     def test_broadcast_shapes_broadcasting_shape2_conditions(self):\n-        shape1 = KerasTensor([5, 3, 2]).shape\n-        shape2 = KerasTensor([1, 3, 2]).shape\n+        shape1 = KerasTensor((5, 3, 2)).shape\n+        shape2 = KerasTensor((1, 3, 2)).shape\n         expected_output = [5, 3, 2]\n         self.assertEqual(knp.broadcast_shapes(shape1, shape2), expected_output)\n \n-        shape1 = KerasTensor([5, 3, 2]).shape\n-        shape2 = KerasTensor([1, None, 2]).shape\n+        shape1 = KerasTensor((5, 3, 2)).shape\n+        shape2 = KerasTensor((1, None, 2)).shape\n         expected_output = [5, 3, 2]\n         self.assertEqual(knp.broadcast_shapes(shape1, shape2), expected_output)\n \n@@ -368,8 +369,8 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n         self.assertEqual(knp.add(x, y).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.add(x, y)\n \n     def test_add_sparse(self):\n@@ -392,16 +393,16 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n         self.assertTrue(result.sparse)\n \n     def test_subtract(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.subtract(x, y).shape, (2, 3))\n \n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.subtract(x, 2).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.subtract(x, y)\n \n     def test_subtract_sparse(self):\n@@ -424,16 +425,16 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n         self.assertTrue(result.sparse)\n \n     def test_multiply(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.multiply(x, y).shape, (2, 3))\n \n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.multiply(x, 2).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.multiply(x, y)\n \n     def test_multiply_sparse(self):\n@@ -456,13 +457,13 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n         self.assertTrue(result.sparse)\n \n     def test_matmul(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([3, 2])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((3, 2))\n         self.assertEqual(knp.matmul(x, y).shape, (2, 2))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([3, 4])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((3, 4))\n+            y = KerasTensor((2, 3, 4))\n             knp.matmul(x, y)\n \n     def test_matmul_sparse(self):\n@@ -483,100 +484,100 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n         self.assertTrue(result.sparse)\n \n     def test_power(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.power(x, y).shape, (2, 3))\n \n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.power(x, 2).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.power(x, y)\n \n     def test_divide(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.divide(x, y).shape, (2, 3))\n \n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.divide(x, 2).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.divide(x, y)\n \n     def test_true_divide(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.true_divide(x, y).shape, (2, 3))\n \n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.true_divide(x, 2).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.true_divide(x, y)\n \n     def test_append(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.append(x, y).shape, (12,))\n \n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.append(x, y, axis=0).shape, (4, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.append(x, y, axis=2)\n \n     def test_arctan2(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.arctan2(x, y).shape, (2, 3))\n \n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.arctan2(x, 2).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.arctan2(x, y)\n \n     def test_cross(self):\n-        x1 = KerasTensor([2, 3, 3])\n-        x2 = KerasTensor([1, 3, 2])\n-        y1 = KerasTensor([2, 3, 3])\n-        y2 = KerasTensor([2, 3, 2])\n+        x1 = KerasTensor((2, 3, 3))\n+        x2 = KerasTensor((1, 3, 2))\n+        y1 = KerasTensor((2, 3, 3))\n+        y2 = KerasTensor((2, 3, 2))\n         self.assertEqual(knp.cross(x1, y1).shape, (2, 3, 3))\n         self.assertEqual(knp.cross(x2, y2).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.cross(x, y)\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([4, 3, 3])\n-            y = KerasTensor([2, 3, 3])\n+            x = KerasTensor((4, 3, 3))\n+            y = KerasTensor((2, 3, 3))\n             knp.cross(x, y)\n \n     def test_einsum(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([3, 4])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((3, 4))\n         self.assertEqual(knp.einsum(\"ij,jk->ik\", x, y).shape, (2, 4))\n         self.assertEqual(knp.einsum(\"ij,jk->ikj\", x, y).shape, (2, 4, 3))\n         self.assertEqual(knp.einsum(\"ii\", x).shape, ())\n         self.assertEqual(knp.einsum(\",ij\", 5, x).shape, (2, 3))\n \n-        x = KerasTensor([2, 3, 4])\n-        y = KerasTensor([3, 4, 5])\n-        z = KerasTensor([1, 1, 1, 9])\n+        x = KerasTensor((2, 3, 4))\n+        y = KerasTensor((3, 4, 5))\n+        z = KerasTensor((1, 1, 1, 9))\n         self.assertEqual(knp.einsum(\"ijk,jkl->li\", x, y).shape, (5, 2))\n         self.assertEqual(knp.einsum(\"ijk,jkl->lij\", x, y).shape, (5, 2, 3))\n         self.assertEqual(knp.einsum(\"...,...j->...j\", x, y).shape, (2, 3, 4, 5))\n@@ -593,136 +594,136 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n         )\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((3, 4))\n             knp.einsum(\"ijk,jk->ik\", x, y)\n \n     def test_full_like(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.full_like(x, 2).shape, (2, 3))\n \n     def test_greater(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.greater(x, y).shape, (2, 3))\n \n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.greater(x, 2).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.greater(x, y)\n \n     def test_greater_equal(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.greater_equal(x, y).shape, (2, 3))\n \n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.greater_equal(x, 2).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.greater_equal(x, y)\n \n     def test_isclose(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.isclose(x, y).shape, (2, 3))\n \n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.isclose(x, 2).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.isclose(x, y)\n \n     def test_less(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.less(x, y).shape, (2, 3))\n \n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.less(x, 2).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.less(x, y)\n \n     def test_less_equal(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.less_equal(x, y).shape, (2, 3))\n \n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.less_equal(x, 2).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.less_equal(x, y)\n \n     def test_linspace(self):\n-        start = KerasTensor([2, 3, 4])\n-        stop = KerasTensor([2, 3, 4])\n+        start = KerasTensor((2, 3, 4))\n+        stop = KerasTensor((2, 3, 4))\n         self.assertEqual(knp.linspace(start, stop, 10).shape, (10, 2, 3, 4))\n \n         with self.assertRaises(ValueError):\n-            start = KerasTensor([2, 3])\n-            stop = KerasTensor([2, 3, 4])\n+            start = KerasTensor((2, 3))\n+            stop = KerasTensor((2, 3, 4))\n             knp.linspace(start, stop)\n \n     def test_logical_and(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.logical_and(x, y).shape, (2, 3))\n \n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.logical_and(x, 2).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.logical_and(x, y)\n \n     def test_logical_or(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.logical_or(x, y).shape, (2, 3))\n \n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.logical_or(x, 2).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.logical_or(x, y)\n \n     def test_logspace(self):\n-        start = KerasTensor([2, 3, 4])\n-        stop = KerasTensor([2, 3, 4])\n+        start = KerasTensor((2, 3, 4))\n+        stop = KerasTensor((2, 3, 4))\n         self.assertEqual(knp.logspace(start, stop, 10).shape, (10, 2, 3, 4))\n \n         with self.assertRaises(ValueError):\n-            start = KerasTensor([2, 3])\n-            stop = KerasTensor([2, 3, 4])\n+            start = KerasTensor((2, 3))\n+            stop = KerasTensor((2, 3, 4))\n             knp.logspace(start, stop)\n \n     def test_maximum(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.maximum(x, y).shape, (2, 3))\n \n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.maximum(x, 2).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.maximum(x, y)\n \n     def test_maximum_sparse(self):\n@@ -745,16 +746,16 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n         self.assertTrue(result.sparse)\n \n     def test_minimum(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.minimum(x, y).shape, (2, 3))\n \n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.minimum(x, 2).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.minimum(x, y)\n \n     def test_minimum_sparse(self):\n@@ -777,68 +778,68 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n         self.assertTrue(result.sparse)\n \n     def test_mod(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.mod(x, y).shape, (2, 3))\n \n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.mod(x, 2).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.mod(x, y)\n \n     def test_not_equal(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.not_equal(x, y).shape, (2, 3))\n \n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.not_equal(x, 2).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.not_equal(x, y)\n \n     def test_outer(self):\n-        x = KerasTensor([3])\n-        y = KerasTensor([4])\n+        x = KerasTensor((3,))\n+        y = KerasTensor((4,))\n         self.assertEqual(knp.outer(x, y).shape, (3, 4))\n \n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([4, 5])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((4, 5))\n         self.assertEqual(knp.outer(x, y).shape, (6, 20))\n \n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.outer(x, 2).shape, (6, 1))\n \n     def test_take(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.take(x, 1).shape, ())\n         self.assertEqual(knp.take(x, [1, 2]).shape, (2,))\n         self.assertEqual(knp.take(x, [[1, 2], [1, 2]], axis=1).shape, (2, 2, 2))\n \n         # test with multi-dimensional indices\n-        x = KerasTensor([2, 3, 4, 5])\n-        indices = KerasTensor([6, 7])\n+        x = KerasTensor((2, 3, 4, 5))\n+        indices = KerasTensor((6, 7))\n         self.assertEqual(knp.take(x, indices, axis=2).shape, (2, 3, 6, 7, 5))\n \n     def test_take_along_axis(self):\n-        x = KerasTensor([2, 3])\n-        indices = KerasTensor([1, 3])\n+        x = KerasTensor((2, 3))\n+        indices = KerasTensor((1, 3))\n         self.assertEqual(knp.take_along_axis(x, indices, axis=0).shape, (1, 3))\n         self.assertEqual(knp.take_along_axis(x, indices, axis=1).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            indices = KerasTensor([1, 4])\n+            x = KerasTensor((2, 3))\n+            indices = KerasTensor((1, 4))\n             knp.take_along_axis(x, indices, axis=0)\n \n     def test_tensordot(self):\n-        x = KerasTensor([2, 3, 3])\n-        y = KerasTensor([3, 3, 4])\n+        x = KerasTensor((2, 3, 3))\n+        y = KerasTensor((3, 3, 4))\n         self.assertEqual(knp.tensordot(x, y, axes=1).shape, (2, 3, 3, 4))\n         self.assertEqual(knp.tensordot(x, y, axes=2).shape, (2, 4))\n         self.assertEqual(\n@@ -846,14 +847,14 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n         )\n \n     def test_vdot(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.vdot(x, y).shape, ())\n \n     def test_where(self):\n-        condition = KerasTensor([2, 3])\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        condition = KerasTensor((2, 3))\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.where(condition, x, y).shape, (2, 3))\n         self.assertAllEqual(knp.where(condition).shape, (2, 3))\n \n@@ -863,8 +864,8 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n         self.assertEqual(knp.floor_divide(x, y).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.floor_divide(x, y)\n \n     def test_xor(self):\n@@ -873,8 +874,8 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n         self.assertEqual(knp.logical_xor(x, y).shape, (2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3, 4))\n             knp.logical_xor(x, y)\n \n     def test_digitize(self):\n@@ -884,185 +885,185 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n         self.assertTrue(knp.digitize(x, bins).dtype == \"int32\")\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            bins = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3))\n+            bins = KerasTensor((2, 3, 4))\n             knp.digitize(x, bins)\n \n \n class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n     def test_mean(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.mean(x).shape, ())\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.mean(x, axis=1).shape, (None, 3))\n         self.assertEqual(knp.mean(x, axis=1, keepdims=True).shape, (None, 1, 3))\n \n     def test_all(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.all(x).shape, ())\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.all(x, axis=1).shape, (None, 3))\n         self.assertEqual(knp.all(x, axis=1, keepdims=True).shape, (None, 1, 3))\n \n     def test_any(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.any(x).shape, ())\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.any(x, axis=1).shape, (None, 3))\n         self.assertEqual(knp.any(x, axis=1, keepdims=True).shape, (None, 1, 3))\n \n     def test_var(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.var(x).shape, ())\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.var(x, axis=1).shape, (None, 3))\n         self.assertEqual(knp.var(x, axis=1, keepdims=True).shape, (None, 1, 3))\n \n     def test_sum(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.sum(x).shape, ())\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.sum(x, axis=1).shape, (None, 3))\n         self.assertEqual(knp.sum(x, axis=1, keepdims=True).shape, (None, 1, 3))\n \n     def test_amax(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.amax(x).shape, ())\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.amax(x, axis=1).shape, (None, 3))\n         self.assertEqual(knp.amax(x, axis=1, keepdims=True).shape, (None, 1, 3))\n \n     def test_amin(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.amin(x).shape, ())\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.amin(x, axis=1).shape, (None, 3))\n         self.assertEqual(knp.amin(x, axis=1, keepdims=True).shape, (None, 1, 3))\n \n     def test_square(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.square(x).shape, (None, 3))\n \n     def test_negative(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.negative(x).shape, (None, 3))\n \n     def test_abs(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.abs(x).shape, (None, 3))\n \n     def test_absolute(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.absolute(x).shape, (None, 3))\n \n     def test_squeeze(self):\n-        x = KerasTensor([None, 1])\n+        x = KerasTensor((None, 1))\n         self.assertEqual(knp.squeeze(x).shape, (None,))\n         self.assertEqual(knp.squeeze(x, axis=1).shape, (None,))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([None, 1])\n+            x = KerasTensor((None, 1))\n             knp.squeeze(x, axis=0)\n \n     def test_transpose(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.transpose(x).shape, (3, None))\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.transpose(x, (2, 0, 1)).shape, (3, None, 3))\n \n     def test_arccos(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.arccos(x).shape, (None, 3))\n \n     def test_arccosh(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.arccosh(x).shape, (None, 3))\n \n     def test_arcsin(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.arcsin(x).shape, (None, 3))\n \n     def test_arcsinh(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.arcsinh(x).shape, (None, 3))\n \n     def test_arctan(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.arctan(x).shape, (None, 3))\n \n     def test_arctanh(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.arctanh(x).shape, (None, 3))\n \n     def test_argmax(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.argmax(x).shape, ())\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.argmax(x, axis=1).shape, (None, 3))\n \n     def test_argmin(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.argmin(x).shape, ())\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.argmin(x, axis=1).shape, (None, 3))\n \n     def test_argsort(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.argsort(x).shape, (None, 3))\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.argsort(x, axis=1).shape, (None, 3, 3))\n \n     def test_array(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.array(x).shape, (None, 3))\n \n     def test_average(self):\n-        x = KerasTensor([None, 3])\n-        weights = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n+        weights = KerasTensor((None, 3))\n         self.assertEqual(knp.average(x, weights=weights).shape, ())\n \n-        x = KerasTensor([None, 3])\n-        weights = KerasTensor([3])\n+        x = KerasTensor((None, 3))\n+        weights = KerasTensor((3,))\n         self.assertEqual(knp.average(x, axis=1, weights=weights).shape, (None,))\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.average(x, axis=1).shape, (None, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([None, 3, 3])\n-            weights = KerasTensor([None, 4])\n+            x = KerasTensor((None, 3, 3))\n+            weights = KerasTensor((None, 4))\n             knp.average(x, weights=weights)\n \n     def test_broadcast_to(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.broadcast_to(x, (2, 3, 3)).shape, (2, 3, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([3, 3])\n+            x = KerasTensor((3, 3))\n             knp.broadcast_to(x, (2, 2, 3))\n \n     def test_ceil(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.ceil(x).shape, (None, 3))\n \n     def test_clip(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.clip(x, 1, 2).shape, (None, 3))\n \n     def test_concatenate(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((None, 3))\n         self.assertEqual(\n             knp.concatenate(\n                 [x, y],\n@@ -1075,8 +1076,8 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n             self.assertEqual(knp.concatenate([x, y], axis=None).shape, (None,))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([None, 3, 5])\n-            y = KerasTensor([None, 4, 6])\n+            x = KerasTensor((None, 3, 5))\n+            y = KerasTensor((None, 4, 6))\n             knp.concatenate([x, y], axis=1)\n \n     def test_concatenate_sparse(self):\n@@ -1099,96 +1100,96 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n         self.assertTrue(result.sparse)\n \n     def test_conjugate(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.conjugate(x).shape, (None, 3))\n \n     def test_conj(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.conj(x).shape, (None, 3))\n \n     def test_copy(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.copy(x).shape, (None, 3))\n \n     def test_cos(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.cos(x).shape, (None, 3))\n \n     def test_cosh(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.cosh(x).shape, (None, 3))\n \n     def test_count_nonzero(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.count_nonzero(x).shape, ())\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.count_nonzero(x, axis=1).shape, (None, 3))\n \n     def test_cumprod(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.cumprod(x).shape, (None,))\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.cumprod(x, axis=1).shape, (None, 3, 3))\n \n     def test_cumsum(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.cumsum(x).shape, (None,))\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.cumsum(x, axis=1).shape, (None, 3, 3))\n \n     def test_diag(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.diag(x).shape, (None,))\n         self.assertEqual(knp.diag(x, k=3).shape, (None,))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3, 4))\n             knp.diag(x)\n \n     def test_diagonal(self):\n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.diagonal(x).shape, (3, None))\n \n     def test_dot(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([3, 2])\n-        z = KerasTensor([None, None, 2])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((3, 2))\n+        z = KerasTensor((None, None, 2))\n         self.assertEqual(knp.dot(x, y).shape, (None, 2))\n         self.assertEqual(knp.dot(x, 2).shape, (None, 3))\n         self.assertEqual(knp.dot(x, z).shape, (None, None, 2))\n \n-        x = KerasTensor([None])\n-        y = KerasTensor([5])\n+        x = KerasTensor((None,))\n+        y = KerasTensor((5,))\n         self.assertEqual(knp.dot(x, y).shape, ())\n \n     def test_exp(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.exp(x).shape, (None, 3))\n \n     def test_expand_dims(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.expand_dims(x, -1).shape, (None, 3, 1))\n         self.assertEqual(knp.expand_dims(x, 0).shape, (1, None, 3))\n         self.assertEqual(knp.expand_dims(x, 1).shape, (None, 1, 3))\n         self.assertEqual(knp.expand_dims(x, -2).shape, (None, 1, 3))\n \n     def test_expm1(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.expm1(x).shape, (None, 3))\n \n     def test_flip(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.flip(x).shape, (None, 3))\n \n     def test_floor(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.floor(x).shape, (None, 3))\n \n     def test_get_item(self):\n-        x = KerasTensor([None, 5, 16])\n+        x = KerasTensor((None, 5, 16))\n         # Simple slice.\n         sliced = knp.get_item(x, 5)\n         self.assertEqual(sliced.shape, (5, 16))\n@@ -1210,61 +1211,61 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n             sliced = knp.get_item(x, np.s_[:, :, :, :])\n \n     def test_hstack(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((None, 3))\n         self.assertEqual(knp.hstack([x, y]).shape, (None, 6))\n \n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([None, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((None, None))\n         self.assertEqual(knp.hstack([x, y]).shape, (None, None))\n \n     def test_imag(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.imag(x).shape, (None, 3))\n \n     def test_isfinite(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.isfinite(x).shape, (None, 3))\n \n     def test_isinf(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.isinf(x).shape, (None, 3))\n \n     def test_isnan(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.isnan(x).shape, (None, 3))\n \n     def test_log(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.log(x).shape, (None, 3))\n \n     def test_log10(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.log10(x).shape, (None, 3))\n \n     def test_log1p(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.log1p(x).shape, (None, 3))\n \n     def test_log2(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.log2(x).shape, (None, 3))\n \n     def test_logaddexp(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.logaddexp(x, x).shape, (None, 3))\n \n     def test_logical_not(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.logical_not(x).shape, (None, 3))\n \n     def test_max(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.max(x).shape, ())\n \n     def test_meshgrid(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((None, 3))\n         self.assertEqual(knp.meshgrid(x, y)[0].shape, (None, None))\n         self.assertEqual(knp.meshgrid(x, y)[1].shape, (None, None))\n \n@@ -1272,7 +1273,7 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n             knp.meshgrid(x, y, indexing=\"kk\")\n \n     def test_moveaxis(self):\n-        x = KerasTensor([None, 3, 4, 5])\n+        x = KerasTensor((None, 3, 4, 5))\n         self.assertEqual(knp.moveaxis(x, 0, -1).shape, (3, 4, 5, None))\n         self.assertEqual(knp.moveaxis(x, -1, 0).shape, (5, None, 3, 4))\n         self.assertEqual(\n@@ -1284,26 +1285,26 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n         )\n \n     def test_ndim(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.ndim(x).shape, (2,))\n \n     def test_ones_like(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.ones_like(x).shape, (None, 3))\n         self.assertEqual(knp.ones_like(x).dtype, x.dtype)\n \n     def test_zeros_like(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.zeros_like(x).shape, (None, 3))\n         self.assertEqual(knp.zeros_like(x).dtype, x.dtype)\n \n     def test_pad(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.pad(x, 1).shape, (None, 5))\n         self.assertEqual(knp.pad(x, (1, 2)).shape, (None, 6))\n         self.assertEqual(knp.pad(x, ((1, 2), (3, 4))).shape, (None, 10))\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.pad(x, 1).shape, (None, 5, 5))\n         self.assertEqual(knp.pad(x, (1, 2)).shape, (None, 6, 6))\n         self.assertEqual(\n@@ -1311,76 +1312,76 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n         )\n \n     def test_prod(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.prod(x).shape, ())\n         self.assertEqual(knp.prod(x, axis=0).shape, (3,))\n         self.assertEqual(knp.prod(x, axis=1, keepdims=True).shape, (None, 1))\n \n     def test_ravel(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.ravel(x).shape, (None,))\n \n     def test_real(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.real(x).shape, (None, 3))\n \n     def test_reciprocal(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.reciprocal(x).shape, (None, 3))\n \n     def test_repeat(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.repeat(x, 2).shape, (None,))\n         self.assertEqual(knp.repeat(x, 3, axis=1).shape, (None, 9))\n         self.assertEqual(knp.repeat(x, [1, 2], axis=0).shape, (3, 3))\n         self.assertEqual(knp.repeat(x, 2, axis=0).shape, (None, 3))\n \n     def test_reshape(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.reshape(x, (3, 2)).shape, (3, 2))\n         self.assertEqual(knp.reshape(x, (3, -1)).shape, (3, None))\n \n     def test_reshape_sparse(self):\n-        x = KerasTensor([None, 3], sparse=True)\n+        x = KerasTensor((None, 3), sparse=True)\n         self.assertTrue(knp.reshape(x, (3, 2)).sparse)\n         self.assertEqual(knp.reshape(x, (3, 2)).shape, (3, 2))\n         self.assertTrue(knp.reshape(x, (3, -1)).sparse)\n         self.assertEqual(knp.reshape(x, (3, -1)).shape, (3, None))\n \n     def test_roll(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.roll(x, 1).shape, (None, 3))\n         self.assertEqual(knp.roll(x, 1, axis=1).shape, (None, 3))\n         self.assertEqual(knp.roll(x, 1, axis=0).shape, (None, 3))\n \n     def test_round(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.round(x).shape, (None, 3))\n \n     def test_sign(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.sign(x).shape, (None, 3))\n \n     def test_sin(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.sin(x).shape, (None, 3))\n \n     def test_sinh(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.sinh(x).shape, (None, 3))\n \n     def test_size(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.size(x).shape, ())\n \n     def test_sort(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.sort(x).shape, (None, 3))\n         self.assertEqual(knp.sort(x, axis=1).shape, (None, 3))\n         self.assertEqual(knp.sort(x, axis=0).shape, (None, 3))\n \n     def test_split(self):\n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.split(x, 2)[0].shape, (None, 3, 3))\n         self.assertEqual(knp.split(x, 3, axis=1)[0].shape, (None, 1, 3))\n         self.assertEqual(len(knp.split(x, [1, 3], axis=1)), 3)\n@@ -1389,118 +1390,118 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n         self.assertEqual(knp.split(x, [1, 3], axis=1)[2].shape, (None, 0, 3))\n \n     def test_sqrt(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.sqrt(x).shape, (None, 3))\n \n     def test_stack(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((None, 3))\n         self.assertEqual(knp.stack([x, y]).shape, (2, None, 3))\n         self.assertEqual(knp.stack([x, y], axis=-1).shape, (None, 3, 2))\n \n     def test_std(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.std(x).shape, ())\n \n-        x = KerasTensor([None, 3, 3])\n+        x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.std(x, axis=1).shape, (None, 3))\n         self.assertEqual(knp.std(x, axis=1, keepdims=True).shape, (None, 1, 3))\n \n     def test_swapaxes(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.swapaxes(x, 0, 1).shape, (3, None))\n \n     def test_tan(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.tan(x).shape, (None, 3))\n \n     def test_tanh(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.tanh(x).shape, (None, 3))\n \n     def test_tile(self):\n-        x = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n         self.assertEqual(knp.tile(x, [2]).shape, (None, 6))\n         self.assertEqual(knp.tile(x, [1, 2]).shape, (None, 6))\n         self.assertEqual(knp.tile(x, [2, 1, 2]).shape, (2, None, 6))\n \n     def test_trace(self):\n-        x = KerasTensor([None, 3, None, 5])\n+        x = KerasTensor((None, 3, None, 5))\n         self.assertEqual(knp.trace(x).shape, (None, 5))\n         self.assertEqual(knp.trace(x, axis1=2, axis2=3).shape, (None, 3))\n \n     def test_tril(self):\n-        x = KerasTensor([None, 3, None, 5])\n+        x = KerasTensor((None, 3, None, 5))\n         self.assertEqual(knp.tril(x).shape, (None, 3, None, 5))\n         self.assertEqual(knp.tril(x, k=1).shape, (None, 3, None, 5))\n         self.assertEqual(knp.tril(x, k=-1).shape, (None, 3, None, 5))\n \n     def test_triu(self):\n-        x = KerasTensor([None, 3, None, 5])\n+        x = KerasTensor((None, 3, None, 5))\n         self.assertEqual(knp.triu(x).shape, (None, 3, None, 5))\n         self.assertEqual(knp.triu(x, k=1).shape, (None, 3, None, 5))\n         self.assertEqual(knp.triu(x, k=-1).shape, (None, 3, None, 5))\n \n     def test_vstack(self):\n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([None, 3])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((None, 3))\n         self.assertEqual(knp.vstack([x, y]).shape, (None, 3))\n \n-        x = KerasTensor([None, 3])\n-        y = KerasTensor([None, None])\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((None, None))\n         self.assertEqual(knp.vstack([x, y]).shape, (None, 3))\n \n \n class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n     def test_mean(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.mean(x).shape, ())\n \n     def test_all(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.all(x).shape, ())\n \n     def test_any(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.any(x).shape, ())\n \n     def test_var(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.var(x).shape, ())\n \n     def test_sum(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.sum(x).shape, ())\n \n     def test_amax(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.amax(x).shape, ())\n \n     def test_amin(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.amin(x).shape, ())\n \n     def test_square(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.square(x).shape, (2, 3))\n \n     def test_negative(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.negative(x).shape, (2, 3))\n \n     def test_abs(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.abs(x).shape, (2, 3))\n \n     def test_absolute(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.absolute(x).shape, (2, 3))\n \n     def test_squeeze(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.squeeze(x).shape, (2, 3))\n \n-        x = KerasTensor([2, 1, 3])\n+        x = KerasTensor((2, 1, 3))\n         self.assertEqual(knp.squeeze(x).shape, (2, 3))\n         self.assertEqual(knp.squeeze(x, axis=1).shape, (2, 3))\n         self.assertEqual(knp.squeeze(x, axis=-2).shape, (2, 3))\n@@ -1509,11 +1510,11 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n             knp.squeeze(x, axis=0)\n \n     def test_squeeze_sparse(self):\n-        x = KerasTensor([2, 3], sparse=True)\n+        x = KerasTensor((2, 3), sparse=True)\n         self.assertTrue(knp.squeeze(x).sparse)\n         self.assertEqual(knp.squeeze(x).shape, (2, 3))\n \n-        x = KerasTensor([2, 1, 3], sparse=True)\n+        x = KerasTensor((2, 1, 3), sparse=True)\n         self.assertTrue(knp.squeeze(x).sparse)\n         self.assertEqual(knp.squeeze(x).shape, (2, 3))\n         self.assertTrue(knp.squeeze(x, axis=1).sparse)\n@@ -1522,79 +1523,79 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n         self.assertEqual(knp.squeeze(x, axis=-2).shape, (2, 3))\n \n     def test_transpose(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.transpose(x).shape, (3, 2))\n \n     def test_transpose_sparse(self):\n-        x = KerasTensor([2, 3], sparse=True)\n+        x = KerasTensor((2, 3), sparse=True)\n         result = knp.transpose(x)\n         self.assertEqual(result.shape, (3, 2))\n         self.assertTrue(result.sparse)\n \n     def test_arccos(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.arccos(x).shape, (2, 3))\n \n     def test_arccosh(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.arccosh(x).shape, (2, 3))\n \n     def test_arcsin(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.arcsin(x).shape, (2, 3))\n \n     def test_arcsinh(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.arcsinh(x).shape, (2, 3))\n \n     def test_arctan(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.arctan(x).shape, (2, 3))\n \n     def test_arctanh(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.arctanh(x).shape, (2, 3))\n \n     def test_argmax(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.argmax(x).shape, ())\n \n     def test_argmin(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.argmin(x).shape, ())\n \n     def test_argsort(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.argsort(x).shape, (2, 3))\n         self.assertEqual(knp.argsort(x, axis=None).shape, (6,))\n \n     def test_array(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.array(x).shape, (2, 3))\n \n     def test_average(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.average(x).shape, ())\n \n     def test_broadcast_to(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.broadcast_to(x, (2, 2, 3)).shape, (2, 2, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([3, 3])\n+            x = KerasTensor((3, 3))\n             knp.broadcast_to(x, (2, 2, 3))\n \n     def test_ceil(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.ceil(x).shape, (2, 3))\n \n     def test_clip(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.clip(x, 1, 2).shape, (2, 3))\n \n     def test_concatenate(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.concatenate([x, y]).shape, (4, 3))\n         self.assertEqual(knp.concatenate([x, y], axis=1).shape, (2, 6))\n \n@@ -1602,93 +1603,93 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n             self.assertEqual(knp.concatenate([x, y], axis=None).shape, (None,))\n \n     def test_conjugate(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.conjugate(x).shape, (2, 3))\n \n     def test_conj(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.conj(x).shape, (2, 3))\n \n     def test_copy(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.copy(x).shape, (2, 3))\n \n     def test_cos(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.cos(x).shape, (2, 3))\n \n     def test_cosh(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.cosh(x).shape, (2, 3))\n \n     def test_count_nonzero(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.count_nonzero(x).shape, ())\n \n     def test_cumprod(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.cumprod(x).shape, (6,))\n \n     def test_cumsum(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.cumsum(x).shape, (6,))\n \n     def test_diag(self):\n-        x = KerasTensor([3])\n+        x = KerasTensor((3,))\n         self.assertEqual(knp.diag(x).shape, (3, 3))\n         self.assertEqual(knp.diag(x, k=3).shape, (6, 6))\n         self.assertEqual(knp.diag(x, k=-2).shape, (5, 5))\n \n-        x = KerasTensor([3, 5])\n+        x = KerasTensor((3, 5))\n         self.assertEqual(knp.diag(x).shape, (3,))\n         self.assertEqual(knp.diag(x, k=3).shape, (2,))\n         self.assertEqual(knp.diag(x, k=-2).shape, (1,))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3, 4])\n+            x = KerasTensor((2, 3, 4))\n             knp.diag(x)\n \n     def test_diagonal(self):\n-        x = KerasTensor([3, 3])\n+        x = KerasTensor((3, 3))\n         self.assertEqual(knp.diagonal(x).shape, (3,))\n         self.assertEqual(knp.diagonal(x, offset=1).shape, (2,))\n \n-        x = KerasTensor([3, 5, 5])\n+        x = KerasTensor((3, 5, 5))\n         self.assertEqual(knp.diagonal(x).shape, (5, 3))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([3])\n+            x = KerasTensor((3,))\n             knp.diagonal(x)\n \n     def test_dot(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([3, 2])\n-        z = KerasTensor([4, 3, 2])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((3, 2))\n+        z = KerasTensor((4, 3, 2))\n         self.assertEqual(knp.dot(x, y).shape, (2, 2))\n         self.assertEqual(knp.dot(x, 2).shape, (2, 3))\n         self.assertEqual(knp.dot(x, z).shape, (2, 4, 2))\n \n-        x = KerasTensor([5])\n-        y = KerasTensor([5])\n+        x = KerasTensor((5,))\n+        y = KerasTensor((5,))\n         self.assertEqual(knp.dot(x, y).shape, ())\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([2, 3])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((2, 3))\n             knp.dot(x, y)\n \n     def test_exp(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.exp(x).shape, (2, 3))\n \n     def test_expand_dims(self):\n-        x = KerasTensor([2, 3, 4])\n+        x = KerasTensor((2, 3, 4))\n         self.assertEqual(knp.expand_dims(x, 0).shape, (1, 2, 3, 4))\n         self.assertEqual(knp.expand_dims(x, 1).shape, (2, 1, 3, 4))\n         self.assertEqual(knp.expand_dims(x, -2).shape, (2, 3, 1, 4))\n \n     def test_expand_dims_sparse(self):\n-        x = KerasTensor([2, 3, 4], sparse=True)\n+        x = KerasTensor((2, 3, 4), sparse=True)\n         self.assertTrue(knp.expand_dims(x, 0).sparse)\n         self.assertEqual(knp.expand_dims(x, 0).shape, (1, 2, 3, 4))\n         self.assertTrue(knp.expand_dims(x, 1).sparse)\n@@ -1697,22 +1698,22 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n         self.assertEqual(knp.expand_dims(x, -2).shape, (2, 3, 1, 4))\n \n     def test_expm1(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.expm1(x).shape, (2, 3))\n \n     def test_flip(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.flip(x).shape, (2, 3))\n \n     def test_floor(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.floor(x).shape, (2, 3))\n \n     def test_get_item(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.get_item(x, 1).shape, (3,))\n \n-        x = KerasTensor([5, 3, 2])\n+        x = KerasTensor((5, 3, 2))\n         self.assertEqual(knp.get_item(x, 3).shape, (3, 2))\n \n         x = KerasTensor(\n@@ -1723,58 +1724,58 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n         self.assertEqual(knp.get_item(x, 0).shape, ())\n \n     def test_hstack(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.hstack([x, y]).shape, (2, 6))\n \n     def test_imag(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.imag(x).shape, (2, 3))\n \n     def test_isfinite(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.isfinite(x).shape, (2, 3))\n \n     def test_isinf(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.isinf(x).shape, (2, 3))\n \n     def test_isnan(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.isnan(x).shape, (2, 3))\n \n     def test_log(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.log(x).shape, (2, 3))\n \n     def test_log10(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.log10(x).shape, (2, 3))\n \n     def test_log1p(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.log1p(x).shape, (2, 3))\n \n     def test_log2(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.log2(x).shape, (2, 3))\n \n     def test_logaddexp(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.logaddexp(x, x).shape, (2, 3))\n \n     def test_logical_not(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.logical_not(x).shape, (2, 3))\n \n     def test_max(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.max(x).shape, ())\n \n     def test_meshgrid(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3, 4])\n-        z = KerasTensor([2, 3, 4, 5])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3, 4))\n+        z = KerasTensor((2, 3, 4, 5))\n         self.assertEqual(knp.meshgrid(x, y)[0].shape, (24, 6))\n         self.assertEqual(knp.meshgrid(x, y)[1].shape, (24, 6))\n         self.assertEqual(knp.meshgrid(x, y, indexing=\"ij\")[0].shape, (6, 24))\n@@ -1785,7 +1786,7 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n             knp.meshgrid(x, y, indexing=\"kk\")\n \n     def test_moveaxis(self):\n-        x = KerasTensor([2, 3, 4, 5])\n+        x = KerasTensor((2, 3, 4, 5))\n         self.assertEqual(knp.moveaxis(x, 0, -1).shape, (3, 4, 5, 2))\n         self.assertEqual(knp.moveaxis(x, -1, 0).shape, (5, 2, 3, 4))\n         self.assertEqual(knp.moveaxis(x, [0, 1], [-1, -2]).shape, (4, 5, 3, 2))\n@@ -1793,62 +1794,62 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n         self.assertEqual(knp.moveaxis(x, [0, 1], [-2, -1]).shape, (4, 5, 2, 3))\n \n     def test_ndim(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.ndim(x).shape, (2,))\n \n     def test_ones_like(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.ones_like(x).shape, (2, 3))\n         self.assertEqual(knp.ones_like(x).dtype, x.dtype)\n \n     def test_zeros_like(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.zeros_like(x).shape, (2, 3))\n         self.assertEqual(knp.zeros_like(x).dtype, x.dtype)\n \n     def test_pad(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.pad(x, 1).shape, (4, 5))\n         self.assertEqual(knp.pad(x, (1, 2)).shape, (5, 6))\n         self.assertEqual(knp.pad(x, ((1, 2), (3, 4))).shape, (5, 10))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n+            x = KerasTensor((2, 3))\n             knp.pad(x, ((1, 2), (3, 4), (5, 6)))\n \n     def test_prod(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.prod(x).shape, ())\n         self.assertEqual(knp.prod(x, axis=0).shape, (3,))\n         self.assertEqual(knp.prod(x, axis=1).shape, (2,))\n \n     def test_ravel(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.ravel(x).shape, (6,))\n \n     def test_real(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.real(x).shape, (2, 3))\n \n     def test_reciprocal(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.reciprocal(x).shape, (2, 3))\n \n     def test_repeat(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.repeat(x, 2).shape, (12,))\n         self.assertEqual(knp.repeat(x, 3, axis=1).shape, (2, 9))\n         self.assertEqual(knp.repeat(x, [1, 2], axis=0).shape, (3, 3))\n \n     def test_reshape(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.reshape(x, (3, 2)).shape, (3, 2))\n         self.assertEqual(knp.reshape(x, (3, -1)).shape, (3, 2))\n         self.assertEqual(knp.reshape(x, (6,)).shape, (6,))\n         self.assertEqual(knp.reshape(x, (-1,)).shape, (6,))\n \n     def test_reshape_sparse(self):\n-        x = KerasTensor([2, 3], sparse=True)\n+        x = KerasTensor((2, 3), sparse=True)\n \n         result = knp.reshape(x, (3, 2))\n         self.assertEqual(result.shape, (3, 2))\n@@ -1867,39 +1868,39 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n         self.assertTrue(result.sparse)\n \n     def test_roll(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.roll(x, 1).shape, (2, 3))\n         self.assertEqual(knp.roll(x, 1, axis=1).shape, (2, 3))\n         self.assertEqual(knp.roll(x, 1, axis=0).shape, (2, 3))\n \n     def test_round(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.round(x).shape, (2, 3))\n \n     def test_sign(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.sign(x).shape, (2, 3))\n \n     def test_sin(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.sin(x).shape, (2, 3))\n \n     def test_sinh(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.sinh(x).shape, (2, 3))\n \n     def test_size(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.size(x).shape, ())\n \n     def test_sort(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.sort(x).shape, (2, 3))\n         self.assertEqual(knp.sort(x, axis=1).shape, (2, 3))\n         self.assertEqual(knp.sort(x, axis=0).shape, (2, 3))\n \n     def test_split(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(len(knp.split(x, 2)), 2)\n         self.assertEqual(knp.split(x, 2)[0].shape, (1, 3))\n         self.assertEqual(knp.split(x, 3, axis=1)[0].shape, (2, 1))\n@@ -1912,62 +1913,62 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n             knp.split(x, 2, axis=1)\n \n     def test_sqrt(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.sqrt(x).shape, (2, 3))\n \n     def test_stack(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.stack([x, y]).shape, (2, 2, 3))\n         self.assertEqual(knp.stack([x, y], axis=-1).shape, (2, 3, 2))\n \n         with self.assertRaises(ValueError):\n-            x = KerasTensor([2, 3])\n-            y = KerasTensor([3, 3])\n+            x = KerasTensor((2, 3))\n+            y = KerasTensor((3, 3))\n             knp.stack([x, y])\n \n     def test_std(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.std(x).shape, ())\n \n     def test_swapaxes(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.swapaxes(x, 0, 1).shape, (3, 2))\n \n     def test_tan(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.tan(x).shape, (2, 3))\n \n     def test_tanh(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.tanh(x).shape, (2, 3))\n \n     def test_tile(self):\n-        x = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n         self.assertEqual(knp.tile(x, [2]).shape, (2, 6))\n         self.assertEqual(knp.tile(x, [1, 2]).shape, (2, 6))\n         self.assertEqual(knp.tile(x, [2, 1, 2]).shape, (2, 2, 6))\n \n     def test_trace(self):\n-        x = KerasTensor([2, 3, 4, 5])\n+        x = KerasTensor((2, 3, 4, 5))\n         self.assertEqual(knp.trace(x).shape, (4, 5))\n         self.assertEqual(knp.trace(x, axis1=2, axis2=3).shape, (2, 3))\n \n     def test_tril(self):\n-        x = KerasTensor([2, 3, 4, 5])\n+        x = KerasTensor((2, 3, 4, 5))\n         self.assertEqual(knp.tril(x).shape, (2, 3, 4, 5))\n         self.assertEqual(knp.tril(x, k=1).shape, (2, 3, 4, 5))\n         self.assertEqual(knp.tril(x, k=-1).shape, (2, 3, 4, 5))\n \n     def test_triu(self):\n-        x = KerasTensor([2, 3, 4, 5])\n+        x = KerasTensor((2, 3, 4, 5))\n         self.assertEqual(knp.triu(x).shape, (2, 3, 4, 5))\n         self.assertEqual(knp.triu(x, k=1).shape, (2, 3, 4, 5))\n         self.assertEqual(knp.triu(x, k=-1).shape, (2, 3, 4, 5))\n \n     def test_vstack(self):\n-        x = KerasTensor([2, 3])\n-        y = KerasTensor([2, 3])\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n         self.assertEqual(knp.vstack([x, y]).shape, (4, 3))\n \n \n@@ -2012,16 +2013,30 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(knp.Matmul()(x, y), np.matmul(x, y))\n         self.assertAllClose(knp.Matmul()(x, z), np.matmul(x, z))\n \n-    @parameterized.product(\n+    @parameterized.named_parameters(\n+        named_product(\n             (\n-            {\"x_shape\": (5, 3), \"y_shape\": (3, 4)},\n-            {\"x_shape\": (2, 5, 3), \"y_shape\": (2, 3, 4)},\n-            {\"x_shape\": (2, 2, 5, 3), \"y_shape\": (2, 2, 3, 4)},\n+                {\n+                    \"testcase_name\": \"rank2\",\n+                    \"x_shape\": (5, 3),\n+                    \"y_shape\": (3, 4),\n+                },\n+                {\n+                    \"testcase_name\": \"rank3\",\n+                    \"x_shape\": (2, 5, 3),\n+                    \"y_shape\": (2, 3, 4),\n+                },\n+                {\n+                    \"testcase_name\": \"rank4\",\n+                    \"x_shape\": (2, 2, 5, 3),\n+                    \"y_shape\": (2, 2, 3, 4),\n+                },\n             ),\n             dtype=[\"float16\", \"float32\", \"float64\", \"int32\"],\n             x_sparse=[False, True],\n             y_sparse=[False, True],\n         )\n+    )\n     @pytest.mark.skipif(\n         not backend.SUPPORTS_SPARSE_TENSORS,\n         reason=\"Backend does not support sparse tensors.\",\n@@ -2441,7 +2456,14 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase, parameterized.TestCase):\n             np.take(x, indices, axis=-2),\n         )\n \n-    @parameterized.product(\n+    @parameterized.named_parameters(\n+        named_product(\n+            [\n+                {\"testcase_name\": \"axis_none\", \"axis\": None},\n+                {\"testcase_name\": \"axis_0\", \"axis\": 0},\n+                {\"testcase_name\": \"axis_1\", \"axis\": 1},\n+                {\"testcase_name\": \"axis_minus1\", \"axis\": -1},\n+            ],\n             dtype=[\n                 \"float16\",\n                 \"float32\",\n@@ -2451,7 +2473,7 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase, parameterized.TestCase):\n                 \"int16\",\n                 \"int32\",\n             ],\n-        axis=[None, 0, 1, -1],\n+        )\n     )\n     @pytest.mark.skipif(\n         not backend.SUPPORTS_SPARSE_TENSORS,\n@@ -3507,7 +3529,8 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(knp.ones_like(x), np.ones_like(x))\n         self.assertAllClose(knp.OnesLike()(x), np.ones_like(x))\n \n-    @parameterized.product(\n+    @parameterized.named_parameters(\n+        named_product(\n             dtype=[\n                 \"float16\",\n                 \"float32\",\n@@ -3519,6 +3542,7 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             ],\n             mode=[\"constant\", \"reflect\", \"symmetric\"],\n         )\n+    )\n     def test_pad(self, dtype, mode):\n         # 2D\n         x = np.ones([2, 3], dtype=dtype)\n@@ -3913,7 +3937,9 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n         self.jax_enable_x64.__exit__(None, None, None)\n         return super().tearDown()\n \n-    @parameterized.product(dtype1=ALL_DTYPES, dtype2=ALL_DTYPES)\n+    @parameterized.named_parameters(\n+        named_product(dtype1=ALL_DTYPES, dtype2=ALL_DTYPES)\n+    )\n     def test_add(self, dtype1, dtype2):\n         import jax.numpy as jnp\n \n@@ -3930,7 +3956,7 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             standardize_dtype(jnp.add(x1_jax, x2_jax).dtype),\n         )\n \n-    @parameterized.parameters(INT_DTYPES)\n+    @parameterized.named_parameters(named_product(dtype=INT_DTYPES))\n     def test_bincount(self, dtype):\n         import jax.numpy as jnp\n \n@@ -3994,7 +4020,9 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n \n     # TODO: test_einsum\n \n-    @parameterized.product(dtype1=ALL_DTYPES, dtype2=ALL_DTYPES)\n+    @parameterized.named_parameters(\n+        named_product(dtype1=ALL_DTYPES, dtype2=ALL_DTYPES)\n+    )\n     def test_subtract(self, dtype1, dtype2):\n         import jax.numpy as jnp\n \n@@ -4013,7 +4041,9 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             knp.Subtract().symbolic_call(x1, x2).dtype, expected_dtype\n         )\n \n-    @parameterized.product(dtype1=ALL_DTYPES, dtype2=ALL_DTYPES)\n+    @parameterized.named_parameters(\n+        named_product(dtype1=ALL_DTYPES, dtype2=ALL_DTYPES)\n+    )\n     def test_matmul(self, dtype1, dtype2):\n         import jax.numpy as jnp\n \n@@ -4041,7 +4071,9 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             knp.Matmul().symbolic_call(x1, x2).dtype, expected_dtype\n         )\n \n-    @parameterized.product(dtype1=ALL_DTYPES, dtype2=ALL_DTYPES)\n+    @parameterized.named_parameters(\n+        named_product(dtype1=ALL_DTYPES, dtype2=ALL_DTYPES)\n+    )\n     def test_multiply(self, dtype1, dtype2):\n         import jax.numpy as jnp\n \n@@ -4057,7 +4089,7 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             knp.Multiply().symbolic_call(x1, x2).dtype, expected_dtype\n         )\n \n-    @parameterized.product(dtype=ALL_DTYPES)\n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_mean(self, dtype):\n         import jax.numpy as jnp\n \n@@ -4069,7 +4101,7 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n         self.assertEqual(standardize_dtype(knp.mean(x).dtype), expected_dtype)\n         self.assertEqual(knp.Mean().symbolic_call(x).dtype, expected_dtype)\n \n-    @parameterized.product(dtype=ALL_DTYPES)\n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_max(self, dtype):\n         import jax.numpy as jnp\n \n@@ -4079,7 +4111,7 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n         self.assertEqual(standardize_dtype(knp.max(x).dtype), expected_dtype)\n         self.assertEqual(knp.Max().symbolic_call(x).dtype, expected_dtype)\n \n-    @parameterized.parameters(ALL_DTYPES)\n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_ones(self, dtype):\n         import jax.numpy as jnp\n \n@@ -4094,7 +4126,7 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             standardize_dtype(jnp.ones([2, 3], dtype=dtype).dtype),\n         )\n \n-    @parameterized.parameters(ALL_DTYPES)\n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_zeros(self, dtype):\n         import jax.numpy as jnp\n \n@@ -4109,7 +4141,7 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             standardize_dtype(jnp.zeros([2, 3], dtype=dtype).dtype),\n         )\n \n-    @parameterized.parameters(ALL_DTYPES)\n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_absolute(self, dtype):\n         import jax.numpy as jnp\n \n@@ -4124,7 +4156,7 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             expected_dtype,\n         )\n \n-    @parameterized.parameters(ALL_DTYPES)\n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_argmax(self, dtype):\n         import jax.numpy as jnp\n \n@@ -4141,7 +4173,7 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             expected_dtype,\n         )\n \n-    @parameterized.parameters(ALL_DTYPES)\n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_argmin(self, dtype):\n         import jax.numpy as jnp\n \n@@ -4158,7 +4190,7 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             expected_dtype,\n         )\n \n-    @parameterized.parameters(ALL_DTYPES)\n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_argsort(self, dtype):\n         import jax.numpy as jnp\n \n@@ -4210,7 +4242,7 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             standardize_dtype(jnp.arange(start, stop, step, dtype).dtype),\n         )\n \n-    @parameterized.parameters(ALL_DTYPES)\n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_ceil(self, dtype):\n         import jax.numpy as jnp\n \n@@ -4237,7 +4269,7 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             expected_dtype,\n         )\n \n-    @parameterized.parameters(ALL_DTYPES)\n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_clip(self, dtype):\n         import jax.numpy as jnp\n \n@@ -4258,7 +4290,9 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             expected_dtype,\n         )\n \n-    @parameterized.product(dtype1=ALL_DTYPES, dtype2=ALL_DTYPES)\n+    @parameterized.named_parameters(\n+        named_product(dtype1=ALL_DTYPES, dtype2=ALL_DTYPES)\n+    )\n     def test_dot(self, dtype1, dtype2):\n         import jax.numpy as jnp\n \n@@ -4287,7 +4321,7 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n         )\n         self.assertEqual(knp.Dot().symbolic_call(x1, x2).dtype, expected_dtype)\n \n-    @parameterized.parameters(ALL_DTYPES)\n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_empty(self, dtype):\n         import jax.numpy as jnp\n \n@@ -4302,7 +4336,7 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             standardize_dtype(jnp.empty([2, 3], dtype=dtype).dtype),\n         )\n \n-    @parameterized.parameters(ALL_DTYPES)\n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_identity(self, dtype):\n         import jax.numpy as jnp\n \n@@ -4323,7 +4357,7 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             standardize_dtype(jnp.identity(3, dtype=dtype).dtype),\n         )\n \n-    @parameterized.parameters(ALL_DTYPES)\n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_tri(self, dtype):\n         import jax.numpy as jnp\n \n@@ -4342,7 +4376,7 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             standardize_dtype(jnp.tri(3, dtype=dtype).dtype),\n         )\n \n-    @parameterized.parameters(ALL_DTYPES)\n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_sqrt(self, dtype):\n         import jax.numpy as jnp\n \n@@ -4364,7 +4398,7 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             standardize_dtype(jnp.sqrt(x1_jax).dtype),\n         )\n \n-    @parameterized.parameters(ALL_DTYPES)\n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_eye(self, dtype):\n         import jax.numpy as jnp\n \n\n@@ -75,3 +75,89 @@ def get_test_data(\n     x_test, y_test = x_test[test_indices], y_test[test_indices]\n \n     return (x_train, y_train), (x_test, y_test)\n+\n+\n+def named_product(*args, **kwargs):\n+    \"\"\"Utility to generate the cartesian product of parameters values and\n+    generate a test case names for each combination.\n+\n+    The result of this function is to be used with the\n+    `@parameterized.named_parameters` decorator. It is a replacement for\n+    `@parameterized.product` which adds explicit test case names.\n+\n+    For example, this code:\n+    ```\n+    class NamedExample(parameterized.TestCase):\n+        @parameterized.named_parameters(\n+            named_product(\n+                [\n+                    {'testcase_name': 'negative', 'x': -1},\n+                    {'testcase_name': 'positive', 'x': 1},\n+                    {'testcase_name': 'zero', 'x': 0},\n+                ],\n+                numeral_type=[float, int],\n+            )\n+        )\n+        def test_conversion(self, x, numeral_type):\n+            self.assertEqual(numeral_type(x), x)\n+    ```\n+    produces six tests (note that absl will reorder them by name):\n+    - `NamedExample::test_conversion_negative_float`\n+    - `NamedExample::test_conversion_positive_float`\n+    - `NamedExample::test_conversion_zero_float`\n+    - `NamedExample::test_conversion_negative_int`\n+    - `NamedExample::test_conversion_positive_int`\n+    - `NamedExample::test_conversion_zero_int`\n+\n+    This function is also useful in the case where there is no product to\n+    generate test case names for one argument:\n+    ```\n+    @parameterized.named_parameters(named_product(numeral_type=[float, int]))\n+    ```\n+\n+    Args:\n+        *args: Each positional parameter is a sequence of keyword arg dicts.\n+            Every test case generated will include exactly one dict from each\n+            positional parameter. These will then be merged to form an overall\n+            list of arguments for the test case. Each dict must contain a\n+            `\"testcase_name\"` key whose value is combined with others to\n+            generate the test case name.\n+        **kwargs: A mapping of parameter names and their possible values.\n+            Possible values should given as either a list or a tuple. A string\n+            representation of each value is used to generate the test case name.\n+\n+    Returns:\n+        A list of maps for the test parameters combinations to pass to\n+        `@parameterized.named_parameters`.\n+    \"\"\"\n+\n+    def value_to_str(value):\n+        if hasattr(value, \"__name__\"):\n+            return value.__name__.lower()\n+        return str(value).lower()\n+\n+    # Convert the keyword arguments in the same dict format as the args\n+    all_test_dicts = args + tuple(\n+        tuple({\"testcase_name\": value_to_str(v), key: v} for v in values)\n+        for key, values in kwargs.items()\n+    )\n+\n+    # The current list of tests, start with one empty test\n+    tests = [{}]\n+    for test_dicts in all_test_dicts:\n+        new_tests = []\n+        for test_dict in test_dicts:\n+            for test in tests:\n+                # Augment the testcase name by appending\n+                testcase_name = test.get(\"testcase_name\", \"\")\n+                testcase_name += \"_\" if testcase_name else \"\"\n+                testcase_name += test_dict[\"testcase_name\"]\n+                new_test = test.copy()\n+                # Augment the test by adding all the parameters\n+                new_test.update(test_dict)\n+                new_test[\"testcase_name\"] = testcase_name\n+                new_tests.append(new_test)\n+        # Overwrite the list of tests with the product obtained so far\n+        tests = new_tests\n+\n+    return tests\n\n@@ -1,4 +1,5 @@\n import numpy as np\n+from absl.testing import parameterized\n \n from keras.testing import test_case\n from keras.testing import test_utils\n@@ -238,3 +239,52 @@ class ClassDistributionTests(test_case.TestCase):\n         )\n         self.assertTrue(np.all(y_train == 0))\n         self.assertTrue(np.all(y_test == 0))\n+\n+\n+class NamedProductTest(parameterized.TestCase):\n+    def test_test_cases(self):\n+        all_tests = test_utils.named_product(\n+            [\n+                {\"testcase_name\": \"negative\", \"x\": -1},\n+                {\"testcase_name\": \"positive\", \"x\": 1},\n+                {\"testcase_name\": \"zero\", \"x\": 0},\n+            ],\n+            numeral_type=[float, int],\n+        )\n+        names = [test[\"testcase_name\"] for test in all_tests]\n+        self.assertListEqual(\n+            names,\n+            [\n+                \"negative_float\",\n+                \"positive_float\",\n+                \"zero_float\",\n+                \"negative_int\",\n+                \"positive_int\",\n+                \"zero_int\",\n+            ],\n+        )\n+\n+    def test_test_cases_no_product(self):\n+        all_tests = test_utils.named_product(numeral_type=[float, int])\n+        names = [test[\"testcase_name\"] for test in all_tests]\n+        self.assertListEqual(names, [\"float\", \"int\"])\n+\n+    @parameterized.named_parameters(\n+        test_utils.named_product(\n+            [\n+                {\"testcase_name\": \"negative\", \"x\": -1},\n+                {\"testcase_name\": \"positive\", \"x\": 1},\n+                {\"testcase_name\": \"zero\", \"x\": 0},\n+            ],\n+            numeral_type=[float, int],\n+        )\n+    )\n+    def test_via_decorator(self, x, numeral_type):\n+        self.assertIn(x, (-1, 1, 0))\n+        self.assertIn(numeral_type, (float, int))\n+\n+    @parameterized.named_parameters(\n+        test_utils.named_product(numeral_type=[float, int])\n+    )\n+    def test_via_decorator_no_product(self, numeral_type):\n+        self.assertIn(numeral_type, (float, int))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
