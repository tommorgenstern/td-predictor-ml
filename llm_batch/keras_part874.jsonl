{"custom_id": "keras#8907bcbff80cfd93b6b4c148eb7a660a95ac69ab", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 14 | Churn Cumulative: 269 | Contributors (this commit): 7 | Commits (past 90d): 9 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -280,7 +280,7 @@ class Attention(Layer):\n         output_spec = KerasTensor(output_shape, dtype=self.compute_dtype)\n \n         # Handle attention scores if requested\n-        if self._return_attention_scores:\n+        if self._return_attention_scores or return_attention_scores:\n             scores_shape = (\n                 query.shape[0],\n                 query.shape[1],\n\n@@ -417,3 +417,15 @@ class AttentionTest(testing.TestCase):\n         self.assertEqual(\n             attention_scores.shape, (2, 8, 4)\n         )  # Attention scores shape\n+\n+    def test_return_attention_scores_with_symbolic_tensors(self):\n+        \"\"\"Test to check outputs with symbolic tensors with\n+        return_attention_scores = True\"\"\"\n+        attention = layers.Attention()\n+        x = layers.Input(shape=(3, 5))\n+        y = layers.Input(shape=(4, 5))\n+        output, attention_scores = attention(\n+            [x, y], return_attention_scores=True\n+        )\n+        self.assertEqual(output.shape, (None, 3, 5))  # Output shape\n+        self.assertEqual(attention_scores.shape, (None, 3, 4))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ca58091ebb5b8ad0a1295cd6fa7618a3f7b0472e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 891 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -179,6 +179,7 @@ to save the entire model as a single file. You can later recreate the same model\n from this file, even if the code that built the model is no longer available.\n \n This saved file includes the:\n+\n - model architecture\n - model weight values (that were learned during training)\n - model training config, if any (as passed to `compile()`)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#be1191f40b578f39bca1325cf85341db7dfdb4e7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 245 | Lines Deleted: 0 | Files Changed: 5 | Hunks: 5 | Methods Changed: 16 | Complexity Δ (Sum/Max): 26/17 | Churn Δ: 245 | Churn Cumulative: 1070 | Contributors (this commit): 7 | Commits (past 90d): 37 | Contributors (cumulative): 21 | DMM Complexity: 0.8\n\nDIFF:\n@@ -176,6 +176,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_grayscale import\n from keras.src.layers.preprocessing.image_preprocessing.random_hue import (\n     RandomHue,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_posterization import (\n+    RandomPosterization,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_rotation import (\n     RandomRotation,\n )\n\n@@ -176,6 +176,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_grayscale import\n from keras.src.layers.preprocessing.image_preprocessing.random_hue import (\n     RandomHue,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_posterization import (\n+    RandomPosterization,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_rotation import (\n     RandomRotation,\n )\n\n@@ -120,6 +120,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_grayscale import\n from keras.src.layers.preprocessing.image_preprocessing.random_hue import (\n     RandomHue,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_posterization import (\n+    RandomPosterization,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_rotation import (\n     RandomRotation,\n )\n\n@@ -0,0 +1,151 @@\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n+    BaseImagePreprocessingLayer,\n+)\n+\n+\n+@keras_export(\"keras.layers.RandomPosterization\")\n+class RandomPosterization(BaseImagePreprocessingLayer):\n+    \"\"\"Reduces the number of bits for each color channel.\n+\n+    References:\n+    - [AutoAugment: Learning Augmentation Policies from Data](https://arxiv.org/abs/1805.09501)\n+    - [RandAugment: Practical automated data augmentation with a reduced search space](https://arxiv.org/abs/1909.13719)\n+\n+    Args:\n+        value_range: a tuple or a list of two elements. The first value\n+            represents the lower bound for values in passed images, the second\n+            represents the upper bound. Images passed to the layer should have\n+            values within `value_range`. Defaults to `(0, 255)`.\n+        factor: integer, the number of bits to keep for each channel. Must be a\n+            value between 1-8.\n+    \"\"\"\n+\n+    _USE_BASE_FACTOR = False\n+    _FACTOR_BOUNDS = (1, 8)\n+    _MAX_FACTOR = 8\n+    _VALUE_RANGE_VALIDATION_ERROR = (\n+        \"The `value_range` argument should be a list of two numbers. \"\n+    )\n+\n+    def __init__(\n+        self,\n+        factor,\n+        value_range=(0, 255),\n+        data_format=None,\n+        seed=None,\n+        **kwargs,\n+    ):\n+        super().__init__(data_format=data_format, **kwargs)\n+        self._set_factor(factor)\n+        self._set_value_range(value_range)\n+        self.seed = seed\n+        self.generator = self.backend.random.SeedGenerator(seed)\n+\n+    def _set_value_range(self, value_range):\n+        if not isinstance(value_range, (tuple, list)):\n+            raise ValueError(\n+                self._VALUE_RANGE_VALIDATION_ERROR\n+                + f\"Received: value_range={value_range}\"\n+            )\n+        if len(value_range) != 2:\n+            raise ValueError(\n+                self._VALUE_RANGE_VALIDATION_ERROR\n+                + f\"Received: value_range={value_range}\"\n+            )\n+        self.value_range = sorted(value_range)\n+\n+    def get_random_transformation(self, data, training=True, seed=None):\n+        if isinstance(data, dict):\n+            images = data[\"images\"]\n+        else:\n+            images = data\n+        images_shape = self.backend.shape(images)\n+        rank = len(images_shape)\n+        if rank == 3:\n+            batch_size = 1\n+        elif rank == 4:\n+            batch_size = images_shape[0]\n+        else:\n+            raise ValueError(\n+                \"Expected the input image to be rank 3 or 4. Received: \"\n+                f\"inputs.shape={images_shape}\"\n+            )\n+\n+        if seed is None:\n+            seed = self._get_seed_generator(self.backend._backend)\n+\n+        if self.factor[0] != self.factor[1]:\n+            factor = self.backend.random.randint(\n+                (batch_size,),\n+                minval=self.factor[0],\n+                maxval=self.factor[1],\n+                seed=seed,\n+                dtype=\"uint8\",\n+            )\n+        else:\n+            factor = (\n+                self.backend.numpy.ones((batch_size,), dtype=\"uint8\")\n+                * self.factor[0]\n+            )\n+\n+        shift_factor = self._MAX_FACTOR - factor\n+        return {\"shift_factor\": shift_factor}\n+\n+    def transform_images(self, images, transformation=None, training=True):\n+        if training:\n+            shift_factor = transformation[\"shift_factor\"]\n+\n+            shift_factor = self.backend.numpy.reshape(\n+                shift_factor, self.backend.shape(shift_factor) + (1, 1, 1)\n+            )\n+\n+            images = self._transform_value_range(\n+                images,\n+                original_range=self.value_range,\n+                target_range=(0, 255),\n+                dtype=self.compute_dtype,\n+            )\n+\n+            images = self.backend.cast(images, \"uint8\")\n+            images = self.backend.numpy.bitwise_left_shift(\n+                self.backend.numpy.bitwise_right_shift(images, shift_factor),\n+                shift_factor,\n+            )\n+            images = self.backend.cast(images, self.compute_dtype)\n+\n+            images = self._transform_value_range(\n+                images,\n+                original_range=(0, 255),\n+                target_range=self.value_range,\n+                dtype=self.compute_dtype,\n+            )\n+\n+        return images\n+\n+    def transform_labels(self, labels, transformation, training=True):\n+        return labels\n+\n+    def transform_segmentation_masks(\n+        self, segmentation_masks, transformation, training=True\n+    ):\n+        return segmentation_masks\n+\n+    def transform_bounding_boxes(\n+        self, bounding_boxes, transformation, training=True\n+    ):\n+        return bounding_boxes\n+\n+    def get_config(self):\n+        config = super().get_config()\n+        config.update(\n+            {\n+                \"factor\": self.factor,\n+                \"value_range\": self.value_range,\n+                \"seed\": self.seed,\n+            }\n+        )\n+        return config\n+\n+    def compute_output_shape(self, input_shape):\n+        return input_shape\n\n@@ -0,0 +1,85 @@\n+import numpy as np\n+import pytest\n+from tensorflow import data as tf_data\n+\n+import keras\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n+\n+\n+class RandomPosterizationTest(testing.TestCase):\n+    @pytest.mark.requires_trainable_backend\n+    def test_layer(self):\n+        self.run_layer_test(\n+            layers.RandomPosterization,\n+            init_kwargs={\n+                \"factor\": 1,\n+                \"value_range\": (20, 200),\n+                \"seed\": 1,\n+            },\n+            input_shape=(8, 3, 4, 3),\n+            supports_masking=False,\n+            expected_output_shape=(8, 3, 4, 3),\n+        )\n+\n+    def test_random_posterization_inference(self):\n+        seed = 3481\n+        layer = layers.RandomPosterization(1, [0, 255])\n+        np.random.seed(seed)\n+        inputs = np.random.randint(0, 255, size=(224, 224, 3))\n+        output = layer(inputs, training=False)\n+        self.assertAllClose(inputs, output)\n+\n+    def test_random_posterization_basic(self):\n+        seed = 3481\n+        layer = layers.RandomPosterization(\n+            1, [0, 255], data_format=\"channels_last\", seed=seed\n+        )\n+        np.random.seed(seed)\n+        inputs = np.asarray(\n+            [[[128.0, 235.0, 87.0], [12.0, 1.0, 23.0], [24.0, 18.0, 121.0]]]\n+        )\n+        output = layer(inputs)\n+        expected_output = np.asarray(\n+            [[[128.0, 128.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]]\n+        )\n+        self.assertAllClose(expected_output, output)\n+\n+    def test_random_posterization_value_range_0_to_1(self):\n+        image = keras.random.uniform(shape=(3, 3, 3), minval=0, maxval=1)\n+\n+        layer = layers.RandomPosterization(1, [0, 1.0])\n+        adjusted_image = layer(image)\n+\n+        self.assertTrue(keras.ops.numpy.all(adjusted_image >= 0))\n+        self.assertTrue(keras.ops.numpy.all(adjusted_image <= 1))\n+\n+    def test_random_posterization_value_range_0_to_255(self):\n+        image = keras.random.uniform(shape=(3, 3, 3), minval=0, maxval=255)\n+\n+        layer = layers.RandomPosterization(1, [0, 255])\n+        adjusted_image = layer(image)\n+\n+        self.assertTrue(keras.ops.numpy.all(adjusted_image >= 0))\n+        self.assertTrue(keras.ops.numpy.all(adjusted_image <= 255))\n+\n+    def test_random_posterization_randomness(self):\n+        image = keras.random.uniform(shape=(3, 3, 3), minval=0, maxval=1)\n+\n+        layer = layers.RandomPosterization(1, [0, 255])\n+        adjusted_images = layer(image)\n+\n+        self.assertNotAllClose(adjusted_images, image)\n+\n+    def test_tf_data_compatibility(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            input_data = np.random.random((2, 8, 8, 3))\n+        else:\n+            input_data = np.random.random((2, 3, 8, 8))\n+        layer = layers.RandomPosterization(1, [0, 255])\n+\n+        ds = tf_data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            output.numpy()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2b073b608daebbf8184fa2ee009b7cae9fa72ed0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 1134 | Contributors (this commit): 11 | Commits (past 90d): 14 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -57,6 +57,9 @@ def get_model(type=\"sequential\", input_shape=(10,), layer_list=None):\n     ),\n )\n @pytest.mark.skipif(testing.jax_uses_gpu(), reason=\"Leads to core dumps on CI\")\n+@pytest.mark.skipif(\n+    testing.torch_uses_gpu(), reason=\"Leads to core dumps on CI\"\n+)\n class ExportSavedModelTest(testing.TestCase):\n     @parameterized.named_parameters(\n         named_product(model_type=[\"sequential\", \"functional\", \"subclass\"])\n@@ -344,6 +347,9 @@ class ExportSavedModelTest(testing.TestCase):\n     reason=\"Export only currently supports the TF and JAX backends.\",\n )\n @pytest.mark.skipif(testing.jax_uses_gpu(), reason=\"Leads to core dumps on CI\")\n+@pytest.mark.skipif(\n+    testing.torch_uses_gpu(), reason=\"Leads to core dumps on CI\"\n+)\n class ExportArchiveTest(testing.TestCase):\n     @parameterized.named_parameters(\n         named_product(model_type=[\"sequential\", \"functional\", \"subclass\"])\n\n@@ -1229,6 +1229,9 @@ class ModelTest(testing.TestCase):\n     @pytest.mark.skipif(\n         testing.jax_uses_gpu(), reason=\"Leads to core dumps on CI\"\n     )\n+    @pytest.mark.skipif(\n+        testing.torch_uses_gpu(), reason=\"Leads to core dumps on CI\"\n+    )\n     def test_export(self):\n         import tensorflow as tf\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6ce93a4c3c9ff8af9a8024f062f38c335e1b5dee", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 242 | Lines Deleted: 0 | Files Changed: 5 | Hunks: 5 | Methods Changed: 14 | Complexity Δ (Sum/Max): 26/18 | Churn Δ: 242 | Churn Cumulative: 1076 | Contributors (this commit): 7 | Commits (past 90d): 40 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -185,6 +185,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_rotation import (\n from keras.src.layers.preprocessing.image_preprocessing.random_saturation import (\n     RandomSaturation,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_sharpness import (\n+    RandomSharpness,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_translation import (\n     RandomTranslation,\n )\n\n@@ -185,6 +185,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_rotation import (\n from keras.src.layers.preprocessing.image_preprocessing.random_saturation import (\n     RandomSaturation,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_sharpness import (\n+    RandomSharpness,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_translation import (\n     RandomTranslation,\n )\n\n@@ -129,6 +129,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_rotation import (\n from keras.src.layers.preprocessing.image_preprocessing.random_saturation import (\n     RandomSaturation,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_sharpness import (\n+    RandomSharpness,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_translation import (\n     RandomTranslation,\n )\n\n@@ -0,0 +1,168 @@\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n+    BaseImagePreprocessingLayer,\n+)\n+from keras.src.random import SeedGenerator\n+\n+\n+@keras_export(\"keras.layers.RandomSharpness\")\n+class RandomSharpness(BaseImagePreprocessingLayer):\n+    \"\"\"Randomly performs the sharpness operation on given images.\n+\n+    The sharpness operation first performs a blur, then blends between the\n+    original image and the processed image. This operation adjusts the clarity\n+    of the edges in an image, ranging from blurred to enhanced sharpness.\n+\n+    Args:\n+        factor: A tuple of two floats or a single float.\n+            `factor` controls the extent to which the image sharpness\n+            is impacted. `factor=0.0` results in a fully blurred image,\n+            `factor=0.5` applies no operation (preserving the original image),\n+            and `factor=1.0` enhances the sharpness beyond the original. Values\n+            should be between `0.0` and `1.0`. If a tuple is used, a `factor`\n+            is sampled between the two values for every image augmented.\n+            If a single float is used, a value between `0.0` and the passed\n+            float is sampled. To ensure the value is always the same,\n+            pass a tuple with two identical floats: `(0.5, 0.5)`.\n+        value_range: the range of values the incoming images will have.\n+            Represented as a two-number tuple written `[low, high]`. This is\n+            typically either `[0, 1]` or `[0, 255]` depending on how your\n+            preprocessing pipeline is set up.\n+        seed: Integer. Used to create a random seed.\n+    \"\"\"\n+\n+    _USE_BASE_FACTOR = False\n+    _FACTOR_BOUNDS = (0, 1)\n+\n+    _VALUE_RANGE_VALIDATION_ERROR = (\n+        \"The `value_range` argument should be a list of two numbers. \"\n+    )\n+\n+    def __init__(\n+        self,\n+        factor,\n+        value_range=(0, 255),\n+        data_format=None,\n+        seed=None,\n+        **kwargs,\n+    ):\n+        super().__init__(data_format=data_format, **kwargs)\n+        self._set_factor(factor)\n+        self._set_value_range(value_range)\n+        self.seed = seed\n+        self.generator = SeedGenerator(seed)\n+\n+    def _set_value_range(self, value_range):\n+        if not isinstance(value_range, (tuple, list)):\n+            raise ValueError(\n+                self._VALUE_RANGE_VALIDATION_ERROR\n+                + f\"Received: value_range={value_range}\"\n+            )\n+        if len(value_range) != 2:\n+            raise ValueError(\n+                self._VALUE_RANGE_VALIDATION_ERROR\n+                + f\"Received: value_range={value_range}\"\n+            )\n+        self.value_range = sorted(value_range)\n+\n+    def get_random_transformation(self, data, training=True, seed=None):\n+        if isinstance(data, dict):\n+            images = data[\"images\"]\n+        else:\n+            images = data\n+        images_shape = self.backend.shape(images)\n+        rank = len(images_shape)\n+        if rank == 3:\n+            batch_size = 1\n+        elif rank == 4:\n+            batch_size = images_shape[0]\n+        else:\n+            raise ValueError(\n+                \"Expected the input image to be rank 3 or 4. Received: \"\n+                f\"inputs.shape={images_shape}\"\n+            )\n+\n+        if seed is None:\n+            seed = self._get_seed_generator(self.backend._backend)\n+\n+        factor = self.backend.random.uniform(\n+            (batch_size,),\n+            minval=self.factor[0],\n+            maxval=self.factor[1],\n+            seed=seed,\n+        )\n+        return {\"factor\": factor}\n+\n+    def transform_images(self, images, transformation=None, training=True):\n+        images = self.backend.cast(images, self.compute_dtype)\n+        if training:\n+            if self.data_format == \"channels_first\":\n+                images = self.backend.numpy.swapaxes(images, -3, -1)\n+\n+            sharpness_factor = self.backend.cast(\n+                transformation[\"factor\"] * 2, dtype=self.compute_dtype\n+            )\n+            sharpness_factor = self.backend.numpy.reshape(\n+                sharpness_factor, (-1, 1, 1, 1)\n+            )\n+\n+            num_channels = self.backend.shape(images)[-1]\n+\n+            a, b = 1.0 / 13.0, 5.0 / 13.0\n+            kernel = self.backend.convert_to_tensor(\n+                [[a, a, a], [a, b, a], [a, a, a]], dtype=self.compute_dtype\n+            )\n+            kernel = self.backend.numpy.reshape(kernel, (3, 3, 1, 1))\n+            kernel = self.backend.numpy.tile(kernel, [1, 1, num_channels, 1])\n+            kernel = self.backend.cast(kernel, self.compute_dtype)\n+\n+            smoothed_image = self.backend.nn.depthwise_conv(\n+                images,\n+                kernel,\n+                strides=1,\n+                padding=\"same\",\n+                data_format=\"channels_last\",\n+            )\n+\n+            smoothed_image = self.backend.cast(\n+                smoothed_image, dtype=self.compute_dtype\n+            )\n+            images = images + (1.0 - sharpness_factor) * (\n+                smoothed_image - images\n+            )\n+\n+            images = self.backend.numpy.clip(\n+                images, self.value_range[0], self.value_range[1]\n+            )\n+\n+            if self.data_format == \"channels_first\":\n+                images = self.backend.numpy.swapaxes(images, -3, -1)\n+\n+        return images\n+\n+    def transform_labels(self, labels, transformation, training=True):\n+        return labels\n+\n+    def transform_segmentation_masks(\n+        self, segmentation_masks, transformation, training=True\n+    ):\n+        return segmentation_masks\n+\n+    def transform_bounding_boxes(\n+        self, bounding_boxes, transformation, training=True\n+    ):\n+        return bounding_boxes\n+\n+    def get_config(self):\n+        config = super().get_config()\n+        config.update(\n+            {\n+                \"factor\": self.factor,\n+                \"value_range\": self.value_range,\n+                \"seed\": self.seed,\n+            }\n+        )\n+        return config\n+\n+    def compute_output_shape(self, input_shape):\n+        return input_shape\n\n@@ -0,0 +1,65 @@\n+import numpy as np\n+import pytest\n+from tensorflow import data as tf_data\n+\n+import keras\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n+\n+\n+class RandomSharpnessTest(testing.TestCase):\n+    @pytest.mark.requires_trainable_backend\n+    def test_layer(self):\n+        self.run_layer_test(\n+            layers.RandomSharpness,\n+            init_kwargs={\n+                \"factor\": 0.75,\n+                \"seed\": 1,\n+            },\n+            input_shape=(8, 3, 4, 3),\n+            supports_masking=False,\n+            expected_output_shape=(8, 3, 4, 3),\n+        )\n+\n+    def test_random_sharpness_value_range(self):\n+        image = keras.random.uniform(shape=(3, 3, 3), minval=0, maxval=1)\n+\n+        layer = layers.RandomSharpness(0.2)\n+        adjusted_image = layer(image)\n+\n+        self.assertTrue(keras.ops.numpy.all(adjusted_image >= 0))\n+        self.assertTrue(keras.ops.numpy.all(adjusted_image <= 1))\n+\n+    def test_random_sharpness_no_op(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            inputs = np.random.random((2, 8, 8, 3))\n+        else:\n+            inputs = np.random.random((2, 3, 8, 8))\n+\n+        layer = layers.RandomSharpness((0.5, 0.5))\n+        output = layer(inputs, training=False)\n+        self.assertAllClose(inputs, output, atol=1e-3, rtol=1e-5)\n+\n+    def test_random_sharpness_randomness(self):\n+        image = keras.random.uniform(shape=(3, 3, 3), minval=0, maxval=1)[:5]\n+\n+        layer = layers.RandomSharpness(0.2)\n+        adjusted_images = layer(image)\n+\n+        self.assertNotAllClose(adjusted_images, image)\n+\n+    def test_tf_data_compatibility(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            input_data = np.random.random((2, 8, 8, 3))\n+        else:\n+            input_data = np.random.random((2, 3, 8, 8))\n+        layer = layers.RandomSharpness(\n+            factor=0.5, data_format=data_format, seed=1337\n+        )\n+\n+        ds = tf_data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            output.numpy()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3c9fee783d2228276fa9a8b021396db08f0693d4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 348 | Lines Deleted: 0 | Files Changed: 5 | Hunks: 5 | Methods Changed: 16 | Complexity Δ (Sum/Max): 35/27 | Churn Δ: 348 | Churn Cumulative: 1191 | Contributors (this commit): 7 | Commits (past 90d): 43 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -188,6 +188,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_saturation import\n from keras.src.layers.preprocessing.image_preprocessing.random_sharpness import (\n     RandomSharpness,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_shear import (\n+    RandomShear,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_translation import (\n     RandomTranslation,\n )\n\n@@ -188,6 +188,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_saturation import\n from keras.src.layers.preprocessing.image_preprocessing.random_sharpness import (\n     RandomSharpness,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_shear import (\n+    RandomShear,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_translation import (\n     RandomTranslation,\n )\n\n@@ -132,6 +132,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_saturation import\n from keras.src.layers.preprocessing.image_preprocessing.random_sharpness import (\n     RandomSharpness,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_shear import (\n+    RandomShear,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_translation import (\n     RandomTranslation,\n )\n\n@@ -0,0 +1,263 @@\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n+    BaseImagePreprocessingLayer,\n+)\n+from keras.src.random.seed_generator import SeedGenerator\n+\n+\n+@keras_export(\"keras.layers.RandomShear\")\n+class RandomShear(BaseImagePreprocessingLayer):\n+    \"\"\"A preprocessing layer that randomly applies shear transformations to\n+    images.\n+\n+    This layer shears the input images along the x-axis and/or y-axis by a\n+    randomly selected factor within the specified range. The shear\n+    transformation is applied to each image independently in a batch. Empty\n+    regions created during the transformation are filled according to the\n+    `fill_mode` and `fill_value` parameters.\n+\n+    Args:\n+        x_factor: A tuple of two floats. For each augmented image, a value\n+            is sampled from the provided range. If a float is passed, the\n+            range is interpreted as `(0, x_factor)`. Values represent a\n+            percentage of the image to shear over. For example, 0.3 shears\n+            pixels up to 30% of the way across the image. All provided values\n+            should be positive.\n+        y_factor: A tuple of two floats. For each augmented image, a value\n+            is sampled from the provided range. If a float is passed, the\n+            range is interpreted as `(0, y_factor)`. Values represent a\n+            percentage of the image to shear over. For example, 0.3 shears\n+            pixels up to 30% of the way across the image. All provided values\n+            should be positive.\n+        interpolation: Interpolation mode. Supported values: `\"nearest\"`,\n+            `\"bilinear\"`.\n+        fill_mode: Points outside the boundaries of the input are filled\n+            according to the given mode. Available methods are `\"constant\"`,\n+            `\"nearest\"`, `\"wrap\"` and `\"reflect\"`. Defaults to `\"constant\"`.\n+            - `\"reflect\"`: `(d c b a | a b c d | d c b a)`\n+                The input is extended by reflecting about the edge of the\n+                last pixel.\n+            - `\"constant\"`: `(k k k k | a b c d | k k k k)`\n+                The input is extended by filling all values beyond the edge\n+                with the same constant value `k` specified by `fill_value`.\n+            - `\"wrap\"`: `(a b c d | a b c d | a b c d)`\n+                The input is extended by wrapping around to the opposite edge.\n+            - `\"nearest\"`: `(a a a a | a b c d | d d d d)`\n+                The input is extended by the nearest pixel.\n+            Note that when using torch backend, `\"reflect\"` is redirected to\n+            `\"mirror\"` `(c d c b | a b c d | c b a b)` because torch does\n+            not support `\"reflect\"`.\n+            Note that torch backend does not support `\"wrap\"`.\n+        fill_value: A float representing the value to be filled outside the\n+            boundaries when `fill_mode=\"constant\"`.\n+        seed: Integer. Used to create a random seed.\n+    \"\"\"\n+\n+    _USE_BASE_FACTOR = False\n+    _FACTOR_BOUNDS = (0, 1)\n+    _FACTOR_VALIDATION_ERROR = (\n+        \"The `factor` argument should be a number (or a list of two numbers) \"\n+        \"in the range [0, 1.0]. \"\n+    )\n+    _SUPPORTED_FILL_MODE = (\"reflect\", \"wrap\", \"constant\", \"nearest\")\n+    _SUPPORTED_INTERPOLATION = (\"nearest\", \"bilinear\")\n+\n+    def __init__(\n+        self,\n+        x_factor=0.0,\n+        y_factor=0.0,\n+        interpolation=\"bilinear\",\n+        fill_mode=\"reflect\",\n+        fill_value=0.0,\n+        data_format=None,\n+        seed=None,\n+        **kwargs,\n+    ):\n+        super().__init__(data_format=data_format, **kwargs)\n+        self.x_factor = self._set_factor_with_name(x_factor, \"x_factor\")\n+        self.y_factor = self._set_factor_with_name(y_factor, \"y_factor\")\n+\n+        if fill_mode not in self._SUPPORTED_FILL_MODE:\n+            raise NotImplementedError(\n+                f\"Unknown `fill_mode` {fill_mode}. Expected of one \"\n+                f\"{self._SUPPORTED_FILL_MODE}.\"\n+            )\n+        if interpolation not in self._SUPPORTED_INTERPOLATION:\n+            raise NotImplementedError(\n+                f\"Unknown `interpolation` {interpolation}. Expected of one \"\n+                f\"{self._SUPPORTED_INTERPOLATION}.\"\n+            )\n+\n+        self.fill_mode = fill_mode\n+        self.fill_value = fill_value\n+        self.interpolation = interpolation\n+        self.seed = seed\n+        self.generator = SeedGenerator(seed)\n+        self.supports_jit = False\n+\n+    def _set_factor_with_name(self, factor, factor_name):\n+        if isinstance(factor, (tuple, list)):\n+            if len(factor) != 2:\n+                raise ValueError(\n+                    self._FACTOR_VALIDATION_ERROR\n+                    + f\"Received: {factor_name}={factor}\"\n+                )\n+            self._check_factor_range(factor[0])\n+            self._check_factor_range(factor[1])\n+            lower, upper = sorted(factor)\n+        elif isinstance(factor, (int, float)):\n+            self._check_factor_range(factor)\n+            factor = abs(factor)\n+            lower, upper = [-factor, factor]\n+        else:\n+            raise ValueError(\n+                self._FACTOR_VALIDATION_ERROR\n+                + f\"Received: {factor_name}={factor}\"\n+            )\n+        return lower, upper\n+\n+    def _check_factor_range(self, input_number):\n+        if input_number > 1.0 or input_number < 0.0:\n+            raise ValueError(\n+                self._FACTOR_VALIDATION_ERROR\n+                + f\"Received: input_number={input_number}\"\n+            )\n+\n+    def get_random_transformation(self, data, training=True, seed=None):\n+        if not training:\n+            return None\n+\n+        if isinstance(data, dict):\n+            images = data[\"images\"]\n+        else:\n+            images = data\n+\n+        images_shape = self.backend.shape(images)\n+        if len(images_shape) == 3:\n+            batch_size = 1\n+        else:\n+            batch_size = images_shape[0]\n+\n+        if seed is None:\n+            seed = self._get_seed_generator(self.backend._backend)\n+\n+        invert = self.backend.random.uniform(\n+            minval=0,\n+            maxval=1,\n+            shape=[batch_size, 1],\n+            seed=seed,\n+            dtype=self.compute_dtype,\n+        )\n+        invert = self.backend.numpy.where(\n+            invert > 0.5,\n+            -self.backend.numpy.ones_like(invert),\n+            self.backend.numpy.ones_like(invert),\n+        )\n+\n+        shear_y = self.backend.random.uniform(\n+            minval=self.y_factor[0],\n+            maxval=self.y_factor[1],\n+            shape=[batch_size, 1],\n+            seed=seed,\n+            dtype=self.compute_dtype,\n+        )\n+        shear_x = self.backend.random.uniform(\n+            minval=self.x_factor[0],\n+            maxval=self.x_factor[1],\n+            shape=[batch_size, 1],\n+            seed=seed,\n+            dtype=self.compute_dtype,\n+        )\n+        shear_factor = (\n+            self.backend.cast(\n+                self.backend.numpy.concatenate([shear_x, shear_y], axis=1),\n+                dtype=self.compute_dtype,\n+            )\n+            * invert\n+        )\n+        return {\"shear_factor\": shear_factor}\n+\n+    def transform_images(self, images, transformation, training=True):\n+        images = self.backend.cast(images, self.compute_dtype)\n+        if training:\n+            return self._shear_inputs(images, transformation)\n+        return images\n+\n+    def _shear_inputs(self, inputs, transformation):\n+        if transformation is None:\n+            return inputs\n+\n+        inputs_shape = self.backend.shape(inputs)\n+        unbatched = len(inputs_shape) == 3\n+        if unbatched:\n+            inputs = self.backend.numpy.expand_dims(inputs, axis=0)\n+\n+        shear_factor = transformation[\"shear_factor\"]\n+        outputs = self.backend.image.affine_transform(\n+            inputs,\n+            transform=self._get_shear_matrix(shear_factor),\n+            interpolation=self.interpolation,\n+            fill_mode=self.fill_mode,\n+            fill_value=self.fill_value,\n+            data_format=self.data_format,\n+        )\n+\n+        if unbatched:\n+            outputs = self.backend.numpy.squeeze(outputs, axis=0)\n+        return outputs\n+\n+    def _get_shear_matrix(self, shear_factors):\n+        num_shear_factors = self.backend.shape(shear_factors)[0]\n+\n+        # The shear matrix looks like:\n+        # [[1   s_x  0]\n+        #  [s_y  1   0]\n+        #  [0    0   1]]\n+\n+        return self.backend.numpy.stack(\n+            [\n+                self.backend.numpy.ones((num_shear_factors,)),\n+                shear_factors[:, 0],\n+                self.backend.numpy.zeros((num_shear_factors,)),\n+                shear_factors[:, 1],\n+                self.backend.numpy.ones((num_shear_factors,)),\n+                self.backend.numpy.zeros((num_shear_factors,)),\n+                self.backend.numpy.zeros((num_shear_factors,)),\n+                self.backend.numpy.zeros((num_shear_factors,)),\n+            ],\n+            axis=1,\n+        )\n+\n+    def transform_labels(self, labels, transformation, training=True):\n+        return labels\n+\n+    def transform_bounding_boxes(\n+        self,\n+        bounding_boxes,\n+        transformation,\n+        training=True,\n+    ):\n+        raise NotImplementedError\n+\n+    def transform_segmentation_masks(\n+        self, segmentation_masks, transformation, training=True\n+    ):\n+        return self.transform_images(\n+            segmentation_masks, transformation, training=training\n+        )\n+\n+    def get_config(self):\n+        base_config = super().get_config()\n+        config = {\n+            \"x_factor\": self.x_factor,\n+            \"y_factor\": self.y_factor,\n+            \"fill_mode\": self.fill_mode,\n+            \"interpolation\": self.interpolation,\n+            \"seed\": self.seed,\n+            \"fill_value\": self.fill_value,\n+            \"data_format\": self.data_format,\n+        }\n+        return {**base_config, **config}\n+\n+    def compute_output_shape(self, input_shape):\n+        return input_shape\n\n@@ -0,0 +1,76 @@\n+import numpy as np\n+import pytest\n+from tensorflow import data as tf_data\n+\n+import keras\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n+\n+\n+class RandomShearTest(testing.TestCase):\n+    @pytest.mark.requires_trainable_backend\n+    def test_layer(self):\n+        self.run_layer_test(\n+            layers.RandomShear,\n+            init_kwargs={\n+                \"x_factor\": (0.5, 1),\n+                \"y_factor\": (0.5, 1),\n+                \"interpolation\": \"bilinear\",\n+                \"fill_mode\": \"reflect\",\n+                \"data_format\": \"channels_last\",\n+                \"seed\": 1,\n+            },\n+            input_shape=(8, 3, 4, 3),\n+            supports_masking=False,\n+            expected_output_shape=(8, 3, 4, 3),\n+        )\n+\n+    def test_random_posterization_inference(self):\n+        seed = 3481\n+        layer = layers.RandomShear(1, 1)\n+        np.random.seed(seed)\n+        inputs = np.random.randint(0, 255, size=(224, 224, 3))\n+        output = layer(inputs, training=False)\n+        self.assertAllClose(inputs, output)\n+\n+    def test_shear_pixel_level(self):\n+        image = np.zeros((1, 5, 5, 3))\n+        image[0, 1:4, 1:4, :] = 1.0\n+        image[0, 2, 2, :] = [0.0, 1.0, 0.0]\n+        image = keras.ops.convert_to_tensor(image, dtype=\"float32\")\n+\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_first\":\n+            image = keras.ops.transpose(image, (0, 3, 1, 2))\n+\n+        shear_layer = layers.RandomShear(\n+            x_factor=(0.2, 0.3),\n+            y_factor=(0.2, 0.3),\n+            interpolation=\"bilinear\",\n+            fill_mode=\"constant\",\n+            fill_value=0.0,\n+            seed=42,\n+            data_format=data_format,\n+        )\n+\n+        sheared_image = shear_layer(image)\n+\n+        if data_format == \"channels_first\":\n+            sheared_image = keras.ops.transpose(sheared_image, (0, 2, 3, 1))\n+\n+        original_pixel = image[0, 2, 2, :]\n+        sheared_pixel = sheared_image[0, 2, 2, :]\n+        self.assertNotAllClose(original_pixel, sheared_pixel)\n+\n+    def test_tf_data_compatibility(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            input_data = np.random.random((2, 8, 8, 3))\n+        else:\n+            input_data = np.random.random((2, 3, 8, 8))\n+        layer = layers.RandomShear(1, 1)\n+\n+        ds = tf_data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            output.numpy()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c8c2c6fc7585a56ca8c8dfd084f5dadad6ad1036", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 67 | Lines Deleted: 16 | Files Changed: 4 | Hunks: 11 | Methods Changed: 8 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 83 | Churn Cumulative: 903 | Contributors (this commit): 12 | Commits (past 90d): 20 | Contributors (cumulative): 22 | DMM Complexity: 0.0\n\nDIFF:\n@@ -33,9 +33,11 @@ class Variable:\n         autocast: Optional. Boolean indicating whether the variable supports\n             autocasting. If `True`, the layer may first convert the variable\n             to the compute data type when accessed. Defaults to `True`.\n-        aggregation: Optional. String specifying how a distributed variable will\n-            be aggregated. This serves as a semantic annotation, to be taken\n-            into account by downstream backends or users. Defaults to `\"mean\"`.\n+        aggregation: Optional string, one of `None`, `\"none\"`, `\"mean\"`,\n+            `\"sum\"` or `\"only_first_replica\"` specifying how a distributed\n+            variable will be aggregated. This serves as a semantic annotation,\n+            to be taken into account by downstream backends or users. Defaults\n+            to `\"none\"`.\n         name: Optional. A unique name for the variable. Automatically generated\n             if not set.\n \n@@ -93,7 +95,7 @@ class Variable:\n         dtype=None,\n         trainable=True,\n         autocast=True,\n-        aggregation=\"mean\",\n+        aggregation=\"none\",\n         name=None,\n     ):\n         name = name or auto_name(self.__class__.__name__)\n@@ -103,12 +105,21 @@ class Variable:\n                 \"cannot contain character `/`. \"\n                 f\"Received: name={name}\"\n             )\n-        if aggregation not in (\"none\", \"mean\", \"sum\", \"only_first_replica\"):\n+        if aggregation not in (\n+            None,\n+            \"none\",\n+            \"mean\",\n+            \"sum\",\n+            \"only_first_replica\",\n+        ):\n             raise ValueError(\n                 \"Invalid valid for argument `aggregation`. Expected \"\n-                \"one of {'none', 'mean', 'sum', 'only_first_replica'}. \"\n+                \"one of `None`, `'none'`, `'mean'`, `'sum'`, \"\n+                \"`'only_first_replica'`. \"\n                 f\"Received: aggregation={aggregation}\"\n             )\n+        if aggregation is None:\n+            aggregation = \"none\"\n         self._name = name\n         parent_path = current_path()\n         if parent_path:\n\n@@ -130,8 +130,8 @@ class DistributeTest(testing.TestCase):\n         with strategy.scope():\n             x = np.random.random((4, 4))\n             v1 = backend.Variable(x, dtype=\"float32\")\n-            self.assertEqual(v1.aggregation, \"mean\")\n-            self.assertEqual(v1.value.aggregation, tf.VariableAggregation.MEAN)\n+            self.assertEqual(v1.aggregation, \"none\")\n+            self.assertEqual(v1.value.aggregation, tf.VariableAggregation.NONE)\n \n             v2 = backend.Variable(x, dtype=\"float32\", aggregation=\"sum\")\n             self.assertEqual(v2.aggregation, \"sum\")\n\n@@ -493,7 +493,7 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n         autocast=True,\n         regularizer=None,\n         constraint=None,\n-        aggregation=\"mean\",\n+        aggregation=\"none\",\n         name=None,\n     ):\n         \"\"\"Add a weight variable to the layer.\n@@ -520,10 +520,11 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n             constraint: Contrainst object to call on the variable after any\n                 optimizer update, or string name of a built-in constraint.\n                 Defaults to `None`.\n-            aggregation: String, one of `'mean'`, `'sum'`,\n-                `'only_first_replica'`. Annotates the variable with the type\n-                of multi-replica aggregation to be used for this variable\n-                when writing custom data parallel training loops.\n+            aggregation: Optional string, one of `None`, `\"none\"`, `\"mean\"`,\n+                `\"sum\"` or `\"only_first_replica\"`. Annotates the variable with\n+                the type of multi-replica aggregation to be used for this\n+                variable when writing custom data parallel training loops.\n+                Defaults to `\"none\"`.\n             name: String name of the variable. Useful for debugging purposes.\n         \"\"\"\n         self._check_super_called()\n\n@@ -245,9 +245,29 @@ class BaseOptimizer(KerasSaveable):\n         shape,\n         initializer=\"zeros\",\n         dtype=None,\n-        aggregation=\"mean\",\n+        aggregation=\"none\",\n         name=None,\n     ):\n+        \"\"\"Add a variable to the optimizer.\n+\n+        Args:\n+            shape: Shape tuple for the variable. Must be fully-defined\n+                (no `None` entries).\n+            initializer: Initializer object to use to populate the initial\n+                variable value, or string name of a built-in initializer\n+                (e.g. `\"random_normal\"`). Defaults to `\"zeros\"`.\n+            dtype: Dtype of the variable to create, e.g. `\"float32\"`. If\n+                unspecified, defaults to the `keras.backend.floatx()`.\n+            aggregation: Optional string, one of `None`, `\"none\"`, `\"mean\"`,\n+                `\"sum\"` or `\"only_first_replica\"`. Annotates the variable with\n+                the type of multi-replica aggregation to be used for this\n+                variable when writing custom data parallel training loops.\n+                Defaults to `\"none\"`.\n+            name: String name of the variable. Useful for debugging purposes.\n+\n+        Returns:\n+            An optimizer variable, in the format of `keras.Variable`.\n+        \"\"\"\n         self._check_super_called()\n         initializer = initializers.get(initializer)\n         with backend.name_scope(self.name, caller=self):\n@@ -265,8 +285,27 @@ class BaseOptimizer(KerasSaveable):\n     def add_variable_from_reference(\n         self, reference_variable, name=None, initializer=\"zeros\"\n     ):\n-        \"\"\"Add an all-zeros variable with the shape and dtype of a reference\n-        variable.\n+        \"\"\"Add an optimizer variable from the model variable.\n+\n+        Create an optimizer variable based on the information of model variable.\n+        For example, in SGD optimizer momemtum, for each model variable, a\n+        corresponding momemtum variable is created of the same shape and dtype.\n+\n+        Args:\n+            reference_variable: `keras.Variable`. The corresponding model\n+                variable to the optimizer variable to be created.\n+            name: Optional string. The name prefix of the optimizer variable to\n+                be created. If not provided, it will be set to `\"var\"`. The\n+                variable name will follow the pattern\n+                `{variable_name}_{reference_variable.name}`,\n+                e.g., `momemtum/dense_1`. Defaults to `None`.\n+            initializer: Initializer object to use to populate the initial\n+                variable value, or string name of a built-in initializer\n+                (e.g. `\"random_normal\"`). If unspecified, defaults to\n+                `\"zeros\"`.\n+\n+        Returns:\n+            An optimizer variable, in the format of `keras.Variable`.\n         \"\"\"\n         name = name or \"var\"\n         if hasattr(reference_variable, \"path\"):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#476a664e711cf9d0bbc0264a4f5cd4bac2f52155", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 57 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -15,7 +15,7 @@ class BackendUtilsTest(testing.TestCase):\n     )\n     def test_dynamic_backend(self, name):\n         dynamic_backend = backend_utils.DynamicBackend()\n-        x = np.random.uniform(size=[1, 2, 3])\n+        x = np.random.uniform(size=[1, 2, 3]).astype(\"float32\")\n \n         if name == \"numpy\":\n             dynamic_backend.set_backend(name)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5b299743442b64afaeeec01e925ddbeb112aad3c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 266 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 8 | Methods Changed: 8 | Complexity Δ (Sum/Max): 14/10 | Churn Δ: 268 | Churn Cumulative: 607 | Contributors (this commit): 1 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2,7 +2,14 @@ from keras.src.api_export import keras_export\n from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n     BaseImagePreprocessingLayer,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.bounding_boxes.converters import (  # noqa: E501\n+    clip_to_image_size,\n+)\n+from keras.src.layers.preprocessing.image_preprocessing.bounding_boxes.converters import (  # noqa: E501\n+    convert_format,\n+)\n from keras.src.random.seed_generator import SeedGenerator\n+from keras.src.utils import backend_utils\n \n \n @keras_export(\"keras.layers.RandomShear\")\n@@ -175,7 +182,7 @@ class RandomShear(BaseImagePreprocessingLayer):\n             )\n             * invert\n         )\n-        return {\"shear_factor\": shear_factor}\n+        return {\"shear_factor\": shear_factor, \"input_shape\": images_shape}\n \n     def transform_images(self, images, transformation, training=True):\n         images = self.backend.cast(images, self.compute_dtype)\n@@ -231,13 +238,144 @@ class RandomShear(BaseImagePreprocessingLayer):\n     def transform_labels(self, labels, transformation, training=True):\n         return labels\n \n+    def get_transformed_x_y(self, x, y, transform):\n+        a0, a1, a2, b0, b1, b2, c0, c1 = self.backend.numpy.split(\n+            transform, 8, axis=-1\n+        )\n+\n+        k = c0 * x + c1 * y + 1\n+        x_transformed = (a0 * x + a1 * y + a2) / k\n+        y_transformed = (b0 * x + b1 * y + b2) / k\n+        return x_transformed, y_transformed\n+\n+    def get_shifted_bbox(self, bounding_boxes, w_shift_factor, h_shift_factor):\n+        bboxes = bounding_boxes[\"boxes\"]\n+        x1, x2, x3, x4 = self.backend.numpy.split(bboxes, 4, axis=-1)\n+\n+        w_shift_factor = self.backend.convert_to_tensor(\n+            w_shift_factor, dtype=x1.dtype\n+        )\n+        h_shift_factor = self.backend.convert_to_tensor(\n+            h_shift_factor, dtype=x1.dtype\n+        )\n+\n+        if len(bboxes.shape) == 3:\n+            w_shift_factor = self.backend.numpy.expand_dims(w_shift_factor, -1)\n+            h_shift_factor = self.backend.numpy.expand_dims(h_shift_factor, -1)\n+\n+        bounding_boxes[\"boxes\"] = self.backend.numpy.concatenate(\n+            [\n+                x1 - w_shift_factor,\n+                x2 - h_shift_factor,\n+                x3 - w_shift_factor,\n+                x4 - h_shift_factor,\n+            ],\n+            axis=-1,\n+        )\n+        return bounding_boxes\n+\n     def transform_bounding_boxes(\n         self,\n         bounding_boxes,\n         transformation,\n         training=True,\n     ):\n-        raise NotImplementedError\n+        def _get_height_width(transformation):\n+            if self.data_format == \"channels_first\":\n+                height_axis = -2\n+                width_axis = -1\n+            else:\n+                height_axis = -3\n+                width_axis = -2\n+            input_height, input_width = (\n+                transformation[\"input_shape\"][height_axis],\n+                transformation[\"input_shape\"][width_axis],\n+            )\n+            return input_height, input_width\n+\n+        if training:\n+            if backend_utils.in_tf_graph():\n+                self.backend.set_backend(\"tensorflow\")\n+\n+            input_height, input_width = _get_height_width(transformation)\n+\n+            bounding_boxes = convert_format(\n+                bounding_boxes,\n+                source=self.bounding_box_format,\n+                target=\"rel_xyxy\",\n+                height=input_height,\n+                width=input_width,\n+                dtype=self.compute_dtype,\n+            )\n+\n+            bounding_boxes = self._shear_bboxes(bounding_boxes, transformation)\n+\n+            bounding_boxes = clip_to_image_size(\n+                bounding_boxes=bounding_boxes,\n+                height=input_height,\n+                width=input_width,\n+                bounding_box_format=\"rel_xyxy\",\n+            )\n+\n+            bounding_boxes = convert_format(\n+                bounding_boxes,\n+                source=\"rel_xyxy\",\n+                target=self.bounding_box_format,\n+                height=input_height,\n+                width=input_width,\n+                dtype=self.compute_dtype,\n+            )\n+\n+            self.backend.reset()\n+\n+        return bounding_boxes\n+\n+    def _shear_bboxes(self, bounding_boxes, transformation):\n+        shear_factor = self.backend.cast(\n+            transformation[\"shear_factor\"], dtype=self.compute_dtype\n+        )\n+        shear_x_amount, shear_y_amount = self.backend.numpy.split(\n+            shear_factor, 2, axis=-1\n+        )\n+\n+        x1, y1, x2, y2 = self.backend.numpy.split(\n+            bounding_boxes[\"boxes\"], 4, axis=-1\n+        )\n+        x1 = self.backend.numpy.squeeze(x1, axis=-1)\n+        y1 = self.backend.numpy.squeeze(y1, axis=-1)\n+        x2 = self.backend.numpy.squeeze(x2, axis=-1)\n+        y2 = self.backend.numpy.squeeze(y2, axis=-1)\n+\n+        if shear_x_amount is not None:\n+            x1_top = x1 - (shear_x_amount * y1)\n+            x1_bottom = x1 - (shear_x_amount * y2)\n+            x1 = self.backend.numpy.where(shear_x_amount < 0, x1_top, x1_bottom)\n+\n+            x2_top = x2 - (shear_x_amount * y1)\n+            x2_bottom = x2 - (shear_x_amount * y2)\n+            x2 = self.backend.numpy.where(shear_x_amount < 0, x2_bottom, x2_top)\n+\n+        if shear_y_amount is not None:\n+            y1_left = y1 - (shear_y_amount * x1)\n+            y1_right = y1 - (shear_y_amount * x2)\n+            y1 = self.backend.numpy.where(shear_y_amount > 0, y1_right, y1_left)\n+\n+            y2_left = y2 - (shear_y_amount * x1)\n+            y2_right = y2 - (shear_y_amount * x2)\n+            y2 = self.backend.numpy.where(shear_y_amount > 0, y2_left, y2_right)\n+\n+        boxes = self.backend.numpy.concatenate(\n+            [\n+                self.backend.numpy.expand_dims(x1, axis=-1),\n+                self.backend.numpy.expand_dims(y1, axis=-1),\n+                self.backend.numpy.expand_dims(x2, axis=-1),\n+                self.backend.numpy.expand_dims(y2, axis=-1),\n+            ],\n+            axis=-1,\n+        )\n+        bounding_boxes[\"boxes\"] = boxes\n+\n+        return bounding_boxes\n \n     def transform_segmentation_masks(\n         self, segmentation_masks, transformation, training=True\n\n@@ -1,11 +1,13 @@\n import numpy as np\n import pytest\n+from absl.testing import parameterized\n from tensorflow import data as tf_data\n \n import keras\n from keras.src import backend\n from keras.src import layers\n from keras.src import testing\n+from keras.src.utils import backend_utils\n \n \n class RandomShearTest(testing.TestCase):\n@@ -74,3 +76,127 @@ class RandomShearTest(testing.TestCase):\n         ds = tf_data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n         for output in ds.take(1):\n             output.numpy()\n+\n+    @parameterized.named_parameters(\n+        (\n+            \"with_x_shift\",\n+            [[1.0, 0.0]],\n+            [[[0.0, 1.0, 3.2, 3.0], [1.2, 4.0, 4.8, 6.0]]],\n+        ),\n+        (\n+            \"with_y_shift\",\n+            [[0.0, 1.0]],\n+            [[[2.0, 0.0, 4.0, 0.5], [6.0, 0.0, 8.0, 0.0]]],\n+        ),\n+        (\n+            \"with_xy_shift\",\n+            [[1.0, 1.0]],\n+            [[[0.0, 0.0, 3.2, 3.5], [1.2, 0.0, 4.8, 4.5]]],\n+        ),\n+    )\n+    def test_random_shear_bounding_boxes(self, translation, expected_boxes):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            image_shape = (10, 8, 3)\n+        else:\n+            image_shape = (3, 10, 8)\n+        input_image = np.random.random(image_shape)\n+        bounding_boxes = {\n+            \"boxes\": np.array(\n+                [\n+                    [2, 1, 4, 3],\n+                    [6, 4, 8, 6],\n+                ]\n+            ),\n+            \"labels\": np.array([[1, 2]]),\n+        }\n+        input_data = {\"images\": input_image, \"bounding_boxes\": bounding_boxes}\n+        layer = layers.RandomShear(\n+            x_factor=0.5,\n+            y_factor=0.5,\n+            data_format=data_format,\n+            seed=42,\n+            bounding_box_format=\"xyxy\",\n+        )\n+\n+        transformation = {\n+            \"shear_factor\": backend_utils.convert_tf_tensor(\n+                np.array(translation)\n+            ),\n+            \"input_shape\": image_shape,\n+        }\n+        output = layer.transform_bounding_boxes(\n+            input_data[\"bounding_boxes\"],\n+            transformation=transformation,\n+            training=True,\n+        )\n+\n+        self.assertAllClose(output[\"boxes\"], expected_boxes)\n+\n+    @parameterized.named_parameters(\n+        (\n+            \"with_x_shift\",\n+            [[1.0, 0.0]],\n+            [[[0.0, 1.0, 3.2, 3.0], [1.2, 4.0, 4.8, 6.0]]],\n+        ),\n+        (\n+            \"with_y_shift\",\n+            [[0.0, 1.0]],\n+            [[[2.0, 0.0, 4.0, 0.5], [6.0, 0.0, 8.0, 0.0]]],\n+        ),\n+        (\n+            \"with_xy_shift\",\n+            [[1.0, 1.0]],\n+            [[[0.0, 0.0, 3.2, 3.5], [1.2, 0.0, 4.8, 4.5]]],\n+        ),\n+    )\n+    def test_random_shear_tf_data_bounding_boxes(\n+        self, translation, expected_boxes\n+    ):\n+        data_format = backend.config.image_data_format()\n+        if backend.config.image_data_format() == \"channels_last\":\n+            image_shape = (1, 10, 8, 3)\n+        else:\n+            image_shape = (1, 3, 10, 8)\n+        input_image = np.random.random(image_shape)\n+        bounding_boxes = {\n+            \"boxes\": np.array(\n+                [\n+                    [\n+                        [2, 1, 4, 3],\n+                        [6, 4, 8, 6],\n+                    ]\n+                ]\n+            ),\n+            \"labels\": np.array([[1, 2]]),\n+        }\n+\n+        input_data = {\"images\": input_image, \"bounding_boxes\": bounding_boxes}\n+\n+        ds = tf_data.Dataset.from_tensor_slices(input_data)\n+        layer = layers.RandomShear(\n+            x_factor=0.5,\n+            y_factor=0.5,\n+            data_format=data_format,\n+            seed=42,\n+            bounding_box_format=\"xyxy\",\n+        )\n+\n+        transformation = {\n+            \"shear_factor\": backend_utils.convert_tf_tensor(\n+                np.array(translation)\n+            ),\n+            \"input_shape\": image_shape,\n+        }\n+\n+        ds = ds.map(\n+            lambda x: layer.transform_bounding_boxes(\n+                x[\"bounding_boxes\"],\n+                transformation=transformation,\n+                training=True,\n+            )\n+        )\n+\n+        output = next(iter(ds))\n+        expected_boxes = np.array(expected_boxes)\n+        self.assertAllClose(output[\"boxes\"], expected_boxes)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
