{"custom_id": "keras#d71a7fe2fb7db9181b9cc5631cf61f34eb1d6af3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 89 | Lines Deleted: 0 | Files Changed: 10 | Hunks: 12 | Methods Changed: 9 | Complexity Δ (Sum/Max): 13/4 | Churn Δ: 89 | Churn Cumulative: 7771 | Contributors (this commit): 28 | Commits (past 90d): 48 | Contributors (cumulative): 118 | DMM Complexity: 1.0\n\nDIFF:\n@@ -135,6 +135,7 @@ from keras.src.ops.numpy import argpartition as argpartition\n from keras.src.ops.numpy import argsort as argsort\n from keras.src.ops.numpy import array as array\n from keras.src.ops.numpy import average as average\n+from keras.src.ops.numpy import bartlett as bartlett\n from keras.src.ops.numpy import bincount as bincount\n from keras.src.ops.numpy import bitwise_and as bitwise_and\n from keras.src.ops.numpy import bitwise_invert as bitwise_invert\n\n@@ -27,6 +27,7 @@ from keras.src.ops.numpy import argpartition as argpartition\n from keras.src.ops.numpy import argsort as argsort\n from keras.src.ops.numpy import array as array\n from keras.src.ops.numpy import average as average\n+from keras.src.ops.numpy import bartlett as bartlett\n from keras.src.ops.numpy import bincount as bincount\n from keras.src.ops.numpy import bitwise_and as bitwise_and\n from keras.src.ops.numpy import bitwise_invert as bitwise_invert\n\n@@ -135,6 +135,7 @@ from keras.src.ops.numpy import argpartition as argpartition\n from keras.src.ops.numpy import argsort as argsort\n from keras.src.ops.numpy import array as array\n from keras.src.ops.numpy import average as average\n+from keras.src.ops.numpy import bartlett as bartlett\n from keras.src.ops.numpy import bincount as bincount\n from keras.src.ops.numpy import bitwise_and as bitwise_and\n from keras.src.ops.numpy import bitwise_invert as bitwise_invert\n\n@@ -27,6 +27,7 @@ from keras.src.ops.numpy import argpartition as argpartition\n from keras.src.ops.numpy import argsort as argsort\n from keras.src.ops.numpy import array as array\n from keras.src.ops.numpy import average as average\n+from keras.src.ops.numpy import bartlett as bartlett\n from keras.src.ops.numpy import bincount as bincount\n from keras.src.ops.numpy import bitwise_and as bitwise_and\n from keras.src.ops.numpy import bitwise_invert as bitwise_invert\n\n@@ -37,6 +37,11 @@ def add(x1, x2):\n     return jnp.add(x1, x2)\n \n \n+def bartlett(x):\n+    x = convert_to_tensor(x)\n+    return jnp.bartlett(x)\n+\n+\n def bincount(x, weights=None, minlength=0, sparse=False):\n     # Note: bincount is never tracable / jittable because the output shape\n     # depends on the values in x.\n\n@@ -305,6 +305,11 @@ def average(x, axis=None, weights=None):\n     return np.average(x, weights=weights, axis=axis)\n \n \n+def bartlett(x):\n+    x = convert_to_tensor(x)\n+    return np.bartlett(x).astype(config.floatx())\n+\n+\n def bincount(x, weights=None, minlength=0, sparse=False):\n     if sparse:\n         raise ValueError(\"Unsupported value `sparse=True` with numpy backend\")\n\n@@ -131,6 +131,21 @@ def add(x1, x2):\n     return tf.add(x1, x2)\n \n \n+def bartlett(x):\n+    x = convert_to_tensor(x, dtype=config.floatx())\n+    if x == 0:\n+        return tf.constant([])\n+    if x == 1:\n+        return tf.ones([1])\n+\n+    n = tf.range(x)\n+    half = (x - 1) / 2\n+\n+    window = tf.where(n <= half, 2.0 * n / (x - 1), 2.0 - 2.0 * n / (x - 1))\n+\n+    return window\n+\n+\n def bincount(x, weights=None, minlength=0, sparse=False):\n     x = convert_to_tensor(x)\n     dtypes_to_resolve = [x.dtype]\n\n@@ -430,6 +430,11 @@ def average(x, axis=None, weights=None):\n     return torch.mean(x, axis)\n \n \n+def bartlett(x):\n+    x = convert_to_tensor(x)\n+    return torch.signal.windows.bartlett(x)\n+\n+\n def bincount(x, weights=None, minlength=0, sparse=False):\n     if sparse:\n         raise ValueError(\"Unsupported value `sparse=True` with torch backend\")\n\n@@ -1210,6 +1210,35 @@ def average(x, axis=None, weights=None):\n     return backend.numpy.average(x, weights=weights, axis=axis)\n \n \n+class Bartlett(Operation):\n+    def call(self, x):\n+        return backend.numpy.bartlett(x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=backend.floatx())\n+\n+\n+@keras_export([\"keras.ops.bartlett\", \"keras.ops.numpy.bartlett\"])\n+def bartlett(x):\n+    \"\"\"Bartlett window function.\n+    The Bartlett window is a triangular window that rises then falls linearly.\n+\n+    Args:\n+        x: Scalar or 1D Tensor. Window length.\n+\n+    Returns:\n+        A 1D tensor containing the Bartlett window values.\n+\n+    Example:\n+    >>> x = keras.ops.convert_to_tensor(5)\n+    >>> keras.ops.bartlett(x)\n+    array([0. , 0.5, 1. , 0.5, 0. ], dtype=float32)\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return Bartlett().symbolic_call(x)\n+    return backend.numpy.bartlett(x)\n+\n+\n class Bincount(Operation):\n     def __init__(self, weights=None, minlength=0, sparse=False):\n         super().__init__()\n\n@@ -1220,6 +1220,10 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n             weights = KerasTensor((None, 4))\n             knp.average(x, weights=weights)\n \n+    def test_bartlett(self):\n+        x = np.random.randint(1, 100 + 1)\n+        self.assertEqual(knp.bartlett(x).shape[0], x)\n+\n     def test_bitwise_invert(self):\n         x = KerasTensor((None, 3))\n         self.assertEqual(knp.bitwise_invert(x).shape, (None, 3))\n@@ -3590,6 +3594,12 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n             np.average(x, axis=1, weights=weights_1d),\n         )\n \n+    def test_bartlett(self):\n+        x = np.random.randint(1, 100 + 1)\n+        self.assertAllClose(knp.bartlett(x), np.bartlett(x))\n+\n+        self.assertAllClose(knp.Bartlett()(x), np.bartlett(x))\n+\n     @parameterized.named_parameters(\n         named_product(sparse_input=(False, True), sparse_arg=(False, True))\n     )\n@@ -5553,6 +5563,22 @@ class NumpyDtypeTest(testing.TestCase):\n                 knp.Add().symbolic_call(x, 1.0).dtype, expected_dtype\n             )\n \n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n+    def test_bartlett(self, dtype):\n+        import jax.numpy as jnp\n+\n+        x = knp.ones((), dtype=dtype)\n+        x_jax = jnp.ones((), dtype=dtype)\n+        expected_dtype = standardize_dtype(jnp.bartlett(x_jax).dtype)\n+\n+        self.assertEqual(\n+            standardize_dtype(knp.bartlett(x).dtype), expected_dtype\n+        )\n+        self.assertEqual(\n+            standardize_dtype(knp.Bartlett().symbolic_call(x).dtype),\n+            expected_dtype,\n+        )\n+\n     @parameterized.named_parameters(named_product(dtype=INT_DTYPES))\n     def test_bincount(self, dtype):\n         import jax.numpy as jnp\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b2fe0a7a881ce9d308c25cf27ff37a80d21a34be", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 8 | Files Changed: 3 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 35 | Churn Cumulative: 49 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -164,12 +164,16 @@ def rnn(\n                 else:\n                     # Assume the first state is the previous output.\n                     output_tm1 = states[0]\n+                    if tree.is_nested(output_tm1):\n+                        # Stacked RNN case: assume first state of last cell.\n+                        output_tm1 = states[-1][0]\n                     masked_outs = jnp.where(is_masked, output_tm1, output_t)\n \n-                new_states = [\n-                    jnp.where(is_masked, s, ns)\n-                    for s, ns in zip(states, new_states)\n-                ]\n+                new_states = tree.map_structure(\n+                    lambda s, ns: jnp.where(is_masked, s, ns),\n+                    states,\n+                    new_states,\n+                )\n                 return (new_states, masked_outs)\n \n             scan_xs = (inputs, mask)\n\n@@ -160,12 +160,16 @@ def rnn(\n                 else:\n                     # Assume the first state is the previous output.\n                     output_tm1 = states[0]\n+                    if tree.is_nested(output_tm1):\n+                        # Stacked RNN case: assume first state of last cell.\n+                        output_tm1 = states[-1][0]\n                     masked_outs = np.where(is_masked, output_tm1, output_t)\n \n-                new_states = [\n-                    np.where(is_masked, s, ns)\n-                    for s, ns in zip(states, new_states)\n-                ]\n+                new_states = tree.map_structure(\n+                    lambda s, ns: np.where(is_masked, s, ns),\n+                    states,\n+                    new_states,\n+                )\n                 return (new_states, masked_outs)\n \n             scan_xs = (inputs, mask)\n\n@@ -275,3 +275,14 @@ class StackedRNNTest(testing.TestCase):\n         self.assertEqual(shape[1][1], (2, 10))\n         self.assertEqual(shape[2][0], (2, 10))\n         self.assertEqual(shape[2][1], (2, 10))\n+\n+    def test_stacked_lstm_cell_mask(self):\n+        sequence = np.ones((2, 3, 4))\n+        mask = np.array([[True, True, True], [True, True, False]])\n+        cell_kwargs = dict(\n+            units=1, kernel_initializer=\"ones\", recurrent_initializer=\"ones\"\n+        )\n+        rnn_cells = [layers.LSTMCell(**cell_kwargs) for _ in range(2)]\n+        stacked_rnn = layers.RNN(rnn_cells)\n+        output = stacked_rnn(sequence, mask=mask)\n+        self.assertAllClose(np.array([[0.7793], [0.5998]]), output, atol=1e-4)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#48a669218ca1d5a2848d7ac25e318e79eef82a44", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 1709 | Contributors (this commit): 19 | Commits (past 90d): 26 | Contributors (cumulative): 19 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1206,7 +1206,11 @@ def quantile(x, q, axis=None, method=\"linear\", keepdims=False):\n \n \n def ravel(x):\n-    raise NotImplementedError(\"`ravel` is not supported with openvino backend\")\n+    x = get_ov_output(x)\n+    target_shape = ov_opset.constant([-1], dtype=Type.i32).output(0)\n+    return OpenVINOKerasTensor(\n+        ov_opset.reshape(x, target_shape, special_zero=False).output(0)\n+    )\n \n \n def real(x):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4c6b7e32f279e5df4514a726d523e698014817d8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 9 | Files Changed: 8 | Hunks: 9 | Methods Changed: 9 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 19 | Churn Cumulative: 3716 | Contributors (this commit): 27 | Commits (past 90d): 24 | Contributors (cumulative): 68 | DMM Complexity: 1.0\n\nDIFF:\n@@ -353,7 +353,7 @@ def depthwise_conv(\n     if num_spatial_dims > 2:\n         raise ValueError(\n             \"`inputs` rank must be 3 (1D conv) or 4 (2D conv). Received: \"\n-            \"{inputs.ndim}.\"\n+            f\"{inputs.ndim}.\"\n         )\n     # Because we use `tf.nn.depthwise_conv2d` for both 1D and 2D convs, we set\n     # `tf_data_format` using 2D conv format.\n\n@@ -1999,7 +1999,7 @@ def unravel_index(x, shape):\n \n     if None in shape:\n         raise ValueError(\n-            \"`shape` argument cannot contain `None`. Received: shape={shape}\"\n+            f\"`shape` argument cannot contain `None`. Received: shape={shape}\"\n         )\n \n     if x.ndim == 1:\n\n@@ -464,7 +464,8 @@ class GroupedQueryAttention(Layer):\n             raise ValueError(\n                 \"The last dimension of `query_shape` and `value_shape` \"\n                 f\"must be equal, but are {query_shape[-1]}, {value_shape[-1]}. \"\n-                \"Received: query_shape={query_shape}, value_shape={value_shape}\"\n+                f\"Received: query_shape={query_shape}, \"\n+                f\"value_shape={value_shape}\"\n             )\n \n         if value_shape[1:-1] != key_shape[1:-1]:\n\n@@ -170,7 +170,7 @@ class Lambda(Layer):\n     def _raise_for_lambda_deserialization(arg_name, safe_mode):\n         if safe_mode:\n             raise ValueError(\n-                \"The `{arg_name}` of this `Lambda` layer is a Python lambda. \"\n+                f\"The `{arg_name}` of this `Lambda` layer is a Python lambda. \"\n                 \"Deserializing it is unsafe. If you trust the source of the \"\n                 \"config artifact, you can override this error \"\n                 \"by passing `safe_mode=False` \"\n\n@@ -157,7 +157,7 @@ class CategoryEncoding(TFDataLayer):\n             if self.output_mode != \"count\":\n                 raise ValueError(\n                     \"`count_weights` is not used when `output_mode` is not \"\n-                    \"`'count'`. Received `count_weights={count_weights}`.\"\n+                    f\"`'count'`. Received `count_weights={count_weights}`.\"\n                 )\n             count_weights = self.backend.convert_to_tensor(\n                 count_weights, dtype=self.compute_dtype\n\n@@ -665,7 +665,7 @@ def _assert_1d(*arrays):\n     for a in arrays:\n         if a.ndim < 1:\n             raise ValueError(\n-                \"Expected input to have rank >= 1. Received scalar input {a}.\"\n+                f\"Expected input to have rank >= 1. Received scalar input {a}.\"\n             )\n \n \n@@ -674,7 +674,7 @@ def _assert_2d(*arrays):\n         if a.ndim < 2:\n             raise ValueError(\n                 \"Expected input to have rank >= 2. \"\n-                \"Received input with shape {a.shape}.\"\n+                f\"Received input with shape {a.shape}.\"\n             )\n \n \n\n@@ -2283,7 +2283,7 @@ class Diagonal(Operation):\n         if len(x_shape) < 2:\n             raise ValueError(\n                 \"`diagonal` requires an array of at least two dimensions, but \"\n-                \"`x` is of shape {x.shape}.\"\n+                f\"`x` is of shape {x.shape}.\"\n             )\n \n         shape_2d = [x_shape[self.axis1], x_shape[self.axis2]]\n\n@@ -406,7 +406,7 @@ def _rescale_dataset_split_sizes(left_size, right_size, total_length):\n     if left_size + right_size > total_length:\n         raise ValueError(\n             \"The sum of `left_size` and `right_size` should \"\n-            \"be smaller than the {total_length}. \"\n+            f\"be smaller than the {total_length}. \"\n             f\"Received: left_size + right_size = {left_size + right_size}\"\n             f\"and total_length = {total_length}\"\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ce955890b1f2b3cdd6c8f7cd0187f96d77db0730", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 18 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 52 | Churn Cumulative: 1328 | Contributors (this commit): 16 | Commits (past 90d): 10 | Contributors (cumulative): 16 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2260,9 +2260,7 @@ def take(x, indices, axis=None):\n \n \n def take_along_axis(x, indices, axis=None):\n-    from keras.src.ops.operation_utils import (\n-        compute_take_along_axis_output_shape,\n-    )\n+    from keras.src.ops import operation_utils\n \n     x = convert_to_tensor(x)\n     indices = convert_to_tensor(indices, \"int64\")\n@@ -2276,28 +2274,46 @@ def take_along_axis(x, indices, axis=None):\n \n     # Compute the static output shape as later on, all shapes manipulations\n     # use dynamic shapes.\n-    static_output_shape = compute_take_along_axis_output_shape(\n+    static_output_shape = operation_utils.compute_take_along_axis_output_shape(\n         x.shape, indices.shape, axis\n     )\n     rank = x.ndim\n     static_axis = axis\n     axis = axis + rank if axis < 0 else axis\n \n-    # Broadcast shapes to match, ensure that the axis of interest is not\n-    # broadcast.\n-    x_shape_original = tf.shape(x, out_type=indices.dtype)\n-    indices_shape_original = tf.shape(indices, out_type=indices.dtype)\n-    x_shape = tf.tensor_scatter_nd_update(x_shape_original, [[axis]], [1])\n-    indices_shape = tf.tensor_scatter_nd_update(\n-        indices_shape_original, [[axis]], [1]\n-    )\n-    broadcasted_shape = tf.broadcast_dynamic_shape(x_shape, indices_shape)\n-    x_shape = tf.tensor_scatter_nd_update(\n-        broadcasted_shape, [[axis]], [x_shape_original[axis]]\n-    )\n-    indices_shape = tf.tensor_scatter_nd_update(\n-        broadcasted_shape, [[axis]], [indices_shape_original[axis]]\n+    if axis >= rank:\n+        raise ValueError(f\"Invalid axis: {static_axis} for input rank: {rank}\")\n+\n+    x_original_shape = shape_op(x)\n+    indices_original_shape = shape_op(indices)\n+\n+    # Broadcast the static shapes first, but not for the `axis` dimension.\n+    x_static_shape = list(x.shape)\n+    indices_static_shape = list(indices.shape)\n+    x_static_shape[axis] = 1\n+    indices_static_shape[axis] = 1\n+    broadcast_shape = operation_utils.broadcast_shapes(\n+        x_static_shape, indices_static_shape\n     )\n+\n+    if None in broadcast_shape:\n+        # Dynamic broadcast case. Note that `tf.broadcast_dynamic_shape` is\n+        # not always XLA compilable with dynamic dimensions.\n+        # We replace `None`s with the dynamic dimensions.\n+        # `maximum` is the correct formula only when shapes are broadcastable,\n+        # we rely on the broacast itself to fail in the incorrect case rather\n+        # than make some expensive dynamic checks here.\n+        broadcast_shape = [\n+            tf.maximum(x_original_shape[i], indices_original_shape[i])\n+            if dim is None\n+            else dim\n+            for i, dim in enumerate(broadcast_shape)\n+        ]\n+\n+    x_shape = list(broadcast_shape)\n+    x_shape[axis] = x_original_shape[axis]\n+    indices_shape = list(broadcast_shape)\n+    indices_shape[axis] = indices_original_shape[axis]\n     x = tf.broadcast_to(x, x_shape)\n     indices = tf.broadcast_to(indices, indices_shape)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f5171b36b388d9e78f231ca5bdcf83377cd99f1d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 93 | Lines Deleted: 0 | Files Changed: 11 | Hunks: 13 | Methods Changed: 10 | Complexity Δ (Sum/Max): 12/4 | Churn Δ: 93 | Churn Cumulative: 9629 | Contributors (this commit): 45 | Commits (past 90d): 88 | Contributors (cumulative): 140 | DMM Complexity: 1.0\n\nDIFF:\n@@ -144,6 +144,7 @@ from keras.src.ops.numpy import bitwise_not as bitwise_not\n from keras.src.ops.numpy import bitwise_or as bitwise_or\n from keras.src.ops.numpy import bitwise_right_shift as bitwise_right_shift\n from keras.src.ops.numpy import bitwise_xor as bitwise_xor\n+from keras.src.ops.numpy import blackman as blackman\n from keras.src.ops.numpy import broadcast_to as broadcast_to\n from keras.src.ops.numpy import ceil as ceil\n from keras.src.ops.numpy import clip as clip\n\n@@ -36,6 +36,7 @@ from keras.src.ops.numpy import bitwise_not as bitwise_not\n from keras.src.ops.numpy import bitwise_or as bitwise_or\n from keras.src.ops.numpy import bitwise_right_shift as bitwise_right_shift\n from keras.src.ops.numpy import bitwise_xor as bitwise_xor\n+from keras.src.ops.numpy import blackman as blackman\n from keras.src.ops.numpy import broadcast_to as broadcast_to\n from keras.src.ops.numpy import ceil as ceil\n from keras.src.ops.numpy import clip as clip\n\n@@ -144,6 +144,7 @@ from keras.src.ops.numpy import bitwise_not as bitwise_not\n from keras.src.ops.numpy import bitwise_or as bitwise_or\n from keras.src.ops.numpy import bitwise_right_shift as bitwise_right_shift\n from keras.src.ops.numpy import bitwise_xor as bitwise_xor\n+from keras.src.ops.numpy import blackman as blackman\n from keras.src.ops.numpy import broadcast_to as broadcast_to\n from keras.src.ops.numpy import ceil as ceil\n from keras.src.ops.numpy import clip as clip\n\n@@ -36,6 +36,7 @@ from keras.src.ops.numpy import bitwise_not as bitwise_not\n from keras.src.ops.numpy import bitwise_or as bitwise_or\n from keras.src.ops.numpy import bitwise_right_shift as bitwise_right_shift\n from keras.src.ops.numpy import bitwise_xor as bitwise_xor\n+from keras.src.ops.numpy import blackman as blackman\n from keras.src.ops.numpy import broadcast_to as broadcast_to\n from keras.src.ops.numpy import ceil as ceil\n from keras.src.ops.numpy import clip as clip\n\n@@ -474,6 +474,11 @@ def right_shift(x, y):\n     return bitwise_right_shift(x, y)\n \n \n+def blackman(x):\n+    x = convert_to_tensor(x)\n+    return jnp.blackman(x)\n+\n+\n def broadcast_to(x, shape):\n     x = convert_to_tensor(x)\n     return jnp.broadcast_to(x, shape)\n\n@@ -390,6 +390,11 @@ def right_shift(x, y):\n     return bitwise_right_shift(x, y)\n \n \n+def blackman(x):\n+    x = convert_to_tensor(x)\n+    return np.blackman(x).astype(config.floatx())\n+\n+\n def broadcast_to(x, shape):\n     return np.broadcast_to(x, shape)\n \n\n@@ -509,6 +509,12 @@ def bincount(x, weights=None, minlength=0, sparse=False):\n         return OpenVINOKerasTensor(final_output)\n \n \n+def blackman(x):\n+    raise NotImplementedError(\n+        \"`blackman` is not supported with openvino backend\"\n+    )\n+\n+\n def broadcast_to(x, shape):\n     assert isinstance(shape, (tuple, list)), (\n         \"`broadcast_to` is supported only for tuple and list `shape`\"\n\n@@ -1058,6 +1058,18 @@ def right_shift(x, y):\n     return bitwise_right_shift(x, y)\n \n \n+def blackman(x):\n+    dtype = config.floatx()\n+    x = tf.cast(x, dtype)\n+    n = tf.range(x, dtype=dtype)\n+    n_minus_1 = tf.cast(x - 1, dtype)\n+    term1 = 0.42\n+    term2 = -0.5 * tf.cos(2 * np.pi * n / n_minus_1)\n+    term3 = 0.08 * tf.cos(4 * np.pi * n / n_minus_1)\n+    window = term1 + term2 + term3\n+    return window\n+\n+\n def broadcast_to(x, shape):\n     return tf.broadcast_to(x, shape)\n \n\n@@ -515,6 +515,11 @@ def right_shift(x, y):\n     return bitwise_right_shift(x, y)\n \n \n+def blackman(x):\n+    x = convert_to_tensor(x)\n+    return torch.signal.windows.blackman(x)\n+\n+\n def broadcast_to(x, shape):\n     x = convert_to_tensor(x)\n     return torch.broadcast_to(x, shape)\n\n@@ -1617,6 +1617,36 @@ def right_shift(x, y):\n     return backend.numpy.right_shift(x, y)\n \n \n+class Blackman(Operation):\n+    def call(self, x):\n+        return backend.numpy.blackman(x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=backend.floatx())\n+\n+\n+@keras_export([\"keras.ops.blackman\", \"keras.ops.numpy.blackman\"])\n+def blackman(x):\n+    \"\"\"Blackman window function.\n+    The Blackman window is a taper formed by using a weighted cosine.\n+\n+    Args:\n+        x: Scalar or 1D Tensor. Window length.\n+\n+    Returns:\n+        A 1D tensor containing the Blackman window values.\n+\n+    Example:\n+    >>> x = keras.ops.convert_to_tensor(5)\n+    >>> keras.ops.blackman(x)\n+    array([-1.3877788e-17,  3.4000000e-01,  1.0000000e+00,  3.4000000e-01,\n+           -1.3877788e-17], dtype=float32)\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return Blackman().symbolic_call(x)\n+    return backend.numpy.blackman(x)\n+\n+\n class BroadcastTo(Operation):\n     def __init__(self, shape):\n         super().__init__()\n\n@@ -1224,6 +1224,10 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n         x = np.random.randint(1, 100 + 1)\n         self.assertEqual(knp.bartlett(x).shape[0], x)\n \n+    def test_blackman(self):\n+        x = np.random.randint(1, 100 + 1)\n+        self.assertEqual(knp.blackman(x).shape[0], x)\n+\n     def test_bitwise_invert(self):\n         x = KerasTensor((None, 3))\n         self.assertEqual(knp.bitwise_invert(x).shape, (None, 3))\n@@ -3600,6 +3604,12 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n \n         self.assertAllClose(knp.Bartlett()(x), np.bartlett(x))\n \n+    def test_blackman(self):\n+        x = np.random.randint(1, 100 + 1)\n+        self.assertAllClose(knp.blackman(x), np.blackman(x))\n+\n+        self.assertAllClose(knp.Blackman()(x), np.blackman(x))\n+\n     @parameterized.named_parameters(\n         named_product(sparse_input=(False, True), sparse_arg=(False, True))\n     )\n@@ -5579,6 +5589,22 @@ class NumpyDtypeTest(testing.TestCase):\n             expected_dtype,\n         )\n \n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n+    def test_blackman(self, dtype):\n+        import jax.numpy as jnp\n+\n+        x = knp.ones((), dtype=dtype)\n+        x_jax = jnp.ones((), dtype=dtype)\n+        expected_dtype = standardize_dtype(jnp.blackman(x_jax).dtype)\n+\n+        self.assertEqual(\n+            standardize_dtype(knp.blackman(x).dtype), expected_dtype\n+        )\n+        self.assertEqual(\n+            standardize_dtype(knp.Blackman().symbolic_call(x).dtype),\n+            expected_dtype,\n+        )\n+\n     @parameterized.named_parameters(named_product(dtype=INT_DTYPES))\n     def test_bincount(self, dtype):\n         import jax.numpy as jnp\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#df36b8e8051f7c76019a32e017871490730ed5e9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 10 | Churn Cumulative: 1725 | Contributors (this commit): 20 | Commits (past 90d): 28 | Contributors (cumulative): 20 | DMM Complexity: 1.0\n\nDIFF:\n@@ -142,6 +142,10 @@ def all(x, axis=None, keepdims=False):\n     )\n \n \n+def angle(x):\n+    raise NotImplementedError(\"`angle` is not supported with openvino backend\")\n+\n+\n def any(x, axis=None, keepdims=False):\n     x = get_ov_output(x)\n     if axis is None:\n@@ -464,6 +468,12 @@ def average(x, axis=None, weights=None):\n     return OpenVINOKerasTensor(mean_ops.output(0))\n \n \n+def bartlett(x):\n+    raise NotImplementedError(\n+        \"`bartlett` is not supported with openvino backend\"\n+    )\n+\n+\n def bincount(x, weights=None, minlength=0, sparse=False):\n     if x is None:\n         raise ValueError(\"input x is None\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#459523949ee53a936894ddd3de446545c651f378", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 76 | Lines Deleted: 31 | Files Changed: 8 | Hunks: 18 | Methods Changed: 8 | Complexity Δ (Sum/Max): 8/8 | Churn Δ: 107 | Churn Cumulative: 767 | Contributors (this commit): 9 | Commits (past 90d): 17 | Contributors (cumulative): 30 | DMM Complexity: 0.0\n\nDIFF:\n@@ -75,11 +75,10 @@ class Adadelta(optimizer.Optimizer):\n         if self.built:\n             return\n         super().build(var_list)\n-        self._accumulated_grads = self.add_optimizer_variables(\n-            var_list, \"accumulated_grad\"\n+        self._accumulated_grads, self._accumulated_delta_vars = (\n+            self.add_optimizer_variables(\n+                var_list, [\"accumulated_grad\", \"accumulated_delta_var\"]\n             )\n-        self._accumulated_delta_vars = self.add_optimizer_variables(\n-            var_list, \"accumulated_delta_var\"\n         )\n \n     def update_step(self, grad, variable, learning_rate):\n\n@@ -1,3 +1,4 @@\n+from keras.src import backend\n from keras.src import ops\n from keras.src.api_export import keras_export\n from keras.src.optimizers import optimizer\n@@ -96,11 +97,16 @@ class Adafactor(optimizer.Optimizer):\n         self._c = []\n         self._v = []\n         for var in var_list:\n-            if (\n-                self._overwrite_variable_with_gradient(var)\n-                or len(var.shape) < 2\n-            ):\n-                # Don't factor if variable is of dimension < 2.\n+            if len(var.shape) < 2:\n+                # Don't factor if variable is of dimension < 2, but we still\n+                # need to create dummy variables as placeholder.\n+                self._r.append(\n+                    backend.Variable(0, name=var.name, trainable=False)\n+                )\n+                self._c.append(\n+                    backend.Variable(0, name=var.name, trainable=False)\n+                )\n+            elif self._overwrite_variable_with_gradient(var):\n                 self._r.append(None)\n                 self._c.append(None)\n             else:\n\n@@ -90,8 +90,9 @@ class Adam(optimizer.Optimizer):\n         if self.built:\n             return\n         super().build(var_list)\n-        self._momentums = self.add_optimizer_variables(var_list, \"momentum\")\n-        self._velocities = self.add_optimizer_variables(var_list, \"velocity\")\n+        self._momentums, self._velocities = self.add_optimizer_variables(\n+            var_list, [\"momentum\", \"velocity\"]\n+        )\n \n         if self.amsgrad:\n             self._velocity_hats = self.add_optimizer_variables(\n\n@@ -98,8 +98,9 @@ class Adamax(optimizer.Optimizer):\n         if self.built:\n             return\n         super().build(var_list)\n-        self._m = self.add_optimizer_variables(var_list, \"momentum\")\n-        self._u = self.add_optimizer_variables(var_list, \"norm\")\n+        self._m, self._u = self.add_optimizer_variables(\n+            var_list, [\"momentum\", \"norm\"]\n+        )\n \n     def update_step(self, gradient, variable, learning_rate):\n         \"\"\"Update step given gradient and the associated model variable.\"\"\"\n\n@@ -338,29 +338,64 @@ class BaseOptimizer(KerasSaveable):\n         Args:\n             trainable_variables: `keras.Variable`, the corresponding model\n                 variable to the optimizer variable to be created.\n-            name: The name prefix of the optimizer variable to be created. The\n-                variable name will follow the pattern\n+            name: The name prefix(es) of the optimizer variable(s) to be\n+                created. Can be a single string or list of strings.  If a\n+                list of strings, will create an optimizer variable for each\n+                prefix.  The variable name will follow the pattern\n                 `{variable_name}_{trainable_variable.name}`, e.g.,\n-                `momemtum/dense_1`. Defaults to `None`.\n-            initializer: Initializer object to use to populate the initial\n-                variable value, or string name of a built-in initializer (e.g.\n-                `\"random_normal\"`). If unspecified, defaults to `\"zeros\"`.\n+                `momemtum/dense_1`.\n+            initializer: Initializer object(s) to use to populate the initial\n+                variable value(s), or string name of a built-in initializer\n+                (e.g. `\"random_normal\"`). If unspecified, defaults to\n+                `\"zeros\"`.\n \n         Returns:\n             A list of optimizer variables, in the format of `keras.Variable`s.\n+            If multiple names are provide, returns a tuple of lists.\n         \"\"\"\n-        optimizer_variables = []\n+        name_list = name\n+        initializer_list = initializer\n+        if isinstance(name, str):\n+            # Single name/initializer.\n+            name_list = [name]\n+            initializer_list = [initializer]\n+        else:\n+            # Multiple names/initializers.\n+            # If there is only one initializer, use it for all names.\n+            if isinstance(initializer, str) or isinstance(\n+                initializer, initializers.Initializer\n+            ):\n+                initializer_list = [initializer] * len(name_list)\n+\n+        if len(name_list) != len(initializer_list):\n+            raise ValueError(\n+                f\"The number of provided names must match the number of \"\n+                f\"provided initializers.  Received name='{name}', \"\n+                f\"initializer='{initializer}'\"\n+            )\n+\n+        # Build up lists of optimizer variables.\n+        optimizer_variables = tuple([] for _ in name_list)\n         for variable in trainable_variables:\n+            # Interleaves adding variables for backward-compatibility.\n             if not self._overwrite_variable_with_gradient(variable):\n-                optimizer_variables.append(\n+                for i, (var_name, var_init) in enumerate(\n+                    zip(name_list, initializer_list)\n+                ):\n+                    optimizer_variables[i].append(\n                         self.add_variable_from_reference(\n                             variable,\n-                        name=name,\n-                        initializer=initializer,\n+                            name=var_name,\n+                            initializer=var_init,\n                         )\n                     )\n             else:\n-                optimizer_variables.append(None)\n+                for i in range(len(name_list)):\n+                    optimizer_variables[i].append(None)\n+\n+        # If single input name, return the single list.\n+        if isinstance(name, str):\n+            return optimizer_variables[0]\n \n         return optimizer_variables\n \n\n@@ -162,10 +162,11 @@ class Ftrl(optimizer.Optimizer):\n         accumulator_initializer = initializers.Constant(\n             self.initial_accumulator_value,\n         )\n-        self._accumulators = self.add_optimizer_variables(\n-            var_list, \"accumulator\", initializer=accumulator_initializer\n+        self._accumulators, self._linears = self.add_optimizer_variables(\n+            var_list,\n+            [\"accumulator\", \"linear\"],\n+            initializer=[accumulator_initializer, \"zeros\"],\n         )\n-        self._linears = self.add_optimizer_variables(var_list, \"linear\")\n \n     def update_step(self, gradient, variable, learning_rate):\n         \"\"\"Update step given gradient and the associated model variable.\"\"\"\n\n@@ -82,8 +82,9 @@ class Lamb(optimizer.Optimizer):\n         if self.built:\n             return\n         super().build(var_list)\n-        self._momentums = self.add_optimizer_variables(var_list, \"momentum\")\n-        self._velocities = self.add_optimizer_variables(var_list, \"velocity\")\n+        self._momentums, self._velocities = self.add_optimizer_variables(\n+            var_list, [\"momentum\", \"velocity\"]\n+        )\n \n     def update_step(self, gradient, variable, learning_rate):\n         \"\"\"Update step given gradient and the associated model variable.\"\"\"\n\n@@ -87,8 +87,9 @@ class Nadam(optimizer.Optimizer):\n         else:\n             dtype = backend.floatx()\n         super().build(var_list)\n-        self._momentums = self.add_optimizer_variables(var_list, \"momentum\")\n-        self._velocities = self.add_optimizer_variables(var_list, \"velocity\")\n+        self._momentums, self._velocities = self.add_optimizer_variables(\n+            var_list, [\"momentum\", \"velocity\"]\n+        )\n         self._u_product = backend.Variable(1.0, dtype=dtype)\n \n     def _backend_update_step(self, grads, trainable_variables, learning_rate):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6ddaefb73ceec2f62e6f1bc78acccc5d02b421a5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 170 | Lines Deleted: 0 | Files Changed: 4 | Hunks: 5 | Methods Changed: 11 | Complexity Δ (Sum/Max): 19/12 | Churn Δ: 170 | Churn Cumulative: 2936 | Contributors (this commit): 20 | Commits (past 90d): 18 | Contributors (cumulative): 48 | DMM Complexity: 1.0\n\nDIFF:\n@@ -60,6 +60,8 @@ from keras.src.ops.math import segment_max as segment_max\n from keras.src.ops.math import segment_sum as segment_sum\n from keras.src.ops.math import stft as stft\n from keras.src.ops.math import top_k as top_k\n+from keras.src.ops.math import view_as_complex as view_as_complex\n+from keras.src.ops.math import view_as_real as view_as_real\n from keras.src.ops.nn import average_pool as average_pool\n from keras.src.ops.nn import batch_normalization as batch_normalization\n from keras.src.ops.nn import binary_crossentropy as binary_crossentropy\n\n@@ -60,6 +60,8 @@ from keras.src.ops.math import segment_max as segment_max\n from keras.src.ops.math import segment_sum as segment_sum\n from keras.src.ops.math import stft as stft\n from keras.src.ops.math import top_k as top_k\n+from keras.src.ops.math import view_as_complex as view_as_complex\n+from keras.src.ops.math import view_as_real as view_as_real\n from keras.src.ops.nn import average_pool as average_pool\n from keras.src.ops.nn import batch_normalization as batch_normalization\n from keras.src.ops.nn import binary_crossentropy as binary_crossentropy\n\n@@ -1044,3 +1044,101 @@ def logdet(x):\n     if any_symbolic_tensors((x,)):\n         return Logdet().symbolic_call(x)\n     return backend.math.logdet(x)\n+\n+\n+class ViewAsComplex(Operation):\n+    def call(self, x):\n+        x = backend.convert_to_tensor(x)\n+        if len(x.shape) < 1 or x.shape[-1] != 2:\n+            raise ValueError(\n+                \"Input tensor's last dimension must be 2 (real and imaginary).\"\n+            )\n+        return x[..., 0] + 1j * x[..., 1]\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(shape=x.shape[:-1], dtype=\"complex64\")\n+\n+\n+class ViewAsReal(Operation):\n+    def call(self, x):\n+        x = backend.convert_to_tensor(x)\n+        real_part = backend.numpy.real(x)\n+        imag_part = backend.numpy.imag(x)\n+        return backend.numpy.stack((real_part, imag_part), axis=-1)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(shape=x.shape + (2,), dtype=\"float32\")\n+\n+\n+@keras_export(\"keras.ops.view_as_complex\")\n+def view_as_complex(x):\n+    \"\"\"Converts a real tensor with shape `(..., 2)` to a complex tensor,\n+    where the last dimension represents the real and imaginary components\n+    of a complex tensor.\n+\n+    Args:\n+        x: A real tensor with last dimension of size 2.\n+\n+    Returns:\n+        A complex tensor with shape `x.shape[:-1]`.\n+\n+    Example:\n+\n+    ```\n+    >>> import numpy as np\n+    >>> from keras import ops\n+\n+    >>> real_imag = np.array([[1.0, 2.0], [3.0, 4.0]])\n+    >>> complex_tensor = ops.view_as_complex(real_imag)\n+    >>> complex_tensor\n+    array([1.+2.j, 3.+4.j])\n+    ```\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return ViewAsComplex().symbolic_call(x)\n+\n+    x = backend.convert_to_tensor(x)\n+    if len(x.shape) < 1 or x.shape[-1] != 2:\n+        raise ValueError(\n+            \"Last dimension of input must be size 2 (real and imaginary). \"\n+            f\"Received shape: {x.shape}\"\n+        )\n+    real_part = x[..., 0]\n+    imag_part = x[..., 1]\n+\n+    return backend.cast(real_part, dtype=\"complex64\") + 1j * backend.cast(\n+        imag_part, dtype=\"complex64\"\n+    )\n+\n+\n+@keras_export(\"keras.ops.view_as_real\")\n+def view_as_real(x):\n+    \"\"\"Converts a complex tensor to a real tensor with shape `(..., 2)`,\n+    where the last dimension represents the real and imaginary components.\n+\n+    Args:\n+        x: A complex tensor.\n+\n+    Returns:\n+        A real tensor where the last dimension contains the\n+        real and imaginary parts.\n+\n+    Example:\n+    ```\n+    >>> import numpy as np\n+    >>> from keras import ops\n+\n+    >>> complex_tensor = np.array([1 + 2j, 3 + 4j])\n+    >>> real = ops.view_as_real(complex_tensor)\n+    >>> real\n+    array([[1., 2.],\n+           [3., 4.]])\n+    ```\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return ViewAsReal().symbolic_call(x)\n+\n+    x = backend.convert_to_tensor(x)\n+    real_part = backend.numpy.real(x)\n+    imag_part = backend.numpy.imag(x)\n+    return backend.numpy.stack((real_part, imag_part), axis=-1)\n\n@@ -9,6 +9,7 @@ from absl.testing import parameterized\n from keras.src import backend\n from keras.src import testing\n from keras.src.backend.common import dtypes\n+from keras.src.backend.common import standardize_dtype\n from keras.src.backend.common.keras_tensor import KerasTensor\n from keras.src.ops import math as kmath\n \n@@ -1494,3 +1495,70 @@ class TestMathErrors(testing.TestCase):\n                 fft_length,\n                 window=incorrect_window,\n             )\n+\n+\n+@pytest.mark.skipif(\n+    backend.backend() == \"openvino\",\n+    reason=\"Complex dtype is not supported on OpenVINO backend.\",\n+)\n+class ViewAsComplexRealTest(testing.TestCase):\n+    def test_view_as_complex_basic(self):\n+        real_imag = np.array([[1.0, 2.0], [3.0, 4.0]])\n+        expected = np.array([1.0 + 2.0j, 3.0 + 4.0j], dtype=np.complex64)\n+\n+        result = kmath.view_as_complex(real_imag)\n+\n+        self.assertEqual(result.shape, expected.shape)\n+        self.assertEqual(standardize_dtype(result.dtype), expected.dtype)\n+        self.assertAllClose(result, expected)\n+\n+    def test_view_as_real_basic(self):\n+        complex_tensor = np.array([1 + 2j, 3 + 4j], dtype=np.complex64)\n+        expected = np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32)\n+\n+        result = kmath.view_as_real(complex_tensor)\n+\n+        self.assertEqual(result.shape, expected.shape)\n+        self.assertEqual(standardize_dtype(result.dtype), expected.dtype)\n+        self.assertAllClose(result, expected)\n+\n+    def test_view_as_complex_invalid_shape(self):\n+        bad_input = np.array([1.0, 2.0, 3.0])  # Last dimension not size 2\n+        with self.assertRaisesRegex(\n+            ValueError, \"Last dimension of input must be size 2\"\n+        ):\n+            kmath.view_as_complex(bad_input)\n+\n+    def test_view_as_complex_symbolic_input(self):\n+        x = KerasTensor(shape=(None, 2), dtype=\"float32\")\n+        result = kmath.view_as_complex(x)\n+\n+        self.assertEqual(result.shape, (None,))\n+        self.assertEqual(standardize_dtype(result.dtype), \"complex64\")\n+\n+    def test_view_as_real_symbolic_input(self):\n+        x = KerasTensor(shape=(None,), dtype=\"complex64\")\n+        result = kmath.view_as_real(x)\n+\n+        self.assertEqual(result.shape, (None, 2))\n+        self.assertEqual(standardize_dtype(result.dtype), \"float32\")\n+\n+    def test_view_as_complex_multi_dimensional(self):\n+        x = np.array([[[1.0, 2.0], [3.0, 4.0]]], dtype=np.float32)\n+        expected = np.array([[1 + 2j, 3 + 4j]], dtype=np.complex64)\n+\n+        result = kmath.view_as_complex(x)\n+\n+        self.assertEqual(result.shape, expected.shape)\n+        self.assertEqual(standardize_dtype(result.dtype), expected.dtype)\n+        self.assertAllClose(result, expected)\n+\n+    def test_view_as_real_multi_dimensional(self):\n+        x = np.array([[1 + 2j, 3 + 4j]], dtype=np.complex64)\n+        expected = np.array([[[1.0, 2.0], [3.0, 4.0]]], dtype=np.float32)\n+\n+        result = kmath.view_as_real(x)\n+\n+        self.assertEqual(result.shape, expected.shape)\n+        self.assertEqual(standardize_dtype(result.dtype), expected.dtype)\n+        self.assertAllClose(result, expected)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3318d8f7b1a6a3c696bee65936a565437d8ae92f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 2980 | Contributors (this commit): 21 | Commits (past 90d): 21 | Contributors (cumulative): 32 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2330,7 +2330,11 @@ def take_along_axis(x, indices, axis=None):\n     indices = tf.broadcast_to(indices, indices_shape)\n \n     # Correct the indices using \"fill\" mode which is the same as in jax\n-    indices = tf.where(indices < 0, indices + x_shape[static_axis], indices)\n+    indices = tf.where(\n+        indices < 0,\n+        indices + tf.cast(x_shape[static_axis], dtype=indices.dtype),\n+        indices,\n+    )\n \n     x = swapaxes(x, static_axis, -1)\n     indices = swapaxes(indices, static_axis, -1)\n\n@@ -8411,14 +8411,16 @@ class NumpyDtypeTest(testing.TestCase):\n             expected_dtype,\n         )\n \n-    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n-    def test_take_along_axis(self, dtype):\n+    @parameterized.named_parameters(\n+        named_product(dtype=ALL_DTYPES, indices_dtype=INT_DTYPES)\n+    )\n+    def test_take_along_axis(self, dtype, indices_dtype):\n         import jax.numpy as jnp\n \n         x = knp.ones((1,), dtype=dtype)\n-        indices = knp.zeros((1,), dtype=\"int32\")\n+        indices = knp.zeros((1,), dtype=indices_dtype)\n         x_jax = jnp.ones((1,), dtype=dtype)\n-        indices_jax = jnp.zeros((1,), dtype=\"int32\")\n+        indices_jax = jnp.zeros((1,), dtype=indices_dtype)\n         expected_dtype = standardize_dtype(\n             jnp.take_along_axis(x_jax, indices_jax, 0).dtype\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d8f3f70670537b6e08149be853c43510626444e3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 175 | Lines Deleted: 31 | Files Changed: 1 | Hunks: 13 | Methods Changed: 3 | Complexity Δ (Sum/Max): 27/27 | Churn Δ: 206 | Churn Cumulative: 1143 | Contributors (this commit): 13 | Commits (past 90d): 5 | Contributors (cumulative): 13 | DMM Complexity: 0.027777777777777776\n\nDIFF:\n@@ -1126,16 +1126,17 @@ def wrap_flash_attention(\n     decoder_segment_ids,\n     custom_mask=None,\n     attn_logits_soft_cap=None,\n+    head_shards=1,\n+    q_seq_shards=1,\n ):\n     if decoder_segment_ids is not None:\n         assert query.shape[2] == decoder_segment_ids.q.shape[1], (\n-            \"Sharding along sequence dimension not allowed in tpu kernel \"\n-            \"attention\"\n+            \"Sharding along sequence dimension not allowed\"\n+            \" in TPU kernel attention\"\n         )\n \n     if custom_mask is not None:\n         mask = splash_attention_mask.NumpyMask(array=custom_mask)\n-\n     else:\n         mask = splash_attention_mask.CausalMask(\n             shape=(query.shape[2], query.shape[2])\n@@ -1147,8 +1148,8 @@ def wrap_flash_attention(\n     )\n     splash_kernel = splash_attention_kernel.make_splash_mha(\n         mask=multi_head_mask,\n-        head_shards=1,\n-        q_seq_shards=1,\n+        head_shards=head_shards,\n+        q_seq_shards=q_seq_shards,\n         attn_logits_soft_cap=attn_logits_soft_cap,\n     )\n \n@@ -1168,6 +1169,38 @@ def dot_product_attention(\n     flash_attention=None,\n     attn_logits_soft_cap=None,\n ):\n+    \"\"\"Computes dot-product attention given query, key, and value.\n+\n+    This is the core computation of attention that is used in transformers.\n+    For TPU platforms, flash attention optimizations are automatically applied\n+    when possible, and sharding parameters are inferred from the layout map\n+    in the current distribution context.\n+\n+    Args:\n+        query: Queries with shape `[batch, time, heads,\n+            depth_k]`.\n+        key: Keys with shape `[batch, time, heads,\n+            depth_k]`.\n+        value: Values with shape `[batch, time, heads,\n+            depth_v]`.\n+        bias: Optional bias with shape broadcastable to\n+            `[batch, heads, dest_time, source_time]`.\n+        mask: Optional mask with shape broadcastable to\n+            `[batch, heads, dest_time, source_time]`.\n+        scale: Float. Optional scale that is applied to the attention\n+            computation.\n+        is_causal: Boolean. Specifying whether causal masking is applied.\n+        flash_attention: Boolean. Whether to use flash attention optimization\n+            for increased performance. Default to None, which means it will\n+            be auto-determined based on the platform, input shapes and\n+            compatibility.\n+        attn_logits_soft_cap: Float. Optional float to softly cap attention\n+            logits to avoid numerical stability issues. Applied as:\n+            `logits = logits / (1.0 + abs(logits) / attn_logits_soft_cap)`.\n+\n+    Returns:\n+        JAX Array of shape `[batch, time, heads, depth_v]`.\n+    \"\"\"\n     query = convert_to_tensor(query)\n     key = convert_to_tensor(key)\n     value = convert_to_tensor(value)\n@@ -1177,37 +1210,131 @@ def dot_product_attention(\n             f\"Received: query.shape={query.shape}, key.shape={key.shape}, \"\n             f\"value.shape={value.shape}.\"\n         )\n-    if flash_attention is None:\n-        flash_attention = _can_use_flash_attention(query, key, value, bias)\n-    elif flash_attention is True:\n-        # Use `raise_error=True` to provide more details if the inputs failed to\n-        # use flash attention\n-        _can_use_flash_attention(query, key, value, bias, raise_error=True)\n \n-    if jax.devices()[0].platform == \"tpu\":\n-        # Transpose to ('batch', 'heads', 'length', 'kv')\n-        query = jnp.transpose(query, axes=(0, 2, 1, 3))\n-        key = jnp.transpose(key, axes=(0, 2, 1, 3))\n-        value = jnp.transpose(value, axes=(0, 2, 1, 3))\n-        B, H, S, KV = query.shape\n+    # Check platform\n+    platform = jax.devices()[0].platform\n+    is_tpu = platform == \"tpu\"\n \n-        segment_ids = jnp.ones([B, S])\n-        # {token_ids, padding_mask, segment_ids} enable packing\n-        out = wrap_flash_attention(\n-            query,\n-            key,\n-            value,\n-            decoder_segment_ids=splash_attention_kernel.SegmentIds(\n-                segment_ids, segment_ids\n-            ),\n-            custom_mask=mask,\n-            attn_logits_soft_cap=attn_logits_soft_cap,\n+    # Get sharding parameters from distribution context\n+    head_shards = 1\n+    q_seq_shards = 1\n+\n+    if is_tpu:\n+        try:\n+            from keras.src.distribution.distribution_lib import ModelParallel\n+            from keras.src.distribution.distribution_lib import (\n+                distribution as get_dist,\n             )\n-        out = jnp.transpose(out, axes=(0, 2, 1, 3))\n-        return out\n \n-    # `dot_product_attention` is only available in jax>=0.4.31\n+            # Get current distribution if available\n+            dist = get_dist()\n+            if dist and isinstance(dist, ModelParallel):\n+                mesh = dist.device_mesh\n+                if \"model\" in mesh.axis_names:\n+                    model_dim_index = mesh.axis_names.index(\"model\")\n+                    # Set head_shards based on the model dimension of the mesh\n+                    head_shards = mesh.shape[model_dim_index]\n+                    # Typically keep q_seq_shards=1 for best performance\n+                    q_seq_shards = 1\n+        except (ImportError, ValueError, AttributeError):\n+            # Use default values if detection fails\n+            head_shards = 1\n+            q_seq_shards = 1\n+\n+    # Check if inputs use partial sharding (not fully replicated)\n+    # Flash attention works well with fully replicated tensors on all platforms\n+    # but may have issues with certain partial sharding patterns on non-TPU\n+    # platforms\n+    partially_sharded_inputs = any(\n+        hasattr(t, \"sharding\") and not t.sharding.is_fully_replicated\n+        for t in (query, key, value)\n+    )\n+\n+    # Determine flash attention compatibility\n+    if flash_attention is None:\n+        # Auto-detect flash attention availability\n+        if is_tpu:\n+            # TPUs have specialized hardware for attention that works with any\n+            # sharding pattern\n+            flash_attention = True\n+        else:\n+            # For GPU/CPU with partially sharded inputs, we need\n+            # multiple devices to efficiently handle the sharding\n+            if partially_sharded_inputs and len(jax.devices()) <= 1:\n+                flash_attention = False\n+            else:\n+                flash_attention = _can_use_flash_attention(\n+                    query, key, value, bias\n+                )\n+    elif flash_attention is True and not is_tpu:\n+        # If flash attention is explicitly requested, validate compatibility\n+        # Skip validation for TPU as it has specialized hardware support\n+        try:\n+            _can_use_flash_attention(query, key, value, bias, raise_error=True)\n+        except Exception:\n+            # Only disable flash attention on non-TPU platforms\n+            # if validation fails\n+            flash_attention = False\n+\n+    # TPU-specific flash attention path\n+    if is_tpu and flash_attention:\n+        # Transpose to ('batch', 'heads', 'length', 'head_dim')\n+        query_tpu_layout = jnp.transpose(query, axes=(0, 2, 1, 3))\n+        key_tpu_layout = jnp.transpose(key, axes=(0, 2, 1, 3))\n+        value_tpu_layout = jnp.transpose(value, axes=(0, 2, 1, 3))\n+\n+        bs, num_heads, q_len, head_dim = query_tpu_layout.shape\n+\n+        # Apply scale to query if provided\n+        if scale is not None:\n+            # TPU kernel applies 1/sqrt(head_dim) internally, to achieve\n+            # overall QK^T * scale, scale query by (scale * sqrt(head_dim))\n+            query_tpu_layout = query_tpu_layout * (scale * math.sqrt(head_dim))\n+\n+        # Create segment IDs for Splash Attention (for packing/batching)\n+        segment_ids = jnp.zeros([bs, q_len], dtype=jnp.int32)\n+        decoder_segment_ids = splash_attention_kernel.SegmentIds(\n+            q=segment_ids, kv=segment_ids\n+        )\n+\n+        # Process mask for Splash Attention\n+        custom_mask = None\n+        if mask is not None:\n+            mask_bool = mask.astype(\"bool\") if mask.dtype != jnp.bool_ else mask\n+\n+            if mask_bool.ndim == 3 and mask_bool.shape[0] == bs:\n+                custom_mask = mask_bool[0]\n+            elif mask_bool.ndim == 4 and mask_bool.shape[0] == bs:\n+                custom_mask = mask_bool[0, 0]\n+\n+            if is_causal and custom_mask is not None:\n+                causal_mask = jnp.tril(\n+                    jnp.ones((q_len, q_len), dtype=jnp.bool_)\n+                )\n+                custom_mask = jnp.logical_and(custom_mask, causal_mask)\n+\n+        if custom_mask is None and is_causal:\n+            custom_mask = jnp.tril(jnp.ones((q_len, q_len), dtype=jnp.bool_))\n+\n+        try:\n+            output = wrap_flash_attention(\n+                query_tpu_layout,\n+                key_tpu_layout,\n+                value_tpu_layout,\n+                decoder_segment_ids=decoder_segment_ids,\n+                custom_mask=custom_mask,\n+                attn_logits_soft_cap=attn_logits_soft_cap,\n+                head_shards=head_shards,\n+                q_seq_shards=q_seq_shards,\n+            )\n+            # Transpose output back to Keras layout\n+            return jnp.transpose(output, axes=(0, 2, 1, 3))\n+        except Exception:\n+            flash_attention = False\n+\n+    # JAX native dot_product_attention for GPU or fallback for TPU\n     if hasattr(jax.nn, \"dot_product_attention\"):\n+        try:\n             return jax.nn.dot_product_attention(\n                 query,\n                 key,\n@@ -1218,6 +1345,20 @@ def dot_product_attention(\n                 is_causal=is_causal,\n                 implementation=\"cudnn\" if flash_attention else \"xla\",\n             )\n+        except Exception:\n+            # If flash attention fails, fall back to XLA implementation\n+            if flash_attention:\n+                return jax.nn.dot_product_attention(\n+                    query,\n+                    key,\n+                    value,\n+                    bias=bias,\n+                    mask=mask,\n+                    scale=scale,\n+                    is_causal=is_causal,\n+                    implementation=\"xla\",\n+                )\n+            raise\n \n     if flash_attention:\n         raise RuntimeError(\n@@ -1228,6 +1369,9 @@ def dot_product_attention(\n     # Ref: jax.nn.dot_product_attention\n     # https://github.com/jax-ml/jax/blob/jax-v0.4.33/jax/_src/nn/functions.py#L886\n     # Not support `query_seq_lengths` and `key_value_seq_lengths` args\n+\n+    # Fallback to custom XLA implementation\n+    # This is the reference implementation from jax.nn.dot_product_attention\n     output_shape = query.shape\n     _, _, K, H = key.shape\n     scale = (1.0 / jnp.sqrt(H)) if scale is None else scale\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
