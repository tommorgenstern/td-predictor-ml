{"custom_id": "keras#23c40e68de2cffa77c92ae48cca1f81913756d2a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 80 | Lines Deleted: 80 | Files Changed: 1 | Hunks: 15 | Methods Changed: 7 | Complexity Δ (Sum/Max): -6/0 | Churn Δ: 160 | Churn Cumulative: 11543 | Contributors (this commit): 62 | Commits (past 90d): 12 | Contributors (cumulative): 62 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2310,7 +2310,68 @@ class ZeroPadding3D(Layer):\n         return dict(list(base_config.items()) + list(config.items()))\n \n \n-class Cropping1D(Layer):\n+class _Cropping(Layer):\n+    \"\"\"Abstract nD copping layer (private, used as implementation base).\n+\n+    # Arguments\n+        cropping: A tuple of tuples of 2 ints.\n+        data_format: A string,\n+            one of `\"channels_last\"` or `\"channels_first\"`.\n+            The ordering of the dimensions in the inputs.\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch, ..., channels)` while `\"channels_first\"` corresponds to\n+            inputs with shape `(batch, channels, ...)`.\n+            It defaults to the `image_data_format` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"channels_last\".\n+            For Cropping1D, the data format is always `\"channels_last\"`.\n+    \"\"\"\n+\n+    def __init__(self, cropping,\n+                 data_format=None,\n+                 **kwargs):\n+        super(_Cropping, self).__init__(**kwargs)\n+        # self.rank is 1 for Cropping1D, 2 for Cropping2D...\n+        self.rank = len(cropping)\n+        self.cropping = cropping\n+        self.data_format = K.normalize_data_format(data_format)\n+        self.input_spec = InputSpec(ndim=2 + self.rank)\n+\n+    def call(self, inputs):\n+        slices_dims = []\n+        for start, end in self.cropping:\n+            if end == 0:\n+                end = None\n+            else:\n+                end = -end\n+            slices_dims.append(slice(start, end))\n+\n+        slices = [slice(None)] + slices_dims + [slice(None)]\n+        slices = tuple(slices)\n+        spatial_axes = list(range(1, 1 + self.rank))\n+        slices = transpose_shape(slices, self.data_format, spatial_axes)\n+        return inputs[slices]\n+\n+    def compute_output_shape(self, input_shape):\n+        cropping_all_dims = ((0, 0),) + self.cropping + ((0, 0),)\n+        spatial_axes = list(range(1, 1 + self.rank))\n+        cropping_all_dims = transpose_shape(cropping_all_dims,\n+                                            self.data_format,\n+                                            spatial_axes)\n+        output_shape = list(input_shape)\n+        for dim in range(len(output_shape)):\n+            if output_shape[dim] is not None:\n+                output_shape[dim] -= sum(cropping_all_dims[dim])\n+        return tuple(output_shape)\n+\n+    def get_config(self):\n+        config = {'cropping': self.cropping,\n+                  'data_format': self.data_format}\n+        base_config = super(_Cropping, self).get_config()\n+        return dict(list(base_config.items()) + list(config.items()))\n+\n+\n+class Cropping1D(_Cropping):\n     \"\"\"Cropping layer for 1D input (e.g. temporal sequence).\n \n     It crops along the time dimension (axis 1).\n@@ -2330,25 +2391,19 @@ class Cropping1D(Layer):\n     \"\"\"\n \n     def __init__(self, cropping=(1, 1), **kwargs):\n-        super(Cropping1D, self).__init__(**kwargs)\n-        self.cropping = conv_utils.normalize_tuple(cropping, 2, 'cropping')\n-        self.input_spec = InputSpec(ndim=3)\n-\n-    def compute_output_shape(self, input_shape):\n-        return _compute_output_shape_cropping(input_shape,\n+        normalized_cropping = (conv_utils.normalize_tuple(cropping, 2, 'cropping'),)\n+        super(Cropping1D, self).__init__(normalized_cropping,\n                                          'channels_last',\n-                                              (self.cropping,))\n-\n-    def call(self, inputs):\n-        return _call_cropping(inputs, 'channels_last', (self.cropping,))\n+                                         **kwargs)\n \n     def get_config(self):\n-        config = {'cropping': self.cropping}\n         base_config = super(Cropping1D, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n+        base_config.pop('data_format')\n+        base_config['cropping'] = base_config['cropping'][0]\n+        return base_config\n \n \n-class Cropping2D(Layer):\n+class Cropping2D(_Cropping):\n     \"\"\"Cropping layer for 2D input (e.g. picture).\n \n     It crops along spatial dimensions, i.e. height and width.\n@@ -2406,10 +2461,8 @@ class Cropping2D(Layer):\n     @interfaces.legacy_cropping2d_support\n     def __init__(self, cropping=((0, 0), (0, 0)),\n                  data_format=None, **kwargs):\n-        super(Cropping2D, self).__init__(**kwargs)\n-        self.data_format = K.normalize_data_format(data_format)\n         if isinstance(cropping, int):\n-            self.cropping = ((cropping, cropping), (cropping, cropping))\n+            normalized_cropping = ((cropping, cropping), (cropping, cropping))\n         elif hasattr(cropping, '__len__'):\n             if len(cropping) != 2:\n                 raise ValueError('`cropping` should have two elements. '\n@@ -2420,7 +2473,7 @@ class Cropping2D(Layer):\n             width_cropping = conv_utils.normalize_tuple(\n                 cropping[1], 2,\n                 '2nd entry of cropping')\n-            self.cropping = (height_cropping, width_cropping)\n+            normalized_cropping = (height_cropping, width_cropping)\n         else:\n             raise ValueError('`cropping` should be either an int, '\n                              'a tuple of 2 ints '\n@@ -2428,24 +2481,12 @@ class Cropping2D(Layer):\n                              'or a tuple of 2 tuples of 2 ints '\n                              '((top_crop, bottom_crop), (left_crop, right_crop)). '\n                              'Found: ' + str(cropping))\n-        self.input_spec = InputSpec(ndim=4)\n-\n-    def compute_output_shape(self, input_shape):\n-        return _compute_output_shape_cropping(input_shape,\n-                                              self.data_format,\n-                                              self.cropping)\n-\n-    def call(self, inputs):\n-        return _call_cropping(inputs, self.data_format, self.cropping)\n-\n-    def get_config(self):\n-        config = {'cropping': self.cropping,\n-                  'data_format': self.data_format}\n-        base_config = super(Cropping2D, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n+        super(Cropping2D, self).__init__(normalized_cropping,\n+                                         data_format,\n+                                         **kwargs)\n \n \n-class Cropping3D(Layer):\n+class Cropping3D(_Cropping):\n     \"\"\"Cropping layer for 3D data (e.g. spatial or spatio-temporal).\n \n     # Arguments\n@@ -2488,10 +2529,9 @@ class Cropping3D(Layer):\n     @interfaces.legacy_cropping3d_support\n     def __init__(self, cropping=((1, 1), (1, 1), (1, 1)),\n                  data_format=None, **kwargs):\n-        super(Cropping3D, self).__init__(**kwargs)\n         self.data_format = K.normalize_data_format(data_format)\n         if isinstance(cropping, int):\n-            self.cropping = ((cropping, cropping),\n+            normalized_cropping = ((cropping, cropping),\n                                    (cropping, cropping),\n                                    (cropping, cropping))\n         elif hasattr(cropping, '__len__'):\n@@ -2504,7 +2544,7 @@ class Cropping3D(Layer):\n                                                        '2nd entry of cropping')\n             dim3_cropping = conv_utils.normalize_tuple(cropping[2], 2,\n                                                        '3rd entry of cropping')\n-            self.cropping = (dim1_cropping, dim2_cropping, dim3_cropping)\n+            normalized_cropping = (dim1_cropping, dim2_cropping, dim3_cropping)\n         else:\n             raise ValueError('`cropping` should be either an int, '\n                              'a tuple of 3 ints '\n@@ -2514,49 +2554,9 @@ class Cropping3D(Layer):\n                              ' (left_dim2_crop, right_dim2_crop),'\n                              ' (left_dim3_crop, right_dim2_crop)). '\n                              'Found: ' + str(cropping))\n-        self.input_spec = InputSpec(ndim=5)\n-\n-    def compute_output_shape(self, input_shape):\n-        return _compute_output_shape_cropping(input_shape,\n-                                              self.data_format,\n-                                              self.cropping)\n-\n-    def call(self, inputs):\n-        return _call_cropping(inputs, self.data_format, self.cropping)\n-\n-    def get_config(self):\n-        config = {'cropping': self.cropping,\n-                  'data_format': self.data_format}\n-        base_config = super(Cropping3D, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-def _call_cropping(inputs, data_format, cropping):\n-    slices_dims = []\n-    for start, end in cropping:\n-        if end == 0:\n-            end = None\n-        else:\n-            end = -end\n-        slices_dims.append(slice(start, end))\n-\n-    slices = [slice(None)] + slices_dims + [slice(None)]\n-    slices = tuple(slices)\n-    spatial_axes = list(range(1, 1 + len(cropping)))\n-    slices = transpose_shape(slices, data_format, spatial_axes)\n-    return inputs[slices]\n-\n-\n-def _compute_output_shape_cropping(input_shape, data_format, cropping):\n-    cropping_all_dims = ((0, 0),) + cropping + ((0, 0),)\n-    spatial_axes = list(range(1, 1 + len(cropping)))\n-    cropping_all_dims = transpose_shape(cropping_all_dims, data_format, spatial_axes)\n-\n-    output_shape = list(input_shape)\n-    for dim in range(len(output_shape)):\n-        if output_shape[dim] is not None:\n-            output_shape[dim] -= sum(cropping_all_dims[dim])\n-    return tuple(output_shape)\n+        super(Cropping3D, self).__init__(normalized_cropping,\n+                                         data_format,\n+                                         **kwargs)\n \n \n # Aliases\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6d30ab70a4f116554aa610ec1c00a6bc5f1247f3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 733 | Lines Deleted: 56 | Files Changed: 16 | Hunks: 35 | Methods Changed: 44 | Complexity Δ (Sum/Max): 58/19 | Churn Δ: 789 | Churn Cumulative: 18700 | Contributors (this commit): 93 | Commits (past 90d): 47 | Contributors (cumulative): 166 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3,19 +3,33 @@ from __future__ import division\n from __future__ import print_function\n \n from .. import backend\n-from .. import engine\n from .. import layers\n from .. import models\n from .. import utils\n \n import keras_applications\n \n+if not hasattr(keras_applications, 'get_submodules_from_kwargs'):\n     keras_applications.set_keras_submodules(\n         backend=backend,\n         layers=layers,\n         models=models,\n         utils=utils)\n \n+\n+def keras_modules_injection(base_fun):\n+\n+    def wrapper(*args, **kwargs):\n+        if hasattr(keras_applications, 'get_submodules_from_kwargs'):\n+            kwargs['backend'] = backend\n+            kwargs['layers'] = layers\n+            kwargs['models'] = models\n+            kwargs['utils'] = utils\n+        return base_fun(*args, **kwargs)\n+\n+    return wrapper\n+\n+\n from .vgg16 import VGG16\n from .vgg19 import VGG19\n from .resnet50 import ResNet50\n@@ -23,6 +37,6 @@ from .inception_v3 import InceptionV3\n from .inception_resnet_v2 import InceptionResNetV2\n from .xception import Xception\n from .mobilenet import MobileNet\n-from .mobilenetv2 import MobileNetV2\n+from .mobilenet_v2 import MobileNetV2\n from .densenet import DenseNet121, DenseNet169, DenseNet201\n from .nasnet import NASNetMobile, NASNetLarge\n\n@@ -3,9 +3,29 @@ from __future__ import division\n from __future__ import print_function\n \n from keras_applications import densenet\n+from . import keras_modules_injection\n \n-DenseNet121 = densenet.DenseNet121\n-DenseNet169 = densenet.DenseNet169\n-DenseNet201 = densenet.DenseNet201\n-decode_predictions = densenet.decode_predictions\n-preprocess_input = densenet.preprocess_input\n+\n+@keras_modules_injection\n+def DenseNet121(*args, **kwargs):\n+    return densenet.DenseNet121(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def DenseNet169(*args, **kwargs):\n+    return densenet.DenseNet169(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def DenseNet201(*args, **kwargs):\n+    return densenet.DenseNet201(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def decode_predictions(*args, **kwargs):\n+    return densenet.decode_predictions(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def preprocess_input(*args, **kwargs):\n+    return densenet.preprocess_input(*args, **kwargs)\n\n@@ -5,6 +5,15 @@ from __future__ import division\n from __future__ import print_function\n \n from keras_applications import imagenet_utils\n+from . import keras_modules_injection\n \n-preprocess_input = imagenet_utils.preprocess_input\n-decode_predictions = imagenet_utils.decode_predictions\n+\n+@keras_modules_injection\n+def decode_predictions(*args, **kwargs):\n+    return imagenet_utils.decode_predictions(\n+        *args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def preprocess_input(*args, **kwargs):\n+    return imagenet_utils.preprocess_input(*args, **kwargs)\n\n@@ -3,7 +3,19 @@ from __future__ import division\n from __future__ import print_function\n \n from keras_applications import inception_resnet_v2\n+from . import keras_modules_injection\n \n-InceptionResNetV2 = inception_resnet_v2.InceptionResNetV2\n-decode_predictions = inception_resnet_v2.decode_predictions\n-preprocess_input = inception_resnet_v2.preprocess_input\n+\n+@keras_modules_injection\n+def InceptionResNetV2(*args, **kwargs):\n+    return inception_resnet_v2.InceptionResNetV2(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def decode_predictions(*args, **kwargs):\n+    return inception_resnet_v2.decode_predictions(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def preprocess_input(*args, **kwargs):\n+    return inception_resnet_v2.preprocess_input(*args, **kwargs)\n\n@@ -3,7 +3,19 @@ from __future__ import division\n from __future__ import print_function\n \n from keras_applications import inception_v3\n+from . import keras_modules_injection\n \n-InceptionV3 = inception_v3.InceptionV3\n-decode_predictions = inception_v3.decode_predictions\n-preprocess_input = inception_v3.preprocess_input\n+\n+@keras_modules_injection\n+def InceptionV3(*args, **kwargs):\n+    return inception_v3.InceptionV3(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def decode_predictions(*args, **kwargs):\n+    return inception_v3.decode_predictions(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def preprocess_input(*args, **kwargs):\n+    return inception_v3.preprocess_input(*args, **kwargs)\n\n@@ -3,7 +3,19 @@ from __future__ import division\n from __future__ import print_function\n \n from keras_applications import mobilenet\n+from . import keras_modules_injection\n \n-MobileNet = mobilenet.MobileNet\n-decode_predictions = mobilenet.decode_predictions\n-preprocess_input = mobilenet.preprocess_input\n+\n+@keras_modules_injection\n+def MobileNet(*args, **kwargs):\n+    return mobilenet.MobileNet(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def decode_predictions(*args, **kwargs):\n+    return mobilenet.decode_predictions(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def preprocess_input(*args, **kwargs):\n+    return mobilenet.preprocess_input(*args, **kwargs)\n\n@@ -0,0 +1,21 @@\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+from keras_applications import mobilenet_v2\n+from . import keras_modules_injection\n+\n+\n+@keras_modules_injection\n+def MobileNetV2(*args, **kwargs):\n+    return mobilenet_v2.MobileNetV2(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def decode_predictions(*args, **kwargs):\n+    return mobilenet_v2.decode_predictions(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def preprocess_input(*args, **kwargs):\n+    return mobilenet_v2.preprocess_input(*args, **kwargs)\n\n@@ -1,9 +1,2 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from keras_applications import mobilenet_v2\n-\n-MobileNetV2 = mobilenet_v2.MobileNetV2\n-decode_predictions = mobilenet_v2.decode_predictions\n-preprocess_input = mobilenet_v2.preprocess_input\n+# Only for backwards compatibility.\n+from .mobilenet_v2 import *\n\n@@ -3,8 +3,24 @@ from __future__ import division\n from __future__ import print_function\n \n from keras_applications import nasnet\n+from . import keras_modules_injection\n \n-NASNetMobile = nasnet.NASNetMobile\n-NASNetLarge = nasnet.NASNetLarge\n-decode_predictions = nasnet.decode_predictions\n-preprocess_input = nasnet.preprocess_input\n+\n+@keras_modules_injection\n+def NASNetMobile(*args, **kwargs):\n+    return nasnet.NASNetMobile(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def NASNetLarge(*args, **kwargs):\n+    return nasnet.NASNetLarge(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def decode_predictions(*args, **kwargs):\n+    return nasnet.decode_predictions(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def preprocess_input(*args, **kwargs):\n+    return nasnet.preprocess_input(*args, **kwargs)\n\n@@ -3,7 +3,19 @@ from __future__ import division\n from __future__ import print_function\n \n from keras_applications import resnet50\n+from . import keras_modules_injection\n \n-ResNet50 = resnet50.ResNet50\n-decode_predictions = resnet50.decode_predictions\n-preprocess_input = resnet50.preprocess_input\n+\n+@keras_modules_injection\n+def ResNet50(*args, **kwargs):\n+    return resnet50.ResNet50(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def decode_predictions(*args, **kwargs):\n+    return resnet50.decode_predictions(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def preprocess_input(*args, **kwargs):\n+    return resnet50.preprocess_input(*args, **kwargs)\n\n@@ -3,7 +3,19 @@ from __future__ import division\n from __future__ import print_function\n \n from keras_applications import vgg16\n+from . import keras_modules_injection\n \n-VGG16 = vgg16.VGG16\n-decode_predictions = vgg16.decode_predictions\n-preprocess_input = vgg16.preprocess_input\n+\n+@keras_modules_injection\n+def VGG16(*args, **kwargs):\n+    return vgg16.VGG16(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def decode_predictions(*args, **kwargs):\n+    return vgg16.decode_predictions(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def preprocess_input(*args, **kwargs):\n+    return vgg16.preprocess_input(*args, **kwargs)\n\n@@ -3,7 +3,19 @@ from __future__ import division\n from __future__ import print_function\n \n from keras_applications import vgg19\n+from . import keras_modules_injection\n \n-VGG19 = vgg19.VGG19\n-decode_predictions = vgg19.decode_predictions\n-preprocess_input = vgg19.preprocess_input\n+\n+@keras_modules_injection\n+def VGG19(*args, **kwargs):\n+    return vgg19.VGG19(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def decode_predictions(*args, **kwargs):\n+    return vgg19.decode_predictions(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def preprocess_input(*args, **kwargs):\n+    return vgg19.preprocess_input(*args, **kwargs)\n\n@@ -3,7 +3,19 @@ from __future__ import division\n from __future__ import print_function\n \n from keras_applications import xception\n+from . import keras_modules_injection\n \n-Xception = xception.Xception\n-decode_predictions = xception.decode_predictions\n-preprocess_input = xception.preprocess_input\n+\n+@keras_modules_injection\n+def Xception(*args, **kwargs):\n+    return xception.Xception(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def decode_predictions(*args, **kwargs):\n+    return xception.decode_predictions(*args, **kwargs)\n+\n+\n+@keras_modules_injection\n+def preprocess_input(*args, **kwargs):\n+    return xception.preprocess_input(*args, **kwargs)\n\n@@ -4,6 +4,10 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n+import inspect\n+\n+from .. import backend\n+from .. import utils\n from keras_preprocessing import image\n \n random_rotation = image.random_rotation\n@@ -15,11 +19,453 @@ random_channel_shift = image.random_channel_shift\n apply_brightness_shift = image.apply_brightness_shift\n random_brightness = image.random_brightness\n apply_affine_transform = image.apply_affine_transform\n-array_to_img = image.array_to_img\n-img_to_array = image.img_to_array\n-save_img = image.save_img\n load_img = image.load_img\n-ImageDataGenerator = image.ImageDataGenerator\n-Iterator = image.Iterator\n-NumpyArrayIterator = image.NumpyArrayIterator\n-DirectoryIterator = image.DirectoryIterator\n+\n+\n+def array_to_img(x, data_format=None, scale=True, dtype=None):\n+    if data_format is None:\n+        data_format = backend.image_data_format()\n+    if 'dtype' in inspect.getargspec(image.array_to_img).args:\n+        if dtype is None:\n+            dtype = backend.floatx()\n+        return image.array_to_img(x,\n+                                  data_format=data_format,\n+                                  scale=scale,\n+                                  dtype=dtype)\n+    return image.array_to_img(x,\n+                              data_format=data_format,\n+                              scale=scale)\n+\n+\n+def img_to_array(img, data_format=None, dtype=None):\n+    if data_format is None:\n+        data_format = backend.image_data_format()\n+    if 'dtype' in inspect.getargspec(image.img_to_array).args:\n+        if dtype is None:\n+            dtype = backend.floatx()\n+        return image.img_to_array(img, data_format=data_format, dtype=dtype)\n+    return image.img_to_array(img, data_format=data_format)\n+\n+\n+def save_img(path,\n+             x,\n+             data_format=None,\n+             file_format=None,\n+             scale=True, **kwargs):\n+    if data_format is None:\n+        data_format = backend.image_data_format()\n+    return image.save_img(path,\n+                          x,\n+                          data_format=data_format,\n+                          file_format=file_format,\n+                          scale=scale, **kwargs)\n+\n+\n+class Iterator(image.Iterator, utils.Sequence):\n+    \"\"\"Base class for image data iterators.\n+\n+    Every `Iterator` must implement the `_get_batches_of_transformed_samples`\n+    method.\n+\n+    # Arguments\n+        n: Integer, total number of samples in the dataset to loop over.\n+        batch_size: Integer, size of a batch.\n+        shuffle: Boolean, whether to shuffle the data between epochs.\n+        seed: Random seeding for data shuffling.\n+    \"\"\"\n+    pass\n+\n+\n+class DirectoryIterator(image.DirectoryIterator, Iterator):\n+    \"\"\"Iterator capable of reading images from a directory on disk.\n+\n+    # Arguments\n+        directory: Path to the directory to read images from.\n+            Each subdirectory in this directory will be\n+            considered to contain images from one class,\n+            or alternatively you could specify class subdirectories\n+            via the `classes` argument.\n+        image_data_generator: Instance of `ImageDataGenerator`\n+            to use for random transformations and normalization.\n+        target_size: tuple of integers, dimensions to resize input images to.\n+        color_mode: One of `\"rgb\"`, `\"rgba\"`, `\"grayscale\"`.\n+            Color mode to read images.\n+        classes: Optional list of strings, names of subdirectories\n+            containing images from each class (e.g. `[\"dogs\", \"cats\"]`).\n+            It will be computed automatically if not set.\n+        class_mode: Mode for yielding the targets:\n+            `\"binary\"`: binary targets (if there are only two classes),\n+            `\"categorical\"`: categorical targets,\n+            `\"sparse\"`: integer targets,\n+            `\"input\"`: targets are images identical to input images (mainly\n+                used to work with autoencoders),\n+            `None`: no targets get yielded (only input images are yielded).\n+        batch_size: Integer, size of a batch.\n+        shuffle: Boolean, whether to shuffle the data between epochs.\n+        seed: Random seed for data shuffling.\n+        data_format: String, one of `channels_first`, `channels_last`.\n+        save_to_dir: Optional directory where to save the pictures\n+            being yielded, in a viewable format. This is useful\n+            for visualizing the random transformations being\n+            applied, for debugging purposes.\n+        save_prefix: String prefix to use for saving sample\n+            images (if `save_to_dir` is set).\n+        save_format: Format to use for saving sample images\n+            (if `save_to_dir` is set).\n+        subset: Subset of data (`\"training\"` or `\"validation\"`) if\n+            validation_split is set in ImageDataGenerator.\n+        interpolation: Interpolation method used to resample the image if the\n+            target size is different from that of the loaded image.\n+            Supported methods are \"nearest\", \"bilinear\", and \"bicubic\".\n+            If PIL version 1.1.3 or newer is installed, \"lanczos\" is also\n+            supported. If PIL version 3.4.0 or newer is installed, \"box\" and\n+            \"hamming\" are also supported. By default, \"nearest\" is used.\n+        dtype: Dtype to use for generated arrays.\n+    \"\"\"\n+\n+    def __init__(self, directory, image_data_generator,\n+                 target_size=(256, 256),\n+                 color_mode='rgb',\n+                 classes=None,\n+                 class_mode='categorical',\n+                 batch_size=32,\n+                 shuffle=True,\n+                 seed=None,\n+                 data_format=None,\n+                 save_to_dir=None,\n+                 save_prefix='',\n+                 save_format='png',\n+                 follow_links=False,\n+                 subset=None,\n+                 interpolation='nearest',\n+                 dtype=None):\n+        if data_format is None:\n+            data_format = backend.image_data_format()\n+        kwargs = {}\n+        if 'dtype' in inspect.getargspec(\n+                image.ImageDataGenerator.__init__).args:\n+            if dtype is None:\n+                dtype = backend.floatx()\n+            kwargs['dtype'] = dtype\n+        super(DirectoryIterator, self).__init__(\n+            directory, image_data_generator,\n+            target_size=target_size,\n+            color_mode=color_mode,\n+            classes=classes,\n+            class_mode=class_mode,\n+            batch_size=batch_size,\n+            shuffle=shuffle,\n+            seed=seed,\n+            data_format=data_format,\n+            save_to_dir=save_to_dir,\n+            save_prefix=save_prefix,\n+            save_format=save_format,\n+            follow_links=follow_links,\n+            subset=subset,\n+            interpolation=interpolation,\n+            **kwargs)\n+\n+\n+class NumpyArrayIterator(image.NumpyArrayIterator, Iterator):\n+    \"\"\"Iterator yielding data from a Numpy array.\n+\n+    # Arguments\n+        x: Numpy array of input data or tuple.\n+            If tuple, the second elements is either\n+            another numpy array or a list of numpy arrays,\n+            each of which gets passed\n+            through as an output without any modifications.\n+        y: Numpy array of targets data.\n+        image_data_generator: Instance of `ImageDataGenerator`\n+            to use for random transformations and normalization.\n+        batch_size: Integer, size of a batch.\n+        shuffle: Boolean, whether to shuffle the data between epochs.\n+        sample_weight: Numpy array of sample weights.\n+        seed: Random seed for data shuffling.\n+        data_format: String, one of `channels_first`, `channels_last`.\n+        save_to_dir: Optional directory where to save the pictures\n+            being yielded, in a viewable format. This is useful\n+            for visualizing the random transformations being\n+            applied, for debugging purposes.\n+        save_prefix: String prefix to use for saving sample\n+            images (if `save_to_dir` is set).\n+        save_format: Format to use for saving sample images\n+            (if `save_to_dir` is set).\n+        subset: Subset of data (`\"training\"` or `\"validation\"`) if\n+            validation_split is set in ImageDataGenerator.\n+        dtype: Dtype to use for the generated arrays.\n+    \"\"\"\n+\n+    def __init__(self, x, y, image_data_generator,\n+                 batch_size=32,\n+                 shuffle=False,\n+                 sample_weight=None,\n+                 seed=None,\n+                 data_format=None,\n+                 save_to_dir=None,\n+                 save_prefix='',\n+                 save_format='png',\n+                 subset=None,\n+                 dtype=None):\n+        if data_format is None:\n+            data_format = backend.image_data_format()\n+        kwargs = {}\n+        if 'dtype' in inspect.getargspec(\n+                image.NumpyArrayIterator.__init__).args:\n+            if dtype is None:\n+                dtype = backend.floatx()\n+            kwargs['dtype'] = dtype\n+        super(NumpyArrayIterator, self).__init__(\n+            x, y, image_data_generator,\n+            batch_size=batch_size,\n+            shuffle=shuffle,\n+            sample_weight=sample_weight,\n+            seed=seed,\n+            data_format=data_format,\n+            save_to_dir=save_to_dir,\n+            save_prefix=save_prefix,\n+            save_format=save_format,\n+            subset=subset,\n+            **kwargs)\n+\n+\n+class ImageDataGenerator(image.ImageDataGenerator):\n+    \"\"\"Generate batches of tensor image data with real-time data augmentation.\n+     The data will be looped over (in batches).\n+\n+    # Arguments\n+        featurewise_center: Boolean.\n+            Set input mean to 0 over the dataset, feature-wise.\n+        samplewise_center: Boolean. Set each sample mean to 0.\n+        featurewise_std_normalization: Boolean.\n+            Divide inputs by std of the dataset, feature-wise.\n+        samplewise_std_normalization: Boolean. Divide each input by its std.\n+        zca_epsilon: epsilon for ZCA whitening. Default is 1e-6.\n+        zca_whitening: Boolean. Apply ZCA whitening.\n+        rotation_range: Int. Degree range for random rotations.\n+        width_shift_range: Float, 1-D array-like or int\n+            - float: fraction of total width, if < 1, or pixels if >= 1.\n+            - 1-D array-like: random elements from the array.\n+            - int: integer number of pixels from interval\n+                `(-width_shift_range, +width_shift_range)`\n+            - With `width_shift_range=2` possible values\n+                are integers `[-1, 0, +1]`,\n+                same as with `width_shift_range=[-1, 0, +1]`,\n+                while with `width_shift_range=1.0` possible values are floats\n+                in the interval [-1.0, +1.0).\n+        height_shift_range: Float, 1-D array-like or int\n+            - float: fraction of total height, if < 1, or pixels if >= 1.\n+            - 1-D array-like: random elements from the array.\n+            - int: integer number of pixels from interval\n+                `(-height_shift_range, +height_shift_range)`\n+            - With `height_shift_range=2` possible values\n+                are integers `[-1, 0, +1]`,\n+                same as with `height_shift_range=[-1, 0, +1]`,\n+                while with `height_shift_range=1.0` possible values are floats\n+                in the interval [-1.0, +1.0).\n+        brightness_range: Tuple or list of two floats. Range for picking\n+            a brightness shift value from.\n+        shear_range: Float. Shear Intensity\n+            (Shear angle in counter-clockwise direction in degrees)\n+        zoom_range: Float or [lower, upper]. Range for random zoom.\n+            If a float, `[lower, upper] = [1-zoom_range, 1+zoom_range]`.\n+        channel_shift_range: Float. Range for random channel shifts.\n+        fill_mode: One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}.\n+            Default is 'nearest'.\n+            Points outside the boundaries of the input are filled\n+            according to the given mode:\n+            - 'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k)\n+            - 'nearest':  aaaaaaaa|abcd|dddddddd\n+            - 'reflect':  abcddcba|abcd|dcbaabcd\n+            - 'wrap':  abcdabcd|abcd|abcdabcd\n+        cval: Float or Int.\n+            Value used for points outside the boundaries\n+            when `fill_mode = \"constant\"`.\n+        horizontal_flip: Boolean. Randomly flip inputs horizontally.\n+        vertical_flip: Boolean. Randomly flip inputs vertically.\n+        rescale: rescaling factor. Defaults to None.\n+            If None or 0, no rescaling is applied,\n+            otherwise we multiply the data by the value provided\n+            (after applying all other transformations).\n+        preprocessing_function: function that will be implied on each input.\n+            The function will run after the image is resized and augmented.\n+            The function should take one argument:\n+            one image (Numpy tensor with rank 3),\n+            and should output a Numpy tensor with the same shape.\n+        data_format: Image data format,\n+            either \"channels_first\" or \"channels_last\".\n+            \"channels_last\" mode means that the images should have shape\n+            `(samples, height, width, channels)`,\n+            \"channels_first\" mode means that the images should have shape\n+            `(samples, channels, height, width)`.\n+            It defaults to the `image_data_format` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"channels_last\".\n+        validation_split: Float. Fraction of images reserved for validation\n+            (strictly between 0 and 1).\n+        dtype: Dtype to use for the generated arrays.\n+\n+    # Examples\n+    Example of using `.flow(x, y)`:\n+\n+    ```python\n+    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n+    y_train = np_utils.to_categorical(y_train, num_classes)\n+    y_test = np_utils.to_categorical(y_test, num_classes)\n+\n+    datagen = ImageDataGenerator(\n+        featurewise_center=True,\n+        featurewise_std_normalization=True,\n+        rotation_range=20,\n+        width_shift_range=0.2,\n+        height_shift_range=0.2,\n+        horizontal_flip=True)\n+\n+    # compute quantities required for featurewise normalization\n+    # (std, mean, and principal components if ZCA whitening is applied)\n+    datagen.fit(x_train)\n+\n+    # fits the model on batches with real-time data augmentation:\n+    model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n+                        steps_per_epoch=len(x_train) / 32, epochs=epochs)\n+\n+    # here's a more \"manual\" example\n+    for e in range(epochs):\n+        print('Epoch', e)\n+        batches = 0\n+        for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\n+            model.fit(x_batch, y_batch)\n+            batches += 1\n+            if batches >= len(x_train) / 32:\n+                # we need to break the loop by hand because\n+                # the generator loops indefinitely\n+                break\n+    ```\n+    Example of using `.flow_from_directory(directory)`:\n+\n+    ```python\n+    train_datagen = ImageDataGenerator(\n+            rescale=1./255,\n+            shear_range=0.2,\n+            zoom_range=0.2,\n+            horizontal_flip=True)\n+\n+    test_datagen = ImageDataGenerator(rescale=1./255)\n+\n+    train_generator = train_datagen.flow_from_directory(\n+            'data/train',\n+            target_size=(150, 150),\n+            batch_size=32,\n+            class_mode='binary')\n+\n+    validation_generator = test_datagen.flow_from_directory(\n+            'data/validation',\n+            target_size=(150, 150),\n+            batch_size=32,\n+            class_mode='binary')\n+\n+    model.fit_generator(\n+            train_generator,\n+            steps_per_epoch=2000,\n+            epochs=50,\n+            validation_data=validation_generator,\n+            validation_steps=800)\n+    ```\n+\n+    Example of transforming images and masks together.\n+\n+    ```python\n+    # we create two instances with the same arguments\n+    data_gen_args = dict(featurewise_center=True,\n+                         featurewise_std_normalization=True,\n+                         rotation_range=90,\n+                         width_shift_range=0.1,\n+                         height_shift_range=0.1,\n+                         zoom_range=0.2)\n+    image_datagen = ImageDataGenerator(**data_gen_args)\n+    mask_datagen = ImageDataGenerator(**data_gen_args)\n+\n+    # Provide the same seed and keyword arguments to the fit and flow methods\n+    seed = 1\n+    image_datagen.fit(images, augment=True, seed=seed)\n+    mask_datagen.fit(masks, augment=True, seed=seed)\n+\n+    image_generator = image_datagen.flow_from_directory(\n+        'data/images',\n+        class_mode=None,\n+        seed=seed)\n+\n+    mask_generator = mask_datagen.flow_from_directory(\n+        'data/masks',\n+        class_mode=None,\n+        seed=seed)\n+\n+    # combine generators into one which yields image and masks\n+    train_generator = zip(image_generator, mask_generator)\n+\n+    model.fit_generator(\n+        train_generator,\n+        steps_per_epoch=2000,\n+        epochs=50)\n+    ```\n+    \"\"\"\n+\n+    def __init__(self,\n+                 featurewise_center=False,\n+                 samplewise_center=False,\n+                 featurewise_std_normalization=False,\n+                 samplewise_std_normalization=False,\n+                 zca_whitening=False,\n+                 zca_epsilon=1e-6,\n+                 rotation_range=0,\n+                 width_shift_range=0.,\n+                 height_shift_range=0.,\n+                 brightness_range=None,\n+                 shear_range=0.,\n+                 zoom_range=0.,\n+                 channel_shift_range=0.,\n+                 fill_mode='nearest',\n+                 cval=0.,\n+                 horizontal_flip=False,\n+                 vertical_flip=False,\n+                 rescale=None,\n+                 preprocessing_function=None,\n+                 data_format=None,\n+                 validation_split=0.0,\n+                 dtype=None):\n+        if data_format is None:\n+            data_format = backend.image_data_format()\n+        kwargs = {}\n+        if 'dtype' in inspect.getargspec(\n+                image.ImageDataGenerator.__init__).args:\n+            if dtype is None:\n+                dtype = backend.floatx()\n+            kwargs['dtype'] = dtype\n+        super(ImageDataGenerator, self).__init__(\n+            featurewise_center=featurewise_center,\n+            samplewise_center=samplewise_center,\n+            featurewise_std_normalization=featurewise_std_normalization,\n+            samplewise_std_normalization=samplewise_std_normalization,\n+            zca_whitening=zca_whitening,\n+            zca_epsilon=zca_epsilon,\n+            rotation_range=rotation_range,\n+            width_shift_range=width_shift_range,\n+            height_shift_range=height_shift_range,\n+            brightness_range=brightness_range,\n+            shear_range=shear_range,\n+            zoom_range=zoom_range,\n+            channel_shift_range=channel_shift_range,\n+            fill_mode=fill_mode,\n+            cval=cval,\n+            horizontal_flip=horizontal_flip,\n+            vertical_flip=vertical_flip,\n+            rescale=rescale,\n+            preprocessing_function=preprocessing_function,\n+            data_format=data_format,\n+            validation_split=validation_split,\n+            **kwargs)\n+\n+\n+array_to_img.__doc__ = image.array_to_img.__doc__\n+img_to_array.__doc__ = image.img_to_array.__doc__\n+save_img.__doc__ = image.save_img.__doc__\n\n@@ -5,9 +5,74 @@ from __future__ import division\n from __future__ import print_function\n \n from keras_preprocessing import sequence\n+from .. import utils\n \n pad_sequences = sequence.pad_sequences\n make_sampling_table = sequence.make_sampling_table\n skipgrams = sequence.skipgrams\n _remove_long_seq = sequence._remove_long_seq  # TODO: make it public?\n-TimeseriesGenerator = sequence.TimeseriesGenerator\n+\n+\n+class TimeseriesGenerator(sequence.TimeseriesGenerator, utils.Sequence):\n+    \"\"\"Utility class for generating batches of temporal data.\n+\n+    This class takes in a sequence of data-points gathered at\n+    equal intervals, along with time series parameters such as\n+    stride, length of history, etc., to produce batches for\n+    training/validation.\n+\n+    # Arguments\n+        data: Indexable generator (such as list or Numpy array)\n+            containing consecutive data points (timesteps).\n+            The data should be at 2D, and axis 0 is expected\n+            to be the time dimension.\n+        targets: Targets corresponding to timesteps in `data`.\n+            It should have same length as `data`.\n+        length: Length of the output sequences (in number of timesteps).\n+        sampling_rate: Period between successive individual timesteps\n+            within sequences. For rate `r`, timesteps\n+            `data[i]`, `data[i-r]`, ... `data[i - length]`\n+            are used for create a sample sequence.\n+        stride: Period between successive output sequences.\n+            For stride `s`, consecutive output samples would\n+            be centered around `data[i]`, `data[i+s]`, `data[i+2*s]`, etc.\n+        start_index: Data points earlier than `start_index` will not be used\n+            in the output sequences. This is useful to reserve part of the\n+            data for test or validation.\n+        end_index: Data points later than `end_index` will not be used\n+            in the output sequences. This is useful to reserve part of the\n+            data for test or validation.\n+        shuffle: Whether to shuffle output samples,\n+            or instead draw them in chronological order.\n+        reverse: Boolean: if `true`, timesteps in each output sample will be\n+            in reverse chronological order.\n+        batch_size: Number of timeseries samples in each batch\n+            (except maybe the last one).\n+\n+    # Returns\n+        A [Sequence](/utils/#sequence) instance.\n+\n+    # Examples\n+\n+    ```python\n+    from keras.preprocessing.sequence import TimeseriesGenerator\n+    import numpy as np\n+\n+    data = np.array([[i] for i in range(50)])\n+    targets = np.array([[i] for i in range(50)])\n+\n+    data_gen = TimeseriesGenerator(data, targets,\n+                                   length=10, sampling_rate=2,\n+                                   batch_size=2)\n+    assert len(data_gen) == 20\n+\n+    batch_0 = data_gen[0]\n+    x, y = batch_0\n+    assert np.array_equal(x,\n+                          np.array([[[0], [2], [4], [6], [8]],\n+                                    [[1], [3], [5], [7], [9]]]))\n+    assert np.array_equal(y,\n+                          np.array([[10], [11]]))\n+    ```\n+    \"\"\"\n+    pass\n\n@@ -3,8 +3,6 @@ import random\n import os\n from multiprocessing import Process, Queue\n from keras.utils.test_utils import keras_test\n-from keras.utils.test_utils import layer_test\n-from keras.models import Sequential\n from keras import applications\n from keras import backend as K\n \n@@ -27,11 +25,15 @@ MODEL_LIST = [\n     (applications.DenseNet121, 1024),\n     (applications.DenseNet169, 1664),\n     (applications.DenseNet201, 1920)\n-    # TODO: enable nasnet tests if they support Theano and CNTK\n-    # (applications.NASNetMobile, 1056),\n-    # (applications.NASNetLarge, 4032)\n ]\n \n+# TODO: enable Nasnet for Theano and CNTK\n+if K.backend() == 'tensorflow':\n+    MODEL_LIST.extend([\n+        (applications.NASNetMobile, 1056),\n+        (applications.NASNetLarge, 4032),\n+    ])\n+\n \n def _get_output_shape(model_fn):\n     if K.backend() == 'cntk':\n@@ -73,6 +75,13 @@ def _test_application_notop(app, last_dim):\n     assert output_shape == (None, None, None, last_dim)\n \n \n+def test_mobilenet_v2_legacy_import():\n+    from keras.applications import mobilenetv2\n+    assert hasattr(mobilenetv2, 'MobileNetV2')\n+    from keras.applications import mobilenet_v2\n+    assert hasattr(mobilenet_v2, 'MobileNetV2')\n+\n+\n def test_applications():\n     for _ in range(3):\n         app, last_dim = random.choice(MODEL_LIST)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c60f1e19dceacf77749a6215b1fc77f758f46327", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): -14/0 | Churn Δ: 14 | Churn Cumulative: 4480 | Contributors (this commit): 29 | Commits (past 90d): 8 | Contributors (cumulative): 29 | DMM Complexity: 0.0\n\nDIFF:\n@@ -207,21 +207,19 @@ def check_composed_tensor_operations(first_function_name, first_function_args,\n class TestBackend(object):\n \n     def test_is_keras_tensor(self):\n-        for k in BACKENDS:\n         np_var = np.array([1, 2])\n         with pytest.raises(ValueError):\n-                k.is_keras_tensor(np_var)\n+            K.is_keras_tensor(np_var)\n \n-            keras_var = k.variable(np_var)\n-            assert k.is_keras_tensor(keras_var) is False\n-            keras_placeholder = k.placeholder(shape=(2, 4, 5))\n-            assert k.is_keras_tensor(keras_placeholder) is False\n+        keras_var = K.variable(np_var)\n+        assert K.is_keras_tensor(keras_var) is False\n+        keras_placeholder = K.placeholder(shape=(2, 4, 5))\n+        assert K.is_keras_tensor(keras_placeholder) is False\n \n     def test_set_learning_phase(self):\n         # not supported learning_phase\n-        for k in BACKENDS:\n         with pytest.raises(ValueError):\n-                k.set_learning_phase(2)\n+            K.set_learning_phase(2)\n \n     def test_eye(self):\n         z_list = [k.eval(k.eye(3)) for k in BACKENDS]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#79a48bd9ac947dd6bfde19f24c4bf88b0002a5a5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 144 | Lines Deleted: 73 | Files Changed: 9 | Hunks: 64 | Methods Changed: 33 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 217 | Churn Cumulative: 6541 | Contributors (this commit): 69 | Commits (past 90d): 21 | Contributors (cumulative): 97 | DMM Complexity: 0.9038461538461539\n\nDIFF:\n@@ -112,7 +112,7 @@ def test_3d_to_3d():\n \n     model = Sequential()\n     model.add(layers.TimeDistributed(\n-        layers.Dense(y_train.shape[-1]), input_shape=(x_train.shape[1], x_train.shape[2])))\n+        layers.Dense(y_train.shape[-1]), input_shape=x_train.shape[1:3]))\n     model.compile(loss='hinge', optimizer='rmsprop')\n     history = model.fit(x_train, y_train, epochs=20, batch_size=16,\n                         validation_data=(x_test, y_test), verbose=0)\n@@ -126,14 +126,18 @@ def test_stacked_lstm_char_prediction():\n     Predict the whole alphabet based on the first two letters ('ab' -> 'ab...z')\n     See non-toy example in examples/lstm_text_generation.py\n     '''\n-    # generate alphabet: http://stackoverflow.com/questions/16060899/alphabet-range-python\n+    # generate alphabet:\n+    # http://stackoverflow.com/questions/16060899/alphabet-range-python\n     alphabet = string.ascii_lowercase\n     number_of_chars = len(alphabet)\n \n-    # generate char sequences of length 'sequence_length' out of alphabet and store the next char as label (e.g. 'ab'->'c')\n+    # generate char sequences of length 'sequence_length' out of alphabet and\n+    # store the next char as label (e.g. 'ab'->'c')\n     sequence_length = 2\n-    sentences = [alphabet[i: i + sequence_length] for i in range(len(alphabet) - sequence_length)]\n-    next_chars = [alphabet[i + sequence_length] for i in range(len(alphabet) - sequence_length)]\n+    sentences = [alphabet[i: i + sequence_length]\n+                 for i in range(len(alphabet) - sequence_length)]\n+    next_chars = [alphabet[i + sequence_length]\n+                  for i in range(len(alphabet) - sequence_length)]\n \n     # Transform sequences and labels into 'one-hot' encoding\n     x = np.zeros((len(sentences), sequence_length, number_of_chars), dtype=np.bool)\n@@ -145,7 +149,8 @@ def test_stacked_lstm_char_prediction():\n \n     # learn the alphabet with stacked LSTM\n     model = Sequential([\n-        layers.LSTM(16, return_sequences=True, input_shape=(sequence_length, number_of_chars)),\n+        layers.LSTM(16, return_sequences=True,\n+                    input_shape=(sequence_length, number_of_chars)),\n         layers.LSTM(16, return_sequences=False),\n         layers.Dense(number_of_chars, activation='softmax')\n     ])\n@@ -206,7 +211,7 @@ def test_masked_temporal():\n     assert(np.abs(history.history['loss'][-1] - ground_truth) < 0.06)\n \n \n-@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TensorFlow backend')\n+@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TF backend')\n @keras_test\n def test_embedding_with_clipnorm():\n     model = Sequential()\n@@ -214,5 +219,6 @@ def test_embedding_with_clipnorm():\n     model.compile(optimizer=optimizers.SGD(clipnorm=0.1), loss='mse')\n     model.fit(np.array([[0]]), np.array([[[0.5]]]), epochs=1)\n \n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n@@ -104,7 +104,8 @@ def test_orthogonal(tensor_shape):\n             target_mean=0.)\n \n \n-@pytest.mark.parametrize('tensor_shape', [(100, 100), (10, 20), (30, 80), (1, 2, 3, 4)],\n+@pytest.mark.parametrize('tensor_shape',\n+                         [(100, 100), (10, 20), (30, 80), (1, 2, 3, 4)],\n                          ids=['FC', 'RNN', 'RNN_INVALID', 'CONV'])\n def test_identity(tensor_shape):\n     if len(tensor_shape) > 2 or max(tensor_shape) % min(tensor_shape) != 0:\n\n@@ -1,5 +1,6 @@\n import pytest\n import numpy as np\n+from numpy.testing import assert_allclose\n \n import keras\n from keras import metrics\n@@ -177,7 +178,8 @@ def test_stateful_metrics(metrics_mode):\n     val_y = np.random.randint(2, size=(val_samples, 1))\n \n     # Test fit and evaluate\n-    history = model.fit(x, y, validation_data=(val_x, val_y), epochs=1, batch_size=10)\n+    history = model.fit(x, y, validation_data=(val_x, val_y),\n+                        epochs=1, batch_size=10)\n     outs = model.evaluate(x, y, batch_size=10)\n     preds = model.predict(x)\n \n@@ -190,14 +192,16 @@ def test_stateful_metrics(metrics_mode):\n     # Test correctness of the validation metric computation\n     val_preds = model.predict(val_x)\n     val_outs = model.evaluate(val_x, val_y, batch_size=10)\n-    np.testing.assert_allclose(val_outs[2], ref_true_pos(val_y, val_preds), atol=1e-5)\n-    np.testing.assert_allclose(val_outs[2], history.history['val_true_positives'][-1], atol=1e-5)\n+    assert_allclose(val_outs[2], ref_true_pos(val_y, val_preds), atol=1e-5)\n+    assert_allclose(val_outs[2], history.history['val_true_positives'][-1],\n+                    atol=1e-5)\n \n     # Test with generators\n     gen = [(np.array([x0]), np.array([y0])) for x0, y0 in zip(x, y)]\n     val_gen = [(np.array([x0]), np.array([y0])) for x0, y0 in zip(val_x, val_y)]\n     history = model.fit_generator(iter(gen), epochs=1, steps_per_epoch=samples,\n-                                  validation_data=iter(val_gen), validation_steps=val_samples)\n+                                  validation_data=iter(val_gen),\n+                                  validation_steps=val_samples)\n     outs = model.evaluate_generator(iter(gen), steps=samples)\n     preds = model.predict_generator(iter(gen), steps=samples)\n \n@@ -207,8 +211,9 @@ def test_stateful_metrics(metrics_mode):\n     # Test correctness of the validation metric computation\n     val_preds = model.predict_generator(iter(val_gen), steps=val_samples)\n     val_outs = model.evaluate_generator(iter(val_gen), steps=val_samples)\n-    np.testing.assert_allclose(val_outs[2], ref_true_pos(val_y, val_preds), atol=1e-5)\n-    np.testing.assert_allclose(val_outs[2], history.history['val_true_positives'][-1], atol=1e-5)\n+    assert_allclose(val_outs[2], ref_true_pos(val_y, val_preds), atol=1e-5)\n+    assert_allclose(val_outs[2], history.history['val_true_positives'][-1],\n+                    atol=1e-5)\n \n \n if __name__ == '__main__':\n\n@@ -76,7 +76,8 @@ def test_no_grad():\n     mod = Model(inp, x)\n     mod.compile('sgd', 'mse')\n     with pytest.raises(ValueError):\n-        mod.fit(np.zeros([10, 3]), np.zeros([10, 1], np.float32), batch_size=10, epochs=10)\n+        mod.fit(np.zeros([10, 3]), np.zeros([10, 1], np.float32),\n+                batch_size=10, epochs=10)\n \n \n @keras_test\n@@ -146,7 +147,8 @@ def test_tfoptimizer():\n     from tensorflow import train\n     optimizer = optimizers.TFOptimizer(train.AdamOptimizer())\n     model = Sequential()\n-    model.add(Dense(num_classes, input_shape=(3,), kernel_constraint=constraints.MaxNorm(1)))\n+    model.add(Dense(num_classes, input_shape=(3,),\n+                    kernel_constraint=constraints.MaxNorm(1)))\n     model.compile(loss='mean_squared_error', optimizer=optimizer)\n     model.fit(np.random.random((5, 3)), np.random.random((5, num_classes)),\n               epochs=1, batch_size=5, verbose=0)\n\n@@ -3,6 +3,7 @@ import multiprocessing\n \n import numpy as np\n import pytest\n+from numpy.testing import assert_allclose\n from csv import reader\n from csv import Sniffer\n import shutil\n@@ -12,7 +13,9 @@ from keras import callbacks\n from keras.models import Sequential, Model\n from keras.layers import Input, Dense, Dropout, add, dot, Lambda, Layer\n from keras.layers.convolutional import Conv2D\n-from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling1D, GlobalAveragePooling2D\n+from keras.layers.pooling import MaxPooling2D\n+from keras.layers.pooling import GlobalAveragePooling1D\n+from keras.layers.pooling import GlobalAveragePooling2D\n from keras.utils.test_utils import get_test_data\n from keras.utils.test_utils import keras_test\n from keras import backend as K\n@@ -104,7 +107,8 @@ def test_stop_training_csv(tmpdir):\n         tot = 0\n         while 1:\n             if tot > 3 * len(X_train):\n-                yield np.ones([batch_size, input_dim]) * np.nan, np.ones([batch_size, num_classes]) * np.nan\n+                yield (np.ones([batch_size, input_dim]) * np.nan,\n+                       np.ones([batch_size, num_classes]) * np.nan)\n             else:\n                 yield (X_train[i * batch_size: (i + 1) * batch_size],\n                        y_train[i * batch_size: (i + 1) * batch_size])\n@@ -278,7 +282,8 @@ def test_EarlyStopping_patience():\n \n     losses = [0.0860, 0.1096, 0.1040, 0.1019]\n \n-    # Should stop after epoch 3, as the loss has not improved after patience=2 epochs.\n+    # Should stop after epoch 3,\n+    # as the loss has not improved after patience=2 epochs.\n     epochs_trained = 0\n     early_stop.on_train_begin()\n \n@@ -305,7 +310,8 @@ def test_EarlyStopping_baseline():\n             pass\n \n     def baseline_tester(acc_levels):\n-        early_stop = callbacks.EarlyStopping(monitor='val_acc', baseline=0.75, patience=2)\n+        early_stop = callbacks.EarlyStopping(monitor='val_acc', baseline=0.75,\n+                                             patience=2)\n         early_stop.model = DummyModel()\n         epochs_trained = 0\n         early_stop.on_train_begin()\n@@ -453,16 +459,18 @@ def test_ReduceLROnPlateau():\n     model = make_model()\n \n     # This should reduce the LR after the first epoch (due to high epsilon).\n-    cbks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, min_delta=10, patience=1, cooldown=5)]\n+    cbks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n+                                        min_delta=10, patience=1, cooldown=5)]\n     model.fit(X_train, y_train, batch_size=batch_size,\n               validation_data=(X_test, y_test), callbacks=cbks, epochs=5, verbose=2)\n-    assert np.allclose(float(K.get_value(model.optimizer.lr)), 0.01, atol=K.epsilon())\n+    assert_allclose(float(K.get_value(model.optimizer.lr)), 0.01, atol=K.epsilon())\n \n     model = make_model()\n-    cbks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, min_delta=0, patience=1, cooldown=5)]\n+    cbks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n+                                        min_delta=0, patience=1, cooldown=5)]\n     model.fit(X_train, y_train, batch_size=batch_size,\n               validation_data=(X_test, y_test), callbacks=cbks, epochs=5, verbose=2)\n-    assert np.allclose(float(K.get_value(model.optimizer.lr)), 0.1, atol=K.epsilon())\n+    assert_allclose(float(K.get_value(model.optimizer.lr)), 0.1, atol=K.epsilon())\n \n \n @keras_test\n@@ -757,7 +765,8 @@ def test_TensorBoard_multi_input_output(tmpdir):\n     inp2 = Input((input_dim, input_dim))\n     inp_3d = add([inp1, inp2])\n     inp_2d = GlobalAveragePooling1D()(inp_3d)\n-    inp_pair = Lambda(lambda x: x)([inp_3d, inp_2d])  # test a layer with a list of output tensors\n+    # test a layer with a list of output tensors\n+    inp_pair = Lambda(lambda x: x)([inp_3d, inp_2d])\n     hidden = dot(inp_pair, axes=-1)\n     hidden = Dense(num_hidden, activation='relu')(hidden)\n     hidden = Dropout(0.1)(hidden)\n@@ -910,14 +919,16 @@ def test_LambdaCallback():\n                   optimizer='sgd',\n                   metrics=['accuracy'])\n \n-    # Start an arbitrary process that should run during model training and be terminated after training has completed.\n+    # Start an arbitrary process that should run during model training and\n+    # be terminated after training has completed.\n     def f():\n         while True:\n             pass\n \n     p = multiprocessing.Process(target=f)\n     p.start()\n-    cleanup_callback = callbacks.LambdaCallback(on_train_end=lambda logs: p.terminate())\n+    cleanup_callback = callbacks.LambdaCallback(\n+        on_train_end=lambda logs: p.terminate())\n \n     cbks = [cleanup_callback]\n     model.fit(X_train, y_train, batch_size=batch_size,\n\n@@ -79,9 +79,11 @@ def test_sequential_fit_generator():\n         i = 0\n         while 1:\n             if train:\n-                yield (x_train[i * batch_size: (i + 1) * batch_size], y_train[i * batch_size: (i + 1) * batch_size])\n+                yield (x_train[i * batch_size: (i + 1) * batch_size],\n+                       y_train[i * batch_size: (i + 1) * batch_size])\n             else:\n-                yield (x_test[i * batch_size: (i + 1) * batch_size], y_test[i * batch_size: (i + 1) * batch_size])\n+                yield (x_test[i * batch_size: (i + 1) * batch_size],\n+                       y_test[i * batch_size: (i + 1) * batch_size])\n             i += 1\n             i = i % max_batch_index\n \n@@ -126,18 +128,24 @@ def test_sequential(in_tmpdir):\n     model.add(Activation('softmax'))\n     model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n \n-    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n-    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=2, validation_split=0.1)\n+    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n+              validation_data=(x_test, y_test))\n+    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=2,\n+              validation_split=0.1)\n     model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n-    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, shuffle=False)\n+    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n+              shuffle=False)\n \n     model.train_on_batch(x_train[:32], y_train[:32])\n \n     loss = model.evaluate(x_test, y_test)\n \n-    prediction = model.predict_generator(data_generator(x_test, y_test), 1, max_queue_size=2, verbose=1)\n-    gen_loss = model.evaluate_generator(data_generator(x_test, y_test, 50), 1, max_queue_size=2)\n-    pred_loss = K.eval(K.mean(losses.get(model.loss)(K.variable(y_test), K.variable(prediction))))\n+    prediction = model.predict_generator(data_generator(x_test, y_test), 1,\n+                                         max_queue_size=2, verbose=1)\n+    gen_loss = model.evaluate_generator(data_generator(x_test, y_test, 50), 1,\n+                                        max_queue_size=2)\n+    pred_loss = K.eval(K.mean(losses.get(model.loss)(K.variable(y_test),\n+                                                     K.variable(prediction))))\n \n     assert(np.isclose(pred_loss, loss))\n     assert(np.isclose(gen_loss, loss))\n@@ -189,10 +197,13 @@ def test_nested_sequential(in_tmpdir):\n     model.add(Activation('softmax'))\n     model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n \n-    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n-    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=2, validation_split=0.1)\n+    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n+              validation_data=(x_test, y_test))\n+    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=2,\n+              validation_split=0.1)\n     model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n-    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, shuffle=False)\n+    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n+              shuffle=False)\n \n     model.train_on_batch(x_train[:32], y_train[:32])\n \n\n@@ -49,7 +49,8 @@ def assert_doc_style(name, member, doc):\n     lines = doc.split(\"\\n\")\n     first_line = lines[0]\n     if len(first_line.strip()) == 0:\n-        raise ValueError(\"{} the documentation should be on the first line.\".format(name),\n+        raise ValueError(\n+            \"{} the documentation should be on the first line.\".format(name),\n             member.__module__)\n     if first_line.strip()[-1] != '.':\n         raise ValueError(\"{} first line should end with a '.'\".format(name),\n@@ -118,8 +119,10 @@ def assert_args_presence(args, doc, member, name):\n     styles = [arg + \":\" not in words for arg in args]\n     if any(styles):\n         raise ValueError(\n-            \"{} {} are not style properly 'argument': documentation\".format(name, list(\n-                compress(args, styles))), member.__module__)\n+            \"{} {} are not style properly 'argument': documentation\".format(\n+                name,\n+                list(compress(args, styles))),\n+            member.__module__)\n \n     # Check arguments order\n     indexes = [words.index(arg + \":\") for arg in args]\n\n@@ -52,7 +52,8 @@ def _get_test_data():\n     sample_weight = np.ones((y_train.shape[0])) * standard_weight\n     sample_weight[int_y_train == weighted_class] = high_weight\n \n-    return (x_train, y_train), (x_test, y_test), (sample_weight, class_weight, test_ids)\n+    return ((x_train, y_train), (x_test, y_test),\n+            (sample_weight, class_weight, test_ids))\n \n \n def create_sequential_model():\n@@ -77,7 +78,8 @@ def test_sequential_class_weights():\n     model = create_sequential_model()\n     model.compile(loss=loss, optimizer='rmsprop')\n \n-    (x_train, y_train), (x_test, y_test), (sample_weight, class_weight, test_ids) = _get_test_data()\n+    ((x_train, y_train), (x_test, y_test),\n+     (sample_weight, class_weight, test_ids)) = _get_test_data()\n \n     model.fit(x_train, y_train, batch_size=batch_size,\n               epochs=epochs // 3, verbose=0,\n@@ -102,7 +104,8 @@ def test_sequential_sample_weights():\n     model = create_sequential_model()\n     model.compile(loss=loss, optimizer='rmsprop')\n \n-    (x_train, y_train), (x_test, y_test), (sample_weight, class_weight, test_ids) = _get_test_data()\n+    ((x_train, y_train), (x_test, y_test),\n+     (sample_weight, class_weight, test_ids)) = _get_test_data()\n \n     model.fit(x_train, y_train, batch_size=batch_size,\n               epochs=epochs // 3, verbose=0,\n@@ -122,7 +125,8 @@ def test_sequential_sample_weights():\n \n @keras_test\n def test_sequential_temporal_sample_weights():\n-    (x_train, y_train), (x_test, y_test), (sample_weight, class_weight, test_ids) = _get_test_data()\n+    ((x_train, y_train), (x_test, y_test),\n+     (sample_weight, class_weight, test_ids)) = _get_test_data()\n \n     temporal_x_train = np.reshape(x_train, (len(x_train), 1, x_train.shape[1]))\n     temporal_x_train = np.repeat(temporal_x_train, timesteps, axis=1)\n@@ -153,7 +157,8 @@ def test_sequential_temporal_sample_weights():\n                          sample_weight=temporal_sample_weight[:32])\n     model.test_on_batch(temporal_x_train[:32], temporal_y_train[:32],\n                         sample_weight=temporal_sample_weight[:32])\n-    score = model.evaluate(temporal_x_test[test_ids], temporal_y_test[test_ids], verbose=0)\n+    score = model.evaluate(temporal_x_test[test_ids], temporal_y_test[test_ids],\n+                           verbose=0)\n     assert(score < standard_score_sequential)\n \n \n@@ -162,16 +167,19 @@ def test_weighted_metrics_with_sample_weight():\n     decimal = decimal_precision[K.backend()]\n \n     model = create_sequential_model()\n-    model.compile(loss=loss, optimizer='rmsprop', metrics=[loss], weighted_metrics=[loss])\n+    model.compile(loss=loss, optimizer='rmsprop',\n+                  metrics=[loss], weighted_metrics=[loss])\n \n-    (x_train, y_train), (x_test, y_test), (sample_weight, class_weight, test_ids) = _get_test_data()\n+    ((x_train, y_train), (x_test, y_test),\n+     (sample_weight, class_weight, test_ids)) = _get_test_data()\n \n     history = model.fit(x_train, y_train, batch_size=batch_size,\n                         epochs=epochs // 3, verbose=0,\n                         sample_weight=sample_weight)\n \n     h = history.history\n-    assert_array_almost_equal(h['loss'], h['weighted_' + loss_full_name], decimal=decimal)\n+    assert_array_almost_equal(h['loss'], h['weighted_' + loss_full_name],\n+                              decimal=decimal)\n \n     history = model.fit(x_train, y_train, batch_size=batch_size,\n                         epochs=epochs // 3, verbose=0,\n@@ -179,7 +187,8 @@ def test_weighted_metrics_with_sample_weight():\n                         validation_split=0.1)\n \n     h = history.history\n-    assert_almost_equal(h['val_loss'], h['val_weighted_' + loss_full_name], decimal=decimal)\n+    assert_almost_equal(h['val_loss'], h['val_weighted_' + loss_full_name],\n+                        decimal=decimal)\n \n     model.train_on_batch(x_train[:32], y_train[:32],\n                          sample_weight=sample_weight[:32])\n@@ -189,7 +198,8 @@ def test_weighted_metrics_with_sample_weight():\n     test_sample_weight = np.ones((y_test.shape[0])) * standard_weight\n     test_sample_weight[test_ids] = high_weight\n \n-    scores = model.evaluate(x_test, y_test, verbose=0, sample_weight=test_sample_weight)\n+    scores = model.evaluate(x_test, y_test, verbose=0,\n+                            sample_weight=test_sample_weight)\n     loss_score, metric_score, weighted_metric_score = scores\n \n     assert loss_score < standard_score_sequential\n@@ -202,7 +212,8 @@ def test_weighted_metrics_with_no_sample_weight():\n     decimal = decimal_precision[K.backend()]\n \n     model = create_sequential_model()\n-    model.compile(loss=loss, optimizer='rmsprop', metrics=[loss], weighted_metrics=[loss])\n+    model.compile(loss=loss, optimizer='rmsprop',\n+                  metrics=[loss], weighted_metrics=[loss])\n \n     (x_train, y_train), (x_test, y_test), _ = _get_test_data()\n \n@@ -211,14 +222,17 @@ def test_weighted_metrics_with_no_sample_weight():\n \n     h = history.history\n     assert_array_almost_equal(h['loss'], h[loss_full_name], decimal=decimal)\n-    assert_array_almost_equal(h['loss'], h['weighted_' + loss_full_name], decimal=decimal)\n+    assert_array_almost_equal(h['loss'], h['weighted_' + loss_full_name],\n+                              decimal=decimal)\n \n     history = model.fit(x_train, y_train, batch_size=batch_size,\n                         epochs=epochs // 3, verbose=0, validation_split=0.1)\n \n     h = history.history\n-    assert_array_almost_equal(h['val_loss'], h['val_' + loss_full_name], decimal=decimal)\n-    assert_array_almost_equal(h['val_loss'], h['val_weighted_' + loss_full_name], decimal=decimal)\n+    assert_array_almost_equal(h['val_loss'], h['val_' + loss_full_name],\n+                              decimal=decimal)\n+    assert_array_almost_equal(h['val_loss'], h['val_weighted_' + loss_full_name],\n+                              decimal=decimal)\n \n     model.train_on_batch(x_train[:32], y_train[:32])\n     model.test_on_batch(x_train[:32], y_train[:32])\n@@ -233,7 +247,8 @@ def test_weighted_metrics_with_no_sample_weight():\n @keras_test\n def test_weighted_metrics_with_weighted_accuracy_metric():\n     model = create_sequential_model()\n-    model.compile(loss=loss, optimizer='rmsprop', metrics=['acc'], weighted_metrics=['acc'])\n+    model.compile(loss=loss, optimizer='rmsprop',\n+                  metrics=['acc'], weighted_metrics=['acc'])\n \n     (x_train, y_train), _, (sample_weight, _, _) = _get_test_data()\n \n@@ -259,7 +274,8 @@ def test_weighted_metrics_with_multiple_outputs():\n     weighted_metrics = {'output2': [loss]}\n     loss_map = {'output1': loss, 'output2': loss}\n \n-    model.compile(loss=loss_map, optimizer='sgd', metrics=metrics, weighted_metrics=weighted_metrics)\n+    model.compile(loss=loss_map, optimizer='sgd',\n+                  metrics=metrics, weighted_metrics=weighted_metrics)\n \n     x = np.array([[1, 1, 1, 1, 1]])\n     y = {'output1': np.array([0]), 'output2': np.array([1])}\n@@ -278,7 +294,8 @@ def test_class_weight_wrong_classes():\n     model = create_sequential_model()\n     model.compile(loss=loss, optimizer='rmsprop')\n \n-    (x_train, y_train), (x_test, y_test), (sample_weight, class_weight, test_ids) = _get_test_data()\n+    ((x_train, y_train), (x_test, y_test),\n+     (sample_weight, class_weight, test_ids)) = _get_test_data()\n \n     del class_weight[1]\n     with pytest.raises(ValueError):\n\n@@ -9,7 +9,8 @@ from numpy.testing import assert_raises\n from keras import backend as K\n from keras.engine.saving import preprocess_weights_for_loading\n from keras.models import Model, Sequential\n-from keras.layers import Dense, Lambda, RepeatVector, TimeDistributed, Bidirectional, GRU, LSTM, CuDNNGRU, CuDNNLSTM\n+from keras.layers import Dense, Lambda, RepeatVector, TimeDistributed\n+from keras.layers import Bidirectional, GRU, LSTM, CuDNNGRU, CuDNNLSTM\n from keras.layers import Conv2D, Flatten\n from keras.layers import Input, InputLayer\n from keras.initializers import Constant\n@@ -21,7 +22,8 @@ from keras.models import save_model, load_model\n \n \n skipif_no_tf_gpu = pytest.mark.skipif(\n-    (K.backend() != 'tensorflow') or (not K.tensorflow_backend._get_available_gpus()),\n+    (K.backend() != 'tensorflow' or\n+     not K.tensorflow_backend._get_available_gpus()),\n     reason='Requires TensorFlow backend and a GPU')\n \n \n@@ -601,8 +603,9 @@ def test_saving_model_with_long_weights_names():\n     # Check that the HDF5 files contains chunked array\n     # of weight names.\n     with h5py.File(fname, 'r') as h5file:\n-        n_weight_names_arrays = len([attr for attr in h5file['model_weights']['nested_model'].attrs\n-                                     if attr.startswith('weight_names')])\n+        attrs = [attr for attr in h5file['model_weights']['nested_model'].attrs\n+                 if attr.startswith('weight_names')]\n+        n_weight_names_arrays = len(attrs)\n \n     os.remove(fname)\n \n@@ -651,10 +654,11 @@ def test_saving_recurrent_layer_without_bias():\n \n @keras_test\n def test_saving_constant_initializer_with_numpy():\n-    \"\"\"Test saving and loading model of constant initializer with numpy ndarray as input.\n+    \"\"\"Test saving and loading model of constant initializer with numpy inputs.\n     \"\"\"\n     model = Sequential()\n-    model.add(Dense(2, input_shape=(3,), kernel_initializer=Constant(np.ones((3, 2)))))\n+    model.add(Dense(2, input_shape=(3,),\n+                    kernel_initializer=Constant(np.ones((3, 2)))))\n     model.add(Dense(3))\n     model.compile(loss='mse', optimizer='sgd', metrics=['acc'])\n \n@@ -666,14 +670,21 @@ def test_saving_constant_initializer_with_numpy():\n \n @keras_test\n @pytest.mark.parametrize('implementation', [1, 2], ids=['impl1', 'impl2'])\n-@pytest.mark.parametrize('bidirectional', [False, True], ids=['single', 'bidirectional'])\n+@pytest.mark.parametrize('bidirectional',\n+                         [False, True],\n+                         ids=['single', 'bidirectional'])\n @pytest.mark.parametrize('to_cudnn', [False, True], ids=['from_cudnn', 'to_cudnn'])\n @pytest.mark.parametrize('rnn_type', ['LSTM', 'GRU'], ids=['LSTM', 'GRU'])\n-@pytest.mark.parametrize('model_nest_level', [1, 2], ids=['model_plain', 'model_nested'])\n-@pytest.mark.parametrize('model_type', ['func', 'seq'], ids=['model_func', 'model_seq'])\n+@pytest.mark.parametrize('model_nest_level',\n+                         [1, 2],\n+                         ids=['model_plain', 'model_nested'])\n+@pytest.mark.parametrize('model_type',\n+                         ['func', 'seq'],\n+                         ids=['model_func', 'model_seq'])\n @skipif_no_tf_gpu\n-def test_load_weights_between_noncudnn_rnn(rnn_type, to_cudnn, bidirectional, implementation,\n-                                           model_nest_level, model_type):\n+def test_load_weights_between_noncudnn_rnn(rnn_type, to_cudnn, bidirectional,\n+                                           implementation, model_nest_level,\n+                                           model_type):\n     input_size = 10\n     timesteps = 6\n     input_shape = (timesteps, input_size)\n@@ -704,7 +715,8 @@ def test_load_weights_between_noncudnn_rnn(rnn_type, to_cudnn, bidirectional, im\n         cudnn_layer = Bidirectional(cudnn_layer)\n \n     model = _make_nested_model(input_shape, layer, model_nest_level, model_type)\n-    cudnn_model = _make_nested_model(input_shape, cudnn_layer, model_nest_level, model_type)\n+    cudnn_model = _make_nested_model(input_shape, cudnn_layer,\n+                                     model_nest_level, model_type)\n \n     if to_cudnn:\n         _convert_model_weights(model, cudnn_model)\n@@ -807,7 +819,8 @@ def test_preprocess_weights_for_loading_gru_incompatible():\n \n     def assert_not_compatible(src, dest, message):\n         with pytest.raises(ValueError) as ex:\n-            preprocess_weights_for_loading(dest, initialize_weights(src).get_weights())\n+            preprocess_weights_for_loading(dest,\n+                                           initialize_weights(src).get_weights())\n         assert message in ex.value.message\n \n     assert_not_compatible(gru(), gru(cudnn=True),\n@@ -815,9 +828,11 @@ def test_preprocess_weights_for_loading_gru_incompatible():\n     assert_not_compatible(gru(cudnn=True), gru(),\n                           'CuDNNGRU is not compatible with GRU(reset_after=False)')\n     assert_not_compatible(gru(), gru(reset_after=True),\n-                          'GRU(reset_after=False) is not compatible with GRU(reset_after=True)')\n+                          'GRU(reset_after=False) is not compatible with '\n+                          'GRU(reset_after=True)')\n     assert_not_compatible(gru(reset_after=True), gru(),\n-                          'GRU(reset_after=True) is not compatible with GRU(reset_after=False)')\n+                          'GRU(reset_after=True) is not compatible with '\n+                          'GRU(reset_after=False)')\n \n \n if __name__ == '__main__':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
