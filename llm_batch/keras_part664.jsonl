{"custom_id": "keras#f0b99c51cf7adb600e064480ae60c52c4bf44bb2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 250 | Contributors (this commit): 2 | Commits (past 90d): 14 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -154,7 +154,7 @@ class Metric:\n         mapping = list(zip(self.variables, metric_variables))\n \n         # Call in stateless scope\n-        with backend.StatelessScope(state_mapping=mapping) as scope:\n+        with backend.StatelessScope(state_mapping=mapping):\n             res = self.result()\n         return res\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d999c2165c03d925a94ef258b584c43c2eb43219", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 30 | Churn Cumulative: 3077 | Contributors (this commit): 8 | Commits (past 90d): 73 | Contributors (cumulative): 10 | DMM Complexity: 0.5714285714285714\n\nDIFF:\n@@ -101,11 +101,13 @@ class TorchTrainer(base_trainer.Trainer):\n             data = data[0]\n             return self.train_step(data)\n \n-        if not self.run_eagerly:\n-            # Temporarily commented the torch compile due to failed unit tests.\n+        if self.jit_compile:\n+            raise ValueError(\n+                \"`jit_compile` is not yet enabled for the PyTorch backend.\"\n+            )\n+            # Temporarily disabled torch compile due to failed unit tests.\n             # TODO: Uncomment the following line when unit tests passes.\n             # self.train_function = torch.compile(one_step_on_data)\n-            self.train_function = one_step_on_data\n         else:\n             self.train_function = one_step_on_data\n \n\n@@ -51,10 +51,10 @@ class Trainer:\n         else:\n             self._compile_metrics = None\n         if jit_compile == \"auto\":\n-            if not run_eagerly and model_supports_jit(self):\n-                jit_compile = True\n-            else:\n+            if run_eagerly:\n                 jit_compile = False\n+            else:\n+                jit_compile = resolve_auto_jit_compile(self)\n         if jit_compile and run_eagerly:\n             jit_compile = False\n             warnings.warn(\n@@ -62,6 +62,12 @@ class Trainer:\n                 \"cannot also be True. Disabling `jit_compile`.\",\n                 stacklevel=2,\n             )\n+        if jit_compile and backend.backend() == \"torch\":\n+            warnings.warn(\n+                \"`jit_compile` is not yet enabled for the PyTorch backend. \"\n+                \"Proceeding with `jit_compile=False`.\"\n+            )\n+            jit_compile = False\n         self.jit_compile = jit_compile\n         self.run_eagerly = run_eagerly\n         self.stop_training = False\n@@ -748,6 +754,16 @@ class Trainer:\n             raise ValueError(msg)\n \n \n+def resolve_auto_jit_compile(model):\n+    if model_supports_jit(model):\n+        if backend.backend() == \"torch\":\n+            # Torch defaults to eager mode\n+            # until torch compile is reliable\n+            return False\n+        return True\n+    return False\n+\n+\n def model_supports_jit(model):\n     if platform.system() == \"Darwin\" and \"arm\" in platform.processor().lower():\n         if backend.backend() == \"tensorflow\":\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#64fd98390fc43b41ec1cafbea6ce684613ad3538", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 632 | Contributors (this commit): 6 | Commits (past 90d): 18 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -96,7 +96,9 @@ def append(\n \n \n def arange(start, stop=None, step=1, dtype=None):\n-    return tfnp.arange(start, stop, step=step, dtype=dtype)\n+    # tfnp.arange has trouble with dynamic Tensors in compiled function.\n+    # tf.range does not.\n+    return tf.range(start, stop, delta=step, dtype=dtype)\n \n \n def arccos(x):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a00ee5bf37f3d59532af5546d12624673bfd4265", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 9 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 30 | Churn Cumulative: 1150 | Contributors (this commit): 4 | Commits (past 90d): 18 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -3,6 +3,7 @@ from keras_core import initializers\n from keras_core import ops\n from keras_core import regularizers\n from keras_core.api_export import keras_core_export\n+from keras_core.backend import standardize_dtype\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n \n@@ -188,6 +189,12 @@ class BatchNormalization(Layer):\n         return input_shape\n \n     def call(self, inputs, training=None, mask=None):\n+        input_dtype = standardize_dtype(inputs.dtype)\n+        if input_dtype in (\"float16\", \"bfloat16\"):\n+            # BN is prone to overflowing for float16/bfloat16 inputs, so we opt\n+            # out BN for mixed precision.\n+            inputs = ops.cast(inputs, \"float32\")\n+\n         broadcast_shape = [1] * len(inputs.shape)\n         broadcast_shape[self.axis] = inputs.shape[self.axis]\n         if training and self.trainable:\n@@ -198,12 +205,20 @@ class BatchNormalization(Layer):\n             outputs = (inputs - mean) / ops.sqrt(variance + self.epsilon)\n             mean = ops.squeeze(mean, self._reduction_axes)\n             variance = ops.squeeze(variance, self._reduction_axes)\n+            moving_mean = ops.cast(self.moving_mean, inputs.dtype)\n+            moving_variance = ops.cast(self.moving_variance, inputs.dtype)\n             self.moving_mean.assign(\n-                self.moving_mean * self.momentum + mean * (1.0 - self.momentum)\n+                ops.cast(\n+                    moving_mean * self.momentum + mean * (1.0 - self.momentum),\n+                    inputs.dtype,\n+                )\n             )\n             self.moving_variance.assign(\n-                self.moving_variance * self.momentum\n-                + variance * (1.0 - self.momentum)\n+                ops.cast(\n+                    moving_variance * self.momentum\n+                    + variance * (1.0 - self.momentum),\n+                    inputs.dtype,\n+                )\n             )\n         else:\n             moving_mean = ops.reshape(self.moving_mean, broadcast_shape)\n@@ -213,9 +228,11 @@ class BatchNormalization(Layer):\n             )\n         if self.scale:\n             gamma = ops.reshape(self.gamma, broadcast_shape)\n+            gamma = ops.cast(gamma, outputs.dtype)\n             outputs = outputs * gamma\n         if self.center:\n             beta = ops.reshape(self.beta, broadcast_shape)\n+            beta = ops.cast(beta, outputs.dtype)\n             outputs = outputs + beta\n         return outputs\n \n\n@@ -205,9 +205,12 @@ class LayerNormalization(Layer):\n         # Compute the batch normalization.\n         inv = 1 / ops.sqrt(variance + self.epsilon)\n         if scale is not None:\n+            scale = ops.cast(scale, inputs.dtype)\n             inv = inv * scale\n-\n-        x = offset - mean * inv if offset is not None else -mean * inv\n+        x = -mean * inv\n+        if offset is not None:\n+            offset = ops.cast(offset, inputs.dtype)\n+            x = offset + x\n         outputs = inputs * ops.cast(inv, inputs.dtype) + ops.cast(\n             x, inputs.dtype\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#55dd36129686ac277314aaa86fc52364d6339f85", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 636 | Contributors (this commit): 6 | Commits (past 90d): 19 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -446,7 +446,9 @@ def reciprocal(x):\n \n \n def repeat(x, repeats, axis=None):\n-    return tfnp.repeat(x, repeats, axis=axis)\n+    # tfnp.repeat has trouble with dynamic Tensors in compiled function.\n+    # tf.repeat does not.\n+    return tf.repeat(x, repeats, axis=axis)\n \n \n def reshape(x, new_shape):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bbe7c8aad0a7abd116e79330213d51ad62112bdf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 200 | Lines Deleted: 86 | Files Changed: 14 | Hunks: 67 | Methods Changed: 23 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 286 | Churn Cumulative: 8034 | Contributors (this commit): 10 | Commits (past 90d): 81 | Contributors (cumulative): 33 | DMM Complexity: 1.0\n\nDIFF:\n@@ -98,6 +98,7 @@ train(model, train_loader, num_epochs, optimizer, loss_fn)\n ######## Using a Keras model or layer in a torch Module ########\n ################################################################\n \n+\n class MyModel(nn.Module):\n     def __init__(self):\n         super().__init__()\n\n@@ -157,7 +157,12 @@ devices = mesh_utils.create_device_mesh((8,))\n # data will be split along the batch axis\n data_mesh = Mesh(devices, axis_names=(\"batch\",))  # naming axes of the mesh\n # naming axes of the sharded partition\n-data_sharding = NamedSharding(data_mesh,P(\"batch\",),)\n+data_sharding = NamedSharding(\n+    data_mesh,\n+    P(\n+        \"batch\",\n+    ),\n+)\n \n # all variables will be replicated on all devices\n var_mesh = Mesh(devices, axis_names=(\"_\"))\n\n@@ -40,6 +40,7 @@ from zipfile import ZipFile\n import keras_core as keras\n from keras_core import layers\n from keras_core import ops\n+\n \"\"\"\n ## First, load the data and apply preprocessing\n \"\"\"\n@@ -97,7 +98,11 @@ print(\n df = df.sample(frac=1, random_state=42)\n x = df[[\"user\", \"movie\"]].values\n # Normalize the targets between 0 and 1. Makes it easy to train.\n-y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n+y = (\n+    df[\"rating\"]\n+    .apply(lambda x: (x - min_rating) / (max_rating - min_rating))\n+    .values\n+)\n # Assuming training on 90% of the data and validating on 10%.\n train_indices = int(0.9 * df.shape[0])\n x_train, x_val, y_train, y_val = (\n@@ -204,7 +209,8 @@ user_movie_array = np.hstack(\n ratings = model.predict(user_movie_array).flatten()\n top_ratings_indices = ratings.argsort()[-10:][::-1]\n recommended_movie_ids = [\n-    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n+    movie_encoded2movie.get(movies_not_watched[x][0])\n+    for x in top_ratings_indices\n ]\n \n print(\"Showing recommendations for user: {}\".format(user_id))\n\n@@ -178,7 +178,9 @@ splitting scheme (split on whitespace).\n \n def custom_standardization(input_string):\n     lowercase = tf.strings.lower(input_string)\n-    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n+    return tf.strings.regex_replace(\n+        lowercase, \"[%s]\" % re.escape(strip_chars), \"\"\n+    )\n \n \n strip_chars = \"!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\n@@ -263,7 +265,9 @@ def get_cnn_model():\n     # We freeze our feature extractor\n     base_model.trainable = False\n     base_model_out = base_model.output\n-    base_model_out = layers.Reshape((-1, base_model_out.shape[-1]))(base_model_out)\n+    base_model_out = layers.Reshape((-1, base_model_out.shape[-1]))(\n+        base_model_out\n+    )\n     cnn_model = keras.models.Model(base_model.input, base_model_out)\n     return cnn_model\n \n@@ -342,7 +346,9 @@ class TransformerDecoderBlock(layers.Layer):\n         self.layernorm_3 = layers.LayerNormalization()\n \n         self.embedding = PositionalEmbedding(\n-            embed_dim=EMBED_DIM, sequence_length=SEQ_LENGTH, vocab_size=VOCAB_SIZE\n+            embed_dim=EMBED_DIM,\n+            sequence_length=SEQ_LENGTH,\n+            vocab_size=VOCAB_SIZE,\n         )\n         self.out = layers.Dense(VOCAB_SIZE, activation=\"softmax\")\n \n@@ -394,7 +400,10 @@ class TransformerDecoderBlock(layers.Layer):\n         mask = tf.cast(i >= j, dtype=\"int32\")\n         mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n         mult = tf.concat(\n-            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n+            [\n+                tf.expand_dims(batch_size, -1),\n+                tf.constant([1, 1], dtype=tf.int32),\n+            ],\n             axis=0,\n         )\n         return tf.tile(mask, mult)\n@@ -431,7 +440,9 @@ class ImageCaptioningModel(keras.Model):\n         mask = tf.cast(mask, dtype=tf.float32)\n         return tf.reduce_sum(accuracy) / tf.reduce_sum(mask)\n \n-    def _compute_caption_loss_and_acc(self, img_embed, batch_seq, training=True):\n+    def _compute_caption_loss_and_acc(\n+        self, img_embed, batch_seq, training=True\n+    ):\n         encoder_out = self.encoder(img_embed, training=training)\n         batch_seq_inp = batch_seq[:, :-1]\n         batch_seq_true = batch_seq[:, 1:]\n@@ -469,7 +480,8 @@ class ImageCaptioningModel(keras.Model):\n \n             # 4. Get the list of all the trainable weights\n             train_vars = (\n-                self.encoder.trainable_variables + self.decoder.trainable_variables\n+                self.encoder.trainable_variables\n+                + self.decoder.trainable_variables\n             )\n \n             # 5. Get the gradients\n@@ -484,7 +496,10 @@ class ImageCaptioningModel(keras.Model):\n         self.acc_tracker.update_state(batch_acc)\n \n         # 8. Return the loss and accuracy values\n-        return {\"loss\": self.loss_tracker.result(), \"acc\": self.acc_tracker.result()}\n+        return {\n+            \"loss\": self.loss_tracker.result(),\n+            \"acc\": self.acc_tracker.result(),\n+        }\n \n     def test_step(self, batch_data):\n         batch_img, batch_seq = batch_data\n@@ -513,7 +528,10 @@ class ImageCaptioningModel(keras.Model):\n         self.acc_tracker.update_state(batch_acc)\n \n         # 5. Return the loss and accuracy values\n-        return {\"loss\": self.loss_tracker.result(), \"acc\": self.acc_tracker.result()}\n+        return {\n+            \"loss\": self.loss_tracker.result(),\n+            \"acc\": self.acc_tracker.result(),\n+        }\n \n     @property\n     def metrics(self):\n@@ -523,8 +541,12 @@ class ImageCaptioningModel(keras.Model):\n \n \n cnn_model = get_cnn_model()\n-encoder = TransformerEncoderBlock(embed_dim=EMBED_DIM, dense_dim=FF_DIM, num_heads=1)\n-decoder = TransformerDecoderBlock(embed_dim=EMBED_DIM, ff_dim=FF_DIM, num_heads=2)\n+encoder = TransformerEncoderBlock(\n+    embed_dim=EMBED_DIM, dense_dim=FF_DIM, num_heads=1\n+)\n+decoder = TransformerDecoderBlock(\n+    embed_dim=EMBED_DIM, ff_dim=FF_DIM, num_heads=2\n+)\n caption_model = ImageCaptioningModel(\n     cnn_model=cnn_model,\n     encoder=encoder,\n@@ -539,15 +561,20 @@ caption_model = ImageCaptioningModel(\n \n # Define the loss function\n cross_entropy = keras.losses.SparseCategoricalCrossentropy(\n-    from_logits=False, reduction=None,\n+    from_logits=False,\n+    reduction=None,\n )\n \n # EarlyStopping criteria\n-early_stopping = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n+early_stopping = keras.callbacks.EarlyStopping(\n+    patience=3, restore_best_weights=True\n+)\n \n \n # Learning Rate Scheduler for the optimizer\n-class LRSchedule(keras.optimizers.schedules.learning_rate_schedule.LearningRateSchedule):\n+class LRSchedule(\n+    keras.optimizers.schedules.learning_rate_schedule.LearningRateSchedule\n+):\n     def __init__(self, post_warmup_learning_rate, warmup_steps):\n         super().__init__()\n         self.post_warmup_learning_rate = post_warmup_learning_rate\n@@ -568,10 +595,14 @@ class LRSchedule(keras.optimizers.schedules.learning_rate_schedule.LearningRateS\n # Create a learning rate schedule\n num_train_steps = len(train_dataset) * EPOCHS\n num_warmup_steps = num_train_steps // 15\n-lr_schedule = LRSchedule(post_warmup_learning_rate=1e-4, warmup_steps=num_warmup_steps)\n+lr_schedule = LRSchedule(\n+    post_warmup_learning_rate=1e-4, warmup_steps=num_warmup_steps\n+)\n \n # Compile the model\n-caption_model.compile(optimizer=keras.optimizers.Adam(lr_schedule), loss=cross_entropy)\n+caption_model.compile(\n+    optimizer=keras.optimizers.Adam(lr_schedule), loss=cross_entropy\n+)\n \n # Fit the model\n caption_model.fit(\n\n@@ -58,7 +58,10 @@ transformer_units = [\n     projection_dim,\n ]  # Size of the transformer layers\n transformer_layers = 8\n-mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier\n+mlp_head_units = [\n+    2048,\n+    1024,\n+]  # Size of the dense layers of the final classifier\n \n \n \"\"\"\n@@ -218,7 +221,9 @@ def create_vit_classifier():\n     representation = layers.Flatten()(representation)\n     representation = layers.Dropout(0.5)(representation)\n     # Add MLP.\n-    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n+    features = mlp(\n+        representation, hidden_units=mlp_head_units, dropout_rate=0.5\n+    )\n     # Classify outputs.\n     logits = layers.Dense(num_classes)(features)\n     # Create the Keras model.\n@@ -241,7 +246,9 @@ def run_experiment(model):\n         loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n         metrics=[\n             keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n-            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n+            keras.metrics.SparseTopKCategoricalAccuracy(\n+                5, name=\"top-5-accuracy\"\n+            ),\n         ],\n     )\n \n\n@@ -123,7 +123,9 @@ class Involution(keras.layers.Layer):\n                 keras.layers.BatchNormalization(),\n                 keras.layers.ReLU(),\n                 keras.layers.Conv2D(\n-                    filters=self.kernel_size * self.kernel_size * self.group_number,\n+                    filters=self.kernel_size\n+                    * self.kernel_size\n+                    * self.group_number,\n                     kernel_size=1,\n                 ),\n             ]\n@@ -198,22 +200,39 @@ input_tensor = tf.random.normal((32, 256, 256, 3))\n \n # Compute involution with stride 1.\n output_tensor, _ = Involution(\n-    channel=3, group_number=1, kernel_size=5, stride=1, reduction_ratio=1, name=\"inv_1\"\n+    channel=3,\n+    group_number=1,\n+    kernel_size=5,\n+    stride=1,\n+    reduction_ratio=1,\n+    name=\"inv_1\",\n )(input_tensor)\n print(f\"with stride 1 ouput shape: {output_tensor.shape}\")\n \n # Compute involution with stride 2.\n output_tensor, _ = Involution(\n-    channel=3, group_number=1, kernel_size=5, stride=2, reduction_ratio=1, name=\"inv_2\"\n+    channel=3,\n+    group_number=1,\n+    kernel_size=5,\n+    stride=2,\n+    reduction_ratio=1,\n+    name=\"inv_2\",\n )(input_tensor)\n print(f\"with stride 2 ouput shape: {output_tensor.shape}\")\n \n # Compute involution with stride 1, channel 16 and reduction ratio 2.\n output_tensor, _ = Involution(\n-    channel=16, group_number=1, kernel_size=5, stride=1, reduction_ratio=2, name=\"inv_3\"\n+    channel=16,\n+    group_number=1,\n+    kernel_size=5,\n+    stride=1,\n+    reduction_ratio=2,\n+    name=\"inv_3\",\n )(input_tensor)\n print(\n-    \"with channel 16 and reduction ratio 2 ouput shape: {}\".format(output_tensor.shape)\n+    \"with channel 16 and reduction ratio 2 ouput shape: {}\".format(\n+        output_tensor.shape\n+    )\n )\n \n \"\"\"\n@@ -250,7 +269,9 @@ train_ds = (\n     .shuffle(256)\n     .batch(256)\n )\n-test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(256)\n+test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(\n+    256\n+)\n \n \"\"\"\n ## Visualise the data\n@@ -287,7 +308,9 @@ plt.show()\n print(\"building the convolution model...\")\n conv_model = keras.Sequential(\n     [\n-        keras.layers.Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding=\"same\"),\n+        keras.layers.Conv2D(\n+            32, (3, 3), input_shape=(32, 32, 3), padding=\"same\"\n+        ),\n         keras.layers.ReLU(name=\"relu1\"),\n         keras.layers.MaxPooling2D((2, 2)),\n         keras.layers.Conv2D(64, (3, 3), padding=\"same\"),\n@@ -323,17 +346,32 @@ print(\"building the involution model...\")\n \n inputs = keras.Input(shape=(32, 32, 3))\n x, _ = Involution(\n-    channel=3, group_number=1, kernel_size=3, stride=1, reduction_ratio=2, name=\"inv_1\"\n+    channel=3,\n+    group_number=1,\n+    kernel_size=3,\n+    stride=1,\n+    reduction_ratio=2,\n+    name=\"inv_1\",\n )(inputs)\n x = keras.layers.ReLU()(x)\n x = keras.layers.MaxPooling2D((2, 2))(x)\n x, _ = Involution(\n-    channel=3, group_number=1, kernel_size=3, stride=1, reduction_ratio=2, name=\"inv_2\"\n+    channel=3,\n+    group_number=1,\n+    kernel_size=3,\n+    stride=1,\n+    reduction_ratio=2,\n+    name=\"inv_2\",\n )(x)\n x = keras.layers.ReLU()(x)\n x = keras.layers.MaxPooling2D((2, 2))(x)\n x, _ = Involution(\n-    channel=3, group_number=1, kernel_size=3, stride=1, reduction_ratio=2, name=\"inv_3\"\n+    channel=3,\n+    group_number=1,\n+    kernel_size=3,\n+    stride=1,\n+    reduction_ratio=2,\n+    name=\"inv_3\",\n )(x)\n x = keras.layers.ReLU()(x)\n x = keras.layers.Flatten()(x)\n\n@@ -140,7 +140,8 @@ certain cases, it may not help improve the performance as well.\n \n # First create the new dataset using our `mix_up` utility\n train_ds_mu = train_ds.map(\n-    lambda ds_one, ds_two: mix_up(ds_one, ds_two, alpha=0.2), num_parallel_calls=AUTO\n+    lambda ds_one, ds_two: mix_up(ds_one, ds_two, alpha=0.2),\n+    num_parallel_calls=AUTO,\n )\n \n # Let's preview 9 samples from the dataset\n@@ -160,7 +161,9 @@ for i, (image, label) in enumerate(zip(sample_images[:9], sample_labels[:9])):\n def get_training_model():\n     model = keras.Sequential(\n         [\n-            layers.Conv2D(16, (5, 5), activation=\"relu\", input_shape=(28, 28, 1)),\n+            layers.Conv2D(\n+                16, (5, 5), activation=\"relu\", input_shape=(28, 28, 1)\n+            ),\n             layers.MaxPooling2D(pool_size=(2, 2)),\n             layers.Conv2D(32, (5, 5), activation=\"relu\"),\n             layers.MaxPooling2D(pool_size=(2, 2)),\n@@ -187,7 +190,9 @@ initial_model.save_weights(\"initial_weights.weights.h5\")\n \n model = get_training_model()\n model.load_weights(\"initial_weights.weights.h5\")\n-model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n+model.compile(\n+    loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n+)\n model.fit(train_ds_mu, validation_data=val_ds, epochs=EPOCHS)\n _, test_acc = model.evaluate(test_ds)\n print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))\n@@ -198,7 +203,9 @@ print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))\n \n model = get_training_model()\n model.load_weights(\"initial_weights.weights.h5\")\n-model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n+model.compile(\n+    loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n+)\n # Notice that we are NOT using the mixed up dataset here\n model.fit(train_ds_one, validation_data=val_ds, epochs=EPOCHS)\n _, test_acc = model.evaluate(test_ds)\n\n@@ -183,7 +183,9 @@ class Patches(layers.Layer):\n             padding=\"VALID\",\n         )\n         patch_dims = patches.shape[-1]\n-        patches = tf.reshape(patches, [batch_size, self.num_patches, patch_dims])\n+        patches = tf.reshape(\n+            patches, [batch_size, self.num_patches, patch_dims]\n+        )\n         return patches\n \n \n@@ -207,7 +209,9 @@ instead of batch normalization.\n \n \n class MLPMixerLayer(layers.Layer):\n-    def __init__(self, num_patches, hidden_units, dropout_rate, *args, **kwargs):\n+    def __init__(\n+        self, num_patches, hidden_units, dropout_rate, *args, **kwargs\n+    ):\n         super().__init__(*args, **kwargs)\n \n         self.mlp1 = keras.Sequential(\n@@ -257,7 +261,10 @@ takes around 8 seconds per epoch.\n \"\"\"\n \n mlpmixer_blocks = keras.Sequential(\n-    [MLPMixerLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n+    [\n+        MLPMixerLayer(num_patches, embedding_dim, dropout_rate)\n+        for _ in range(num_blocks)\n+    ]\n )\n learning_rate = 0.005\n mlpmixer_classifier = build_classifier(mlpmixer_blocks)\n@@ -292,7 +299,9 @@ in the Transformer block with a parameter-free 2D Fourier transformation layer:\n \n \n class FNetLayer(layers.Layer):\n-    def __init__(self, num_patches, embedding_dim, dropout_rate, *args, **kwargs):\n+    def __init__(\n+        self, num_patches, embedding_dim, dropout_rate, *args, **kwargs\n+    ):\n         super().__init__(*args, **kwargs)\n \n         self.ffn = keras.Sequential(\n@@ -332,7 +341,10 @@ takes around 8 seconds per epoch.\n \"\"\"\n \n fnet_blocks = keras.Sequential(\n-    [FNetLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n+    [\n+        FNetLayer(num_patches, embedding_dim, dropout_rate)\n+        for _ in range(num_blocks)\n+    ]\n )\n learning_rate = 0.001\n fnet_classifier = build_classifier(fnet_blocks, positional_encoding=True)\n@@ -363,7 +375,9 @@ The SGU enables cross-patch interactions across the spatial (channel) dimension,\n \n \n class gMLPLayer(layers.Layer):\n-    def __init__(self, num_patches, embedding_dim, dropout_rate, *args, **kwargs):\n+    def __init__(\n+        self, num_patches, embedding_dim, dropout_rate, *args, **kwargs\n+    ):\n         super().__init__(*args, **kwargs)\n \n         self.channel_projection1 = keras.Sequential(\n@@ -416,7 +430,10 @@ takes around 9 seconds per epoch.\n \"\"\"\n \n gmlp_blocks = keras.Sequential(\n-    [gMLPLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n+    [\n+        gMLPLayer(num_patches, embedding_dim, dropout_rate)\n+        for _ in range(num_blocks)\n+    ]\n )\n learning_rate = 0.003\n gmlp_classifier = build_classifier(gmlp_blocks)\n\n@@ -71,14 +71,18 @@ image_size = 64  # We'll resize input images to this size.\n patch_size = 2  # Size of the patches to be extract from the input images.\n num_patches = (image_size // patch_size) ** 2  # Size of the data array.\n latent_dim = 256  # Size of the latent array.\n-projection_dim = 256  # Embedding size of each element in the data and latent arrays.\n+projection_dim = (\n+    256  # Embedding size of each element in the data and latent arrays.\n+)\n num_heads = 8  # Number of Transformer heads.\n ffn_units = [\n     projection_dim,\n     projection_dim,\n ]  # Size of the Transformer Feedforward network.\n num_transformer_blocks = 4\n-num_iterations = 2  # Repetitions of the cross-attention and Transformer modules.\n+num_iterations = (\n+    2  # Repetitions of the cross-attention and Transformer modules.\n+)\n classifier_units = [\n     projection_dim,\n     num_classes,\n@@ -205,13 +209,19 @@ def create_cross_attention_module(\n ):\n     inputs = {\n         # Recieve the latent array as an input of shape [1, latent_dim, projection_dim].\n-        \"latent_array\": layers.Input(shape=(latent_dim, projection_dim), name=\"latent_array\"),\n+        \"latent_array\": layers.Input(\n+            shape=(latent_dim, projection_dim), name=\"latent_array\"\n+        ),\n         # Recieve the data_array (encoded image) as an input of shape [batch_size, data_dim, projection_dim].\n-        \"data_array\": layers.Input(shape=(data_dim, projection_dim), name=\"data_array\"),\n+        \"data_array\": layers.Input(\n+            shape=(data_dim, projection_dim), name=\"data_array\"\n+        ),\n     }\n \n     # Apply layer norm to the inputs\n-    latent_array = layers.LayerNormalization(epsilon=1e-6)(inputs[\"latent_array\"])\n+    latent_array = layers.LayerNormalization(epsilon=1e-6)(\n+        inputs[\"latent_array\"]\n+    )\n     data_array = layers.LayerNormalization(epsilon=1e-6)(inputs[\"data_array\"])\n \n     # Create query tensor: [1, latent_dim, projection_dim].\n\n@@ -148,7 +148,9 @@ model.compile(\n )\n model.summary()\n \n-callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n+callbacks = [\n+    keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n+]\n \n model.fit(\n     x_train,\n\n@@ -96,7 +96,9 @@ positive class label is randomly placed among the instances in the positive bag.\n \"\"\"\n \n \n-def create_bags(input_data, input_labels, positive_class, bag_count, instance_count):\n+def create_bags(\n+    input_data, input_labels, positive_class, bag_count, instance_count\n+):\n     # Set up bags.\n     bags = []\n     bag_labels = []\n@@ -109,7 +111,9 @@ def create_bags(input_data, input_labels, positive_class, bag_count, instance_co\n \n     for _ in range(bag_count):\n         # Pick a fixed size random subset of samples.\n-        index = np.random.choice(input_data.shape[0], instance_count, replace=False)\n+        index = np.random.choice(\n+            input_data.shape[0], instance_count, replace=False\n+        )\n         instances_data = input_data[index]\n         instances_labels = input_labels[index]\n \n@@ -241,7 +245,9 @@ class MILAttentionLayer(layers.Layer):\n \n     def call(self, inputs):\n         # Assigning variables from the number of inputs.\n-        instances = [self.compute_attention_scores(instance) for instance in inputs]\n+        instances = [\n+            self.compute_attention_scores(instance) for instance in inputs\n+        ]\n \n         # Stack instances into a single tensor.\n         instances = ops.stack(instances)\n@@ -257,7 +263,9 @@ class MILAttentionLayer(layers.Layer):\n         original_instance = instance\n \n         # tanh(v*h_k^T)\n-        instance = ops.tanh(ops.tensordot(instance, self.v_weight_params, axes=1))\n+        instance = ops.tanh(\n+            ops.tensordot(instance, self.v_weight_params, axes=1)\n+        )\n \n         # for learning non-linear relations efficiently.\n         if self.use_gated:\n@@ -499,12 +507,16 @@ def predict(data, labels, trained_models):\n         models_predictions.append(predictions)\n \n         # Create intermediate model to get MIL attention layer weights.\n-        intermediate_model = keras.Model(model.input, model.get_layer(\"alpha\").output)\n+        intermediate_model = keras.Model(\n+            model.input, model.get_layer(\"alpha\").output\n+        )\n \n         # Predict MIL attention layer weights.\n         intermediate_predictions = intermediate_model.predict(data)\n \n-        attention_weights = np.squeeze(np.swapaxes(intermediate_predictions, 1, 0))\n+        attention_weights = np.squeeze(\n+            np.swapaxes(intermediate_predictions, 1, 0)\n+        )\n         models_attention_weights.append(attention_weights)\n \n         loss, accuracy = model.evaluate(data, labels, verbose=0)\n@@ -523,7 +535,9 @@ def predict(data, labels, trained_models):\n \n \n # Evaluate and predict classes and attention scores on validation data.\n-class_predictions, attention_params = predict(val_data, val_labels, trained_models)\n+class_predictions, attention_params = predict(\n+    val_data, val_labels, trained_models\n+)\n \n # Plot some results from our validation data.\n plot(\n\n@@ -96,9 +96,7 @@ def append(\n \n \n def arange(start, stop=None, step=1, dtype=None):\n-    # tfnp.arange has trouble with dynamic Tensors in compiled function.\n-    # tf.range does not.\n-    return tf.range(start, stop, delta=step, dtype=dtype)\n+    return tfnp.arange(start, stop, step=step, dtype=dtype)\n \n \n def arccos(x):\n@@ -446,9 +444,7 @@ def reciprocal(x):\n \n \n def repeat(x, repeats, axis=None):\n-    # tfnp.repeat has trouble with dynamic Tensors in compiled function.\n-    # tf.repeat does not.\n-    return tf.repeat(x, repeats, axis=axis)\n+    return tfnp.repeat(x, repeats, axis=axis)\n \n \n def reshape(x, new_shape):\n\n@@ -3,7 +3,6 @@ from keras_core import initializers\n from keras_core import ops\n from keras_core import regularizers\n from keras_core.api_export import keras_core_export\n-from keras_core.backend import standardize_dtype\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n \n@@ -189,12 +188,6 @@ class BatchNormalization(Layer):\n         return input_shape\n \n     def call(self, inputs, training=None, mask=None):\n-        input_dtype = standardize_dtype(inputs.dtype)\n-        if input_dtype in (\"float16\", \"bfloat16\"):\n-            # BN is prone to overflowing for float16/bfloat16 inputs, so we opt\n-            # out BN for mixed precision.\n-            inputs = ops.cast(inputs, \"float32\")\n-\n         broadcast_shape = [1] * len(inputs.shape)\n         broadcast_shape[self.axis] = inputs.shape[self.axis]\n         if training and self.trainable:\n@@ -205,20 +198,12 @@ class BatchNormalization(Layer):\n             outputs = (inputs - mean) / ops.sqrt(variance + self.epsilon)\n             mean = ops.squeeze(mean, self._reduction_axes)\n             variance = ops.squeeze(variance, self._reduction_axes)\n-            moving_mean = ops.cast(self.moving_mean, inputs.dtype)\n-            moving_variance = ops.cast(self.moving_variance, inputs.dtype)\n             self.moving_mean.assign(\n-                ops.cast(\n-                    moving_mean * self.momentum + mean * (1.0 - self.momentum),\n-                    inputs.dtype,\n-                )\n+                self.moving_mean * self.momentum + mean * (1.0 - self.momentum)\n             )\n             self.moving_variance.assign(\n-                ops.cast(\n-                    moving_variance * self.momentum\n-                    + variance * (1.0 - self.momentum),\n-                    inputs.dtype,\n-                )\n+                self.moving_variance * self.momentum\n+                + variance * (1.0 - self.momentum)\n             )\n         else:\n             moving_mean = ops.reshape(self.moving_mean, broadcast_shape)\n@@ -228,11 +213,9 @@ class BatchNormalization(Layer):\n             )\n         if self.scale:\n             gamma = ops.reshape(self.gamma, broadcast_shape)\n-            gamma = ops.cast(gamma, outputs.dtype)\n             outputs = outputs * gamma\n         if self.center:\n             beta = ops.reshape(self.beta, broadcast_shape)\n-            beta = ops.cast(beta, outputs.dtype)\n             outputs = outputs + beta\n         return outputs\n \n\n@@ -205,12 +205,9 @@ class LayerNormalization(Layer):\n         # Compute the batch normalization.\n         inv = 1 / ops.sqrt(variance + self.epsilon)\n         if scale is not None:\n-            scale = ops.cast(scale, inputs.dtype)\n             inv = inv * scale\n-        x = -mean * inv\n-        if offset is not None:\n-            offset = ops.cast(offset, inputs.dtype)\n-            x = offset + x\n+\n+        x = offset - mean * inv if offset is not None else -mean * inv\n         outputs = inputs * ops.cast(inv, inputs.dtype) + ops.cast(\n             x, inputs.dtype\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7c1d647d0e4356832084c71a86a74769d310666e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 13 | Files Changed: 2 | Hunks: 7 | Methods Changed: 3 | Complexity Δ (Sum/Max): 25/23 | Churn Δ: 28 | Churn Cumulative: 1474 | Contributors (this commit): 3 | Commits (past 90d): 6 | Contributors (cumulative): 5 | DMM Complexity: 0.0\n\nDIFF:\n@@ -99,16 +99,17 @@ class ExportArchive(tf.__internal__.tracking.AutoTrackable):\n         self.non_trainable_variables = []\n \n     @tf.__internal__.tracking.no_automatic_dependency_tracking\n-    def track(self, layer):\n-        \"\"\"Track the variables (and other resources) of a layer or model.\"\"\"\n-        if not isinstance(layer, base_layer.Layer):\n+    def track(self, resource):\n+        \"\"\"Track the variables (and other assets) of a layer or model.\"\"\"\n+        if not isinstance(resource, tf.__internal__.tracking.Trackable):\n             raise ValueError(\n-                \"Invalid layer type. Expected an instance of \"\n-                \"`keras.layers.Layer` or `keras.Model`. \"\n-                f\"Received instead an object of type '{type(layer)}'. \"\n-                f\"Object received: {layer}\"\n+                \"Invalid resource type. Expected an instance of a \"\n+                \"TensorFlow `Trackable` (such as a Keras `Layer` or `Model`). \"\n+                f\"Received instead an object of type '{type(resource)}'. \"\n+                f\"Object received: {resource}\"\n             )\n-        if not layer.built:\n+        if isinstance(resource, base_layer.Layer):\n+            if not resource.built:\n                 raise ValueError(\n                     \"The layer provided has not yet been built. \"\n                     \"It must be built before export.\"\n@@ -119,13 +120,14 @@ class ExportArchive(tf.__internal__.tracking.AutoTrackable):\n         # no_automatic_dependency_tracking scope.\n         if not hasattr(self, \"_tracked\"):\n             self._tracked = []\n-        self._tracked.append(layer)\n+        self._tracked.append(resource)\n \n+        if isinstance(resource, base_layer.Layer):\n             # Variables in the lists below are actually part of the trackables\n             # that get saved, because the lists are created in __init__.\n-        self.variables += layer.variables\n-        self.trainable_variables += layer.trainable_variables\n-        self.non_trainable_variables += layer.non_trainable_variables\n+            self.variables += resource.variables\n+            self.trainable_variables += resource.trainable_variables\n+            self.non_trainable_variables += resource.non_trainable_variables\n \n     def add_endpoint(self, name, fn, input_signature=None):\n         \"\"\"Register a new serving endpoint.\n\n@@ -402,7 +402,7 @@ class ExportArchiveTest(tf.test.TestCase, parameterized.TestCase):\n             export_archive.write_out(temp_filepath)\n \n         # Invalid object type\n-        with self.assertRaisesRegex(ValueError, \"Invalid layer type\"):\n+        with self.assertRaisesRegex(ValueError, \"Invalid resource type\"):\n             export_archive = export_lib.ExportArchive()\n             export_archive.track(\"model\")\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9911098dc84b511160f27a3c27cb3a31dc144cf5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 92 | Lines Deleted: 201 | Files Changed: 15 | Hunks: 68 | Methods Changed: 23 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 293 | Churn Cumulative: 8461 | Contributors (this commit): 10 | Commits (past 90d): 99 | Contributors (cumulative): 48 | DMM Complexity: 0.0\n\nDIFF:\n@@ -98,7 +98,6 @@ train(model, train_loader, num_epochs, optimizer, loss_fn)\n ######## Using a Keras model or layer in a torch Module ########\n ################################################################\n \n-\n class MyModel(nn.Module):\n     def __init__(self):\n         super().__init__()\n\n@@ -157,12 +157,7 @@ devices = mesh_utils.create_device_mesh((8,))\n # data will be split along the batch axis\n data_mesh = Mesh(devices, axis_names=(\"batch\",))  # naming axes of the mesh\n # naming axes of the sharded partition\n-data_sharding = NamedSharding(\n-    data_mesh,\n-    P(\n-        \"batch\",\n-    ),\n-)\n+data_sharding = NamedSharding(data_mesh,P(\"batch\",),)\n \n # all variables will be replicated on all devices\n var_mesh = Mesh(devices, axis_names=(\"_\"))\n\n@@ -40,7 +40,6 @@ from zipfile import ZipFile\n import keras_core as keras\n from keras_core import layers\n from keras_core import ops\n-\n \"\"\"\n ## First, load the data and apply preprocessing\n \"\"\"\n@@ -98,11 +97,7 @@ print(\n df = df.sample(frac=1, random_state=42)\n x = df[[\"user\", \"movie\"]].values\n # Normalize the targets between 0 and 1. Makes it easy to train.\n-y = (\n-    df[\"rating\"]\n-    .apply(lambda x: (x - min_rating) / (max_rating - min_rating))\n-    .values\n-)\n+y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n # Assuming training on 90% of the data and validating on 10%.\n train_indices = int(0.9 * df.shape[0])\n x_train, x_val, y_train, y_val = (\n@@ -209,8 +204,7 @@ user_movie_array = np.hstack(\n ratings = model.predict(user_movie_array).flatten()\n top_ratings_indices = ratings.argsort()[-10:][::-1]\n recommended_movie_ids = [\n-    movie_encoded2movie.get(movies_not_watched[x][0])\n-    for x in top_ratings_indices\n+    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n ]\n \n print(\"Showing recommendations for user: {}\".format(user_id))\n\n@@ -178,9 +178,7 @@ splitting scheme (split on whitespace).\n \n def custom_standardization(input_string):\n     lowercase = tf.strings.lower(input_string)\n-    return tf.strings.regex_replace(\n-        lowercase, \"[%s]\" % re.escape(strip_chars), \"\"\n-    )\n+    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n \n \n strip_chars = \"!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\n@@ -265,9 +263,7 @@ def get_cnn_model():\n     # We freeze our feature extractor\n     base_model.trainable = False\n     base_model_out = base_model.output\n-    base_model_out = layers.Reshape((-1, base_model_out.shape[-1]))(\n-        base_model_out\n-    )\n+    base_model_out = layers.Reshape((-1, base_model_out.shape[-1]))(base_model_out)\n     cnn_model = keras.models.Model(base_model.input, base_model_out)\n     return cnn_model\n \n@@ -346,9 +342,7 @@ class TransformerDecoderBlock(layers.Layer):\n         self.layernorm_3 = layers.LayerNormalization()\n \n         self.embedding = PositionalEmbedding(\n-            embed_dim=EMBED_DIM,\n-            sequence_length=SEQ_LENGTH,\n-            vocab_size=VOCAB_SIZE,\n+            embed_dim=EMBED_DIM, sequence_length=SEQ_LENGTH, vocab_size=VOCAB_SIZE\n         )\n         self.out = layers.Dense(VOCAB_SIZE, activation=\"softmax\")\n \n@@ -400,10 +394,7 @@ class TransformerDecoderBlock(layers.Layer):\n         mask = tf.cast(i >= j, dtype=\"int32\")\n         mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n         mult = tf.concat(\n-            [\n-                tf.expand_dims(batch_size, -1),\n-                tf.constant([1, 1], dtype=tf.int32),\n-            ],\n+            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n             axis=0,\n         )\n         return tf.tile(mask, mult)\n@@ -440,9 +431,7 @@ class ImageCaptioningModel(keras.Model):\n         mask = tf.cast(mask, dtype=tf.float32)\n         return tf.reduce_sum(accuracy) / tf.reduce_sum(mask)\n \n-    def _compute_caption_loss_and_acc(\n-        self, img_embed, batch_seq, training=True\n-    ):\n+    def _compute_caption_loss_and_acc(self, img_embed, batch_seq, training=True):\n         encoder_out = self.encoder(img_embed, training=training)\n         batch_seq_inp = batch_seq[:, :-1]\n         batch_seq_true = batch_seq[:, 1:]\n@@ -480,8 +469,7 @@ class ImageCaptioningModel(keras.Model):\n \n             # 4. Get the list of all the trainable weights\n             train_vars = (\n-                self.encoder.trainable_variables\n-                + self.decoder.trainable_variables\n+                self.encoder.trainable_variables + self.decoder.trainable_variables\n             )\n \n             # 5. Get the gradients\n@@ -496,10 +484,7 @@ class ImageCaptioningModel(keras.Model):\n         self.acc_tracker.update_state(batch_acc)\n \n         # 8. Return the loss and accuracy values\n-        return {\n-            \"loss\": self.loss_tracker.result(),\n-            \"acc\": self.acc_tracker.result(),\n-        }\n+        return {\"loss\": self.loss_tracker.result(), \"acc\": self.acc_tracker.result()}\n \n     def test_step(self, batch_data):\n         batch_img, batch_seq = batch_data\n@@ -528,10 +513,7 @@ class ImageCaptioningModel(keras.Model):\n         self.acc_tracker.update_state(batch_acc)\n \n         # 5. Return the loss and accuracy values\n-        return {\n-            \"loss\": self.loss_tracker.result(),\n-            \"acc\": self.acc_tracker.result(),\n-        }\n+        return {\"loss\": self.loss_tracker.result(), \"acc\": self.acc_tracker.result()}\n \n     @property\n     def metrics(self):\n@@ -541,12 +523,8 @@ class ImageCaptioningModel(keras.Model):\n \n \n cnn_model = get_cnn_model()\n-encoder = TransformerEncoderBlock(\n-    embed_dim=EMBED_DIM, dense_dim=FF_DIM, num_heads=1\n-)\n-decoder = TransformerDecoderBlock(\n-    embed_dim=EMBED_DIM, ff_dim=FF_DIM, num_heads=2\n-)\n+encoder = TransformerEncoderBlock(embed_dim=EMBED_DIM, dense_dim=FF_DIM, num_heads=1)\n+decoder = TransformerDecoderBlock(embed_dim=EMBED_DIM, ff_dim=FF_DIM, num_heads=2)\n caption_model = ImageCaptioningModel(\n     cnn_model=cnn_model,\n     encoder=encoder,\n@@ -561,20 +539,15 @@ caption_model = ImageCaptioningModel(\n \n # Define the loss function\n cross_entropy = keras.losses.SparseCategoricalCrossentropy(\n-    from_logits=False,\n-    reduction=None,\n+    from_logits=False, reduction=None,\n )\n \n # EarlyStopping criteria\n-early_stopping = keras.callbacks.EarlyStopping(\n-    patience=3, restore_best_weights=True\n-)\n+early_stopping = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n \n \n # Learning Rate Scheduler for the optimizer\n-class LRSchedule(\n-    keras.optimizers.schedules.learning_rate_schedule.LearningRateSchedule\n-):\n+class LRSchedule(keras.optimizers.schedules.learning_rate_schedule.LearningRateSchedule):\n     def __init__(self, post_warmup_learning_rate, warmup_steps):\n         super().__init__()\n         self.post_warmup_learning_rate = post_warmup_learning_rate\n@@ -595,14 +568,10 @@ class LRSchedule(\n # Create a learning rate schedule\n num_train_steps = len(train_dataset) * EPOCHS\n num_warmup_steps = num_train_steps // 15\n-lr_schedule = LRSchedule(\n-    post_warmup_learning_rate=1e-4, warmup_steps=num_warmup_steps\n-)\n+lr_schedule = LRSchedule(post_warmup_learning_rate=1e-4, warmup_steps=num_warmup_steps)\n \n # Compile the model\n-caption_model.compile(\n-    optimizer=keras.optimizers.Adam(lr_schedule), loss=cross_entropy\n-)\n+caption_model.compile(optimizer=keras.optimizers.Adam(lr_schedule), loss=cross_entropy)\n \n # Fit the model\n caption_model.fit(\n\n@@ -58,10 +58,7 @@ transformer_units = [\n     projection_dim,\n ]  # Size of the transformer layers\n transformer_layers = 8\n-mlp_head_units = [\n-    2048,\n-    1024,\n-]  # Size of the dense layers of the final classifier\n+mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier\n \n \n \"\"\"\n@@ -221,9 +218,7 @@ def create_vit_classifier():\n     representation = layers.Flatten()(representation)\n     representation = layers.Dropout(0.5)(representation)\n     # Add MLP.\n-    features = mlp(\n-        representation, hidden_units=mlp_head_units, dropout_rate=0.5\n-    )\n+    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n     # Classify outputs.\n     logits = layers.Dense(num_classes)(features)\n     # Create the Keras model.\n@@ -246,9 +241,7 @@ def run_experiment(model):\n         loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n         metrics=[\n             keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n-            keras.metrics.SparseTopKCategoricalAccuracy(\n-                5, name=\"top-5-accuracy\"\n-            ),\n+            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n         ],\n     )\n \n\n@@ -123,9 +123,7 @@ class Involution(keras.layers.Layer):\n                 keras.layers.BatchNormalization(),\n                 keras.layers.ReLU(),\n                 keras.layers.Conv2D(\n-                    filters=self.kernel_size\n-                    * self.kernel_size\n-                    * self.group_number,\n+                    filters=self.kernel_size * self.kernel_size * self.group_number,\n                     kernel_size=1,\n                 ),\n             ]\n@@ -200,39 +198,22 @@ input_tensor = tf.random.normal((32, 256, 256, 3))\n \n # Compute involution with stride 1.\n output_tensor, _ = Involution(\n-    channel=3,\n-    group_number=1,\n-    kernel_size=5,\n-    stride=1,\n-    reduction_ratio=1,\n-    name=\"inv_1\",\n+    channel=3, group_number=1, kernel_size=5, stride=1, reduction_ratio=1, name=\"inv_1\"\n )(input_tensor)\n print(f\"with stride 1 ouput shape: {output_tensor.shape}\")\n \n # Compute involution with stride 2.\n output_tensor, _ = Involution(\n-    channel=3,\n-    group_number=1,\n-    kernel_size=5,\n-    stride=2,\n-    reduction_ratio=1,\n-    name=\"inv_2\",\n+    channel=3, group_number=1, kernel_size=5, stride=2, reduction_ratio=1, name=\"inv_2\"\n )(input_tensor)\n print(f\"with stride 2 ouput shape: {output_tensor.shape}\")\n \n # Compute involution with stride 1, channel 16 and reduction ratio 2.\n output_tensor, _ = Involution(\n-    channel=16,\n-    group_number=1,\n-    kernel_size=5,\n-    stride=1,\n-    reduction_ratio=2,\n-    name=\"inv_3\",\n+    channel=16, group_number=1, kernel_size=5, stride=1, reduction_ratio=2, name=\"inv_3\"\n )(input_tensor)\n print(\n-    \"with channel 16 and reduction ratio 2 ouput shape: {}\".format(\n-        output_tensor.shape\n-    )\n+    \"with channel 16 and reduction ratio 2 ouput shape: {}\".format(output_tensor.shape)\n )\n \n \"\"\"\n@@ -269,9 +250,7 @@ train_ds = (\n     .shuffle(256)\n     .batch(256)\n )\n-test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(\n-    256\n-)\n+test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(256)\n \n \"\"\"\n ## Visualise the data\n@@ -308,9 +287,7 @@ plt.show()\n print(\"building the convolution model...\")\n conv_model = keras.Sequential(\n     [\n-        keras.layers.Conv2D(\n-            32, (3, 3), input_shape=(32, 32, 3), padding=\"same\"\n-        ),\n+        keras.layers.Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding=\"same\"),\n         keras.layers.ReLU(name=\"relu1\"),\n         keras.layers.MaxPooling2D((2, 2)),\n         keras.layers.Conv2D(64, (3, 3), padding=\"same\"),\n@@ -346,32 +323,17 @@ print(\"building the involution model...\")\n \n inputs = keras.Input(shape=(32, 32, 3))\n x, _ = Involution(\n-    channel=3,\n-    group_number=1,\n-    kernel_size=3,\n-    stride=1,\n-    reduction_ratio=2,\n-    name=\"inv_1\",\n+    channel=3, group_number=1, kernel_size=3, stride=1, reduction_ratio=2, name=\"inv_1\"\n )(inputs)\n x = keras.layers.ReLU()(x)\n x = keras.layers.MaxPooling2D((2, 2))(x)\n x, _ = Involution(\n-    channel=3,\n-    group_number=1,\n-    kernel_size=3,\n-    stride=1,\n-    reduction_ratio=2,\n-    name=\"inv_2\",\n+    channel=3, group_number=1, kernel_size=3, stride=1, reduction_ratio=2, name=\"inv_2\"\n )(x)\n x = keras.layers.ReLU()(x)\n x = keras.layers.MaxPooling2D((2, 2))(x)\n x, _ = Involution(\n-    channel=3,\n-    group_number=1,\n-    kernel_size=3,\n-    stride=1,\n-    reduction_ratio=2,\n-    name=\"inv_3\",\n+    channel=3, group_number=1, kernel_size=3, stride=1, reduction_ratio=2, name=\"inv_3\"\n )(x)\n x = keras.layers.ReLU()(x)\n x = keras.layers.Flatten()(x)\n\n@@ -140,8 +140,7 @@ certain cases, it may not help improve the performance as well.\n \n # First create the new dataset using our `mix_up` utility\n train_ds_mu = train_ds.map(\n-    lambda ds_one, ds_two: mix_up(ds_one, ds_two, alpha=0.2),\n-    num_parallel_calls=AUTO,\n+    lambda ds_one, ds_two: mix_up(ds_one, ds_two, alpha=0.2), num_parallel_calls=AUTO\n )\n \n # Let's preview 9 samples from the dataset\n@@ -161,9 +160,7 @@ for i, (image, label) in enumerate(zip(sample_images[:9], sample_labels[:9])):\n def get_training_model():\n     model = keras.Sequential(\n         [\n-            layers.Conv2D(\n-                16, (5, 5), activation=\"relu\", input_shape=(28, 28, 1)\n-            ),\n+            layers.Conv2D(16, (5, 5), activation=\"relu\", input_shape=(28, 28, 1)),\n             layers.MaxPooling2D(pool_size=(2, 2)),\n             layers.Conv2D(32, (5, 5), activation=\"relu\"),\n             layers.MaxPooling2D(pool_size=(2, 2)),\n@@ -190,9 +187,7 @@ initial_model.save_weights(\"initial_weights.weights.h5\")\n \n model = get_training_model()\n model.load_weights(\"initial_weights.weights.h5\")\n-model.compile(\n-    loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n-)\n+model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n model.fit(train_ds_mu, validation_data=val_ds, epochs=EPOCHS)\n _, test_acc = model.evaluate(test_ds)\n print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))\n@@ -203,9 +198,7 @@ print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))\n \n model = get_training_model()\n model.load_weights(\"initial_weights.weights.h5\")\n-model.compile(\n-    loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n-)\n+model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n # Notice that we are NOT using the mixed up dataset here\n model.fit(train_ds_one, validation_data=val_ds, epochs=EPOCHS)\n _, test_acc = model.evaluate(test_ds)\n\n@@ -183,9 +183,7 @@ class Patches(layers.Layer):\n             padding=\"VALID\",\n         )\n         patch_dims = patches.shape[-1]\n-        patches = tf.reshape(\n-            patches, [batch_size, self.num_patches, patch_dims]\n-        )\n+        patches = tf.reshape(patches, [batch_size, self.num_patches, patch_dims])\n         return patches\n \n \n@@ -209,9 +207,7 @@ instead of batch normalization.\n \n \n class MLPMixerLayer(layers.Layer):\n-    def __init__(\n-        self, num_patches, hidden_units, dropout_rate, *args, **kwargs\n-    ):\n+    def __init__(self, num_patches, hidden_units, dropout_rate, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n \n         self.mlp1 = keras.Sequential(\n@@ -261,10 +257,7 @@ takes around 8 seconds per epoch.\n \"\"\"\n \n mlpmixer_blocks = keras.Sequential(\n-    [\n-        MLPMixerLayer(num_patches, embedding_dim, dropout_rate)\n-        for _ in range(num_blocks)\n-    ]\n+    [MLPMixerLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n )\n learning_rate = 0.005\n mlpmixer_classifier = build_classifier(mlpmixer_blocks)\n@@ -299,9 +292,7 @@ in the Transformer block with a parameter-free 2D Fourier transformation layer:\n \n \n class FNetLayer(layers.Layer):\n-    def __init__(\n-        self, num_patches, embedding_dim, dropout_rate, *args, **kwargs\n-    ):\n+    def __init__(self, num_patches, embedding_dim, dropout_rate, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n \n         self.ffn = keras.Sequential(\n@@ -341,10 +332,7 @@ takes around 8 seconds per epoch.\n \"\"\"\n \n fnet_blocks = keras.Sequential(\n-    [\n-        FNetLayer(num_patches, embedding_dim, dropout_rate)\n-        for _ in range(num_blocks)\n-    ]\n+    [FNetLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n )\n learning_rate = 0.001\n fnet_classifier = build_classifier(fnet_blocks, positional_encoding=True)\n@@ -375,9 +363,7 @@ The SGU enables cross-patch interactions across the spatial (channel) dimension,\n \n \n class gMLPLayer(layers.Layer):\n-    def __init__(\n-        self, num_patches, embedding_dim, dropout_rate, *args, **kwargs\n-    ):\n+    def __init__(self, num_patches, embedding_dim, dropout_rate, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n \n         self.channel_projection1 = keras.Sequential(\n@@ -430,10 +416,7 @@ takes around 9 seconds per epoch.\n \"\"\"\n \n gmlp_blocks = keras.Sequential(\n-    [\n-        gMLPLayer(num_patches, embedding_dim, dropout_rate)\n-        for _ in range(num_blocks)\n-    ]\n+    [gMLPLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n )\n learning_rate = 0.003\n gmlp_classifier = build_classifier(gmlp_blocks)\n\n@@ -71,18 +71,14 @@ image_size = 64  # We'll resize input images to this size.\n patch_size = 2  # Size of the patches to be extract from the input images.\n num_patches = (image_size // patch_size) ** 2  # Size of the data array.\n latent_dim = 256  # Size of the latent array.\n-projection_dim = (\n-    256  # Embedding size of each element in the data and latent arrays.\n-)\n+projection_dim = 256  # Embedding size of each element in the data and latent arrays.\n num_heads = 8  # Number of Transformer heads.\n ffn_units = [\n     projection_dim,\n     projection_dim,\n ]  # Size of the Transformer Feedforward network.\n num_transformer_blocks = 4\n-num_iterations = (\n-    2  # Repetitions of the cross-attention and Transformer modules.\n-)\n+num_iterations = 2  # Repetitions of the cross-attention and Transformer modules.\n classifier_units = [\n     projection_dim,\n     num_classes,\n@@ -209,19 +205,13 @@ def create_cross_attention_module(\n ):\n     inputs = {\n         # Recieve the latent array as an input of shape [1, latent_dim, projection_dim].\n-        \"latent_array\": layers.Input(\n-            shape=(latent_dim, projection_dim), name=\"latent_array\"\n-        ),\n+        \"latent_array\": layers.Input(shape=(latent_dim, projection_dim), name=\"latent_array\"),\n         # Recieve the data_array (encoded image) as an input of shape [batch_size, data_dim, projection_dim].\n-        \"data_array\": layers.Input(\n-            shape=(data_dim, projection_dim), name=\"data_array\"\n-        ),\n+        \"data_array\": layers.Input(shape=(data_dim, projection_dim), name=\"data_array\"),\n     }\n \n     # Apply layer norm to the inputs\n-    latent_array = layers.LayerNormalization(epsilon=1e-6)(\n-        inputs[\"latent_array\"]\n-    )\n+    latent_array = layers.LayerNormalization(epsilon=1e-6)(inputs[\"latent_array\"])\n     data_array = layers.LayerNormalization(epsilon=1e-6)(inputs[\"data_array\"])\n \n     # Create query tensor: [1, latent_dim, projection_dim].\n\n@@ -148,9 +148,7 @@ model.compile(\n )\n model.summary()\n \n-callbacks = [\n-    keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n-]\n+callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n \n model.fit(\n     x_train,\n\n@@ -96,9 +96,7 @@ positive class label is randomly placed among the instances in the positive bag.\n \"\"\"\n \n \n-def create_bags(\n-    input_data, input_labels, positive_class, bag_count, instance_count\n-):\n+def create_bags(input_data, input_labels, positive_class, bag_count, instance_count):\n     # Set up bags.\n     bags = []\n     bag_labels = []\n@@ -111,9 +109,7 @@ def create_bags(\n \n     for _ in range(bag_count):\n         # Pick a fixed size random subset of samples.\n-        index = np.random.choice(\n-            input_data.shape[0], instance_count, replace=False\n-        )\n+        index = np.random.choice(input_data.shape[0], instance_count, replace=False)\n         instances_data = input_data[index]\n         instances_labels = input_labels[index]\n \n@@ -245,9 +241,7 @@ class MILAttentionLayer(layers.Layer):\n \n     def call(self, inputs):\n         # Assigning variables from the number of inputs.\n-        instances = [\n-            self.compute_attention_scores(instance) for instance in inputs\n-        ]\n+        instances = [self.compute_attention_scores(instance) for instance in inputs]\n \n         # Stack instances into a single tensor.\n         instances = ops.stack(instances)\n@@ -263,9 +257,7 @@ class MILAttentionLayer(layers.Layer):\n         original_instance = instance\n \n         # tanh(v*h_k^T)\n-        instance = ops.tanh(\n-            ops.tensordot(instance, self.v_weight_params, axes=1)\n-        )\n+        instance = ops.tanh(ops.tensordot(instance, self.v_weight_params, axes=1))\n \n         # for learning non-linear relations efficiently.\n         if self.use_gated:\n@@ -507,16 +499,12 @@ def predict(data, labels, trained_models):\n         models_predictions.append(predictions)\n \n         # Create intermediate model to get MIL attention layer weights.\n-        intermediate_model = keras.Model(\n-            model.input, model.get_layer(\"alpha\").output\n-        )\n+        intermediate_model = keras.Model(model.input, model.get_layer(\"alpha\").output)\n \n         # Predict MIL attention layer weights.\n         intermediate_predictions = intermediate_model.predict(data)\n \n-        attention_weights = np.squeeze(\n-            np.swapaxes(intermediate_predictions, 1, 0)\n-        )\n+        attention_weights = np.squeeze(np.swapaxes(intermediate_predictions, 1, 0))\n         models_attention_weights.append(attention_weights)\n \n         loss, accuracy = model.evaluate(data, labels, verbose=0)\n@@ -535,9 +523,7 @@ def predict(data, labels, trained_models):\n \n \n # Evaluate and predict classes and attention scores on validation data.\n-class_predictions, attention_params = predict(\n-    val_data, val_labels, trained_models\n-)\n+class_predictions, attention_params = predict(val_data, val_labels, trained_models)\n \n # Plot some results from our validation data.\n plot(\n\n@@ -96,7 +96,9 @@ def append(\n \n \n def arange(start, stop=None, step=1, dtype=None):\n-    return tfnp.arange(start, stop, step=step, dtype=dtype)\n+    # tfnp.arange has trouble with dynamic Tensors in compiled function.\n+    # tf.range does not.\n+    return tf.range(start, stop, delta=step, dtype=dtype)\n \n \n def arccos(x):\n@@ -444,7 +446,9 @@ def reciprocal(x):\n \n \n def repeat(x, repeats, axis=None):\n-    return tfnp.repeat(x, repeats, axis=axis)\n+    # tfnp.repeat has trouble with dynamic Tensors in compiled function.\n+    # tf.repeat does not.\n+    return tf.repeat(x, repeats, axis=axis)\n \n \n def reshape(x, new_shape):\n\n@@ -3,6 +3,7 @@ from keras_core import initializers\n from keras_core import ops\n from keras_core import regularizers\n from keras_core.api_export import keras_core_export\n+from keras_core.backend import standardize_dtype\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n \n@@ -188,6 +189,12 @@ class BatchNormalization(Layer):\n         return input_shape\n \n     def call(self, inputs, training=None, mask=None):\n+        input_dtype = standardize_dtype(inputs.dtype)\n+        if input_dtype in (\"float16\", \"bfloat16\"):\n+            # BN is prone to overflowing for float16/bfloat16 inputs, so we opt\n+            # out BN for mixed precision.\n+            inputs = ops.cast(inputs, \"float32\")\n+\n         broadcast_shape = [1] * len(inputs.shape)\n         broadcast_shape[self.axis] = inputs.shape[self.axis]\n         if training and self.trainable:\n@@ -198,12 +205,20 @@ class BatchNormalization(Layer):\n             outputs = (inputs - mean) / ops.sqrt(variance + self.epsilon)\n             mean = ops.squeeze(mean, self._reduction_axes)\n             variance = ops.squeeze(variance, self._reduction_axes)\n+            moving_mean = ops.cast(self.moving_mean, inputs.dtype)\n+            moving_variance = ops.cast(self.moving_variance, inputs.dtype)\n             self.moving_mean.assign(\n-                self.moving_mean * self.momentum + mean * (1.0 - self.momentum)\n+                ops.cast(\n+                    moving_mean * self.momentum + mean * (1.0 - self.momentum),\n+                    inputs.dtype,\n+                )\n             )\n             self.moving_variance.assign(\n-                self.moving_variance * self.momentum\n-                + variance * (1.0 - self.momentum)\n+                ops.cast(\n+                    moving_variance * self.momentum\n+                    + variance * (1.0 - self.momentum),\n+                    inputs.dtype,\n+                )\n             )\n         else:\n             moving_mean = ops.reshape(self.moving_mean, broadcast_shape)\n@@ -213,9 +228,11 @@ class BatchNormalization(Layer):\n             )\n         if self.scale:\n             gamma = ops.reshape(self.gamma, broadcast_shape)\n+            gamma = ops.cast(gamma, outputs.dtype)\n             outputs = outputs * gamma\n         if self.center:\n             beta = ops.reshape(self.beta, broadcast_shape)\n+            beta = ops.cast(beta, outputs.dtype)\n             outputs = outputs + beta\n         return outputs\n \n\n@@ -205,9 +205,12 @@ class LayerNormalization(Layer):\n         # Compute the batch normalization.\n         inv = 1 / ops.sqrt(variance + self.epsilon)\n         if scale is not None:\n+            scale = ops.cast(scale, inputs.dtype)\n             inv = inv * scale\n-\n-        x = offset - mean * inv if offset is not None else -mean * inv\n+        x = -mean * inv\n+        if offset is not None:\n+            offset = ops.cast(offset, inputs.dtype)\n+            x = offset + x\n         outputs = inputs * ops.cast(inv, inputs.dtype) + ops.cast(\n             x, inputs.dtype\n         )\n\n@@ -93,7 +93,12 @@ class DTypePolicy:\n         return cls(**config)\n \n \n-@keras_core_export(\"keras_core.mixed_precision.set_dtype_policy\")\n+@keras_core_export(\n+    [\n+        \"keras_core.mixed_precision.set_dtype_policy\",\n+        \"keras_core.mixed_precision.set_global_policy\",\n+    ]\n+)\n def set_dtype_policy(policy):\n     if not isinstance(policy, DTypePolicy):\n         if isinstance(policy, str):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
