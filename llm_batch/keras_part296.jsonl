{"custom_id": "keras#979b636c08f1372f95bdf334cd95ab953d8ac54c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 40 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 12 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 45 | Churn Cumulative: 3897 | Contributors (this commit): 44 | Commits (past 90d): 11 | Contributors (cumulative): 47 | DMM Complexity: 1.0\n\nDIFF:\n@@ -32,7 +32,7 @@ class Loss(object):\n     # Arguments\n         reduction: (Optional) Type of loss Reduction to apply to loss.\n           Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: Optional name for the op.\n+        name: Optional name for the object.\n     \"\"\"\n \n     def __init__(self,\n@@ -295,7 +295,7 @@ class BinaryCrossentropy(LossFunctionWrapper):\n             Larger values of `label_smoothing` correspond to heavier smoothing.\n         reduction: (Optional) Type of loss reduction to apply to loss.\n             Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: (Optional) Name for the op.\n+        name: (Optional) Name for the object.\n     \"\"\"\n \n     def __init__(self,\n@@ -351,7 +351,7 @@ class CategoricalCrossentropy(LossFunctionWrapper):\n             Larger values of `label_smoothing` correspond to heavier smoothing.\n         reduction: (Optional) Type of loss reduction to apply to loss.\n             Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: (Optional) Name for the op.\n+        name: (Optional) Name for the object.\n     \"\"\"\n \n     def __init__(self,\n@@ -404,7 +404,7 @@ class SparseCategoricalCrossentropy(LossFunctionWrapper):\n             (i.e., values in [0, 1]).\n         reduction: (Optional) Type of loss reduction to apply to loss.\n             Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: (Optional) Name for the op.\n+        name: (Optional) Name for the object.\n     \"\"\"\n \n     def __init__(self,\n@@ -430,6 +430,11 @@ class Hinge(LossFunctionWrapper):\n     model = keras.Model(inputs, outputs)\n     model.compile('sgd', loss=keras.losses.Hinge())\n     ```\n+\n+    # Arguments\n+        reduction: (Optional) Type of loss reduction to apply to loss.\n+            Default value is `SUM_OVER_BATCH_SIZE`.\n+        name: (Optional) Name for the object.\n     \"\"\"\n \n     def __init__(self,\n@@ -450,6 +455,11 @@ class SquaredHinge(LossFunctionWrapper):\n     model = keras.Model(inputs, outputs)\n     model.compile('sgd', loss=keras.losses.SquaredHinge())\n     ```\n+\n+    # Arguments\n+        reduction: (Optional) Type of loss reduction to apply to loss.\n+            Default value is `SUM_OVER_BATCH_SIZE`.\n+        name: (Optional) Name for the object.\n     \"\"\"\n \n     def __init__(self,\n@@ -468,6 +478,11 @@ class CategoricalHinge(LossFunctionWrapper):\n     model = keras.Model(inputs, outputs)\n     model.compile('sgd', loss=keras.losses.CategoricalHinge())\n     ```\n+\n+    # Arguments\n+        reduction: (Optional) Type of loss reduction to apply to loss.\n+            Default value is `SUM_OVER_BATCH_SIZE`.\n+        name: (Optional) Name for the object.\n     \"\"\"\n \n     def __init__(self,\n@@ -488,6 +503,11 @@ class Poisson(LossFunctionWrapper):\n     model = keras.Model(inputs, outputs)\n     model.compile('sgd', loss=keras.losses.Poisson())\n     ```\n+\n+    # Arguments\n+        reduction: (Optional) Type of loss reduction to apply to loss.\n+            Default value is `SUM_OVER_BATCH_SIZE`.\n+        name: (Optional) Name for the object.\n     \"\"\"\n \n     def __init__(self,\n@@ -508,6 +528,11 @@ class LogCosh(LossFunctionWrapper):\n     model = keras.Model(inputs, outputs)\n     model.compile('sgd', loss=keras.losses.LogCosh())\n     ```\n+\n+    # Arguments\n+        reduction: (Optional) Type of loss reduction to apply to loss.\n+            Default value is `SUM_OVER_BATCH_SIZE`.\n+        name: (Optional) Name for the object.\n     \"\"\"\n \n     def __init__(self,\n@@ -529,6 +554,11 @@ class KLDivergence(LossFunctionWrapper):\n     model = keras.Model(inputs, outputs)\n     model.compile('sgd', loss=keras.losses.KLDivergence())\n     ```\n+\n+    # Arguments\n+        reduction: (Optional) Type of loss reduction to apply to loss.\n+            Default value is `SUM_OVER_BATCH_SIZE`.\n+        name: (Optional) Name for the object.\n     \"\"\"\n \n     def __init__(self,\n@@ -559,7 +589,7 @@ class Huber(LossFunctionWrapper):\n         delta: A float, the point where the Huber loss function changes from a\n             quadratic to linear.\n         reduction: (Optional) Type of reduction to apply to loss.\n-        name: Optional name for the op.\n+        name: Optional name for the object.\n     \"\"\"\n     def __init__(self,\n                  delta=1.0,\n\n@@ -154,6 +154,11 @@ class Optimizer(object):\n     def from_config(cls, config):\n         return cls(**config)\n \n+    @property\n+    def lr(self):\n+        # Legacy support.\n+        return self.learning_rate\n+\n \n class SGD(Optimizer):\n     \"\"\"Stochastic gradient descent optimizer.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#613aeff37a721450d94906df1a3f3cc51e2299d4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 57/57 | Churn Δ: 2 | Churn Cumulative: 14668 | Contributors (this commit): 131 | Commits (past 90d): 8 | Contributors (cumulative): 131 | DMM Complexity: None\n\nDIFF:\n@@ -3611,7 +3611,7 @@ def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n \n     output_shape = output.get_shape()\n     targets = cast(flatten(target), 'int64')\n-    logits = tf.reshape(output, [-1, int(output_shape[-1])])\n+    logits = tf.reshape(output, [-1, tf.shape(output)[-1]])\n     res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n         labels=targets,\n         logits=logits)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#442423e30d72aeb2f63cce7baee056b0d929930d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 13 | Files Changed: 1 | Hunks: 7 | Methods Changed: 3 | Complexity Δ (Sum/Max): -57/0 | Churn Δ: 16 | Churn Cumulative: 14684 | Contributors (this commit): 131 | Commits (past 90d): 9 | Contributors (cumulative): 131 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1187,7 +1187,6 @@ def count_params(x):\n     return np.prod(int_shape(x))\n \n \n-@symbolic\n def cast(x, dtype):\n     \"\"\"Casts a tensor to a different dtype and returns it.\n \n@@ -1223,7 +1222,6 @@ def cast(x, dtype):\n # UPDATES OPS\n \n \n-@symbolic\n def update(x, new_x):\n     \"\"\"Update the value of `x` to `new_x`.\n \n@@ -1234,12 +1232,9 @@ def update(x, new_x):\n     # Returns\n         The variable `x` updated.\n     \"\"\"\n-    op = tf_state_ops.assign(x, new_x)\n-    with tf.control_dependencies([op]):\n-        return tf.identity(x)\n+    return tf_state_ops.assign(x, new_x)\n \n \n-@symbolic\n def update_add(x, increment):\n     \"\"\"Update the value of `x` by adding `increment`.\n \n@@ -1250,12 +1245,9 @@ def update_add(x, increment):\n     # Returns\n         The variable `x` updated.\n     \"\"\"\n-    op = tf_state_ops.assign_add(x, increment)\n-    with tf.control_dependencies([op]):\n-        return tf.identity(x)\n+    return tf_state_ops.assign_add(x, increment)\n \n \n-@symbolic\n def update_sub(x, decrement):\n     \"\"\"Update the value of `x` by subtracting `decrement`.\n \n@@ -1266,9 +1258,7 @@ def update_sub(x, decrement):\n     # Returns\n         The variable `x` updated.\n     \"\"\"\n-    op = tf_state_ops.assign_sub(x, decrement)\n-    with tf.control_dependencies([op]):\n-        return tf.identity(x)\n+    return tf_state_ops.assign_sub(x, decrement)\n \n \n @symbolic\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#aa04a83d09a5bdbe9379427cfa02ad2e74dc87be", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 33 | Lines Deleted: 27 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 60 | Churn Cumulative: 229 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -95,6 +95,38 @@ def reduce_weighted_loss(weighted_losses, reduction=Reduction.SUM_OVER_BATCH_SIZ\n     return loss\n \n \n+def broadcast_weights(values, sample_weight):\n+    # Broadcast weights if possible.\n+    weights_shape = K.int_shape(sample_weight)\n+    values_shape = K.int_shape(values)\n+    if values_shape != weights_shape:\n+        weights_rank = K.ndim(sample_weight)\n+        values_rank = K.ndim(values)\n+\n+        # Raise error if ndim of weights is > values.\n+        if weights_rank > values_rank:\n+            raise ValueError(\n+                'Incompatible shapes: `values` {} vs `sample_weight` {}'.format(\n+                    values_shape, weights_shape))\n+\n+        # Expand dim of weights to match ndim of values, if required.\n+        for i in range(weights_rank, values_rank):\n+            sample_weight = K.expand_dims(sample_weight, axis=i)\n+\n+        for i in range(weights_rank):\n+            if (weights_shape[i] is not None and values_shape[i] is not None and\n+                    weights_shape[i] != values_shape[i]):\n+                # Cannot be broadcasted.\n+                if weights_shape[i] != 1:\n+                    raise ValueError(\n+                        'Incompatible shapes: `values` {} vs '\n+                        '`sample_weight` {}'.format(\n+                            values_shape, weights_shape))\n+                sample_weight = K.repeat_elements(\n+                    sample_weight, values_shape[i], axis=i)\n+    return sample_weight\n+\n+\n def compute_weighted_loss(losses,\n                           sample_weight=None,\n                           reduction=Reduction.SUM_OVER_BATCH_SIZE,\n@@ -129,33 +161,7 @@ def compute_weighted_loss(losses,\n             losses, None, sample_weight)\n \n         # Broadcast weights if possible.\n-        weights_shape = K.int_shape(sample_weight)\n-        losses_shape = K.int_shape(losses)\n-        if losses_shape != weights_shape:\n-            weights_rank = K.ndim(sample_weight)\n-            losses_rank = K.ndim(losses)\n-\n-            # Raise error if ndim of weights is > losses.\n-            if weights_rank > losses_rank:\n-                raise ValueError(\n-                    'Incompatible shapes: `losses` {} vs `sample_weight` {}'.format(\n-                        losses_shape, weights_shape))\n-\n-            # Expand dim of weights to match ndim of losses, if required.\n-            for i in range(weights_rank, losses_rank):\n-                sample_weight = K.expand_dims(sample_weight, axis=i)\n-\n-            for i in range(weights_rank):\n-                if (weights_shape[i] is not None and losses_shape[i] is not None and\n-                        weights_shape[i] != losses_shape[i]):\n-                    # Cannot be broadcasted.\n-                    if weights_shape[i] != 1:\n-                        raise ValueError(\n-                            'Incompatible shapes: `losses` {} vs '\n-                            '`sample_weight` {}'.format(\n-                                losses_shape, weights_shape))\n-                    sample_weight = K.repeat_elements(\n-                        sample_weight, losses_shape[i], axis=i)\n+        sample_weight = broadcast_weights(losses, sample_weight)\n \n         # Apply weights to losses.\n         weighted_losses = sample_weight * losses\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d01f8cb5d6198a7140daac173f67a179fefb1ba6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 490 | Lines Deleted: 225 | Files Changed: 5 | Hunks: 19 | Methods Changed: 40 | Complexity Δ (Sum/Max): 25/22 | Churn Δ: 715 | Churn Cumulative: 1932 | Contributors (this commit): 27 | Commits (past 90d): 8 | Contributors (cumulative): 42 | DMM Complexity: 0.7419354838709677\n\nDIFF:\n@@ -4,8 +4,12 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n+import abc\n import six\n+import types\n+\n from . import backend as K\n+from .layers import Layer\n from .losses import mean_squared_error\n from .losses import mean_absolute_error\n from .losses import mean_absolute_percentage_error\n@@ -19,10 +23,201 @@ from .losses import binary_crossentropy\n from .losses import kullback_leibler_divergence\n from .losses import poisson\n from .losses import cosine_proximity\n+from .utils import losses_utils\n+from .utils import metrics_utils\n from .utils.generic_utils import deserialize_keras_object\n from .utils.generic_utils import serialize_keras_object\n \n \n+@six.add_metaclass(abc.ABCMeta)\n+class Metric(Layer):\n+    \"\"\"Encapsulates metric logic and state.\n+\n+    Standalone usage:\n+    ```python\n+    m = SomeMetric(...)\n+    for input in ...:\n+        m.update_state(input)\n+    m.result()\n+    ```\n+\n+    Usage with the `compile` API:\n+    ```python\n+    model.compile(optimizer='rmsprop',\n+                  loss=keras.losses.categorical_crossentropy,\n+                  metrics=[keras.metrics.CategoricalAccuracy()])\n+    ```\n+\n+    To be implemented by subclasses:\n+    * `__init__()`: All state variables should be created in this method by\n+        calling `self.add_weight()` like: `self.var = self.add_weight(...)`\n+    * `update_state()`: Has all updates to the state variables like:\n+        self.var.assign_add(...).\n+    * `result()`: Computes and returns a value for the metric\n+        from the state variables.\n+    \"\"\"\n+\n+    def __init__(self, name=None, dtype=None, **kwargs):\n+        super(Metric, self).__init__(name=name, dtype=dtype, **kwargs)\n+        self.stateful = True  # All metric layers are stateful.\n+        self.built = True\n+        self.dtype = K.floatx() if dtype is None else dtype\n+\n+    def __new__(cls, *args, **kwargs):\n+        obj = super(Metric, cls).__new__(cls)\n+        update_state_fn = obj.update_state\n+\n+        obj.update_state = types.MethodType(\n+            metrics_utils.update_state_wrapper(update_state_fn), obj)\n+        return obj\n+\n+    def __call__(self, *args, **kwargs):\n+        \"\"\"Accumulates statistics and then computes metric result value.\"\"\"\n+        update_op = self.update_state(*args, **kwargs)\n+        return self.result()\n+\n+    def get_config(self):\n+        \"\"\"Returns the serializable config of the metric.\"\"\"\n+        return {'name': self.name, 'dtype': self.dtype}\n+\n+    def reset_states(self):\n+        \"\"\"Resets all of the metric state variables.\n+        This function is called between epochs/steps,\n+        when a metric is evaluated during training.\n+        \"\"\"\n+        K.batch_set_value([(v, 0) for v in self.weights])\n+\n+    @abc.abstractmethod\n+    def update_state(self, *args, **kwargs):\n+        \"\"\"Accumulates statistics for the metric. \"\"\"\n+        raise NotImplementedError('Must be implemented in subclasses.')\n+\n+    @abc.abstractmethod\n+    def result(self):\n+        \"\"\"Computes and returns the metric value tensor.\n+        Result computation is an idempotent operation that simply calculates the\n+        metric value using the state variables.\n+        \"\"\"\n+        raise NotImplementedError('Must be implemented in subclasses.')\n+\n+    # For use by subclasses #\n+    def add_weight(self,\n+                   name,\n+                   shape=(),\n+                   initializer=None,\n+                   dtype=None):\n+        \"\"\"Adds state variable. Only for use by subclasses.\"\"\"\n+        return super(Metric, self).add_weight(\n+            name=name,\n+            shape=shape,\n+            dtype=self.dtype if dtype is None else dtype,\n+            trainable=False,\n+            initializer=initializer)\n+\n+    # End: For use by subclasses ###\n+\n+\n+class Reduce(Metric):\n+    \"\"\"Encapsulates metrics that perform a reduce operation on the values.\"\"\"\n+\n+    def __init__(self, reduction, name, dtype=None):\n+        \"\"\"Creates a `Reduce` instance.\n+        # Arguments\n+            reduction: a metrics `Reduction` enum value.\n+            name: string name of the metric instance.\n+            dtype: (Optional) data type of the metric result.\n+        \"\"\"\n+        super(Reduce, self).__init__(name=name, dtype=dtype)\n+        self.reduction = reduction\n+        self.total = self.add_weight('total', initializer='zeros')\n+        if reduction in [metrics_utils.Reduction.SUM_OVER_BATCH_SIZE,\n+                         metrics_utils.Reduction.WEIGHTED_MEAN]:\n+            self.count = self.add_weight('count', initializer='zeros')\n+\n+    def update_state(self, values, sample_weight=None):\n+        \"\"\"Accumulates statistics for computing the reduction metric.\n+        For example, if `values` is [1, 3, 5, 7] and reduction=SUM_OVER_BATCH_SIZE,\n+        then the value of `result()` is 4. If the `sample_weight` is specified as\n+        [1, 1, 0, 0] then value of `result()` would be 2.\n+        # Arguments\n+            values: Per-example value.\n+            sample_weight: Optional weighting of each example. Defaults to 1.\n+        \"\"\"\n+        values = K.cast(values, self.dtype)\n+        if sample_weight is not None:\n+            sample_weight = K.cast(sample_weight, self.dtype)\n+            # Update dimensions of weights to match with values if possible.\n+            values, _, sample_weight = losses_utils.squeeze_or_expand_dimensions(\n+                values, sample_weight=sample_weight)\n+\n+            # Broadcast weights if possible.\n+            sample_weight = losses_utils.broadcast_weights(sample_weight, values)\n+            values = values * sample_weight\n+\n+        value_sum = K.sum(values)\n+        update_total_op = K.update_add(self.total, value_sum)\n+\n+        # Exit early if the reduction doesn't have a denominator.\n+        if self.reduction == metrics_utils.Reduction.SUM:\n+            return update_total_op\n+\n+        # Update `count` for reductions that require a denominator.\n+        if self.reduction == metrics_utils.Reduction.SUM_OVER_BATCH_SIZE:\n+            num_values = K.cast(K.size(values), self.dtype)\n+        elif self.reduction == metrics_utils.Reduction.WEIGHTED_MEAN:\n+            if sample_weight is None:\n+                num_values = K.cast(K.size(values), self.dtype)\n+            else:\n+                num_values = K.sum(sample_weight)\n+        else:\n+            raise NotImplementedError(\n+                'reduction [%s] not implemented' % self.reduction)\n+\n+        with K.control_dependencies([update_total_op]):\n+            return K.update_add(self.count, num_values)\n+\n+    def result(self):\n+        if self.reduction == metrics_utils.Reduction.SUM:\n+            return self.total\n+        elif self.reduction in [\n+            metrics_utils.Reduction.WEIGHTED_MEAN,\n+            metrics_utils.Reduction.SUM_OVER_BATCH_SIZE\n+        ]:\n+            return self.total / self.count\n+        else:\n+            raise NotImplementedError(\n+                'reduction [%s] not implemented' % self.reduction)\n+\n+\n+class Sum(Reduce):\n+    \"\"\"Computes the (weighted) sum of the given values.\n+\n+    For example, if values is [1, 3, 5, 7] then the sum is 16.\n+    If the weights were specified as [1, 1, 0, 0] then the sum would be 4.\n+\n+    This metric creates one variable, `total`, that is used to compute the sum of\n+    `values`. This is ultimately returned as `sum`.\n+    If `sample_weight` is `None`, weights default to 1.  Use `sample_weight` of 0\n+    to mask values.\n+\n+    Standalone usage:\n+    ```python\n+    m = keras.metrics.Sum()\n+    m.update_state([1, 3, 5, 7])\n+    m.result()\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, name='sum', dtype=None):\n+        \"\"\"Creates a `Sum` instance.\n+        # Arguments\n+            name: (Optional) string name of the metric instance.\n+            dtype: (Optional) data type of the metric result.\n+        \"\"\"\n+        super(Sum, self).__init__(reduction=metrics_utils.Reduction.SUM,\n+                                  name=name, dtype=dtype)\n+\n+\n def binary_accuracy(y_true, y_pred):\n     return K.mean(K.equal(y_true, K.round(y_pred)), axis=-1)\n \n\n@@ -5,6 +5,7 @@ from . import data_utils\n from . import io_utils\n from . import conv_utils\n from . import losses_utils\n+from . import metrics_utils\n \n # Globally-importable utils.\n from .io_utils import HDF5Matrix\n\n@@ -0,0 +1,35 @@\n+\"\"\"Utilities related to metrics.\"\"\"\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+\n+class Reduction(object):\n+    \"\"\"Types of metrics reduction.\n+    Contains the following values:\n+    * `SUM`: Scalar sum of weighted values.\n+    * `SUM_OVER_BATCH_SIZE`: Scalar `SUM` of weighted values divided by\n+        number of elements in values.\n+    * `WEIGHTED_MEAN`: Scalar sum of weighted values divided by sum of weights.\n+    \"\"\"\n+\n+    SUM = 'sum'\n+    SUM_OVER_BATCH_SIZE = 'sum_over_batch_size'\n+    WEIGHTED_MEAN = 'weighted_mean'\n+\n+\n+def update_state_wrapper(update_state_fn):\n+    \"\"\"Decorator to wrap metric `update_state()` with `add_update()`.\n+    # Arguments\n+        update_state_fn: function that accumulates metric statistics.\n+    # Returns\n+        Decorated function that wraps `update_state_fn()` with `add_update()`.\n+    \"\"\"\n+    def decorated(metric_obj, *args, **kwargs):\n+        \"\"\"Decorated function with `add_update()`.\"\"\"\n+\n+        update_op = update_state_fn(*args, **kwargs)\n+        metric_obj.add_update(update_op)\n+        return update_op\n+\n+    return decorated\n\n@@ -0,0 +1,238 @@\n+import pytest\n+import numpy as np\n+from numpy.testing import assert_allclose\n+from flaky import flaky\n+\n+import keras\n+from keras import metrics\n+from keras import backend as K\n+\n+all_metrics = [\n+    metrics.binary_accuracy,\n+    metrics.categorical_accuracy,\n+    metrics.mean_squared_error,\n+    metrics.mean_absolute_error,\n+    metrics.mean_absolute_percentage_error,\n+    metrics.mean_squared_logarithmic_error,\n+    metrics.squared_hinge,\n+    metrics.hinge,\n+    metrics.categorical_crossentropy,\n+    metrics.binary_crossentropy,\n+    metrics.poisson,\n+    metrics.cosine_proximity,\n+    metrics.logcosh,\n+]\n+\n+all_sparse_metrics = [\n+    metrics.sparse_categorical_accuracy,\n+    metrics.sparse_categorical_crossentropy,\n+]\n+\n+\n+@pytest.mark.parametrize('metric', all_metrics)\n+def test_metrics(metric):\n+    y_a = K.variable(np.random.random((6, 7)))\n+    y_b = K.variable(np.random.random((6, 7)))\n+    output = metric(y_a, y_b)\n+    assert K.eval(output).shape == (6,)\n+\n+\n+@pytest.mark.parametrize('metric', all_sparse_metrics)\n+def test_sparse_metrics(metric):\n+    y_a = K.variable(np.random.randint(0, 7, (6,)), dtype=K.floatx())\n+    y_b = K.variable(np.random.random((6, 7)), dtype=K.floatx())\n+    assert K.eval(metric(y_a, y_b)).shape == (6,)\n+\n+\n+@pytest.mark.parametrize('shape', [(6,), (6, 3), (6, 3, 1)])\n+def test_sparse_categorical_accuracy_correctness(shape):\n+    y_a = K.variable(np.random.randint(0, 7, shape), dtype=K.floatx())\n+    y_b_shape = shape + (7,)\n+    y_b = K.variable(np.random.random(y_b_shape), dtype=K.floatx())\n+    # use one_hot embedding to convert sparse labels to equivalent dense labels\n+    y_a_dense_labels = K.cast(K.one_hot(K.cast(y_a, dtype='int32'), 7),\n+                              dtype=K.floatx())\n+    sparse_categorical_acc = metrics.sparse_categorical_accuracy(y_a, y_b)\n+    categorical_acc = metrics.categorical_accuracy(y_a_dense_labels, y_b)\n+    assert np.allclose(K.eval(sparse_categorical_acc), K.eval(categorical_acc))\n+\n+\n+def test_serialize():\n+    '''This is a mock 'round trip' of serialize and deserialize.\n+    '''\n+\n+    class MockMetric:\n+        def __init__(self):\n+            self.__name__ = \"mock_metric\"\n+\n+    mock = MockMetric()\n+    found = metrics.serialize(mock)\n+    assert found == \"mock_metric\"\n+\n+    found = metrics.deserialize('mock_metric',\n+                                custom_objects={'mock_metric': True})\n+    assert found is True\n+\n+\n+def test_invalid_get():\n+\n+    with pytest.raises(ValueError):\n+        metrics.get(5)\n+\n+\n+@pytest.mark.skipif((K.backend() == 'cntk'),\n+                    reason='CNTK backend does not support top_k yet')\n+def test_top_k_categorical_accuracy():\n+    y_pred = K.variable(np.array([[0.3, 0.2, 0.1], [0.1, 0.2, 0.7]]))\n+    y_true = K.variable(np.array([[0, 1, 0], [1, 0, 0]]))\n+    success_result = K.eval(metrics.top_k_categorical_accuracy(y_true, y_pred,\n+                                                               k=3))\n+    assert np.mean(success_result) == 1\n+    partial_result = K.eval(metrics.top_k_categorical_accuracy(y_true, y_pred,\n+                                                               k=2))\n+    assert np.mean(partial_result) == 0.5\n+    failure_result = K.eval(metrics.top_k_categorical_accuracy(y_true, y_pred,\n+                                                               k=1))\n+    assert np.mean(failure_result) == 0\n+\n+\n+@pytest.mark.skipif((K.backend() == 'cntk'),\n+                    reason='CNTK backend does not support top_k yet')\n+@pytest.mark.parametrize('y_pred, y_true', [\n+    # Test correctness if the shape of y_true is (num_samples, 1)\n+    (np.array([[0.3, 0.2, 0.1], [0.1, 0.2, 0.7]]), np.array([[1], [0]])),\n+    # Test correctness if the shape of y_true is (num_samples,)\n+    (np.array([[0.3, 0.2, 0.1], [0.1, 0.2, 0.7]]), np.array([1, 0])),\n+])\n+def test_sparse_top_k_categorical_accuracy(y_pred, y_true):\n+    y_pred = K.variable(y_pred)\n+    y_true = K.variable(y_true)\n+    success_result = K.eval(\n+        metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=3))\n+\n+    assert np.mean(success_result) == 1\n+    partial_result = K.eval(\n+        metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=2))\n+\n+    assert np.mean(partial_result) == 0.5\n+    failure_result = K.eval(\n+        metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=1))\n+\n+    assert np.mean(failure_result) == 0\n+\n+\n+# TODO: resolve flakyness issue. Tracked with #11064\n+@pytest.mark.parametrize('metrics_mode', ['list', 'dict'])\n+@flaky(rerun_filter=lambda err, *args: issubclass(err[0], AssertionError))\n+def test_stateful_metrics(metrics_mode):\n+    np.random.seed(1334)\n+\n+    class BinaryTruePositives(keras.layers.Layer):\n+        \"\"\"Stateful Metric to count the total true positives over all batches.\n+\n+        Assumes predictions and targets of shape `(samples, 1)`.\n+\n+        # Arguments\n+            name: String, name for the metric.\n+        \"\"\"\n+\n+        def __init__(self, name='true_positives', **kwargs):\n+            super(BinaryTruePositives, self).__init__(name=name, **kwargs)\n+            self.stateful = True\n+            self.true_positives = K.variable(value=0, dtype='int32')\n+\n+        def reset_states(self):\n+            K.set_value(self.true_positives, 0)\n+\n+        def __call__(self, y_true, y_pred):\n+            \"\"\"Computes the number of true positives in a batch.\n+\n+            # Arguments\n+                y_true: Tensor, batch_wise labels\n+                y_pred: Tensor, batch_wise predictions\n+\n+            # Returns\n+                The total number of true positives seen this epoch at the\n+                    completion of the batch.\n+            \"\"\"\n+            y_true = K.cast(y_true, 'int32')\n+            y_pred = K.cast(K.round(y_pred), 'int32')\n+            correct_preds = K.cast(K.equal(y_pred, y_true), 'int32')\n+            true_pos = K.cast(K.sum(correct_preds * y_true), 'int32')\n+            current_true_pos = self.true_positives * 1\n+            self.add_update(K.update_add(self.true_positives,\n+                                         true_pos),\n+                            inputs=[y_true, y_pred])\n+            return current_true_pos + true_pos\n+\n+    metric_fn = BinaryTruePositives()\n+    config = metrics.serialize(metric_fn)\n+    metric_fn = metrics.deserialize(\n+        config, custom_objects={'BinaryTruePositives': BinaryTruePositives})\n+\n+    # Test on simple model\n+    inputs = keras.Input(shape=(2,))\n+    outputs = keras.layers.Dense(1, activation='sigmoid', name='out')(inputs)\n+    model = keras.Model(inputs, outputs)\n+\n+    if metrics_mode == 'list':\n+        model.compile(optimizer='sgd',\n+                      loss='binary_crossentropy',\n+                      metrics=['acc', metric_fn])\n+    elif metrics_mode == 'dict':\n+        model.compile(optimizer='sgd',\n+                      loss='binary_crossentropy',\n+                      metrics={'out': ['acc', metric_fn]})\n+\n+    samples = 1000\n+    x = np.random.random((samples, 2))\n+    y = np.random.randint(2, size=(samples, 1))\n+\n+    val_samples = 10\n+    val_x = np.random.random((val_samples, 2))\n+    val_y = np.random.randint(2, size=(val_samples, 1))\n+\n+    # Test fit and evaluate\n+    history = model.fit(x, y, validation_data=(val_x, val_y),\n+                        epochs=1, batch_size=10)\n+    outs = model.evaluate(x, y, batch_size=10)\n+    preds = model.predict(x)\n+\n+    def ref_true_pos(y_true, y_pred):\n+        return np.sum(np.logical_and(y_pred > 0.5, y_true == 1))\n+\n+    # Test correctness (e.g. updates should have been run)\n+    np.testing.assert_allclose(outs[2], ref_true_pos(y, preds), atol=1e-5)\n+\n+    # Test correctness of the validation metric computation\n+    val_preds = model.predict(val_x)\n+    val_outs = model.evaluate(val_x, val_y, batch_size=10)\n+    assert_allclose(val_outs[2], ref_true_pos(val_y, val_preds), atol=1e-5)\n+    assert_allclose(val_outs[2], history.history['val_true_positives'][-1],\n+                    atol=1e-5)\n+\n+    # Test with generators\n+    gen = [(np.array([x0]), np.array([y0])) for x0, y0 in zip(x, y)]\n+    val_gen = [(np.array([x0]), np.array([y0])) for x0, y0 in zip(val_x, val_y)]\n+    history = model.fit_generator(iter(gen), epochs=1, steps_per_epoch=samples,\n+                                  validation_data=iter(val_gen),\n+                                  validation_steps=val_samples)\n+    outs = model.evaluate_generator(iter(gen), steps=samples, workers=0)\n+    preds = model.predict_generator(iter(gen), steps=samples, workers=0)\n+\n+    # Test correctness of the metric re ref_true_pos()\n+    np.testing.assert_allclose(outs[2], ref_true_pos(y, preds),\n+                               atol=1e-5)\n+\n+    # Test correctness of the validation metric computation\n+    val_preds = model.predict_generator(iter(val_gen), steps=val_samples, workers=0)\n+    val_outs = model.evaluate_generator(iter(val_gen), steps=val_samples, workers=0)\n+    np.testing.assert_allclose(val_outs[2], ref_true_pos(val_y, val_preds),\n+                               atol=1e-5)\n+    np.testing.assert_allclose(val_outs[2],\n+                               history.history['val_true_positives'][-1],\n+                               atol=1e-5)\n+\n+\n+if __name__ == '__main__':\n+    pytest.main([__file__])\n\n@@ -1,238 +1,34 @@\n+\"\"\"Tests for Keras metrics classes.\"\"\"\n import pytest\n import numpy as np\n-from numpy.testing import assert_allclose\n-from flaky import flaky\n \n-import keras\n from keras import metrics\n from keras import backend as K\n \n-all_metrics = [\n-    metrics.binary_accuracy,\n-    metrics.categorical_accuracy,\n-    metrics.mean_squared_error,\n-    metrics.mean_absolute_error,\n-    metrics.mean_absolute_percentage_error,\n-    metrics.mean_squared_logarithmic_error,\n-    metrics.squared_hinge,\n-    metrics.hinge,\n-    metrics.categorical_crossentropy,\n-    metrics.binary_crossentropy,\n-    metrics.poisson,\n-    metrics.cosine_proximity,\n-    metrics.logcosh,\n-]\n \n-all_sparse_metrics = [\n-    metrics.sparse_categorical_accuracy,\n-    metrics.sparse_categorical_crossentropy,\n-]\n+class TestKerasSum:\n \n+    def test_sum(self):\n+        m = metrics.Sum(name='my_sum', dtype='float32')\n \n-@pytest.mark.parametrize('metric', all_metrics)\n-def test_metrics(metric):\n-    y_a = K.variable(np.random.random((6, 7)))\n-    y_b = K.variable(np.random.random((6, 7)))\n-    output = metric(y_a, y_b)\n-    assert K.eval(output).shape == (6,)\n+        # check config\n+        assert m.name == 'my_sum'\n+        assert m.stateful\n+        assert m.dtype == 'float32'\n+        assert len(m.weights) == 1\n \n+        # check initial state\n+        assert K.eval(m.total) == 0\n \n-@pytest.mark.parametrize('metric', all_sparse_metrics)\n-def test_sparse_metrics(metric):\n-    y_a = K.variable(np.random.randint(0, 7, (6,)), dtype=K.floatx())\n-    y_b = K.variable(np.random.random((6, 7)), dtype=K.floatx())\n-    assert K.eval(metric(y_a, y_b)).shape == (6,)\n+        # check __call__\n+        assert K.eval(m(100.0)) == 100\n+        assert K.eval(m.total) == 100\n \n+        # check update_state() and result() + state accumulation + tensor input\n+        K.eval(m.update_state([1, 5]))\n+        assert np.isclose(K.eval(m.result()), 106)\n+        assert K.eval(m.total) == 106  # 100 + 1 + 5\n \n-@pytest.mark.parametrize('shape', [(6,), (6, 3), (6, 3, 1)])\n-def test_sparse_categorical_accuracy_correctness(shape):\n-    y_a = K.variable(np.random.randint(0, 7, shape), dtype=K.floatx())\n-    y_b_shape = shape + (7,)\n-    y_b = K.variable(np.random.random(y_b_shape), dtype=K.floatx())\n-    # use one_hot embedding to convert sparse labels to equivalent dense labels\n-    y_a_dense_labels = K.cast(K.one_hot(K.cast(y_a, dtype='int32'), 7),\n-                              dtype=K.floatx())\n-    sparse_categorical_acc = metrics.sparse_categorical_accuracy(y_a, y_b)\n-    categorical_acc = metrics.categorical_accuracy(y_a_dense_labels, y_b)\n-    assert np.allclose(K.eval(sparse_categorical_acc), K.eval(categorical_acc))\n-\n-\n-def test_serialize():\n-    '''This is a mock 'round trip' of serialize and deserialize.\n-    '''\n-\n-    class MockMetric:\n-        def __init__(self):\n-            self.__name__ = \"mock_metric\"\n-\n-    mock = MockMetric()\n-    found = metrics.serialize(mock)\n-    assert found == \"mock_metric\"\n-\n-    found = metrics.deserialize('mock_metric',\n-                                custom_objects={'mock_metric': True})\n-    assert found is True\n-\n-\n-def test_invalid_get():\n-\n-    with pytest.raises(ValueError):\n-        metrics.get(5)\n-\n-\n-@pytest.mark.skipif((K.backend() == 'cntk'),\n-                    reason='CNTK backend does not support top_k yet')\n-def test_top_k_categorical_accuracy():\n-    y_pred = K.variable(np.array([[0.3, 0.2, 0.1], [0.1, 0.2, 0.7]]))\n-    y_true = K.variable(np.array([[0, 1, 0], [1, 0, 0]]))\n-    success_result = K.eval(metrics.top_k_categorical_accuracy(y_true, y_pred,\n-                                                               k=3))\n-    assert np.mean(success_result) == 1\n-    partial_result = K.eval(metrics.top_k_categorical_accuracy(y_true, y_pred,\n-                                                               k=2))\n-    assert np.mean(partial_result) == 0.5\n-    failure_result = K.eval(metrics.top_k_categorical_accuracy(y_true, y_pred,\n-                                                               k=1))\n-    assert np.mean(failure_result) == 0\n-\n-\n-@pytest.mark.skipif((K.backend() == 'cntk'),\n-                    reason='CNTK backend does not support top_k yet')\n-@pytest.mark.parametrize('y_pred, y_true', [\n-    # Test correctness if the shape of y_true is (num_samples, 1)\n-    (np.array([[0.3, 0.2, 0.1], [0.1, 0.2, 0.7]]), np.array([[1], [0]])),\n-    # Test correctness if the shape of y_true is (num_samples,)\n-    (np.array([[0.3, 0.2, 0.1], [0.1, 0.2, 0.7]]), np.array([1, 0])),\n-])\n-def test_sparse_top_k_categorical_accuracy(y_pred, y_true):\n-    y_pred = K.variable(y_pred)\n-    y_true = K.variable(y_true)\n-    success_result = K.eval(\n-        metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=3))\n-\n-    assert np.mean(success_result) == 1\n-    partial_result = K.eval(\n-        metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=2))\n-\n-    assert np.mean(partial_result) == 0.5\n-    failure_result = K.eval(\n-        metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=1))\n-\n-    assert np.mean(failure_result) == 0\n-\n-\n-# TODO: resolve flakyness issue. Tracked with #11064\n-@pytest.mark.parametrize('metrics_mode', ['list', 'dict'])\n-@flaky(rerun_filter=lambda err, *args: issubclass(err[0], AssertionError))\n-def test_stateful_metrics(metrics_mode):\n-    np.random.seed(1334)\n-\n-    class BinaryTruePositives(keras.layers.Layer):\n-        \"\"\"Stateful Metric to count the total true positives over all batches.\n-\n-        Assumes predictions and targets of shape `(samples, 1)`.\n-\n-        # Arguments\n-            name: String, name for the metric.\n-        \"\"\"\n-\n-        def __init__(self, name='true_positives', **kwargs):\n-            super(BinaryTruePositives, self).__init__(name=name, **kwargs)\n-            self.stateful = True\n-            self.true_positives = K.variable(value=0, dtype='int32')\n-\n-        def reset_states(self):\n-            K.set_value(self.true_positives, 0)\n-\n-        def __call__(self, y_true, y_pred):\n-            \"\"\"Computes the number of true positives in a batch.\n-\n-            # Arguments\n-                y_true: Tensor, batch_wise labels\n-                y_pred: Tensor, batch_wise predictions\n-\n-            # Returns\n-                The total number of true positives seen this epoch at the\n-                    completion of the batch.\n-            \"\"\"\n-            y_true = K.cast(y_true, 'int32')\n-            y_pred = K.cast(K.round(y_pred), 'int32')\n-            correct_preds = K.cast(K.equal(y_pred, y_true), 'int32')\n-            true_pos = K.cast(K.sum(correct_preds * y_true), 'int32')\n-            current_true_pos = self.true_positives * 1\n-            self.add_update(K.update_add(self.true_positives,\n-                                         true_pos),\n-                            inputs=[y_true, y_pred])\n-            return current_true_pos + true_pos\n-\n-    metric_fn = BinaryTruePositives()\n-    config = metrics.serialize(metric_fn)\n-    metric_fn = metrics.deserialize(\n-        config, custom_objects={'BinaryTruePositives': BinaryTruePositives})\n-\n-    # Test on simple model\n-    inputs = keras.Input(shape=(2,))\n-    outputs = keras.layers.Dense(1, activation='sigmoid', name='out')(inputs)\n-    model = keras.Model(inputs, outputs)\n-\n-    if metrics_mode == 'list':\n-        model.compile(optimizer='sgd',\n-                      loss='binary_crossentropy',\n-                      metrics=['acc', metric_fn])\n-    elif metrics_mode == 'dict':\n-        model.compile(optimizer='sgd',\n-                      loss='binary_crossentropy',\n-                      metrics={'out': ['acc', metric_fn]})\n-\n-    samples = 1000\n-    x = np.random.random((samples, 2))\n-    y = np.random.randint(2, size=(samples, 1))\n-\n-    val_samples = 10\n-    val_x = np.random.random((val_samples, 2))\n-    val_y = np.random.randint(2, size=(val_samples, 1))\n-\n-    # Test fit and evaluate\n-    history = model.fit(x, y, validation_data=(val_x, val_y),\n-                        epochs=1, batch_size=10)\n-    outs = model.evaluate(x, y, batch_size=10)\n-    preds = model.predict(x)\n-\n-    def ref_true_pos(y_true, y_pred):\n-        return np.sum(np.logical_and(y_pred > 0.5, y_true == 1))\n-\n-    # Test correctness (e.g. updates should have been run)\n-    np.testing.assert_allclose(outs[2], ref_true_pos(y, preds), atol=1e-5)\n-\n-    # Test correctness of the validation metric computation\n-    val_preds = model.predict(val_x)\n-    val_outs = model.evaluate(val_x, val_y, batch_size=10)\n-    assert_allclose(val_outs[2], ref_true_pos(val_y, val_preds), atol=1e-5)\n-    assert_allclose(val_outs[2], history.history['val_true_positives'][-1],\n-                    atol=1e-5)\n-\n-    # Test with generators\n-    gen = [(np.array([x0]), np.array([y0])) for x0, y0 in zip(x, y)]\n-    val_gen = [(np.array([x0]), np.array([y0])) for x0, y0 in zip(val_x, val_y)]\n-    history = model.fit_generator(iter(gen), epochs=1, steps_per_epoch=samples,\n-                                  validation_data=iter(val_gen),\n-                                  validation_steps=val_samples)\n-    outs = model.evaluate_generator(iter(gen), steps=samples, workers=0)\n-    preds = model.predict_generator(iter(gen), steps=samples, workers=0)\n-\n-    # Test correctness of the metric re ref_true_pos()\n-    np.testing.assert_allclose(outs[2], ref_true_pos(y, preds),\n-                               atol=1e-5)\n-\n-    # Test correctness of the validation metric computation\n-    val_preds = model.predict_generator(iter(val_gen), steps=val_samples, workers=0)\n-    val_outs = model.evaluate_generator(iter(val_gen), steps=val_samples, workers=0)\n-    np.testing.assert_allclose(val_outs[2], ref_true_pos(val_y, val_preds),\n-                               atol=1e-5)\n-    np.testing.assert_allclose(val_outs[2],\n-                               history.history['val_true_positives'][-1],\n-                               atol=1e-5)\n-\n-\n-if __name__ == '__main__':\n-    pytest.main([__file__])\n+        # check reset_states()\n+        m.reset_states()\n+        assert K.eval(m.total) == 0\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fd35671505f7b9523e14b75ffc061d20c7aaa98d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 8 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 1060 | Contributors (this commit): 17 | Commits (past 90d): 5 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -82,6 +82,7 @@ class Metric(Layer):\n \n     def reset_states(self):\n         \"\"\"Resets all of the metric state variables.\n+\n         This function is called between epochs/steps,\n         when a metric is evaluated during training.\n         \"\"\"\n@@ -95,6 +96,7 @@ class Metric(Layer):\n     @abc.abstractmethod\n     def result(self):\n         \"\"\"Computes and returns the metric value tensor.\n+\n         Result computation is an idempotent operation that simply calculates the\n         metric value using the state variables.\n         \"\"\"\n@@ -122,6 +124,7 @@ class Reduce(Metric):\n \n     def __init__(self, reduction, name, dtype=None):\n         \"\"\"Creates a `Reduce` instance.\n+\n         # Arguments\n             reduction: a metrics `Reduction` enum value.\n             name: string name of the metric instance.\n@@ -136,9 +139,11 @@ class Reduce(Metric):\n \n     def update_state(self, values, sample_weight=None):\n         \"\"\"Accumulates statistics for computing the reduction metric.\n+\n         For example, if `values` is [1, 3, 5, 7] and reduction=SUM_OVER_BATCH_SIZE,\n         then the value of `result()` is 4. If the `sample_weight` is specified as\n         [1, 1, 0, 0] then value of `result()` would be 2.\n+\n         # Arguments\n             values: Per-example value.\n             sample_weight: Optional weighting of each example. Defaults to 1.\n\n@@ -6,6 +6,7 @@ from __future__ import print_function\n \n class Reduction(object):\n     \"\"\"Types of metrics reduction.\n+\n     Contains the following values:\n     * `SUM`: Scalar sum of weighted values.\n     * `SUM_OVER_BATCH_SIZE`: Scalar `SUM` of weighted values divided by\n@@ -20,8 +21,10 @@ class Reduction(object):\n \n def update_state_wrapper(update_state_fn):\n     \"\"\"Decorator to wrap metric `update_state()` with `add_update()`.\n+\n     # Arguments\n         update_state_fn: function that accumulates metric statistics.\n+\n     # Returns\n         Decorated function that wraps `update_state_fn()` with `add_update()`.\n     \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e73a8ce6f75f6dfdc71bc46dd1d784c96590e6cb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 43 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 6 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 46 | Churn Cumulative: 1891 | Contributors (this commit): 23 | Commits (past 90d): 11 | Contributors (cumulative): 33 | DMM Complexity: 1.0\n\nDIFF:\n@@ -151,12 +151,14 @@ class Reduce(Metric):\n         values = K.cast(values, self.dtype)\n         if sample_weight is not None:\n             sample_weight = K.cast(sample_weight, self.dtype)\n+\n             # Update dimensions of weights to match with values if possible.\n             values, _, sample_weight = losses_utils.squeeze_or_expand_dimensions(\n                 values, sample_weight=sample_weight)\n \n             # Broadcast weights if possible.\n-            sample_weight = losses_utils.broadcast_weights(sample_weight, values)\n+            sample_weight = losses_utils.broadcast_weights(values, sample_weight)\n+\n             values = values * sample_weight\n \n         value_sum = K.sum(values)\n\n@@ -35,7 +35,7 @@ class Reduction(object):\n             raise ValueError('Invalid Reduction Key %s.' % key)\n \n \n-def squeeze_or_expand_dimensions(y_pred, y_true, sample_weight):\n+def squeeze_or_expand_dimensions(y_pred, y_true=None, sample_weight=None):\n     \"\"\"Squeeze or expand last dimension if needed.\n \n     1. Squeezes last dim of `y_pred` or `y_true` if their rank differs by 1.\n@@ -66,7 +66,7 @@ def squeeze_or_expand_dimensions(y_pred, y_true, sample_weight):\n             y_true = K.squeeze(y_true, -1)\n \n     if sample_weight is None:\n-        return y_pred, y_true, None\n+        return y_pred, y_true\n \n     y_pred_rank = K.ndim(y_pred)\n     weights_rank = K.ndim(sample_weight)\n@@ -99,6 +99,7 @@ def broadcast_weights(values, sample_weight):\n     # Broadcast weights if possible.\n     weights_shape = K.int_shape(sample_weight)\n     values_shape = K.int_shape(values)\n+\n     if values_shape != weights_shape:\n         weights_rank = K.ndim(sample_weight)\n         values_rank = K.ndim(values)\n\n@@ -32,3 +32,40 @@ class TestKerasSum:\n         # check reset_states()\n         m.reset_states()\n         assert K.eval(m.total) == 0\n+\n+    def test_sum_with_sample_weight(self):\n+        m = metrics.Sum(dtype='float64')\n+        assert m.dtype == 'float64'\n+\n+        # check scalar weight\n+        result_t = m(100, sample_weight=0.5)\n+        assert K.eval(result_t) == 50\n+        assert K.eval(m.total) == 50\n+\n+        # check weights not scalar and weights rank matches values rank\n+        result_t = m([1, 5], sample_weight=[1, 0.2])\n+        result = K.eval(result_t)\n+        assert np.isclose(result, 52.)  # 50 + 1 + 5 * 0.2\n+        assert np.isclose(K.eval(m.total), 52.)\n+\n+        # check weights broadcast\n+        result_t = m([1, 2], sample_weight=0.5)\n+        assert np.isclose(K.eval(result_t), 53.5)  # 52 + 0.5 + 1\n+        assert np.isclose(K.eval(m.total), 53.5)\n+\n+        # check weights squeeze\n+        result_t = m([1, 5], sample_weight=[[1], [0.2]])\n+        assert np.isclose(K.eval(result_t), 55.5)  # 53.5 + 1 + 1\n+        assert np.isclose(K.eval(m.total), 55.5)\n+\n+        # check weights expand\n+        result_t = m([[1], [5]], sample_weight=[1, 0.2])\n+        assert np.isclose(K.eval(result_t), 57.5, 2)  # 55.5 + 1 + 1\n+        assert np.isclose(K.eval(m.total), 57.5, 1)\n+\n+        # check values reduced to the dimensions of weight\n+        result_t = m([[[1., 2.], [3., 2.], [0.5, 4.]]], sample_weight=[0.5])\n+        result = np.round(K.eval(result_t), decimals=2)\n+        # result = (prev: 57.5) + 0.5 + 1 + 1.5 + 1 + 0.25 + 2\n+        assert np.isclose(result, 63.75, 2)\n+        assert np.isclose(K.eval(m.total), 63.75, 2)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7350d1e85b6107619860f814315a30299f8cdcca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 137 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 5 | Methods Changed: 6 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 139 | Churn Cumulative: 1796 | Contributors (this commit): 23 | Commits (past 90d): 9 | Contributors (cumulative): 32 | DMM Complexity: 1.0\n\nDIFF:\n@@ -180,7 +180,6 @@ class Reduce(Metric):\n             raise NotImplementedError(\n                 'reduction [%s] not implemented' % self.reduction)\n \n-        with K.control_dependencies([update_total_op]):\n         return K.update_add(self.count, num_values)\n \n     def result(self):\n@@ -217,6 +216,7 @@ class Sum(Reduce):\n \n     def __init__(self, name='sum', dtype=None):\n         \"\"\"Creates a `Sum` instance.\n+\n         # Arguments\n             name: (Optional) string name of the metric instance.\n             dtype: (Optional) data type of the metric result.\n@@ -225,6 +225,39 @@ class Sum(Reduce):\n                                   name=name, dtype=dtype)\n \n \n+class Mean(Reduce):\n+    \"\"\"Computes the (weighted) mean of the given values.\n+\n+    For example, if values is [1, 3, 5, 7] then the mean is 4.\n+    If the weights were specified as [1, 1, 0, 0] then the mean would be 2.\n+\n+    This metric creates two variables, `total` and `count` that are used to\n+    compute the average of `values`. This average is ultimately returned as `mean`\n+    which is an idempotent operation that simply divides `total` by `count`.\n+\n+    If `sample_weight` is `None`, weights default to 1.\n+    Use `sample_weight` of 0 to mask values.\n+\n+    Usage:\n+\n+    ```python\n+    m = tf.keras.metrics.Mean()\n+    m.update_state([1, 3, 5, 7])\n+    m.result()\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, name='mean', dtype=None):\n+        \"\"\"Creates a `Mean` instance.\n+\n+        #Arguments\n+            name: (Optional) string name of the metric instance.\n+            dtype: (Optional) data type of the metric result.\n+        \"\"\"\n+        super(Mean, self).__init__(\n+            reduction=metrics_utils.Reduction.WEIGHTED_MEAN, name=name, dtype=dtype)\n+\n+\n def binary_accuracy(y_true, y_pred):\n     return K.mean(K.equal(y_true, K.round(y_pred)), axis=-1)\n \n\n@@ -6,7 +6,7 @@ from keras import metrics\n from keras import backend as K\n \n \n-class TestKerasSum:\n+class TestSum:\n \n     def test_sum(self):\n         m = metrics.Sum(name='my_sum', dtype='float32')\n@@ -69,3 +69,105 @@ class TestKerasSum:\n         # result = (prev: 57.5) + 0.5 + 1 + 1.5 + 1 + 0.25 + 2\n         assert np.isclose(result, 63.75, 2)\n         assert np.isclose(K.eval(m.total), 63.75, 2)\n+\n+\n+class TestMean:\n+\n+    def test_mean(self):\n+        m = metrics.Mean(name='my_mean')\n+\n+        # check config\n+        assert m.name == 'my_mean'\n+        assert m.stateful\n+        assert m.dtype == 'float32'\n+        assert len(m.weights) == 2\n+\n+        # check initial state\n+        assert K.eval(m.total) == 0\n+        assert K.eval(m.count) == 0\n+\n+        # check __call__()\n+        assert K.eval(m(100)) == 100\n+        assert K.eval(m.total) == 100\n+        assert K.eval(m.count) == 1\n+\n+        # check update_state() and result()\n+        update_op = m.update_state([1, 5])\n+        K.eval(update_op)\n+        assert np.isclose(K.eval(m.result()), 106 / 3)\n+        assert K.eval(m.total) == 106  # 100 + 1 + 5\n+        assert K.eval(m.count) == 3\n+\n+        # check reset_states()\n+        m.reset_states()\n+        assert K.eval(m.total) == 0\n+        assert K.eval(m.count) == 0\n+\n+        # Check save and restore config\n+        m2 = metrics.Mean.from_config(m.get_config())\n+        assert m2.name == 'my_mean'\n+        assert m2.stateful\n+        assert m2.dtype == 'float32'\n+        assert len(m2.weights) == 2\n+\n+    def test_mean_with_sample_weight(self):\n+        m = metrics.Mean(dtype='float64')\n+        assert m.dtype == 'float64'\n+\n+        # check scalar weight\n+        result_t = m(100, sample_weight=0.5)\n+        assert K.eval(result_t) == 50 / 0.5\n+        assert K.eval(m.total) == 50\n+        assert K.eval(m.count) == 0.5\n+\n+        # check weights not scalar and weights rank matches values rank\n+        result_t = m([1, 5], sample_weight=[1, 0.2])\n+        result = K.eval(result_t)\n+        assert np.isclose(result, 52 / 1.7)\n+        assert np.isclose(K.eval(m.total), 52)  # 50 + 1 + 5 * 0.2\n+        assert np.isclose(K.eval(m.count), 1.7)  # 0.5 + 1.2\n+\n+        # check weights broadcast\n+        result_t = m([1, 2], sample_weight=0.5)\n+        assert np.isclose(K.eval(result_t), 53.5 / 2.7, rtol=3)\n+        assert np.isclose(K.eval(m.total), 53.5, rtol=3)  # 52 + 0.5 + 1\n+        assert np.isclose(K.eval(m.count), 2.7, rtol=3)  # 1.7 + 0.5 + 0.5\n+\n+        # check weights squeeze\n+        result_t = m([1, 5], sample_weight=[[1], [0.2]])\n+        assert np.isclose(K.eval(result_t), 55.5 / 3.9, rtol=3)\n+        assert np.isclose(K.eval(m.total), 55.5, rtol=3)  # 53.5 + 1 + 1\n+        assert np.isclose(K.eval(m.count), 3.9, rtol=3)  # 2.7 + 1.2\n+\n+        # check weights expand\n+        result_t = m([[1], [5]], sample_weight=[1, 0.2])\n+        assert np.isclose(K.eval(result_t), 57.5 / 5.1, rtol=3)\n+        assert np.isclose(K.eval(m.total), 57.5, rtol=3)  # 55.5 + 1 + 1\n+        assert np.isclose(K.eval(m.count), 5.1, rtol=3)  # 3.9 + 1.2\n+\n+    def test_multiple_instances(self):\n+        m = metrics.Mean()\n+        m2 = metrics.Mean()\n+\n+        assert m.name == 'mean'\n+        assert m2.name == 'mean'\n+\n+        # check initial state\n+        assert K.eval(m.total) == 0\n+        assert K.eval(m.count) == 0\n+        assert K.eval(m2.total) == 0\n+        assert K.eval(m2.count) == 0\n+\n+        # check __call__()\n+        assert K.eval(m(100)) == 100\n+        assert K.eval(m.total) == 100\n+        assert K.eval(m.count) == 1\n+        assert K.eval(m2.total) == 0\n+        assert K.eval(m2.count) == 0\n+\n+        assert K.eval(m2([63, 10])) == 36.5\n+        assert K.eval(m2.total) == 73\n+        assert K.eval(m2.count) == 2\n+        assert K.eval(m.result()) == 100\n+        assert K.eval(m.total) == 100\n+        assert K.eval(m.count) == 1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
