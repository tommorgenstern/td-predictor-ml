{"custom_id": "keras#d3c33613a1752f091229aa203bbd83efd4eb8671", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 16 | Churn Cumulative: 2278 | Contributors (this commit): 11 | Commits (past 90d): 8 | Contributors (cumulative): 19 | DMM Complexity: 0.0\n\nDIFF:\n@@ -577,14 +577,21 @@ def generator_methods_args_preprocessor(args, kwargs):\n             if hasattr(generator, 'batch_size'):\n                 kwargs['steps_per_epoch'] = samples_per_epoch // generator.batch_size\n             else:\n+                kwargs['steps_per_epoch'] = samples_per_epoch\n+            converted.append(('samples_per_epoch', 'steps_per_epoch'))\n+\n+    keras1_args = {'samples_per_epoch', 'val_samples', 'nb_epoch', 'nb_val_samples', 'nb_worker'}\n+    if keras1_args.intersection(kwargs.keys()):\n         warnings.warn('The semantics of the Keras 2 argument '\n                       '`steps_per_epoch` is not the same as the '\n                       'Keras 1 argument `samples_per_epoch`. '\n                       '`steps_per_epoch` is the number of batches '\n                       'to draw from the generator at each epoch. '\n+                      'Basically steps_per_epoch = samples_per_epoch/batch_size. '\n+                      'Similarly `nb_val_samples`->`validation_steps` and '\n+                      '`val_samples`->`steps` arguments have changed. '\n                       'Update your method calls accordingly.', stacklevel=3)\n-                kwargs['steps_per_epoch'] = samples_per_epoch\n-            converted.append(('samples_per_epoch', 'steps_per_epoch'))\n+\n     return args, kwargs, converted\n \n \n\n@@ -808,6 +808,11 @@ def test_generator_methods_interface():\n                         validation_data=val_generator(),\n                         nb_val_samples=1,\n                         nb_worker=1)\n+    model.fit_generator(train_generator(),\n+                        10,\n+                        1,\n+                        nb_val_samples=1,\n+                        nb_worker=1)\n     model.evaluate_generator(generator=train_generator(),\n                              val_samples=2,\n                              nb_worker=1)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c0f0b660a69aa464bddeeb1e3e897d2c5b4ca9cc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 4330 | Contributors (this commit): 51 | Commits (past 90d): 20 | Contributors (cumulative): 51 | DMM Complexity: None\n\nDIFF:\n@@ -254,7 +254,7 @@ def _check_loss_and_target_compatibility(targets, loss_fns, output_shapes):\n         ValueError: if a loss function or target array\n             is incompatible with an output.\n     \"\"\"\n-    key_losses = {'mean_square_error',\n+    key_losses = {'mean_squared_error',\n                   'binary_crossentropy',\n                   'categorical_crossentropy'}\n     for y, loss, shape in zip(targets, loss_fns, output_shapes):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8d5b2ce60c21a0c18c00610dda41687b42fd5c13", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 174 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 174 | Churn Cumulative: 174 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,174 @@\n+'''Compares self-normalizing MLPs with regular MLPs.\n+\n+Compares the performance of a simple MLP using two\n+different activation functions: RELU and SELU\n+on the Reuters newswire topic classification task.\n+\n+# Reference:\n+  Klambauer, G., Unterthiner, T., Mayr, A., & Hochreiter, S. (2017).\n+  Self-Normalizing Neural Networks. arXiv preprint arXiv:1706.02515.\n+  https://arxiv.org/abs/1706.02515\n+'''\n+from __future__ import print_function\n+\n+import numpy as np\n+import matplotlib.pyplot as plt\n+import keras\n+from keras.datasets import reuters\n+from keras.models import Sequential\n+from keras.layers import Dense, Activation, Dropout\n+from keras.layers.noise import AlphaDropout\n+from keras.preprocessing.text import Tokenizer\n+\n+max_words = 1000\n+batch_size = 16\n+epochs = 40\n+plot = True\n+\n+\n+def create_network(n_dense=6,\n+                   dense_units=16,\n+                   activation='selu',\n+                   dropout=AlphaDropout,\n+                   dropout_rate=0.1,\n+                   kernel_initializer='lecun_normal',\n+                   optimizer='adam',\n+                   num_classes=1,\n+                   max_words=max_words):\n+    \"\"\"Generic function to create a fully-connected neural network.\n+\n+    # Arguments\n+        n_dense: int > 0. Number of dense layers.\n+        dense_units: int > 0. Number of dense units per layer.\n+        dropout: keras.layers.Layer. A dropout layer to apply.\n+        dropout_rate: 0 <= float <= 1. The rate of dropout.\n+        kernel_initializer: str. The initializer for the weights.\n+        optimizer: str/keras.optimizers.Optimizer. The optimizer to use.\n+        num_classes: int > 0. The number of classes to predict.\n+        max_words: int > 0. The maximum number of words per data point.\n+\n+    # Returns\n+        A Keras model instance (compiled).\n+    \"\"\"\n+    model = Sequential()\n+    model.add(Dense(dense_units, input_shape=(max_words,),\n+                    kernel_initializer=kernel_initializer))\n+    model.add(Activation(activation))\n+    model.add(dropout(dropout_rate))\n+\n+    for i in range(n_dense - 1):\n+        model.add(Dense(dense_units, kernel_initializer=kernel_initializer))\n+        model.add(Activation(activation))\n+        model.add(dropout(dropout_rate))\n+\n+    model.add(Dense(num_classes))\n+    model.add(Activation('softmax'))\n+    model.compile(loss='categorical_crossentropy',\n+                  optimizer=optimizer,\n+                  metrics=['accuracy'])\n+    return model\n+\n+\n+network1 = {\n+    'n_dense': 6,\n+    'dense_units': 16,\n+    'activation': 'relu',\n+    'dropout': Dropout,\n+    'dropout_rate': 0.5,\n+    'kernel_initializer': 'glorot_uniform',\n+    'optimizer': 'sgd'\n+}\n+\n+network2 = {\n+    'n_dense': 6,\n+    'dense_units': 16,\n+    'activation': 'selu',\n+    'dropout': AlphaDropout,\n+    'dropout_rate': 0.1,\n+    'kernel_initializer': 'lecun_normal',\n+    'optimizer': 'sgd'\n+}\n+\n+print('Loading data...')\n+(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,\n+                                                         test_split=0.2)\n+print(len(x_train), 'train sequences')\n+print(len(x_test), 'test sequences')\n+\n+num_classes = np.max(y_train) + 1\n+print(num_classes, 'classes')\n+\n+print('Vectorizing sequence data...')\n+tokenizer = Tokenizer(num_words=max_words)\n+x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n+x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n+print('x_train shape:', x_train.shape)\n+print('x_test shape:', x_test.shape)\n+\n+print('Convert class vector to binary class matrix '\n+      '(for use with categorical_crossentropy)')\n+y_train = keras.utils.to_categorical(y_train, num_classes)\n+y_test = keras.utils.to_categorical(y_test, num_classes)\n+print('y_train shape:', y_train.shape)\n+print('y_test shape:', y_test.shape)\n+\n+print('\\nBuilding network 1...')\n+\n+model1 = create_network(num_classes=num_classes, **network1)\n+history_model1 = model1.fit(x_train,\n+                            y_train,\n+                            batch_size=batch_size,\n+                            epochs=epochs,\n+                            verbose=1,\n+                            validation_split=0.1)\n+\n+score_model1 = model1.evaluate(x_test,\n+                               y_test,\n+                               batch_size=batch_size,\n+                               verbose=1)\n+\n+\n+print('\\nBuilding network 2...')\n+model2 = create_network(num_classes=num_classes, **network2)\n+\n+history_model2 = model2.fit(x_train,\n+                            y_train,\n+                            batch_size=batch_size,\n+                            epochs=epochs,\n+                            verbose=1,\n+                            validation_split=0.1)\n+\n+score_model2 = model2.evaluate(x_test,\n+                               y_test,\n+                               batch_size=batch_size,\n+                               verbose=1)\n+\n+print('\\nNetwork 1 results')\n+print('Hyperparameters:', network1)\n+print('Test score:', score_model1[0])\n+print('Test accuracy:', score_model1[1])\n+print('Network 2 results')\n+print('Hyperparameters:', network2)\n+print('Test score:', score_model2[0])\n+print('Test accuracy:', score_model2[1])\n+\n+plt.plot(range(epochs),\n+         history_model1.history['val_loss'],\n+         'g-',\n+         label='Network 1 Val Loss')\n+plt.plot(range(epochs),\n+         history_model2.history['val_loss'],\n+         'r-',\n+         label='Network 2 Val Loss')\n+plt.plot(range(epochs),\n+         history_model1.history['loss'],\n+         'g--',\n+         label='Network 1 Loss')\n+plt.plot(range(epochs),\n+         history_model2.history['loss'],\n+         'r--',\n+         label='Network 2 Loss')\n+plt.xlabel('Epochs')\n+plt.ylabel('Loss')\n+plt.legend()\n+plt.savefig('comparison_of_networks.png')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ced84c4b42d9186842e4cad6c11b0c8f2c18439b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 116 | Lines Deleted: 38 | Files Changed: 12 | Hunks: 42 | Methods Changed: 14 | Complexity Δ (Sum/Max): 18/12 | Churn Δ: 154 | Churn Cumulative: 37524 | Contributors (this commit): 191 | Commits (past 90d): 119 | Contributors (cumulative): 331 | DMM Complexity: 0.3448275862068966\n\nDIFF:\n@@ -1,5 +1,6 @@\n from __future__ import absolute_import\r\n \r\n+from . import utils\r\n from . import activations\r\n from . import applications\r\n from . import backend\r\n@@ -7,7 +8,6 @@ from . import datasets\n from . import engine\r\n from . import layers\r\n from . import preprocessing\r\n-from . import utils\r\n from . import wrappers\r\n from . import callbacks\r\n from . import constraints\r\n\n@@ -7,13 +7,14 @@ from tensorflow.python.ops import ctc_ops as ctc\n from tensorflow.python.ops import variables as tf_variables\n \n from collections import defaultdict\n-import inspect\n+\n import numpy as np\n import os\n \n from .common import floatx\n from .common import _EPSILON\n from .common import image_data_format\n+from ..utils.generic_utils import has_arg\n \n # Legacy functions\n from .common import set_image_dim_ordering\n@@ -2285,8 +2286,7 @@ def function(inputs, outputs, updates=None, **kwargs):\n     \"\"\"\n     if kwargs:\n         for key in kwargs:\n-            if (key not in inspect.getargspec(tf.Session.run)[0] and\n-                    key not in inspect.getargspec(Function.__init__)[0]):\n+            if not (has_arg(tf.Session.run, key, True) or has_arg(Function.__init__, key, True)):\n                 msg = 'Invalid argument \"%s\" passed to K.function with Tensorflow backend' % key\n                 raise ValueError(msg)\n     return Function(inputs, outputs, updates=updates, **kwargs)\n\n@@ -14,9 +14,10 @@ try:\n     from theano.tensor.nnet.nnet import softsign as T_softsign\n except ImportError:\n     from theano.sandbox.softsign import softsign as T_softsign\n-import inspect\n+\n import numpy as np\n from .common import _FLOATX, floatx, _EPSILON, image_data_format\n+from ..utils.generic_utils import has_arg\n # Legacy functions\n from .common import set_image_dim_ordering, image_dim_ordering\n \n@@ -1194,9 +1195,8 @@ class Function(object):\n \n def function(inputs, outputs, updates=[], **kwargs):\n     if len(kwargs) > 0:\n-        function_args = inspect.getargspec(theano.function)[0]\n         for key in kwargs.keys():\n-            if key not in function_args:\n+            if not has_arg(theano.function, key, True):\n                 msg = 'Invalid argument \"%s\" passed to K.function with Theano backend' % key\n                 raise ValueError(msg)\n     return Function(inputs, outputs, updates=updates, **kwargs)\n\n@@ -10,13 +10,13 @@ import warnings\n import copy\n import os\n import re\n-import inspect\n from six.moves import zip\n \n from .. import backend as K\n from .. import initializers\n from ..utils.io_utils import ask_to_proceed_with_overwrite\n from ..utils.layer_utils import print_summary as print_layer_summary\n+from ..utils.generic_utils import has_arg\n from ..utils import conv_utils\n from ..legacy import interfaces\n \n@@ -584,7 +584,7 @@ class Layer(object):\n             user_kwargs = copy.copy(kwargs)\n             if not _is_all_none(previous_mask):\n                 # The previous layer generated a mask.\n-                if 'mask' in inspect.getargspec(self.call).args:\n+                if has_arg(self.call, 'mask'):\n                     if 'mask' not in kwargs:\n                         # If mask is explicitly passed to __call__,\n                         # we should override the default mask.\n@@ -2206,7 +2206,7 @@ class Container(Layer):\n                             kwargs = {}\n                         if len(computed_data) == 1:\n                             computed_tensor, computed_mask = computed_data[0]\n-                            if 'mask' in inspect.getargspec(layer.call).args:\n+                            if has_arg(layer.call, 'mask'):\n                                 if 'mask' not in kwargs:\n                                     kwargs['mask'] = computed_mask\n                             output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n@@ -2217,7 +2217,7 @@ class Container(Layer):\n                         else:\n                             computed_tensors = [x[0] for x in computed_data]\n                             computed_masks = [x[1] for x in computed_data]\n-                            if 'mask' in inspect.getargspec(layer.call).args:\n+                            if has_arg(layer.call, 'mask'):\n                                 if 'mask' not in kwargs:\n                                     kwargs['mask'] = computed_masks\n                             output_tensors = _to_list(layer.call(computed_tensors, **kwargs))\n\n@@ -5,7 +5,6 @@ from __future__ import division\n import numpy as np\n \n import copy\n-import inspect\n import types as python_types\n import warnings\n \n@@ -19,6 +18,7 @@ from ..engine import Layer\n from ..utils.generic_utils import func_dump\n from ..utils.generic_utils import func_load\n from ..utils.generic_utils import deserialize_keras_object\n+from ..utils.generic_utils import has_arg\n from ..legacy import interfaces\n \n \n@@ -642,8 +642,7 @@ class Lambda(Layer):\n \n     def call(self, inputs, mask=None):\n         arguments = self.arguments\n-        arg_spec = inspect.getargspec(self.function)\n-        if 'mask' in arg_spec.args:\n+        if has_arg(self.function, 'mask'):\n             arguments['mask'] = mask\n         return self.function(inputs, **arguments)\n \n\n@@ -2,9 +2,9 @@\n from __future__ import absolute_import\n \n import copy\n-import inspect\n from ..engine import Layer\n from ..engine import InputSpec\n+from ..utils.generic_utils import has_arg\n from .. import backend as K\n \n \n@@ -272,10 +272,9 @@ class Bidirectional(Wrapper):\n \n     def call(self, inputs, training=None, mask=None):\n         kwargs = {}\n-        func_args = inspect.getargspec(self.layer.call).args\n-        if 'training' in func_args:\n+        if has_arg(self.layer.call, 'training'):\n             kwargs['training'] = training\n-        if 'mask' in func_args:\n+        if has_arg(self.layer.call, 'mask'):\n             kwargs['mask'] = mask\n \n         y = self.forward_layer.call(inputs, **kwargs)\n\n@@ -1,10 +1,9 @@\n-import inspect\n import types as python_types\n import warnings\n \n from ..engine.topology import Layer, InputSpec\n from .. import backend as K\n-from ..utils.generic_utils import func_dump, func_load\n+from ..utils.generic_utils import func_dump, func_load, has_arg\n from .. import regularizers\n from .. import constraints\n from .. import activations\n@@ -197,8 +196,7 @@ class Merge(Layer):\n         # Case: \"mode\" is a lambda or function.\n         if callable(self.mode):\n             arguments = self.arguments\n-            arg_spec = inspect.getargspec(self.mode)\n-            if 'mask' in arg_spec.args:\n+            if has_arg(self.mode, 'mask'):\n                 arguments['mask'] = mask\n             return self.mode(inputs, **arguments)\n \n\n@@ -1,9 +1,9 @@\n from __future__ import absolute_import\n from . import np_utils\n-from . import conv_utils\n-from . import data_utils\n from . import generic_utils\n+from . import data_utils\n from . import io_utils\n+from . import conv_utils\n \n # Globally-importable utils.\n from .io_utils import HDF5Matrix\n\n@@ -132,9 +132,8 @@ def deserialize_keras_object(identifier, module_objects=None,\n                 raise ValueError('Unknown ' + printable_module_name +\n                                  ': ' + class_name)\n         if hasattr(cls, 'from_config'):\n-            arg_spec = inspect.getargspec(cls.from_config)\n             custom_objects = custom_objects or {}\n-            if 'custom_objects' in arg_spec.args:\n+            if has_arg(cls.from_config, 'custom_objects'):\n                 return cls.from_config(config['config'],\n                                        custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n                                                            list(custom_objects.items())))\n@@ -207,6 +206,48 @@ def func_load(code, defaults=None, closure=None, globs=None):\n                                      closure=closure)\n \n \n+def has_arg(fn, name, accept_all=False):\n+    \"\"\"Checks if a callable accepts a given keyword argument.\n+\n+    For Python 2, checks if there is an argument with the given name.\n+\n+    For Python 3, checks if there is an argument with the given name, and\n+    also whether this argument can be called with a keyword (i.e. if it is\n+    not a positional-only argument).\n+\n+    # Arguments\n+        fn: Callable to inspect.\n+        name: Check if `fn` can be called with `name` as a keyword argument.\n+        accept_all: What to return if there is no parameter called `name`\n+                    but the function accepts a `**kwargs` argument.\n+\n+    # Returns\n+        bool, whether `fn` accepts a `name` keyword argument.\n+    \"\"\"\n+    if sys.version_info < (3,):\n+        arg_spec = inspect.getargspec(fn)\n+        if accept_all and arg_spec.keywords is not None:\n+            return True\n+        return (name in arg_spec.args)\n+    elif sys.version_info < (3, 3):\n+        arg_spec = inspect.getfullargspec(fn)\n+        if accept_all and arg_spec.varkw is not None:\n+            return True\n+        return (name in arg_spec.args or\n+                name in arg_spec.kwonlyargs)\n+    else:\n+        signature = inspect.signature(fn)\n+        parameter = signature.parameters.get(name)\n+        if parameter is None:\n+            if accept_all:\n+                for param in signature.parameters.values():\n+                    if param.kind == inspect.Parameter.VAR_KEYWORD:\n+                        return True\n+            return False\n+        return (parameter.kind in (inspect.Parameter.POSITIONAL_OR_KEYWORD,\n+                                   inspect.Parameter.KEYWORD_ONLY))\n+\n+\n class Progbar(object):\n     \"\"\"Displays a progress bar.\n \n\n@@ -1,9 +1,9 @@\n \"\"\"Utilities related to Keras unit tests.\"\"\"\n import numpy as np\n from numpy.testing import assert_allclose\n-import inspect\n import six\n \n+from .generic_utils import has_arg\n from ..engine import Model, Input\n from ..models import Sequential\n from ..models import model_from_json\n@@ -71,7 +71,9 @@ def layer_test(layer_cls, kwargs={}, input_shape=None, input_dtype=None,\n     layer.set_weights(weights)\n \n     # test and instantiation from weights\n-    if 'weights' in inspect.getargspec(layer_cls.__init__):\n+    # Checking for empty weights array to avoid a problem where some\n+    # legacy layers return bad values from get_weights()\n+    if has_arg(layer_cls.__init__, 'weights') and len(weights):\n         kwargs['weights'] = weights\n         layer = layer_cls(**kwargs)\n \n\n@@ -1,12 +1,12 @@\n from __future__ import absolute_import\n \n import copy\n-import inspect\n import types\n \n import numpy as np\n \n from ..utils.np_utils import to_categorical\n+from ..utils.generic_utils import has_arg\n from ..models import Sequential\n \n \n@@ -75,13 +75,11 @@ class BaseWrapper(object):\n         else:\n             legal_params_fns.append(self.build_fn)\n \n-        legal_params = []\n-        for fn in legal_params_fns:\n-            legal_params += inspect.getargspec(fn)[0]\n-        legal_params = set(legal_params)\n-\n         for params_name in params:\n-            if params_name not in legal_params:\n+            for fn in legal_params_fns:\n+                if has_arg(fn, params_name):\n+                    break\n+            else:\n                 if params_name != 'nb_epoch':\n                     raise ValueError(\n                         '{} is not a legal parameter'.format(params_name))\n@@ -163,9 +161,8 @@ class BaseWrapper(object):\n         \"\"\"\n         override = override or {}\n         res = {}\n-        fn_args = inspect.getargspec(fn)[0]\n         for name, value in self.sk_params.items():\n-            if name in fn_args:\n+            if has_arg(fn, name):\n                 res.update({name: value})\n         res.update(override)\n         return res\n\n@@ -1,5 +1,6 @@\n+import sys\n import pytest\n-from keras.utils.generic_utils import custom_object_scope\n+from keras.utils.generic_utils import custom_object_scope, has_arg\n from keras import activations\n from keras import regularizers\n \n@@ -20,5 +21,46 @@ def test_custom_objects_scope():\n         assert cl.__class__ == CustomClass\n \n \n+@pytest.mark.parametrize('fn, name, accept_all, expected', [\n+    ('f(x)', 'x', False, True),\n+    ('f(x)', 'y', False, False),\n+    ('f(x)', 'y', True, False),\n+    ('f(x, y)', 'y', False, True),\n+    ('f(x, y=1)', 'y', False, True),\n+    ('f(x, **kwargs)', 'x', False, True),\n+    ('f(x, **kwargs)', 'y', False, False),\n+    ('f(x, **kwargs)', 'y', True, True),\n+    ('f(x, y=1, **kwargs)', 'y', False, True),\n+    # Keyword-only arguments (Python 3 only)\n+    ('f(x, *args, y=1)', 'y', False, True),\n+    ('f(x, *args, y=1)', 'z', True, False),\n+    ('f(x, *, y=1)', 'x', False, True),\n+    ('f(x, *, y=1)', 'y', False, True),\n+    # lambda\n+    (lambda x: x, 'x', False, True),\n+    (lambda x: x, 'y', False, False),\n+    (lambda x: x, 'y', True, False),\n+])\n+def test_has_arg(fn, name, accept_all, expected):\n+    if isinstance(fn, str):\n+        context = dict()\n+        try:\n+            exec('def {}: pass'.format(fn), context)\n+        except SyntaxError:\n+            if sys.version_info >= (3,):\n+                raise\n+            pytest.skip('Function is not compatible with Python 2')\n+        context.pop('__builtins__', None)  # Sometimes exec adds builtins to the context\n+        fn, = context.values()\n+\n+    assert has_arg(fn, name, accept_all) is expected\n+\n+\n+@pytest.mark.xfail(sys.version_info < (3, 3),\n+                   reason='inspect API does not reveal positional-only arguments')\n+def test_has_arg_positional_only():\n+    assert has_arg(pow, 'x') is False\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4135aeebc46a29487757bb97c51f213d17b529c0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 39 | Lines Deleted: 117 | Files Changed: 12 | Hunks: 41 | Methods Changed: 14 | Complexity Δ (Sum/Max): -18/0 | Churn Δ: 156 | Churn Cumulative: 37680 | Contributors (this commit): 191 | Commits (past 90d): 127 | Contributors (cumulative): 331 | DMM Complexity: 0.6551724137931034\n\nDIFF:\n@@ -1,6 +1,5 @@\n from __future__ import absolute_import\r\n \r\n-from . import utils\r\n from . import activations\r\n from . import applications\r\n from . import backend\r\n@@ -8,6 +7,7 @@ from . import datasets\n from . import engine\r\n from . import layers\r\n from . import preprocessing\r\n+from . import utils\r\n from . import wrappers\r\n from . import callbacks\r\n from . import constraints\r\n\n@@ -7,14 +7,13 @@ from tensorflow.python.ops import ctc_ops as ctc\n from tensorflow.python.ops import variables as tf_variables\n \n from collections import defaultdict\n-\n+import inspect\n import numpy as np\n import os\n \n from .common import floatx\n from .common import _EPSILON\n from .common import image_data_format\n-from ..utils.generic_utils import has_arg\n \n # Legacy functions\n from .common import set_image_dim_ordering\n@@ -2286,7 +2285,8 @@ def function(inputs, outputs, updates=None, **kwargs):\n     \"\"\"\n     if kwargs:\n         for key in kwargs:\n-            if not (has_arg(tf.Session.run, key, True) or has_arg(Function.__init__, key, True)):\n+            if (key not in inspect.getargspec(tf.Session.run)[0] and\n+                    key not in inspect.getargspec(Function.__init__)[0]):\n                 msg = 'Invalid argument \"%s\" passed to K.function with Tensorflow backend' % key\n                 raise ValueError(msg)\n     return Function(inputs, outputs, updates=updates, **kwargs)\n\n@@ -14,10 +14,9 @@ try:\n     from theano.tensor.nnet.nnet import softsign as T_softsign\n except ImportError:\n     from theano.sandbox.softsign import softsign as T_softsign\n-\n+import inspect\n import numpy as np\n from .common import _FLOATX, floatx, _EPSILON, image_data_format\n-from ..utils.generic_utils import has_arg\n # Legacy functions\n from .common import set_image_dim_ordering, image_dim_ordering\n \n@@ -1195,8 +1194,9 @@ class Function(object):\n \n def function(inputs, outputs, updates=[], **kwargs):\n     if len(kwargs) > 0:\n+        function_args = inspect.getargspec(theano.function)[0]\n         for key in kwargs.keys():\n-            if not has_arg(theano.function, key, True):\n+            if key not in function_args:\n                 msg = 'Invalid argument \"%s\" passed to K.function with Theano backend' % key\n                 raise ValueError(msg)\n     return Function(inputs, outputs, updates=updates, **kwargs)\n\n@@ -10,13 +10,13 @@ import warnings\n import copy\n import os\n import re\n+import inspect\n from six.moves import zip\n \n from .. import backend as K\n from .. import initializers\n from ..utils.io_utils import ask_to_proceed_with_overwrite\n from ..utils.layer_utils import print_summary as print_layer_summary\n-from ..utils.generic_utils import has_arg\n from ..utils import conv_utils\n from ..legacy import interfaces\n \n@@ -584,7 +584,7 @@ class Layer(object):\n             user_kwargs = copy.copy(kwargs)\n             if not _is_all_none(previous_mask):\n                 # The previous layer generated a mask.\n-                if has_arg(self.call, 'mask'):\n+                if 'mask' in inspect.getargspec(self.call).args:\n                     if 'mask' not in kwargs:\n                         # If mask is explicitly passed to __call__,\n                         # we should override the default mask.\n@@ -2206,7 +2206,7 @@ class Container(Layer):\n                             kwargs = {}\n                         if len(computed_data) == 1:\n                             computed_tensor, computed_mask = computed_data[0]\n-                            if has_arg(layer.call, 'mask'):\n+                            if 'mask' in inspect.getargspec(layer.call).args:\n                                 if 'mask' not in kwargs:\n                                     kwargs['mask'] = computed_mask\n                             output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n@@ -2217,7 +2217,7 @@ class Container(Layer):\n                         else:\n                             computed_tensors = [x[0] for x in computed_data]\n                             computed_masks = [x[1] for x in computed_data]\n-                            if has_arg(layer.call, 'mask'):\n+                            if 'mask' in inspect.getargspec(layer.call).args:\n                                 if 'mask' not in kwargs:\n                                     kwargs['mask'] = computed_masks\n                             output_tensors = _to_list(layer.call(computed_tensors, **kwargs))\n\n@@ -5,6 +5,7 @@ from __future__ import division\n import numpy as np\n \n import copy\n+import inspect\n import types as python_types\n import warnings\n \n@@ -18,7 +19,6 @@ from ..engine import Layer\n from ..utils.generic_utils import func_dump\n from ..utils.generic_utils import func_load\n from ..utils.generic_utils import deserialize_keras_object\n-from ..utils.generic_utils import has_arg\n from ..legacy import interfaces\n \n \n@@ -642,7 +642,8 @@ class Lambda(Layer):\n \n     def call(self, inputs, mask=None):\n         arguments = self.arguments\n-        if has_arg(self.function, 'mask'):\n+        arg_spec = inspect.getargspec(self.function)\n+        if 'mask' in arg_spec.args:\n             arguments['mask'] = mask\n         return self.function(inputs, **arguments)\n \n\n@@ -2,9 +2,9 @@\n from __future__ import absolute_import\n \n import copy\n+import inspect\n from ..engine import Layer\n from ..engine import InputSpec\n-from ..utils.generic_utils import has_arg\n from .. import backend as K\n \n \n@@ -272,9 +272,10 @@ class Bidirectional(Wrapper):\n \n     def call(self, inputs, training=None, mask=None):\n         kwargs = {}\n-        if has_arg(self.layer.call, 'training'):\n+        func_args = inspect.getargspec(self.layer.call).args\n+        if 'training' in func_args:\n             kwargs['training'] = training\n-        if has_arg(self.layer.call, 'mask'):\n+        if 'mask' in func_args:\n             kwargs['mask'] = mask\n \n         y = self.forward_layer.call(inputs, **kwargs)\n\n@@ -1,9 +1,10 @@\n+import inspect\n import types as python_types\n import warnings\n \n from ..engine.topology import Layer, InputSpec\n from .. import backend as K\n-from ..utils.generic_utils import func_dump, func_load, has_arg\n+from ..utils.generic_utils import func_dump, func_load\n from .. import regularizers\n from .. import constraints\n from .. import activations\n@@ -196,7 +197,8 @@ class Merge(Layer):\n         # Case: \"mode\" is a lambda or function.\n         if callable(self.mode):\n             arguments = self.arguments\n-            if has_arg(self.mode, 'mask'):\n+            arg_spec = inspect.getargspec(self.mode)\n+            if 'mask' in arg_spec.args:\n                 arguments['mask'] = mask\n             return self.mode(inputs, **arguments)\n \n\n@@ -1,9 +1,9 @@\n from __future__ import absolute_import\n from . import np_utils\n-from . import generic_utils\n-from . import data_utils\n-from . import io_utils\n from . import conv_utils\n+from . import data_utils\n+from . import generic_utils\n+from . import io_utils\n \n # Globally-importable utils.\n from .io_utils import HDF5Matrix\n\n@@ -132,8 +132,9 @@ def deserialize_keras_object(identifier, module_objects=None,\n                 raise ValueError('Unknown ' + printable_module_name +\n                                  ': ' + class_name)\n         if hasattr(cls, 'from_config'):\n+            arg_spec = inspect.getargspec(cls.from_config)\n             custom_objects = custom_objects or {}\n-            if has_arg(cls.from_config, 'custom_objects'):\n+            if 'custom_objects' in arg_spec.args:\n                 return cls.from_config(config['config'],\n                                        custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n                                                            list(custom_objects.items())))\n@@ -206,48 +207,6 @@ def func_load(code, defaults=None, closure=None, globs=None):\n                                      closure=closure)\n \n \n-def has_arg(fn, name, accept_all=False):\n-    \"\"\"Checks if a callable accepts a given keyword argument.\n-\n-    For Python 2, checks if there is an argument with the given name.\n-\n-    For Python 3, checks if there is an argument with the given name, and\n-    also whether this argument can be called with a keyword (i.e. if it is\n-    not a positional-only argument).\n-\n-    # Arguments\n-        fn: Callable to inspect.\n-        name: Check if `fn` can be called with `name` as a keyword argument.\n-        accept_all: What to return if there is no parameter called `name`\n-                    but the function accepts a `**kwargs` argument.\n-\n-    # Returns\n-        bool, whether `fn` accepts a `name` keyword argument.\n-    \"\"\"\n-    if sys.version_info < (3,):\n-        arg_spec = inspect.getargspec(fn)\n-        if accept_all and arg_spec.keywords is not None:\n-            return True\n-        return (name in arg_spec.args)\n-    elif sys.version_info < (3, 3):\n-        arg_spec = inspect.getfullargspec(fn)\n-        if accept_all and arg_spec.varkw is not None:\n-            return True\n-        return (name in arg_spec.args or\n-                name in arg_spec.kwonlyargs)\n-    else:\n-        signature = inspect.signature(fn)\n-        parameter = signature.parameters.get(name)\n-        if parameter is None:\n-            if accept_all:\n-                for param in signature.parameters.values():\n-                    if param.kind == inspect.Parameter.VAR_KEYWORD:\n-                        return True\n-            return False\n-        return (parameter.kind in (inspect.Parameter.POSITIONAL_OR_KEYWORD,\n-                                   inspect.Parameter.KEYWORD_ONLY))\n-\n-\n class Progbar(object):\n     \"\"\"Displays a progress bar.\n \n\n@@ -1,9 +1,9 @@\n \"\"\"Utilities related to Keras unit tests.\"\"\"\n import numpy as np\n from numpy.testing import assert_allclose\n+import inspect\n import six\n \n-from .generic_utils import has_arg\n from ..engine import Model, Input\n from ..models import Sequential\n from ..models import model_from_json\n@@ -71,9 +71,7 @@ def layer_test(layer_cls, kwargs={}, input_shape=None, input_dtype=None,\n     layer.set_weights(weights)\n \n     # test and instantiation from weights\n-    # Checking for empty weights array to avoid a problem where some\n-    # legacy layers return bad values from get_weights()\n-    if has_arg(layer_cls.__init__, 'weights') and len(weights):\n+    if 'weights' in inspect.getargspec(layer_cls.__init__):\n         kwargs['weights'] = weights\n         layer = layer_cls(**kwargs)\n \n\n@@ -1,12 +1,12 @@\n from __future__ import absolute_import\n \n import copy\n+import inspect\n import types\n \n import numpy as np\n \n from ..utils.np_utils import to_categorical\n-from ..utils.generic_utils import has_arg\n from ..models import Sequential\n \n \n@@ -75,11 +75,13 @@ class BaseWrapper(object):\n         else:\n             legal_params_fns.append(self.build_fn)\n \n-        for params_name in params:\n+        legal_params = []\n         for fn in legal_params_fns:\n-                if has_arg(fn, params_name):\n-                    break\n-            else:\n+            legal_params += inspect.getargspec(fn)[0]\n+        legal_params = set(legal_params)\n+\n+        for params_name in params:\n+            if params_name not in legal_params:\n                 if params_name != 'nb_epoch':\n                     raise ValueError(\n                         '{} is not a legal parameter'.format(params_name))\n@@ -161,8 +163,9 @@ class BaseWrapper(object):\n         \"\"\"\n         override = override or {}\n         res = {}\n+        fn_args = inspect.getargspec(fn)[0]\n         for name, value in self.sk_params.items():\n-            if has_arg(fn, name):\n+            if name in fn_args:\n                 res.update({name: value})\n         res.update(override)\n         return res\n\n@@ -1,6 +1,5 @@\n-import sys\n import pytest\n-from keras.utils.generic_utils import custom_object_scope, has_arg\n+from keras.utils.generic_utils import custom_object_scope\n from keras import activations\n from keras import regularizers\n \n@@ -21,46 +20,5 @@ def test_custom_objects_scope():\n         assert cl.__class__ == CustomClass\n \n \n-@pytest.mark.parametrize('fn, name, accept_all, expected', [\n-    ('f(x)', 'x', False, True),\n-    ('f(x)', 'y', False, False),\n-    ('f(x)', 'y', True, False),\n-    ('f(x, y)', 'y', False, True),\n-    ('f(x, y=1)', 'y', False, True),\n-    ('f(x, **kwargs)', 'x', False, True),\n-    ('f(x, **kwargs)', 'y', False, False),\n-    ('f(x, **kwargs)', 'y', True, True),\n-    ('f(x, y=1, **kwargs)', 'y', False, True),\n-    # Keyword-only arguments (Python 3 only)\n-    ('f(x, *args, y=1)', 'y', False, True),\n-    ('f(x, *args, y=1)', 'z', True, False),\n-    ('f(x, *, y=1)', 'x', False, True),\n-    ('f(x, *, y=1)', 'y', False, True),\n-    # lambda\n-    (lambda x: x, 'x', False, True),\n-    (lambda x: x, 'y', False, False),\n-    (lambda x: x, 'y', True, False),\n-])\n-def test_has_arg(fn, name, accept_all, expected):\n-    if isinstance(fn, str):\n-        context = dict()\n-        try:\n-            exec('def {}: pass'.format(fn), context)\n-        except SyntaxError:\n-            if sys.version_info >= (3,):\n-                raise\n-            pytest.skip('Function is not compatible with Python 2')\n-        context.pop('__builtins__', None)  # Sometimes exec adds builtins to the context\n-        fn, = context.values()\n-\n-    assert has_arg(fn, name, accept_all) is expected\n-\n-\n-@pytest.mark.xfail(sys.version_info < (3, 3),\n-                   reason='inspect API does not reveal positional-only arguments')\n-def test_has_arg_positional_only():\n-    assert has_arg(pow, 'x') is False\n-\n-\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7766ab341f56632cfae71e72af9b6abb56c906a3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 1555 | Contributors (this commit): 11 | Commits (past 90d): 9 | Contributors (cumulative): 11 | DMM Complexity: 0.0\n\nDIFF:\n@@ -839,7 +839,7 @@ class TestBackend(object):\n                         np.log(np.sum(np.exp(x_np), axis=axis, keepdims=keepdims)),\n                         rtol=1e-5)\n \n-    @pytest.mark.parametrize('K', [KTH, KTF], ids=[\"KTH\", \"KTF\"])\n+    @pytest.mark.parametrize('K', [KTF], ids=[\"KTF\"])\n     def test_logsumexp_optim(self, K):\n         '''\n         Check if optimization works.\n@@ -1387,12 +1387,6 @@ class TestBackend(object):\n             ztf = KTF.eval(ztf)\n             assert zth.shape == ztf.shape\n \n-            # TODO remove this if statement when Theano without\n-            # T.nnet.bn.batch_normalization_train is deprecated\n-            zth2, _, _ = KTH._old_normalize_batch_in_training(xth, None, None,\n-                                                              reduction_axes=[0, 1, 2, 3])\n-            assert zth.shape == tuple(KTH.eval(zth2.shape))\n-\n     def test_ctc(self):\n         # simplified version of TensorFlow's test\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ff45159b69cd72969ef90932470dddc6186d658a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 2699 | Contributors (this commit): 52 | Commits (past 90d): 15 | Contributors (cumulative): 52 | DMM Complexity: 0.0\n\nDIFF:\n@@ -657,11 +657,12 @@ class TensorBoard(Callback):\n             for layer in self.model.layers:\n \n                 for weight in layer.weights:\n-                    tf.summary.histogram(weight.name, weight)\n+                    mapped_weight_name = weight.name.replace(':', '_')\n+                    tf.summary.histogram(mapped_weight_name, weight)\n                     if self.write_grads:\n                         grads = model.optimizer.get_gradients(model.total_loss,\n                                                               weight)\n-                        tf.summary.histogram('{}_grad'.format(weight.name), grads)\n+                        tf.summary.histogram('{}_grad'.format(mapped_weight_name), grads)\n                     if self.write_images:\n                         w_img = tf.squeeze(weight)\n                         shape = K.int_shape(w_img)\n@@ -694,7 +695,7 @@ class TensorBoard(Callback):\n \n                         shape = K.int_shape(w_img)\n                         assert len(shape) == 4 and shape[-1] in [1, 3, 4]\n-                        tf.summary.image(weight.name, w_img)\n+                        tf.summary.image(mapped_weight_name, w_img)\n \n                 if hasattr(layer, 'output'):\n                     tf.summary.histogram('{}_out'.format(layer.name),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d852c2d7725ac0a8bacede622680bf6e6456926b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 19 | Churn Cumulative: 2718 | Contributors (this commit): 53 | Commits (past 90d): 16 | Contributors (cumulative): 53 | DMM Complexity: None\n\nDIFF:\n@@ -976,7 +976,7 @@ class CSVLogger(Callback):\n \n \n class LambdaCallback(Callback):\n-    \"\"\"Callback for creating simple, custom callbacks on-the-fly.\n+    r\"\"\"Callback for creating simple, custom callbacks on-the-fly.\n \n     This callback is constructed with anonymous functions that will be called\n     at the appropriate time. Note that the callbacks expects positional\n@@ -1003,12 +1003,15 @@ class LambdaCallback(Callback):\n         batch_print_callback = LambdaCallback(\n             on_batch_begin=lambda batch,logs: print(batch))\n \n-        # Plot the loss after every epoch.\n-        import numpy as np\n-        import matplotlib.pyplot as plt\n-        plot_loss_callback = LambdaCallback(\n-            on_epoch_end=lambda epoch, logs: plt.plot(np.arange(epoch),\n-                                                      logs['loss']))\n+        # Stream the epoch loss to a file in JSON format. The file content\n+        # is not well-formed JSON but rather has a JSON object per line.\n+        import json\n+        json_log = open('loss_log.json', mode='wt', buffering=1)\n+        json_logging_callback = LambdaCallback(\n+            on_epoch_end=lambda epoch, logs: json_log.write(\n+                json.dumps({'epoch': epoch, 'loss': logs['loss']}) + '\\n'),\n+            on_train_end=lambda logs: json_log.close()\n+        )\n \n         # Terminate some processes after having finished model training.\n         processes = ...\n@@ -1018,7 +1021,7 @@ class LambdaCallback(Callback):\n \n         model.fit(...,\n                   callbacks=[batch_print_callback,\n-                             plot_loss_callback,\n+                             json_logging_callback,\n                              cleanup_callback])\n         ```\n     \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#767846e642dc73e421ac426380485fc3348c4f69", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 6703 | Contributors (this commit): 42 | Commits (past 90d): 14 | Contributors (cumulative): 42 | DMM Complexity: None\n\nDIFF:\n@@ -953,7 +953,7 @@ class LSTM(Recurrent):\n             the linear transformation of the recurrent state.\n \n     # References\n-        - [Long short-term memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf) (original 1997 paper)\n+        - [Long short-term memory](http://www.bioinf.jku.at/publications/older/2604.pdf) (original 1997 paper)\n         - [Learning to forget: Continual prediction with LSTM](http://www.mitpressjournals.org/doi/pdf/10.1162/089976600300015015)\n         - [Supervised sequence labeling with recurrent neural networks](http://www.cs.toronto.edu/~graves/preprint.pdf)\n         - [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e0543fbfc8103fd7b3e78f066634f1685ec675ab", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 9 | Churn Cumulative: 5131 | Contributors (this commit): 54 | Commits (past 90d): 22 | Contributors (cumulative): 61 | DMM Complexity: 0.625\n\nDIFF:\n@@ -2030,6 +2030,9 @@ class Model(Container):\n                     batch_size = len(list(x.values())[0])\n                 else:\n                     batch_size = len(x)\n+                if batch_size == 0:\n+                    raise ValueError('Received an empty batch. '\n+                                     'Batches should at least contain one item.')\n                 all_outs.append(outs)\n \n                 steps_done += 1\n\n@@ -203,6 +203,12 @@ def test_model_methods():\n     out = model.evaluate([input_a_np, input_b_np], [output_a_np, output_b_np], batch_size=4)\n     out = model.predict([input_a_np, input_b_np], batch_size=4)\n \n+    # empty batch\n+    with pytest.raises(ValueError):\n+        def gen_data():\n+            yield (np.asarray([]), np.asarray([]))\n+        out = model.evaluate_generator(gen_data(), steps=1)\n+\n     # x is not a list of numpy arrays.\n     with pytest.raises(ValueError):\n         out = model.predict([None])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3d9428d3445a429b535a247168d93b8a5910219d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 1659 | Contributors (this commit): 13 | Commits (past 90d): 15 | Contributors (cumulative): 16 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1180,6 +1180,9 @@ class TestBackend(object):\n         cntk_check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), pool_size=(2, 3, 2),\n                                            strides=(1, 1, 1), pool_mode='avg')\n \n+        check_single_tensor_operation('pool3d', (2, 6, 6, 6, 3), [KTH, KTF], pool_size=(3, 3, 3),\n+                                      strides=(1, 1, 1), padding='same', pool_mode='avg')\n+\n     def test_random_normal(self):\n         mean = 0.\n         std = 1.\n\n@@ -144,6 +144,12 @@ class TestImage:\n         assert(len(dir_iterator.classes) == count)\n         assert(sorted(dir_iterator.filenames) == sorted(filenames))\n \n+        # Test invalid use cases\n+        with pytest.raises(ValueError):\n+            generator.flow_from_directory(str(tmpdir), color_mode='cmyk')\n+        with pytest.raises(ValueError):\n+            generator.flow_from_directory(str(tmpdir), class_mode='output')\n+\n     def test_directory_iterator_class_mode_input(self, tmpdir):\n         tmpdir.join('class-1').mkdir()\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#929ae992c274a13446c53c6e23367629dac94d05", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 322 | Contributors (this commit): 5 | Commits (past 90d): 4 | Contributors (cumulative): 5 | DMM Complexity: 0.0\n\nDIFF:\n@@ -270,14 +270,13 @@ def test_multiprocessing_evaluate_error():\n \n @keras_test\n def test_multiprocessing_predict_error():\n-    batch_size = 10\n     good_batches = 3\n \n     def custom_generator():\n         \"\"\"Raises an exception after a few good batches\"\"\"\n         for i in range(good_batches):\n-            yield (np.random.randint(batch_size, 256, (50, 2)),\n-                   np.random.randint(batch_size, 2, 50))\n+            yield (np.random.randint(1, 256, (2, 50)),\n+                   np.random.randint(1, 256, (2, 50)))\n         raise RuntimeError\n \n     model = Sequential()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
