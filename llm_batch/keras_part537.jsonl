{"custom_id": "keras#4197aac29ad0fafd2cf118469efc647615f99157", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 7 | Files Changed: 3 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 19 | Churn Cumulative: 673 | Contributors (this commit): 1 | Commits (past 90d): 18 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -73,7 +73,9 @@ class Sequential(Model):\n         if not isinstance(input_shape, (tuple, list)):\n             # Do not attempt to build if the model does not have a single input tensor.\n             return\n-        if input_shape and not (isinstance(input_shape[0], int) or input_shape[0] is None):\n+        if input_shape and not (\n+            isinstance(input_shape[0], int) or input_shape[0] is None\n+        ):\n             # Do not attempt to build if the model does not have a single input tensor.\n             return\n         if not self._layers:\n\n@@ -158,7 +158,7 @@ class SequentialTest(testing.TestCase):\n     def test_shape_inference_failure(self):\n         class DynamicLayer(layers.Layer):\n             def call(self, inputs):\n-                return inputs + 1.\n+                return inputs + 1.0\n \n             def compute_output_spec(self, *args, **kwargs):\n                 raise NotImplementedError\n\n@@ -1,11 +1,13 @@\n-from keras_core.utils import io_utils\n-from keras_core.api_export import keras_core_export\n-import sys\n-import os\n-import time\n import math\n+import os\n+import sys\n+import time\n+\n import numpy as np\n \n+from keras_core.api_export import keras_core_export\n+from keras_core.utils import io_utils\n+\n \n @keras_core_export(\"keras_core.utils.Progbar\")\n class Progbar:\n@@ -21,6 +23,7 @@ class Progbar:\n         interval: Minimum visual progress update interval (in seconds).\n         unit_name: Display name for step counts (usually \"step\" or \"sample\").\n     \"\"\"\n+\n     def __init__(\n         self,\n         target,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#22719735608aff6c2f059ee320b12859cf0a88fb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 924 | Lines Deleted: 24 | Files Changed: 3 | Hunks: 17 | Methods Changed: 61 | Complexity Δ (Sum/Max): 148/112 | Churn Δ: 948 | Churn Cumulative: 4157 | Contributors (this commit): 3 | Commits (past 90d): 19 | Contributors (cumulative): 7 | DMM Complexity: 0.8916184971098265\n\nDIFF:\n@@ -48,6 +48,7 @@ ALLOWED_DTYPES = {\n     \"int32\",\n     \"int64\",\n     \"bfloat16\",\n+    \"bool\",\n }\n \n \n\n@@ -31,7 +31,6 @@ cross\n cumprod\n cumsum\n diag\n-diag_indices\n diagonal\n diff\n divide\n@@ -53,16 +52,11 @@ greater_equal\n hstack\n identity\n imag\n-indices\n interp\n isclose\n isfinite\n-isin\n isinf\n isnan\n-isscalar\n-issubdtype\n-issubctype\n less\n less_equal\n linspace\n@@ -165,10 +159,10 @@ def broadcast_shapes(shape1, shape2):\n     for i in range(len(shape1)):\n         if shape1[i] == 1:\n             output_shape[i] = shape2[i]\n-        elif shape1[i] == None:\n+        elif shape1[i] is None:\n             output_shape[i] = shape2[i]\n         else:\n-            if shape2[i] == 1 or shape2[i] == None or shape2[i] == shape1[i]:\n+            if shape2[i] == 1 or shape2[i] is None or shape2[i] == shape1[i]:\n                 output_shape[i] = shape1[i]\n             else:\n                 raise ValueError(\n@@ -780,6 +774,71 @@ def count_nonzero(x, axis=None):\n     return backend.execute(\"count_nonzero\", x, axis=axis)\n \n \n+class Cross(Operation):\n+    def __init__(self, axisa=-1, axisb=-1, axisc=-1, axis=None):\n+        super().__init__()\n+        if axis is not None:\n+            self.axisa = axis\n+            self.axisb = axis\n+            self.axisc = axis\n+        else:\n+            self.axisa = axisa\n+            self.axisb = axisb\n+            self.axisc = axisc\n+\n+    def call(self, x1, x2):\n+        return backend.execute(\n+            \"cross\", x1, x2, self.axisa, self.axisb, self.axisc\n+        )\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = list(x1.shape)\n+        x2_shape = list(x2.shape)\n+\n+        x1_value_size = x1_shape[self.axisa]\n+        x2_value_size = x2_shape[self.axisa]\n+        del x1_shape[self.axisa]\n+        del x2_shape[self.axisb]\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n+\n+        if x1_value_size is not None and x1_value_size not in (2, 3):\n+            raise ValueError(\n+                \"`x1`'s dim on `axis={axisa}` must be either 2 or 3, but \"\n+                f\"received: {x1_value_size}\"\n+            )\n+        if x2_value_size is not None and x2_value_size not in (2, 3):\n+            raise ValueError(\n+                \"`x2`'s dim on `axis={axisb}` must be either 2 or 3, but \"\n+                f\"received: {x2_value_size}\"\n+            )\n+\n+        if x1_value_size == 3 or x2_value_size == 3:\n+            value_size = [3]\n+        else:\n+            value_size = []\n+\n+        output_shape = (\n+            output_shape[: self.axisc] + value_size + output_shape[self.axisc :]\n+        )\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def cross(x1, x2, axisa=-1, axisb=-1, axisc=-1, axis=None):\n+    if any_symbolic_tensors((x1, x2)):\n+        return Cross(\n+            axisa=axisa, axisb=axisb, axisc=axisc, axis=axis\n+        ).symbolic_call(x1, x2)\n+    return backend.execute(\n+        \"cross\",\n+        x1,\n+        x2,\n+        axisa=axisa,\n+        axisb=axisb,\n+        axisc=axisc,\n+        axis=axis,\n+    )\n+\n+\n class Cumprod(Operation):\n     def __init__(self, axis=None):\n         super().__init__()\n@@ -828,6 +887,429 @@ def cumsum(x, axis=None):\n     return backend.execute(\"cumsum\", x, axis=axis)\n \n \n+class Diag(Operation):\n+    def __init__(self, k=0):\n+        super().__init__()\n+        self.k = k\n+\n+    def call(self, x):\n+        return backend.execute(\"diag\", x, k=self.k)\n+\n+    def compute_output_spec(self, x):\n+        x_shape = x.shape\n+        if len(x_shape) == 1:\n+            if x_shape[0] is None:\n+                output_shape = [None, None]\n+            else:\n+                output_shape = [\n+                    x_shape[0] + int(np.abs(self.k)),\n+                    x_shape[0] + int(np.abs(self.k)),\n+                ]\n+        elif len(x_shape) == 2:\n+            if None in x_shape:\n+                output_shape = [None]\n+            else:\n+                shorter_side = min(x_shape[0], x_shape[1])\n+                if self.k > 0:\n+                    remaining = x_shape[1] - self.k\n+                else:\n+                    remaining = x_shape[0] + self.k\n+                output_shape = [max(0, min(remaining, shorter_side))]\n+        else:\n+            raise ValueError(\n+                f\"`x` must be 1-D or 2-D, but received shape {x.shape}.\"\n+            )\n+        return KerasTensor(output_shape, dtype=x.dtype)\n+\n+\n+def diag(x, k=0):\n+    if any_symbolic_tensors((x,)):\n+        return Diag(k=k).symbolic_call(x)\n+    return backend.execute(\"diag\", x, k=k)\n+\n+\n+class Diagonal(Operation):\n+    def __init__(self, offset=0, axis1=0, axis2=1):\n+        super().__init__()\n+        self.offset = offset\n+        self.axis1 = axis1\n+        self.axis2 = axis2\n+\n+    def call(self, x):\n+        return backend.execute(\n+            \"diagonal\",\n+            x,\n+            offset=self.offset,\n+            axis1=self.axis1,\n+            axis2=self.axis2,\n+        )\n+\n+    def compute_output_spec(self, x):\n+        x_shape = list(x.shape)\n+        if len(x_shape) < 2:\n+            raise ValueError(\n+                \"`diagonal` requires an array of at least two dimensions, but \"\n+                \"`x` is of shape {x.shape}.\"\n+            )\n+\n+        shape_2d = [x_shape[self.axis1], x_shape[self.axis2]]\n+        x_shape[self.axis1] = -1\n+        x_shape[self.axis2] = -1\n+        output_shape = list(filter((-1).__ne__, x_shape))\n+        if None in shape_2d:\n+            diag_shape = [None]\n+        else:\n+            shorter_side = min(shape_2d[0], shape_2d[1])\n+            if self.offset > 0:\n+                remaining = shape_2d[1] - self.offset\n+            else:\n+                remaining = shape_2d[0] + self.offset\n+            diag_shape = [max(0, min(remaining, shorter_side))]\n+        output_shape = output_shape + diag_shape\n+        return KerasTensor(output_shape, dtype=x.dtype)\n+\n+\n+def diagonal(x, offset=0, axis1=0, axis2=1):\n+    if any_symbolic_tensors((x,)):\n+        return Diagonal(\n+            offset=offset,\n+            axis1=axis1,\n+            axis2=axis2,\n+        ).symbolic_call(x)\n+    return backend.execute(\n+        \"diagonal\",\n+        x,\n+        offset=offset,\n+        axis1=axis1,\n+        axis2=axis2,\n+    )\n+\n+\n+class Dot(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"dot\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        if x1_shape == [] or x2_shape == []:\n+            return multiply(x1, x2)\n+        if len(x1_shape) == 1 and len(x2_shape) == 1:\n+            return KerasTensor([], dtype=x1.dtype)\n+        if len(x2_shape) == 1:\n+            if x1_shape[-1] != x2_shape[0]:\n+                raise ValueError(\n+                    \"Shape must match on the last axis of `x1` and `x2` when \"\n+                    \"`x1` is N-d array while `x2` is 1-D, but receive shape \"\n+                    f\"`x1.shape={x1.shape}` and x2.shape=`{x2.shape}`.\"\n+                )\n+            return KerasTensor(x1_shape[:-1], dtype=x1.dtype)\n+\n+        if x1_shape[-1] != x2_shape[-2]:\n+            raise ValueError(\n+                \"Shape must match on the last axis of `x1` and second last \"\n+                \"axis of `x2` when `x1` is N-d array while `x2` is M-D, but \"\n+                f\"received `x1.shape={x1.shape}` and x2.shape=`{x2.shape}`.\"\n+            )\n+        del x1_shape[-1]\n+        del x2_shape[-2]\n+        return KerasTensor(x1_shape + x2_shape, dtype=x1.dtype)\n+\n+\n+class Empty(Operation):\n+    def call(self, shape, dtype=\"float32\"):\n+        return backend.execute(\"empty\", shape, dtype=dtype)\n+\n+    def compute_output_spec(self, shape, dtype=\"float32\"):\n+        return KerasTensor(shape, dtype=dtype)\n+\n+\n+def empty(shape, dtype=\"float32\"):\n+    return backend.execute(\"empty\", shape, dtype=dtype)\n+\n+\n+class Equal(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"equal\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def equal(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return Equal().symbolic_call(x1, x2)\n+    return backend.execute(\"equal\", x1, x2)\n+\n+\n+class Exp(Operation):\n+    def call(self, x):\n+        return backend.execute(\"exp\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def exp(x):\n+    if any_symbolic_tensors((x,)):\n+        return Exp().symbolic_call(x)\n+    return backend.execute(\"exp\", x)\n+\n+\n+class ExpandDims(Operation):\n+    def __init__(self, axis):\n+        super().__init__()\n+        if isinstance(axis, list):\n+            raise ValueError(\n+                \"The `axis` argument to `expand_dims` should be an integer, \"\n+                f\"but received a list: {axis}.\"\n+            )\n+        self.axis = axis\n+\n+    def call(self, x):\n+        return backend.execute(\"expand_dims\", x, self.axis)\n+\n+    def compute_output_spec(self, x):\n+        x_shape = list(x.shape)\n+        if self.axis < 0:\n+            output_shape = (\n+                x_shape[: self.axis + 1] + [1] + x_shape[self.axis + 1 :]\n+            )\n+        else:\n+            output_shape = x_shape[: self.axis] + [1] + x_shape[self.axis :]\n+        return KerasTensor(output_shape, dtype=x.dtype)\n+\n+\n+def expand_dims(x, axis):\n+    if any_symbolic_tensors((x,)):\n+        return ExpandDims(axis=axis).symbolic_call(x)\n+    return backend.execute(\"expand_dims\", x, axis)\n+\n+\n+class Expm1(Operation):\n+    def call(self, x):\n+        return backend.execute(\"expm1\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def expm1(x):\n+    if any_symbolic_tensors((x,)):\n+        return Expm1().symbolic_call(x)\n+    return backend.execute(\"expm1\", x)\n+\n+\n+class Flip(Operation):\n+    def __init__(self, axis=None):\n+        super().__init__()\n+        self.axis = axis\n+\n+    def call(self, x):\n+        return backend.execute(\"flip\", x, axis=self.axis)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def flip(x, axis=None):\n+    if any_symbolic_tensors((x,)):\n+        return Flip(axis=axis).symbolic_call(x)\n+    return backend.execute(\"flip\", x, axis=axis)\n+\n+\n+class Floor(Operation):\n+    def call(self, x):\n+        return backend.execute(\"floor\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def floor(x):\n+    if any_symbolic_tensors((x,)):\n+        return Floor().symbolic_call(x)\n+    return backend.execute(\"floor\", x)\n+\n+\n+class Full(Operation):\n+    def call(self, shape, fill_value, dtype=None):\n+        return backend.execute(\"full\", shape, fill_value, dtype=dtype)\n+\n+    def compute_output_spec(self, shape, fill_value, dtype=None):\n+        return KerasTensor(shape, dtype=dtype)\n+\n+\n+def full(shape, fill_value, dtype=None):\n+    return backend.execute(\"full\", shape, fill_value, dtype=dtype)\n+\n+\n+class FullLike(Operation):\n+    def call(self, x, fill_value, dtype=None):\n+        return backend.execute(\"full_like\", x, fill_value, dtype=dtype)\n+\n+    def compute_output_spec(self, x, fill_value, dtype=None):\n+        return KerasTensor(x.shape, dtype=dtype)\n+\n+\n+def full_like(x, fill_value, dtype=None):\n+    if any_symbolic_tensors((x,)):\n+        return FullLike().symbolic_call(x, fill_value, dtype=dtype)\n+    return backend.execute(\"full_like\", x, fill_value, dtype=dtype)\n+\n+\n+class Greater(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"greater\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def greater(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return Greater().symbolic_call(x1, x2)\n+    return backend.execute(\"greater\", x1, x2)\n+\n+\n+class GreaterEqual(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"greater_equal\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def greater_equal(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return GreaterEqual().symbolic_call(x1, x2)\n+    return backend.execute(\"greater_equal\", x1, x2)\n+\n+\n+class Hstack(Operation):\n+    def call(self, xs):\n+        return backend.execute(\"hstack\", xs)\n+\n+    def compute_output_spec(self, xs):\n+        first_shape = xs[0].shape\n+        total_size_on_axis = 0\n+        for x in xs:\n+            if not shape_equal(x.shape, first_shape, axis=[1], allow_none=True):\n+                raise ValueError(\n+                    \"Every value in `xs` must have the same shape except on \"\n+                    f\"the `axis` dim. But found element of shape {x.shape}, \"\n+                    f\"which is different from the first element's \"\n+                    f\"shape {first_shape}.\"\n+                )\n+            if total_size_on_axis is None or x.shape[1] is None:\n+                total_size_on_axis = None\n+            else:\n+                total_size_on_axis += x.shape[1]\n+        output_shape = list(first_shape)\n+        output_shape[1] = total_size_on_axis\n+        return KerasTensor(output_shape)\n+\n+\n+def hstack(xs):\n+    if any_symbolic_tensors((xs,)):\n+        return Hstack().symbolic_call(xs)\n+    return backend.execute(\"hstack\", xs)\n+\n+\n+class Identity(Operation):\n+    def call(self, n, dtype=\"float32\"):\n+        return backend.execute(\"identity\", n, dtype=dtype)\n+\n+    def compute_output_spec(self, n, dtype=\"float32\"):\n+        return KerasTensor([n, n], dtype=dtype)\n+\n+\n+def identity(n, dtype=\"float32\"):\n+    return backend.execute(\"identity\", n, dtype=dtype)\n+\n+\n+class Imag(Operation):\n+    def call(self, x):\n+        return backend.execute(\"imag\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def imag(x):\n+    if any_symbolic_tensors((x,)):\n+        return Imag().symbolic_call(x)\n+    return backend.execute(\"imag\", x)\n+\n+\n+class Isclose(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"isclose\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def isclose(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return Isclose().symbolic_call(x1, x2)\n+    return backend.execute(\"isclose\", x1, x2)\n+\n+\n+class Isfinite(Operation):\n+    def call(self, x):\n+        return backend.execute(\"isfinite\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=\"bool\")\n+\n+\n+def isfinite(x):\n+    if any_symbolic_tensors((x,)):\n+        return Isfinite().symbolic_call(x)\n+    return backend.execute(\"isfinite\", x)\n+\n+\n+class Isinf(Operation):\n+    def call(self, x):\n+        return backend.execute(\"isinf\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=\"bool\")\n+\n+\n+def isinf(x):\n+    if any_symbolic_tensors((x,)):\n+        return Isinf().symbolic_call(x)\n+    return backend.execute(\"isinf\", x)\n+\n+\n+class Isnan(Operation):\n+    def call(self, x):\n+        return backend.execute(\"isnan\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=\"bool\")\n+\n+\n+def isnan(x):\n+    if any_symbolic_tensors((x,)):\n+        return Isnan().symbolic_call(x)\n+    return backend.execute(\"isnan\", x)\n+\n+\n class Matmul(Operation):\n     def call(self, x1, x2):\n         return backend.execute(\"matmul\", x1, x2)\n@@ -968,20 +1450,6 @@ def negative(x):\n     return backend.execute(\"negative\", x)\n \n \n-class Absolute(Operation):\n-    def call(self, x):\n-        return backend.execute(\"absolute\", x)\n-\n-    def compute_output_spec(self, x):\n-        return KerasTensor(x.shape, dtype=x.dtype)\n-\n-\n-def absolute(x):\n-    if any_symbolic_tensors((x,)):\n-        return Absolute().symbolic_call(x)\n-    return backend.execute(\"absolute\", x)\n-\n-\n class Square(Operation):\n     def call(self, x):\n         return backend.execute(\"square\", x)\n\n@@ -1,11 +1,9 @@\n import numpy as np\n from tensorflow.python.ops.numpy_ops import np_config\n \n-from keras_core import backend\n from keras_core import testing\n from keras_core.backend.keras_tensor import KerasTensor\n from keras_core.operations import numpy as knp\n-from keras_core.operations import operation\n \n np_config.enable_numpy_behavior()\n \n@@ -162,6 +160,88 @@ class NumpyTwoInputOpsShapeTest(testing.TestCase):\n             y = KerasTensor([2, 3, 4])\n             knp.arctan2(x, y)\n \n+    def test_cross(self):\n+        x1 = KerasTensor([2, 3, 3])\n+        x2 = KerasTensor([1, 3, 2])\n+        y1 = KerasTensor([2, 3, 3])\n+        y2 = KerasTensor([None, 1, 2])\n+        y3 = KerasTensor([2, 3, 2])\n+        self.assertEqual(knp.cross(x1, y1).shape, (2, 3, 3))\n+        self.assertEqual(knp.cross(x1, y2).shape, (2, 3, 3))\n+        self.assertEqual(knp.cross(x2, y2).shape, (None, 3))\n+        self.assertEqual(knp.cross(x2, y3).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.cross(x, y)\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([4, 3, 3])\n+            y = KerasTensor([2, 3, 3])\n+            knp.cross(x, y)\n+\n+    def test_full_like(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.full_like(x, 2).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.full_like(x, KerasTensor([1, 3])).shape, (None, 3))\n+\n+        x = KerasTensor([None, 3, 3])\n+        self.assertEqual(knp.full_like(x, 2).shape, (None, 3, 3))\n+\n+    def test_greater(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.greater(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.greater(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.greater(x, 2).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.greater(x, y)\n+\n+    def test_greater_equal(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.greater_equal(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.greater_equal(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.greater_equal(x, 2).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.greater_equal(x, y)\n+\n+    def test_isclose(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.isclose(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.isclose(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.isclose(x, 2).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.isclose(x, y)\n+\n \n class NumpyOneInputOpsShapeTest(testing.TestCase):\n     def test_mean(self):\n@@ -466,6 +546,120 @@ class NumpyOneInputOpsShapeTest(testing.TestCase):\n         x = KerasTensor([None, 3, 3])\n         self.assertEqual(knp.cumsum(x, axis=1).shape, (None, 3, 3))\n \n+    def test_diag(self):\n+        x = KerasTensor([3])\n+        self.assertEqual(knp.diag(x).shape, (3, 3))\n+        self.assertEqual(knp.diag(x, k=3).shape, (6, 6))\n+        self.assertEqual(knp.diag(x, k=-2).shape, (5, 5))\n+\n+        x = KerasTensor([3, 5])\n+        self.assertEqual(knp.diag(x).shape, (3,))\n+        self.assertEqual(knp.diag(x, k=3).shape, (2,))\n+        self.assertEqual(knp.diag(x, k=-2).shape, (1,))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.diag(x).shape, (None,))\n+        self.assertEqual(knp.diag(x, k=3).shape, (None,))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3, 4])\n+            knp.diag(x)\n+\n+    def test_diagonal(self):\n+        x = KerasTensor([3, 3])\n+        self.assertEqual(knp.diagonal(x).shape, (3,))\n+        self.assertEqual(knp.diagonal(x, offset=1).shape, (2,))\n+\n+        x = KerasTensor([3, 5, 5])\n+        self.assertEqual(knp.diagonal(x).shape, (5, 3))\n+\n+        x = KerasTensor([None, 3, 3])\n+        self.assertEqual(knp.diagonal(x).shape, (3, None))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([3])\n+            knp.diagonal(x)\n+\n+    def test_exp(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.exp(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.exp(x).shape, (None, 3))\n+\n+    def test_expand_dims(self):\n+        x = KerasTensor([2, 3, 4])\n+        self.assertEqual(knp.expand_dims(x, 0).shape, (1, 2, 3, 4))\n+        self.assertEqual(knp.expand_dims(x, 1).shape, (2, 1, 3, 4))\n+        self.assertEqual(knp.expand_dims(x, -2).shape, (2, 3, 1, 4))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.expand_dims(x, 0).shape, (1, None, 3))\n+        self.assertEqual(knp.expand_dims(x, 1).shape, (None, 1, 3))\n+        self.assertEqual(knp.expand_dims(x, -2).shape, (None, 1, 3))\n+\n+    def test_expm1(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.expm1(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.expm1(x).shape, (None, 3))\n+\n+    def test_flip(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.flip(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.flip(x).shape, (None, 3))\n+\n+    def test_floor(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.floor(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.floor(x).shape, (None, 3))\n+\n+    def test_hstack(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.hstack([x, y]).shape, (2, 6))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([None, 3])\n+        self.assertEqual(knp.hstack([x, y]).shape, (None, 6))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([None, None])\n+        self.assertEqual(knp.hstack([x, y]).shape, (None, None))\n+\n+    def test_imag(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.imag(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.imag(x).shape, (None, 3))\n+\n+    def test_isfinite(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.isfinite(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.isfinite(x).shape, (None, 3))\n+\n+    def test_isinf(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.isinf(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.isinf(x).shape, (None, 3))\n+\n+    def test_isnan(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.isnan(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.isnan(x).shape, (None, 3))\n+\n \n class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n     def test_add(self):\n@@ -569,6 +763,95 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n \n         self.assertAllClose(np.array(knp.Arctan2()(x, y)), np.arctan2(x, y))\n \n+    def test_cross(self):\n+        x1 = np.ones([2, 1, 4, 3])\n+        x2 = np.ones([2, 1, 4, 2])\n+        y1 = np.ones([2, 1, 4, 3])\n+        y2 = np.ones([1, 5, 4, 3])\n+        y3 = np.ones([1, 5, 4, 2])\n+        self.assertAllClose(np.array(knp.cross(x1, y1)), np.cross(x1, y1))\n+        self.assertAllClose(np.array(knp.cross(x1, y2)), np.cross(x1, y2))\n+        self.assertAllClose(np.array(knp.cross(x1, y3)), np.cross(x1, y3))\n+        self.assertAllClose(np.array(knp.cross(x2, y3)), np.cross(x2, y3))\n+\n+        self.assertAllClose(np.array(knp.Cross()(x1, y1)), np.cross(x1, y1))\n+        self.assertAllClose(np.array(knp.Cross()(x1, y2)), np.cross(x1, y2))\n+        self.assertAllClose(np.array(knp.Cross()(x1, y3)), np.cross(x1, y3))\n+        self.assertAllClose(np.array(knp.Cross()(x2, y3)), np.cross(x2, y3))\n+\n+    def test_full_like(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.full_like(x, 2)), np.full_like(x, 2))\n+        self.assertAllClose(\n+            np.array(knp.full_like(x, np.ones([2, 3]))),\n+            np.full_like(x, np.ones([2, 3])),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.full_like(x, 2, dtype=\"float32\")),\n+            np.full_like(x, 2, dtype=\"float32\"),\n+        )\n+\n+        self.assertAllClose(np.array(knp.FullLike()(x, 2)), np.full_like(x, 2))\n+        self.assertAllClose(\n+            np.array(knp.FullLike()(x, np.ones([2, 3]))),\n+            np.full_like(x, np.ones([2, 3])),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.FullLike()(x, 2, dtype=\"float32\")),\n+            np.full_like(x, 2, dtype=\"float32\"),\n+        )\n+\n+    def test_greater(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        y = np.array([[4, 5, 6], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.greater(x, y)), np.greater(x, y))\n+        self.assertAllClose(np.array(knp.greater(x, 2)), np.greater(x, 2))\n+        self.assertAllClose(np.array(knp.greater(2, x)), np.greater(2, x))\n+\n+        self.assertAllClose(np.array(knp.Greater()(x, y)), np.greater(x, y))\n+        self.assertAllClose(np.array(knp.Greater()(x, 2)), np.greater(x, 2))\n+        self.assertAllClose(np.array(knp.Greater()(2, x)), np.greater(2, x))\n+\n+    def test_greater_equal(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        y = np.array([[4, 5, 6], [3, 2, 1]])\n+        self.assertAllClose(\n+            np.array(knp.greater_equal(x, y)),\n+            np.greater_equal(x, y),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.greater_equal(x, 2)),\n+            np.greater_equal(x, 2),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.greater_equal(2, x)),\n+            np.greater_equal(2, x),\n+        )\n+\n+        self.assertAllClose(\n+            np.array(knp.GreaterEqual()(x, y)),\n+            np.greater_equal(x, y),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.GreaterEqual()(x, 2)),\n+            np.greater_equal(x, 2),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.GreaterEqual()(2, x)),\n+            np.greater_equal(2, x),\n+        )\n+\n+    def test_isclose(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        y = np.array([[4, 5, 6], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.isclose(x, y)), np.isclose(x, y))\n+        self.assertAllClose(np.array(knp.isclose(x, 2)), np.isclose(x, 2))\n+        self.assertAllClose(np.array(knp.isclose(2, x)), np.isclose(2, x))\n+\n+        self.assertAllClose(np.array(knp.Isclose()(x, y)), np.isclose(x, y))\n+        self.assertAllClose(np.array(knp.Isclose()(x, 2)), np.isclose(x, 2))\n+        self.assertAllClose(np.array(knp.Isclose()(2, x)), np.isclose(2, x))\n+\n \n class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n     def test_mean(self):\n@@ -944,6 +1227,133 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n             np.cumsum(x, axis=1),\n         )\n \n+    def test_diag(self):\n+        x = np.array([1, 2, 3])\n+        self.assertAllClose(np.array(knp.diag(x)), np.diag(x))\n+        self.assertAllClose(np.array(knp.diag(x, k=1)), np.diag(x, k=1))\n+        self.assertAllClose(np.array(knp.diag(x, k=-1)), np.diag(x, k=-1))\n+\n+        self.assertAllClose(np.array(knp.Diag()(x)), np.diag(x))\n+        self.assertAllClose(np.array(knp.Diag(k=1)(x)), np.diag(x, k=1))\n+        self.assertAllClose(np.array(knp.Diag(k=-1)(x)), np.diag(x, k=-1))\n+\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.diag(x)), np.diag(x))\n+        self.assertAllClose(np.array(knp.diag(x, k=1)), np.diag(x, k=1))\n+        self.assertAllClose(np.array(knp.diag(x, k=-1)), np.diag(x, k=-1))\n+\n+        self.assertAllClose(np.array(knp.Diag()(x)), np.diag(x))\n+        self.assertAllClose(np.array(knp.Diag(k=1)(x)), np.diag(x, k=1))\n+        self.assertAllClose(np.array(knp.Diag(k=-1)(x)), np.diag(x, k=-1))\n+\n+    def test_diagonal(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.diagonal(x)), np.diagonal(x))\n+        self.assertAllClose(\n+            np.array(knp.diagonal(x, offset=1)),\n+            np.diagonal(x, offset=1),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.diagonal(x, offset=-1)), np.diagonal(x, offset=-1)\n+        )\n+\n+        self.assertAllClose(np.array(knp.Diagonal()(x)), np.diagonal(x))\n+        self.assertAllClose(\n+            np.array(knp.Diagonal(offset=1)(x)), np.diagonal(x, offset=1)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Diagonal(offset=-1)(x)), np.diagonal(x, offset=-1)\n+        )\n+\n+        x = np.ones([2, 3, 4, 5])\n+        self.assertAllClose(np.array(knp.diagonal(x)), np.diagonal(x))\n+        self.assertAllClose(\n+            np.array(knp.diagonal(x, offset=1, axis1=2, axis2=3)),\n+            np.diagonal(x, offset=1, axis1=2, axis2=3),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.diagonal(x, offset=-1, axis1=2, axis2=3)),\n+            np.diagonal(x, offset=-1, axis1=2, axis2=3),\n+        )\n+\n+    def test_exp(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.exp(x)), np.exp(x))\n+        self.assertAllClose(np.array(knp.Exp()(x)), np.exp(x))\n+\n+    def test_expand_dims(self):\n+        x = np.ones([2, 3, 4])\n+        self.assertAllClose(\n+            np.array(knp.expand_dims(x, 0)), np.expand_dims(x, 0)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.expand_dims(x, 1)), np.expand_dims(x, 1)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.expand_dims(x, -2)), np.expand_dims(x, -2)\n+        )\n+\n+        self.assertAllClose(\n+            np.array(knp.ExpandDims(0)(x)), np.expand_dims(x, 0)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.ExpandDims(1)(x)), np.expand_dims(x, 1)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.ExpandDims(-2)(x)), np.expand_dims(x, -2)\n+        )\n+\n+    def test_expm1(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.expm1(x)), np.expm1(x))\n+        self.assertAllClose(np.array(knp.Expm1()(x)), np.expm1(x))\n+\n+    def test_flip(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.flip(x)), np.flip(x))\n+        self.assertAllClose(np.array(knp.flip(x, 0)), np.flip(x, 0))\n+        self.assertAllClose(np.array(knp.flip(x, 1)), np.flip(x, 1))\n+\n+        self.assertAllClose(np.array(knp.Flip()(x)), np.flip(x))\n+        self.assertAllClose(np.array(knp.Flip(0)(x)), np.flip(x, 0))\n+        self.assertAllClose(np.array(knp.Flip(1)(x)), np.flip(x, 1))\n+\n+    def test_floor(self):\n+        x = np.array([[1.1, 2.2, -3.3], [3.3, 2.2, -1.1]])\n+        self.assertAllClose(np.array(knp.floor(x)), np.floor(x))\n+        self.assertAllClose(np.array(knp.Floor()(x)), np.floor(x))\n+\n+    def test_hstack(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        y = np.array([[4, 5, 6], [6, 5, 4]])\n+        self.assertAllClose(np.array(knp.hstack([x, y])), np.hstack([x, y]))\n+        self.assertAllClose(np.array(knp.Hstack()([x, y])), np.hstack([x, y]))\n+\n+        x = np.ones([2, 3, 4])\n+        y = np.ones([2, 5, 4])\n+        self.assertAllClose(np.array(knp.hstack([x, y])), np.hstack([x, y]))\n+        self.assertAllClose(np.array(knp.Hstack()([x, y])), np.hstack([x, y]))\n+\n+    def test_imag(self):\n+        x = np.array([[1 + 1j, 2 + 2j, 3 + 3j], [3 + 3j, 2 + 2j, 1 + 1j]])\n+        self.assertAllClose(np.array(knp.imag(x)), np.imag(x))\n+        self.assertAllClose(np.array(knp.Imag()(x)), np.imag(x))\n+\n+    def test_isfinite(self):\n+        x = np.array([[1, 2, np.inf], [np.nan, np.nan, np.nan]])\n+        self.assertAllClose(np.array(knp.isfinite(x)), np.isfinite(x))\n+        self.assertAllClose(np.array(knp.Isfinite()(x)), np.isfinite(x))\n+\n+    def test_isinf(self):\n+        x = np.array([[1, 2, np.inf], [np.nan, np.nan, np.nan]])\n+        self.assertAllClose(np.array(knp.isinf(x)), np.isinf(x))\n+        self.assertAllClose(np.array(knp.Isinf()(x)), np.isinf(x))\n+\n+    def test_isnan(self):\n+        x = np.array([[1, 2, np.inf], [np.nan, np.nan, np.nan]])\n+        self.assertAllClose(np.array(knp.isnan(x)), np.isnan(x))\n+        self.assertAllClose(np.array(knp.Isnan()(x)), np.isnan(x))\n+\n \n class NumpyArrayCreateOpsCorrectnessTest(testing.TestCase):\n     def test_ones(self):\n@@ -971,3 +1381,24 @@ class NumpyArrayCreateOpsCorrectnessTest(testing.TestCase):\n         self.assertAllClose(np.array(knp.Arange()(3)), np.arange(3))\n         self.assertAllClose(np.array(knp.Arange()(3, 7)), np.arange(3, 7))\n         self.assertAllClose(np.array(knp.Arange()(3, 7, 2)), np.arange(3, 7, 2))\n+\n+    def test_full(self):\n+        self.assertAllClose(np.array(knp.full([2, 3], 0)), np.full([2, 3], 0))\n+        self.assertAllClose(\n+            np.array(knp.full([2, 3], 0.1)), np.full([2, 3], 0.1)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.full([2, 3], [1, 4, 5])), np.full([2, 3], [1, 4, 5])\n+        )\n+\n+        self.assertAllClose(np.array(knp.Full()([2, 3], 0)), np.full([2, 3], 0))\n+        self.assertAllClose(\n+            np.array(knp.Full()([2, 3], 0.1)), np.full([2, 3], 0.1)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Full()([2, 3], [1, 4, 5])), np.full([2, 3], [1, 4, 5])\n+        )\n+\n+    def test_identity(self):\n+        self.assertAllClose(np.array(knp.identity(3)), np.identity(3))\n+        self.assertAllClose(np.array(knp.Identity()(3)), np.identity(3))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1f38fe8fa7e660b58f14dbaf3966ea660dbde9ef", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 75/60 | Churn Δ: 19 | Churn Cumulative: 1256 | Contributors (this commit): 6 | Commits (past 90d): 8 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -396,6 +396,8 @@ def export_model(model, filepath):\n     export_archive.track(model)\n     if isinstance(model, (functional.Functional, sequential.Sequential)):\n         input_signature = tf.nest.map_structure(_make_tensor_spec, model.inputs)\n+        if isinstance(input_signature, list) and len(input_signature) > 1:\n+            input_signature = [input_signature]\n         export_archive.add_endpoint(\"serve\", model.__call__, input_signature)\n     else:\n         save_spec = model._get_save_spec()\n\n@@ -295,6 +295,23 @@ class WideDeepModelTest(test_combinations.TestCase):\n         )\n         self.assertEqual(cloned_wide_deep_model.activation, my_activation)\n \n+    def test_export(self):\n+        input1 = input_layer.Input(shape=(1,))\n+        output1 = linear.LinearModel()(input1)\n+        linear_model = training.Model(input1, output1)\n+\n+        input2 = input_layer.Input(shape=(1,))\n+        output2 = core.Dense(units=1)(input2)\n+        dnn_model = training.Model(input2, output2)\n+\n+        wide_deep_model = wide_deep.WideDeepModel(linear_model, dnn_model)\n+        wide_deep_model.compile(optimizer=[\"adam\", \"adam\"])\n+\n+        output = wide_deep_model([input1, input2])\n+        model = training.Model([input1, input2], output)\n+        model.compile()\n+        model.export(self.get_temp_dir())\n+\n \n if __name__ == \"__main__\":\n     tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#70741d9050acbc72d9d703fd8959a6ff3df19a89", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 7 | Files Changed: 3 | Hunks: 6 | Methods Changed: 5 | Complexity Δ (Sum/Max): 395/226 | Churn Δ: 14 | Churn Cumulative: 5044 | Contributors (this commit): 36 | Commits (past 90d): 19 | Contributors (cumulative): 43 | DMM Complexity: None\n\nDIFF:\n@@ -573,8 +573,8 @@ def serialize(activation, use_legacy_format=False):\n             f\"Unknown activation function '{activation}' cannot be \"\n             \"serialized due to invalid function name. Make sure to use \"\n             \"an activation name that matches the references defined in \"\n-            \"activations.py or use `@keras.utils.register_keras_serializable` \"\n-            \"for any custom activations. \"\n+            \"activations.py or use `@keras.utils.register_keras_serializable()`\"\n+            \"to register any custom activations. \"\n             f\"config={fn_config}\"\n         )\n     if not isinstance(activation, types.FunctionType):\n\n@@ -604,7 +604,7 @@ class KerasObjectLoader:\n                         \"One of several possible causes could be \"\n                         \"a missing custom object. \"\n                         \"Decorate your custom object with \"\n-                        \"`@keras.utils.register_keras_serializable` and \"\n+                        \"`@keras.utils.register_keras_serializable()` and \"\n                         \"include that file in your program, \"\n                         \"or pass your class in a \"\n                         \"`keras.utils.CustomObjectScope` \"\n\n@@ -295,7 +295,7 @@ def serialize_with_public_class(cls, inner_config=None):\n \n     Called to check and retrieve the config of any class that has a public\n     Keras API or has been registered as serializable via\n-    `keras.utils.register_keras_serializable`.\n+    `keras.utils.register_keras_serializable()`.\n     \"\"\"\n     # This gets the `keras.*` exported name, such as \"keras.optimizers.Adam\".\n     keras_api_name = tf_export.get_canonical_name_for_symbol(\n@@ -325,7 +325,7 @@ def serialize_with_public_fn(fn, config, fn_module_name=None):\n \n     Called to check and retrieve the config of any function that has a public\n     Keras API or has been registered as serializable via\n-    `keras.utils.register_keras_serializable`. If function's module name is\n+    `keras.utils.register_keras_serializable()`. If function's module name is\n     already known, returns corresponding config.\n     \"\"\"\n     if fn_module_name:\n@@ -695,7 +695,7 @@ def _retrieve_class_or_fn(\n     name, registered_name, module, obj_type, full_config, custom_objects=None\n ):\n     # If there is a custom object registered via\n-    # `register_keras_serializable`, that takes precedence.\n+    # `register_keras_serializable()`, that takes precedence.\n     if obj_type == \"function\":\n         custom_obj = object_registration.get_registered_object(\n             name, custom_objects=custom_objects\n@@ -767,6 +767,6 @@ def _retrieve_class_or_fn(\n     raise TypeError(\n         f\"Could not locate {obj_type} '{name}'. \"\n         \"Make sure custom classes are decorated with \"\n-        \"`@keras.utils.register_keras_serializable`. \"\n+        \"`@keras.utils.register_keras_serializable()`. \"\n         f\"Full object config: {full_config}\"\n     )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#136986b86ba13da7f98b785e6a05cecc1a9e01ee", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 63 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 6 | Methods Changed: 5 | Complexity Δ (Sum/Max): 58/57 | Churn Δ: 65 | Churn Cumulative: 2090 | Contributors (this commit): 4 | Commits (past 90d): 14 | Contributors (cumulative): 7 | DMM Complexity: 0.7857142857142857\n\nDIFF:\n@@ -735,5 +735,49 @@ class SavingV3Test(tf.test.TestCase, parameterized.TestCase):\n         self.assertAllClose(ref_out, out, atol=1e-6)\n \n \n+class CustomRNN(keras.layers.Layer):\n+    def __init__(self, units):\n+        super(CustomRNN, self).__init__()\n+        self.units = units\n+        self.projection_1 = keras.layers.Dense(units=units, activation=\"tanh\")\n+        self.projection_2 = keras.layers.Dense(units=units, activation=\"tanh\")\n+        self.classifier = keras.layers.Dense(1)\n+\n+    def call(self, inputs):\n+        outputs = []\n+        state = tf.zeros(shape=(inputs.shape[0], self.units))\n+        for t in range(inputs.shape[1]):\n+            x = inputs[:, t, :]\n+            h = self.projection_1(x)\n+            y = h + self.projection_2(state)\n+            state = y\n+            outputs.append(y)\n+        features = tf.stack(outputs, axis=1)\n+        return self.classifier(features)\n+\n+\n+@test_utils.run_v2_only\n+class SavingV3BattleTest(tf.test.TestCase, parameterized.TestCase):\n+    def test_custom_model_without_registration_error(self):\n+        temp_filepath = os.path.join(\n+            self.get_temp_dir(), \"my_custom_model.keras\"\n+        )\n+        timesteps = 10\n+        input_dim = 5\n+        batch_size = 16\n+\n+        inputs = keras.Input(batch_shape=(batch_size, timesteps, input_dim))\n+        x = keras.layers.Conv1D(32, 3)(inputs)\n+        outputs = CustomRNN(32)(x)\n+\n+        model = keras.Model(inputs, outputs)\n+\n+        with self.assertRaisesRegex(\n+            TypeError, \"is a custom class, please register it\"\n+        ):\n+            model.save(temp_filepath)\n+            _ = keras.models.load_model(temp_filepath)\n+\n+\n if __name__ == \"__main__\":\n     tf.test.main()\n\n@@ -38,6 +38,8 @@ SAFE_MODE = threading.local()\n # TODO(nkovela): Debug serialization of decorated functions inside lambdas\n # to allow for serialization of custom_gradient.\n NON_SERIALIZABLE_CLASS_MODULES = (\"tensorflow.python.ops.custom_gradient\",)\n+\n+# List of Keras modules with built-in string representations for Keras defaults\n BUILTIN_MODULES = (\n     \"activations\",\n     \"constraints\",\n@@ -301,16 +303,22 @@ def serialize_with_public_class(cls, inner_config=None):\n     keras_api_name = tf_export.get_canonical_name_for_symbol(\n         cls, api_name=\"keras\"\n     )\n+\n+    # Case of custom or unknown class object\n     if keras_api_name is None:\n         registered_name = object_registration.get_registered_name(cls)\n-        if registered_name:\n+        if registered_name is None:\n+            return None\n+\n+        # Return custom object config with corresponding registration name\n         return {\n             \"module\": cls.__module__,\n             \"class_name\": cls.__name__,\n             \"config\": inner_config,\n             \"registered_name\": registered_name,\n         }\n-        return None\n+\n+    # Split the canonical Keras API name into a Keras module and class name.\n     parts = keras_api_name.split(\".\")\n     return {\n         \"module\": \".\".join(parts[:-1]),\n@@ -559,6 +567,15 @@ def deserialize_keras_object(\n \n             # Case where config is class but not in custom objects\n             else:\n+                if config.get(\"module\", \"_\") is None:\n+                    raise TypeError(\n+                        \"Cannot deserialize object of type \"\n+                        f\"`{config['class_name']}`. If \"\n+                        f\"`{config['class_name']}` is a custom class, please \"\n+                        \"register it using the \"\n+                        \"`@keras.utils.register_keras_serializable()` \"\n+                        \"decorator.\"\n+                    )\n                 config = config[\"class_name\"]\n         if not has_custom_object:\n             # Return if not found in either module objects or custom objects\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cb7115768a24370e054a499a92e83e0535f5f068", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1637 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 10 | Methods Changed: 85 | Complexity Δ (Sum/Max): 250/187 | Churn Δ: 1641 | Churn Cumulative: 5640 | Contributors (this commit): 3 | Commits (past 90d): 15 | Contributors (cumulative): 4 | DMM Complexity: 0.94453125\n\nDIFF:\n@@ -909,12 +909,14 @@ class Diag(Operation):\n             if None in x_shape:\n                 output_shape = [None]\n             else:\n-                shorter_side = min(x_shape[0], x_shape[1])\n+                shorter_side = np.minimum(x_shape[0], x_shape[1])\n                 if self.k > 0:\n                     remaining = x_shape[1] - self.k\n                 else:\n                     remaining = x_shape[0] + self.k\n-                output_shape = [max(0, min(remaining, shorter_side))]\n+                output_shape = [\n+                    int(np.maximum(0, np.minimum(remaining, shorter_side)))\n+                ]\n         else:\n             raise ValueError(\n                 f\"`x` must be 1-D or 2-D, but received shape {x.shape}.\"\n@@ -959,12 +961,14 @@ class Diagonal(Operation):\n         if None in shape_2d:\n             diag_shape = [None]\n         else:\n-            shorter_side = min(shape_2d[0], shape_2d[1])\n+            shorter_side = np.minimum(shape_2d[0], shape_2d[1])\n             if self.offset > 0:\n                 remaining = shape_2d[1] - self.offset\n             else:\n                 remaining = shape_2d[0] + self.offset\n-            diag_shape = [max(0, min(remaining, shorter_side))]\n+            diag_shape = [\n+                int(np.maximum(0, np.minimum(remaining, shorter_side)))\n+            ]\n         output_shape = output_shape + diag_shape\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n@@ -1310,6 +1314,285 @@ def isnan(x):\n     return backend.execute(\"isnan\", x)\n \n \n+class Less(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"less\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def less(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return Less().symbolic_call(x1, x2)\n+    return backend.execute(\"less\", x1, x2)\n+\n+\n+class LessEqual(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"less_equal\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def less_equal(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return LessEqual().symbolic_call(x1, x2)\n+    return backend.execute(\"less_equal\", x1, x2)\n+\n+\n+class Linspace(Operation):\n+    def __init__(\n+        self, num=50, endpoint=True, retstep=False, dtype=float, axis=0\n+    ):\n+        super().__init__()\n+        self.num = num\n+        self.endpoint = endpoint\n+        self.retstep = retstep\n+        self.dtype = dtype\n+        self.axis = axis\n+\n+    def call(self, start, stop):\n+        return backend.execute(\n+            \"linspace\",\n+            start,\n+            stop,\n+            num=self.num,\n+            endpoint=self.endpoint,\n+            retstep=self.retstep,\n+            dtype=self.dtype,\n+            axis=self.axis,\n+        )\n+\n+    def compute_output_spec(self, start, stop):\n+        start_shape = getattr(start, \"shape\", [])\n+        stop_shape = getattr(stop, \"shape\", [])\n+        output_shape = broadcast_shapes(start_shape, stop_shape)\n+        if self.axis == -1:\n+            output_shape = output_shape + [self.num]\n+        elif self.axis >= 0:\n+            output_shape = (\n+                output_shape[: self.axis]\n+                + [self.num]\n+                + output_shape[self.axis :]\n+            )\n+        else:\n+            output_shape = (\n+                output_shape[: self.axis + 1]\n+                + [self.num]\n+                + output_shape[self.axis + 1 :]\n+            )\n+\n+        dtype = self.dtype if self.dtype is not None else start.dtype\n+        if self.retstep:\n+            return (KerasTensor(output_shape, dtype=dtype), None)\n+        return KerasTensor(output_shape, dtype=dtype)\n+\n+\n+def linspace(\n+    start, stop, num=50, endpoint=True, retstep=False, dtype=None, axis=0\n+):\n+    if any_symbolic_tensors((start, stop)):\n+        return Linspace(num, endpoint, retstep, dtype, axis)(start, stop)\n+    return backend.execute(\n+        \"linspace\",\n+        start,\n+        stop,\n+        num=num,\n+        endpoint=endpoint,\n+        retstep=retstep,\n+        dtype=dtype,\n+        axis=axis,\n+    )\n+\n+\n+class Log(Operation):\n+    def call(self, x):\n+        return backend.execute(\"log\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def log(x):\n+    if any_symbolic_tensors((x,)):\n+        return Log().symbolic_call(x)\n+    return backend.execute(\"log\", x)\n+\n+\n+class Log10(Operation):\n+    def call(self, x):\n+        return backend.execute(\"log10\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def log10(x):\n+    if any_symbolic_tensors((x,)):\n+        return Log10().symbolic_call(x)\n+    return backend.execute(\"log10\", x)\n+\n+\n+class Log1p(Operation):\n+    def call(self, x):\n+        return backend.execute(\"log1p\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def log1p(x):\n+    if any_symbolic_tensors((x,)):\n+        return Log10().symbolic_call(x)\n+    return backend.execute(\"log1p\", x)\n+\n+\n+class Log2(Operation):\n+    def call(self, x):\n+        return backend.execute(\"log2\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def log2(x):\n+    if any_symbolic_tensors((x,)):\n+        return Log2().symbolic_call(x)\n+    return backend.execute(\"log2\", x)\n+\n+\n+class Logaddexp(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"logaddexp\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def logaddexp(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return Logaddexp().symbolic_call(x1, x2)\n+    return backend.execute(\"logaddexp\", x1, x2)\n+\n+\n+class LogicalAnd(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"logical_and\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def logical_and(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return LogicalAnd().symbolic_call(x1, x2)\n+    return backend.execute(\"logical_and\", x1, x2)\n+\n+\n+class LogicalNot(Operation):\n+    def call(self, x):\n+        return backend.execute(\"logical_not\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def logical_not(x):\n+    if any_symbolic_tensors((x,)):\n+        return LogicalNot().symbolic_call(x)\n+    return backend.execute(\"logical_not\", x)\n+\n+\n+class LogicalOr(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"logical_or\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def logical_or(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return LogicalOr().symbolic_call(x1, x2)\n+    return backend.execute(\"logical_or\", x1, x2)\n+\n+\n+class Logspace(Operation):\n+    def __init__(self, num=50, endpoint=True, base=10, dtype=float, axis=0):\n+        super().__init__()\n+        self.num = num\n+        self.endpoint = endpoint\n+        self.base = base\n+        self.dtype = dtype\n+        self.axis = axis\n+\n+    def call(self, start, stop):\n+        return backend.execute(\n+            \"logspace\",\n+            start,\n+            stop,\n+            num=self.num,\n+            endpoint=self.endpoint,\n+            base=self.base,\n+            dtype=self.dtype,\n+            axis=self.axis,\n+        )\n+\n+    def compute_output_spec(self, start, stop):\n+        start_shape = getattr(start, \"shape\", [])\n+        stop_shape = getattr(stop, \"shape\", [])\n+        output_shape = broadcast_shapes(start_shape, stop_shape)\n+        if self.axis == -1:\n+            output_shape = output_shape + [self.num]\n+        elif self.axis >= 0:\n+            output_shape = (\n+                output_shape[: self.axis]\n+                + [self.num]\n+                + output_shape[self.axis :]\n+            )\n+        else:\n+            output_shape = (\n+                output_shape[: self.axis + 1]\n+                + [self.num]\n+                + output_shape[self.axis + 1 :]\n+            )\n+\n+        dtype = self.dtype if self.dtype is not None else start.dtype\n+        return KerasTensor(output_shape, dtype=dtype)\n+\n+\n+def logspace(start, stop, num=50, endpoint=True, base=10, dtype=None, axis=0):\n+    if any_symbolic_tensors((start, stop)):\n+        return Logspace(num, endpoint, base, dtype, axis)(start, stop)\n+    return backend.execute(\n+        \"logspace\",\n+        start,\n+        stop,\n+        num=num,\n+        endpoint=endpoint,\n+        base=base,\n+        dtype=dtype,\n+        axis=axis,\n+    )\n+\n+\n class Matmul(Operation):\n     def call(self, x1, x2):\n         return backend.execute(\"matmul\", x1, x2)\n@@ -1351,6 +1634,494 @@ def matmul(x1, x2):\n     return backend.execute(\"matmul\", x1, x2)\n \n \n+class Max(Operation):\n+    def __init__(self, axis=None, keepdims=False):\n+        super().__init__()\n+        if isinstance(axis, int):\n+            self.axis = [axis]\n+        else:\n+            self.axis = axis\n+        self.keepdims = keepdims\n+\n+    def call(self, x):\n+        return backend.execute(\"max\", x, axis=self.axis, keepdims=self.keepdims)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(\n+            reduce_shape(x.shape, axis=self.axis, keepdims=self.keepdims),\n+            dtype=x.dtype,\n+        )\n+\n+\n+def max(x, axis=None, keepdims=False):\n+    if any_symbolic_tensors((x,)):\n+        return Max(axis=axis, keepdims=keepdims).symbolic_call(x)\n+    return backend.execute(\"max\", x, axis=axis, keepdims=keepdims)\n+\n+\n+class Maximum(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"maximum\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def maximum(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return Maximum().symbolic_call(x1, x2)\n+    return backend.execute(\"maximum\", x1, x2)\n+\n+\n+class Meshgrid(Operation):\n+    def __init__(self, indexing=\"xy\"):\n+        super().__init__()\n+        if indexing not in (\"xy\", \"ij\"):\n+            raise ValueError(\n+                \"Valid values for `indexing` are 'xy' and 'ij', but received {index}.\"\n+            )\n+        self.indexing = indexing\n+\n+    def call(self, *x):\n+        return backend.execute(\"meshgrid\", *x, indexing=self.indexing)\n+\n+    def compute_output_spec(self, *x):\n+        output_shape = []\n+        for xi in x:\n+            if len(xi.shape) == 0:\n+                size = 1\n+            else:\n+                if None in xi.shape:\n+                    size = None\n+                else:\n+                    size = int(np.prod(xi.shape))\n+            output_shape.append(size)\n+        if self.indexing == \"ij\":\n+            return [KerasTensor(output_shape) for _ in range(len(x))]\n+        tmp = output_shape[0]\n+        output_shape[0] = output_shape[1]\n+        output_shape[1] = tmp\n+        return [KerasTensor(output_shape) for _ in range(len(x))]\n+\n+\n+def meshgrid(*x, indexing=\"xy\"):\n+    if any_symbolic_tensors(x):\n+        return Meshgrid(indexing=indexing).symbolic_call(*x)\n+    return backend.execute(\"meshgrid\", *x, indexing=indexing)\n+\n+\n+class Min(Operation):\n+    def __init__(self, axis=None, keepdims=False):\n+        if isinstance(axis, int):\n+            self.axis = [axis]\n+        else:\n+            self.axis = axis\n+        self.keepdims = keepdims\n+\n+    def call(self, x):\n+        return backend.execute(\"min\", x, axis=self.axis, keepdims=self.keepdims)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(\n+            reduce_shape(x.shape, axis=self.axis, keepdims=self.keepdims),\n+            dtype=x.dtype,\n+        )\n+\n+\n+def min(x, axis=None, keepdims=False):\n+    if any_symbolic_tensors((x,)):\n+        return Min(axis=axis, keepdims=keepdims).symbolic_call(x)\n+    return backend.execute(\"min\", x, axis=axis, keepdims=keepdims)\n+\n+\n+class Minimum(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"minimum\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def minimum(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return Minimum().symbolic_call(x1, x2)\n+    return backend.execute(\"minimum\", x1, x2)\n+\n+\n+class Mod(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"mod\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def mod(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return Mod().symbolic_call(x1, x2)\n+    return backend.execute(\"mod\", x1, x2)\n+\n+\n+class Moveaxis(Operation):\n+    def __init__(self, source, destination):\n+        super().__init__()\n+        if isinstance(source, int):\n+            self.source = [source]\n+        else:\n+            self.source = source\n+        if isinstance(destination, int):\n+            self.destination = [destination]\n+        else:\n+            self.destination = destination\n+\n+        if len(self.source) != len(self.destination):\n+            raise ValueError(\n+                \"`source` and `destination` arguments must have the same \"\n+                f\"number of elements, but received `source={source}` and \"\n+                f\"`destination={destination}`.\"\n+            )\n+\n+    def call(self, x):\n+        return backend.execute(\"moveaxis\", x, self.source, self.destination)\n+\n+    def compute_output_spec(self, x):\n+        x_shape = list(x.shape)\n+        output_shape = [-1 for _ in range(len(x.shape))]\n+        for sc, dst in zip(self.source, self.destination):\n+            output_shape[dst] = x_shape[sc]\n+            x_shape[sc] = -1\n+        i, j = 0, 0\n+        while i < len(output_shape):\n+            while i < len(output_shape) and output_shape[i] != -1:\n+                # Find the first dim unset.\n+                i += 1\n+            while j < len(output_shape) and x_shape[j] == -1:\n+                # Find the first dim not being passed.\n+                j += 1\n+            if i == len(output_shape):\n+                break\n+            output_shape[i] = x_shape[j]\n+            i += 1\n+            j += 1\n+        return KerasTensor(output_shape, dtype=x.dtype)\n+\n+\n+def moveaxis(x, source, destination):\n+    if any_symbolic_tensors((x,)):\n+        return Moveaxis(source, destination).symbolic_call(x)\n+    return backend.execute(\n+        \"moveaxis\", x, source=source, destination=destination\n+    )\n+\n+\n+class Ndim(Operation):\n+    def call(self, x):\n+        return backend.execute(\n+            \"ndim\",\n+            x,\n+        )\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor([len(x.shape)])\n+\n+\n+def ndim(x):\n+    if any_symbolic_tensors((x,)):\n+        return Ndim().symbolic_call(x)\n+    return backend.execute(\"ndim\", x)\n+\n+\n+class Nonzero(Operation):\n+    def call(self, x):\n+        return backend.execute(\"nonzero\", x)\n+\n+    def compute_output_spec(self, x):\n+        output = []\n+        for _ in range(len(x.shape)):\n+            output.append(KerasTensor([None]))\n+        return tuple(output)\n+\n+\n+def nonzero(x):\n+    if any_symbolic_tensors((x,)):\n+        return Nonzero().symbolic_call(x)\n+    return backend.execute(\"nonzero\", x)\n+\n+\n+class NotEqual(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"not_equal\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        output_shape = broadcast_shapes(x1_shape, x2_shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def not_equal(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return NotEqual().symbolic_call(x1, x2)\n+    return backend.execute(\"not_equal\", x1, x2)\n+\n+\n+class OnesLike(Operation):\n+    def call(self, x, dtype=None):\n+        return backend.execute(\"ones_like\", x, dtype=dtype)\n+\n+    def compute_output_spec(self, x, dtype=None):\n+        return KerasTensor(x.shape, dtype=dtype)\n+\n+\n+def ones_like(x, dtype=None):\n+    if any_symbolic_tensors((x,)):\n+        return OnesLike().symbolic_call(x, dtype=dtype)\n+    return backend.execute(\"ones_like\", x, dtype=dtype)\n+\n+\n+class Outer(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"outer\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = getattr(x1, \"shape\", [1])\n+        x2_shape = getattr(x2, \"shape\", [1])\n+        if None in x1_shape:\n+            x1_flatten_shape = None\n+        else:\n+            x1_flatten_shape = int(np.prod(x1_shape))\n+        if None in x2_shape:\n+            x2_flatten_shape = None\n+        else:\n+            x2_flatten_shape = int(np.prod(x2_shape))\n+        output_shape = [x1_flatten_shape, x2_flatten_shape]\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def outer(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return Outer().symbolic_call(x1, x2)\n+    return backend.execute(\"outer\", x1, x2)\n+\n+\n+class Pad(Operation):\n+    def __init__(self, pad_width, mode=\"constant\"):\n+        super().__init__()\n+        self.pad_width = self._process_pad_width(pad_width)\n+        self.mode = mode\n+\n+    def _process_pad_width(self, pad_width):\n+        if isinstance(pad_width, int):\n+            return ((pad_width, pad_width),)\n+        if isinstance(pad_width, (tuple, list)) and isinstance(\n+            pad_width[0], int\n+        ):\n+            return (pad_width,)\n+        first_len = len(pad_width[0])\n+        for i, pw in enumerate(pad_width):\n+            if len(pw) != first_len:\n+                raise ValueError(\n+                    \"`pad_width` should be a list of tuples of length 2 or \"\n+                    f\"1, but received {pad_width}.\"\n+                )\n+            if len(pw) == 1:\n+                pad_width[i] = (pw[0], pw[0])\n+        return pad_width\n+\n+    def call(self, x):\n+        return backend.execute(\n+            \"pad\", x, pad_width=self.pad_width, mode=self.mode\n+        )\n+\n+    def compute_output_spec(self, x):\n+        output_shape = list(x.shape)\n+        if len(self.pad_width) == 1:\n+            pad_width = [self.pad_width[0] for _ in range(len(output_shape))]\n+        elif len(self.pad_width) == len(output_shape):\n+            pad_width = self.pad_width\n+        else:\n+            raise ValueError(\n+                \"`pad_width` must have the same length as `x.shape`, but \"\n+                f\"received {len(self.pad_width)} and {len(x.shape)}.\"\n+            )\n+\n+        for i in range(len(output_shape)):\n+            if output_shape[i] is None:\n+                output_shape[i] = None\n+            else:\n+                output_shape[i] += pad_width[i][0] + pad_width[i][1]\n+        return KerasTensor(output_shape, dtype=x.dtype)\n+\n+\n+def pad(x, pad_width, mode=\"constant\"):\n+    if any_symbolic_tensors((x,)):\n+        return Pad(pad_width, mode=mode).symbolic_call(x)\n+    return backend.execute(\"pad\", x, pad_width, mode=mode)\n+\n+\n+class Prod(Operation):\n+    def __init__(self, axis=None, keepdims=False, dtype=None):\n+        super().__init__()\n+        if isinstance(axis, int):\n+            self.axis = [axis]\n+        else:\n+            self.axis = axis\n+        self.keepdims = keepdims\n+        self.dtype = dtype\n+\n+    def call(self, x):\n+        return backend.execute(\n+            \"prod\",\n+            x,\n+            axis=self.axis,\n+            keepdims=self.keepdims,\n+            dtype=self.dtype,\n+        )\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(\n+            reduce_shape(x.shape, axis=self.axis, keepdims=self.keepdims),\n+            dtype=self.dtype,\n+        )\n+\n+\n+def prod(x, axis=None, keepdims=False, dtype=None):\n+    if any_symbolic_tensors((x,)):\n+        return Prod(axis=axis, keepdims=keepdims, dtype=dtype).symbolic_call(x)\n+    return backend.execute(\"prod\", x, axis=axis, keepdims=keepdims, dtype=dtype)\n+\n+\n+class Ravel(Operation):\n+    def call(self, x):\n+        return backend.execute(\"ravel\", x)\n+\n+    def compute_output_spec(self, x):\n+        if None in x.shape:\n+            output_shape = [\n+                None,\n+            ]\n+        else:\n+            output_shape = [int(np.prod(x.shape))]\n+        return KerasTensor(output_shape, dtype=x.dtype)\n+\n+\n+def ravel(x):\n+    if any_symbolic_tensors((x,)):\n+        return Ravel().symbolic_call(x)\n+    return backend.execute(\"ravel\", x)\n+\n+\n+class Real(Operation):\n+    def call(self, x):\n+        return backend.execute(\"real\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape)\n+\n+\n+def real(x):\n+    if any_symbolic_tensors((x,)):\n+        return Real().symbolic_call(x)\n+    return backend.execute(\"real\", x)\n+\n+\n+class Reciprocal(Operation):\n+    def call(self, x):\n+        return backend.execute(\"reciprocal\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape)\n+\n+\n+def reciprocal(x):\n+    if any_symbolic_tensors((x,)):\n+        return Reciprocal().symbolic_call(x)\n+    return backend.execute(\"reciprocal\", x)\n+\n+\n+class Repeat(Operation):\n+    def __init__(self, repeats, axis=None):\n+        super().__init__()\n+        self.axis = axis\n+        self.repeats = repeats\n+\n+    def call(self, x):\n+        return backend.execute(\"repeat\", x, self.repeats, axis=self.axis)\n+\n+    def compute_output_spec(self, x):\n+        x_shape = list(x.shape)\n+        if self.axis is None:\n+            if None in x_shape:\n+                return KerasTensor([None], dtype=x.dtype)\n+\n+            x_flatten_size = int(np.prod(x_shape))\n+            if isinstance(self.repeats, int):\n+                output_shape = [x_flatten_size * self.repeats]\n+            else:\n+                output_shape = [int(np.sum(self.repeats))]\n+            return KerasTensor(output_shape, dtype=x.dtype)\n+\n+        size_on_ax = x_shape[self.axis]\n+        output_shape = x_shape\n+        if isinstance(self.repeats, int):\n+            output_shape[self.axis] = size_on_ax * self.repeats\n+        else:\n+            output_shape[self.axis] = int(np.sum(self.repeats))\n+        return KerasTensor(output_shape, dtype=x.dtype)\n+\n+\n+def repeat(x, repeats, axis=None):\n+    if any_symbolic_tensors((x,)):\n+        return Repeat(repeats, axis=axis).symbolic_call(x)\n+    return backend.execute(\"repeat\", x, repeats, axis=axis)\n+\n+\n+class Reshape(Operation):\n+    def __init__(self, new_shape):\n+        super().__init__()\n+        self.new_shape = new_shape\n+\n+    def call(self, x):\n+        return backend.execute(\"reshape\", x, self.new_shape)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(self.new_shape, dtype=x.dtype)\n+\n+\n+def reshape(x, new_shape):\n+    if any_symbolic_tensors((x,)):\n+        return Reshape(new_shape).symbolic_call(x)\n+    return backend.execute(\"reshape\", x, new_shape)\n+\n+\n+class Roll(Operation):\n+    def __init__(self, shift, axis=None):\n+        super().__init__()\n+        self.shift = shift\n+        self.axis = axis\n+\n+    def call(self, x):\n+        return backend.execute(\"roll\", x, self.shift, self.axis)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def roll(x, shift, axis=None):\n+    if any_symbolic_tensors((x,)):\n+        return Roll(shift, axis=axis).symbolic_call(x)\n+    return backend.execute(\"roll\", x, shift, axis=axis)\n+\n+\n class Subtract(Operation):\n     def call(self, x1, x2):\n         return backend.execute(\"subtract\", x1, x2)\n\n@@ -242,6 +242,202 @@ class NumpyTwoInputOpsShapeTest(testing.TestCase):\n             y = KerasTensor([2, 3, 4])\n             knp.isclose(x, y)\n \n+    def test_less(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.less(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.less(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.less(x, 2).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.less(x, y)\n+\n+    def test_less_equal(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.less_equal(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.less_equal(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.less_equal(x, 2).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.less_equal(x, y)\n+\n+    def test_linspace(self):\n+        start = KerasTensor([2, 3, 4])\n+        stop = KerasTensor([2, 3, 4])\n+        self.assertEqual(knp.linspace(start, stop, 10).shape, (10, 2, 3, 4))\n+\n+        start = KerasTensor([None, 3, 4])\n+        stop = KerasTensor([2, 3, 4])\n+        self.assertEqual(\n+            knp.linspace(start, stop, 10, axis=1).shape, (2, 10, 3, 4)\n+        )\n+\n+        start = KerasTensor([None, 3])\n+        stop = 2\n+        self.assertEqual(\n+            knp.linspace(start, stop, 10, axis=1).shape, (None, 10, 3)\n+        )\n+\n+        with self.assertRaises(ValueError):\n+            start = KerasTensor([2, 3])\n+            stop = KerasTensor([2, 3, 4])\n+            knp.linspace(start, stop)\n+\n+    def test_logical_and(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.logical_and(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.logical_and(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.logical_and(x, 2).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.logical_and(x, y)\n+\n+    def test_logical_or(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.logical_or(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.logical_or(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.logical_or(x, 2).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.logical_or(x, y)\n+\n+    def test_logspace(self):\n+        start = KerasTensor([2, 3, 4])\n+        stop = KerasTensor([2, 3, 4])\n+        self.assertEqual(knp.logspace(start, stop, 10).shape, (10, 2, 3, 4))\n+\n+        start = KerasTensor([None, 3, 4])\n+        stop = KerasTensor([2, 3, 4])\n+        self.assertEqual(\n+            knp.logspace(start, stop, 10, axis=1).shape, (2, 10, 3, 4)\n+        )\n+\n+        start = KerasTensor([None, 3])\n+        stop = 2\n+        self.assertEqual(\n+            knp.logspace(start, stop, 10, axis=1).shape, (None, 10, 3)\n+        )\n+\n+        with self.assertRaises(ValueError):\n+            start = KerasTensor([2, 3])\n+            stop = KerasTensor([2, 3, 4])\n+            knp.logspace(start, stop)\n+\n+    def test_maximum(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.maximum(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.maximum(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.maximum(x, 2).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.maximum(x, y)\n+\n+    def test_minimum(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.minimum(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.minimum(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.minimum(x, 2).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.minimum(x, y)\n+\n+    def test_mod(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.mod(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.mod(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.mod(x, 2).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.mod(x, y)\n+\n+    def test_not_equal(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.not_equal(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.not_equal(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.not_equal(x, 2).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.not_equal(x, y)\n+\n+    def test_outer(self):\n+        x = KerasTensor([3])\n+        y = KerasTensor([4])\n+        self.assertEqual(knp.outer(x, y).shape, (3, 4))\n+\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([4, 5])\n+        self.assertEqual(knp.outer(x, y).shape, (6, 20))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.outer(x, y).shape, (None, None))\n+\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.outer(x, 2).shape, (6, 1))\n+\n \n class NumpyOneInputOpsShapeTest(testing.TestCase):\n     def test_mean(self):\n@@ -660,6 +856,199 @@ class NumpyOneInputOpsShapeTest(testing.TestCase):\n         x = KerasTensor([None, 3])\n         self.assertEqual(knp.isnan(x).shape, (None, 3))\n \n+    def test_log(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.log(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.log(x).shape, (None, 3))\n+\n+    def test_log10(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.log10(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.log10(x).shape, (None, 3))\n+\n+    def test_log1p(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.log1p(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.log1p(x).shape, (None, 3))\n+\n+    def test_log2(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.log2(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.log2(x).shape, (None, 3))\n+\n+    def test_logaddexp(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.logaddexp(x, x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.logaddexp(x, x).shape, (None, 3))\n+\n+    def test_logical_not(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.logical_not(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.logical_not(x).shape, (None, 3))\n+\n+    def test_max(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.max(x).shape, ())\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.max(x).shape, ())\n+\n+    def test_meshgrid(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3, 4])\n+        z = KerasTensor([2, 3, 4, 5])\n+        self.assertEqual(knp.meshgrid(x, y)[0].shape, (24, 6))\n+        self.assertEqual(knp.meshgrid(x, y)[1].shape, (24, 6))\n+        self.assertEqual(knp.meshgrid(x, y, indexing=\"ij\")[0].shape, (6, 24))\n+        self.assertEqual(\n+            knp.meshgrid(x, y, z, indexing=\"ij\")[0].shape, (6, 24, 120)\n+        )\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([None, 3])\n+        self.assertEqual(knp.meshgrid(x, y)[0].shape, (None, None))\n+        self.assertEqual(knp.meshgrid(x, y)[1].shape, (None, None))\n+\n+        with self.assertRaises(ValueError):\n+            knp.meshgrid(x, y, indexing=\"kk\")\n+\n+    def test_moveaxis(self):\n+        x = KerasTensor([2, 3, 4, 5])\n+        self.assertEqual(knp.moveaxis(x, 0, -1).shape, (3, 4, 5, 2))\n+        self.assertEqual(knp.moveaxis(x, -1, 0).shape, (5, 2, 3, 4))\n+        self.assertEqual(knp.moveaxis(x, [0, 1], [-1, -2]).shape, (4, 5, 3, 2))\n+        self.assertEqual(knp.moveaxis(x, [0, 1], [1, 0]).shape, (3, 2, 4, 5))\n+        self.assertEqual(knp.moveaxis(x, [0, 1], [-2, -1]).shape, (4, 5, 2, 3))\n+\n+        x = KerasTensor([None, 3, 4, 5])\n+        self.assertEqual(knp.moveaxis(x, 0, -1).shape, (3, 4, 5, None))\n+        self.assertEqual(knp.moveaxis(x, -1, 0).shape, (5, None, 3, 4))\n+        self.assertEqual(\n+            knp.moveaxis(x, [0, 1], [-1, -2]).shape, (4, 5, 3, None)\n+        )\n+        self.assertEqual(knp.moveaxis(x, [0, 1], [1, 0]).shape, (3, None, 4, 5))\n+        self.assertEqual(\n+            knp.moveaxis(x, [0, 1], [-2, -1]).shape, (4, 5, None, 3)\n+        )\n+\n+    def test_ndim(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.ndim(x).shape, (2,))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.ndim(x).shape, (2,))\n+\n+    def test_nonzero(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(len(knp.nonzero(x)), 2)\n+        self.assertEqual(knp.nonzero(x)[0].shape, (None,))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(len(knp.nonzero(x)), 2)\n+        self.assertEqual(knp.nonzero(x)[0].shape, (None,))\n+\n+    def test_ones_like(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.ones_like(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.ones_like(x).shape, (None, 3))\n+\n+    def test_pad(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.pad(x, 1).shape, (4, 5))\n+        self.assertEqual(knp.pad(x, (1, 2)).shape, (5, 6))\n+        self.assertEqual(knp.pad(x, ((1, 2), (3, 4))).shape, (5, 10))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.pad(x, 1).shape, (None, 5))\n+        self.assertEqual(knp.pad(x, (1, 2)).shape, (None, 6))\n+        self.assertEqual(knp.pad(x, ((1, 2), (3, 4))).shape, (None, 10))\n+\n+        x = KerasTensor([None, 3, 3])\n+        self.assertEqual(knp.pad(x, 1).shape, (None, 5, 5))\n+        self.assertEqual(knp.pad(x, (1, 2)).shape, (None, 6, 6))\n+        self.assertEqual(\n+            knp.pad(x, ((1, 2), (3, 4), (5, 6))).shape, (None, 10, 14)\n+        )\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            knp.pad(x, ((1, 2), (3, 4), (5, 6)))\n+\n+    def test_prod(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.prod(x).shape, ())\n+        self.assertEqual(knp.prod(x, axis=0).shape, (3,))\n+        self.assertEqual(knp.prod(x, axis=1).shape, (2,))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.prod(x).shape, ())\n+        self.assertEqual(knp.prod(x, axis=0).shape, (3,))\n+        self.assertEqual(knp.prod(x, axis=1, keepdims=True).shape, (None, 1))\n+\n+    def test_ravel(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.ravel(x).shape, (6,))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.ravel(x).shape, (None,))\n+\n+    def test_real(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.real(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.real(x).shape, (None, 3))\n+\n+    def test_reciprocal(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.reciprocal(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.reciprocal(x).shape, (None, 3))\n+\n+    def test_repeat(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.repeat(x, 2).shape, (12,))\n+        self.assertEqual(knp.repeat(x, 3, axis=1).shape, (2, 9))\n+        self.assertEqual(knp.repeat(x, [1, 2], axis=0).shape, (3, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.repeat(x, 2).shape, (None,))\n+        self.assertEqual(knp.repeat(x, 3, axis=1).shape, (None, 9))\n+        self.assertEqual(knp.repeat(x, [1, 2], axis=0).shape, (3, 3))\n+\n+    def test_reshape(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.reshape(x, (3, 2)).shape, (3, 2))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.reshape(x, (3, 2)).shape, (3, 2))\n+\n+    def test_roll(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.roll(x, 1).shape, (2, 3))\n+        self.assertEqual(knp.roll(x, 1, axis=1).shape, (2, 3))\n+        self.assertEqual(knp.roll(x, 1, axis=0).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.roll(x, 1).shape, (None, 3))\n+        self.assertEqual(knp.roll(x, 1, axis=1).shape, (None, 3))\n+        self.assertEqual(knp.roll(x, 1, axis=0).shape, (None, 3))\n+\n \n class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n     def test_add(self):\n@@ -852,6 +1241,229 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n         self.assertAllClose(np.array(knp.Isclose()(x, 2)), np.isclose(x, 2))\n         self.assertAllClose(np.array(knp.Isclose()(2, x)), np.isclose(2, x))\n \n+    def test_less(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        y = np.array([[4, 5, 6], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.less(x, y)), np.less(x, y))\n+        self.assertAllClose(np.array(knp.less(x, 2)), np.less(x, 2))\n+        self.assertAllClose(np.array(knp.less(2, x)), np.less(2, x))\n+\n+        self.assertAllClose(np.array(knp.Less()(x, y)), np.less(x, y))\n+        self.assertAllClose(np.array(knp.Less()(x, 2)), np.less(x, 2))\n+        self.assertAllClose(np.array(knp.Less()(2, x)), np.less(2, x))\n+\n+    def test_less_equal(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        y = np.array([[4, 5, 6], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.less_equal(x, y)), np.less_equal(x, y))\n+        self.assertAllClose(np.array(knp.less_equal(x, 2)), np.less_equal(x, 2))\n+        self.assertAllClose(np.array(knp.less_equal(2, x)), np.less_equal(2, x))\n+\n+        self.assertAllClose(\n+            np.array(knp.LessEqual()(x, y)), np.less_equal(x, y)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.LessEqual()(x, 2)), np.less_equal(x, 2)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.LessEqual()(2, x)), np.less_equal(2, x)\n+        )\n+\n+    def test_linspace(self):\n+        self.assertAllClose(\n+            np.array(knp.linspace(0, 10, 5)), np.linspace(0, 10, 5)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.linspace(0, 10, 5, endpoint=False)),\n+            np.linspace(0, 10, 5, endpoint=False),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Linspace(num=5)(0, 10)), np.linspace(0, 10, 5)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Linspace(num=5, endpoint=False)(0, 10)),\n+            np.linspace(0, 10, 5, endpoint=False),\n+        )\n+\n+        start = np.zeros([2, 3, 4])\n+        stop = np.ones([2, 3, 4])\n+        self.assertAllClose(\n+            np.array(knp.linspace(start, stop, 5, retstep=True)[0]),\n+            np.linspace(start, stop, 5, retstep=True)[0],\n+        )\n+        self.assertAllClose(\n+            np.array(\n+                knp.linspace(start, stop, 5, endpoint=False, retstep=True)[0]\n+            ),\n+            np.linspace(start, stop, 5, endpoint=False, retstep=True)[0],\n+        )\n+        self.assertAllClose(\n+            np.array(\n+                knp.linspace(\n+                    start, stop, 5, endpoint=False, retstep=True, dtype=\"int32\"\n+                )[0]\n+            ),\n+            np.linspace(\n+                start, stop, 5, endpoint=False, retstep=True, dtype=\"int32\"\n+            )[0],\n+        )\n+\n+        self.assertAllClose(\n+            np.array(knp.Linspace(5, retstep=True)(start, stop)[0]),\n+            np.linspace(start, stop, 5, retstep=True)[0],\n+        )\n+        self.assertAllClose(\n+            np.array(\n+                knp.Linspace(5, endpoint=False, retstep=True)(start, stop)[0]\n+            ),\n+            np.linspace(start, stop, 5, endpoint=False, retstep=True)[0],\n+        )\n+        self.assertAllClose(\n+            np.array(\n+                knp.Linspace(5, endpoint=False, retstep=True, dtype=\"int32\")(\n+                    start, stop\n+                )[0]\n+            ),\n+            np.linspace(\n+                start, stop, 5, endpoint=False, retstep=True, dtype=\"int32\"\n+            )[0],\n+        )\n+\n+    def test_logical_and(self):\n+        x = np.array([[True, False], [True, True]])\n+        y = np.array([[False, False], [True, False]])\n+        self.assertAllClose(\n+            np.array(knp.logical_and(x, y)), np.logical_and(x, y)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.logical_and(x, True)), np.logical_and(x, True)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.logical_and(True, x)), np.logical_and(True, x)\n+        )\n+\n+        self.assertAllClose(\n+            np.array(knp.LogicalAnd()(x, y)), np.logical_and(x, y)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.LogicalAnd()(x, True)), np.logical_and(x, True)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.LogicalAnd()(True, x)), np.logical_and(True, x)\n+        )\n+\n+    def test_logical_or(self):\n+        x = np.array([[True, False], [True, True]])\n+        y = np.array([[False, False], [True, False]])\n+        self.assertAllClose(np.array(knp.logical_or(x, y)), np.logical_or(x, y))\n+        self.assertAllClose(\n+            np.array(knp.logical_or(x, True)), np.logical_or(x, True)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.logical_or(True, x)), np.logical_or(True, x)\n+        )\n+\n+        self.assertAllClose(\n+            np.array(knp.LogicalOr()(x, y)), np.logical_or(x, y)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.LogicalOr()(x, True)), np.logical_or(x, True)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.LogicalOr()(True, x)), np.logical_or(True, x)\n+        )\n+\n+    def test_logspace(self):\n+        self.assertAllClose(\n+            np.array(knp.logspace(0, 10, 5)), np.logspace(0, 10, 5)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.logspace(0, 10, 5, endpoint=False)),\n+            np.logspace(0, 10, 5, endpoint=False),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Logspace(num=5)(0, 10)), np.logspace(0, 10, 5)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Logspace(num=5, endpoint=False)(0, 10)),\n+            np.logspace(0, 10, 5, endpoint=False),\n+        )\n+\n+        start = np.zeros([2, 3, 4])\n+        stop = np.ones([2, 3, 4])\n+        self.assertAllClose(\n+            np.array(knp.logspace(start, stop, 5, base=10)),\n+            np.logspace(start, stop, 5, base=10),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.logspace(start, stop, 5, endpoint=False, base=10)),\n+            np.logspace(start, stop, 5, endpoint=False, base=10),\n+        )\n+\n+        self.assertAllClose(\n+            np.array(knp.Logspace(5, base=10)(start, stop)),\n+            np.logspace(start, stop, 5, base=10),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Logspace(5, endpoint=False, base=10)(start, stop)),\n+            np.logspace(start, stop, 5, endpoint=False, base=10),\n+        )\n+\n+    def test_maximum(self):\n+        x = np.array([[1, 2], [3, 4]])\n+        y = np.array([[5, 6], [7, 8]])\n+        self.assertAllClose(np.array(knp.maximum(x, y)), np.maximum(x, y))\n+        self.assertAllClose(np.array(knp.maximum(x, 1)), np.maximum(x, 1))\n+        self.assertAllClose(np.array(knp.maximum(1, x)), np.maximum(1, x))\n+\n+        self.assertAllClose(np.array(knp.Maximum()(x, y)), np.maximum(x, y))\n+        self.assertAllClose(np.array(knp.Maximum()(x, 1)), np.maximum(x, 1))\n+        self.assertAllClose(np.array(knp.Maximum()(1, x)), np.maximum(1, x))\n+\n+    def test_minimum(self):\n+        x = np.array([[1, 2], [3, 4]])\n+        y = np.array([[5, 6], [7, 8]])\n+        self.assertAllClose(np.array(knp.minimum(x, y)), np.minimum(x, y))\n+        self.assertAllClose(np.array(knp.minimum(x, 1)), np.minimum(x, 1))\n+        self.assertAllClose(np.array(knp.minimum(1, x)), np.minimum(1, x))\n+\n+        self.assertAllClose(np.array(knp.Minimum()(x, y)), np.minimum(x, y))\n+        self.assertAllClose(np.array(knp.Minimum()(x, 1)), np.minimum(x, 1))\n+        self.assertAllClose(np.array(knp.Minimum()(1, x)), np.minimum(1, x))\n+\n+    def test_mod(self):\n+        x = np.array([[1, 2], [3, 4]])\n+        y = np.array([[5, 6], [7, 8]])\n+        self.assertAllClose(np.array(knp.mod(x, y)), np.mod(x, y))\n+        self.assertAllClose(np.array(knp.mod(x, 1)), np.mod(x, 1))\n+        self.assertAllClose(np.array(knp.mod(1, x)), np.mod(1, x))\n+\n+        self.assertAllClose(np.array(knp.Mod()(x, y)), np.mod(x, y))\n+        self.assertAllClose(np.array(knp.Mod()(x, 1)), np.mod(x, 1))\n+        self.assertAllClose(np.array(knp.Mod()(1, x)), np.mod(1, x))\n+\n+    def test_not_equal(self):\n+        x = np.array([[1, 2], [3, 4]])\n+        y = np.array([[5, 6], [7, 8]])\n+        self.assertAllClose(np.array(knp.not_equal(x, y)), np.not_equal(x, y))\n+        self.assertAllClose(np.array(knp.not_equal(x, 1)), np.not_equal(x, 1))\n+        self.assertAllClose(np.array(knp.not_equal(1, x)), np.not_equal(1, x))\n+\n+        self.assertAllClose(np.array(knp.NotEqual()(x, y)), np.not_equal(x, y))\n+        self.assertAllClose(np.array(knp.NotEqual()(x, 1)), np.not_equal(x, 1))\n+        self.assertAllClose(np.array(knp.NotEqual()(1, x)), np.not_equal(1, x))\n+\n+    def test_outer(self):\n+        x = np.array([1, 2, 3])\n+        y = np.array([4, 5, 6])\n+        self.assertAllClose(np.array(knp.outer(x, y)), np.outer(x, y))\n+        self.assertAllClose(np.array(knp.Outer()(x, y)), np.outer(x, y))\n+\n+        x = np.ones([2, 3, 4])\n+        y = np.ones([2, 3, 4, 5, 6])\n+        self.assertAllClose(np.array(knp.outer(x, y)), np.outer(x, y))\n+        self.assertAllClose(np.array(knp.Outer()(x, y)), np.outer(x, y))\n+\n \n class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n     def test_mean(self):\n@@ -1354,6 +1966,256 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n         self.assertAllClose(np.array(knp.isnan(x)), np.isnan(x))\n         self.assertAllClose(np.array(knp.Isnan()(x)), np.isnan(x))\n \n+    def test_log(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.log(x)), np.log(x))\n+        self.assertAllClose(np.array(knp.Log()(x)), np.log(x))\n+\n+    def test_log10(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.log10(x)), np.log10(x))\n+        self.assertAllClose(np.array(knp.Log10()(x)), np.log10(x))\n+\n+    def test_log1p(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.log1p(x)), np.log1p(x))\n+        self.assertAllClose(np.array(knp.Log1p()(x)), np.log1p(x))\n+\n+    def test_log2(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.log2(x)), np.log2(x))\n+        self.assertAllClose(np.array(knp.Log2()(x)), np.log2(x))\n+\n+    def test_logaddexp(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        y = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.logaddexp(x, y)), np.logaddexp(x, y))\n+        self.assertAllClose(np.array(knp.Logaddexp()(x, y)), np.logaddexp(x, y))\n+\n+    def test_logical_not(self):\n+        x = np.array([[True, False], [False, True]])\n+        self.assertAllClose(np.array(knp.logical_not(x)), np.logical_not(x))\n+        self.assertAllClose(np.array(knp.LogicalNot()(x)), np.logical_not(x))\n+\n+    def test_max(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.max(x)), np.max(x))\n+        self.assertAllClose(np.array(knp.Max()(x)), np.max(x))\n+\n+        self.assertAllClose(np.array(knp.max(x, 0)), np.max(x, 0))\n+        self.assertAllClose(np.array(knp.Max(0)(x)), np.max(x, 0))\n+\n+        self.assertAllClose(np.array(knp.max(x, 1)), np.max(x, 1))\n+        self.assertAllClose(np.array(knp.Max(1)(x)), np.max(x, 1))\n+\n+    def test_min(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.min(x)), np.min(x))\n+        self.assertAllClose(np.array(knp.Min()(x)), np.min(x))\n+\n+        self.assertAllClose(np.array(knp.min(x, 0)), np.min(x, 0))\n+        self.assertAllClose(np.array(knp.Min(0)(x)), np.min(x, 0))\n+\n+        self.assertAllClose(np.array(knp.min(x, 1)), np.min(x, 1))\n+        self.assertAllClose(np.array(knp.Min(1)(x)), np.min(x, 1))\n+\n+    def test_meshgrid(self):\n+        x = np.array([1, 2, 3])\n+        y = np.array([4, 5, 6])\n+        z = np.array([7, 8, 9])\n+        self.assertAllClose(np.array(knp.meshgrid(x, y)), np.meshgrid(x, y))\n+        self.assertAllClose(np.array(knp.meshgrid(x, z)), np.meshgrid(x, z))\n+        self.assertAllClose(\n+            np.array(knp.meshgrid(x, y, z, indexing=\"ij\")),\n+            np.meshgrid(x, y, z, indexing=\"ij\"),\n+        )\n+        self.assertAllClose(np.array(knp.Meshgrid()(x, y)), np.meshgrid(x, y))\n+        self.assertAllClose(np.array(knp.Meshgrid()(x, z)), np.meshgrid(x, z))\n+        self.assertAllClose(\n+            np.array(knp.Meshgrid(indexing=\"ij\")(x, y, z)),\n+            np.meshgrid(x, y, z, indexing=\"ij\"),\n+        )\n+\n+        x = np.ones([1, 2, 3])\n+        y = np.ones([4, 5, 6, 6])\n+        z = np.ones([7, 8])\n+        self.assertAllClose(np.array(knp.meshgrid(x, y)), np.meshgrid(x, y))\n+        self.assertAllClose(np.array(knp.meshgrid(x, z)), np.meshgrid(x, z))\n+        self.assertAllClose(\n+            np.array(knp.meshgrid(x, y, z, indexing=\"ij\")),\n+            np.meshgrid(x, y, z, indexing=\"ij\"),\n+        )\n+        self.assertAllClose(np.array(knp.Meshgrid()(x, y)), np.meshgrid(x, y))\n+        self.assertAllClose(np.array(knp.Meshgrid()(x, z)), np.meshgrid(x, z))\n+        self.assertAllClose(\n+            np.array(knp.Meshgrid(indexing=\"ij\")(x, y, z)),\n+            np.meshgrid(x, y, z, indexing=\"ij\"),\n+        )\n+\n+    def test_moveaxis(self):\n+        x = np.array([[[0, 1], [2, 3]], [[4, 5], [6, 7]]])\n+        self.assertAllClose(\n+            np.array(knp.moveaxis(x, 0, -1)), np.moveaxis(x, 0, -1)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.moveaxis(x, -1, 0)), np.moveaxis(x, -1, 0)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.moveaxis(x, (0, 1), (1, 0))),\n+            np.moveaxis(x, (0, 1), (1, 0)),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.moveaxis(x, [0, 1, 2], [2, 0, 1])),\n+            np.moveaxis(x, [0, 1, 2], [2, 0, 1]),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Moveaxis(-1, 0)(x)), np.moveaxis(x, -1, 0)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Moveaxis((0, 1), (1, 0))(x)),\n+            np.moveaxis(x, (0, 1), (1, 0)),\n+        )\n+\n+        self.assertAllClose(\n+            np.array(knp.Moveaxis([0, 1, 2], [2, 0, 1])(x)),\n+            np.moveaxis(x, [0, 1, 2], [2, 0, 1]),\n+        )\n+\n+    def test_ndim(self):\n+        x = np.array([1, 2, 3])\n+        self.assertEqual(knp.ndim(x), np.ndim(x))\n+        self.assertEqual(knp.Ndim()(x), np.ndim(x))\n+\n+    def test_nonzero(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.nonzero(x)), np.nonzero(x))\n+        self.assertAllClose(np.array(knp.Nonzero()(x)), np.nonzero(x))\n+\n+    def test_ones_like(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.ones_like(x)), np.ones_like(x))\n+        self.assertAllClose(np.array(knp.OnesLike()(x)), np.ones_like(x))\n+\n+    def test_pad(self):\n+        x = np.array([[1, 2], [3, 4]])\n+        self.assertAllClose(\n+            np.array(knp.pad(x, ((1, 1), (1, 1)))), np.pad(x, ((1, 1), (1, 1)))\n+        )\n+        self.assertAllClose(\n+            np.array(knp.pad(x, ((1, 1), (1, 1)))),\n+            np.pad(x, ((1, 1), (1, 1))),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.pad(x, ((1, 1), (1, 1)), mode=\"reflect\")),\n+            np.pad(x, ((1, 1), (1, 1)), mode=\"reflect\"),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.pad(x, ((1, 1), (1, 1)), mode=\"symmetric\")),\n+            np.pad(x, ((1, 1), (1, 1)), mode=\"symmetric\"),\n+        )\n+\n+        self.assertAllClose(\n+            np.array(knp.Pad(((1, 1), (1, 1)))(x)), np.pad(x, ((1, 1), (1, 1)))\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Pad(((1, 1), (1, 1)))(x)),\n+            np.pad(x, ((1, 1), (1, 1))),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Pad(((1, 1), (1, 1)), mode=\"reflect\")(x)),\n+            np.pad(x, ((1, 1), (1, 1)), mode=\"reflect\"),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Pad(((1, 1), (1, 1)), mode=\"symmetric\")(x)),\n+            np.pad(x, ((1, 1), (1, 1)), mode=\"symmetric\"),\n+        )\n+\n+        x = np.ones([2, 3, 4, 5])\n+        self.assertAllClose(\n+            np.array(knp.pad(x, ((2, 3), (1, 1), (1, 1), (1, 1)))),\n+            np.pad(x, ((2, 3), (1, 1), (1, 1), (1, 1))),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Pad(((2, 3), (1, 1), (1, 1), (1, 1)))(x)),\n+            np.pad(x, ((2, 3), (1, 1), (1, 1), (1, 1))),\n+        )\n+\n+    def test_prod(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.prod(x)), np.prod(x))\n+        self.assertAllClose(np.array(knp.prod(x, axis=1)), np.prod(x, axis=1))\n+        self.assertAllClose(\n+            np.array(knp.prod(x, axis=1, keepdims=True)),\n+            np.prod(x, axis=1, keepdims=True),\n+        )\n+\n+        self.assertAllClose(np.array(knp.Prod()(x)), np.prod(x))\n+        self.assertAllClose(np.array(knp.Prod(axis=1)(x)), np.prod(x, axis=1))\n+        self.assertAllClose(\n+            np.array(knp.Prod(axis=1, keepdims=True)(x)),\n+            np.prod(x, axis=1, keepdims=True),\n+        )\n+\n+    def test_ravel(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.ravel(x)), np.ravel(x))\n+        self.assertAllClose(np.array(knp.Ravel()(x)), np.ravel(x))\n+\n+    def test_real(self):\n+        x = np.array([[1, 2, 3 - 3j], [3, 2, 1 + 5j]])\n+        self.assertAllClose(np.array(knp.real(x)), np.real(x))\n+        self.assertAllClose(np.array(knp.Real()(x)), np.real(x))\n+\n+    def test_reciprocal(self):\n+        x = np.array([[1.0, 2.0, 3.0], [3.0, 2.0, 1.0]])\n+        self.assertAllClose(np.array(knp.reciprocal(x)), np.reciprocal(x))\n+        self.assertAllClose(np.array(knp.Reciprocal()(x)), np.reciprocal(x))\n+\n+    def test_repeat(self):\n+        x = np.array([[1, 2], [3, 4]])\n+        self.assertAllClose(np.array(knp.repeat(x, 2)), np.repeat(x, 2))\n+        self.assertAllClose(\n+            np.array(knp.repeat(x, 3, axis=1)), np.repeat(x, 3, axis=1)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.repeat(x, [1, 2], axis=-1)),\n+            np.repeat(x, [1, 2], axis=-1),\n+        )\n+        self.assertAllClose(np.array(knp.Repeat(2)(x)), np.repeat(x, 2))\n+        self.assertAllClose(\n+            np.array(knp.Repeat(3, axis=1)(x)), np.repeat(x, 3, axis=1)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Repeat([1, 2], axis=0)(x)),\n+            np.repeat(x, [1, 2], axis=0),\n+        )\n+\n+    def test_reshape(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(\n+            np.array(knp.reshape(x, [3, 2])), np.reshape(x, [3, 2])\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Reshape([3, 2])(x)), np.reshape(x, [3, 2])\n+        )\n+\n+    def test_roll(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        self.assertAllClose(np.array(knp.roll(x, 1)), np.roll(x, 1))\n+        self.assertAllClose(\n+            np.array(knp.roll(x, 1, axis=1)), np.roll(x, 1, axis=1)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.roll(x, -1, axis=0)), np.roll(x, -1, axis=0)\n+        )\n+        self.assertAllClose(np.array(knp.Roll(1)(x)), np.roll(x, 1))\n+        self.assertAllClose(\n+            np.array(knp.Roll(1, axis=1)(x)), np.roll(x, 1, axis=1)\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Roll(-1, axis=0)(x)), np.roll(x, -1, axis=0)\n+        )\n+\n \n class NumpyArrayCreateOpsCorrectnessTest(testing.TestCase):\n     def test_ones(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
