{"custom_id": "keras#424420588fc55cdb9f5040d975a31532f9a3e324", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 10 | Churn Cumulative: 26103 | Contributors (this commit): 146 | Commits (past 90d): 9 | Contributors (cumulative): 146 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1351,15 +1351,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                     model._train_counter.assign_add(1)\n                 return outputs\n \n-            if self.jit_compile and not isinstance(\n-                model.distribute_strategy,\n-                (\n-                    tf.compat.v1.distribute.experimental.TPUStrategy,\n-                    tf.distribute.TPUStrategy,\n-                ),\n-            ):\n-                # TODO(b/258249546): Explicit `jit_compile=True` on TPU causes\n-                # unexpected behavior, so we skip TPU training now.\n+            if self.jit_compile:\n                 run_step = tf.function(\n                     run_step, jit_compile=True, reduce_retracing=True\n                 )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6830a925a5d1aaefd270a484bf0c9178c6459769", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 107 | Contributors (this commit): 5 | Commits (past 90d): 12 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -2,7 +2,7 @@ import random as python_random\n \n import numpy as np\n \n-import keras_core.backend\n+from keras_core import backend\n from keras_core.api_export import keras_core_export\n \n \n@@ -33,7 +33,7 @@ class SeedGenerator:\n         if custom_backend is not None:\n             self.backend = custom_backend\n         else:\n-            self.backend = keras_core.backend\n+            self.backend = backend\n \n         if seed is None:\n             seed = make_default_seed()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f60cd3e408ee415b5b7aabd1eb4ecc07ae5033c7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 211 | Contributors (this commit): 3 | Commits (past 90d): 8 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -3,7 +3,12 @@ from keras_core.api_export import keras_core_export\n from keras_core.backend.common import global_state\n \n \n-@keras_core_export(\"keras_core.mixed_precision.DTypePolicy\")\n+@keras_core_export(\n+    [\n+        \"keras_core.mixed_precision.DTypePolicy\",\n+        \"keras_core.mixed_precision.Policy\",\n+    ]\n+)\n class DTypePolicy:\n     \"\"\"A dtype policy for a Keras layer.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bea61227f1c2dffe6d475e401b0e18037c0f7601", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 28 | Files Changed: 3 | Hunks: 13 | Methods Changed: 5 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 38 | Churn Cumulative: 3170 | Contributors (this commit): 11 | Commits (past 90d): 104 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -13,6 +13,7 @@ from keras_core.api_export import keras_core_export\n from keras_core.backend.common import global_state\n from keras_core.saving import object_registration\n from keras_core.utils import python_utils\n+from keras_core.utils.module_utils import tensorflow as tf\n \n PLAIN_TYPES = (str, int, float, bool)\n \n@@ -127,11 +128,6 @@ def serialize_keras_object(obj):\n         A python dict that represents the object. The python dict can be\n         deserialized via `deserialize_keras_object()`.\n     \"\"\"\n-    if backend.backend() == \"tensorflow\":\n-        import tensorflow as tf\n-    else:\n-        tf = None\n-\n     if obj is None:\n         return obj\n \n@@ -163,7 +159,7 @@ def serialize_keras_object(obj):\n                 \"keras_history\": history,\n             },\n         }\n-    if tf is not None and isinstance(obj, tf.TensorShape):\n+    if tf.available and isinstance(obj, tf.TensorShape):\n         return obj.as_list() if obj._dims is not None else None\n     if backend.is_tensor(obj):\n         return {\n@@ -185,7 +181,7 @@ def serialize_keras_object(obj):\n         else:\n             # Treat numpy floats / etc as plain types.\n             return obj.item()\n-    if tf is not None and isinstance(obj, tf.DType):\n+    if tf.available and isinstance(obj, tf.DType):\n         return obj.name\n     if isinstance(obj, types.FunctionType) and obj.__name__ == \"<lambda>\":\n         warnings.warn(\n@@ -203,7 +199,7 @@ def serialize_keras_object(obj):\n                 \"value\": python_utils.func_dump(obj),\n             },\n         }\n-    if tf is not None and isinstance(obj, tf.TypeSpec):\n+    if tf.available and isinstance(obj, tf.TypeSpec):\n         ts_config = obj._serialize()\n         # TensorShape and tf.DType conversion\n         ts_config = list(\n@@ -472,11 +468,6 @@ def deserialize_keras_object(\n     Returns:\n         The object described by the `config` dictionary.\n     \"\"\"\n-    if backend.backend() == \"tensorflow\":\n-        import tensorflow as tf\n-    else:\n-        tf = None\n-\n     safe_scope_arg = in_safe_mode()  # Enforces SafeModeScope\n     safe_mode = safe_scope_arg if safe_scope_arg is not None else safe_mode\n \n\n@@ -46,6 +46,7 @@ from keras_core.trainers.data_adapters import generator_data_adapter\n from keras_core.trainers.data_adapters import py_dataset_adapter\n from keras_core.trainers.data_adapters import tf_dataset_adapter\n from keras_core.trainers.data_adapters import torch_data_adapter\n+from keras_core.utils.module_utils import tensorflow as tf\n \n \n class EpochIterator:\n@@ -60,11 +61,6 @@ class EpochIterator:\n         class_weight=None,\n         steps_per_execution=1,\n     ):\n-        try:\n-            import tensorflow as tf\n-        except ImportError:\n-            tf = None\n-\n         self.steps_per_epoch = steps_per_epoch\n         self.steps_per_execution = steps_per_execution\n         if steps_per_epoch:\n@@ -80,7 +76,7 @@ class EpochIterator:\n                 batch_size=batch_size,\n                 steps=steps_per_epoch,\n             )\n-        elif tf is not None and isinstance(x, tf.data.Dataset):\n+        elif tf.available and isinstance(x, tf.data.Dataset):\n             self.data_adapter = tf_dataset_adapter.TFDatasetAdapter(\n                 x, class_weight=class_weight\n             )\n@@ -164,11 +160,6 @@ class EpochIterator:\n         return iterator\n \n     def enumerate_epoch(self, return_type=\"np\"):\n-        try:\n-            import tensorflow as tf\n-        except ImportError:\n-            tf = None\n-\n         buffer = []\n         if self.steps_per_epoch:\n             if not self._current_iterator:\n@@ -179,10 +170,10 @@ class EpochIterator:\n                 if self._insufficient_data:\n                     break\n \n-                if tf is None:\n-                    errors = (StopIteration,)\n-                else:\n+                if tf.available:\n                     errors = (StopIteration, tf.errors.OutOfRangeError)\n+                else:\n+                    errors = (StopIteration,)\n \n                 try:\n                     data = next(self._current_iterator)\n\n@@ -771,7 +771,7 @@ def resolve_auto_jit_compile(model):\n def model_supports_jit(model):\n     if platform.system() == \"Darwin\" and \"arm\" in platform.processor().lower():\n         if backend.backend() == \"tensorflow\":\n-            import tensorflow as tf\n+            from keras_core.utils.module_utils import tensorflow as tf\n \n             if tf.config.list_physical_devices(\"GPU\"):\n                 return False\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e395f16bfd03e0ec65dd77247f465caa69cc83ab", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 18 | Churn Cumulative: 2864 | Contributors (this commit): 12 | Commits (past 90d): 98 | Contributors (cumulative): 18 | DMM Complexity: 1.0\n\nDIFF:\n@@ -44,7 +44,7 @@ class Trainer:\n             )\n         else:\n             self._compile_loss = None\n-        if metrics is not None:\n+        if metrics is not None or weighted_metrics is not None:\n             self._compile_metrics = CompileMetrics(\n                 metrics, weighted_metrics, output_names=output_names\n             )\n\n@@ -109,6 +109,22 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n         # And those weights are tracked at the model level\n         self.assertEqual(len(model.metrics_variables), 6)\n \n+        # Models with only weighted_metrics should have the same 3 metrics\n+        model_weighted = ModelWithMetric(units=3)\n+        model_weighted.compile(\n+            optimizer=optimizers.SGD(),\n+            loss=losses.MeanSquaredError(),\n+            weighted_metrics=[metrics.MeanSquaredError()],\n+        )\n+        model_weighted.fit(\n+            x,\n+            y,\n+            batch_size=2,\n+            epochs=1,\n+            sample_weight=np.ones(2),\n+        )\n+        self.assertEqual(len(model_weighted.metrics), 3)\n+\n     @parameterized.named_parameters(\n         [\n             (\"eager\", True, False, False),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e327db2f7016e3605593f6687e48daf815391a7f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 22/22 | Churn Δ: 3 | Churn Cumulative: 670 | Contributors (this commit): 11 | Commits (past 90d): 1 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -20,6 +20,7 @@ import threading\n from tensorflow.core.framework import attr_value_pb2\n from tensorflow.python.eager import context\n from tensorflow.python.framework import ops\n+from tensorflow.python.framework import tensor\n from tensorflow.python.ops import gen_resource_variable_ops\n from tensorflow.python.ops import resource_variable_ops\n from tensorflow.python.ops import variable_scope\n@@ -121,7 +122,7 @@ class LazyInitVariable(resource_variable_ops.BaseResourceVariable):\n             )\n \n         if (\n-            isinstance(initial_value, ops.Tensor)\n+            isinstance(initial_value, tensor.Tensor)\n             and hasattr(initial_value, \"graph\")\n             and initial_value.graph.building_function\n         ):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7b97f716222a3f63d2794a4cb99305ad8e9ef778", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 94 | Lines Deleted: 98 | Files Changed: 27 | Hunks: 83 | Methods Changed: 57 | Complexity Δ (Sum/Max): 12/12 | Churn Δ: 192 | Churn Cumulative: 8826 | Contributors (this commit): 13 | Commits (past 90d): 240 | Contributors (cumulative): 62 | DMM Complexity: 1.0\n\nDIFF:\n@@ -83,7 +83,7 @@ def clear_session():\n     GLOBAL_SETTINGS_TRACKER = threading.local()\n \n     if backend.backend() == \"tensorflow\":\n-        import tensorflow as tf\n+        from keras_core.utils.module_utils import tensorflow as tf\n \n         tf.compat.v1.reset_default_graph()\n         if tf.executing_eagerly():\n\n@@ -2,6 +2,7 @@ from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.utils import backend_utils\n+from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.CategoryEncoding\")\n@@ -83,9 +84,7 @@ class CategoryEncoding(Layer):\n     \"\"\"\n \n     def __init__(self, num_tokens=None, output_mode=\"multi_hot\", **kwargs):\n-        try:\n-            import tensorflow as tf\n-        except ImportError:\n+        if not tf.available:\n             raise ImportError(\n                 \"Layer CategoryEncoding requires TensorFlow. \"\n                 \"Install it via `pip install tensorflow`.\"\n\n@@ -4,6 +4,7 @@ from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.utils import backend_utils\n+from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.Discretization\")\n@@ -102,9 +103,7 @@ class Discretization(Layer):\n         dtype=None,\n         **kwargs,\n     ):\n-        try:\n-            import tensorflow as tf\n-        except ImportError:\n+        if not tf.available:\n             raise ImportError(\n                 \"Layer Discretization requires TensorFlow. \"\n                 \"Install it via `pip install tensorflow`.\"\n@@ -193,8 +192,6 @@ class Discretization(Layer):\n         return backend.KerasTensor(shape=inputs.shape, dtype=\"int32\")\n \n     def __call__(self, inputs):\n-        import tensorflow as tf\n-\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, backend.KerasTensor)):\n             inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n         if not self.built:\n\n@@ -2,6 +2,7 @@ from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.utils import backend_utils\n+from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.HashedCrossing\")\n@@ -74,9 +75,7 @@ class HashedCrossing(Layer):\n         dtype=None,\n         **kwargs,\n     ):\n-        try:\n-            import tensorflow as tf\n-        except ImportError:\n+        if not tf.available:\n             raise ImportError(\n                 \"Layer HashedCrossing requires TensorFlow. \"\n                 \"Install it via `pip install tensorflow`.\"\n\n@@ -4,6 +4,7 @@ from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.utils import backend_utils\n+from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.Hashing\")\n@@ -143,9 +144,7 @@ class Hashing(Layer):\n         name=None,\n         **kwargs,\n     ):\n-        try:\n-            import tensorflow as tf\n-        except ImportError:\n+        if not tf.available:\n             raise ImportError(\n                 \"Layer Hashing requires TensorFlow. \"\n                 \"Install it via `pip install tensorflow`.\"\n@@ -183,8 +182,6 @@ class Hashing(Layer):\n         self.supports_jit = False\n \n     def call(self, inputs):\n-        import tensorflow as tf\n-\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n         outputs = self.layer.call(inputs)\n\n@@ -4,6 +4,7 @@ from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.utils import backend_utils\n+from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.IntegerLookup\")\n@@ -309,9 +310,7 @@ class IntegerLookup(Layer):\n         name=None,\n         **kwargs,\n     ):\n-        try:\n-            import tensorflow as tf\n-        except ImportError:\n+        if not tf.available:\n             raise ImportError(\n                 \"Layer IntegerLookup requires TensorFlow. \"\n                 \"Install it via `pip install tensorflow`.\"\n@@ -449,8 +448,6 @@ class IntegerLookup(Layer):\n         self.layer.set_vocabulary(vocabulary, idf_weights=idf_weights)\n \n     def call(self, inputs):\n-        import tensorflow as tf\n-\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n         outputs = self.layer.call(inputs)\n\n@@ -6,6 +6,7 @@ from keras_core import backend\n from keras_core import ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n+from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.Normalization\")\n@@ -216,8 +217,6 @@ class Normalization(Layer):\n                 data is batched, and if that assumption doesn't hold, the mean\n                 and variance may be incorrectly computed.\n         \"\"\"\n-        import tensorflow as tf\n-\n         if isinstance(data, np.ndarray) or backend.is_tensor(data):\n             input_shape = data.shape\n         elif isinstance(data, tf.data.Dataset):\n\n@@ -4,6 +4,7 @@ from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.utils import backend_utils\n+from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.RandomCrop\")\n@@ -52,9 +53,7 @@ class RandomCrop(Layer):\n     \"\"\"\n \n     def __init__(self, height, width, seed=None, name=None, **kwargs):\n-        try:\n-            import tensorflow as tf\n-        except ImportError:\n+        if not tf.available:\n             raise ImportError(\n                 \"Layer RandomCrop requires TensorFlow. \"\n                 \"Install it via `pip install tensorflow`.\"\n@@ -74,8 +73,6 @@ class RandomCrop(Layer):\n         self._allow_non_tensor_positional_args = True\n \n     def call(self, inputs, training=True):\n-        import tensorflow as tf\n-\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n         outputs = self.layer.call(inputs, training=training)\n\n@@ -4,6 +4,7 @@ from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.utils import backend_utils\n+from keras_core.utils.module_utils import tensorflow as tf\n \n HORIZONTAL = \"horizontal\"\n VERTICAL = \"vertical\"\n@@ -45,9 +46,7 @@ class RandomFlip(Layer):\n     def __init__(\n         self, mode=HORIZONTAL_AND_VERTICAL, seed=None, name=None, **kwargs\n     ):\n-        try:\n-            import tensorflow as tf\n-        except ImportError:\n+        if not tf.available:\n             raise ImportError(\n                 \"Layer RandomFlip requires TensorFlow. \"\n                 \"Install it via `pip install tensorflow`.\"\n@@ -66,8 +65,6 @@ class RandomFlip(Layer):\n         self._allow_non_tensor_positional_args = True\n \n     def call(self, inputs, training=True):\n-        import tensorflow as tf\n-\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n         outputs = self.layer.call(inputs, training=training)\n\n@@ -4,6 +4,7 @@ from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.utils import backend_utils\n+from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.RandomRotation\")\n@@ -85,9 +86,7 @@ class RandomRotation(Layer):\n         name=None,\n         **kwargs,\n     ):\n-        try:\n-            import tensorflow as tf\n-        except ImportError:\n+        if not tf.available:\n             raise ImportError(\n                 \"Layer RandomRotation requires TensorFlow. \"\n                 \"Install it via `pip install tensorflow`.\"\n@@ -109,8 +108,6 @@ class RandomRotation(Layer):\n         self._allow_non_tensor_positional_args = True\n \n     def call(self, inputs, training=True):\n-        import tensorflow as tf\n-\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n         outputs = self.layer.call(inputs, training=training)\n\n@@ -4,6 +4,7 @@ from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.utils import backend_utils\n+from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.RandomTranslation\")\n@@ -75,9 +76,7 @@ class RandomTranslation(Layer):\n         name=None,\n         **kwargs,\n     ):\n-        try:\n-            import tensorflow as tf\n-        except ImportError:\n+        if not tf.available:\n             raise ImportError(\n                 \"Layer RandomTranslation requires TensorFlow. \"\n                 \"Install it via `pip install tensorflow`.\"\n@@ -99,8 +98,6 @@ class RandomTranslation(Layer):\n         self._allow_non_tensor_positional_args = True\n \n     def call(self, inputs, training=True):\n-        import tensorflow as tf\n-\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n         outputs = self.layer.call(inputs, training=training)\n\n@@ -4,6 +4,7 @@ from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.utils import backend_utils\n+from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.RandomZoom\")\n@@ -97,9 +98,7 @@ class RandomZoom(Layer):\n         name=None,\n         **kwargs,\n     ):\n-        try:\n-            import tensorflow as tf\n-        except ImportError:\n+        if not tf.available:\n             raise ImportError(\n                 \"Layer RandomZoom requires TensorFlow. \"\n                 \"Install it via `pip install tensorflow`.\"\n@@ -122,8 +121,6 @@ class RandomZoom(Layer):\n         self.supports_jit = False\n \n     def call(self, inputs, training=True):\n-        import tensorflow as tf\n-\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n         outputs = self.layer.call(inputs, training=training)\n\n@@ -4,6 +4,7 @@ from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.utils import backend_utils\n+from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.StringLookup\")\n@@ -307,9 +308,7 @@ class StringLookup(Layer):\n         dtype=None,\n         **kwargs,\n     ):\n-        try:\n-            import tensorflow as tf\n-        except ImportError:\n+        if not tf.available:\n             raise ImportError(\n                 \"Layer StringLookup requires TensorFlow. \"\n                 \"Install it via `pip install tensorflow`.\"\n@@ -443,8 +442,6 @@ class StringLookup(Layer):\n         self.layer.set_vocabulary(vocabulary, idf_weights=idf_weights)\n \n     def call(self, inputs):\n-        import tensorflow as tf\n-\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n         outputs = self.layer.call(inputs)\n\n@@ -5,6 +5,7 @@ from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.saving import serialization_lib\n from keras_core.utils import backend_utils\n+from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.TextVectorization\")\n@@ -212,9 +213,7 @@ class TextVectorization(Layer):\n         name=None,\n         **kwargs,\n     ):\n-        try:\n-            import tensorflow as tf\n-        except ImportError:\n+        if not tf.available:\n             raise ImportError(\n                 \"Layer TextVectorization requires TensorFlow. \"\n                 \"Install it via `pip install tensorflow`.\"\n@@ -366,8 +365,6 @@ class TextVectorization(Layer):\n         self.layer.set_vocabulary(vocabulary, idf_weights=idf_weights)\n \n     def call(self, inputs):\n-        import tensorflow as tf\n-\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n         outputs = self.layer.call(inputs)\n\n@@ -109,7 +109,7 @@ def load_model(filepath, custom_objects=None, compile=True, safe_mode=True):\n \n     # Support for remote zip files\n     if (\n-        saving_lib.is_remote_path(filepath)\n+        file_utils.is_remote_path(filepath)\n         and not file_utils.isdir(filepath)\n         and not is_keras_zip\n     ):\n\n@@ -4,7 +4,6 @@ import datetime\n import io\n import json\n import os\n-import re\n import tempfile\n import warnings\n import zipfile\n@@ -87,7 +86,7 @@ def save_model(model, filepath, weights_format=\"h5\"):\n         }\n     )\n     # TODO(rameshsampath): Need a better logic for local vs remote path\n-    if is_remote_path(filepath):\n+    if file_utils.is_remote_path(filepath):\n         # Remote path. Zip to local drive and copy to remote\n         zip_filepath = os.path.join(get_temp_dir(), \"tmp_model.keras\")\n     else:\n@@ -124,7 +123,7 @@ def save_model(model, filepath, weights_format=\"h5\"):\n         weights_store.close()\n         asset_store.close()\n \n-    if is_remote_path(filepath):\n+    if file_utils.is_remote_path(filepath):\n         # Using gfile context manager doesn't close zip file when\n         # writing to GCS. Hence writing to local and copying to filepath.\n         file_utils.copy(zip_filepath, filepath, overwrite=True)\n@@ -245,12 +244,6 @@ def load_weights_only(model, filepath, skip_mismatch=False):\n         archive.close()\n \n \n-def is_remote_path(filepath):\n-    if re.match(r\"^(/cns|/cfs|/gcs|.*://).*$\", str(filepath)):\n-        return True\n-    return False\n-\n-\n def _write_to_zip_recursively(zipfile_to_save, system_path, zip_path):\n     if not file_utils.isdir(system_path):\n         zipfile_to_save.write(system_path, zip_path)\n\n@@ -107,7 +107,7 @@ class ArrayDataAdapter(DataAdapter):\n             yield tree.map_structure(lambda x: x[start:stop], inputs)\n \n     def get_tf_dataset(self):\n-        import tensorflow as tf\n+        from keras_core.utils.module_utils import tensorflow as tf\n \n         inputs = self._inputs\n         shuffle = self._shuffle\n@@ -302,7 +302,7 @@ def convert_to_arrays(arrays, dtype=None):\n             elif isinstance(x, pandas.DataFrame):\n                 x = x.to_numpy(dtype=dtype)\n         if is_tf_ragged_tensor(x):\n-            import tensorflow as tf\n+            from keras_core.utils.module_utils import tensorflow as tf\n \n             return tf.cast(x, dtype=dtype)\n         if not isinstance(x, np.ndarray):\n\n@@ -17,7 +17,7 @@ except ImportError:\n # backend framework we are not currently using just to do type-checking.\n ARRAY_TYPES = (np.ndarray,)\n if backend.backend() == \"tensorflow\":\n-    import tensorflow as tf\n+    from keras_core.utils.module_utils import tensorflow as tf\n \n     ARRAY_TYPES = ARRAY_TYPES + (np.ndarray, tf.RaggedTensor)\n if pandas:\n\n@@ -22,7 +22,7 @@ class GeneratorDataAdapter(DataAdapter):\n             )\n \n     def _set_tf_output_signature(self):\n-        import tensorflow as tf\n+        from keras_core.utils.module_utils import tensorflow as tf\n \n         data, generator = peek_and_restore(self.generator)\n         self.generator = generator\n@@ -47,7 +47,7 @@ class GeneratorDataAdapter(DataAdapter):\n             yield batch\n \n     def get_tf_dataset(self):\n-        import tensorflow as tf\n+        from keras_core.utils.module_utils import tensorflow as tf\n \n         if self._output_signature is None:\n             self._set_tf_output_signature()\n\n@@ -188,7 +188,7 @@ class PyDatasetAdapter(DataAdapter):\n         self._output_signature = None\n \n     def _set_tf_output_signature(self):\n-        import tensorflow as tf\n+        from keras_core.utils.module_utils import tensorflow as tf\n \n         def get_tensor_spec(x):\n             shape = x.shape\n@@ -273,7 +273,7 @@ class PyDatasetAdapter(DataAdapter):\n                 self.enqueuer.stop()\n \n     def get_tf_dataset(self):\n-        import tensorflow as tf\n+        from keras_core.utils.module_utils import tensorflow as tf\n \n         if self._output_signature is None:\n             self._set_tf_output_signature()\n\n@@ -8,7 +8,7 @@ class TFDatasetAdapter(DataAdapter):\n     \"\"\"Adapter that handles `tf.data.Dataset`.\"\"\"\n \n     def __init__(self, dataset, class_weight=None):\n-        import tensorflow as tf\n+        from keras_core.utils.module_utils import tensorflow as tf\n \n         if not isinstance(dataset, tf.data.Dataset):\n             raise ValueError(\n@@ -64,7 +64,7 @@ def make_class_weight_map_fn(class_weight):\n         A function that can be used with `tf.data.Dataset.map` to apply class\n         weighting.\n     \"\"\"\n-    import tensorflow as tf\n+    from keras_core.utils.module_utils import tensorflow as tf\n \n     class_weight_tensor = tf.convert_to_tensor(\n         [\n\n@@ -28,7 +28,7 @@ class TorchDataLoaderAdapter(DataAdapter):\n         return self._dataloader\n \n     def get_tf_dataset(self):\n-        import tensorflow as tf\n+        from keras_core.utils.module_utils import tensorflow as tf\n \n         output_signature = self.peek_and_get_tensor_spec()\n         return tf.data.Dataset.from_generator(\n@@ -37,7 +37,7 @@ class TorchDataLoaderAdapter(DataAdapter):\n         )\n \n     def peek_and_get_tensor_spec(self):\n-        import tensorflow as tf\n+        from keras_core.utils.module_utils import tensorflow as tf\n \n         batch_data = next(iter(self._dataloader))\n \n\n@@ -513,7 +513,7 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n         reason=\"Only tensorflow supports raggeds\",\n     )\n     def test_trainer_with_raggeds(self, model_class):\n-        import tensorflow as tf\n+        from keras_core.utils.module_utils import tensorflow as tf\n \n         def loss_fn(y, y_pred, sample_weight=None):\n             return 0\n\n@@ -5,7 +5,7 @@ from keras_core import backend as backend_module\n \n def in_tf_graph():\n     if \"tensorflow\" in sys.modules:\n-        import tensorflow as tf\n+        from keras_core.utils.module_utils import tensorflow as tf\n \n         return not tf.executing_eagerly()\n     return False\n\n@@ -1,4 +1,5 @@\n from keras_core.api_export import keras_core_export\n+from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.utils.split_dataset\")\n@@ -35,8 +36,6 @@ def split_dataset(\n     >>> int(right_ds.cardinality())\n     200\n     \"\"\"\n-    import tensorflow as tf\n-\n     # TODO: long-term, port implementation.\n     return tf.keras.utils.split_dataset(\n         dataset,\n@@ -181,8 +180,6 @@ def image_dataset_from_directory(\n     - if `color_mode` is `\"rgba\"`,\n         there are 4 channels in the image tensors.\n     \"\"\"\n-    import tensorflow as tf\n-\n     # TODO: long-term, port implementation.\n     return tf.keras.utils.image_dataset_from_directory(\n         directory,\n@@ -331,8 +328,6 @@ def timeseries_dataset_from_array(\n         break\n     ```\n     \"\"\"\n-    import tensorflow as tf\n-\n     # TODO: long-term, port implementation.\n     return tf.keras.utils.timeseries_dataset_from_array(\n         data,\n@@ -452,8 +447,6 @@ def text_dataset_from_directory(\n         of shape `(batch_size, num_classes)`, representing a one-hot\n         encoding of the class index.\n     \"\"\"\n-    import tensorflow as tf\n-\n     # TODO: long-term, port implementation.\n     return tf.keras.utils.text_dataset_from_directory(\n         directory,\n@@ -574,8 +567,6 @@ def audio_dataset_from_directory(\n       of shape `(batch_size, num_classes)`, representing a one-hot\n       encoding of the class index.\n     \"\"\"\n-    import tensorflow as tf\n-\n     # TODO: long-term, port implementation.\n     return tf.keras.utils.audio_dataset_from_directory(\n         directory,\n\n@@ -1,6 +1,7 @@\n import hashlib\n import os\n import pathlib\n+import re\n import shutil\n import tarfile\n import urllib\n@@ -382,52 +383,91 @@ def validate_file(fpath, file_hash, algorithm=\"auto\", chunk_size=65535):\n         return False\n \n \n-# Below are gfile utils\n+def is_remote_path(filepath):\n+    \"\"\"Returns `True` for paths that represent a remote GCS location.\"\"\"\n+    # TODO: improve generality.\n+    if re.match(r\"^(/cns|/cfs|/gcs|.*://).*$\", str(filepath)):\n+        return True\n+    return False\n+\n+\n+# Below are gfile-replacement utils.\n+\n+\n+def _raise_if_no_gfile(path):\n+    raise ValueError(\n+        \"Handling remote paths requires installing TensorFlow \"\n+        f\"(in order to use gfile). Received path: {path}\"\n+    )\n \n \n def exists(path):\n+    if is_remote_path(path):\n         if gfile.available:\n             return gfile.exists(path)\n+        else:\n+            _raise_if_no_gfile(path)\n     return os.path.exists(path)\n \n \n-def File(fname, mode=\"r\"):\n+def File(path, mode=\"r\"):\n+    if is_remote_path(path):\n         if gfile.available:\n-        return gfile.GFile(fname, mode=mode)\n-    return open(fname, mode=mode)\n+            return gfile.GFile(path, mode=mode)\n+        else:\n+            _raise_if_no_gfile(path)\n+    return open(path, mode=mode)\n \n \n def join(path, *paths):\n+    if is_remote_path(path):\n         if gfile.available:\n             return gfile.join(path, *paths)\n+        else:\n+            _raise_if_no_gfile(path)\n     return os.path.join(path, *paths)\n \n \n def isdir(path):\n+    if is_remote_path(path):\n         if gfile.available:\n             return gfile.isdir(path)\n+        else:\n+            _raise_if_no_gfile(path)\n     return os.path.isdir(path)\n \n \n def rmtree(path):\n+    if is_remote_path(path):\n         if gfile.available:\n             return gfile.rmtree(path)\n+        else:\n+            _raise_if_no_gfile(path)\n     return shutil.rmtree\n \n \n def listdir(path):\n+    if is_remote_path(path):\n         if gfile.available:\n             return gfile.listdir(path)\n+        else:\n+            _raise_if_no_gfile(path)\n     return os.listdir(path)\n \n \n def copy(src, dst):\n+    if is_remote_path(src) or is_remote_path(dst):\n         if gfile.available:\n             return gfile.copy(src, dst)\n+        else:\n+            _raise_if_no_gfile(f\"src={src} dst={dst}\")\n     return shutil.copy(src, dst)\n \n \n def makedirs(path):\n+    if is_remote_path(path):\n         if gfile.available:\n             return gfile.makedirs(path)\n+        else:\n+            _raise_if_no_gfile(path)\n     return os.makedirs(path)\n\n@@ -2,6 +2,7 @@ import random\n \n import numpy as np\n \n+from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.utils.module_utils import tensorflow as tf\n \n@@ -21,7 +22,7 @@ def set_random_seed(seed):\n     ```python\n     import random\n     import numpy as np\n-    import tensorflow as tf\n+    from keras_core.utils.module_utils import tensorflow as tf\n     random.seed(seed)\n     np.random.seed(seed)\n     tf.random.set_seed(seed)\n@@ -42,5 +43,9 @@ def set_random_seed(seed):\n         )\n     random.seed(seed)\n     np.random.seed(seed)\n+    if tf.available:\n         tf.random.set_seed(seed)\n-    # TODO: also seed other backends.\n+    if backend.backend() == \"torch\":\n+        import torch\n+\n+        torch.manual_seed(seed)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#063f0f5d70bed711a087f02bd5cf85dc739f80bc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 547 | Contributors (this commit): 22 | Commits (past 90d): 5 | Contributors (cumulative): 22 | DMM Complexity: None\n\nDIFF:\n@@ -36,7 +36,6 @@ setup(\n     author_email=\"keras-users@googlegroups.com\",\n     license=\"Apache License 2.0\",\n     install_requires=[\n-        \"tensorflow\",\n         \"absl-py\",\n         \"numpy\",\n         \"rich\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3f73f958752b10bafc176492444a0330b5620c44", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 795 | Contributors (this commit): 1 | Commits (past 90d): 10 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -85,7 +85,6 @@ def save_model(model, filepath, weights_format=\"h5\"):\n             \"date_saved\": datetime.datetime.now().strftime(\"%Y-%m-%d@%H:%M:%S\"),\n         }\n     )\n-    # TODO(rameshsampath): Need a better logic for local vs remote path\n     if file_utils.is_remote_path(filepath):\n         # Remote path. Zip to local drive and copy to remote\n         zip_filepath = os.path.join(get_temp_dir(), \"tmp_model.keras\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e467db9030119d07930470fe789132c79de21b99", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 42 | Lines Deleted: 11 | Files Changed: 1 | Hunks: 7 | Methods Changed: 6 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 53 | Churn Cumulative: 185 | Contributors (this commit): 5 | Commits (past 90d): 11 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3,10 +3,14 @@ import numpy as np\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n-from keras_core.utils import backend_utils\n+from keras_core.utils import backend_utils, image_utils\n from keras_core.utils.module_utils import tensorflow as tf\n \n \n+H_AXIS = -3\n+W_AXIS = -2\n+\n+\n @keras_core_export(\"keras_core.layers.RandomCrop\")\n class RandomCrop(Layer):\n     \"\"\"A preprocessing layer which randomly crops images during training.\n@@ -60,13 +64,9 @@ class RandomCrop(Layer):\n             )\n \n         super().__init__(name=name, **kwargs)\n+        self.height = height\n+        self.width = width\n         self.seed = seed or backend.random.make_default_seed()\n-        self.layer = tf.keras.layers.RandomCrop(\n-            height=height,\n-            width=width,\n-            seed=self.seed,\n-            name=name,\n-        )\n         self.supports_masking = False\n         self.supports_jit = False\n         self._convert_input_args = False\n@@ -75,7 +75,33 @@ class RandomCrop(Layer):\n     def call(self, inputs, training=True):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n-        outputs = self.layer.call(inputs, training=training)\n+\n+        input_shape = tf.shape(inputs)\n+        h_diff = input_shape[H_AXIS] - self.height\n+        w_diff = input_shape[W_AXIS] - self.width\n+\n+        def random_crop():\n+            dtype = input_shape.dtype\n+            rands = tf.random.uniform([2], 0, dtype.max, dtype)\n+            h_start = rands[0] % (h_diff + 1)\n+            w_start = rands[1] % (w_diff + 1)\n+            return tf.image.crop_to_bounding_box(\n+                inputs, h_start, w_start, self.height, self.width\n+            )\n+\n+        def resize():\n+            outputs = image_utils.smart_resize(\n+                inputs, [self.height, self.width]\n+            )\n+            # smart_resize will always output float32, so we need to re-cast.\n+            return tf.cast(outputs, self.compute_dtype)\n+\n+        outputs = tf.cond(\n+            tf.reduce_all((training, h_diff >= 0, w_diff >= 0)),\n+            random_crop,\n+            resize,\n+        )\n+\n         if (\n             backend.backend() != \"tensorflow\"\n             and not backend_utils.in_tf_graph()\n@@ -84,9 +110,14 @@ class RandomCrop(Layer):\n         return outputs\n \n     def compute_output_shape(self, input_shape):\n-        return tuple(self.layer.compute_output_shape(input_shape))\n+        input_shape = tf.TensorShape(input_shape).as_list()\n+        input_shape[H_AXIS] = self.height\n+        input_shape[W_AXIS] = self.width\n+        return tf.TensorShape(input_shape)\n \n     def get_config(self):\n-        config = self.layer.get_config()\n-        config.update({\"seed\": self.seed})\n+        config = super().get_config()\n+        config.update(\n+            {\"height\": self.height, \"width\": self.width, \"seed\": self.seed}\n+        )\n         return config\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#87dec5ea778d8cbfcfb38f1b1b45cbdabea74c7b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 55 | Lines Deleted: 42 | Files Changed: 3 | Hunks: 9 | Methods Changed: 10 | Complexity Δ (Sum/Max): 1/3 | Churn Δ: 97 | Churn Cumulative: 432 | Contributors (this commit): 7 | Commits (past 90d): 20 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,43 @@\n+import numpy as np\n+\n+from keras_core import backend\n+from keras_core import initializers\n+from keras_core import testing\n+\n+\n+class ConstantInitializersTest(testing.TestCase):\n+    def test_zeros_initializer(self):\n+        shape = (3, 3)\n+\n+        initializer = initializers.Zeros()\n+        values = initializer(shape=shape)\n+        self.assertEqual(values.shape, shape)\n+        np_values = backend.convert_to_numpy(values).data\n+        self.assertEqual(np_values, np.zeros(shape=shape))\n+\n+        self.run_class_serialization_test(initializer)\n+\n+    def test_ones_initializer(self):\n+        shape = (3, 3)\n+\n+        initializer = initializers.Ones()\n+        values = initializer(shape=shape)\n+        self.assertEqual(values.shape, shape)\n+        np_values = backend.convert_to_numpy(values).data\n+        self.assertEqual(np_values, np.ones(shape=shape))\n+\n+        self.run_class_serialization_test(initializer)\n+\n+    def test_constant_initializer(self):\n+        shape = (3, 3)\n+        constant_value = 6.0\n+\n+        initializer = initializers.Constant(value=constant_value)\n+        values = initializer(shape=shape)\n+        self.assertEqual(values.shape, shape)\n+        np_values = backend.convert_to_numpy(values).data\n+        self.assertEqual(\n+            np_values, np.full(shape=shape, fill_value=constant_value)\n+        )\n+\n+        self.run_class_serialization_test(initializer)\n\n@@ -30,6 +30,7 @@ class Constant(Initializer):\n         self.value = float(value)\n \n     def __call__(self, shape, dtype=None):\n+        dtype = standardize_dtype(dtype)\n         return self.value * ops.ones(shape=shape, dtype=dtype)\n \n     def get_config(self):\n\n@@ -3,14 +3,10 @@ import numpy as np\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n-from keras_core.utils import backend_utils, image_utils\n+from keras_core.utils import backend_utils\n from keras_core.utils.module_utils import tensorflow as tf\n \n \n-H_AXIS = -3\n-W_AXIS = -2\n-\n-\n @keras_core_export(\"keras_core.layers.RandomCrop\")\n class RandomCrop(Layer):\n     \"\"\"A preprocessing layer which randomly crops images during training.\n@@ -64,9 +60,13 @@ class RandomCrop(Layer):\n             )\n \n         super().__init__(name=name, **kwargs)\n-        self.height = height\n-        self.width = width\n         self.seed = seed or backend.random.make_default_seed()\n+        self.layer = tf.keras.layers.RandomCrop(\n+            height=height,\n+            width=width,\n+            seed=self.seed,\n+            name=name,\n+        )\n         self.supports_masking = False\n         self.supports_jit = False\n         self._convert_input_args = False\n@@ -75,33 +75,7 @@ class RandomCrop(Layer):\n     def call(self, inputs, training=True):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n-\n-        input_shape = tf.shape(inputs)\n-        h_diff = input_shape[H_AXIS] - self.height\n-        w_diff = input_shape[W_AXIS] - self.width\n-\n-        def random_crop():\n-            dtype = input_shape.dtype\n-            rands = tf.random.uniform([2], 0, dtype.max, dtype)\n-            h_start = rands[0] % (h_diff + 1)\n-            w_start = rands[1] % (w_diff + 1)\n-            return tf.image.crop_to_bounding_box(\n-                inputs, h_start, w_start, self.height, self.width\n-            )\n-\n-        def resize():\n-            outputs = image_utils.smart_resize(\n-                inputs, [self.height, self.width]\n-            )\n-            # smart_resize will always output float32, so we need to re-cast.\n-            return tf.cast(outputs, self.compute_dtype)\n-\n-        outputs = tf.cond(\n-            tf.reduce_all((training, h_diff >= 0, w_diff >= 0)),\n-            random_crop,\n-            resize,\n-        )\n-\n+        outputs = self.layer.call(inputs, training=training)\n         if (\n             backend.backend() != \"tensorflow\"\n             and not backend_utils.in_tf_graph()\n@@ -110,14 +84,9 @@ class RandomCrop(Layer):\n         return outputs\n \n     def compute_output_shape(self, input_shape):\n-        input_shape = tf.TensorShape(input_shape).as_list()\n-        input_shape[H_AXIS] = self.height\n-        input_shape[W_AXIS] = self.width\n-        return tf.TensorShape(input_shape)\n+        return tuple(self.layer.compute_output_shape(input_shape))\n \n     def get_config(self):\n-        config = super().get_config()\n-        config.update(\n-            {\"height\": self.height, \"width\": self.width, \"seed\": self.seed}\n-        )\n+        config = self.layer.get_config()\n+        config.update({\"seed\": self.seed})\n         return config\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d353e689b4258ac801361d319e9aa6f73c224897", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 53 | Lines Deleted: 55 | Files Changed: 3 | Hunks: 11 | Methods Changed: 12 | Complexity Δ (Sum/Max): 2/5 | Churn Δ: 108 | Churn Cumulative: 540 | Contributors (this commit): 7 | Commits (past 90d): 23 | Contributors (cumulative): 13 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,43 +0,0 @@\n-import numpy as np\n-\n-from keras_core import backend\n-from keras_core import initializers\n-from keras_core import testing\n-\n-\n-class ConstantInitializersTest(testing.TestCase):\n-    def test_zeros_initializer(self):\n-        shape = (3, 3)\n-\n-        initializer = initializers.Zeros()\n-        values = initializer(shape=shape)\n-        self.assertEqual(values.shape, shape)\n-        np_values = backend.convert_to_numpy(values).data\n-        self.assertEqual(np_values, np.zeros(shape=shape))\n-\n-        self.run_class_serialization_test(initializer)\n-\n-    def test_ones_initializer(self):\n-        shape = (3, 3)\n-\n-        initializer = initializers.Ones()\n-        values = initializer(shape=shape)\n-        self.assertEqual(values.shape, shape)\n-        np_values = backend.convert_to_numpy(values).data\n-        self.assertEqual(np_values, np.ones(shape=shape))\n-\n-        self.run_class_serialization_test(initializer)\n-\n-    def test_constant_initializer(self):\n-        shape = (3, 3)\n-        constant_value = 6.0\n-\n-        initializer = initializers.Constant(value=constant_value)\n-        values = initializer(shape=shape)\n-        self.assertEqual(values.shape, shape)\n-        np_values = backend.convert_to_numpy(values).data\n-        self.assertEqual(\n-            np_values, np.full(shape=shape, fill_value=constant_value)\n-        )\n-\n-        self.run_class_serialization_test(initializer)\n\n@@ -30,7 +30,6 @@ class Constant(Initializer):\n         self.value = float(value)\n \n     def __call__(self, shape, dtype=None):\n-        dtype = standardize_dtype(dtype)\n         return self.value * ops.ones(shape=shape, dtype=dtype)\n \n     def get_config(self):\n\n@@ -1,9 +1,11 @@\n import numpy as np\n \n+from keras_core import ops\n from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.utils import backend_utils\n+from keras_core.utils import image_utils\n from keras_core.utils.module_utils import tensorflow as tf\n \n \n@@ -52,7 +54,9 @@ class RandomCrop(Layer):\n             `name` and `dtype`.\n     \"\"\"\n \n-    def __init__(self, height, width, seed=None, name=None, **kwargs):\n+    def __init__(\n+        self, height, width, seed=None, data_format=None, name=None, **kwargs\n+    ):\n         if not tf.available:\n             raise ImportError(\n                 \"Layer RandomCrop requires TensorFlow. \"\n@@ -60,13 +64,20 @@ class RandomCrop(Layer):\n             )\n \n         super().__init__(name=name, **kwargs)\n+        self.height = height\n+        self.width = width\n         self.seed = seed or backend.random.make_default_seed()\n-        self.layer = tf.keras.layers.RandomCrop(\n-            height=height,\n-            width=width,\n-            seed=self.seed,\n-            name=name,\n+        self.data_format = (\n+            \"channels_last\" if data_format is None else \"channels_first\"\n         )\n+\n+        if self.data_format == \"channels_first\":\n+            self.heigh_axis = -2\n+            self.width_axis = -1\n+        elif self.data_format == \"channels_last\":\n+            self.height_axis = -3\n+            self.width_axis = -2\n+\n         self.supports_masking = False\n         self.supports_jit = False\n         self._convert_input_args = False\n@@ -75,7 +86,33 @@ class RandomCrop(Layer):\n     def call(self, inputs, training=True):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n-        outputs = self.layer.call(inputs, training=training)\n+\n+        input_shape = ops.shape(inputs)\n+        h_diff = input_shape[self.height_axis] - self.height\n+        w_diff = input_shape[self.width_axis] - self.width\n+\n+        def random_crop():\n+            dtype = input_shape.dtype\n+            rands = tf.random.uniform([2], 0, dtype.max, dtype)\n+            h_start = rands[0] % (h_diff + 1)\n+            w_start = rands[1] % (w_diff + 1)\n+            return tf.image.crop_to_bounding_box(\n+                inputs, h_start, w_start, self.height, self.width\n+            )\n+\n+        def resize():\n+            outputs = image_utils.smart_resize(\n+                inputs, [self.height, self.width]\n+            )\n+            # smart_resize will always output float32, so we need to re-cast.\n+            return ops.cast(outputs, self.compute_dtype)\n+\n+        outputs = ops.cond(\n+            tf.reduce_all((training, h_diff >= 0, w_diff >= 0)),\n+            random_crop,\n+            resize,\n+        )\n+\n         if (\n             backend.backend() != \"tensorflow\"\n             and not backend_utils.in_tf_graph()\n@@ -83,10 +120,15 @@ class RandomCrop(Layer):\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n-    def compute_output_shape(self, input_shape):\n-        return tuple(self.layer.compute_output_shape(input_shape))\n+    def compute_output_shape(self, input_shape, *args, **kwargs):\n+        input_shape = tf.TensorShape(input_shape).as_list()\n+        input_shape[self.height_axis] = self.height\n+        input_shape[self.width_axis] = self.width\n+        return tf.TensorShape(input_shape)\n \n     def get_config(self):\n-        config = self.layer.get_config()\n-        config.update({\"seed\": self.seed})\n+        config = super().get_config()\n+        config.update(\n+            {\"height\": self.height, \"width\": self.width, \"seed\": self.seed}\n+        )\n         return config\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
