{"custom_id": "keras#8b45efc5ee1e42b245e84a4de49ba2051bfdd3dd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 73 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -24,6 +24,14 @@ class RandomCrop(Layer):\n     of integer or floating point dtype. By default, the layer will output\n     floats.\n \n+    **Note:** This layer wraps `tf.keras.layers.RandomCrop`. It cannot\n+    be used as part of the compiled computation graph of a model with\n+    any backend other than TensorFlow.\n+    It can however be used with any backend when running eagerly.\n+    It can also always be used as part of an input preprocessing pipeline\n+    with any backend (outside the model itself), which is how we recommend\n+    to use this layer.\n+\n     Input shape:\n         3D (unbatched) or 4D (batched) tensor with shape:\n         `(..., height, width, channels)`, in `\"channels_last\"` format.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b27593e5b0691455bdda23eec78f4bd41c466a9e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1308 | Lines Deleted: 24 | Files Changed: 16 | Hunks: 39 | Methods Changed: 37 | Complexity Δ (Sum/Max): 42/19 | Churn Δ: 1332 | Churn Cumulative: 10742 | Contributors (this commit): 14 | Commits (past 90d): 154 | Contributors (cumulative): 49 | DMM Complexity: 0.8747993579454254\n\nDIFF:\n@@ -33,16 +33,17 @@ def _compute_conv_transpose_output_length(\n \n \n def compute_conv_transpose_output_shape(\n-    inputs,\n-    kernel,\n+    input_shape,\n+    kernel_size,\n+    filters,\n     strides,\n     padding,\n     output_padding=None,\n     data_format=\"channels_last\",\n     dilation_rate=1,\n ):\n-    num_spatial_dims = len(inputs.shape) - 2\n-    kernel_spatial_shape = kernel.shape[:-2]\n+    num_spatial_dims = len(input_shape) - 2\n+    kernel_spatial_shape = kernel_size\n \n     if isinstance(output_padding, int):\n         output_padding = (output_padding,) * len(kernel_spatial_shape)\n@@ -52,9 +53,9 @@ def compute_conv_transpose_output_shape(\n         dilation_rate = (dilation_rate,) * num_spatial_dims\n \n     if data_format == \"channels_last\":\n-        inputs_spatial_shape = inputs.shape[1:-1]\n+        input_spatial_shape = input_shape[1:-1]\n     else:\n-        inputs_spatial_shape = inputs.shape[2:]\n+        input_spatial_shape = input_shape[2:]\n \n     output_shape = []\n     for i in range(num_spatial_dims):\n@@ -63,7 +64,7 @@ def compute_conv_transpose_output_shape(\n         )\n         output_shape.append(\n             _compute_conv_transpose_output_length(\n-                inputs_spatial_shape[i],\n+                input_spatial_shape[i],\n                 kernel_spatial_shape[i],\n                 padding=padding,\n                 output_padding=current_output_padding,\n@@ -73,7 +74,7 @@ def compute_conv_transpose_output_shape(\n         )\n \n     if data_format == \"channels_last\":\n-        output_shape = [inputs.shape[0]] + output_shape + [kernel.shape[-2]]\n+        output_shape = [input_shape[0]] + output_shape + [filters]\n     else:\n-        output_shape = [inputs.shape[0], kernel.shape[-1]] + output_shape\n+        output_shape = [input_shape[0], filters] + output_shape\n     return output_shape\n\n@@ -1,10 +1,12 @@\n \"\"\"Tests for tf.distribute related functionality under tf implementation.\"\"\"\n \n+import numpy as np\n import pytest\n import tensorflow as tf\n from tensorflow.python.eager import context\n \n from keras_core import backend\n+from keras_core.backend.tensorflow import trainer as tf_trainer\n from keras_core import layers\n from keras_core import models\n from keras_core import testing\n@@ -79,3 +81,41 @@ class DistributeTest(testing.TestCase):\n         self.assertEqual(result.values[1].shape, [8, 2])\n         self.assertNotAllClose(result.values[0], result.values[1])\n         self.assertAllClose(result.values[0], tf.zeros([8, 2]))\n+\n+    def test_epoch_iterator(self):\n+        x = np.random.random((100, 16))\n+        y = np.random.random((100, 4))\n+        sample_weight = np.random.random((100,))\n+        batch_size = 16\n+        shuffle = True\n+\n+        strategy = tf.distribute.MirroredStrategy(['CPU:0', 'CPU:1'])\n+\n+        epoch_iterator = tf_trainer.TFEpochIterator(\n+            x=x,\n+            y=y,\n+            sample_weight=sample_weight,\n+            batch_size=batch_size,\n+            shuffle=shuffle,\n+            distribute_strategy=strategy\n+        )\n+        steps_seen = []\n+        for step, data_iterator in epoch_iterator.enumerate_epoch():\n+            steps_seen.append(step)\n+            batch = next(data_iterator)\n+            self.assertEqual(len(batch), 3)\n+            x, y, sample_weight = batch\n+            self.assertTrue(\n+                isinstance(x,\n+                           tf.types.experimental.distributed.PerReplica))\n+            # Make sure the local batch size is 8\n+            if step < 6:\n+                self.assertEqual(x.values[0].shape, [8, 16])\n+                self.assertEqual(y.values[0].shape, [8, 4])\n+                self.assertEqual(sample_weight.values[0].shape, [8])\n+            else:\n+                # Last partial batch\n+                self.assertEqual(x.values[0].shape, [2, 16])\n+                self.assertEqual(y.values[0].shape, [2, 4])\n+                self.assertEqual(sample_weight.values[0].shape, [2])\n+        self.assertEqual(steps_seen, [0, 1, 2, 3, 4, 5, 6])\n\n@@ -360,9 +360,12 @@ def conv_transpose(\n     dilation_rate=1,\n ):\n     tf_data_format = _convert_data_format(data_format, len(inputs.shape))\n+    kernel_size = kernel.shape[:-2]\n+    filters = kernel.shape[-2]\n     output_shape = compute_conv_transpose_output_shape(\n-        inputs,\n-        kernel,\n+        inputs.shape,\n+        kernel_size,\n+        filters,\n         strides,\n         padding,\n         output_padding,\n\n@@ -243,6 +243,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             steps_per_epoch=steps_per_epoch,\n             shuffle=shuffle,\n             class_weight=class_weight,\n+            distribute_strategy=self.distribute_strategy,\n         )\n \n         # Container that configures and calls callbacks.\n@@ -285,6 +286,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n                         y=val_y,\n                         sample_weight=val_sample_weight,\n                         batch_size=validation_batch_size or batch_size,\n+                        distribute_strategy=self.distribute_strategy,\n                     )\n                 val_logs = self.evaluate(\n                     x=val_x,\n@@ -346,6 +348,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n                 batch_size=batch_size,\n                 steps_per_epoch=steps,\n                 shuffle=False,\n+                distribute_strategy=self.distribute_strategy,\n             )\n \n         # Container that configures and calls callbacks.\n@@ -385,6 +388,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             batch_size=batch_size,\n             steps_per_epoch=steps,\n             shuffle=False,\n+            distribute_strategy=self.distribute_strategy,\n         )\n \n         # Container that configures and calls callbacks.\n@@ -428,20 +432,23 @@ class TensorFlowTrainer(base_trainer.Trainer):\n \n \n class TFEpochIterator(EpochIterator):\n-    def __init__(self, *args, **kwargs):\n+    def __init__(self, distribute_strategy=None, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n+        self._distribute_strategy = distribute_strategy\n         self._steps_seen = 0\n \n     def enumerate_epoch(self):\n         if self.steps_per_epoch:\n             if not self._current_iterator:\n                 self._current_iterator = iter(\n-                    self.data_adapter.get_tf_dataset()\n-                )\n+                    self._distribute_strategy.experimental_distribute_dataset(\n+                        self.data_adapter.get_tf_dataset()))\n             for step in range(self.steps_per_epoch):\n                 yield step, self._current_iterator\n         else:\n-            iterator = iter(self.data_adapter.get_tf_dataset())\n+            iterator = iter(\n+                self._distribute_strategy.experimental_distribute_dataset(\n+                    self.data_adapter.get_tf_dataset()))\n             if self.num_batches:\n                 for step in range(self.num_batches):\n                     yield step, iterator\n\n@@ -34,7 +34,7 @@ class ReduceLROnPlateauTest(testing.TestCase):\n \n     def test_reduces_lr_with_model_fit(self):\n         reduce_lr = callbacks.ReduceLROnPlateau(\n-            patience=1, factor=0.1, monitor=\"val_loss\", min_delta=10\n+            patience=1, factor=0.1, monitor=\"val_loss\", min_delta=100\n         )\n \n         self.model.fit(\n@@ -49,7 +49,7 @@ class ReduceLROnPlateauTest(testing.TestCase):\n \n     def test_throws_when_optimizer_has_schedule(self):\n         reduce_lr = callbacks.ReduceLROnPlateau(\n-            patience=1, factor=0.1, monitor=\"val_loss\", min_delta=10\n+            patience=1, factor=0.1, monitor=\"val_loss\", min_delta=100\n         )\n \n         self.model.compile(\n@@ -75,7 +75,7 @@ class ReduceLROnPlateauTest(testing.TestCase):\n \n     def test_verbose_logging(self):\n         reduce_lr = callbacks.ReduceLROnPlateau(\n-            patience=1, factor=0.1, monitor=\"val_loss\", min_delta=10, verbose=1\n+            patience=1, factor=0.1, monitor=\"val_loss\", min_delta=100, verbose=1\n         )\n         io_utils.disable_interactive_logging()\n \n@@ -111,7 +111,11 @@ class ReduceLROnPlateauTest(testing.TestCase):\n \n     def test_cooldown(self):\n         reduce_lr = callbacks.ReduceLROnPlateau(\n-            patience=1, factor=0.1, monitor=\"val_loss\", min_delta=10, cooldown=2\n+            patience=1,\n+            factor=0.1,\n+            monitor=\"val_loss\",\n+            min_delta=100,\n+            cooldown=2,\n         )\n \n         self.model.fit(\n\n@@ -1,8 +1,11 @@\n from keras_core.layers.activations.activation import Activation\n from keras_core.layers.attention.attention import Attention\n from keras_core.layers.convolutional.conv1d import Conv1D\n+from keras_core.layers.convolutional.conv1d_transpose import Conv1DTranspose\n from keras_core.layers.convolutional.conv2d import Conv2D\n+from keras_core.layers.convolutional.conv2d_transpose import Conv2DTranspose\n from keras_core.layers.convolutional.conv3d import Conv3D\n+from keras_core.layers.convolutional.conv3d_transpose import Conv3DTranspose\n from keras_core.layers.core.dense import Dense\n from keras_core.layers.core.einsum_dense import EinsumDense\n from keras_core.layers.core.embedding import Embedding\n@@ -78,6 +81,7 @@ from keras_core.layers.regularization.gaussian_noise import GaussianNoise\n from keras_core.layers.regularization.spatial_dropout import SpatialDropout1D\n from keras_core.layers.regularization.spatial_dropout import SpatialDropout2D\n from keras_core.layers.regularization.spatial_dropout import SpatialDropout3D\n+from keras_core.layers.reshaping.cropping1d import Cropping1D\n from keras_core.layers.reshaping.flatten import Flatten\n from keras_core.layers.reshaping.permute import Permute\n from keras_core.layers.reshaping.repeat_vector import RepeatVector\n\n@@ -0,0 +1,255 @@\n+\"\"\"Keras base class for transpose convolution layers.\"\"\"\n+\n+from keras_core import activations\n+from keras_core import constraints\n+from keras_core import initializers\n+from keras_core import operations as ops\n+from keras_core import regularizers\n+from keras_core.backend import standardize_data_format\n+from keras_core.backend.common.backend_utils import (\n+    compute_conv_transpose_output_shape,\n+)\n+from keras_core.layers.input_spec import InputSpec\n+from keras_core.layers.layer import Layer\n+\n+\n+class BaseConvTranspose(Layer):\n+    \"\"\"Abstract N-D transpose convolution layer.\n+\n+    The need for transposed convolutions generally arises\n+    from the desire to use a transformation going in the opposite direction\n+    of a normal convolution, i.e., from something that has the shape of the\n+    output of some convolution to something that has the shape of its input\n+    while maintaining a connectivity pattern that is compatible with\n+    said convolution.\n+\n+    Args:\n+        rank: int, the rank of the transposed convolution, e.g. 2 for 2D\n+            transposed convolution.\n+        filters: int, the dimension of the output space (the number of filters\n+            in the transposed convolution).\n+        kernel_size: int or tuple/list of N integers (N=`rank`), specifying the\n+            size of the transposed convolution window.\n+        strides: int or tuple/list of N integers, specifying the stride length\n+            of the transposed convolution. If only one int is specified, the\n+            same stride size will be used for all dimensions.\n+            `stride value != 1` is incompatible with `dilation_rate != 1`.\n+        padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n+            `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n+            the left/right or up/down of the input such that output has the same\n+            height/width dimension as the input.\n+        data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n+            The ordering of the dimensions in the inputs. `\"channels_last\"`\n+            corresponds to inputs with shape `(batch, steps, features)`\n+            while `\"channels_first\"` corresponds to inputs with shape\n+            `(batch, features, steps)`. It defaults to the `image_data_format`\n+            value found in your Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be `\"channels_last\"`.\n+        dilation_rate: int or tuple/list of N integers, specifying the dilation\n+            rate to use for dilated convolution. If only one int is specified,\n+            the same dilation rate will be used for all dimensions.\n+        activation: Activation function. If `None`, no activation is applied.\n+        use_bias: bool, if `True`, bias will be added to the output.\n+        kernel_initializer: Initializer for the convolution kernel. If `None`,\n+            the default initializer (`\"glorot_uniform\"`) will be used.\n+        bias_initializer: Initializer for the bias vector. If `None`, the\n+            default initializer (`\"zeros\"`) will be used.\n+        kernel_regularizer: Optional regularizer for the convolution kernel.\n+        bias_regularizer: Optional regularizer for the bias vector.\n+        activity_regularizer: Optional regularizer function for the output.\n+        kernel_constraint: Optional projection function to be applied to the\n+            kernel after being updated by an `Optimizer` (e.g. used to implement\n+            norm constraints or value constraints for layer weights). The\n+            function must take as input the unprojected variable and must return\n+            the projected variable (which must have the same shape). Constraints\n+            are not safe to use when doing asynchronous distributed training.\n+        bias_constraint: Optional projection function to be applied to the\n+            bias after being updated by an `Optimizer`.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        rank,\n+        filters,\n+        kernel_size,\n+        strides=1,\n+        padding=\"valid\",\n+        data_format=None,\n+        dilation_rate=1,\n+        activation=None,\n+        use_bias=True,\n+        kernel_initializer=\"glorot_uniform\",\n+        bias_initializer=\"zeros\",\n+        kernel_regularizer=None,\n+        bias_regularizer=None,\n+        activity_regularizer=None,\n+        kernel_constraint=None,\n+        bias_constraint=None,\n+        trainable=True,\n+        name=None,\n+        **kwargs,\n+    ):\n+        super().__init__(\n+            trainable=trainable,\n+            name=name,\n+            activity_regularizer=activity_regularizer,\n+            **kwargs,\n+        )\n+        self.rank = rank\n+        self.filters = filters\n+\n+        if isinstance(kernel_size, int):\n+            kernel_size = (kernel_size,) * self.rank\n+        self.kernel_size = kernel_size\n+\n+        if isinstance(strides, int):\n+            strides = (strides,) * self.rank\n+        self.strides = strides\n+\n+        if isinstance(dilation_rate, int):\n+            dilation_rate = (dilation_rate,) * self.rank\n+        self.dilation_rate = dilation_rate\n+\n+        self.padding = padding\n+        self.data_format = standardize_data_format(data_format)\n+        self.activation = activations.get(activation)\n+        self.use_bias = use_bias\n+        self.kernel_initializer = initializers.get(kernel_initializer)\n+        self.bias_initializer = initializers.get(bias_initializer)\n+        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n+        self.bias_regularizer = regularizers.get(bias_regularizer)\n+        self.kernel_constraint = constraints.get(kernel_constraint)\n+        self.bias_constraint = constraints.get(bias_constraint)\n+        self.input_spec = InputSpec(min_ndim=self.rank + 2)\n+        self.data_format = self.data_format\n+\n+        if self.filters is not None and self.filters <= 0:\n+            raise ValueError(\n+                \"Invalid value for argument `filters`. Expected a strictly \"\n+                f\"positive value. Received filters={self.filters}.\"\n+            )\n+\n+        if not all(self.kernel_size):\n+            raise ValueError(\n+                \"The argument `kernel_size` cannot contain 0. Received: \"\n+                f\"{self.kernel_size}\"\n+            )\n+\n+        if not all(self.strides):\n+            raise ValueError(\n+                \"The argument `strides` cannot contains 0. Received: \"\n+                f\"{self.strides}\"\n+            )\n+\n+        if max(self.strides) > 1 and max(self.dilation_rate) > 1:\n+            raise ValueError(\n+                \"`strides > 1` not supported in conjunction with \"\n+                f\"`dilation_rate > 1`. Received: strides={self.strides} and \"\n+                f\"dilation_rate={self.dilation_rate}\"\n+            )\n+\n+    def build(self, input_shape):\n+        if self.data_format == \"channels_last\":\n+            channel_axis = -1\n+            input_channel = input_shape[-1]\n+        else:\n+            channel_axis = 1\n+            input_channel = input_shape[1]\n+        self.input_spec = InputSpec(\n+            min_ndim=self.rank + 2, axes={channel_axis: input_channel}\n+        )\n+        kernel_shape = self.kernel_size + (\n+            self.filters,\n+            input_channel,\n+        )\n+\n+        self.kernel = self.add_weight(\n+            name=\"kernel\",\n+            shape=kernel_shape,\n+            initializer=self.kernel_initializer,\n+            regularizer=self.kernel_regularizer,\n+            constraint=self.kernel_constraint,\n+            trainable=True,\n+            dtype=self.dtype,\n+        )\n+        if self.use_bias:\n+            self.bias = self.add_weight(\n+                name=\"bias\",\n+                shape=(self.filters,),\n+                initializer=self.bias_initializer,\n+                regularizer=self.bias_regularizer,\n+                constraint=self.bias_constraint,\n+                trainable=True,\n+                dtype=self.dtype,\n+            )\n+        else:\n+            self.bias = None\n+        self.built = True\n+\n+    def call(self, inputs):\n+        outputs = ops.conv_transpose(\n+            inputs,\n+            self.kernel,\n+            strides=list(self.strides),\n+            padding=self.padding,\n+            dilation_rate=self.dilation_rate,\n+            data_format=self.data_format,\n+        )\n+\n+        if self.use_bias:\n+            if self.data_format == \"channels_last\":\n+                bias_shape = (1,) * (self.rank + 1) + (self.filters,)\n+            else:\n+                bias_shape = (1, self.filters) + (1,) * self.rank\n+            bias = ops.reshape(self.bias, bias_shape)\n+            outputs += bias\n+\n+        if self.activation is not None:\n+            return self.activation(outputs)\n+        return outputs\n+\n+    def compute_output_shape(self, input_shape):\n+        return compute_conv_transpose_output_shape(\n+            input_shape,\n+            self.kernel_size,\n+            self.filters,\n+            strides=self.strides,\n+            padding=self.padding,\n+            data_format=self.data_format,\n+            dilation_rate=self.dilation_rate,\n+        )\n+\n+    def get_config(self):\n+        config = super().get_config()\n+        config.update(\n+            {\n+                \"filters\": self.filters,\n+                \"kernel_size\": self.kernel_size,\n+                \"strides\": self.strides,\n+                \"padding\": self.padding,\n+                \"data_format\": self.data_format,\n+                \"dilation_rate\": self.dilation_rate,\n+                \"activation\": activations.serialize(self.activation),\n+                \"use_bias\": self.use_bias,\n+                \"kernel_initializer\": initializers.serialize(\n+                    self.kernel_initializer\n+                ),\n+                \"bias_initializer\": initializers.serialize(\n+                    self.bias_initializer\n+                ),\n+                \"kernel_regularizer\": regularizers.serialize(\n+                    self.kernel_regularizer\n+                ),\n+                \"bias_regularizer\": regularizers.serialize(\n+                    self.bias_regularizer\n+                ),\n+                \"activity_regularizer\": regularizers.serialize(\n+                    self.activity_regularizer\n+                ),\n+                \"kernel_constraint\": constraints.serialize(\n+                    self.kernel_constraint\n+                ),\n+                \"bias_constraint\": constraints.serialize(self.bias_constraint),\n+            }\n+        )\n+        return config\n\n@@ -80,8 +80,7 @@ class Conv1D(BaseConv):\n \n     >>> # The inputs are 128-length vectors with 10 timesteps, and the\n     >>> # batch size is 4.\n-    >>> input_shape = (4, 10, 128)\n-    >>> x = np.random.normal(4, 10, 128)\n+    >>> x = np.random.rand(4, 10, 128)\n     >>> y = keras_core.layers.Conv1D(32, 3, activation='relu')(x)\n     >>> print(y.shape)\n     (4, 8, 32)\n\n@@ -0,0 +1,136 @@\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.convolutional.base_conv_transpose import (\n+    BaseConvTranspose,\n+)\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.layers.Conv1DTranspose\",\n+        \"keras_core.layers.Convolution1DTranspose\",\n+    ]\n+)\n+class Conv1DTranspose(BaseConvTranspose):\n+    \"\"\"1D transposed convolution layer.\n+\n+    The need for transposed convolutions generally arise from the desire to use\n+    a transformation going in the opposite direction of a normal convolution,\n+    i.e., from something that has the shape of the output of some convolution\n+    to something that has the shape of its input while maintaining a\n+    connectivity pattern that is compatible with said convolution.\n+\n+    Args:\n+        filters: int, the dimension of the output space (the number of filters\n+            in the transpose convolution).\n+        kernel_size: int or tuple/list of 1 integer, specifying the size of the\n+            transposed convolution window.\n+        strides: int or tuple/list of 1 integer, specifying the stride length\n+            of the transposed convolution. `stride value != 1` is incompatible\n+            with `dilation_rate != 1`.\n+        padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n+            `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n+            the left/right or up/down of the input such that output has the same\n+            height/width dimension as the input.\n+        data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n+            The ordering of the dimensions in the inputs. `\"channels_last\"`\n+            corresponds to inputs with shape `(batch, steps, features)`\n+            while `\"channels_first\"` corresponds to inputs with shape\n+            `(batch, features, steps)`. It defaults to the `image_data_format`\n+            value found in your Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be `\"channels_last\"`.\n+        dilation_rate: int or tuple/list of 1 integers, specifying the dilation\n+            rate to use for dilated transposed convolution.\n+        groups: A positive int specifying the number of groups in which the\n+            input is split along the channel axis. Each group is convolved\n+            separately with `filters // groups` filters. The output is the\n+            concatenation of all the `groups` results along the channel axis.\n+            Input channels and `filters` must both be divisible by `groups`.\n+        activation: Activation function. If `None`, no activation is applied.\n+        use_bias: bool, if `True`, bias will be added to the output.\n+        kernel_initializer: Initializer for the convolution kernel. If `None`,\n+            the default initializer (`\"glorot_uniform\"`) will be used.\n+        bias_initializer: Initializer for the bias vector. If `None`, the\n+            default initializer (`\"zeros\"`) will be used.\n+        kernel_regularizer: Optional regularizer for the convolution kernel.\n+        bias_regularizer: Optional regularizer for the bias vector.\n+        activity_regularizer: Optional regularizer function for the output.\n+        kernel_constraint: Optional projection function to be applied to the\n+            kernel after being updated by an `Optimizer` (e.g. used to implement\n+            norm constraints or value constraints for layer weights). The\n+            function must take as input the unprojected variable and must return\n+            the projected variable (which must have the same shape). Constraints\n+            are not safe to use when doing asynchronous distributed training.\n+        bias_constraint: Optional projection function to be applied to the\n+            bias after being updated by an `Optimizer`.\n+\n+    Input shape:\n+    - If `data_format=\"channels_last\"`:\n+        A 3D tensor with shape: `(batch_shape, steps, channels)`\n+    - If `data_format=\"channels_first\"`:\n+        A 3D tensor with shape: `(batch_shape, channels, steps)`\n+\n+    Output shape:\n+    - If `data_format=\"channels_last\"`:\n+        A 3D tensor with shape: `(batch_shape, new_steps, channels)`\n+    - If `data_format=\"channels_first\"`:\n+        A 3D tensor with shape: `(batch_shape, channels, new_steps)`\n+\n+    Returns:\n+        A 3D tensor representing\n+        `activation(conv1d_transpose(inputs, kernel) + bias)`.\n+\n+    Raises:\n+        ValueError: when both `strides > 1` and `dilation_rate > 1`.\n+\n+    References:\n+    - [A guide to convolution arithmetic for deep learning](\n+        https://arxiv.org/abs/1603.07285v1)\n+    - [Deconvolutional Networks](\n+        https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n+\n+    Examples:\n+\n+    >>> x = np.random.rand(4, 10, 128)\n+    >>> y = keras_core.layers.Conv1DTranspose(32, 3, 2, activation='relu')(x)\n+    >>> print(y.shape)\n+    (4, 21, 32)\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        filters,\n+        kernel_size,\n+        strides=1,\n+        padding=\"valid\",\n+        data_format=\"channels_last\",\n+        dilation_rate=1,\n+        activation=None,\n+        use_bias=True,\n+        kernel_initializer=\"glorot_uniform\",\n+        bias_initializer=\"zeros\",\n+        kernel_regularizer=None,\n+        bias_regularizer=None,\n+        activity_regularizer=None,\n+        kernel_constraint=None,\n+        bias_constraint=None,\n+        **kwargs\n+    ):\n+        super().__init__(\n+            rank=1,\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+            activation=activation,\n+            use_bias=use_bias,\n+            kernel_initializer=kernel_initializer,\n+            bias_initializer=bias_initializer,\n+            kernel_regularizer=kernel_regularizer,\n+            bias_regularizer=bias_regularizer,\n+            activity_regularizer=activity_regularizer,\n+            kernel_constraint=kernel_constraint,\n+            bias_constraint=bias_constraint,\n+            **kwargs\n+        )\n\n@@ -80,7 +80,7 @@ class Conv2D(BaseConv):\n \n     Examples:\n \n-    >>> x = np.random.normal(4, 10, 10, 128)\n+    >>> x = np.random.rand(4, 10, 10, 128)\n     >>> y = keras_core.layers.Conv2D(32, 3, activation='relu')(x)\n     >>> print(y.shape)\n     (4, 8, 8, 32)\n\n@@ -0,0 +1,133 @@\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.convolutional.base_conv_transpose import (\n+    BaseConvTranspose,\n+)\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.layers.Conv2DTranspose\",\n+        \"keras_core.layers.Convolution2DTranspose\",\n+    ]\n+)\n+class Conv2DTranspose(BaseConvTranspose):\n+    \"\"\"2D transposed convolution layer.\n+\n+    The need for transposed convolutions generally arise from the desire to use\n+    a transformation going in the opposite direction of a normal convolution,\n+    i.e., from something that has the shape of the output of some convolution\n+    to something that has the shape of its input while maintaining a\n+    connectivity pattern that is compatible with said convolution.\n+\n+    Args:\n+        filters: int, the dimension of the output space (the number of filters\n+            in the transposed convolution).\n+        kernel_size: int or tuple/list of 1 integer, specifying the size of the\n+            transposed convolution window.\n+        strides: int or tuple/list of 1 integer, specifying the stride length\n+            of the transposed convolution. `stride value != 1` is incompatible\n+            with `dilation_rate != 1`.\n+        padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n+            `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n+            the left/right or up/down of the input such that output has the same\n+            height/width dimension as the input.\n+        data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n+            The ordering of the dimensions in the inputs. `\"channels_last\"`\n+            corresponds to inputs with shape\n+            `(batch_size, channels, height, width)`\n+            while `\"channels_first\"` corresponds to inputs with shape\n+            `(batch_size, channels, height, width)`. It defaults to the\n+            `image_data_format` value found in your Keras config file at\n+            `~/.keras/keras.json`. If you never set it, then it will be\n+            `\"channels_last\"`.\n+        dilation_rate: int or tuple/list of 1 integers, specifying the dilation\n+            rate to use for dilated transposed convolution.\n+        activation: Activation function. If `None`, no activation is applied.\n+        use_bias: bool, if `True`, bias will be added to the output.\n+        kernel_initializer: Initializer for the convolution kernel. If `None`,\n+            the default initializer (`\"glorot_uniform\"`) will be used.\n+        bias_initializer: Initializer for the bias vector. If `None`, the\n+            default initializer (`\"zeros\"`) will be used.\n+        kernel_regularizer: Optional regularizer for the convolution kernel.\n+        bias_regularizer: Optional regularizer for the bias vector.\n+        activity_regularizer: Optional regularizer function for the output.\n+        kernel_constraint: Optional projection function to be applied to the\n+            kernel after being updated by an `Optimizer` (e.g. used to implement\n+            norm constraints or value constraints for layer weights). The\n+            function must take as input the unprojected variable and must return\n+            the projected variable (which must have the same shape). Constraints\n+            are not safe to use when doing asynchronous distributed training.\n+        bias_constraint: Optional projection function to be applied to the\n+            bias after being updated by an `Optimizer`.\n+\n+    Input shape:\n+    - If `data_format=\"channels_last\"`:\n+        A 4D tensor with shape: `(batch_size, height, width, channels)`\n+    - If `data_format=\"channels_first\"`:\n+        A 4D tensor with shape: `(batch_size, channels, height, width)`\n+\n+    Output shape:\n+    - If `data_format=\"channels_last\"`:\n+        A 4D tensor with shape: `(batch_size, new_height, new_width filters)`\n+    - If `data_format=\"channels_first\"`:\n+        A 4D tensor with shape: `(batch_size, filters, new_height, new_width)`\n+\n+    Returns:\n+        A 4D tensor representing\n+        `activation(conv2d_transpose(inputs, kernel) + bias)`.\n+\n+    Raises:\n+        ValueError: when both `strides > 1` and `dilation_rate > 1`.\n+\n+    References:\n+    - [A guide to convolution arithmetic for deep learning](\n+        https://arxiv.org/abs/1603.07285v1)\n+    - [Deconvolutional Networks](\n+        https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n+\n+    Examples:\n+\n+    >>> x = np.random.rand(4, 10, 8, 128)\n+    >>> y = keras_core.layers.Conv2DTranspose(32, 2, 2, activation='relu')(x)\n+    >>> print(y.shape)\n+    (4, 20, 16, 32)\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        filters,\n+        kernel_size,\n+        strides=1,\n+        padding=\"valid\",\n+        data_format=\"channels_last\",\n+        dilation_rate=1,\n+        activation=None,\n+        use_bias=True,\n+        kernel_initializer=\"glorot_uniform\",\n+        bias_initializer=\"zeros\",\n+        kernel_regularizer=None,\n+        bias_regularizer=None,\n+        activity_regularizer=None,\n+        kernel_constraint=None,\n+        bias_constraint=None,\n+        **kwargs\n+    ):\n+        super().__init__(\n+            rank=2,\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+            activation=activation,\n+            use_bias=use_bias,\n+            kernel_initializer=kernel_initializer,\n+            bias_initializer=bias_initializer,\n+            kernel_regularizer=kernel_regularizer,\n+            bias_regularizer=bias_regularizer,\n+            activity_regularizer=activity_regularizer,\n+            kernel_constraint=kernel_constraint,\n+            bias_constraint=bias_constraint,\n+            **kwargs\n+        )\n\n@@ -0,0 +1,138 @@\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.convolutional.base_conv_transpose import (\n+    BaseConvTranspose,\n+)\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.layers.Conv3DTranspose\",\n+        \"keras_core.layers.Convolution3DTranspose\",\n+    ]\n+)\n+class Conv3DTranspose(BaseConvTranspose):\n+    \"\"\"3D transposed convolution layer.\n+\n+    The need for transposed convolutions generally arise from the desire to use\n+    a transformation going in the opposite direction of a normal convolution,\n+    i.e., from something that has the shape of the output of some convolution\n+    to something that has the shape of its input while maintaining a\n+    connectivity pattern that is compatible with said convolution.\n+\n+    Args:\n+        filters: int, the dimension of the output space (the number of filters\n+            in the transposed convolution).\n+        kernel_size: int or tuple/list of 1 integer, specifying the size of the\n+            transposed convolution window.\n+        strides: int or tuple/list of 1 integer, specifying the stride length\n+            of the transposed convolution. `stride value != 1` is incompatible\n+            with `dilation_rate != 1`.\n+        padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n+            `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n+            the left/right or up/down of the input such that output has the same\n+            height/width dimension as the input.\n+        data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n+            The ordering of the dimensions in the inputs. `\"channels_last\"`\n+            corresponds to inputs with shape\n+            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n+            while `\"channels_first\"` corresponds to inputs with shape\n+            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`.\n+            It defaults to the `image_data_format` value found in your Keras\n+            config file at `~/.keras/keras.json`. If you never set it, then it\n+            will be `\"channels_last\"`.\n+        dilation_rate: int or tuple/list of 1 integers, specifying the dilation\n+            rate to use for dilated transposed convolution.\n+        activation: Activation function. If `None`, no activation is applied.\n+        use_bias: bool, if `True`, bias will be added to the output.\n+        kernel_initializer: Initializer for the convolution kernel. If `None`,\n+            the default initializer (`\"glorot_uniform\"`) will be used.\n+        bias_initializer: Initializer for the bias vector. If `None`, the\n+            default initializer (`\"zeros\"`) will be used.\n+        kernel_regularizer: Optional regularizer for the convolution kernel.\n+        bias_regularizer: Optional regularizer for the bias vector.\n+        activity_regularizer: Optional regularizer function for the output.\n+        kernel_constraint: Optional projection function to be applied to the\n+            kernel after being updated by an `Optimizer` (e.g. used to implement\n+            norm constraints or value constraints for layer weights). The\n+            function must take as input the unprojected variable and must return\n+            the projected variable (which must have the same shape). Constraints\n+            are not safe to use when doing asynchronous distributed training.\n+        bias_constraint: Optional projection function to be applied to the\n+            bias after being updated by an `Optimizer`.\n+\n+    Input shape:\n+    - If `data_format=\"channels_last\"`:\n+        5D tensor with shape:\n+        `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n+    - If `data_format=\"channels_first\"`:\n+        5D tensor with shape:\n+        `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n+\n+    Output shape:\n+    - If `data_format=\"channels_last\"`:\n+        5D tensor with shape:\n+        `(batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3,\n+        channels)`\n+    - If `data_format=\"channels_first\"`:\n+        5D tensor with shape:\n+        `(batch_size, channels, new_spatial_dim1, new_spatial_dim2,\n+        new_spatial_dim3)`\n+\n+    Returns:\n+        A 5D tensor representing `activation(conv3d(inputs, kernel) + bias)`.\n+\n+    Raises:\n+        ValueError: when both `strides > 1` and `dilation_rate > 1`.\n+\n+    References:\n+    - [A guide to convolution arithmetic for deep learning](\n+        https://arxiv.org/abs/1603.07285v1)\n+    - [Deconvolutional Networks](\n+        https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n+\n+    Examples:\n+\n+    >>> x = np.random.rand(4, 10, 8, 12, 128)\n+    >>> y = keras_core.layers.Conv3DTranspose(32, 2, 2, activation='relu')(x)\n+    >>> print(y.shape)\n+    (4, 20, 16, 24, 32)\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        filters,\n+        kernel_size,\n+        strides=1,\n+        padding=\"valid\",\n+        data_format=\"channels_last\",\n+        dilation_rate=1,\n+        activation=None,\n+        use_bias=True,\n+        kernel_initializer=\"glorot_uniform\",\n+        bias_initializer=\"zeros\",\n+        kernel_regularizer=None,\n+        bias_regularizer=None,\n+        activity_regularizer=None,\n+        kernel_constraint=None,\n+        bias_constraint=None,\n+        **kwargs\n+    ):\n+        super().__init__(\n+            rank=3,\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+            activation=activation,\n+            use_bias=use_bias,\n+            kernel_initializer=kernel_initializer,\n+            bias_initializer=bias_initializer,\n+            kernel_regularizer=kernel_regularizer,\n+            bias_regularizer=bias_regularizer,\n+            activity_regularizer=activity_regularizer,\n+            kernel_constraint=kernel_constraint,\n+            bias_constraint=bias_constraint,\n+            **kwargs\n+        )\n\n@@ -0,0 +1,420 @@\n+import numpy as np\n+import tensorflow as tf\n+from absl.testing import parameterized\n+\n+from keras_core import layers\n+from keras_core import testing\n+\n+\n+class ConvTransposeBasicTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.parameters(\n+        {\n+            \"filters\": 5,\n+            \"kernel_size\": 2,\n+            \"strides\": 2,\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+            \"input_shape\": (2, 8, 4),\n+            \"output_shape\": (2, 16, 5),\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": 3,\n+            \"padding\": \"same\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1,),\n+            \"input_shape\": (2, 8, 4),\n+            \"output_shape\": (2, 24, 6),\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": (2,),\n+            \"strides\": (2,),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+            \"input_shape\": (2, 8, 4),\n+            \"output_shape\": (2, 16, 6),\n+        },\n+    )\n+    def test_conv1d_transpose_basic(\n+        self,\n+        filters,\n+        kernel_size,\n+        strides,\n+        padding,\n+        data_format,\n+        dilation_rate,\n+        input_shape,\n+        output_shape,\n+    ):\n+        self.run_layer_test(\n+            layers.Conv1DTranspose,\n+            init_kwargs={\n+                \"filters\": filters,\n+                \"kernel_size\": kernel_size,\n+                \"strides\": strides,\n+                \"padding\": padding,\n+                \"data_format\": data_format,\n+                \"dilation_rate\": dilation_rate,\n+            },\n+            input_shape=input_shape,\n+            expected_output_shape=output_shape,\n+            expected_num_trainable_weights=2,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+        )\n+\n+    @parameterized.parameters(\n+        {\n+            \"filters\": 5,\n+            \"kernel_size\": 2,\n+            \"strides\": 2,\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+            \"input_shape\": (2, 8, 8, 4),\n+            \"output_shape\": (2, 16, 16, 5),\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": 3,\n+            \"padding\": \"same\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1, 1),\n+            \"input_shape\": (2, 8, 8, 4),\n+            \"output_shape\": (2, 24, 24, 6),\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": (2, 3),\n+            \"strides\": (2, 1),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1, 1),\n+            \"input_shape\": (2, 8, 8, 4),\n+            \"output_shape\": (2, 16, 10, 6),\n+        },\n+    )\n+    def test_conv2d_transpose_basic(\n+        self,\n+        filters,\n+        kernel_size,\n+        strides,\n+        padding,\n+        data_format,\n+        dilation_rate,\n+        input_shape,\n+        output_shape,\n+    ):\n+        self.run_layer_test(\n+            layers.Conv2DTranspose,\n+            init_kwargs={\n+                \"filters\": filters,\n+                \"kernel_size\": kernel_size,\n+                \"strides\": strides,\n+                \"padding\": padding,\n+                \"data_format\": data_format,\n+                \"dilation_rate\": dilation_rate,\n+            },\n+            input_shape=input_shape,\n+            expected_output_shape=output_shape,\n+            expected_num_trainable_weights=2,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+        )\n+\n+    @parameterized.parameters(\n+        {\n+            \"filters\": 5,\n+            \"kernel_size\": 2,\n+            \"strides\": 2,\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+            \"input_shape\": (2, 8, 8, 8, 4),\n+            \"output_shape\": (2, 16, 16, 16, 5),\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": 3,\n+            \"padding\": \"same\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1, 1, 1),\n+            \"input_shape\": (2, 8, 8, 8, 4),\n+            \"output_shape\": (2, 24, 24, 24, 6),\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": (2, 2, 3),\n+            \"strides\": (2, 1, 2),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1, 1, 1),\n+            \"input_shape\": (2, 8, 8, 8, 4),\n+            \"output_shape\": (2, 16, 9, 17, 6),\n+        },\n+    )\n+    def test_conv3d_transpose_basic(\n+        self,\n+        filters,\n+        kernel_size,\n+        strides,\n+        padding,\n+        data_format,\n+        dilation_rate,\n+        input_shape,\n+        output_shape,\n+    ):\n+        self.run_layer_test(\n+            layers.Conv3DTranspose,\n+            init_kwargs={\n+                \"filters\": filters,\n+                \"kernel_size\": kernel_size,\n+                \"strides\": strides,\n+                \"padding\": padding,\n+                \"data_format\": data_format,\n+                \"dilation_rate\": dilation_rate,\n+            },\n+            input_shape=input_shape,\n+            expected_output_shape=output_shape,\n+            expected_num_trainable_weights=2,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+        )\n+\n+    def test_bad_init_args(self):\n+        # `filters` is not positive.\n+        with self.assertRaises(ValueError):\n+            layers.Conv1DTranspose(filters=0, kernel_size=1)\n+\n+        # `kernel_size` has 0.\n+        with self.assertRaises(ValueError):\n+            layers.Conv2DTranspose(filters=2, kernel_size=(1, 0))\n+\n+        # `strides` has 0.\n+        with self.assertRaises(ValueError):\n+            layers.Conv2DTranspose(\n+                filters=2, kernel_size=(2, 2), strides=(1, 0)\n+            )\n+\n+        # `dilation_rate > 1` while `strides > 1`.\n+        with self.assertRaises(ValueError):\n+            layers.Conv2DTranspose(\n+                filters=2, kernel_size=(2, 2), strides=2, dilation_rate=(2, 1)\n+            )\n+\n+\n+class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.parameters(\n+        {\n+            \"filters\": 5,\n+            \"kernel_size\": 2,\n+            \"strides\": 2,\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": 3,\n+            \"padding\": \"same\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1,),\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": (2,),\n+            \"strides\": (2,),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+        },\n+    )\n+    def test_conv1d_transpose(\n+        self,\n+        filters,\n+        kernel_size,\n+        strides,\n+        padding,\n+        data_format,\n+        dilation_rate,\n+    ):\n+        layer = layers.Conv1DTranspose(\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+        )\n+        tf_keras_layer = tf.keras.layers.Conv1DTranspose(\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+        )\n+\n+        inputs = np.random.normal(size=[2, 8, 4])\n+        layer.build(input_shape=inputs.shape)\n+        tf_keras_layer.build(input_shape=inputs.shape)\n+\n+        kernel_shape = layer.kernel.shape\n+        kernel_weights = np.random.normal(size=kernel_shape)\n+        bias_weights = np.random.normal(size=(filters,))\n+        layer.kernel.assign(kernel_weights)\n+        tf_keras_layer.kernel.assign(kernel_weights)\n+\n+        layer.bias.assign(bias_weights)\n+        tf_keras_layer.bias.assign(bias_weights)\n+\n+        outputs = layer(inputs)\n+        expected = tf_keras_layer(inputs)\n+        self.assertAllClose(outputs, expected)\n+\n+    @parameterized.parameters(\n+        {\n+            \"filters\": 5,\n+            \"kernel_size\": 2,\n+            \"strides\": 2,\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": 3,\n+            \"padding\": \"same\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1, 1),\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": (2, 3),\n+            \"strides\": (2, 1),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1, 1),\n+        },\n+    )\n+    def test_conv2d_transpose(\n+        self,\n+        filters,\n+        kernel_size,\n+        strides,\n+        padding,\n+        data_format,\n+        dilation_rate,\n+    ):\n+        layer = layers.Conv2DTranspose(\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+        )\n+        tf_keras_layer = tf.keras.layers.Conv2DTranspose(\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+        )\n+\n+        inputs = np.random.normal(size=[2, 8, 8, 4])\n+        layer.build(input_shape=inputs.shape)\n+        tf_keras_layer.build(input_shape=inputs.shape)\n+\n+        kernel_shape = layer.kernel.shape\n+        kernel_weights = np.random.normal(size=kernel_shape)\n+        bias_weights = np.random.normal(size=(filters,))\n+        layer.kernel.assign(kernel_weights)\n+        tf_keras_layer.kernel.assign(kernel_weights)\n+\n+        layer.bias.assign(bias_weights)\n+        tf_keras_layer.bias.assign(bias_weights)\n+\n+        outputs = layer(inputs)\n+        expected = tf_keras_layer(inputs)\n+        self.assertAllClose(outputs, expected)\n+\n+    @parameterized.parameters(\n+        {\n+            \"filters\": 5,\n+            \"kernel_size\": 2,\n+            \"strides\": 2,\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": 3,\n+            \"padding\": \"same\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1, 1, 1),\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": (2, 2, 3),\n+            \"strides\": (2, 1, 2),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1, 1, 1),\n+        },\n+    )\n+    def test_conv3d_transpose(\n+        self,\n+        filters,\n+        kernel_size,\n+        strides,\n+        padding,\n+        data_format,\n+        dilation_rate,\n+    ):\n+        layer = layers.Conv3DTranspose(\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+        )\n+        tf_keras_layer = tf.keras.layers.Conv3DTranspose(\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+        )\n+\n+        inputs = np.random.normal(size=[2, 8, 8, 8, 4])\n+        layer.build(input_shape=inputs.shape)\n+        tf_keras_layer.build(input_shape=inputs.shape)\n+\n+        kernel_shape = layer.kernel.shape\n+        kernel_weights = np.random.normal(size=kernel_shape)\n+        bias_weights = np.random.normal(size=(filters,))\n+        layer.kernel.assign(kernel_weights)\n+        tf_keras_layer.kernel.assign(kernel_weights)\n+\n+        layer.bias.assign(bias_weights)\n+        tf_keras_layer.bias.assign(bias_weights)\n+        outputs = layer(inputs)\n+        expected = tf_keras_layer(inputs)\n+        self.assertAllClose(outputs, expected)\n\n@@ -0,0 +1,79 @@\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.input_spec import InputSpec\n+from keras_core.layers.layer import Layer\n+\n+\n+@keras_core_export(\"keras_core.layers.Cropping1D\")\n+class Cropping1D(Layer):\n+    \"\"\"Cropping layer for 1D input (e.g. temporal sequence).\n+\n+    It crops along the time dimension (axis 1).\n+\n+    Examples:\n+\n+    >>> input_shape = (2, 3, 2)\n+    >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n+    >>> print(x)\n+    [[[ 0  1]\n+      [ 2  3]\n+      [ 4  5]]\n+     [[ 6  7]\n+      [ 8  9]\n+      [10 11]]]\n+    >>> y = keras_core.layers.Cropping1D(cropping=1)(x)\n+    >>> print(y)\n+    [[[2 3]]\n+     [[8 9]]]\n+\n+    Args:\n+        cropping: Integer or tuple of integers of length 2.\n+            How many units should be trimmed off at the beginning and end of\n+            the cropping dimension (axis 1).\n+            If a single int is provided, the same value will be used for both.\n+\n+    Input shape:\n+        3D tensor with shape `(batch_size, axis_to_crop, features)`\n+\n+    Output shape:\n+        3D tensor with shape `(batch_size, cropped_axis, features)`\n+    \"\"\"\n+\n+    def __init__(self, cropping=(1, 1), name=None, dtype=None):\n+        super().__init__(name=name, dtype=dtype)\n+        if isinstance(cropping, int):\n+            cropping = (cropping, cropping)\n+        self.cropping = cropping\n+        self.input_spec = InputSpec(ndim=3)\n+\n+    def compute_output_shape(self, input_shape):\n+        if input_shape[1] is not None:\n+            length = input_shape[1] - self.cropping[0] - self.cropping[1]\n+            if length <= 0:\n+                raise ValueError(\n+                    \"`cropping` parameter of `Cropping1D` layer must be \"\n+                    \"greater than the input length. Received: input_shape=\"\n+                    f\"{input_shape}, cropping={self.cropping}\"\n+                )\n+        else:\n+            length = None\n+        return (input_shape[0], length, input_shape[2])\n+\n+    def call(self, inputs):\n+        if (\n+            inputs.shape[1] is not None\n+            and sum(self.cropping) >= inputs.shape[1]\n+        ):\n+            raise ValueError(\n+                \"`cropping` parameter of `Cropping1D` layer must be \"\n+                \"greater than the input length. Received: inputs.shape=\"\n+                f\"{inputs.shape}, cropping={self.cropping}\"\n+            )\n+        if self.cropping[1] == 0:\n+            return inputs[:, self.cropping[0] :, :]\n+        else:\n+            return inputs[:, self.cropping[0] : -self.cropping[1], :]\n+\n+    def get_config(self):\n+        config = {\"cropping\": self.cropping}\n+        base_config = super().get_config()\n+        return {**base_config, **config}\n\n@@ -0,0 +1,62 @@\n+import numpy as np\n+import pytest\n+\n+from keras_core import backend\n+from keras_core import layers\n+from keras_core import operations as ops\n+from keras_core import testing\n+\n+\n+class CroppingTest(testing.TestCase):\n+    def test_cropping_1d(self):\n+        inputs = np.random.rand(3, 5, 7)\n+\n+        # Cropping with different values on the left and the right.\n+        self.run_layer_test(\n+            layers.Cropping1D,\n+            init_kwargs={\"cropping\": (1, 2)},\n+            input_data=inputs,\n+            expected_output=ops.convert_to_tensor(inputs[:, 1:3, :]),\n+        )\n+        # Same cropping on the left and the right.\n+        self.run_layer_test(\n+            layers.Cropping1D,\n+            init_kwargs={\"cropping\": (1, 1)},\n+            input_data=inputs,\n+            expected_output=ops.convert_to_tensor(inputs[:, 1:4, :]),\n+        )\n+        # Same cropping on the left and the right provided as an int.\n+        self.run_layer_test(\n+            layers.Cropping1D,\n+            init_kwargs={\"cropping\": 1},\n+            input_data=inputs,\n+            expected_output=ops.convert_to_tensor(inputs[:, 1:4, :]),\n+        )\n+        # Cropping on the right only.\n+        self.run_layer_test(\n+            layers.Cropping1D,\n+            init_kwargs={\"cropping\": (0, 1)},\n+            input_data=inputs,\n+            expected_output=ops.convert_to_tensor(inputs[:, 0:4, :]),\n+        )\n+        # Cropping on the left only.\n+        self.run_layer_test(\n+            layers.Cropping1D,\n+            init_kwargs={\"cropping\": (1, 0)},\n+            input_data=inputs,\n+            expected_output=ops.convert_to_tensor(inputs[:, 1:5, :]),\n+        )\n+\n+    @pytest.mark.skipif(\n+        not backend.DYNAMIC_SHAPES_OK,\n+        reason=\"Backend does not support dynamic shapes\",\n+    )\n+    def test_cropping_1d_with_dynamic_batch_size(self):\n+        input_layer = layers.Input(batch_shape=(None, 5, 7))\n+        permuted = layers.Cropping1D((1, 2))(input_layer)\n+        self.assertEqual(permuted.shape, (None, 2, 7))\n+\n+    def test_cropping_1d_errors_if_cropping_more_than_available(self):\n+        with self.assertRaises(ValueError):\n+            input_layer = layers.Input(shape=(3, 4, 7))\n+            layers.Cropping1D(cropping=(2, 3))(input_layer)\n\n@@ -831,9 +831,12 @@ class ConvTranspose(Operation):\n         )\n \n     def compute_output_spec(self, inputs, kernel):\n+        kernel_size = kernel.shape[:-2]\n+        filters = kernel.shape[-2]\n         output_shape = compute_conv_transpose_output_shape(\n-            inputs,\n-            kernel,\n+            inputs.shape,\n+            kernel_size,\n+            filters,\n             self.strides,\n             self.padding,\n             self.output_padding,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
