{"custom_id": "keras#8bf5b1418b49d460fffff487b9f0584a893fc633", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 68 | Lines Deleted: 68 | Files Changed: 51 | Hunks: 65 | Methods Changed: 64 | Complexity Δ (Sum/Max): 0/1 | Churn Δ: 136 | Churn Cumulative: 3882 | Contributors (this commit): 34 | Commits (past 90d): 85 | Contributors (cumulative): 193 | DMM Complexity: 0.17391304347826086\n\nDIFF:\n@@ -215,7 +215,7 @@ class SavedModelTest(testing.TestCase):\n         @object_registration.register_keras_serializable(package=\"my_package\")\n         class CustomLayer(layers.Layer):\n             def build(self, *input_shape):\n-                self.built = True\n+                pass\n \n             def call(self, *input_list):\n                 self.add_loss(input_list[-2] * 2)\n@@ -226,7 +226,6 @@ class SavedModelTest(testing.TestCase):\n             def build(self, *input_shape):\n                 self.layer = CustomLayer()\n                 self.layer.build(*input_shape)\n-                self.built = True\n \n             @tf.function\n             def call(self, *inputs):\n\n@@ -116,7 +116,8 @@ class TFSMLayer(layers.Layer):\n             self._add_existing_weight(v)\n         for v in ntvs:\n             self._add_existing_weight(v)\n-        self.built = True\n+\n+        self._build_at_init()\n \n     def _add_existing_weight(self, weight):\n         \"\"\"Tracks an existing weight.\"\"\"\n\n@@ -26,7 +26,8 @@ class Activation(Layer):\n         super().__init__(**kwargs)\n         self.supports_masking = True\n         self.activation = activations.get(activation)\n-        self.built = True\n+\n+        self._build_at_init()\n \n     def call(self, inputs):\n         return self.activation(inputs)\n\n@@ -23,7 +23,8 @@ class ELU(Layer):\n         super().__init__(**kwargs)\n         self.alpha = alpha\n         self.supports_masking = True\n-        self.built = True\n+\n+        self._build_at_init()\n \n     def call(self, inputs):\n         return activations.elu(inputs, alpha=self.alpha)\n\n@@ -50,7 +50,8 @@ class LeakyReLU(Layer):\n             )\n         self.negative_slope = negative_slope\n         self.supports_masking = True\n-        self.built = True\n+\n+        self._build_at_init()\n \n     def call(self, inputs):\n         return activations.leaky_relu(\n\n@@ -70,7 +70,6 @@ class PReLU(Layer):\n                 if i not in self.shared_axes:\n                     axes[i] = input_shape[i]\n         self.input_spec = InputSpec(ndim=len(input_shape), axes=axes)\n-        self.built = True\n \n     def call(self, inputs):\n         pos = activations.relu(inputs)\n\n@@ -61,7 +61,8 @@ class ReLU(Layer):\n         self.negative_slope = negative_slope\n         self.threshold = threshold\n         self.supports_masking = True\n-        self.built = True\n+\n+        self._build_at_init()\n \n     def call(self, inputs):\n         return activations.relu(\n\n@@ -47,7 +47,8 @@ class Softmax(Layer):\n         super().__init__(**kwargs)\n         self.axis = axis\n         self.supports_masking = True\n-        self.built = True\n+\n+        self._build_at_init()\n \n     def call(self, inputs, mask=None):\n         if mask is not None:\n\n@@ -77,7 +77,6 @@ class AdditiveAttention(Attention):\n                 dtype=self.dtype,\n                 trainable=True,\n             )\n-        self.built = True\n \n     def _calculate_scores(self, query, key):\n         \"\"\"Calculates attention scores as a nonlinear sum of query and key.\n\n@@ -107,7 +107,6 @@ class Attention(Layer):\n                 dtype=self.dtype,\n                 trainable=True,\n             )\n-        self.built = True\n \n     def _calculate_scores(self, query, key):\n         \"\"\"Calculates attention scores as a query-key dot product.\n\n@@ -198,7 +198,6 @@ class GroupedQueryAttention(Layer):\n         self._output_dense.build(\n             (None, None, self.num_query_heads, self.head_dim)\n         )\n-        self.built = True\n \n     def _get_common_kwargs_for_sublayer(self):\n         common_kwargs = dict(\n\n@@ -299,7 +299,6 @@ class MultiHeadAttention(Layer):\n         )\n         output_dense_input_shape[-1] = self._value_dim\n         self._output_dense.build(tuple(output_dense_input_shape))\n-        self.built = True\n \n     @property\n     def query_dense(self):\n\n@@ -186,7 +186,6 @@ class BaseConvTranspose(Layer):\n             )\n         else:\n             self.bias = None\n-        self.built = True\n \n     def call(self, inputs):\n         outputs = ops.conv_transpose(\n\n@@ -190,7 +190,6 @@ class BaseDepthwiseConv(Layer):\n             )\n         else:\n             self.bias = None\n-        self.built = True\n \n     def _get_input_channel(self, input_shape):\n         if self.data_format == \"channels_last\":\n\n@@ -213,7 +213,6 @@ class BaseSeparableConv(Layer):\n             )\n         else:\n             self.bias = None\n-        self.built = True\n \n     def call(self, inputs):\n         outputs = ops.separable_conv(\n\n@@ -15,7 +15,8 @@ class Identity(Layer):\n     def __init__(self, **kwargs):\n         super().__init__(**kwargs)\n         self.supports_masking = True\n-        self.built = True\n+\n+        self._build_at_init()\n \n     def call(self, inputs):\n         return inputs\n\n@@ -51,7 +51,8 @@ class Masking(Layer):\n             mask_value = deserialize_keras_object(mask_value)\n         self.mask_value = mask_value\n         self.supports_masking = True\n-        self.built = True\n+\n+        self._build_at_init()\n \n     def compute_mask(self, inputs, mask=None):\n         return ops.any(ops.not_equal(inputs, self.mask_value), axis=-1)\n\n@@ -31,7 +31,6 @@ class Wrapper(Layer):\n         if not self.layer.built:\n             self.layer.build(input_shape)\n             self.layer.built = True\n-        self.built = True\n \n     def get_config(self):\n         config = {\"layer\": serialization_lib.serialize_keras_object(self.layer)}\n\n@@ -372,6 +372,18 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n             # Reset attribute tracking (TF-specific)\n             self._self_setattr_tracking = _self_setattr_tracking\n \n+    def _build_at_init(self):\n+        \"\"\"Build the layer at `Layer.__init__`.\n+\n+        We can only safely mark the layer as `built=True` in `Layer.__init__` if\n+        `build` is not overridden. Otherwise, it might cause the subclasses to\n+        ignore the user's `build`.\n+        \"\"\"\n+        if utils.is_default(self.build):\n+            self.built = True\n+            self._post_build()\n+            self._lock_state()\n+\n     @property\n     def path(self):\n         \"\"\"The path of the layer.\n@@ -455,7 +467,6 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n                 self.build(config[\"input_shape\"])\n             elif \"shapes_dict\" in config:\n                 self.build(**config[\"shapes_dict\"])\n-            self.built = True\n \n     def _obj_type(self):\n         return \"Layer\"\n@@ -920,7 +931,6 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n                             outputs, layout\n                         )\n \n-                if not self.built:\n                 self.built = True\n                 # Record activity regularizer loss.\n                 if self.activity_regularizer is not None:\n\n@@ -645,7 +645,7 @@ class LayerTest(testing.TestCase):\n                     trainable=True,\n                     dtype=\"float32\",\n                 )\n-                self.built = True\n+                self._build_at_init()\n \n             def call(self, x):\n                 # Should not autocast.\n@@ -661,7 +661,7 @@ class LayerTest(testing.TestCase):\n                     initializer=\"ones\",\n                     trainable=True,\n                 )\n-                self.built = True\n+                self._build_at_init()\n \n             def call(self, x):\n                 # Should not autocast.\n@@ -679,7 +679,7 @@ class LayerTest(testing.TestCase):\n                     trainable=True,\n                     autocast=False,\n                 )\n-                self.built = True\n+                self._build_at_init()\n \n             def call(self, x):\n                 # Should not autocast `self.v`.\n@@ -698,7 +698,7 @@ class LayerTest(testing.TestCase):\n                 self.inner_one = InnerLayerOne()\n                 self.inner_two = InnerLayerTwo()\n                 self.inner_three = InnerLayerThree()\n-                self.built = True\n+                self._build_at_init()\n \n             def call(self, x):\n                 # Should autocast.\n@@ -862,7 +862,7 @@ class LayerTest(testing.TestCase):\n                     trainable=True,\n                     regularizer=\"l1\",\n                 )\n-                self.built = True\n+                self._build_at_init()\n \n             def call(self, x):\n                 x = backend.convert_to_tensor(x, dtype=\"float32\")\n@@ -1007,7 +1007,6 @@ class LayerTest(testing.TestCase):\n             def build(self, bar_shape, foo_shape):\n                 self.foo_shape = foo_shape\n                 self.bar_shape = bar_shape\n-                self.built = True\n \n             def call(self, foo, bar):\n                 return foo[:, 0] + bar[:, 0]\n@@ -1016,7 +1015,6 @@ class LayerTest(testing.TestCase):\n             def build(self, baz_shape, foo_shape):\n                 self.foo_shape = foo_shape\n                 self.baz_shape = baz_shape\n-                self.built = True\n \n             def call(self, foo, bar=None, baz=None):\n                 return foo[:, 0] + bar[:, 0] + baz[:, 0]\n@@ -1024,7 +1022,6 @@ class LayerTest(testing.TestCase):\n         class SingleArgument(layers.Layer):\n             def build(self, anything_whatsoever):\n                 self.foo_shape = anything_whatsoever\n-                self.built = True\n \n             def call(self, foo, bar):\n                 return foo[:, 0] + bar[:, 0]\n\n@@ -139,7 +139,6 @@ class Merge(Layer):\n             self._reshape_required = False\n         else:\n             self._reshape_required = True\n-        self.built = True\n \n     def call(self, inputs):\n         if not isinstance(inputs, (list, tuple)):\n\n@@ -97,7 +97,6 @@ class Concatenate(Merge):\n                 )\n                 if len(unique_dims) > 1:\n                     raise ValueError(err_msg)\n-        self.built = True\n \n     def _merge_function(self, inputs):\n         return ops.concatenate(inputs, axis=self.axis)\n\n@@ -288,7 +288,6 @@ class Dot(Merge):\n                 f\"{shape2[axes[1]]} (at axis {axes[1]}). \"\n                 f\"Full input shapes: {shape1}, {shape2}\"\n             )\n-        self.built = True\n \n     def _merge_function(self, inputs):\n         if len(inputs) != 2:\n\n@@ -215,7 +215,6 @@ class BatchNormalization(Layer):\n         reduction_axes = list(range(len(input_shape)))\n         del reduction_axes[self.axis]\n         self._reduction_axes = reduction_axes\n-        self.built = True\n \n     def compute_output_shape(self, input_shape):\n         if isinstance(self.axis, int):\n\n@@ -179,8 +179,6 @@ class LayerNormalization(Layer):\n         else:\n             self.beta = None\n \n-        self.built = True\n-\n     def call(self, inputs):\n         # Compute the axes along which to reduce the mean / variance\n         input_shape = inputs.shape\n\n@@ -37,7 +37,8 @@ class UnitNormalization(Layer):\n                 f\"Received: axis={axis}\"\n             )\n         self.supports_masking = True\n-        self.built = True\n+\n+        self._build_at_init()\n \n     def call(self, inputs):\n         return ops.normalize(inputs, axis=self.axis, order=2, epsilon=1e-12)\n\n@@ -14,7 +14,8 @@ class BaseGlobalPooling(Layer):\n         self.data_format = backend.standardize_data_format(data_format)\n         self.keepdims = keepdims\n         self.input_spec = InputSpec(ndim=pool_dimensions + 2)\n-        self.built = True\n+\n+        self._build_at_init()\n \n     def call(self, inputs):\n         raise NotImplementedError\n\n@@ -34,7 +34,8 @@ class BasePooling(Layer):\n         self.data_format = backend.standardize_data_format(data_format)\n \n         self.input_spec = InputSpec(ndim=pool_dimensions + 2)\n-        self.built = True\n+\n+        self._build_at_init()\n \n     def call(self, inputs):\n         if self.pool_mode == \"max\":\n\n@@ -151,9 +151,6 @@ class Discretization(TFDataLayer):\n         else:\n             self.summary = np.array([[], []], dtype=\"float32\")\n \n-    def build(self, input_shape=None):\n-        self.built = True\n-\n     @property\n     def input_dtype(self):\n         return backend.floatx()\n\n@@ -530,14 +530,11 @@ class IndexLookup(Layer):\n             )\n             self.idf_weights_const = self.idf_weights.value()\n \n-    def build(self):\n-        self.built = True\n-\n     def get_build_config(self):\n         return {}\n \n     def build_from_config(self, config):\n-        self.build()\n+        self.build(None)\n \n     @property\n     def compute_dtype(self):\n\n@@ -194,7 +194,6 @@ class Normalization(TFDataLayer):\n             variance = ops.broadcast_to(variance, self._broadcast_shape)\n             self.mean = ops.cast(mean, dtype=self.compute_dtype)\n             self.variance = ops.cast(variance, dtype=self.compute_dtype)\n-            self.built = True\n \n     def adapt(self, data):\n         \"\"\"Computes the mean and variance of values in a dataset.\n\n@@ -229,7 +229,6 @@ class STFTSpectrogram(layers.Layer):\n                     \"imag\", self.window, self.scaling, self.periodic\n                 ),\n             )\n-        self.built = True\n \n     def _adjust_shapes(self, outputs):\n         _, channels, freq_channels, time_seq = ops.shape(outputs)\n\n@@ -27,7 +27,8 @@ class ActivityRegularization(Layer):\n         self.supports_masking = True\n         self.l1 = l1\n         self.l2 = l2\n-        self.built = True\n+\n+        self._build_at_init()\n \n     def call(self, inputs):\n         return inputs\n\n@@ -46,7 +46,8 @@ class AlphaDropout(Layer):\n         if rate > 0:\n             self.seed_generator = backend.random.SeedGenerator(seed)\n         self.supports_masking = True\n-        self.built = True\n+\n+        self._build_at_init()\n \n     def call(self, inputs, training=False):\n         if training and self.rate > 0:\n\n@@ -52,7 +52,8 @@ class Dropout(Layer):\n         if rate > 0:\n             self.seed_generator = backend.random.SeedGenerator(seed)\n         self.supports_masking = True\n-        self.built = True\n+\n+        self._build_at_init()\n \n     def call(self, inputs, training=False):\n         if training and self.rate > 0:\n\n@@ -37,7 +37,8 @@ class GaussianDropout(layers.Layer):\n         if rate > 0:\n             self.seed_generator = backend.random.SeedGenerator(seed)\n         self.supports_masking = True\n-        self.built = True\n+\n+        self._build_at_init()\n \n     def call(self, inputs, training=False):\n         if training and self.rate > 0:\n\n@@ -38,7 +38,8 @@ class GaussianNoise(layers.Layer):\n         if stddev > 0:\n             self.seed_generator = backend.random.SeedGenerator(seed)\n         self.supports_masking = True\n-        self.built = True\n+\n+        self._build_at_init()\n \n     def call(self, inputs, training=False):\n         if training and self.stddev > 0:\n\n@@ -60,7 +60,6 @@ class Reshape(Layer):\n         self._resolved_target_shape = tuple(\n             -1 if d is None else d for d in sample_output_shape\n         )\n-        self.built = True\n \n     def call(self, inputs):\n         return ops.reshape(\n\n@@ -275,7 +275,6 @@ class Bidirectional(Layer):\n             self.forward_layer.build(sequences_shape)\n         if not self.backward_layer.built:\n             self.backward_layer.build(sequences_shape)\n-        self.built = True\n \n     def compute_mask(self, _, mask):\n         if isinstance(mask, list):\n\n@@ -228,7 +228,6 @@ class ConvLSTMCell(Layer, DropoutRNNCell):\n             )\n         else:\n             self.bias = None\n-        self.built = True\n \n     def call(self, inputs, states, training=False):\n         h_tm1 = states[0]  # previous memory state\n\n@@ -30,7 +30,6 @@ class RNNCellWithDropout(layers.Layer, DropoutRNNCell):\n             initializer=\"ones\",\n             name=\"recurrent_kernel\",\n         )\n-        self.built = True\n \n     def call(self, inputs, states, training=False):\n         if training:\n\n@@ -178,7 +178,6 @@ class GRUCell(Layer, DropoutRNNCell):\n             )\n         else:\n             self.bias = None\n-        self.built = True\n \n     def call(self, inputs, states, training=False):\n         h_tm1 = (\n\n@@ -191,7 +191,6 @@ class LSTMCell(Layer, DropoutRNNCell):\n             )\n         else:\n             self.bias = None\n-        self.built = True\n \n     def _compute_carry_and_output(self, x, h_tm1, c_tm1):\n         \"\"\"Computes carry and output using split kernels.\"\"\"\n\n@@ -148,7 +148,6 @@ class RNN(Layer):\n                 shape=(self.units, self.units),\n                 initializer='uniform',\n                 name='recurrent_kernel')\n-            self.built = True\n \n         def call(self, inputs, states):\n             prev_output = states[0]\n@@ -284,7 +283,6 @@ class RNN(Layer):\n                         f\"batch size: sequence.shape={sequences_shape}\"\n                     )\n                 self._create_state_variables(sequences_shape[0])\n-        self.built = True\n \n     @tracking.no_automatic_dependency_tracking\n     def _create_state_variables(self, batch_size):\n\n@@ -23,7 +23,6 @@ class OneStateRNNCell(layers.Layer):\n             initializer=\"ones\",\n             name=\"recurrent_kernel\",\n         )\n-        self.built = True\n \n     def call(self, inputs, states):\n         prev_output = states[0]\n@@ -55,7 +54,6 @@ class TwoStatesRNNCell(layers.Layer):\n             initializer=\"ones\",\n             name=\"recurrent_kernel_2\",\n         )\n-        self.built = True\n \n     def call(self, inputs, states):\n         prev_1 = states[0]\n\n@@ -150,7 +150,6 @@ class SimpleRNNCell(Layer, DropoutRNNCell):\n             )\n         else:\n             self.bias = None\n-        self.built = True\n \n     def call(self, sequence, states, training=False):\n         prev_output = states[0] if isinstance(states, (list, tuple)) else states\n\n@@ -117,7 +117,6 @@ class StackedRNNCells(Layer):\n                 output_dim = cell.state_size\n             batch_size = tree.flatten(input_shape)[0]\n             input_shape = (batch_size, output_dim)\n-        self.built = True\n \n     def get_config(self):\n         cells = []\n\n@@ -69,7 +69,6 @@ class TimeDistributed(Wrapper):\n     def build(self, input_shape):\n         child_input_shape = self._get_child_input_shape(input_shape)\n         super().build(child_input_shape)\n-        self.built = True\n \n     def call(self, inputs, training=None, mask=None):\n         input_shape = ops.shape(inputs)\n\n@@ -214,7 +214,6 @@ class Sequential(Model):\n                 raise e\n         outputs = x\n         self._functional = Functional(inputs=inputs, outputs=outputs)\n-        self.built = True\n \n     def call(self, inputs, training=None, mask=None):\n         if self._functional:\n\n@@ -565,6 +565,22 @@ class TestCase(parameterized.TestCase, unittest.TestCase):\n                     ),\n                 )\n \n+                # Ensure that the subclass layer doesn't mark itself as built\n+                # when `build` is overriden.\n+\n+                class ModifiedBuildLayer(layer_cls):\n+                    def build(self, *args, **kwargs):\n+                        pass\n+\n+                layer = ModifiedBuildLayer(**init_kwargs)\n+                self.assertFalse(\n+                    layer.built,\n+                    msg=(\n+                        f\"The `build` of {type(layer)} is overriden, so it \"\n+                        \"should not be built after instantiation.\"\n+                    ),\n+                )\n+\n         # Eager call test and compiled training test.\n         if input_data is not None or input_shape is not None:\n             if input_data is None:\n\n@@ -237,7 +237,7 @@ class JaxLayer(Layer):\n         self.tracked_params = self._create_variables(params, trainable=True)\n         self.tracked_state = self._create_variables(state, trainable=False)\n         if self.params is not None or self.state is not None:\n-            self.built = True\n+            self._build_at_init()\n \n         self.call_fn_arguments = self._validate_signature(\n             call_fn,\n@@ -397,7 +397,6 @@ class JaxLayer(Layer):\n             init_params, trainable=True\n         )\n         self.tracked_state = self._create_variables(init_state, trainable=False)\n-        self.built = True\n \n     def call(self, inputs, training=False):\n         def unwrap_variable(variable):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d42143ddf3a754d9b8dd04b150f132597855e9e7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 174 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 10/10 | Churn Δ: 177 | Churn Cumulative: 4533 | Contributors (this commit): 10 | Commits (past 90d): 18 | Contributors (cumulative): 22 | DMM Complexity: 0.3333333333333333\n\nDIFF:\n@@ -828,20 +828,26 @@ def elastic_transform(\n         channel_axis = 1\n \n     seed = draw_seed(seed)\n-    dx = tf.random.stateless_normal(\n+    dx = (\n+        tf.random.stateless_normal(\n             shape=(batch_size, height, width),\n             mean=0.0,\n             stddev=1.0,\n             dtype=input_dtype,\n             seed=seed,\n         )\n-    dy = tf.random.stateless_normal(\n+        * sigma\n+    )\n+    dy = (\n+        tf.random.stateless_normal(\n             shape=(batch_size, height, width),\n             mean=0.0,\n             stddev=1.0,\n             dtype=input_dtype,\n             seed=seed,\n         )\n+        * sigma\n+    )\n \n     dx = gaussian_blur(\n         tf.expand_dims(dx, axis=channel_axis),\n\n@@ -989,7 +989,7 @@ def elastic_transform(\n     x, y = torch.meshgrid(\n         torch.arange(width), torch.arange(height), indexing=\"xy\"\n     )\n-    x, y = x.unsqueeze(0), y.unsqueeze(0)\n+    x, y = x.unsqueeze(0).to(images.device), y.unsqueeze(0).to(images.device)\n \n     distorted_x = x + alpha * dx\n     distorted_y = y + alpha * dy\n\n@@ -694,6 +694,112 @@ def gaussian_blur_np(\n     return blurred_images\n \n \n+def elastic_transform_np(\n+    images,\n+    alpha=20.0,\n+    sigma=5.0,\n+    interpolation=\"bilinear\",\n+    fill_mode=\"reflect\",\n+    fill_value=0.0,\n+    seed=None,\n+    data_format=None,\n+):\n+    data_format = backend.standardize_data_format(data_format)\n+\n+    images = np.asarray(images)\n+    input_dtype = images.dtype\n+\n+    alpha = np.asarray(alpha, dtype=input_dtype)\n+    sigma = np.asarray(sigma, dtype=input_dtype)\n+\n+    kernel_size = (int(6 * sigma) | 1, int(6 * sigma) | 1)\n+\n+    need_squeeze = False\n+    if len(images.shape) == 3:\n+        images = np.expand_dims(images, axis=0)\n+        need_squeeze = True\n+\n+    if data_format == \"channels_last\":\n+        batch_size, height, width, channels = images.shape\n+        channel_axis = -1\n+    else:\n+        batch_size, channels, height, width = images.shape\n+        channel_axis = 1\n+\n+    rng = np.random.default_rng([seed, 0])\n+    dx = (\n+        rng.normal(size=(batch_size, height, width), loc=0.0, scale=1.0).astype(\n+            input_dtype\n+        )\n+        * sigma\n+    )\n+    dy = (\n+        rng.normal(size=(batch_size, height, width), loc=0.0, scale=1.0).astype(\n+            input_dtype\n+        )\n+        * sigma\n+    )\n+\n+    dx = gaussian_blur_np(\n+        np.expand_dims(dx, axis=channel_axis),\n+        kernel_size=kernel_size,\n+        sigma=(sigma, sigma),\n+        data_format=data_format,\n+    )\n+    dy = gaussian_blur_np(\n+        np.expand_dims(dy, axis=channel_axis),\n+        kernel_size=kernel_size,\n+        sigma=(sigma, sigma),\n+        data_format=data_format,\n+    )\n+\n+    dx = np.squeeze(dx)\n+    dy = np.squeeze(dy)\n+\n+    x, y = np.meshgrid(np.arange(width), np.arange(height))\n+    x, y = x[None, :, :], y[None, :, :]\n+\n+    distorted_x = x + alpha * dx\n+    distorted_y = y + alpha * dy\n+\n+    transformed_images = np.zeros_like(images)\n+\n+    if data_format == \"channels_last\":\n+        for i in range(channels):\n+            transformed_images[..., i] = np.stack(\n+                [\n+                    _fixed_map_coordinates(\n+                        images[b, ..., i],\n+                        [distorted_y[b], distorted_x[b]],\n+                        order=AFFINE_TRANSFORM_INTERPOLATIONS[interpolation],\n+                        fill_mode=fill_mode,\n+                        fill_value=fill_value,\n+                    )\n+                    for b in range(batch_size)\n+                ]\n+            )\n+    else:\n+        for i in range(channels):\n+            transformed_images[:, i, :, :] = np.stack(\n+                [\n+                    _fixed_map_coordinates(\n+                        images[b, i, ...],\n+                        [distorted_y[b], distorted_x[b]],\n+                        order=AFFINE_TRANSFORM_INTERPOLATIONS[interpolation],\n+                        fill_mode=fill_mode,\n+                        fill_value=fill_value,\n+                    )\n+                    for b in range(batch_size)\n+                ]\n+            )\n+\n+    if need_squeeze:\n+        transformed_images = np.squeeze(transformed_images, axis=0)\n+    transformed_images = transformed_images.astype(input_dtype)\n+\n+    return transformed_images\n+\n+\n def _compute_homography_matrix(start_points, end_points):\n     start_x1, start_y1 = start_points[:, 0, 0], start_points[:, 0, 1]\n     start_x2, start_y2 = start_points[:, 1, 0], start_points[:, 1, 1]\n@@ -1700,6 +1806,65 @@ class ImageOpsCorrectnessTest(testing.TestCase):\n         self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n         self.assertAllClose(ref_out, out, atol=1e-2, rtol=1e-2)\n \n+    def test_elastic_transform(self):\n+        # Test channels_last\n+        backend.set_image_data_format(\"channels_last\")\n+        np.random.seed(42)\n+        x = np.random.uniform(size=(50, 50, 3)).astype(\"float32\")\n+        alpha, sigma, seed = 20.0, 5.0, 42\n+\n+        out = kimage.elastic_transform(\n+            x,\n+            alpha=alpha,\n+            sigma=sigma,\n+            seed=seed,\n+            data_format=\"channels_last\",\n+        )\n+\n+        ref_out = elastic_transform_np(\n+            x,\n+            alpha=alpha,\n+            sigma=sigma,\n+            seed=seed,\n+            data_format=\"channels_last\",\n+        )\n+\n+        out = np.asarray(out)\n+\n+        self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n+        self.assertAllClose(\n+            np.mean(ref_out), np.mean(out), atol=1e-2, rtol=1e-2\n+        )\n+        self.assertAllClose(np.var(ref_out), np.var(out), atol=1e-2, rtol=1e-2)\n+\n+        # Test channels_first\n+        backend.set_image_data_format(\"channels_first\")\n+        x = np.random.uniform(size=(3, 50, 50)).astype(\"float32\")\n+        alpha, sigma, seed = 20.0, 5.0, 42\n+\n+        ref_out = elastic_transform_np(\n+            x,\n+            alpha=alpha,\n+            sigma=sigma,\n+            seed=seed,\n+            data_format=\"channels_first\",\n+        )\n+\n+        out = kimage.elastic_transform(\n+            x,\n+            alpha=alpha,\n+            sigma=sigma,\n+            seed=seed,\n+            data_format=\"channels_first\",\n+        )\n+        out = np.asarray(out)\n+\n+        self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n+        self.assertAllClose(\n+            np.mean(ref_out), np.mean(out), atol=1e-2, rtol=1e-2\n+        )\n+        self.assertAllClose(np.var(ref_out), np.var(out), atol=1e-2, rtol=1e-2)\n+\n \n class ImageOpsBehaviorTests(testing.TestCase):\n     def setUp(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#538ee7b954dbf0287eace64d994625fe35dc3818", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 42 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 45 | Churn Cumulative: 1352 | Contributors (this commit): 8 | Commits (past 90d): 15 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -380,9 +380,48 @@ def average(x, axis=None, weights=None):\n \n \n def bincount(x, weights=None, minlength=0, sparse=False):\n-    raise NotImplementedError(\n-        \"`bincount` is not supported with openvino backend\"\n-    )\n+    if x is None:\n+        raise ValueError(\"input x is None\")\n+    if sparse:\n+        raise ValueError(\"Unsupported value `sparse=True`\")\n+    x = get_ov_output(x)\n+    x_type = x.get_element_type()\n+    shape_x = ov_opset.shape_of(x, \"i64\").output(0)\n+    rank_x = ov_opset.shape_of(shape_x, \"i64\").output(0)\n+    rank_x = ov_opset.convert(rank_x, x_type).output(0)\n+    scalar_shape = ov_opset.constant([], x_type).output(0)\n+    rank_x = ov_opset.reshape(rank_x, scalar_shape, False).output(0)\n+    const_minus_one = ov_opset.constant(-1, x_type).output(0)\n+    rank_minus_one = ov_opset.add(rank_x, const_minus_one).output(0)\n+    minlength = get_ov_output(minlength)\n+    minlength = ov_opset.convert(minlength, x_type).output(0)\n+    const_one = ov_opset.constant(1, x_type).output(0)\n+    const_zero = ov_opset.constant(0, x_type).output(0)\n+    max_element = ov_opset.reduce_max(x, const_zero, keep_dims=False).output(0)\n+    depth = ov_opset.add(max_element, const_one).output(0)\n+    depth = ov_opset.maximum(depth, minlength).output(0)\n+    depth_scalar = ov_opset.reduce_max(\n+        depth, const_zero, keep_dims=False\n+    ).output(0)\n+    one_hot = ov_opset.one_hot(\n+        x, depth_scalar, const_one, const_zero, axis=-1\n+    ).output(0)\n+    if weights is not None:\n+        weights = get_ov_output(weights)\n+        weights_type = weights.get_element_type()\n+        weights_new = ov_opset.reshape(weights, [-1, 1], False).output(0)\n+        one_hot = ov_opset.convert(one_hot, weights_type).output(0)\n+        final_one_hot = ov_opset.multiply(one_hot, weights_new).output(0)\n+        final_output = ov_opset.reduce_sum(\n+            final_one_hot, rank_minus_one, keep_dims=False\n+        ).output(0)\n+        return OpenVINOKerasTensor(final_output)\n+    else:\n+        final_output = ov_opset.reduce_sum(\n+            one_hot, rank_minus_one, keep_dims=False\n+        ).output(0)\n+        final_output = ov_opset.convert(final_output, Type.i32).output(0)\n+        return OpenVINOKerasTensor(final_output)\n \n \n def broadcast_to(x, shape):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3820c0fefacbb6d7af0214818f164a8b26d277ec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 2646 | Contributors (this commit): 9 | Commits (past 90d): 8 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -1829,7 +1829,7 @@ class ImageOpsCorrectnessTest(testing.TestCase):\n             data_format=\"channels_last\",\n         )\n \n-        out = np.asarray(out)\n+        out = backend.convert_to_numpy(out)\n \n         self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n         self.assertAllClose(\n@@ -1857,7 +1857,7 @@ class ImageOpsCorrectnessTest(testing.TestCase):\n             seed=seed,\n             data_format=\"channels_first\",\n         )\n-        out = np.asarray(out)\n+        out = backend.convert_to_numpy(out)\n \n         self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n         self.assertAllClose(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#37e21774824a57255fe5428cf53df9674c6b7fa6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 32 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 34 | Churn Cumulative: 2050 | Contributors (this commit): 11 | Commits (past 90d): 23 | Contributors (cumulative): 15 | DMM Complexity: 0.9\n\nDIFF:\n@@ -73,6 +73,9 @@ def get_ov_output(x, ov_type=None):\n             ov_type = Type.i32\n         x = ov_opset.constant(x, ov_type).output(0)\n     elif isinstance(x, np.ndarray):\n+        if x.dtype == np.dtype(\"bfloat16\"):\n+            x = ov_opset.constant(x, OPENVINO_DTYPES[\"bfloat16\"]).output(0)\n+        else:\n             x = ov_opset.constant(x).output(0)\n     elif np.isscalar(x):\n         x = ov_opset.constant(x).output(0)\n\n@@ -336,9 +336,36 @@ def argmin(x, axis=None, keepdims=False):\n \n \n def argsort(x, axis=-1):\n-    raise NotImplementedError(\n-        \"`argsort` is not supported with openvino backend\"\n+    x = get_ov_output(x)\n+    x_shape = x.get_partial_shape()\n+    rank = x_shape.rank.get_length()\n+    if rank == 0:\n+        return OpenVINOKerasTensor(ov_opset.constant([0], Type.i32).output(0))\n+    if axis is None:\n+        flatten_shape = ov_opset.constant([-1], Type.i32).output(0)\n+        x = ov_opset.reshape(x, flatten_shape, False).output(0)\n+        x_shape_tensor = ov_opset.shape_of(x, Type.i32).output(0)\n+        k = ov_opset.reduce_prod(\n+            x_shape_tensor, ov_opset.constant([0], Type.i32), keep_dims=False\n         )\n+        axis = 0\n+    else:\n+        if axis < 0:\n+            axis = rank + axis\n+        x_shape_tensor = ov_opset.shape_of(x, Type.i32).output(0)\n+        k = ov_opset.gather(\n+            x_shape_tensor,\n+            ov_opset.constant(axis, Type.i32).output(0),\n+            ov_opset.constant(0, Type.i32).output(0),\n+        ).output(0)\n+    sorted_indices = ov_opset.topk(\n+        x,\n+        k=k,\n+        axis=axis,\n+        mode=\"min\",\n+        sort=\"value\",\n+    ).output(1)\n+    return OpenVINOKerasTensor(sorted_indices)\n \n \n def array(x, dtype=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c877b894b911a4b2b96579afa5a07df71d439bd7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 932 | Contributors (this commit): 11 | Commits (past 90d): 3 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -1129,7 +1129,7 @@ def wrap_flash_attention(\n         )\n \n     if custom_mask is not None:\n-        mask = splash_attention_mask.NumpyMask(mask=custom_mask)\n+        mask = splash_attention_mask.NumpyMask(array=custom_mask)\n \n     else:\n         mask = splash_attention_mask.CausalMask(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5a48a31d8e4b8ec6c7bcafea079e4344b24bcac3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 10 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 22 | Churn Cumulative: 450 | Contributors (this commit): 13 | Commits (past 90d): 7 | Contributors (cumulative): 13 | DMM Complexity: 0.0\n\nDIFF:\n@@ -391,8 +391,10 @@ class JAXTrainer(base_trainer.Trainer):\n         self.make_train_function()\n         self.stop_training = False\n         training_logs = {}\n+        training_finished = False\n         callbacks.on_train_begin()\n         initial_epoch = self._initial_epoch or initial_epoch\n+        try:\n             for epoch in range(initial_epoch, epochs):\n                 self.reset_metrics()\n                 callbacks.on_epoch_begin(epoch)\n@@ -423,8 +425,8 @@ class JAXTrainer(base_trainer.Trainer):\n                             metrics_variables,\n                         ) = state\n \n-                    # Setting _jax_state enables callbacks to force a state sync\n-                    # if they need to.\n+                        # Setting _jax_state enables callbacks to force a state\n+                        # sync if they need to.\n                         self._jax_state = {\n                             \"trainable_variables\": trainable_variables,\n                             \"non_trainable_variables\": non_trainable_variables,\n@@ -439,12 +441,14 @@ class JAXTrainer(base_trainer.Trainer):\n                             # this flag in on_(train_)batch_end.\n                             break\n \n-            # Reattach state to the model (if not already done by a callback).\n+                # Reattach state to the model\n+                # (if not already done by a callback).\n                 # NOTE: doing this after each step would be a big performance\n                 # bottleneck.\n                 self.jax_state_sync()\n \n-            # Override with model metrics instead of last step logs if needed.\n+                # Override with model metrics instead of last step logs if\n+                # needed.\n                 # The jax spmd_mode is need for multi-process context, since the\n                 # metrics values are replicated, and we don't want to do a all\n                 # gather, and only need the local copy of the value.\n@@ -485,16 +489,21 @@ class JAXTrainer(base_trainer.Trainer):\n                 training_logs = epoch_logs\n                 if self.stop_training:\n                     break\n+            training_finished = True\n \n+        finally:\n+            self.jax_state_sync()\n             if (\n                 isinstance(self.optimizer, optimizers_module.Optimizer)\n                 and epochs > 0\n             ):\n                 self.optimizer.finalize_variable_values(self.trainable_weights)\n \n-        # If _eval_epoch_iterator exists, delete it after all epochs are done.\n+            # If _eval_epoch_iterator exists, delete it after all epochs\n+            # are done.\n             if getattr(self, \"_eval_epoch_iterator\", None) is not None:\n                 del self._eval_epoch_iterator\n+            if training_finished:\n                 callbacks.on_train_end(logs=training_logs)\n             self._jax_state = None\n             self._clear_jax_state_sharding()\n@@ -522,7 +531,8 @@ class JAXTrainer(base_trainer.Trainer):\n         if use_cached_eval_dataset:\n             epoch_iterator = self._eval_epoch_iterator\n         else:\n-            # Create an iterator that yields batches of input/target data.\n+            # Create an iterator that yields batches of\n+            # input/target data.\n             epoch_iterator = JAXEpochIterator(\n                 x=x,\n                 y=y,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#df2fc371bec023d1429e78efe10e192fd96fb2f0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 12 | Churn Cumulative: 1395 | Contributors (this commit): 10 | Commits (past 90d): 17 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -650,9 +650,15 @@ def full(shape, fill_value, dtype=None):\n \n \n def full_like(x, fill_value, dtype=None):\n-    raise NotImplementedError(\n-        \"`full_like` is not supported with openvino backend\"\n-    )\n+    x = get_ov_output(x)\n+    shape_x = ov_opset.shape_of(x)\n+    if dtype is not None:\n+        ov_type = OPENVINO_DTYPES[standardize_dtype(dtype)]\n+    else:\n+        ov_type = x.get_element_type()\n+    const_value = ov_opset.constant(fill_value, ov_type).output(0)\n+    res = ov_opset.broadcast(const_value, shape_x).output(0)\n+    return OpenVINOKerasTensor(res)\n \n \n def greater(x1, x2):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#66cc6d5a86f77f55327d96bd9c0338a7dbae17ca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 70 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 71 | Churn Cumulative: 1466 | Contributors (this commit): 11 | Commits (past 90d): 18 | Contributors (cumulative): 11 | DMM Complexity: 0.0\n\nDIFF:\n@@ -568,7 +568,76 @@ def diagonal(x, offset=0, axis1=0, axis2=1):\n \n \n def diff(a, n=1, axis=-1):\n-    raise NotImplementedError(\"`diff` is not supported with openvino backend\")\n+    if n == 0:\n+        return OpenVINOKerasTensor(get_ov_output(a))\n+    if n < 0:\n+        raise ValueError(\"order must be non-negative but got \" + repr(n))\n+    a = get_ov_output(a)\n+    a_type = a.get_element_type()\n+    if isinstance(a, np.ndarray):\n+        rank = a.ndim\n+    else:\n+        rank = a.get_partial_shape().rank.get_length()\n+    if axis < 0:\n+        axis = axis + rank\n+    result = a\n+    for _ in range(n):\n+        rank = result.get_partial_shape().rank.get_length()\n+        strides = ov_opset.constant(\n+            np.array([1] * rank, dtype=np.int64), Type.i64\n+        ).output(0)\n+\n+        begin_upper_list = [0] * rank\n+        begin_upper_list[axis] = 1\n+        begin_upper = ov_opset.constant(\n+            np.array(begin_upper_list, dtype=np.int64), Type.i64\n+        ).output(0)\n+        end_upper = ov_opset.constant(\n+            np.array([0] * rank, dtype=np.int64), Type.i64\n+        ).output(0)\n+        begin_mask_upper = [1] * rank\n+        begin_mask_upper[axis] = 0\n+        end_mask_upper = [1] * rank\n+        upper = ov_opset.strided_slice(\n+            data=result,\n+            begin=begin_upper,\n+            end=end_upper,\n+            strides=strides,\n+            begin_mask=begin_mask_upper,\n+            end_mask=end_mask_upper,\n+            new_axis_mask=[],\n+            shrink_axis_mask=[],\n+            ellipsis_mask=[],\n+        ).output(0)\n+\n+        begin_lower = ov_opset.constant(\n+            np.array([0] * rank, dtype=np.int64), Type.i64\n+        ).output(0)\n+        end_lower_list = [0] * rank\n+        end_lower_list[axis] = -1\n+        end_lower = ov_opset.constant(\n+            np.array(end_lower_list, dtype=np.int64), Type.i64\n+        ).output(0)\n+        begin_mask_lower = [1] * rank\n+        end_mask_lower = [1] * rank\n+        end_mask_lower[axis] = 0\n+        lower = ov_opset.strided_slice(\n+            data=result,\n+            begin=begin_lower,\n+            end=end_lower,\n+            strides=strides,\n+            begin_mask=begin_mask_lower,\n+            end_mask=end_mask_lower,\n+            new_axis_mask=[],\n+            shrink_axis_mask=[],\n+            ellipsis_mask=[],\n+        ).output(0)\n+\n+        if a_type == Type.boolean:\n+            result = ov_opset.not_equal(upper, lower).output(0)\n+        else:\n+            result = ov_opset.subtract(upper, lower).output(0)\n+    return OpenVINOKerasTensor(result)\n \n \n def digitize(x, bins):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#decd6baafbbc4152a62ad763533db6213c982356", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 11 | Churn Cumulative: 1477 | Contributors (this commit): 12 | Commits (past 90d): 19 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -661,7 +661,16 @@ def dot(x, y):\n \n \n def empty(shape, dtype=None):\n-    raise NotImplementedError(\"`empty` is not supported with openvino backend\")\n+    dtype = standardize_dtype(dtype) or config.floatx()\n+    ov_type = OPENVINO_DTYPES[dtype]\n+    if isinstance(shape, tuple):\n+        shape = list(shape)\n+    elif isinstance(shape, int):\n+        shape = [shape]\n+    shape_node = ov_opset.constant(shape, Type.i32).output(0)\n+    const_zero = ov_opset.constant(0, dtype=ov_type).output(0)\n+    empty_tensor = ov_opset.broadcast(const_zero, shape_node).output(0)\n+    return OpenVINOKerasTensor(empty_tensor)\n \n \n def equal(x1, x2):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d7c5d42bab0dd2f7ba52d2be7d89b2fa4160666e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 380 | Lines Deleted: 1 | Files Changed: 6 | Hunks: 7 | Methods Changed: 15 | Complexity Δ (Sum/Max): 37/28 | Churn Δ: 381 | Churn Cumulative: 2135 | Contributors (this commit): 12 | Commits (past 90d): 55 | Contributors (cumulative): 36 | DMM Complexity: 0.7024793388429752\n\nDIFF:\n@@ -173,6 +173,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_contrast import (\n from keras.src.layers.preprocessing.image_preprocessing.random_crop import (\n     RandomCrop,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_elastic_transform import (\n+    RandomElasticTransform,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_erasing import (\n     RandomErasing,\n )\n\n@@ -173,6 +173,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_contrast import (\n from keras.src.layers.preprocessing.image_preprocessing.random_crop import (\n     RandomCrop,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_elastic_transform import (\n+    RandomElasticTransform,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_erasing import (\n     RandomErasing,\n )\n\n@@ -813,7 +813,8 @@ def elastic_transform(\n \n     alpha = convert_to_tensor(alpha, dtype=input_dtype)\n     sigma = convert_to_tensor(sigma, dtype=input_dtype)\n-    kernel_size = (int(6 * sigma) | 1, int(6 * sigma) | 1)\n+    kernel_factor = convert_to_tensor(sigma, dtype=\"int32\")\n+    kernel_size = (6 * kernel_factor | 1, 6 * kernel_factor | 1)\n \n     need_squeeze = False\n     if len(images.shape) == 3:\n@@ -828,6 +829,10 @@ def elastic_transform(\n         channel_axis = 1\n \n     seed = draw_seed(seed)\n+\n+    if batch_size is None:\n+        batch_size = 1\n+\n     dx = (\n         tf.random.stateless_normal(\n             shape=(batch_size, height, width),\n\n@@ -117,6 +117,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_contrast import (\n from keras.src.layers.preprocessing.image_preprocessing.random_crop import (\n     RandomCrop,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_elastic_transform import (\n+    RandomElasticTransform,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_erasing import (\n     RandomErasing,\n )\n\n@@ -0,0 +1,276 @@\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n+    BaseImagePreprocessingLayer,\n+)\n+from keras.src.random.seed_generator import SeedGenerator\n+\n+\n+@keras_export(\"keras.layers.RandomElasticTransform\")\n+class RandomElasticTransform(BaseImagePreprocessingLayer):\n+    \"\"\"A preprocessing layer that applies random elastic transformations.\n+\n+    This layer distorts input images by applying elastic deformations,\n+    simulating a physically realistic transformation. The magnitude of the\n+    distortion is controlled by the `scale` parameter, while the `factor`\n+    determines the probability of applying the transformation.\n+\n+    Args:\n+        factor: A single float or a tuple of two floats.\n+            `factor` controls the probability of applying the transformation.\n+            - `factor=0.0` ensures no erasing is applied.\n+            - `factor=1.0` means erasing is always applied.\n+            - If a tuple `(min, max)` is provided, a probability value\n+              is sampled between `min` and `max` for each image.\n+            - If a single float is provided, a probability is sampled\n+              between `0.0` and the given float.\n+            Default is 1.0.\n+        scale: A float or a tuple of two floats defining the magnitude of\n+            the distortion applied.\n+            - If a tuple `(min, max)` is provided, a random scale value is\n+              sampled within this range.\n+            - If a single float is provided, a random scale value is sampled\n+              between `0.0` and the given float.\n+            Default is 1.0.\n+        interpolation: Interpolation mode. Supported values: `\"nearest\"`,\n+            `\"bilinear\"`.\n+        fill_mode: Points outside the boundaries of the input are filled\n+            according to the given mode. Available methods are `\"constant\"`,\n+            `\"nearest\"`, `\"wrap\"` and `\"reflect\"`. Defaults to `\"constant\"`.\n+            - `\"reflect\"`: `(d c b a | a b c d | d c b a)`\n+                The input is extended by reflecting about the edge of the last\n+                pixel.\n+            - `\"constant\"`: `(k k k k | a b c d | k k k k)`\n+                The input is extended by filling all values beyond\n+                the edge with the same constant value k specified by\n+                `fill_value`.\n+            - `\"wrap\"`: `(a b c d | a b c d | a b c d)`\n+                The input is extended by wrapping around to the opposite edge.\n+            - `\"nearest\"`: `(a a a a | a b c d | d d d d)`\n+                The input is extended by the nearest pixel.\n+            Note that when using torch backend, `\"reflect\"` is redirected to\n+            `\"mirror\"` `(c d c b | a b c d | c b a b)` because torch does not\n+            support `\"reflect\"`.\n+            Note that torch backend does not support `\"wrap\"`.\n+        fill_value: a float represents the value to be filled outside the\n+            boundaries when `fill_mode=\"constant\"`.\n+        value_range: the range of values the incoming images will have.\n+            Represented as a two-number tuple written `[low, high]`. This is\n+            typically either `[0, 1]` or `[0, 255]` depending on how your\n+            preprocessing pipeline is set up.\n+        seed: Integer. Used to create a random seed.\n+\n+    \"\"\"\n+\n+    _USE_BASE_FACTOR = False\n+    _FACTOR_BOUNDS = (0, 1)\n+    _SUPPORTED_INTERPOLATION = (\"nearest\", \"bilinear\")\n+    _SUPPORTED_FILL_MODES = {\n+        \"constant\",\n+        \"nearest\",\n+        \"wrap\",\n+        \"mirror\",\n+        \"reflect\",\n+    }\n+\n+    def __init__(\n+        self,\n+        factor=1.0,\n+        scale=1.0,\n+        interpolation=\"bilinear\",\n+        fill_mode=\"reflect\",\n+        fill_value=0.0,\n+        value_range=(0, 255),\n+        seed=None,\n+        data_format=None,\n+        **kwargs,\n+    ):\n+        super().__init__(data_format=data_format, **kwargs)\n+        self._set_factor(factor)\n+        self.scale = self._set_factor_by_name(scale, \"scale\")\n+        self.interpolation = interpolation\n+        self.fill_mode = fill_mode\n+        self.fill_value = fill_value\n+        self.value_range = value_range\n+        self.seed = seed\n+        self.generator = SeedGenerator(seed)\n+\n+        if interpolation not in self._SUPPORTED_INTERPOLATION:\n+            raise NotImplementedError(\n+                f\"Unknown `interpolation` {interpolation}. Expected of one \"\n+                f\"{self._SUPPORTED_INTERPOLATION}.\"\n+            )\n+\n+        if fill_mode not in self._SUPPORTED_FILL_MODES:\n+            raise NotImplementedError(\n+                f\"Unknown `fill_mode` {fill_mode}. Expected of one \"\n+                f\"{self._SUPPORTED_FILL_MODES}.\"\n+            )\n+\n+        if self.data_format == \"channels_first\":\n+            self.height_axis = -2\n+            self.width_axis = -1\n+            self.channel_axis = -3\n+        else:\n+            self.height_axis = -3\n+            self.width_axis = -2\n+            self.channel_axis = -1\n+\n+    def _set_factor_by_name(self, factor, name):\n+        error_msg = (\n+            f\"The `{name}` argument should be a number \"\n+            \"(or a list of two numbers) \"\n+            \"in the range \"\n+            f\"[{self._FACTOR_BOUNDS[0]}, {self._FACTOR_BOUNDS[1]}]. \"\n+            f\"Received: factor={factor}\"\n+        )\n+        if isinstance(factor, (tuple, list)):\n+            if len(factor) != 2:\n+                raise ValueError(error_msg)\n+            if (\n+                factor[0] > self._FACTOR_BOUNDS[1]\n+                or factor[1] < self._FACTOR_BOUNDS[0]\n+            ):\n+                raise ValueError(error_msg)\n+            lower, upper = sorted(factor)\n+        elif isinstance(factor, (int, float)):\n+            if (\n+                factor < self._FACTOR_BOUNDS[0]\n+                or factor > self._FACTOR_BOUNDS[1]\n+            ):\n+                raise ValueError(error_msg)\n+            factor = abs(factor)\n+            lower, upper = [max(-factor, self._FACTOR_BOUNDS[0]), factor]\n+        else:\n+            raise ValueError(error_msg)\n+        return lower, upper\n+\n+    def get_random_transformation(self, data, training=True, seed=None):\n+        if not training:\n+            return None\n+\n+        if (self.scale[1] == 0) or (self.factor[1] == 0):\n+            return None\n+\n+        if isinstance(data, dict):\n+            images = data[\"images\"]\n+        else:\n+            images = data\n+\n+        images_shape = self.backend.shape(images)\n+        unbatched = len(images_shape) == 3\n+        if unbatched:\n+            batch_size = 1\n+        else:\n+            batch_size = images_shape[0]\n+\n+        seed = seed or self._get_seed_generator(self.backend._backend)\n+\n+        transformation_probability = self.backend.random.uniform(\n+            shape=(batch_size,),\n+            minval=self.factor[0],\n+            maxval=self.factor[1],\n+            seed=seed,\n+        )\n+\n+        random_threshold = self.backend.random.uniform(\n+            shape=(batch_size,),\n+            minval=0.0,\n+            maxval=1.0,\n+            seed=seed,\n+        )\n+        apply_transform = random_threshold < transformation_probability\n+\n+        distortion_factor = self.backend.random.uniform(\n+            shape=(),\n+            minval=self.scale[0],\n+            maxval=self.scale[1],\n+            seed=seed,\n+            dtype=self.compute_dtype,\n+        )\n+\n+        return {\n+            \"apply_transform\": apply_transform,\n+            \"distortion_factor\": distortion_factor,\n+            \"seed\": seed,\n+        }\n+\n+    def get_elastic_transform_params(self, height, width, factor):\n+        alpha_scale = 0.1 * factor\n+        sigma_scale = 0.05 * factor\n+\n+        alpha = max(height, width) * alpha_scale\n+        sigma = min(height, width) * sigma_scale\n+\n+        return alpha, sigma\n+\n+    def transform_images(self, images, transformation, training=True):\n+        images = self.backend.cast(images, self.compute_dtype)\n+        if training and transformation is not None:\n+            apply_transform = transformation[\"apply_transform\"]\n+            distortion_factor = transformation[\"distortion_factor\"]\n+            seed = transformation[\"seed\"]\n+\n+            height, width = (\n+                images.shape[self.height_axis],\n+                images.shape[self.width_axis],\n+            )\n+\n+            alpha, sigma = self.get_elastic_transform_params(\n+                height, width, distortion_factor\n+            )\n+\n+            transformed_images = self.backend.image.elastic_transform(\n+                images,\n+                alpha=alpha,\n+                sigma=sigma,\n+                interpolation=self.interpolation,\n+                fill_mode=self.fill_mode,\n+                fill_value=self.fill_value,\n+                seed=seed,\n+                data_format=self.data_format,\n+            )\n+\n+            apply_transform = (\n+                apply_transform[:, None, None]\n+                if len(images.shape) == 3\n+                else apply_transform[:, None, None, None]\n+            )\n+\n+            images = self.backend.numpy.where(\n+                apply_transform,\n+                transformed_images,\n+                images,\n+            )\n+\n+            images = self.backend.numpy.clip(\n+                images, self.value_range[0], self.value_range[1]\n+            )\n+\n+            images = self.backend.cast(images, self.compute_dtype)\n+        return images\n+\n+    def transform_labels(self, labels, transformation, training=True):\n+        return labels\n+\n+    def transform_segmentation_masks(\n+        self, segmentation_masks, transformation, training=True\n+    ):\n+        return self.transform_images(\n+            segmentation_masks, transformation, training=training\n+        )\n+\n+    def compute_output_shape(self, input_shape):\n+        return input_shape\n+\n+    def get_config(self):\n+        base_config = super().get_config()\n+        config = {\n+            \"factor\": self.factor,\n+            \"scale\": self.scale,\n+            \"interpolation\": self.interpolation,\n+            \"fill_mode\": self.fill_mode,\n+            \"fill_value\": self.fill_value,\n+            \"value_range\": self.value_range,\n+            \"seed\": self.seed,\n+        }\n+        return {**base_config, **config}\n\n@@ -0,0 +1,89 @@\n+import numpy as np\n+import pytest\n+from tensorflow import data as tf_data\n+\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n+\n+\n+class RandomElasticTransformTest(testing.TestCase):\n+    @pytest.mark.requires_trainable_backend\n+    def test_layer(self):\n+        self.run_layer_test(\n+            layers.RandomElasticTransform,\n+            init_kwargs={\n+                \"factor\": 1.0,\n+                \"scale\": 0.5,\n+                \"interpolation\": \"bilinear\",\n+                \"fill_mode\": \"reflect\",\n+                \"fill_value\": 0,\n+                \"value_range\": (0, 255),\n+                \"seed\": 1,\n+            },\n+            input_shape=(8, 3, 4, 3),\n+            supports_masking=False,\n+            expected_output_shape=(8, 3, 4, 3),\n+            run_training_check=False,\n+        )\n+\n+    def test_random_elastic_transform_inference(self):\n+        seed = 3481\n+        layer = layers.RandomElasticTransform()\n+\n+        np.random.seed(seed)\n+        inputs = np.random.randint(0, 255, size=(224, 224, 3))\n+        output = layer(inputs, training=False)\n+        self.assertAllClose(inputs, output)\n+\n+    def test_random_elastic_transform_no_op(self):\n+        seed = 3481\n+        layer = layers.RandomElasticTransform(factor=0)\n+\n+        np.random.seed(seed)\n+        inputs = np.random.randint(0, 255, size=(224, 224, 3))\n+        output = layer(inputs)\n+        self.assertAllClose(inputs, output)\n+\n+        layer = layers.RandomElasticTransform(scale=0)\n+\n+        np.random.seed(seed)\n+        inputs = np.random.randint(0, 255, size=(224, 224, 3))\n+        output = layer(inputs)\n+        self.assertAllClose(inputs, output)\n+\n+    def test_random_elastic_transform_basic(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            inputs = np.zeros((8, 8, 1))\n+            inputs[3:5, 3:5, :] = 1.0\n+        else:\n+            inputs = np.zeros((1, 8, 8))\n+            inputs[:, 3:5, 3:5] = 1.0\n+\n+        layer = layers.RandomElasticTransform(data_format=data_format)\n+\n+        transformation = {\n+            \"apply_transform\": np.array([True]),\n+            \"distortion_factor\": np.float32(0.9109325),\n+            \"seed\": 42,\n+        }\n+\n+        output = layer.transform_images(inputs, transformation)\n+\n+        self.assertNotAllClose(inputs, output)\n+        self.assertEqual(inputs.shape, output.shape)\n+\n+    def test_tf_data_compatibility(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            input_data = np.random.random((2, 8, 8, 3))\n+        else:\n+            input_data = np.random.random((2, 3, 8, 8))\n+        layer = layers.RandomElasticTransform(data_format=data_format)\n+\n+        ds = tf_data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            print(\"Output shape:\", output.shape)  # Debugging line\n+            output_numpy = output.numpy()\n+            print(\"Output numpy shape:\", output_numpy.shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
