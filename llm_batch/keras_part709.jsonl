{"custom_id": "keras#a954d064e50479d79982272b8fb193986acf1fc6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 741 | Lines Deleted: 1 | Files Changed: 7 | Hunks: 28 | Methods Changed: 26 | Complexity Δ (Sum/Max): 100/22 | Churn Δ: 742 | Churn Cumulative: 2568 | Contributors (this commit): 15 | Commits (past 90d): 63 | Contributors (cumulative): 46 | DMM Complexity: 0.55\n\nDIFF:\n@@ -1,6 +1,12 @@\n+import math\n+\n import jax\n import jax.numpy as jnp\n \n+from keras_core.backend import standardize_dtype\n+from keras_core.backend.jax.core import convert_to_tensor\n+from keras_core.utils.module_utils import scipy\n+\n \n def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n     if num_segments is None:\n@@ -56,6 +62,20 @@ def qr(x, mode=\"reduced\"):\n     return jax.numpy.linalg.qr(x, mode=mode)\n \n \n+def extract_sequences(x, sequence_length, sequence_stride):\n+    *batch_shape, signal_length = x.shape\n+    batch_shape = list(batch_shape)\n+    x = jax.numpy.reshape(x, (math.prod(batch_shape), signal_length, 1))\n+    x = jax.lax.conv_general_dilated_patches(\n+        x,\n+        (sequence_length,),\n+        (sequence_stride,),\n+        \"VALID\",\n+        dimension_numbers=(\"NTC\", \"OIT\", \"NTC\"),\n+    )\n+    return jax.numpy.reshape(x, (*batch_shape, *x.shape[-2:]))\n+\n+\n def _get_complex_tensor_from_tuple(a):\n     if not isinstance(a, (tuple, list)) or len(a) != 2:\n         raise ValueError(\n@@ -96,5 +116,60 @@ def fft2(a):\n     return jax.numpy.real(complex_output), jax.numpy.imag(complex_output)\n \n \n+def rfft(x, fft_length=None):\n+    complex_output = jax.numpy.fft.rfft(\n+        x, n=fft_length, axis=-1, norm=\"backward\"\n+    )\n+    return jax.numpy.real(complex_output), jax.numpy.imag(complex_output)\n+\n+\n+def stft(\n+    x, sequence_length, sequence_stride, fft_length, window=\"hann\", center=True\n+):\n+    if standardize_dtype(x.dtype) not in {\"float32\", \"float64\"}:\n+        raise TypeError(\n+            \"Invalid input type. Expected `float32` or `float64`. \"\n+            f\"Received: input type={x.dtype}\"\n+        )\n+    if fft_length < sequence_length:\n+        raise ValueError(\n+            \"`fft_length` must equal or larger than `sequence_length`. \"\n+            f\"Received: sequence_length={sequence_length}, \"\n+            f\"fft_length={fft_length}\"\n+        )\n+    if isinstance(window, str):\n+        if window not in {\"hann\", \"hamming\"}:\n+            raise ValueError(\n+                \"If a string is passed to `window`, it must be one of \"\n+                f'`\"hann\"`, `\"hamming\"`. Received: window={window}'\n+            )\n+\n+    if center:\n+        pad_width = [(0, 0) for _ in range(len(x.shape))]\n+        pad_width[-1] = (fft_length // 2, fft_length // 2)\n+        x = jnp.pad(x, pad_width, mode=\"reflect\")\n+\n+    x = extract_sequences(x, fft_length, sequence_stride)\n+\n+    if window is not None:\n+        if isinstance(window, str):\n+            win = convert_to_tensor(\n+                scipy.signal.get_window(window, sequence_length), dtype=x.dtype\n+            )\n+        else:\n+            win = convert_to_tensor(window, dtype=x.dtype)\n+        if len(win.shape) != 1 or win.shape[-1] != sequence_length:\n+            raise ValueError(\n+                \"The shape of `window` must be equal to [sequence_length].\"\n+                f\"Received: window shape={win.shape}\"\n+            )\n+        l_pad = (fft_length - sequence_length) // 2\n+        r_pad = fft_length - sequence_length - l_pad\n+        win = jnp.pad(win, [[l_pad, r_pad]])\n+        x = jnp.multiply(x, win)\n+\n+    return rfft(x, fft_length)\n+\n+\n def rsqrt(x):\n     return jax.lax.rsqrt(x)\n\n@@ -1,7 +1,10 @@\n import numpy as np\n \n+from keras_core.backend import standardize_dtype\n from keras_core.backend.jax.math import fft as jax_fft\n from keras_core.backend.jax.math import fft2 as jax_fft2\n+from keras_core.backend.numpy.core import convert_to_tensor\n+from keras_core.utils.module_utils import scipy\n \n \n def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n@@ -106,6 +109,21 @@ def qr(x, mode=\"reduced\"):\n     return np.linalg.qr(x, mode=mode)\n \n \n+def extract_sequences(x, sequence_length, sequence_stride):\n+    *batch_shape, _ = x.shape\n+    batch_shape = list(batch_shape)\n+    shape = x.shape[:-1] + (\n+        (x.shape[-1] - (sequence_length - sequence_stride)) // sequence_stride,\n+        sequence_length,\n+    )\n+    strides = x.strides[:-1] + (\n+        sequence_stride * x.strides[-1],\n+        x.strides[-1],\n+    )\n+    x = np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides)\n+    return np.reshape(x, (*batch_shape, *x.shape[-2:]))\n+\n+\n def fft(a):\n     real, imag = jax_fft(a)\n     return np.array(real), np.array(imag)\n@@ -114,3 +132,55 @@ def fft(a):\n def fft2(a):\n     real, imag = jax_fft2(a)\n     return np.array(real), np.array(imag)\n+\n+\n+def rfft(x, fft_length=None):\n+    complex_output = np.fft.rfft(x, n=fft_length, axis=-1, norm=\"backward\")\n+    return np.real(complex_output), np.imag(complex_output)\n+\n+\n+def stft(\n+    x, sequence_length, sequence_stride, fft_length, window=\"hann\", center=True\n+):\n+    if standardize_dtype(x.dtype) not in {\"float32\", \"float64\"}:\n+        raise TypeError(\n+            \"Invalid input type. Expected `float32` or `float64`. \"\n+            f\"Received: input type={x.dtype}\"\n+        )\n+    if fft_length < sequence_length:\n+        raise ValueError(\n+            \"`fft_length` must equal or larger than `sequence_length`. \"\n+            f\"Received: sequence_length={sequence_length}, \"\n+            f\"fft_length={fft_length}\"\n+        )\n+    if isinstance(window, str):\n+        if window not in {\"hann\", \"hamming\"}:\n+            raise ValueError(\n+                \"If a string is passed to `window`, it must be one of \"\n+                f'`\"hann\"`, `\"hamming\"`. Received: window={window}'\n+            )\n+\n+    if center:\n+        pad_width = [(0, 0) for _ in range(len(x.shape))]\n+        pad_width[-1] = (fft_length // 2, fft_length // 2)\n+        x = np.pad(x, pad_width, mode=\"reflect\")\n+    x = extract_sequences(x, fft_length, sequence_stride)\n+\n+    if window is not None:\n+        if isinstance(window, str):\n+            win = scipy.signal.get_window(window, sequence_length).astype(\n+                x.dtype\n+            )\n+        else:\n+            win = convert_to_tensor(window, dtype=x.dtype)\n+        if len(win.shape) != 1 or win.shape[-1] != sequence_length:\n+            raise ValueError(\n+                \"The shape of `window` must be equal to [sequence_length].\"\n+                f\"Received: window shape={win.shape}\"\n+            )\n+        l_pad = (fft_length - sequence_length) // 2\n+        r_pad = fft_length - sequence_length - l_pad\n+        win = np.pad(win, [[l_pad, r_pad]])\n+        x = np.multiply(x, win)\n+\n+    return rfft(x, fft_length)\n\n@@ -1,5 +1,6 @@\n import tensorflow as tf\n \n+from keras_core.backend import standardize_dtype\n from keras_core.backend.tensorflow.core import convert_to_tensor\n \n \n@@ -47,6 +48,16 @@ def qr(x, mode=\"reduced\"):\n     return tf.linalg.qr(x, full_matrices=True)\n \n \n+def extract_sequences(x, sequence_length, sequence_stride):\n+    return tf.signal.frame(\n+        x,\n+        frame_length=sequence_length,\n+        frame_step=sequence_stride,\n+        axis=-1,\n+        pad_end=False,\n+    )\n+\n+\n def _get_complex_tensor_from_tuple(a):\n     if not isinstance(a, (tuple, list)) or len(a) != 2:\n         raise ValueError(\n@@ -87,5 +98,66 @@ def fft2(a):\n     return tf.math.real(complex_output), tf.math.imag(complex_output)\n \n \n+def rfft(x, fft_length=None):\n+    if fft_length is not None:\n+        fft_length = [fft_length]\n+    complex_output = tf.signal.rfft(x, fft_length=fft_length)\n+    return tf.math.real(complex_output), tf.math.imag(complex_output)\n+\n+\n+def stft(\n+    x, sequence_length, sequence_stride, fft_length, window=\"hann\", center=True\n+):\n+    if standardize_dtype(x.dtype) not in {\"float32\", \"float64\"}:\n+        raise TypeError(\n+            \"Invalid input type. Expected `float32` or `float64`. \"\n+            f\"Received: input type={x.dtype}\"\n+        )\n+    if fft_length < sequence_length:\n+        raise ValueError(\n+            \"`fft_length` must equal or larger than `sequence_length`. \"\n+            f\"Received: sequence_length={sequence_length}, \"\n+            f\"fft_length={fft_length}\"\n+        )\n+    if isinstance(window, str):\n+        if window not in {\"hann\", \"hamming\"}:\n+            raise ValueError(\n+                \"If a string is passed to `window`, it must be one of \"\n+                f'`\"hann\"`, `\"hamming\"`. Received: window={window}'\n+            )\n+    x = convert_to_tensor(x)\n+\n+    if center:\n+        pad_width = [(0, 0) for _ in range(len(x.shape))]\n+        pad_width[-1] = (fft_length // 2, fft_length // 2)\n+        x = tf.pad(x, pad_width, mode=\"reflect\")\n+\n+    x = extract_sequences(x, fft_length, sequence_stride)\n+\n+    if window is not None:\n+        if isinstance(window, str):\n+            if window == \"hann\":\n+                win = tf.signal.hann_window(\n+                    sequence_length, periodic=True, dtype=x.dtype\n+                )\n+            else:\n+                win = tf.signal.hamming_window(\n+                    sequence_length, periodic=True, dtype=x.dtype\n+                )\n+        else:\n+            win = convert_to_tensor(window, dtype=x.dtype)\n+        if len(win.shape) != 1 or win.shape[-1] != sequence_length:\n+            raise ValueError(\n+                \"The shape of `window` must be equal to [sequence_length].\"\n+                f\"Received: window shape={win.shape}\"\n+            )\n+        l_pad = (fft_length - sequence_length) // 2\n+        r_pad = fft_length - sequence_length - l_pad\n+        win = tf.pad(win, [[l_pad, r_pad]])\n+        x = tf.multiply(x, win)\n+\n+    return rfft(x, fft_length)\n+\n+\n def rsqrt(x):\n     return tf.math.rsqrt(x)\n\n@@ -1,7 +1,9 @@\n import torch\n \n+from keras_core.backend import standardize_dtype\n from keras_core.backend.torch.core import convert_to_tensor\n from keras_core.backend.torch.core import get_device\n+from keras_core.backend.torch.numpy import pad\n \n \n def segment_sum(data, segment_ids, num_segments=None, **kwargs):\n@@ -121,6 +123,13 @@ def qr(x, mode=\"reduced\"):\n     return torch.linalg.qr(x, mode=mode)\n \n \n+def extract_sequences(x, sequence_length, sequence_stride):\n+    x = convert_to_tensor(x)\n+    return torch.unfold_copy(\n+        x, dimension=-1, size=sequence_length, step=sequence_stride\n+    )\n+\n+\n def _get_complex_tensor_from_tuple(a):\n     if not isinstance(a, (tuple, list)) or len(a) != 2:\n         raise ValueError(\n@@ -162,6 +171,76 @@ def fft2(a):\n     return complex_output.real, complex_output.imag\n \n \n+def rfft(x, fft_length=None):\n+    x = convert_to_tensor(x)\n+    complex_output = torch.fft.rfft(x, n=fft_length, dim=-1, norm=\"backward\")\n+    return complex_output.real, complex_output.imag\n+\n+\n+def stft(\n+    x, sequence_length, sequence_stride, fft_length, window=\"hann\", center=True\n+):\n+    if standardize_dtype(x.dtype) not in {\"float32\", \"float64\"}:\n+        raise TypeError(\n+            \"Invalid input type. Expected `float32` or `float64`. \"\n+            f\"Received: input type={x.dtype}\"\n+        )\n+    if fft_length < sequence_length:\n+        raise ValueError(\n+            \"`fft_length` must equal or larger than `sequence_length`. \"\n+            f\"Received: sequence_length={sequence_length}, \"\n+            f\"fft_length={fft_length}\"\n+        )\n+    if isinstance(window, str):\n+        if window not in {\"hann\", \"hamming\"}:\n+            raise ValueError(\n+                \"If a string is passed to `window`, it must be one of \"\n+                f'`\"hann\"`, `\"hamming\"`. Received: window={window}'\n+            )\n+    x = convert_to_tensor(x)\n+\n+    if center:\n+        pad_width = [(0, 0) for _ in range(x.ndim)]\n+        pad_width[-1] = (fft_length // 2, fft_length // 2)\n+        # torch does not support reflect padding when x.ndim >= 3\n+        if x.ndim < 3:\n+            x = pad(x, pad_width, \"reflect\")\n+        else:\n+            x = pad(x, pad_width, \"constant\")\n+\n+    x = extract_sequences(x, fft_length, sequence_stride)\n+\n+    if window is not None:\n+        if isinstance(window, str):\n+            if window == \"hann\":\n+                win = torch.hann_window(\n+                    sequence_length,\n+                    periodic=True,\n+                    dtype=x.dtype,\n+                    device=get_device(),\n+                )\n+            else:\n+                win = torch.hamming_window(\n+                    sequence_length,\n+                    periodic=True,\n+                    dtype=x.dtype,\n+                    device=get_device(),\n+                )\n+        else:\n+            win = convert_to_tensor(window, dtype=x.dtype)\n+        if len(win.shape) != 1 or win.shape[-1] != sequence_length:\n+            raise ValueError(\n+                \"The shape of `window` must be equal to [sequence_length].\"\n+                f\"Received: window shape={win.shape}\"\n+            )\n+        l_pad = (fft_length - sequence_length) // 2\n+        r_pad = fft_length - sequence_length - l_pad\n+        win = pad(win, [[l_pad, r_pad]], \"constant\")\n+        x = torch.multiply(x, win)\n+\n+    return rfft(x, fft_length)\n+\n+\n def rsqrt(x):\n     x = convert_to_tensor(x)\n     return torch.rsqrt(x)\n\n@@ -314,6 +314,70 @@ def qr(x, mode=\"reduced\"):\n     return backend.math.qr(x, mode=mode)\n \n \n+class ExtractSequences(Operation):\n+    def __init__(self, sequence_length, sequence_stride):\n+        super().__init__()\n+        self.sequence_length = sequence_length\n+        self.sequence_stride = sequence_stride\n+\n+    def compute_output_spec(self, x):\n+        if len(x.shape) < 1:\n+            raise ValueError(\n+                f\"Input should have rank >= 1. \"\n+                f\"Received: input.shape = {x.shape}\"\n+            )\n+        if x.shape[-1] is not None:\n+            num_sequences = (\n+                1 + (x.shape[-1] - self.sequence_length) // self.sequence_stride\n+            )\n+        else:\n+            num_sequences = None\n+        new_shape = x.shape[:-1] + (num_sequences, self.sequence_length)\n+        return KerasTensor(shape=new_shape, dtype=x.dtype)\n+\n+    def call(self, x):\n+        return backend.math.extract_sequences(\n+            x,\n+            sequence_length=self.sequence_length,\n+            sequence_stride=self.sequence_stride,\n+        )\n+\n+\n+@keras_core_export(\"keras_core.ops.extract_sequences\")\n+def extract_sequences(x, sequence_length, sequence_stride):\n+    \"\"\"Expands the dimension of last axis into sequences of `sequence_length`.\n+\n+    Slides a window of size `sequence_length` over the last axis of the input\n+    with a stride of `sequence_stride`, replacing the last axis with\n+    `[num_sequences, sequence_length]` sequences.\n+\n+    If the dimension along the last axis is N, the number of sequences can be\n+    computed by:\n+\n+    `num_sequences = 1 + (N - sequence_length) // sequence_stride`\n+\n+    Args:\n+        x: Input tensor.\n+        sequence_length: An integer representing the sequences length.\n+        sequence_stride: An integer representing the sequences hop size.\n+\n+    Returns:\n+        A tensor of sequences with shape [..., num_sequences, sequence_length].\n+\n+    Example:\n+\n+    >>> x = keras_core.ops.convert_to_tensor([1, 2, 3, 4, 5, 6])\n+    >>> extract_sequences(x, 3, 2)\n+    array([[1, 2, 3],\n+       [3, 4, 5]])\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return ExtractSequences(sequence_length, sequence_stride).symbolic_call(\n+            x\n+        )\n+    return backend.math.extract_sequences(x, sequence_length, sequence_stride)\n+\n+\n class FFT(Operation):\n     def compute_output_spec(self, x):\n         if not isinstance(x, (tuple, list)) or len(x) != 2:\n@@ -452,6 +516,175 @@ def fft2(x):\n     return backend.math.fft2(x)\n \n \n+class RFFT(Operation):\n+    def __init__(self, fft_length=None):\n+        super().__init__()\n+        self.fft_length = fft_length\n+\n+    def compute_output_spec(self, x):\n+        # We are calculating 1D RFFT. Hence, rank >= 1.\n+        if len(x.shape) < 1:\n+            raise ValueError(\n+                f\"Input should have rank >= 1. \"\n+                f\"Received: input.shape = {x.shape}\"\n+            )\n+\n+        if self.fft_length is not None:\n+            new_last_dimension = self.fft_length // 2 + 1\n+        else:\n+            new_last_dimension = x.shape[-1] // 2 + 1\n+        new_shape = x.shape[:-1] + (new_last_dimension,)\n+\n+        return (\n+            KerasTensor(shape=new_shape, dtype=x.dtype),\n+            KerasTensor(shape=new_shape, dtype=x.dtype),\n+        )\n+\n+    def call(self, x):\n+        return backend.math.rfft(x, fft_length=self.fft_length)\n+\n+\n+@keras_core_export(\"keras_core.ops.rfft\")\n+def rfft(x, fft_length=None):\n+    \"\"\"Real-valued Fast Fourier Transform along the last axis of the input.\n+\n+    Computes the 1D Discrete Fourier Transform of a real-valued signal over the\n+    inner-most dimension of input.\n+\n+    Since the Discrete Fourier Transform of a real-valued signal is\n+    Hermitian-symmetric, RFFT only returns the `fft_length / 2 + 1` unique\n+    components of the FFT: the zero-frequency term, followed by the\n+    `fft_length / 2` positive-frequency terms.\n+\n+    Along the axis RFFT is computed on, if `fft_length` is smaller than the\n+    corresponding dimension of the input, the dimension is cropped. If it is\n+    larger, the dimension is padded with zeros.\n+\n+    Args:\n+        x: Input tensor.\n+        fft_length: An integer representing the number of the fft length. If not\n+            specified, it is inferred from the length of the last axis of `x`.\n+            Defaults to `None`.\n+\n+    Returns:\n+        A tuple containing two tensors - the real and imaginary parts of the\n+        output.\n+\n+    Examples:\n+\n+    >>> x = keras_core.ops.convert_to_tensor([0.0, 1.0, 2.0, 3.0, 4.0])\n+    >>> rfft(x)\n+    (array([10.0, -2.5, -2.5]), array([0.0, 3.4409548, 0.81229924]))\n+\n+    >>> rfft(x, 3)\n+    (array([3.0, -1.5]), array([0.0, 0.8660254]))\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return RFFT(fft_length).symbolic_call(x)\n+    return backend.math.rfft(x, fft_length)\n+\n+\n+class STFT(Operation):\n+    def __init__(\n+        self,\n+        sequence_length,\n+        sequence_stride,\n+        fft_length,\n+        window=\"hann\",\n+        center=True,\n+    ):\n+        super().__init__()\n+        self.sequence_length = sequence_length\n+        self.sequence_stride = sequence_stride\n+        self.fft_length = fft_length\n+        self.window = window\n+        self.center = center\n+\n+    def compute_output_spec(self, x):\n+        if len(x.shape) < 1:\n+            raise ValueError(\n+                f\"Input should have rank >= 1. \"\n+                f\"Received: input shape = {x.shape}\"\n+            )\n+        if x.shape[-1] is not None:\n+            padded = 0 if self.center is False else (self.fft_length // 2) * 2\n+            num_sequences = (\n+                1\n+                + (x.shape[-1] + padded - self.fft_length)\n+                // self.sequence_stride\n+            )\n+        else:\n+            num_sequences = None\n+        new_shape = x.shape[:-1] + (num_sequences, self.fft_length // 2 + 1)\n+        return (\n+            KerasTensor(shape=new_shape, dtype=x.dtype),\n+            KerasTensor(shape=new_shape, dtype=x.dtype),\n+        )\n+\n+    def call(self, x):\n+        return backend.math.stft(\n+            x,\n+            sequence_length=self.sequence_length,\n+            sequence_stride=self.sequence_stride,\n+            fft_length=self.fft_length,\n+            window=self.window,\n+            center=self.center,\n+        )\n+\n+\n+@keras_core_export(\"keras_core.ops.stft\")\n+def stft(\n+    x, sequence_length, sequence_stride, fft_length, window=\"hann\", center=True\n+):\n+    \"\"\"Short-Time Fourier Transform along the last axis of the input.\n+\n+    The STFT computes the Fourier transform of short overlapping windows of the\n+    input. This giving frequency components of the signal as they change over\n+    time.\n+\n+    Args:\n+        x: Input tensor.\n+        sequence_length: An integer representing the sequence length.\n+        sequence_stride: An integer representing the sequence hop size.\n+        fft_length: An integer representing the size of the FFT to apply. If not\n+            specified, uses the smallest power of 2 enclosing `sequence_length`.\n+        window: A string, a tensor of the window or `None`. If `window` is a\n+            string, available values are `\"hann\"` and `\"hamming\"`. If `window`\n+            is a tensor, it will be used directly as the window and its length\n+            must be `sequence_length`. If `window` is `None`, no windowing is\n+            used. Defaults to `\"hann\"`.\n+        center: Whether to pad `x` on both sides so that the t-th sequence is\n+            centered at time `t * sequence_stride`. Otherwise, the t-th sequence\n+            begins at time `t * sequence_stride`. Defaults to `True`.\n+\n+    Returns:\n+        A tuple containing two tensors - the real and imaginary parts of the\n+        STFT output.\n+\n+    Example:\n+\n+    >>> x = keras_core.ops.convert_to_tensor([0.0, 1.0, 2.0, 3.0, 4.0])\n+    >>> stft(x, 3, 2, 3)\n+    (array([[0.75, -0.375],\n+       [3.75, -1.875],\n+       [5.25, -2.625]]), array([[0.0, 0.64951905],\n+       [0.0, 0.64951905],\n+       [0.0, -0.64951905]]))\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return STFT(\n+            sequence_length, sequence_stride, fft_length, center, window\n+        ).symbolic_call(x)\n+    return backend.math.stft(\n+        x,\n+        sequence_length=sequence_length,\n+        sequence_stride=sequence_stride,\n+        fft_length=fft_length,\n+        window=window,\n+        center=center,\n+    )\n+\n+\n class Rsqrt(Operation):\n     \"\"\"Computes reciprocal of square root of x element-wise.\n \n\n@@ -1,5 +1,7 @@\n import numpy as np\n import pytest\n+import scipy.signal\n+from absl.testing import parameterized\n \n from keras_core import backend\n from keras_core import testing\n@@ -7,6 +9,60 @@ from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.ops import math as kmath\n \n \n+def _stft(\n+    x, sequence_length, sequence_stride, fft_length, window=\"hann\", center=True\n+):\n+    # pure numpy version of stft\n+    if backend.standardize_dtype(x.dtype) not in {\"float32\", \"float64\"}:\n+        raise TypeError(\n+            \"Invalid input type. Expected `float32` or `float64`. \"\n+            f\"Received: input type={x.dtype}\"\n+        )\n+    if fft_length < sequence_length:\n+        raise ValueError(\n+            \"`fft_length` must equal or larger than `sequence_length`. \"\n+            f\"Received: sequence_length={sequence_length}, \"\n+            f\"fft_length={fft_length}\"\n+        )\n+\n+    if center:\n+        pad_width = [(0, 0) for _ in range(len(x.shape))]\n+        pad_width[-1] = (fft_length // 2, fft_length // 2)\n+        if backend.backend() != \"torch\" or len(x.shape) < 3:\n+            x = np.pad(x, pad_width, mode=\"reflect\")\n+        else:\n+            # torch not support reflect padding for N-D cases when N >= 3\n+            x = np.pad(x, pad_width, mode=\"constant\")\n+\n+    # extract_sequences\n+    *batch_shape, _ = x.shape\n+    batch_shape = list(batch_shape)\n+    shape = x.shape[:-1] + (\n+        (x.shape[-1] - (fft_length - sequence_stride)) // sequence_stride,\n+        fft_length,\n+    )\n+    strides = x.strides[:-1] + (sequence_stride * x.strides[-1], x.strides[-1])\n+    x = np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides)\n+    x = np.reshape(x, (*batch_shape, *x.shape[-2:]))\n+\n+    if window is not None:\n+        if isinstance(window, str):\n+            window = scipy.signal.get_window(window, sequence_length)\n+        win = np.array(window, dtype=x.dtype)\n+        if len(win.shape) != 1 or win.shape[-1] != sequence_length:\n+            raise ValueError(\n+                \"The shape of `window` must be equal to [sequence_length].\"\n+                f\"Received: window shape={win.shape}\"\n+            )\n+        l_pad = (fft_length - sequence_length) // 2\n+        r_pad = fft_length - sequence_length - l_pad\n+        win = np.pad(win, [[l_pad, r_pad]])\n+        x = np.multiply(x, win)\n+\n+    x = np.fft.rfft(x, fft_length)\n+    return np.real(x), np.imag(x)\n+\n+\n class MathOpsDynamicShapeTest(testing.TestCase):\n     def test_segment_sum(self):\n         data = KerasTensor((None, 4), dtype=\"float32\")\n@@ -64,6 +120,22 @@ class MathOpsDynamicShapeTest(testing.TestCase):\n         self.assertEqual(q.shape, qref_shape)\n         self.assertEqual(r.shape, rref_shape)\n \n+    def test_extract_sequences(self):\n+        # Defined dimension\n+        x = KerasTensor((None, 32), dtype=\"float32\")\n+        sequence_length = 3\n+        sequence_stride = 2\n+        outputs = kmath.extract_sequences(x, sequence_length, sequence_stride)\n+        num_sequences = 1 + (x.shape[-1] - sequence_length) // sequence_stride\n+        self.assertEqual(outputs.shape, (None, num_sequences, sequence_length))\n+\n+        # Undefined dimension\n+        x = KerasTensor((None, None), dtype=\"float32\")\n+        sequence_length = 3\n+        sequence_stride = 2\n+        outputs = kmath.extract_sequences(x, sequence_length, sequence_stride)\n+        self.assertEqual(outputs.shape, (None, None, sequence_length))\n+\n     def test_fft(self):\n         real = KerasTensor((None, 4, 3), dtype=\"float32\")\n         imag = KerasTensor((None, 4, 3), dtype=\"float32\")\n@@ -82,6 +154,30 @@ class MathOpsDynamicShapeTest(testing.TestCase):\n         self.assertEqual(real_output.shape, ref_shape)\n         self.assertEqual(imag_output.shape, ref_shape)\n \n+    def test_rfft(self):\n+        x = KerasTensor((None, 4, 3), dtype=\"float32\")\n+        real_output, imag_output = kmath.rfft(x)\n+        ref = np.fft.rfft(np.ones((2, 4, 3)))\n+        ref_shape = (None,) + ref.shape[1:]\n+        self.assertEqual(real_output.shape, ref_shape)\n+        self.assertEqual(imag_output.shape, ref_shape)\n+\n+    def test_stft(self):\n+        x = KerasTensor((None, 32), dtype=\"float32\")\n+        sequence_length = 10\n+        sequence_stride = 3\n+        fft_length = 15\n+        real_output, imag_output = kmath.stft(\n+            x, sequence_length, sequence_stride, fft_length\n+        )\n+        real_ref, imag_ref = _stft(\n+            np.ones((2, 32)), sequence_length, sequence_stride, fft_length\n+        )\n+        real_ref_shape = (None,) + real_ref.shape[1:]\n+        imag_ref_shape = (None,) + imag_ref.shape[1:]\n+        self.assertEqual(real_output.shape, real_ref_shape)\n+        self.assertEqual(imag_output.shape, imag_ref_shape)\n+\n     def test_rsqrt(self):\n         x = KerasTensor([None, 3])\n         self.assertEqual(kmath.rsqrt(x).shape, (None, 3))\n@@ -148,6 +244,14 @@ class MathOpsStaticShapeTest(testing.TestCase):\n         self.assertEqual(q.shape, qref.shape)\n         self.assertEqual(r.shape, rref.shape)\n \n+    def test_extract_sequences(self):\n+        x = KerasTensor((10, 16), dtype=\"float32\")\n+        sequence_length = 3\n+        sequence_stride = 2\n+        outputs = kmath.extract_sequences(x, sequence_length, sequence_stride)\n+        num_sequences = 1 + (x.shape[-1] - sequence_length) // sequence_stride\n+        self.assertEqual(outputs.shape, (10, num_sequences, sequence_length))\n+\n     def test_fft(self):\n         real = KerasTensor((2, 4, 3), dtype=\"float32\")\n         imag = KerasTensor((2, 4, 3), dtype=\"float32\")\n@@ -164,12 +268,33 @@ class MathOpsStaticShapeTest(testing.TestCase):\n         self.assertEqual(real_output.shape, ref.shape)\n         self.assertEqual(imag_output.shape, ref.shape)\n \n+    def test_rfft(self):\n+        x = KerasTensor((2, 4, 3), dtype=\"float32\")\n+        real_output, imag_output = kmath.rfft(x)\n+        ref = np.fft.rfft(np.ones((2, 4, 3)))\n+        self.assertEqual(real_output.shape, ref.shape)\n+        self.assertEqual(imag_output.shape, ref.shape)\n+\n     def test_rsqrt(self):\n         x = KerasTensor([4, 3], dtype=\"float32\")\n         self.assertEqual(kmath.rsqrt(x).shape, (4, 3))\n \n+    def test_stft(self):\n+        x = KerasTensor((2, 32), dtype=\"float32\")\n+        sequence_length = 10\n+        sequence_stride = 3\n+        fft_length = 15\n+        real_output, imag_output = kmath.stft(\n+            x, sequence_length, sequence_stride, fft_length\n+        )\n+        real_ref, imag_ref = _stft(\n+            np.ones((2, 32)), sequence_length, sequence_stride, fft_length\n+        )\n+        self.assertEqual(real_output.shape, real_ref.shape)\n+        self.assertEqual(imag_output.shape, imag_ref.shape)\n \n-class MathOpsCorrectnessTest(testing.TestCase):\n+\n+class MathOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n     @pytest.mark.skipif(\n         backend.backend() == \"jax\",\n         reason=\"JAX does not support `num_segments=None`.\",\n@@ -379,6 +504,35 @@ class MathOpsCorrectnessTest(testing.TestCase):\n         self.assertAllClose(qref, q)\n         self.assertAllClose(rref, r)\n \n+    def test_extract_sequences(self):\n+        # Test 1D case.\n+        x = np.random.random((10,))\n+        sequence_length = 3\n+        sequence_stride = 2\n+        output = kmath.extract_sequences(x, sequence_length, sequence_stride)\n+\n+        num_sequences = 1 + (x.shape[-1] - sequence_length) // sequence_stride\n+        expected = np.zeros(shape=(num_sequences, sequence_length))\n+        pos = 0\n+        for i in range(num_sequences):\n+            expected[i] = x[pos : pos + sequence_length]\n+            pos += sequence_stride\n+        self.assertAllClose(output, expected)\n+\n+        # Test N-D case.\n+        x = np.random.random((4, 8))\n+        sequence_length = 3\n+        sequence_stride = 2\n+        output = kmath.extract_sequences(x, sequence_length, sequence_stride)\n+\n+        num_sequences = 1 + (x.shape[-1] - sequence_length) // sequence_stride\n+        expected = np.zeros(shape=(4, num_sequences, sequence_length))\n+        pos = 0\n+        for i in range(num_sequences):\n+            expected[:, i] = x[:, pos : pos + sequence_length]\n+            pos += sequence_stride\n+        self.assertAllClose(output, expected)\n+\n     def test_fft(self):\n         real = np.random.random((2, 4, 3))\n         imag = np.random.random((2, 4, 3))\n@@ -403,6 +557,62 @@ class MathOpsCorrectnessTest(testing.TestCase):\n         self.assertAllClose(real_ref, real_output)\n         self.assertAllClose(imag_ref, imag_output)\n \n+    @parameterized.parameters([(None,), (3,), (15,)])\n+    def test_rfft(self, n):\n+        # Test 1D.\n+        x = np.random.random((10,))\n+        real_output, imag_output = kmath.rfft(x, fft_length=n)\n+        ref = np.fft.rfft(x, n=n)\n+        real_ref = np.real(ref)\n+        imag_ref = np.imag(ref)\n+        self.assertAllClose(real_ref, real_output, atol=1e-5, rtol=1e-5)\n+        self.assertAllClose(imag_ref, imag_output, atol=1e-5, rtol=1e-5)\n+\n+        # Test N-D case.\n+        x = np.random.random((2, 3, 10))\n+        real_output, imag_output = kmath.rfft(x, fft_length=n)\n+        ref = np.fft.rfft(x, n=n)\n+        real_ref = np.real(ref)\n+        imag_ref = np.imag(ref)\n+        self.assertAllClose(real_ref, real_output, atol=1e-5, rtol=1e-5)\n+        self.assertAllClose(imag_ref, imag_output, atol=1e-5, rtol=1e-5)\n+\n+    @parameterized.parameters(\n+        [\n+            (32, 8, 32, \"hann\", True),\n+            (8, 8, 16, \"hann\", True),\n+            (4, 4, 7, \"hann\", True),\n+            (32, 8, 32, \"hamming\", True),\n+            (32, 8, 32, \"hann\", False),\n+            (32, 8, 32, np.ones((32,)), True),\n+            (32, 8, 32, None, True),\n+        ]\n+    )\n+    def test_stft(\n+        self, sequence_length, sequence_stride, fft_length, window, center\n+    ):\n+        # Test 1D case.\n+        x = np.random.random((32,))\n+        real_output, imag_output = kmath.stft(\n+            x, sequence_length, sequence_stride, fft_length, window, center\n+        )\n+        real_ref, imag_ref = _stft(\n+            x, sequence_length, sequence_stride, fft_length, window, center\n+        )\n+        self.assertAllClose(real_ref, real_output, atol=1e-5, rtol=1e-5)\n+        self.assertAllClose(imag_ref, imag_output, atol=1e-5, rtol=1e-5)\n+\n+        # Test N-D case.\n+        x = np.random.random((2, 3, 32))\n+        real_output, imag_output = kmath.stft(\n+            x, sequence_length, sequence_stride, fft_length, window, center\n+        )\n+        real_ref, imag_ref = _stft(\n+            x, sequence_length, sequence_stride, fft_length, window, center\n+        )\n+        self.assertAllClose(real_ref, real_output, atol=1e-5, rtol=1e-5)\n+        self.assertAllClose(imag_ref, imag_output, atol=1e-5, rtol=1e-5)\n+\n     @pytest.mark.skipif(\n         backend.backend() == \"numpy\",\n         reason=\"Numpy does not support rsqrt.\",\n\n@@ -39,3 +39,4 @@ class LazyModule:\n tensorflow = LazyModule(\"tensorflow\")\n gfile = LazyModule(\"tensorflow.io.gfile\", pip_name=\"tensorflow\")\n tensorflow_io = LazyModule(\"tensorflow_io\")\n+scipy = LazyModule(\"scipy\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#40886394d30919d2656df1d13a8099de82574c21", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 100 | Lines Deleted: 208 | Files Changed: 5 | Hunks: 36 | Methods Changed: 37 | Complexity Δ (Sum/Max): -23/1 | Churn Δ: 308 | Churn Cumulative: 2662 | Contributors (this commit): 6 | Commits (past 90d): 27 | Contributors (cumulative): 10 | DMM Complexity: 0.0\n\nDIFF:\n@@ -115,4 +115,4 @@ class LayerNormalizationTest(testing.TestCase):\n         )\n         inputs = np.arange(5).astype(\"float32\")[None, :]\n         out = layer(inputs)\n-        self.assertAllClose(out, [[0., 0.70693, 1.41386, 2.12079, 2.82772]])\n+        self.assertAllClose(out, [[0.0, 0.70693, 1.41386, 2.12079, 2.82772]])\n\n@@ -560,9 +560,11 @@ class IndexLookup(Layer):\n             output_shape = (inputs.shape[0], depth)\n         return backend.KerasTensor(output_shape, dtype=output_dtype)\n \n-    def adapt(self, data):\n+    def adapt(self, data, steps=None):\n         self.reset_state()\n         if isinstance(data, tf.data.Dataset):\n+            if steps is not None:\n+                data = data.take(steps)\n             for batch in data:\n                 self.update_state(batch)\n         else:\n@@ -766,7 +768,7 @@ class IndexLookup(Layer):\n             lookup_checks.append(assertion)\n         elif self.num_oov_indices > 1:\n             # If we have multiple oov indices, we need a further hashing step.\n-            if self._key_dtype.is_integer:\n+            if tf.as_dtype(self._key_dtype).is_integer:\n                 oov_indices = tf.math.floormod(inputs, self.num_oov_indices)\n             else:\n                 oov_indices = tf.strings.to_hash_bucket_fast(\n\n@@ -2,13 +2,13 @@ import numpy as np\n \n from keras_core import backend\n from keras_core.api_export import keras_core_export\n-from keras_core.layers.layer import Layer\n+from keras_core.layers.preprocessing.index_lookup import IndexLookup\n from keras_core.utils import backend_utils\n from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.IntegerLookup\")\n-class IntegerLookup(Layer):\n+class IntegerLookup(IndexLookup):\n     \"\"\"A preprocessing layer that maps integers to (possibly encoded) indices.\n \n     This layer maps a set of arbitrary integer input tokens into indexed integer\n@@ -315,14 +315,29 @@ class IntegerLookup(Layer):\n                 \"Layer IntegerLookup requires TensorFlow. \"\n                 \"Install it via `pip install tensorflow`.\"\n             )\n-\n-        super().__init__(name=name)\n+        if max_tokens is not None and max_tokens <= 1:\n+            raise ValueError(\n+                \"If `max_tokens` is set for `IntegerLookup`, it must be \"\n+                f\"greater than 1. Received: max_tokens={max_tokens}.\"\n+            )\n+        if num_oov_indices < 0:\n+            raise ValueError(\n+                \"The value of `num_oov_indices` argument for `IntegerLookup` \"\n+                \"must >= 0. Received num_oov_indices=\"\n+                f\"{num_oov_indices}.\"\n+            )\n         if sparse and backend.backend() != \"tensorflow\":\n             raise ValueError(\n                 \"`sparse` can only be set to True with the \"\n                 \"TensorFlow backend.\"\n             )\n-        self.layer = tf.keras.layers.IntegerLookup(\n+        if vocabulary_dtype != \"int64\":\n+            raise ValueError(\n+                \"Only vocabulary_dtype='int64' is supported \"\n+                \"at this time. Received: \"\n+                f\"vocabulary_dtype={vocabulary_dtype}\"\n+            )\n+        super().__init__(\n             max_tokens=max_tokens,\n             num_oov_indices=num_oov_indices,\n             mask_token=mask_token,\n@@ -341,7 +356,7 @@ class IntegerLookup(Layer):\n         self._allow_non_tensor_positional_args = True\n         self.supports_jit = False\n \n-    def adapt(self, data, batch_size=None, steps=None):\n+    def adapt(self, data, steps=None):\n         \"\"\"Computes a vocabulary of interger terms from tokens in a dataset.\n \n         Calling `adapt()` on an `IntegerLookup` layer is an alternative to\n@@ -362,61 +377,18 @@ class IntegerLookup(Layer):\n             data: The data to train on. It can be passed either as a\n                 batched `tf.data.Dataset`, as a list of integers,\n                 or as a NumPy array.\n-            batch_size: Integer or `None`.\n-                Number of samples per state update.\n-                If unspecified, `batch_size` will default to 32.\n-                Do not specify the `batch_size` if your data is in the\n-                form of a `tf.data.Dataset`\n-                (it is expected to be already batched).\n             steps: Integer or `None`.\n-                Total number of steps (batches of samples)\n-                When training with input tensors such as\n-                the default `None` is equal to\n-                the number of samples in your dataset divided by\n-                the batch size, or 1 if that cannot be determined.\n+                Total number of steps (batches of samples) to process.\n                 If `data` is a `tf.data.Dataset`, and `steps` is `None`,\n                 `adapt()` will run until the input dataset is exhausted.\n                 When passing an infinitely\n                 repeating dataset, you must specify the `steps` argument. This\n                 argument is not supported with array inputs or list inputs.\n         \"\"\"\n-        self.layer.adapt(data, batch_size=batch_size, steps=steps)\n-\n-    def update_state(self, data):\n-        self.layer.update_state(data)\n-\n-    def finalize_state(self):\n-        self.layer.finalize_state()\n-\n-    def reset_state(self):\n-        self.layer.reset_state()\n-\n-    def get_vocabulary(self, include_special_tokens=True):\n-        \"\"\"Returns the current vocabulary of the layer.\n-\n-        Args:\n-            include_special_tokens: If `True`, the returned vocabulary\n-                will include the padding and OOV tokens,\n-                and a term's index in the vocabulary will equal\n-                the term's index when calling the layer. If `False`, the\n-                returned vocabulary will not include any padding\n-                or OOV tokens.\n-        \"\"\"\n-        return self.layer.get_vocabulary(\n-            include_special_tokens=include_special_tokens\n-        )\n-\n-    def vocabulary_size(self):\n-        \"\"\"Gets the current size of the layer's vocabulary.\n-\n-        Returns:\n-            The integer size of the vocabulary, including optional\n-            mask and OOV indices.\n-        \"\"\"\n-        return self.layer.vocabulary_size()\n+        super().adapt(data, steps=steps)\n \n     def get_config(self):\n-        config = self.layer.get_config()\n+        config = super().get_config()\n         if config[\"oov_token\"] is not None:\n             config[\"oov_token\"] = int(config[\"oov_token\"])\n         if config[\"mask_token\"] is not None:\n@@ -425,59 +397,13 @@ class IntegerLookup(Layer):\n             config[\"vocabulary\"] = [int(v) for v in config[\"vocabulary\"]]\n         return config\n \n-    def set_vocabulary(self, vocabulary, idf_weights=None):\n-        \"\"\"Sets vocabulary (and optionally document frequency) for this layer.\n-\n-        This method sets the vocabulary and IDF weights for this layer directly,\n-        instead of analyzing a dataset through `adapt()`. It should be used\n-        whenever the vocab (and optionally document frequency) information is\n-        already known. If vocabulary data is already present in the layer, this\n-        method will replace it.\n-\n-        Args:\n-            vocabulary: Either an array or a string path to a text file.\n-                If passing an array, can pass a tuple, list, 1D NumPy array,\n-                or 1D tensor containing the vocbulary terms.\n-                If passing a file path, the file should contain one line\n-                per term in the vocabulary.\n-            idf_weights: A tuple, list, 1D NumPy array, or 1D tensor of inverse\n-                document frequency weights with equal length to vocabulary.\n-                Must be set if `output_mode` is `\"tf_idf\"`.\n-                Should not be set otherwise.\n-        \"\"\"\n-        self.layer.set_vocabulary(vocabulary, idf_weights=idf_weights)\n-\n     def call(self, inputs):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n-        outputs = self.layer.call(inputs)\n+        outputs = super().call(inputs)\n         if (\n             backend.backend() != \"tensorflow\"\n             and not backend_utils.in_tf_graph()\n         ):\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n-\n-    def save_own_variables(self, store):\n-        if hasattr(self.layer, \"save_own_variables\"):\n-            self.layer.save_own_variables(store)\n-        else:\n-            self.layer._save_own_variables(store)\n-\n-    def load_own_variables(self, store):\n-        if hasattr(self.layer, \"load_own_variables\"):\n-            self.layer.load_own_variables(store)\n-        else:\n-            self.layer._load_own_variables(store)\n-\n-    def save_assets(self, dir_path):\n-        if hasattr(self.layer, \"save_assets\"):\n-            self.layer.save_assets(dir_path)\n-        else:\n-            self.layer._save_assets(dir_path)\n-\n-    def load_assets(self, dir_path):\n-        if hasattr(self.layer, \"save_assets\"):\n-            self.layer.load_assets(dir_path)\n-        else:\n-            self.layer._load_assets(dir_path)\n\n@@ -17,14 +17,61 @@ class IntegerLookupTest(testing.TestCase):\n         self.run_class_serialization_test(layer)\n \n     def test_adapt_flow(self):\n+        adapt_data = [1, 1, 1, 2, 2, 3]\n+        single_sample_input_data = [1, 2, 4]\n+        batch_input_data = [[1, 2, 4], [2, 3, 5]]\n+\n+        # int mode\n         layer = layers.IntegerLookup(\n             output_mode=\"int\",\n         )\n-        layer.adapt([1, 1, 1, 1, 2, 2, 2, 3, 3, 4])\n-        input_data = [2, 3, 4, 5]\n-        output = layer(input_data)\n+        layer.adapt(adapt_data)\n+        output = layer(single_sample_input_data)\n         self.assertTrue(backend.is_tensor(output))\n-        self.assertAllClose(output, np.array([2, 3, 4, 0]))\n+        self.assertAllClose(output, np.array([1, 2, 0]))\n+        output = layer(batch_input_data)\n+        self.assertTrue(backend.is_tensor(output))\n+        self.assertAllClose(output, np.array([[1, 2, 0], [2, 3, 0]]))\n+\n+        # one_hot mode\n+        layer = layers.IntegerLookup(\n+            output_mode=\"one_hot\",\n+        )\n+        layer.adapt(adapt_data)\n+        output = layer(single_sample_input_data)\n+        self.assertTrue(backend.is_tensor(output))\n+        self.assertAllClose(\n+            output, np.array([[0, 1, 0, 0], [0, 0, 1, 0], [1, 0, 0, 0]])\n+        )\n+\n+        # multi_hot mode\n+        layer = layers.IntegerLookup(\n+            output_mode=\"multi_hot\",\n+        )\n+        layer.adapt(adapt_data)\n+        output = layer(single_sample_input_data)\n+        self.assertTrue(backend.is_tensor(output))\n+        self.assertAllClose(output, np.array([1, 1, 1, 0]))\n+\n+        # tf_idf mode\n+        layer = layers.IntegerLookup(\n+            output_mode=\"tf_idf\",\n+        )\n+        layer.adapt(adapt_data)\n+        output = layer(single_sample_input_data)\n+        self.assertTrue(backend.is_tensor(output))\n+        self.assertAllClose(\n+            output, np.array([1.133732, 0.916291, 1.098612, 0.0])\n+        )\n+\n+        # count mode\n+        layer = layers.IntegerLookup(\n+            output_mode=\"count\",\n+        )\n+        layer.adapt(adapt_data)\n+        output = layer([1, 2, 3, 4, 1, 2, 1])\n+        self.assertTrue(backend.is_tensor(output))\n+        self.assertAllClose(output, np.array([1, 3, 2, 1]))\n \n     def test_fixed_vocabulary(self):\n         layer = layers.IntegerLookup(\n\n@@ -2,13 +2,13 @@ import numpy as np\n \n from keras_core import backend\n from keras_core.api_export import keras_core_export\n-from keras_core.layers.layer import Layer\n+from keras_core.layers.preprocessing.index_lookup import IndexLookup\n from keras_core.utils import backend_utils\n from keras_core.utils.module_utils import tensorflow as tf\n \n \n @keras_core_export(\"keras_core.layers.StringLookup\")\n-class StringLookup(Layer):\n+class StringLookup(IndexLookup):\n     \"\"\"A preprocessing layer that maps strings to (possibly encoded) indices.\n \n     This layer translates a set of arbitrary strings into integer output via a\n@@ -305,7 +305,6 @@ class StringLookup(Layer):\n         sparse=False,\n         encoding=\"utf-8\",\n         name=None,\n-        dtype=None,\n         **kwargs,\n     ):\n         if not tf.available:\n@@ -313,16 +312,12 @@ class StringLookup(Layer):\n                 \"Layer StringLookup requires TensorFlow. \"\n                 \"Install it via `pip install tensorflow`.\"\n             )\n-\n-        if output_mode == \"int\" and dtype is None:\n-            dtype = \"int64\"\n-        super().__init__(name=name)\n         if sparse and backend.backend() != \"tensorflow\":\n             raise ValueError(\n                 \"`sparse` can only be set to True with the \"\n                 \"TensorFlow backend.\"\n             )\n-        self.layer = tf.keras.layers.StringLookup(\n+        super().__init__(\n             max_tokens=max_tokens,\n             num_oov_indices=num_oov_indices,\n             mask_token=mask_token,\n@@ -333,16 +328,16 @@ class StringLookup(Layer):\n             output_mode=output_mode,\n             pad_to_max_tokens=pad_to_max_tokens,\n             sparse=sparse,\n-            encoding=encoding,\n             name=name,\n-            dtype=dtype,\n+            vocabulary_dtype=\"string\",\n             **kwargs,\n         )\n+        self.encoding = encoding\n         self._convert_input_args = False\n         self._allow_non_tensor_positional_args = True\n         self.supports_jit = False\n \n-    def adapt(self, data, batch_size=None, steps=None):\n+    def adapt(self, data, steps=None):\n         \"\"\"Computes a vocabulary of interger terms from tokens in a dataset.\n \n         Calling `adapt()` on a `StringLookup` layer is an alternative to passing\n@@ -363,115 +358,37 @@ class StringLookup(Layer):\n             data: The data to train on. It can be passed either as a\n                 batched `tf.data.Dataset`, as a list of strings,\n                 or as a NumPy array.\n-            batch_size: Integer or `None`.\n-                Number of samples per state update.\n-                If unspecified, `batch_size` will default to 32.\n-                Do not specify the `batch_size` if your data is in the\n-                form of a `tf.data.Dataset`\n-                (it is expected to be already batched).\n             steps: Integer or `None`.\n-                Total number of steps (batches of samples)\n-                When training with input tensors such as\n-                the default `None` is equal to\n-                the number of samples in your dataset divided by\n-                the batch size, or 1 if that cannot be determined.\n+                Total number of steps (batches of samples) to process.\n                 If `data` is a `tf.data.Dataset`, and `steps` is `None`,\n                 `adapt()` will run until the input dataset is exhausted.\n                 When passing an infinitely\n                 repeating dataset, you must specify the `steps` argument. This\n                 argument is not supported with array inputs or list inputs.\n         \"\"\"\n-        self.layer.adapt(data, batch_size=batch_size, steps=steps)\n+        super().adapt(data, steps=steps)\n \n-    def update_state(self, data):\n-        self.layer.update_state(data)\n-\n-    def finalize_state(self):\n-        self.layer.finalize_state()\n-\n-    def reset_state(self):\n-        self.layer.reset_state()\n-\n-    def get_vocabulary(self, include_special_tokens=True):\n-        \"\"\"Returns the current vocabulary of the layer.\n-\n-        Args:\n-            include_special_tokens: If `True`, the returned vocabulary\n-                will include the padding and OOV tokens,\n-                and a term's index in the vocabulary will equal\n-                the term's index when calling the layer. If `False`, the\n-                returned vocabulary will not include any padding\n-                or OOV tokens.\n-        \"\"\"\n-        return self.layer.get_vocabulary(\n-            include_special_tokens=include_special_tokens\n+    # Overridden methods from IndexLookup.\n+    def _tensor_vocab_to_numpy(self, vocabulary):\n+        vocabulary = vocabulary.numpy()\n+        return np.array(\n+            [tf.compat.as_text(x, self.encoding) for x in vocabulary]\n         )\n \n-    def vocabulary_size(self):\n-        \"\"\"Gets the current size of the layer's vocabulary.\n-\n-        Returns:\n-            The integer size of the vocabulary, including optional\n-            mask and OOV indices.\n-        \"\"\"\n-        return self.layer.vocabulary_size()\n-\n     def get_config(self):\n-        return self.layer.get_config()\n-\n-    def set_vocabulary(self, vocabulary, idf_weights=None):\n-        \"\"\"Sets vocabulary (and optionally document frequency) for this layer.\n-\n-        This method sets the vocabulary and IDF weights for this layer directly,\n-        instead of analyzing a dataset through `adapt()`. It should be used\n-        whenever the vocab (and optionally document frequency) information is\n-        already known. If vocabulary data is already present in the layer, this\n-        method will replace it.\n-\n-        Args:\n-            vocabulary: Either an array or a string path to a text file.\n-                If passing an array, can pass a tuple, list, 1D NumPy array,\n-                or 1D tensor containing the vocbulary terms.\n-                If passing a file path, the file should contain one line\n-                per term in the vocabulary.\n-            idf_weights: A tuple, list, 1D NumPy array, or 1D tensor of inverse\n-                document frequency weights with equal length to vocabulary.\n-                Must be set if `output_mode` is `\"tf_idf\"`.\n-                Should not be set otherwise.\n-        \"\"\"\n-        self.layer.set_vocabulary(vocabulary, idf_weights=idf_weights)\n+        config = {\"encoding\": self.encoding}\n+        base_config = super().get_config()\n+        # There is only one valid dtype for strings, so we don't expose this.\n+        del base_config[\"vocabulary_dtype\"]\n+        return {**base_config, **config}\n \n     def call(self, inputs):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n             inputs = tf.convert_to_tensor(np.array(inputs))\n-        outputs = self.layer.call(inputs)\n+        outputs = super().call(inputs)\n         if (\n             backend.backend() != \"tensorflow\"\n             and not backend_utils.in_tf_graph()\n         ):\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n-\n-    def save_own_variables(self, store):\n-        if hasattr(self.layer, \"save_own_variables\"):\n-            self.layer.save_own_variables(store)\n-        else:\n-            self.layer._save_own_variables(store)\n-\n-    def load_own_variables(self, store):\n-        if hasattr(self.layer, \"load_own_variables\"):\n-            self.layer.load_own_variables(store)\n-        else:\n-            self.layer._load_own_variables(store)\n-\n-    def save_assets(self, dir_path):\n-        if hasattr(self.layer, \"save_assets\"):\n-            self.layer.save_assets(dir_path)\n-        else:\n-            self.layer._save_assets(dir_path)\n-\n-    def load_assets(self, dir_path):\n-        if hasattr(self.layer, \"save_assets\"):\n-            self.layer.load_assets(dir_path)\n-        else:\n-            self.layer._load_assets(dir_path)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
