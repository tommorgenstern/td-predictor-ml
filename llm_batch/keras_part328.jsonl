{"custom_id": "keras#661cbd3e445ba6bf9b19be808d73041b93dc1b62", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 177 | Lines Deleted: 183 | Files Changed: 12 | Hunks: 137 | Methods Changed: 103 | Complexity Δ (Sum/Max): -7/2 | Churn Δ: 360 | Churn Cumulative: 32266 | Contributors (this commit): 170 | Commits (past 90d): 101 | Contributors (cumulative): 209 | DMM Complexity: 1.0\n\nDIFF:\n@@ -630,6 +630,30 @@ class Callback:\n   ...           callbacks=[MyCallback()])\n   >>> assert training_finished == True\n \n+  If you want to use `Callback` objects in a custom training loop:\n+\n+  1. You should pack all your callbacks into a single `callbacks.CallbackList`\n+     so they can all be called together.\n+  2. You will need to manually call all the `on_*` methods at the apropriate\n+     locations in your loop. Like this:\n+\n+     ```\n+     callbacks =  tf.keras.callbacks.CallbackList([...])\n+     callbacks.append(...)\n+\n+     callbacks.on_train_begin(...)\n+     for epoch in range(EPOCHS):\n+       callbacks.on_epoch_begin(epoch)\n+       for i, data in dataset.enumerate():\n+         callbacks.on_train_batch_begin(i)\n+         batch_logs = model.train_step(data)\n+         callbacks.on_train_batch_end(i, batch_logs)\n+       epoch_logs = ...\n+       callbacks.on_epoch_end(epoch, epoch_logs)\n+     final_logs=...\n+     callbacks.on_train_end(final_logs)\n+     ```\n+\n   Attributes:\n       params: Dict. Training parameters\n           (eg. verbosity, batch size, number of epochs...).\n\n@@ -44,13 +44,21 @@ class OptimizerTest(tf.test.TestCase, parameterized.TestCase):\n       v = tf.Variable([0., 0.])\n       optimizer = gradient_descent.SGD(0.1)\n \n+    class PerReplica(values.DistributedValues):\n+      \"\"\"Holds a map from replica to unsynchronized values.\"\"\"\n+\n+      @property\n+      def values(self):\n+        \"\"\"Returns the per replica values.\"\"\"\n+        return self._values\n+\n     @tf.function\n     def optimize():\n       with tf.compat.v1.device(distribution.extended.worker_devices[0]):\n         v1 = tf.convert_to_tensor([1., 1.])\n       with tf.compat.v1.device(distribution.extended.worker_devices[1]):\n         v2 = tf.convert_to_tensor([2., 2.])\n-      grads = values.PerReplica([v1, v2])\n+      grads = PerReplica([v1, v2])\n       def step_fn(grads):\n         optimizer.apply_gradients(\n             [(grads, v)],\n\n@@ -21,7 +21,6 @@ import itertools\n import json\n import os\n import warnings\n-from tensorflow.python.distribute import values as ds_values\n from tensorflow.python.eager import context\n from keras import backend\n from keras import callbacks as callbacks_module\n@@ -2769,7 +2768,7 @@ def reduce_per_replica(values, strategy, reduction='first'):\n     \"\"\"Reduce a single `PerReplica` object.\"\"\"\n     if reduction == 'concat' and _collective_all_reduce_multi_worker(strategy):\n       return _multi_worker_concat(v, strategy)\n-    if not isinstance(v, ds_values.PerReplica):\n+    if not _is_per_replica_instance(v):\n       return v\n     elif reduction == 'first':\n       return strategy.unwrap(v)[0]\n@@ -2823,7 +2822,7 @@ def _multi_worker_concat(v, strategy):\n   \"\"\"Order PerReplica objects for CollectiveAllReduceStrategy and concat.\"\"\"\n   replicas = strategy.gather(v, axis=0)\n   # v might not have the same shape on different replicas\n-  if isinstance(v, ds_values.PerReplica):\n+  if _is_per_replica_instance(v):\n     shapes = tf.concat([\n         tf.expand_dims(tf.compat.v1.shape(single_value)[0], axis=0)\n         for single_value in v.values\n@@ -2930,3 +2929,8 @@ def flatten_metrics_in_order(logs, metrics_names):\n   if len(results) == 1:\n     return results[0]\n   return results\n+\n+\n+def _is_per_replica_instance(obj):\n+  return (isinstance(obj, tf.distribute.DistributedValues) and\n+          isinstance(obj, tf.__internal__.CompositeTensor))\n\n@@ -273,14 +273,13 @@ class IndexLookup(base_preprocessing_layer.CombinerPreprocessingLayer):\n             value_index=value_index,\n             value_index_offset=self._token_start_index())\n \n-      self._table = self._static_table_class()(\n+      self._table = tf.lookup.StaticHashTable(\n           initializer, default_value=default_value)\n       self._table_handler = table_utils.TableHandler(\n           table=self._table,\n           mask_token=self._mask_key,\n           mask_value=self._mask_value,\n-          oov_tokens=oov_indices,\n-          use_v1_apis=self._use_v1_apis())\n+          oov_tokens=oov_indices)\n \n       tracked_table = self._add_trackable(self._table, trainable=False)\n \n@@ -293,8 +292,7 @@ class IndexLookup(base_preprocessing_layer.CombinerPreprocessingLayer):\n           name=(self._name + \"_index_table\"))\n       self._table_handler = table_utils.TableHandler(\n           table=self._table,\n-          oov_tokens=oov_indices,\n-          use_v1_apis=self._use_v1_apis())\n+          oov_tokens=oov_indices)\n       if vocabulary is not None:\n         self.set_vocabulary(vocabulary)\n       tracked_table = self._add_trackable(self._table, trainable=False)\n@@ -621,12 +619,6 @@ class IndexLookup(base_preprocessing_layer.CombinerPreprocessingLayer):\n   def _convert_to_ndarray(self, x):\n     return np.array(x) if isinstance(x, (list, tuple)) else x\n \n-  def _use_v1_apis(self):\n-    return False\n-\n-  def _static_table_class(self):\n-    return tf.lookup.StaticHashTable\n-\n   def _oov_start_index(self):\n     return 1 if self.mask_token is not None and self.output_mode == INT else 0\n \n\n@@ -32,10 +32,6 @@ from keras.layers.preprocessing import preprocessing_test_utils\n from keras.utils.generic_utils import CustomObjectScope\n \n \n-def get_layer_class():\n-  return index_lookup.IndexLookup\n-\n-\n def zip_and_sort(weight_values):\n   keys, values = weight_values\n   return sorted(zip(keys, values), key=lambda x: x[1])\n@@ -304,7 +300,7 @@ class IndexLookupLayerTest(keras_parameterized.TestCase,\n   def test_layer_end_to_end_with_adapt(self, vocab_data, input_data, kwargs,\n                                        use_dataset, expected_output,\n                                        input_dtype):\n-    cls = get_layer_class()\n+    cls = index_lookup.IndexLookup\n     if \"invert\" in kwargs and kwargs[\"invert\"]:\n       expected_output_dtype = kwargs[\"dtype\"]\n     elif \"output_mode\" in kwargs and kwargs[\"output_mode\"] != index_lookup.INT:\n@@ -365,7 +361,7 @@ class CategoricalEncodingInputTest(\n     expected_dense_shape = [3, 4]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string, sparse=True)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -391,7 +387,7 @@ class CategoricalEncodingInputTest(\n     expected_dense_shape = [3, 4]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.int64, sparse=True)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         dtype=tf.int64,\n         num_oov_indices=1,\n@@ -412,7 +408,7 @@ class CategoricalEncodingInputTest(\n     expected_output = [[2, 3, 5], [5, 4, 2, 1]]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string, ragged=True)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -431,7 +427,7 @@ class CategoricalEncodingInputTest(\n     expected_output = [[2, 3, 5], [5, 4, 2, 1]]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.int64, ragged=True)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         dtype=tf.int64,\n         num_oov_indices=1,\n@@ -450,7 +446,7 @@ class CategoricalEncodingInputTest(\n     expected_output = [[2, 3, 5], [5, 4, 2, 1]]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.int32, ragged=True)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         dtype=tf.int64,\n         num_oov_indices=1,\n@@ -478,7 +474,7 @@ class CategoricalEncodingMultiOOVTest(\n     expected_dense_shape = [3, 4]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string, sparse=True)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=2,\n         mask_token=\"\",\n@@ -504,7 +500,7 @@ class CategoricalEncodingMultiOOVTest(\n     expected_dense_shape = [3, 4]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.int64, sparse=True)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         dtype=tf.int64,\n         num_oov_indices=2,\n@@ -526,7 +522,7 @@ class CategoricalEncodingMultiOOVTest(\n     expected_output = [[3, 4, 6], [6, 5, 3, 2]]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string, ragged=True)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=2,\n         mask_token=\"\",\n@@ -545,7 +541,7 @@ class CategoricalEncodingMultiOOVTest(\n     expected_output = [[3, 4, 6], [6, 5, 3, 2]]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.int64, ragged=True)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         dtype=tf.int64,\n         num_oov_indices=2,\n@@ -570,7 +566,7 @@ class CategoricalEncodingAdaptTest(\n         dense_shape=[3, 4])\n     vocab_dataset = tf.data.Dataset.from_tensors(vocab_data)\n \n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -585,7 +581,7 @@ class CategoricalEncodingAdaptTest(\n                                               [\"fire\", \"michigan\"]])\n     vocab_dataset = tf.data.Dataset.from_tensors(vocab_data)\n \n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -607,7 +603,7 @@ class CategoricalEncodingAdaptTest(\n     expected_dense_shape = [3, 4]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.int64, sparse=True)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         dtype=tf.int64,\n         num_oov_indices=1,\n@@ -628,7 +624,7 @@ class CategoricalEncodingAdaptTest(\n     expected_output = [[2, 3, 5], [5, 4, 2, 1]]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string, ragged=True)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -647,7 +643,7 @@ class CategoricalEncodingAdaptTest(\n     expected_output = [[2, 3, 5], [5, 4, 2, 1]]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.int64, ragged=True)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         dtype=tf.int64,\n         num_oov_indices=1,\n@@ -669,7 +665,7 @@ class CategoricalEncodingAdaptTest(\n                                             tf.TensorShape([]))\n     batched_ds = ds.take(2)\n     input_t = keras.Input(shape=(), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=10,\n         num_oov_indices=0,\n         mask_token=None,\n@@ -699,7 +695,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     expected_output = [[2, 3, 4, 5], [5, 4, 2, 1]]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -713,7 +709,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n \n   def test_int_output_shape(self):\n     input_data = keras.Input(batch_size=16, shape=(4,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=2,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -729,7 +725,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     expected_output = [[1, 2, 3, 4], [4, 3, 1, 0]]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=None,\n@@ -748,7 +744,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     expected_output = [[1, 2, 3, -1], [4, 3, 1, -1]]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=0,\n         mask_token=\"\",\n@@ -767,7 +763,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     expected_output = [[2, 3, 4, 5], [5, 4, 2, 1]]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         vocabulary=vocab_data,\n         max_tokens=None,\n         num_oov_indices=1,\n@@ -790,7 +786,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     ]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=6,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -815,7 +811,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     ]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=5,\n         num_oov_indices=0,\n         mask_token=\"\",\n@@ -847,7 +843,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     ]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=5,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -878,7 +874,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     ]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -893,7 +889,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n \n   def test_binary_output_shape(self):\n     input_data = keras.Input(batch_size=16, shape=(4,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=2,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -914,7 +910,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     ]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=6,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -939,7 +935,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     ]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -954,7 +950,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n \n   def test_count_output_shape(self):\n     input_data = keras.Input(batch_size=16, shape=(4,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=2,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -977,7 +973,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     ]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=6,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1004,7 +1000,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     ]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1019,7 +1015,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n \n   def test_ifidf_output_shape(self):\n     input_data = keras.Input(batch_size=16, shape=(4,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=2,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1038,7 +1034,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     vocab_file = self._write_to_temp_file(\"temp\", vocab_data)\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         vocabulary=vocab_file,\n         max_tokens=None,\n         num_oov_indices=1,\n@@ -1065,7 +1061,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n \n     @tf.function\n     def compute(data):\n-      layer = get_layer_class()(\n+      layer = index_lookup.IndexLookup(\n           vocabulary=vocab_file,\n           max_tokens=None,\n           num_oov_indices=1,\n@@ -1083,7 +1079,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n \n     vocab_file = self._write_to_temp_file(\"temp\", vocab_data)\n \n-    file_layer = get_layer_class()(\n+    file_layer = index_lookup.IndexLookup(\n         vocabulary=vocab_file,\n         max_tokens=None,\n         num_oov_indices=1,\n@@ -1091,7 +1087,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n         oov_token=\"[OOV]\",\n         dtype=tf.string)\n \n-    list_layer = get_layer_class()(\n+    list_layer = index_lookup.IndexLookup(\n         vocabulary=vocab_data,\n         max_tokens=None,\n         num_oov_indices=1,\n@@ -1118,7 +1114,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n \n     vocab_file = self._write_to_temp_file(\"temp\", vocab_data)\n \n-    file_layer = get_layer_class()(\n+    file_layer = index_lookup.IndexLookup(\n         vocabulary=vocab_file,\n         max_tokens=None,\n         num_oov_indices=2,\n@@ -1126,7 +1122,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n         oov_token=\"[OOV]\",\n         dtype=tf.string)\n \n-    list_layer = get_layer_class()(\n+    list_layer = index_lookup.IndexLookup(\n         vocabulary=vocab_data,\n         max_tokens=None,\n         num_oov_indices=2,\n@@ -1152,7 +1148,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n \n     vocab_file = self._write_to_temp_file(\"temp\", vocab_data)\n \n-    file_layer = get_layer_class()(\n+    file_layer = index_lookup.IndexLookup(\n         vocabulary=vocab_file,\n         max_tokens=None,\n         num_oov_indices=2,\n@@ -1160,7 +1156,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n         oov_token=\"[OOV]\",\n         dtype=tf.string)\n \n-    list_layer = get_layer_class()(\n+    list_layer = index_lookup.IndexLookup(\n         vocabulary=vocab_data,\n         max_tokens=None,\n         num_oov_indices=2,\n@@ -1190,7 +1186,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     vocab_file = self._write_to_temp_file(\"temp\", vocab_data)\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         vocabulary=vocab_file,\n         max_tokens=None,\n         mask_token=None,\n@@ -1211,7 +1207,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     vocab_file = self._write_to_temp_file(\"temp\", vocab_data)\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         vocabulary=vocab_file,\n         max_tokens=None,\n         mask_token=None,\n@@ -1231,7 +1227,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n \n     vocab_file = self._write_to_temp_file(\"temp\", vocab_data)\n     idata = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         vocabulary=vocab_file,\n         max_tokens=None,\n         mask_token=None,\n@@ -1242,7 +1238,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n \n     input_data = keras.Input(shape=(None,), dtype=tf.int64)\n \n-    invert_layer = get_layer_class()(\n+    invert_layer = index_lookup.IndexLookup(\n         vocabulary=layer.get_vocabulary(),\n         max_tokens=None,\n         oov_token=\"[OOV]\",\n@@ -1262,7 +1258,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n \n     vocab_file = self._write_to_temp_file(\"temp\", vocab_data)\n     input_data = keras.Input(shape=(None,), dtype=tf.int64)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         vocabulary=vocab_file,\n         max_tokens=None,\n         num_oov_indices=1,\n@@ -1279,7 +1275,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n \n     vocab_file = self._write_to_temp_file(\"temp\", vocab_data)\n \n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         vocabulary=vocab_file,\n         max_tokens=None,\n         num_oov_indices=1,\n@@ -1303,7 +1299,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n     expected_output = [[2, 3, 4, 5], [5, 4, 2, 1]]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         vocabulary=vocab_data,\n         max_tokens=None,\n         num_oov_indices=1,\n@@ -1322,7 +1318,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n     expected_output = [[2, 3, 4, 5], [5, 4, 2, 1]]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         vocabulary=vocab_data,\n         max_tokens=None,\n         num_oov_indices=1,\n@@ -1336,7 +1332,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_vocab_with_max_cap(self):\n     vocab_data = [\"\", \"[OOV]\", \"wind\", \"and\", \"fire\"]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=5,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1349,7 +1345,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_int_vocab_with_max_cap(self):\n     vocab_data = [0, -1, 42, 1276, 1138]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=5,\n         num_oov_indices=1,\n         mask_token=0,\n@@ -1362,7 +1358,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_vocab_with_multiple_oov_indices(self):\n     vocab_data = [\"\", \"[OOV]\", \"[OOV]\", \"[OOV]\", \"wind\"]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=3,\n         mask_token=\"\",\n@@ -1374,7 +1370,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_int_vocab_with_multiple_oov_indices(self):\n     vocab_data = [0, -1, -1, -1, 42]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=3,\n         mask_token=0,\n@@ -1387,7 +1383,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n   def test_non_unique_vocab_fails(self):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\", \"fire\"]\n     with self.assertRaisesRegex(ValueError, \".*repeated term.*fire.*\"):\n-      _ = get_layer_class()(\n+      _ = index_lookup.IndexLookup(\n           vocabulary=vocab_data,\n           max_tokens=None,\n           num_oov_indices=1,\n@@ -1397,7 +1393,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_vocab_with_oov_and_wrong_mask_fails(self):\n     vocab_data = [\"custom_mask\", \"[OOV]\", \"earth\", \"wind\", \"and\", \"fire\"]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1408,7 +1404,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_vocab_with_oov_and_no_mask_fails(self):\n     vocab_data = [\"[OOV]\", \"earth\", \"wind\", \"and\", \"fire\"]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1419,7 +1415,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_vocab_with_mask_but_no_oov_fails(self):\n     vocab_data = [\"\", \"earth\", \"wind\", \"and\", \"fire\"]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1430,7 +1426,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_vocab_with_repeated_element_fails(self):\n     vocab_data = [\"earth\", \"earth\", \"wind\", \"and\", \"fire\"]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1441,7 +1437,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_vocab_with_reserved_oov_element_fails(self):\n     vocab_data = [\"earth\", \"test\", \"[OOV]\", \"wind\", \"and\", \"fire\"]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1452,7 +1448,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_vocab_with_reserved_mask_element_fails(self):\n     vocab_data = [\"earth\", \"mask_token\", \"wind\", \"and\", \"fire\"]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"mask_token\",\n@@ -1463,7 +1459,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_vocab_set_after_call_pad_to_max_false_fails(self):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1480,7 +1476,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n   def test_vocab_with_idf_weights_non_tfidf_output_fails(self):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n     weight_data = [1, 1, 1, 1, 1]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1494,7 +1490,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n   def test_vocab_with_idf_weights_length_mismatch_fails(self):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n     weight_data = [1, 1, 1, 1, 1]  # too long\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1507,7 +1503,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_vocab_without_idf_weights_tfidf_output_fails(self):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1521,7 +1517,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n   def test_non_unique_int_vocab_fails(self):\n     vocab_data = [12, 13, 14, 15, 15]\n     with self.assertRaisesRegex(ValueError, \"repeated term.*15\"):\n-      _ = get_layer_class()(\n+      _ = index_lookup.IndexLookup(\n           vocabulary=vocab_data,\n           max_tokens=None,\n           num_oov_indices=1,\n@@ -1531,7 +1527,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_int_vocab_with_oov_and_wrong_mask_fails(self):\n     vocab_data = [1234, -1, 11, 21, 13, 14]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=0,\n@@ -1542,7 +1538,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_int_vocab_with_oov_and_no_mask_fails(self):\n     vocab_data = [-1, 11, 12, 13, 14]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=0,\n@@ -1553,7 +1549,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_int_vocab_with_mask_but_no_oov_fails(self):\n     vocab_data = [0, 11, 12, 13, 14]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=0,\n@@ -1564,7 +1560,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_int_vocab_with_repeated_element_fails(self):\n     vocab_data = [11, 11, 34, 23, 124]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=0,\n@@ -1575,7 +1571,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_int_vocab_with_reserved_oov_element_fails(self):\n     vocab_data = [14, 38, -1, 34, 3, 84]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=0,\n@@ -1586,7 +1582,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_int_vocab_with_reserved_mask_element_fails(self):\n     vocab_data = [125, 0, 3, 4, 94]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=0,\n@@ -1597,7 +1593,7 @@ class IndexLookupVocabularyTest(keras_parameterized.TestCase,\n \n   def test_no_vocab_file_string_fails(self):\n     with self.assertRaisesRegex(ValueError, \".*non_existent_file.*\"):\n-      _ = get_layer_class()(\n+      _ = index_lookup.IndexLookup(\n           vocabulary=\"non_existent_file\",\n           max_tokens=None,\n           num_oov_indices=1,\n@@ -1618,7 +1614,7 @@ class IndexLookupInverseVocabularyTest(\n                                 [\"fire\", \"and\", \"earth\", \"[OOV]\"]])\n \n     input_data = keras.Input(shape=(None,), dtype=tf.int64)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         vocabulary=vocab_data,\n         max_tokens=None,\n         num_oov_indices=1,\n@@ -1633,7 +1629,7 @@ class IndexLookupInverseVocabularyTest(\n \n   def test_vocab_with_max_cap(self):\n     vocab_data = [\"\", \"[OOV]\", \"wind\", \"and\", \"fire\"]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=5,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1646,7 +1642,7 @@ class IndexLookupInverseVocabularyTest(\n \n   def test_int_vocab_with_max_cap(self):\n     vocab_data = [0, -1, 42, 1276, 1138]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=5,\n         num_oov_indices=1,\n         mask_token=0,\n@@ -1660,7 +1656,7 @@ class IndexLookupInverseVocabularyTest(\n   def test_non_unique_vocab_fails(self):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\", \"fire\"]\n     with self.assertRaisesRegex(ValueError, \".*repeated term.*fire.*\"):\n-      _ = get_layer_class()(\n+      _ = index_lookup.IndexLookup(\n           vocabulary=vocab_data,\n           max_tokens=None,\n           num_oov_indices=1,\n@@ -1671,7 +1667,7 @@ class IndexLookupInverseVocabularyTest(\n \n   def test_non_int_output_fails(self):\n     with self.assertRaisesRegex(ValueError, \"`output_mode` must be int\"):\n-      _ = get_layer_class()(\n+      _ = index_lookup.IndexLookup(\n           max_tokens=None,\n           num_oov_indices=1,\n           mask_token=\"\",\n@@ -1682,7 +1678,7 @@ class IndexLookupInverseVocabularyTest(\n \n   def test_vocab_with_repeated_element_fails(self):\n     vocab_data = [\"earth\", \"earth\", \"wind\", \"and\", \"fire\"]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1694,7 +1690,7 @@ class IndexLookupInverseVocabularyTest(\n \n   def test_vocab_with_reserved_mask_element_fails(self):\n     vocab_data = [\"earth\", \"mask_token\", \"wind\", \"and\", \"fire\"]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"mask_token\",\n@@ -1707,7 +1703,7 @@ class IndexLookupInverseVocabularyTest(\n   def test_non_unique_int_vocab_fails(self):\n     vocab_data = [12, 13, 14, 15, 15]\n     with self.assertRaisesRegex(ValueError, \".*repeated term.*15.*\"):\n-      _ = get_layer_class()(\n+      _ = index_lookup.IndexLookup(\n           vocabulary=vocab_data,\n           max_tokens=None,\n           num_oov_indices=1,\n@@ -1718,7 +1714,7 @@ class IndexLookupInverseVocabularyTest(\n \n   def test_int_vocab_with_repeated_element_fails(self):\n     vocab_data = [11, 11, 34, 23, 124]\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=0,\n@@ -1736,7 +1732,7 @@ class IndexLookupErrorTest(keras_parameterized.TestCase,\n   def test_too_long_vocab_fails_in_single_setting(self):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n \n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=4,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1748,7 +1744,7 @@ class IndexLookupErrorTest(keras_parameterized.TestCase,\n \n   def test_zero_max_tokens_fails(self):\n     with self.assertRaisesRegex(ValueError, \".*max_tokens.*\"):\n-      _ = get_layer_class()(\n+      _ = index_lookup.IndexLookup(\n           max_tokens=0,\n           num_oov_indices=1,\n           mask_token=\"\",\n@@ -1777,7 +1773,7 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n \n     # Build and validate a golden model.\n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1800,7 +1796,7 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n       keras.backend.clear_session()\n \n     loaded_model = keras.models.load_model(\n-        output_path, custom_objects={\"IndexLookup\": get_layer_class()})\n+        output_path, custom_objects={\"IndexLookup\": index_lookup.IndexLookup})\n \n     # Ensure that the loaded model is unique (so that the save/load is real)\n     self.assertIsNot(model, loaded_model)\n@@ -1818,7 +1814,7 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n \n     # Build and validate a golden model.\n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1850,7 +1846,7 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n \n     # Build and validate a golden model.\n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1892,7 +1888,7 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n \n     # Build and validate a golden model.\n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1934,7 +1930,7 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n \n     # Build and validate a golden model.\n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -1958,7 +1954,7 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n     tf.compat.v1.gfile.Remove(vocab_file)\n \n     loaded_model = keras.models.load_model(\n-        output_path, custom_objects={\"IndexLookup\": get_layer_class()})\n+        output_path, custom_objects={\"IndexLookup\": index_lookup.IndexLookup})\n \n     # Ensure that the loaded model is unique (so that the save/load is real)\n     self.assertIsNot(model, loaded_model)\n@@ -1986,7 +1982,7 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n       keras.backend.clear_session()\n \n     loaded_model = keras.models.load_model(\n-        output_path, custom_objects={\"IndexLookup\": get_layer_class()})\n+        output_path, custom_objects={\"IndexLookup\": index_lookup.IndexLookup})\n \n     # Ensure that the loaded model is unique (so that the save/load is real)\n     self.assertIsNot(model, loaded_model)\n@@ -2005,7 +2001,7 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n \n     # Build and validate a golden model.\n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -2029,7 +2025,7 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n     tf.compat.v1.gfile.Remove(vocab_file)\n \n     loaded_model = keras.models.load_model(\n-        output_path, custom_objects={\"IndexLookup\": get_layer_class()})\n+        output_path, custom_objects={\"IndexLookup\": index_lookup.IndexLookup})\n \n     # Ensure that the loaded model is unique (so that the save/load is real)\n     self.assertIsNot(model, loaded_model)\n@@ -2077,7 +2073,7 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n \n     # Build and validate a golden model.\n     input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = get_layer_class()(\n+    layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n         mask_token=\"\",\n@@ -2101,7 +2097,7 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n     tf.compat.v1.gfile.Remove(vocab_file)\n \n     loaded_model = keras.models.load_model(\n-        output_path, custom_objects={\"IndexLookup\": get_layer_class()})\n+        output_path, custom_objects={\"IndexLookup\": index_lookup.IndexLookup})\n \n     # Ensure that the loaded model is unique (so that the save/load is real)\n     self.assertIsNot(model, loaded_model)\n@@ -2129,7 +2125,7 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n       keras.backend.clear_session()\n \n     loaded_model = keras.models.load_model(\n-        output_path, custom_objects={\"IndexLookup\": get_layer_class()})\n+        output_path, custom_objects={\"IndexLookup\": index_lookup.IndexLookup})\n \n     # Ensure that the loaded model is unique (so that the save/load is real)\n     self.assertIsNot(model, loaded_model)\n@@ -2147,7 +2143,7 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n     expected_output = [[2, 3, 4, 5], [5, 4, 2, 1]]\n \n     # Build and validate a golden model.\n-    layer_cls = get_layer_class()\n+    layer_cls = index_lookup.IndexLookup\n     layer = layer_cls(\n         max_tokens=None,\n         num_oov_indices=1,\n\n@@ -19,7 +19,6 @@ import tensorflow.compat.v2 as tf\n import collections\n import os\n import numpy as np\n-from keras import backend\n from keras.utils import tf_utils\n from tensorflow.python.ops import lookup_ops\n \n@@ -31,23 +30,12 @@ class TableHandler(object):\n                table,\n                oov_tokens=None,\n                mask_token=None,\n-               mask_value=0,\n-               use_v1_apis=False):\n+               mask_value=0):\n     self.table = table\n-\n-    # If we are using V1 APIs, and the table has an initializer, we need to run\n-    # it. However, not all tables have initializers, so we try-except here.\n-    if use_v1_apis:\n-      try:\n-        backend.get_session().run(self.table.initializer)\n-      except AttributeError:\n-        pass\n-\n     self.mutable = isinstance(table, lookup_ops.MutableHashTable)\n     self.mask_token = mask_token\n     self.mask_value = mask_value\n \n-    self.use_v1_apis = use_v1_apis\n     if oov_tokens is None:\n       self.oov_tokens = oov_tokens\n     else:\n@@ -57,17 +45,17 @@ class TableHandler(object):\n \n   def data(self):\n     keys, values = self.table.export()\n-    return (self._eval(keys), self._eval(values))\n+    return (keys.numpy(), values.numpy())\n \n   def table_size(self):\n-    return self._eval(self.table.size())\n+    return self.table.size().numpy()\n \n   def clear(self):\n     if not self.mutable:\n       return RuntimeError(\"Unable to clear a statically-backed table.\")\n \n     keys, _ = self.table.export()\n-    self._run(self.table.remove(keys))\n+    self.table.remove(keys)\n \n   def insert(self, keys, values):\n     \"\"\"Insert values into the backed table.\"\"\"\n@@ -85,7 +73,7 @@ class TableHandler(object):\n     if values.shape.ndims != 1:\n       raise ValueError(\"`values` must be 1-dimensional, got an input with \"\n                        \" %s dimensions.\" % values.shape.ndims)\n-    self._run(self.table.insert(keys, values))\n+    self.table.insert(keys, values)\n \n   def _replace_oov_buckets(self, inputs, lookups):\n     \"\"\"Replace the default OOV value with one of the OOV bucket values.\"\"\"\n@@ -172,16 +160,6 @@ class TableHandler(object):\n     inputs = tf.convert_to_tensor(inputs)\n     return self._tensor_lookup(inputs)\n \n-  def _eval(self, tensor):\n-    if self.use_v1_apis:\n-      return backend.get_session().run(tensor)\n-    else:\n-      return tensor.numpy()\n-\n-  def _run(self, op):\n-    if self.use_v1_apis:\n-      backend.get_session().run(op)\n-\n \n def num_tokens_in_file(vocabulary_path):\n   \"\"\"Count the number of lines in a vocab file to get the number of tokens.\"\"\"\n\n@@ -32,8 +32,7 @@ def get_table(dtype=tf.string, oov_tokens=None):\n       value_dtype=tf.int64,\n       default_value=-7,\n       name=\"index_table\")\n-  return table_utils.TableHandler(\n-      table, oov_tokens, use_v1_apis=(not tf.executing_eagerly()))\n+  return table_utils.TableHandler(table, oov_tokens)\n \n \n def get_static_table(tmpdir,\n@@ -59,19 +58,14 @@ def get_static_table(tmpdir,\n       tf.int64,\n       tf.lookup.TextFileIndex.LINE_NUMBER,\n       value_index_offset=offset)\n-  if tf.executing_eagerly():\n   table = tf.lookup.StaticHashTable(init, default_value=-7)\n-  else:\n-    table = tf.compat.v1.lookup.StaticHashTable(init, default_value=-7)\n-\n   return table_utils.TableHandler(\n       table,\n       oov_tokens,\n-      mask_token=mask_token,\n-      use_v1_apis=(not tf.executing_eagerly()))\n+      mask_token=mask_token)\n \n \n-@keras_parameterized.run_all_keras_modes\n+@keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class CategoricalEncodingInputTest(\n     keras_parameterized.TestCase,\n     preprocessing_test_utils.PreprocessingLayerTest):\n@@ -148,7 +142,7 @@ class CategoricalEncodingInputTest(\n       table.insert(key_data, value_data)\n \n \n-@keras_parameterized.run_all_keras_modes\n+@keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class CategoricalEncodingMultiOOVTest(\n     keras_parameterized.TestCase,\n     preprocessing_test_utils.PreprocessingLayerTest):\n@@ -238,7 +232,7 @@ class CategoricalEncodingMultiOOVTest(\n     self.assertAllEqual(expected_output, output_data)\n \n \n-@keras_parameterized.run_all_keras_modes\n+@keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class IndexLookupOutputTest(keras_parameterized.TestCase,\n                             preprocessing_test_utils.PreprocessingLayerTest):\n \n@@ -278,7 +272,7 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     self.assertAllEqual(expected_output, output_data)\n \n \n-@keras_parameterized.run_all_keras_modes\n+@keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class StaticIndexLookupOutputTest(\n     keras_parameterized.TestCase,\n     preprocessing_test_utils.PreprocessingLayerTest):\n@@ -322,7 +316,7 @@ class StaticIndexLookupOutputTest(\n     self.assertAllEqual(expected_output, output_data)\n \n \n-@keras_parameterized.run_all_keras_modes\n+@keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class CategoricalEncodingStaticInputTest(\n     keras_parameterized.TestCase,\n     preprocessing_test_utils.PreprocessingLayerTest):\n\n@@ -194,21 +194,6 @@ class TextVectorization(base_preprocessing_layer.CombinerPreprocessingLayer):\n   This example instantiates a TextVectorization layer by passing a list\n   of vocabulary terms to the layer's __init__ method.\n \n-    input_array = np.array([[\"earth\", \"wind\", \"and\", \"fire\"],\n-                            [\"fire\", \"and\", \"earth\", \"michigan\"]])\n-    expected_output = [[2, 3, 4, 5], [5, 4, 2, 1]]\n-\n-    input_data = keras.Input(shape=(None,), dtype=dtypes.string)\n-    layer = get_layer_class()(\n-        max_tokens=None,\n-        standardize=None,\n-        split=None,\n-        output_mode=text_vectorization.INT,\n-        vocabulary=vocab_data)\n-    int_data = layer(input_data)\n-    model = keras.Model(inputs=input_data, outputs=int_data)\n-\n-    output_dataset = model.predict(input_array)\n   >>> vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n   >>> max_len = 4  # Sequence length to pad the outputs to.\n   >>>\n@@ -319,17 +304,13 @@ class TextVectorization(base_preprocessing_layer.CombinerPreprocessingLayer):\n     base_preprocessing_layer.keras_kpl_gauge.get_cell(\n         \"TextVectorization\").set(True)\n \n-    self._index_lookup_layer = self._get_index_lookup_class()(\n+    self._index_lookup_layer = string_lookup.StringLookup(\n         max_tokens=max_tokens,\n         vocabulary=vocabulary,\n         pad_to_max_tokens=pad_to_max_tokens,\n         output_mode=output_mode if output_mode is not None else INT,\n         vocabulary_size=vocabulary_size)\n \n-  def _get_index_lookup_class(self):\n-    return string_lookup.StringLookup\n-  # End of V1/V2 shim points.\n-\n   def _assert_same_type(self, expected_type, values, value_name):\n     if tf.as_dtype(expected_type) != tf.as_dtype(values.dtype):\n       raise RuntimeError(\"Expected %s type %s, got %s\" %\n\n@@ -23,7 +23,6 @@ from keras.mixed_precision import device_compatibility_check\n from keras.mixed_precision import loss_scale as keras_loss_scale_module\n from keras.utils import generic_utils\n from tensorflow.python.platform import tf_logging\n-from tensorflow.python.training.experimental import mixed_precision_global_state\n from tensorflow.python.util.tf_export import keras_export\n \n \n@@ -444,7 +443,7 @@ def global_policy():\n \n \n def _check_if_mixed_precision_graph_rewrite_is_enabled(policy):\n-  if mixed_precision_global_state.mixed_precision_graph_rewrite_is_enabled:\n+  if tf.__internal__.train.is_mixed_precision_graph_rewrite_enabled():\n     raise ValueError(\n         'The global dtype policy cannot be set to \"{policy.name}\", because the '\n         'mixed precision graph rewrite has already been enabled.\\n'\n@@ -515,7 +514,7 @@ def set_policy(policy):\n                      '\"mixed_float16\", but got policy: %s'\n                      % (policy.name,))\n   _global_policy = policy\n-  mixed_precision_global_state.using_mixed_precision_policy = is_mixed_policy\n+  tf.__internal__.train.set_using_mixed_precision_policy(is_mixed_policy)\n \n \n # TODO(reedwm): Make this thread local\n\n@@ -1346,11 +1346,11 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n              self._distribution_strategy)):\n       initializer = trackable.CheckpointInitialValueCallable(\n           checkpoint_position=slot_variable_position)\n-      # Shape is unknown until we read the checkpoint value.\n       slot_variable = self.add_slot(\n           var=variable,\n           initializer=initializer,\n-          slot_name=slot_name)\n+          slot_name=slot_name,\n+          shape=slot_variable_position.value_shape())\n       # Slot variables are not owned by any one object (because we don't want to\n       # save the slot variable if the optimizer is saved without the non-slot\n       # variable, or if the non-slot variable is saved without the optimizer;\n\n@@ -683,6 +683,26 @@ class OptimizerTest(tf.test.TestCase, parameterized.TestCase):\n \n     self.assertEqual(5, self.evaluate(iterations_var))\n \n+  @combinations.generate(combinations.combine(mode=['eager']))\n+  def testSlotWithNonstandardShapeRestoresBasedOnCheckpoint(self):\n+    # First create an optimizer and a slot variable with a non-standard shape.\n+    x = tf.Variable([[1.0, 2.0], [3.0, 4.0]], dtype=tf.float32)\n+    slot_shape = [2, 1]\n+    optimizer_1 = optimizer_v2.OptimizerV2(name='test')\n+    optimizer_1.add_slot(x, 'test_slot', 'ones', shape=slot_shape)\n+\n+    # Then save the variable and optimizer to a checkpoint.\n+    checkpoint_1 = tf.train.Checkpoint(var=x, optimizer=optimizer_1)\n+    checkpoint_path = checkpoint_1.save(self.get_temp_dir())\n+\n+    # Create a new optimizer and call restore on it (and x)\n+    optimizer_2 = optimizer_v2.OptimizerV2(name='test')\n+    checkpoint_2 = tf.train.Checkpoint(var=x, optimizer=optimizer_2)\n+    checkpoint_2.restore(checkpoint_path)\n+\n+    self.assertEqual(slot_shape,\n+                     optimizer_2.get_slot(x, 'test_slot').shape.as_list())\n+\n \n @keras_parameterized.run_all_keras_modes\n class OptimizersCompatibilityTest(keras_parameterized.TestCase):\n\n@@ -22,8 +22,6 @@ import tempfile\n \n from absl.testing import parameterized\n import numpy as np\n-\n-from tensorflow.python.data import Dataset\n from keras import keras_parameterized\n from keras import layers\n from keras import testing_utils\n@@ -77,7 +75,7 @@ class TestImage(keras_parameterized.TestCase):\n   @testing_utils.run_v2_only\n   def test_smart_resize_tf_dataset(self, size):\n     test_input_np = np.random.random((2, 20, 40, 3))\n-    test_ds = Dataset.from_tensor_slices(test_input_np)\n+    test_ds = tf.data.Dataset.from_tensor_slices(test_input_np)\n \n     resize = lambda img: preprocessing_image.smart_resize(img, size=size)\n     test_ds = test_ds.map(resize)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
