{"custom_id": "keras#701355a720b4405a8b2140ca3f5b5023bf9465dd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 87 | Lines Deleted: 28 | Files Changed: 1 | Hunks: 18 | Methods Changed: 12 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 115 | Churn Cumulative: 7054 | Contributors (this commit): 27 | Commits (past 90d): 32 | Contributors (cumulative): 27 | DMM Complexity: None\n\nDIFF:\n@@ -340,6 +340,9 @@ class Layer(object):\n                 that the layer itself is also trainable).\n             regularizer: An optional Regularizer instance.\n             constraint: An optional Constraint instance.\n+\n+        # Returns\n+            The created weight variable.\n         \"\"\"\n         initializer = initializers.get(initializer)\n         weight = K.variable(initializer(shape), dtype=K.floatx(), name=name)\n@@ -360,6 +363,9 @@ class Layer(object):\n         verify the input assumptions of the layer\n         (if any). If not, exceptions are raised.\n \n+        # Arguments\n+            inputs: input tensor or list of input tensors.\n+\n         # Raises\n             ValueError: in case of mismatch between\n                 the provided inputs and the expectations of the layer.\n@@ -471,7 +477,7 @@ class Layer(object):\n                 This is done as part of _add_inbound_node().\n \n         # Arguments\n-            x: Can be a tensor or list/tuple of tensors.\n+            inputs: Can be a tensor or list/tuple of tensors.\n             **kwargs: Additional keyword arguments to be passed to `call()`.\n \n         # Returns\n@@ -554,8 +560,7 @@ class Layer(object):\n             # Apply activity regularizer if any:\n             if hasattr(self, 'activity_regularizer') and self.activity_regularizer is not None:\n                 regularization_losses = [self.activity_regularizer(x) for x in _to_list(output)]\n-                self.add_loss(regularization_losses, _to_list(x))\n-\n+                self.add_loss(regularization_losses, _to_list(inputs))\n         return output\n \n     def _add_inbound_node(self, input_tensors, output_tensors,\n@@ -755,12 +760,17 @@ class Layer(object):\n \n     @property\n     def input(self):\n-        \"\"\"Retrieves the input tensor(s) of a layer (only applicable if\n-        the layer has exactly one inbound node, i.e. if it is connected\n-        to one incoming layer).\n+        \"\"\"Retrieves the input tensor(s) of a layer.\n+\n+        Only applicable if the layer has exactly one inbound node,\n+        i.e. if it is connected to one incoming layer.\n \n         # Returns\n-            TODO\n+            Input tensor or list of input tensors.\n+\n+        # Raises\n+            AttributeError: if the layer is connected to\n+            more than one incoming layers.\n         \"\"\"\n         if len(self.inbound_nodes) > 1:\n             raise AttributeError('Layer ' + self.name +\n@@ -776,12 +786,17 @@ class Layer(object):\n \n     @property\n     def output(self):\n-        \"\"\"Retrieves the output tensor(s) of a layer (only applicable if\n-        the layer has exactly one inbound node, i.e. if it is connected\n-        to one incoming layer).\n+        \"\"\"Retrieves the output tensor(s) of a layer.\n+\n+        Only applicable if the layer has exactly one inbound node,\n+        i.e. if it is connected to one incoming layer.\n \n         # Returns\n-            TODO\n+            Output tensor or list of output tensors.\n+\n+        # Raises\n+            AttributeError: if the layer is connected to\n+            more than one incoming layers.\n         \"\"\"\n         if len(self.inbound_nodes) == 0:\n             raise AttributeError('Layer ' + self.name +\n@@ -797,12 +812,18 @@ class Layer(object):\n \n     @property\n     def input_mask(self):\n-        \"\"\"Retrieves the input mask tensor(s) of a layer (only applicable if\n-        the layer has exactly one inbound node, i.e. if it is connected\n-        to one incoming layer).\n+        \"\"\"Retrieves the input mask tensor(s) of a layer.\n+\n+        Only applicable if the layer has exactly one inbound node,\n+        i.e. if it is connected to one incoming layer.\n \n         # Returns\n-            TODO\n+            Input mask tensor (potentially None) or list of input\n+            mask tensors.\n+\n+        # Raises\n+            AttributeError: if the layer is connected to\n+            more than one incoming layers.\n         \"\"\"\n         if len(self.inbound_nodes) != 1:\n             raise AttributeError('Layer ' + self.name +\n@@ -816,12 +837,18 @@ class Layer(object):\n \n     @property\n     def output_mask(self):\n-        \"\"\"Retrieves the output mask tensor(s) of a layer (only applicable if\n-        the layer has exactly one inbound node, i.e. if it is connected\n-        to one incoming layer).\n+        \"\"\"Retrieves the output mask tensor(s) of a layer.\n+\n+        Only applicable if the layer has exactly one inbound node,\n+        i.e. if it is connected to one incoming layer.\n \n         # Returns\n-            TODO\n+            Output mask tensor (potentially None) or list of output\n+            mask tensors.\n+\n+        # Raises\n+            AttributeError: if the layer is connected to\n+            more than one incoming layers.\n         \"\"\"\n         if len(self.inbound_nodes) != 1:\n             raise AttributeError('Layer ' + self.name +\n@@ -835,12 +862,18 @@ class Layer(object):\n \n     @property\n     def input_shape(self):\n-        \"\"\"Retrieves the input shape tuple(s) of a layer. Only applicable\n-        if the layer has one inbound node,\n-        or if all inbound nodes have the same input shape.\n+        \"\"\"Retrieves the input shape tuple(s) of a layer.\n+\n+        Only applicable if the layer has exactly one inbound node,\n+        i.e. if it is connected to one incoming layer.\n \n         # Returns\n-            TODO\n+            Input shape tuple\n+            (or list of input shape tuples, one tuple per input tensor).\n+\n+        # Raises\n+            AttributeError: if the layer is connected to\n+            more than one incoming layers.\n         \"\"\"\n         if not self.inbound_nodes:\n             raise AttributeError('The layer has never been called '\n@@ -868,7 +901,12 @@ class Layer(object):\n         or if all inbound nodes have the same output shape.\n \n         # Returns\n-            TODO\n+            Output shape tuple\n+            (or list of input shape tuples, one tuple per output tensor).\n+\n+        # Raises\n+            AttributeError: if the layer is connected to\n+            more than one incoming layers.\n         \"\"\"\n         if not self.inbound_nodes:\n             raise AttributeError('The layer has never been called '\n@@ -890,7 +928,19 @@ class Layer(object):\n                                  'instead.')\n \n     def add_loss(self, losses, inputs=None):\n-        \"\"\"TODO\n+        \"\"\"Add losses to the layer.\n+\n+        The loss may potentially be conditional on some inputs tensors,\n+        for instance activity losses are conditional on the layer's inputs.\n+\n+        # Arguments\n+            losses: loss tensor or list of loss tensors\n+                to add to the layer.\n+            inputs: input tensor or list of inputs tensors to mark\n+                the losses as conditional on these inputs.\n+                If None is passed, the loss is assumed unconditional\n+                (e.g. L2 weight regularization, which only depends\n+                on the layer's weights variables, not on any inputs tensors).\n         \"\"\"\n         if losses is None:\n             return\n@@ -920,7 +970,17 @@ class Layer(object):\n         self._per_input_losses[inputs_hash] += losses\n \n     def add_update(self, updates, inputs=None):\n-        \"\"\"TODO\n+        \"\"\"Add updates to the layer.\n+\n+        The updates may potentially be conditional on some inputs tensors,\n+        for instance batch norm updates are conditional on the layer's inputs.\n+\n+        # Arguments\n+            updates: update op or list of update ops\n+                to add to the layer.\n+            inputs: input tensor or list of inputs tensors to mark\n+                the updates as conditional on these inputs.\n+                If None is passed, the updates are assumed unconditional.\n         \"\"\"\n         if updates is None:\n             return\n@@ -2308,8 +2368,7 @@ class Container(Layer):\n \n \n def get_source_inputs(tensor, layer=None, node_index=None):\n-    \"\"\"Returns the list of input tensors\n-    necessary to compute `tensor`.\n+    \"\"\"Returns the list of input tensors necessary to compute `tensor`.\n \n     Output will always be a list of tensors\n     (potentially with 1 element).\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7dc8a32f8955023c75f681e029c15e841da443e0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 4 | Files Changed: 3 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 8099 | Contributors (this commit): 31 | Commits (past 90d): 53 | Contributors (cumulative): 35 | DMM Complexity: 1.0\n\nDIFF:\n@@ -371,7 +371,7 @@ class Layer(object):\n                 the provided inputs and the expectations of the layer.\n         \"\"\"\n         if not self.input_spec:\n-            return True\n+            return\n         if not isinstance(self.input_spec, (list, tuple)):\n             input_spec = _to_list(self.input_spec)\n         else:\n\n@@ -1,5 +1,6 @@\n from __future__ import absolute_import\n \n+from ..utils.generic_utils import deserialize_keras_object\n from ..engine import Layer\n from ..engine import Input\n from ..engine import InputLayer\n\n@@ -413,9 +413,10 @@ class ConvLSTM2D(ConvRecurrent2D):\n         input_shape = self.input_spec.shape\n         output_shape = self.compute_output_shape(input_shape)\n         if not input_shape[0]:\n-            raise ValueError('If a RNN is stateful, a complete ' +\n-                             'input_shape must be provided ' +\n-                             '(including batch size).')\n+            raise ValueError('If a RNN is stateful, a complete '\n+                             'input_shape must be provided '\n+                             '(including batch size). '\n+                             'Got input shape: ' + str(input_shape))\n \n         if self.return_sequences:\n             out_row, out_col, out_filter = output_shape[2:]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b257dad10c0a5441c8638142b7de4c26fc76b69f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 105 | Lines Deleted: 13 | Files Changed: 1 | Hunks: 13 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 118 | Churn Cumulative: 488 | Contributors (this commit): 1 | Commits (past 90d): 7 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -3,7 +3,12 @@ from .. import backend as K\n \n \n class _Merge(Layer):\n-    \"\"\"TODO\n+    \"\"\"Generic merge layer for elementwise merge functions.\n+\n+    Used to implement `Sum`, `Average`, etc.\n+\n+    # Arguments\n+        **kwargs: standard layer keyword arguments.\n     \"\"\"\n \n     def __init__(self, **kwargs):\n@@ -53,7 +58,11 @@ class _Merge(Layer):\n \n \n class Sum(_Merge):\n-    \"\"\"TODO\n+    \"\"\"Layer that sums a list of inputs.\n+\n+    It takes as input a list of tensors,\n+    all of the same shape, and returns\n+    a single tensor (also of the same shape).\n     \"\"\"\n \n     def _merge_function(self, inputs):\n@@ -64,7 +73,11 @@ class Sum(_Merge):\n \n \n class Multiply(_Merge):\n-    \"\"\"TODO\n+    \"\"\"Layer that multiplies (element-wise) a list of inputs.\n+\n+    It takes as input a list of tensors,\n+    all of the same shape, and returns\n+    a single tensor (also of the same shape).\n     \"\"\"\n \n     def _merge_function(self, inputs):\n@@ -75,7 +88,11 @@ class Multiply(_Merge):\n \n \n class Average(_Merge):\n-    \"\"\"TODO\n+    \"\"\"Layer that averages a list of inputs.\n+\n+    It takes as input a list of tensors,\n+    all of the same shape, and returns\n+    a single tensor (also of the same shape).\n     \"\"\"\n \n     def _merge_function(self, inputs):\n@@ -86,7 +103,11 @@ class Average(_Merge):\n \n \n class Maximum(_Merge):\n-    \"\"\"TODO\n+    \"\"\"Layer that computes the maximum (element-wise) a list of inputs.\n+\n+    It takes as input a list of tensors,\n+    all of the same shape, and returns\n+    a single tensor (also of the same shape).\n     \"\"\"\n \n     def _merge_function(self, inputs):\n@@ -97,7 +118,15 @@ class Maximum(_Merge):\n \n \n class Concatenate(_Merge):\n-    \"\"\"TODO\n+    \"\"\"Layer that concatenates a list of inputs.\n+\n+    It takes as input a list of tensors,\n+    all of the same shape expect for the concatenation axis,\n+    and returns a single tensor, the concatenation of all inputs.\n+\n+    # Arguments\n+        axis: Axis along which to concatenate.\n+        **kwargs: standard layer keyword arguments.\n     \"\"\"\n \n     def __init__(self, axis=-1, **kwargs):\n@@ -180,7 +209,21 @@ class Concatenate(_Merge):\n \n \n class Dot(_Merge):\n-    \"\"\"TODO\n+    \"\"\"Layer that computes a dot product between samples in two tensors.\n+\n+    E.g. if applied to two tensors `a` and `b` of shape `(batch_size, n)`,\n+    the output will be a tensor of shape `(batch_size, 1)`\n+    where each entry `i` will be the dot product between\n+    `a[i]` and `b[i]`.\n+\n+    # Arguments\n+        axes: Integer or tuple of integers,\n+            axis or axes along which to take the dot product.\n+        normalize: Whether to L2-normalize samples along the\n+            dot product axis before taking the dot product.\n+            If set to True, then the output of the dot product\n+            is the cosine proximity between the two samples.\n+        **kwargs: Standard layer keyword arguments.\n     \"\"\"\n \n     def __init__(self, axes, normalize=False, **kwargs):\n@@ -271,36 +314,85 @@ class Dot(_Merge):\n \n \n def sum(inputs, **kwargs):\n-    \"\"\"TODO\n+    \"\"\"Functional interface to the `Sum` layer.\n+\n+    # Arguments\n+        inputs: A list of input tensors (at least 2).\n+        **kwargs: Standard layer keyword arguments.\n+\n+    # Returns\n+        A tensor, the sum of the inputs.\n     \"\"\"\n     return Sum(**kwargs)(inputs)\n \n \n def multiply(inputs, **kwargs):\n-    \"\"\"TODO\n+    \"\"\"Functional interface to the `Multiply` layer.\n+\n+    # Arguments\n+        inputs: A list of input tensors (at least 2).\n+        **kwargs: Standard layer keyword arguments.\n+\n+    # Returns\n+        A tensor, the element-wise product of the inputs.\n     \"\"\"\n     return Multiply(**kwargs)(inputs)\n \n \n def average(inputs, **kwargs):\n-    \"\"\"TODO\n+    \"\"\"Functional interface to the `Average` layer.\n+\n+    # Arguments\n+        inputs: A list of input tensors (at least 2).\n+        **kwargs: Standard layer keyword arguments.\n+\n+    # Returns\n+        A tensor, the average of the inputs.\n     \"\"\"\n     return Average(**kwargs)(inputs)\n \n \n def maximum(inputs, **kwargs):\n-    \"\"\"TODO\n+    \"\"\"Functional interface to the `Maximum` layer.\n+\n+    # Arguments\n+        inputs: A list of input tensors (at least 2).\n+        **kwargs: Standard layer keyword arguments.\n+\n+    # Returns\n+        A tensor, the element-wise maximum of the inputs.\n     \"\"\"\n     return Maximum(**kwargs)(inputs)\n \n \n def concatenate(inputs, axis=-1, **kwargs):\n-    \"\"\"TODO\n+    \"\"\"Functional interface to the `Concatenate` layer.\n+\n+    # Arguments\n+        inputs: A list of input tensors (at least 2).\n+        axis: Concatenation axis.\n+        **kwargs: Standard layer keyword arguments.\n+\n+    # Returns\n+        A tensor, the concatenation of the inputs alongside axis `axis`.\n     \"\"\"\n     return Concatenate(axis=axis, **kwargs)(inputs)\n \n \n def dot(inputs, axes, normalize=False, **kwargs):\n-    \"\"\"TODO\n+    \"\"\"Functional interface to the `Dot` layer.\n+\n+    # Arguments\n+        inputs: A list of input tensors (at least 2).\n+        axes: Integer or tuple of integers,\n+            axis or axes along which to take the dot product.\n+        normalize: Whether to L2-normalize samples along the\n+            dot product axis before taking the dot product.\n+            If set to True, then the output of the dot product\n+            is the cosine proximity between the two samples.\n+        **kwargs: Standard layer keyword arguments.\n+\n+    # Returns\n+        A tensor, the dot product of the samples from the inputs.\n     \"\"\"\n     return Dot(axes=axes, normalize=normalize, **kwargs)(inputs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#67b43e3b0d46b2315e0f0128c691e916e65f8c83", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 3 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 7953 | Contributors (this commit): 44 | Commits (past 90d): 44 | Contributors (cumulative): 50 | DMM Complexity: None\n\nDIFF:\n@@ -60,6 +60,7 @@ def _time_distributed_dense(x, w, b=None, dropout=None,\n \n class Recurrent(Layer):\n     \"\"\"Abstract base class for recurrent layers.\n+\n     Do not use in a model -- it's not a valid layer!\n     Use its children classes `LSTM`, `GRU` and `SimpleRNN` instead.\n \n@@ -936,7 +937,7 @@ class LSTM(Recurrent):\n         assert self.stateful, 'Layer must be stateful.'\n         input_shape = self.input_spec.shape\n         if not input_shape[0]:\n-            raise ValueError('If a RNN is stateful, a complete ' +\n+            raise ValueError('If a RNN is stateful, a complete '\n                              'input_shape must be provided '\n                              '(including batch size).')\n         if hasattr(self, 'states'):\n\n@@ -233,7 +233,7 @@ class Bidirectional(Wrapper):\n         self.backward_layer.build(input_shape)\n         self.built = True\n \n-    def compute_mask(self, input, mask):\n+    def compute_mask(self, inputs, mask):\n         if self.return_sequences:\n             if not self.merge_mode:\n                 return [mask, mask]\n\n@@ -88,8 +88,7 @@ class BaseWrapper(object):\n         \"\"\"Gets parameters for this estimator.\n \n         # Returns\n-            params : dict\n-                Dictionary of parameter names mapped to their values.\n+            **params: Dictionary of parameter names mapped to their values.\n         \"\"\"\n         res = copy.deepcopy(self.sk_params)\n         res.update({'build_fn': self.build_fn})\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#59e67fd049252fe1d9194071ed38e81f9fbc2dcf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 25 | Churn Cumulative: 1825 | Contributors (this commit): 19 | Commits (past 90d): 14 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -622,6 +622,18 @@ def serialize(optimizer):\n \n \n def deserialize(config, custom_objects=None):\n+    \"\"\"Inverse of the `serialize` function.\n+\n+    # Arguments\n+        config: Optimizer configuration dictionary.\n+        custom_objects: Optional dictionary mapping\n+            names (strings) to custom objects\n+            (classes and functions)\n+            to be considered during deserialization.\n+\n+    # Returns\n+        A Keras Optimizer instance.\n+    \"\"\"\n     all_classes = {\n         'sgd': SGD,\n         'rmsprop': RMSprop,\n@@ -640,6 +652,19 @@ def deserialize(config, custom_objects=None):\n \n \n def get(identifier):\n+    \"\"\"Retrieves a Keras Optimizer instance.\n+\n+    # Arguments\n+        identifier: Optimizer identifier, one of\n+            - String: name of an optimizer\n+            - Dictionary: configuration dictionary.\n+            - Keras Optimizer instance (it will be returned unchanged).\n+            - TensorFlow Optimizer instance\n+                (it will be wrapped as a Keras Optimizer).\n+\n+    # Returns\n+        A Keras Optimizer instance.\n+    \"\"\"\n     if K.backend() == 'tensorflow':\n         # Wrap TF optimizer instances\n         if isinstance(identifier, tf.train.Optimizer):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fb21b1bad8a7e6f5cf5bb7843aa9037b6213e35a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 31 | Churn Cumulative: 3538 | Contributors (this commit): 31 | Commits (past 90d): 35 | Contributors (cumulative): 33 | DMM Complexity: None\n\nDIFF:\n@@ -41,6 +41,20 @@ def conv2d_bn(x, filters, num_row, num_col,\n               padding='same', strides=(1, 1),\n               name=None):\n     \"\"\"Utility function to apply conv + BN.\n+\n+    # Arguments\n+        x: input tensor.\n+        filters: filters in `Conv2D`.\n+        num_row: height of the convolution kernel.\n+        num_cols: width of the convolution kernel.\n+        padding: padding mode in `Conv2D`.\n+        strides: strides in `Conv2D`.\n+        name: name of the ops; will become `name + '_conv'`\n+            for the convolution and `name + '_bn'` for the\n+            batch norm layer.\n+\n+    # Returns\n+        Output tensor after applying `Conv2D` and `BatchNormalization`.\n     \"\"\"\n     if name is not None:\n         bn_name = name + '_bn'\n@@ -65,8 +79,9 @@ def InceptionV3(include_top=True, weights='imagenet',\n                 input_tensor=None, input_shape=None,\n                 pooling=None,\n                 classes=1000):\n-    \"\"\"Instantiate the Inception v3 architecture,\n-    optionally loading weights pre-trained\n+    \"\"\"Instantiates the Inception v3 architecture.\n+\n+    Optionally loads weights pre-trained\n     on ImageNet. Note that when using TensorFlow,\n     for best performance you should set\n     `image_data_format=\"channels_last\"` in your Keras config\n@@ -110,6 +125,10 @@ def InceptionV3(include_top=True, weights='imagenet',\n \n     # Returns\n         A Keras model instance.\n+\n+    # Raises\n+        ValueError: in case of invalid argument for `weights`,\n+            or invalid input shape.\n     \"\"\"\n     if weights not in {'imagenet', None}:\n         raise ValueError('The `weights` argument should be either '\n\n@@ -664,6 +664,9 @@ def get(identifier):\n \n     # Returns\n         A Keras Optimizer instance.\n+\n+    # Raises\n+        ValueError: If `identifier` cannot be interpreted.\n     \"\"\"\n     if K.backend() == 'tensorflow':\n         # Wrap TF optimizer instances\n\n@@ -87,8 +87,11 @@ class BaseWrapper(object):\n     def get_params(self, **params):\n         \"\"\"Gets parameters for this estimator.\n \n+        # Arguments\n+            **params: ignored (exists for API compatiblity).\n+\n         # Returns\n-            **params: Dictionary of parameter names mapped to their values.\n+            Dictionary of parameter names mapped to their values.\n         \"\"\"\n         res = copy.deepcopy(self.sk_params)\n         res.update({'build_fn': self.build_fn})\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3a57f184de26a70df1359c7b0afa5b1ee943fe07", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 100 | Lines Deleted: 28 | Files Changed: 6 | Hunks: 25 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 128 | Churn Cumulative: 2282 | Contributors (this commit): 4 | Commits (past 90d): 57 | Contributors (cumulative): 18 | DMM Complexity: 1.0\n\nDIFF:\n@@ -22,13 +22,21 @@ import warnings\n \n from ..models import Model\n from .. import layers\n-from ..layers import Flatten, Dense, Input, BatchNormalization\n-from ..layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n+from ..layers import Flatten\n+from ..layers import Dense\n+from ..layers import Input\n+from ..layers import BatchNormalization\n+from ..layers import Conv2D\n+from ..layers import MaxPooling2D\n+from ..layers import AveragePooling2D\n+from ..layers import GlobalAveragePooling2D\n+from ..layers import GlobalMaxPooling2D\n from ..engine.topology import get_source_inputs\n from ..utils.layer_utils import convert_all_kernels_in_model\n from ..utils.data_utils import get_file\n from .. import backend as K\n-from .imagenet_utils import decode_predictions, _obtain_input_shape\n+from .imagenet_utils import decode_predictions\n+from .imagenet_utils import _obtain_input_shape\n \n \n TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/inception_v3_weights_th_dim_ordering_th_kernels.h5'\n@@ -46,7 +54,7 @@ def conv2d_bn(x, filters, num_row, num_col,\n         x: input tensor.\n         filters: filters in `Conv2D`.\n         num_row: height of the convolution kernel.\n-        num_cols: width of the convolution kernel.\n+        num_col: width of the convolution kernel.\n         padding: padding mode in `Conv2D`.\n         strides: strides in `Conv2D`.\n         name: name of the ops; will become `name + '_conv'`\n\n@@ -14,14 +14,16 @@ from ..layers import Input, Dense\n from ..models import Model\n from ..layers import Reshape, Permute\n from ..layers.convolutional import Conv2D\n-from ..layers.convolutional import MaxPooling2D, ZeroPadding2D\n+from ..layers.convolutional import MaxPooling2D\n+from ..layers.convolutional import ZeroPadding2D\n from ..layers.normalization import BatchNormalization\n from ..layers.advanced_activations import ELU\n from ..layers.recurrent import GRU\n from ..engine.topology import get_source_inputs\n from ..utils.data_utils import get_file\n from ..utils.layer_utils import convert_all_kernels_in_model\n-from .audio_conv_utils import decode_predictions, preprocess_input\n+from .audio_conv_utils import decode_predictions\n+from .audio_conv_utils import preprocess_input\n \n TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.3/music_tagger_crnn_weights_tf_kernels_th_data_format.h5'\n TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.3/music_tagger_crnn_weights_tf_kernels_tf_data_format.h5'\n@@ -30,8 +32,9 @@ TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/dow\n def MusicTaggerCRNN(weights='msd', input_tensor=None,\n                     include_top=True,\n                     classes=50):\n-    \"\"\"Instantiate the MusicTaggerCRNN architecture,\n-    optionally loading weights pre-trained\n+    \"\"\"Instantiates the MusicTaggerCRNN architecture.\n+\n+    Optionally loads weights pre-trained\n     on Million Song Dataset. Note that when using TensorFlow,\n     for best performance you should set\n     `image_data_format=\"channels_last\"` in your Keras config\n@@ -61,6 +64,10 @@ def MusicTaggerCRNN(weights='msd', input_tensor=None,\n \n     # Returns\n         A Keras model instance.\n+\n+    # Raises\n+        ValueError: in case of invalid argument for `weights`,\n+            or invalid input shape.\n     \"\"\"\n     if weights not in {'msd', None}:\n         raise ValueError('The `weights` argument should be either '\n\n@@ -14,15 +14,24 @@ import warnings\n \n from ..layers import Input\n from .. import layers\n-from ..layers import Dense, Activation, Flatten\n-from ..layers import Conv2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n+from ..layers import Dense\n+from ..layers import Activation\n+from ..layers import Flatten\n+from ..layers import Conv2D\n+from ..layers import MaxPooling2D\n+from ..layers import ZeroPadding2D\n+from ..layers import AveragePooling2D\n+from ..layers import GlobalAveragePooling2D\n+from ..layers import GlobalMaxPooling2D\n from ..layers import BatchNormalization\n from ..models import Model\n from .. import backend as K\n from ..engine.topology import get_source_inputs\n from ..utils.layer_utils import convert_all_kernels_in_model\n from ..utils.data_utils import get_file\n-from .imagenet_utils import decode_predictions, preprocess_input, _obtain_input_shape\n+from .imagenet_utils import decode_predictions\n+from .imagenet_utils import preprocess_input\n+from .imagenet_utils import _obtain_input_shape\n \n \n TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_th_dim_ordering_th_kernels.h5'\n@@ -40,6 +49,9 @@ def identity_block(input_tensor, kernel_size, filters, stage, block):\n         filters: list of integers, the filterss of 3 conv layer at main path\n         stage: integer, current stage label, used for generating layer names\n         block: 'a','b'..., current block label, used for generating layer names\n+\n+    # Returns\n+        Output tensor for the block.\n     \"\"\"\n     filters1, filters2, filters3 = filters\n     if K.image_data_format() == 'channels_last':\n@@ -76,6 +88,9 @@ def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2))\n         stage: integer, current stage label, used for generating layer names\n         block: 'a','b'..., current block label, used for generating layer names\n \n+    # Returns\n+        Output tensor for the block.\n+\n     Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n     And the shortcut should have strides=(2,2) as well\n     \"\"\"\n@@ -113,8 +128,9 @@ def ResNet50(include_top=True, weights='imagenet',\n              input_tensor=None, input_shape=None,\n              pooling=None,\n              classes=1000):\n-    \"\"\"Instantiate the ResNet50 architecture,\n-    optionally loading weights pre-trained\n+    \"\"\"Instantiates the ResNet50 architecture.\n+\n+    Optionally loads weights pre-trained\n     on ImageNet. Note that when using TensorFlow,\n     for best performance you should set\n     `image_data_format=\"channels_last\"` in your Keras config\n@@ -156,6 +172,10 @@ def ResNet50(include_top=True, weights='imagenet',\n \n     # Returns\n         A Keras model instance.\n+\n+    # Raises\n+        ValueError: in case of invalid argument for `weights`,\n+            or invalid input shape.\n     \"\"\"\n     if weights not in {'imagenet', None}:\n         raise ValueError('The `weights` argument should be either '\n\n@@ -12,13 +12,20 @@ from __future__ import absolute_import\n import warnings\n \n from ..models import Model\n-from ..layers import Flatten, Dense, Input\n-from ..layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n+from ..layers import Flatten\n+from ..layers import Dense\n+from ..layers import Input\n+from ..layers import Conv2D\n+from ..layers import MaxPooling2D\n+from ..layers import GlobalAveragePooling2D\n+from ..layers import GlobalMaxPooling2D\n from ..engine.topology import get_source_inputs\n from ..utils.layer_utils import convert_all_kernels_in_model\n from ..utils.data_utils import get_file\n from .. import backend as K\n-from .imagenet_utils import decode_predictions, preprocess_input, _obtain_input_shape\n+from .imagenet_utils import decode_predictions\n+from .imagenet_utils import preprocess_input\n+from .imagenet_utils import _obtain_input_shape\n \n \n TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_th_dim_ordering_th_kernels.h5'\n@@ -31,8 +38,9 @@ def VGG16(include_top=True, weights='imagenet',\n           input_tensor=None, input_shape=None,\n           pooling=None,\n           classes=1000):\n-    \"\"\"Instantiate the VGG16 architecture,\n-    optionally loading weights pre-trained\n+    \"\"\"Instantiates the VGG16 architecture.\n+\n+    Optionally loads weights pre-trained\n     on ImageNet. Note that when using TensorFlow,\n     for best performance you should set\n     `image_data_format=\"channels_last\"` in your Keras config\n@@ -74,6 +82,10 @@ def VGG16(include_top=True, weights='imagenet',\n \n     # Returns\n         A Keras model instance.\n+\n+    # Raises\n+        ValueError: in case of invalid argument for `weights`,\n+            or invalid input shape.\n     \"\"\"\n     if weights not in {'imagenet', None}:\n         raise ValueError('The `weights` argument should be either '\n\n@@ -12,13 +12,20 @@ from __future__ import absolute_import\n import warnings\n \n from ..models import Model\n-from ..layers import Flatten, Dense, Input\n-from ..layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n+from ..layers import Flatten\n+from ..layers import Dense\n+from ..layers import Input\n+from ..layers import Conv2D\n+from ..layers import MaxPooling2D\n+from ..layers import GlobalAveragePooling2D\n+from ..layers import GlobalMaxPooling2D\n from ..engine.topology import get_source_inputs\n from ..utils.layer_utils import convert_all_kernels_in_model\n from ..utils.data_utils import get_file\n from .. import backend as K\n-from .imagenet_utils import decode_predictions, preprocess_input, _obtain_input_shape\n+from .imagenet_utils import decode_predictions\n+from .imagenet_utils import preprocess_input\n+from .imagenet_utils import _obtain_input_shape\n \n \n TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_th_dim_ordering_th_kernels.h5'\n@@ -31,8 +38,9 @@ def VGG19(include_top=True, weights='imagenet',\n           input_tensor=None, input_shape=None,\n           pooling=None,\n           classes=1000):\n-    \"\"\"Instantiate the VGG19 architecture,\n-    optionally loading weights pre-trained\n+    \"\"\"Instantiates the VGG19 architecture.\n+\n+    Optionally loads weights pre-trained\n     on ImageNet. Note that when using TensorFlow,\n     for best performance you should set\n     `image_data_format=\"channels_last\"` in your Keras config\n@@ -74,6 +82,10 @@ def VGG19(include_top=True, weights='imagenet',\n \n     # Returns\n         A Keras model instance.\n+\n+    # Raises\n+        ValueError: in case of invalid argument for `weights`,\n+            or invalid input shape.\n     \"\"\"\n     if weights not in {'imagenet', None}:\n         raise ValueError('The `weights` argument should be either '\n\n@@ -24,12 +24,20 @@ import warnings\n \n from ..models import Model\n from .. import layers\n-from ..layers import Dense, Input, BatchNormalization, Activation\n-from ..layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n+from ..layers import Dense\n+from ..layers import Input\n+from ..layers import BatchNormalization\n+from ..layers import Activation\n+from ..layers import Conv2D\n+from ..layers import SeparableConv2D\n+from ..layers import MaxPooling2D\n+from ..layers import GlobalAveragePooling2D\n+from ..layers import GlobalMaxPooling2D\n from ..engine.topology import get_source_inputs\n from ..utils.data_utils import get_file\n from .. import backend as K\n-from .imagenet_utils import decode_predictions, _obtain_input_shape\n+from .imagenet_utils import decode_predictions\n+from .imagenet_utils import _obtain_input_shape\n \n \n TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels.h5'\n@@ -40,8 +48,9 @@ def Xception(include_top=True, weights='imagenet',\n              input_tensor=None, input_shape=None,\n              pooling=None,\n              classes=1000):\n-    \"\"\"Instantiate the Xception architecture,\n-    optionally loading weights pre-trained\n+    \"\"\"Instantiates the Xception architecture.\n+\n+    Optionally loads weights pre-trained\n     on ImageNet. This model is available for TensorFlow only,\n     and can only be used with inputs following the TensorFlow\n     data format `(width, height, channels)`.\n@@ -80,6 +89,10 @@ def Xception(include_top=True, weights='imagenet',\n \n     # Returns\n         A Keras model instance.\n+\n+    # Raises\n+        ValueError: in case of invalid argument for `weights`,\n+            or invalid input shape.\n     \"\"\"\n     if weights not in {'imagenet', None}:\n         raise ValueError('The `weights` argument should be either '\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#97db7e26661f249aefc51d4e73e0d1ba97ad7cb2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 2 | Files Changed: 3 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 876 | Contributors (this commit): 3 | Commits (past 90d): 24 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -41,7 +41,7 @@ TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/relea\n \n \n def identity_block(input_tensor, kernel_size, filters, stage, block):\n-    \"\"\"The identity_block is the block that has no conv layer at shortcut\n+    \"\"\"The identity block is the block that has no conv layer at shortcut.\n \n     # Arguments\n         input_tensor: input tensor\n\n@@ -93,6 +93,8 @@ def Xception(include_top=True, weights='imagenet',\n     # Raises\n         ValueError: in case of invalid argument for `weights`,\n             or invalid input shape.\n+        RuntimeError: If attempting to run this model with a\n+            backend that does not support separable convolutions.\n     \"\"\"\n     if weights not in {'imagenet', None}:\n         raise ValueError('The `weights` argument should be either '\n\n@@ -3,15 +3,19 @@ import numpy as np\n \n \n def load_data(path='boston_housing.npz', seed=113, test_split=0.2):\n-    \"\"\"Loads the MNIST dataset.\n+    \"\"\"Loads the Boston Housing dataset.\n \n     # Arguments\n         path: path where to cache the dataset locally\n             (relative to ~/.keras/datasets).\n+        seed: Random seed for shuffling the data\n+            before computing the test split.\n+        test_split: fraction of the data to reserve as test set.\n \n     # Returns\n         Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n     \"\"\"\n+    assert 0 <= test_split < 1\n     path = get_file(path, origin='https://s3.amazonaws.com/keras-datasets/boston_housing.npz')\n     f = np.load(path)\n     x = f['x']\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3cde2c1f8af4dc10d3ba2fd2663e1335d8f8714c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 8 | Churn Cumulative: 1999 | Contributors (this commit): 23 | Commits (past 90d): 16 | Contributors (cumulative): 23 | DMM Complexity: 0.0\n\nDIFF:\n@@ -295,11 +295,15 @@ def load_img(path, grayscale=False, target_size=None):\n                           'The use of `array_to_img` requires PIL.')\n     img = pil_image.open(path)\n     if grayscale:\n+        if img.mode != 'L':\n             img = img.convert('L')\n-    else:  # Ensure 3 channel even when loaded image is grayscale\n+    else:\n+        if img.mode != 'RGB':\n             img = img.convert('RGB')\n     if target_size:\n-        img = img.resize((target_size[1], target_size[0]))\n+        wh_tuple = (target_size[1], target_size[0])\n+        if img.size != wh_tuple:\n+            img = img.resize(wh_tuple)\n     return img\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7e7d2ed1f9d87e5ab46a5c1e7254a000c7d0b9a3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 144 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -88,7 +88,7 @@ validator = GridSearchCV(my_classifier,\n                                      'filterss': [8],\n                                      'num_conv': [3],\n                                      'num_pool': [2]},\n-                         scoring='log_loss',\n+                         scoring='neg_log_loss',\n                          n_jobs=1)\n validator.fit(X_train, y_train)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#00dc75116f80d81e4cb9bc90e2cffa9b40eed153", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 102 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 13 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 112 | Churn Cumulative: 2111 | Contributors (this commit): 23 | Commits (past 90d): 17 | Contributors (cumulative): 23 | DMM Complexity: 1.0\n\nDIFF:\n@@ -173,12 +173,36 @@ def transform_matrix_offset_center(matrix, x, y):\n     return transform_matrix\n \n \n-def apply_transform(x, transform_matrix, channel_axis=0, fill_mode='nearest', cval=0.):\n+def apply_transform(x,\n+                    transform_matrix,\n+                    channel_axis=0,\n+                    fill_mode='nearest',\n+                    cval=0.):\n+    \"\"\"Apply the image transformation specified by a matrix.\n+\n+    # Arguments\n+        x: 2D numpy array, single image.\n+        transform_matrix: Numpy array specifying the geometric transformation.\n+        channel_axis: Index of axis for channels in the input tensor.\n+        fill_mode: Points outside the boundaries of the input\n+            are filled according to the given mode\n+            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n+        cval: Value used for points outside the boundaries\n+            of the input if `mode='constant'`.\n+\n+    # Returns\n+        The transformed version of the input.\n+    \"\"\"\n     x = np.rollaxis(x, channel_axis, 0)\n     final_affine_matrix = transform_matrix[:2, :2]\n     final_offset = transform_matrix[:2, 2]\n-    channel_images = [ndi.interpolation.affine_transform(x_channel, final_affine_matrix,\n-                                                         final_offset, order=0, mode=fill_mode, cval=cval) for x_channel in x]\n+    channel_images = [ndi.interpolation.affine_transform(\n+        x_channel,\n+        final_affine_matrix,\n+        final_offset,\n+        order=0,\n+        mode=fill_mode,\n+        cval=cval) for x_channel in x]\n     x = np.stack(channel_images, axis=0)\n     x = np.rollaxis(x, 0, channel_axis + 1)\n     return x\n@@ -498,7 +522,13 @@ class ImageDataGenerator(object):\n         return x\n \n     def random_transform(self, x):\n-        \"\"\"TODO\n+        \"\"\"Randomly augment a single image tensor.\n+\n+        # Arguments\n+            x: 3D tensor, single image.\n+\n+        # Returns\n+            A randomly transformed version of the input (same shape).\n         \"\"\"\n         # x is a single image, so it doesn't have image number at index 0\n         img_row_axis = self.row_axis - 1\n@@ -645,6 +675,14 @@ class ImageDataGenerator(object):\n \n \n class Iterator(object):\n+    \"\"\"Abstract base class for image data iterators.\n+\n+    # Arguments\n+        n: Integer, total number of samples in the dataset to loop over.\n+        batch_size: Integer, size of a batch.\n+        shuffle: Boolean, whether to shuffle the data between epochs.\n+        seed: Random seeding for data shuffling.\n+    \"\"\"\n \n     def __init__(self, n, batch_size, shuffle, seed):\n         self.n = n\n@@ -659,7 +697,7 @@ class Iterator(object):\n         self.batch_index = 0\n \n     def _flow_index(self, n, batch_size=32, shuffle=False, seed=None):\n-        # ensure self.batch_index is 0\n+        # Ensure self.batch_index is 0.\n         self.reset()\n         while 1:\n             if seed is not None:\n@@ -681,7 +719,7 @@ class Iterator(object):\n                    current_index, current_batch_size)\n \n     def __iter__(self):\n-        # needed if we want to do something like:\n+        # Needed if we want to do something like:\n         # for x, y in data_gen.flow(...):\n         return self\n \n@@ -690,6 +728,26 @@ class Iterator(object):\n \n \n class NumpyArrayIterator(Iterator):\n+    \"\"\"Iterator yielding data from a Numpy array.\n+\n+    # Arguments\n+        x: Numpy array of input data.\n+        y: Numpy array of targets data.\n+        image_data_generator: Instance of `ImageDataGenerator`\n+            to use for random transformations and normalization.\n+        batch_size: Integer, size of a batch.\n+        shuffle: Boolean, whether to shuffle the data between epochs.\n+        seed: Random seed for data shuffling.\n+        data_format: String, one of `channels_first`, `channels_last`.\n+        save_to_dir: Optional directory where to save the pictures\n+            being yielded, in a viewable format. This is useful\n+            for visualizing the random transformations being\n+            applied, for debugging purposes.\n+        save_prefix: String prefix to use for saving sample\n+            images (if `save_to_dir` is set).\n+        save_format: Format to use for saving sample images\n+            (if `save_to_dir` is set).\n+    \"\"\"\n \n     def __init__(self, x, y, image_data_generator,\n                  batch_size=32, shuffle=False, seed=None,\n@@ -729,10 +787,9 @@ class NumpyArrayIterator(Iterator):\n         super(NumpyArrayIterator, self).__init__(x.shape[0], batch_size, shuffle, seed)\n \n     def next(self):\n-        # for python 2.x.\n+        # For python 2.x. Yields the next batch.\n         # Keeps under lock only the mechanism which advances\n-        # the indexing of each batch\n-        # see http://anandology.com/blog/using-iterators-and-generators/\n+        # the indexing of each batch.\n         with self.lock:\n             index_array, current_index, current_batch_size = next(self.index_generator)\n         # The transformation of images is not under thread lock\n@@ -758,12 +815,45 @@ class NumpyArrayIterator(Iterator):\n \n \n class DirectoryIterator(Iterator):\n+    \"\"\"Iterator capable of reading images from a directory on disk.\n+\n+    # Arguments\n+        directory: Path to the directory to read images from.\n+            Each subdirectory in this directory will be\n+            considered to contain images from one class,\n+            or alternatively you could specify class subdirectories\n+            via the `classes` argument.\n+        image_data_generator: Instance of `ImageDataGenerator`\n+            to use for random transformations and normalization.\n+        target_size: tuple of integers, dimensions to resize input images to.\n+        color_mode: One of `\"rgb\"`, `\"grayscale\"`. Color mode to read images.\n+        classes: Optional list of strings, names of sudirectories\n+            containing images from each class (e.g. `[\"dogs\", \"cats\"]`).\n+            It will be computed automatically if not set.\n+        class_mode: Mode for yielding the targets:\n+            `\"binary\"`: binary targets (if there are only two classes),\n+            `\"categorical\"`: categorical targets,\n+            `\"sparse\"`: integer targets,\n+            `None`: no targets get yielded (only input images are yielded).\n+        batch_size: Integer, size of a batch.\n+        shuffle: Boolean, whether to shuffle the data between epochs.\n+        seed: Random seed for data shuffling.\n+        data_format: String, one of `channels_first`, `channels_last`.\n+        save_to_dir: Optional directory where to save the pictures\n+            being yielded, in a viewable format. This is useful\n+            for visualizing the random transformations being\n+            applied, for debugging purposes.\n+        save_prefix: String prefix to use for saving sample\n+            images (if `save_to_dir` is set).\n+        save_format: Format to use for saving sample images\n+            (if `save_to_dir` is set).\n+    \"\"\"\n \n     def __init__(self, directory, image_data_generator,\n                  target_size=(256, 256), color_mode='rgb',\n-                 data_format=None,\n                  classes=None, class_mode='categorical',\n                  batch_size=32, shuffle=True, seed=None,\n+                 data_format=None,\n                  save_to_dir=None, save_prefix='', save_format='jpeg',\n                  follow_links=False):\n         if data_format is None:\n@@ -847,6 +937,8 @@ class DirectoryIterator(Iterator):\n         super(DirectoryIterator, self).__init__(self.samples, batch_size, shuffle, seed)\n \n     def next(self):\n+        \"\"\"For python 2.x. Yields the next batch.\n+        \"\"\"\n         with self.lock:\n             index_array, current_index, current_batch_size = next(self.index_generator)\n         # The transformation of images is not under thread lock\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
