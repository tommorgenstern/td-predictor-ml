{"custom_id": "keras#ff0f78d114a7cb74bb961baddce1ba351b5a51fe", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 218 | Lines Deleted: 23 | Files Changed: 10 | Hunks: 14 | Methods Changed: 16 | Complexity Δ (Sum/Max): 25/13 | Churn Δ: 241 | Churn Cumulative: 2853 | Contributors (this commit): 11 | Commits (past 90d): 112 | Contributors (cumulative): 27 | DMM Complexity: 0.5056179775280899\n\nDIFF:\n@@ -105,6 +105,7 @@ from keras_core.layers.reshaping.repeat_vector import RepeatVector\n from keras_core.layers.reshaping.reshape import Reshape\n from keras_core.layers.reshaping.up_sampling1d import UpSampling1D\n from keras_core.layers.reshaping.up_sampling3d import UpSampling3D\n+from keras_core.layers.reshaping.zero_padding2d import ZeroPadding2D\n from keras_core.layers.reshaping.zero_padding3d import ZeroPadding3D\n from keras_core.layers.rnn.bidirectional import Bidirectional\n from keras_core.layers.rnn.conv_lstm1d import ConvLSTM1D\n\n@@ -7,7 +7,7 @@ from keras_core import operations as ops\n from keras_core import testing\n \n \n-class CroppingTest(testing.TestCase):\n+class Cropping1DTest(testing.TestCase):\n     def test_cropping_1d(self):\n         inputs = np.random.rand(3, 5, 7)\n \n@@ -51,10 +51,10 @@ class CroppingTest(testing.TestCase):\n         not backend.DYNAMIC_SHAPES_OK,\n         reason=\"Backend does not support dynamic shapes\",\n     )\n-    def test_cropping_1d_with_dynamic_batch_size(self):\n-        input_layer = layers.Input(batch_shape=(None, 5, 7))\n-        permuted = layers.Cropping1D((1, 2))(input_layer)\n-        self.assertEqual(permuted.shape, (None, 2, 7))\n+    def test_cropping_1d_with_dynamic_spatial_dim(self):\n+        input_layer = layers.Input(batch_shape=(1, None, 7))\n+        cropped = layers.Cropping1D((1, 2))(input_layer)\n+        self.assertEqual(cropped.shape, (1, None, 7))\n \n     def test_cropping_1d_errors_if_cropping_more_than_available(self):\n         with self.assertRaises(ValueError):\n\n@@ -26,7 +26,7 @@ class Cropping2D(Layer):\n               cropping values for height and width:\n               `(symmetric_height_crop, symmetric_width_crop)`.\n             - If tuple of 2 tuples of 2 ints: interpreted as\n-              `((top_crop, bottom_crop), (left_crop, right_crop))`\n+              `((top_crop, bottom_crop), (left_crop, right_crop))`.\n         data_format: A string, one of `\"channels_last\"` (default) or\n             `\"channels_first\"`. The ordering of the dimensions in the inputs.\n             `\"channels_last\"` corresponds to inputs with shape\n\n@@ -8,7 +8,7 @@ from keras_core import operations as ops\n from keras_core import testing\n \n \n-class CroppingTest(testing.TestCase, parameterized.TestCase):\n+class Cropping2DTest(testing.TestCase, parameterized.TestCase):\n     @parameterized.product(\n         (\n             # different cropping values\n@@ -66,10 +66,10 @@ class CroppingTest(testing.TestCase, parameterized.TestCase):\n         not backend.DYNAMIC_SHAPES_OK,\n         reason=\"Backend does not support dynamic shapes\",\n     )\n-    def test_cropping_2d_with_dynamic_batch_size(self):\n-        input_layer = layers.Input(batch_shape=(None, 7, 9, 5))\n-        permuted = layers.Cropping2D(((1, 2), (3, 4)))(input_layer)\n-        self.assertEqual(permuted.shape, (None, 4, 2, 5))\n+    def test_cropping_2d_with_dynamic_spatial_dim(self):\n+        input_layer = layers.Input(batch_shape=(1, 7, None, 5))\n+        cropped = layers.Cropping2D(((1, 2), (3, 4)))(input_layer)\n+        self.assertEqual(cropped.shape, (1, 4, None, 5))\n \n     @parameterized.product(\n         (\n\n@@ -25,7 +25,7 @@ class Cropping3D(Layer):\n               `(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)`.\n             - If tuple of 3 tuples of 2 ints: interpreted as\n               `((left_dim1_crop, right_dim1_crop), (left_dim2_crop,\n-              right_dim2_crop), (left_dim3_crop, right_dim3_crop))`\n+              right_dim2_crop), (left_dim3_crop, right_dim3_crop))`.\n         data_format: A string, one of `\"channels_last\"` (default) or\n             `\"channels_first\"`. The ordering of the dimensions in the inputs.\n             `\"channels_last\"` corresponds to inputs with shape\n\n@@ -8,7 +8,7 @@ from keras_core import operations as ops\n from keras_core import testing\n \n \n-class CroppingTest(testing.TestCase, parameterized.TestCase):\n+class Cropping3DTest(testing.TestCase, parameterized.TestCase):\n     @parameterized.product(\n         (\n             {\"dim1_cropping\": (1, 2), \"dim1_expected\": (1, 5)},  # both\n@@ -125,10 +125,10 @@ class CroppingTest(testing.TestCase, parameterized.TestCase):\n         not backend.DYNAMIC_SHAPES_OK,\n         reason=\"Backend does not support dynamic shapes\",\n     )\n-    def test_cropping_3d_with_dynamic_batch_size(self):\n-        input_layer = layers.Input(batch_shape=(None, 7, 9, 13, 5))\n-        permuted = layers.Cropping3D(((1, 2), (3, 4), (5, 6)))(input_layer)\n-        self.assertEqual(permuted.shape, (None, 4, 2, 2, 5))\n+    def test_cropping_3d_with_dynamic_spatial_dim(self):\n+        input_layer = layers.Input(batch_shape=(1, 7, None, 13, 5))\n+        cropped = layers.Cropping3D(((1, 2), (3, 4), (5, 6)))(input_layer)\n+        self.assertEqual(cropped.shape, (1, 4, None, 2, 5))\n \n     @parameterized.product(\n         (\n\n@@ -0,0 +1,118 @@\n+from keras_core import backend\n+from keras_core import operations as ops\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.input_spec import InputSpec\n+from keras_core.layers.layer import Layer\n+\n+\n+@keras_core_export(\"keras_core.layers.ZeroPadding2D\")\n+class ZeroPadding2D(Layer):\n+    \"\"\"Zero-padding layer for 2D input (e.g. picture).\n+\n+    This layer can add rows and columns of zeros at the top, bottom, left and\n+    right side of an image tensor.\n+\n+    Examples:\n+\n+    >>> input_shape = (1, 1, 2, 2)\n+    >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n+    >>> x\n+    [[[[0 1]\n+       [2 3]]]]\n+    >>> y = keras_core.layers.ZeroPadding2D(padding=1)(x)\n+    >>> y\n+    [[[[0 0]\n+       [0 0]\n+       [0 0]\n+       [0 0]]\n+      [[0 0]\n+       [0 1]\n+       [2 3]\n+       [0 0]]\n+      [[0 0]\n+       [0 0]\n+       [0 0]\n+       [0 0]]]]\n+\n+    Args:\n+        padding: Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n+            - If int: the same symmetric padding is applied to height and width.\n+            - If tuple of 2 ints: interpreted as two different symmetric padding\n+              values for height and width:\n+              `(symmetric_height_pad, symmetric_width_pad)`.\n+            - If tuple of 2 tuples of 2 ints: interpreted as\n+             `((top_pad, bottom_pad), (left_pad, right_pad))`.\n+        data_format: A string, one of `\"channels_last\"` (default) or\n+            `\"channels_first\"`. The ordering of the dimensions in the inputs.\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch_size, height, width, channels)` while `\"channels_first\"`\n+            corresponds to inputs with shape\n+            `(batch_size, channels, height, width)`.\n+            When unspecified, uses `image_data_format` value found in your Keras\n+            config file at `~/.keras/keras.json` (if exists). Defaults to\n+            `\"channels_last\"`.\n+\n+    Input shape:\n+        4D tensor with shape:\n+        - If `data_format` is `\"channels_last\"`:\n+          `(batch_size, height, width, channels)`\n+        - If `data_format` is `\"channels_first\"`:\n+          `(batch_size, channels, height, width)`\n+\n+    Output shape:\n+        4D tensor with shape:\n+        - If `data_format` is `\"channels_last\"`:\n+          `(batch_size, padded_height, padded_width, channels)`\n+        - If `data_format` is `\"channels_first\"`:\n+          `(batch_size, channels, padded_height, padded_width)`\n+    \"\"\"\n+\n+    def __init__(self, padding=(1, 1), data_format=None, **kwargs):\n+        super().__init__(**kwargs)\n+        self.data_format = backend.standardize_data_format(data_format)\n+        if isinstance(padding, int):\n+            self.padding = ((padding, padding), (padding, padding))\n+        elif hasattr(padding, \"__len__\"):\n+            if len(padding) != 2:\n+                raise ValueError(\n+                    \"`padding` should have two elements. \"\n+                    f\"Received: padding={padding}.\"\n+                )\n+            height_padding = padding[0]\n+            if isinstance(height_padding, int):\n+                height_padding = (height_padding, height_padding)\n+            width_padding = padding[1]\n+            if isinstance(width_padding, int):\n+                width_padding = (width_padding, width_padding)\n+            self.padding = (height_padding, width_padding)\n+        else:\n+            raise ValueError(\n+                \"`padding` should be either an int, a tuple of 2 ints \"\n+                \"(symmetric_height_crop, symmetric_width_crop), \"\n+                \"or a tuple of 2 tuples of 2 ints \"\n+                \"((top_crop, bottom_crop), (left_crop, right_crop)). \"\n+                f\"Received: padding={padding}.\"\n+            )\n+        self.input_spec = InputSpec(ndim=4)\n+\n+    def compute_output_shape(self, input_shape):\n+        output_shape = list(input_shape)\n+        spatial_dims_offset = 2 if self.data_format == \"channels_first\" else 1\n+        for index in range(0, 2):\n+            if output_shape[index + spatial_dims_offset] is not None:\n+                output_shape[index + spatial_dims_offset] += (\n+                    self.padding[index][0] + self.padding[index][1]\n+                )\n+        return tuple(output_shape)\n+\n+    def call(self, inputs):\n+        if self.data_format == \"channels_first\":\n+            all_dims_padding = ((0, 0), (0, 0), *self.padding)\n+        else:\n+            all_dims_padding = ((0, 0), *self.padding, (0, 0))\n+        return ops.pad(inputs, all_dims_padding)\n+\n+    def get_config(self):\n+        config = {\"padding\": self.padding, \"data_format\": self.data_format}\n+        base_config = super().get_config()\n+        return {**base_config, **config}\n\n@@ -0,0 +1,76 @@\n+import numpy as np\n+import pytest\n+from absl.testing import parameterized\n+\n+from keras_core import backend\n+from keras_core import layers\n+from keras_core import testing\n+\n+\n+class ZeroPadding2DTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.named_parameters(\n+        (\"channels_first\", \"channels_first\"), (\"channels_last\", \"channels_last\")\n+    )\n+    def test_zero_padding_2d(self, data_format):\n+        inputs = np.random.rand(1, 2, 3, 4)\n+        outputs = layers.ZeroPadding2D(\n+            padding=((1, 2), (3, 4)), data_format=data_format\n+        )(inputs)\n+\n+        if data_format == \"channels_first\":\n+            for index in [0, -1, -2]:\n+                self.assertAllClose(outputs[:, :, index, :], 0.0)\n+            for index in [0, 1, 2, -1, -2, -3, -4]:\n+                self.assertAllClose(outputs[:, :, :, index], 0.0)\n+            self.assertAllClose(outputs[:, :, 1:-2, 3:-4], inputs)\n+        else:\n+            for index in [0, -1, -2]:\n+                self.assertAllClose(outputs[:, index, :, :], 0.0)\n+            for index in [0, 1, 2, -1, -2, -3, -4]:\n+                self.assertAllClose(outputs[:, :, index, :], 0.0)\n+            self.assertAllClose(outputs[:, 1:-2, 3:-4, :], inputs)\n+\n+    @parameterized.product(\n+        (\n+            {\"padding\": ((2, 2), (2, 2))},  # 2 tuples\n+            {\"padding\": (2, 2)},  # 1 tuple\n+            {\"padding\": 2},  # 1 int\n+        ),\n+        (\n+            {\"data_format\": \"channels_first\"},\n+            {\"data_format\": \"channels_last\"},\n+        ),\n+    )\n+    def test_zero_padding_2d_with_same_padding(self, padding, data_format):\n+        inputs = np.random.rand(1, 2, 3, 4)\n+        outputs = layers.ZeroPadding2D(\n+            padding=padding, data_format=data_format\n+        )(inputs)\n+\n+        if data_format == \"channels_first\":\n+            for index in [0, 1, -1, -2]:\n+                self.assertAllClose(outputs[:, :, index, :], 0.0)\n+                self.assertAllClose(outputs[:, :, :, index], 0.0)\n+            self.assertAllClose(outputs[:, :, 2:-2, 2:-2], inputs)\n+        else:\n+            for index in [0, 1, -1, -2]:\n+                self.assertAllClose(outputs[:, index, :, :], 0.0)\n+                self.assertAllClose(outputs[:, :, index, :], 0.0)\n+            self.assertAllClose(outputs[:, 2:-2, 2:-2, :], inputs)\n+\n+    @pytest.mark.skipif(\n+        not backend.DYNAMIC_SHAPES_OK,\n+        reason=\"Backend does not support dynamic shapes\",\n+    )\n+    def test_zero_padding_2d_with_dynamic_spatial_dim(self):\n+        input_layer = layers.Input(batch_shape=(1, 2, None, 4))\n+        padded = layers.ZeroPadding2D(((1, 2), (3, 4)))(input_layer)\n+        self.assertEqual(padded.shape, (1, 5, None, 4))\n+\n+    def test_zero_padding_2d_errors_if_padding_argument_invalid(self):\n+        with self.assertRaises(ValueError):\n+            layers.ZeroPadding2D(padding=(1,))\n+        with self.assertRaises(ValueError):\n+            layers.ZeroPadding2D(padding=(1, 2, 3))\n+        with self.assertRaises(ValueError):\n+            layers.ZeroPadding2D(padding=\"1\")\n\n@@ -26,7 +26,7 @@ class ZeroPadding3D(Layer):\n               `(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad)`.\n             - If tuple of 3 tuples of 2 ints: interpreted as\n               `((left_dim1_pad, right_dim1_pad), (left_dim2_pad,\n-              right_dim2_pad), (left_dim3_pad, right_dim3_pad))`\n+              right_dim2_pad), (left_dim3_pad, right_dim3_pad))`.\n         data_format: A string, one of `\"channels_last\"` (default) or\n             `\"channels_first\"`. The ordering of the dimensions in the inputs.\n             `\"channels_last\"` corresponds to inputs with shape\n\n@@ -7,7 +7,7 @@ from keras_core import layers\n from keras_core import testing\n \n \n-class ZeroPaddingTest(testing.TestCase, parameterized.TestCase):\n+class ZeroPadding3DTest(testing.TestCase, parameterized.TestCase):\n     @parameterized.named_parameters(\n         (\"channels_first\", \"channels_first\"), (\"channels_last\", \"channels_last\")\n     )\n@@ -68,10 +68,10 @@ class ZeroPaddingTest(testing.TestCase, parameterized.TestCase):\n         not backend.DYNAMIC_BATCH_SIZE_OK,\n         reason=\"Backend does not support dynamic batch sizes\",\n     )\n-    def test_zero_padding_3d_with_dynamic_batch_size(self):\n-        input_layer = layers.Input(batch_shape=(None, 2, 3, 4, 5))\n-        permuted = layers.ZeroPadding3D(((1, 2), (3, 4), (5, 6)))(input_layer)\n-        self.assertEqual(permuted.shape, (None, 5, 10, 15, 5))\n+    def test_zero_padding_3d_with_dynamic_spatial_dim(self):\n+        input_layer = layers.Input(batch_shape=(1, 2, None, 4, 5))\n+        padded = layers.ZeroPadding3D(((1, 2), (3, 4), (5, 6)))(input_layer)\n+        self.assertEqual(padded.shape, (1, 5, None, 15, 5))\n \n     def test_zero_padding_3d_errors_if_padding_argument_invalid(self):\n         with self.assertRaises(ValueError):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#44caf660418a051df7359603eaeaae9bd8e1e8fb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 45 | Lines Deleted: 25 | Files Changed: 4 | Hunks: 46 | Methods Changed: 44 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 70 | Churn Cumulative: 13687 | Contributors (this commit): 12 | Commits (past 90d): 92 | Contributors (cumulative): 26 | DMM Complexity: 0.8888888888888888\n\nDIFF:\n@@ -4,6 +4,7 @@ import numpy as np\n from jax import lax\n from jax import nn as jnn\n \n+from keras_core.backend import standardize_data_format\n from keras_core.backend.common.backend_utils import (\n     compute_conv_transpose_output_length,\n )\n@@ -135,8 +136,9 @@ def max_pool(\n     pool_size,\n     strides=None,\n     padding=\"valid\",\n-    data_format=\"channels_last\",\n+    data_format=None,\n ):\n+    data_format = standardize_data_format(data_format)\n     num_spatial_dims = inputs.ndim - 2\n     pool_size = _convert_to_spatial_operand(\n         pool_size, num_spatial_dims, data_format\n@@ -153,8 +155,9 @@ def average_pool(\n     pool_size,\n     strides,\n     padding,\n-    data_format=\"channels_last\",\n+    data_format=None,\n ):\n+    data_format = standardize_data_format(data_format)\n     num_spatial_dims = inputs.ndim - 2\n     pool_size = _convert_to_spatial_operand(\n         pool_size, num_spatial_dims, data_format\n@@ -217,9 +220,10 @@ def conv(\n     kernel,\n     strides=1,\n     padding=\"valid\",\n-    data_format=\"channels_last\",\n+    data_format=None,\n     dilation_rate=1,\n ):\n+    data_format = standardize_data_format(data_format)\n     num_spatial_dims = inputs.ndim - 2\n     dimension_numbers = _convert_to_lax_conv_dimension_numbers(\n         num_spatial_dims,\n@@ -266,9 +270,10 @@ def depthwise_conv(\n     kernel,\n     strides=1,\n     padding=\"valid\",\n-    data_format=\"channels_last\",\n+    data_format=None,\n     dilation_rate=1,\n ):\n+    data_format = standardize_data_format(data_format)\n     num_spatial_dims = inputs.ndim - 2\n     dimension_numbers = _convert_to_lax_conv_dimension_numbers(\n         num_spatial_dims,\n@@ -311,9 +316,10 @@ def separable_conv(\n     pointwise_kernel,\n     strides=1,\n     padding=\"valid\",\n-    data_format=\"channels_last\",\n+    data_format=None,\n     dilation_rate=1,\n ):\n+    data_format = standardize_data_format(data_format)\n     depthwise_conv_output = depthwise_conv(\n         inputs,\n         depthwise_kernel,\n@@ -413,9 +419,10 @@ def conv_transpose(\n     strides=1,\n     padding=\"valid\",\n     output_padding=None,\n-    data_format=\"channels_last\",\n+    data_format=None,\n     dilation_rate=1,\n ):\n+    data_format = standardize_data_format(data_format)\n     num_spatial_dims = inputs.ndim - 2\n     padding_values = _compute_padding_values(\n         inputs.shape,\n\n@@ -2,6 +2,7 @@ import warnings\n \n import tensorflow as tf\n \n+from keras_core.backend import standardize_data_format\n from keras_core.backend.common.backend_utils import (\n     compute_conv_transpose_output_shape,\n )\n@@ -126,8 +127,9 @@ def max_pool(\n     pool_size,\n     strides=None,\n     padding=\"valid\",\n-    data_format=\"channels_last\",\n+    data_format=None,\n ):\n+    data_format = standardize_data_format(data_format)\n     strides = pool_size if strides is None else strides\n     padding = padding.upper()\n     tf_data_format = _convert_data_format(\"channels_last\", len(inputs.shape))\n@@ -153,8 +155,9 @@ def average_pool(\n     pool_size,\n     strides=None,\n     padding=\"valid\",\n-    data_format=\"channels_last\",\n+    data_format=None,\n ):\n+    data_format = standardize_data_format(data_format)\n     strides = pool_size if strides is None else strides\n     padding = padding.upper()\n     tf_data_format = _convert_data_format(\"channels_last\", len(inputs.shape))\n@@ -212,7 +215,7 @@ def conv(\n     kernel,\n     strides=1,\n     padding=\"valid\",\n-    data_format=\"channel_last\",\n+    data_format=None,\n     dilation_rate=1,\n ):\n     def _conv():\n@@ -232,6 +235,7 @@ def conv(\n     def _conv_xla():\n         return _conv()\n \n+    data_format = standardize_data_format(data_format)\n     if data_format == \"channels_last\":\n         channels = inputs.shape[-1]\n     else:\n@@ -248,9 +252,10 @@ def depthwise_conv(\n     kernel,\n     strides=1,\n     padding=\"valid\",\n-    data_format=\"channels_last\",\n+    data_format=None,\n     dilation_rate=1,\n ):\n+    data_format = standardize_data_format(data_format)\n     num_spatial_dims = len(inputs.shape) - 2\n     if num_spatial_dims > 2:\n         raise ValueError(\n@@ -310,9 +315,10 @@ def separable_conv(\n     pointwise_kernel,\n     strides=1,\n     padding=\"valid\",\n-    data_format=\"channels_last\",\n+    data_format=None,\n     dilation_rate=1,\n ):\n+    data_format = standardize_data_format(data_format)\n     num_spatial_dims = len(inputs.shape) - 2\n     if num_spatial_dims > 2:\n         raise ValueError(\n@@ -372,9 +378,10 @@ def conv_transpose(\n     strides=1,\n     padding=\"valid\",\n     output_padding=None,\n-    data_format=\"channels_last\",\n+    data_format=None,\n     dilation_rate=1,\n ):\n+    data_format = standardize_data_format(data_format)\n     tf_data_format = _convert_data_format(data_format, len(inputs.shape))\n     kernel_size = kernel.shape[:-2]\n     filters = kernel.shape[-2]\n\n@@ -33,6 +33,7 @@ from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.backend import KerasTensor\n from keras_core.backend import any_symbolic_tensors\n+from keras_core.backend import standardize_data_format\n from keras_core.backend.common.backend_utils import (\n     compute_conv_transpose_output_shape,\n )\n@@ -343,7 +344,7 @@ class MaxPool(Operation):\n         pool_size,\n         strides=None,\n         padding=\"valid\",\n-        data_format=\"channels_last\",\n+        data_format=None,\n     ):\n         super().__init__()\n         self.pool_size = pool_size\n@@ -379,7 +380,7 @@ def max_pool(\n     pool_size,\n     strides=None,\n     padding=\"valid\",\n-    data_format=\"channels_last\",\n+    data_format=None,\n ):\n     \"\"\"Max pooling operation.\n \n@@ -413,6 +414,7 @@ def max_pool(\n     Returns:\n         A tensor of rank N+2, the result of the max pooling operation.\n     \"\"\"\n+    data_format = standardize_data_format(data_format)\n     if any_symbolic_tensors((inputs,)):\n         return MaxPool(\n             pool_size,\n@@ -429,7 +431,7 @@ class AveragePool(Operation):\n         pool_size,\n         strides=None,\n         padding=\"valid\",\n-        data_format=\"channels_last\",\n+        data_format=None,\n     ):\n         super().__init__()\n         self.pool_size = pool_size\n@@ -468,7 +470,7 @@ def average_pool(\n     pool_size,\n     strides=None,\n     padding=\"valid\",\n-    data_format=\"channels_last\",\n+    data_format=None,\n ):\n     \"\"\"Average pooling operation.\n \n@@ -502,6 +504,7 @@ def average_pool(\n     Returns:\n         A tensor of rank N+2, the result of the average pooling operation.\n     \"\"\"\n+    data_format = standardize_data_format(data_format)\n     if any_symbolic_tensors((inputs,)):\n         return AveragePool(\n             pool_size,\n@@ -519,7 +522,7 @@ class Conv(Operation):\n         self,\n         strides=1,\n         padding=\"valid\",\n-        data_format=\"channel_last\",\n+        data_format=None,\n         dilation_rate=1,\n     ):\n         super().__init__()\n@@ -559,7 +562,7 @@ def conv(\n     kernel,\n     strides=1,\n     padding=\"valid\",\n-    data_format=\"channels_last\",\n+    data_format=None,\n     dilation_rate=1,\n ):\n     \"\"\"General N-D convolution.\n@@ -599,6 +602,7 @@ def conv(\n     Returns:\n         A tensor of rank N+2, the result of the conv operation.\n     \"\"\"\n+    data_format = standardize_data_format(data_format)\n     if any_symbolic_tensors((inputs,)):\n         return Conv(strides, padding, data_format, dilation_rate).symbolic_call(\n             inputs, kernel\n@@ -613,7 +617,7 @@ class DepthwiseConv(Operation):\n         self,\n         strides=1,\n         padding=\"valid\",\n-        data_format=\"channels_last\",\n+        data_format=None,\n         dilation_rate=1,\n     ):\n         super().__init__()\n@@ -656,7 +660,7 @@ def depthwise_conv(\n     kernel,\n     strides=1,\n     padding=\"valid\",\n-    data_format=\"channels_last\",\n+    data_format=None,\n     dilation_rate=1,\n ):\n     \"\"\"General N-D depthwise convolution.\n@@ -696,6 +700,7 @@ def depthwise_conv(\n     Returns:\n         A tensor of rank N+2, the result of the depthwise conv operation.\n     \"\"\"\n+    data_format = standardize_data_format(data_format)\n     if any_symbolic_tensors((inputs,)):\n         return DepthwiseConv(\n             strides, padding, data_format, dilation_rate\n@@ -715,7 +720,7 @@ class SeparableConv(Operation):\n         self,\n         strides=1,\n         padding=\"valid\",\n-        data_format=\"channels_last\",\n+        data_format=None,\n         dilation_rate=1,\n     ):\n         super().__init__()\n@@ -765,7 +770,7 @@ def separable_conv(\n     pointwise_kernel,\n     strides=1,\n     padding=\"valid\",\n-    data_format=\"channels_last\",\n+    data_format=None,\n     dilation_rate=1,\n ):\n     \"\"\"General N-D separable convolution.\n@@ -809,6 +814,7 @@ def separable_conv(\n     Returns:\n         A tensor of rank N+2, the result of the depthwise conv operation.\n     \"\"\"\n+    data_format = standardize_data_format(data_format)\n     if any_symbolic_tensors((inputs,)):\n         return SeparableConv(\n             strides,\n@@ -833,7 +839,7 @@ class ConvTranspose(Operation):\n         strides,\n         padding=\"valid\",\n         output_padding=None,\n-        data_format=\"channels_last\",\n+        data_format=None,\n         dilation_rate=1,\n     ):\n         super().__init__()\n@@ -886,7 +892,7 @@ def conv_transpose(\n     strides,\n     padding=\"valid\",\n     output_padding=None,\n-    data_format=\"channels_last\",\n+    data_format=None,\n     dilation_rate=1,\n ):\n     \"\"\"General N-D convolution transpose.\n@@ -933,6 +939,7 @@ def conv_transpose(\n     Returns:\n         A tensor of rank N+2, the result of the conv operation.\n     \"\"\"\n+    data_format = standardize_data_format(data_format)\n     if any_symbolic_tensors((inputs,)):\n         return ConvTranspose(\n             strides, padding, output_padding, data_format, dilation_rate\n\n@@ -1849,7 +1849,6 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n         reason=\"`torch.linspace` has no support for array start/stop.\",\n     )\n     def test_linspace_without_torch(self):\n-\n         start = np.zeros([2, 3, 4])\n         stop = np.ones([2, 3, 4])\n         self.assertAllClose(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fbda0e8872bd0afa17af4b62e09cdb979a53aab8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 14 | Churn Cumulative: 592 | Contributors (this commit): 7 | Commits (past 90d): 3 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -38,9 +38,9 @@ ONE_HOT = utils.ONE_HOT\n class HashedCrossing(base_layer.Layer):\n     \"\"\"A preprocessing layer which crosses features using the \"hashing trick\".\n \n-    This layer performs crosses of categorical features using the \"hasing\n+    This layer performs crosses of categorical features using the \"hashing\n     trick\". Conceptually, the transformation can be thought of as:\n-    hash(concatenation of features) % `num_bins`.\n+    `hash(concatenate(features)) % num_bins`.\n \n     This layer currently only performs crosses of scalar inputs and batches of\n     scalar inputs. Valid input shapes are `(batch_size, 1)`, `(batch_size,)` and\n@@ -55,11 +55,11 @@ class HashedCrossing(base_layer.Layer):\n             `\"int\"`, or `\"one_hot\"` configuring the layer as follows:\n             - `\"int\"`: Return the integer bin indices directly.\n             - `\"one_hot\"`: Encodes each individual element in the input into an\n-            array the same size as `num_bins`, containing a 1 at the input's bin\n-            index.\n-        Defaults to `\"int\"`.\n-      sparse: Boolean. Only applicable to `\"one_hot\"` mode. If True, returns a\n-        `SparseTensor` instead of a dense `Tensor`. Defaults to `False`.\n+                array the same size as `num_bins`, containing a 1 at the input's\n+                bin index. Defaults to `\"int\"`.\n+        sparse: Boolean. Only applicable to `\"one_hot\"` mode. If `True`,\n+            returns a `SparseTensor` instead of a dense `Tensor`.\n+            Defaults to `False`.\n         **kwargs: Keyword arguments to construct a layer.\n \n     Examples:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ed4d749199c0cb4fe17b02cdaa0fddd7600c27a8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 858 | Contributors (this commit): 5 | Commits (past 90d): 24 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -372,6 +372,7 @@ PYTHON_DTYPES_MAP = {\n     bool: \"bool\",\n     int: \"int\",  # TBD by backend\n     float: \"float32\",\n+    str: \"string\",\n }\n \n \n\n@@ -65,7 +65,7 @@ class ZeroPadding3DTest(testing.TestCase, parameterized.TestCase):\n             self.assertAllClose(outputs[:, 2:-2, 2:-2, 2:-2, :], inputs)\n \n     @pytest.mark.skipif(\n-        not backend.DYNAMIC_BATCH_SIZE_OK,\n+        not backend.DYNAMIC_SHAPES_OK,\n         reason=\"Backend does not support dynamic batch sizes\",\n     )\n     def test_zero_padding_3d_with_dynamic_spatial_dim(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#752f4b581b34e0b261453f41c292a706080b9d01", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 279 | Lines Deleted: 66 | Files Changed: 8 | Hunks: 34 | Methods Changed: 35 | Complexity Δ (Sum/Max): 25/8 | Churn Δ: 345 | Churn Cumulative: 5815 | Contributors (this commit): 10 | Commits (past 90d): 70 | Contributors (cumulative): 33 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3,6 +3,11 @@ import jax.numpy as jnp\n \n \n def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n+    if num_segments is None:\n+        raise ValueError(\n+            \"Argument `num_segments` must be set when using the JAX backend. \"\n+            \"Received: num_segments=None\"\n+        )\n     return jax.ops.segment_sum(\n         data, segment_ids, num_segments, indices_are_sorted=sorted\n     )\n@@ -17,16 +22,16 @@ def top_k(x, k, sorted=True):\n \n \n def in_top_k(targets, predictions, k):\n-    topk_indices = top_k(predictions, k)[1]\n     targets = targets[..., None]\n-    mask = targets == topk_indices\n+    topk_values = top_k(predictions, k)[0]\n+    targets_values = jnp.take_along_axis(predictions, targets, axis=-1)\n+    mask = targets_values >= topk_values\n     return jax.numpy.any(mask, axis=1)\n \n \n def logsumexp(x, axis=None, keepdims=False):\n     max_x = jnp.max(x, axis=axis, keepdims=True)\n     result = (\n-        jnp.log(jnp.sum(jnp.exp(x - max_x), axis=axis, keepdims=keepdims))\n-        + max_x\n+        jnp.log(jnp.sum(jnp.exp(x - max_x), axis=axis, keepdims=True)) + max_x\n     )\n     return jnp.squeeze(result) if not keepdims else result\n\n@@ -5,6 +5,9 @@ def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n     if sorted:\n         return tf.math.segment_sum(data, segment_ids)\n     else:\n+        if num_segments is None:\n+            unique_segment_ids, _ = tf.unique(segment_ids)\n+            num_segments = tf.shape(unique_segment_ids)[0]\n         return tf.math.unsorted_segment_sum(data, segment_ids, num_segments)\n \n \n\n@@ -49,7 +49,7 @@ class Variable(KerasVariable):\n \n def convert_to_tensor(x, dtype=None):\n     # TODO: Need to address device placement arg of `as_tensor`\n-    dtype = to_torch_dtype(dtype or x.dtype)\n+    dtype = to_torch_dtype(dtype or getattr(x, \"dtype\", None))\n     if isinstance(x, Variable):\n         if dtype and dtype != x.dtype:\n             return x.value.to(dtype)\n\n@@ -0,0 +1,49 @@\n+import torch\n+\n+from keras_core.backend.torch.core import convert_to_tensor\n+\n+\n+def segment_sum(data, segment_ids, num_segments=None, **kwargs):\n+    data = convert_to_tensor(data)\n+    segment_ids = convert_to_tensor(segment_ids)\n+    num_repeats = torch.prod(torch.tensor(data.shape[1:])).long()\n+    # To use `scatter_add` in torch, we need to replicate `segment_ids` into the\n+    # shape of `data`.\n+    segment_ids = (\n+        segment_ids.repeat_interleave(num_repeats)\n+        .view(*data.shape)\n+        .type(torch.int64)\n+    )\n+    num_segments = num_segments or len(torch.unique(segment_ids))\n+    shape = (num_segments,) + tuple(data.shape[1:])\n+    result = torch.zeros(*shape).scatter_add(0, segment_ids, data.float())\n+    return result.type(data.dtype)\n+\n+\n+def top_k(x, k, sorted=True):\n+    x = convert_to_tensor(x)\n+    return torch.topk(x, k, sorted=sorted)\n+\n+\n+def in_top_k(targets, predictions, k):\n+    targets = convert_to_tensor(targets).type(torch.int64)\n+    targets = targets[:, None]\n+    predictions = convert_to_tensor(predictions)\n+    topk_values = top_k(predictions, k).values\n+    targets_values = torch.take_along_dim(predictions, targets, dim=-1)\n+    mask = targets_values >= topk_values\n+    return torch.any(mask, axis=-1)\n+\n+\n+def logsumexp(x, axis=None, keepdims=False):\n+    x = convert_to_tensor(x)\n+    if axis is None:\n+        max_x = torch.max(x)\n+        return torch.log(torch.sum(torch.exp(x - max_x))) + max_x\n+\n+    max_x = torch.max(x, dim=axis, keepdim=True).values\n+    result = (\n+        torch.log(torch.sum(torch.exp(x - max_x), dim=axis, keepdim=True))\n+        + max_x\n+    )\n+    return torch.squeeze(result, dim=axis) if not keepdims else result\n\n@@ -7,55 +7,102 @@ logsumexp\n \n from keras_core import backend\n from keras_core.api_export import keras_core_export\n+from keras_core.backend import KerasTensor\n from keras_core.backend import any_symbolic_tensors\n from keras_core.operations.operation import Operation\n+from keras_core.operations.operation_utils import reduce_shape\n \n \n class SegmentSum(Operation):\n-    def call(self, data, segment_ids, num_segments=None, sorted=False):\n-        return backend.math.segment_sum(data, segment_ids, num_segments, sorted)\n+    def __init__(self, num_segments=None, sorted=False):\n+        super().__init__()\n+        self.num_segments = num_segments\n+        self.sorted = sorted\n+\n+    def compute_output_spec(self, data, segment_ids):\n+        num_segments = self.num_segments\n+        output_shape = (num_segments,) + tuple(data.shape[1:])\n+        return KerasTensor(shape=output_shape, dtype=data.dtype)\n+\n+    def call(self, data, segment_ids):\n+        return backend.math.segment_sum(\n+            data,\n+            segment_ids,\n+            num_segments=self.num_segments,\n+            sorted=self.sorted,\n+        )\n \n \n @keras_core_export(\"keras_core.operations.segment_sum\")\n def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n     if any_symbolic_tensors((data,)):\n-        return SegmentSum().symbolic_call(\n-            data, segment_ids, num_segments, sorted\n+        return SegmentSum(num_segments, sorted).symbolic_call(data, segment_ids)\n+    return backend.math.segment_sum(\n+        data, segment_ids, num_segments=num_segments, sorted=sorted\n     )\n-    return backend.math.segment_sum(data, segment_ids, num_segments, sorted)\n \n \n class TopK(Operation):\n-    def call(self, x, k, sorted=True):\n-        return backend.math.top_k(x, k, sorted)\n+    def __init__(self, k, sorted=False):\n+        super().__init__()\n+        self.k = k\n+        self.sorted = sorted\n+\n+    def compute_output_spec(self, x):\n+        output_shape = list(x.shape)\n+        output_shape[-1] = self.k\n+        # Return a tuple (values, indices).\n+        return (\n+            KerasTensor(shape=output_shape, dtype=x.dtype),\n+            KerasTensor(shape=output_shape, dtype=\"int32\"),\n+        )\n+\n+    def call(self, x):\n+        return backend.math.top_k(x, self.k, self.sorted)\n \n \n @keras_core_export(\"keras_core.operations.top_k\")\n def top_k(x, k, sorted=True):\n     if any_symbolic_tensors((x,)):\n-        return TopK().symbolic_call(x, k, sorted)\n+        return TopK(k, sorted).symbolic_call(x)\n     return backend.math.top_k(x, k, sorted)\n \n \n class InTopK(Operation):\n-    def call(self, targets, predictions, k):\n-        return backend.math.in_top_k(targets, predictions, k)\n+    def __init__(self, k):\n+        super().__init__()\n+        self.k = k\n+\n+    def compute_output_spec(self, targets, predictions):\n+        return KerasTensor(shape=targets.shape, dtype=\"bool\")\n+\n+    def call(self, targets, predictions):\n+        return backend.math.in_top_k(targets, predictions, self.k)\n \n \n @keras_core_export(\"keras_core.operations.in_top_k\")\n def in_top_k(targets, predictions, k):\n     if any_symbolic_tensors((targets, predictions)):\n-        return InTopK().symbolic_call(targets, predictions, k)\n+        return InTopK(k).symbolic_call(targets, predictions)\n     return backend.math.in_top_k(targets, predictions, k)\n \n \n class Logsumexp(Operation):\n-    def call(self, x, axis=None, keepdims=False):\n-        return backend.math.logsumexp(x, axis=axis, keepdims=keepdims)\n+    def __init__(self, axis=None, keepdims=False):\n+        super().__init__()\n+        self.axis = axis\n+        self.keepdims = keepdims\n+\n+    def compute_output_spec(self, x):\n+        output_shape = reduce_shape(x.shape, self.axis, self.keepdims)\n+        return KerasTensor(shape=output_shape)\n+\n+    def call(self, x):\n+        return backend.math.logsumexp(x, axis=self.axis, keepdims=self.keepdims)\n \n \n @keras_core_export(\"keras_core.operations.logsumexp\")\n def logsumexp(x, axis=None, keepdims=False):\n     if any_symbolic_tensors((x,)):\n-        return Logsumexp().symbolic_call(x, axis=axis, keepdims=keepdims)\n+        return Logsumexp(axis, keepdims).symbolic_call(x)\n     return backend.math.logsumexp(x, axis=axis, keepdims=keepdims)\n\n@@ -1,5 +1,6 @@\n import numpy as np\n import pytest\n+import tensorflow as tf\n \n from keras_core import backend\n from keras_core import testing\n@@ -12,40 +13,165 @@ from keras_core.operations import math as kmath\n     reason=\"Backend does not support dynamic shapes\",\n )\n class MathOpsDynamicShapeTest(testing.TestCase):\n+    def test_segment_sum(self):\n+        data = KerasTensor((None, 4), dtype=\"float32\")\n+        segment_ids = KerasTensor((10,), dtype=\"int32\")\n+        outputs = kmath.segment_sum(data, segment_ids)\n+        self.assertEqual(outputs.shape, (None, 4))\n+\n+        data = KerasTensor((None, 4), dtype=\"float32\")\n+        segment_ids = KerasTensor((10,), dtype=\"int32\")\n+        outputs = kmath.segment_sum(data, segment_ids, num_segments=5)\n+        self.assertEqual(outputs.shape, (5, 4))\n+\n     def test_topk(self):\n-        x = KerasTensor([None, 2, 3])\n+        x = KerasTensor((None, 2, 3))\n         values, indices = kmath.top_k(x, k=1)\n         self.assertEqual(values.shape, (None, 2, 1))\n         self.assertEqual(indices.shape, (None, 2, 1))\n \n+    def test_in_top_k(self):\n+        targets = KerasTensor((None,))\n+        predictions = KerasTensor((None, 10))\n+        self.assertEqual(\n+            kmath.in_top_k(targets, predictions, k=1).shape, (None,)\n+        )\n+\n     def test_logsumexp(self):\n-        x = KerasTensor([None, 2, 3], dtype=\"float32\")\n+        x = KerasTensor((None, 2, 3), dtype=\"float32\")\n         result = kmath.logsumexp(x)\n         self.assertEqual(result.shape, ())\n \n \n class MathOpsStaticShapeTest(testing.TestCase):\n+    @pytest.mark.skipif(\n+        backend.backend() == \"jax\",\n+        reason=\"JAX does not support `num_segments=None`.\",\n+    )\n+    def test_segment_sum(self):\n+        data = KerasTensor((10, 4), dtype=\"float32\")\n+        segment_ids = KerasTensor((10,), dtype=\"int32\")\n+        outputs = kmath.segment_sum(data, segment_ids)\n+        self.assertEqual(outputs.shape, (None, 4))\n+\n+    def test_segment_sum_explicit_num_segments(self):\n+        data = KerasTensor((10, 4), dtype=\"float32\")\n+        segment_ids = KerasTensor((10,), dtype=\"int32\")\n+        outputs = kmath.segment_sum(data, segment_ids, num_segments=5)\n+        self.assertEqual(outputs.shape, (5, 4))\n+\n     def test_topk(self):\n-        x = KerasTensor([1, 2, 3])\n+        x = KerasTensor((1, 2, 3))\n         values, indices = kmath.top_k(x, k=1)\n         self.assertEqual(values.shape, (1, 2, 1))\n         self.assertEqual(indices.shape, (1, 2, 1))\n \n+    def test_in_top_k(self):\n+        targets = KerasTensor((5,))\n+        predictions = KerasTensor((5, 10))\n+        self.assertEqual(kmath.in_top_k(targets, predictions, k=1).shape, (5,))\n+\n     def test_logsumexp(self):\n-        x = KerasTensor([1, 2, 3], dtype=\"float32\")\n+        x = KerasTensor((1, 2, 3), dtype=\"float32\")\n         result = kmath.logsumexp(x)\n         self.assertEqual(result.shape, ())\n \n \n class MathOpsCorrectnessTest(testing.TestCase):\n-    def test_topk(self):\n+    @pytest.mark.skipif(\n+        backend.backend() == \"jax\",\n+        reason=\"JAX does not support `num_segments=None`.\",\n+    )\n+    def test_segment_sum(self):\n+        # Test 1D case.\n+        data = np.array([1, 2, 3, 4, 5, 6, 7, 8], dtype=np.float32)\n+        segment_ids = np.array([0, 0, 1, 1, 1, 2, 2, 2], dtype=np.int32)\n+        outputs = kmath.segment_sum(data, segment_ids)\n+        expected = tf.math.segment_sum(data, segment_ids)\n+        self.assertAllClose(outputs, expected)\n+\n+        # Test N-D case.\n+        data = np.random.rand(9, 3, 3)\n+        segment_ids = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2], dtype=np.int32)\n+        outputs = kmath.segment_sum(data, segment_ids)\n+        expected = tf.math.segment_sum(data, segment_ids)\n+        self.assertAllClose(outputs, expected)\n+\n+    def test_segment_sum_explicit_num_segments(self):\n+        # Test 1D case.\n+        data = np.array([1, 2, 3, 4, 5, 6, 7, 8], dtype=np.float32)\n+        segment_ids = np.array([0, 0, 1, 1, 1, 2, 2, 2], dtype=np.int32)\n+        outputs = kmath.segment_sum(data, segment_ids, num_segments=4)\n+        expected = tf.math.unsorted_segment_sum(\n+            data, segment_ids, num_segments=4\n+        )\n+        self.assertAllClose(outputs, expected)\n+\n+        # Test N-D case.\n+        data = np.random.rand(9, 3, 3)\n+        segment_ids = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2], dtype=np.int32)\n+        outputs = kmath.segment_sum(data, segment_ids, num_segments=4)\n+        expected = tf.math.unsorted_segment_sum(\n+            data, segment_ids, num_segments=4\n+        )\n+        self.assertAllClose(outputs, expected)\n+\n+    def test_top_k(self):\n         x = np.array([0, 4, 2, 1, 3, -1], dtype=np.float32)\n         values, indices = kmath.top_k(x, k=2)\n         self.assertAllClose(values, [4, 3])\n         self.assertAllClose(indices, [1, 4])\n \n+        x = np.random.rand(5, 5)\n+        outputs = kmath.top_k(x, k=2)\n+        expected = tf.math.top_k(x, k=2)\n+        self.assertAllClose(outputs[0], expected[0])\n+        self.assertAllClose(outputs[1], expected[1])\n+\n+    def test_in_top_k(self):\n+        targets = np.array([1, 0, 2])\n+        predictions = np.array(\n+            [\n+                [0.1, 0.9, 0.8, 0.8],\n+                [0.05, 0.95, 0, 1],\n+                [0.1, 0.8, 0.3, 1],\n+            ]\n+        )\n+        self.assertAllEqual(\n+            kmath.in_top_k(targets, predictions, k=1), [True, False, False]\n+        )\n+        self.assertAllEqual(\n+            kmath.in_top_k(targets, predictions, k=2), [True, False, False]\n+        )\n+        self.assertAllEqual(\n+            kmath.in_top_k(targets, predictions, k=3), [True, True, True]\n+        )\n+\n+        # Test tie cases.\n+        targets = np.array([1, 0, 2])\n+        predictions = np.array(\n+            [\n+                [0.1, 0.9, 0.8, 0.8],\n+                [0.95, 0.95, 0, 0.95],\n+                [0.1, 0.8, 0.8, 0.95],\n+            ]\n+        )\n+        self.assertAllEqual(\n+            kmath.in_top_k(targets, predictions, k=1), [True, True, False]\n+        )\n+        self.assertAllEqual(\n+            kmath.in_top_k(targets, predictions, k=2), [True, True, True]\n+        )\n+        self.assertAllEqual(\n+            kmath.in_top_k(targets, predictions, k=3), [True, True, True]\n+        )\n+\n     def test_logsumexp(self):\n-        x_np = np.random.rand(5, 5)\n-        y_tf_np = kmath.logsumexp(x_np)\n-        y_np = np.log(np.sum(np.exp(x_np)))\n-        self.assertAllClose(y_tf_np, y_np)\n+        x = np.random.rand(5, 5)\n+        outputs = kmath.logsumexp(x)\n+        expected = np.log(np.sum(np.exp(x)))\n+        self.assertAllClose(outputs, expected)\n+\n+        outputs = kmath.logsumexp(x, axis=1)\n+        expected = np.log(np.sum(np.exp(x), axis=1))\n+        self.assertAllClose(outputs, expected)\n\n@@ -142,14 +142,9 @@ from keras_core.backend import KerasTensor\n from keras_core.backend import any_symbolic_tensors\n from keras_core.operations import operation_utils\n from keras_core.operations.operation import Operation\n+from keras_core.operations.operation_utils import reduce_shape\n \n \n-@keras_core_export(\n-    [\n-        \"keras_core.operations.broadcast_shapes\",\n-        \"keras_core.operations.numpy.broadcast_shapes\",\n-    ]\n-)\n def broadcast_shapes(shape1, shape2):\n     # Broadcast input shapes to a unified shape.\n     # Convert to list for mutability.\n@@ -181,38 +176,6 @@ def broadcast_shapes(shape1, shape2):\n     return output_shape\n \n \n-@keras_core_export(\n-    [\n-        \"keras_core.operations.reduce_shape\",\n-        \"keras_core.operations.numpy.reduce_shape\",\n-    ]\n-)\n-def reduce_shape(shape, axis=None, keepdims=False):\n-    shape = list(shape)\n-    if axis is None:\n-        if keepdims:\n-            output_shape = [1 for _ in range(shape)]\n-        else:\n-            output_shape = []\n-        return output_shape\n-\n-    if keepdims:\n-        for ax in axis:\n-            shape[ax] = 1\n-        return shape\n-    else:\n-        for ax in axis:\n-            shape[ax] = -1\n-        output_shape = list(filter((-1).__ne__, shape))\n-        return output_shape\n-\n-\n-@keras_core_export(\n-    [\n-        \"keras_core.operations.shape_equal\",\n-        \"keras_core.operations.numpy.shape_equal\",\n-    ]\n-)\n def shape_equal(shape1, shape2, axis=None, allow_none=True):\n     \"\"\"Check if two shapes are equal.\n \n\n@@ -161,3 +161,23 @@ def compute_reshape_output_shape(input_shape, new_shape, new_shape_arg_name):\n     output_shape = list(new_shape)\n     output_shape[unknown_dim_index] = input_size // known_output_size\n     return tuple(output_shape)\n+\n+\n+def reduce_shape(shape, axis=None, keepdims=False):\n+    shape = list(shape)\n+    if axis is None:\n+        if keepdims:\n+            output_shape = [1 for _ in range(shape)]\n+        else:\n+            output_shape = []\n+        return output_shape\n+\n+    if keepdims:\n+        for ax in axis:\n+            shape[ax] = 1\n+        return shape\n+    else:\n+        for ax in axis:\n+            shape[ax] = -1\n+        output_shape = list(filter((-1).__ne__, shape))\n+        return output_shape\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6b90fb1bd34a8278874f70db44280edf4f46189f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 35 | Lines Deleted: 11 | Files Changed: 2 | Hunks: 7 | Methods Changed: 5 | Complexity Δ (Sum/Max): 5/3 | Churn Δ: 46 | Churn Cumulative: 26169 | Contributors (this commit): 145 | Commits (past 90d): 21 | Contributors (cumulative): 150 | DMM Complexity: 1.0\n\nDIFF:\n@@ -47,9 +47,16 @@ class MnistTest(test_util.DTensorBaseTest):\n             integration_test_utils.get_all_replicated_layout_map(mesh)\n         )\n \n+        self.assertIsInstance(model._train_counter, dtensor.DVariable)\n+        self.assertIsInstance(model._test_counter, dtensor.DVariable)\n+        self.assertIsInstance(model._predict_counter, dtensor.DVariable)\n+\n         optimizer = adam.Adam(learning_rate=0.001, mesh=mesh)\n         optimizer.build(model.trainable_variables)\n \n+        model.compile(loss=\"CategoricalCrossentropy\", optimizer=optimizer)\n+        self.assertIsInstance(model._steps_per_execution, dtensor.DVariable)\n+\n         train_losses = integration_test_utils.train_mnist_model_batch_sharded(\n             model,\n             optimizer,\n\n@@ -26,6 +26,7 @@ import tensorflow.compat.v2 as tf\n from keras import backend\n from keras import callbacks as callbacks_module\n from keras import optimizers\n+from keras.dtensor import dtensor_api\n from keras.dtensor import layout_map as layout_map_lib\n from keras.engine import base_layer\n from keras.engine import base_layer_utils\n@@ -320,6 +321,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n \n         self._steps_per_execution = None\n \n+        self._layout_map = layout_map_lib.get_current_layout_map()\n+\n         self._init_batch_counters()\n         self._base_model_initialized = True\n \n@@ -328,7 +331,25 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         # `fit`, `evaluate`, and `predict`.\n         self._jit_compile = None\n \n-        self._layout_map = layout_map_lib.get_current_layout_map()\n+    def _create_counter_variable(self, init_value):\n+        \"\"\"Helper function for counter variable creation.\n+\n+        For the DTensor use case with layout map, since the variable are not\n+        tracked by model, they can't be visited by the layout map, and need to\n+        be properly initialized as DVariable.\n+        \"\"\"\n+        # This function should be removed after we move to the strategy based\n+        # implementation for DTensor.\n+        if self._layout_map is None:\n+            agg = tf.VariableAggregation.ONLY_FIRST_REPLICA\n+            return tf.Variable(init_value, dtype=\"int64\", aggregation=agg)\n+        else:\n+            layout = dtensor_api.Layout.replicated(\n+                mesh=self._layout_map.get_default_mesh(), rank=0\n+            )\n+            return dtensor_api.DVariable(\n+                init_value, dtype=\"int64\", layout=layout\n+            )\n \n     @tf.__internal__.tracking.no_automatic_dependency_tracking\n     def _init_batch_counters(self):\n@@ -340,12 +361,10 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n             # inside tf.function.\n             # These variables are not connected to outputs so they have no\n             # effect on graph generation anyway.\n-            agg = tf.VariableAggregation.ONLY_FIRST_REPLICA\n-            self._train_counter = tf.Variable(0, dtype=\"int64\", aggregation=agg)\n-            self._test_counter = tf.Variable(0, dtype=\"int64\", aggregation=agg)\n-            self._predict_counter = tf.Variable(\n-                0, dtype=\"int64\", aggregation=agg\n-            )\n+\n+            self._train_counter = self._create_counter_variable(0)\n+            self._test_counter = self._create_counter_variable(0)\n+            self._predict_counter = self._create_counter_variable(0)\n \n     def __setattr__(self, name, value):\n         if not getattr(self, \"_self_setattr_tracking\", True):\n@@ -821,10 +840,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n \n     @tf.__internal__.tracking.no_automatic_dependency_tracking\n     def _configure_steps_per_execution(self, steps_per_execution):\n-        self._steps_per_execution = tf.Variable(\n-            steps_per_execution,\n-            dtype=\"int64\",\n-            aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA,\n+        self._steps_per_execution = self._create_counter_variable(\n+            steps_per_execution\n         )\n \n     @property\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
