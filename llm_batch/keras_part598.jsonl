{"custom_id": "keras#b26160dd30e838f0f55d732eb39235b9188b6608", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 444 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 9 | Complexity Δ (Sum/Max): 41/34 | Churn Δ: 444 | Churn Cumulative: 581 | Contributors (this commit): 9 | Commits (past 90d): 69 | Contributors (cumulative): 11 | DMM Complexity: 0.3074433656957929\n\nDIFF:\n@@ -94,6 +94,7 @@ from keras_core.layers.regularization.spatial_dropout import SpatialDropout2D\n from keras_core.layers.regularization.spatial_dropout import SpatialDropout3D\n from keras_core.layers.reshaping.cropping1d import Cropping1D\n from keras_core.layers.reshaping.cropping2d import Cropping2D\n+from keras_core.layers.reshaping.cropping3d import Cropping3D\n from keras_core.layers.reshaping.flatten import Flatten\n from keras_core.layers.reshaping.permute import Permute\n from keras_core.layers.reshaping.repeat_vector import RepeatVector\n\n@@ -0,0 +1,282 @@\n+from keras_core import backend\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.input_spec import InputSpec\n+from keras_core.layers.layer import Layer\n+\n+\n+@keras_core_export(\"keras_core.layers.Cropping3D\")\n+class Cropping3D(Layer):\n+    \"\"\"Cropping layer for 3D data (e.g. spatial or spatio-temporal).\n+\n+    Examples:\n+\n+    >>> input_shape = (2, 28, 28, 10, 3)\n+    >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n+    >>> y = keras_core.layers.Cropping3D(cropping=(2, 4, 2))(x)\n+    >>> y.shape\n+    (2, 24, 20, 6, 3)\n+\n+    Args:\n+        cropping: Int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n+            - If int: the same symmetric cropping is applied to depth, height,\n+              and width.\n+            - If tuple of 3 ints: interpreted as three different symmetric\n+              cropping values for depth, height, and width:\n+              `(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)`.\n+            - If tuple of 3 tuples of 2 ints: interpreted as\n+              `((left_dim1_crop, right_dim1_crop), (left_dim2_crop,\n+              right_dim2_crop), (left_dim3_crop, right_dim3_crop))`\n+        data_format: A string, one of `\"channels_last\"` (default) or\n+            `\"channels_first\"`. The ordering of the dimensions in the inputs.\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n+            while `\"channels_first\"` corresponds to inputs with shape\n+            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n+            When unspecified, uses `image_data_format` value found in your Keras\n+            config file at `~/.keras/keras.json` (if exists). Defaults to\n+            `\"channels_last\"`.\n+\n+    Input shape:\n+        5D tensor with shape:\n+        - If `data_format` is `\"channels_last\"`:\n+          `(batch_size, first_axis_to_crop, second_axis_to_crop,\n+          third_axis_to_crop, channels)`\n+        - If `data_format` is `\"channels_first\"`:\n+          `(batch_size, channels, first_axis_to_crop, second_axis_to_crop,\n+          third_axis_to_crop)`\n+\n+    Output shape:\n+        5D tensor with shape:\n+        - If `data_format` is `\"channels_last\"`:\n+          `(batch_size, first_cropped_axis, second_cropped_axis,\n+          third_cropped_axis, channels)`\n+        - If `data_format` is `\"channels_first\"`:\n+          `(batch_size, channels, first_cropped_axis, second_cropped_axis,\n+          third_cropped_axis)`\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        cropping=((1, 1), (1, 1), (1, 1)),\n+        data_format=None,\n+        name=None,\n+        dtype=None,\n+    ):\n+        super().__init__(name=name, dtype=dtype)\n+        self.data_format = backend.standardize_data_format(data_format)\n+        if isinstance(cropping, int):\n+            self.cropping = (\n+                (cropping, cropping),\n+                (cropping, cropping),\n+                (cropping, cropping),\n+            )\n+        elif hasattr(cropping, \"__len__\"):\n+            if len(cropping) != 3:\n+                raise ValueError(\n+                    f\"`cropping` should have 3 elements. Received: {cropping}.\"\n+                )\n+            dim1_cropping = cropping[0]\n+            if isinstance(dim1_cropping, int):\n+                dim1_cropping = (dim1_cropping, dim1_cropping)\n+            dim2_cropping = cropping[1]\n+            if isinstance(dim2_cropping, int):\n+                dim2_cropping = (dim2_cropping, dim2_cropping)\n+            dim3_cropping = cropping[2]\n+            if isinstance(dim3_cropping, int):\n+                dim3_cropping = (dim3_cropping, dim3_cropping)\n+            self.cropping = (dim1_cropping, dim2_cropping, dim3_cropping)\n+        else:\n+            raise ValueError(\n+                \"`cropping` should be either an int, a tuple of 3 ints \"\n+                \"(symmetric_dim1_crop, symmetric_dim2_crop, \"\n+                \"symmetric_dim3_crop), \"\n+                \"or a tuple of 3 tuples of 2 ints \"\n+                \"((left_dim1_crop, right_dim1_crop),\"\n+                \" (left_dim2_crop, right_dim2_crop),\"\n+                \" (left_dim3_crop, right_dim2_crop)). \"\n+                f\"Received: {cropping}.\"\n+            )\n+        self.input_spec = InputSpec(ndim=5)\n+\n+    def compute_output_shape(self, input_shape):\n+        if self.data_format == \"channels_first\":\n+            spatial_dims = list(input_shape[2:5])\n+        else:\n+            spatial_dims = list(input_shape[1:4])\n+\n+        for index in range(0, 3):\n+            if spatial_dims[index] is None:\n+                continue\n+            spatial_dims[index] -= sum(self.cropping[index])\n+            if spatial_dims[index] <= 0:\n+                raise ValueError(\n+                    \"Values in `cropping` argument should be greater than the \"\n+                    \"corresponding spatial dimension of the input. Received: \"\n+                    f\"input_shape={input_shape}, cropping={self.cropping}\"\n+                )\n+\n+        if self.data_format == \"channels_first\":\n+            return (input_shape[0], input_shape[1], *spatial_dims)\n+        else:\n+            return (input_shape[0], *spatial_dims, input_shape[4])\n+\n+    def call(self, inputs):\n+        if self.data_format == \"channels_first\":\n+            spatial_dims = list(inputs.shape[2:5])\n+        else:\n+            spatial_dims = list(inputs.shape[1:4])\n+\n+        for index in range(0, 3):\n+            if spatial_dims[index] is None:\n+                continue\n+            spatial_dims[index] -= sum(self.cropping[index])\n+            if spatial_dims[index] <= 0:\n+                raise ValueError(\n+                    \"Values in `cropping` argument should be greater than the \"\n+                    \"corresponding spatial dimension of the input. Received: \"\n+                    f\"inputs.shape={inputs.shape}, cropping={self.cropping}\"\n+                )\n+\n+        if self.data_format == \"channels_first\":\n+            if (\n+                self.cropping[0][1]\n+                == self.cropping[1][1]\n+                == self.cropping[2][1]\n+                == 0\n+            ):\n+                return inputs[\n+                    :,\n+                    :,\n+                    self.cropping[0][0] :,\n+                    self.cropping[1][0] :,\n+                    self.cropping[2][0] :,\n+                ]\n+            elif self.cropping[0][1] == self.cropping[1][1] == 0:\n+                return inputs[\n+                    :,\n+                    :,\n+                    self.cropping[0][0] :,\n+                    self.cropping[1][0] :,\n+                    self.cropping[2][0] : -self.cropping[2][1],\n+                ]\n+            elif self.cropping[1][1] == self.cropping[2][1] == 0:\n+                return inputs[\n+                    :,\n+                    :,\n+                    self.cropping[0][0] : -self.cropping[0][1],\n+                    self.cropping[1][0] :,\n+                    self.cropping[2][0] :,\n+                ]\n+            elif self.cropping[0][1] == self.cropping[2][1] == 0:\n+                return inputs[\n+                    :,\n+                    :,\n+                    self.cropping[0][0] :,\n+                    self.cropping[1][0] : -self.cropping[1][1],\n+                    self.cropping[2][0] :,\n+                ]\n+            elif self.cropping[0][1] == 0:\n+                return inputs[\n+                    :,\n+                    :,\n+                    self.cropping[0][0] :,\n+                    self.cropping[1][0] : -self.cropping[1][1],\n+                    self.cropping[2][0] : -self.cropping[2][1],\n+                ]\n+            elif self.cropping[1][1] == 0:\n+                return inputs[\n+                    :,\n+                    :,\n+                    self.cropping[0][0] : -self.cropping[0][1],\n+                    self.cropping[1][0] :,\n+                    self.cropping[2][0] : -self.cropping[2][1],\n+                ]\n+            elif self.cropping[2][1] == 0:\n+                return inputs[\n+                    :,\n+                    :,\n+                    self.cropping[0][0] : -self.cropping[0][1],\n+                    self.cropping[1][0] : -self.cropping[1][1],\n+                    self.cropping[2][0] :,\n+                ]\n+            return inputs[\n+                :,\n+                :,\n+                self.cropping[0][0] : -self.cropping[0][1],\n+                self.cropping[1][0] : -self.cropping[1][1],\n+                self.cropping[2][0] : -self.cropping[2][1],\n+            ]\n+        else:\n+            if (\n+                self.cropping[0][1]\n+                == self.cropping[1][1]\n+                == self.cropping[2][1]\n+                == 0\n+            ):\n+                return inputs[\n+                    :,\n+                    self.cropping[0][0] :,\n+                    self.cropping[1][0] :,\n+                    self.cropping[2][0] :,\n+                    :,\n+                ]\n+            elif self.cropping[0][1] == self.cropping[1][1] == 0:\n+                return inputs[\n+                    :,\n+                    self.cropping[0][0] :,\n+                    self.cropping[1][0] :,\n+                    self.cropping[2][0] : -self.cropping[2][1],\n+                    :,\n+                ]\n+            elif self.cropping[1][1] == self.cropping[2][1] == 0:\n+                return inputs[\n+                    :,\n+                    self.cropping[0][0] : -self.cropping[0][1],\n+                    self.cropping[1][0] :,\n+                    self.cropping[2][0] :,\n+                    :,\n+                ]\n+            elif self.cropping[0][1] == self.cropping[2][1] == 0:\n+                return inputs[\n+                    :,\n+                    self.cropping[0][0] :,\n+                    self.cropping[1][0] : -self.cropping[1][1],\n+                    self.cropping[2][0] :,\n+                    :,\n+                ]\n+            elif self.cropping[0][1] == 0:\n+                return inputs[\n+                    :,\n+                    self.cropping[0][0] :,\n+                    self.cropping[1][0] : -self.cropping[1][1],\n+                    self.cropping[2][0] : -self.cropping[2][1],\n+                    :,\n+                ]\n+            elif self.cropping[1][1] == 0:\n+                return inputs[\n+                    :,\n+                    self.cropping[0][0] : -self.cropping[0][1],\n+                    self.cropping[1][0] :,\n+                    self.cropping[2][0] : -self.cropping[2][1],\n+                    :,\n+                ]\n+            elif self.cropping[2][1] == 0:\n+                return inputs[\n+                    :,\n+                    self.cropping[0][0] : -self.cropping[0][1],\n+                    self.cropping[1][0] : -self.cropping[1][1],\n+                    self.cropping[2][0] :,\n+                    :,\n+                ]\n+            return inputs[\n+                :,\n+                self.cropping[0][0] : -self.cropping[0][1],\n+                self.cropping[1][0] : -self.cropping[1][1],\n+                self.cropping[2][0] : -self.cropping[2][1],\n+                :,\n+            ]\n+\n+    def get_config(self):\n+        config = {\"cropping\": self.cropping, \"data_format\": self.data_format}\n+        base_config = super().get_config()\n+        return {**base_config, **config}\n\n@@ -0,0 +1,161 @@\n+import numpy as np\n+import pytest\n+from absl.testing import parameterized\n+\n+from keras_core import backend\n+from keras_core import layers\n+from keras_core import operations as ops\n+from keras_core import testing\n+\n+\n+class CroppingTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.product(\n+        (\n+            {\"dim1_cropping\": (1, 2), \"dim1_expected\": (1, 5)},  # both\n+            {\"dim1_cropping\": (0, 2), \"dim1_expected\": (0, 5)},  # left only\n+            {\"dim1_cropping\": (1, 0), \"dim1_expected\": (1, 7)},  # right only\n+        ),\n+        (\n+            {\"dim2_cropping\": (3, 4), \"dim2_expected\": (3, 5)},  # both\n+            {\"dim2_cropping\": (0, 4), \"dim2_expected\": (0, 5)},  # left only\n+            {\"dim2_cropping\": (3, 0), \"dim2_expected\": (3, 9)},  # right only\n+        ),\n+        (\n+            {\"dim3_cropping\": (5, 6), \"dim3_expected\": (5, 7)},  # both\n+            {\"dim3_cropping\": (0, 6), \"dim3_expected\": (0, 7)},  # left only\n+            {\"dim3_cropping\": (5, 0), \"dim3_expected\": (5, 13)},  # right only\n+        ),\n+        (\n+            {\"data_format\": \"channels_first\"},\n+            {\"data_format\": \"channels_last\"},\n+        ),\n+    )\n+    def test_cropping_3d(\n+        self,\n+        dim1_cropping,\n+        dim2_cropping,\n+        dim3_cropping,\n+        data_format,\n+        dim1_expected,\n+        dim2_expected,\n+        dim3_expected,\n+    ):\n+        if data_format == \"channels_first\":\n+            inputs = np.random.rand(3, 5, 7, 9, 13)\n+            expected_output = ops.convert_to_tensor(\n+                inputs[\n+                    :,\n+                    :,\n+                    dim1_expected[0] : dim1_expected[1],\n+                    dim2_expected[0] : dim2_expected[1],\n+                    dim3_expected[0] : dim3_expected[1],\n+                ]\n+            )\n+        else:\n+            inputs = np.random.rand(3, 7, 9, 13, 5)\n+            expected_output = ops.convert_to_tensor(\n+                inputs[\n+                    :,\n+                    dim1_expected[0] : dim1_expected[1],\n+                    dim2_expected[0] : dim2_expected[1],\n+                    dim3_expected[0] : dim3_expected[1],\n+                    :,\n+                ]\n+            )\n+\n+        cropping = (dim1_cropping, dim2_cropping, dim3_cropping)\n+        self.run_layer_test(\n+            layers.Cropping3D,\n+            init_kwargs={\"cropping\": cropping, \"data_format\": data_format},\n+            input_data=inputs,\n+            expected_output=expected_output,\n+        )\n+\n+    @parameterized.product(\n+        (\n+            # same cropping values with 3 tuples\n+            {\n+                \"cropping\": ((2, 2), (2, 2), (2, 2)),\n+                \"expected\": ((2, 5), (2, 7), (2, 11)),\n+            },\n+            # same cropping values with 1 tuple\n+            {\"cropping\": (2, 2, 2), \"expected\": ((2, 5), (2, 7), (2, 11))},\n+            # same cropping values with an integer\n+            {\"cropping\": 2, \"expected\": ((2, 5), (2, 7), (2, 11))},\n+        ),\n+        (\n+            {\"data_format\": \"channels_first\"},\n+            {\"data_format\": \"channels_last\"},\n+        ),\n+    )\n+    def test_cropping_3d_with_same_cropping(\n+        self, cropping, data_format, expected\n+    ):\n+        if data_format == \"channels_first\":\n+            inputs = np.random.rand(3, 5, 7, 9, 13)\n+            expected_output = ops.convert_to_tensor(\n+                inputs[\n+                    :,\n+                    :,\n+                    expected[0][0] : expected[0][1],\n+                    expected[1][0] : expected[1][1],\n+                    expected[2][0] : expected[2][1],\n+                ]\n+            )\n+        else:\n+            inputs = np.random.rand(3, 7, 9, 13, 5)\n+            expected_output = ops.convert_to_tensor(\n+                inputs[\n+                    :,\n+                    expected[0][0] : expected[0][1],\n+                    expected[1][0] : expected[1][1],\n+                    expected[2][0] : expected[2][1],\n+                    :,\n+                ]\n+            )\n+\n+        self.run_layer_test(\n+            layers.Cropping3D,\n+            init_kwargs={\"cropping\": cropping, \"data_format\": data_format},\n+            input_data=inputs,\n+            expected_output=expected_output,\n+        )\n+\n+    @pytest.mark.skipif(\n+        not backend.DYNAMIC_SHAPES_OK,\n+        reason=\"Backend does not support dynamic shapes\",\n+    )\n+    def test_cropping_3d_with_dynamic_batch_size(self):\n+        input_layer = layers.Input(batch_shape=(None, 7, 9, 13, 5))\n+        permuted = layers.Cropping3D(((1, 2), (3, 4), (5, 6)))(input_layer)\n+        self.assertEqual(permuted.shape, (None, 4, 2, 2, 5))\n+\n+    @parameterized.product(\n+        (\n+            {\"cropping\": ((3, 6), (0, 0), (0, 0))},\n+            {\"cropping\": ((0, 0), (5, 8), (0, 0))},\n+            {\"cropping\": ((0, 0), (0, 0), (7, 6))},\n+        ),\n+        (\n+            {\"data_format\": \"channels_first\"},\n+            {\"data_format\": \"channels_last\"},\n+        ),\n+    )\n+    def test_cropping_3d_errors_if_cropping_more_than_available(\n+        self, cropping, data_format\n+    ):\n+        input_layer = layers.Input(batch_shape=(3, 7, 9, 13, 5))\n+        with self.assertRaises(ValueError):\n+            layers.Cropping3D(cropping=cropping, data_format=data_format)(\n+                input_layer\n+            )\n+\n+    def test_cropping_3d_errors_if_cropping_argument_invalid(self):\n+        with self.assertRaises(ValueError):\n+            layers.Cropping3D(cropping=(1,))\n+        with self.assertRaises(ValueError):\n+            layers.Cropping3D(cropping=(1, 2))\n+        with self.assertRaises(ValueError):\n+            layers.Cropping3D(cropping=(1, 2, 3, 4))\n+        with self.assertRaises(ValueError):\n+            layers.Cropping3D(cropping=\"1\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f12771c86208b9bf89dc3fcbb5cff0e6e02d4a17", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 77 | Lines Deleted: 52 | Files Changed: 5 | Hunks: 9 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/12 | Churn Δ: 129 | Churn Cumulative: 2076 | Contributors (this commit): 3 | Commits (past 90d): 22 | Contributors (cumulative): 10 | DMM Complexity: 0.0\n\nDIFF:\n@@ -9,6 +9,7 @@ from keras_core.backend import standardize_data_format\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n from keras_core.operations.operation_utils import compute_conv_output_shape\n+from keras_core.utils.argument_validation import normalize_tuple\n \n \n class BaseConv(Layer):\n@@ -103,19 +104,11 @@ class BaseConv(Layer):\n         self.rank = rank\n         self.filters = filters\n         self.groups = groups or 1\n-\n-        if isinstance(kernel_size, int):\n-            kernel_size = (kernel_size,) * self.rank\n-        self.kernel_size = kernel_size\n-\n-        if isinstance(strides, int):\n-            strides = (strides,) * self.rank\n-        self.strides = strides\n-\n-        if isinstance(dilation_rate, int):\n-            dilation_rate = (dilation_rate,) * self.rank\n-        self.dilation_rate = dilation_rate\n-\n+        self.kernel_size = normalize_tuple(kernel_size, rank, \"kernel_size\")\n+        self.strides = normalize_tuple(strides, rank, \"strides\")\n+        self.dilation_rate = normalize_tuple(\n+            dilation_rate, rank, \"dilation_rate\"\n+        )\n         self.padding = padding\n         self.data_format = standardize_data_format(data_format)\n         self.activation = activations.get(activation)\n\n@@ -11,6 +11,7 @@ from keras_core.backend.common.backend_utils import (\n )\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n+from keras_core.utils.argument_validation import normalize_tuple\n \n \n class BaseConvTranspose(Layer):\n@@ -96,19 +97,11 @@ class BaseConvTranspose(Layer):\n         )\n         self.rank = rank\n         self.filters = filters\n-\n-        if isinstance(kernel_size, int):\n-            kernel_size = (kernel_size,) * self.rank\n-        self.kernel_size = kernel_size\n-\n-        if isinstance(strides, int):\n-            strides = (strides,) * self.rank\n-        self.strides = strides\n-\n-        if isinstance(dilation_rate, int):\n-            dilation_rate = (dilation_rate,) * self.rank\n-        self.dilation_rate = dilation_rate\n-\n+        self.kernel_size = normalize_tuple(kernel_size, rank, \"kernel_size\")\n+        self.strides = normalize_tuple(strides, rank, \"strides\")\n+        self.dilation_rate = normalize_tuple(\n+            dilation_rate, rank, \"dilation_rate\"\n+        )\n         self.padding = padding\n         self.data_format = standardize_data_format(data_format)\n         self.activation = activations.get(activation)\n\n@@ -9,6 +9,7 @@ from keras_core.backend import standardize_data_format\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n from keras_core.operations.operation_utils import compute_conv_output_shape\n+from keras_core.utils.argument_validation import normalize_tuple\n \n \n class BaseDepthwiseConv(Layer):\n@@ -108,19 +109,11 @@ class BaseDepthwiseConv(Layer):\n         )\n         self.rank = rank\n         self.depth_multiplier = depth_multiplier\n-\n-        if isinstance(kernel_size, int):\n-            kernel_size = (kernel_size,) * self.rank\n-        self.kernel_size = kernel_size\n-\n-        if isinstance(strides, int):\n-            strides = (strides,) * self.rank\n-        self.strides = strides\n-\n-        if isinstance(dilation_rate, int):\n-            dilation_rate = (dilation_rate,) * self.rank\n-        self.dilation_rate = dilation_rate\n-\n+        self.kernel_size = normalize_tuple(kernel_size, rank, \"kernel_size\")\n+        self.strides = normalize_tuple(strides, rank, \"strides\")\n+        self.dilation_rate = normalize_tuple(\n+            dilation_rate, rank, \"dilation_rate\"\n+        )\n         self.padding = padding\n         self.data_format = standardize_data_format(data_format)\n         self.activation = activations.get(activation)\n\n@@ -10,6 +10,7 @@ from keras_core.backend import standardize_data_format\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n from keras_core.operations.operation_utils import compute_conv_output_shape\n+from keras_core.utils.argument_validation import normalize_tuple\n \n \n class BaseSeparableConv(Layer):\n@@ -109,19 +110,11 @@ class BaseSeparableConv(Layer):\n         self.rank = rank\n         self.depth_multiplier = depth_multiplier\n         self.filters = filters\n-\n-        if isinstance(kernel_size, int):\n-            kernel_size = (kernel_size,) * self.rank\n-        self.kernel_size = kernel_size\n-\n-        if isinstance(strides, int):\n-            strides = (strides,) * self.rank\n-        self.strides = strides\n-\n-        if isinstance(dilation_rate, int):\n-            dilation_rate = (dilation_rate,) * self.rank\n-        self.dilation_rate = dilation_rate\n-\n+        self.kernel_size = normalize_tuple(kernel_size, rank, \"kernel_size\")\n+        self.strides = normalize_tuple(strides, rank, \"strides\")\n+        self.dilation_rate = normalize_tuple(\n+            dilation_rate, rank, \"dilation_rate\"\n+        )\n         self.padding = padding\n         self.data_format = standardize_data_format(data_format)\n         self.activation = activations.get(activation)\n\n@@ -0,0 +1,53 @@\n+def normalize_tuple(value, n, name, allow_zero=False):\n+    \"\"\"Transforms non-negative/positive integer/integers into an integer tuple.\n+\n+    Args:\n+        value: int or iterable of ints. The value to validate and convert.\n+        n: int. The size of the tuple to be returned.\n+        name: string. The name of the argument being validated, e.g. \"strides\"\n+            or \"kernel_size\". This is only used to format error messages.\n+        allow_zero: bool, defaults to False. A ValueError will raised if zero is\n+            received and this param is False.\n+\n+    Returns:\n+        A tuple of n integers.\n+    \"\"\"\n+    error_msg = (\n+        f\"The `{name}` argument must be a tuple of {n} integers. \"\n+        f\"Received `{name}`={value}\"\n+    )\n+\n+    if isinstance(value, int):\n+        value_tuple = (value,) * n\n+    else:\n+        try:\n+            value_tuple = tuple(value)\n+        except TypeError:\n+            raise ValueError(error_msg)\n+        if len(value_tuple) != n:\n+            raise ValueError(error_msg)\n+        for single_value in value_tuple:\n+            try:\n+                int(single_value)\n+            except (ValueError, TypeError):\n+                error_msg += (\n+                    f\"including element {single_value} of \"\n+                    f\"type {type(single_value)}\"\n+                )\n+                raise ValueError(error_msg)\n+\n+    if allow_zero:\n+        unqualified_values = {v for v in value_tuple if v < 0}\n+        req_msg = \">= 0\"\n+    else:\n+        unqualified_values = {v for v in value_tuple if v <= 0}\n+        req_msg = \"> 0\"\n+\n+    if unqualified_values:\n+        error_msg += (\n+            f\" including {unqualified_values}\"\n+            f\" that does not satisfy the requirement `{req_msg}`.\"\n+        )\n+        raise ValueError(error_msg)\n+\n+    return value_tuple\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#78557925307236f7fbafe26c5aedd172824f395f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 59 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -14,7 +14,7 @@ def normalize_tuple(value, n, name, allow_zero=False):\n     \"\"\"\n     error_msg = (\n         f\"The `{name}` argument must be a tuple of {n} integers. \"\n-        f\"Received `{name}`={value}\"\n+        f\"Received {name}={value}\"\n     )\n \n     if isinstance(value, int):\n@@ -45,8 +45,8 @@ def normalize_tuple(value, n, name, allow_zero=False):\n \n     if unqualified_values:\n         error_msg += (\n-            f\" including {unqualified_values}\"\n-            f\" that does not satisfy the requirement `{req_msg}`.\"\n+            f\", including values {unqualified_values}\"\n+            f\" that do not satisfy `value {req_msg}`\"\n         )\n         raise ValueError(error_msg)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d85668d3813a2af1c05374294cd783d7209836b7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1113 | Contributors (this commit): 6 | Commits (past 90d): 59 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -574,7 +574,6 @@ class Layer(Operation):\n                 # More than one shape: pass them by name.\n                 output_shape = self.compute_output_shape(**shapes_dict)\n \n-            print(\"output_shape\", output_shape)\n             if (\n                 isinstance(output_shape, list)\n                 and output_shape\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2d40cb20b974ced614850e9d5568b13536f1cdd5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4612 | Lines Deleted: 2070 | Files Changed: 59 | Hunks: 122 | Methods Changed: 370 | Complexity Δ (Sum/Max): 156/139 | Churn Δ: 6682 | Churn Cumulative: 49100 | Contributors (this commit): 16 | Commits (past 90d): 706 | Contributors (cumulative): 258 | DMM Complexity: 0.6132536664856056\n\nDIFF:\n@@ -39,8 +39,9 @@ def test_model_fit():\n     batch_size = 32\n     epochs = 5\n \n+    with strategy.scope():\n         model.compile(\n-        optimizer=optimizers.SGD(learning_rate=0.001),\n+            optimizer=optimizers.SGD(learning_rate=0.001, momentum=0.01),\n             loss=losses.MeanSquaredError(),\n             metrics=[metrics.MeanSquaredError()],\n             # TODO(scottzhu): Find out where is the variable that is not created eagerly\n\n@@ -1,9 +1,6 @@\n import json\n import os\n \n-import numpy as np\n-import torch\n-\n from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.backend.common.keras_tensor import any_symbolic_tensors\n from keras_core.backend.common.keras_tensor import is_keras_tensor\n@@ -32,8 +29,5 @@ if backend() == \"tensorflow\":\n elif backend() == \"jax\":\n     print_msg(\"Using JAX backend.\")\n     from keras_core.backend.jax import *  # noqa: F403\n-elif backend() == \"pytorch\":\n-    print_msg(\"Using PyTorch backend.\")\n-    from keras_core.backend.pytorch import *  # noqa: F403\n else:\n     raise ValueError(f\"Unable to import backend : {backend()}\")\n\n@@ -11,6 +11,7 @@ from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.backend.common.stateless_scope import StatelessScope\n from keras_core.backend.common.stateless_scope import get_stateless_scope\n from keras_core.backend.common.stateless_scope import in_stateless_scope\n+from keras_core.backend.jax import core\n from keras_core.backend.jax import image\n from keras_core.backend.jax import math\n from keras_core.backend.jax import nn\n\n@@ -0,0 +1,7 @@\n+import jax.numpy as jnp\n+\n+\n+def scatter(indices, values, shape):\n+    zeros = jnp.zeros(shape, values.dtype)\n+    key = tuple(jnp.moveaxis(indices, -1, 0))\n+    return zeros.at[key].set(values)\n\n@@ -5,6 +5,16 @@ def add(x1, x2):\n     return jnp.add(x1, x2)\n \n \n+def bincount(x, weights=None, minlength=0):\n+    if len(x.shape) == 2:\n+        bincounts = [\n+            jnp.bincount(arr, weights=weights, minlength=minlength)\n+            for arr in list(x)\n+        ]\n+        return jnp.stack(bincounts)\n+    return jnp.bincount(x, weights=weights, minlength=minlength)\n+\n+\n def einsum(subscripts, *operands, **kwargs):\n     return jnp.einsum(subscripts, *operands, **kwargs)\n \n\n@@ -1,128 +0,0 @@\n-import numpy as np\n-import torch\n-\n-from keras_core.backend.common import KerasVariable\n-from keras_core.backend.common import get_autocast_scope\n-from keras_core.backend.common import standardize_dtype\n-from keras_core.backend.common import standardize_shape\n-from keras_core.backend.common.keras_tensor import KerasTensor\n-from keras_core.backend.common.stateless_scope import StatelessScope\n-from keras_core.backend.common.stateless_scope import get_stateless_scope\n-from keras_core.backend.common.stateless_scope import in_stateless_scope\n-from keras_core.backend.pytorch import image\n-from keras_core.backend.pytorch import math\n-from keras_core.backend.pytorch import nn\n-from keras_core.backend.pytorch import numpy\n-from keras_core.backend.pytorch import random\n-\n-\n-def convert_to_tensor(x, dtype=None):\n-    # TODO: Need to address device placement arg of `as_tensor`\n-    if dtype is not None:\n-        dtype = standardize_dtype(dtype)\n-    if isinstance(x, Variable):\n-        if dtype and dtype != x.dtype:\n-            return x.value.astype(dtype)\n-        return x.value\n-    return torch.as_tensor(x, dtype=dtype)\n-\n-\n-def is_tensor(x):\n-    return torch.is_tensor(x)\n-\n-\n-def shape(x):\n-    return x.shape\n-\n-\n-def cast(x, dtype):\n-    return x.to(dtype)\n-\n-\n-def cond(pred, true_fn, false_fn):\n-    if pred:\n-        return true_fn\n-    return false_fn\n-\n-\n-def name_scope(name):\n-    # TODO: PyTorch doesn't have Named Scope\n-    return name\n-\n-\n-def vectorized_map(function, elements):\n-    return torch.vmap(function)(elements)\n-\n-\n-class Variable(KerasVariable):\n-    def _initialize(self, value):\n-        self._value = convert_to_tensor(value, dtype=self._dtype)\n-\n-    def assign(self, value):\n-        value = convert_to_tensor(value, dtype=self.dtype)\n-        if value.shape != self.shape:\n-            raise ValueError(\n-                \"The shape of the target variable and \"\n-                \"the shape of the target value in \"\n-                \"`variable.assign(value)` must match. \"\n-                f\"Received: value.shape={value.shape}; \"\n-                f\"variable.shape={self.value.shape}\"\n-            )\n-        if in_stateless_scope():\n-            scope = get_stateless_scope()\n-            scope.add_update((self, value))\n-        else:\n-            # torch `as_tensor` by default, doesn't copy if tensor is same type\n-            self._value = convert_to_tensor(value, dtype=self.dtype)\n-\n-    @property\n-    def value(self):\n-        if in_stateless_scope():\n-            scope = get_stateless_scope()\n-            value = scope.get_current_value(self)\n-            if value is not None:\n-                return self._maybe_autocast(value)\n-        if self._value is None:\n-            # Unitialized variable. Return a placeholder.\n-            # This is fine because it's only ever used\n-            # during shape inference in a scratch graph\n-            # (anything else would be a bug, to be fixed.)\n-            return self._maybe_autocast(\n-                convert_to_tensor(\n-                    self._initializer(self._shape, dtype=self._dtype),\n-                    dtype=self._dtype,\n-                )\n-            )\n-        return self._maybe_autocast(self._value)\n-\n-    def numpy(self):\n-        return np.array(self.value)\n-\n-    # Overload native accessor.\n-    def __torch_tensor__(self):\n-        return self\n-\n-    def _convert_to_tensor(self, value, dtype=None):\n-        return convert_to_tensor(value, dtype=dtype)\n-\n-\n-# Shape / dtype inference util\n-def compute_output_spec(fn, *args, **kwargs):\n-    raise NotImplementedError(\n-        \"`compute_output_spec` not implemented for PyTorch backend\"\n-    )\n-\n-\n-def traceable_tensor(shape, dtype=None):\n-    \"\"\"Create a \"traceable tensor\".\n-\n-    That's a tensor that can be passed as input\n-    to a stateful backend-native function to\n-    create state during the trace.\n-    \"\"\"\n-    shape = list(shape)\n-    dtype = dtype or \"float32\"\n-    for i, x in enumerate(shape):\n-        if x is None:\n-            shape[i] = 1\n-    return torch.ones(shape, dtype=dtype)\n\n\n\n\n@@ -1,690 +0,0 @@\n-import numpy as np\n-import torch\n-\n-\n-def add(x1, x2):\n-    pass\n-    # return tfnp.add(x1, x2)\n-\n-\n-def einsum(subscripts, *operands, **kwargs):\n-    pass\n-    # return tfnp.einsum(subscripts, *operands, **kwargs)\n-\n-\n-def subtract(x1, x2):\n-    pass\n-    # return tfnp.subtract(x1, x2)\n-\n-\n-def matmul(x1, x2):\n-    pass\n-    # return tfnp.matmul(x1, x2)\n-\n-\n-def multiply(x1, x2):\n-    pass\n-    # return tfnp.multiply(x1, x2)\n-\n-\n-def mean(x, axis=None, keepdims=False):\n-    pass\n-    # return tfnp.mean(x, axis=axis, keepdims=keepdims)\n-\n-\n-def max(x, axis=None, keepdims=False, initial=None):\n-    pass\n-    # The TensorFlow numpy API implementation doesn't support `initial` so we\n-    # handle it manually here.\n-    # if initial is not None:\n-    #    return tf.math.maximum(\n-    #        tfnp.max(x, axis=axis, keepdims=keepdims), initial\n-    #    )\n-\n-    # TensorFlow returns -inf by default for an empty list, but for consistency\n-    # with other backends and the numpy API we want to throw in this case.\n-    # tf.assert_greater(\n-    #    size(x),\n-    #    tf.constant(0, dtype=tf.int64),\n-    #    message=\"Cannot compute the max of an empty tensor.\",\n-    # )\n-\n-    # return tfnp.max(x, axis=axis, keepdims=keepdims)\n-\n-\n-def ones(shape, dtype=\"float32\"):\n-    pass\n-    # return tf.ones(shape, dtype=dtype)\n-\n-\n-def zeros(shape, dtype=\"float32\"):\n-    pass\n-    # return tf.zeros(shape, dtype=dtype)\n-\n-\n-def absolute(x):\n-    pass\n-    # return tfnp.absolute(x)\n-\n-\n-def abs(x):\n-    pass\n-    # return absolute(x)\n-\n-\n-def all(x, axis=None, keepdims=False):\n-    pass\n-    # return tfnp.all(x, axis=axis, keepdims=keepdims)\n-\n-\n-def any(x, axis=None, keepdims=False):\n-    pass\n-    # return tfnp.any(x, axis=axis, keepdims=keepdims)\n-\n-\n-def amax(x, axis=None, keepdims=False):\n-    pass\n-    # return tfnp.amax(x, axis=axis, keepdims=keepdims)\n-\n-\n-def amin(x, axis=None, keepdims=False):\n-    pass\n-    # return tfnp.amin(x, axis=axis, keepdims=keepdims)\n-\n-\n-def append(\n-    x1,\n-    x2,\n-    axis=None,\n-):\n-    pass\n-    # return tfnp.append(x1, x2, axis=axis)\n-\n-\n-def arange(start, stop=None, step=None, dtype=None):\n-    pass\n-    # return tfnp.arange(start, stop, step=step, dtype=dtype)\n-\n-\n-def arccos(x):\n-    pass\n-    # return tfnp.arccos(x)\n-\n-\n-def arcsin(x):\n-    pass\n-    # return tfnp.arcsin(x)\n-\n-\n-def arctan(x):\n-    pass\n-    # return tfnp.arctan(x)\n-\n-\n-def arctan2(x1, x2):\n-    pass\n-    # return tfnp.arctan2(x1, x2)\n-\n-\n-def argmax(x, axis=None):\n-    pass\n-    # return tfnp.argmax(x, axis=axis)\n-\n-\n-def argmin(x, axis=None):\n-    pass\n-    # return tfnp.argmin(x, axis=axis)\n-\n-\n-def argsort(x, axis=-1):\n-    pass\n-    # return tfnp.argsort(x, axis=axis)\n-\n-\n-def array(x, dtype=None):\n-    pass\n-    # return tfnp.array(x, dtype=dtype)\n-\n-\n-def average(x, axis=None, weights=None):\n-    pass\n-    # return tfnp.average(x, weights=weights, axis=axis)\n-\n-\n-def broadcast_to(x, shape):\n-    pass\n-    # return tfnp.broadcast_to(x, shape)\n-\n-\n-def ceil(x):\n-    pass\n-    # return tfnp.ceil(x)\n-\n-\n-def clip(x, x_min, x_max):\n-    pass\n-    # return tfnp.clip(x, x_min, x_max)\n-\n-\n-def concatenate(xs, axis=0):\n-    pass\n-    # return tfnp.concatenate(xs, axis=axis)\n-\n-\n-def conjugate(x):\n-    pass\n-    # return tfnp.conjugate(x)\n-\n-\n-def conj(x):\n-    pass\n-    # return conjugate(x)\n-\n-\n-def copy(x):\n-    pass\n-    # return tfnp.copy(x)\n-\n-\n-def cos(x):\n-    pass\n-    # return tfnp.cos(x)\n-\n-\n-def count_nonzero(x, axis=None):\n-    pass\n-    # return tfnp.count_nonzero(x, axis=axis)\n-\n-\n-def cross(x1, x2, axisa=-1, axisb=-1, axisc=-1, axis=None):\n-    pass\n-    # return tfnp.cross(\n-    #    x1,\n-    #    x2,\n-    #    axisa=axisa,\n-    #    axisb=axisb,\n-    #    axisc=axisc,\n-    #    axis=axis,\n-    # )\n-\n-\n-def cumprod(x, axis=None):\n-    pass\n-    # return tfnp.cumprod(x, axis=axis)\n-\n-\n-def cumsum(x, axis=None):\n-    pass\n-    # return tfnp.cumsum(x, axis=axis)\n-\n-\n-def diag(x, k=0):\n-    pass\n-    # return tfnp.diag(x, k=k)\n-\n-\n-def diagonal(x, offset=0, axis1=0, axis2=1):\n-    pass\n-    # return tfnp.diagonal(\n-    #    x,\n-    #    offset=offset,\n-    #    axis1=axis1,\n-    #    axis2=axis2,\n-    # )\n-\n-\n-def dot(x, y):\n-    pass\n-    # return tfnp.dot(x, y)\n-\n-\n-def empty(shape, dtype=\"float32\"):\n-    pass\n-    # return tfnp.empty(shape, dtype=dtype)\n-\n-\n-def equal(x1, x2):\n-    pass\n-    # return tfnp.equal(x1, x2)\n-\n-\n-def exp(x):\n-    pass\n-    # return tfnp.exp(x)\n-\n-\n-def expand_dims(x, axis):\n-    pass\n-    # return tfnp.expand_dims(x, axis)\n-\n-\n-def expm1(x):\n-    pass\n-    # return tfnp.expm1(x)\n-\n-\n-def flip(x, axis=None):\n-    pass\n-    # return tfnp.flip(x, axis=axis)\n-\n-\n-def floor(x):\n-    pass\n-    # return tfnp.floor(x)\n-\n-\n-def full(shape, fill_value, dtype=None):\n-    pass\n-    # return tfnp.full(shape, fill_value, dtype=dtype)\n-\n-\n-def full_like(x, fill_value, dtype=None):\n-    pass\n-    # return tfnp.full_like(x, fill_value, dtype=dtype)\n-\n-\n-def greater(x1, x2):\n-    pass\n-    # return tfnp.greater(x1, x2)\n-\n-\n-def greater_equal(x1, x2):\n-    pass\n-    # return tfnp.greater_equal(x1, x2)\n-\n-\n-def hstack(xs):\n-    pass\n-    # return tfnp.hstack(xs)\n-\n-\n-def identity(n, dtype=\"float32\"):\n-    pass\n-    # return tfnp.identity(n, dtype=dtype)\n-\n-\n-def imag(x):\n-    pass\n-    # return tfnp.imag(x)\n-\n-\n-def isclose(x1, x2):\n-    pass\n-    # return tfnp.isclose(x1, x2)\n-\n-\n-def isfinite(x):\n-    pass\n-    # return tfnp.isfinite(x)\n-\n-\n-def isinf(x):\n-    pass\n-    # return tfnp.isinf(x)\n-\n-\n-def isnan(x):\n-    pass\n-    # return tfnp.isnan(x)\n-\n-\n-def less(x1, x2):\n-    pass\n-    # return tfnp.less(x1, x2)\n-\n-\n-def less_equal(x1, x2):\n-    pass\n-    # return tfnp.less_equal(x1, x2)\n-\n-\n-def linspace(\n-    start, stop, num=50, endpoint=True, retstep=False, dtype=None, axis=0\n-):\n-    pass\n-    # return tfnp.linspace(\n-    #    start,\n-    #    stop,\n-    #    num=num,\n-    #    endpoint=endpoint,\n-    #    retstep=retstep,\n-    #    dtype=dtype,\n-    #    axis=axis,\n-    # )\n-\n-\n-def log(x):\n-    pass\n-    # return tfnp.log(x)\n-\n-\n-def log10(x):\n-    pass\n-    # return tfnp.log10(x)\n-\n-\n-def log1p(x):\n-    pass\n-    # return tfnp.log1p(x)\n-\n-\n-def log2(x):\n-    pass\n-    # return tfnp.log2(x)\n-\n-\n-def logaddexp(x1, x2):\n-    pass\n-    # return tfnp.logaddexp(x1, x2)\n-\n-\n-def logical_and(x1, x2):\n-    pass\n-    # return tfnp.logical_and(x1, x2)\n-\n-\n-def logical_not(x):\n-    pass\n-    # return tfnp.logical_not(x)\n-\n-\n-def logical_or(x1, x2):\n-    pass\n-    # return tfnp.logical_or(x1, x2)\n-\n-\n-def logspace(start, stop, num=50, endpoint=True, base=10, dtype=None, axis=0):\n-    pass\n-    # return tfnp.logspace(\n-    #    start,\n-    #    stop,\n-    #    num=num,\n-    #    endpoint=endpoint,\n-    #    base=base,\n-    #    dtype=dtype,\n-    #    axis=axis,\n-    # )\n-\n-\n-def maximum(x1, x2):\n-    pass\n-    # return tfnp.maximum(x1, x2)\n-\n-\n-def meshgrid(*x, indexing=\"xy\"):\n-    pass\n-    # return tfnp.meshgrid(*x, indexing=indexing)\n-\n-\n-def min(x, axis=None, keepdims=False, initial=None):\n-    pass\n-    ## The TensorFlow numpy API implementation doesn't support `initial` so we\n-    ## handle it manually here.\n-    # if initial is not None:\n-    #    return tf.math.minimum(\n-    #        tfnp.min(x, axis=axis, keepdims=keepdims), initial\n-    #    )\n-\n-    ## TensorFlow returns inf by default for an empty list, but for consistency\n-    ## with other backends and the numpy API we want to throw in this case.\n-    # tf.assert_greater(\n-    #    size(x),\n-    #    tf.constant(0, dtype=tf.int64),\n-    #    message=\"Cannot compute the min of an empty tensor.\",\n-    # )\n-\n-    # return tfnp.min(x, axis=axis, keepdims=keepdims)\n-\n-\n-def minimum(x1, x2):\n-    pass\n-    # return tfnp.minimum(x1, x2)\n-\n-\n-def mod(x1, x2):\n-    pass\n-    # return tfnp.mod(x1, x2)\n-\n-\n-def moveaxis(x, source, destination):\n-    pass\n-    # return tfnp.moveaxis(x, source=source, destination=destination)\n-\n-\n-def nan_to_num(x):\n-    pass\n-    ## Replace NaN with 0\n-    # x = tf.where(tf.math.is_nan(x), 0, x)\n-\n-    ## Replace positive infinitiy with dtype.max\n-    # x = tf.where(tf.math.is_inf(x) & (x > 0), x.dtype.max, x)\n-\n-    ## Replace negative infinity with dtype.min\n-    # x = tf.where(tf.math.is_inf(x) & (x < 0), x.dtype.min, x)\n-\n-    # return x\n-\n-\n-def ndim(x):\n-    pass\n-    # return tfnp.ndim(x)\n-\n-\n-def nonzero(x):\n-    pass\n-    # return tfnp.nonzero(x)\n-\n-\n-def not_equal(x1, x2):\n-    pass\n-    # return tfnp.not_equal(x1, x2)\n-\n-\n-def ones_like(x, dtype=None):\n-    pass\n-    # return tfnp.ones_like(x, dtype=dtype)\n-\n-\n-def outer(x1, x2):\n-    pass\n-    # return tfnp.outer(x1, x2)\n-\n-\n-def pad(x, pad_width, mode=\"constant\"):\n-    pass\n-    # return tfnp.pad(x, pad_width, mode=mode)\n-\n-\n-def prod(x, axis=None, keepdims=False, dtype=None):\n-    pass\n-    # return tfnp.prod(x, axis=axis, keepdims=keepdims, dtype=dtype)\n-\n-\n-def ravel(x):\n-    pass\n-    # return tfnp.ravel(x)\n-\n-\n-def real(x):\n-    pass\n-    # return tfnp.real(x)\n-\n-\n-def reciprocal(x):\n-    pass\n-    # return tfnp.reciprocal(x)\n-\n-\n-def repeat(x, repeats, axis=None):\n-    pass\n-    # return tfnp.repeat(x, repeats, axis=axis)\n-\n-\n-def reshape(x, new_shape):\n-    pass\n-    # return tfnp.reshape(x, new_shape)\n-\n-\n-def roll(x, shift, axis=None):\n-    pass\n-    # return tfnp.roll(x, shift, axis=axis)\n-\n-\n-def sign(x):\n-    pass\n-    # return tfnp.sign(x)\n-\n-\n-def sin(x):\n-    pass\n-    # return tfnp.sin(x)\n-\n-\n-def size(x):\n-    pass\n-    # return tfnp.size(x)\n-\n-\n-def sort(x, axis=-1):\n-    pass\n-    # return tfnp.sort(x, axis=axis)\n-\n-\n-def split(x, indices_or_sections, axis=0):\n-    pass\n-    # return tfnp.split(x, indices_or_sections, axis=axis)\n-\n-\n-def stack(x, axis=0):\n-    pass\n-    # return tfnp.stack(x, axis=axis)\n-\n-\n-def std(x, axis=None, keepdims=False):\n-    pass\n-    # return tfnp.std(x, axis=axis, keepdims=keepdims)\n-\n-\n-def swapaxes(x, axis1, axis2):\n-    pass\n-    # return tfnp.swapaxes(x, axis1=axis1, axis2=axis2)\n-\n-\n-def take(x, indices, axis=None):\n-    pass\n-    # return tfnp.take(x, indices, axis=axis)\n-\n-\n-def take_along_axis(x, indices, axis=None):\n-    pass\n-    # return tfnp.take_along_axis(x, indices, axis=axis)\n-\n-\n-def tan(x):\n-    pass\n-    # return tfnp.tan(x)\n-\n-\n-def tensordot(x1, x2, axes=2):\n-    pass\n-    # return tfnp.tensordot(x1, x2, axes=axes)\n-\n-\n-def round(x, decimals=0):\n-    pass\n-    # return tfnp.round(x, decimals=decimals)\n-\n-\n-def tile(x, repeats):\n-    pass\n-    # return tfnp.tile(x, repeats)\n-\n-\n-def trace(x, offset=0, axis1=0, axis2=1):\n-    pass\n-    # return tfnp.trace(x, offset=offset, axis1=axis1, axis2=axis2)\n-\n-\n-def tri(N, M=None, k=0, dtype=\"float32\"):\n-    pass\n-    # return tfnp.tri(N, M=M, k=k, dtype=dtype)\n-\n-\n-def tril(x, k=0):\n-    pass\n-    # return tfnp.tril(x, k=k)\n-\n-\n-def triu(x, k=0):\n-    pass\n-    return tfnp.triu(x, k=k)\n-\n-\n-def vdot(x1, x2):\n-    pass\n-    # return tfnp.vdot(x1, x2)\n-\n-\n-def vstack(xs):\n-    pass\n-    # return tfnp.vstack(xs)\n-\n-\n-def where(condition, x1, x2):\n-    pass\n-    # return tfnp.where(condition, x1, x2)\n-\n-\n-def divide(x1, x2):\n-    pass\n-    # return tfnp.divide(x1, x2)\n-\n-\n-def true_divide(x1, x2):\n-    pass\n-    # return tfnp.true_divide(x1, x2)\n-\n-\n-def power(x1, x2):\n-    pass\n-    # return tfnp.power(x1, x2)\n-\n-\n-def negative(x):\n-    pass\n-    # return tfnp.negative(x)\n-\n-\n-def square(x):\n-    pass\n-    # return tfnp.square(x)\n-\n-\n-def sqrt(x):\n-    pass\n-    # return tfnp.sqrt(x)\n-\n-\n-def squeeze(x, axis=None):\n-    pass\n-    # return tfnp.squeeze(x, axis=axis)\n-\n-\n-def transpose(x, axes=None):\n-    pass\n-    # return tfnp.transpose(x, axes=axes)\n-\n-\n-def var(x, axis=None, keepdims=False):\n-    pass\n-    # return tfnp.var(x, axis=axis, keepdims=keepdims)\n-\n-\n-def sum(x, axis=None, keepdims=False):\n-    pass\n-    # return tfnp.sum(x, axis=axis, keepdims=keepdims)\n-\n-\n-def eye(N, M=None, k=0, dtype=\"float32\"):\n-    pass\n-    # return tfnp.eye(N, M=M, k=k, dtype=dtype)\n\n\n@@ -8,11 +8,15 @@ from keras_core.backend.common.keras_tensor import KerasTensor\n from keras_core.backend.common.stateless_scope import StatelessScope\n from keras_core.backend.common.stateless_scope import get_stateless_scope\n from keras_core.backend.common.stateless_scope import in_stateless_scope\n+from keras_core.backend.tensorflow import core\n from keras_core.backend.tensorflow import image\n from keras_core.backend.tensorflow import math\n from keras_core.backend.tensorflow import nn\n from keras_core.backend.tensorflow import numpy\n from keras_core.backend.tensorflow import random\n+from keras_core.backend.tensorflow.rnn import gru\n+from keras_core.backend.tensorflow.rnn import lstm\n+from keras_core.backend.tensorflow.rnn import rnn\n from keras_core.utils.naming import auto_name\n \n DYNAMIC_SHAPES_OK = True\n@@ -27,7 +31,7 @@ class Variable(KerasVariable, tf.__internal__.types.Tensor):\n \n     def _initialize(self, value):\n         self._value = tf.Variable(\n-            value, dtype=self._dtype, trainable=self.trainable\n+            value, dtype=self._dtype, trainable=self.trainable, name=self.name\n         )\n \n     def assign(self, value):\n\n@@ -0,0 +1,5 @@\n+import tensorflow as tf\n+\n+\n+def scatter(indices, values, shape):\n+    return tf.scatter_nd(indices, values, shape)\n\n@@ -602,458 +602,3 @@ def binary_crossentropy(target, output, from_logits=False):\n     bce = target * tf.math.log(output)\n     bce += (1 - target) * tf.math.log(1 - output)\n     return -bce\n-\n-\n-def rnn(\n-    step_function,\n-    inputs,\n-    initial_states,\n-    go_backwards=False,\n-    mask=None,\n-    constants=None,\n-    unroll=False,\n-    input_length=None,\n-    time_major=False,\n-    zero_output_for_mask=False,\n-    return_all_outputs=True,\n-):\n-    \"\"\"Iterates over the time dimension of a tensor.\n-\n-    Args:\n-        step_function: RNN step function.\n-            Args;\n-                `input`; Tensor with shape `(samples, ...)` (no time dimension),\n-                    representing input for the batch of samples at a certain\n-                    time step.\n-                `states`; List of tensors.\n-            Returns;\n-                `output`; Tensor with shape `(samples, output_dim)`\n-                    (no time dimension).\n-                `new_states`; List of tensors, same length and shapes\n-                    as 'states'. The first state in the list must be the\n-                    output tensor at the previous timestep.\n-        inputs: Tensor of temporal data of shape `(samples, time, ...)`\n-            (at least 3D), or nested tensors, and each of which has shape\n-            `(samples, time, ...)`.\n-        initial_states: Tensor with shape `(samples, state_size)`\n-            (no time dimension), containing the initial values for the states\n-            used in the step function. In the case that state_size is in a\n-            nested shape, the shape of initial_states will also follow the\n-            nested structure.\n-        go_backwards: Boolean. If `True`, do the iteration over the time\n-            dimension in reverse order and return the reversed sequence.\n-        mask: Binary tensor with shape `(samples, time, 1)`,\n-            with a zero for every element that is masked.\n-        constants: List of constant values passed at each step.\n-        unroll: Whether to unroll the RNN or to use a symbolic `while_loop`.\n-        input_length: An integer or a 1-D Tensor, depending on whether\n-            the time dimension is fixed-length or not. In case of variable\n-            length input, it is used for masking in case there's no mask\n-            specified.\n-        time_major: Boolean. If `True`, the inputs and outputs will be in shape\n-            `(timesteps, batch, ...)`, whereas in the False case, it will be\n-            `(batch, timesteps, ...)`. Using `time_major = True` is a bit more\n-            efficient because it avoids transposes at the beginning and end of\n-            the RNN calculation. However, most TensorFlow data is batch-major,\n-            so by default this function accepts input and emits output in\n-            batch-major form.\n-        zero_output_for_mask: Boolean. If `True`, the output for masked timestep\n-            will be zeros, whereas in the `False` case, output from previous\n-            timestep is returned.\n-        return_all_outputs: Boolean. If `True`, return the recurrent outputs for\n-            all timesteps in the sequence. If `False`, only return the output\n-            for the last timestep (which consumes less memory).\n-\n-    Returns:\n-        A tuple, `(last_output, outputs, new_states)`.\n-            - `last_output`: the latest output of the rnn,\n-                with shape `(samples, ...)`.\n-            - `outputs`:\n-                - If `return_all_outputs=True`: a tensor with shape\n-                  `(samples, time, ...)` where each entry `outputs[s, t]` is the\n-                  output of the step function at time `t` for sample `s`\n-                - Else, a tensor equal to `last_output` with shape\n-                  `(samples, 1, ...)`\n-            - `new_states`: list of tensors, latest states returned by\n-                the step function, of shape `(samples, ...)`.\n-    \"\"\"\n-\n-    def swap_batch_timestep(input_t):\n-        # Swap the batch and timestep dim for the incoming tensor.\n-        axes = list(range(len(input_t.shape)))\n-        axes[0], axes[1] = 1, 0\n-        return tf.transpose(input_t, axes)\n-\n-    if not time_major:\n-        inputs = tf.nest.map_structure(swap_batch_timestep, inputs)\n-\n-    flatted_inputs = tf.nest.flatten(inputs)\n-    time_steps = flatted_inputs[0].shape[0]\n-    batch = flatted_inputs[0].shape[1]\n-    time_steps_t = tf.shape(flatted_inputs[0])[0]\n-\n-    for input_ in flatted_inputs:\n-        input_.shape.with_rank_at_least(3)\n-\n-    if mask is not None:\n-        if mask.dtype != tf.bool:\n-            mask = tf.cast(mask, tf.bool)\n-        if len(mask.shape) == 2:\n-            mask = tf.expand_dims(mask, axis=-1)\n-        if not time_major:\n-            mask = swap_batch_timestep(mask)\n-\n-    if constants is None:\n-        constants = []\n-\n-    # tf.where needs its condition tensor to be the same shape as its two\n-    # result tensors, but in our case the condition (mask) tensor is\n-    # (nsamples, 1), and inputs are (nsamples, ndimensions) or even more.\n-    # So we need to broadcast the mask to match the shape of inputs.\n-    # That's what the tile call does, it just repeats the mask along its\n-    # second dimension n times.\n-    def _expand_mask(mask_t, input_t, fixed_dim=1):\n-        if tf.nest.is_nested(mask_t):\n-            raise ValueError(\n-                f\"mask_t is expected to be tensor, but got {mask_t}\"\n-            )\n-        if tf.nest.is_nested(input_t):\n-            raise ValueError(\n-                f\"input_t is expected to be tensor, but got {input_t}\"\n-            )\n-        rank_diff = len(input_t.shape) - len(mask_t.shape)\n-        for _ in range(rank_diff):\n-            mask_t = tf.expand_dims(mask_t, -1)\n-        multiples = [1] * fixed_dim + input_t.shape.as_list()[fixed_dim:]\n-        return tf.tile(mask_t, multiples)\n-\n-    if unroll:\n-        if not time_steps:\n-            raise ValueError(\"Unrolling requires a fixed number of timesteps.\")\n-        states = tuple(initial_states)\n-        successive_states = []\n-        successive_outputs = []\n-\n-        # Process the input tensors. The input tensor need to be split on the\n-        # time_step dim, and reverse if go_backwards is True. In the case of\n-        # nested input, the input is flattened and then transformed\n-        # individually.  The result of this will be a tuple of lists, each of\n-        # the item in tuple is list of the tensor with shape (batch, feature)\n-        def _process_single_input_t(input_t):\n-            input_t = tf.unstack(input_t)  # unstack for time_step dim\n-            if go_backwards:\n-                input_t.reverse()\n-            return input_t\n-\n-        if tf.nest.is_nested(inputs):\n-            processed_input = tf.nest.map_structure(\n-                _process_single_input_t, inputs\n-            )\n-        else:\n-            processed_input = (_process_single_input_t(inputs),)\n-\n-        def _get_input_tensor(time):\n-            inp = [t_[time] for t_ in processed_input]\n-            return tf.nest.pack_sequence_as(inputs, inp)\n-\n-        if mask is not None:\n-            mask_list = tf.unstack(mask)\n-            if go_backwards:\n-                mask_list.reverse()\n-\n-            for i in range(time_steps):\n-                inp = _get_input_tensor(i)\n-                mask_t = mask_list[i]\n-                output, new_states = step_function(\n-                    inp, tuple(states) + tuple(constants)\n-                )\n-                tiled_mask_t = _expand_mask(mask_t, output)\n-\n-                if not successive_outputs:\n-                    prev_output = tf.zeros_like(output)\n-                else:\n-                    prev_output = successive_outputs[-1]\n-\n-                output = tf.where(tiled_mask_t, output, prev_output)\n-\n-                flat_states = tf.nest.flatten(states)\n-                flat_new_states = tf.nest.flatten(new_states)\n-                tiled_mask_t = tuple(\n-                    _expand_mask(mask_t, s) for s in flat_states\n-                )\n-                flat_final_states = tuple(\n-                    tf.where(m, s, ps)\n-                    for m, s, ps in zip(\n-                        tiled_mask_t, flat_new_states, flat_states\n-                    )\n-                )\n-                states = tf.nest.pack_sequence_as(states, flat_final_states)\n-\n-                if return_all_outputs:\n-                    successive_outputs.append(output)\n-                    successive_states.append(states)\n-                else:\n-                    successive_outputs = [output]\n-                    successive_states = [states]\n-            last_output = successive_outputs[-1]\n-            new_states = successive_states[-1]\n-            outputs = tf.stack(successive_outputs)\n-\n-            if zero_output_for_mask:\n-                last_output = tf.where(\n-                    _expand_mask(mask_list[-1], last_output),\n-                    last_output,\n-                    tf.zeros_like(last_output),\n-                )\n-                outputs = tf.where(\n-                    _expand_mask(mask, outputs, fixed_dim=2),\n-                    outputs,\n-                    tf.zeros_like(outputs),\n-                )\n-\n-        else:  # mask is None\n-            for i in range(time_steps):\n-                inp = _get_input_tensor(i)\n-                output, states = step_function(\n-                    inp, tuple(states) + tuple(constants)\n-                )\n-                if return_all_outputs:\n-                    successive_outputs.append(output)\n-                    successive_states.append(states)\n-                else:\n-                    successive_outputs = [output]\n-                    successive_states = [states]\n-            last_output = successive_outputs[-1]\n-            new_states = successive_states[-1]\n-            outputs = tf.stack(successive_outputs)\n-\n-    else:  # Unroll == False\n-        states = tuple(initial_states)\n-\n-        # Create input tensor array, if the inputs is nested tensors, then it\n-        # will be flattened first, and tensor array will be created one per\n-        # flattened tensor.\n-        input_ta = tuple(\n-            tf.TensorArray(\n-                dtype=inp.dtype,\n-                size=time_steps_t,\n-                tensor_array_name=f\"input_ta_{i}\",\n-            )\n-            for i, inp in enumerate(flatted_inputs)\n-        )\n-        input_ta = tuple(\n-            ta.unstack(input_)\n-            if not go_backwards\n-            else ta.unstack(tf.reverse(input_, [0]))\n-            for ta, input_ in zip(input_ta, flatted_inputs)\n-        )\n-\n-        # Get the time(0) input and compute the output for that, the output will\n-        # be used to determine the dtype of output tensor array. Don't read from\n-        # input_ta due to TensorArray clear_after_read default to True.\n-        input_time_zero = tf.nest.pack_sequence_as(\n-            inputs, [inp[0] for inp in flatted_inputs]\n-        )\n-        # output_time_zero is used to determine the cell output shape and its\n-        # dtype.  the value is discarded.\n-        output_time_zero, _ = step_function(\n-            input_time_zero, tuple(initial_states) + tuple(constants)\n-        )\n-\n-        output_ta_size = time_steps_t if return_all_outputs else 1\n-        output_ta = tuple(\n-            tf.TensorArray(\n-                dtype=out.dtype,\n-                size=output_ta_size,\n-                element_shape=out.shape,\n-                tensor_array_name=f\"output_ta_{i}\",\n-            )\n-            for i, out in enumerate(tf.nest.flatten(output_time_zero))\n-        )\n-\n-        time = tf.constant(0, dtype=\"int32\", name=\"time\")\n-\n-        if input_length is None:\n-            max_iterations = time_steps_t\n-        else:\n-            max_iterations = tf.reduce_max(input_length)\n-\n-        while_loop_kwargs = {\n-            \"cond\": lambda time, *_: time < time_steps_t,\n-            \"maximum_iterations\": max_iterations,\n-            \"parallel_iterations\": 32,\n-            \"swap_memory\": True,\n-        }\n-        if mask is not None:\n-            if go_backwards:\n-                mask = tf.reverse(mask, [0])\n-\n-            mask_ta = tf.TensorArray(\n-                dtype=tf.bool, size=time_steps_t, tensor_array_name=\"mask_ta\"\n-            )\n-            mask_ta = mask_ta.unstack(mask)\n-\n-            def masking_fn(time):\n-                return mask_ta.read(time)\n-\n-            def compute_masked_output(mask_t, flat_out, flat_mask):\n-                tiled_mask_t = tuple(\n-                    _expand_mask(mask_t, o, fixed_dim=len(mask_t.shape))\n-                    for o in flat_out\n-                )\n-                return tuple(\n-                    tf.where(m, o, fm)\n-                    for m, o, fm in zip(tiled_mask_t, flat_out, flat_mask)\n-                )\n-\n-        elif isinstance(input_length, tf.Tensor):\n-            if go_backwards:\n-                max_len = tf.reduce_max(input_length, axis=0)\n-                rev_input_length = tf.subtract(max_len - 1, input_length)\n-\n-                def masking_fn(time):\n-                    return tf.less(rev_input_length, time)\n-\n-            else:\n-\n-                def masking_fn(time):\n-                    return tf.greater(input_length, time)\n-\n-            def compute_masked_output(mask_t, flat_out, flat_mask):\n-                return tuple(\n-                    tf.where(mask_t, o, zo)\n-                    for (o, zo) in zip(flat_out, flat_mask)\n-                )\n-\n-        else:\n-            masking_fn = None\n-\n-        if masking_fn is not None:\n-            # Mask for the T output will be base on the output of T - 1. In the\n-            # case T = 0, a zero filled tensor will be used.\n-            flat_zero_output = tuple(\n-                tf.zeros_like(o) for o in tf.nest.flatten(output_time_zero)\n-            )\n-\n-            def _step(time, output_ta_t, prev_output, *states):\n-                \"\"\"RNN step function.\n-\n-                Args:\n-                    time: Current timestep value.\n-                    output_ta_t: TensorArray.\n-                    prev_output: tuple of outputs from time - 1.\n-                    *states: List of states.\n-\n-                Returns:\n-                    Tuple: `(time + 1, output_ta_t, output) + tuple(new_states)`\n-                \"\"\"\n-                current_input = tuple(ta.read(time) for ta in input_ta)\n-                # maybe set shape.\n-                current_input = tf.nest.pack_sequence_as(inputs, current_input)\n-                mask_t = masking_fn(time)\n-                output, new_states = step_function(\n-                    current_input, tuple(states) + tuple(constants)\n-                )\n-                # mask output\n-                flat_output = tf.nest.flatten(output)\n-                flat_mask_output = (\n-                    flat_zero_output\n-                    if zero_output_for_mask\n-                    else tf.nest.flatten(prev_output)\n-                )\n-                flat_new_output = compute_masked_output(\n-                    mask_t, flat_output, flat_mask_output\n-                )\n-\n-                # mask states\n-                flat_state = tf.nest.flatten(states)\n-                flat_new_state = tf.nest.flatten(new_states)\n-                flat_final_state = compute_masked_output(\n-                    mask_t, flat_new_state, flat_state\n-                )\n-                new_states = tf.nest.pack_sequence_as(\n-                    new_states, flat_final_state\n-                )\n-\n-                ta_index_to_write = time if return_all_outputs else 0\n-                output_ta_t = tuple(\n-                    ta.write(ta_index_to_write, out)\n-                    for ta, out in zip(output_ta_t, flat_new_output)\n-                )\n-\n-                return (time + 1, output_ta_t, tuple(flat_new_output)) + tuple(\n-                    new_states\n-                )\n-\n-            final_outputs = tf.while_loop(\n-                body=_step,\n-                loop_vars=(time, output_ta, flat_zero_output) + states,\n-                **while_loop_kwargs,\n-            )\n-            # Skip final_outputs[2] which is the output for final timestep.\n-            new_states = final_outputs[3:]\n-        else:\n-\n-            def _step(time, output_ta_t, *states):\n-                \"\"\"RNN step function.\n-\n-                Args:\n-                    time: Current timestep value.\n-                    output_ta_t: TensorArray.\n-                    *states: List of states.\n-\n-                Returns:\n-                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n-                \"\"\"\n-                current_input = tuple(ta.read(time) for ta in input_ta)\n-                current_input = tf.nest.pack_sequence_as(inputs, current_input)\n-                output, new_states = step_function(\n-                    current_input, tuple(states) + tuple(constants)\n-                )\n-                flat_new_state = tf.nest.flatten(new_states)\n-\n-                flat_output = tf.nest.flatten(output)\n-                ta_index_to_write = time if return_all_outputs else 0\n-                output_ta_t = tuple(\n-                    ta.write(ta_index_to_write, out)\n-                    for ta, out in zip(output_ta_t, flat_output)\n-                )\n-\n-                new_states = tf.nest.pack_sequence_as(\n-                    initial_states, flat_new_state\n-                )\n-                return (time + 1, output_ta_t) + tuple(new_states)\n-\n-            final_outputs = tf.while_loop(\n-                body=_step,\n-                loop_vars=(time, output_ta) + states,\n-                **while_loop_kwargs,\n-            )\n-            new_states = final_outputs[2:]\n-\n-        output_ta = final_outputs[1]\n-\n-        outputs = tuple(o.stack() for o in output_ta)\n-        last_output = tuple(o[-1] for o in outputs)\n-\n-        outputs = tf.nest.pack_sequence_as(output_time_zero, outputs)\n-        last_output = tf.nest.pack_sequence_as(output_time_zero, last_output)\n-\n-    # static shape inference\n-    def set_shape(output_):\n-        if isinstance(output_, tf.Tensor):\n-            shape = output_.shape.as_list()\n-            if return_all_outputs:\n-                shape[0] = time_steps\n-            else:\n-                shape[0] = 1\n-            shape[1] = batch\n-            output_.set_shape(shape)\n-        return output_\n-\n-    outputs = tf.nest.map_structure(set_shape, outputs)\n-\n-    if not time_major:\n-        outputs = tf.nest.map_structure(swap_batch_timestep, outputs)\n-\n-    return last_output, outputs, new_states\n\n@@ -6,6 +6,12 @@ def add(x1, x2):\n     return tfnp.add(x1, x2)\n \n \n+def bincount(x, weights=None, minlength=None):\n+    if minlength is not None:\n+        x = tf.cast(x, tf.int32)\n+    return tf.math.bincount(x, weights=weights, minlength=minlength, axis=-1)\n+\n+\n def einsum(subscripts, *operands, **kwargs):\n     return tfnp.einsum(subscripts, *operands, **kwargs)\n \n\n@@ -0,0 +1,124 @@\n+import tensorflow as tf\n+\n+from keras_core import backend\n+from keras_core.optimizers import base_optimizer\n+\n+\n+class TFOptimizer(base_optimizer.Optimizer):\n+    \"\"\"A class for Tensorflow specific optimizer logic.\n+\n+    The major behavior change for this class is for tf.distribute.\n+\n+    It will override methods from base Keras core Optimizer,\n+    which provide distribute specific functionality, e.g. variable\n+    creation, loss reduction, etc.\n+    \"\"\"\n+\n+    def __init__(self, *args, **kwargs):\n+        super().__init__(*args, **kwargs)\n+        self._distribution_strategy = tf.distribute.get_strategy()\n+\n+    def add_variable_from_reference(self, reference_variable, name=None):\n+        if isinstance(reference_variable, backend.Variable):\n+            colocate_var = reference_variable.value\n+        else:\n+            colocate_var = reference_variable\n+\n+        with self._distribution_strategy.extended.colocate_vars_with(\n+            colocate_var\n+        ):\n+            return super().add_variable_from_reference(\n+                reference_variable, name=name\n+            )\n+\n+    def _var_key(self, variable):\n+        if isinstance(variable, backend.Variable):\n+            variable = variable.value  # Convert to tf.Variable\n+        if hasattr(variable, \"_distributed_container\"):\n+            variable = variable._distributed_container()\n+        elif (\n+            isinstance(variable, tf.__internal__.CompositeTensor)\n+            and hasattr(variable, \"handle\")\n+            and hasattr(variable.handle, \"_distributed_container\")\n+        ):\n+            # For ResourceVariables, the _distributed_container attribute\n+            # is added to their handle tensors.\n+            variable = variable.handle._distributed_container()\n+        return variable._unique_id\n+\n+    def _apply_weight_decay(self, variables):\n+        if self.weight_decay is None:\n+            return\n+\n+        def distributed_apply_weight_decay(distribution, variables, **kwargs):\n+            def weight_decay_fn(variable):\n+                if self._use_weight_decay(variable):\n+                    lr = tf.cast(self.learning_rate, variable.dtype)\n+                    wd = tf.cast(self.weight_decay, variable.dtype)\n+                    variable.assign(variable - variable * wd * lr)\n+\n+            for variable in variables:\n+                distribution.extended.update(\n+                    variable, weight_decay_fn, group=False\n+                )\n+\n+        tf.__internal__.distribute.interim.maybe_merge_call(\n+            distributed_apply_weight_decay,\n+            self._distribution_strategy,\n+            variables,\n+        )\n+\n+    def _internal_apply_gradients(self, grads_and_vars):\n+        tf.__internal__.distribute.interim.maybe_merge_call(\n+            self._distributed_apply_gradients_fn,\n+            self._distribution_strategy,\n+            grads_and_vars,\n+        )\n+\n+    def _distributed_apply_gradients_fn(\n+        self, distribution, grads_and_vars, **kwargs\n+    ):\n+        \"\"\"`apply_gradients` using a `DistributionStrategy`.\"\"\"\n+\n+        def apply_grad_to_update_var(var, grad):\n+            learning_rate = self._get_current_learning_rate()\n+            return self.update_step(grad, var, learning_rate)\n+\n+        for grad, var in grads_and_vars:\n+            distribution.extended.update(\n+                var, apply_grad_to_update_var, args=(grad,), group=False\n+            )\n+\n+        if self.use_ema:\n+            _, var_list = zip(*grads_and_vars)\n+            self._update_model_variables_moving_average(var_list)\n+            if self.ema_overwrite_frequency:\n+                # Only when self.ema_overwrite_frequency is not None, we\n+                # overwrite the model variables.\n+                should_overwrite_model_vars = (\n+                    self.iterations + 1\n+                ) % self.ema_overwrite_frequency == 0\n+                tf.cond(\n+                    tf.cast(should_overwrite_model_vars, tf.bool),\n+                    true_fn=lambda: self._overwrite_model_variables_with_average_value(  # noqa: E501\n+                        var_list\n+                    ),\n+                    false_fn=lambda: None,\n+                )\n+        self.iterations.assign(self.iterations + 1)\n+\n+    def _overwrite_model_variables_with_average_value(self, var_list):\n+        \"\"\"Overwrite model variables with their moving average values.\n+\n+        This function overwrites variables on each device.\n+        Args:\n+          var_list: list of model variables.\n+        \"\"\"\n+        strategy = self._distribution_strategy\n+        # Override model variable by the stored average value on all devices.\n+        for var, average_var in zip(\n+            var_list, self._model_variables_moving_average\n+        ):\n+            strategy.extended.update(\n+                var, lambda a, b: a.assign(b), args=(average_var,)\n+            )\n\n@@ -0,0 +1,132 @@\n+# flake8: noqa\n+\n+import numpy as np\n+import pytest\n+import tensorflow as tf\n+from tensorflow.python.eager import context\n+\n+from keras_core import backend\n+from keras_core import testing\n+from keras_core.optimizers.sgd import SGD\n+\n+\n+@pytest.mark.skipif(\n+    backend.backend() != \"tensorflow\",\n+    reason=\"The distribute test can only run with TF backend.\",\n+)\n+class OptimizerDistributeTest(testing.TestCase):\n+    def setUp(self):\n+        super().setUp()\n+        # Need at least 2 devices for distribution related tests.\n+        cpus = tf.config.list_physical_devices(\"CPU\")\n+        context._reset_context()\n+        tf.config.set_logical_device_configuration(\n+            cpus[0],\n+            [\n+                tf.config.LogicalDeviceConfiguration(),\n+                tf.config.LogicalDeviceConfiguration(),\n+            ],\n+        )\n+        self.strategy = tf.distribute.MirroredStrategy([\"CPU:0\", \"CPU:1\"])\n+\n+    def test_config(self):\n+        with self.strategy.scope():\n+            optimizer = SGD(\n+                learning_rate=0.5,\n+                momentum=0.06,\n+                nesterov=True,\n+                weight_decay=0.004,\n+            )\n+        self.run_class_serialization_test(optimizer)\n+\n+    def test_single_step(self):\n+        with self.strategy.scope():\n+            optimizer = SGD(\n+                learning_rate=0.5,\n+                momentum=0.06,\n+            )\n+            grads = tf.constant([1.0, 6.0, 7.0, 2.0])\n+            vars = backend.Variable([1.0, 2.0, 3.0, 4.0]).value\n+\n+            self.strategy.run(\n+                lambda: optimizer.apply_gradients(zip([grads], [vars]))\n+            )\n+            self.assertAllClose(\n+                vars, [0.5, -1.0, -0.5, 3.0], rtol=1e-4, atol=1e-4\n+            )\n+\n+    def test_weight_decay(self):\n+        with self.strategy.scope():\n+            grads, var1, var2, var3 = (\n+                tf.zeros(()),\n+                backend.Variable(2.0).value,\n+                backend.Variable(3.0, name=\"exclude\").value,\n+                backend.Variable(4.0).value,\n+            )\n+            optimizer_1 = SGD(learning_rate=1.0, weight_decay=0.004)\n+            self.strategy.run(\n+                lambda: optimizer_1.apply_gradients(zip([grads], [var1]))\n+            )\n+\n+            optimizer_2 = SGD(learning_rate=1.0, weight_decay=0.004)\n+\n+            def opt2_run():\n+                optimizer_2.exclude_from_weight_decay(var_names=[\"exclude\"])\n+                optimizer_2.apply_gradients(zip([grads, grads], [var1, var2]))\n+\n+            self.strategy.run(opt2_run)\n+\n+            optimizer_3 = SGD(learning_rate=1.0, weight_decay=0.004)\n+\n+            def opt3_run():\n+                optimizer_3.exclude_from_weight_decay(var_list=[var3])\n+                optimizer_3.apply_gradients(zip([grads, grads], [var1, var3]))\n+\n+            self.strategy.run(opt3_run)\n+\n+        self.assertAlmostEqual(var1.numpy(), 1.9760959)\n+        self.assertAlmostEqual(var2.numpy(), 3.0)\n+        self.assertAlmostEqual(var3.numpy(), 4.0)\n+\n+    def test_correctness_with_golden(self):\n+        with self.strategy.scope():\n+            optimizer = SGD(nesterov=True)\n+\n+            x = backend.Variable(np.ones([10])).value\n+            grads = np.arange(0.1, 1.1, 0.1)\n+            first_grads = np.full((10,), 0.01)\n+\n+        # fmt: off\n+        golden = np.array(\n+            [[0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n+            0.9999, 0.9999], [0.9989, 0.9979, 0.9969, 0.9959, 0.9949, 0.9939,\n+            0.9929, 0.9919, 0.9909, 0.9899], [0.9979, 0.9959, 0.9939, 0.9919,\n+            0.9899, 0.9879, 0.9859, 0.9839, 0.9819, 0.9799], [0.9969, 0.9939,\n+            0.9909, 0.9879, 0.9849, 0.9819, 0.9789, 0.9759, 0.9729, 0.9699],\n+            [0.9959, 0.9919, 0.9879, 0.9839, 0.9799, 0.9759, 0.9719, 0.9679,\n+            0.9639, 0.9599]]\n+        )\n+        # fmt: on\n+\n+        self.strategy.run(\n+            lambda: optimizer.apply_gradients(zip([first_grads], [x]))\n+        )\n+        for i in range(5):\n+            self.assertAllClose(x, golden[i], rtol=5e-4, atol=5e-4)\n+            self.strategy.run(\n+                lambda: optimizer.apply_gradients(zip([grads], [x]))\n+            )\n+\n+    def test_clip_norm(self):\n+        with self.strategy.scope():\n+            optimizer = SGD(clipnorm=1)\n+            grad = [np.array([100.0, 100.0])]\n+            clipped_grad = optimizer._clip_gradients(grad)\n+            self.assertAllClose(clipped_grad[0], [2**0.5 / 2, 2**0.5 / 2])\n+\n+    def test_clip_value(self):\n+        with self.strategy.scope():\n+            optimizer = SGD(clipvalue=1)\n+            grad = [np.array([100.0, 100.0])]\n+            clipped_grad = optimizer._clip_gradients(grad)\n+            self.assertAllClose(clipped_grad[0], [1.0, 1.0])\n\n@@ -0,0 +1,957 @@\n+import tensorflow as tf\n+\n+\n+def rnn(\n+    step_function,\n+    inputs,\n+    initial_states,\n+    go_backwards=False,\n+    mask=None,\n+    constants=None,\n+    unroll=False,\n+    input_length=None,\n+    time_major=False,\n+    zero_output_for_mask=False,\n+    return_all_outputs=True,\n+):\n+    \"\"\"Iterates over the time dimension of a tensor.\n+\n+    Args:\n+        step_function: RNN step function.\n+            Args;\n+                `input`; Tensor with shape `(samples, ...)` (no time dimension),\n+                    representing input for the batch of samples at a certain\n+                    time step.\n+                `states`; List of tensors.\n+            Returns;\n+                `output`; Tensor with shape `(samples, output_dim)`\n+                    (no time dimension).\n+                `new_states`; List of tensors, same length and shapes\n+                    as 'states'. The first state in the list must be the\n+                    output tensor at the previous timestep.\n+        inputs: Tensor of temporal data of shape `(samples, time, ...)`\n+            (at least 3D), or nested tensors, and each of which has shape\n+            `(samples, time, ...)`.\n+        initial_states: Tensor with shape `(samples, state_size)`\n+            (no time dimension), containing the initial values for the states\n+            used in the step function. In the case that state_size is in a\n+            nested shape, the shape of initial_states will also follow the\n+            nested structure.\n+        go_backwards: Boolean. If `True`, do the iteration over the time\n+            dimension in reverse order and return the reversed sequence.\n+        mask: Binary tensor with shape `(samples, time, 1)`,\n+            with a zero for every element that is masked.\n+        constants: List of constant values passed at each step.\n+        unroll: Whether to unroll the RNN or to use a symbolic `while_loop`.\n+        input_length: An integer or a 1-D Tensor, depending on whether\n+            the time dimension is fixed-length or not. In case of variable\n+            length input, it is used for masking in case there's no mask\n+            specified.\n+        time_major: Boolean. If `True`, the inputs and outputs will be in shape\n+            `(timesteps, batch, ...)`, whereas in the False case, it will be\n+            `(batch, timesteps, ...)`. Using `time_major = True` is a bit more\n+            efficient because it avoids transposes at the beginning and end of\n+            the RNN calculation. However, most TensorFlow data is batch-major,\n+            so by default this function accepts input and emits output in\n+            batch-major form.\n+        zero_output_for_mask: Boolean. If `True`, the output for masked timestep\n+            will be zeros, whereas in the `False` case, output from previous\n+            timestep is returned.\n+        return_all_outputs: Boolean. If `True`, return the recurrent outputs for\n+            all timesteps in the sequence. If `False`, only return the output\n+            for the last timestep (which consumes less memory).\n+\n+    Returns:\n+        A tuple, `(last_output, outputs, new_states)`.\n+            - `last_output`: the latest output of the rnn,\n+                with shape `(samples, ...)`.\n+            - `outputs`:\n+                - If `return_all_outputs=True`: a tensor with shape\n+                  `(samples, time, ...)` where each entry `outputs[s, t]` is the\n+                  output of the step function at time `t` for sample `s`\n+                - Else, a tensor equal to `last_output` with shape\n+                  `(samples, 1, ...)`\n+            - `new_states`: list of tensors, latest states returned by\n+                the step function, of shape `(samples, ...)`.\n+    \"\"\"\n+\n+    def swap_batch_timestep(input_t):\n+        # Swap the batch and timestep dim for the incoming tensor.\n+        axes = list(range(len(input_t.shape)))\n+        axes[0], axes[1] = 1, 0\n+        return tf.transpose(input_t, axes)\n+\n+    if not time_major:\n+        inputs = tf.nest.map_structure(swap_batch_timestep, inputs)\n+\n+    flatted_inputs = tf.nest.flatten(inputs)\n+    time_steps = flatted_inputs[0].shape[0]\n+    batch = flatted_inputs[0].shape[1]\n+    time_steps_t = tf.shape(flatted_inputs[0])[0]\n+\n+    for input_ in flatted_inputs:\n+        input_.shape.with_rank_at_least(3)\n+\n+    if mask is not None:\n+        if mask.dtype != tf.bool:\n+            mask = tf.cast(mask, tf.bool)\n+        if len(mask.shape) == 2:\n+            mask = tf.expand_dims(mask, axis=-1)\n+        if not time_major:\n+            mask = swap_batch_timestep(mask)\n+\n+    if constants is None:\n+        constants = []\n+\n+    # tf.where needs its condition tensor to be the same shape as its two\n+    # result tensors, but in our case the condition (mask) tensor is\n+    # (nsamples, 1), and inputs are (nsamples, ndimensions) or even more.\n+    # So we need to broadcast the mask to match the shape of inputs.\n+    # That's what the tile call does, it just repeats the mask along its\n+    # second dimension n times.\n+    def _expand_mask(mask_t, input_t, fixed_dim=1):\n+        if tf.nest.is_nested(mask_t):\n+            raise ValueError(\n+                f\"mask_t is expected to be tensor, but got {mask_t}\"\n+            )\n+        if tf.nest.is_nested(input_t):\n+            raise ValueError(\n+                f\"input_t is expected to be tensor, but got {input_t}\"\n+            )\n+        rank_diff = len(input_t.shape) - len(mask_t.shape)\n+        for _ in range(rank_diff):\n+            mask_t = tf.expand_dims(mask_t, -1)\n+        multiples = [1] * fixed_dim + input_t.shape.as_list()[fixed_dim:]\n+        return tf.tile(mask_t, multiples)\n+\n+    if unroll:\n+        if not time_steps:\n+            raise ValueError(\"Unrolling requires a fixed number of timesteps.\")\n+        states = tuple(initial_states)\n+        successive_states = []\n+        successive_outputs = []\n+\n+        # Process the input tensors. The input tensor need to be split on the\n+        # time_step dim, and reverse if go_backwards is True. In the case of\n+        # nested input, the input is flattened and then transformed\n+        # individually.  The result of this will be a tuple of lists, each of\n+        # the item in tuple is list of the tensor with shape (batch, feature)\n+        def _process_single_input_t(input_t):\n+            input_t = tf.unstack(input_t)  # unstack for time_step dim\n+            if go_backwards:\n+                input_t.reverse()\n+            return input_t\n+\n+        if tf.nest.is_nested(inputs):\n+            processed_input = tf.nest.map_structure(\n+                _process_single_input_t, inputs\n+            )\n+        else:\n+            processed_input = (_process_single_input_t(inputs),)\n+\n+        def _get_input_tensor(time):\n+            inp = [t_[time] for t_ in processed_input]\n+            return tf.nest.pack_sequence_as(inputs, inp)\n+\n+        if mask is not None:\n+            mask_list = tf.unstack(mask)\n+            if go_backwards:\n+                mask_list.reverse()\n+\n+            for i in range(time_steps):\n+                inp = _get_input_tensor(i)\n+                mask_t = mask_list[i]\n+                output, new_states = step_function(\n+                    inp, tuple(states) + tuple(constants)\n+                )\n+                tiled_mask_t = _expand_mask(mask_t, output)\n+\n+                if not successive_outputs:\n+                    prev_output = tf.zeros_like(output)\n+                else:\n+                    prev_output = successive_outputs[-1]\n+\n+                output = tf.where(tiled_mask_t, output, prev_output)\n+\n+                flat_states = tf.nest.flatten(states)\n+                flat_new_states = tf.nest.flatten(new_states)\n+                tiled_mask_t = tuple(\n+                    _expand_mask(mask_t, s) for s in flat_states\n+                )\n+                flat_final_states = tuple(\n+                    tf.where(m, s, ps)\n+                    for m, s, ps in zip(\n+                        tiled_mask_t, flat_new_states, flat_states\n+                    )\n+                )\n+                states = tf.nest.pack_sequence_as(states, flat_final_states)\n+\n+                if return_all_outputs:\n+                    successive_outputs.append(output)\n+                    successive_states.append(states)\n+                else:\n+                    successive_outputs = [output]\n+                    successive_states = [states]\n+            last_output = successive_outputs[-1]\n+            new_states = successive_states[-1]\n+            outputs = tf.stack(successive_outputs)\n+\n+            if zero_output_for_mask:\n+                last_output = tf.where(\n+                    _expand_mask(mask_list[-1], last_output),\n+                    last_output,\n+                    tf.zeros_like(last_output),\n+                )\n+                outputs = tf.where(\n+                    _expand_mask(mask, outputs, fixed_dim=2),\n+                    outputs,\n+                    tf.zeros_like(outputs),\n+                )\n+\n+        else:  # mask is None\n+            for i in range(time_steps):\n+                inp = _get_input_tensor(i)\n+                output, states = step_function(\n+                    inp, tuple(states) + tuple(constants)\n+                )\n+                if return_all_outputs:\n+                    successive_outputs.append(output)\n+                    successive_states.append(states)\n+                else:\n+                    successive_outputs = [output]\n+                    successive_states = [states]\n+            last_output = successive_outputs[-1]\n+            new_states = successive_states[-1]\n+            outputs = tf.stack(successive_outputs)\n+\n+    else:  # Unroll == False\n+        states = tuple(initial_states)\n+\n+        # Create input tensor array, if the inputs is nested tensors, then it\n+        # will be flattened first, and tensor array will be created one per\n+        # flattened tensor.\n+        input_ta = tuple(\n+            tf.TensorArray(\n+                dtype=inp.dtype,\n+                size=time_steps_t,\n+                tensor_array_name=f\"input_ta_{i}\",\n+            )\n+            for i, inp in enumerate(flatted_inputs)\n+        )\n+        input_ta = tuple(\n+            ta.unstack(input_)\n+            if not go_backwards\n+            else ta.unstack(tf.reverse(input_, [0]))\n+            for ta, input_ in zip(input_ta, flatted_inputs)\n+        )\n+\n+        # Get the time(0) input and compute the output for that, the output will\n+        # be used to determine the dtype of output tensor array. Don't read from\n+        # input_ta due to TensorArray clear_after_read default to True.\n+        input_time_zero = tf.nest.pack_sequence_as(\n+            inputs, [inp[0] for inp in flatted_inputs]\n+        )\n+        # output_time_zero is used to determine the cell output shape and its\n+        # dtype.  the value is discarded.\n+        output_time_zero, _ = step_function(\n+            input_time_zero, tuple(initial_states) + tuple(constants)\n+        )\n+\n+        output_ta_size = time_steps_t if return_all_outputs else 1\n+        output_ta = tuple(\n+            tf.TensorArray(\n+                dtype=out.dtype,\n+                size=output_ta_size,\n+                element_shape=out.shape,\n+                tensor_array_name=f\"output_ta_{i}\",\n+            )\n+            for i, out in enumerate(tf.nest.flatten(output_time_zero))\n+        )\n+\n+        time = tf.constant(0, dtype=\"int32\", name=\"time\")\n+\n+        if input_length is None:\n+            max_iterations = time_steps_t\n+        else:\n+            max_iterations = tf.reduce_max(input_length)\n+\n+        while_loop_kwargs = {\n+            \"cond\": lambda time, *_: time < time_steps_t,\n+            \"maximum_iterations\": max_iterations,\n+            \"parallel_iterations\": 32,\n+            \"swap_memory\": True,\n+        }\n+        if mask is not None:\n+            if go_backwards:\n+                mask = tf.reverse(mask, [0])\n+\n+            mask_ta = tf.TensorArray(\n+                dtype=tf.bool, size=time_steps_t, tensor_array_name=\"mask_ta\"\n+            )\n+            mask_ta = mask_ta.unstack(mask)\n+\n+            def masking_fn(time):\n+                return mask_ta.read(time)\n+\n+            def compute_masked_output(mask_t, flat_out, flat_mask):\n+                tiled_mask_t = tuple(\n+                    _expand_mask(mask_t, o, fixed_dim=len(mask_t.shape))\n+                    for o in flat_out\n+                )\n+                return tuple(\n+                    tf.where(m, o, fm)\n+                    for m, o, fm in zip(tiled_mask_t, flat_out, flat_mask)\n+                )\n+\n+        elif isinstance(input_length, tf.Tensor):\n+            if go_backwards:\n+                max_len = tf.reduce_max(input_length, axis=0)\n+                rev_input_length = tf.subtract(max_len - 1, input_length)\n+\n+                def masking_fn(time):\n+                    return tf.less(rev_input_length, time)\n+\n+            else:\n+\n+                def masking_fn(time):\n+                    return tf.greater(input_length, time)\n+\n+            def compute_masked_output(mask_t, flat_out, flat_mask):\n+                return tuple(\n+                    tf.where(mask_t, o, zo)\n+                    for (o, zo) in zip(flat_out, flat_mask)\n+                )\n+\n+        else:\n+            masking_fn = None\n+\n+        if masking_fn is not None:\n+            # Mask for the T output will be base on the output of T - 1. In the\n+            # case T = 0, a zero filled tensor will be used.\n+            flat_zero_output = tuple(\n+                tf.zeros_like(o) for o in tf.nest.flatten(output_time_zero)\n+            )\n+\n+            def _step(time, output_ta_t, prev_output, *states):\n+                \"\"\"RNN step function.\n+\n+                Args:\n+                    time: Current timestep value.\n+                    output_ta_t: TensorArray.\n+                    prev_output: tuple of outputs from time - 1.\n+                    *states: List of states.\n+\n+                Returns:\n+                    Tuple: `(time + 1, output_ta_t, output) + tuple(new_states)`\n+                \"\"\"\n+                current_input = tuple(ta.read(time) for ta in input_ta)\n+                # maybe set shape.\n+                current_input = tf.nest.pack_sequence_as(inputs, current_input)\n+                mask_t = masking_fn(time)\n+                output, new_states = step_function(\n+                    current_input, tuple(states) + tuple(constants)\n+                )\n+                # mask output\n+                flat_output = tf.nest.flatten(output)\n+                flat_mask_output = (\n+                    flat_zero_output\n+                    if zero_output_for_mask\n+                    else tf.nest.flatten(prev_output)\n+                )\n+                flat_new_output = compute_masked_output(\n+                    mask_t, flat_output, flat_mask_output\n+                )\n+\n+                # mask states\n+                flat_state = tf.nest.flatten(states)\n+                flat_new_state = tf.nest.flatten(new_states)\n+                flat_final_state = compute_masked_output(\n+                    mask_t, flat_new_state, flat_state\n+                )\n+                new_states = tf.nest.pack_sequence_as(\n+                    new_states, flat_final_state\n+                )\n+\n+                ta_index_to_write = time if return_all_outputs else 0\n+                output_ta_t = tuple(\n+                    ta.write(ta_index_to_write, out)\n+                    for ta, out in zip(output_ta_t, flat_new_output)\n+                )\n+\n+                return (time + 1, output_ta_t, tuple(flat_new_output)) + tuple(\n+                    new_states\n+                )\n+\n+            final_outputs = tf.while_loop(\n+                body=_step,\n+                loop_vars=(time, output_ta, flat_zero_output) + states,\n+                **while_loop_kwargs,\n+            )\n+            # Skip final_outputs[2] which is the output for final timestep.\n+            new_states = final_outputs[3:]\n+        else:\n+\n+            def _step(time, output_ta_t, *states):\n+                \"\"\"RNN step function.\n+\n+                Args:\n+                    time: Current timestep value.\n+                    output_ta_t: TensorArray.\n+                    *states: List of states.\n+\n+                Returns:\n+                    Tuple: `(time + 1,output_ta_t) + tuple(new_states)`\n+                \"\"\"\n+                current_input = tuple(ta.read(time) for ta in input_ta)\n+                current_input = tf.nest.pack_sequence_as(inputs, current_input)\n+                output, new_states = step_function(\n+                    current_input, tuple(states) + tuple(constants)\n+                )\n+                flat_new_state = tf.nest.flatten(new_states)\n+\n+                flat_output = tf.nest.flatten(output)\n+                ta_index_to_write = time if return_all_outputs else 0\n+                output_ta_t = tuple(\n+                    ta.write(ta_index_to_write, out)\n+                    for ta, out in zip(output_ta_t, flat_output)\n+                )\n+\n+                new_states = tf.nest.pack_sequence_as(\n+                    initial_states, flat_new_state\n+                )\n+                return (time + 1, output_ta_t) + tuple(new_states)\n+\n+            final_outputs = tf.while_loop(\n+                body=_step,\n+                loop_vars=(time, output_ta) + states,\n+                **while_loop_kwargs,\n+            )\n+            new_states = final_outputs[2:]\n+\n+        output_ta = final_outputs[1]\n+\n+        outputs = tuple(o.stack() for o in output_ta)\n+        last_output = tuple(o[-1] for o in outputs)\n+\n+        outputs = tf.nest.pack_sequence_as(output_time_zero, outputs)\n+        last_output = tf.nest.pack_sequence_as(output_time_zero, last_output)\n+\n+    # static shape inference\n+    def set_shape(output_):\n+        if isinstance(output_, tf.Tensor):\n+            shape = output_.shape.as_list()\n+            if return_all_outputs:\n+                shape[0] = time_steps\n+            else:\n+                shape[0] = 1\n+            shape[1] = batch\n+            output_.set_shape(shape)\n+        return output_\n+\n+    outputs = tf.nest.map_structure(set_shape, outputs)\n+\n+    if not time_major:\n+        outputs = tf.nest.map_structure(swap_batch_timestep, outputs)\n+\n+    return last_output, outputs, new_states\n+\n+\n+def gru(\n+    inputs,\n+    initial_state,\n+    mask,\n+    kernel,\n+    recurrent_kernel,\n+    bias,\n+    activation,\n+    recurrent_activation,\n+    return_sequences=False,\n+    go_backwards=False,\n+    unroll=False,\n+    time_major=False,\n+    reset_after=True,\n+):\n+    args_supported = _do_gru_arguments_support_cudnn(\n+        activation=activation,\n+        recurrent_activation=recurrent_activation,\n+        unroll=unroll,\n+        bias=bias,\n+        reset_after=reset_after,\n+    )\n+    inputs_supported = _do_rnn_inputs_support_cudnn(mask, time_major)\n+    if not args_supported or not inputs_supported:\n+        raise NotImplementedError\n+\n+    from keras_core.backend.tensorflow import Variable\n+\n+    if isinstance(kernel, Variable):\n+        kernel = kernel.value\n+    if isinstance(recurrent_kernel, Variable):\n+        recurrent_kernel = recurrent_kernel.value\n+    if isinstance(bias, Variable):\n+        bias = bias.value\n+\n+    try:\n+        return _cudnn_gru(\n+            inputs,\n+            initial_state,\n+            kernel,\n+            recurrent_kernel,\n+            bias,\n+            mask,\n+            time_major,\n+            go_backwards,\n+            return_sequences,\n+        )\n+    except tf.errors.InvalidArgumentError:\n+        # cuDNN op not found.\n+        raise NotImplementedError\n+    except tf.errors.NotFoundError:\n+        # alternative error: device not found for op\n+        raise NotImplementedError\n+\n+\n+def _do_gru_arguments_support_cudnn(\n+    activation,\n+    recurrent_activation,\n+    unroll,\n+    bias,\n+    reset_after,\n+):\n+    from keras_core import activations\n+    from keras_core import operations as ops\n+\n+    return (\n+        activation in (activations.tanh, tf.tanh, ops.tanh)\n+        and recurrent_activation\n+        in (activations.sigmoid, tf.sigmoid, ops.sigmoid)\n+        and not unroll\n+        and bias is not None\n+        and reset_after\n+    )\n+\n+\n+def _do_lstm_arguments_support_cudnn(\n+    activation,\n+    recurrent_activation,\n+    unroll,\n+    bias,\n+):\n+    from keras_core import activations\n+    from keras_core import operations as ops\n+\n+    return (\n+        activation in (activations.tanh, tf.tanh, ops.tanh)\n+        and recurrent_activation\n+        in (activations.sigmoid, tf.sigmoid, ops.sigmoid)\n+        and not unroll\n+        and bias is not None\n+    )\n+\n+\n+def _do_rnn_inputs_support_cudnn(mask, time_major):\n+    if tf.sysconfig.get_build_info()[\"is_rocm_build\"]:\n+        if mask is not None:\n+            return tf.reduce_all(mask)\n+        return True\n+    if mask is None:\n+        return True\n+    if time_major:\n+        mask = tf.transpose(mask)\n+    return tf.logical_and(\n+        _is_sequence_right_padded(mask),\n+        tf.logical_not(_has_fully_masked_sequence(mask)),\n+    )\n+\n+\n+def _is_sequence_right_padded(mask):\n+    \"\"\"Check the mask tensor and see if it right padded.\n+\n+    For cuDNN kernel, it uses the sequence length param to skip the tailing\n+    timestep. If the data is left padded, or not a strict right padding (has\n+    masked value in the middle of the sequence), then cuDNN kernel won't be work\n+    properly in those cases.\n+\n+    Left padded data: [[False, False, True, True, True]].\n+    Right padded data: [[True, True, True, False, False]].\n+    Mixture of mask/unmasked data: [[True, False, True, False, False]].\n+\n+    Note that for the mixed data example above, the actually data RNN should see\n+    are those 2 Trues (index 0 and 2), the index 1 False should be ignored and\n+    not pollute the internal states.\n+\n+    Args:\n+      mask: the Boolean tensor with shape [batch, timestep]\n+\n+    Returns:\n+      boolean scalar tensor, whether the mask is strictly right padded.\n+    \"\"\"\n+    max_seq_length = tf.shape(mask)[1]\n+    count_of_true = tf.reduce_sum(tf.cast(mask, tf.int32), axis=1)\n+    right_padded_mask = tf.sequence_mask(count_of_true, maxlen=max_seq_length)\n+    return tf.reduce_all(tf.equal(mask, right_padded_mask))\n+\n+\n+def _has_fully_masked_sequence(mask):\n+    # Cudnn kernel will error out if the input sequence contains any\n+    # fully masked data. We walk around this issue by rerouting the computation\n+    # to standard kernel, until the issue on cudnn side has been fixed.  For a\n+    # fully masked sequence, it will contain all Falses. To make it easy to\n+    # check, we inverse the boolean, check if any of the sequence has all True.\n+    return tf.reduce_any(tf.reduce_all(tf.logical_not(mask), axis=1))\n+\n+\n+def _standardize_cudnn_weights(weights, biases, shape, transpose_weights=False):\n+    \"\"\"Utility function convert variable to cuDNN compatible parameter.\n+\n+    Note that Keras weights for kernels are different from the cuDNN format.\n+    Eg.:\n+\n+    ```\n+      Keras                 cuDNN\n+      [[0, 1, 2],  <--->  [[0, 2, 4],\n+       [3, 4, 5]]          [1, 3, 5]]\n+    ```\n+\n+    If the input weights need to be in a unified format, then set\n+    `transpose_weights=True` to convert the weights.\n+\n+    Args:\n+        weights: list of weights for the kernels and recurrent kernels.\n+        biases: list of biases for individual gate.\n+        shape: the shape for the converted variables that will be feed to cuDNN.\n+        transpose_weights: boolean, whether to transpose the weights.\n+\n+    Returns:\n+        The converted weights that can be feed to cuDNN ops as param.\n+    \"\"\"\n+\n+    def convert(w):\n+        return tf.transpose(w) if transpose_weights else w\n+\n+    weights = [tf.reshape(convert(x), shape) for x in weights]\n+    biases = [tf.reshape(x, shape) for x in biases]\n+    return tf.concat(weights + biases, axis=0)\n+\n+\n+def _compute_sequence_length_from_mask(mask, time_major):\n+    \"\"\"Calculate the sequence length tensor (1-D) based on the masking tensor.\n+\n+    The masking tensor is a 2D boolean tensor with shape [batch, timestep]. For\n+    any timestep that should be masked, the corresponding field will be False.\n+    Consider the following example:\n+      a = [[True, True, False, False],\n+           [True, True, True, False]]\n+    It is a (2, 4) tensor, and the corresponding sequence length result should\n+    be 1D tensor with value [2, 3]. Note that the masking tensor must be right\n+    padded that could be checked by, e.g., `is_sequence_right_padded()`.\n+\n+    Args:\n+      mask: Boolean tensor with shape [batch, timestep] or [timestep, batch] if\n+        time_major=True.\n+      time_major: Boolean, which indicates whether the mask is time major or\n+        batch major.\n+    Returns:\n+      sequence_length: 1D int32 tensor.\n+    \"\"\"\n+    timestep_index = 0 if time_major else 1\n+    return tf.reduce_sum(tf.cast(mask, tf.int32), axis=timestep_index)\n+\n+\n+@tf.function(autograph=False)\n+def _cudnn_gru(\n+    inputs,\n+    initial_state,\n+    kernel,\n+    recurrent_kernel,\n+    bias,\n+    mask,\n+    time_major,\n+    go_backwards,\n+    return_sequences,\n+):\n+    \"\"\"GRU with cuDNN implementation which is only available for GPU.\"\"\"\n+    if mask is not None:\n+        sequence_lengths = _compute_sequence_length_from_mask(mask, time_major)\n+    else:\n+        sequence_lengths = None\n+\n+    if not time_major and sequence_lengths is None:\n+        inputs = tf.transpose(inputs, perm=(1, 0, 2))\n+        seq_axis, batch_axis = (0, 1)\n+    else:\n+        seq_axis, batch_axis = (0, 1) if time_major else (1, 0)\n+    # For init_h, cuDNN expects one more dim of num_layers before or after batch\n+    # dim for time major or batch major inputs respectively\n+    init_h = tf.expand_dims(initial_state, axis=seq_axis)\n+\n+    weights = tf.split(kernel, 3, axis=1)\n+    weights += tf.split(recurrent_kernel, 3, axis=1)\n+    # Note that the bias was initialized as shape (2, 3 * units), flatten it to\n+    # (6 * units)\n+    bias = tf.split(tf.reshape(bias, [-1]), 6)\n+\n+    if tf.sysconfig.get_build_info()[\"is_cuda_build\"]:\n+        # Note that the gate order for cuDNN is different from the canonical\n+        # format.  canonical format is [z, r, h], whereas cuDNN is [r, z, h].\n+        # The swap need to be done for kernel, recurrent_kernel, input_bias,\n+        # recurrent_bias.\n+        # z is update gate weights.\n+        # r is reset gate weights.\n+        # h is output gate weights.\n+        weights[0], weights[1] = weights[1], weights[0]\n+        weights[3], weights[4] = weights[4], weights[3]\n+        bias[0], bias[1] = bias[1], bias[0]\n+        bias[3], bias[4] = bias[4], bias[3]\n+\n+    params = _standardize_cudnn_weights(\n+        weights=weights,\n+        biases=bias,\n+        shape=tf.constant([-1]),\n+        transpose_weights=True,\n+    )\n+\n+    if sequence_lengths is not None:\n+        if go_backwards:\n+            # Three reversals are required. E.g.,\n+            # normal input = [1, 2, 3, 0, 0]  # where 0 need to be masked\n+            # reversed_input_to_cudnn = [3, 2, 1, 0, 0]\n+            # output_from_cudnn = [6, 5, 4, 0, 0]\n+            # expected_output = [0, 0, 6, 5 ,4]\n+            inputs = tf.reverse_sequence(\n+                inputs,\n+                sequence_lengths,\n+                seq_axis=seq_axis,\n+                batch_axis=batch_axis,\n+            )\n+        outputs, h, _, _, _ = tf.raw_ops.CudnnRNNV3(\n+            input=inputs,\n+            input_h=init_h,\n+            input_c=0,\n+            params=params,\n+            is_training=True,\n+            rnn_mode=\"gru\",\n+            sequence_lengths=sequence_lengths,\n+            time_major=time_major,\n+        )\n+        if go_backwards:\n+            outputs = tf.reverse_sequence(\n+                outputs,\n+                sequence_lengths,\n+                seq_axis=seq_axis,\n+                batch_axis=batch_axis,\n+            )\n+            outputs = tf.reverse(outputs, axis=[seq_axis])\n+    else:\n+        if go_backwards:\n+            # Reverse axis 0 since the input is already convert to time major.\n+            inputs = tf.reverse(inputs, axis=[0])\n+        outputs, h, _, _ = tf.raw_ops.CudnnRNN(\n+            input=inputs,\n+            input_h=init_h,\n+            input_c=0,\n+            params=params,\n+            is_training=True,\n+            rnn_mode=\"gru\",\n+        )\n+\n+    last_output = outputs[-1]\n+    if not time_major and sequence_lengths is None and return_sequences:\n+        outputs = tf.transpose(outputs, perm=[1, 0, 2])\n+    state = tf.squeeze(h, axis=seq_axis)\n+\n+    # In the case of variable length input, the cudnn kernel will fill zeros for\n+    # the output, whereas the default keras behavior is to bring over the\n+    # previous output for t-1, so that in the return_sequence=False case, user\n+    # can quickly get the final effect output instead just 0s at the last\n+    # timestep.  In order to mimic the default keras behavior, we copy the final\n+    # h state as the last_output, since it is numerically same as the output.\n+    if sequence_lengths is not None:\n+        last_output = state\n+\n+    # Match CPU return format\n+    if not return_sequences:\n+        outputs = tf.expand_dims(last_output, axis=0 if time_major else 1)\n+\n+    return (\n+        last_output,\n+        outputs,\n+        state,\n+    )\n+\n+\n+def lstm(\n+    inputs,\n+    initial_state_h,\n+    initial_state_c,\n+    mask,\n+    kernel,\n+    recurrent_kernel,\n+    bias,\n+    activation,\n+    recurrent_activation,\n+    return_sequences=False,\n+    go_backwards=False,\n+    unroll=False,\n+    time_major=False,\n+):\n+    args_supported = _do_lstm_arguments_support_cudnn(\n+        activation=activation,\n+        recurrent_activation=recurrent_activation,\n+        unroll=unroll,\n+        bias=bias,\n+    )\n+    inputs_supported = _do_rnn_inputs_support_cudnn(mask, time_major)\n+    if not args_supported or not inputs_supported:\n+        raise NotImplementedError\n+\n+    from keras_core.backend.tensorflow import Variable\n+\n+    if isinstance(kernel, Variable):\n+        kernel = kernel.value\n+    if isinstance(recurrent_kernel, Variable):\n+        recurrent_kernel = recurrent_kernel.value\n+    if isinstance(bias, Variable):\n+        bias = bias.value\n+\n+    try:\n+        return _cudnn_lstm(\n+            inputs,\n+            initial_state_h,\n+            initial_state_c,\n+            kernel,\n+            recurrent_kernel,\n+            bias,\n+            mask,\n+            time_major,\n+            go_backwards,\n+            return_sequences,\n+        )\n+    except tf.errors.InvalidArgumentError:\n+        # cuDNN op not found.\n+        raise NotImplementedError\n+    except tf.errors.NotFoundError:\n+        # alternative error: device not found for op\n+        raise NotImplementedError\n+\n+\n+def _cudnn_lstm(\n+    inputs,\n+    initial_state_h,\n+    initial_state_c,\n+    kernel,\n+    recurrent_kernel,\n+    bias,\n+    mask,\n+    time_major,\n+    go_backwards,\n+    return_sequences,\n+):\n+    if mask is not None:\n+        sequence_lengths = _compute_sequence_length_from_mask(mask, time_major)\n+    else:\n+        sequence_lengths = None\n+\n+    if not time_major and sequence_lengths is None:\n+        inputs = tf.transpose(inputs, perm=(1, 0, 2))\n+        seq_axis, batch_axis = (0, 1)\n+    else:\n+        seq_axis, batch_axis = (0, 1) if time_major else (1, 0)\n+    # For init_h and init_c, cuDNN expects one more dim of num_layers before or\n+    # after batch dim for time major or batch major inputs respectively\n+    init_h = tf.expand_dims(initial_state_h, axis=seq_axis)\n+    init_c = tf.expand_dims(initial_state_c, axis=seq_axis)\n+\n+    weights = tf.split(kernel, 4, axis=1)\n+    weights += tf.split(recurrent_kernel, 4, axis=1)\n+    # cuDNN has an extra set of bias for inputs, we disable them (setting to 0),\n+    # so that mathematically it is same as the canonical LSTM implementation.\n+    full_bias = tf.concat((tf.zeros_like(bias), bias), 0)\n+\n+    if tf.sysconfig.get_build_info()[\"is_rocm_build\"]:\n+        # ROCm MIOpen's weight sequence for LSTM is different from both\n+        # canonical and Cudnn format\n+        # MIOpen: [i, f, o, c] Cudnn/Canonical: [i, f, c, o]\n+        # i is input gate weights.\n+        # f is forget gate weights.\n+        # o is output gate weights.\n+        # c is cell gate weights.\n+        weights = [weights[x] for x in (0, 1, 3, 2, 4, 5, 7, 6)]\n+        # full_bias is a tensor of shape (8*n,)\n+        full_bias = tf.split(full_bias, 8, axis=0)\n+        full_bias = [full_bias[x] for x in (0, 1, 3, 2, 4, 5, 7, 6)]\n+\n+    params = _standardize_cudnn_weights(\n+        weights=weights,\n+        biases=tf.split(full_bias, 8),\n+        shape=tf.constant([-1]),\n+        transpose_weights=True,\n+    )\n+\n+    if sequence_lengths is not None:\n+        if go_backwards:\n+            # Three reversals are required. E.g.,\n+            # normal input = [1, 2, 3, 0, 0]  # where 0 need to be masked\n+            # reversed_input_to_cudnn = [3, 2, 1, 0, 0]\n+            # output_from_cudnn = [6, 5, 4, 0, 0]\n+            # expected_output = [0, 0, 6, 5 ,4]\n+            inputs = tf.reverse_sequence(\n+                inputs,\n+                sequence_lengths,\n+                seq_axis=seq_axis,\n+                batch_axis=batch_axis,\n+            )\n+        outputs, h, c, _, _ = tf.raw_ops.CudnnRNNV3(\n+            input=inputs,\n+            input_h=init_h,\n+            input_c=init_c,\n+            params=params,\n+            is_training=True,\n+            rnn_mode=\"lstm\",\n+            sequence_lengths=sequence_lengths,\n+            time_major=time_major,\n+        )\n+        if go_backwards:\n+            outputs = tf.reverse_sequence(\n+                outputs,\n+                sequence_lengths,\n+                seq_axis=seq_axis,\n+                batch_axis=batch_axis,\n+            )\n+            outputs = tf.reverse(outputs, axis=[seq_axis])\n+    else:\n+        # # Fill the array with shape [batch] with value of max timesteps.\n+        # sequence_length = array_ops.fill([array_ops.shape(inputs)[1]],\n+        #                                  array_ops.shape(inputs)[0])\n+        if go_backwards:\n+            # Reverse axis 0 since the input is already convert to time major.\n+            inputs = tf.reverse(inputs, axis=[0])\n+        outputs, h, c, _ = tf.raw_ops.CudnnRNN(\n+            input=inputs,\n+            input_h=init_h,\n+            input_c=init_c,\n+            params=params,\n+            is_training=True,\n+            rnn_mode=\"lstm\",\n+        )\n+\n+    last_output = outputs[-1]\n+    if not time_major and sequence_lengths is None and return_sequences:\n+        outputs = tf.transpose(outputs, perm=[1, 0, 2])\n+    h = tf.squeeze(h, axis=seq_axis)\n+    c = tf.squeeze(c, axis=seq_axis)\n+\n+    # In the case of variable length input, the cudnn kernel will fill zeros for\n+    # the output, whereas the default keras behavior is to bring over the\n+    # previous output for t-1, so that in the return_sequence=False case, user\n+    # can quickly get the final effect output instead just 0s at the last\n+    # timestep.  In order to mimic the default keras behavior, we copy the final\n+    # h state as the last_output, since it is numerically same as the output.\n+    if sequence_lengths is not None:\n+        last_output = h\n+\n+    # Match CPU return format\n+    if not return_sequences:\n+        outputs = tf.expand_dims(last_output, axis=0 if time_major else 1)\n+\n+    return (last_output, outputs, [h, c])\n\n@@ -114,12 +114,15 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             )\n             return outputs\n \n+        def train_function(iterator):\n+            \"\"\"Runs a training execution with multiple steps.\"\"\"\n+            for _ in tf.range(self.steps_per_execution):\n+                outputs = one_step_on_iterator(iterator)\n+            return outputs\n+\n         if not self.run_eagerly:\n-            train_function = tf.function(\n-                one_step_on_iterator, reduce_retracing=True\n-            )\n-        else:\n-            train_function = one_step_on_iterator\n+            train_function = tf.function(train_function, reduce_retracing=True)\n+\n         self.train_function = train_function\n \n     def make_test_function(self, force=False):\n@@ -244,6 +247,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             shuffle=shuffle,\n             class_weight=class_weight,\n             distribute_strategy=self.distribute_strategy,\n+            steps_per_execution=self.steps_per_execution,\n         )\n \n         # Container that configures and calls callbacks.\n@@ -445,7 +449,9 @@ class TFEpochIterator(EpochIterator):\n                         self.data_adapter.get_tf_dataset()\n                     )\n                 )\n-            for step in range(self.steps_per_epoch):\n+            for step in range(\n+                0, self.steps_per_epoch, self.steps_per_execution\n+            ):\n                 yield step, self._current_iterator\n         else:\n             iterator = iter(\n@@ -454,12 +460,14 @@ class TFEpochIterator(EpochIterator):\n                 )\n             )\n             if self.num_batches:\n-                for step in range(self.num_batches):\n+                for step in range(\n+                    0, self.num_batches, self.steps_per_execution\n+                ):\n                     yield step, iterator\n             else:\n                 step = -1\n                 while True:\n-                    step += 1\n+                    step += self.steps_per_execution\n                     self._steps_seen = step + 1\n                     yield step, iterator\n         self.data_adapter.on_epoch_end()\n\n@@ -67,6 +67,7 @@ from keras_core.layers.pooling.global_max_pooling3d import GlobalMaxPooling3D\n from keras_core.layers.pooling.max_pooling1d import MaxPooling1D\n from keras_core.layers.pooling.max_pooling2d import MaxPooling2D\n from keras_core.layers.pooling.max_pooling3d import MaxPooling3D\n+from keras_core.layers.preprocessing.category_encoding import CategoryEncoding\n from keras_core.layers.preprocessing.center_crop import CenterCrop\n from keras_core.layers.preprocessing.discretization import Discretization\n from keras_core.layers.preprocessing.hashing import Hashing\n@@ -94,11 +95,14 @@ from keras_core.layers.regularization.spatial_dropout import SpatialDropout2D\n from keras_core.layers.regularization.spatial_dropout import SpatialDropout3D\n from keras_core.layers.reshaping.cropping1d import Cropping1D\n from keras_core.layers.reshaping.cropping2d import Cropping2D\n+from keras_core.layers.reshaping.cropping3d import Cropping3D\n from keras_core.layers.reshaping.flatten import Flatten\n from keras_core.layers.reshaping.permute import Permute\n from keras_core.layers.reshaping.repeat_vector import RepeatVector\n from keras_core.layers.reshaping.reshape import Reshape\n from keras_core.layers.reshaping.up_sampling1d import UpSampling1D\n+from keras_core.layers.rnn.gru import GRU\n+from keras_core.layers.rnn.lstm import LSTM\n from keras_core.layers.rnn.rnn import RNN\n from keras_core.layers.rnn.simple_rnn import SimpleRNN\n from keras_core.layers.rnn.stacked_rnn_cells import StackedRNNCells\n\n@@ -9,16 +9,17 @@ from keras_core.backend import standardize_data_format\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n from keras_core.operations.operation_utils import compute_conv_output_shape\n+from keras_core.utils.argument_validation import normalize_tuple\n \n \n class BaseConv(Layer):\n     \"\"\"Abstract N-D convolution layer (private, used as implementation base).\n \n-    This layer creates a convolution kernel that is convolved\n-    (actually cross-correlated) with the layer input to produce a tensor of\n-    outputs. If `use_bias` is True (and a `bias_initializer` is provided),\n-    a bias vector is created and added to the outputs. Finally, if\n-    `activation` is not `None`, it is applied to the outputs as well.\n+    This layer creates a convolution kernel that is convolved (actually\n+    cross-correlated) with the layer input to produce a tensor of outputs. If\n+    `use_bias` is True (and a `bias_initializer` is provided), a bias vector is\n+    created and added to the outputs. Finally, if `activation` is not `None`, it\n+    is applied to the outputs as well.\n \n     Note: layer attributes cannot be modified after the layer has been called\n     once (except the `trainable` attribute).\n@@ -27,12 +28,12 @@ class BaseConv(Layer):\n         rank: int, the rank of the convolution, e.g. 2 for 2D convolution.\n         filters: int, the dimension of the output space (the number of filters\n             in the convolution).\n-        kernel_size: int or tuple/list of N integers (N=`rank`), specifying the\n-            size of the convolution window.\n-        strides: int or tuple/list of N integers, specifying the stride length\n-            of the convolution. If only one int is specified, the same stride\n-            size will be used for all dimensions. `stride value != 1` is\n-            incompatible with `dilation_rate != 1`.\n+        kernel_size: int or tuple/list of `rank` integers, specifying the size\n+            of the convolution window.\n+        strides: int or tuple/list of `rank` integers, specifying the stride\n+            length of the convolution. If only one int is specified, the same\n+            stride size will be used for all dimensions. `strides > 1` is\n+            incompatible with `dilation_rate > 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n@@ -44,9 +45,9 @@ class BaseConv(Layer):\n             `(batch, features, steps)`. It defaults to the `image_data_format`\n             value found in your Keras config file at `~/.keras/keras.json`.\n             If you never set it, then it will be `\"channels_last\"`.\n-        dilation_rate: int or tuple/list of N integers, specifying the dilation\n-            rate to use for dilated convolution. If only one int is specified,\n-            the same dilation rate will be used for all dimensions.\n+        dilation_rate: int or tuple/list of `rank` integers, specifying the\n+            dilation rate to use for dilated convolution. If only one int is\n+            specified, the same dilation rate will be used for all dimensions.\n         groups: A positive int specifying the number of groups in which the\n             input is split along the channel axis. Each group is convolved\n             separately with `filters // groups` filters. The output is the\n@@ -97,25 +98,17 @@ class BaseConv(Layer):\n         super().__init__(\n             trainable=trainable,\n             name=name,\n-            activity_regularizer=regularizers.get(activity_regularizer),\n+            activity_regularizer=activity_regularizer,\n             **kwargs,\n         )\n         self.rank = rank\n         self.filters = filters\n         self.groups = groups or 1\n-\n-        if isinstance(kernel_size, int):\n-            kernel_size = (kernel_size,) * self.rank\n-        self.kernel_size = kernel_size\n-\n-        if isinstance(strides, int):\n-            strides = (strides,) * self.rank\n-        self.strides = strides\n-\n-        if isinstance(dilation_rate, int):\n-            dilation_rate = (dilation_rate,) * self.rank\n-        self.dilation_rate = dilation_rate\n-\n+        self.kernel_size = normalize_tuple(kernel_size, rank, \"kernel_size\")\n+        self.strides = normalize_tuple(strides, rank, \"strides\")\n+        self.dilation_rate = normalize_tuple(\n+            dilation_rate, rank, \"dilation_rate\"\n+        )\n         self.padding = padding\n         self.data_format = standardize_data_format(data_format)\n         self.activation = activations.get(activation)\n@@ -144,14 +137,14 @@ class BaseConv(Layer):\n \n         if not all(self.kernel_size):\n             raise ValueError(\n-                \"The argument `kernel_size` cannot contain 0(s). Received: \"\n-                f\"{self.kernel_size}\"\n+                \"The argument `kernel_size` cannot contain 0. Received \"\n+                f\"kernel_size={self.kernel_size}.\"\n             )\n \n         if not all(self.strides):\n             raise ValueError(\n-                \"The argument `strides` cannot contains 0(s). Received: \"\n-                f\"{self.strides}\"\n+                \"The argument `strides` cannot contains 0. Received \"\n+                f\"strides={self.strides}\"\n             )\n \n         if max(self.strides) > 1 and max(self.dilation_rate) > 1:\n\n@@ -11,29 +11,29 @@ from keras_core.backend.common.backend_utils import (\n )\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n+from keras_core.utils.argument_validation import normalize_tuple\n \n \n class BaseConvTranspose(Layer):\n-    \"\"\"Abstract N-D transpose convolution layer.\n+    \"\"\"Abstract N-D transposed convolution layer.\n \n-    The need for transposed convolutions generally arises\n-    from the desire to use a transformation going in the opposite direction\n-    of a normal convolution, i.e., from something that has the shape of the\n-    output of some convolution to something that has the shape of its input\n-    while maintaining a connectivity pattern that is compatible with\n-    said convolution.\n+    The need for transposed convolutions generally arises from the desire to use\n+    a transformation going in the opposite direction of a normal convolution,\n+    i.e., from something that has the shape of the output of some convolution to\n+    something that has the shape of its input while maintaining a connectivity\n+    pattern that is compatible with said convolution.\n \n     Args:\n         rank: int, the rank of the transposed convolution, e.g. 2 for 2D\n             transposed convolution.\n         filters: int, the dimension of the output space (the number of filters\n             in the transposed convolution).\n-        kernel_size: int or tuple/list of N integers (N=`rank`), specifying the\n-            size of the transposed convolution window.\n-        strides: int or tuple/list of N integers, specifying the stride length\n-            of the transposed convolution. If only one int is specified, the\n-            same stride size will be used for all dimensions.\n-            `stride value != 1` is incompatible with `dilation_rate != 1`.\n+        kernel_size: int or tuple/list of `rank` integers, specifying the size\n+            of the transposed convolution window.\n+        strides: int or tuple/list of `rank` integers, specifying the stride\n+            length of the transposed convolution. If only one int is specified,\n+            the same stride size will be used for all dimensions.\n+            `strides > 1` is incompatible with `dilation_rate > 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n@@ -45,9 +45,9 @@ class BaseConvTranspose(Layer):\n             `(batch, features, steps)`. It defaults to the `image_data_format`\n             value found in your Keras config file at `~/.keras/keras.json`.\n             If you never set it, then it will be `\"channels_last\"`.\n-        dilation_rate: int or tuple/list of N integers, specifying the dilation\n-            rate to use for dilated convolution. If only one int is specified,\n-            the same dilation rate will be used for all dimensions.\n+        dilation_rate: int or tuple/list of `rank` integers, specifying the\n+            dilation rate to use for dilated convolution. If only one int is\n+            specified, the same dilation rate will be used for all dimensions.\n         activation: Activation function. If `None`, no activation is applied.\n         use_bias: bool, if `True`, bias will be added to the output.\n         kernel_initializer: Initializer for the convolution kernel. If `None`,\n@@ -97,19 +97,11 @@ class BaseConvTranspose(Layer):\n         )\n         self.rank = rank\n         self.filters = filters\n-\n-        if isinstance(kernel_size, int):\n-            kernel_size = (kernel_size,) * self.rank\n-        self.kernel_size = kernel_size\n-\n-        if isinstance(strides, int):\n-            strides = (strides,) * self.rank\n-        self.strides = strides\n-\n-        if isinstance(dilation_rate, int):\n-            dilation_rate = (dilation_rate,) * self.rank\n-        self.dilation_rate = dilation_rate\n-\n+        self.kernel_size = normalize_tuple(kernel_size, rank, \"kernel_size\")\n+        self.strides = normalize_tuple(strides, rank, \"strides\")\n+        self.dilation_rate = normalize_tuple(\n+            dilation_rate, rank, \"dilation_rate\"\n+        )\n         self.padding = padding\n         self.data_format = standardize_data_format(data_format)\n         self.activation = activations.get(activation)\n@@ -131,14 +123,14 @@ class BaseConvTranspose(Layer):\n \n         if not all(self.kernel_size):\n             raise ValueError(\n-                \"The argument `kernel_size` cannot contain 0. Received: \"\n-                f\"{self.kernel_size}\"\n+                \"The argument `kernel_size` cannot contain 0. Received \"\n+                f\"kernel_size={self.kernel_size}.\"\n             )\n \n         if not all(self.strides):\n             raise ValueError(\n-                \"The argument `strides` cannot contains 0. Received: \"\n-                f\"{self.strides}\"\n+                \"The argument `strides` cannot contains 0. Received \"\n+                f\"strides={self.strides}.\"\n             )\n \n         if max(self.strides) > 1 and max(self.dilation_rate) > 1:\n\n@@ -9,6 +9,7 @@ from keras_core.backend import standardize_data_format\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n from keras_core.operations.operation_utils import compute_conv_output_shape\n+from keras_core.utils.argument_validation import normalize_tuple\n \n \n class BaseDepthwiseConv(Layer):\n@@ -39,12 +40,12 @@ class BaseDepthwiseConv(Layer):\n         depth_multiplier: The number of depthwise convolution output channels\n             for each input channel. The total number of depthwise convolution\n             output channels will be equal to `input_channel * depth_multiplier`.\n-        kernel_size: int or tuple/list of N integers (N=`rank`), specifying the\n-            size of the depthwise convolution window.\n-        strides: int or tuple/list of N integers, specifying the stride length\n-            of the depthwise convolution. If only one int is specified, the same\n-            stride size will be used for all dimensions. `stride value != 1` is\n-            incompatible with `dilation_rate != 1`.\n+        kernel_size: int or tuple/list of `rank` integers, specifying the size\n+            of the depthwise convolution window.\n+        strides: int or tuple/list of `rank` integers, specifying the stride\n+            length of the depthwise convolution. If only one int is specified,\n+            the same stride size will be used for all dimensions.\n+            `strides > 1` is incompatible with `dilation_rate > 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n@@ -56,9 +57,9 @@ class BaseDepthwiseConv(Layer):\n             `(batch, features, steps)`. It defaults to the `image_data_format`\n             value found in your Keras config file at `~/.keras/keras.json`.\n             If you never set it, then it will be `\"channels_last\"`.\n-        dilation_rate: int or tuple/list of N integers, specifying the dilation\n-            rate to use for dilated convolution. If only one int is specified,\n-            the same dilation rate will be used for all dimensions.\n+        dilation_rate: int or tuple/list of `rank` integers, specifying the\n+            dilation rate to use for dilated convolution. If only one int is\n+            specified, the same dilation rate will be used for all dimensions.\n         activation: Activation function. If `None`, no activation is applied.\n         use_bias: bool, if `True`, bias will be added to the output.\n         kernel_initializer: Initializer for the convolution kernel. If `None`,\n@@ -108,19 +109,11 @@ class BaseDepthwiseConv(Layer):\n         )\n         self.rank = rank\n         self.depth_multiplier = depth_multiplier\n-\n-        if isinstance(kernel_size, int):\n-            kernel_size = (kernel_size,) * self.rank\n-        self.kernel_size = kernel_size\n-\n-        if isinstance(strides, int):\n-            strides = (strides,) * self.rank\n-        self.strides = strides\n-\n-        if isinstance(dilation_rate, int):\n-            dilation_rate = (dilation_rate,) * self.rank\n-        self.dilation_rate = dilation_rate\n-\n+        self.kernel_size = normalize_tuple(kernel_size, rank, \"kernel_size\")\n+        self.strides = normalize_tuple(strides, rank, \"strides\")\n+        self.dilation_rate = normalize_tuple(\n+            dilation_rate, rank, \"dilation_rate\"\n+        )\n         self.padding = padding\n         self.data_format = standardize_data_format(data_format)\n         self.activation = activations.get(activation)\n@@ -143,14 +136,14 @@ class BaseDepthwiseConv(Layer):\n \n         if not all(self.kernel_size):\n             raise ValueError(\n-                \"The argument `kernel_size` cannot contain 0(s). Received: \"\n-                f\"{self.kernel_size}\"\n+                \"The argument `kernel_size` cannot contain 0. Received \"\n+                f\"kernel_size={self.kernel_size}.\"\n             )\n \n         if not all(self.strides):\n             raise ValueError(\n-                \"The argument `strides` cannot contains 0(s). Received: \"\n-                f\"{self.strides}\"\n+                \"The argument `strides` cannot contains 0. Received \"\n+                f\"strides={self.strides}\"\n             )\n \n         if max(self.strides) > 1 and max(self.dilation_rate) > 1:\n\n@@ -10,6 +10,7 @@ from keras_core.backend import standardize_data_format\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n from keras_core.operations.operation_utils import compute_conv_output_shape\n+from keras_core.utils.argument_validation import normalize_tuple\n \n \n class BaseSeparableConv(Layer):\n@@ -109,19 +110,11 @@ class BaseSeparableConv(Layer):\n         self.rank = rank\n         self.depth_multiplier = depth_multiplier\n         self.filters = filters\n-\n-        if isinstance(kernel_size, int):\n-            kernel_size = (kernel_size,) * self.rank\n-        self.kernel_size = kernel_size\n-\n-        if isinstance(strides, int):\n-            strides = (strides,) * self.rank\n-        self.strides = strides\n-\n-        if isinstance(dilation_rate, int):\n-            dilation_rate = (dilation_rate,) * self.rank\n-        self.dilation_rate = dilation_rate\n-\n+        self.kernel_size = normalize_tuple(kernel_size, rank, \"kernel_size\")\n+        self.strides = normalize_tuple(strides, rank, \"strides\")\n+        self.dilation_rate = normalize_tuple(\n+            dilation_rate, rank, \"dilation_rate\"\n+        )\n         self.padding = padding\n         self.data_format = standardize_data_format(data_format)\n         self.activation = activations.get(activation)\n\n@@ -21,8 +21,8 @@ class Conv1D(BaseConv):\n         kernel_size: int or tuple/list of 1 integer, specifying the size of the\n             convolution window.\n         strides: int or tuple/list of 1 integer, specifying the stride length\n-            of the convolution. `stride value != 1` is incompatible with\n-            `dilation_rate != 1`.\n+            of the convolution. `strides > 1` is incompatible with\n+            `dilation_rate > 1`.\n         padding: string, `\"valid\"`, `\"same\"` or `\"causal\"`(case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n@@ -72,9 +72,9 @@ class Conv1D(BaseConv):\n \n     Output shape:\n     - If `data_format=\"channels_last\"`:\n-        A 3D tensor with shape: `(batch_shape, new_steps, channels)`\n+        A 3D tensor with shape: `(batch_shape, new_steps, filters)`\n     - If `data_format=\"channels_first\"`:\n-        A 3D tensor with shape: `(batch_shape, channels, new_steps)`\n+        A 3D tensor with shape: `(batch_shape, filters, new_steps)`\n \n     Returns:\n         A 3D tensor representing `activation(conv1d(inputs, kernel) + bias)`.\n\n@@ -25,8 +25,8 @@ class Conv1DTranspose(BaseConvTranspose):\n         kernel_size: int or tuple/list of 1 integer, specifying the size of the\n             transposed convolution window.\n         strides: int or tuple/list of 1 integer, specifying the stride length\n-            of the transposed convolution. `stride value != 1` is incompatible\n-            with `dilation_rate != 1`.\n+            of the transposed convolution. `strides > 1` is incompatible with\n+            `dilation_rate > 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n@@ -40,11 +40,6 @@ class Conv1DTranspose(BaseConvTranspose):\n             If you never set it, then it will be `\"channels_last\"`.\n         dilation_rate: int or tuple/list of 1 integers, specifying the dilation\n             rate to use for dilated transposed convolution.\n-        groups: A positive int specifying the number of groups in which the\n-            input is split along the channel axis. Each group is convolved\n-            separately with `filters // groups` filters. The output is the\n-            concatenation of all the `groups` results along the channel axis.\n-            Input channels and `filters` must both be divisible by `groups`.\n         activation: Activation function. If `None`, no activation is applied.\n         use_bias: bool, if `True`, bias will be added to the output.\n         kernel_initializer: Initializer for the convolution kernel. If `None`,\n@@ -71,9 +66,9 @@ class Conv1DTranspose(BaseConvTranspose):\n \n     Output shape:\n     - If `data_format=\"channels_last\"`:\n-        A 3D tensor with shape: `(batch_shape, new_steps, channels)`\n+        A 3D tensor with shape: `(batch_shape, new_steps, filters)`\n     - If `data_format=\"channels_first\"`:\n-        A 3D tensor with shape: `(batch_shape, channels, new_steps)`\n+        A 3D tensor with shape: `(batch_shape, filters, new_steps)`\n \n     Returns:\n         A 3D tensor representing\n\n@@ -20,8 +20,8 @@ class Conv2D(BaseConv):\n         kernel_size: int or tuple/list of 2 integer, specifying the size of the\n             convolution window.\n         strides: int or tuple/list of 2 integer, specifying the stride length\n-            of the convolution. `stride value != 1` is incompatible with\n-            `dilation_rate != 1`.\n+            of the convolution. `strides > 1` is incompatible with\n+            `dilation_rate > 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n@@ -68,7 +68,7 @@ class Conv2D(BaseConv):\n \n     Output shape:\n     - If `data_format=\"channels_last\"`:\n-        A 4D tensor with shape: `(batch_size, new_height, new_width filters)`\n+        A 4D tensor with shape: `(batch_size, new_height, new_width, filters)`\n     - If `data_format=\"channels_first\"`:\n         A 4D tensor with shape: `(batch_size, filters, new_height, new_width)`\n \n\n@@ -25,8 +25,8 @@ class Conv2DTranspose(BaseConvTranspose):\n         kernel_size: int or tuple/list of 1 integer, specifying the size of the\n             transposed convolution window.\n         strides: int or tuple/list of 1 integer, specifying the stride length\n-            of the transposed convolution. `stride value != 1` is incompatible\n-            with `dilation_rate != 1`.\n+            of the transposed convolution. `strides > 1` is incompatible with\n+            `dilation_rate > 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n@@ -68,7 +68,7 @@ class Conv2DTranspose(BaseConvTranspose):\n \n     Output shape:\n     - If `data_format=\"channels_last\"`:\n-        A 4D tensor with shape: `(batch_size, new_height, new_width filters)`\n+        A 4D tensor with shape: `(batch_size, new_height, new_width, filters)`\n     - If `data_format=\"channels_first\"`:\n         A 4D tensor with shape: `(batch_size, filters, new_height, new_width)`\n \n\n@@ -20,8 +20,8 @@ class Conv3D(BaseConv):\n         kernel_size: int or tuple/list of 3 integer, specifying the size of the\n             convolution window.\n         strides: int or tuple/list of 3 integer, specifying the stride length\n-            of the convolution. `stride value != 1` is incompatible with\n-            `dilation_rate != 1`.\n+            of the convolution. `strides > 1` is incompatible with\n+            `dilation_rate > 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n@@ -72,10 +72,10 @@ class Conv3D(BaseConv):\n     - If `data_format=\"channels_last\"`:\n         5D tensor with shape:\n         `(batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3,\n-        channels)`\n+        filters)`\n     - If `data_format=\"channels_first\"`:\n         5D tensor with shape:\n-        `(batch_size, channels, new_spatial_dim1, new_spatial_dim2,\n+        `(batch_size, filters, new_spatial_dim1, new_spatial_dim2,\n         new_spatial_dim3)`\n \n     Returns:\n\n@@ -25,8 +25,8 @@ class Conv3DTranspose(BaseConvTranspose):\n         kernel_size: int or tuple/list of 1 integer, specifying the size of the\n             transposed convolution window.\n         strides: int or tuple/list of 1 integer, specifying the stride length\n-            of the transposed convolution. `stride value != 1` is incompatible\n-            with `dilation_rate != 1`.\n+            of the transposed convolution. `strides > 1` is incompatible with\n+            `dilation_rate > 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n@@ -72,10 +72,10 @@ class Conv3DTranspose(BaseConvTranspose):\n     - If `data_format=\"channels_last\"`:\n         5D tensor with shape:\n         `(batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3,\n-        channels)`\n+        filters)`\n     - If `data_format=\"channels_first\"`:\n         5D tensor with shape:\n-        `(batch_size, channels, new_spatial_dim1, new_spatial_dim2,\n+        `(batch_size, filters, new_spatial_dim1, new_spatial_dim2,\n         new_spatial_dim3)`\n \n     Returns:\n\n@@ -417,4 +417,4 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         tf_keras_layer.bias.assign(bias_weights)\n         outputs = layer(inputs)\n         expected = tf_keras_layer(inputs)\n-        self.assertAllClose(outputs, expected)\n+        self.assertAllClose(outputs, expected, atol=1e-5)\n\n@@ -34,8 +34,8 @@ class DepthwiseConv1D(BaseDepthwiseConv):\n         kernel_size: int or tuple/list of 1 integer, specifying the size of the\n             depthwise convolution window.\n         strides: int or tuple/list of 1 integer, specifying the stride length\n-            of the convolution. `stride value != 1` is incompatible\n-            with `dilation_rate != 1`.\n+            of the convolution. `strides > 1` is incompatible with\n+            `dilation_rate > 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n\n@@ -34,8 +34,8 @@ class DepthwiseConv2D(BaseDepthwiseConv):\n         kernel_size: int or tuple/list of 2 integer, specifying the size of the\n             depthwise convolution window.\n         strides: int or tuple/list of 2 integer, specifying the stride length\n-            of the depthwise convolution. `stride value != 1` is incompatible\n-            with `dilation_rate != 1`.\n+            of the depthwise convolution. `strides > 1` is incompatible with\n+            `dilation_rate > 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n\n@@ -29,8 +29,8 @@ class SeparableConv1D(BaseSeparableConv):\n             depthwise convolution window.\n         strides: int or tuple/list of 1 integers, specifying the stride length\n             of the depthwise convolution. If only one int is specified, the same\n-            stride size will be used for all dimensions. `stride value != 1` is\n-            incompatible with `dilation_rate != 1`.\n+            stride size will be used for all dimensions. `strides > 1` is\n+            incompatible with `dilation_rate > 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n\n@@ -29,8 +29,8 @@ class SeparableConv2D(BaseSeparableConv):\n             depthwise convolution window.\n         strides: int or tuple/list of 2 integers, specifying the stride length\n             of the depthwise convolution. If only one int is specified, the same\n-            stride size will be used for all dimensions. `stride value != 1` is\n-            incompatible with `dilation_rate != 1`.\n+            stride size will be used for all dimensions. `strides > 1` is\n+            incompatible with `dilation_rate > 1`.\n         padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n\n@@ -574,7 +574,6 @@ class Layer(Operation):\n                 # More than one shape: pass them by name.\n                 output_shape = self.compute_output_shape(**shapes_dict)\n \n-            print(\"output_shape\", output_shape)\n             if (\n                 isinstance(output_shape, list)\n                 and output_shape\n\n@@ -0,0 +1,197 @@\n+from keras_core import operations as ops\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.layer import Layer\n+\n+\n+@keras_core_export(\"keras_core.layers.CategoryEncoding\")\n+class CategoryEncoding(Layer):\n+    \"\"\"A preprocessing layer which encodes integer features.\n+\n+    This layer provides options for condensing data into a categorical encoding\n+    when the total number of tokens are known in advance. It accepts integer\n+    values as inputs, and it outputs a dense or sparse representation of those\n+    inputs. For integer inputs where the total number of tokens is not known,\n+    use `keras_core.layers.IntegerLookup` instead.\n+\n+    Examples:\n+\n+    **One-hot encoding data**\n+\n+    >>> layer = keras_core.layers.CategoryEncoding(\n+    ...           num_tokens=4, output_mode=\"one_hot\")\n+    >>> layer([3, 2, 0, 1])\n+    array([[0., 0., 0., 1.],\n+            [0., 0., 1., 0.],\n+            [1., 0., 0., 0.],\n+            [0., 1., 0., 0.]]>\n+\n+    **Multi-hot encoding data**\n+\n+    >>> layer = keras_core.layers.CategoryEncoding(\n+    ...           num_tokens=4, output_mode=\"multi_hot\")\n+    >>> layer([[0, 1], [0, 0], [1, 2], [3, 1]])\n+    array([[1., 1., 0., 0.],\n+            [1., 0., 0., 0.],\n+            [0., 1., 1., 0.],\n+            [0., 1., 0., 1.]]>\n+\n+    **Using weighted inputs in `\"count\"` mode**\n+\n+    >>> layer = keras_core.layers.CategoryEncoding(\n+    ...           num_tokens=4, output_mode=\"count\")\n+    >>> count_weights = np.array([[.1, .2], [.1, .1], [.2, .3], [.4, .2]])\n+    >>> layer([[0, 1], [0, 0], [1, 2], [3, 1]], count_weights=count_weights)\n+      array([[0.1, 0.2, 0. , 0. ],\n+             [0.2, 0. , 0. , 0. ],\n+             [0. , 0.2, 0.3, 0. ],\n+             [0. , 0.2, 0. , 0.4]]>\n+\n+    Args:\n+        num_tokens: The total number of tokens the layer should support. All\n+            inputs to the layer must integers in the range `0 <= value <\n+            num_tokens`, or an error will be thrown.\n+        output_mode: Specification for the output of the layer.\n+            Values can be `\"one_hot\"`, `\"multi_hot\"` or `\"count\"`,\n+            configuring the layer as follows:\n+                - `\"one_hot\"`: Encodes each individual element in the input\n+                    into an array of `num_tokens` size, containing a 1 at the\n+                    element index. If the last dimension is size 1, will encode\n+                    on that dimension. If the last dimension is not size 1,\n+                    will append a new dimension for the encoded output.\n+                - `\"multi_hot\"`: Encodes each sample in the input into a single\n+                    array of `num_tokens` size, containing a 1 for each\n+                    vocabulary term present in the sample. Treats the last\n+                    dimension as the sample dimension, if input shape is\n+                    `(..., sample_length)`, output shape will be\n+                    `(..., num_tokens)`.\n+                - `\"count\"`: Like `\"multi_hot\"`, but the int array contains a\n+                    count of the number of times the token at that index\n+                    appeared in the sample.\n+            For all output modes, currently only output up to rank 2 is\n+            supported.\n+            Defaults to `\"multi_hot\"`.\n+\n+    Call arguments:\n+        inputs: A 1D or 2D tensor of integer inputs.\n+        count_weights: A tensor in the same shape as `inputs` indicating the\n+            weight for each sample value when summing up in `count` mode.\n+            Not used in `\"multi_hot\"` or `\"one_hot\"` modes.\n+    \"\"\"\n+\n+    def __init__(self, num_tokens=None, output_mode=\"multi_hot\", **kwargs):\n+        # max_tokens is an old name for the num_tokens arg we continue to\n+        # support because of usage.\n+        if \"max_tokens\" in kwargs:\n+            num_tokens = kwargs[\"max_tokens\"]\n+            del kwargs[\"max_tokens\"]\n+\n+        super().__init__(**kwargs)\n+\n+        # Support deprecated names for output_modes.\n+        if output_mode == \"binary\":\n+            output_mode = \"multi_hot\"\n+        # 'output_mode' must be one of (\"count\", \"one_hot\", \"multi_hot\")\n+        if output_mode not in (\"count\", \"one_hot\", \"multi_hot\"):\n+            raise ValueError(f\"Unknown arg for output_mode: {output_mode}\")\n+\n+        if num_tokens is None:\n+            raise ValueError(\n+                \"num_tokens must be set to use this layer. If the \"\n+                \"number of tokens is not known beforehand, use the \"\n+                \"IntegerLookup layer instead.\"\n+            )\n+        if num_tokens < 1:\n+            raise ValueError(\n+                f\"`num_tokens` must be >= 1. Received: num_tokens={num_tokens}.\"\n+            )\n+\n+        self.num_tokens = num_tokens\n+        self.output_mode = output_mode\n+\n+    def compute_output_shape(self, input_shape):\n+        input_shape = list(input_shape)\n+        if not input_shape:\n+            return ops.shape(self.num_tokens)\n+        if self.output_mode == \"one_hot\" and input_shape[-1] != 1:\n+            return tuple(input_shape + [self.num_tokens])\n+        else:\n+            return tuple(input_shape[:-1] + [self.num_tokens])\n+\n+    def get_config(self):\n+        config = {\n+            \"num_tokens\": self.num_tokens,\n+            \"output_mode\": self.output_mode,\n+        }\n+        base_config = super().get_config()\n+        return {**base_config, **config}\n+\n+    def call(self, inputs, count_weights=None):\n+\n+        if count_weights is not None:\n+            if self.output_mode != \"count\":\n+                raise ValueError(\n+                    \"`count_weights` is not used when `output_mode` is not \"\n+                    \"`'count'`. Received `count_weights={count_weights}`.\"\n+                )\n+            count_weights = ops.cast(count_weights, self.compute_dtype)\n+\n+        depth = self.num_tokens\n+\n+        max_value = ops.amax(inputs)\n+        min_value = ops.amin(inputs)\n+        condition = ops.logical_and(\n+            ops.greater(ops.cast(depth, max_value.dtype), max_value),\n+            ops.greater_equal(min_value, ops.cast(0, min_value.dtype)),\n+        )\n+        if not condition:\n+            raise ValueError(\n+                \"Input values must be in the range 0 <= values < num_tokens\"\n+                f\" with num_tokens={depth}\"\n+            )\n+\n+        return self._encode_categorical_inputs(\n+            inputs,\n+            output_mode=self.output_mode,\n+            depth=depth,\n+            count_weights=count_weights,\n+        )\n+\n+    def _encode_categorical_inputs(\n+        self,\n+        inputs,\n+        output_mode,\n+        depth,\n+        count_weights=None,\n+    ):\n+\n+        # In all cases, we should uprank scalar input to a single sample.\n+        if len(inputs.shape) == 0:\n+            inputs = ops.expand_dims(inputs, -1)\n+        # One hot will uprank only if the final output dimension\n+        # is not already 1.\n+        if output_mode == \"one_hot\":\n+            if len(inputs.shape) > 1 and inputs.shape[-1] != 1:\n+                inputs = ops.expand_dims(inputs, -1)\n+\n+        # TODO(b/190445202): remove output rank restriction.\n+        if len(inputs.shape) > 2:\n+            raise ValueError(\n+                \"When output_mode is not `'int'`, maximum supported \"\n+                f\"output rank is 2. Received output_mode {output_mode} \"\n+                f\"and input shape {inputs.shape}, \"\n+                f\"which would result in output rank {len(inputs.shape)}.\"\n+            )\n+\n+        binary_output = output_mode in (\"multi_hot\", \"one_hot\")\n+        inputs = ops.cast(inputs, \"int32\")\n+\n+        if binary_output:\n+            bincounts = ops.one_hot(inputs, num_classes=depth)\n+            if output_mode == \"multi_hot\":\n+                bincounts = ops.sum(bincounts, axis=0)\n+        else:\n+            bincounts = ops.bincount(\n+                inputs, minlength=depth, weights=count_weights\n+            )\n+\n+        return bincounts\n\n@@ -0,0 +1,53 @@\n+import numpy as np\n+\n+from keras_core import layers\n+from keras_core import testing\n+\n+\n+class CategoryEncodingTest(testing.TestCase):\n+    def test_count_output(self):\n+        input_array = np.array([[1, 2, 3, 1], [0, 3, 1, 0]])\n+        expected_output = np.array([[0, 2, 1, 1, 0, 0], [2, 1, 0, 1, 0, 0]])\n+\n+        num_tokens = 6\n+        expected_output_shape = (2, num_tokens)\n+\n+        layer = layers.CategoryEncoding(num_tokens=6, output_mode=\"count\")\n+        int_data = layer(input_array)\n+        self.assertEqual(expected_output_shape, int_data.shape)\n+        self.assertAllClose(int_data, expected_output)\n+\n+    def test_multi_hot(self):\n+        input_data = np.array([3, 2, 0, 1])\n+        expected_output = np.array([1, 1, 1, 1, 0, 0])\n+        num_tokens = 6\n+        expected_output_shape = (num_tokens,)\n+\n+        # Test call on layer directly.\n+        layer = layers.CategoryEncoding(\n+            num_tokens=num_tokens, output_mode=\"multi_hot\"\n+        )\n+        output_data = layer(input_data)\n+        self.assertAllClose(expected_output, output_data)\n+        self.assertEqual(expected_output_shape, output_data.shape)\n+\n+    def test_one_hot(self):\n+        input_data = np.array([3, 2, 0, 1])\n+        expected_output = np.array(\n+            [\n+                [0, 0, 0, 1],\n+                [0, 0, 1, 0],\n+                [1, 0, 0, 0],\n+                [0, 1, 0, 0],\n+            ]\n+        )\n+        num_tokens = 4\n+        expected_output_shape = (num_tokens, num_tokens)\n+\n+        # Test call on layer directly.\n+        layer = layers.CategoryEncoding(\n+            num_tokens=num_tokens, output_mode=\"one_hot\"\n+        )\n+        output_data = layer(input_data)\n+        self.assertAllClose(expected_output, output_data)\n+        self.assertEqual(expected_output_shape, output_data.shape)\n\n@@ -0,0 +1,282 @@\n+from keras_core import backend\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.input_spec import InputSpec\n+from keras_core.layers.layer import Layer\n+\n+\n+@keras_core_export(\"keras_core.layers.Cropping3D\")\n+class Cropping3D(Layer):\n+    \"\"\"Cropping layer for 3D data (e.g. spatial or spatio-temporal).\n+\n+    Examples:\n+\n+    >>> input_shape = (2, 28, 28, 10, 3)\n+    >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n+    >>> y = keras_core.layers.Cropping3D(cropping=(2, 4, 2))(x)\n+    >>> y.shape\n+    (2, 24, 20, 6, 3)\n+\n+    Args:\n+        cropping: Int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n+            - If int: the same symmetric cropping is applied to depth, height,\n+              and width.\n+            - If tuple of 3 ints: interpreted as three different symmetric\n+              cropping values for depth, height, and width:\n+              `(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)`.\n+            - If tuple of 3 tuples of 2 ints: interpreted as\n+              `((left_dim1_crop, right_dim1_crop), (left_dim2_crop,\n+              right_dim2_crop), (left_dim3_crop, right_dim3_crop))`\n+        data_format: A string, one of `\"channels_last\"` (default) or\n+            `\"channels_first\"`. The ordering of the dimensions in the inputs.\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n+            while `\"channels_first\"` corresponds to inputs with shape\n+            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n+            When unspecified, uses `image_data_format` value found in your Keras\n+            config file at `~/.keras/keras.json` (if exists). Defaults to\n+            `\"channels_last\"`.\n+\n+    Input shape:\n+        5D tensor with shape:\n+        - If `data_format` is `\"channels_last\"`:\n+          `(batch_size, first_axis_to_crop, second_axis_to_crop,\n+          third_axis_to_crop, channels)`\n+        - If `data_format` is `\"channels_first\"`:\n+          `(batch_size, channels, first_axis_to_crop, second_axis_to_crop,\n+          third_axis_to_crop)`\n+\n+    Output shape:\n+        5D tensor with shape:\n+        - If `data_format` is `\"channels_last\"`:\n+          `(batch_size, first_cropped_axis, second_cropped_axis,\n+          third_cropped_axis, channels)`\n+        - If `data_format` is `\"channels_first\"`:\n+          `(batch_size, channels, first_cropped_axis, second_cropped_axis,\n+          third_cropped_axis)`\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        cropping=((1, 1), (1, 1), (1, 1)),\n+        data_format=None,\n+        name=None,\n+        dtype=None,\n+    ):\n+        super().__init__(name=name, dtype=dtype)\n+        self.data_format = backend.standardize_data_format(data_format)\n+        if isinstance(cropping, int):\n+            self.cropping = (\n+                (cropping, cropping),\n+                (cropping, cropping),\n+                (cropping, cropping),\n+            )\n+        elif hasattr(cropping, \"__len__\"):\n+            if len(cropping) != 3:\n+                raise ValueError(\n+                    f\"`cropping` should have 3 elements. Received: {cropping}.\"\n+                )\n+            dim1_cropping = cropping[0]\n+            if isinstance(dim1_cropping, int):\n+                dim1_cropping = (dim1_cropping, dim1_cropping)\n+            dim2_cropping = cropping[1]\n+            if isinstance(dim2_cropping, int):\n+                dim2_cropping = (dim2_cropping, dim2_cropping)\n+            dim3_cropping = cropping[2]\n+            if isinstance(dim3_cropping, int):\n+                dim3_cropping = (dim3_cropping, dim3_cropping)\n+            self.cropping = (dim1_cropping, dim2_cropping, dim3_cropping)\n+        else:\n+            raise ValueError(\n+                \"`cropping` should be either an int, a tuple of 3 ints \"\n+                \"(symmetric_dim1_crop, symmetric_dim2_crop, \"\n+                \"symmetric_dim3_crop), \"\n+                \"or a tuple of 3 tuples of 2 ints \"\n+                \"((left_dim1_crop, right_dim1_crop),\"\n+                \" (left_dim2_crop, right_dim2_crop),\"\n+                \" (left_dim3_crop, right_dim2_crop)). \"\n+                f\"Received: {cropping}.\"\n+            )\n+        self.input_spec = InputSpec(ndim=5)\n+\n+    def compute_output_shape(self, input_shape):\n+        if self.data_format == \"channels_first\":\n+            spatial_dims = list(input_shape[2:5])\n+        else:\n+            spatial_dims = list(input_shape[1:4])\n+\n+        for index in range(0, 3):\n+            if spatial_dims[index] is None:\n+                continue\n+            spatial_dims[index] -= sum(self.cropping[index])\n+            if spatial_dims[index] <= 0:\n+                raise ValueError(\n+                    \"Values in `cropping` argument should be greater than the \"\n+                    \"corresponding spatial dimension of the input. Received: \"\n+                    f\"input_shape={input_shape}, cropping={self.cropping}\"\n+                )\n+\n+        if self.data_format == \"channels_first\":\n+            return (input_shape[0], input_shape[1], *spatial_dims)\n+        else:\n+            return (input_shape[0], *spatial_dims, input_shape[4])\n+\n+    def call(self, inputs):\n+        if self.data_format == \"channels_first\":\n+            spatial_dims = list(inputs.shape[2:5])\n+        else:\n+            spatial_dims = list(inputs.shape[1:4])\n+\n+        for index in range(0, 3):\n+            if spatial_dims[index] is None:\n+                continue\n+            spatial_dims[index] -= sum(self.cropping[index])\n+            if spatial_dims[index] <= 0:\n+                raise ValueError(\n+                    \"Values in `cropping` argument should be greater than the \"\n+                    \"corresponding spatial dimension of the input. Received: \"\n+                    f\"inputs.shape={inputs.shape}, cropping={self.cropping}\"\n+                )\n+\n+        if self.data_format == \"channels_first\":\n+            if (\n+                self.cropping[0][1]\n+                == self.cropping[1][1]\n+                == self.cropping[2][1]\n+                == 0\n+            ):\n+                return inputs[\n+                    :,\n+                    :,\n+                    self.cropping[0][0] :,\n+                    self.cropping[1][0] :,\n+                    self.cropping[2][0] :,\n+                ]\n+            elif self.cropping[0][1] == self.cropping[1][1] == 0:\n+                return inputs[\n+                    :,\n+                    :,\n+                    self.cropping[0][0] :,\n+                    self.cropping[1][0] :,\n+                    self.cropping[2][0] : -self.cropping[2][1],\n+                ]\n+            elif self.cropping[1][1] == self.cropping[2][1] == 0:\n+                return inputs[\n+                    :,\n+                    :,\n+                    self.cropping[0][0] : -self.cropping[0][1],\n+                    self.cropping[1][0] :,\n+                    self.cropping[2][0] :,\n+                ]\n+            elif self.cropping[0][1] == self.cropping[2][1] == 0:\n+                return inputs[\n+                    :,\n+                    :,\n+                    self.cropping[0][0] :,\n+                    self.cropping[1][0] : -self.cropping[1][1],\n+                    self.cropping[2][0] :,\n+                ]\n+            elif self.cropping[0][1] == 0:\n+                return inputs[\n+                    :,\n+                    :,\n+                    self.cropping[0][0] :,\n+                    self.cropping[1][0] : -self.cropping[1][1],\n+                    self.cropping[2][0] : -self.cropping[2][1],\n+                ]\n+            elif self.cropping[1][1] == 0:\n+                return inputs[\n+                    :,\n+                    :,\n+                    self.cropping[0][0] : -self.cropping[0][1],\n+                    self.cropping[1][0] :,\n+                    self.cropping[2][0] : -self.cropping[2][1],\n+                ]\n+            elif self.cropping[2][1] == 0:\n+                return inputs[\n+                    :,\n+                    :,\n+                    self.cropping[0][0] : -self.cropping[0][1],\n+                    self.cropping[1][0] : -self.cropping[1][1],\n+                    self.cropping[2][0] :,\n+                ]\n+            return inputs[\n+                :,\n+                :,\n+                self.cropping[0][0] : -self.cropping[0][1],\n+                self.cropping[1][0] : -self.cropping[1][1],\n+                self.cropping[2][0] : -self.cropping[2][1],\n+            ]\n+        else:\n+            if (\n+                self.cropping[0][1]\n+                == self.cropping[1][1]\n+                == self.cropping[2][1]\n+                == 0\n+            ):\n+                return inputs[\n+                    :,\n+                    self.cropping[0][0] :,\n+                    self.cropping[1][0] :,\n+                    self.cropping[2][0] :,\n+                    :,\n+                ]\n+            elif self.cropping[0][1] == self.cropping[1][1] == 0:\n+                return inputs[\n+                    :,\n+                    self.cropping[0][0] :,\n+                    self.cropping[1][0] :,\n+                    self.cropping[2][0] : -self.cropping[2][1],\n+                    :,\n+                ]\n+            elif self.cropping[1][1] == self.cropping[2][1] == 0:\n+                return inputs[\n+                    :,\n+                    self.cropping[0][0] : -self.cropping[0][1],\n+                    self.cropping[1][0] :,\n+                    self.cropping[2][0] :,\n+                    :,\n+                ]\n+            elif self.cropping[0][1] == self.cropping[2][1] == 0:\n+                return inputs[\n+                    :,\n+                    self.cropping[0][0] :,\n+                    self.cropping[1][0] : -self.cropping[1][1],\n+                    self.cropping[2][0] :,\n+                    :,\n+                ]\n+            elif self.cropping[0][1] == 0:\n+                return inputs[\n+                    :,\n+                    self.cropping[0][0] :,\n+                    self.cropping[1][0] : -self.cropping[1][1],\n+                    self.cropping[2][0] : -self.cropping[2][1],\n+                    :,\n+                ]\n+            elif self.cropping[1][1] == 0:\n+                return inputs[\n+                    :,\n+                    self.cropping[0][0] : -self.cropping[0][1],\n+                    self.cropping[1][0] :,\n+                    self.cropping[2][0] : -self.cropping[2][1],\n+                    :,\n+                ]\n+            elif self.cropping[2][1] == 0:\n+                return inputs[\n+                    :,\n+                    self.cropping[0][0] : -self.cropping[0][1],\n+                    self.cropping[1][0] : -self.cropping[1][1],\n+                    self.cropping[2][0] :,\n+                    :,\n+                ]\n+            return inputs[\n+                :,\n+                self.cropping[0][0] : -self.cropping[0][1],\n+                self.cropping[1][0] : -self.cropping[1][1],\n+                self.cropping[2][0] : -self.cropping[2][1],\n+                :,\n+            ]\n+\n+    def get_config(self):\n+        config = {\"cropping\": self.cropping, \"data_format\": self.data_format}\n+        base_config = super().get_config()\n+        return {**base_config, **config}\n\n@@ -0,0 +1,161 @@\n+import numpy as np\n+import pytest\n+from absl.testing import parameterized\n+\n+from keras_core import backend\n+from keras_core import layers\n+from keras_core import operations as ops\n+from keras_core import testing\n+\n+\n+class CroppingTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.product(\n+        (\n+            {\"dim1_cropping\": (1, 2), \"dim1_expected\": (1, 5)},  # both\n+            {\"dim1_cropping\": (0, 2), \"dim1_expected\": (0, 5)},  # left only\n+            {\"dim1_cropping\": (1, 0), \"dim1_expected\": (1, 7)},  # right only\n+        ),\n+        (\n+            {\"dim2_cropping\": (3, 4), \"dim2_expected\": (3, 5)},  # both\n+            {\"dim2_cropping\": (0, 4), \"dim2_expected\": (0, 5)},  # left only\n+            {\"dim2_cropping\": (3, 0), \"dim2_expected\": (3, 9)},  # right only\n+        ),\n+        (\n+            {\"dim3_cropping\": (5, 6), \"dim3_expected\": (5, 7)},  # both\n+            {\"dim3_cropping\": (0, 6), \"dim3_expected\": (0, 7)},  # left only\n+            {\"dim3_cropping\": (5, 0), \"dim3_expected\": (5, 13)},  # right only\n+        ),\n+        (\n+            {\"data_format\": \"channels_first\"},\n+            {\"data_format\": \"channels_last\"},\n+        ),\n+    )\n+    def test_cropping_3d(\n+        self,\n+        dim1_cropping,\n+        dim2_cropping,\n+        dim3_cropping,\n+        data_format,\n+        dim1_expected,\n+        dim2_expected,\n+        dim3_expected,\n+    ):\n+        if data_format == \"channels_first\":\n+            inputs = np.random.rand(3, 5, 7, 9, 13)\n+            expected_output = ops.convert_to_tensor(\n+                inputs[\n+                    :,\n+                    :,\n+                    dim1_expected[0] : dim1_expected[1],\n+                    dim2_expected[0] : dim2_expected[1],\n+                    dim3_expected[0] : dim3_expected[1],\n+                ]\n+            )\n+        else:\n+            inputs = np.random.rand(3, 7, 9, 13, 5)\n+            expected_output = ops.convert_to_tensor(\n+                inputs[\n+                    :,\n+                    dim1_expected[0] : dim1_expected[1],\n+                    dim2_expected[0] : dim2_expected[1],\n+                    dim3_expected[0] : dim3_expected[1],\n+                    :,\n+                ]\n+            )\n+\n+        cropping = (dim1_cropping, dim2_cropping, dim3_cropping)\n+        self.run_layer_test(\n+            layers.Cropping3D,\n+            init_kwargs={\"cropping\": cropping, \"data_format\": data_format},\n+            input_data=inputs,\n+            expected_output=expected_output,\n+        )\n+\n+    @parameterized.product(\n+        (\n+            # same cropping values with 3 tuples\n+            {\n+                \"cropping\": ((2, 2), (2, 2), (2, 2)),\n+                \"expected\": ((2, 5), (2, 7), (2, 11)),\n+            },\n+            # same cropping values with 1 tuple\n+            {\"cropping\": (2, 2, 2), \"expected\": ((2, 5), (2, 7), (2, 11))},\n+            # same cropping values with an integer\n+            {\"cropping\": 2, \"expected\": ((2, 5), (2, 7), (2, 11))},\n+        ),\n+        (\n+            {\"data_format\": \"channels_first\"},\n+            {\"data_format\": \"channels_last\"},\n+        ),\n+    )\n+    def test_cropping_3d_with_same_cropping(\n+        self, cropping, data_format, expected\n+    ):\n+        if data_format == \"channels_first\":\n+            inputs = np.random.rand(3, 5, 7, 9, 13)\n+            expected_output = ops.convert_to_tensor(\n+                inputs[\n+                    :,\n+                    :,\n+                    expected[0][0] : expected[0][1],\n+                    expected[1][0] : expected[1][1],\n+                    expected[2][0] : expected[2][1],\n+                ]\n+            )\n+        else:\n+            inputs = np.random.rand(3, 7, 9, 13, 5)\n+            expected_output = ops.convert_to_tensor(\n+                inputs[\n+                    :,\n+                    expected[0][0] : expected[0][1],\n+                    expected[1][0] : expected[1][1],\n+                    expected[2][0] : expected[2][1],\n+                    :,\n+                ]\n+            )\n+\n+        self.run_layer_test(\n+            layers.Cropping3D,\n+            init_kwargs={\"cropping\": cropping, \"data_format\": data_format},\n+            input_data=inputs,\n+            expected_output=expected_output,\n+        )\n+\n+    @pytest.mark.skipif(\n+        not backend.DYNAMIC_SHAPES_OK,\n+        reason=\"Backend does not support dynamic shapes\",\n+    )\n+    def test_cropping_3d_with_dynamic_batch_size(self):\n+        input_layer = layers.Input(batch_shape=(None, 7, 9, 13, 5))\n+        permuted = layers.Cropping3D(((1, 2), (3, 4), (5, 6)))(input_layer)\n+        self.assertEqual(permuted.shape, (None, 4, 2, 2, 5))\n+\n+    @parameterized.product(\n+        (\n+            {\"cropping\": ((3, 6), (0, 0), (0, 0))},\n+            {\"cropping\": ((0, 0), (5, 8), (0, 0))},\n+            {\"cropping\": ((0, 0), (0, 0), (7, 6))},\n+        ),\n+        (\n+            {\"data_format\": \"channels_first\"},\n+            {\"data_format\": \"channels_last\"},\n+        ),\n+    )\n+    def test_cropping_3d_errors_if_cropping_more_than_available(\n+        self, cropping, data_format\n+    ):\n+        input_layer = layers.Input(batch_shape=(3, 7, 9, 13, 5))\n+        with self.assertRaises(ValueError):\n+            layers.Cropping3D(cropping=cropping, data_format=data_format)(\n+                input_layer\n+            )\n+\n+    def test_cropping_3d_errors_if_cropping_argument_invalid(self):\n+        with self.assertRaises(ValueError):\n+            layers.Cropping3D(cropping=(1,))\n+        with self.assertRaises(ValueError):\n+            layers.Cropping3D(cropping=(1, 2))\n+        with self.assertRaises(ValueError):\n+            layers.Cropping3D(cropping=(1, 2, 3, 4))\n+        with self.assertRaises(ValueError):\n+            layers.Cropping3D(cropping=\"1\")\n\n@@ -0,0 +1,653 @@\n+from tensorflow import nest\n+\n+from keras_core import activations\n+from keras_core import backend\n+from keras_core import constraints\n+from keras_core import initializers\n+from keras_core import operations as ops\n+from keras_core import regularizers\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.input_spec import InputSpec\n+from keras_core.layers.layer import Layer\n+from keras_core.layers.rnn.dropout_rnn_cell import DropoutRNNCell\n+from keras_core.layers.rnn.rnn import RNN\n+\n+\n+@keras_core_export(\"keras_core.layers.GRUCell\")\n+class GRUCell(Layer, DropoutRNNCell):\n+    \"\"\"Cell class for the GRU layer.\n+\n+    This class processes one step within the whole time sequence input, whereas\n+    `keras_core.layer.GRU` processes the whole sequence.\n+\n+    Args:\n+        units: Positive integer, dimensionality of the output space.\n+        activation: Activation function to use. Default: hyperbolic tangent\n+            (`tanh`). If you pass None, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        recurrent_activation: Activation function to use for the recurrent step.\n+            Default: sigmoid (`sigmoid`). If you pass `None`, no activation is\n+            applied (ie. \"linear\" activation: `a(x) = x`).\n+        use_bias: Boolean, (default `True`), whether the layer\n+            should use a bias vector.\n+        kernel_initializer: Initializer for the `kernel` weights matrix,\n+            used for the linear transformation of the inputs. Default:\n+            `\"glorot_uniform\"`.\n+        recurrent_initializer: Initializer for the `recurrent_kernel`\n+            weights matrix, used for the linear transformation\n+            of the recurrent state. Default: `\"orthogonal\"`.\n+        bias_initializer: Initializer for the bias vector. Default: `\"zeros\"`.\n+        kernel_regularizer: Regularizer function applied to the `kernel` weights\n+            matrix. Default: `None`.\n+        recurrent_regularizer: Regularizer function applied to the\n+            `recurrent_kernel` weights matrix. Default: `None`.\n+        bias_regularizer: Regularizer function applied to the bias vector.\n+            Default: `None`.\n+        kernel_constraint: Constraint function applied to the `kernel` weights\n+            matrix. Default: `None`.\n+        recurrent_constraint: Constraint function applied to the\n+            `recurrent_kernel` weights matrix. Default: `None`.\n+        bias_constraint: Constraint function applied to the bias vector.\n+            Default: `None`.\n+        dropout: Float between 0 and 1. Fraction of the units to drop for the\n+            linear transformation of the inputs. Default: 0.\n+        recurrent_dropout: Float between 0 and 1. Fraction of the units to drop\n+            for the linear transformation of the recurrent state. Default: 0.\n+        reset_after: GRU convention (whether to apply reset gate after or\n+            before matrix multiplication). False = \"before\",\n+            True = \"after\" (default and cuDNN compatible).\n+\n+    Call arguments:\n+        inputs: A 2D tensor, with shape `(batch, features)`.\n+        states: A 2D tensor with shape `(batch, units)`, which is the state\n+            from the previous time step.\n+        training: Python boolean indicating whether the layer should behave in\n+            training mode or in inference mode. Only relevant when `dropout` or\n+            `recurrent_dropout` is used.\n+\n+    Example:\n+\n+    >>> inputs = np.random.random((32, 10, 8))\n+    >>> rnn = keras_core.layers.RNN(keras_core.layers.GRUCell(4))\n+    >>> output = rnn(inputs)\n+    >>> output.shape\n+    (32, 4)\n+    >>> rnn = keras_core.layers.RNN(\n+    ...    keras_core.layers.GRUCell(4),\n+    ...    return_sequences=True,\n+    ...    return_state=True)\n+    >>> whole_sequence_output, final_state = rnn(inputs)\n+    >>> whole_sequence_output.shape\n+    (32, 10, 4)\n+    >>> final_state.shape\n+    (32, 4)\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        units,\n+        activation=\"tanh\",\n+        recurrent_activation=\"sigmoid\",\n+        use_bias=True,\n+        kernel_initializer=\"glorot_uniform\",\n+        recurrent_initializer=\"orthogonal\",\n+        bias_initializer=\"zeros\",\n+        kernel_regularizer=None,\n+        recurrent_regularizer=None,\n+        bias_regularizer=None,\n+        kernel_constraint=None,\n+        recurrent_constraint=None,\n+        bias_constraint=None,\n+        dropout=0.0,\n+        recurrent_dropout=0.0,\n+        reset_after=True,\n+        seed=None,\n+        **kwargs,\n+    ):\n+        if units <= 0:\n+            raise ValueError(\n+                \"Received an invalid value for argument `units`, \"\n+                f\"expected a positive integer, got {units}.\"\n+            )\n+        implementation = kwargs.pop(\"implementation\", 2)\n+        super().__init__(**kwargs)\n+        self.implementation = implementation\n+        self.units = units\n+        self.activation = activations.get(activation)\n+        self.recurrent_activation = activations.get(recurrent_activation)\n+        self.use_bias = use_bias\n+\n+        self.kernel_initializer = initializers.get(kernel_initializer)\n+        self.recurrent_initializer = initializers.get(recurrent_initializer)\n+        self.bias_initializer = initializers.get(bias_initializer)\n+\n+        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n+        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n+        self.bias_regularizer = regularizers.get(bias_regularizer)\n+\n+        self.kernel_constraint = constraints.get(kernel_constraint)\n+        self.recurrent_constraint = constraints.get(recurrent_constraint)\n+        self.bias_constraint = constraints.get(bias_constraint)\n+\n+        self.dropout = min(1.0, max(0.0, dropout))\n+        self.recurrent_dropout = min(1.0, max(0.0, recurrent_dropout))\n+        self.seed = seed\n+        self.seed_generator = backend.random.SeedGenerator(seed=seed)\n+\n+        self.reset_after = reset_after\n+        self.state_size = self.units\n+        self.output_size = self.units\n+\n+    def build(self, input_shape):\n+        super().build(input_shape)\n+        input_dim = input_shape[-1]\n+        self.kernel = self.add_weight(\n+            shape=(input_dim, self.units * 3),\n+            name=\"kernel\",\n+            initializer=self.kernel_initializer,\n+            regularizer=self.kernel_regularizer,\n+            constraint=self.kernel_constraint,\n+        )\n+        self.recurrent_kernel = self.add_weight(\n+            shape=(self.units, self.units * 3),\n+            name=\"recurrent_kernel\",\n+            initializer=self.recurrent_initializer,\n+            regularizer=self.recurrent_regularizer,\n+            constraint=self.recurrent_constraint,\n+        )\n+\n+        if self.use_bias:\n+            if not self.reset_after:\n+                bias_shape = (3 * self.units,)\n+            else:\n+                # separate biases for input and recurrent kernels\n+                # Note: the shape is intentionally different from CuDNNGRU\n+                # biases `(2 * 3 * self.units,)`, so that we can distinguish the\n+                # classes when loading and converting saved weights.\n+                bias_shape = (2, 3 * self.units)\n+            self.bias = self.add_weight(\n+                shape=bias_shape,\n+                name=\"bias\",\n+                initializer=self.bias_initializer,\n+                regularizer=self.bias_regularizer,\n+                constraint=self.bias_constraint,\n+            )\n+        else:\n+            self.bias = None\n+        self.built = True\n+\n+    def call(self, inputs, states, training=None):\n+        h_tm1 = (\n+            states[0] if nest.is_nested(states) else states\n+        )  # previous state\n+\n+        dp_mask = self.get_dropout_mask(inputs)\n+        rec_dp_mask = self.get_recurrent_dropout_mask(h_tm1)\n+\n+        if self.use_bias:\n+            if not self.reset_after:\n+                input_bias, recurrent_bias = self.bias, None\n+            else:\n+                input_bias, recurrent_bias = (\n+                    ops.squeeze(e, axis=0)\n+                    for e in ops.split(self.bias, self.bias.shape[0], axis=0)\n+                )\n+\n+        if training and 0.0 < self.dropout < 1.0:\n+            inputs *= dp_mask\n+        if training and 0.0 < self.recurrent_dropout < 1.0:\n+            h_tm1 *= rec_dp_mask\n+\n+        if self.implementation == 1:\n+            inputs_z = inputs\n+            inputs_r = inputs\n+            inputs_h = inputs\n+\n+            x_z = ops.matmul(inputs_z, self.kernel[:, : self.units])\n+            x_r = ops.matmul(\n+                inputs_r, self.kernel[:, self.units : self.units * 2]\n+            )\n+            x_h = ops.matmul(inputs_h, self.kernel[:, self.units * 2 :])\n+\n+            if self.use_bias:\n+                x_z += input_bias[: self.units]\n+                x_r += input_bias[self.units : self.units * 2]\n+                x_h += input_bias[self.units * 2 :]\n+\n+            h_tm1_z = h_tm1\n+            h_tm1_r = h_tm1\n+            h_tm1_h = h_tm1\n+\n+            recurrent_z = ops.matmul(\n+                h_tm1_z, self.recurrent_kernel[:, : self.units]\n+            )\n+            recurrent_r = ops.matmul(\n+                h_tm1_r, self.recurrent_kernel[:, self.units : self.units * 2]\n+            )\n+            if self.reset_after and self.use_bias:\n+                recurrent_z += recurrent_bias[: self.units]\n+                recurrent_r += recurrent_bias[self.units : self.units * 2]\n+\n+            z = self.recurrent_activation(x_z + recurrent_z)\n+            r = self.recurrent_activation(x_r + recurrent_r)\n+\n+            # reset gate applied after/before matrix multiplication\n+            if self.reset_after:\n+                recurrent_h = ops.matmul(\n+                    h_tm1_h, self.recurrent_kernel[:, self.units * 2 :]\n+                )\n+                if self.use_bias:\n+                    recurrent_h += recurrent_bias[self.units * 2 :]\n+                recurrent_h = r * recurrent_h\n+            else:\n+                recurrent_h = ops.matmul(\n+                    r * h_tm1_h, self.recurrent_kernel[:, self.units * 2 :]\n+                )\n+\n+            hh = self.activation(x_h + recurrent_h)\n+        else:\n+            if 0.0 < self.dropout < 1.0:\n+                inputs = inputs * dp_mask[0]\n+\n+            # inputs projected by all gate matrices at once\n+            matrix_x = ops.matmul(inputs, self.kernel)\n+            if self.use_bias:\n+                # biases: bias_z_i, bias_r_i, bias_h_i\n+                matrix_x += input_bias\n+\n+            x_z, x_r, x_h = ops.split(matrix_x, 3, axis=-1)\n+\n+            if self.reset_after:\n+                # hidden state projected by all gate matrices at once\n+                matrix_inner = ops.matmul(h_tm1, self.recurrent_kernel)\n+                if self.use_bias:\n+                    matrix_inner += recurrent_bias\n+            else:\n+                # hidden state projected separately for update/reset and new\n+                matrix_inner = ops.matmul(\n+                    h_tm1, self.recurrent_kernel[:, : 2 * self.units]\n+                )\n+\n+            recurrent_z = matrix_inner[:, : self.units]\n+            recurrent_r = matrix_inner[:, self.units : self.units * 2]\n+            recurrent_h = matrix_inner[:, self.units * 2 :]\n+\n+            z = self.recurrent_activation(x_z + recurrent_z)\n+            r = self.recurrent_activation(x_r + recurrent_r)\n+\n+            if self.reset_after:\n+                recurrent_h = r * recurrent_h\n+            else:\n+                recurrent_h = ops.matmul(\n+                    r * h_tm1, self.recurrent_kernel[:, 2 * self.units :]\n+                )\n+\n+            hh = self.activation(x_h + recurrent_h)\n+\n+        # previous and candidate state mixed by update gate\n+        h = z * h_tm1 + (1 - z) * hh\n+        new_state = [h] if nest.is_nested(states) else h\n+        return h, new_state\n+\n+    def get_config(self):\n+        config = {\n+            \"units\": self.units,\n+            \"activation\": activations.serialize(self.activation),\n+            \"recurrent_activation\": activations.serialize(\n+                self.recurrent_activation\n+            ),\n+            \"use_bias\": self.use_bias,\n+            \"kernel_initializer\": initializers.serialize(\n+                self.kernel_initializer\n+            ),\n+            \"recurrent_initializer\": initializers.serialize(\n+                self.recurrent_initializer\n+            ),\n+            \"bias_initializer\": initializers.serialize(self.bias_initializer),\n+            \"kernel_regularizer\": regularizers.serialize(\n+                self.kernel_regularizer\n+            ),\n+            \"recurrent_regularizer\": regularizers.serialize(\n+                self.recurrent_regularizer\n+            ),\n+            \"bias_regularizer\": regularizers.serialize(self.bias_regularizer),\n+            \"kernel_constraint\": constraints.serialize(self.kernel_constraint),\n+            \"recurrent_constraint\": constraints.serialize(\n+                self.recurrent_constraint\n+            ),\n+            \"bias_constraint\": constraints.serialize(self.bias_constraint),\n+            \"dropout\": self.dropout,\n+            \"recurrent_dropout\": self.recurrent_dropout,\n+            \"reset_after\": self.reset_after,\n+        }\n+        base_config = super().get_config()\n+        return {**base_config, **config}\n+\n+    def get_initial_state(self, batch_size=None):\n+        return [\n+            ops.zeros((batch_size, self.state_size), dtype=self.compute_dtype)\n+        ]\n+\n+\n+class GRU(RNN):\n+    \"\"\"Gated Recurrent Unit - Cho et al. 2014.\n+\n+    Based on available runtime hardware and constraints, this layer\n+    will choose different implementations (cuDNN-based or backend-native)\n+    to maximize the performance. If a GPU is available and all\n+    the arguments to the layer meet the requirement of the cuDNN kernel\n+    (see below for details), the layer will use a fast cuDNN implementation\n+    when using the TensorFlow backend.\n+\n+    The requirements to use the cuDNN implementation are:\n+\n+    1. `activation` == `tanh`\n+    2. `recurrent_activation` == `sigmoid`\n+    3. `dropout` == 0 and `recurrent_dropout` == 0\n+    4. `unroll` is `False`\n+    5. `use_bias` is `True`\n+    6. `reset_after` is `True`\n+    7. Inputs, if use masking, are strictly right-padded.\n+    8. Eager execution is enabled in the outermost context.\n+\n+    There are two variants of the GRU implementation. The default one is based\n+    on [v3](https://arxiv.org/abs/1406.1078v3) and has reset gate applied to\n+    hidden state before matrix multiplication. The other one is based on\n+    [original](https://arxiv.org/abs/1406.1078v1) and has the order reversed.\n+\n+    The second variant is compatible with CuDNNGRU (GPU-only) and allows\n+    inference on CPU. Thus it has separate biases for `kernel` and\n+    `recurrent_kernel`. To use this variant, set `reset_after=True` and\n+    `recurrent_activation='sigmoid'`.\n+\n+    For example:\n+\n+    >>> inputs = np.random.random((32, 10, 8))\n+    >>> gru = keras_core.layers.GRU(4)\n+    >>> output = gru(inputs)\n+    >>> output.shape\n+    (32, 4)\n+    >>> gru = keras_core.layers.GRU(4, return_sequences=True, return_state=True)\n+    >>> whole_sequence_output, final_state = gru(inputs)\n+    >>> whole_sequence_output.shape\n+    (32, 10, 4)\n+    >>> final_state.shape\n+    (32, 4)\n+\n+    Args:\n+        units: Positive integer, dimensionality of the output space.\n+        activation: Activation function to use.\n+            Default: hyperbolic tangent (`tanh`).\n+            If you pass `None`, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        recurrent_activation: Activation function to use\n+            for the recurrent step.\n+            Default: sigmoid (`sigmoid`).\n+            If you pass `None`, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        use_bias: Boolean, (default `True`), whether the layer\n+            should use a bias vector.\n+        kernel_initializer: Initializer for the `kernel` weights matrix,\n+            used for the linear transformation of the inputs. Default:\n+            `\"glorot_uniform\"`.\n+        recurrent_initializer: Initializer for the `recurrent_kernel`\n+            weights matrix, used for the linear transformation of the recurrent\n+            state. Default: `\"orthogonal\"`.\n+        bias_initializer: Initializer for the bias vector. Default: `\"zeros\"`.\n+        kernel_regularizer: Regularizer function applied to the `kernel` weights\n+            matrix. Default: `None`.\n+        recurrent_regularizer: Regularizer function applied to the\n+            `recurrent_kernel` weights matrix. Default: `None`.\n+        bias_regularizer: Regularizer function applied to the bias vector.\n+            Default: `None`.\n+        activity_regularizer: Regularizer function applied to the output of the\n+            layer (its \"activation\"). Default: `None`.\n+        kernel_constraint: Constraint function applied to the `kernel` weights\n+            matrix. Default: `None`.\n+        recurrent_constraint: Constraint function applied to the\n+            `recurrent_kernel` weights matrix. Default: `None`.\n+        bias_constraint: Constraint function applied to the bias vector.\n+            Default: `None`.\n+        dropout: Float between 0 and 1. Fraction of the units to drop for the\n+            linear transformation of the inputs. Default: 0.\n+        recurrent_dropout: Float between 0 and 1. Fraction of the units to drop\n+            for the linear transformation of the recurrent state. Default: 0.\n+        return_sequences: Boolean. Whether to return the last output\n+            in the output sequence, or the full sequence. Default: `False`.\n+        return_state: Boolean. Whether to return the last state in addition\n+            to the output. Default: `False`.\n+        go_backwards: Boolean (default `False`).\n+            If `True`, process the input sequence backwards and return the\n+            reversed sequence.\n+        stateful: Boolean (default False). If `True`, the last state\n+            for each sample at index i in a batch will be used as initial\n+            state for the sample of index i in the following batch.\n+        unroll: Boolean (default False).\n+            If `True`, the network will be unrolled,\n+            else a symbolic loop will be used.\n+            Unrolling can speed-up a RNN,\n+            although it tends to be more memory-intensive.\n+            Unrolling is only suitable for short sequences.\n+        reset_after: GRU convention (whether to apply reset gate after or\n+            before matrix multiplication). `False` is `\"before\"`,\n+            `True` is `\"after\"` (default and cuDNN compatible).\n+\n+    Call arguments:\n+        inputs: A 3D tensor, with shape `(batch, timesteps, feature)`.\n+        mask: Binary tensor of shape `(samples, timesteps)` indicating whether\n+            a given timestep should be masked  (optional).\n+            An individual `True` entry indicates that the corresponding timestep\n+            should be utilized, while a `False` entry indicates that the\n+            corresponding timestep should be ignored. Defaults to `None`.\n+        training: Python boolean indicating whether the layer should behave in\n+            training mode or in inference mode. This argument is passed to the\n+            cell when calling it. This is only relevant if `dropout` or\n+            `recurrent_dropout` is used  (optional). Defaults to `None`.\n+        initial_state: List of initial state tensors to be passed to the first\n+            call of the cell (optional, `None` causes creation\n+            of zero-filled initial state tensors). Defaults to `None`.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        units,\n+        activation=\"tanh\",\n+        recurrent_activation=\"sigmoid\",\n+        use_bias=True,\n+        kernel_initializer=\"glorot_uniform\",\n+        recurrent_initializer=\"orthogonal\",\n+        bias_initializer=\"zeros\",\n+        kernel_regularizer=None,\n+        recurrent_regularizer=None,\n+        bias_regularizer=None,\n+        activity_regularizer=None,\n+        kernel_constraint=None,\n+        recurrent_constraint=None,\n+        bias_constraint=None,\n+        dropout=0.0,\n+        recurrent_dropout=0.0,\n+        return_sequences=False,\n+        return_state=False,\n+        go_backwards=False,\n+        stateful=False,\n+        unroll=False,\n+        reset_after=True,\n+        seed=None,\n+        **kwargs,\n+    ):\n+        cell = GRUCell(\n+            units,\n+            activation=activation,\n+            recurrent_activation=recurrent_activation,\n+            use_bias=use_bias,\n+            kernel_initializer=kernel_initializer,\n+            recurrent_initializer=recurrent_initializer,\n+            bias_initializer=bias_initializer,\n+            kernel_regularizer=kernel_regularizer,\n+            recurrent_regularizer=recurrent_regularizer,\n+            bias_regularizer=bias_regularizer,\n+            kernel_constraint=kernel_constraint,\n+            recurrent_constraint=recurrent_constraint,\n+            bias_constraint=bias_constraint,\n+            dropout=dropout,\n+            recurrent_dropout=recurrent_dropout,\n+            reset_after=reset_after,\n+            dtype=kwargs.get(\"dtype\", None),\n+            trainable=kwargs.get(\"trainable\", True),\n+            name=\"gru_cell\",\n+            seed=seed,\n+        )\n+        super().__init__(\n+            cell,\n+            return_sequences=return_sequences,\n+            return_state=return_state,\n+            go_backwards=go_backwards,\n+            stateful=stateful,\n+            unroll=unroll,\n+            activity_regularizer=activity_regularizer,\n+            **kwargs,\n+        )\n+        self.input_spec = InputSpec(ndim=3)\n+\n+    def inner_loop(self, sequence, initial_state, mask, training=False):\n+        if nest.is_nested(initial_state):\n+            initial_state = initial_state[0]\n+        if nest.is_nested(mask):\n+            mask = mask[0]\n+\n+        if not self.dropout and not self.recurrent_dropout:\n+            try:\n+                # Backends are allowed to specify (optionally) optimized\n+                # implementation of the inner GRU loop. In the case of\n+                # TF for instance, it will leverage cuDNN when feasible, and\n+                # it will raise NotImplementedError otherwise.\n+                return backend.gru(\n+                    sequence,\n+                    initial_state,\n+                    mask,\n+                    kernel=self.cell.kernel,\n+                    recurrent_kernel=self.cell.recurrent_kernel,\n+                    bias=self.cell.bias,\n+                    activation=self.cell.activation,\n+                    recurrent_activation=self.cell.recurrent_activation,\n+                    return_sequences=self.return_sequences,\n+                    go_backwards=self.go_backwards,\n+                    unroll=self.unroll,\n+                    reset_after=self.cell.reset_after,\n+                )\n+            except NotImplementedError:\n+                pass\n+        return super().inner_loop(\n+            sequence, initial_state, mask=mask, training=training\n+        )\n+\n+    def call(self, sequence, initial_state=None, mask=None, training=None):\n+        return super().call(\n+            sequence, mask=mask, training=training, initial_state=initial_state\n+        )\n+\n+    @property\n+    def units(self):\n+        return self.cell.units\n+\n+    @property\n+    def activation(self):\n+        return self.cell.activation\n+\n+    @property\n+    def recurrent_activation(self):\n+        return self.cell.recurrent_activation\n+\n+    @property\n+    def use_bias(self):\n+        return self.cell.use_bias\n+\n+    @property\n+    def kernel_initializer(self):\n+        return self.cell.kernel_initializer\n+\n+    @property\n+    def recurrent_initializer(self):\n+        return self.cell.recurrent_initializer\n+\n+    @property\n+    def bias_initializer(self):\n+        return self.cell.bias_initializer\n+\n+    @property\n+    def kernel_regularizer(self):\n+        return self.cell.kernel_regularizer\n+\n+    @property\n+    def recurrent_regularizer(self):\n+        return self.cell.recurrent_regularizer\n+\n+    @property\n+    def bias_regularizer(self):\n+        return self.cell.bias_regularizer\n+\n+    @property\n+    def kernel_constraint(self):\n+        return self.cell.kernel_constraint\n+\n+    @property\n+    def recurrent_constraint(self):\n+        return self.cell.recurrent_constraint\n+\n+    @property\n+    def bias_constraint(self):\n+        return self.cell.bias_constraint\n+\n+    @property\n+    def dropout(self):\n+        return self.cell.dropout\n+\n+    @property\n+    def recurrent_dropout(self):\n+        return self.cell.recurrent_dropout\n+\n+    @property\n+    def reset_after(self):\n+        return self.cell.reset_after\n+\n+    def get_config(self):\n+        config = {\n+            \"units\": self.units,\n+            \"activation\": activations.serialize(self.activation),\n+            \"recurrent_activation\": activations.serialize(\n+                self.recurrent_activation\n+            ),\n+            \"use_bias\": self.use_bias,\n+            \"kernel_initializer\": initializers.serialize(\n+                self.kernel_initializer\n+            ),\n+            \"recurrent_initializer\": initializers.serialize(\n+                self.recurrent_initializer\n+            ),\n+            \"bias_initializer\": initializers.serialize(self.bias_initializer),\n+            \"kernel_regularizer\": regularizers.serialize(\n+                self.kernel_regularizer\n+            ),\n+            \"recurrent_regularizer\": regularizers.serialize(\n+                self.recurrent_regularizer\n+            ),\n+            \"bias_regularizer\": regularizers.serialize(self.bias_regularizer),\n+            \"activity_regularizer\": regularizers.serialize(\n+                self.activity_regularizer\n+            ),\n+            \"kernel_constraint\": constraints.serialize(self.kernel_constraint),\n+            \"recurrent_constraint\": constraints.serialize(\n+                self.recurrent_constraint\n+            ),\n+            \"bias_constraint\": constraints.serialize(self.bias_constraint),\n+            \"dropout\": self.dropout,\n+            \"recurrent_dropout\": self.recurrent_dropout,\n+            \"reset_after\": self.reset_after,\n+        }\n+        base_config = super().get_config()\n+        del base_config[\"cell\"]\n+        return {**base_config, **config}\n+\n+    @classmethod\n+    def from_config(cls, config):\n+        return cls(**config)\n\n@@ -0,0 +1,174 @@\n+import numpy as np\n+import pytest\n+from absl.testing import parameterized\n+\n+from keras_core import backend\n+from keras_core import initializers\n+from keras_core import layers\n+from keras_core import testing\n+\n+\n+@pytest.mark.skipif(\n+    backend.backend() != \"tensorflow\",\n+    reason=\"Only implemented for TF for now.\",\n+)\n+class GRUTest(testing.TestCase, parameterized.TestCase):\n+    def test_basics(self):\n+        self.run_layer_test(\n+            layers.GRU,\n+            init_kwargs={\"units\": 3, \"dropout\": 0.5, \"recurrent_dropout\": 0.5},\n+            input_shape=(3, 2, 4),\n+            call_kwargs={\"training\": True},\n+            expected_output_shape=(3, 3),\n+            expected_num_trainable_weights=3,\n+            expected_num_non_trainable_weights=0,\n+            supports_masking=True,\n+        )\n+        self.run_layer_test(\n+            layers.GRU,\n+            init_kwargs={\n+                \"units\": 3,\n+                \"return_sequences\": True,\n+                \"bias_regularizer\": \"l1\",\n+                \"kernel_regularizer\": \"l2\",\n+                \"recurrent_regularizer\": \"l2\",\n+            },\n+            input_shape=(3, 2, 4),\n+            expected_output_shape=(3, 2, 3),\n+            expected_num_losses=3,\n+            expected_num_trainable_weights=3,\n+            expected_num_non_trainable_weights=0,\n+            supports_masking=True,\n+        )\n+\n+    @parameterized.parameters([1, 2])\n+    def test_correctness(self, implementation):\n+        sequence = np.arange(72).reshape((3, 6, 4)).astype(\"float32\")\n+        layer = layers.GRU(\n+            3,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+        )\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.5217289, 0.5217289, 0.5217289],\n+                    [0.6371659, 0.6371659, 0.6371659],\n+                    [0.39384964, 0.39384964, 0.3938496],\n+                ]\n+            ),\n+            output,\n+        )\n+\n+        layer = layers.GRU(\n+            3,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+            go_backwards=True,\n+        )\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.24406259, 0.24406259, 0.24406259],\n+                    [0.611516, 0.611516, 0.611516],\n+                    [0.3928808, 0.3928808, 0.3928808],\n+                ]\n+            ),\n+            output,\n+        )\n+\n+        layer = layers.GRU(\n+            3,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+            unroll=True,\n+        )\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.5217289, 0.5217289, 0.5217289],\n+                    [0.6371659, 0.6371659, 0.6371659],\n+                    [0.39384964, 0.39384964, 0.3938496],\n+                ]\n+            ),\n+            output,\n+        )\n+\n+        layer = layers.GRU(\n+            3,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+            reset_after=False,\n+        )\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.51447755, 0.51447755, 0.51447755],\n+                    [0.6426879, 0.6426879, 0.6426879],\n+                    [0.40208298, 0.40208298, 0.40208298],\n+                ]\n+            ),\n+            output,\n+        )\n+\n+        layer = layers.GRU(\n+            3,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+            use_bias=False,\n+        )\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.49988455, 0.49988455, 0.49988455],\n+                    [0.64701194, 0.64701194, 0.64701194],\n+                    [0.4103359, 0.4103359, 0.4103359],\n+                ]\n+            ),\n+            output,\n+        )\n+\n+    def test_statefulness(self):\n+        sequence = np.arange(24).reshape((2, 3, 4)).astype(\"float32\")\n+        layer = layers.GRU(\n+            4,\n+            stateful=True,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+        )\n+        layer(sequence)\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.29542392, 0.29542392, 0.29542392, 0.29542392],\n+                    [0.5885018, 0.5885018, 0.5885018, 0.5885018],\n+                ]\n+            ),\n+            output,\n+        )\n+        layer.reset_state()\n+        layer(sequence)\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.29542392, 0.29542392, 0.29542392, 0.29542392],\n+                    [0.5885018, 0.5885018, 0.5885018, 0.5885018],\n+                ]\n+            ),\n+            output,\n+        )\n+\n+    # TODO: test masking\n\n@@ -0,0 +1,632 @@\n+from tensorflow import nest\n+\n+from keras_core import activations\n+from keras_core import backend\n+from keras_core import constraints\n+from keras_core import initializers\n+from keras_core import operations as ops\n+from keras_core import regularizers\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.input_spec import InputSpec\n+from keras_core.layers.layer import Layer\n+from keras_core.layers.rnn.dropout_rnn_cell import DropoutRNNCell\n+from keras_core.layers.rnn.rnn import RNN\n+\n+\n+@keras_core_export(\"keras_core.layers.LSTMCell\")\n+class LSTMCell(Layer, DropoutRNNCell):\n+    \"\"\"Cell class for the LSTM layer.\n+\n+    This class processes one step within the whole time sequence input, whereas\n+    `keras_core.layer.LSTM` processes the whole sequence.\n+\n+    Args:\n+        units: Positive integer, dimensionality of the output space.\n+        activation: Activation function to use. Default: hyperbolic tangent\n+            (`tanh`). If you pass None, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        recurrent_activation: Activation function to use for the recurrent step.\n+            Default: sigmoid (`sigmoid`). If you pass `None`, no activation is\n+            applied (ie. \"linear\" activation: `a(x) = x`).\n+        use_bias: Boolean, (default `True`), whether the layer\n+            should use a bias vector.\n+        kernel_initializer: Initializer for the `kernel` weights matrix,\n+            used for the linear transformation of the inputs. Default:\n+            `\"glorot_uniform\"`.\n+        recurrent_initializer: Initializer for the `recurrent_kernel`\n+            weights matrix, used for the linear transformation\n+            of the recurrent state. Default: `\"orthogonal\"`.\n+        bias_initializer: Initializer for the bias vector. Default: `\"zeros\"`.\n+        unit_forget_bias: Boolean (default `True`). If `True`,\n+            add 1 to the bias of the forget gate at initialization.\n+            Setting it to `True` will also force `bias_initializer=\"zeros\"`.\n+            This is recommended in [Jozefowicz et al.](\n+            https://github.com/mlresearch/v37/blob/gh-pages/jozefowicz15.pdf)\n+        kernel_regularizer: Regularizer function applied to the `kernel` weights\n+            matrix. Default: `None`.\n+        recurrent_regularizer: Regularizer function applied to the\n+            `recurrent_kernel` weights matrix. Default: `None`.\n+        bias_regularizer: Regularizer function applied to the bias vector.\n+            Default: `None`.\n+        kernel_constraint: Constraint function applied to the `kernel` weights\n+            matrix. Default: `None`.\n+        recurrent_constraint: Constraint function applied to the\n+            `recurrent_kernel` weights matrix. Default: `None`.\n+        bias_constraint: Constraint function applied to the bias vector.\n+            Default: `None`.\n+        dropout: Float between 0 and 1. Fraction of the units to drop for the\n+            linear transformation of the inputs. Default: 0.\n+        recurrent_dropout: Float between 0 and 1. Fraction of the units to drop\n+            for the linear transformation of the recurrent state. Default: 0.\n+\n+    Call arguments:\n+        inputs: A 2D tensor, with shape `(batch, features)`.\n+        states: A 2D tensor with shape `(batch, units)`, which is the state\n+            from the previous time step.\n+        training: Python boolean indicating whether the layer should behave in\n+            training mode or in inference mode. Only relevant when `dropout` or\n+            `recurrent_dropout` is used.\n+\n+    Example:\n+\n+    >>> inputs = np.random.random((32, 10, 8))\n+    >>> rnn = keras_core.layers.RNN(keras_core.layers.LSTMCell(4))\n+    >>> output = rnn(inputs)\n+    >>> output.shape\n+    (32, 4)\n+    >>> rnn = keras_core.layers.RNN(\n+    ...    keras_core.layers.LSTMCell(4),\n+    ...    return_sequences=True,\n+    ...    return_state=True)\n+    >>> whole_sequence_output, final_state = rnn(inputs)\n+    >>> whole_sequence_output.shape\n+    (32, 10, 4)\n+    >>> final_state.shape\n+    (32, 4)\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        units,\n+        activation=\"tanh\",\n+        recurrent_activation=\"sigmoid\",\n+        use_bias=True,\n+        kernel_initializer=\"glorot_uniform\",\n+        recurrent_initializer=\"orthogonal\",\n+        bias_initializer=\"zeros\",\n+        unit_forget_bias=True,\n+        kernel_regularizer=None,\n+        recurrent_regularizer=None,\n+        bias_regularizer=None,\n+        kernel_constraint=None,\n+        recurrent_constraint=None,\n+        bias_constraint=None,\n+        dropout=0.0,\n+        recurrent_dropout=0.0,\n+        seed=None,\n+        **kwargs,\n+    ):\n+        if units <= 0:\n+            raise ValueError(\n+                \"Received an invalid value for argument `units`, \"\n+                f\"expected a positive integer, got {units}.\"\n+            )\n+        implementation = kwargs.pop(\"implementation\", 2)\n+        super().__init__(**kwargs)\n+        self.units = units\n+        self.activation = activations.get(activation)\n+        self.recurrent_activation = activations.get(recurrent_activation)\n+        self.use_bias = use_bias\n+\n+        self.kernel_initializer = initializers.get(kernel_initializer)\n+        self.recurrent_initializer = initializers.get(recurrent_initializer)\n+        self.bias_initializer = initializers.get(bias_initializer)\n+\n+        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n+        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n+        self.bias_regularizer = regularizers.get(bias_regularizer)\n+\n+        self.kernel_constraint = constraints.get(kernel_constraint)\n+        self.recurrent_constraint = constraints.get(recurrent_constraint)\n+        self.bias_constraint = constraints.get(bias_constraint)\n+\n+        self.dropout = min(1.0, max(0.0, dropout))\n+        self.recurrent_dropout = min(1.0, max(0.0, recurrent_dropout))\n+        self.seed = seed\n+        self.seed_generator = backend.random.SeedGenerator(seed=seed)\n+\n+        self.unit_forget_bias = unit_forget_bias\n+        self.state_size = [self.units, self.units]\n+        self.output_size = self.units\n+        self.implementation = implementation\n+\n+    def build(self, input_shape):\n+        super().build(input_shape)\n+        input_dim = input_shape[-1]\n+        self.kernel = self.add_weight(\n+            shape=(input_dim, self.units * 4),\n+            name=\"kernel\",\n+            initializer=self.kernel_initializer,\n+            regularizer=self.kernel_regularizer,\n+            constraint=self.kernel_constraint,\n+        )\n+        self.recurrent_kernel = self.add_weight(\n+            shape=(self.units, self.units * 4),\n+            name=\"recurrent_kernel\",\n+            initializer=self.recurrent_initializer,\n+            regularizer=self.recurrent_regularizer,\n+            constraint=self.recurrent_constraint,\n+        )\n+\n+        if self.use_bias:\n+            if self.unit_forget_bias:\n+\n+                def bias_initializer(_, *args, **kwargs):\n+                    return ops.concatenate(\n+                        [\n+                            self.bias_initializer(\n+                                (self.units,), *args, **kwargs\n+                            ),\n+                            initializers.get(\"ones\")(\n+                                (self.units,), *args, **kwargs\n+                            ),\n+                            self.bias_initializer(\n+                                (self.units * 2,), *args, **kwargs\n+                            ),\n+                        ]\n+                    )\n+\n+            else:\n+                bias_initializer = self.bias_initializer\n+            self.bias = self.add_weight(\n+                shape=(self.units * 4,),\n+                name=\"bias\",\n+                initializer=bias_initializer,\n+                regularizer=self.bias_regularizer,\n+                constraint=self.bias_constraint,\n+            )\n+        else:\n+            self.bias = None\n+        self.built = True\n+\n+    def _compute_carry_and_output(self, x, h_tm1, c_tm1):\n+        \"\"\"Computes carry and output using split kernels.\"\"\"\n+        x_i, x_f, x_c, x_o = x\n+        h_tm1_i, h_tm1_f, h_tm1_c, h_tm1_o = h_tm1\n+        i = self.recurrent_activation(\n+            x_i + ops.matmul(h_tm1_i, self.recurrent_kernel[:, : self.units])\n+        )\n+        f = self.recurrent_activation(\n+            x_f\n+            + ops.matmul(\n+                h_tm1_f, self.recurrent_kernel[:, self.units : self.units * 2]\n+            )\n+        )\n+        c = f * c_tm1 + i * self.activation(\n+            x_c\n+            + ops.matmul(\n+                h_tm1_c,\n+                self.recurrent_kernel[:, self.units * 2 : self.units * 3],\n+            )\n+        )\n+        o = self.recurrent_activation(\n+            x_o\n+            + ops.matmul(h_tm1_o, self.recurrent_kernel[:, self.units * 3 :])\n+        )\n+        return c, o\n+\n+    def _compute_carry_and_output_fused(self, z, c_tm1):\n+        \"\"\"Computes carry and output using fused kernels.\"\"\"\n+        z0, z1, z2, z3 = z\n+        i = self.recurrent_activation(z0)\n+        f = self.recurrent_activation(z1)\n+        c = f * c_tm1 + i * self.activation(z2)\n+        o = self.recurrent_activation(z3)\n+        return c, o\n+\n+    def call(self, inputs, states, training=None):\n+        h_tm1 = states[0]  # previous memory state\n+        c_tm1 = states[1]  # previous carry state\n+\n+        dp_mask = self.get_dropout_mask(inputs)\n+        rec_dp_mask = self.get_recurrent_dropout_mask(h_tm1)\n+\n+        if training and 0.0 < self.dropout < 1.0:\n+            inputs *= dp_mask\n+        if training and 0.0 < self.recurrent_dropout < 1.0:\n+            h_tm1 *= rec_dp_mask\n+\n+        if self.implementation == 1:\n+            inputs_i = inputs\n+            inputs_f = inputs\n+            inputs_c = inputs\n+            inputs_o = inputs\n+            k_i, k_f, k_c, k_o = ops.split(self.kernel, 4, axis=1)\n+            x_i = ops.matmul(inputs_i, k_i)\n+            x_f = ops.matmul(inputs_f, k_f)\n+            x_c = ops.matmul(inputs_c, k_c)\n+            x_o = ops.matmul(inputs_o, k_o)\n+            if self.use_bias:\n+                b_i, b_f, b_c, b_o = ops.split(self.bias, 4, axis=0)\n+                x_i += b_i\n+                x_f += b_f\n+                x_c += b_c\n+                x_o += b_o\n+\n+            h_tm1_i = h_tm1\n+            h_tm1_f = h_tm1\n+            h_tm1_c = h_tm1\n+            h_tm1_o = h_tm1\n+            x = (x_i, x_f, x_c, x_o)\n+            h_tm1 = (h_tm1_i, h_tm1_f, h_tm1_c, h_tm1_o)\n+            c, o = self._compute_carry_and_output(x, h_tm1, c_tm1)\n+        else:\n+            if 0.0 < self.dropout < 1.0:\n+                inputs = inputs * dp_mask[0]\n+            z = ops.matmul(inputs, self.kernel)\n+\n+            z += ops.matmul(h_tm1, self.recurrent_kernel)\n+            if self.use_bias:\n+                z += self.bias\n+\n+            z = ops.split(z, 4, axis=1)\n+            c, o = self._compute_carry_and_output_fused(z, c_tm1)\n+\n+        h = o * self.activation(c)\n+        return h, [h, c]\n+\n+    def get_config(self):\n+        config = {\n+            \"units\": self.units,\n+            \"activation\": activations.serialize(self.activation),\n+            \"recurrent_activation\": activations.serialize(\n+                self.recurrent_activation\n+            ),\n+            \"use_bias\": self.use_bias,\n+            \"unit_forget_bias\": self.unit_forget_bias,\n+            \"kernel_initializer\": initializers.serialize(\n+                self.kernel_initializer\n+            ),\n+            \"recurrent_initializer\": initializers.serialize(\n+                self.recurrent_initializer\n+            ),\n+            \"bias_initializer\": initializers.serialize(self.bias_initializer),\n+            \"kernel_regularizer\": regularizers.serialize(\n+                self.kernel_regularizer\n+            ),\n+            \"recurrent_regularizer\": regularizers.serialize(\n+                self.recurrent_regularizer\n+            ),\n+            \"bias_regularizer\": regularizers.serialize(self.bias_regularizer),\n+            \"kernel_constraint\": constraints.serialize(self.kernel_constraint),\n+            \"recurrent_constraint\": constraints.serialize(\n+                self.recurrent_constraint\n+            ),\n+            \"bias_constraint\": constraints.serialize(self.bias_constraint),\n+            \"dropout\": self.dropout,\n+            \"recurrent_dropout\": self.recurrent_dropout,\n+        }\n+        base_config = super().get_config()\n+        return {**base_config, **config}\n+\n+    def get_initial_state(self, batch_size=None):\n+        return [\n+            ops.zeros((batch_size, d), dtype=self.compute_dtype)\n+            for d in self.state_size\n+        ]\n+\n+\n+class LSTM(RNN):\n+    \"\"\"Long Short-Term Memory layer - Hochreiter 1997.\n+\n+    Based on available runtime hardware and constraints, this layer\n+    will choose different implementations (cuDNN-based or backend-native)\n+    to maximize the performance. If a GPU is available and all\n+    the arguments to the layer meet the requirement of the cuDNN kernel\n+    (see below for details), the layer will use a fast cuDNN implementation\n+    when using the TensorFlow backend.\n+    The requirements to use the cuDNN implementation are:\n+\n+    1. `activation` == `tanh`\n+    2. `recurrent_activation` == `sigmoid`\n+    3. `dropout` == 0 and `recurrent_dropout` == 0\n+    4. `unroll` is `False`\n+    5. `use_bias` is `True`\n+    6. Inputs, if use masking, are strictly right-padded.\n+    7. Eager execution is enabled in the outermost context.\n+\n+    For example:\n+\n+    >>> inputs = np.random.random((32, 10, 8))\n+    >>> lstm = keras_core.layers.LSTM(4)\n+    >>> output = lstm(inputs)\n+    >>> output.shape\n+    (32, 4)\n+    >>> lstm = keras_core.layers.LSTM(\n+    ...     4, return_sequences=True, return_state=True)\n+    >>> whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)\n+    >>> whole_seq_output.shape\n+    (32, 10, 4)\n+    >>> final_memory_state.shape\n+    (32, 4)\n+    >>> final_carry_state.shape\n+    (32, 4)\n+\n+    Args:\n+        units: Positive integer, dimensionality of the output space.\n+        activation: Activation function to use.\n+            Default: hyperbolic tangent (`tanh`).\n+            If you pass `None`, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        recurrent_activation: Activation function to use\n+            for the recurrent step.\n+            Default: sigmoid (`sigmoid`).\n+            If you pass `None`, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        use_bias: Boolean, (default `True`), whether the layer\n+            should use a bias vector.\n+        kernel_initializer: Initializer for the `kernel` weights matrix,\n+            used for the linear transformation of the inputs. Default:\n+            `\"glorot_uniform\"`.\n+        recurrent_initializer: Initializer for the `recurrent_kernel`\n+            weights matrix, used for the linear transformation of the recurrent\n+            state. Default: `\"orthogonal\"`.\n+        bias_initializer: Initializer for the bias vector. Default: `\"zeros\"`.\n+        unit_forget_bias: Boolean (default `True`). If `True`,\n+            add 1 to the bias of the forget gate at initialization.\n+            Setting it to `True` will also force `bias_initializer=\"zeros\"`.\n+            This is recommended in [Jozefowicz et al.](\n+            https://github.com/mlresearch/v37/blob/gh-pages/jozefowicz15.pdf)\n+        kernel_regularizer: Regularizer function applied to the `kernel` weights\n+            matrix. Default: `None`.\n+        recurrent_regularizer: Regularizer function applied to the\n+            `recurrent_kernel` weights matrix. Default: `None`.\n+        bias_regularizer: Regularizer function applied to the bias vector.\n+            Default: `None`.\n+        activity_regularizer: Regularizer function applied to the output of the\n+            layer (its \"activation\"). Default: `None`.\n+        kernel_constraint: Constraint function applied to the `kernel` weights\n+            matrix. Default: `None`.\n+        recurrent_constraint: Constraint function applied to the\n+            `recurrent_kernel` weights matrix. Default: `None`.\n+        bias_constraint: Constraint function applied to the bias vector.\n+            Default: `None`.\n+        dropout: Float between 0 and 1. Fraction of the units to drop for the\n+            linear transformation of the inputs. Default: 0.\n+        recurrent_dropout: Float between 0 and 1. Fraction of the units to drop\n+            for the linear transformation of the recurrent state. Default: 0.\n+        return_sequences: Boolean. Whether to return the last output\n+            in the output sequence, or the full sequence. Default: `False`.\n+        return_state: Boolean. Whether to return the last state in addition\n+            to the output. Default: `False`.\n+        go_backwards: Boolean (default `False`).\n+            If `True`, process the input sequence backwards and return the\n+            reversed sequence.\n+        stateful: Boolean (default False). If `True`, the last state\n+            for each sample at index i in a batch will be used as initial\n+            state for the sample of index i in the following batch.\n+        unroll: Boolean (default False).\n+            If `True`, the network will be unrolled,\n+            else a symbolic loop will be used.\n+            Unrolling can speed-up a RNN,\n+            although it tends to be more memory-intensive.\n+            Unrolling is only suitable for short sequences.\n+\n+    Call arguments:\n+        inputs: A 3D tensor, with shape `(batch, timesteps, feature)`.\n+        mask: Binary tensor of shape `(samples, timesteps)` indicating whether\n+            a given timestep should be masked  (optional).\n+            An individual `True` entry indicates that the corresponding timestep\n+            should be utilized, while a `False` entry indicates that the\n+            corresponding timestep should be ignored. Defaults to `None`.\n+        training: Python boolean indicating whether the layer should behave in\n+            training mode or in inference mode. This argument is passed to the\n+            cell when calling it. This is only relevant if `dropout` or\n+            `recurrent_dropout` is used  (optional). Defaults to `None`.\n+        initial_state: List of initial state tensors to be passed to the first\n+            call of the cell (optional, `None` causes creation\n+            of zero-filled initial state tensors). Defaults to `None`.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        units,\n+        activation=\"tanh\",\n+        recurrent_activation=\"sigmoid\",\n+        use_bias=True,\n+        kernel_initializer=\"glorot_uniform\",\n+        recurrent_initializer=\"orthogonal\",\n+        bias_initializer=\"zeros\",\n+        unit_forget_bias=True,\n+        kernel_regularizer=None,\n+        recurrent_regularizer=None,\n+        bias_regularizer=None,\n+        activity_regularizer=None,\n+        kernel_constraint=None,\n+        recurrent_constraint=None,\n+        bias_constraint=None,\n+        dropout=0.0,\n+        recurrent_dropout=0.0,\n+        return_sequences=False,\n+        return_state=False,\n+        go_backwards=False,\n+        stateful=False,\n+        unroll=False,\n+        seed=None,\n+        **kwargs,\n+    ):\n+        cell = LSTMCell(\n+            units,\n+            activation=activation,\n+            recurrent_activation=recurrent_activation,\n+            use_bias=use_bias,\n+            kernel_initializer=kernel_initializer,\n+            unit_forget_bias=unit_forget_bias,\n+            recurrent_initializer=recurrent_initializer,\n+            bias_initializer=bias_initializer,\n+            kernel_regularizer=kernel_regularizer,\n+            recurrent_regularizer=recurrent_regularizer,\n+            bias_regularizer=bias_regularizer,\n+            kernel_constraint=kernel_constraint,\n+            recurrent_constraint=recurrent_constraint,\n+            bias_constraint=bias_constraint,\n+            dropout=dropout,\n+            recurrent_dropout=recurrent_dropout,\n+            dtype=kwargs.get(\"dtype\", None),\n+            trainable=kwargs.get(\"trainable\", True),\n+            name=\"lstm_cell\",\n+            seed=seed,\n+            implementation=kwargs.pop(\"implementation\", 2),\n+        )\n+        super().__init__(\n+            cell,\n+            return_sequences=return_sequences,\n+            return_state=return_state,\n+            go_backwards=go_backwards,\n+            stateful=stateful,\n+            unroll=unroll,\n+            activity_regularizer=activity_regularizer,\n+            **kwargs,\n+        )\n+        self.input_spec = InputSpec(ndim=3)\n+\n+    def inner_loop(self, sequence, initial_state, mask, training=False):\n+        if nest.is_nested(mask):\n+            mask = mask[0]\n+\n+        if not self.dropout and not self.recurrent_dropout:\n+            try:\n+                # Backends are allowed to specify (optionally) optimized\n+                # implementation of the inner LSTM loop. In the case of\n+                # TF for instance, it will leverage cuDNN when feasible, and\n+                # it will raise NotImplementedError otherwise.\n+                return backend.lstm(\n+                    sequence,\n+                    initial_state[0],\n+                    initial_state[1],\n+                    mask,\n+                    kernel=self.cell.kernel,\n+                    recurrent_kernel=self.cell.recurrent_kernel,\n+                    bias=self.cell.bias,\n+                    activation=self.cell.activation,\n+                    recurrent_activation=self.cell.recurrent_activation,\n+                    return_sequences=self.return_sequences,\n+                    go_backwards=self.go_backwards,\n+                    unroll=self.unroll,\n+                )\n+            except NotImplementedError:\n+                pass\n+        return super().inner_loop(\n+            sequence, initial_state, mask=mask, training=training\n+        )\n+\n+    def call(self, sequence, initial_state=None, mask=None, training=None):\n+        return super().call(\n+            sequence, mask=mask, training=training, initial_state=initial_state\n+        )\n+\n+    @property\n+    def units(self):\n+        return self.cell.units\n+\n+    @property\n+    def activation(self):\n+        return self.cell.activation\n+\n+    @property\n+    def recurrent_activation(self):\n+        return self.cell.recurrent_activation\n+\n+    @property\n+    def use_bias(self):\n+        return self.cell.use_bias\n+\n+    @property\n+    def unit_forget_bias(self):\n+        return self.cell.unit_forget_bias\n+\n+    @property\n+    def kernel_initializer(self):\n+        return self.cell.kernel_initializer\n+\n+    @property\n+    def recurrent_initializer(self):\n+        return self.cell.recurrent_initializer\n+\n+    @property\n+    def bias_initializer(self):\n+        return self.cell.bias_initializer\n+\n+    @property\n+    def kernel_regularizer(self):\n+        return self.cell.kernel_regularizer\n+\n+    @property\n+    def recurrent_regularizer(self):\n+        return self.cell.recurrent_regularizer\n+\n+    @property\n+    def bias_regularizer(self):\n+        return self.cell.bias_regularizer\n+\n+    @property\n+    def kernel_constraint(self):\n+        return self.cell.kernel_constraint\n+\n+    @property\n+    def recurrent_constraint(self):\n+        return self.cell.recurrent_constraint\n+\n+    @property\n+    def bias_constraint(self):\n+        return self.cell.bias_constraint\n+\n+    @property\n+    def dropout(self):\n+        return self.cell.dropout\n+\n+    @property\n+    def recurrent_dropout(self):\n+        return self.cell.recurrent_dropout\n+\n+    def get_config(self):\n+        config = {\n+            \"units\": self.units,\n+            \"activation\": activations.serialize(self.activation),\n+            \"recurrent_activation\": activations.serialize(\n+                self.recurrent_activation\n+            ),\n+            \"use_bias\": self.use_bias,\n+            \"kernel_initializer\": initializers.serialize(\n+                self.kernel_initializer\n+            ),\n+            \"recurrent_initializer\": initializers.serialize(\n+                self.recurrent_initializer\n+            ),\n+            \"bias_initializer\": initializers.serialize(self.bias_initializer),\n+            \"unit_forget_bias\": self.unit_forget_bias,\n+            \"kernel_regularizer\": regularizers.serialize(\n+                self.kernel_regularizer\n+            ),\n+            \"recurrent_regularizer\": regularizers.serialize(\n+                self.recurrent_regularizer\n+            ),\n+            \"bias_regularizer\": regularizers.serialize(self.bias_regularizer),\n+            \"activity_regularizer\": regularizers.serialize(\n+                self.activity_regularizer\n+            ),\n+            \"kernel_constraint\": constraints.serialize(self.kernel_constraint),\n+            \"recurrent_constraint\": constraints.serialize(\n+                self.recurrent_constraint\n+            ),\n+            \"bias_constraint\": constraints.serialize(self.bias_constraint),\n+            \"dropout\": self.dropout,\n+            \"recurrent_dropout\": self.recurrent_dropout,\n+        }\n+        base_config = super().get_config()\n+        del base_config[\"cell\"]\n+        return {**base_config, **config}\n+\n+    @classmethod\n+    def from_config(cls, config):\n+        return cls(**config)\n\n@@ -0,0 +1,179 @@\n+import numpy as np\n+import pytest\n+from absl.testing import parameterized\n+\n+from keras_core import backend\n+from keras_core import initializers\n+from keras_core import layers\n+from keras_core import testing\n+\n+\n+@pytest.mark.skipif(\n+    backend.backend() != \"tensorflow\",\n+    reason=\"Only implemented for TF for now.\",\n+)\n+class LSTMTest(testing.TestCase, parameterized.TestCase):\n+    def test_basics(self):\n+        self.run_layer_test(\n+            layers.LSTM,\n+            init_kwargs={\"units\": 3, \"dropout\": 0.5, \"recurrent_dropout\": 0.5},\n+            input_shape=(3, 2, 4),\n+            call_kwargs={\"training\": True},\n+            expected_output_shape=(3, 3),\n+            expected_num_trainable_weights=3,\n+            expected_num_non_trainable_weights=0,\n+            supports_masking=True,\n+        )\n+        self.run_layer_test(\n+            layers.LSTM,\n+            init_kwargs={\n+                \"units\": 3,\n+                \"return_sequences\": True,\n+                \"bias_regularizer\": \"l1\",\n+                \"kernel_regularizer\": \"l2\",\n+                \"recurrent_regularizer\": \"l2\",\n+            },\n+            input_shape=(3, 2, 4),\n+            expected_output_shape=(3, 2, 3),\n+            expected_num_losses=3,\n+            expected_num_trainable_weights=3,\n+            expected_num_non_trainable_weights=0,\n+            supports_masking=True,\n+        )\n+\n+    @parameterized.parameters([1, 2])\n+    def test_correctness(self, implementation):\n+        sequence = np.arange(72).reshape((3, 6, 4)).astype(\"float32\")\n+        layer = layers.LSTM(\n+            3,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+            implementation=implementation,\n+        )\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.6288687, 0.6288687, 0.6288687],\n+                    [0.86899155, 0.86899155, 0.86899155],\n+                    [0.9460773, 0.9460773, 0.9460773],\n+                ]\n+            ),\n+            output,\n+        )\n+\n+        layer = layers.LSTM(\n+            3,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+            go_backwards=True,\n+            implementation=implementation,\n+        )\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.35622165, 0.35622165, 0.35622165],\n+                    [0.74789524, 0.74789524, 0.74789524],\n+                    [0.8872726, 0.8872726, 0.8872726],\n+                ]\n+            ),\n+            output,\n+        )\n+\n+        layer = layers.LSTM(\n+            3,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+            unroll=True,\n+            implementation=implementation,\n+        )\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.6288687, 0.6288687, 0.6288687],\n+                    [0.86899155, 0.86899155, 0.86899155],\n+                    [0.9460773, 0.9460773, 0.9460773],\n+                ]\n+            ),\n+            output,\n+        )\n+\n+        layer = layers.LSTM(\n+            3,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+            unit_forget_bias=False,\n+            implementation=implementation,\n+        )\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.57019705, 0.57019705, 0.57019705],\n+                    [0.8661914, 0.8661914, 0.8661914],\n+                    [0.9459622, 0.9459622, 0.9459622],\n+                ]\n+            ),\n+            output,\n+        )\n+\n+        layer = layers.LSTM(\n+            3,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+            use_bias=False,\n+            implementation=implementation,\n+        )\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.54986924, 0.54986924, 0.54986924],\n+                    [0.86226785, 0.86226785, 0.86226785],\n+                    [0.9443936, 0.9443936, 0.9443936],\n+                ]\n+            ),\n+            output,\n+        )\n+\n+    def test_statefulness(self):\n+        sequence = np.arange(24).reshape((2, 3, 4)).astype(\"float32\")\n+        layer = layers.LSTM(\n+            4,\n+            stateful=True,\n+            kernel_initializer=initializers.Constant(0.01),\n+            recurrent_initializer=initializers.Constant(0.02),\n+            bias_initializer=initializers.Constant(0.03),\n+        )\n+        layer(sequence)\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.3124785, 0.3124785, 0.3124785, 0.3124785],\n+                    [0.6863672, 0.6863672, 0.6863672, 0.6863672],\n+                ]\n+            ),\n+            output,\n+        )\n+        layer.reset_state()\n+        layer(sequence)\n+        output = layer(sequence)\n+        self.assertAllClose(\n+            np.array(\n+                [\n+                    [0.3124785, 0.3124785, 0.3124785, 0.3124785],\n+                    [0.6863672, 0.6863672, 0.6863672, 0.6863672],\n+                ]\n+            ),\n+            output,\n+        )\n+\n+    # TODO: test masking\n\n@@ -321,6 +321,32 @@ class RNN(Layer):\n             for v in self.states:\n                 v.assign(ops.zeros_like(v))\n \n+    def inner_loop(self, sequence, initial_state, mask, training=False):\n+        cell_kwargs = {}\n+        if isinstance(self.cell, Layer) and self.cell._call_has_training_arg():\n+            cell_kwargs[\"training\"] = training\n+\n+        def step(inputs, states):\n+            output, new_states = self.cell(inputs, states, **cell_kwargs)\n+            if not nest.is_nested(new_states):\n+                new_states = [new_states]\n+            return output, new_states\n+\n+        if not nest.is_nested(initial_state):\n+            initial_state = [initial_state]\n+\n+        return backend.rnn(\n+            step,\n+            sequence,\n+            initial_state,\n+            go_backwards=self.go_backwards,\n+            mask=mask,\n+            unroll=self.unroll,\n+            input_length=sequence.shape[1],\n+            zero_output_for_mask=self.zero_output_for_mask,\n+            return_all_outputs=self.return_sequences,\n+        )\n+\n     def call(\n         self,\n         sequence,\n@@ -335,18 +361,12 @@ class RNN(Layer):\n                 \"time dimension is undefined. \\n\"\n                 \"- If using a Sequential model, \"\n                 \"specify the time dimension by passing \"\n-                \"an `input_shape` or `batch_input_shape` \"\n-                \"argument to your first layer. If your \"\n-                \"first layer is an Embedding, you can \"\n-                \"also use the `input_length` argument.\\n\"\n+                \"an `Input()` as your first layer.\\n\"\n                 \"- If using the functional API, specify \"\n                 \"the time dimension by passing a `shape` \"\n-                \"or `batch_shape` argument to your Input layer.\"\n+                \"or `batch_shape` argument to your `Input()`.\"\n             )\n \n-        cell_kwargs = {}\n-        if isinstance(self.cell, Layer) and self.cell._call_has_training_arg():\n-            cell_kwargs[\"training\"] = training\n         if initial_state is None:\n             if self.stateful:\n                 initial_state = self.states\n@@ -366,22 +386,11 @@ class RNN(Layer):\n             lambda x: ops.cast(x, dtype=self.compute_dtype), initial_state\n         )\n \n-        def step(inputs, states):\n-            output, new_states = self.cell(inputs, states, **cell_kwargs)\n-            if not nest.is_nested(new_states):\n-                new_states = [new_states]\n-            return output, new_states\n-\n-        last_output, outputs, states = backend.nn.rnn(\n-            step,\n-            sequence,\n-            initial_state,\n-            go_backwards=self.go_backwards,\n+        last_output, outputs, states = self.inner_loop(\n+            sequence=sequence,\n+            initial_state=initial_state,\n             mask=mask,\n-            unroll=self.unroll,\n-            input_length=timesteps,\n-            zero_output_for_mask=self.zero_output_for_mask,\n-            return_all_outputs=self.return_sequences,\n+            training=training,\n         )\n         self._maybe_reset_dropout_masks(self.cell)\n \n\n@@ -51,7 +51,7 @@ class SimpleRNNCell(Layer, DropoutRNNCell):\n             for the linear transformation of the recurrent state. Default: 0.\n \n     Call arguments:\n-        inputs: A 2D tensor, with shape `(batch, feature)`.\n+        inputs: A 2D tensor, with shape `(batch, features)`.\n         states: A 2D tensor with shape `(batch, units)`, which is the state\n             from the previous time step.\n         training: Python boolean indicating whether the layer should behave in\n@@ -334,7 +334,7 @@ class SimpleRNN(RNN):\n             dropout=dropout,\n             recurrent_dropout=recurrent_dropout,\n             seed=seed,\n-            dtype=kwargs.get(\"dtype\"),\n+            dtype=kwargs.get(\"dtype\", None),\n             trainable=kwargs.get(\"trainable\", True),\n             name=\"simple_rnn_cell\",\n         )\n@@ -347,10 +347,9 @@ class SimpleRNN(RNN):\n             unroll=unroll,\n             **kwargs,\n         )\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n         self.input_spec = [InputSpec(ndim=3)]\n \n-    def call(self, inputs, mask=None, training=None, initial_state=None):\n+    def call(self, inputs, initial_state=None, mask=None, training=None):\n         return super().call(\n             inputs, mask=mask, training=training, initial_state=initial_state\n         )\n\n@@ -102,5 +102,7 @@ class MetricTest(testing.TestCase):\n         self.assertEqual(len(metric.variables), 6)\n \n     def test_serialization(self):\n-        # TODO\n-        pass\n+        self.run_class_serialization_test(\n+            ExampleMetric(name=\"mse\"),\n+            custom_objects={\"ExampleMetric\": ExampleMetric},\n+        )\n\n@@ -0,0 +1,22 @@\n+\"\"\"\n+scatter\n+\"\"\"\n+\n+from keras_core import backend\n+from keras_core.backend import KerasTensor\n+from keras_core.backend import any_symbolic_tensors\n+from keras_core.operations.operation import Operation\n+\n+\n+class Scatter(Operation):\n+    def call(self, indices, values, shape):\n+        return backend.core.scatter(indices, values, shape)\n+\n+    def compute_output_spec(self, indices, values, shape):\n+        return KerasTensor(shape, dtype=values.dtype)\n+\n+\n+def scatter(indices, values, shape):\n+    if any_symbolic_tensors((indices, values, shape)):\n+        return Scatter().symbolic_call(indices, values, shape)\n+    return backend.core.scatter(indices, values, shape)\n\n@@ -0,0 +1,64 @@\n+import numpy as np\n+import pytest\n+\n+from keras_core import backend\n+from keras_core import testing\n+from keras_core.operations import core\n+\n+\n+@pytest.mark.skipif(\n+    not backend.DYNAMIC_SHAPES_OK,\n+    reason=\"Backend does not support dynamic shapes\",\n+)\n+class CoreOpsDynamicShapeTest(testing.TestCase):\n+    pass\n+\n+\n+class CoreOpsStaticShapeTest(testing.TestCase):\n+    def test_scatter(self):\n+        # Requires dtype\n+        indices = np.array([[0]], dtype=\"int32\")\n+        values = np.array([0], dtype=\"int32\")\n+        shape = (8,)\n+        self.assertEqual(core.scatter(indices, values, shape).shape, (8,))\n+\n+\n+class CoreOpsCorrectnessTest(testing.TestCase):\n+    def test_scatter(self):\n+        # Test 1D\n+        indices = np.array([[1], [3], [4], [7]])\n+        values = np.array([9, 10, 11, 12])\n+        self.assertAllClose(\n+            core.scatter(indices, values, (8,)),\n+            [0, 9, 0, 10, 11, 0, 0, 12],\n+        )\n+        # Test 2D\n+        indices = np.array([[0, 1], [2, 0]])\n+        values = np.array([5, 10])\n+        self.assertAllClose(\n+            core.scatter(indices, values, (3, 2)), [[0, 5], [0, 0], [10, 0]]\n+        )\n+        # Test 3D\n+        indices = np.array([[1], [3]])\n+        values = np.array(\n+            [\n+                [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n+                [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n+            ]\n+        )\n+        self.assertAllClose(\n+            core.scatter(indices, values, (4, 4, 4)),\n+            [\n+                [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],\n+                [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n+                [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],\n+                [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n+            ],\n+        )\n+        # Test slices\n+        indices = np.array([[2], [4]])\n+        values = np.array([[1, 2, 3], [4, 5, 6]])\n+        self.assertAllClose(\n+            core.scatter(indices, values, (6, 3)),\n+            [[0, 0, 0], [0, 0, 0], [1, 2, 3], [0, 0, 0], [4, 5, 6], [0, 0, 0]],\n+        )\n\n@@ -18,6 +18,7 @@ argmin\n argsort\n array\n average\n+bincount\n broadcast_to\n ceil\n clip\n@@ -633,6 +634,28 @@ def average(x, axis=None, weights=None):\n     return backend.numpy.average(x, weights=weights, axis=axis)\n \n \n+class Bincount(Operation):\n+    def __init__(self, weights=None, minlength=0):\n+        super().__init__()\n+        self.weights = weights\n+        self.minlength = minlength\n+\n+    def call(self, x):\n+        return backend.numpy.bincount(\n+            x, weights=self.weights, minlength=self.minlength\n+        )\n+\n+    def compute_output_spec(self, x):\n+        out_shape = backend.numpy.amax(x) + 1\n+        return KerasTensor(out_shape, dtype=x.dtype)\n+\n+\n+def bincount(x, weights=None, minlength=0):\n+    if any_symbolic_tensors((x,)):\n+        return Bincount(weights=weights, minlength=minlength).symbolic_call(x)\n+    return backend.numpy.bincount(x, weights=weights, minlength=minlength)\n+\n+\n class BroadcastTo(Operation):\n     def __init__(self, shape):\n         super().__init__()\n\n@@ -2334,6 +2334,19 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n             np.average(x, axis=1, weights=weights_1d),\n         )\n \n+    def test_bincount(self):\n+        x = np.array([1, 1, 2, 3, 2, 4, 4, 5])\n+        weights = np.array([0, 0, 3, 2, 1, 1, 4, 2])\n+        minlength = 3\n+        self.assertAllClose(\n+            np.array(knp.bincount(x, weights=weights, minlength=minlength)),\n+            np.bincount(x, weights=weights, minlength=minlength),\n+        )\n+        self.assertAllClose(\n+            np.array(knp.Bincount(weights=weights, minlength=minlength)(x)),\n+            np.bincount(x, weights=weights, minlength=minlength),\n+        )\n+\n     def test_broadcast_to(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         self.assertAllClose(\n\n@@ -0,0 +1,626 @@\n+import re\n+import warnings\n+\n+import numpy as np\n+\n+from keras_core import backend\n+from keras_core import initializers\n+from keras_core import operations as ops\n+from keras_core.optimizers.schedules import learning_rate_schedule\n+from keras_core.saving import serialization_lib\n+from keras_core.utils.naming import auto_name\n+from keras_core.utils.tracking import Tracker\n+\n+\n+class Optimizer:\n+    def __init__(\n+        self,\n+        learning_rate,\n+        weight_decay=None,\n+        clipnorm=None,\n+        clipvalue=None,\n+        global_clipnorm=None,\n+        use_ema=False,\n+        ema_momentum=0.99,\n+        ema_overwrite_frequency=None,\n+        name=None,\n+    ):\n+        self.name = name\n+        self.weight_decay = weight_decay\n+        self.clipnorm = clipnorm\n+        self.global_clipnorm = global_clipnorm\n+        self.clipvalue = clipvalue\n+        self.use_ema = use_ema\n+\n+        if use_ema:\n+            # Verify the arguments related to EMA.\n+            if ema_momentum > 1 or ema_momentum < 0:\n+                raise ValueError(\n+                    \"`ema_momentum` must be in the range [0, 1]. \"\n+                    f\"Received: ema_momentum={ema_momentum}\"\n+                )\n+            if ema_overwrite_frequency and (\n+                not isinstance(ema_overwrite_frequency, int)\n+                or ema_overwrite_frequency < 1\n+            ):\n+                raise ValueError(\n+                    \"`ema_overwrite_frequency` must be an integer >= 1 or \"\n+                    \"None. Received: ema_overwrite_frequency=\"\n+                    f\"{ema_overwrite_frequency}\"\n+                )\n+        self.ema_momentum = ema_momentum\n+        self.ema_overwrite_frequency = ema_overwrite_frequency\n+\n+        if self.clipnorm is not None and self.global_clipnorm is not None:\n+            raise ValueError(\n+                \"Only one of `clipnorm` and `global_clipnorm` can \"\n+                f\"be set. Received: clipnorm={self.clipnorm}, \"\n+                f\"global_clipnorm={self.global_clipnorm}\"\n+            )\n+\n+        self.built = False\n+        # Note: dtype=\"int\" will resolve to int32 in JAX\n+        # (since int64 is disallowed in JAX) and to int64 in TF.\n+        self.iterations = backend.Variable(\n+            0, name=\"iteration\", dtype=\"int\", trainable=False\n+        )\n+        if isinstance(\n+            learning_rate, learning_rate_schedule.LearningRateSchedule\n+        ):\n+            self._learning_rate = learning_rate\n+        elif callable(learning_rate):\n+            self._learning_rate = learning_rate\n+        else:\n+            if not isinstance(learning_rate, float):\n+                raise ValueError(\n+                    \"Argument `learning_rate` should be float, or an instance \"\n+                    \"of LearningRateSchedule, or a callable \"\n+                    \"(that takes in the current iteration value \"\n+                    \"and returns the corresponding learning rate value). \"\n+                    f\"Received instead: learning_rate={learning_rate}\"\n+                )\n+            self._learning_rate = backend.Variable(\n+                learning_rate,\n+                name=\"learning_rate\",\n+                dtype=backend.floatx(),\n+                trainable=False,\n+            )\n+        self._variables = []\n+        self._trainable_variables = []\n+        self._tracker = Tracker(\n+            {\n+                \"variables\": (\n+                    lambda x: isinstance(x, backend.Variable),\n+                    self._variables,\n+                ),\n+            }\n+        )\n+        self._trainable_variables_indices = {}\n+\n+    def build(self, variables):\n+        for i, variable in enumerate(variables):\n+            self._trainable_variables_indices[self._var_key(variable)] = i\n+        self._trainable_variables = variables[:]\n+        self.built = True\n+\n+    def _var_key(self, variable):\n+        # Helper function to get a stable ID and the variable instance mapping.\n+        return id(variable)\n+\n+    @property\n+    def variables(self):\n+        return self._variables[:]\n+\n+    def _get_variable_index(self, variable):\n+        return self._trainable_variables_indices[self._var_key(variable)]\n+\n+    def add_variable(\n+        self,\n+        shape,\n+        initializer,\n+        dtype=None,\n+        name=None,\n+    ):\n+        self._check_super_called()\n+        initializer = initializers.get(initializer)\n+        variable = backend.Variable(\n+            initializer=initializer,\n+            shape=shape,\n+            dtype=dtype,\n+            trainable=False,\n+            name=name,\n+        )\n+        self._variables.append(variable)\n+        # Prevent double-tracking\n+        self._tracker.stored_ids[\"variables\"].add(self._var_key(variable))\n+        return variable\n+\n+    def add_variable_from_reference(self, reference_variable, name=None):\n+        \"\"\"Add an all-zeros variable with the shape and dtype of a reference\n+        variable.\n+        \"\"\"\n+        initializer = initializers.Zeros()\n+        name = name or auto_name(self.__class__.__name__)\n+        return self.add_variable(\n+            shape=reference_variable.shape,\n+            initializer=initializer,\n+            dtype=reference_variable.dtype,\n+            name=name,\n+        )\n+\n+    def _check_variables_are_known(self, variables):\n+        for v in variables:\n+            if self._var_key(v) not in self._trainable_variables_indices:\n+                raise ValueError(\n+                    f\"Unknown variable: {v}. This optimizer can only \"\n+                    \"be called for the variables it was originally built with. \"\n+                    \"When working with a new set of variables, you should \"\n+                    \"recreate a new optimizer instance.\"\n+                )\n+\n+    def update_step(self, gradient, variable, learning_rate):\n+        raise NotImplementedError\n+\n+    def apply_gradients(self, grads_and_vars):\n+        grads, trainable_variables = zip(*grads_and_vars)\n+        return self.apply(grads, trainable_variables)\n+\n+    def apply(self, grads, variables=None):\n+        \"\"\"\n+        `grads` should be a list of gradient tensors\n+        with 1:1 mapping to the list of variables the optimizer was built with.\n+\n+        `variables` can be provided on the first call to build the optimizer.\n+        \"\"\"\n+        grads = list(grads)\n+        if len(grads) == 0:\n+            # It is possible that the grad is empty. In this case,\n+            # `apply_gradients` is a no-op.\n+            return\n+\n+        if variables is None:\n+            if not self.built:\n+                raise ValueError(\n+                    \"When passing `grads` without `variables`, the optimizer \"\n+                    \"must already be built on a list of variables. \"\n+                    \"Call `optimizer.build(trainable_variables)` first. \"\n+                )\n+            if len(grads) != len(self._trainable_variables_indices):\n+                raise ValueError(\n+                    \"When passing `grads` as a list of gradient tensors, the \"\n+                    f\"gradients must match `optimizer.variables` one-to-on. \"\n+                    f\"Received a list of {len(grads)} gradients, but the \"\n+                    f\"optimizer is tracking {len(self._trainable_variables)} \"\n+                    \"trainable variables.\"\n+                )\n+            trainable_variables = self._trainable_variables\n+        else:\n+            trainable_variables = list(variables)\n+            # Optionally build optimizer.\n+            if not self.built:\n+                with ops.name_scope(self.name):\n+                    self.build(trainable_variables)\n+                self.built = True\n+            self._check_variables_are_known(trainable_variables)\n+\n+        grads_and_vars = list(zip(grads, self._trainable_variables))\n+\n+        with ops.name_scope(self.name):\n+            # Filter empty gradients.\n+            grads_and_vars = self._filter_empty_gradients(grads_and_vars)\n+            if len(list(grads_and_vars)) == 0:\n+                return\n+\n+            # Apply clipping and weight decay.\n+            grads, trainable_variables = zip(*grads_and_vars)\n+            grads = self._clip_gradients(grads)\n+            self._apply_weight_decay(trainable_variables)\n+\n+            # Apply gradient updates.\n+            self._internal_apply_gradients(\n+                list(zip(grads, trainable_variables))\n+            )\n+\n+            # Apply variable constraints after applying gradients.\n+            for variable in trainable_variables:\n+                if getattr(variable, \"constraint\", None) is not None:\n+                    variable.assign(variable.constraint(variable))\n+            return self.iterations\n+\n+    def _internal_apply_gradients(self, grads_and_vars):\n+        learning_rate = self._get_current_learning_rate()\n+        for grad, var in grads_and_vars:\n+            self.update_step(grad, var, learning_rate)\n+        self.iterations.assign(self.iterations + 1)\n+\n+    def stateless_apply(self, grads, trainable_variables, optimizer_variables):\n+        self._check_super_called()\n+\n+        if not self.built:\n+            raise ValueError(\n+                \"To call stateless_apply_gradients, {self.__class__.__name__} \"\n+                \"must be built (i.e. its variables must have been created). \"\n+                \"You can build it via `optimizer.build(trainable_variables)`.\"\n+            )\n+        if len(optimizer_variables) != len(self.variables):\n+            raise ValueError(\n+                \"Argument `optimizer_variables` must be a list of tensors \"\n+                f\"corresponding 1:1 to {self.__class__.__name__}().variables. \"\n+                f\"Received list with length {len(optimizer_variables)}, but \"\n+                f\"expected {len(self.variables)} variables.\"\n+            )\n+        if len(trainable_variables) != len(self._trainable_variables):\n+            raise ValueError(\n+                \"Argument `optimizer_variables` must be a list of tensors \"\n+                \"corresponding 1:1 to the trainable variables list that \"\n+                \"the optimizer was built with. Received \"\n+                f\"len(trainable_variables) == {len(trainable_variables)} \"\n+                \"whereas the optimizer was built with \"\n+                f\"{len(self._trainable_variables)} variables.\"\n+            )\n+\n+        # Gather variable mapping\n+        mapping = list(\n+            zip(self._trainable_variables, trainable_variables)\n+        ) + list(zip(self.variables, optimizer_variables))\n+\n+        # Call in stateless scope\n+        with backend.StatelessScope(state_mapping=mapping) as scope:\n+            self.apply(grads)\n+\n+        # Gather updated variables\n+        trainable_variables = []\n+        for v in self._trainable_variables:\n+            new_v = scope.get_current_value(v)\n+            if new_v is not None:\n+                trainable_variables.append(new_v)\n+            else:\n+                trainable_variables.append(v)\n+        optimizer_variables = []\n+        for v in self.variables:\n+            new_v = scope.get_current_value(v)\n+            if new_v is not None:\n+                optimizer_variables.append(new_v)\n+            else:\n+                optimizer_variables.append(v)\n+        return trainable_variables, optimizer_variables\n+\n+    @property\n+    def learning_rate(self):\n+        return self._get_current_learning_rate()\n+\n+    @learning_rate.setter\n+    def learning_rate(self, learning_rate):\n+        if isinstance(\n+            learning_rate, learning_rate_schedule.LearningRateSchedule\n+        ):\n+            self._learning_rate = learning_rate\n+        elif callable(learning_rate):\n+            self._learning_rate = learning_rate\n+        else:\n+            if isinstance(\n+                self._learning_rate, learning_rate_schedule.LearningRateSchedule\n+            ):\n+                raise TypeError(\n+                    \"This optimizer was created with a `LearningRateSchedule`\"\n+                    \" object as its `learning_rate` constructor argument, \"\n+                    \"hence its learning rate is not settable. If you need the\"\n+                    \" learning rate to be settable, you should instantiate \"\n+                    \"the optimizer with a float `learning_rate` argument.\"\n+                )\n+            self._learning_rate.assign(learning_rate)\n+\n+    def save_own_variables(self, store):\n+        \"\"\"Get the state of this optimizer object.\"\"\"\n+        for i, variable in enumerate(self.variables):\n+            store[str(i)] = np.array(variable)\n+\n+    def load_own_variables(self, store):\n+        \"\"\"Set the state of this optimizer object.\"\"\"\n+        if len(store.keys()) != len(self.variables):\n+            msg = (\n+                f\"Skipping variable loading for optimizer '{self.name}', \"\n+                f\"because it has {len(self.variables)} variables whereas \"\n+                f\"the saved optimizer has {len(store.keys())} variables. \"\n+            )\n+            if len(self.variables) == 0:\n+                msg += (\n+                    \"This is likely because the optimizer has not been \"\n+                    \"called/built yet.\"\n+                )\n+            warnings.warn(msg, stacklevel=2)\n+            return\n+        for i, variable in enumerate(self.variables):\n+            variable.assign(store[str(i)])\n+\n+    def _get_current_learning_rate(self):\n+        if isinstance(\n+            self._learning_rate, learning_rate_schedule.LearningRateSchedule\n+        ):\n+            return self._learning_rate(self.iterations)\n+        elif callable(self._learning_rate):\n+            return self._learning_rate(self.iterations)\n+        return self._learning_rate\n+\n+    def _filter_empty_gradients(self, grads_and_vars):\n+        filtered = [(g, v) for g, v in grads_and_vars if g is not None]\n+        if not filtered:\n+            raise ValueError(\"No gradients provided for any variable.\")\n+        if len(filtered) < len(grads_and_vars):\n+            missing_grad_vars = [v for g, v in grads_and_vars if g is None]\n+            warnings.warn(\n+                \"Gradients do not exist for variables \"\n+                f\"{[v.name for v in missing_grad_vars]} when minimizing the \"\n+                \"loss. If you're using `model.compile()`, did you forget to \"\n+                \"provide a `loss` argument?\"\n+            )\n+        return filtered\n+\n+    def _clip_gradients(self, grads):\n+        if self.clipnorm and self.clipnorm > 0:\n+            clipped_grads = []\n+            for g in grads:\n+                if g is None:\n+                    clipped_grads.append(g)\n+                else:\n+                    clipped_grads.append(clip_by_norm(g, self.clipnorm))\n+            return clipped_grads\n+\n+        if self.global_clipnorm and self.global_clipnorm > 0:\n+            return clip_by_global_norm(grads, self.global_clipnorm)\n+\n+        if self.clipvalue and self.clipvalue > 0:\n+            clipped_grads = []\n+            for g in grads:\n+                if g is None:\n+                    clipped_grads.append(g)\n+                else:\n+                    clipped_grads.append(\n+                        ops.clip(g, -self.clipvalue, self.clipvalue)\n+                    )\n+            return clipped_grads\n+        return grads\n+\n+    def exclude_from_weight_decay(self, var_list=None, var_names=None):\n+        \"\"\"Exclude variables from weight decay.\n+\n+        This method must be called before the optimizer's `build` method is\n+        called. You can set specific variables to exclude out, or set a list of\n+        strings as the anchor words, if any of which appear in a variable's\n+        name, then the variable is excluded.\n+\n+        Args:\n+            var_list: A list of `tf.Variable`s to exclude from weight decay.\n+            var_names: A list of strings. If any string in `var_names` appear\n+                in the model variable's name, then this model variable is\n+                excluded from weight decay. For example, `var_names=['bias']`\n+                excludes all bias variables from weight decay.\n+        \"\"\"\n+        if hasattr(self, \"_built\") and self._built:\n+            raise ValueError(\n+                \"`exclude_from_weight_decay()` can only be configued before \"\n+                \"the optimizer is built.\"\n+            )\n+\n+        if var_list:\n+            self._exclude_from_weight_decay = [\n+                self._var_key(variable) for variable in var_list\n+            ]\n+        else:\n+            self._exclude_from_weight_decay = []\n+        self._exclude_from_weight_decay_names = var_names or []\n+\n+    def _use_weight_decay(self, variable):\n+        exclude_from_weight_decay = getattr(\n+            self, \"_exclude_from_weight_decay\", []\n+        )\n+        exclude_from_weight_decay_names = getattr(\n+            self, \"_exclude_from_weight_decay_names\", []\n+        )\n+        variable_id = self._var_key(variable)\n+        for exclude_id in exclude_from_weight_decay:\n+            if variable_id == exclude_id:\n+                return False\n+        for name in exclude_from_weight_decay_names:\n+            if re.search(name, variable.name) is not None:\n+                return False\n+        return True\n+\n+    def _apply_weight_decay(self, variables):\n+        if self.weight_decay is None:\n+            return\n+        for variable in variables:\n+            if self._use_weight_decay(variable):\n+                lr = ops.cast(self._get_current_learning_rate(), variable.dtype)\n+                wd = ops.cast(self.weight_decay, variable.dtype)\n+                variable.assign(variable - variable * wd * lr)\n+\n+    def _check_super_called(self):\n+        if not hasattr(self, \"_tracker\"):\n+            raise RuntimeError(\n+                f\"In optimizer '{self.__class__.__name__}', you forgot to call \"\n+                \"`super().__init__()` in the `__init__()` method. \"\n+                \"Go add it!\"\n+            )\n+\n+    def _update_model_variables_moving_average(self, var_list):\n+        \"\"\"Update the stored moving average using the latest value.\"\"\"\n+        if self.use_ema:\n+            for var, average in zip(\n+                var_list, self._model_variables_moving_average\n+            ):\n+                average.assign(\n+                    self.ema_momentum * average + (1 - self.ema_momentum) * var\n+                )\n+\n+    def _overwrite_model_variables_with_average_value(self, var_list):\n+        \"\"\"Overwrite model variables with its moving average.\"\"\"\n+        if len(var_list) != len(self._model_variables_moving_average):\n+            raise ValueError(\n+                f\"The length of model variables ({len(var_list)}) to \"\n+                \"override does not match the length of model variables \"\n+                \"stored in the optimizer \"\n+                f\"({len(self._model_variables_moving_average)}). Please \"\n+                \"check if the optimizer was called on your model.\"\n+            )\n+        self._overwrite_model_variables_with_average_value_helper(var_list)\n+\n+    def _overwrite_model_variables_with_average_value_helper(self, var_list):\n+        \"\"\"Helper function that overwrites model variables.\"\"\"\n+        for var, average_var in zip(\n+            var_list, self._model_variables_moving_average\n+        ):\n+            var.assign(average_var)\n+\n+    def finalize_variable_values(self, var_list):\n+        \"\"\"Set the final value of model's trainable variables.\n+\n+        Sometimes there are some extra steps before ending the variable updates,\n+        such as overriding the model variables with its average value.\n+\n+        Args:\n+          var_list: list of model variables.\n+        \"\"\"\n+        if self.use_ema:\n+            # If the optimizer uses EMA, then when finalizing, we replace the\n+            # model variable value with its moving average stored inside\n+            # optimizer.\n+            self._overwrite_model_variables_with_average_value(var_list)\n+\n+    def get_config(self):\n+        \"\"\"Returns the config of the optimizer.\n+\n+        An optimizer config is a Python dictionary (serializable)\n+        containing the configuration of an optimizer.\n+        The same optimizer can be reinstantiated later\n+        (without any saved state) from this configuration.\n+\n+        Subclass optimizer should override this method to include other\n+        hyperparameters.\n+\n+        Returns:\n+            Python dictionary.\n+        \"\"\"\n+\n+        if isinstance(\n+            self._learning_rate, learning_rate_schedule.LearningRateSchedule\n+        ):\n+            learning_rate = learning_rate_schedule.serialize(\n+                self._learning_rate\n+            )\n+        elif isinstance(self._learning_rate, backend.Variable):\n+            learning_rate = float(self._learning_rate.numpy())\n+        elif ops.is_tensor(self._learning_rate):\n+            learning_rate = float(self._learning_rate)\n+        elif callable(self._learning_rate):\n+            learning_rate = serialization_lib.serialize_keras_object(\n+                self._learning_rate\n+            )\n+\n+        config = {\n+            \"name\": self.name,\n+            \"learning_rate\": learning_rate,\n+            \"weight_decay\": self.weight_decay,\n+            \"clipnorm\": self.clipnorm,\n+            \"global_clipnorm\": self.global_clipnorm,\n+            \"clipvalue\": self.clipvalue,\n+            \"use_ema\": self.use_ema,\n+            \"ema_momentum\": self.ema_momentum,\n+            \"ema_overwrite_frequency\": self.ema_overwrite_frequency,\n+        }\n+        return config\n+\n+    @classmethod\n+    def from_config(cls, config, custom_objects=None):\n+        \"\"\"Creates an optimizer from its config.\n+\n+        This method is the reverse of `get_config`, capable of instantiating the\n+        same optimizer from the config dictionary.\n+\n+        Args:\n+            config: A Python dictionary, typically the output of get_config.\n+            custom_objects: A Python dictionary mapping names to additional\n+              user-defined Python objects needed to recreate this optimizer.\n+\n+        Returns:\n+            An optimizer instance.\n+        \"\"\"\n+        if \"learning_rate\" in config:\n+            if isinstance(config[\"learning_rate\"], dict):\n+                config[\n+                    \"learning_rate\"\n+                ] = serialization_lib.deserialize_keras_object(\n+                    config[\"learning_rate\"], custom_objects=custom_objects\n+                )\n+        return cls(**config)\n+\n+\n+base_optimizer_keyword_args = \"\"\"name: String. The name to use\n+          for momentum accumulator weights created by\n+          the optimizer.\n+      weight_decay: Float, defaults to None. If set, weight decay is applied.\n+      clipnorm: Float. If set, the gradient of each weight is individually\n+          clipped so that its norm is no higher than this value.\n+      clipvalue: Float. If set, the gradient of each weight is clipped to be no\n+          higher than this value.\n+      global_clipnorm: Float. If set, the gradient of all weights is clipped so\n+          that their global norm is no higher than this value.\n+      use_ema: Boolean, defaults to False. If True, exponential moving average\n+          (EMA) is applied. EMA consists of computing an exponential moving\n+          average of the weights of the model (as the weight values change after\n+          each training batch), and periodically overwriting the weights with\n+          their moving average.\n+      ema_momentum: Float, defaults to 0.99. Only used if `use_ema=True`.\n+          This is the momentum to use when computing\n+          the EMA of the model's weights:\n+          `new_average = ema_momentum * old_average + (1 - ema_momentum) *\n+          current_variable_value`.\n+      ema_overwrite_frequency: Int or None, defaults to None. Only used if\n+          `use_ema=True`. Every `ema_overwrite_frequency` steps of iterations,\n+          we overwrite the model variable by its moving average.\n+          If None, the optimizer\n+          does not overwrite model variables in the middle of training, and you\n+          need to explicitly overwrite the variables at the end of training\n+          by calling `optimizer.finalize_variable_values()`\n+          (which updates the model\n+          variables in-place). When using the built-in `fit()` training loop,\n+          this happens automatically after the last epoch,\n+          and you don't need to do anything.\"\"\"\n+\n+\n+def clip_by_norm(values, clip_norm, axes=None):\n+    # Calculate L2-norm, clip elements by ratio of clip_norm to L2-norm\n+    l2sum = ops.sum(values * values, axes, keepdims=True)\n+    pred = l2sum > 0\n+    # Two-tap tf.where trick to bypass NaN gradients\n+    l2sum_safe = ops.where(pred, l2sum, ops.ones_like(l2sum))\n+    l2norm = ops.where(pred, ops.sqrt(l2sum_safe), l2sum)\n+    intermediate = values * clip_norm\n+    values_clip = intermediate / ops.maximum(l2norm, clip_norm)\n+    return values_clip\n+\n+\n+def global_norm(value_list):\n+    \"\"\"Computes the global norm of multiple tensors.\"\"\"\n+    squared_norms = []\n+    for v in value_list:\n+        if v is not None:\n+            squared_norms.append(ops.sum(ops.square(v)))\n+    squared_norm = ops.sum(ops.stack(squared_norms))\n+    return ops.sqrt(squared_norm)\n+\n+\n+def clip_by_global_norm(value_list, clip_norm):\n+    use_norm = global_norm(value_list)\n+    # Calculate L2-norm, clip elements by ratio of clip_norm to L2-norm\n+    scale_for_finite = clip_norm * ops.minimum(1.0 / use_norm, 1.0 / clip_norm)\n+    # If use_norm is any finite number, this is a no-op. For inf/-inf/NaN,\n+    # this will make scale NaN.\n+    scale = scale_for_finite + (use_norm - use_norm)\n+    values_clipped = []\n+    for v in value_list:\n+        if v is None:\n+            values_clipped.append(None)\n+        else:\n+            values_clipped.append(v * scale)\n+    return values_clipped\n\n@@ -1,618 +1,18 @@\n-import re\n-import warnings\n-\n-import numpy as np\n-\n from keras_core import backend\n-from keras_core import initializers\n-from keras_core import operations as ops\n from keras_core.api_export import keras_core_export\n-from keras_core.optimizers.schedules import learning_rate_schedule\n-from keras_core.saving import serialization_lib\n-from keras_core.utils.naming import auto_name\n-from keras_core.utils.tracking import Tracker\n+from keras_core.optimizers import base_optimizer\n \n+if backend.backend() == \"tensorflow\":\n+    from keras_core.backend.tensorflow import optimizer as tf_optimizer\n \n-@keras_core_export([\"keras_core.Optimizer\", \"keras_core.optimizers.Optimizer\"])\n-class Optimizer:\n-    def __init__(\n-        self,\n-        learning_rate,\n-        weight_decay=None,\n-        clipnorm=None,\n-        clipvalue=None,\n-        global_clipnorm=None,\n-        use_ema=False,\n-        ema_momentum=0.99,\n-        ema_overwrite_frequency=None,\n-        name=None,\n-    ):\n-        self.name = name\n-        self.weight_decay = weight_decay\n-        self.clipnorm = clipnorm\n-        self.global_clipnorm = global_clipnorm\n-        self.clipvalue = clipvalue\n-        self.use_ema = use_ema\n-\n-        if use_ema:\n-            # Verify the arguments related to EMA.\n-            if ema_momentum > 1 or ema_momentum < 0:\n-                raise ValueError(\n-                    \"`ema_momentum` must be in the range [0, 1]. \"\n-                    f\"Received: ema_momentum={ema_momentum}\"\n-                )\n-            if ema_overwrite_frequency and (\n-                not isinstance(ema_overwrite_frequency, int)\n-                or ema_overwrite_frequency < 1\n-            ):\n-                raise ValueError(\n-                    \"`ema_overwrite_frequency` must be an integer >= 1 or \"\n-                    \"None. Received: ema_overwrite_frequency=\"\n-                    f\"{ema_overwrite_frequency}\"\n-                )\n-        self.ema_momentum = ema_momentum\n-        self.ema_overwrite_frequency = ema_overwrite_frequency\n-\n-        if self.clipnorm is not None and self.global_clipnorm is not None:\n-            raise ValueError(\n-                \"Only one of `clipnorm` and `global_clipnorm` can \"\n-                f\"be set. Received: clipnorm={self.clipnorm}, \"\n-                f\"global_clipnorm={self.global_clipnorm}\"\n-            )\n-\n-        self.built = False\n-        # Note: dtype=\"int\" will resolve to int32 in JAX\n-        # (since int64 is disallowed in JAX) and to int64 in TF.\n-        self.iterations = backend.Variable(\n-            0, name=\"iteration\", dtype=\"int\", trainable=False\n-        )\n-        if isinstance(\n-            learning_rate, learning_rate_schedule.LearningRateSchedule\n-        ):\n-            self._learning_rate = learning_rate\n-        elif callable(learning_rate):\n-            self._learning_rate = learning_rate\n+    Optimizer = tf_optimizer.TFOptimizer\n else:\n-            if not isinstance(learning_rate, float):\n-                raise ValueError(\n-                    \"Argument `learning_rate` should be float, or an instance \"\n-                    \"of LearningRateSchedule, or a callable \"\n-                    \"(that takes in the current iteration value \"\n-                    \"and returns the corresponding learning rate value). \"\n-                    f\"Received instead: learning_rate={learning_rate}\"\n-                )\n-            self._learning_rate = backend.Variable(\n-                learning_rate,\n-                name=\"learning_rate\",\n-                dtype=backend.floatx(),\n-                trainable=False,\n-            )\n-        self._variables = []\n-        self._trainable_variables = []\n-        self._tracker = Tracker(\n-            {\n-                \"variables\": (\n-                    lambda x: isinstance(x, backend.Variable),\n-                    self._variables,\n-                ),\n-            }\n-        )\n-        self._trainable_variables_indices = {}\n+    Optimizer = base_optimizer.Optimizer\n \n-    def build(self, variables):\n-        for i, variable in enumerate(variables):\n-            self._trainable_variables_indices[id(variable)] = i\n-        self._trainable_variables = variables[:]\n-        self.built = True\n \n-    @property\n-    def variables(self):\n-        return self._variables[:]\n-\n-    def _get_variable_index(self, variable):\n-        return self._trainable_variables_indices[id(variable)]\n-\n-    def add_variable(\n-        self,\n-        shape,\n-        initializer,\n-        dtype=None,\n-        name=None,\n-    ):\n-        self._check_super_called()\n-        initializer = initializers.get(initializer)\n-        variable = backend.Variable(\n-            initializer=initializer,\n-            shape=shape,\n-            dtype=dtype,\n-            trainable=False,\n-            name=name,\n-        )\n-        self._variables.append(variable)\n-        # Prevent double-tracking\n-        self._tracker.stored_ids[\"variables\"].add(id(variable))\n-        return variable\n-\n-    def add_variable_from_reference(self, reference_variable, name=None):\n-        \"\"\"Add an all-zeros variable with the shape and dtype of a reference\n-        variable.\n-        \"\"\"\n-        initializer = initializers.Zeros()\n-        name = name or auto_name(self.__class__.__name__)\n-        return self.add_variable(\n-            shape=reference_variable.shape,\n-            initializer=initializer,\n-            dtype=reference_variable.dtype,\n-            name=name,\n+keras_core_export([\"keras_core.Optimizer\", \"keras_core.optimizers.Optimizer\"])(\n+    Optimizer\n )\n \n-    def _check_variables_are_known(self, variables):\n-        for v in variables:\n-            if id(v) not in self._trainable_variables_indices:\n-                raise ValueError(\n-                    f\"Unknown variable: {v}. This optimizer can only \"\n-                    \"be called for the variables it was originally built with. \"\n-                    \"When working with a new set of variables, you should \"\n-                    \"recreate a new optimizer instance.\"\n-                )\n \n-    def update_step(self, gradient, variable, learning_rate):\n-        raise NotImplementedError\n-\n-    def apply_gradients(self, grads_and_vars):\n-        grads, trainable_variables = zip(*grads_and_vars)\n-        return self.apply(grads, trainable_variables)\n-\n-    def apply(self, grads, variables=None):\n-        \"\"\"\n-        `grads` should be a list of gradient tensors\n-        with 1:1 mapping to the list of variables the optimizer was built with.\n-\n-        `variables` can be provided on the first call to build the optimizer.\n-        \"\"\"\n-        grads = list(grads)\n-        if len(grads) == 0:\n-            # It is possible that the grad is empty. In this case,\n-            # `apply_gradients` is a no-op.\n-            return\n-\n-        if variables is None:\n-            if not self.built:\n-                raise ValueError(\n-                    \"When passing `grads` without `variables`, the optimizer \"\n-                    \"must already be built on a list of variables. \"\n-                    \"Call `optimizer.build(trainable_variables)` first. \"\n-                )\n-            if len(grads) != len(self._trainable_variables_indices):\n-                raise ValueError(\n-                    \"When passing `grads` as a list of gradient tensors, the \"\n-                    f\"gradients must match `optimizer.variables` one-to-on. \"\n-                    f\"Received a list of {len(grads)} gradients, but the \"\n-                    f\"optimizer is tracking {len(self._trainable_variables)} \"\n-                    \"trainable variables.\"\n-                )\n-            trainable_variables = self._trainable_variables\n-        else:\n-            trainable_variables = list(variables)\n-            # Optionally build optimizer.\n-            if not self.built:\n-                with ops.name_scope(self.name):\n-                    self.build(trainable_variables)\n-                self.built = True\n-            self._check_variables_are_known(trainable_variables)\n-\n-        grads_and_vars = list(zip(grads, self._trainable_variables))\n-\n-        with ops.name_scope(self.name):\n-            # Filter empty gradients.\n-            grads_and_vars = self._filter_empty_gradients(grads_and_vars)\n-            if len(list(grads_and_vars)) == 0:\n-                return\n-\n-            # Apply clipping and weight decay.\n-            grads, trainable_variables = zip(*grads_and_vars)\n-            grads = self._clip_gradients(grads)\n-            self._apply_weight_decay(trainable_variables)\n-\n-            # Apply gradient updates.\n-            learning_rate = self._get_current_learning_rate()\n-            for grad, var in zip(grads, trainable_variables):\n-                self.update_step(grad, var, learning_rate)\n-            self.iterations.assign(self.iterations + 1)\n-\n-            # Apply variable constraints after applying gradients.\n-            for variable in trainable_variables:\n-                if getattr(variable, \"constraint\", None) is not None:\n-                    variable.assign(variable.constraint(variable))\n-\n-    def stateless_apply(self, grads, trainable_variables, optimizer_variables):\n-        self._check_super_called()\n-\n-        if not self.built:\n-            raise ValueError(\n-                \"To call stateless_apply_gradients, {self.__class__.__name__} \"\n-                \"must be built (i.e. its variables must have been created). \"\n-                \"You can build it via `optimizer.build(trainable_variables)`.\"\n-            )\n-        if len(optimizer_variables) != len(self.variables):\n-            raise ValueError(\n-                \"Argument `optimizer_variables` must be a list of tensors \"\n-                f\"corresponding 1:1 to {self.__class__.__name__}().variables. \"\n-                f\"Received list with length {len(optimizer_variables)}, but \"\n-                f\"expected {len(self.variables)} variables.\"\n-            )\n-        if len(trainable_variables) != len(self._trainable_variables):\n-            raise ValueError(\n-                \"Argument `optimizer_variables` must be a list of tensors \"\n-                \"corresponding 1:1 to the trainable variables list that \"\n-                \"the optimizer was built with. Received \"\n-                f\"len(trainable_variables) == {len(trainable_variables)} \"\n-                \"whereas the optimizer was built with \"\n-                f\"{len(self._trainable_variables)} variables.\"\n-            )\n-\n-        # Gather variable mapping\n-        mapping = list(\n-            zip(self._trainable_variables, trainable_variables)\n-        ) + list(zip(self.variables, optimizer_variables))\n-\n-        # Call in stateless scope\n-        with backend.StatelessScope(state_mapping=mapping) as scope:\n-            self.apply(grads)\n-\n-        # Gather updated variables\n-        trainable_variables = []\n-        for v in self._trainable_variables:\n-            new_v = scope.get_current_value(v)\n-            if new_v is not None:\n-                trainable_variables.append(new_v)\n-            else:\n-                trainable_variables.append(v)\n-        optimizer_variables = []\n-        for v in self.variables:\n-            new_v = scope.get_current_value(v)\n-            if new_v is not None:\n-                optimizer_variables.append(new_v)\n-            else:\n-                optimizer_variables.append(v)\n-        return trainable_variables, optimizer_variables\n-\n-    @property\n-    def learning_rate(self):\n-        return self._get_current_learning_rate()\n-\n-    @learning_rate.setter\n-    def learning_rate(self, learning_rate):\n-        if isinstance(\n-            learning_rate, learning_rate_schedule.LearningRateSchedule\n-        ):\n-            self._learning_rate = learning_rate\n-        elif callable(learning_rate):\n-            self._learning_rate = learning_rate\n-        else:\n-            if isinstance(\n-                self._learning_rate, learning_rate_schedule.LearningRateSchedule\n-            ):\n-                raise TypeError(\n-                    \"This optimizer was created with a `LearningRateSchedule`\"\n-                    \" object as its `learning_rate` constructor argument, \"\n-                    \"hence its learning rate is not settable. If you need the\"\n-                    \" learning rate to be settable, you should instantiate \"\n-                    \"the optimizer with a float `learning_rate` argument.\"\n-                )\n-            self._learning_rate.assign(learning_rate)\n-\n-    def save_own_variables(self, store):\n-        \"\"\"Get the state of this optimizer object.\"\"\"\n-        for i, variable in enumerate(self.variables):\n-            store[str(i)] = np.array(variable)\n-\n-    def load_own_variables(self, store):\n-        \"\"\"Set the state of this optimizer object.\"\"\"\n-        if len(store.keys()) != len(self.variables):\n-            msg = (\n-                f\"Skipping variable loading for optimizer '{self.name}', \"\n-                f\"because it has {len(self.variables)} variables whereas \"\n-                f\"the saved optimizer has {len(store.keys())} variables. \"\n-            )\n-            if len(self.variables) == 0:\n-                msg += (\n-                    \"This is likely because the optimizer has not been \"\n-                    \"called/built yet.\"\n-                )\n-            warnings.warn(msg, stacklevel=2)\n-            return\n-        for i, variable in enumerate(self.variables):\n-            variable.assign(store[str(i)])\n-\n-    def _get_current_learning_rate(self):\n-        if isinstance(\n-            self._learning_rate, learning_rate_schedule.LearningRateSchedule\n-        ):\n-            return self._learning_rate(self.iterations)\n-        elif callable(self._learning_rate):\n-            return self._learning_rate(self.iterations)\n-        return self._learning_rate\n-\n-    def _filter_empty_gradients(self, grads_and_vars):\n-        filtered = [(g, v) for g, v in grads_and_vars if g is not None]\n-        if not filtered:\n-            raise ValueError(\"No gradients provided for any variable.\")\n-        if len(filtered) < len(grads_and_vars):\n-            missing_grad_vars = [v for g, v in grads_and_vars if g is None]\n-            warnings.warn(\n-                \"Gradients do not exist for variables \"\n-                f\"{[v.name for v in missing_grad_vars]} when minimizing the \"\n-                \"loss. If you're using `model.compile()`, did you forget to \"\n-                \"provide a `loss` argument?\"\n-            )\n-        return filtered\n-\n-    def _clip_gradients(self, grads):\n-        if self.clipnorm and self.clipnorm > 0:\n-            clipped_grads = []\n-            for g in grads:\n-                if g is None:\n-                    clipped_grads.append(g)\n-                else:\n-                    clipped_grads.append(clip_by_norm(g, self.clipnorm))\n-            return clipped_grads\n-\n-        if self.global_clipnorm and self.global_clipnorm > 0:\n-            return clip_by_global_norm(grads, self.global_clipnorm)\n-\n-        if self.clipvalue and self.clipvalue > 0:\n-            clipped_grads = []\n-            for g in grads:\n-                if g is None:\n-                    clipped_grads.append(g)\n-                else:\n-                    clipped_grads.append(\n-                        ops.clip(g, -self.clipvalue, self.clipvalue)\n-                    )\n-            return clipped_grads\n-        return grads\n-\n-    def exclude_from_weight_decay(self, var_list=None, var_names=None):\n-        \"\"\"Exclude variables from weight decay.\n-\n-        This method must be called before the optimizer's `build` method is\n-        called. You can set specific variables to exclude out, or set a list of\n-        strings as the anchor words, if any of which appear in a variable's\n-        name, then the variable is excluded.\n-\n-        Args:\n-            var_list: A list of `tf.Variable`s to exclude from weight decay.\n-            var_names: A list of strings. If any string in `var_names` appear\n-                in the model variable's name, then this model variable is\n-                excluded from weight decay. For example, `var_names=['bias']`\n-                excludes all bias variables from weight decay.\n-        \"\"\"\n-        if hasattr(self, \"_built\") and self._built:\n-            raise ValueError(\n-                \"`exclude_from_weight_decay()` can only be configued before \"\n-                \"the optimizer is built.\"\n-            )\n-\n-        if var_list:\n-            self._exclude_from_weight_decay = [\n-                id(variable) for variable in var_list\n-            ]\n-        else:\n-            self._exclude_from_weight_decay = []\n-        self._exclude_from_weight_decay_names = var_names or []\n-\n-    def _use_weight_decay(self, variable):\n-        exclude_from_weight_decay = getattr(\n-            self, \"_exclude_from_weight_decay\", []\n-        )\n-        exclude_from_weight_decay_names = getattr(\n-            self, \"_exclude_from_weight_decay_names\", []\n-        )\n-        variable_id = id(variable)\n-        for exclude_id in exclude_from_weight_decay:\n-            if variable_id == exclude_id:\n-                return False\n-        for name in exclude_from_weight_decay_names:\n-            if re.search(name, variable.name) is not None:\n-                return False\n-        return True\n-\n-    def _apply_weight_decay(self, variables):\n-        if self.weight_decay is None:\n-            return\n-        for variable in variables:\n-            if self._use_weight_decay(variable):\n-                lr = ops.cast(self._get_current_learning_rate(), variable.dtype)\n-                wd = ops.cast(self.weight_decay, variable.dtype)\n-                variable.assign(variable - variable * wd * lr)\n-\n-    def _check_super_called(self):\n-        if not hasattr(self, \"_tracker\"):\n-            raise RuntimeError(\n-                f\"In optimizer '{self.__class__.__name__}', you forgot to call \"\n-                \"`super().__init__()` in the `__init__()` method. \"\n-                \"Go add it!\"\n-            )\n-\n-    def _update_model_variables_moving_average(self, var_list):\n-        \"\"\"Update the stored moving average using the latest value.\"\"\"\n-        if self.use_ema:\n-            for var, average in zip(\n-                var_list, self._model_variables_moving_average\n-            ):\n-                average.assign(\n-                    self.ema_momentum * average + (1 - self.ema_momentum) * var\n-                )\n-\n-    def _overwrite_model_variables_with_average_value(self, var_list):\n-        \"\"\"Overwrite model variables with its moving average.\"\"\"\n-        if len(var_list) != len(self._model_variables_moving_average):\n-            raise ValueError(\n-                f\"The length of model variables ({len(var_list)}) to \"\n-                \"override does not match the length of model variables \"\n-                \"stored in the optimizer \"\n-                f\"({len(self._model_variables_moving_average)}). Please \"\n-                \"check if the optimizer was called on your model.\"\n-            )\n-        self._overwrite_model_variables_with_average_value_helper(var_list)\n-\n-    def _overwrite_model_variables_with_average_value_helper(self, var_list):\n-        \"\"\"Helper function that overwrites model variables.\"\"\"\n-        for var, average_var in zip(\n-            var_list, self._model_variables_moving_average\n-        ):\n-            var.assign(average_var)\n-\n-    def finalize_variable_values(self, var_list):\n-        \"\"\"Set the final value of model's trainable variables.\n-\n-        Sometimes there are some extra steps before ending the variable updates,\n-        such as overriding the model variables with its average value.\n-\n-        Args:\n-          var_list: list of model variables.\n-        \"\"\"\n-        if self.use_ema:\n-            # If the optimizer uses EMA, then when finalizing, we replace the\n-            # model variable value with its moving average stored inside\n-            # optimizer.\n-            self._overwrite_model_variables_with_average_value(var_list)\n-\n-    def get_config(self):\n-        \"\"\"Returns the config of the optimizer.\n-\n-        An optimizer config is a Python dictionary (serializable)\n-        containing the configuration of an optimizer.\n-        The same optimizer can be reinstantiated later\n-        (without any saved state) from this configuration.\n-\n-        Subclass optimizer should override this method to include other\n-        hyperparameters.\n-\n-        Returns:\n-            Python dictionary.\n-        \"\"\"\n-\n-        if isinstance(\n-            self._learning_rate, learning_rate_schedule.LearningRateSchedule\n-        ):\n-            learning_rate = learning_rate_schedule.serialize(\n-                self._learning_rate\n-            )\n-        elif isinstance(self._learning_rate, backend.Variable):\n-            learning_rate = float(self._learning_rate.numpy())\n-        elif ops.is_tensor(self._learning_rate):\n-            learning_rate = float(self._learning_rate)\n-        elif callable(self._learning_rate):\n-            learning_rate = serialization_lib.serialize_keras_object(\n-                self._learning_rate\n-            )\n-\n-        config = {\n-            \"name\": self.name,\n-            \"learning_rate\": learning_rate,\n-            \"weight_decay\": self.weight_decay,\n-            \"clipnorm\": self.clipnorm,\n-            \"global_clipnorm\": self.global_clipnorm,\n-            \"clipvalue\": self.clipvalue,\n-            \"use_ema\": self.use_ema,\n-            \"ema_momentum\": self.ema_momentum,\n-            \"ema_overwrite_frequency\": self.ema_overwrite_frequency,\n-        }\n-        return config\n-\n-    @classmethod\n-    def from_config(cls, config, custom_objects=None):\n-        \"\"\"Creates an optimizer from its config.\n-\n-        This method is the reverse of `get_config`, capable of instantiating the\n-        same optimizer from the config dictionary.\n-\n-        Args:\n-            config: A Python dictionary, typically the output of get_config.\n-            custom_objects: A Python dictionary mapping names to additional\n-              user-defined Python objects needed to recreate this optimizer.\n-\n-        Returns:\n-            An optimizer instance.\n-        \"\"\"\n-        if \"learning_rate\" in config:\n-            if isinstance(config[\"learning_rate\"], dict):\n-                config[\n-                    \"learning_rate\"\n-                ] = serialization_lib.deserialize_keras_object(\n-                    config[\"learning_rate\"], custom_objects=custom_objects\n-                )\n-        return cls(**config)\n-\n-\n-base_optimizer_keyword_args = \"\"\"name: String. The name to use\n-          for momentum accumulator weights created by\n-          the optimizer.\n-      weight_decay: Float, defaults to None. If set, weight decay is applied.\n-      clipnorm: Float. If set, the gradient of each weight is individually\n-          clipped so that its norm is no higher than this value.\n-      clipvalue: Float. If set, the gradient of each weight is clipped to be no\n-          higher than this value.\n-      global_clipnorm: Float. If set, the gradient of all weights is clipped so\n-          that their global norm is no higher than this value.\n-      use_ema: Boolean, defaults to False. If True, exponential moving average\n-          (EMA) is applied. EMA consists of computing an exponential moving\n-          average of the weights of the model (as the weight values change after\n-          each training batch), and periodically overwriting the weights with\n-          their moving average.\n-      ema_momentum: Float, defaults to 0.99. Only used if `use_ema=True`.\n-          This is the momentum to use when computing\n-          the EMA of the model's weights:\n-          `new_average = ema_momentum * old_average + (1 - ema_momentum) *\n-          current_variable_value`.\n-      ema_overwrite_frequency: Int or None, defaults to None. Only used if\n-          `use_ema=True`. Every `ema_overwrite_frequency` steps of iterations,\n-          we overwrite the model variable by its moving average.\n-          If None, the optimizer\n-          does not overwrite model variables in the middle of training, and you\n-          need to explicitly overwrite the variables at the end of training\n-          by calling `optimizer.finalize_variable_values()`\n-          (which updates the model\n-          variables in-place). When using the built-in `fit()` training loop,\n-          this happens automatically after the last epoch,\n-          and you don't need to do anything.\"\"\"\n-\n-\n-def clip_by_norm(values, clip_norm, axes=None):\n-    # Calculate L2-norm, clip elements by ratio of clip_norm to L2-norm\n-    l2sum = ops.sum(values * values, axes, keepdims=True)\n-    pred = l2sum > 0\n-    # Two-tap tf.where trick to bypass NaN gradients\n-    l2sum_safe = ops.where(pred, l2sum, ops.ones_like(l2sum))\n-    l2norm = ops.where(pred, ops.sqrt(l2sum_safe), l2sum)\n-    intermediate = values * clip_norm\n-    values_clip = intermediate / ops.maximum(l2norm, clip_norm)\n-    return values_clip\n-\n-\n-def global_norm(value_list):\n-    \"\"\"Computes the global norm of multiple tensors.\"\"\"\n-    squared_norms = []\n-    for v in value_list:\n-        if v is not None:\n-            squared_norms.append(ops.sum(ops.square(v)))\n-    squared_norm = ops.sum(ops.stack(squared_norms))\n-    return ops.sqrt(squared_norm)\n-\n-\n-def clip_by_global_norm(value_list, clip_norm):\n-    use_norm = global_norm(value_list)\n-    # Calculate L2-norm, clip elements by ratio of clip_norm to L2-norm\n-    scale_for_finite = clip_norm * ops.minimum(1.0 / use_norm, 1.0 / clip_norm)\n-    # If use_norm is any finite number, this is a no-op. For inf/-inf/NaN,\n-    # this will make scale NaN.\n-    scale = scale_for_finite + (use_norm - use_norm)\n-    values_clipped = []\n-    for v in value_list:\n-        if v is None:\n-            values_clipped.append(None)\n-        else:\n-            values_clipped.append(v * scale)\n-    return values_clipped\n+base_optimizer_keyword_args = base_optimizer.base_optimizer_keyword_args\n\n@@ -67,11 +67,15 @@ def get_metric(identifier, y_true, y_pred):\n             y_true, y_pred\n         )\n         if is_binary:\n-            metric_obj = metrics_module.binary_accuracy\n+            metric_obj = metrics_module.BinaryAccuracy(name=str(identifier))\n         elif is_sparse_categorical:\n-            metric_obj = metrics_module.sparse_categorical_accuracy\n+            metric_obj = metrics_module.SparseCategoricalAccuracy(\n+                name=str(identifier)\n+            )\n         else:\n-            metric_obj = metrics_module.categorical_accuracy\n+            metric_obj = metrics_module.CategoricalAccuracy(\n+                name=str(identifier)\n+            )\n \n     if not isinstance(metric_obj, metrics_module.Metric):\n         if isinstance(identifier, str):\n\n@@ -178,6 +178,21 @@ class TestCompileMetrics(testing.TestCase):\n         self.assertAllClose(result[\"mean_squared_error\"], 0.0)\n         self.assertAllClose(result[\"weighted_mean_squared_error\"], 0.0)\n \n+    def test_name_conversions(self):\n+        compile_metrics = CompileMetrics(\n+            metrics=[\"acc\", \"accuracy\"],\n+            weighted_metrics=[],\n+        )\n+        y_true = np.array([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])\n+        y_pred = np.array([[0.4, 0.1], [0.2, 0.6], [0.6, 0.1]])\n+        compile_metrics.build(y_true, y_pred)\n+        compile_metrics.update_state(y_true, y_pred, sample_weight=None)\n+        result = compile_metrics.result()\n+        self.assertTrue(isinstance(result, dict))\n+        self.assertEqual(len(result), 2)\n+        self.assertAllClose(result[\"acc\"], 0.333333)\n+        self.assertAllClose(result[\"accuracy\"], 0.333333)\n+\n \n class TestCompileLoss(testing.TestCase):\n     def test_single_output_case(self):\n\n@@ -60,8 +60,10 @@ class EpochIterator:\n         steps_per_epoch=None,\n         shuffle=False,\n         class_weight=None,\n+        steps_per_execution=1,\n     ):\n         self.steps_per_epoch = steps_per_epoch\n+        self.steps_per_execution = steps_per_execution\n         if steps_per_epoch:\n             self._current_iterator = None\n             self._insufficient_data = False\n\n@@ -26,6 +26,7 @@ class Trainer:\n         metrics=None,\n         weighted_metrics=None,\n         run_eagerly=False,\n+        steps_per_execution=1,\n         jit_compile=True,\n     ):\n         self.optimizer = optimizers.get(optimizer)\n@@ -49,6 +50,7 @@ class Trainer:\n         self.stop_training = False\n         self.compiled = True\n         self._loss_tracker = metrics_module.Mean(name=\"loss\")\n+        self.steps_per_execution = steps_per_execution\n \n         self._compile_config = serialization_lib.SerializableDict(\n             optimizer=optimizer,\n@@ -57,6 +59,7 @@ class Trainer:\n             metrics=metrics,\n             weighted_metrics=weighted_metrics,\n             run_eagerly=run_eagerly,\n+            steps_per_execution=steps_per_execution,\n             jit_compile=jit_compile,\n         )\n \n\n@@ -1,4 +1,5 @@\n import numpy as np\n+import pytest\n \n from keras_core import backend\n from keras_core import initializers\n@@ -7,6 +8,7 @@ from keras_core import losses\n from keras_core import metrics\n from keras_core import optimizers\n from keras_core import testing\n+from keras_core.callbacks.callback import Callback\n \n if backend.backend() == \"jax\":\n     from keras_core.backend.jax.trainer import JAXTrainer as Trainer\n@@ -213,3 +215,32 @@ class TestTrainer(testing.TestCase):\n \n     def test_predict_flow_jit(self):\n         self._test_predict_flow(run_eagerly=False, jit_compile=True)\n+\n+    # TODO: Remove the skipif when implemented steps_per_execution for JAX.\n+    @pytest.mark.skipif(\n+        backend.backend() != \"tensorflow\",\n+        reason=\"JAX does not support steps_per_execution yet\",\n+    )\n+    def test_steps_per_execution_steps_count(self):\n+        class StepCount(Callback):\n+            def __init__(self):\n+                super().__init__()\n+                self.count = 0\n+                self.batches = [0, 3, 6]\n+\n+            def on_batch_begin(self, batch, logs=None):\n+                assert batch == self.batches[self.count]\n+                self.count += 1\n+\n+        x = np.ones((100, 4))\n+        y = np.ones((100, 1))\n+        model = ExampleModel(units=1)\n+        model.compile(loss=\"mse\", optimizer=\"adam\", steps_per_execution=3)\n+        step_count = StepCount()\n+        model.fit(x=x, y=y, batch_size=16, callbacks=[step_count])\n+        self.assertEqual(step_count.count, 3)\n+\n+        model_2 = ExampleModel(units=1)\n+        model_2.compile(loss=\"mse\", optimizer=\"adam\", steps_per_execution=1)\n+        model_2.fit(x=x, y=y, batch_size=16)\n+        self.assertAllClose(model.get_weights(), model_2.get_weights())\n\n@@ -0,0 +1,53 @@\n+def normalize_tuple(value, n, name, allow_zero=False):\n+    \"\"\"Transforms non-negative/positive integer/integers into an integer tuple.\n+\n+    Args:\n+        value: int or iterable of ints. The value to validate and convert.\n+        n: int. The size of the tuple to be returned.\n+        name: string. The name of the argument being validated, e.g. \"strides\"\n+            or \"kernel_size\". This is only used to format error messages.\n+        allow_zero: bool, defaults to False. A ValueError will raised if zero is\n+            received and this param is False.\n+\n+    Returns:\n+        A tuple of n integers.\n+    \"\"\"\n+    error_msg = (\n+        f\"The `{name}` argument must be a tuple of {n} integers. \"\n+        f\"Received {name}={value}\"\n+    )\n+\n+    if isinstance(value, int):\n+        value_tuple = (value,) * n\n+    else:\n+        try:\n+            value_tuple = tuple(value)\n+        except TypeError:\n+            raise ValueError(error_msg)\n+        if len(value_tuple) != n:\n+            raise ValueError(error_msg)\n+        for single_value in value_tuple:\n+            try:\n+                int(single_value)\n+            except (ValueError, TypeError):\n+                error_msg += (\n+                    f\"including element {single_value} of \"\n+                    f\"type {type(single_value)}\"\n+                )\n+                raise ValueError(error_msg)\n+\n+    if allow_zero:\n+        unqualified_values = {v for v in value_tuple if v < 0}\n+        req_msg = \">= 0\"\n+    else:\n+        unqualified_values = {v for v in value_tuple if v <= 0}\n+        req_msg = \"> 0\"\n+\n+    if unqualified_values:\n+        error_msg += (\n+            f\", including values {unqualified_values}\"\n+            f\" that do not satisfy `value {req_msg}`\"\n+        )\n+        raise ValueError(error_msg)\n+\n+    return value_tuple\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
