{"custom_id": "keras#7e62e94fddd6f937a9c1ca54cb0fdd43c44e0ad1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 28 | Files Changed: 1 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 44 | Churn Cumulative: 1194 | Contributors (this commit): 8 | Commits (past 90d): 6 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1032,36 +1032,32 @@ class BidirectionalTest(tf.test.TestCase, parameterized.TestCase):\n         bid_stateless = keras.layers.Bidirectional(stateless)\n         bid_stateful = keras.layers.Bidirectional(stateful)\n \n-        _ = keras.Model(\n-            inp,\n-            [\n-                bid_stateless(inp),\n-                bid_stateful(inp),\n-            ],\n-        )\n+        # _ = keras.Model(\n+        #    inp,\n+        #    [\n+        #        bid_stateless(inp),\n+        #        bid_stateful(inp),\n+        #    ],\n+        # )\n \n-        self.assertRaisesRegex(\n+        with self.assertRaisesRegex(\n             AttributeError,\n             \"Layer must be stateful.\",\n-            bid_stateless.reset_states,\n-        )\n-        self.assertRaisesRegex(\n-            AttributeError,\n-            \"Layer must be stateful.\",\n-            bid_stateless.reset_states,\n-            [],\n-        )\n+        ):\n+            bid_stateless.reset_states()\n+\n+        with self.assertRaisesRegex(AttributeError, \"Layer must be stateful.\"):\n+            bid_stateless.reset_states([])\n \n         bid_stateful.reset_states()\n         bid_stateful.reset_states([ref_state, ref_state])\n \n-        self.assertRaisesRegex(\n+        with self.assertRaisesRegex(\n             ValueError,\n             \"Unrecognized value for `states`. Received: {}Expected `states` \"\n             \"to be list or tuple\",\n-            bid_stateful.reset_states,\n-            {},\n-        )\n+        ):\n+            bid_stateful.reset_states({})\n \n     def test_trainable_parameter_argument(self):\n         inp = keras.layers.Input([None, 3])\n@@ -1105,14 +1101,6 @@ class BidirectionalTest(tf.test.TestCase, parameterized.TestCase):\n         test(fwd, None, trainable=False)\n \n \n-def test(states):\n-    raise ValueError(\n-        \"Unrecognized value for `states`. \"\n-        f\"Received: {states}\"\n-        \"Expected `states` to be list or tuple\"\n-    )\n-\n-\n def _to_list(ls):\n     if isinstance(ls, list):\n         return ls\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#315bf5134aee6e69b516b136a192f37e25d5fa04", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 1209 | Contributors (this commit): 8 | Commits (past 90d): 7 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1032,13 +1032,14 @@ class BidirectionalTest(tf.test.TestCase, parameterized.TestCase):\n         bid_stateless = keras.layers.Bidirectional(stateless)\n         bid_stateful = keras.layers.Bidirectional(stateful)\n \n-        # _ = keras.Model(\n-        #    inp,\n-        #    [\n-        #        bid_stateless(inp),\n-        #        bid_stateful(inp),\n-        #    ],\n-        # )\n+        # required to correctly initialize the state in the layers\n+        _ = keras.Model(\n+            inp,\n+            [\n+                bid_stateless(inp),\n+                bid_stateful(inp),\n+            ],\n+        )\n \n         with self.assertRaisesRegex(\n             AttributeError,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#82c4d6ebfb0f3345f433b17741c3bd746964bf2b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 11 | Files Changed: 1 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 25 | Churn Cumulative: 140 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -82,16 +82,16 @@ sgd_new_fn = tf.__internal__.test.combinations.NamedObject(\n )\n \n OPTIMIZER_FN = [\n-    adadelta_new_fn,\n-    adagrad_new_fn,\n-    adafactor_new_fn,\n+    # adadelta_new_fn,\n+    # adagrad_new_fn,\n+    # adafactor_new_fn,\n     adam_new_fn,\n-    adamax_new_fn,\n-    adamw_new_fn,\n-    ftrl_new_fn,\n-    nadam_new_fn,\n-    rmsprop_new_fn,\n-    sgd_new_fn,\n+    # adamax_new_fn,\n+    # adamw_new_fn,\n+    # ftrl_new_fn,\n+    # nadam_new_fn,\n+    # rmsprop_new_fn,\n+    # sgd_new_fn,\n ]\n \n \n@@ -422,12 +422,15 @@ class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n         # Create a new optimizer and call restore on it (and x)\n         x2 = tf.Variable([[0.0, 0.0], [0.0, 0.0]], dtype=x.dtype)\n         optimizer_2 = adam_new.Adam(\n-            learning_rate=0.02, beta_1=0.7, beta_2=0.777\n+            learning_rate=lr_schedule, beta_1=0.8, beta_2=0.888\n         )\n-        optimizer_2.build([x2])\n         checkpoint_2 = tf.train.Checkpoint(var=x2, optimizer=optimizer_2)\n         checkpoint_2.restore(checkpoint_path)\n \n+        for _ in range(2):\n+            optimizer_1.apply_gradients(zip([grads], [x]))\n+            optimizer_2.apply_gradients(zip([grads], [x]))\n+\n         self.assertTrue(\n             (\n                 self.evaluate(optimizer_1._momentums._storage[0])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b1660f03675d061f87ec3ef9135cda750ba22385", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 1436 | Contributors (this commit): 13 | Commits (past 90d): 3 | Contributors (cumulative): 13 | DMM Complexity: 0.0\n\nDIFF:\n@@ -480,8 +480,7 @@ class NormalizationAdaptTest(\n \n         # Save the model to disk.\n         output_path = os.path.join(\n-            self.get_temp_dir(),\n-            \"tf_keras_saved_model_invert\"\n+            self.get_temp_dir(), \"tf_keras_saved_model_invert\"\n         )\n         model.save(output_path, save_format=save_format)\n         loaded_model = keras.models.load_model(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3791bbe06a06d4b71caa9df15e8a1a83881881dd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 18 | Churn Cumulative: 158 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -82,16 +82,16 @@ sgd_new_fn = tf.__internal__.test.combinations.NamedObject(\n )\n \n OPTIMIZER_FN = [\n-    # adadelta_new_fn,\n-    # adagrad_new_fn,\n-    # adafactor_new_fn,\n+    adadelta_new_fn,\n+    adagrad_new_fn,\n+    adafactor_new_fn,\n     adam_new_fn,\n-    # adamax_new_fn,\n-    # adamw_new_fn,\n-    # ftrl_new_fn,\n-    # nadam_new_fn,\n-    # rmsprop_new_fn,\n-    # sgd_new_fn,\n+    adamax_new_fn,\n+    adamw_new_fn,\n+    ftrl_new_fn,\n+    nadam_new_fn,\n+    rmsprop_new_fn,\n+    sgd_new_fn,\n ]\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4fffb513b2a6fb64c0d6b1e3406cd0de63f6b78c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 28 | Files Changed: 2 | Hunks: 10 | Methods Changed: 2 | Complexity Δ (Sum/Max): 104/104 | Churn Δ: 56 | Churn Cumulative: 435 | Contributors (this commit): 7 | Commits (past 90d): 3 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -18,8 +18,8 @@ import threading\n \n import tensorflow.compat.v2 as tf\n \n+from keras.initializers import initializers\n from keras.initializers import initializers_v1\n-from keras.initializers import initializers_v2\n from keras.saving.legacy import serialization as legacy_serialization\n from keras.utils import generic_utils\n from keras.utils import tf_inspect as inspect\n@@ -53,40 +53,40 @@ def populate_deserializable_objects():\n     LOCAL.GENERATED_WITH_V2 = tf.__internal__.tf2.enabled()\n \n     # Compatibility aliases (need to exist in both V1 and V2).\n-    LOCAL.ALL_OBJECTS[\"ConstantV2\"] = initializers_v2.Constant\n-    LOCAL.ALL_OBJECTS[\"GlorotNormalV2\"] = initializers_v2.GlorotNormal\n-    LOCAL.ALL_OBJECTS[\"GlorotUniformV2\"] = initializers_v2.GlorotUniform\n-    LOCAL.ALL_OBJECTS[\"HeNormalV2\"] = initializers_v2.HeNormal\n-    LOCAL.ALL_OBJECTS[\"HeUniformV2\"] = initializers_v2.HeUniform\n-    LOCAL.ALL_OBJECTS[\"IdentityV2\"] = initializers_v2.Identity\n-    LOCAL.ALL_OBJECTS[\"LecunNormalV2\"] = initializers_v2.LecunNormal\n-    LOCAL.ALL_OBJECTS[\"LecunUniformV2\"] = initializers_v2.LecunUniform\n-    LOCAL.ALL_OBJECTS[\"OnesV2\"] = initializers_v2.Ones\n-    LOCAL.ALL_OBJECTS[\"OrthogonalV2\"] = initializers_v2.Orthogonal\n-    LOCAL.ALL_OBJECTS[\"RandomNormalV2\"] = initializers_v2.RandomNormal\n-    LOCAL.ALL_OBJECTS[\"RandomUniformV2\"] = initializers_v2.RandomUniform\n-    LOCAL.ALL_OBJECTS[\"TruncatedNormalV2\"] = initializers_v2.TruncatedNormal\n-    LOCAL.ALL_OBJECTS[\"VarianceScalingV2\"] = initializers_v2.VarianceScaling\n-    LOCAL.ALL_OBJECTS[\"ZerosV2\"] = initializers_v2.Zeros\n+    LOCAL.ALL_OBJECTS[\"ConstantV2\"] = initializers.Constant\n+    LOCAL.ALL_OBJECTS[\"GlorotNormalV2\"] = initializers.GlorotNormal\n+    LOCAL.ALL_OBJECTS[\"GlorotUniformV2\"] = initializers.GlorotUniform\n+    LOCAL.ALL_OBJECTS[\"HeNormalV2\"] = initializers.HeNormal\n+    LOCAL.ALL_OBJECTS[\"HeUniformV2\"] = initializers.HeUniform\n+    LOCAL.ALL_OBJECTS[\"IdentityV2\"] = initializers.Identity\n+    LOCAL.ALL_OBJECTS[\"LecunNormalV2\"] = initializers.LecunNormal\n+    LOCAL.ALL_OBJECTS[\"LecunUniformV2\"] = initializers.LecunUniform\n+    LOCAL.ALL_OBJECTS[\"OnesV2\"] = initializers.Ones\n+    LOCAL.ALL_OBJECTS[\"OrthogonalV2\"] = initializers.Orthogonal\n+    LOCAL.ALL_OBJECTS[\"RandomNormalV2\"] = initializers.RandomNormal\n+    LOCAL.ALL_OBJECTS[\"RandomUniformV2\"] = initializers.RandomUniform\n+    LOCAL.ALL_OBJECTS[\"TruncatedNormalV2\"] = initializers.TruncatedNormal\n+    LOCAL.ALL_OBJECTS[\"VarianceScalingV2\"] = initializers.VarianceScaling\n+    LOCAL.ALL_OBJECTS[\"ZerosV2\"] = initializers.Zeros\n \n     # Out of an abundance of caution we also include these aliases that have\n     # a non-zero probability of having been included in saved configs in the\n     # past.\n-    LOCAL.ALL_OBJECTS[\"glorot_normalV2\"] = initializers_v2.GlorotNormal\n-    LOCAL.ALL_OBJECTS[\"glorot_uniformV2\"] = initializers_v2.GlorotUniform\n-    LOCAL.ALL_OBJECTS[\"he_normalV2\"] = initializers_v2.HeNormal\n-    LOCAL.ALL_OBJECTS[\"he_uniformV2\"] = initializers_v2.HeUniform\n-    LOCAL.ALL_OBJECTS[\"lecun_normalV2\"] = initializers_v2.LecunNormal\n-    LOCAL.ALL_OBJECTS[\"lecun_uniformV2\"] = initializers_v2.LecunUniform\n+    LOCAL.ALL_OBJECTS[\"glorot_normalV2\"] = initializers.GlorotNormal\n+    LOCAL.ALL_OBJECTS[\"glorot_uniformV2\"] = initializers.GlorotUniform\n+    LOCAL.ALL_OBJECTS[\"he_normalV2\"] = initializers.HeNormal\n+    LOCAL.ALL_OBJECTS[\"he_uniformV2\"] = initializers.HeUniform\n+    LOCAL.ALL_OBJECTS[\"lecun_normalV2\"] = initializers.LecunNormal\n+    LOCAL.ALL_OBJECTS[\"lecun_uniformV2\"] = initializers.LecunUniform\n \n     if tf.__internal__.tf2.enabled():\n         # For V2, entries are generated automatically based on the content of\n-        # initializers_v2.py.\n+        # initializers.py.\n         v2_objs = {}\n-        base_cls = initializers_v2.Initializer\n+        base_cls = initializers.Initializer\n         generic_utils.populate_dict_with_module_objects(\n             v2_objs,\n-            [initializers_v2],\n+            [initializers],\n             obj_filter=lambda x: inspect.isclass(x) and issubclass(x, base_cls),\n         )\n         for key, value in v2_objs.items():\n@@ -172,7 +172,7 @@ def get(identifier):\n \n     >>> identifier = 'Ones'\n     >>> tf.keras.initializers.deserialize(identifier)\n-    <...keras.initializers.initializers_v2.Ones...>\n+    <...keras.initializers.initializers.Ones...>\n \n     You can also specify `config` of the initializer to this function by passing\n     dict containing `class_name` and `config` as an identifier. Also note that\n@@ -180,7 +180,7 @@ def get(identifier):\n \n     >>> cfg = {'class_name': 'Ones', 'config': {}}\n     >>> tf.keras.initializers.deserialize(cfg)\n-    <...keras.initializers.initializers_v2.Ones...>\n+    <...keras.initializers.initializers.Ones...>\n \n     In the case that the `identifier` is a class, this method will return a new\n     instance of the class by its constructor.\n\n@@ -12,7 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-\"\"\"Keras initializers for TF 2.\"\"\"\n+\"\"\"Keras initializers.\"\"\"\n \n import math\n import warnings\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6dd9459698d0fdab7900b9d991519075b8905fca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 77 | Lines Deleted: 0 | Files Changed: 5 | Hunks: 11 | Methods Changed: 11 | Complexity Δ (Sum/Max): 12/3 | Churn Δ: 77 | Churn Cumulative: 2674 | Contributors (this commit): 10 | Commits (past 90d): 6 | Contributors (cumulative): 26 | DMM Complexity: 0.9090909090909091\n\nDIFF:\n@@ -197,6 +197,13 @@ class Conv(Layer):\n                     \"and `SeparableConv1D`.\"\n                 )\n \n+        if max(self.strides) > 1 and max(self.dilation_rate) > 1:\n+            raise ValueError(\n+                \"`strides > 1` not supported in conjunction with \"\n+                f\"`dilation_rate > 1`. Received: strides={self.strides} and \"\n+                f\"dilation_rate={self.dilation_rate}\"\n+            )\n+\n     def build(self, input_shape):\n         input_shape = tf.TensorShape(input_shape)\n         input_channel = self._get_input_channel(input_shape)\n\n@@ -163,6 +163,13 @@ class Conv1DTest(test_combinations.TestCase):\n             layer = keras.layers.Conv1D(**kwargs)\n             layer.build((None, 5, 2))\n \n+    def test_conv1d_invalid_strides_and_dilation_rate(self):\n+        kwargs = {\"strides\": 2, \"dilation_rate\": 2}\n+        with self.assertRaisesRegex(\n+            ValueError, r\"\"\"`strides > 1` not supported in conjunction\"\"\"\n+        ):\n+            keras.layers.Conv1D(filters=1, kernel_size=2, **kwargs)\n+\n \n @test_combinations.run_all_keras_modes\n class Conv2DTest(test_combinations.TestCase):\n@@ -313,6 +320,13 @@ class Conv2DTest(test_combinations.TestCase):\n             layer = keras.layers.Conv2D(**kwargs)\n             layer.build((None, 5, 5, 2))\n \n+    def test_conv2d_invalid_strides_and_dilation_rate(self):\n+        kwargs = {\"strides\": [1, 2], \"dilation_rate\": [2, 1]}\n+        with self.assertRaisesRegex(\n+            ValueError, r\"\"\"`strides > 1` not supported in conjunction\"\"\"\n+        ):\n+            keras.layers.Conv2D(filters=1, kernel_size=2, **kwargs)\n+\n \n @test_combinations.run_all_keras_modes\n class Conv3DTest(test_combinations.TestCase):\n@@ -454,6 +468,13 @@ class Conv3DTest(test_combinations.TestCase):\n         # The layer doesn't crash with 0 dim input\n         _ = conv(x)\n \n+    def test_conv3d_invalid_strides_and_dilation_rate(self):\n+        kwargs = {\"strides\": [1, 1, 2], \"dilation_rate\": [1, 2, 1]}\n+        with self.assertRaisesRegex(\n+            ValueError, r\"\"\"`strides > 1` not supported in conjunction\"\"\"\n+        ):\n+            keras.layers.Conv3D(filters=1, kernel_size=2, **kwargs)\n+\n \n @test_combinations.run_all_keras_modes(always_skip_v1=True)\n class GroupedConvTest(test_combinations.TestCase):\n\n@@ -56,6 +56,13 @@ class Conv1DTransposeTest(test_combinations.TestCase):\n         ) or tf.test.is_gpu_available(cuda_only=True):\n             self._run_test(kwargs, expected_output_shape)\n \n+    def test_conv1d_transpose_invalid_strides_and_dilation_rate(self):\n+        kwargs = {\"strides\": 2, \"dilation_rate\": 2}\n+        with self.assertRaisesRegex(\n+            ValueError, r\"\"\"`strides > 1` not supported in conjunction\"\"\"\n+        ):\n+            keras.layers.Conv1DTranspose(filters=1, kernel_size=2, **kwargs)\n+\n \n @test_combinations.run_all_keras_modes\n class Conv2DTransposeTest(test_combinations.TestCase):\n@@ -164,6 +171,13 @@ class Conv2DTransposeTest(test_combinations.TestCase):\n             expected_output=expected_output,\n         )\n \n+    def test_conv2d_transpose_invalid_strides_and_dilation_rate(self):\n+        kwargs = {\"strides\": [2, 1], \"dilation_rate\": [2, 1]}\n+        with self.assertRaisesRegex(\n+            ValueError, r\"\"\"`strides > 1` not supported in conjunction\"\"\"\n+        ):\n+            keras.layers.Conv2DTranspose(filters=1, kernel_size=2, **kwargs)\n+\n \n @test_combinations.run_all_keras_modes\n class Conv3DTransposeTest(test_combinations.TestCase):\n@@ -265,6 +279,13 @@ class Conv3DTransposeTest(test_combinations.TestCase):\n                     input_data=input_data,\n                 )\n \n+    def test_conv3d_transpose_invalid_strides_and_dilation_rate(self):\n+        kwargs = {\"strides\": [2, 2, 1], \"dilation_rate\": [2, 2, 1]}\n+        with self.assertRaisesRegex(\n+            ValueError, r\"\"\"`strides > 1` not supported in conjunction\"\"\"\n+        ):\n+            keras.layers.Conv3DTranspose(filters=1, kernel_size=2, **kwargs)\n+\n \n if __name__ == \"__main__\":\n     tf.test.main()\n\n@@ -72,6 +72,13 @@ class DepthwiseConv1DTest(test_combinations.TestCase):\n         }\n         self._run_test(kwargs)\n \n+    def test_depthwise_conv1d_invalid_strides_and_dilation_rate(self):\n+        kwargs = {\"strides\": 2, \"dilation_rate\": 2}\n+        with self.assertRaisesRegex(\n+            ValueError, r\"\"\"`strides > 1` not supported in conjunction\"\"\"\n+        ):\n+            keras.layers.DepthwiseConv1D(kernel_size=2, **kwargs)\n+\n \n @test_combinations.run_all_keras_modes\n class DepthwiseConv2DTest(test_combinations.TestCase):\n@@ -124,6 +131,13 @@ class DepthwiseConv2DTest(test_combinations.TestCase):\n         }\n         self._run_test(kwargs)\n \n+    def test_depthwise_conv2d_invalid_strides_and_dilation_rate(self):\n+        kwargs = {\"strides\": [2, 1], \"dilation_rate\": [2, 1]}\n+        with self.assertRaisesRegex(\n+            ValueError, r\"\"\"`strides > 1` not supported in conjunction\"\"\"\n+        ):\n+            keras.layers.DepthwiseConv2D(kernel_size=2, **kwargs)\n+\n \n if __name__ == \"__main__\":\n     tf.test.main()\n\n@@ -90,6 +90,13 @@ class SeparableConv1DTest(test_combinations.TestCase):\n             self.assertEqual(layer.pointwise_kernel.constraint, p_constraint)\n             self.assertEqual(layer.bias.constraint, b_constraint)\n \n+    def test_separable_conv1d_invalid_strides_and_dilation_rate(self):\n+        kwargs = {\"strides\": 2, \"dilation_rate\": 2}\n+        with self.assertRaisesRegex(\n+            ValueError, r\"\"\"`strides > 1` not supported in conjunction\"\"\"\n+        ):\n+            keras.layers.SeparableConv1D(filters=1, kernel_size=2, **kwargs)\n+\n \n @test_combinations.run_all_keras_modes\n class SeparableConv2DTest(test_combinations.TestCase):\n@@ -164,6 +171,13 @@ class SeparableConv2DTest(test_combinations.TestCase):\n             self.assertEqual(layer.pointwise_kernel.constraint, p_constraint)\n             self.assertEqual(layer.bias.constraint, b_constraint)\n \n+    def test_separable_conv2d_invalid_strides_and_dilation_rate(self):\n+        kwargs = {\"strides\": [2, 1], \"dilation_rate\": [2, 1]}\n+        with self.assertRaisesRegex(\n+            ValueError, r\"\"\"`strides > 1` not supported in conjunction\"\"\"\n+        ):\n+            keras.layers.SeparableConv2D(filters=1, kernel_size=2, **kwargs)\n+\n \n if __name__ == \"__main__\":\n     tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#db11e9674157c9125c9215b3bd4928675cf5af53", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 9 | Methods Changed: 4 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 38 | Churn Cumulative: 793 | Contributors (this commit): 12 | Commits (past 90d): 12 | Contributors (cumulative): 14 | DMM Complexity: 0.6190476190476191\n\nDIFF:\n@@ -19,7 +19,10 @@ For more examples see the base class `tf.keras.optimizers.Optimizer`.\n \n # Imports needed for deserialization.\n \n+import platform\n+\n import tensorflow.compat.v2 as tf\n+from absl import logging\n \n from keras import backend\n from keras.optimizers import adadelta\n@@ -87,6 +90,10 @@ def serialize(optimizer, use_legacy_format=False):\n     return serialize_keras_object(optimizer)\n \n \n+def is_arm_mac():\n+    return platform.system() == \"Darwin\" and platform.processor() == \"arm\"\n+\n+\n @keras_export(\"keras.optimizers.deserialize\")\n def deserialize(config, custom_objects=None, use_legacy_format=False, **kwargs):\n     \"\"\"Inverse of the `serialize` function.\n@@ -118,8 +125,11 @@ def deserialize(config, custom_objects=None, use_legacy_format=False, **kwargs):\n     if (\n         tf.__internal__.tf2.enabled()\n         and tf.executing_eagerly()\n+        and not is_arm_mac()\n         and not use_legacy_optimizer\n     ):\n+        # We observed a slowdown of optimizer on M1 Mac, so we fall back to the\n+        # legacy optimizer for M1 users now, see b/263339144 for more context.\n         all_classes = {\n             \"adadelta\": adadelta.Adadelta,\n             \"adagrad\": adagrad.Adagrad,\n@@ -270,10 +280,20 @@ def get(identifier, **kwargs):\n     ):\n         return identifier\n     elif isinstance(identifier, base_optimizer.Optimizer):\n-        if tf.__internal__.tf2.enabled():\n+        if tf.__internal__.tf2.enabled() and not is_arm_mac():\n             return identifier\n         else:\n-            # If TF2 is disabled, we convert to the legacy optimizer.\n+            # If TF2 is disabled or on a M1 mac, we convert to the legacy\n+            # optimizer. We observed a slowdown of optimizer on M1 Mac, so we\n+            # fall back to the legacy optimizer for now, see b/263339144\n+            # for more context.\n+            optimizer_name = identifier.__class__.__name__\n+            logging.warning(\n+                \"There is a known slowdown when using v2.11+ Keras optimizers \"\n+                \"on M1/M2 Macs. Falling back to the \"\n+                \"legacy Keras optimizer, i.e., \"\n+                f\"`tf.keras.optimizers.legacy.{optimizer_name}`.\"\n+            )\n             return convert_to_legacy_optimizer(identifier)\n \n     # Wrap legacy TF optimizer instances\n\n@@ -4,6 +4,7 @@ More context in go/new-keras-optimizer\n \"\"\"\n \n import os\n+from unittest import mock\n \n import numpy as np\n import tensorflow.compat.v2 as tf\n@@ -606,6 +607,19 @@ class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n             legacy_optimizer.get_config()[\"learning_rate\"],\n         )\n \n+    @test_utils.run_v2_only\n+    def test_arm_mac_get_legacy_optimizer(self):\n+        with mock.patch(\n+            \"platform.system\",\n+            mock.MagicMock(return_value=\"Darwin\"),\n+        ):\n+            with mock.patch(\n+                \"platform.processor\",\n+                mock.MagicMock(return_value=\"arm\"),\n+            ):\n+                optimizer = keras.optimizers.get(\"adam\")\n+        self.assertIsInstance(optimizer, adam_old.Adam)\n+\n \n class OptimizerRegressionTest(tf.test.TestCase, parameterized.TestCase):\n     \"\"\"Test optimizer outputs the same numerical results as optimizer_v2.\"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ba1207c3d32ee1e8adb7fcdf3fd59a0b1d06877c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 1441 | Contributors (this commit): 13 | Commits (past 90d): 4 | Contributors (cumulative): 13 | DMM Complexity: 0.0\n\nDIFF:\n@@ -465,13 +465,12 @@ class NormalizationAdaptTest(\n         input_data = [[-1.0], [1.0], [-1.0], [1.0]]\n \n         cls = normalization.Normalization\n-        cls.invert = True\n         inputs = keras.Input(shape=(1,), dtype=tf.float32)\n         if adapt:\n-            layer = cls(axis=-1)\n+            layer = cls(axis=-1, invert=True)\n             layer.adapt(expected_output)\n         else:\n-            layer = cls(mean=1.0, variance=1.0)\n+            layer = cls(mean=1.0, variance=1.0, invert=True)\n         outputs = layer(inputs)\n         model = keras.Model(inputs=inputs, outputs=outputs)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6da3b6d351c41b5d51cab43cfb0ada486de9952b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 501 | Contributors (this commit): 11 | Commits (past 90d): 3 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -28,6 +28,6 @@ from keras.engine.training import Model\n from tensorflow.python import tf2\n from tensorflow.python.util.tf_export import keras_export\n \n-__version__ = \"2.12.0\"\n+__version__ = \"2.13.0\"\n \n keras_export(\"keras.__version__\").export_constant(__name__, \"__version__\")\n\n@@ -31,7 +31,7 @@ DOCLINES = __doc__.split(\"\\n\")\n # This version string is semver compatible, but incompatible with pip.\n # For pip, we will remove all '-' characters from this string, and use the\n # result for pip.\n-_VERSION = \"2.12.0\"\n+_VERSION = \"2.13.0\"\n \n REQUIRED_PACKAGES = [\n     # We depend on TensorFlow's declared pip dependencies.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#794c7ada723a28bfe5d8834334a0804cc3ff83e5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 604 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 17 | Complexity Δ (Sum/Max): 38/29 | Churn Δ: 604 | Churn Cumulative: 1096 | Contributors (this commit): 5 | Commits (past 90d): 5 | Contributors (cumulative): 7 | DMM Complexity: 0.7588424437299035\n\nDIFF:\n@@ -94,6 +94,10 @@ from keras.metrics.confusion_metrics import SpecificityAtSensitivity\n from keras.metrics.confusion_metrics import TrueNegatives\n from keras.metrics.confusion_metrics import TruePositives\n \n+# F-Scores\n+from keras.metrics.f_score_metrics import FBetaScore\n+from keras.metrics.f_score_metrics import F1Score\n+\n # IoU metrics\n from keras.metrics.iou_metrics import BinaryIoU\n from keras.metrics.iou_metrics import IoU\n\n@@ -0,0 +1,323 @@\n+# Copyright 2023 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"F-Score metrics.\"\"\"\n+\n+import tensorflow.compat.v2 as tf\n+from tensorflow.python.util.tf_export import keras_export\n+\n+from keras.dtensor import utils as dtensor_utils\n+from keras.metrics import base_metric\n+\n+\n+# Adapted from TF-Addons implementation.\n+@keras_export(\"keras.metrics.FBetaScore\")\n+class FBetaScore(base_metric.Metric):\n+    \"\"\"Computes F-Beta score.\n+\n+    This is the weighted harmonic mean of precision and recall.\n+    Its output range is `[0, 1]`. It works for both multi-class\n+    and multi-label classification.\n+\n+    It is defined as:\n+\n+    ```python\n+    b2 = beta ** 2\n+    f_beta_score = (1 + b2) * (precision * recall) / (precision * b2 + recall)\n+    ```\n+\n+    Args:\n+        average: Type of averaging to be performed across per-class results\n+            in the multi-class case.\n+            Acceptable values are `None`, `\"micro\"`, `\"macro\"` and\n+            `\"weighted\"`. Default value is `None`.\n+            If `None`, no averaging is performed and `result()` will return\n+            the score for each class.\n+            If `\"micro\"`, compute metrics globally by counting the total\n+            true positives, false negatives and false positives.\n+            If `\"macro\"`, compute metrics for each label,\n+            and return their unweighted mean.\n+            This does not take label imbalance into account.\n+            If `\"weighted\"`, compute metrics for each label,\n+            and return their average weighted by support\n+            (the number of true instances for each label).\n+            This alters `\"macro\"` to account for label imbalance.\n+            It can result in an score that is not between precision and recall.\n+        beta: Determines the weight of given to recall\n+            in the harmonic mean between precision and recall (see pseudocode\n+            equation above). Default value is 1.\n+        threshold: Elements of `y_pred` greater than `threshold` are\n+            converted to be 1, and the rest 0. If `threshold` is\n+            `None`, the argmax of `y_pred` is converted to 1, and the rest to 0.\n+        name: Optional. String name of the metric instance.\n+        dtype: Optional. Data type of the metric result.\n+\n+    Returns:\n+        F-Beta Score: float.\n+\n+    Example:\n+\n+    >>> metric = tf.keras.metrics.FBetaScore(beta=2.0, threshold=0.5)\n+    >>> y_true = np.array([[1, 1, 1],\n+    ...                    [1, 0, 0],\n+    ...                    [1, 1, 0]], np.int32)\n+    >>> y_pred = np.array([[0.2, 0.6, 0.7],\n+    ...                    [0.2, 0.6, 0.6],\n+    ...                    [0.6, 0.8, 0.0]], np.float32)\n+    >>> metric.update_state(y_true, y_pred)\n+    >>> result = metric.result()\n+    >>> result.numpy()\n+    array([0.3846154 , 0.90909094, 0.8333334 ], dtype=float32)\n+    \"\"\"\n+\n+    @dtensor_utils.inject_mesh\n+    def __init__(\n+        self,\n+        average=None,\n+        beta=1.0,\n+        threshold=None,\n+        name=\"fbeta_score\",\n+        dtype=None,\n+    ):\n+        super().__init__(name=name, dtype=dtype)\n+\n+        if average not in (None, \"micro\", \"macro\", \"weighted\"):\n+            raise ValueError(\n+                \"Invalid `average` argument value. Expected one of: \"\n+                \"{None, 'micro', 'macro', 'weighted'}. \"\n+                f\"Received: average={average}\"\n+            )\n+\n+        if not isinstance(beta, float):\n+            raise ValueError(\n+                \"Invalid `beta` argument value. \"\n+                \"It should be a Python float. \"\n+                f\"Received: beta={beta} of type '{type(beta)}'\"\n+            )\n+        if beta <= 0.0:\n+            raise ValueError(\n+                \"Invalid `beta` argument value. \"\n+                \"It should be > 0. \"\n+                f\"Received: beta={beta}\"\n+            )\n+\n+        if threshold is not None:\n+            if not isinstance(threshold, float):\n+                raise ValueError(\n+                    \"Invalid `threshold` argument value. \"\n+                    \"It should be a Python float. \"\n+                    f\"Received: threshold={threshold} \"\n+                    f\"of type '{type(threshold)}'\"\n+                )\n+            if threshold > 1.0 or threshold <= 0.0:\n+                raise ValueError(\n+                    \"Invalid `threshold` argument value. \"\n+                    \"It should verify 0 < threshold <= 1. \"\n+                    f\"Received: threshold={threshold}\"\n+                )\n+\n+        self.average = average\n+        self.beta = beta\n+        self.threshold = threshold\n+        self.axis = None\n+        self.built = False\n+\n+        if self.average != \"micro\":\n+            self.axis = 0\n+\n+    def build(self, y_true_shape, y_pred_shape):\n+        if len(y_pred_shape) != 2 or len(y_true_shape) != 2:\n+            raise ValueError(\n+                \"FBetaScore expects 2D inputs with shape \"\n+                \"(batch_size, output_dim). Received input \"\n+                f\"shapes: y_pred.shape={y_pred_shape} and \"\n+                f\"y_true.shape={y_true_shape}.\"\n+            )\n+        if y_pred_shape[-1] is None or y_true_shape[-1] is None:\n+            raise ValueError(\n+                \"FBetaScore expects 2D inputs with shape \"\n+                \"(batch_size, output_dim), with output_dim fully \"\n+                \"defined (not None). Received input \"\n+                f\"shapes: y_pred.shape={y_pred_shape} and \"\n+                f\"y_true.shape={y_true_shape}.\"\n+            )\n+        num_classes = y_pred_shape[-1]\n+        if self.average != \"micro\":\n+            init_shape = [num_classes]\n+        else:\n+            init_shape = []\n+\n+        def _add_zeros_weight(name):\n+            return self.add_weight(\n+                name,\n+                shape=init_shape,\n+                initializer=\"zeros\",\n+                dtype=self.dtype,\n+            )\n+\n+        self.true_positives = _add_zeros_weight(\"true_positives\")\n+        self.false_positives = _add_zeros_weight(\"false_positives\")\n+        self.false_negatives = _add_zeros_weight(\"false_negatives\")\n+        self.intermediate_weights = _add_zeros_weight(\"intermediate_weights\")\n+        self.built = True\n+\n+    def update_state(self, y_true, y_pred, sample_weight=None):\n+        y_true = tf.convert_to_tensor(y_true, dtype=self.dtype)\n+        y_pred = tf.convert_to_tensor(y_pred, dtype=self.dtype)\n+        if not self.built:\n+            self.build(y_true.shape, y_pred.shape)\n+\n+        if self.threshold is None:\n+            threshold = tf.reduce_max(y_pred, axis=-1, keepdims=True)\n+            # make sure [0, 0, 0] doesn't become [1, 1, 1]\n+            # Use abs(x) > eps, instead of x != 0 to check for zero\n+            y_pred = tf.logical_and(y_pred >= threshold, tf.abs(y_pred) > 1e-9)\n+        else:\n+            y_pred = y_pred > self.threshold\n+        y_pred = tf.cast(y_pred, dtype=self.dtype)\n+\n+        def _weighted_sum(val, sample_weight):\n+            if sample_weight is not None:\n+                val = tf.math.multiply(val, tf.expand_dims(sample_weight, 1))\n+            return tf.reduce_sum(val, axis=self.axis)\n+\n+        self.true_positives.assign_add(\n+            _weighted_sum(y_pred * y_true, sample_weight)\n+        )\n+        self.false_positives.assign_add(\n+            _weighted_sum(y_pred * (1 - y_true), sample_weight)\n+        )\n+        self.false_negatives.assign_add(\n+            _weighted_sum((1 - y_pred) * y_true, sample_weight)\n+        )\n+        self.intermediate_weights.assign_add(\n+            _weighted_sum(y_true, sample_weight)\n+        )\n+\n+    def result(self):\n+        precision = tf.math.divide_no_nan(\n+            self.true_positives, self.true_positives + self.false_positives\n+        )\n+        recall = tf.math.divide_no_nan(\n+            self.true_positives, self.true_positives + self.false_negatives\n+        )\n+\n+        mul_value = precision * recall\n+        add_value = (tf.math.square(self.beta) * precision) + recall\n+        mean = tf.math.divide_no_nan(mul_value, add_value)\n+        f1_score = mean * (1 + tf.math.square(self.beta))\n+\n+        if self.average == \"weighted\":\n+            weights = tf.math.divide_no_nan(\n+                self.intermediate_weights,\n+                tf.reduce_sum(self.intermediate_weights),\n+            )\n+            f1_score = tf.reduce_sum(f1_score * weights)\n+\n+        elif self.average is not None:  # [micro, macro]\n+            f1_score = tf.reduce_mean(f1_score)\n+\n+        return f1_score\n+\n+    def get_config(self):\n+        \"\"\"Returns the serializable config of the metric.\"\"\"\n+\n+        config = {\n+            \"average\": self.average,\n+            \"beta\": self.beta,\n+            \"threshold\": self.threshold,\n+        }\n+\n+        base_config = super().get_config()\n+        return {**base_config, **config}\n+\n+    def reset_state(self):\n+        for v in self.variables:\n+            v.assign(tf.zeros(v.shape, dtype=v.dtype))\n+\n+\n+@keras_export(\"keras.metrics.F1Score\")\n+class F1Score(FBetaScore):\n+    r\"\"\"Computes F-1 Score.\n+\n+    This is the harmonic mean of precision and recall.\n+    Its output range is `[0, 1]`. It works for both multi-class\n+    and multi-label classification.\n+\n+    It is defined as:\n+\n+    ```python\n+    f1_score = 2 * (precision * recall) / (precision + recall)\n+    ```\n+\n+    Args:\n+        average: Type of averaging to be performed on data.\n+            Acceptable values are `None`, `\"micro\"`, `\"macro\"`\n+            and `\"weighted\"`. Default value is `None`.\n+            If `None`, no averaging is performed and `result()` will return\n+            the score for each class.\n+            If `\"micro\"`, compute metrics globally by counting the total\n+            true positives, false negatives and false positives.\n+            If `\"macro\"`, compute metrics for each label,\n+            and return their unweighted mean.\n+            This does not take label imbalance into account.\n+            If `\"weighted\"`, compute metrics for each label,\n+            and return their average weighted by support\n+            (the number of true instances for each label).\n+            This alters `\"macro\"` to account for label imbalance.\n+            It can result in an score that is not between precision and recall.\n+        threshold: Elements of `y_pred` greater than `threshold` are\n+            converted to be 1, and the rest 0. If `threshold` is\n+            `None`, the argmax of `y_pred` is converted to 1, and the rest to 0.\n+        name: Optional. String name of the metric instance.\n+        dtype: Optional. Data type of the metric result.\n+\n+    Returns:\n+        F-1 Score: float.\n+\n+    Example:\n+\n+    >>> metric = tf.keras.metrics.F1Score(threshold=0.5)\n+    >>> y_true = np.array([[1, 1, 1],\n+    ...                    [1, 0, 0],\n+    ...                    [1, 1, 0]], np.int32)\n+    >>> y_pred = np.array([[0.2, 0.6, 0.7],\n+    ...                    [0.2, 0.6, 0.6],\n+    ...                    [0.6, 0.8, 0.0]], np.float32)\n+    >>> metric.update_state(y_true, y_pred)\n+    >>> result = metric.result()\n+    >>> result.numpy()\n+    array([0.5      , 0.8      , 0.6666667], dtype=float32)\n+    \"\"\"\n+\n+    @dtensor_utils.inject_mesh\n+    def __init__(\n+        self,\n+        average=None,\n+        threshold=None,\n+        name=\"f1_score\",\n+        dtype=None,\n+    ):\n+        super().__init__(\n+            average=average,\n+            beta=1.0,\n+            threshold=threshold,\n+            name=name,\n+            dtype=dtype,\n+        )\n+\n+    def get_config(self):\n+        base_config = super().get_config()\n+        del base_config[\"beta\"]\n+        return base_config\n\n@@ -0,0 +1,277 @@\n+# Copyright 2023 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests for F-score metrics.\"\"\"\n+\n+import tensorflow.compat.v2 as tf\n+from absl.testing import parameterized\n+\n+from keras.metrics import f_score_metrics\n+from keras.testing_infra import test_utils\n+\n+\n+@test_utils.run_v2_only\n+class FBetaScoreTest(parameterized.TestCase, tf.test.TestCase):\n+    def _run_test(\n+        self,\n+        y_true,\n+        y_pred,\n+        sample_weights,\n+        average,\n+        beta,\n+        threshold,\n+        reference_result,\n+    ):\n+        y_true = tf.constant(y_true, dtype=\"float32\")\n+        y_pred = tf.constant(y_pred, dtype=\"float32\")\n+        fbeta = f_score_metrics.FBetaScore(average, beta, threshold)\n+        fbeta.update_state(y_true, y_pred, sample_weights)\n+        result = fbeta.result().numpy()\n+        self.assertAllClose(result, reference_result, atol=1e-6)\n+\n+    def test_config(self):\n+        fbeta_obj = f_score_metrics.FBetaScore(\n+            beta=0.5, threshold=0.3, average=None\n+        )\n+        self.assertEqual(fbeta_obj.beta, 0.5)\n+        self.assertEqual(fbeta_obj.average, None)\n+        self.assertEqual(fbeta_obj.threshold, 0.3)\n+        self.assertEqual(fbeta_obj.dtype, tf.float32)\n+\n+        # Check save and restore config\n+        fbeta_obj2 = f_score_metrics.FBetaScore.from_config(\n+            fbeta_obj.get_config()\n+        )\n+        self.assertEqual(fbeta_obj2.beta, 0.5)\n+        self.assertEqual(fbeta_obj2.average, None)\n+        self.assertEqual(fbeta_obj2.threshold, 0.3)\n+        self.assertEqual(fbeta_obj2.dtype, tf.float32)\n+\n+    @tf.__internal__.distribute.combinations.generate(\n+        tf.__internal__.test.combinations.combine(\n+            average=[\"micro\", \"macro\", \"weighted\"], beta=[0.5, 1.0, 2.0]\n+        )\n+    )\n+    def test_fbeta_perfect_score(self, average, beta):\n+        y_true = [[1, 1, 1], [1, 0, 0], [1, 1, 0]]\n+        y_pred = [[0.7, 0.7, 0.7], [1, 0, 0], [0.9, 0.8, 0]]\n+        self._run_test(\n+            y_true,\n+            y_pred,\n+            None,\n+            average=average,\n+            beta=beta,\n+            threshold=0.66,\n+            reference_result=1.0,\n+        )\n+\n+    @tf.__internal__.distribute.combinations.generate(\n+        tf.__internal__.test.combinations.combine(\n+            average=[\"micro\", \"macro\", \"weighted\"], beta=[0.5, 1.0, 2.0]\n+        )\n+    )\n+    def test_fbeta_worst_score(self, average, beta):\n+        y_true = [[0, 0, 0], [0, 1, 0], [0, 0, 1]]\n+        y_pred = [[0.7, 0.7, 0.7], [1, 0, 0], [0.9, 0.8, 0]]\n+        self._run_test(\n+            y_true,\n+            y_pred,\n+            None,\n+            average=average,\n+            beta=beta,\n+            threshold=0.66,\n+            reference_result=0.0,\n+        )\n+\n+    @parameterized.parameters(\n+        # average, beta, result\n+        (None, 0.5, [0.71428573, 0.5, 0.833334]),\n+        (None, 1.0, [0.8, 0.5, 0.6666667]),\n+        (None, 2.0, [0.9090904, 0.5, 0.555556]),\n+        (\"micro\", 0.5, 0.6666667),\n+        (\"micro\", 1.0, 0.6666667),\n+        (\"micro\", 2.0, 0.6666667),\n+        (\"macro\", 0.5, 0.6825397),\n+        (\"macro\", 1.0, 0.6555555),\n+        (\"macro\", 2.0, 0.6548822),\n+        (\"weighted\", 0.5, 0.6825397),\n+        (\"weighted\", 1.0, 0.6555555),\n+        (\"weighted\", 2.0, 0.6548822),\n+    )\n+    def test_fbeta_random_score(self, average, beta, result):\n+        y_pred = [[0.7, 0.7, 0.7], [1, 0, 0], [0.9, 0.8, 0]]\n+        y_true = [[0, 0, 1], [1, 1, 0], [1, 1, 1]]\n+        self._run_test(\n+            y_true,\n+            y_pred,\n+            None,\n+            average=average,\n+            beta=beta,\n+            threshold=0.66,\n+            reference_result=result,\n+        )\n+\n+    @parameterized.parameters(\n+        # average, beta, result\n+        (None, 0.5, [0.9090904, 0.555556, 1.0]),\n+        (None, 1.0, [0.8, 0.6666667, 1.0]),\n+        (None, 2.0, [0.71428573, 0.833334, 1.0]),\n+        (\"micro\", 0.5, 0.833334),\n+        (\"micro\", 1.0, 0.833334),\n+        (\"micro\", 2.0, 0.833334),\n+        (\"macro\", 0.5, 0.821549),\n+        (\"macro\", 1.0, 0.822222),\n+        (\"macro\", 2.0, 0.849206),\n+        (\"weighted\", 0.5, 0.880471),\n+        (\"weighted\", 1.0, 0.844445),\n+        (\"weighted\", 2.0, 0.829365),\n+    )\n+    def test_fbeta_random_score_none(self, average, beta, result):\n+        y_true = [\n+            [1, 0, 0],\n+            [0, 1, 0],\n+            [0, 0, 1],\n+            [1, 0, 0],\n+            [1, 0, 0],\n+            [0, 0, 1],\n+        ]\n+        y_pred = [\n+            [0.9, 0.1, 0],\n+            [0.2, 0.6, 0.2],\n+            [0, 0, 1],\n+            [0.4, 0.3, 0.3],\n+            [0, 0.9, 0.1],\n+            [0, 0, 1],\n+        ]\n+        self._run_test(\n+            y_true,\n+            y_pred,\n+            None,\n+            average=average,\n+            beta=beta,\n+            threshold=None,\n+            reference_result=result,\n+        )\n+\n+    @parameterized.parameters(\n+        # average, beta, sample_weights, result\n+        (None, 0.5, [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.909091, 0.555556, 1.0]),\n+        (None, 0.5, [1.0, 0.0, 1.0, 1.0, 0.0, 1.0], [1.0, 0.0, 1.0]),\n+        (None, 0.5, [0.5, 1.0, 1.0, 1.0, 0.5, 1.0], [0.9375, 0.714286, 1.0]),\n+        (None, 1.0, [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.8, 0.666667, 1.0]),\n+        (None, 1.0, [1.0, 0.0, 1.0, 1.0, 0.0, 1.0], [1.0, 0.0, 1.0]),\n+        (None, 1.0, [0.5, 1.0, 1.0, 1.0, 0.5, 1.0], [0.857143, 0.8, 1.0]),\n+        (None, 2.0, [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.714286, 0.833333, 1.0]),\n+        (None, 2.0, [1.0, 0.0, 1.0, 1.0, 0.0, 1.0], [1.0, 0.0, 1.0]),\n+        (None, 2.0, [0.5, 1.0, 1.0, 1.0, 0.5, 1.0], [0.789474, 0.909091, 1.0]),\n+        (\"micro\", 0.5, [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.833333),\n+        (\"micro\", 0.5, [1.0, 0.0, 1.0, 1.0, 0.0, 1.0], 1.0),\n+        (\"micro\", 0.5, [0.5, 1.0, 1.0, 1.0, 0.5, 1.0], 0.9),\n+        (\"micro\", 1.0, [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.833333),\n+        (\"micro\", 1.0, [1.0, 0.0, 1.0, 1.0, 0.0, 1.0], 1.0),\n+        (\"micro\", 1.0, [0.5, 1.0, 1.0, 1.0, 0.5, 1.0], 0.9),\n+        (\"micro\", 2.0, [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.833333),\n+        (\"micro\", 2.0, [1.0, 0.0, 1.0, 1.0, 0.0, 1.0], 1.0),\n+        (\"micro\", 2.0, [0.5, 1.0, 1.0, 1.0, 0.5, 1.0], 0.9),\n+        (\"macro\", 0.5, [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.821549),\n+        (\"macro\", 0.5, [1.0, 0.0, 1.0, 1.0, 0.0, 1.0], 0.666667),\n+        (\"macro\", 0.5, [0.5, 1.0, 1.0, 1.0, 0.5, 1.0], 0.883929),\n+        (\"macro\", 1.0, [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.822222),\n+        (\"macro\", 1.0, [1.0, 0.0, 1.0, 1.0, 0.0, 1.0], 0.666667),\n+        (\"macro\", 1.0, [0.5, 1.0, 1.0, 1.0, 0.5, 1.0], 0.885714),\n+        (\"macro\", 2.0, [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.849206),\n+        (\"macro\", 2.0, [1.0, 0.0, 1.0, 1.0, 0.0, 1.0], 0.666667),\n+        (\"macro\", 2.0, [0.5, 1.0, 1.0, 1.0, 0.5, 1.0], 0.899522),\n+        (\"weighted\", 0.5, [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.880471),\n+        (\"weighted\", 0.5, [1.0, 0.0, 1.0, 1.0, 0.0, 1.0], 1.0),\n+        (\"weighted\", 0.5, [0.5, 1.0, 1.0, 1.0, 0.5, 1.0], 0.917857),\n+        (\"weighted\", 1.0, [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.844444),\n+        (\"weighted\", 1.0, [1.0, 0.0, 1.0, 1.0, 0.0, 1.0], 1.0),\n+        (\"weighted\", 1.0, [0.5, 1.0, 1.0, 1.0, 0.5, 1.0], 0.902857),\n+        (\"weighted\", 2.0, [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.829365),\n+        (\"weighted\", 2.0, [1.0, 0.0, 1.0, 1.0, 0.0, 1.0], 1.0),\n+        (\"weighted\", 2.0, [0.5, 1.0, 1.0, 1.0, 0.5, 1.0], 0.897608),\n+    )\n+    def test_fbeta_weighted_random_score_none(\n+        self, average, beta, sample_weights, result\n+    ):\n+        y_true = [\n+            [1, 0, 0],\n+            [0, 1, 0],\n+            [0, 0, 1],\n+            [1, 0, 0],\n+            [1, 0, 0],\n+            [0, 0, 1],\n+        ]\n+        y_pred = [\n+            [0.9, 0.1, 0],\n+            [0.2, 0.6, 0.2],\n+            [0, 0, 1],\n+            [0.4, 0.3, 0.3],\n+            [0, 0.9, 0.1],\n+            [0, 0, 1],\n+        ]\n+        self._run_test(\n+            y_true,\n+            y_pred,\n+            sample_weights,\n+            average=average,\n+            beta=beta,\n+            threshold=None,\n+            reference_result=result,\n+        )\n+\n+\n+@test_utils.run_v2_only\n+class F1ScoreTest(tf.test.TestCase):\n+    def test_config(self):\n+        f1_obj = f_score_metrics.F1Score()\n+        config = f1_obj.get_config()\n+        self.assertNotIn(\"beta\", config)\n+\n+        # Check save and restore config\n+        f1_obj = f_score_metrics.F1Score.from_config(config)\n+        self.assertEqual(f1_obj.average, None)\n+        self.assertEqual(f1_obj.dtype, tf.float32)\n+\n+    def test_correctness(self):\n+        f1 = f_score_metrics.F1Score()\n+        fbeta = f_score_metrics.FBetaScore(beta=1.0)\n+\n+        y_true = [\n+            [1, 0, 0],\n+            [0, 1, 0],\n+            [0, 0, 1],\n+            [1, 0, 0],\n+            [1, 0, 0],\n+            [0, 0, 1],\n+        ]\n+        y_pred = [\n+            [0.9, 0.1, 0],\n+            [0.2, 0.6, 0.2],\n+            [0, 0, 1],\n+            [0.4, 0.3, 0.3],\n+            [0, 0.9, 0.1],\n+            [0, 0, 1],\n+        ]\n+\n+        fbeta.update_state(y_true, y_pred)\n+        f1.update_state(y_true, y_pred)\n+        self.assertAllClose(\n+            fbeta.result().numpy(), f1.result().numpy(), atol=1e-6\n+        )\n+\n+\n+if __name__ == \"__main__\":\n+    tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
