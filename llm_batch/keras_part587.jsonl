{"custom_id": "keras#f9eee45efc31ed85326f5dd65345238f9ade1f45", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 40 | Lines Deleted: 13 | Files Changed: 3 | Hunks: 16 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 53 | Churn Cumulative: 1326 | Contributors (this commit): 4 | Commits (past 90d): 24 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -34,7 +34,7 @@ class RandomNormal(Initializer):\n             `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n+            or `None` (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n             of `keras_core.backend.SeedGenerator`.\n@@ -87,7 +87,7 @@ class TruncatedNormal(Initializer):\n             `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n+            or `None` (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n             of `keras_core.backend.SeedGenerator`.\n@@ -137,7 +137,7 @@ class RandomUniform(Initializer):\n             `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n+            or `None` (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n             of `keras_core.backend.SeedGenerator`.\n@@ -199,7 +199,7 @@ class VarianceScaling(Initializer):\n             `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n+            or `None` (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n             of `keras_core.backend.SeedGenerator`.\n@@ -298,7 +298,7 @@ class GlorotUniform(VarianceScaling):\n             `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n+            or `None` (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n             of `keras_core.backend.SeedGenerator`.\n@@ -341,7 +341,7 @@ class GlorotNormal(VarianceScaling):\n             `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n+            or `None` (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n             of `keras_core.backend.SeedGenerator`.\n@@ -390,7 +390,7 @@ class LecunNormal(VarianceScaling):\n             `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n+            or `None` (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n             of `keras_core.backend.SeedGenerator`.\n@@ -432,7 +432,7 @@ class LecunUniform(VarianceScaling):\n             `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n+            or `None` (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n             of `keras_core.backend.SeedGenerator`.\n@@ -474,7 +474,7 @@ class HeNormal(VarianceScaling):\n             `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n+            or `None` (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n             of `keras_core.backend.SeedGenerator`.\n@@ -516,7 +516,7 @@ class HeUniform(VarianceScaling):\n             `keras_core.backend.SeedGenerator`.\n             Used to make the behavior of the initializer\n             deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n+            or `None` (unseeded) will produce the same random values\n             across multiple calls. To get different random values\n             across multiple calls, use as seed an instance\n             of `keras_core.backend.SeedGenerator`.\n\n@@ -2,13 +2,13 @@ import numpy as np\n \n from keras_core import initializers\n from keras_core import testing\n+from keras_core import utils\n \n \n class InitializersTest(testing.TestCase):\n-    # TODO: missing many initializer tests.\n-\n     def test_random_normal(self):\n-        shape = (5, 5)\n+        utils.set_random_seed(1337)\n+        shape = (25, 20)\n         mean = 0.0\n         stddev = 1.0\n         seed = 1234\n@@ -20,6 +20,7 @@ class InitializersTest(testing.TestCase):\n         self.assertEqual(initializer.stddev, stddev)\n         self.assertEqual(initializer.seed, seed)\n         self.assertEqual(values.shape, shape)\n+        self.assertAllClose(np.std(values), stddev, atol=1e-1)\n \n         self.run_class_serialization_test(initializer)\n \n@@ -41,6 +42,31 @@ class InitializersTest(testing.TestCase):\n \n         self.run_class_serialization_test(initializer)\n \n+    def test_variance_scaling(self):\n+        utils.set_random_seed(1337)\n+        shape = (25, 20)\n+        scale = 2.0\n+        seed = 1234\n+        initializer = initializers.VarianceScaling(\n+            scale=scale, seed=seed, mode=\"fan_in\"\n+        )\n+        values = initializer(shape=shape)\n+        self.assertEqual(initializer.scale, scale)\n+        self.assertEqual(initializer.seed, seed)\n+        self.assertEqual(values.shape, shape)\n+        self.assertAllClose(np.std(values), np.sqrt(scale / 25), atol=1e-1)\n+        self.run_class_serialization_test(initializer)\n+\n+        initializer = initializers.VarianceScaling(\n+            scale=scale, seed=seed, mode=\"fan_out\"\n+        )\n+        values = initializer(shape=shape)\n+        self.assertEqual(initializer.scale, scale)\n+        self.assertEqual(initializer.seed, seed)\n+        self.assertEqual(values.shape, shape)\n+        self.assertAllClose(np.std(values), np.sqrt(scale / 20), atol=1e-1)\n+        self.run_class_serialization_test(initializer)\n+\n     def test_orthogonal_initializer(self):\n         shape = (5, 5)\n         gain = 2.0\n\n@@ -1,2 +1,3 @@\n from keras_core.utils.python_utils import default\n from keras_core.utils.python_utils import is_default\n+from keras_core.utils.rng_utils import set_random_seed\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dd18f20914cfbf0e9282dc90de7c290cd2073c70", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 127 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 9 | Complexity Δ (Sum/Max): 11/6 | Churn Δ: 127 | Churn Cumulative: 229 | Contributors (this commit): 9 | Commits (past 90d): 48 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -64,6 +64,7 @@ from keras_core.layers.preprocessing.discretization import Discretization\n from keras_core.layers.preprocessing.hashing import Hashing\n from keras_core.layers.preprocessing.integer_lookup import IntegerLookup\n from keras_core.layers.preprocessing.normalization import Normalization\n+from keras_core.layers.preprocessing.random_crop import RandomCrop\n from keras_core.layers.preprocessing.rescaling import Rescaling\n from keras_core.layers.preprocessing.resizing import Resizing\n from keras_core.layers.preprocessing.string_lookup import StringLookup\n\n@@ -0,0 +1,65 @@\n+import numpy as np\n+import tensorflow as tf\n+\n+from keras_core import backend\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.layer import Layer\n+\n+\n+@keras_core_export(\"keras_core.layers.RandomCrop\")\n+class RandomCrop(Layer):\n+    \"\"\"A preprocessing layer which randomly crops images during training.\n+\n+    During training, this layer will randomly choose a location to crop images\n+    down to a target size. The layer will crop all the images in the same batch\n+    to the same cropping location.\n+\n+    At inference time, and during training if an input image is smaller than the\n+    target size, the input will be resized and cropped so as to return the\n+    largest possible window in the image that matches the target aspect ratio.\n+    If you need to apply random cropping at inference time, set `training` to\n+    True when calling the layer.\n+\n+    Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and\n+    of integer or floating point dtype. By default, the layer will output\n+    floats.\n+\n+    Input shape:\n+        3D (unbatched) or 4D (batched) tensor with shape:\n+        `(..., height, width, channels)`, in `\"channels_last\"` format.\n+\n+    Output shape:\n+        3D (unbatched) or 4D (batched) tensor with shape:\n+        `(..., target_height, target_width, channels)`.\n+\n+    Args:\n+        height: Integer, the height of the output shape.\n+        width: Integer, the width of the output shape.\n+        seed: Integer. Used to create a random seed.\n+        **kwargs: Base layer keyword arguments, such as\n+            `name` and `dtype`.\n+    \"\"\"\n+\n+    def __init__(self, height, width, seed=None, name=None, **kwargs):\n+        super().__init__()\n+        self.layer = tf.keras.layers.RandomCrop(\n+            height=height,\n+            width=width,\n+            seed=seed,\n+            name=name,\n+        )\n+        self.supports_masking = False\n+\n+    def call(self, inputs, training=True):\n+        if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n+            inputs = tf.convert_to_tensor(np.array(inputs))\n+        outputs = self.layer.call(inputs)\n+        if backend.backend() != \"tensorflow\":\n+            outputs = backend.convert_to_tensor(outputs)\n+        return outputs\n+\n+    def compute_output_shape(self, input_shape):\n+        return tuple(self.layer.compute_output_shape(input_shape))\n+\n+    def get_config(self):\n+        return self.layer.get_config()\n\n@@ -0,0 +1,61 @@\n+import numpy as np\n+\n+from keras_core import layers\n+from keras_core import testing\n+\n+\n+class RandomCropTest(testing.TestCase):\n+    def test_random_crop(self):\n+        self.run_layer_test(\n+            layers.RandomCrop,\n+            init_kwargs={\n+                \"height\": 1,\n+                \"width\": 1,\n+            },\n+            input_shape=(2, 3, 4),\n+            supports_masking=False,\n+        )\n+\n+    def test_random_crop_full(self):\n+        np.random.seed(1337)\n+        height, width = 8, 16\n+        inp = np.random.random((12, 8, 16, 3))\n+        layer = layers.RandomCrop(height, width)\n+        actual_output = layer(inp, training=False)\n+        self.assertAllClose(inp, actual_output)\n+\n+    def test_random_crop_partial(self):\n+        self.run_layer_test(\n+            layers.RandomCrop,\n+            init_kwargs={\n+                \"height\": 8,\n+                \"width\": 8,\n+            },\n+            input_shape=(12, 8, 16, 3),\n+            expected_output_shape=(12, 8, 8, 3),\n+            supports_masking=False,\n+        )\n+\n+    def test_predicting_with_longer_height(self):\n+        self.run_layer_test(\n+            layers.RandomCrop,\n+            init_kwargs={\n+                \"height\": 10,\n+                \"width\": 8,\n+            },\n+            input_shape=(12, 8, 16, 3),\n+            expected_output_shape=(12, 10, 8, 3),\n+            supports_masking=False,\n+        )\n+\n+    def test_predicting_with_longer_width(self):\n+        self.run_layer_test(\n+            layers.RandomCrop,\n+            init_kwargs={\n+                \"height\": 8,\n+                \"width\": 18,\n+            },\n+            input_shape=(12, 8, 16, 3),\n+            expected_output_shape=(12, 8, 18, 3),\n+            supports_masking=False,\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bc0760d38d3b19a019a792f35decf125051ce88f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 71 | Lines Deleted: 18 | Files Changed: 2 | Hunks: 8 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 89 | Churn Cumulative: 271 | Contributors (this commit): 5 | Commits (past 90d): 3 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,60 @@\n+# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests of ModelCheckpoint callback.\"\"\"\n+\n+import os\n+import sys\n+\n+import tensorflow.compat.v2 as tf\n+from absl.testing import parameterized\n+\n+from keras import callbacks\n+from keras.distribute import multi_worker_testing_utils\n+\n+\n+class ModelCheckpointTest(tf.test.TestCase, parameterized.TestCase):\n+    @tf.__internal__.distribute.combinations.generate(\n+        tf.__internal__.test.combinations.combine(\n+            mode=[\"eager\"],\n+            file_format=[\"h5\", \"tf\"],\n+            save_weights_only=[True, False],\n+        )\n+    )\n+    def testCheckpointExists(self, file_format, save_weights_only):\n+        train_ds, _ = multi_worker_testing_utils.mnist_synthetic_dataset(64, 2)\n+        model = multi_worker_testing_utils.get_mnist_model((28, 28, 1))\n+        saving_dir = self.get_temp_dir()\n+        saving_filepath = os.path.join(saving_dir, \"checkpoint.\" + file_format)\n+        callbacks_list = [\n+            callbacks.ModelCheckpoint(\n+                filepath=saving_filepath, save_weights_only=save_weights_only\n+            )\n+        ]\n+        self.assertFalse(tf.io.gfile.exists(saving_filepath))\n+        model.fit(\n+            x=train_ds, epochs=2, steps_per_epoch=2, callbacks=callbacks_list\n+        )\n+        tf_saved_model_exists = tf.io.gfile.exists(saving_filepath)\n+        tf_weights_only_checkpoint_exists = tf.io.gfile.exists(\n+            saving_filepath + \".index\"\n+        )\n+        self.assertTrue(\n+            tf_saved_model_exists or tf_weights_only_checkpoint_exists\n+        )\n+\n+\n+if __name__ == \"__main__\":\n+    with tf.compat.v1.test.mock.patch.object(sys, \"exit\", os._exit):\n+        tf.test.main()\n\n@@ -24,35 +24,28 @@ from keras import callbacks\n from keras.distribute import multi_worker_testing_utils\n \n \n-class ModelCheckpointTest(tf.test.TestCase, parameterized.TestCase):\n+class WorkerTrainingStateTest(tf.test.TestCase, parameterized.TestCase):\n     @tf.__internal__.distribute.combinations.generate(\n-        tf.__internal__.test.combinations.combine(\n-            mode=[\"eager\"],\n-            file_format=[\"h5\", \"tf\"],\n-            save_weights_only=[True, False],\n+        tf.__internal__.test.combinations.combine(mode=[\"eager\"])\n     )\n-    )\n-    def testCheckpointExists(self, file_format, save_weights_only):\n+    def testCheckpointExists(self):\n         train_ds, _ = multi_worker_testing_utils.mnist_synthetic_dataset(64, 2)\n         model = multi_worker_testing_utils.get_mnist_model((28, 28, 1))\n         saving_dir = self.get_temp_dir()\n-        saving_filepath = os.path.join(saving_dir, \"checkpoint.\" + file_format)\n         callbacks_list = [\n-            callbacks.ModelCheckpoint(\n-                filepath=saving_filepath, save_weights_only=save_weights_only\n+            callbacks.BackupAndRestore(\n+                backup_dir=saving_dir, delete_checkpoint=False\n             )\n         ]\n-        self.assertFalse(tf.io.gfile.exists(saving_filepath))\n+        self.assertLen(tf.io.gfile.glob(os.path.join(saving_dir, \"*\")), 0)\n         model.fit(\n             x=train_ds, epochs=2, steps_per_epoch=2, callbacks=callbacks_list\n         )\n-        tf_saved_model_exists = tf.io.gfile.exists(saving_filepath)\n-        tf_weights_only_checkpoint_exists = tf.io.gfile.exists(\n-            saving_filepath + \".index\"\n-        )\n-        self.assertTrue(\n-            tf_saved_model_exists or tf_weights_only_checkpoint_exists\n-        )\n+        # By default worker_training_state only keeps the results from one\n+        # checkpoint. Even though the test is expected to checkpoint twice, it\n+        # only keeps the checkpoint files from the second checkpoint.\n+        checkpoint_path = os.path.join(saving_dir, \"chief\", \"ckpt-2.index\")\n+        self.assertLen(tf.io.gfile.glob(checkpoint_path), 1)\n \n \n if __name__ == \"__main__\":\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#56e62ea9ee2fc399390ce592618989e1259bbf5c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 7 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 25 | Churn Cumulative: 1030 | Contributors (this commit): 4 | Commits (past 90d): 23 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -105,10 +105,12 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             \"\"\"Runs a single training step given a Dataset iterator.\"\"\"\n             data = next(iterator)\n             outputs = self.distribute_strategy.run(\n-                one_step_on_data, args=(data,))\n+                one_step_on_data, args=(data,)\n+            )\n             outputs = reduce_per_replica(\n-                outputs, self.distribute_strategy,\n-                reduction=self.distribute_reduction_method\n+                outputs,\n+                self.distribute_strategy,\n+                reduction=self.distribute_reduction_method,\n             )\n             return outputs\n \n@@ -138,10 +140,12 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             \"\"\"Runs a single test step given a Dataset iterator.\"\"\"\n             data = next(iterator)\n             outputs = self.distribute_strategy.run(\n-                one_step_on_data, args=(data,))\n+                one_step_on_data, args=(data,)\n+            )\n             outputs = reduce_per_replica(\n-                outputs, self.distribute_strategy,\n-                reduction=self.distribute_reduction_method\n+                outputs,\n+                self.distribute_strategy,\n+                reduction=self.distribute_reduction_method,\n             )\n             return outputs\n \n@@ -171,10 +175,12 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             \"\"\"Runs a single predict step given a Dataset iterator.\"\"\"\n             data = next(iterator)\n             outputs = self.distribute_strategy.run(\n-                one_step_on_data, args=(data,))\n+                one_step_on_data, args=(data,)\n+            )\n             outputs = reduce_per_replica(\n-                outputs, self.distribute_strategy,\n-                reduction=self.distribute_reduction_method\n+                outputs,\n+                self.distribute_strategy,\n+                reduction=self.distribute_reduction_method,\n             )\n             return outputs\n \n@@ -636,6 +642,7 @@ def _is_tpu_strategy(strategy):\n def _is_tpu_strategy_class(clz):\n     def is_tpu_strat(k):\n         return k.__name__.startswith(\"TPUStrategy\")\n+\n     if is_tpu_strat(clz):\n         return True\n     return any(map(_is_tpu_strategy_class, clz.__bases__))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0a054562a18afde6632b638127646060471c0e08", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 51 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 11 | Methods Changed: 7 | Complexity Δ (Sum/Max): 9/9 | Churn Δ: 55 | Churn Cumulative: 1085 | Contributors (this commit): 4 | Commits (past 90d): 25 | Contributors (cumulative): 5 | DMM Complexity: 0.875\n\nDIFF:\n@@ -1,10 +1,12 @@\n \"\"\"Tests for tf.distribute related functionality under tf implementation.\"\"\"\n \n+import numpy as np\n import pytest\n import tensorflow as tf\n from tensorflow.python.eager import context\n \n from keras_core import backend\n+from keras_core.backend.tensorflow import trainer as tf_trainer\n from keras_core import layers\n from keras_core import models\n from keras_core import testing\n@@ -79,3 +81,41 @@ class DistributeTest(testing.TestCase):\n         self.assertEqual(result.values[1].shape, [8, 2])\n         self.assertNotAllClose(result.values[0], result.values[1])\n         self.assertAllClose(result.values[0], tf.zeros([8, 2]))\n+\n+    def test_epoch_iterator(self):\n+        x = np.random.random((100, 16))\n+        y = np.random.random((100, 4))\n+        sample_weight = np.random.random((100,))\n+        batch_size = 16\n+        shuffle = True\n+\n+        strategy = tf.distribute.MirroredStrategy(['CPU:0', 'CPU:1'])\n+\n+        epoch_iterator = tf_trainer.TFEpochIterator(\n+            x=x,\n+            y=y,\n+            sample_weight=sample_weight,\n+            batch_size=batch_size,\n+            shuffle=shuffle,\n+            distribute_strategy=strategy\n+        )\n+        steps_seen = []\n+        for step, data_iterator in epoch_iterator.enumerate_epoch():\n+            steps_seen.append(step)\n+            batch = next(data_iterator)\n+            self.assertEqual(len(batch), 3)\n+            x, y, sample_weight = batch\n+            self.assertTrue(\n+                isinstance(x,\n+                           tf.types.experimental.distributed.PerReplica))\n+            # Make sure the local batch size is 8\n+            if step < 6:\n+                self.assertEqual(x.values[0].shape, [8, 16])\n+                self.assertEqual(y.values[0].shape, [8, 4])\n+                self.assertEqual(sample_weight.values[0].shape, [8])\n+            else:\n+                # Last partial batch\n+                self.assertEqual(x.values[0].shape, [2, 16])\n+                self.assertEqual(y.values[0].shape, [2, 4])\n+                self.assertEqual(sample_weight.values[0].shape, [2])\n+        self.assertEqual(steps_seen, [0, 1, 2, 3, 4, 5, 6])\n\n@@ -243,6 +243,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             steps_per_epoch=steps_per_epoch,\n             shuffle=shuffle,\n             class_weight=class_weight,\n+            distribute_strategy=self.distribute_strategy,\n         )\n \n         # Container that configures and calls callbacks.\n@@ -285,6 +286,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n                         y=val_y,\n                         sample_weight=val_sample_weight,\n                         batch_size=validation_batch_size or batch_size,\n+                        distribute_strategy=self.distribute_strategy,\n                     )\n                 val_logs = self.evaluate(\n                     x=val_x,\n@@ -346,6 +348,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n                 batch_size=batch_size,\n                 steps_per_epoch=steps,\n                 shuffle=False,\n+                distribute_strategy=self.distribute_strategy,\n             )\n \n         # Container that configures and calls callbacks.\n@@ -385,6 +388,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n             batch_size=batch_size,\n             steps_per_epoch=steps,\n             shuffle=False,\n+            distribute_strategy=self.distribute_strategy,\n         )\n \n         # Container that configures and calls callbacks.\n@@ -428,20 +432,23 @@ class TensorFlowTrainer(base_trainer.Trainer):\n \n \n class TFEpochIterator(EpochIterator):\n-    def __init__(self, *args, **kwargs):\n+    def __init__(self, distribute_strategy=None, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n+        self._distribute_strategy = distribute_strategy\n         self._steps_seen = 0\n \n     def enumerate_epoch(self):\n         if self.steps_per_epoch:\n             if not self._current_iterator:\n                 self._current_iterator = iter(\n-                    self.data_adapter.get_tf_dataset()\n-                )\n+                    self._distribute_strategy.experimental_distribute_dataset(\n+                        self.data_adapter.get_tf_dataset()))\n             for step in range(self.steps_per_epoch):\n                 yield step, self._current_iterator\n         else:\n-            iterator = iter(self.data_adapter.get_tf_dataset())\n+            iterator = iter(\n+                self._distribute_strategy.experimental_distribute_dataset(\n+                    self.data_adapter.get_tf_dataset()))\n             if self.num_batches:\n                 for step in range(self.num_batches):\n                     yield step, iterator\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b8069e8f89a773d2eb731855d0ffc1f2aedc64ae", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 139 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -34,7 +34,7 @@ class ReduceLROnPlateauTest(testing.TestCase):\n \n     def test_reduces_lr_with_model_fit(self):\n         reduce_lr = callbacks.ReduceLROnPlateau(\n-            patience=1, factor=0.1, monitor=\"val_loss\", min_delta=10\n+            patience=1, factor=0.1, monitor=\"val_loss\", min_delta=100\n         )\n \n         self.model.fit(\n@@ -49,7 +49,7 @@ class ReduceLROnPlateauTest(testing.TestCase):\n \n     def test_throws_when_optimizer_has_schedule(self):\n         reduce_lr = callbacks.ReduceLROnPlateau(\n-            patience=1, factor=0.1, monitor=\"val_loss\", min_delta=10\n+            patience=1, factor=0.1, monitor=\"val_loss\", min_delta=100\n         )\n \n         self.model.compile(\n@@ -75,7 +75,7 @@ class ReduceLROnPlateauTest(testing.TestCase):\n \n     def test_verbose_logging(self):\n         reduce_lr = callbacks.ReduceLROnPlateau(\n-            patience=1, factor=0.1, monitor=\"val_loss\", min_delta=10, verbose=1\n+            patience=1, factor=0.1, monitor=\"val_loss\", min_delta=100, verbose=1\n         )\n         io_utils.disable_interactive_logging()\n \n@@ -111,7 +111,11 @@ class ReduceLROnPlateauTest(testing.TestCase):\n \n     def test_cooldown(self):\n         reduce_lr = callbacks.ReduceLROnPlateau(\n-            patience=1, factor=0.1, monitor=\"val_loss\", min_delta=10, cooldown=2\n+            patience=1,\n+            factor=0.1,\n+            monitor=\"val_loss\",\n+            min_delta=100,\n+            cooldown=2,\n         )\n \n         self.model.fit(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2484922d54ca8a94a5fda05e1f4bc480b1ef6ba1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1107 | Lines Deleted: 16 | Files Changed: 11 | Hunks: 21 | Methods Changed: 19 | Complexity Δ (Sum/Max): 29/19 | Churn Δ: 1123 | Churn Cumulative: 6296 | Contributors (this commit): 13 | Commits (past 90d): 93 | Contributors (cumulative): 30 | DMM Complexity: 0.8548707753479126\n\nDIFF:\n@@ -33,16 +33,17 @@ def _compute_conv_transpose_output_length(\n \n \n def compute_conv_transpose_output_shape(\n-    inputs,\n-    kernel,\n+    input_shape,\n+    kernel_size,\n+    filters,\n     strides,\n     padding,\n     output_padding=None,\n     data_format=\"channels_last\",\n     dilation_rate=1,\n ):\n-    num_spatial_dims = len(inputs.shape) - 2\n-    kernel_spatial_shape = kernel.shape[:-2]\n+    num_spatial_dims = len(input_shape) - 2\n+    kernel_spatial_shape = kernel_size\n \n     if isinstance(output_padding, int):\n         output_padding = (output_padding,) * len(kernel_spatial_shape)\n@@ -52,9 +53,9 @@ def compute_conv_transpose_output_shape(\n         dilation_rate = (dilation_rate,) * num_spatial_dims\n \n     if data_format == \"channels_last\":\n-        inputs_spatial_shape = inputs.shape[1:-1]\n+        input_spatial_shape = input_shape[1:-1]\n     else:\n-        inputs_spatial_shape = inputs.shape[2:]\n+        input_spatial_shape = input_shape[2:]\n \n     output_shape = []\n     for i in range(num_spatial_dims):\n@@ -63,7 +64,7 @@ def compute_conv_transpose_output_shape(\n         )\n         output_shape.append(\n             _compute_conv_transpose_output_length(\n-                inputs_spatial_shape[i],\n+                input_spatial_shape[i],\n                 kernel_spatial_shape[i],\n                 padding=padding,\n                 output_padding=current_output_padding,\n@@ -73,7 +74,7 @@ def compute_conv_transpose_output_shape(\n         )\n \n     if data_format == \"channels_last\":\n-        output_shape = [inputs.shape[0]] + output_shape + [kernel.shape[-2]]\n+        output_shape = [input_shape[0]] + output_shape + [filters]\n     else:\n-        output_shape = [inputs.shape[0], kernel.shape[-1]] + output_shape\n+        output_shape = [input_shape[0], filters] + output_shape\n     return output_shape\n\n@@ -360,9 +360,12 @@ def conv_transpose(\n     dilation_rate=1,\n ):\n     tf_data_format = _convert_data_format(data_format, len(inputs.shape))\n+    kernel_size = kernel.shape[:-2]\n+    filters = kernel.shape[-2]\n     output_shape = compute_conv_transpose_output_shape(\n-        inputs,\n-        kernel,\n+        inputs.shape,\n+        kernel_size,\n+        filters,\n         strides,\n         padding,\n         output_padding,\n\n@@ -1,8 +1,11 @@\n from keras_core.layers.activations.activation import Activation\n from keras_core.layers.attention.attention import Attention\n from keras_core.layers.convolutional.conv1d import Conv1D\n+from keras_core.layers.convolutional.conv1d_transpose import Conv1DTranspose\n from keras_core.layers.convolutional.conv2d import Conv2D\n+from keras_core.layers.convolutional.conv2d_transpose import Conv2DTranspose\n from keras_core.layers.convolutional.conv3d import Conv3D\n+from keras_core.layers.convolutional.conv3d_transpose import Conv3DTranspose\n from keras_core.layers.core.dense import Dense\n from keras_core.layers.core.einsum_dense import EinsumDense\n from keras_core.layers.core.embedding import Embedding\n\n@@ -0,0 +1,255 @@\n+\"\"\"Keras base class for transpose convolution layers.\"\"\"\n+\n+from keras_core import activations\n+from keras_core import constraints\n+from keras_core import initializers\n+from keras_core import operations as ops\n+from keras_core import regularizers\n+from keras_core.backend import standardize_data_format\n+from keras_core.backend.common.backend_utils import (\n+    compute_conv_transpose_output_shape,\n+)\n+from keras_core.layers.input_spec import InputSpec\n+from keras_core.layers.layer import Layer\n+\n+\n+class BaseConvTranspose(Layer):\n+    \"\"\"Abstract N-D transpose convolution layer.\n+\n+    The need for transposed convolutions generally arises\n+    from the desire to use a transformation going in the opposite direction\n+    of a normal convolution, i.e., from something that has the shape of the\n+    output of some convolution to something that has the shape of its input\n+    while maintaining a connectivity pattern that is compatible with\n+    said convolution.\n+\n+    Args:\n+        rank: int, the rank of the transposed convolution, e.g. 2 for 2D\n+            transposed convolution.\n+        filters: int, the dimension of the output space (the number of filters\n+            in the transposed convolution).\n+        kernel_size: int or tuple/list of N integers (N=`rank`), specifying the\n+            size of the transposed convolution window.\n+        strides: int or tuple/list of N integers, specifying the stride length\n+            of the transposed convolution. If only one int is specified, the\n+            same stride size will be used for all dimensions.\n+            `stride value != 1` is incompatible with `dilation_rate != 1`.\n+        padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n+            `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n+            the left/right or up/down of the input such that output has the same\n+            height/width dimension as the input.\n+        data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n+            The ordering of the dimensions in the inputs. `\"channels_last\"`\n+            corresponds to inputs with shape `(batch, steps, features)`\n+            while `\"channels_first\"` corresponds to inputs with shape\n+            `(batch, features, steps)`. It defaults to the `image_data_format`\n+            value found in your Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be `\"channels_last\"`.\n+        dilation_rate: int or tuple/list of N integers, specifying the dilation\n+            rate to use for dilated convolution. If only one int is specified,\n+            the same dilation rate will be used for all dimensions.\n+        activation: Activation function. If `None`, no activation is applied.\n+        use_bias: bool, if `True`, bias will be added to the output.\n+        kernel_initializer: Initializer for the convolution kernel. If `None`,\n+            the default initializer (`\"glorot_uniform\"`) will be used.\n+        bias_initializer: Initializer for the bias vector. If `None`, the\n+            default initializer (`\"zeros\"`) will be used.\n+        kernel_regularizer: Optional regularizer for the convolution kernel.\n+        bias_regularizer: Optional regularizer for the bias vector.\n+        activity_regularizer: Optional regularizer function for the output.\n+        kernel_constraint: Optional projection function to be applied to the\n+            kernel after being updated by an `Optimizer` (e.g. used to implement\n+            norm constraints or value constraints for layer weights). The\n+            function must take as input the unprojected variable and must return\n+            the projected variable (which must have the same shape). Constraints\n+            are not safe to use when doing asynchronous distributed training.\n+        bias_constraint: Optional projection function to be applied to the\n+            bias after being updated by an `Optimizer`.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        rank,\n+        filters,\n+        kernel_size,\n+        strides=1,\n+        padding=\"valid\",\n+        data_format=None,\n+        dilation_rate=1,\n+        activation=None,\n+        use_bias=True,\n+        kernel_initializer=\"glorot_uniform\",\n+        bias_initializer=\"zeros\",\n+        kernel_regularizer=None,\n+        bias_regularizer=None,\n+        activity_regularizer=None,\n+        kernel_constraint=None,\n+        bias_constraint=None,\n+        trainable=True,\n+        name=None,\n+        **kwargs,\n+    ):\n+        super().__init__(\n+            trainable=trainable,\n+            name=name,\n+            activity_regularizer=activity_regularizer,\n+            **kwargs,\n+        )\n+        self.rank = rank\n+        self.filters = filters\n+\n+        if isinstance(kernel_size, int):\n+            kernel_size = (kernel_size,) * self.rank\n+        self.kernel_size = kernel_size\n+\n+        if isinstance(strides, int):\n+            strides = (strides,) * self.rank\n+        self.strides = strides\n+\n+        if isinstance(dilation_rate, int):\n+            dilation_rate = (dilation_rate,) * self.rank\n+        self.dilation_rate = dilation_rate\n+\n+        self.padding = padding\n+        self.data_format = standardize_data_format(data_format)\n+        self.activation = activations.get(activation)\n+        self.use_bias = use_bias\n+        self.kernel_initializer = initializers.get(kernel_initializer)\n+        self.bias_initializer = initializers.get(bias_initializer)\n+        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n+        self.bias_regularizer = regularizers.get(bias_regularizer)\n+        self.kernel_constraint = constraints.get(kernel_constraint)\n+        self.bias_constraint = constraints.get(bias_constraint)\n+        self.input_spec = InputSpec(min_ndim=self.rank + 2)\n+        self.data_format = self.data_format\n+\n+        if self.filters is not None and self.filters <= 0:\n+            raise ValueError(\n+                \"Invalid value for argument `filters`. Expected a strictly \"\n+                f\"positive value. Received filters={self.filters}.\"\n+            )\n+\n+        if not all(self.kernel_size):\n+            raise ValueError(\n+                \"The argument `kernel_size` cannot contain 0. Received: \"\n+                f\"{self.kernel_size}\"\n+            )\n+\n+        if not all(self.strides):\n+            raise ValueError(\n+                \"The argument `strides` cannot contains 0. Received: \"\n+                f\"{self.strides}\"\n+            )\n+\n+        if max(self.strides) > 1 and max(self.dilation_rate) > 1:\n+            raise ValueError(\n+                \"`strides > 1` not supported in conjunction with \"\n+                f\"`dilation_rate > 1`. Received: strides={self.strides} and \"\n+                f\"dilation_rate={self.dilation_rate}\"\n+            )\n+\n+    def build(self, input_shape):\n+        if self.data_format == \"channels_last\":\n+            channel_axis = -1\n+            input_channel = input_shape[-1]\n+        else:\n+            channel_axis = 1\n+            input_channel = input_shape[1]\n+        self.input_spec = InputSpec(\n+            min_ndim=self.rank + 2, axes={channel_axis: input_channel}\n+        )\n+        kernel_shape = self.kernel_size + (\n+            self.filters,\n+            input_channel,\n+        )\n+\n+        self.kernel = self.add_weight(\n+            name=\"kernel\",\n+            shape=kernel_shape,\n+            initializer=self.kernel_initializer,\n+            regularizer=self.kernel_regularizer,\n+            constraint=self.kernel_constraint,\n+            trainable=True,\n+            dtype=self.dtype,\n+        )\n+        if self.use_bias:\n+            self.bias = self.add_weight(\n+                name=\"bias\",\n+                shape=(self.filters,),\n+                initializer=self.bias_initializer,\n+                regularizer=self.bias_regularizer,\n+                constraint=self.bias_constraint,\n+                trainable=True,\n+                dtype=self.dtype,\n+            )\n+        else:\n+            self.bias = None\n+        self.built = True\n+\n+    def call(self, inputs):\n+        outputs = ops.conv_transpose(\n+            inputs,\n+            self.kernel,\n+            strides=list(self.strides),\n+            padding=self.padding,\n+            dilation_rate=self.dilation_rate,\n+            data_format=self.data_format,\n+        )\n+\n+        if self.use_bias:\n+            if self.data_format == \"channels_last\":\n+                bias_shape = (1,) * (self.rank + 1) + (self.filters,)\n+            else:\n+                bias_shape = (1, self.filters) + (1,) * self.rank\n+            bias = ops.reshape(self.bias, bias_shape)\n+            outputs += bias\n+\n+        if self.activation is not None:\n+            return self.activation(outputs)\n+        return outputs\n+\n+    def compute_output_shape(self, input_shape):\n+        return compute_conv_transpose_output_shape(\n+            input_shape,\n+            self.kernel_size,\n+            self.filters,\n+            strides=self.strides,\n+            padding=self.padding,\n+            data_format=self.data_format,\n+            dilation_rate=self.dilation_rate,\n+        )\n+\n+    def get_config(self):\n+        config = super().get_config()\n+        config.update(\n+            {\n+                \"filters\": self.filters,\n+                \"kernel_size\": self.kernel_size,\n+                \"strides\": self.strides,\n+                \"padding\": self.padding,\n+                \"data_format\": self.data_format,\n+                \"dilation_rate\": self.dilation_rate,\n+                \"activation\": activations.serialize(self.activation),\n+                \"use_bias\": self.use_bias,\n+                \"kernel_initializer\": initializers.serialize(\n+                    self.kernel_initializer\n+                ),\n+                \"bias_initializer\": initializers.serialize(\n+                    self.bias_initializer\n+                ),\n+                \"kernel_regularizer\": regularizers.serialize(\n+                    self.kernel_regularizer\n+                ),\n+                \"bias_regularizer\": regularizers.serialize(\n+                    self.bias_regularizer\n+                ),\n+                \"activity_regularizer\": regularizers.serialize(\n+                    self.activity_regularizer\n+                ),\n+                \"kernel_constraint\": constraints.serialize(\n+                    self.kernel_constraint\n+                ),\n+                \"bias_constraint\": constraints.serialize(self.bias_constraint),\n+            }\n+        )\n+        return config\n\n@@ -80,8 +80,7 @@ class Conv1D(BaseConv):\n \n     >>> # The inputs are 128-length vectors with 10 timesteps, and the\n     >>> # batch size is 4.\n-    >>> input_shape = (4, 10, 128)\n-    >>> x = np.random.normal(4, 10, 128)\n+    >>> x = np.random.rand(4, 10, 128)\n     >>> y = keras_core.layers.Conv1D(32, 3, activation='relu')(x)\n     >>> print(y.shape)\n     (4, 8, 32)\n\n@@ -0,0 +1,136 @@\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.convolutional.base_conv_transpose import (\n+    BaseConvTranspose,\n+)\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.layers.Conv1DTranspose\",\n+        \"keras_core.layers.Convolution1DTranspose\",\n+    ]\n+)\n+class Conv1DTranspose(BaseConvTranspose):\n+    \"\"\"1D transposed convolution layer.\n+\n+    The need for transposed convolutions generally arise from the desire to use\n+    a transformation going in the opposite direction of a normal convolution,\n+    i.e., from something that has the shape of the output of some convolution\n+    to something that has the shape of its input while maintaining a\n+    connectivity pattern that is compatible with said convolution.\n+\n+    Args:\n+        filters: int, the dimension of the output space (the number of filters\n+            in the transpose convolution).\n+        kernel_size: int or tuple/list of 1 integer, specifying the size of the\n+            transposed convolution window.\n+        strides: int or tuple/list of 1 integer, specifying the stride length\n+            of the transposed convolution. `stride value != 1` is incompatible\n+            with `dilation_rate != 1`.\n+        padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n+            `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n+            the left/right or up/down of the input such that output has the same\n+            height/width dimension as the input.\n+        data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n+            The ordering of the dimensions in the inputs. `\"channels_last\"`\n+            corresponds to inputs with shape `(batch, steps, features)`\n+            while `\"channels_first\"` corresponds to inputs with shape\n+            `(batch, features, steps)`. It defaults to the `image_data_format`\n+            value found in your Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be `\"channels_last\"`.\n+        dilation_rate: int or tuple/list of 1 integers, specifying the dilation\n+            rate to use for dilated transposed convolution.\n+        groups: A positive int specifying the number of groups in which the\n+            input is split along the channel axis. Each group is convolved\n+            separately with `filters // groups` filters. The output is the\n+            concatenation of all the `groups` results along the channel axis.\n+            Input channels and `filters` must both be divisible by `groups`.\n+        activation: Activation function. If `None`, no activation is applied.\n+        use_bias: bool, if `True`, bias will be added to the output.\n+        kernel_initializer: Initializer for the convolution kernel. If `None`,\n+            the default initializer (`\"glorot_uniform\"`) will be used.\n+        bias_initializer: Initializer for the bias vector. If `None`, the\n+            default initializer (`\"zeros\"`) will be used.\n+        kernel_regularizer: Optional regularizer for the convolution kernel.\n+        bias_regularizer: Optional regularizer for the bias vector.\n+        activity_regularizer: Optional regularizer function for the output.\n+        kernel_constraint: Optional projection function to be applied to the\n+            kernel after being updated by an `Optimizer` (e.g. used to implement\n+            norm constraints or value constraints for layer weights). The\n+            function must take as input the unprojected variable and must return\n+            the projected variable (which must have the same shape). Constraints\n+            are not safe to use when doing asynchronous distributed training.\n+        bias_constraint: Optional projection function to be applied to the\n+            bias after being updated by an `Optimizer`.\n+\n+    Input shape:\n+    - If `data_format=\"channels_last\"`:\n+        A 3D tensor with shape: `(batch_shape, steps, channels)`\n+    - If `data_format=\"channels_first\"`:\n+        A 3D tensor with shape: `(batch_shape, channels, steps)`\n+\n+    Output shape:\n+    - If `data_format=\"channels_last\"`:\n+        A 3D tensor with shape: `(batch_shape, new_steps, channels)`\n+    - If `data_format=\"channels_first\"`:\n+        A 3D tensor with shape: `(batch_shape, channels, new_steps)`\n+\n+    Returns:\n+        A 3D tensor representing\n+        `activation(conv1d_transpose(inputs, kernel) + bias)`.\n+\n+    Raises:\n+        ValueError: when both `strides > 1` and `dilation_rate > 1`.\n+\n+    References:\n+    - [A guide to convolution arithmetic for deep learning](\n+        https://arxiv.org/abs/1603.07285v1)\n+    - [Deconvolutional Networks](\n+        https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n+\n+    Examples:\n+\n+    >>> x = np.random.rand(4, 10, 128)\n+    >>> y = keras_core.layers.Conv1DTranspose(32, 3, 2, activation='relu')(x)\n+    >>> print(y.shape)\n+    (4, 21, 32)\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        filters,\n+        kernel_size,\n+        strides=1,\n+        padding=\"valid\",\n+        data_format=\"channels_last\",\n+        dilation_rate=1,\n+        activation=None,\n+        use_bias=True,\n+        kernel_initializer=\"glorot_uniform\",\n+        bias_initializer=\"zeros\",\n+        kernel_regularizer=None,\n+        bias_regularizer=None,\n+        activity_regularizer=None,\n+        kernel_constraint=None,\n+        bias_constraint=None,\n+        **kwargs\n+    ):\n+        super().__init__(\n+            rank=1,\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+            activation=activation,\n+            use_bias=use_bias,\n+            kernel_initializer=kernel_initializer,\n+            bias_initializer=bias_initializer,\n+            kernel_regularizer=kernel_regularizer,\n+            bias_regularizer=bias_regularizer,\n+            activity_regularizer=activity_regularizer,\n+            kernel_constraint=kernel_constraint,\n+            bias_constraint=bias_constraint,\n+            **kwargs\n+        )\n\n@@ -80,7 +80,7 @@ class Conv2D(BaseConv):\n \n     Examples:\n \n-    >>> x = np.random.normal(4, 10, 10, 128)\n+    >>> x = np.random.rand(4, 10, 10, 128)\n     >>> y = keras_core.layers.Conv2D(32, 3, activation='relu')(x)\n     >>> print(y.shape)\n     (4, 8, 8, 32)\n\n@@ -0,0 +1,133 @@\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.convolutional.base_conv_transpose import (\n+    BaseConvTranspose,\n+)\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.layers.Conv2DTranspose\",\n+        \"keras_core.layers.Convolution2DTranspose\",\n+    ]\n+)\n+class Conv2DTranspose(BaseConvTranspose):\n+    \"\"\"2D transposed convolution layer.\n+\n+    The need for transposed convolutions generally arise from the desire to use\n+    a transformation going in the opposite direction of a normal convolution,\n+    i.e., from something that has the shape of the output of some convolution\n+    to something that has the shape of its input while maintaining a\n+    connectivity pattern that is compatible with said convolution.\n+\n+    Args:\n+        filters: int, the dimension of the output space (the number of filters\n+            in the transposed convolution).\n+        kernel_size: int or tuple/list of 1 integer, specifying the size of the\n+            transposed convolution window.\n+        strides: int or tuple/list of 1 integer, specifying the stride length\n+            of the transposed convolution. `stride value != 1` is incompatible\n+            with `dilation_rate != 1`.\n+        padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n+            `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n+            the left/right or up/down of the input such that output has the same\n+            height/width dimension as the input.\n+        data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n+            The ordering of the dimensions in the inputs. `\"channels_last\"`\n+            corresponds to inputs with shape\n+            `(batch_size, channels, height, width)`\n+            while `\"channels_first\"` corresponds to inputs with shape\n+            `(batch_size, channels, height, width)`. It defaults to the\n+            `image_data_format` value found in your Keras config file at\n+            `~/.keras/keras.json`. If you never set it, then it will be\n+            `\"channels_last\"`.\n+        dilation_rate: int or tuple/list of 1 integers, specifying the dilation\n+            rate to use for dilated transposed convolution.\n+        activation: Activation function. If `None`, no activation is applied.\n+        use_bias: bool, if `True`, bias will be added to the output.\n+        kernel_initializer: Initializer for the convolution kernel. If `None`,\n+            the default initializer (`\"glorot_uniform\"`) will be used.\n+        bias_initializer: Initializer for the bias vector. If `None`, the\n+            default initializer (`\"zeros\"`) will be used.\n+        kernel_regularizer: Optional regularizer for the convolution kernel.\n+        bias_regularizer: Optional regularizer for the bias vector.\n+        activity_regularizer: Optional regularizer function for the output.\n+        kernel_constraint: Optional projection function to be applied to the\n+            kernel after being updated by an `Optimizer` (e.g. used to implement\n+            norm constraints or value constraints for layer weights). The\n+            function must take as input the unprojected variable and must return\n+            the projected variable (which must have the same shape). Constraints\n+            are not safe to use when doing asynchronous distributed training.\n+        bias_constraint: Optional projection function to be applied to the\n+            bias after being updated by an `Optimizer`.\n+\n+    Input shape:\n+    - If `data_format=\"channels_last\"`:\n+        A 4D tensor with shape: `(batch_size, height, width, channels)`\n+    - If `data_format=\"channels_first\"`:\n+        A 4D tensor with shape: `(batch_size, channels, height, width)`\n+\n+    Output shape:\n+    - If `data_format=\"channels_last\"`:\n+        A 4D tensor with shape: `(batch_size, new_height, new_width filters)`\n+    - If `data_format=\"channels_first\"`:\n+        A 4D tensor with shape: `(batch_size, filters, new_height, new_width)`\n+\n+    Returns:\n+        A 4D tensor representing\n+        `activation(conv2d_transpose(inputs, kernel) + bias)`.\n+\n+    Raises:\n+        ValueError: when both `strides > 1` and `dilation_rate > 1`.\n+\n+    References:\n+    - [A guide to convolution arithmetic for deep learning](\n+        https://arxiv.org/abs/1603.07285v1)\n+    - [Deconvolutional Networks](\n+        https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n+\n+    Examples:\n+\n+    >>> x = np.random.rand(4, 10, 8, 128)\n+    >>> y = keras_core.layers.Conv2DTranspose(32, 2, 2, activation='relu')(x)\n+    >>> print(y.shape)\n+    (4, 20, 16, 32)\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        filters,\n+        kernel_size,\n+        strides=1,\n+        padding=\"valid\",\n+        data_format=\"channels_last\",\n+        dilation_rate=1,\n+        activation=None,\n+        use_bias=True,\n+        kernel_initializer=\"glorot_uniform\",\n+        bias_initializer=\"zeros\",\n+        kernel_regularizer=None,\n+        bias_regularizer=None,\n+        activity_regularizer=None,\n+        kernel_constraint=None,\n+        bias_constraint=None,\n+        **kwargs\n+    ):\n+        super().__init__(\n+            rank=2,\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+            activation=activation,\n+            use_bias=use_bias,\n+            kernel_initializer=kernel_initializer,\n+            bias_initializer=bias_initializer,\n+            kernel_regularizer=kernel_regularizer,\n+            bias_regularizer=bias_regularizer,\n+            activity_regularizer=activity_regularizer,\n+            kernel_constraint=kernel_constraint,\n+            bias_constraint=bias_constraint,\n+            **kwargs\n+        )\n\n@@ -0,0 +1,138 @@\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.convolutional.base_conv_transpose import (\n+    BaseConvTranspose,\n+)\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.layers.Conv3DTranspose\",\n+        \"keras_core.layers.Convolution3DTranspose\",\n+    ]\n+)\n+class Conv3DTranspose(BaseConvTranspose):\n+    \"\"\"3D transposed convolution layer.\n+\n+    The need for transposed convolutions generally arise from the desire to use\n+    a transformation going in the opposite direction of a normal convolution,\n+    i.e., from something that has the shape of the output of some convolution\n+    to something that has the shape of its input while maintaining a\n+    connectivity pattern that is compatible with said convolution.\n+\n+    Args:\n+        filters: int, the dimension of the output space (the number of filters\n+            in the transposed convolution).\n+        kernel_size: int or tuple/list of 1 integer, specifying the size of the\n+            transposed convolution window.\n+        strides: int or tuple/list of 1 integer, specifying the stride length\n+            of the transposed convolution. `stride value != 1` is incompatible\n+            with `dilation_rate != 1`.\n+        padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n+            `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n+            the left/right or up/down of the input such that output has the same\n+            height/width dimension as the input.\n+        data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n+            The ordering of the dimensions in the inputs. `\"channels_last\"`\n+            corresponds to inputs with shape\n+            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n+            while `\"channels_first\"` corresponds to inputs with shape\n+            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`.\n+            It defaults to the `image_data_format` value found in your Keras\n+            config file at `~/.keras/keras.json`. If you never set it, then it\n+            will be `\"channels_last\"`.\n+        dilation_rate: int or tuple/list of 1 integers, specifying the dilation\n+            rate to use for dilated transposed convolution.\n+        activation: Activation function. If `None`, no activation is applied.\n+        use_bias: bool, if `True`, bias will be added to the output.\n+        kernel_initializer: Initializer for the convolution kernel. If `None`,\n+            the default initializer (`\"glorot_uniform\"`) will be used.\n+        bias_initializer: Initializer for the bias vector. If `None`, the\n+            default initializer (`\"zeros\"`) will be used.\n+        kernel_regularizer: Optional regularizer for the convolution kernel.\n+        bias_regularizer: Optional regularizer for the bias vector.\n+        activity_regularizer: Optional regularizer function for the output.\n+        kernel_constraint: Optional projection function to be applied to the\n+            kernel after being updated by an `Optimizer` (e.g. used to implement\n+            norm constraints or value constraints for layer weights). The\n+            function must take as input the unprojected variable and must return\n+            the projected variable (which must have the same shape). Constraints\n+            are not safe to use when doing asynchronous distributed training.\n+        bias_constraint: Optional projection function to be applied to the\n+            bias after being updated by an `Optimizer`.\n+\n+    Input shape:\n+    - If `data_format=\"channels_last\"`:\n+        5D tensor with shape:\n+        `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n+    - If `data_format=\"channels_first\"`:\n+        5D tensor with shape:\n+        `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n+\n+    Output shape:\n+    - If `data_format=\"channels_last\"`:\n+        5D tensor with shape:\n+        `(batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3,\n+        channels)`\n+    - If `data_format=\"channels_first\"`:\n+        5D tensor with shape:\n+        `(batch_size, channels, new_spatial_dim1, new_spatial_dim2,\n+        new_spatial_dim3)`\n+\n+    Returns:\n+        A 5D tensor representing `activation(conv3d(inputs, kernel) + bias)`.\n+\n+    Raises:\n+        ValueError: when both `strides > 1` and `dilation_rate > 1`.\n+\n+    References:\n+    - [A guide to convolution arithmetic for deep learning](\n+        https://arxiv.org/abs/1603.07285v1)\n+    - [Deconvolutional Networks](\n+        https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n+\n+    Examples:\n+\n+    >>> x = np.random.rand(4, 10, 8, 12, 128)\n+    >>> y = keras_core.layers.Conv3DTranspose(32, 2, 2, activation='relu')(x)\n+    >>> print(y.shape)\n+    (4, 20, 16, 24, 32)\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        filters,\n+        kernel_size,\n+        strides=1,\n+        padding=\"valid\",\n+        data_format=\"channels_last\",\n+        dilation_rate=1,\n+        activation=None,\n+        use_bias=True,\n+        kernel_initializer=\"glorot_uniform\",\n+        bias_initializer=\"zeros\",\n+        kernel_regularizer=None,\n+        bias_regularizer=None,\n+        activity_regularizer=None,\n+        kernel_constraint=None,\n+        bias_constraint=None,\n+        **kwargs\n+    ):\n+        super().__init__(\n+            rank=3,\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+            activation=activation,\n+            use_bias=use_bias,\n+            kernel_initializer=kernel_initializer,\n+            bias_initializer=bias_initializer,\n+            kernel_regularizer=kernel_regularizer,\n+            bias_regularizer=bias_regularizer,\n+            activity_regularizer=activity_regularizer,\n+            kernel_constraint=kernel_constraint,\n+            bias_constraint=bias_constraint,\n+            **kwargs\n+        )\n\n@@ -0,0 +1,420 @@\n+import numpy as np\n+import tensorflow as tf\n+from absl.testing import parameterized\n+\n+from keras_core import layers\n+from keras_core import testing\n+\n+\n+class ConvTransposeBasicTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.parameters(\n+        {\n+            \"filters\": 5,\n+            \"kernel_size\": 2,\n+            \"strides\": 2,\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+            \"input_shape\": (2, 8, 4),\n+            \"output_shape\": (2, 16, 5),\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": 3,\n+            \"padding\": \"same\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1,),\n+            \"input_shape\": (2, 8, 4),\n+            \"output_shape\": (2, 24, 6),\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": (2,),\n+            \"strides\": (2,),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+            \"input_shape\": (2, 8, 4),\n+            \"output_shape\": (2, 16, 6),\n+        },\n+    )\n+    def test_conv1d_transpose_basic(\n+        self,\n+        filters,\n+        kernel_size,\n+        strides,\n+        padding,\n+        data_format,\n+        dilation_rate,\n+        input_shape,\n+        output_shape,\n+    ):\n+        self.run_layer_test(\n+            layers.Conv1DTranspose,\n+            init_kwargs={\n+                \"filters\": filters,\n+                \"kernel_size\": kernel_size,\n+                \"strides\": strides,\n+                \"padding\": padding,\n+                \"data_format\": data_format,\n+                \"dilation_rate\": dilation_rate,\n+            },\n+            input_shape=input_shape,\n+            expected_output_shape=output_shape,\n+            expected_num_trainable_weights=2,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+        )\n+\n+    @parameterized.parameters(\n+        {\n+            \"filters\": 5,\n+            \"kernel_size\": 2,\n+            \"strides\": 2,\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+            \"input_shape\": (2, 8, 8, 4),\n+            \"output_shape\": (2, 16, 16, 5),\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": 3,\n+            \"padding\": \"same\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1, 1),\n+            \"input_shape\": (2, 8, 8, 4),\n+            \"output_shape\": (2, 24, 24, 6),\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": (2, 3),\n+            \"strides\": (2, 1),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1, 1),\n+            \"input_shape\": (2, 8, 8, 4),\n+            \"output_shape\": (2, 16, 10, 6),\n+        },\n+    )\n+    def test_conv2d_transpose_basic(\n+        self,\n+        filters,\n+        kernel_size,\n+        strides,\n+        padding,\n+        data_format,\n+        dilation_rate,\n+        input_shape,\n+        output_shape,\n+    ):\n+        self.run_layer_test(\n+            layers.Conv2DTranspose,\n+            init_kwargs={\n+                \"filters\": filters,\n+                \"kernel_size\": kernel_size,\n+                \"strides\": strides,\n+                \"padding\": padding,\n+                \"data_format\": data_format,\n+                \"dilation_rate\": dilation_rate,\n+            },\n+            input_shape=input_shape,\n+            expected_output_shape=output_shape,\n+            expected_num_trainable_weights=2,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+        )\n+\n+    @parameterized.parameters(\n+        {\n+            \"filters\": 5,\n+            \"kernel_size\": 2,\n+            \"strides\": 2,\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+            \"input_shape\": (2, 8, 8, 8, 4),\n+            \"output_shape\": (2, 16, 16, 16, 5),\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": 3,\n+            \"padding\": \"same\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1, 1, 1),\n+            \"input_shape\": (2, 8, 8, 8, 4),\n+            \"output_shape\": (2, 24, 24, 24, 6),\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": (2, 2, 3),\n+            \"strides\": (2, 1, 2),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1, 1, 1),\n+            \"input_shape\": (2, 8, 8, 8, 4),\n+            \"output_shape\": (2, 16, 9, 17, 6),\n+        },\n+    )\n+    def test_conv3d_transpose_basic(\n+        self,\n+        filters,\n+        kernel_size,\n+        strides,\n+        padding,\n+        data_format,\n+        dilation_rate,\n+        input_shape,\n+        output_shape,\n+    ):\n+        self.run_layer_test(\n+            layers.Conv3DTranspose,\n+            init_kwargs={\n+                \"filters\": filters,\n+                \"kernel_size\": kernel_size,\n+                \"strides\": strides,\n+                \"padding\": padding,\n+                \"data_format\": data_format,\n+                \"dilation_rate\": dilation_rate,\n+            },\n+            input_shape=input_shape,\n+            expected_output_shape=output_shape,\n+            expected_num_trainable_weights=2,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+        )\n+\n+    def test_bad_init_args(self):\n+        # `filters` is not positive.\n+        with self.assertRaises(ValueError):\n+            layers.Conv1DTranspose(filters=0, kernel_size=1)\n+\n+        # `kernel_size` has 0.\n+        with self.assertRaises(ValueError):\n+            layers.Conv2DTranspose(filters=2, kernel_size=(1, 0))\n+\n+        # `strides` has 0.\n+        with self.assertRaises(ValueError):\n+            layers.Conv2DTranspose(\n+                filters=2, kernel_size=(2, 2), strides=(1, 0)\n+            )\n+\n+        # `dilation_rate > 1` while `strides > 1`.\n+        with self.assertRaises(ValueError):\n+            layers.Conv2DTranspose(\n+                filters=2, kernel_size=(2, 2), strides=2, dilation_rate=(2, 1)\n+            )\n+\n+\n+class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.parameters(\n+        {\n+            \"filters\": 5,\n+            \"kernel_size\": 2,\n+            \"strides\": 2,\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": 3,\n+            \"padding\": \"same\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1,),\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": (2,),\n+            \"strides\": (2,),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+        },\n+    )\n+    def test_conv1d_transpose(\n+        self,\n+        filters,\n+        kernel_size,\n+        strides,\n+        padding,\n+        data_format,\n+        dilation_rate,\n+    ):\n+        layer = layers.Conv1DTranspose(\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+        )\n+        tf_keras_layer = tf.keras.layers.Conv1DTranspose(\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+        )\n+\n+        inputs = np.random.normal(size=[2, 8, 4])\n+        layer.build(input_shape=inputs.shape)\n+        tf_keras_layer.build(input_shape=inputs.shape)\n+\n+        kernel_shape = layer.kernel.shape\n+        kernel_weights = np.random.normal(size=kernel_shape)\n+        bias_weights = np.random.normal(size=(filters,))\n+        layer.kernel.assign(kernel_weights)\n+        tf_keras_layer.kernel.assign(kernel_weights)\n+\n+        layer.bias.assign(bias_weights)\n+        tf_keras_layer.bias.assign(bias_weights)\n+\n+        outputs = layer(inputs)\n+        expected = tf_keras_layer(inputs)\n+        self.assertAllClose(outputs, expected)\n+\n+    @parameterized.parameters(\n+        {\n+            \"filters\": 5,\n+            \"kernel_size\": 2,\n+            \"strides\": 2,\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": 3,\n+            \"padding\": \"same\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1, 1),\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": (2, 3),\n+            \"strides\": (2, 1),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1, 1),\n+        },\n+    )\n+    def test_conv2d_transpose(\n+        self,\n+        filters,\n+        kernel_size,\n+        strides,\n+        padding,\n+        data_format,\n+        dilation_rate,\n+    ):\n+        layer = layers.Conv2DTranspose(\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+        )\n+        tf_keras_layer = tf.keras.layers.Conv2DTranspose(\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+        )\n+\n+        inputs = np.random.normal(size=[2, 8, 8, 4])\n+        layer.build(input_shape=inputs.shape)\n+        tf_keras_layer.build(input_shape=inputs.shape)\n+\n+        kernel_shape = layer.kernel.shape\n+        kernel_weights = np.random.normal(size=kernel_shape)\n+        bias_weights = np.random.normal(size=(filters,))\n+        layer.kernel.assign(kernel_weights)\n+        tf_keras_layer.kernel.assign(kernel_weights)\n+\n+        layer.bias.assign(bias_weights)\n+        tf_keras_layer.bias.assign(bias_weights)\n+\n+        outputs = layer(inputs)\n+        expected = tf_keras_layer(inputs)\n+        self.assertAllClose(outputs, expected)\n+\n+    @parameterized.parameters(\n+        {\n+            \"filters\": 5,\n+            \"kernel_size\": 2,\n+            \"strides\": 2,\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": 1,\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": 3,\n+            \"padding\": \"same\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1, 1, 1),\n+        },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": (2, 2, 3),\n+            \"strides\": (2, 1, 2),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (1, 1, 1),\n+        },\n+    )\n+    def test_conv3d_transpose(\n+        self,\n+        filters,\n+        kernel_size,\n+        strides,\n+        padding,\n+        data_format,\n+        dilation_rate,\n+    ):\n+        layer = layers.Conv3DTranspose(\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+        )\n+        tf_keras_layer = tf.keras.layers.Conv3DTranspose(\n+            filters=filters,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            dilation_rate=dilation_rate,\n+        )\n+\n+        inputs = np.random.normal(size=[2, 8, 8, 8, 4])\n+        layer.build(input_shape=inputs.shape)\n+        tf_keras_layer.build(input_shape=inputs.shape)\n+\n+        kernel_shape = layer.kernel.shape\n+        kernel_weights = np.random.normal(size=kernel_shape)\n+        bias_weights = np.random.normal(size=(filters,))\n+        layer.kernel.assign(kernel_weights)\n+        tf_keras_layer.kernel.assign(kernel_weights)\n+\n+        layer.bias.assign(bias_weights)\n+        tf_keras_layer.bias.assign(bias_weights)\n+        outputs = layer(inputs)\n+        expected = tf_keras_layer(inputs)\n+        self.assertAllClose(outputs, expected)\n\n@@ -831,9 +831,12 @@ class ConvTranspose(Operation):\n         )\n \n     def compute_output_spec(self, inputs, kernel):\n+        kernel_size = kernel.shape[:-2]\n+        filters = kernel.shape[-2]\n         output_shape = compute_conv_transpose_output_shape(\n-            inputs,\n-            kernel,\n+            inputs.shape,\n+            kernel_size,\n+            filters,\n             self.strides,\n             self.padding,\n             self.output_padding,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
