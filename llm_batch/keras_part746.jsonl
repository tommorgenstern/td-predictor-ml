{"custom_id": "keras#39d034a2d1f6da75d521332c2d4954dfb9d53a89", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 139 | Lines Deleted: 13 | Files Changed: 4 | Hunks: 10 | Methods Changed: 11 | Complexity Δ (Sum/Max): 19/9 | Churn Δ: 152 | Churn Cumulative: 206 | Contributors (this commit): 2 | Commits (past 90d): 7 | Contributors (cumulative): 7 | DMM Complexity: 0.7582417582417582\n\nDIFF:\n@@ -1,13 +1,16 @@\n import tensorflow as tf\n \n+from keras.backend.tensorflow.trackable import KerasAutoTrackable\n from keras.utils import tf_utils\n+from keras.utils import tracking\n \n \n-class TFLayer(tf.__internal__.tracking.AutoTrackable):\n+class TFLayer(KerasAutoTrackable):\n     def __init__(self, *args, **kwargs):\n         # Export-related attributes\n         self._saved_model_inputs_spec = None\n         self._saved_model_arg_spec = None\n+        self._tracked = []\n \n     @tf.__internal__.tracking.no_automatic_dependency_tracking\n     def _set_save_spec(self, inputs, args=None, kwargs=None):\n@@ -58,6 +61,15 @@ class TFLayer(tf.__internal__.tracking.AutoTrackable):\n             self.test_function = test_function\n             self.predict_function = predict_function\n \n+            for tracked_attr in self._tracked:\n+                tracked_item = getattr(self, tracked_attr)\n+                if isinstance(tracked_item, tracking.TrackedList):\n+                    children[tracked_attr] = list(tracked_item)\n+                if isinstance(tracked_item, tracking.TrackedDict):\n+                    children[tracked_attr] = dict(tracked_item)\n+                if isinstance(tracked_item, tracking.TrackedSet):\n+                    children[tracked_attr] = list(tracked_item)\n+\n         return children\n \n     @property\n\n@@ -178,3 +178,71 @@ class SavedModelTest(testing.TestCase):\n         restored_model = tf.saved_model.load(path)\n         output = restored_model.call(*inp)\n         self.assertAllClose(expected, output, rtol=1e-4, atol=1e-4)\n+\n+    def test_list_trackable_children_tracking(self):\n+        @object_registration.register_keras_serializable(package=\"my_package\")\n+        class CustomLayerList(layers.Layer):\n+            def __init__(self):\n+                super().__init__()\n+                self.sublayers = [\n+                    layers.Dense(2),\n+                    layers.Dense(2),\n+                ]\n+\n+            def call(self, inputs):\n+                x = inputs\n+                for sublayer in self.sublayers:\n+                    x = sublayer(x)\n+                return x\n+\n+        inputs = layers.Input(shape=(1,))\n+        outputs = CustomLayerList()(inputs)\n+        model = models.Model(inputs, outputs)\n+\n+        inp = np.array([[1.0]])\n+        expected = model(inp)\n+        path = os.path.join(self.get_temp_dir(), \"my_keras_model\")\n+        tf.saved_model.save(model, path)\n+        restored_model = tf.saved_model.load(path)\n+        self.assertAllClose(\n+            expected,\n+            restored_model.signatures[\"serving_default\"](\n+                tf.convert_to_tensor(inp, dtype=tf.float32)\n+            )[\"output_0\"],\n+            rtol=1e-4,\n+            atol=1e-4,\n+        )\n+\n+    def test_dict_trackable_children_tracking(self):\n+        @object_registration.register_keras_serializable(package=\"my_package\")\n+        class CustomLayerDict(layers.Layer):\n+            def __init__(self):\n+                super().__init__()\n+                self.sublayers = {\n+                    \"first_layer\": layers.Dense(2),\n+                    \"second_layer\": layers.Dense(2),\n+                }\n+\n+            def call(self, inputs):\n+                x = inputs\n+                for key, sublayer in self.sublayers.items():\n+                    x = sublayer(x)\n+                return x\n+\n+        inputs = layers.Input(shape=(1,))\n+        outputs = CustomLayerDict()(inputs)\n+        model = models.Model(inputs, outputs)\n+\n+        inp = np.array([[1.0]])\n+        expected = model(inp)\n+        path = os.path.join(self.get_temp_dir(), \"my_keras_model\")\n+        tf.saved_model.save(model, path)\n+        restored_model = tf.saved_model.load(path)\n+        self.assertAllClose(\n+            expected,\n+            restored_model.signatures[\"serving_default\"](\n+                tf.convert_to_tensor(inp, dtype=tf.float32)\n+            )[\"output_0\"],\n+            rtol=1e-4,\n+            atol=1e-4,\n+        )\n\n@@ -0,0 +1,58 @@\n+import tensorflow as tf\n+\n+from keras.utils import tracking\n+\n+\n+class KerasAutoTrackable(tf.__internal__.tracking.AutoTrackable):\n+    \"\"\"Manages dependencies on other objects with Keras tracking.\n+\n+    Similar to TF AutoTrackable, but disabling tracking is based\n+    on tracking within Keras.\n+\n+    This serves as an interface between Keras tracking and TF tracking.\n+    \"\"\"\n+\n+    def __setattr__(self, name, value):\n+        \"\"\"Support self.foo = trackable syntax.\"\"\"\n+        try:\n+            if getattr(self, name) is value:\n+                # Short circuit for `self.$x = self.$x`.\n+                return\n+        except AttributeError:\n+            pass\n+\n+        if getattr(self, \"_self_setattr_tracking\", True):\n+            value = sticky_attribute_assignment(\n+                trackable=self, value=value, name=name\n+            )\n+        super().__setattr__(name, value)\n+\n+\n+def sticky_attribute_assignment(trackable, name, value):\n+    \"\"\"Adds dependencies, called from __setattr__.\n+\n+    Args:\n+        trackable: The object to add dependencies to (generally the one having\n+        an attribute assigned).\n+        name: The attribute name being assigned.\n+        value: The value being assigned. Not necessarily a trackable object.\n+\n+    Returns:\n+        The value which should be stored in the attribute.\n+    \"\"\"\n+    if isinstance(\n+        value, (tracking.TrackedList, tracking.TrackedDict, tracking.TrackedSet)\n+    ) and hasattr(trackable, \"_tracked\"):\n+        trackable._tracked.append(name)\n+    if not tracking.is_tracking_enabled():\n+        return value\n+    if isinstance(value, tf.__internal__.tracking.Trackable):\n+        trackable._track_trackable(  # pylint: disable=protected-access\n+            value,\n+            name=name,\n+            # Allow the user to switch the Trackable which is tracked by this\n+            # name, since assigning a new variable to an attribute has\n+            # historically been fine (e.g. Adam did this).\n+            overwrite=True,\n+        )\n+    return value\n\n@@ -4,7 +4,6 @@ import tree\n \n from keras.api_export import keras_export\n from keras.backend import KerasTensor\n-from keras.backend.config import backend\n from keras.ops.operation import Operation\n from keras.utils.nest import pack_sequence_as\n \n@@ -47,21 +46,10 @@ class Function(Operation):\n     def __init__(self, inputs, outputs, name=None):\n         super().__init__(name=name)\n \n-        if backend() == \"tensorflow\":\n-            # Temporary work around for\n-            # https://github.com/keras-team/keras/issues/931\n-            # This stop tensorflow from wrapping tf.function output in a\n-            # _DictWrapper object.\n-            _self_setattr_tracking = getattr(\n-                self, \"_self_setattr_tracking\", True\n-            )\n-            self._self_setattr_tracking = False\n         self._inputs_struct = tree.map_structure(lambda x: x, inputs)\n         self._outputs_struct = tree.map_structure(lambda x: x, outputs)\n         self._inputs = tree.flatten(inputs)\n         self._outputs = tree.flatten(outputs)\n-        if backend() == \"tensorflow\":\n-            self._self_setattr_tracking = _self_setattr_tracking\n \n         (nodes, nodes_by_depth, operations, operations_by_depth) = map_graph(\n             self._inputs, self._outputs\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#59e60aa3c9a3baafc109601f6c2ad257d4df10a8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 306 | Lines Deleted: 15 | Files Changed: 3 | Hunks: 11 | Methods Changed: 20 | Complexity Δ (Sum/Max): 23/17 | Churn Δ: 321 | Churn Cumulative: 353 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 5 | DMM Complexity: 0.8157894736842105\n\nDIFF:\n@@ -54,13 +54,16 @@ class ModelCheckpointTest(testing.TestCase):\n         # automatic directory creation.\n         filepath = os.path.join(temp_dir, \"subdir\", \"checkpoint.keras\")\n         (x_train, y_train), (x_test, y_test) = test_utils.get_test_data(\n+            random_seed=42,\n             train_samples=TRAIN_SAMPLES,\n             test_samples=TEST_SAMPLES,\n             input_shape=(INPUT_DIM,),\n             num_classes=NUM_CLASSES,\n         )\n-        y_test = numerical_utils.to_categorical(y_test)\n-        y_train = numerical_utils.to_categorical(y_train)\n+        y_test = numerical_utils.to_categorical(y_test, num_classes=NUM_CLASSES)\n+        y_train = numerical_utils.to_categorical(\n+            y_train, num_classes=NUM_CLASSES\n+        )\n \n         # Case 1\n         monitor = \"val_loss\"\n@@ -449,7 +452,7 @@ class ModelCheckpointTest(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_model_checkpoint_loading(self):\n         def get_model():\n-            inputs = layers.Input(shape=(INPUT_DIM,), batch_size=2)\n+            inputs = layers.Input(shape=(INPUT_DIM,), batch_size=5)\n             x = layers.Dense(NUM_HIDDEN, activation=\"relu\")(inputs)\n             outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n             functional_model = models.Model(inputs, outputs)\n@@ -461,13 +464,16 @@ class ModelCheckpointTest(testing.TestCase):\n             return functional_model\n \n         (x_train, y_train), (x_test, y_test) = test_utils.get_test_data(\n+            random_seed=42,\n             train_samples=TRAIN_SAMPLES,\n             test_samples=TEST_SAMPLES,\n             input_shape=(INPUT_DIM,),\n             num_classes=NUM_CLASSES,\n         )\n-        y_test = numerical_utils.to_categorical(y_test)\n-        y_train = numerical_utils.to_categorical(y_train)\n+        y_test = numerical_utils.to_categorical(y_test, num_classes=NUM_CLASSES)\n+        y_train = numerical_utils.to_categorical(\n+            y_train, num_classes=NUM_CLASSES\n+        )\n \n         # Model Checkpoint load model (default)\n         model = get_model()\n\n@@ -4,7 +4,7 @@ import numpy as np\n def get_test_data(\n     train_samples, test_samples, input_shape, num_classes, random_seed=None\n ):\n-    \"\"\"Generates test data to train a model on.\n+    \"\"\"Generates balanced, stratified synthetic test data to train a model on.\n \n     Args:\n         train_samples: Integer, how many training samples to generate.\n@@ -16,17 +16,62 @@ def get_test_data(\n     Returns:\n         A tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n     \"\"\"\n-    if random_seed is not None:\n     np.random.seed(random_seed)\n-    num_sample = train_samples + test_samples\n+\n+    # Total samples\n+    total_samples = train_samples + test_samples\n+\n+    # Ensure that we generate a balanced dataset\n+    samples_per_class = total_samples // num_classes\n+    y = np.array(\n+        [i for i in range(num_classes) for _ in range(samples_per_class)],\n+        dtype=np.int32,\n+    )\n+\n+    # Generate extra samples in a deterministic manner\n+    extra_samples = total_samples - len(y)\n+    y_extra = np.array(\n+        [i % num_classes for i in range(extra_samples)], dtype=np.int64\n+    )\n+    y = np.concatenate([y, y_extra])\n+\n+    # Generate data\n     templates = 2 * num_classes * np.random.random((num_classes,) + input_shape)\n-    y = np.random.randint(0, num_classes, size=(num_sample,))\n-    x = np.zeros((num_sample,) + input_shape, dtype=np.float32)\n-    for i in range(num_sample):\n+    x = np.zeros((total_samples,) + input_shape, dtype=np.float32)\n+    for i in range(total_samples):\n         x[i] = templates[y[i]] + np.random.normal(\n             loc=0, scale=1.0, size=input_shape\n         )\n-    return (\n-        (x[:train_samples], y[:train_samples]),\n-        (x[train_samples:], y[train_samples:]),\n-    )\n+\n+    # Shuffle the entire dataset to ensure randomness based on seed\n+    indices = np.arange(total_samples)\n+    np.random.shuffle(indices)\n+    x, y = x[indices], y[indices]\n+\n+    # Stratified Shuffle Split\n+    x_train, y_train, x_test, y_test = [], [], [], []\n+    for cls in range(num_classes):\n+        cls_indices = np.where(y == cls)[0]\n+        np.random.shuffle(cls_indices)\n+        train_count = int(train_samples / num_classes)\n+\n+        x_train.extend(x[cls_indices[:train_count]])\n+        y_train.extend(y[cls_indices[:train_count]])\n+\n+        x_test.extend(x[cls_indices[train_count:]])\n+        y_test.extend(y[cls_indices[train_count:]])\n+\n+    # Convert to numpy arrays\n+    x_train, y_train = np.array(x_train), np.array(y_train)\n+    x_test, y_test = np.array(x_test), np.array(y_test)\n+\n+    # Shuffle training and test sets after stratified split\n+    train_indices = np.arange(len(x_train))\n+    test_indices = np.arange(len(x_test))\n+    np.random.shuffle(train_indices)\n+    np.random.shuffle(test_indices)\n+\n+    x_train, y_train = x_train[train_indices], y_train[train_indices]\n+    x_test, y_test = x_test[test_indices], y_test[test_indices]\n+\n+    return (x_train, y_train), (x_test, y_test)\n\n@@ -0,0 +1,240 @@\n+import numpy as np\n+\n+from keras.testing import test_case\n+from keras.testing import test_utils\n+\n+\n+class GetTestDataTest(test_case.TestCase):\n+    def setUp(self):\n+        self.train_samples = 100\n+        self.test_samples = 50\n+        self.input_shape = (28, 28)\n+        self.num_classes = 10\n+\n+    def test_labels_within_range(self):\n+        \"\"\"Check if labels are within valid range.\"\"\"\n+        (_, y_train), (_, y_test) = test_utils.get_test_data(\n+            self.train_samples,\n+            self.test_samples,\n+            self.input_shape,\n+            self.num_classes,\n+        )\n+        self.assertTrue(np.all(y_train < self.num_classes))\n+        self.assertTrue(np.all(y_train >= 0))\n+        self.assertTrue(np.all(y_test < self.num_classes))\n+        self.assertTrue(np.all(y_test >= 0))\n+\n+    def test_edge_cases_for_zero_samples(self):\n+        \"\"\"Test when train or test samples are zero.\"\"\"\n+        (x_train, _), (x_test, _) = test_utils.get_test_data(\n+            0, self.test_samples, self.input_shape, self.num_classes\n+        )\n+        self.assertEqual(len(x_train), 0)\n+\n+        (x_train, _), (x_test, _) = test_utils.get_test_data(\n+            self.train_samples, 0, self.input_shape, self.num_classes\n+        )\n+        self.assertEqual(len(x_test), 0)\n+\n+    def test_get_test_data_returns_correct_number_of_samples(self):\n+        \"\"\"Check if returned samples count is correct.\"\"\"\n+        (x_train, y_train), (x_test, y_test) = test_utils.get_test_data(\n+            self.train_samples,\n+            self.test_samples,\n+            self.input_shape,\n+            self.num_classes,\n+        )\n+        self.assertEqual(len(x_train), self.train_samples)\n+        self.assertEqual(len(y_train), self.train_samples)\n+        self.assertEqual(len(x_test), self.test_samples)\n+        self.assertEqual(len(y_test), self.test_samples)\n+\n+    def test_get_test_data_returns_correct_shape_of_data(self):\n+        \"\"\"Check if returned data shape is correct.\"\"\"\n+        (x_train, y_train), (x_test, y_test) = test_utils.get_test_data(\n+            self.train_samples,\n+            self.test_samples,\n+            self.input_shape,\n+            self.num_classes,\n+        )\n+        self.assertEqual(\n+            x_train.shape, (self.train_samples,) + self.input_shape\n+        )\n+        self.assertEqual(y_train.shape, (self.train_samples,))\n+        self.assertEqual(x_test.shape, (self.test_samples,) + self.input_shape)\n+        self.assertEqual(y_test.shape, (self.test_samples,))\n+\n+    def test_get_test_data_returns_different_data_for_different_seeds(self):\n+        \"\"\"Test variability with different seeds.\"\"\"\n+        (x_train_1, y_train_1), (x_test_1, y_test_1) = test_utils.get_test_data(\n+            self.train_samples,\n+            self.test_samples,\n+            self.input_shape,\n+            self.num_classes,\n+            random_seed=1,\n+        )\n+        (x_train_2, y_train_2), (x_test_2, y_test_2) = test_utils.get_test_data(\n+            self.train_samples,\n+            self.test_samples,\n+            self.input_shape,\n+            self.num_classes,\n+            random_seed=2,\n+        )\n+        self.assertFalse(np.array_equal(x_train_1, x_train_2))\n+        self.assertFalse(np.array_equal(y_train_1, y_train_2))\n+        self.assertFalse(np.array_equal(x_test_1, x_test_2))\n+        self.assertFalse(np.array_equal(y_test_1, y_test_2))\n+\n+    def test_get_test_data_returns_consistent_data_for_same_seed(self):\n+        \"\"\"Test consistency with the same seed.\"\"\"\n+        (x_train_1, y_train_1), (x_test_1, y_test_1) = test_utils.get_test_data(\n+            self.train_samples,\n+            self.test_samples,\n+            self.input_shape,\n+            self.num_classes,\n+            random_seed=1,\n+        )\n+        (x_train_2, y_train_2), (x_test_2, y_test_2) = test_utils.get_test_data(\n+            self.train_samples,\n+            self.test_samples,\n+            self.input_shape,\n+            self.num_classes,\n+            random_seed=1,\n+        )\n+        self.assertTrue(np.array_equal(x_train_1, x_train_2))\n+        self.assertTrue(np.array_equal(y_train_1, y_train_2))\n+        self.assertTrue(np.array_equal(x_test_1, x_test_2))\n+        self.assertTrue(np.array_equal(y_test_1, y_test_2))\n+\n+    def test_input_shape_variations(self):\n+        \"\"\"Check function for different input shapes.\"\"\"\n+        input_shape_3d = (28, 28, 3)\n+        (x_train_3d, _), (_, _) = test_utils.get_test_data(\n+            self.train_samples,\n+            self.test_samples,\n+            input_shape_3d,\n+            self.num_classes,\n+        )\n+        self.assertEqual(\n+            x_train_3d.shape, (self.train_samples,) + input_shape_3d\n+        )\n+\n+    def test_all_classes_represented(self):\n+        \"\"\"Ensure all classes are represented in the data.\"\"\"\n+        (_, y_train), (_, y_test) = test_utils.get_test_data(\n+            self.train_samples,\n+            self.test_samples,\n+            self.input_shape,\n+            self.num_classes,\n+        )\n+        self.assertEqual(len(np.unique(y_train)), self.num_classes)\n+        self.assertEqual(len(np.unique(y_test)), self.num_classes)\n+\n+    def test_data_type(self):\n+        \"\"\"Validate the type of the generated data.\"\"\"\n+        (x_train, _), (x_test, _) = test_utils.get_test_data(\n+            self.train_samples,\n+            self.test_samples,\n+            self.input_shape,\n+            self.num_classes,\n+        )\n+        self.assertEqual(x_train.dtype, np.float32)\n+        self.assertEqual(x_test.dtype, np.float32)\n+\n+    def test_label_type(self):\n+        \"\"\"Validate label type of the generated labels.\"\"\"\n+        (_, y_train), (_, y_test) = test_utils.get_test_data(\n+            self.train_samples,\n+            self.test_samples,\n+            self.input_shape,\n+            self.num_classes,\n+        )\n+        self.assertEqual(y_train.dtype, np.int64)\n+        self.assertEqual(y_test.dtype, np.int64)\n+\n+\n+class ClassDistributionTests(test_case.TestCase):\n+    def setUp(self):\n+        self.train_samples = 100\n+        self.test_samples = 50\n+        self.input_shape = (28, 28)\n+        self.num_classes = 10\n+\n+    def test_equal_class_distribution(self):\n+        \"\"\"Verify equal class distribution in train and test sets.\"\"\"\n+        (_, y_train), (_, y_test) = test_utils.get_test_data(\n+            self.train_samples,\n+            self.test_samples,\n+            self.input_shape,\n+            self.num_classes,\n+        )\n+        _, counts_train = np.unique(y_train, return_counts=True)\n+        _, counts_test = np.unique(y_test, return_counts=True)\n+\n+        self.assertTrue(\n+            np.all(counts_train == self.train_samples // self.num_classes)\n+        )\n+        self.assertTrue(\n+            np.all(counts_test == self.test_samples // self.num_classes)\n+        )\n+\n+    def test_uneven_samples_class_distribution(self):\n+        \"\"\"Check class distribution with uneven samples.\"\"\"\n+        train_samples = 103\n+        test_samples = 52\n+        (_, y_train), (_, y_test) = test_utils.get_test_data(\n+            train_samples,\n+            test_samples,\n+            self.input_shape,\n+            self.num_classes,\n+        )\n+        _, counts_train = np.unique(y_train, return_counts=True)\n+        _, counts_test = np.unique(y_test, return_counts=True)\n+\n+        self.assertTrue(np.max(counts_train) - np.min(counts_train) <= 1)\n+        self.assertTrue(np.max(counts_test) - np.min(counts_test) <= 1)\n+\n+    def test_randomness_in_class_distribution(self):\n+        \"\"\"Ensure class distribution isn't too deterministic.\"\"\"\n+        (_, y_train_1), (_, y_test_1) = test_utils.get_test_data(\n+            self.train_samples,\n+            self.test_samples,\n+            self.input_shape,\n+            self.num_classes,\n+        )\n+        (_, y_train_2), (_, y_test_2) = test_utils.get_test_data(\n+            self.train_samples,\n+            self.test_samples,\n+            self.input_shape,\n+            self.num_classes,\n+        )\n+        self.assertFalse(np.array_equal(y_train_1, y_train_2))\n+        self.assertFalse(np.array_equal(y_test_1, y_test_2))\n+\n+    def test_large_number_of_classes(self):\n+        \"\"\"Validate function with a large number of classes.\"\"\"\n+        num_classes = 150\n+        train_samples = (\n+            num_classes * 10\n+        )  # 10 samples for each class in training\n+        test_samples = num_classes * 5  # 5 samples for each class in testing\n+        (_, y_train), (_, y_test) = test_utils.get_test_data(\n+            train_samples,\n+            test_samples,\n+            self.input_shape,\n+            num_classes,\n+        )\n+        self.assertEqual(len(np.unique(y_train)), num_classes)\n+        self.assertEqual(len(np.unique(y_test)), num_classes)\n+\n+    def test_single_class(self):\n+        \"\"\"Test with a single class.\"\"\"\n+        num_classes = 1\n+        (_, y_train), (_, y_test) = test_utils.get_test_data(\n+            self.train_samples,\n+            self.test_samples,\n+            self.input_shape,\n+            num_classes,\n+        )\n+        self.assertTrue(np.all(y_train == 0))\n+        self.assertTrue(np.all(y_test == 0))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#43be5fc78dc879c5fe1938ee7d356cd3390ab707", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 745 | Contributors (this commit): 3 | Commits (past 90d): 7 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -61,6 +61,9 @@ def subtract(x1, x2):\n \n \n def matmul(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n+\n     def with_combined_batch_dimensions(a, b, fn_3d):\n         batch_shape = (\n             b.shape[:-2] if isinstance(b, tf.SparseTensor) else a.shape[:-2]\n\n@@ -3407,9 +3407,6 @@ def matmul(x1, x2):\n     \"\"\"\n     if any_symbolic_tensors((x1, x2)):\n         return Matmul().symbolic_call(x1, x2)\n-    # The below conversion works around an outstanding JAX bug.\n-    x1 = backend.convert_to_tensor(x1)\n-    x2 = backend.convert_to_tensor(x2)\n     return backend.numpy.matmul(x1, x2)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5536dc593d8a6de8d7e415dfd76228738a1e3809", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 20 | Churn Cumulative: 38 | Contributors (this commit): 1 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -227,8 +227,12 @@ class RandomZoom(TFDataLayer):\n         #      [0 0 1]]\n         # where the last entry is implicit.\n         # zoom matrices are always float32.\n-        x_offset = ((float(image_width) - 1.0) / 2.0) * (1.0 - zooms[:, 0:1])\n-        y_offset = ((float(image_height) - 1.0) / 2.0) * (1.0 - zooms[:, 1:])\n+        x_offset = ((self.backend.cast(image_width, \"float32\") - 1.0) / 2.0) * (\n+            1.0 - zooms[:, 0:1]\n+        )\n+        y_offset = (\n+            (self.backend.cast(image_height, \"float32\") - 1.0) / 2.0\n+        ) * (1.0 - zooms[:, 1:])\n         return self.backend.numpy.concatenate(\n             [\n                 zooms[:, 0:1],\n\n@@ -4,6 +4,7 @@ from tensorflow import data as tf_data\n \n from keras import backend\n from keras import layers\n+from keras import models\n from keras import testing\n \n \n@@ -108,3 +109,14 @@ class RandomZoomTest(testing.TestCase, parameterized.TestCase):\n         for output in ds.take(1):\n             output = output.numpy()\n         self.assertAllClose(expected_output, output)\n+\n+    def test_dynamic_shape(self):\n+        inputs = layers.Input((None, None, 3))\n+        outputs = layers.RandomZoom(\n+            height_factor=(0.5, 0.5),\n+            width_factor=(0.8, 0.8),\n+            interpolation=\"nearest\",\n+            fill_mode=\"constant\",\n+        )(inputs)\n+        model = models.Model(inputs, outputs)\n+        model.predict(np.random.random((1, 6, 6, 3)))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#185b333b76af93c746b18eed42776cdcedd65080", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 482 | Contributors (this commit): 9 | Commits (past 90d): 6 | Contributors (cumulative): 13 | DMM Complexity: 0.0\n\nDIFF:\n@@ -33,6 +33,7 @@ class TorchOptimizer(BaseOptimizer):\n             return OPTIMIZERS[cls](*args, **kwargs)\n         return super().__new__(cls)\n \n+    @torch.no_grad\n     def _apply_weight_decay(self, variables):\n         if self.weight_decay is None:\n             return\n\n@@ -1,7 +1,10 @@\n+import torch\n+\n from keras.optimizers.base_optimizer import BaseOptimizer\n \n \n class TorchParallelOptimizer(BaseOptimizer):\n+    @torch.no_grad\n     def _internal_apply_gradients(self, grads_and_vars):\n         grads, trainable_variables = zip(*grads_and_vars)\n \n\n@@ -151,6 +151,7 @@ class UpSampling2D(Layer):\n \n         new_shape = x.shape[rows : cols + 1]\n         new_shape *= np.array([height_factor, width_factor])\n+        new_shape = new_shape.tolist()\n \n         if data_format == \"channels_first\":\n             x = ops.transpose(x, [0, 2, 3, 1])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#775639aef0b2af1234999ba504b8e7aa48e4147f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 51 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 4 | Methods Changed: 5 | Complexity Δ (Sum/Max): 5/3 | Churn Δ: 54 | Churn Cumulative: 1990 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -113,11 +113,22 @@ class BinaryAccuracy(reduction_metrics.MeanMetricWrapper):\n     ```\n     \"\"\"\n \n-    def __init__(self, name=\"binary_accuracy\", dtype=None):\n-        super().__init__(fn=binary_accuracy, name=name, dtype=dtype)\n+    def __init__(self, name=\"binary_accuracy\", dtype=None, threshold=0.5):\n+        if threshold is not None and (threshold <= 0 or threshold >= 1):\n+            raise ValueError(\n+                f\"Invalid value for argument `threshold`. Expected a value in internal (0, 1). Received: threshold={threshold}\"\n+            )\n+        super().__init__(\n+            fn=binary_accuracy, name=name, dtype=dtype, threshold=threshold\n+        )\n+        self.threshold = threshold\n \n     def get_config(self):\n-        return {\"name\": self.name, \"dtype\": self.dtype}\n+        return {\n+            \"name\": self.name,\n+            \"dtype\": self.dtype,\n+            \"threshold\": self.threshold,\n+        }\n \n \n @keras_export(\"keras.metrics.categorical_accuracy\")\n\n@@ -1,3 +1,5 @@\n+import re\n+\n import numpy as np\n \n from keras import testing\n@@ -81,6 +83,41 @@ class BinaryAccuracyTest(testing.TestCase):\n         result = bin_acc_obj.result()\n         self.assertAllClose(result, 0.5, atol=1e-3)\n \n+    def test_threshold(self):\n+        bin_acc_obj_1 = accuracy_metrics.BinaryAccuracy(\n+            name=\"binary_accuracy\", dtype=\"float32\", threshold=0.3\n+        )\n+        bin_acc_obj_2 = accuracy_metrics.BinaryAccuracy(\n+            name=\"binary_accuracy\", dtype=\"float32\", threshold=0.9\n+        )\n+        y_true = np.array([[1], [1], [0], [0]])\n+        y_pred = np.array([[0.98], [0.5], [0.1], [0.2]])\n+\n+        bin_acc_obj_1.update_state(y_true, y_pred)\n+        bin_acc_obj_2.update_state(y_true, y_pred)\n+        result_1 = bin_acc_obj_1.result()\n+        result_2 = bin_acc_obj_2.result()\n+\n+        # Higher threshold must result in lower measured accuracy.\n+        self.assertAllClose(result_1, 1.0)\n+        self.assertAllClose(result_2, 0.75)\n+\n+    def test_invalid_threshold(self):\n+        self.assertRaisesRegex(\n+            ValueError,\n+            re.compile(\n+                r\"Invalid value for argument `threshold`\\. Expected a value in internal \\(0, 1\\). Received: threshold=-0.5\"\n+            ),\n+            lambda: accuracy_metrics.BinaryAccuracy(threshold=-0.5),\n+        )\n+        self.assertRaisesRegex(\n+            ValueError,\n+            re.compile(\n+                r\"Invalid value for argument `threshold`\\. Expected a value in internal \\(0, 1\\). Received: threshold=1.5\"\n+            ),\n+            lambda: accuracy_metrics.BinaryAccuracy(threshold=1.5),\n+        )\n+\n \n class CategoricalAccuracyTest(testing.TestCase):\n     def test_config(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9b7a9b8990171c0f110bede64eef8cdf2b441fd7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 2002 | Contributors (this commit): 4 | Commits (past 90d): 6 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -116,7 +116,9 @@ class BinaryAccuracy(reduction_metrics.MeanMetricWrapper):\n     def __init__(self, name=\"binary_accuracy\", dtype=None, threshold=0.5):\n         if threshold is not None and (threshold <= 0 or threshold >= 1):\n             raise ValueError(\n-                f\"Invalid value for argument `threshold`. Expected a value in internal (0, 1). Received: threshold={threshold}\"\n+                \"Invalid value for argument `threshold`. \"\n+                \"Expected a value in interval (0, 1). \"\n+                f\"Received: threshold={threshold}\"\n             )\n         super().__init__(\n             fn=binary_accuracy, name=name, dtype=dtype, threshold=threshold\n\n@@ -105,16 +105,12 @@ class BinaryAccuracyTest(testing.TestCase):\n     def test_invalid_threshold(self):\n         self.assertRaisesRegex(\n             ValueError,\n-            re.compile(\n-                r\"Invalid value for argument `threshold`\\. Expected a value in internal \\(0, 1\\). Received: threshold=-0.5\"\n-            ),\n+            re.compile(r\"Invalid value for argument `threshold`\"),\n             lambda: accuracy_metrics.BinaryAccuracy(threshold=-0.5),\n         )\n         self.assertRaisesRegex(\n             ValueError,\n-            re.compile(\n-                r\"Invalid value for argument `threshold`\\. Expected a value in internal \\(0, 1\\). Received: threshold=1.5\"\n-            ),\n+            re.compile(r\"Invalid value for argument `threshold`\"),\n             lambda: accuracy_metrics.BinaryAccuracy(threshold=1.5),\n         )\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#38bfa3cb7652af922b23aaaa0c185dfb2ab23eaa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 24 | Churn Cumulative: 1059 | Contributors (this commit): 14 | Commits (past 90d): 2 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -95,3 +95,27 @@ def get(identifier):\n     if isinstance(obj, Optimizer):\n         return obj\n     raise ValueError(f\"Could not interpret optimizer identifier: {identifier}\")\n+\n+\n+# We will add this temporarily so that tensorflow packages that depend on\n+# estimators will continue to import (there are a large number). Note that\n+# Keras 3 will not work with the estimators API.\n+@keras_export(\n+    [\n+        \"keras.optimizers.legacy.Adagrad\",\n+        \"keras.optimizers.legacy.Adam\",\n+        \"keras.optimizers.legacy.Ftrl\",\n+        \"keras.optimizers.legacy.RMSprop\",\n+        \"keras.optimizers.legacy.SGD\",\n+        \"keras.optimizers.legacy.Optimizer\",\n+    ]\n+)\n+class LegacyOptimizerWarning:\n+    def __init__(self, *args, **kwargs):\n+        raise ImportError(\n+            \"`keras.optimizers.legacy` is not supported in Keras 3. When using \"\n+            \"`tf.keras`, to continue using a `tf.keras.optimizers.legacy` \"\n+            \"optimizer, you can install the `tf_keras` package (Keras 2) and \"\n+            \"set the environment variable `TF_USE_LEGACY_KERAS=True` to \"\n+            \"configure TensorFlow to use `tf_keras` when accessing `tf.keras`.\"\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1427f1472a5ef7b1528b08e263f0508699770e20", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 12 | Churn Cumulative: 514 | Contributors (this commit): 3 | Commits (past 90d): 9 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -936,6 +936,14 @@ def tensordot(x1, x2, axes=2):\n     # Conversion to long necessary for `torch.tensordot`\n     x1 = cast(x1, \"int64\") if x1.dtype in TORCH_INT_TYPES else x1\n     x2 = cast(x2, \"int64\") if x2.dtype in TORCH_INT_TYPES else x2\n+    # torch only handles dims=((0,), (1,)), numpy accepts axes=(0, 1).\n+    if isinstance(axes, (list, tuple)):\n+        first, second = axes\n+        if not isinstance(first, (list, tuple)):\n+            first = (first,)\n+        if not isinstance(second, (list, tuple)):\n+            second = (second,)\n+        axes = (first, second)\n     return torch.tensordot(x1, x2, dims=axes)\n \n \n\n@@ -2511,6 +2511,10 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase, parameterized.TestCase):\n             knp.Tensordot(axes=([0, 1], [2, 3]))(x, y),\n             np.tensordot(x, y, axes=([0, 1], [2, 3])),\n         )\n+        self.assertAllClose(\n+            knp.Tensordot(axes=[0, 2])(x, y),\n+            np.tensordot(x, y, axes=[0, 2]),\n+        )\n \n     def test_vdot(self):\n         x = np.array([1.0, 2.0, 3.0])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9284cb9980abe755e54516aaa7c50ac579d0af1b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 263 | Lines Deleted: 35 | Files Changed: 6 | Hunks: 37 | Methods Changed: 36 | Complexity Δ (Sum/Max): 52/40 | Churn Δ: 298 | Churn Cumulative: 1809 | Contributors (this commit): 4 | Commits (past 90d): 30 | Contributors (cumulative): 16 | DMM Complexity: 0.5989304812834224\n\nDIFF:\n@@ -185,7 +185,12 @@ def broadcast_to(x, shape):\n \n \n def ceil(x):\n-    return jnp.ceil(x)\n+    x = convert_to_tensor(x)\n+    if standardize_dtype(x.dtype) == \"int64\":\n+        dtype = config.floatx()\n+    else:\n+        dtype = dtypes.result_type(x.dtype, float)\n+    return cast(jnp.ceil(x), dtype)\n \n \n def clip(x, x_min, x_max):\n\n@@ -145,17 +145,17 @@ def arctanh(x):\n \n def argmax(x, axis=None):\n     axis = tuple(axis) if isinstance(axis, list) else axis\n-    return np.argmax(x, axis=axis)\n+    return np.argmax(x, axis=axis).astype(\"int32\")\n \n \n def argmin(x, axis=None):\n     axis = tuple(axis) if isinstance(axis, list) else axis\n-    return np.argmin(x, axis=axis)\n+    return np.argmin(x, axis=axis).astype(\"int32\")\n \n \n def argsort(x, axis=-1):\n     axis = tuple(axis) if isinstance(axis, list) else axis\n-    return np.argsort(x, axis=axis)\n+    return np.argsort(x, axis=axis).astype(\"int32\")\n \n \n def array(x, dtype=None):\n@@ -201,11 +201,19 @@ def broadcast_to(x, shape):\n \n \n def ceil(x):\n-    return np.ceil(x)\n+    x = convert_to_tensor(x)\n+    if standardize_dtype(x.dtype) == \"int64\":\n+        dtype = config.floatx()\n+    else:\n+        dtype = dtypes.result_type(x.dtype, float)\n+    return np.ceil(x).astype(dtype)\n \n \n def clip(x, x_min, x_max):\n-    return np.clip(x, x_min, x_max)\n+    dtype = standardize_dtype(x.dtype)\n+    if dtype == \"bool\":\n+        dtype = \"int64\"\n+    return np.clip(x, x_min, x_max).astype(dtype)\n \n \n def concatenate(xs, axis=0):\n@@ -280,6 +288,11 @@ def digitize(x, bins):\n \n \n def dot(x, y):\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    dtype = dtypes.result_type(x.dtype, y.dtype)\n+    x = x.astype(dtype)\n+    y = y.astype(dtype)\n     return np.dot(x, y)\n \n \n\n@@ -267,6 +267,10 @@ def zeros(shape, dtype=None):\n \n \n def absolute(x):\n+    # uintx and bool are always non-negative\n+    dtype = standardize_dtype(x.dtype)\n+    if \"uint\" in dtype or dtype == \"bool\":\n+        return x\n     return tfnp.absolute(x)\n \n \n@@ -341,15 +345,15 @@ def arctanh(x):\n \n \n def argmax(x, axis=None):\n-    return tfnp.argmax(x, axis=axis)\n+    return tf.cast(tfnp.argmax(x, axis=axis), dtype=\"int32\")\n \n \n def argmin(x, axis=None):\n-    return tfnp.argmin(x, axis=axis)\n+    return tf.cast(tfnp.argmin(x, axis=axis), dtype=\"int32\")\n \n \n def argsort(x, axis=-1):\n-    return tfnp.argsort(x, axis=axis)\n+    return tf.cast(tfnp.argsort(x, axis=axis), dtype=\"int32\")\n \n \n def array(x, dtype=None):\n@@ -370,11 +374,19 @@ def broadcast_to(x, shape):\n \n \n def ceil(x):\n-    return tfnp.ceil(x)\n+    x = convert_to_tensor(x)\n+    if standardize_dtype(x.dtype) == \"int64\":\n+        dtype = config.floatx()\n+    else:\n+        dtype = dtypes.result_type(x.dtype, float)\n+    return tf.cast(tfnp.ceil(x), dtype=dtype)\n \n \n def clip(x, x_min, x_max):\n-    return tfnp.clip(x, x_min, x_max)\n+    dtype = standardize_dtype(x.dtype)\n+    if dtype == \"bool\":\n+        dtype = \"int64\"\n+    return tf.cast(tfnp.clip(x, x_min, x_max), dtype=dtype)\n \n \n def concatenate(xs, axis=0):\n@@ -463,7 +475,14 @@ def digitize(x, bins):\n \n \n def dot(x, y):\n-    return tfnp.dot(x, y)\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    result_dtype = dtypes.result_type(x.dtype, y.dtype)\n+    # GPU only supports float types\n+    compute_dtype = dtypes.result_type(result_dtype, float)\n+    x = tf.cast(x, compute_dtype)\n+    y = tf.cast(y, compute_dtype)\n+    return tf.cast(tfnp.dot(x, y), dtype=result_dtype)\n \n \n def empty(shape, dtype=None):\n\n@@ -125,6 +125,9 @@ def absolute(x):\n \n def abs(x):\n     x = convert_to_tensor(x)\n+    # bool are always non-negative\n+    if standardize_dtype(x.dtype) == \"bool\":\n+        return x\n     return torch.abs(x)\n \n \n@@ -237,12 +240,12 @@ def arctanh(x):\n \n def argmax(x, axis=None):\n     x = convert_to_tensor(x)\n-    return torch.argmax(x, dim=axis)\n+    return cast(torch.argmax(x, dim=axis), dtype=\"int32\")\n \n \n def argmin(x, axis=None):\n     x = convert_to_tensor(x)\n-    return torch.argmin(x, dim=axis)\n+    return cast(torch.argmin(x, dim=axis), dtype=\"int32\")\n \n \n def argsort(x, axis=-1):\n@@ -250,7 +253,7 @@ def argsort(x, axis=-1):\n     if axis is None:\n         axis = -1\n         x = x.reshape(-1)\n-    return torch.argsort(x, dim=axis, stable=True)\n+    return cast(torch.argsort(x, dim=axis, stable=True), dtype=\"int32\")\n \n \n def array(x, dtype=None):\n@@ -311,13 +314,21 @@ def broadcast_to(x, shape):\n \n def ceil(x):\n     x = convert_to_tensor(x)\n-    return torch.ceil(x)\n+    if standardize_dtype(x.dtype) == \"int64\":\n+        dtype = config.floatx()\n+    else:\n+        dtype = dtypes.result_type(x.dtype, float)\n+    return cast(torch.ceil(x), dtype=dtype)\n \n \n def clip(x, x_min, x_max):\n     x = convert_to_tensor(x)\n-    x_min, x_max = convert_to_tensor(x_min), convert_to_tensor(x_max)\n-    return torch.clip(x, min=x_min, max=x_max)\n+    x_min = convert_to_tensor(x_min)\n+    x_max = convert_to_tensor(x_max)\n+    dtype = standardize_dtype(x.dtype)\n+    if dtype == \"bool\":\n+        dtype = \"int64\"\n+    return cast(torch.clip(x, min=x_min, max=x_max), dtype=dtype)\n \n \n def concatenate(xs, axis=0):\n@@ -409,7 +420,11 @@ def digitize(x, bins):\n \n \n def dot(x, y):\n-    x, y = convert_to_tensor(x), convert_to_tensor(y)\n+    x = convert_to_tensor(x)\n+    y = convert_to_tensor(y)\n+    result_dtype = dtypes.result_type(x.dtype, y.dtype)\n+    x = cast(x, result_dtype)\n+    y = cast(y, result_dtype)\n     if x.ndim == 0 or y.ndim == 0:\n         return torch.multiply(x, y)\n     return torch.matmul(x, y)\n\n@@ -1343,7 +1343,11 @@ class Ceil(Operation):\n         return backend.numpy.ceil(x)\n \n     def compute_output_spec(self, x):\n-        return KerasTensor(x.shape, dtype=x.dtype)\n+        if backend.standardize_dtype(x.dtype) == \"int64\":\n+            dtype = backend.floatx()\n+        else:\n+            dtype = dtypes.result_type(x.dtype, float)\n+        return KerasTensor(x.shape, dtype=dtype)\n \n \n @keras_export([\"keras.ops.ceil\", \"keras.ops.numpy.ceil\"])\n@@ -1357,7 +1361,7 @@ def ceil(x):\n         x: Input tensor.\n \n     Returns:\n-        The ceiling of each element in `x`.\n+        The ceiling of each element in `x`, with float dtype.\n     \"\"\"\n     if any_symbolic_tensors((x,)):\n         return Ceil().symbolic_call(x)\n@@ -1374,7 +1378,10 @@ class Clip(Operation):\n         return backend.numpy.clip(x, self.x_min, self.x_max)\n \n     def compute_output_spec(self, x):\n-        return KerasTensor(x.shape, dtype=x.dtype)\n+        dtype = backend.standardize_dtype(x.dtype)\n+        if dtype == \"bool\":\n+            dtype = \"int64\"\n+        return KerasTensor(x.shape, dtype=dtype)\n \n \n @keras_export([\"keras.ops.clip\", \"keras.ops.numpy.clip\"])\n@@ -2001,10 +2008,14 @@ class Dot(Operation):\n     def compute_output_spec(self, x1, x2):\n         x1_shape = list(getattr(x1, \"shape\", []))\n         x2_shape = list(getattr(x2, \"shape\", []))\n+        dtype = dtypes.result_type(\n+            getattr(x1, \"dtype\", type(x1)),\n+            getattr(x2, \"dtype\", type(x2)),\n+        )\n         if x1_shape == [] or x2_shape == []:\n             return multiply(x1, x2)\n         if len(x1_shape) == 1 and len(x2_shape) == 1:\n-            return KerasTensor([], dtype=x1.dtype)\n+            return KerasTensor([], dtype=dtype)\n         if len(x2_shape) == 1:\n             if x1_shape[-1] != x2_shape[0]:\n                 raise ValueError(\n@@ -2012,7 +2023,7 @@ class Dot(Operation):\n                     \"`x1` is N-d array while `x2` is 1-D, but receive shape \"\n                     f\"`x1.shape={x1.shape}` and x2.shape=`{x2.shape}`.\"\n                 )\n-            return KerasTensor(x1_shape[:-1], dtype=x1.dtype)\n+            return KerasTensor(x1_shape[:-1], dtype=dtype)\n \n         if (\n             x1_shape[-1] is None\n@@ -2021,7 +2032,7 @@ class Dot(Operation):\n         ):\n             del x1_shape[-1]\n             del x2_shape[-2]\n-            return KerasTensor(x1_shape + x2_shape, dtype=x1.dtype)\n+            return KerasTensor(x1_shape + x2_shape, dtype=dtype)\n \n         raise ValueError(\n             \"Shape must match on the last axis of `x1` and second last \"\n\n@@ -2926,22 +2926,15 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(knp.Argmin()(x), np.argmin(x))\n         self.assertAllClose(knp.Argmin(axis=1)(x), np.argmin(x, axis=1))\n \n-    # TODO: fix and reenable\n-    def DISABLED_test_argsort(self):\n+    def test_argsort(self):\n         x = np.array([[1, 2, 3], [4, 5, 6]])\n         self.assertAllClose(knp.argsort(x), np.argsort(x))\n         self.assertAllClose(knp.argsort(x, axis=1), np.argsort(x, axis=1))\n-        self.assertAllClose(\n-            knp.argsort(x, axis=None),\n-            np.argsort(x, axis=None),\n-        )\n+        self.assertAllClose(knp.argsort(x, axis=None), np.argsort(x, axis=None))\n \n         self.assertAllClose(knp.Argsort()(x), np.argsort(x))\n         self.assertAllClose(knp.Argsort(axis=1)(x), np.argsort(x, axis=1))\n-        self.assertAllClose(\n-            knp.Argsort(axis=None)(x),\n-            np.argsort(x, axis=None),\n-        )\n+        self.assertAllClose(knp.Argsort(axis=None)(x), np.argsort(x, axis=None))\n \n     def test_array(self):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n@@ -2979,6 +2972,12 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         )\n \n     def test_bincount(self):\n+        if backend.backend() == \"tensorflow\":\n+            import tensorflow as tf\n+\n+            if tf.test.is_gpu_available():\n+                self.skipTest(\"bincount does not work in tensorflow gpu\")\n+\n         x = np.array([1, 1, 2, 3, 2, 4, 4, 5])\n         weights = np.array([0, 0, 3, 2, 1, 1, 4, 2])\n         minlength = 3\n@@ -3935,6 +3934,12 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n     def test_bincount(self, dtype):\n         import jax.numpy as jnp\n \n+        if backend.backend() == \"tensorflow\":\n+            import tensorflow as tf\n+\n+            if tf.test.is_gpu_available():\n+                self.skipTest(\"bincount does not work in tensorflow gpu\")\n+\n         x = np.array([1, 1, 2, 3, 2, 4, 4, 5], dtype=dtype)\n         weights = np.array([0, 0, 3, 2, 1, 1, 4, 2], dtype=dtype)\n         minlength = 3\n@@ -4013,10 +4018,16 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n         import jax.numpy as jnp\n \n         if backend.backend() == \"torch\":\n+            import torch\n+\n             if dtype1 == \"float16\" or dtype2 == \"float16\":\n                 self.skipTest(\"matmul does not support float16 in torch\")\n             if dtype1 == \"bool\" and dtype2 == \"bool\":\n                 self.skipTest(\"matmul does not support bool in torch\")\n+            if torch.cuda.is_available():\n+                dtype = backend.result_type(dtype1, dtype2)\n+                if \"int\" in dtype:\n+                    self.skipTest(f\"dot does not support {dtype} in torch gpu\")\n \n         x1 = knp.ones((1,), dtype=dtype1)\n         x2 = knp.ones((1,), dtype=dtype2)\n@@ -4098,6 +4109,83 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             standardize_dtype(jnp.zeros([2, 3], dtype=dtype).dtype),\n         )\n \n+    @parameterized.parameters(ALL_DTYPES)\n+    def test_absolute(self, dtype):\n+        import jax.numpy as jnp\n+\n+        x = knp.ones((1,), dtype=dtype)\n+        x_jax = jnp.ones((1,), dtype=dtype)\n+        expected_dtype = standardize_dtype(jnp.absolute(x_jax).dtype)\n+        self.assertEqual(\n+            standardize_dtype(knp.absolute(x).dtype), expected_dtype\n+        )\n+        self.assertEqual(\n+            standardize_dtype(knp.Absolute().symbolic_call(x).dtype),\n+            expected_dtype,\n+        )\n+\n+    @parameterized.parameters(ALL_DTYPES)\n+    def test_argmax(self, dtype):\n+        import jax.numpy as jnp\n+\n+        if backend.backend() == \"torch\":\n+            if dtype == \"bool\":\n+                self.skipTest(f\"argmax does not support {dtype} in torch\")\n+\n+        x = knp.array([[1, 2, 3], [3, 2, 1]], dtype=dtype)\n+        x_jax = jnp.array([[1, 2, 3], [3, 2, 1]], dtype=dtype)\n+        expected_dtype = standardize_dtype(jnp.argmax(x_jax).dtype)\n+        self.assertEqual(standardize_dtype(knp.argmax(x).dtype), expected_dtype)\n+        self.assertEqual(\n+            standardize_dtype(knp.Argmax().symbolic_call(x).dtype),\n+            expected_dtype,\n+        )\n+\n+    @parameterized.parameters(ALL_DTYPES)\n+    def test_argmin(self, dtype):\n+        import jax.numpy as jnp\n+\n+        if backend.backend() == \"torch\":\n+            if dtype == \"bool\":\n+                self.skipTest(f\"argmin does not support {dtype} in torch\")\n+\n+        x = knp.array([[1, 2, 3], [3, 2, 1]], dtype=dtype)\n+        x_jax = jnp.array([[1, 2, 3], [3, 2, 1]], dtype=dtype)\n+        expected_dtype = standardize_dtype(jnp.argmin(x_jax).dtype)\n+        self.assertEqual(standardize_dtype(knp.argmin(x).dtype), expected_dtype)\n+        self.assertEqual(\n+            standardize_dtype(knp.Argmin().symbolic_call(x).dtype),\n+            expected_dtype,\n+        )\n+\n+    @parameterized.parameters(ALL_DTYPES)\n+    def test_argsort(self, dtype):\n+        import jax.numpy as jnp\n+\n+        if backend.backend() == \"tensorflow\":\n+            if dtype == \"bool\":\n+                self.skipTest(f\"argsort does not support {dtype} in tensorflow\")\n+\n+        if backend.backend() == \"torch\":\n+            import torch\n+\n+            if torch.cuda.is_available():\n+                if dtype in [\"bool\", \"int64\"]:\n+                    self.skipTest(\n+                        f\"argsort does not support {dtype} in torch gpu\"\n+                    )\n+\n+        x = knp.array([[1, 2, 3], [4, 5, 6]], dtype=dtype)\n+        x_jax = jnp.array([[1, 2, 3], [4, 5, 6]], dtype=dtype)\n+        expected_dtype = standardize_dtype(jnp.argsort(x_jax).dtype)\n+        self.assertEqual(\n+            standardize_dtype(knp.argsort(x).dtype), expected_dtype\n+        )\n+        self.assertEqual(\n+            standardize_dtype(knp.Argsort().symbolic_call(x).dtype),\n+            expected_dtype,\n+        )\n+\n     @parameterized.parameters(\n         (10, None, 1, None),\n         (0, 10, 1, None),\n@@ -4122,6 +4210,83 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             standardize_dtype(jnp.arange(start, stop, step, dtype).dtype),\n         )\n \n+    @parameterized.parameters(ALL_DTYPES)\n+    def test_ceil(self, dtype):\n+        import jax.numpy as jnp\n+\n+        if backend.backend() == \"torch\":\n+            import torch\n+\n+            if dtype is None:\n+                # TODO: knp.array returns float32 instead of float64 when dtype\n+                # is None in torch\n+                dtype = \"float64\"\n+            if not torch.cuda.is_available() and dtype == \"float16\":\n+                self.skipTest(f\"ceil does not support {dtype} in torch cpu\")\n+            if dtype == \"bool\":\n+                self.skipTest(f\"ceil does not support {dtype} in torch\")\n+\n+        x = knp.array([[1.2, 2.1, 2.5], [2.4, 11.9, 5.5]], dtype=dtype)\n+        x_jax = jnp.array([[1.2, 2.1, 2.5], [2.4, 11.9, 5.5]], dtype=dtype)\n+        expected_dtype = standardize_dtype(jnp.ceil(x_jax).dtype)\n+        if dtype == \"int64\":\n+            expected_dtype = backend.floatx()\n+        self.assertEqual(standardize_dtype(knp.ceil(x).dtype), expected_dtype)\n+        self.assertEqual(\n+            standardize_dtype(knp.Ceil().symbolic_call(x).dtype),\n+            expected_dtype,\n+        )\n+\n+    @parameterized.parameters(ALL_DTYPES)\n+    def test_clip(self, dtype):\n+        import jax.numpy as jnp\n+\n+        if backend.backend() == \"torch\":\n+            import torch\n+\n+            if not torch.cuda.is_available() and dtype == \"float16\":\n+                self.skipTest(f\"clip does not support {dtype} in torch cpu\")\n+\n+        x = knp.ones((1,), dtype=dtype)\n+        x_jax = jnp.ones((1,), dtype=dtype)\n+        expected_dtype = standardize_dtype(jnp.clip(x_jax, -2, 2).dtype)\n+        self.assertEqual(\n+            standardize_dtype(knp.clip(x, -2, 2).dtype), expected_dtype\n+        )\n+        self.assertEqual(\n+            standardize_dtype(knp.Clip(-2, 2).symbolic_call(x).dtype),\n+            expected_dtype,\n+        )\n+\n+    @parameterized.product(dtype1=ALL_DTYPES, dtype2=ALL_DTYPES)\n+    def test_dot(self, dtype1, dtype2):\n+        import jax.numpy as jnp\n+\n+        if backend.backend() == \"tensorflow\":\n+            if dtype1 == \"bool\" and dtype2 == \"bool\":\n+                self.skipTest(\"dot does not support bool in tensorflow\")\n+        if backend.backend() == \"torch\":\n+            import torch\n+\n+            if \"float16\" in [dtype1, dtype2]:\n+                self.skipTest(\"dot does not support float16 in torch\")\n+            if dtype1 == \"bool\" and dtype2 == \"bool\":\n+                self.skipTest(\"dot does not support bool in torch\")\n+            if torch.cuda.is_available():\n+                dtype = backend.result_type(dtype1, dtype2)\n+                if \"int\" in dtype:\n+                    self.skipTest(f\"dot does not support {dtype} in torch gpu\")\n+\n+        x1 = knp.ones((2, 3, 4), dtype=dtype1)\n+        x2 = knp.ones((4, 3), dtype=dtype2)\n+        x1_jax = jnp.ones((2, 3, 4), dtype=dtype1)\n+        x2_jax = jnp.ones((4, 3), dtype=dtype2)\n+        expected_dtype = standardize_dtype(jnp.dot(x1_jax, x2_jax).dtype)\n+        self.assertEqual(\n+            standardize_dtype(knp.dot(x1, x2).dtype), expected_dtype\n+        )\n+        self.assertEqual(knp.Dot().symbolic_call(x1, x2).dtype, expected_dtype)\n+\n     @parameterized.parameters(ALL_DTYPES)\n     def test_empty(self, dtype):\n         import jax.numpy as jnp\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
