{"custom_id": "keras#1278bf9cfa5b137c428d9d93bc66785f83dded67", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 6010 | Contributors (this commit): 62 | Commits (past 90d): 42 | Contributors (cumulative): 65 | DMM Complexity: None\n\nDIFF:\n@@ -352,7 +352,7 @@ def int_shape(x):\n         x: Tensor or variable.\n \n     # Returns\n-        A tuple of integers.\n+        A tuple of integers (or None entries).\n \n     # Examples\n     ```python\n\n@@ -2,7 +2,6 @@ from __future__ import absolute_import\n from . import backend as K\n from .utils.generic_utils import get_from_module\n from six.moves import zip\n-import warnings\n \n \n def clip_norm(g, c, n):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1fcb74f2180ec9108ce10e6663dce1503354e658", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 49 | Lines Deleted: 6 | Files Changed: 3 | Hunks: 9 | Methods Changed: 5 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 55 | Churn Cumulative: 12043 | Contributors (this commit): 65 | Commits (past 90d): 17 | Contributors (cumulative): 74 | DMM Complexity: 0.20689655172413793\n\nDIFF:\n@@ -622,20 +622,27 @@ class Lambda(Layer):\n         return dict(list(base_config.items()) + list(config.items()))\n \n     @classmethod\n-    def from_config(cls, config):\n+    def from_config(cls, config, custom_objects={}):\n+        # Insert custom objects into globals.\n+        if custom_objects:\n+            globs = globals().copy()\n+            globs.update(custom_objects)\n+        else:\n+            globs = globals()\n+\n         function_type = config.pop('function_type')\n         if function_type == 'function':\n-            function = globals()[config['function']]\n+            function = globs[config['function']]\n         elif function_type == 'lambda':\n-            function = func_load(config['function'], globs=globals())\n+            function = func_load(config['function'], globs=globs)\n         else:\n             raise TypeError('Unknown function type:', function_type)\n \n         output_shape_type = config.pop('output_shape_type')\n         if output_shape_type == 'function':\n-            output_shape = globals()[config['output_shape']]\n+            output_shape = globs[config['output_shape']]\n         elif output_shape_type == 'lambda':\n-            output_shape = func_load(config['output_shape'], globs=globals())\n+            output_shape = func_load(config['output_shape'], globs=globs)\n         else:\n             output_shape = config['output_shape']\n \n\n@@ -1,4 +1,5 @@\n from __future__ import print_function\n+import inspect\n \n from .generic_utils import get_from_module\n from .np_utils import convert_kernel\n@@ -31,6 +32,11 @@ def layer_from_config(config, custom_objects={}):\n     else:\n         layer_class = get_from_module(class_name, globals(), 'layer',\n                                       instantiate=False)\n+\n+    arg_spec = inspect.getargspec(layer_class.from_config)\n+    if 'custom_objects' in arg_spec.args:\n+        return layer_class.from_config(config['config'], custom_objects=custom_objects)\n+    else:\n         return layer_class.from_config(config['config'])\n \n \n\n@@ -5,7 +5,7 @@ import numpy as np\n from numpy.testing import assert_allclose\n \n from keras.models import Model, Sequential\n-from keras.layers import Dense, Dropout, RepeatVector, TimeDistributed\n+from keras.layers import Dense, Dropout, Lambda, RepeatVector, TimeDistributed\n from keras.layers import Input\n from keras import optimizers\n from keras import objectives\n@@ -232,5 +232,35 @@ def test_loading_weights_by_name_2():\n     assert_allclose(np.zeros_like(jessica[1]), jessica[1])  # biases init to 0\n \n \n+# a function to be called from the Lambda layer\n+def square_fn(x):\n+    return x * x\n+\n+\n+@keras_test\n+def test_saving_lambda_custom_objects():\n+    input = Input(shape=(3,))\n+    x = Lambda(lambda x: square_fn(x), output_shape=(3,))(input)\n+    output = Dense(3)(x)\n+\n+    model = Model(input, output)\n+    model.compile(loss=objectives.MSE,\n+                  optimizer=optimizers.RMSprop(lr=0.0001),\n+                  metrics=[metrics.categorical_accuracy])\n+    x = np.random.random((1, 3))\n+    y = np.random.random((1, 3))\n+    model.train_on_batch(x, y)\n+\n+    out = model.predict(x)\n+    _, fname = tempfile.mkstemp('.h5')\n+    save_model(model, fname)\n+\n+    model = load_model(fname, custom_objects={'square_fn': square_fn})\n+    os.remove(fname)\n+\n+    out2 = model.predict(x)\n+    assert_allclose(out, out2, atol=1e-05)\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0c842391d34d444393ab0f55382d11a4c5105994", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 18 | Churn Cumulative: 4460 | Contributors (this commit): 49 | Commits (past 90d): 34 | Contributors (cumulative): 49 | DMM Complexity: 0.0\n\nDIFF:\n@@ -782,7 +782,7 @@ def dot(x, y):\n         >>> y = K.placeholder(shape=(3, 4))\n         >>> xy = K.dot(x, y)\n         >>> xy\n-        <tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>\n+        <tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>\n     ```\n \n     ```python\n@@ -795,8 +795,20 @@ def dot(x, y):\n     ```\n     '''\n     if ndim(x) is not None and (ndim(x) > 2 or ndim(y) > 2):\n-        x_shape = (-1,) + int_shape(x)[1:]\n-        y_shape = int_shape(y)\n+        x_shape = []\n+        for i, s in zip(int_shape(x), tf.unpack(tf.shape(x))):\n+            if s is None:\n+                x_shape.append(i)\n+            else:\n+                x_shape.append(s)\n+        x_shape = tuple(x_shape)\n+        y_shape = []\n+        for i, s in zip(int_shape(y), tf.unpack(tf.shape(y))):\n+            if s is None:\n+                y_shape.append(i)\n+            else:\n+                y_shape.append(s)\n+        y_shape = tuple(y_shape)\n         y_permute_dim = list(range(ndim(y)))\n         y_permute_dim = [y_permute_dim.pop(-2)] + y_permute_dim\n         xt = tf.reshape(x, [-1, x_shape[-1]])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9333179ad96fad2760221f2b3e2dec31f7c77f40", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 21 | Churn Cumulative: 1465 | Contributors (this commit): 15 | Commits (past 90d): 6 | Contributors (cumulative): 17 | DMM Complexity: 0.21428571428571427\n\nDIFF:\n@@ -45,7 +45,12 @@ def layer_test(layer_cls, kwargs={}, input_shape=None, input_dtype=None,\n         assert input_shape\n         if not input_dtype:\n             input_dtype = K.floatx()\n-        input_data = (10 * np.random.random(input_shape)).astype(input_dtype)\n+        input_data_shape = list(input_shape)\n+        for i, e in enumerate(input_data_shape):\n+            if e is None:\n+                input_data_shape[i] = np.random.randint(1, 4)\n+        input_data = (10 * np.random.random(input_data_shape))\n+        input_data = input_data.astype(input_dtype)\n     elif input_shape is None:\n         input_shape = input_data.shape\n \n@@ -78,7 +83,10 @@ def layer_test(layer_cls, kwargs={}, input_shape=None, input_dtype=None,\n     expected_output_shape = layer.get_output_shape_for(input_shape)\n     actual_output = model.predict(input_data)\n     actual_output_shape = actual_output.shape\n-    assert expected_output_shape == actual_output_shape\n+    for expected_dim, actual_dim in zip(expected_output_shape,\n+                                        actual_output_shape):\n+        if expected_dim is not None:\n+            assert expected_dim == actual_dim\n     if expected_output is not None:\n         assert_allclose(actual_output, expected_output, rtol=1e-3)\n \n@@ -97,7 +105,10 @@ def layer_test(layer_cls, kwargs={}, input_shape=None, input_dtype=None,\n     model.compile('rmsprop', 'mse')\n     actual_output = model.predict(input_data)\n     actual_output_shape = actual_output.shape\n-    assert expected_output_shape == actual_output_shape\n+    for expected_dim, actual_dim in zip(expected_output_shape,\n+                                        actual_output_shape):\n+        if expected_dim is not None:\n+            assert expected_dim == actual_dim\n     if expected_output is not None:\n         assert_allclose(actual_output, expected_output, rtol=1e-3)\n \n\n@@ -329,6 +329,10 @@ def test_dense():\n                kwargs={'output_dim': 3},\n                input_shape=(3, 4, 2))\n \n+    layer_test(core.Dense,\n+               kwargs={'output_dim': 3},\n+               input_shape=(None, None, 2))\n+\n     layer_test(core.Dense,\n                kwargs={'output_dim': 3},\n                input_shape=(3, 4, 5, 2))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2a3d4722c21d99d882b2cbc2da451108147fe1c4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 9 | Files Changed: 3 | Hunks: 9 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 18 | Churn Cumulative: 6009 | Contributors (this commit): 44 | Commits (past 90d): 21 | Contributors (cumulative): 52 | DMM Complexity: None\n\nDIFF:\n@@ -105,7 +105,7 @@ class BatchNormalization(Layer):\n     def call(self, x, mask=None):\n         if self.mode == 0 or self.mode == 2:\n             assert self.built, 'Layer must be built before being called'\n-            input_shape = self.input_spec[0].shape\n+            input_shape = K.int_shape(x)\n \n             reduction_axes = list(range(len(input_shape)))\n             del reduction_axes[self.axis]\n\n@@ -198,7 +198,7 @@ class Recurrent(Layer):\n         # input shape: (nb_samples, time (padded with zeros), input_dim)\n         # note that the .build() method of subclasses MUST define\n         # self.input_spec with a complete input shape.\n-        input_shape = self.input_spec[0].shape\n+        input_shape = K.int_shape(x)\n         if self.unroll and input_shape[1] is None:\n             raise ValueError('Cannot unroll a RNN if the '\n                              'time dimension is undefined. \\n'\n@@ -345,7 +345,7 @@ class SimpleRNN(Recurrent):\n \n     def preprocess_input(self, x):\n         if self.consume_less == 'cpu':\n-            input_shape = self.input_spec[0].shape\n+            input_shape = K.int_shape(x)\n             input_dim = input_shape[2]\n             timesteps = input_shape[1]\n             return time_distributed_dense(x, self.W, self.b, self.dropout_W,\n@@ -377,7 +377,7 @@ class SimpleRNN(Recurrent):\n         else:\n             constants.append(K.cast_to_floatx(1.))\n         if self.consume_less == 'cpu' and 0 < self.dropout_W < 1:\n-            input_shape = self.input_spec[0].shape\n+            input_shape = K.int_shape(x)\n             input_dim = input_shape[-1]\n             ones = K.ones_like(K.reshape(x[:, 0, 0], (-1, 1)))\n             ones = K.tile(ones, (1, int(input_dim)))\n@@ -531,7 +531,7 @@ class GRU(Recurrent):\n \n     def preprocess_input(self, x):\n         if self.consume_less == 'cpu':\n-            input_shape = self.input_spec[0].shape\n+            input_shape = K.int_shape(x)\n             input_dim = input_shape[2]\n             timesteps = input_shape[1]\n \n@@ -595,7 +595,7 @@ class GRU(Recurrent):\n             constants.append([K.cast_to_floatx(1.) for _ in range(3)])\n \n         if 0 < self.dropout_W < 1:\n-            input_shape = self.input_spec[0].shape\n+            input_shape = K.int_shape(x)\n             input_dim = input_shape[-1]\n             ones = K.ones_like(K.reshape(x[:, 0, 0], (-1, 1)))\n             ones = K.tile(ones, (1, int(input_dim)))\n@@ -790,7 +790,7 @@ class LSTM(Recurrent):\n                 dropout = self.dropout_W\n             else:\n                 dropout = 0\n-            input_shape = self.input_spec[0].shape\n+            input_shape = K.int_shape(x)\n             input_dim = input_shape[2]\n             timesteps = input_shape[1]\n \n@@ -857,7 +857,7 @@ class LSTM(Recurrent):\n             constants.append([K.cast_to_floatx(1.) for _ in range(4)])\n \n         if 0 < self.dropout_W < 1:\n-            input_shape = self.input_spec[0].shape\n+            input_shape = K.int_shape(x)\n             input_dim = input_shape[-1]\n             ones = K.ones_like(K.reshape(x[:, 0, 0], (-1, 1)))\n             ones = K.tile(ones, (1, int(input_dim)))\n\n@@ -106,7 +106,7 @@ class TimeDistributed(Wrapper):\n         return (child_output_shape[0], timesteps) + child_output_shape[1:]\n \n     def call(self, X, mask=None):\n-        input_shape = self.input_spec[0].shape\n+        input_shape = K.int_shape(X)\n         if input_shape[0]:\n             # batch size matters, use rnn-based implementation\n             def step(x, states):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#48d8853cadf548c53a992637d94e1f53f0a48074", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 24 | Churn Cumulative: 587 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -8,6 +8,13 @@ e.g.:\n ```\n python neural_style_transfer.py img/tuebingen.jpg img/starry_night.jpg results/my_result\n ```\n+Optional parameters:\n+```\n+--iter, To specify the number of iterations the style transfer takes place (Default is 10)\n+--content_weight, The weight given to the content loss (Default is 0.025)\n+--style_weight, The weight given to the style loss (Default is 1.0)\n+--tv_weight, The weight given to the total variation loss (Default is 1.0)\n+```\n \n It is preferable to run this script on GPU, for speed.\n \n@@ -60,16 +67,25 @@ parser.add_argument('style_reference_image_path', metavar='ref', type=str,\n                     help='Path to the style reference image.')\n parser.add_argument('result_prefix', metavar='res_prefix', type=str,\n                     help='Prefix for the saved results.')\n+parser.add_argument('--iter', type=int, default=10, required=False,\n+                    help='Number of iterations to run.')\n+parser.add_argument('--content_weight', type=float, default=0.025, required=False,\n+                    help='Content weight.')\n+parser.add_argument('--style_weight', type=float, default=1.0, required=False,\n+                    help='Style weight.')\n+parser.add_argument('--tv_weight', type=float, default=1.0, required=False,\n+                    help='Total Variation weight.')\n \n args = parser.parse_args()\n base_image_path = args.base_image_path\n style_reference_image_path = args.style_reference_image_path\n result_prefix = args.result_prefix\n+iterations = args.iter\n \n # these are the weights of the different loss components\n-total_variation_weight = 1.\n-style_weight = 1.\n-content_weight = 0.025\n+total_variation_weight = args.tv_weight\n+style_weight = args.style_weight\n+content_weight = args.content_weight\n \n # dimensions of the generated picture.\n img_nrows = 400\n@@ -246,7 +262,7 @@ if K.image_dim_ordering() == 'th':\n else:\n     x = np.random.uniform(0, 255, (1, img_nrows, img_ncols, 3)) - 128.\n \n-for i in range(10):\n+for i in range(iterations):\n     print('Start of iteration', i)\n     start_time = time.time()\n     x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fefb70b217af9d9a5de780873db218fffaaf9544", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 226 | Contributors (this commit): 5 | Commits (past 90d): 1 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -75,7 +75,7 @@ def create_base_network(input_dim):\n def compute_accuracy(predictions, labels):\n     '''Compute classification accuracy with a fixed threshold on distances.\n     '''\n-    return labels[predictions.ravel() < 0.5].mean()\n+    return np.mean(labels == (predictions.ravel() > 0.5))\n \n \n # the data, shuffled and split between train and test sets\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6b1bf7d917992c66fe4d920982f561cb279ced11", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 14 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 14 | Churn Cumulative: 4474 | Contributors (this commit): 49 | Commits (past 90d): 35 | Contributors (cumulative): 49 | DMM Complexity: None\n\nDIFF:\n@@ -486,9 +486,7 @@ def ones(shape, dtype=None, name=None):\n \n     # Arguments\n         shape: Tuple of integers, shape of returned Keras variable.\n-\n         dtype: String, data type of returned Keras variable.\n-\n         name: String, name of returned Keras variable.\n \n     # Returns\n@@ -517,9 +515,7 @@ def eye(size, dtype=None, name=None):\n \n     # Arguments\n         size: Integer, number of rows/columns.\n-\n         dtype: String, data type of returned Keras variable.\n-\n         name: String, name of returned Keras variable.\n \n     # Returns\n@@ -592,15 +588,10 @@ def random_uniform_variable(shape, low, high, dtype=None,\n \n     # Arguments\n         shape: Tuple of integers, shape of returned Keras variable.\n-\n         low: Float, lower boundary of the output inteval.\n-\n         high: Float, upper boundary of the output interval.\n-\n         dtype: String, dtype of returned Keras variable.\n-\n         name: String, name of returned Keras variable.\n-\n         seed: Integer, random seed.\n \n     # Returns\n@@ -636,15 +627,10 @@ def random_normal_variable(shape, mean, scale, dtype=None,\n \n     # Arguments\n         shape: Tuple of integers, shape of returned Keras variable.\n-\n         mean: Float, mean of the normal distribution.\n-\n         scale: Float, standard deviation of the normal distribution.\n-\n         dtype: String, dtype of returned Keras variable.\n-\n         name: String, name of returned Keras variable.\n-\n         seed: Integer, random seed.\n \n     # Returns\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#12d068f67554f49707e34cca62981d1196c76aff", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 252 | Contributors (this commit): 9 | Commits (past 90d): 6 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -15,4 +15,4 @@ from . import objectives\n from . import optimizers\r\n from . import regularizers\r\n \r\n-__version__ = '1.1.2'\r\n+__version__ = '1.2.0'\r\n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='1.1.2',\n+      version='1.2.0',\n       description='Deep Learning for Python',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/fchollet/keras',\n-      download_url='https://github.com/fchollet/keras/tarball/1.1.2',\n+      download_url='https://github.com/fchollet/keras/tarball/1.2.0',\n       license='MIT',\n       install_requires=['theano', 'pyyaml', 'six'],\n       extras_require={\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d0b4779071c0383f2ec9092ab9eee4b8ed4f81c2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 591 | Contributors (this commit): 6 | Commits (past 90d): 3 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -88,9 +88,9 @@ style_weight = args.style_weight\n content_weight = args.content_weight\n \n # dimensions of the generated picture.\n+width, height = load_img(base_image_path).size\n img_nrows = 400\n-img_ncols = 400\n-assert img_ncols == img_nrows, 'Due to the use of the Gram matrix, width and height must match.'\n+img_ncols = int(width * img_nrows / height)\n \n # util function to open, resize and format pictures into appropriate tensors\n def preprocess_image(image_path):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dcbc2b933ad09830e907d5e547ff04241b397774", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 8 | Methods Changed: 4 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 18 | Churn Cumulative: 15603 | Contributors (this commit): 71 | Commits (past 90d): 30 | Contributors (cumulative): 81 | DMM Complexity: None\n\nDIFF:\n@@ -1171,7 +1171,7 @@ def Input(shape=None, batch_shape=None,\n         sparse: A boolean specifying whether the placeholder\n             to be created is sparse.\n \n-    # Example usage\n+    # Example\n \n         ```python\n         # this is a logistic regression in Keras\n@@ -1204,7 +1204,7 @@ class Merge(Layer):\n     '''A `Merge` layer can be used to merge a list of tensors\n     into a single tensor, following some merge `mode`.\n \n-    # Example usage\n+    # Example\n \n     ```python\n     model1 = Sequential()\n@@ -1214,7 +1214,7 @@ class Merge(Layer):\n     model2.add(Dense(32, input_dim=32))\n \n     merged_model = Sequential()\n-    merged_model.add(Merge([model1, model2], mode='concat', concat_axis=1)\n+    merged_model.add(Merge([model1, model2], mode='concat', concat_axis=1))\n     ```\n \n     # Arguments\n@@ -1619,7 +1619,7 @@ def merge(inputs, mode='sum', concat_axis=-1,\n     '''Functional merge, to apply to Keras tensors (NOT layers).\n     Returns a Keras tensor.\n \n-    # Example usage:\n+    # Example\n \n     ```python\n     tensor_a = Input(shape=(32,))\n@@ -2606,7 +2606,7 @@ class Container(Layer):\n         is a compiled model ready to be used (unless the saved model\n         was never compiled in the first place).\n \n-        # Example usage\n+        # Example\n \n         ```python\n         from keras.models import load_model\n\n@@ -539,9 +539,9 @@ class Lambda(Layer):\n     # Output shape\n         Specified by `output_shape` argument.\n     '''\n-    def __init__(self, function, output_shape=None, arguments={}, **kwargs):\n+    def __init__(self, function, output_shape=None, arguments=None, **kwargs):\n         self.function = function\n-        self.arguments = arguments\n+        self.arguments = arguments if arguments else {}\n         self.supports_masking = False\n \n         if output_shape is None:\n@@ -793,8 +793,8 @@ class Dense(Layer):\n \n \n class ActivityRegularization(Layer):\n-    '''Layer that passes through its input unchanged, but applies an update\n-    to the cost function based on the activity.\n+    '''Layer that returns its input unchanged, but applies an update\n+    to the cost function based on the activity of the input.\n \n     # Arguments\n         l1: L1 regularization factor (positive float).\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8bc3f4d916ec39c26f34921282f01b07ac20d729", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 943 | Contributors (this commit): 9 | Commits (past 90d): 6 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -139,9 +139,6 @@ PAGES = [\n             core.Dense,\n             core.Activation,\n             core.Dropout,\n-            core.SpatialDropout1D,\n-            core.SpatialDropout2D,\n-            core.SpatialDropout3D,\n             core.Flatten,\n             core.Reshape,\n             core.Permute,\n@@ -152,7 +149,6 @@ PAGES = [\n             core.Masking,\n             core.Highway,\n             core.MaxoutDense,\n-            core.TimeDistributedDense,\n         ],\n     },\n     {\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fdb20dbc7efcde720b8728afbff971ca26c99680", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 14 | Churn Cumulative: 8044 | Contributors (this commit): 54 | Commits (past 90d): 14 | Contributors (cumulative): 54 | DMM Complexity: 0.5\n\nDIFF:\n@@ -597,7 +597,7 @@ class Sequential(Model):\n \n     def fit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=[],\n             validation_split=0., validation_data=None, shuffle=True,\n-            class_weight=None, sample_weight=None, **kwargs):\n+            class_weight=None, sample_weight=None, initial_epoch=0, **kwargs):\n         '''Trains the model for a fixed number of epochs.\n \n         # Arguments\n@@ -632,6 +632,8 @@ class Sequential(Model):\n                 to apply a different weight to every timestep of every sample.\n                 In this case you should make sure to specify\n                 sample_weight_mode=\"temporal\" in compile().\n+            initial_epoch: epoch at which to start training\n+                (useful for resuming a previous training run)\n \n         # Returns\n             A `History` object. Its `History.history` attribute is\n@@ -661,7 +663,8 @@ class Sequential(Model):\n                               validation_data=validation_data,\n                               shuffle=shuffle,\n                               class_weight=class_weight,\n-                              sample_weight=sample_weight)\n+                              sample_weight=sample_weight,\n+                              initial_epoch=initial_epoch)\n \n     def evaluate(self, x, y, batch_size=32, verbose=1,\n                  sample_weight=None, **kwargs):\n@@ -833,7 +836,7 @@ class Sequential(Model):\n                       verbose=1, callbacks=[],\n                       validation_data=None, nb_val_samples=None,\n                       class_weight=None, max_q_size=10, nb_worker=1,\n-                      pickle_safe=False, **kwargs):\n+                      pickle_safe=False, initial_epoch=0, **kwargs):\n         '''Fits the model on data generated batch-by-batch by\n         a Python generator.\n         The generator is run in parallel to the model, for efficiency.\n@@ -869,6 +872,8 @@ class Sequential(Model):\n                 this implementation relies on multiprocessing, you should not pass\n                 non picklable arguments to the generator as they can't be passed\n                 easily to children processes.\n+            initial_epoch: epoch at which to start training\n+                (useful for resuming a previous training run)\n \n         # Returns\n             A `History` object.\n@@ -921,7 +926,8 @@ class Sequential(Model):\n                                         class_weight=class_weight,\n                                         max_q_size=max_q_size,\n                                         nb_worker=nb_worker,\n-                                        pickle_safe=pickle_safe)\n+                                        pickle_safe=pickle_safe,\n+                                        initial_epoch=initial_epoch)\n \n     def evaluate_generator(self, generator, val_samples,\n                            max_q_size=10, nb_worker=1,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#497cff977298768530bfcd9992688731c0fa54b3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 25 | Files Changed: 5 | Hunks: 27 | Methods Changed: 34 | Complexity Δ (Sum/Max): 9/4 | Churn Δ: 55 | Churn Cumulative: 17694 | Contributors (this commit): 105 | Commits (past 90d): 70 | Contributors (cumulative): 140 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1254,7 +1254,7 @@ class Merge(Layer):\n     '''\n     def __init__(self, layers=None, mode='sum', concat_axis=-1,\n                  dot_axes=-1, output_shape=None, output_mask=None,\n-                 arguments={}, node_indices=None, tensor_indices=None,\n+                 arguments=None, node_indices=None, tensor_indices=None,\n                  name=None):\n         self.layers = layers\n         self.mode = mode\n@@ -1263,7 +1263,7 @@ class Merge(Layer):\n         self._output_shape = output_shape\n         self.node_indices = node_indices\n         self._output_mask = output_mask\n-        self.arguments = arguments\n+        self.arguments = arguments if arguments else {}\n \n         # Layer parameters.\n         self.inbound_nodes = []\n@@ -1615,7 +1615,7 @@ class Merge(Layer):\n \n def merge(inputs, mode='sum', concat_axis=-1,\n           dot_axes=-1, output_shape=None, output_mask=None,\n-          arguments={}, name=None):\n+          arguments=None, name=None):\n     '''Functional merge, to apply to Keras tensors (NOT layers).\n     Returns a Keras tensor.\n \n@@ -2534,7 +2534,7 @@ class Container(Layer):\n         return copy.deepcopy(config)\n \n     @classmethod\n-    def from_config(cls, config, custom_objects={}):\n+    def from_config(cls, config, custom_objects=None):\n         '''Instantiates a Model from its config (output of `get_config()`).\n         '''\n         from keras.utils.layer_utils import layer_from_config\n\n@@ -440,7 +440,7 @@ def generator_queue(generator, max_q_size=10,\n \n class Model(Container):\n \n-    def compile(self, optimizer, loss, metrics=[], loss_weights=None,\n+    def compile(self, optimizer, loss, metrics=None, loss_weights=None,\n                 sample_weight_mode=None, **kwargs):\n         '''Configures the model for training.\n \n@@ -750,10 +750,10 @@ class Model(Container):\n                                                updates=self.state_updates,\n                                                **kwargs)\n \n-    def _fit_loop(self, f, ins, out_labels=[], batch_size=32,\n-                  nb_epoch=100, verbose=1, callbacks=[],\n+    def _fit_loop(self, f, ins, out_labels=None, batch_size=32,\n+                  nb_epoch=100, verbose=1, callbacks=None,\n                   val_f=None, val_ins=None, shuffle=True,\n-                  callback_metrics=[], initial_epoch=0):\n+                  callback_metrics=None, initial_epoch=0):\n         '''Abstract fit function for f(ins).\n         Assume that f returns a list, labeled by out_labels.\n \n@@ -790,10 +790,11 @@ class Model(Container):\n         index_array = np.arange(nb_train_sample)\n \n         self.history = cbks.History()\n-        callbacks = [cbks.BaseLogger()] + callbacks + [self.history]\n+        callbacks = [cbks.BaseLogger()] + (callbacks or []) + [self.history]\n         if verbose:\n             callbacks += [cbks.ProgbarLogger()]\n         callbacks = cbks.CallbackList(callbacks)\n+        out_labels = out_labels or []\n \n         # it's possible to callback a different model than self\n         # (used by Sequential models)\n@@ -809,7 +810,7 @@ class Model(Container):\n             'nb_sample': nb_train_sample,\n             'verbose': verbose,\n             'do_validation': do_validation,\n-            'metrics': callback_metrics,\n+            'metrics': callback_metrics or [],\n         })\n         callbacks.on_train_begin()\n         callback_model.stop_training = False\n@@ -1001,7 +1002,7 @@ class Model(Container):\n                                  str(x[0].shape[0]) + ' samples')\n         return x, y, sample_weights\n \n-    def fit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=[],\n+    def fit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=None,\n             validation_split=0., validation_data=None, shuffle=True,\n             class_weight=None, sample_weight=None, initial_epoch=0):\n         '''Trains the model for a fixed number of epochs (iterations on a dataset).\n@@ -1327,9 +1328,9 @@ class Model(Container):\n         return outputs\n \n     def fit_generator(self, generator, samples_per_epoch, nb_epoch,\n-                      verbose=1, callbacks=[],\n+                      verbose=1, callbacks=None,\n                       validation_data=None, nb_val_samples=None,\n-                      class_weight={},\n+                      class_weight=None,\n                       max_q_size=10, nb_worker=1, pickle_safe=False,\n                       initial_epoch=0):\n         '''Fits the model on data generated batch-by-batch by\n@@ -1415,7 +1416,7 @@ class Model(Container):\n \n         # prepare callbacks\n         self.history = cbks.History()\n-        callbacks = [cbks.BaseLogger()] + callbacks + [self.history]\n+        callbacks = [cbks.BaseLogger()] + (callbacks or []) + [self.history]\n         if verbose:\n             callbacks += [cbks.ProgbarLogger()]\n         callbacks = cbks.CallbackList(callbacks)\n\n@@ -106,7 +106,9 @@ def save_model(model, filepath, overwrite=True):\n     f.close()\n \n \n-def load_model(filepath, custom_objects={}):\n+def load_model(filepath, custom_objects=None):\n+    if not custom_objects:\n+        custom_objects = {}\n \n     def deserialize(obj):\n         if isinstance(obj, list):\n@@ -181,7 +183,7 @@ def load_model(filepath, custom_objects={}):\n     return model\n \n \n-def model_from_config(config, custom_objects={}):\n+def model_from_config(config, custom_objects=None):\n     from keras.utils.layer_utils import layer_from_config\n     if isinstance(config, list):\n         raise TypeError('`model_fom_config` expects a dictionary, not a list. '\n@@ -190,7 +192,7 @@ def model_from_config(config, custom_objects={}):\n     return layer_from_config(config, custom_objects=custom_objects)\n \n \n-def model_from_yaml(yaml_string, custom_objects={}):\n+def model_from_yaml(yaml_string, custom_objects=None):\n     '''Parses a yaml model configuration file\n     and returns a model instance.\n     '''\n@@ -200,7 +202,7 @@ def model_from_yaml(yaml_string, custom_objects={}):\n     return layer_from_config(config, custom_objects=custom_objects)\n \n \n-def model_from_json(json_string, custom_objects={}):\n+def model_from_json(json_string, custom_objects=None):\n     '''Parses a JSON model configuration file\n     and returns a model instance.\n     '''\n@@ -246,7 +248,7 @@ class Sequential(Model):\n             model.add(Dense(32))\n         ```\n     '''\n-    def __init__(self, layers=[], name=None):\n+    def __init__(self, layers=None, name=None):\n         self.layers = []  # stack of layers\n         self.model = None  # internal Model instance\n         self.inputs = []  # tensors\n@@ -264,6 +266,7 @@ class Sequential(Model):\n             name = prefix + str(K.get_uid(prefix))\n         self.name = name\n \n+        if layers:\n             for layer in layers:\n                 self.add(layer)\n \n@@ -545,7 +548,7 @@ class Sequential(Model):\n         return self.model.training_data\n \n     def compile(self, optimizer, loss,\n-                metrics=[],\n+                metrics=None,\n                 sample_weight_mode=None,\n                 **kwargs):\n         '''Configures the learning process.\n@@ -595,7 +598,7 @@ class Sequential(Model):\n         self.metrics_names = self.model.metrics_names\n         self.sample_weight_mode = self.model.sample_weight_mode\n \n-    def fit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=[],\n+    def fit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=None,\n             validation_split=0., validation_data=None, shuffle=True,\n             class_weight=None, sample_weight=None, **kwargs):\n         '''Trains the model for a fixed number of epochs.\n@@ -830,7 +833,7 @@ class Sequential(Model):\n             return (proba > 0.5).astype('int32')\n \n     def fit_generator(self, generator, samples_per_epoch, nb_epoch,\n-                      verbose=1, callbacks=[],\n+                      verbose=1, callbacks=None,\n                       validation_data=None, nb_val_samples=None,\n                       class_weight=None, max_q_size=10, nb_worker=1,\n                       pickle_safe=False, **kwargs):\n\n@@ -10,7 +10,7 @@ def clip_norm(g, c, n):\n     return g\n \n \n-def optimizer_from_config(config, custom_objects={}):\n+def optimizer_from_config(config, custom_objects=None):\n     all_classes = {\n         'sgd': SGD,\n         'rmsprop': RMSprop,\n@@ -22,7 +22,7 @@ def optimizer_from_config(config, custom_objects={}):\n         'tfoptimizer': TFOptimizer,\n     }\n     class_name = config['class_name']\n-    if class_name in custom_objects:\n+    if custom_objects and class_name in custom_objects:\n         cls = custom_objects[class_name]\n     else:\n         if class_name.lower() not in all_classes:\n\n@@ -8,7 +8,7 @@ from ..models import Model, Sequential\n from .. import backend as K\n \n \n-def layer_from_config(config, custom_objects={}):\n+def layer_from_config(config, custom_objects=None):\n     '''\n     # Arguments\n         config: dict of the form {'class_name': str, 'config': dict}\n@@ -20,6 +20,7 @@ def layer_from_config(config, custom_objects={}):\n     '''\n     # Insert custom layers into globals so they can\n     # be accessed by `get_from_module`.\n+    if custom_objects:\n         for cls_key in custom_objects:\n             globals()[cls_key] = custom_objects[cls_key]\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2b3eae5f08ab7669c0003027f715abac422bc153", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 6 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 10 | Churn Cumulative: 10978 | Contributors (this commit): 56 | Commits (past 90d): 10 | Contributors (cumulative): 56 | DMM Complexity: 1.0\n\nDIFF:\n@@ -622,7 +622,7 @@ class Lambda(Layer):\n         return dict(list(base_config.items()) + list(config.items()))\n \n     @classmethod\n-    def from_config(cls, config, custom_objects={}):\n+    def from_config(cls, config, custom_objects=None):\n         # Insert custom objects into globals.\n         if custom_objects:\n             globs = globals().copy()\n@@ -966,7 +966,6 @@ class Highway(Layer):\n             or alternatively, Theano function to use for weights\n             initialization. This parameter is only relevant\n             if you don't pass a `weights` argument.\n-        transform_bias: value for the bias to take on initially (default -2)\n         activation: name of activation function to use\n             (see [activations](../activations.md)),\n             or alternatively, elementwise Theano function.\n@@ -1002,7 +1001,6 @@ class Highway(Layer):\n     '''\n     def __init__(self,\n                  init='glorot_uniform',\n-                 transform_bias=-2,\n                  activation=None,\n                  weights=None,\n                  W_regularizer=None,\n@@ -1013,8 +1011,11 @@ class Highway(Layer):\n                  bias=True,\n                  input_dim=None,\n                  **kwargs):\n+        if 'transform_bias' in kwargs:\n+            kwargs.pop('transform_bias')\n+            warnings.warn('`transform_bias` argument is deprecated and '\n+                          'will be removed after 5/2017.')\n         self.init = initializations.get(init)\n-        self.transform_bias = transform_bias\n         self.activation = activations.get(activation)\n \n         self.W_regularizer = regularizers.get(W_regularizer)\n@@ -1078,7 +1079,6 @@ class Highway(Layer):\n \n     def get_config(self):\n         config = {'init': self.init.__name__,\n-                  'transform_bias': self.transform_bias,\n                   'activation': self.activation.__name__,\n                   'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n                   'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#72c7716902da61379aea15a059983ee0de843208", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 49 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -12/0 | Churn Δ: 61 | Churn Cumulative: 213 | Contributors (this commit): 11 | Commits (past 90d): 6 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -68,56 +68,19 @@ def convert_kernel(kernel, dim_ordering='default'):\n     '''\n     if dim_ordering == 'default':\n         dim_ordering = K.image_dim_ordering()\n-    new_kernel = np.copy(kernel)\n-    if kernel.ndim == 4:\n-        # conv 2d\n-        # TH kernel shape: (depth, input_depth, rows, cols)\n-        # TF kernel shape: (rows, cols, input_depth, depth)\n-        if dim_ordering == 'th':\n-            w = kernel.shape[2]\n-            h = kernel.shape[3]\n-            for i in range(w):\n-                for j in range(h):\n-                    new_kernel[:, :, i, j] = kernel[:, :, w - i - 1, h - j - 1]\n-        elif dim_ordering == 'tf':\n-            w = kernel.shape[0]\n-            h = kernel.shape[1]\n-            for i in range(w):\n-                for j in range(h):\n-                    new_kernel[i, j, :, :] = kernel[w - i - 1, h - j - 1, :, :]\n-        else:\n-            raise ValueError('Invalid dim_ordering:', dim_ordering)\n-    elif kernel.ndim == 5:\n-        # conv 3d\n-        # TH kernel shape: (out_depth, input_depth, kernel_dim1, kernel_dim2, kernel_dim3)\n-        # TF kernel shape: (kernel_dim1, kernel_dim2, kernel_dim3, input_depth, out_depth)\n-        if dim_ordering == 'th':\n-            w = kernel.shape[2]\n-            h = kernel.shape[3]\n-            z = kernel.shape[4]\n-            for i in range(w):\n-                for j in range(h):\n-                    for k in range(z):\n-                        new_kernel[:, :, i, j, k] = kernel[:, :,\n-                                                           w - i - 1,\n-                                                           h - j - 1,\n-                                                           z - k - 1]\n-        elif dim_ordering == 'tf':\n-            w = kernel.shape[0]\n-            h = kernel.shape[1]\n-            z = kernel.shape[2]\n-            for i in range(w):\n-                for j in range(h):\n-                    for k in range(z):\n-                        new_kernel[i, j, k, :, :] = kernel[w - i - 1,\n-                                                           h - j - 1,\n-                                                           z - k - 1,\n-                                                           :, :]\n-        else:\n-            raise ValueError('Invalid dim_ordering:', dim_ordering)\n-    else:\n+    if not 4 <= kernel.ndim <= 5:\n         raise ValueError('Invalid kernel shape:', kernel.shape)\n-    return new_kernel\n+\n+    slices = [slice(None, None, -1) for i in range(kernel.ndim)]\n+    no_flip = (slice(None, None), slice(None, None))\n+    if dim_ordering == 'th':  # (out_depth, input_depth, ...)\n+        slices[:2] = no_flip\n+    elif dim_ordering == 'tf':  # (..., input_depth, out_depth)\n+        slices[-2:] = no_flip\n+    else:\n+        raise ValueError('Invalid dim_ordering:', dim_ordering)\n+\n+    return np.copy(kernel[slices])\n \n \n def conv_output_length(input_length, filter_size, border_mode, stride, dilation=1):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c4f3155d192935c7cb659cac6d38c76b15ec971e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 17 | Files Changed: 3 | Hunks: 9 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 31 | Churn Cumulative: 13457 | Contributors (this commit): 82 | Commits (past 90d): 48 | Contributors (cumulative): 94 | DMM Complexity: None\n\nDIFF:\n@@ -299,10 +299,10 @@ class Layer(object):\n \n         # These properties will be set upon call of self.build(),\n         # which itself will be called upon self.add_inbound_node if necessary.\n-        if not hasattr(self, 'trainable_weights'):\n-            self.trainable_weights = []\n-        if not hasattr(self, 'non_trainable_weights'):\n-            self.non_trainable_weights = []\n+        if not hasattr(self, '_trainable_weights'):\n+            self._trainable_weights = []\n+        if not hasattr(self, '_non_trainable_weights'):\n+            self._non_trainable_weights = []\n         if not hasattr(self, 'losses'):\n             self.losses = []\n         if not hasattr(self, 'constraints'):\n@@ -418,9 +418,9 @@ class Layer(object):\n         if constraint is not None:\n             self.constraints[weight] = constraint\n         if trainable:\n-            self.trainable_weights.append(weight)\n+            self._trainable_weights.append(weight)\n         else:\n-            self.non_trainable_weights.append(weight)\n+            self._non_trainable_weights.append(weight)\n         return weight\n \n     def assert_input_compatibility(self, input):\n@@ -1053,16 +1053,11 @@ class InputLayer(Layer):\n         self.uses_learning_phase = False\n         self.trainable = False\n         self.built = True\n-        self.trainable_weights = []\n-        self.non_trainable_weights = []\n-\n+        self._trainable_weights = []\n+        self._non_trainable_weights = []\n         self.inbound_nodes = []\n         self.outbound_nodes = []\n-\n-        self.trainable_weights = []\n-        self.non_trainable_weights = []\n         self.constraints = {}\n-\n         self.sparse = sparse\n \n         if not name:\n@@ -1269,8 +1264,8 @@ class Merge(Layer):\n         self.inbound_nodes = []\n         self.outbound_nodes = []\n         self.constraints = {}\n-        self.trainable_weights = []\n-        self.non_trainable_weights = []\n+        self._trainable_weights = []\n+        self._non_trainable_weights = []\n         self.supports_masking = True\n         self.uses_learning_phase = False\n         self.input_spec = None  # Compatible with anything.\n\n@@ -153,7 +153,8 @@ def load_model(filepath, custom_objects=None):\n         return model\n     training_config = json.loads(training_config.decode('utf-8'))\n     optimizer_config = training_config['optimizer_config']\n-    optimizer = optimizer_from_config(optimizer_config, custom_objects=custom_objects)\n+    optimizer = optimizer_from_config(optimizer_config,\n+                                      custom_objects=custom_objects)\n \n     # recover loss functions and metrics\n     loss = deserialize(training_config['loss'])\n\n@@ -36,7 +36,8 @@ def layer_from_config(config, custom_objects=None):\n \n     arg_spec = inspect.getargspec(layer_class.from_config)\n     if 'custom_objects' in arg_spec.args:\n-        return layer_class.from_config(config['config'], custom_objects=custom_objects)\n+        return layer_class.from_config(config['config'],\n+                                       custom_objects=custom_objects)\n     else:\n         return layer_class.from_config(config['config'])\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
