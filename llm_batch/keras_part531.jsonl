{"custom_id": "keras#d7189027c06ba1a4e5d7e710cf6604107cd784b9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 798 | Contributors (this commit): 2 | Commits (past 90d): 10 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -442,7 +442,7 @@ class RandomNormal(Initializer):\n             mean=self.mean,\n             stddev=self.stddev,\n             seed=self.seed,\n-            dtype=dtype\n+            dtype=dtype,\n         )\n \n     def get_config(self):\n@@ -491,7 +491,7 @@ class RandomUniform(Initializer):\n             minval=self.minval,\n             maxval=self.maxval,\n             seed=self.seed,\n-            dtype=dtype\n+            dtype=dtype,\n         )\n \n     def get_config(self):\n\n@@ -11,9 +11,7 @@ class InitializersTest(testing.TestCase):\n         seed = 1234\n         external_config = {\"mean\": 1.0, \"stddev\": 0.5, \"seed\": 42}\n         initializer = initializers.RandomNormal(\n-            mean=mean,\n-            stddev=stddev,\n-            seed=seed\n+            mean=mean, stddev=stddev, seed=seed\n         )\n         values = initializer(shape=shape)\n         self.assertEqual(initializer.mean, mean)\n@@ -29,9 +27,7 @@ class InitializersTest(testing.TestCase):\n         seed = 1234\n         external_config = {\"minval\": 0.0, \"maxval\": 1.0, \"seed\": 42}\n         initializer = initializers.RandomUniform(\n-            minval=minval,\n-            maxval=maxval,\n-            seed=seed\n+            minval=minval, maxval=maxval, seed=seed\n         )\n         values = initializer(shape=shape)\n         self.assertEqual(initializer.minval, minval)\n@@ -46,4 +42,3 @@ class InitializersTest(testing.TestCase):\n     def test_load_external_config(self, initializer, config):\n         initializer = initializer.from_config(config)\n         self.assertEqual(initializer.get_config(), config)\n-\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#eabdb87f9f336e9ae7d38665298d29632b9ba116", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1320 | Lines Deleted: 339 | Files Changed: 48 | Hunks: 135 | Methods Changed: 58 | Complexity Δ (Sum/Max): 116/62 | Churn Δ: 1659 | Churn Cumulative: 8599 | Contributors (this commit): 22 | Commits (past 90d): 214 | Contributors (cumulative): 142 | DMM Complexity: 0.9005847953216374\n\nDIFF:\n@@ -1,9 +1,9 @@\n from keras_core import backend\n-from keras_core.layers.layer import Layer\n-from keras_core.backend import KerasTensor\n-from keras_core.operations.function import Function\n from keras_core import initializers\n+from keras_core.backend import KerasTensor\n+from keras_core.layers.layer import Layer\n from keras_core.operations import numpy as knp\n+from keras_core.operations.function import Function\n \n \n class MiniDense(Layer):\n\n@@ -1,11 +1,12 @@\n-from keras_core import operations as ops\n-from keras_core import backend\n-from keras_core.optimizers import SGD\n-from keras_core.layers.layer import Layer\n-from keras_core import initializers\n import jax\n-from jax import numpy as jnp\n import numpy as np\n+from jax import numpy as jnp\n+\n+from keras_core import backend\n+from keras_core import initializers\n+from keras_core import operations as ops\n+from keras_core.layers.layer import Layer\n+from keras_core.optimizers import SGD\n \n \n class MiniDense(Layer):\n\n@@ -0,0 +1,2 @@\n+from keras_core import backend\n+from keras_core import operations\n\n@@ -1,4 +1,5 @@\n import types\n+\n from keras_core.saving import register_keras_core_serializable\n \n try:\n\n@@ -1,21 +1,20 @@\n-import os\n import json\n+import os\n import sys\n-from keras_core.utils.io_utils import print_msg\n \n-from keras_core.backend.keras_tensor import KerasTensor\n-from keras_core.backend.keras_tensor import is_keras_tensor\n-from keras_core.backend.keras_tensor import any_symbolic_tensors\n-from keras_core.backend.config import floatx\n-from keras_core.backend.config import epsilon\n-from keras_core.backend.config import image_data_format\n-from keras_core.backend.config import set_floatx\n-from keras_core.backend.config import set_epsilon\n-from keras_core.backend.config import set_image_data_format\n-from keras_core.backend.common import standardize_shape\n-from keras_core.backend.common import standardize_dtype\n from keras_core.backend.common import StatelessScope\n-\n+from keras_core.backend.common import standardize_dtype\n+from keras_core.backend.common import standardize_shape\n+from keras_core.backend.config import epsilon\n+from keras_core.backend.config import floatx\n+from keras_core.backend.config import image_data_format\n+from keras_core.backend.config import set_epsilon\n+from keras_core.backend.config import set_floatx\n+from keras_core.backend.config import set_image_data_format\n+from keras_core.backend.keras_tensor import KerasTensor\n+from keras_core.backend.keras_tensor import any_symbolic_tensors\n+from keras_core.backend.keras_tensor import is_keras_tensor\n+from keras_core.utils.io_utils import print_msg\n \n # Set Keras base dir path given KERAS_HOME env variable, if applicable.\n # Otherwise either ~/.keras or /tmp.\n\n@@ -1,7 +1,9 @@\n-from keras_core.backend.config import floatx\n-from tensorflow import nest\n import threading\n \n+from tensorflow import nest\n+\n+from keras_core.backend.config import floatx\n+\n \n class KerasVariable:\n     def __init__(self, value, dtype, trainable=True, name=None):\n\n@@ -1,14 +1,15 @@\n-from jax import numpy as jnp\n+import jax\n import numpy as np\n+from jax import numpy as jnp\n+from tensorflow import nest\n+\n from keras_core.backend.common import KerasVariable\n+from keras_core.backend.common import StatelessScope\n+from keras_core.backend.common import get_stateless_scope\n+from keras_core.backend.common import in_stateless_scope\n from keras_core.backend.common import standardize_dtype\n from keras_core.backend.keras_tensor import KerasTensor\n from keras_core.utils.naming import auto_name\n-from keras_core.backend.common import in_stateless_scope\n-from keras_core.backend.common import get_stateless_scope\n-from keras_core.backend.common import StatelessScope\n-from tensorflow import nest\n-import jax\n \n DYNAMIC_SHAPES_OK = False  # Dynamic shapes NG\n \n\n@@ -1,4 +1,5 @@\n import jax\n+\n from keras_core.backend import floatx\n from keras_core.backend.random import draw_seed\n \n\n@@ -1,6 +1,7 @@\n-from keras_core.utils.naming import auto_name\n from tensorflow import nest\n \n+from keras_core.utils.naming import auto_name\n+\n \n class KerasTensor:\n     def __init__(self, shape, dtype=\"float32\", name=None):\n\n@@ -1,5 +1,4 @@\n from keras_core.backend import backend\n-\n from keras_core.backend.random.random_seed_generator import RandomSeedGenerator\n from keras_core.backend.random.random_seed_generator import draw_seed\n from keras_core.backend.random.random_seed_generator import make_default_seed\n\n@@ -1,13 +1,13 @@\n import tensorflow as tf\n from tensorflow.experimental import numpy as tfnp\n+\n from keras_core.backend.common import KerasVariable\n+from keras_core.backend.common import get_stateless_scope\n+from keras_core.backend.common import in_stateless_scope\n from keras_core.backend.common import standardize_dtype\n from keras_core.backend.keras_tensor import KerasTensor\n-from keras_core.utils.naming import auto_name\n from keras_core.backend.tensorflow.trainer import Trainer\n-from keras_core.backend.common import in_stateless_scope\n-from keras_core.backend.common import get_stateless_scope\n-\n+from keras_core.utils.naming import auto_name\n \n DYNAMIC_SHAPES_OK = True\n \n\n@@ -1,6 +1,7 @@\n-from keras_core.backend.random import draw_seed\n import tensorflow as tf\n+\n from keras_core.backend import floatx\n+from keras_core.backend.random import draw_seed\n \n \n def tf_draw_seed(seed):\n\n@@ -1,6 +1,7 @@\n-from keras_core.trainers import trainer\n import tensorflow as tf\n \n+from keras_core.trainers import trainer\n+\n \n class Trainer(trainer.Trainer):\n     def train_step(self, data):\n\n@@ -1,3 +1,3 @@\n+from keras_core.initializers.constant_initializers import *\n from keras_core.initializers.initializer import Initializer\n from keras_core.initializers.random_initializers import *\n-from keras_core.initializers.constant_initializers import *\n\n@@ -1,6 +1,6 @@\n+from keras_core.backend import standardize_dtype\n from keras_core.initializers.initializer import Initializer\n from keras_core.operations import numpy as knp\n-from keras_core.backend import standardize_dtype\n \n \n class Zeros(Initializer):\n\n@@ -1,4 +1,5 @@\n import warnings\n+\n from keras_core.api_export import keras_core_export\n \n \n\n@@ -1,6 +1,7 @@\n import math\n-from keras_core.initializers.initializer import Initializer\n+\n from keras_core.backend import random\n+from keras_core.initializers.initializer import Initializer\n \n \n class VarianceScaling(Initializer):\n\n@@ -1,5 +1,6 @@\n-from keras_core import backend\n from tensorflow import nest\n+\n+from keras_core import backend\n from keras_core.api_export import keras_core_export\n \n \n\n@@ -14,21 +14,23 @@ And some more magic:\n - metric tracking\n - RNG seed tracking\n \"\"\"\n-from keras_core.operations.operation import Operation\n-from keras_core.backend import KerasTensor\n-from keras_core import backend\n-from keras_core.utils.tracking import Tracker\n-from keras_core.metrics.metric import Metric\n-from keras_core import utils\n-from keras_core.utils import summary_utils\n-from keras_core.layers import input_spec\n-from keras_core.api_export import keras_core_export\n-from tensorflow import nest\n-from tensorflow import keras as tf_keras\n-import numpy as np\n+import collections\n import inspect\n import threading\n-import collections\n+\n+import numpy as np\n+from tensorflow import keras as tf_keras\n+from tensorflow import nest\n+\n+from keras_core import backend\n+from keras_core import utils\n+from keras_core.api_export import keras_core_export\n+from keras_core.backend import KerasTensor\n+from keras_core.layers import input_spec\n+from keras_core.metrics.metric import Metric\n+from keras_core.operations.operation import Operation\n+from keras_core.utils import summary_utils\n+from keras_core.utils.tracking import Tracker\n \n # TODO: cache all call signature processing. See layer_utils.CallFunctionSpec() in Keras.\n \n\n@@ -1,7 +1,8 @@\n+import numpy as np\n+\n from keras_core import testing\n from keras_core.engine import keras_tensor\n from keras_core.layers.layer import Layer\n-import numpy as np\n \n \n class FunctionTest(testing.TestCase):\n\n@@ -1,8 +1,9 @@\n-from keras_core import operations as ops\n from keras_core import backend\n from keras_core.utils.naming import auto_name\n from keras_core.utils import dtype_utils\n+from keras_core import operations as ops\n from keras_core.api_export import keras_core_export\n+from keras_core.utils.naming import auto_name\n \n \n @keras_core_export([\"keras_core.Loss\", \"keras_core.losses.Loss\"])\n\n@@ -1,7 +1,8 @@\n+import numpy as np\n+\n+from keras_core import operations as ops\n from keras_core import testing\n from keras_core.losses.loss import Loss\n-from keras_core import operations as ops\n-import numpy as np\n \n \n class ExampleLoss(Loss):\n\n@@ -1,5 +1,5 @@\n-from keras_core.losses.loss import Loss\n from keras_core import operations as ops\n+from keras_core.losses.loss import Loss\n from keras_core.losses.loss import squeeze_to_same_rank\n \n \n\n@@ -1,7 +1,7 @@\n from keras_core import backend\n-from keras_core.utils.tracking import Tracker\n-from keras_core.utils.naming import auto_name\n from keras_core.api_export import keras_core_export\n+from keras_core.utils.naming import auto_name\n+from keras_core.utils.tracking import Tracker\n \n \n @keras_core_export([\"keras_core.Metric\", \"keras_core.metrics.Metric\"])\n\n@@ -1,9 +1,10 @@\n-from keras_core import testing\n+import numpy as np\n+\n+from keras_core import backend\n from keras_core import initializers\n from keras_core import operations as ops\n-from keras_core import backend\n+from keras_core import testing\n from keras_core.metrics.metric import Metric\n-import numpy as np\n \n \n class ExampleMetric(Metric):\n\n@@ -1,6 +1,6 @@\n-from keras_core.metrics.metric import Metric\n from keras_core import backend\n from keras_core import initializers\n+from keras_core.metrics.metric import Metric\n \n \n class MeanSquareError(Metric):\n\n@@ -1,6 +1,6 @@\n-from keras_core.operations.function import Function\n-from keras_core.models.model import Model\n from keras_core.layers.layer import Layer\n+from keras_core.models.model import Model\n+from keras_core.operations.function import Function\n \n \n class Functional(Function, Model):\n\n@@ -1,6 +1,6 @@\n from keras_core.api_export import keras_core_export\n-from keras_core.layers.layer import Layer\n from keras_core.backend import Trainer\n+from keras_core.layers.layer import Layer\n \n \n @keras_core_export([\"keras_core.Model\", \"keras_core.models.Model\"])\n\n@@ -2,11 +2,11 @@\n # from keras_core.operations.numpy import Add, add\n # from keras_core.operations.numpy import Multiply, multiply\n \n-from keras_core.operations.numpy import *\n-from keras_core.operations.nn import *\n-from keras_core.backend import is_tensor\n-from keras_core.backend import convert_to_tensor\n from keras_core.backend import cast\n-from keras_core.backend import shape\n from keras_core.backend import cond\n+from keras_core.backend import convert_to_tensor\n+from keras_core.backend import is_tensor\n from keras_core.backend import name_scope\n+from keras_core.backend import shape\n+from keras_core.operations.nn import *\n+from keras_core.operations.numpy import *\n\n@@ -1,8 +1,10 @@\n+import collections\n+\n+from tensorflow import nest\n+\n from keras_core.backend import KerasTensor\n from keras_core.operations.operation import Operation\n from keras_core.utils.naming import auto_name\n-from tensorflow import nest\n-import collections\n \n \n class Function(Operation):\n\n@@ -1,10 +1,11 @@\n+import numpy as np\n+import pytest\n+\n+from keras_core import backend\n+from keras_core import testing\n from keras_core.backend import keras_tensor\n from keras_core.operations import function\n from keras_core.operations import numpy as knp\n-from keras_core import testing\n-from keras_core import backend\n-import pytest\n-import numpy as np\n \n \n class FunctionTest(testing.TestCase):\n\n@@ -1,5 +1,7 @@\n import collections\n+\n from tensorflow import nest\n+\n from keras_core.backend import KerasTensor\n from keras_core.operations.symbolic_arguments import SymbolicArguments\n \n\n@@ -1,201 +1,217 @@\n \"\"\"\n MANIFEST:\n \n-matmul\n-add\n-subtract\n-multiply\n-divide\n-true_divide\n-power\n-negative\n+abs\n absolute\n+add\n+all\n+amax\n+amin\n+append\n+arange\n+arccos\n+arcsin\n+arctan\n+arctanh\n+argmax\n+argmin\n+argsort\n+array\n+array_equal\n+average\n+broadcast_to\n+ceil\n+clip\n+concatenate\n+conj\n+conjugate\n+copy\n+cos\n+count_nonzero\n+cov\n+cross\n+cumprod\n+cumsum\n+diag\n+diag_indices\n+diagonal\n+diff\n+divide\n+dot\n+dtype\n+einsum\n+empty\n+equal\n+exp\n+expand_dims\n+expm1\n+eye\n+flip\n+floor\n+full\n+full_like\n+greater\n+greater_equal\n+hstack\n+identity\n+imag\n+indices\n+interp\n+isclose\n+isfinite\n+isin\n+isinf\n+isnan\n+isscalar\n+issubdtype\n+issubctype\n+less\n+less_equal\n+linspace\n+log\n+log10\n+log1p\n+log2\n+logaddexp\n+logical_and\n+logical_not\n+logical_or\n+logspace\n+matmul\n+max\n+maximum\n mean\n-var\n-zeros\n+median\n+meshgrid\n+mgrid\n+min\n+minimum\n+mod\n+moveaxis\n+multiply\n+nan_to_num\n+ndim\n+nonzero\n+not_equal\n ones\n+ones_like\n+outer\n+pad\n+percentile\n+power\n+prod\n+ravel\n+real\n+reciprocal\n+repeat\n+reshape\n+roll\n+round\n+shape\n+sign\n+sin\n+size\n+sort\n+split\n+sqrt\n+square\n+squeeze\n+stack\n+std\n+subtract\n+sum\n+swapaxes\n+take\n+take_along_axis\n+tan\n+tensordot\n+tile\n+trace\n+transpose\n+tri\n+tril\n+triu\n+true_divide\n+unique\n+unrival_index\n+vdot\n+vectorize\n+vstack\n+where\n+zeros\n+zeros_like\n \n \n \"\"\"\n+import numpy as np\n+\n+from keras_core import backend\n from keras_core.backend import KerasTensor\n from keras_core.backend import any_symbolic_tensors\n-from keras_core.backend import convert_to_tensor\n-from keras_core.operations.symbolic_arguments import SymbolicArguments\n from keras_core.operations.operation import Operation\n-from keras_core import backend\n-\n-from tensorflow import nest\n-import jax\n \n \n-# TODO: replace this function with one that can handle\n-# dynamic shapes.\n-def compute_np_output_spec(op_name, *args, **kwargs):\n-    op = getattr(jax.numpy, op_name)\n+def broadcast_shapes(shape1, shape2):\n+    # Broadcast input shapes to a unified shape.\n+    # Convert to list for mutability.\n+    shape1 = list(shape1)\n+    shape2 = list(shape2)\n+    origin_shape1 = shape1\n+    origin_shape2 = shape2\n \n-    def convert_keras_tensor_to_jax_array(x):\n-        if isinstance(x, KerasTensor):\n-            return jax.numpy.zeros(x.shape, dtype=x.dtype)\n-        return x\n-\n-    args, kwargs = SymbolicArguments(*args, **kwargs).convert(\n-        convert_keras_tensor_to_jax_array\n+    if len(shape1) > len(shape2):\n+        shape2 = [None] * (len(shape1) - len(shape2)) + shape2\n+    if len(shape1) < len(shape2):\n+        shape1 = [None] * (len(shape2) - len(shape1)) + shape1\n+    output_shape = list(shape1)\n+    for i in range(len(shape1)):\n+        if shape1[i] == 1:\n+            output_shape[i] = shape2[i]\n+        elif shape1[i] == None:\n+            output_shape[i] = shape2[i]\n+        else:\n+            if shape2[i] == 1 or shape2[i] == None or shape2[i] == shape1[i]:\n+                output_shape[i] = shape1[i]\n+            else:\n+                raise ValueError(\n+                    \"Cannot broadcast shape, the failure dim has value \"\n+                    f\"{shape1[i]}, which cannot be broadcasted to {shape2[i]}. \"\n+                    f\"Input shapes are: {origin_shape1} and {origin_shape2}.\"\n                 )\n-    jax_out = jax.eval_shape(op, *args, **kwargs)\n \n-    def convert_jax_spec_to_keras_tensor(x):\n-        if isinstance(x, jax.ShapeDtypeStruct):\n-            return KerasTensor(x.shape, x.dtype)\n-        return x\n-\n-    return nest.map_structure(convert_jax_spec_to_keras_tensor, jax_out)\n+    return output_shape\n \n \n-#####################\n-### Two-input ops ###\n-#####################\n+def reduce_shape(shape, axis=None, keepdims=False):\n+    shape = list(shape)\n+    if axis is None:\n+        if keepdims:\n+            output_shape = [1 for _ in range(shape)]\n+        else:\n+            output_shape = []\n+        return output_shape\n+\n+    if keepdims:\n+        for ax in axis:\n+            shape[ax] = 1\n+        return shape\n+    else:\n+        for ax in axis:\n+            shape[ax] = -1\n+        output_shape = list(filter((-1).__ne__, shape))\n+        return output_shape\n \n \n-### matmul ###\n-\n-\n-class Matmul(Operation):\n-    def call(self, x1, x2):\n-        return backend.execute(\"matmul\", x1, x2)\n-\n-    def compute_output_spec(self, x1, x2):\n-        return compute_np_output_spec(\"matmul\", x1, x2)\n-\n-\n-def matmul(x1, x2):\n-    if any_symbolic_tensors((x1, x2)):\n-        return Matmul().symbolic_call(x1, x2)\n-    x1 = convert_to_tensor(x1, x1.dtype)\n-    x2 = convert_to_tensor(x2, x2.dtype)\n-    return backend.execute(\"matmul\", x1, x2)\n-\n-\n-### add ###\n-\n-\n-class Add(Operation):\n-    def call(self, x1, x2):\n-        return backend.execute(\"add\", x1, x2)\n-\n-    def compute_output_spec(self, x1, x2):\n-        return compute_np_output_spec(\"add\", x1, x2)\n-\n-\n-def add(x1, x2):\n-    if any_symbolic_tensors((x1, x2)):\n-        return Add().symbolic_call(x1, x2)\n-    return backend.execute(\"add\", x1, x2)\n-\n-\n-### subtract ###\n-\n-\n-class Subtract(Operation):\n-    def call(self, x1, x2):\n-        return backend.execute(\"subtract\", x1, x2)\n-\n-    def compute_output_spec(self, x1, x2):\n-        return compute_np_output_spec(\"subtract\", x1, x2)\n-\n-\n-def subtract(x1, x2):\n-    if any_symbolic_tensors((x1, x2)):\n-        return Subtract().symbolic_call(x1, x2)\n-    return backend.execute(\"subtract\", x1, x2)\n-\n-\n-### multiply ###\n-\n-\n-class Multiply(Operation):\n-    def call(self, x1, x2):\n-        return backend.execute(\"multiply\", x1, x2)\n-\n-    def compute_output_spec(self, x1, x2):\n-        return compute_np_output_spec(\"multiply\", x1, x2)\n-\n-\n-def multiply(x1, x2):\n-    if any_symbolic_tensors((x1, x2)):\n-        return Multiply().symbolic_call(x1, x2)\n-    return backend.execute(\"multiply\", x1, x2)\n-\n-\n-### divide ###\n-\n-\n-class Divide(Operation):\n-    def call(self, x1, x2):\n-        return backend.execute(\"divide\", x1, x2)\n-\n-    def compute_output_spec(self, x1, x2):\n-        return compute_np_output_spec(\"divide\", x1, x2)\n-\n-\n-def divide(x1, x2):\n-    if any_symbolic_tensors((x1, x2)):\n-        return Divide().symbolic_call(x1, x2)\n-    return backend.execute(\"divide\", x1, x2)\n-\n-\n-### true_divide ###\n-\n-\n-class TrueDivide(Operation):\n-    def call(self, x1, x2):\n-        return backend.execute(\"true_divide\", x1, x2)\n-\n-    def compute_output_spec(self, x1, x2):\n-        return compute_np_output_spec(\"true_divide\", x1, x2)\n-\n-\n-def true_divide(x1, x2):\n-    if any_symbolic_tensors((x1, x2)):\n-        return TrueDivide().symbolic_call(x1, x2)\n-    return backend.execute(\"true_divide\", x1, x2)\n-\n-\n-class Power(Operation):\n-    def call(self, x1, x2):\n-        return backend.execute(\"power\", x1, x2)\n-\n-    def compute_output_spec(self, x1, x2):\n-        return KerasTensor(x1.shape, dtype=x1.dtype)\n-\n-\n-def power(x1, x2):\n-    if any_symbolic_tensors((x1, x2)):\n-        return Power().symbolic_call(x1, x2)\n-    return backend.execute(\"power\", x1, x2)\n-\n-\n-########################\n-### Single-input ops ###\n-########################\n-\n-### negative ###\n-\n-\n-class Negative(Operation):\n-    def call(self, x):\n-        return backend.execute(\"negative\", x)\n-\n-    def compute_output_spec(self, x):\n-        return KerasTensor(x.shape, dtype=x.dtype)\n-\n-\n-def negative(x):\n-    if any_symbolic_tensors((x,)):\n-        return Negative().symbolic_call(x)\n-    return backend.execute(\"negative\", x)\n-\n-\n-### absolute ###\n+def shape_equal(shape1, shape2, axis=None):\n+    if len(shape1) != len(shape2):\n+        return False\n+    if axis is not None:\n+        shape1 = list(shape1)\n+        shape2 = list(shape2)\n+        for ax in axis:\n+            shape1[ax] = -1\n+            shape2[ax] = -1\n+    return shape1 == shape2\n \n \n class Absolute(Operation):\n@@ -212,7 +228,297 @@ def absolute(x):\n     return backend.execute(\"absolute\", x)\n \n \n-### square ###\n+class Abs(Absolute):\n+    pass\n+\n+\n+def abs(x):\n+    return absolute(x)\n+\n+\n+class Add(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"add\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        output_shape = broadcast_shapes(x1.shape, x2.shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def add(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return Add().symbolic_call(x1, x2)\n+    return backend.execute(\"add\", x1, x2)\n+\n+\n+class All(Operation):\n+    def __init__(self, axis=None, keepdims=False):\n+        super().__init__()\n+        if isinstance(axis, int):\n+            self.axis = [axis]\n+        else:\n+            self.axis = axis\n+        self.keepdims = keepdims\n+\n+    def call(self, x):\n+        return backend.execute(\n+            \"all\",\n+            x,\n+            axis=self.axis,\n+            keepdims=self.keepdims,\n+        )\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(\n+            reduce_shape(\n+                x.shape,\n+                axis=self.axis,\n+                keepdims=self.keepdims,\n+            ),\n+            dtype=x.dtype,\n+        )\n+\n+\n+def all(x, axis=None, keepdims=False):\n+    if any_symbolic_tensors((x,)):\n+        return All(axis=axis, keepdims=keepdims).symbolic_call(x)\n+    return backend.execute(\"all\", x, axis=axis, keepdims=keepdims)\n+\n+\n+class Amax(Operation):\n+    def __init__(self, axis=None, keepdims=False):\n+        super().__init__()\n+        if isinstance(axis, int):\n+            axis = [axis]\n+        self.axis = axis\n+        self.keepdims = keepdims\n+\n+    def call(self, x):\n+        return backend.execute(\n+            \"amax\",\n+            x,\n+            axis=self.axis,\n+            keepdims=self.keepdims,\n+        )\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(\n+            reduce_shape(x.shape, axis=self.axis, keepdims=self.keepdims),\n+            dtype=x.dtype,\n+        )\n+\n+\n+def amax(x, axis=None, keepdims=False):\n+    if any_symbolic_tensors((x,)):\n+        return All(axis=axis, keepdims=keepdims).symbolic_call(x)\n+    return backend.execute(\"amax\", x, axis=axis, keepdims=keepdims)\n+\n+\n+class Amin(Operation):\n+    def __init__(self, axis=None, keepdims=False):\n+        super().__init__()\n+        if isinstance(axis, int):\n+            axis = [axis]\n+        self.axis = axis\n+        self.keepdims = keepdims\n+\n+    def call(self, x):\n+        return backend.execute(\n+            \"amin\", x, axis=self.axis, keepdims=self.keepdims\n+        )\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(\n+            reduce_shape(x.shape, axis=self.axis, keepdims=self.keepdims),\n+            dtype=x.dtype,\n+        )\n+\n+\n+def amin(x, axis=None, keepdims=False):\n+    if any_symbolic_tensors((x,)):\n+        return All(axis=axis, keepdims=keepdims).symbolic_call(x)\n+    return backend.execute(\"amin\", x, axis=axis, keepdims=keepdims)\n+\n+\n+class Append(Operation):\n+    def __init__(self, axis=None):\n+        super().__init__()\n+        self.axis = axis\n+\n+    def call(self, x1, x2):\n+        return backend.execute(\"append\", x1, x2, axis=self.axis)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = x1.shape\n+        x2_shape = x2.shape\n+        if self.axis is None:\n+            if None in x1_shape or None in x2_shape:\n+                output_shape = [None]\n+            else:\n+                output_shape = [int(np.prod(x1_shape) + np.prod(x2_shape))]\n+            return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+        if not shape_equal(x1_shape, x2_shape, [self.axis]):\n+            raise ValueError(\n+                \"`append` requires inputs to have the same shape except the \"\n+                f\"`axis={self.axis}`, but received shape {x1_shape} and \"\n+                f\"{x2_shape}.\"\n+            )\n+\n+        output_shape = list(x1_shape)\n+        output_shape[self.axis] = x1_shape[self.axis] + x2_shape[self.axis]\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def append(\n+    x1,\n+    x2,\n+    axis=None,\n+):\n+    if any_symbolic_tensors((x1, x2)):\n+        return Append(axis=axis).symbolic_call(x1, x2)\n+    return backend.execute(\"append\", x1, x2, axis=axis)\n+\n+\n+class Matmul(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"matmul\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = x1.shape\n+        x2_shape = x2.shape\n+        if len(x1_shape) == 1:\n+            x1_shape = (1, x1_shape[0])\n+        if len(x2_shape) == 1:\n+            x2_shape = (x2_shape[0], 1)\n+        if (\n+            x1_shape[-1] is not None\n+            and x2_shape[-2] is not None\n+            and x1_shape[-1] != x2_shape[-2]\n+        ):\n+            raise ValueError(\n+                \"Inner dimensions (`x1.shape[-1]` and `x2.shape[-2]`) must be \"\n+                f\"equal, but received `x1.shape={x1.shape}` and \"\n+                f\"`x2.shape={x2.shape}`.\"\n+            )\n+\n+        leading_shape = broadcast_shapes(x1_shape[:-2], x2_shape[:-2])\n+        last_2_dims_shape = [x1_shape[-2], x2_shape[-1]]\n+        output_shape = leading_shape + last_2_dims_shape\n+        if len(x1.shape) == 1:\n+            del output_shape[-2]\n+        if len(x2.shape) == 1:\n+            del output_shape[-1]\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def matmul(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return Matmul().symbolic_call(x1, x2)\n+    return backend.execute(\"matmul\", x1, x2)\n+\n+\n+class Subtract(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"subtract\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        output_shape = broadcast_shapes(x1.shape, x2.shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def subtract(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return Subtract().symbolic_call(x1, x2)\n+    return backend.execute(\"subtract\", x1, x2)\n+\n+\n+class Multiply(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"multiply\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        output_shape = broadcast_shapes(x1.shape, x2.shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def multiply(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return Multiply().symbolic_call(x1, x2)\n+    return backend.execute(\"multiply\", x1, x2)\n+\n+\n+class Divide(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"divide\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        output_shape = broadcast_shapes(x1.shape, x2.shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def divide(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return Divide().symbolic_call(x1, x2)\n+    return backend.execute(\"divide\", x1, x2)\n+\n+\n+class TrueDivide(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"true_divide\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        output_shape = broadcast_shapes(x1.shape, x2.shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def true_divide(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return TrueDivide().symbolic_call(x1, x2)\n+    return backend.execute(\"true_divide\", x1, x2)\n+\n+\n+class Power(Operation):\n+    def call(self, x1, x2):\n+        return backend.execute(\"power\", x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        output_shape = broadcast_shapes(x1.shape, x2.shape)\n+        return KerasTensor(output_shape, dtype=x1.dtype)\n+\n+\n+def power(x1, x2):\n+    if any_symbolic_tensors((x1, x2)):\n+        return Power().symbolic_call(x1, x2)\n+    return backend.execute(\"power\", x1, x2)\n+\n+\n+class Negative(Operation):\n+    def call(self, x):\n+        return backend.execute(\"negative\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def negative(x):\n+    if any_symbolic_tensors((x,)):\n+        return Negative().symbolic_call(x)\n+    return backend.execute(\"negative\", x)\n+\n+\n+class Absolute(Operation):\n+    def call(self, x):\n+        return backend.execute(\"absolute\", x)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n+\n+\n+def absolute(x):\n+    if any_symbolic_tensors((x,)):\n+        return Absolute().symbolic_call(x)\n+    return backend.execute(\"absolute\", x)\n \n \n class Square(Operation):\n@@ -229,58 +535,70 @@ def square(x):\n     return backend.execute(\"square\", x)\n \n \n-#####################\n-### Reshaping ops ###\n-#####################\n-\n-\n-### squeeze ###\n-\n-\n class Squeeze(Operation):\n     def __init__(self, axis=None):\n+        super().__init__()\n         self.axis = axis\n \n-    def call(self, a):\n-        return backend.execute(\"squeeze\", a, axis=self.axis)\n+    def call(self, x):\n+        return backend.execute(\"squeeze\", x, axis=self.axis)\n \n-    def compute_output_spec(self, a):\n-        return compute_np_output_spec(\"squeeze\", a, axis=self.axis)\n+    def compute_output_spec(self, x, axis=None):\n+        input_shape = list(x.shape)\n+        if axis is None:\n+            output_shape = list(filter((1).__ne__, input_shape))\n+            return KerasTensor(output_shape)\n+        else:\n+            if input_shape[axis] != 1:\n+                raise ValueError(\n+                    f\"Cannot squeeze axis {axis}, because the dimension is not \"\n+                    \"1.\"\n+                )\n+            del input_shape[axis]\n+            return KerasTensor(input_shape, dtype=x.dtype)\n \n \n-def squeeze(a, axis=None):\n-    if any_symbolic_tensors((a,)):\n-        return Squeeze().symbolic_call(a, axis=axis)\n-    return backend.execute(\"squeeze\", a, axis=axis)\n-\n-\n-### transpose ###\n+def squeeze(x, axis=None):\n+    if any_symbolic_tensors((x,)):\n+        return Squeeze().symbolic_call(x, axis=axis)\n+    return backend.execute(\"squeeze\", x, axis=axis)\n \n \n class Transpose(Operation):\n     def __init__(self, axes=None):\n+        super().__init__()\n         self.axes = axes\n \n-    def call(self, a):\n-        return backend.execute(\"transpose\", a, axes=self.axes)\n+    def call(self, x):\n+        return backend.execute(\"transpose\", x, axes=self.axes)\n \n-    def compute_output_spec(self, a):\n-        return compute_np_output_spec(\"transpose\", a, axes=self.axes)\n+    def compute_output_spec(self, x):\n+        x_shape = x.shape\n+        if self.axes is None:\n+            return KerasTensor(x_shape[::-1])\n+\n+        if len(self.axes) != len(x_shape):\n+            raise ValueError(\n+                \"axis must be a list of the same length as the input shape, \"\n+                f\"expected {len(x_shape)}, but received {len(self.axes)}.\"\n+            )\n+        output_shape = []\n+        for ax in self.axes:\n+            output_shape.append(x_shape[ax])\n+        return KerasTensor(output_shape, dtype=x.dtype)\n \n \n-def transpose(a, axes=None):\n-    if any_symbolic_tensors((a,)):\n-        return Transpose().symbolic_call(a, axes=axes)\n-    return backend.execute(\"transpose\", a, axes=axes)\n-\n-\n-#####################\n-### Reduction ops ###\n-#####################\n+def transpose(x, axes=None):\n+    if any_symbolic_tensors((x,)):\n+        return Transpose(axes=axes).symbolic_call(x)\n+    return backend.execute(\"transpose\", x, axes=axes)\n \n \n class Mean(Operation):\n     def __init__(self, axis=None, keepdims=False):\n+        super().__init__()\n+        if isinstance(axis, int):\n+            axis = [axis]\n         self.axis = axis\n         self.keepdims = keepdims\n \n@@ -290,8 +608,9 @@ class Mean(Operation):\n         )\n \n     def compute_output_spec(self, x):\n-        return compute_np_output_spec(\n-            \"mean\", x, axis=self.axis, keepdims=self.keepdims\n+        return KerasTensor(\n+            reduce_shape(x.shape, axis=self.axis, keepdims=self.keepdims),\n+            dtype=x.dtype,\n         )\n \n \n@@ -303,6 +622,9 @@ def mean(x, axis=None, keepdims=False):\n \n class Var(Operation):\n     def __init__(self, axis=None, keepdims=False):\n+        super().__init__()\n+        if isinstance(axis, int):\n+            axis = [axis]\n         self.axis = axis\n         self.keepdims = keepdims\n \n@@ -310,8 +632,9 @@ class Var(Operation):\n         return backend.execute(\"var\", x, axis=self.axis, keepdims=self.keepdims)\n \n     def compute_output_spec(self, x):\n-        return compute_np_output_spec(\n-            \"var\", x, axis=self.axis, keepdims=self.keepdims\n+        return KerasTensor(\n+            reduce_shape(x.shape, axis=self.axis, keepdims=self.keepdims),\n+            dtype=x.dtype,\n         )\n \n \n@@ -323,6 +646,9 @@ def var(x, axis=None, keepdims=False):\n \n class Sum(Operation):\n     def __init__(self, axis=None, keepdims=False):\n+        super().__init__()\n+        if isinstance(axis, int):\n+            axis = [axis]\n         self.axis = axis\n         self.keepdims = keepdims\n \n@@ -330,8 +656,9 @@ class Sum(Operation):\n         return backend.execute(\"sum\", x, axis=self.axis, keepdims=self.keepdims)\n \n     def compute_output_spec(self, x):\n-        return compute_np_output_spec(\n-            \"sum\", x, axis=self.axis, keepdims=self.keepdims\n+        return KerasTensor(\n+            reduce_shape(x.shape, axis=self.axis, keepdims=self.keepdims),\n+            dtype=x.dtype,\n         )\n \n \n@@ -341,14 +668,6 @@ def sum(x, axis=None, keepdims=False):\n     return backend.execute(\"sum\", x, axis=axis, keepdims=keepdims)\n \n \n-##########################\n-### Array creation ops ###\n-##########################\n-\n-\n-### zeros ###\n-\n-\n class Zeros(Operation):\n     def call(self, shape, dtype=\"float32\"):\n         return backend.execute(\"zeros\", shape, dtype)\n@@ -361,9 +680,6 @@ def zeros(shape, dtype=\"float32\"):\n     return backend.execute(\"zeros\", shape, dtype)\n \n \n-### ones ###\n-\n-\n class Ones(Operation):\n     def call(self, shape, dtype=\"float32\"):\n         return backend.execute(\"ones\", shape, dtype)\n@@ -376,9 +692,6 @@ def ones(shape, dtype=\"float32\"):\n     return backend.execute(\"ones\", shape, dtype)\n \n \n-### eye ###\n-\n-\n class Eye(Operation):\n     def call(self, N, M=None, k=0, dtype=\"float32\"):\n         return backend.execute(\"eye\", N, M=M, k=k, dtype=dtype)\n\n@@ -0,0 +1,594 @@\n+import numpy as np\n+\n+from keras_core import backend\n+from keras_core import testing\n+from keras_core.backend.keras_tensor import KerasTensor\n+from keras_core.operations import numpy as knp\n+from keras_core.operations import operation\n+\n+\n+class NumpyTwoInputOpsShapeTest(testing.TestCase):\n+    def test_add(self):\n+        x = KerasTensor((2, 3))\n+        y = KerasTensor((2, 3))\n+        self.assertEqual(knp.add(x, y).shape, (2, 3))\n+\n+        x = KerasTensor((None, 3))\n+        y = KerasTensor((2, None))\n+        self.assertEqual(knp.add(x, y).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.add(x, y)\n+\n+    def test_subtract(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.subtract(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.subtract(x, y).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.subtract(x, y)\n+\n+    def test_multiply(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.multiply(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.multiply(x, y).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.multiply(x, y)\n+\n+    def test_matmul(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([3, 2])\n+        self.assertEqual(knp.matmul(x, y).shape, (2, 2))\n+\n+        x = KerasTensor([None, 3, 4])\n+        y = KerasTensor([3, None, 4, 5])\n+        self.assertEqual(knp.matmul(x, y).shape, (3, None, 3, 5))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([3, 4])\n+            y = KerasTensor([2, 3, 4])\n+            knp.matmul(x, y)\n+\n+    def test_power(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.power(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.power(x, y).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.power(x, y)\n+\n+    def test_divide(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.divide(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.divide(x, y).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.divide(x, y)\n+\n+    def test_true_divide(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.true_divide(x, y).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.true_divide(x, y).shape, (2, 3))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.true_divide(x, y)\n+\n+    def test_append(self):\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.append(x, y).shape, (12,))\n+\n+        x = KerasTensor([2, 3])\n+        y = KerasTensor([2, 3])\n+        self.assertEqual(knp.append(x, y, axis=0).shape, (4, 3))\n+\n+        x = KerasTensor([None, 3])\n+        y = KerasTensor([2, None])\n+        self.assertEqual(knp.append(x, y).shape, (None,))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([2, 3])\n+            y = KerasTensor([2, 3, 4])\n+            knp.append(x, y, axis=2)\n+\n+\n+class NumpyOneInputOpsShapeTest(testing.TestCase):\n+    def test_mean(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.mean(x).shape, ())\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.mean(x).shape, ())\n+\n+        x = KerasTensor([None, 3, 3])\n+        self.assertEqual(knp.mean(x, axis=1).shape, (None, 3))\n+        self.assertEqual(knp.mean(x, axis=1, keepdims=True).shape, (None, 1, 3))\n+\n+    def test_all(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.all(x).shape, ())\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.all(x).shape, ())\n+\n+        x = KerasTensor([None, 3, 3])\n+        self.assertEqual(knp.all(x, axis=1).shape, (None, 3))\n+        self.assertEqual(knp.all(x, axis=1, keepdims=True).shape, (None, 1, 3))\n+\n+    def test_var(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.var(x).shape, ())\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.var(x).shape, ())\n+\n+        x = KerasTensor([None, 3, 3])\n+        self.assertEqual(knp.var(x, axis=1).shape, (None, 3))\n+        self.assertEqual(knp.var(x, axis=1, keepdims=True).shape, (None, 1, 3))\n+\n+    def test_sum(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.sum(x).shape, ())\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.sum(x).shape, ())\n+\n+        x = KerasTensor([None, 3, 3])\n+        self.assertEqual(knp.sum(x, axis=1).shape, (None, 3))\n+        self.assertEqual(knp.sum(x, axis=1, keepdims=True).shape, (None, 1, 3))\n+\n+    def test_amax(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.amax(x).shape, ())\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.amax(x).shape, ())\n+\n+        x = KerasTensor([None, 3, 3])\n+        self.assertEqual(knp.amax(x, axis=1).shape, (None, 3))\n+        self.assertEqual(knp.amax(x, axis=1, keepdims=True).shape, (None, 1, 3))\n+\n+    def test_amin(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.amin(x).shape, ())\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.amin(x).shape, ())\n+\n+        x = KerasTensor([None, 3, 3])\n+        self.assertEqual(knp.amin(x, axis=1).shape, (None, 3))\n+        self.assertEqual(knp.amin(x, axis=1, keepdims=True).shape, (None, 1, 3))\n+\n+    def test_square(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.square(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.square(x).shape, (None, 3))\n+\n+    def test_negative(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.negative(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.negative(x).shape, (None, 3))\n+\n+    def test_abs(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.abs(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.abs(x).shape, (None, 3))\n+\n+    def test_absolute(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.absolute(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.absolute(x).shape, (None, 3))\n+\n+    def test_squeeze(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.squeeze(x).shape, (2, 3))\n+\n+        x = KerasTensor([None, 1])\n+        self.assertEqual(knp.squeeze(x).shape, (None,))\n+        self.assertEqual(knp.squeeze(x, axis=1).shape, (None,))\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor([None, 1])\n+            knp.squeeze(x, axis=0)\n+\n+    def test_transpose(self):\n+        x = KerasTensor([2, 3])\n+        self.assertEqual(knp.transpose(x).shape, (3, 2))\n+\n+        x = KerasTensor([None, 3])\n+        self.assertEqual(knp.transpose(x).shape, (3, None))\n+\n+        x = KerasTensor([None, 3, 3])\n+        self.assertEqual(knp.transpose(x, (2, 0, 1)).shape, (3, None, 3))\n+\n+\n+class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n+    def test_add(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        y = np.array([[4, 5, 6], [3, 2, 1]])\n+        z = np.array([[[1, 2, 3], [3, 2, 1]]])\n+        np.testing.assert_array_equal(np.array(knp.add(x, y)), np.add(x, y))\n+        np.testing.assert_array_equal(np.array(knp.add(x, z)), np.add(x, z))\n+\n+        np.testing.assert_array_equal(np.array(knp.Add()(x, y)), np.add(x, y))\n+        np.testing.assert_array_equal(np.array(knp.Add()(x, z)), np.add(x, z))\n+\n+    def test_subtract(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        y = np.array([[4, 5, 6], [3, 2, 1]])\n+        z = np.array([[[1, 2, 3], [3, 2, 1]]])\n+        np.testing.assert_array_equal(\n+            np.array(knp.subtract(x, y)), np.subtract(x, y)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.subtract(x, z)), np.subtract(x, z)\n+        )\n+\n+        np.testing.assert_array_equal(\n+            np.array(knp.Subtract()(x, y)), np.subtract(x, y)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.Subtract()(x, z)), np.subtract(x, z)\n+        )\n+\n+    def test_multiply(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        y = np.array([[4, 5, 6], [3, 2, 1]])\n+        z = np.array([[[1, 2, 3], [3, 2, 1]]])\n+        np.testing.assert_array_equal(\n+            np.array(knp.multiply(x, y)), np.multiply(x, y)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.multiply(x, z)), np.multiply(x, z)\n+        )\n+\n+        np.testing.assert_array_equal(\n+            np.array(knp.Multiply()(x, y)), np.multiply(x, y)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.Multiply()(x, z)), np.multiply(x, z)\n+        )\n+\n+    def test_matmul(self):\n+        x = np.ones([2, 3, 4, 5])\n+        y = np.ones([2, 3, 5, 6])\n+        z = np.ones([5, 6])\n+        np.testing.assert_array_equal(\n+            np.array(knp.matmul(x, y)), np.matmul(x, y)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.matmul(x, z)), np.matmul(x, z)\n+        )\n+\n+        np.testing.assert_array_equal(\n+            np.array(knp.Matmul()(x, y)), np.matmul(x, y)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.Matmul()(x, z)), np.matmul(x, z)\n+        )\n+\n+    def test_power(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        y = np.array([[4, 5, 6], [3, 2, 1]])\n+        z = np.array([[[1, 2, 3], [3, 2, 1]]])\n+        np.testing.assert_array_equal(np.array(knp.power(x, y)), np.power(x, y))\n+        np.testing.assert_array_equal(np.array(knp.power(x, z)), np.power(x, z))\n+\n+        np.testing.assert_array_equal(\n+            np.array(knp.Power()(x, y)), np.power(x, y)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.Power()(x, z)), np.power(x, z)\n+        )\n+\n+    def test_divide(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        y = np.array([[4, 5, 6], [3, 2, 1]])\n+        z = np.array([[[1, 2, 3], [3, 2, 1]]])\n+        np.testing.assert_array_equal(\n+            np.array(knp.divide(x, y)), np.divide(x, y)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.divide(x, z)), np.divide(x, z)\n+        )\n+\n+        np.testing.assert_array_equal(\n+            np.array(knp.Divide()(x, y)), np.divide(x, y)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.Divide()(x, z)), np.divide(x, z)\n+        )\n+\n+    def test_true_divide(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        y = np.array([[4, 5, 6], [3, 2, 1]])\n+        z = np.array([[[1, 2, 3], [3, 2, 1]]])\n+        np.testing.assert_array_equal(\n+            np.array(knp.true_divide(x, y)), np.true_divide(x, y)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.true_divide(x, z)), np.true_divide(x, z)\n+        )\n+\n+        np.testing.assert_array_equal(\n+            np.array(knp.TrueDivide()(x, y)), np.true_divide(x, y)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.TrueDivide()(x, z)), np.true_divide(x, z)\n+        )\n+\n+    def test_append(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        y = np.array([[4, 5, 6], [3, 2, 1]])\n+        z = np.array([[[1, 2, 3], [3, 2, 1]], [[4, 5, 6], [3, 2, 1]]])\n+        np.testing.assert_array_equal(\n+            np.array(knp.append(x, y)), np.append(x, y)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.append(x, y, axis=1)), np.append(x, y, axis=1)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.append(x, z)), np.append(x, z)\n+        )\n+\n+        np.testing.assert_array_equal(\n+            np.array(knp.Append()(x, y)), np.append(x, y)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.Append(axis=1)(x, y)), np.append(x, y, axis=1)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.Append()(x, z)), np.append(x, z)\n+        )\n+\n+\n+class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n+    def test_mean(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        np.testing.assert_array_equal(np.array(knp.mean(x)), np.mean(x))\n+        np.testing.assert_array_equal(\n+            np.array(knp.mean(x, axis=1)), np.mean(x, axis=1)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.mean(x, axis=1, keepdims=True)),\n+            np.mean(x, axis=1, keepdims=True),\n+        )\n+\n+        np.testing.assert_array_equal(np.array(knp.Mean()(x)), np.mean(x))\n+        np.testing.assert_array_equal(\n+            np.array(knp.Mean(axis=1)(x)), np.mean(x, axis=1)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.Mean(axis=1, keepdims=True)(x)),\n+            np.mean(x, axis=1, keepdims=True),\n+        )\n+\n+    def test_all(self):\n+        x = np.array([[True, False, True], [True, True, True]])\n+        np.testing.assert_array_equal(np.array(knp.all(x)), np.all(x))\n+        np.testing.assert_array_equal(\n+            np.array(knp.all(x, axis=1)), np.all(x, axis=1)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.all(x, axis=1, keepdims=True)),\n+            np.all(x, axis=1, keepdims=True),\n+        )\n+\n+        np.testing.assert_array_equal(np.array(knp.All()(x)), np.all(x))\n+        np.testing.assert_array_equal(\n+            np.array(knp.All(axis=1)(x)), np.all(x, axis=1)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.All(axis=1, keepdims=True)(x)),\n+            np.all(x, axis=1, keepdims=True),\n+        )\n+\n+    def test_var(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        np.testing.assert_array_equal(np.array(knp.var(x)), np.var(x))\n+        np.testing.assert_array_equal(\n+            np.array(knp.var(x, axis=1)), np.var(x, axis=1)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.var(x, axis=1, keepdims=True)),\n+            np.var(x, axis=1, keepdims=True),\n+        )\n+\n+        np.testing.assert_array_equal(np.array(knp.Var()(x)), np.var(x))\n+        np.testing.assert_array_equal(\n+            np.array(knp.Var(axis=1)(x)), np.var(x, axis=1)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.Var(axis=1, keepdims=True)(x)),\n+            np.var(x, axis=1, keepdims=True),\n+        )\n+\n+    def test_sum(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        np.testing.assert_array_equal(np.array(knp.sum(x)), np.sum(x))\n+        np.testing.assert_array_equal(\n+            np.array(knp.sum(x, axis=1)), np.sum(x, axis=1)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.sum(x, axis=1, keepdims=True)),\n+            np.sum(x, axis=1, keepdims=True),\n+        )\n+\n+        np.testing.assert_array_equal(np.array(knp.Sum()(x)), np.sum(x))\n+        np.testing.assert_array_equal(\n+            np.array(knp.Sum(axis=1)(x)), np.sum(x, axis=1)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.Sum(axis=1, keepdims=True)(x)),\n+            np.sum(x, axis=1, keepdims=True),\n+        )\n+\n+    def test_amax(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        np.testing.assert_array_equal(np.array(knp.amax(x)), np.amax(x))\n+        np.testing.assert_array_equal(\n+            np.array(knp.amax(x, axis=1)), np.amax(x, axis=1)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.amax(x, axis=1, keepdims=True)),\n+            np.amax(x, axis=1, keepdims=True),\n+        )\n+\n+        np.testing.assert_array_equal(np.array(knp.Amax()(x)), np.amax(x))\n+        np.testing.assert_array_equal(\n+            np.array(knp.Amax(axis=1)(x)), np.amax(x, axis=1)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.Amax(axis=1, keepdims=True)(x)),\n+            np.amax(x, axis=1, keepdims=True),\n+        )\n+\n+    def test_amin(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        np.testing.assert_array_equal(np.array(knp.amin(x)), np.amin(x))\n+        np.testing.assert_array_equal(\n+            np.array(knp.amin(x, axis=1)), np.amin(x, axis=1)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.amin(x, axis=1, keepdims=True)),\n+            np.amin(x, axis=1, keepdims=True),\n+        )\n+\n+        np.testing.assert_array_equal(np.array(knp.Amin()(x)), np.amin(x))\n+        np.testing.assert_array_equal(\n+            np.array(knp.Amin(axis=1)(x)), np.amin(x, axis=1)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.Amin(axis=1, keepdims=True)(x)),\n+            np.amin(x, axis=1, keepdims=True),\n+        )\n+\n+    def test_square(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        np.testing.assert_array_equal(np.array(knp.square(x)), np.square(x))\n+\n+        np.testing.assert_array_equal(np.array(knp.Square()(x)), np.square(x))\n+\n+    def test_negative(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        np.testing.assert_array_equal(np.array(knp.negative(x)), np.negative(x))\n+\n+        np.testing.assert_array_equal(\n+            np.array(knp.Negative()(x)), np.negative(x)\n+        )\n+\n+    def test_abs(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        np.testing.assert_array_equal(np.array(knp.abs(x)), np.abs(x))\n+\n+        np.testing.assert_array_equal(np.array(knp.Abs()(x)), np.abs(x))\n+\n+    def test_absolute(self):\n+        x = np.array([[1, 2, 3], [3, 2, 1]])\n+        np.testing.assert_array_equal(np.array(knp.absolute(x)), np.absolute(x))\n+\n+        np.testing.assert_array_equal(\n+            np.array(knp.Absolute()(x)), np.absolute(x)\n+        )\n+\n+    def test_squeeze(self):\n+        x = np.ones([1, 2, 3, 4, 5])\n+        np.testing.assert_array_equal(np.array(knp.squeeze(x)), np.squeeze(x))\n+        np.testing.assert_array_equal(\n+            np.array(knp.squeeze(x, axis=0)), np.squeeze(x, axis=0)\n+        )\n+\n+        np.testing.assert_array_equal(np.array(knp.Squeeze()(x)), np.squeeze(x))\n+        np.testing.assert_array_equal(\n+            np.array(knp.Squeeze(axis=0)(x)), np.squeeze(x, axis=0)\n+        )\n+\n+    def test_transpose(self):\n+        x = np.ones([1, 2, 3, 4, 5])\n+        np.testing.assert_array_equal(\n+            np.array(knp.transpose(x)), np.transpose(x)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.transpose(x, axes=(1, 0, 3, 2, 4))),\n+            np.transpose(x, axes=(1, 0, 3, 2, 4)),\n+        )\n+\n+        np.testing.assert_array_equal(\n+            np.array(knp.Transpose()(x)), np.transpose(x)\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.Transpose(axes=(1, 0, 3, 2, 4))(x)),\n+            np.transpose(x, axes=(1, 0, 3, 2, 4)),\n+        )\n+\n+\n+class NumpyArrayCreateOpsCorrectnessTest(testing.TestCase):\n+    def test_ones(self):\n+        np.testing.assert_array_equal(\n+            np.array(knp.ones([2, 3])), np.ones([2, 3])\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.Ones()([2, 3])), np.ones([2, 3])\n+        )\n+\n+    def test_zeros(self):\n+        np.testing.assert_array_equal(\n+            np.array(knp.zeros([2, 3])), np.zeros([2, 3])\n+        )\n+        np.testing.assert_array_equal(\n+            np.array(knp.Zeros()([2, 3])), np.zeros([2, 3])\n+        )\n+\n+    def test_eye(self):\n+        np.testing.assert_array_equal(np.array(knp.eye(3)), np.eye(3))\n+        np.testing.assert_array_equal(np.array(knp.eye(3, 4)), np.eye(3, 4))\n+        np.testing.assert_array_equal(\n+            np.array(knp.eye(3, 4, 1)), np.eye(3, 4, 1)\n+        )\n+\n+        np.testing.assert_array_equal(np.array(knp.Eye()(3)), np.eye(3))\n+        np.testing.assert_array_equal(np.array(knp.Eye()(3, 4)), np.eye(3, 4))\n+        np.testing.assert_array_equal(\n+            np.array(knp.Eye()(3, 4, 1)), np.eye(3, 4, 1)\n+        )\n\n@@ -1,7 +1,7 @@\n+from keras_core import backend\n from keras_core.backend.keras_tensor import any_symbolic_tensors\n from keras_core.operations.node import Node\n from keras_core.utils.naming import auto_name\n-from keras_core import backend\n \n \n class Operation:\n\n@@ -1,9 +1,10 @@\n-from keras_core.operations import operation\n-from keras_core.engine import keras_tensor\n-from keras_core.operations import numpy as knp\n+import numpy as np\n+\n from keras_core import backend\n from keras_core import testing\n-import numpy as np\n+from keras_core.engine import keras_tensor\n+from keras_core.operations import numpy as knp\n+from keras_core.operations import operation\n \n \n class OpWithMultipleInputs(operation.Operation):\n\n@@ -8,7 +8,7 @@ truncated_normal\n dropout\n \"\"\"\n \n-from keras_core.backend.random import normal\n-from keras_core.backend.random import uniform\n-from keras_core.backend.random import truncated_normal\n from keras_core.backend.random import dropout\n+from keras_core.backend.random import normal\n+from keras_core.backend.random import truncated_normal\n+from keras_core.backend.random import uniform\n\n@@ -1,4 +1,5 @@\n from tensorflow import nest\n+\n from keras_core.backend import KerasTensor\n \n \n\n@@ -1,13 +1,14 @@\n-from keras_core import backend\n-from keras_core import operations as ops\n-from keras_core.utils.tracking import Tracker\n-from keras_core import initializers\n-from keras_core.optimizers.schedules import learning_rate_schedule\n-from keras_core.utils.naming import auto_name\n-from keras_core.api_export import keras_core_export\n import re\n import warnings\n \n+from keras_core import backend\n+from keras_core import initializers\n+from keras_core import operations as ops\n+from keras_core.api_export import keras_core_export\n+from keras_core.optimizers.schedules import learning_rate_schedule\n+from keras_core.utils.naming import auto_name\n+from keras_core.utils.tracking import Tracker\n+\n \n @keras_core_export([\"keras_core.Optimizer\", \"keras_core.optimizers.Optimizer\"])\n class Optimizer:\n\n@@ -1,5 +1,5 @@\n-from keras_core.optimizers import optimizer\n from keras_core import operations as ops\n+from keras_core.optimizers import optimizer\n \n \n class SGD(optimizer.Optimizer):\n\n@@ -1,5 +1,5 @@\n-from keras_core.regularizers.regularizers import Regularizer\n from keras_core.regularizers.regularizers import L1\n-from keras_core.regularizers.regularizers import L2\n from keras_core.regularizers.regularizers import L1L2\n+from keras_core.regularizers.regularizers import L2\n from keras_core.regularizers.regularizers import OrthogonalRegularizer\n+from keras_core.regularizers.regularizers import Regularizer\n\n@@ -1,4 +1,5 @@\n import math\n+\n from keras_core import operations as ops\n from keras_core.api_export import keras_core_export\n \n\n@@ -1,9 +1,10 @@\n-from keras_core import testing\n+import numpy as np\n+\n+from keras_core import backend\n from keras_core import initializers\n from keras_core import operations as ops\n-from keras_core import backend\n from keras_core import regularizers\n-import numpy as np\n+from keras_core import testing\n \n \n # TODO: serialization tests\n\n@@ -1,6 +1,7 @@\n-import numpy as np\n import unittest\n \n+import numpy as np\n+\n \n class TestCase(unittest.TestCase):\n     def assertAllClose(self, x1, x2, atol=1e-7, rtol=1e-7):\n\n@@ -1,8 +1,10 @@\n-from keras_core.api_export import keras_core_export\n-import threading\n import sys\n+import threading\n+\n from absl import logging\n \n+from keras_core.api_export import keras_core_export\n+\n INTERACTIVE_LOGGING = threading.local()\n INTERACTIVE_LOGGING.enable = True\n \n\n@@ -79,7 +79,8 @@ def print_summary(\n             matches `layer_range[1]`. By default (`None`) all\n             layers in the model are included in the summary.\n     \"\"\"\n-    from keras_core.models import Sequential, Functional\n+    from keras_core.models import Functional\n+    from keras_core.models import Sequential\n \n     if print_fn is None:\n         print_fn = io_utils.print_msg\n\n@@ -0,0 +1,42 @@\n+\"\"\"Setup script.\"\"\"\n+\n+import pathlib\n+\n+from setuptools import find_packages\n+from setuptools import setup\n+\n+HERE = pathlib.Path(__file__).parent\n+\n+setup(\n+    name=\"keras-core\",\n+    description=\"Multi-backend Keras.\",\n+    long_description_content_type=\"text/markdown\",\n+    version=\"0.1.0\",\n+    url=\"https://github.com/keras-team/keras-core\",\n+    author=\"Keras team\",\n+    author_email=\"keras@google.com\",\n+    license=\"Apache License 2.0\",\n+    install_requires=[\n+        \"absl-py\",\n+        \"numpy\",\n+        \"packaging\",\n+    ],\n+    # Supported Python versions\n+    python_requires=\">=3.8\",\n+    classifiers=[\n+        \"Development Status :: 3 - Alpha\",\n+        \"Programming Language :: Python :: 3\",\n+        \"Programming Language :: Python :: 3.8\",\n+        \"Programming Language :: Python :: 3.9\",\n+        \"Programming Language :: Python :: 3.10\",\n+        \"Programming Language :: Python :: 3.11\",\n+        \"Programming Language :: Python :: 3 :: Only\",\n+        \"Operating System :: Unix\",\n+        \"Operating System :: Microsoft :: Windows\",\n+        \"Operating System :: MacOS\",\n+        \"Intended Audience :: Science/Research\",\n+        \"Topic :: Scientific/Engineering\",\n+        \"Topic :: Software Development\",\n+    ],\n+    packages=find_packages(exclude=(\"*_test.py\",)),\n+)\n\n@@ -1,9 +1,9 @@\n from keras_core import backend\n-from keras_core.layers.layer import Layer\n-from keras_core.backend import KerasTensor\n-from keras_core.operations.function import Function\n from keras_core import initializers\n+from keras_core.backend import KerasTensor\n+from keras_core.layers.layer import Layer\n from keras_core.operations import numpy as knp\n+from keras_core.operations.function import Function\n \n \n class MiniDense(Layer):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
