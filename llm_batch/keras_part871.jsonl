{"custom_id": "keras#90d36dc0dfdafeb0dedb9dab1172b1af9a5a8178", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 144 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3,6 +3,7 @@ import itertools\n import numpy as np\n from absl.testing import parameterized\n \n+from keras.src import ops\n from keras.src import testing\n from keras.src.layers.preprocessing.image_preprocessing.bounding_boxes.converters import (  # noqa: E501\n     affine_transform,\n@@ -139,4 +140,5 @@ class ConvertersTest(testing.TestCase):\n             height=self.height,\n             width=self.width,\n         )\n+        transformed_boxes = ops.convert_to_numpy(transformed_boxes)\n         self.assertAllClose(self.boxes[\"xyxy\"], transformed_boxes)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#38a714c2229c3c1dd5d13435a1e43af2dce13bbc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 62 | Files Changed: 4 | Hunks: 7 | Methods Changed: 5 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 79 | Churn Cumulative: 2462 | Contributors (this commit): 10 | Commits (past 90d): 20 | Contributors (cumulative): 15 | DMM Complexity: 0.0\n\nDIFF:\n@@ -419,11 +419,11 @@ class BoundingBox:\n         shear_x = -shear_x\n         shear_y = -shear_y\n \n-        cx = center_x * (width - 1)\n-        cy = center_y * (height - 1)\n+        cx = ops.numpy.multiply(center_x, (width - 1))\n+        cy = ops.numpy.multiply(center_y, (height - 1))\n         rot = ops.numpy.multiply(angle, 1.0 / 180.0 * math.pi)\n-        tx = -translate_x * (width - 1)\n-        ty = -translate_y * (height - 1)\n+        tx = ops.numpy.multiply(-translate_x, (width - 1))\n+        ty = ops.numpy.multiply(-translate_y, (height - 1))\n         sx = ops.numpy.multiply(shear_x, 1.0 / 180.0 * math.pi)\n         sy = ops.numpy.multiply(shear_y, 1.0 / 180.0 * math.pi)\n \n@@ -442,10 +442,10 @@ class BoundingBox:\n \n         # Inverted rotation matrix with scale and shear\n         # det([[a, b], [c, d]]) == 1, since det(rotation) = 1 and det(shear) = 1\n-        a0 = d * scale\n-        a1 = -b * scale\n-        b0 = -c * scale\n-        b1 = a * scale\n+        a0 = ops.numpy.multiply(d, scale)\n+        a1 = ops.numpy.multiply(-b, scale)\n+        b0 = ops.numpy.multiply(-c, scale)\n+        b1 = ops.numpy.multiply(a, scale)\n         a2 = cx - a0 * cx_plus_tx - a1 * cy_plus_ty\n         b2 = cy - b0 * cx_plus_tx - b1 * cy_plus_ty\n \n\n@@ -45,7 +45,7 @@ class ConvertersTest(testing.TestCase):\n             [[[0.01, 0.02, 0.1, 0.1], [0.02, 0.03, 0.1, 0.1]]], dtype=\"float32\"\n         )\n \n-        self.images = np.ones([2, 1000, 1000, 3])\n+        self.images = np.ones([2, 1000, 1000, 3], dtype=\"float32\")\n         self.height = 1000\n         self.width = 1000\n \n@@ -131,12 +131,12 @@ class ConvertersTest(testing.TestCase):\n         batch_size = self.boxes[\"xyxy\"].shape[0]\n         transformed_boxes = affine_transform(\n             boxes=self.boxes[\"xyxy\"],\n-            angle=np.zeros([batch_size]),\n-            translate_x=np.zeros([batch_size]),\n-            translate_y=np.zeros([batch_size]),\n-            scale=np.ones([batch_size]),\n-            shear_x=np.zeros([batch_size]),\n-            shear_y=np.zeros([batch_size]),\n+            angle=np.zeros([batch_size], dtype=\"float32\"),\n+            translate_x=np.zeros([batch_size], dtype=\"float32\"),\n+            translate_y=np.zeros([batch_size], dtype=\"float32\"),\n+            scale=np.ones([batch_size], dtype=\"float32\"),\n+            shear_x=np.zeros([batch_size], dtype=\"float32\"),\n+            shear_y=np.zeros([batch_size], dtype=\"float32\"),\n             height=self.height,\n             width=self.width,\n         )\n\n@@ -17,6 +17,8 @@ class MixUpTest(testing.TestCase):\n             input_shape=(8, 3, 4, 3),\n             supports_masking=False,\n             expected_output_shape=(8, 3, 4, 3),\n+            # StatelessRandomGammaV3 is not supported on XLA_GPU_JIT\n+            run_training_check=not testing.tensorflow_uses_gpu(),\n         )\n \n     def test_mix_up_basic_functionality(self):\n\n@@ -2745,50 +2745,3 @@ class TestTrainer(testing.TestCase):\n             verbose=0,\n         )\n         self.assertLessEqual(tracing_count[0], 2)\n-\n-\n-class TrainerDistributeTest(testing.TestCase):\n-    @pytest.mark.skipif(\n-        backend.backend() != \"tensorflow\", reason=\"Requires tf.distribute\"\n-    )\n-    def test_end_to_end_tf_distribute(self):\n-        import tensorflow as tf\n-        from tensorflow.python.eager import context\n-\n-        context._reset_context()\n-        cpus = tf.config.list_physical_devices(\"CPU\")\n-        tf.config.set_logical_device_configuration(\n-            cpus[0],\n-            [\n-                tf.config.LogicalDeviceConfiguration(),\n-                tf.config.LogicalDeviceConfiguration(),\n-            ],\n-        )\n-        strategy = tf.distribute.MirroredStrategy([\"CPU:0\", \"CPU:1\"])\n-        with strategy.scope():\n-            model = keras.Sequential(\n-                [\n-                    keras.Input((2,)),\n-                    keras.layers.Dense(\n-                        2,\n-                        activation=\"softmax\",\n-                        use_bias=False,\n-                        kernel_initializer=\"ones\",\n-                    ),\n-                ]\n-            )\n-            model.compile(\n-                optimizer=\"sgd\",\n-                loss=\"sparse_categorical_crossentropy\",\n-                metrics=[\"sparse_categorical_accuracy\"],\n-            )\n-        x = (np.arange(512) / 128).reshape((256, 2))\n-        y = (np.arange(256) % 2).reshape((256, 1))\n-        out_fit = model.fit(x, y)\n-        self.assertLess(out_fit.history[\"sparse_categorical_accuracy\"][0], 0.6)\n-        out_eval = model.evaluate(x, y)\n-        self.assertLess(out_eval[1], 0.6)\n-        out_predict = model.predict(x)\n-        self.assertEqual(out_predict.shape, (256, 2))\n-\n-        context._reset_context()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#007f5e78b5968fe4a8f9313b7d992393b3e46a6b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 28 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -256,12 +256,12 @@ class SimpleRNN(RNN):\n             If `True`, process the input sequence backwards and return the\n             reversed sequence.\n         stateful: Boolean (default: `False`). If `True`, the last state\n-            for each sample at index i in a batch will be used as initial\n-            state for the sample of index i in the following batch.\n+            for each sample at index i in a batch will be used as the \n+            initial state for the sample of index i in the following batch.\n         unroll: Boolean (default: `False`).\n             If `True`, the network will be unrolled,\n             else a symbolic loop will be used.\n-            Unrolling can speed-up a RNN,\n+            Unrolling can speed-up an RNN,\n             although it tends to be more memory-intensive.\n             Unrolling is only suitable for short sequences.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#345ceccf8a53fe61123ad2c518eeac5ea34b37db", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 273 | Lines Deleted: 0 | Files Changed: 5 | Hunks: 5 | Methods Changed: 15 | Complexity Δ (Sum/Max): 33/25 | Churn Δ: 273 | Churn Cumulative: 1052 | Contributors (this commit): 6 | Commits (past 90d): 27 | Contributors (cumulative): 20 | DMM Complexity: 0.847457627118644\n\nDIFF:\n@@ -164,6 +164,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_crop import (\n from keras.src.layers.preprocessing.image_preprocessing.random_flip import (\n     RandomFlip,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_hue import (\n+    RandomHue,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_rotation import (\n     RandomRotation,\n )\n\n@@ -164,6 +164,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_crop import (\n from keras.src.layers.preprocessing.image_preprocessing.random_flip import (\n     RandomFlip,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_hue import (\n+    RandomHue,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_rotation import (\n     RandomRotation,\n )\n\n@@ -107,6 +107,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_crop import (\n from keras.src.layers.preprocessing.image_preprocessing.random_flip import (\n     RandomFlip,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_hue import (\n+    RandomHue,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_rotation import (\n     RandomRotation,\n )\n\n@@ -0,0 +1,198 @@\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n+    BaseImagePreprocessingLayer,\n+)\n+from keras.src.random import SeedGenerator\n+\n+\n+def transform_value_range(images, original_range, target_range):\n+    if (\n+        original_range[0] == target_range[0]\n+        and original_range[1] == target_range[1]\n+    ):\n+        return images\n+\n+    original_min_value, original_max_value = original_range\n+    target_min_value, target_max_value = target_range\n+\n+    # images in the [0, 1] scale\n+    images = (images - original_min_value) / (\n+        original_max_value - original_min_value\n+    )\n+\n+    scale_factor = target_max_value - target_min_value\n+    return (images * scale_factor) + target_min_value\n+\n+\n+@keras_export(\"keras.layers.RandomHue\")\n+class RandomHue(BaseImagePreprocessingLayer):\n+    \"\"\"Randomly adjusts the hue on given images.\n+\n+    This layer will randomly increase/reduce the hue for the input RGB\n+    images.\n+\n+    The image hue is adjusted by converting the image(s) to HSV and rotating the\n+    hue channel (H) by delta. The image is then converted back to RGB.\n+\n+    Args:\n+        factor: A single float or a tuple of two floats.\n+            `factor` controls the extent to which the\n+            image hue is impacted. `factor=0.0` makes this layer perform a\n+            no-op operation, while a value of `1.0` performs the most aggressive\n+            contrast adjustment available. If a tuple is used, a `factor` is\n+            sampled between the two values for every image augmented. If a\n+            single float is used, a value between `0.0` and the passed float is\n+            sampled. In order to ensure the value is always the same, please\n+            pass a tuple with two identical floats: `(0.5, 0.5)`.\n+        value_range: the range of values the incoming images will have.\n+            Represented as a two-number tuple written `[low, high]`. This is\n+            typically either `[0, 1]` or `[0, 255]` depending on how your\n+            preprocessing pipeline is set up.\n+        seed: Integer. Used to create a random seed.\n+\n+    ```python\n+    (images, labels), _ = keras.datasets.cifar10.load_data()\n+    random_hue = keras.layers.RandomHue(factor=0.5, value_range=[0, 1])\n+    augmented_images = random_hue(images)\n+    ```\n+    \"\"\"\n+\n+    def __init__(\n+        self, factor, value_range, data_format=None, seed=None, **kwargs\n+    ):\n+        super().__init__(data_format=data_format, **kwargs)\n+        self.factor = factor\n+        self.value_range = value_range\n+        self.seed = seed\n+        self.generator = SeedGenerator(seed)\n+\n+    def parse_factor(\n+        self, min_value=0.0, max_value=1.0, param_name=\"factor\", shape=None\n+    ):\n+        factors = self.factor\n+        if isinstance(factors, float) or isinstance(factors, int):\n+            factors = (min_value, factors)\n+\n+        if factors[0] > factors[1]:\n+            raise ValueError(\n+                f\"`{param_name}[0] > {param_name}[1]`, \"\n+                f\"`{param_name}[0]` must be \"\n+                f\"<= `{param_name}[1]`. Got `{param_name}={factors}`\"\n+            )\n+        if (min_value is not None and factors[0] < min_value) or (\n+            max_value is not None and factors[1] > max_value\n+        ):\n+            raise ValueError(\n+                f\"`{param_name}` should be inside of range \"\n+                f\"[{min_value}, {max_value}]. Got {param_name}={factors}\"\n+            )\n+\n+        if factors[0] == factors[1]:\n+            return self.backend.numpy.ones(shape=shape) * factors[0]\n+\n+        return self.backend.random.uniform(\n+            shape,\n+            seed=self.generator,\n+            minval=factors[0],\n+            maxval=factors[1],\n+        )\n+\n+    def get_random_transformation(self, data, training=True, seed=None):\n+        if isinstance(data, dict):\n+            images = data[\"images\"]\n+        else:\n+            images = data\n+        images_shape = self.backend.shape(images)\n+        rank = len(images_shape)\n+        if rank == 3:\n+            batch_size = 1\n+        elif rank == 4:\n+            batch_size = images_shape[0]\n+        else:\n+            raise ValueError(\n+                \"Expected the input image to be rank 3 or 4. Received \"\n+                f\"inputs.shape={images_shape}\"\n+            )\n+\n+        if seed is None:\n+            seed = self._get_seed_generator(self.backend._backend)\n+        invert = self.backend.random.uniform((1,), seed=seed)\n+\n+        invert = self.backend.numpy.where(\n+            invert > 0.5,\n+            -self.backend.numpy.ones_like(invert),\n+            self.backend.numpy.ones_like(invert),\n+        )\n+\n+        factor = self.parse_factor(shape=(batch_size,))\n+\n+        return {\"factor\": invert * factor * 0.5}\n+\n+    def transform_images(self, images, transformation=None, training=True):\n+        images = transform_value_range(images, self.value_range, (0, 1))\n+        adjust_factors = transformation[\"factor\"]\n+        adjust_factors = self.backend.cast(adjust_factors, images.dtype)\n+        adjust_factors = self.backend.numpy.expand_dims(adjust_factors, -1)\n+        adjust_factors = self.backend.numpy.expand_dims(adjust_factors, -1)\n+\n+        images = self.backend.image.rgb_to_hsv(\n+            images, data_format=self.data_format\n+        )\n+\n+        if self.data_format == \"channels_first\":\n+            h_channel = images[:, 0, :, :] + adjust_factors\n+            h_channel = self.backend.numpy.where(\n+                h_channel > 1.0, h_channel - 1.0, h_channel\n+            )\n+            h_channel = self.backend.numpy.where(\n+                h_channel < 0.0, h_channel + 1.0, h_channel\n+            )\n+            images = self.backend.numpy.stack(\n+                [h_channel, images[:, 1, :, :], images[:, 2, :, :]], axis=1\n+            )\n+        else:\n+            h_channel = images[..., 0] + adjust_factors\n+            h_channel = self.backend.numpy.where(\n+                h_channel > 1.0, h_channel - 1.0, h_channel\n+            )\n+            h_channel = self.backend.numpy.where(\n+                h_channel < 0.0, h_channel + 1.0, h_channel\n+            )\n+            images = self.backend.numpy.stack(\n+                [h_channel, images[..., 1], images[..., 2]], axis=-1\n+            )\n+        images = self.backend.image.hsv_to_rgb(\n+            images, data_format=self.data_format\n+        )\n+\n+        images = self.backend.numpy.clip(images, 0, 1)\n+        images = transform_value_range(images, (0, 1), self.value_range)\n+\n+        return images\n+\n+    def transform_labels(self, labels, transformation, training=True):\n+        return labels\n+\n+    def transform_segmentation_masks(\n+        self, segmentation_masks, transformation, training=True\n+    ):\n+        return segmentation_masks\n+\n+    def transform_bounding_boxes(\n+        self, bounding_boxes, transformation, training=True\n+    ):\n+        return bounding_boxes\n+\n+    def get_config(self):\n+        config = super().get_config()\n+        config.update(\n+            {\n+                \"factor\": self.factor,\n+                \"value_range\": self.value_range,\n+                \"seed\": self.seed,\n+            }\n+        )\n+        return config\n+\n+    def compute_output_shape(self, input_shape):\n+        return input_shape\n\n@@ -0,0 +1,66 @@\n+import numpy as np\n+import pytest\n+from tensorflow import data as tf_data\n+\n+import keras\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n+\n+\n+class RandomHueTest(testing.TestCase):\n+    @pytest.mark.requires_trainable_backend\n+    def test_layer(self):\n+        self.run_layer_test(\n+            layers.RandomHue,\n+            init_kwargs={\n+                \"factor\": 0.75,\n+                \"value_range\": (20, 200),\n+                \"seed\": 1,\n+            },\n+            input_shape=(8, 3, 4, 3),\n+            supports_masking=False,\n+            expected_output_shape=(8, 3, 4, 3),\n+        )\n+\n+    def test_random_hue_value_range(self):\n+        image = keras.random.uniform(shape=(3, 3, 3), minval=0, maxval=1)\n+\n+        layer = layers.RandomHue(0.2, (0, 255))\n+        adjusted_image = layer(image)\n+\n+        self.assertTrue(keras.ops.numpy.all(adjusted_image >= 0))\n+        self.assertTrue(keras.ops.numpy.all(adjusted_image <= 1))\n+\n+    def test_random_hue_no_change_with_zero_factor(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            inputs = keras.random.randint((224, 224, 3), 0, 255)\n+        else:\n+            inputs = keras.random.randint((3, 224, 224), 0, 255)\n+\n+        layer = layers.RandomHue(0, (0, 255), data_format=data_format)\n+        output = layer(inputs, training=False)\n+        self.assertAllClose(inputs, output, atol=1e-3, rtol=1e-5)\n+\n+    def test_random_hue_randomness(self):\n+        image = keras.random.uniform(shape=(3, 3, 3), minval=0, maxval=1)[:5]\n+\n+        layer = layers.RandomHue(0.2, (0, 255))\n+        adjusted_images = layer(image)\n+\n+        self.assertNotAllClose(adjusted_images, image)\n+\n+    def test_tf_data_compatibility(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            input_data = np.random.random((2, 8, 8, 3))\n+        else:\n+            input_data = np.random.random((2, 3, 8, 8))\n+        layer = layers.RandomHue(\n+            factor=0.5, value_range=[0, 1], data_format=data_format, seed=1337\n+        )\n+\n+        ds = tf_data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            output.numpy()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8465c3dc439c8c4506781d56cb3a388661e9f77f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 202 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -50,10 +50,12 @@ class RandomHue(BaseImagePreprocessingLayer):\n             preprocessing pipeline is set up.\n         seed: Integer. Used to create a random seed.\n \n+    Example:\n+\n     ```python\n     (images, labels), _ = keras.datasets.cifar10.load_data()\n     random_hue = keras.layers.RandomHue(factor=0.5, value_range=[0, 1])\n-    augmented_images = random_hue(images)\n+    augmented_images_batch = random_hue(images[:32])\n     ```\n     \"\"\"\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2d968380fc02676833ce778c79047c61c08e0f0f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 35 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): -9/0 | Churn Δ: 45 | Churn Cumulative: 247 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -59,46 +59,18 @@ class RandomHue(BaseImagePreprocessingLayer):\n     ```\n     \"\"\"\n \n+    _USE_BASE_FACTOR = True\n+    _FACTOR_BOUNDS = (0, 1)\n+\n     def __init__(\n         self, factor, value_range, data_format=None, seed=None, **kwargs\n     ):\n         super().__init__(data_format=data_format, **kwargs)\n-        self.factor = factor\n+        self._set_factor(factor)\n         self.value_range = value_range\n         self.seed = seed\n         self.generator = SeedGenerator(seed)\n \n-    def parse_factor(\n-        self, min_value=0.0, max_value=1.0, param_name=\"factor\", shape=None\n-    ):\n-        factors = self.factor\n-        if isinstance(factors, float) or isinstance(factors, int):\n-            factors = (min_value, factors)\n-\n-        if factors[0] > factors[1]:\n-            raise ValueError(\n-                f\"`{param_name}[0] > {param_name}[1]`, \"\n-                f\"`{param_name}[0]` must be \"\n-                f\"<= `{param_name}[1]`. Got `{param_name}={factors}`\"\n-            )\n-        if (min_value is not None and factors[0] < min_value) or (\n-            max_value is not None and factors[1] > max_value\n-        ):\n-            raise ValueError(\n-                f\"`{param_name}` should be inside of range \"\n-                f\"[{min_value}, {max_value}]. Got {param_name}={factors}\"\n-            )\n-\n-        if factors[0] == factors[1]:\n-            return self.backend.numpy.ones(shape=shape) * factors[0]\n-\n-        return self.backend.random.uniform(\n-            shape,\n-            seed=self.generator,\n-            minval=factors[0],\n-            maxval=factors[1],\n-        )\n-\n     def get_random_transformation(self, data, training=True, seed=None):\n         if isinstance(data, dict):\n             images = data[\"images\"]\n@@ -125,9 +97,12 @@ class RandomHue(BaseImagePreprocessingLayer):\n             -self.backend.numpy.ones_like(invert),\n             self.backend.numpy.ones_like(invert),\n         )\n-\n-        factor = self.parse_factor(shape=(batch_size,))\n-\n+        factor = self.backend.random.uniform(\n+            (batch_size,),\n+            minval=self.factor[0],\n+            maxval=self.factor[1],\n+            seed=seed,\n+        )\n         return {\"factor\": invert * factor * 0.5}\n \n     def transform_images(self, images, transformation=None, training=True):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a2374373fee646a9341946ccab53a9b078f57440", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 252 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -55,7 +55,8 @@ class RandomHue(BaseImagePreprocessingLayer):\n     ```python\n     (images, labels), _ = keras.datasets.cifar10.load_data()\n     random_hue = keras.layers.RandomHue(factor=0.5, value_range=[0, 1])\n-    augmented_images_batch = random_hue(images[:32])\n+    images = keras.ops.cast(images, \"float32\")\n+    augmented_images_batch = random_hue(images[:8])\n     ```\n     \"\"\"\n \n@@ -90,7 +91,7 @@ class RandomHue(BaseImagePreprocessingLayer):\n \n         if seed is None:\n             seed = self._get_seed_generator(self.backend._backend)\n-        invert = self.backend.random.uniform((1,), seed=seed)\n+        invert = self.backend.random.uniform((batch_size,), seed=seed)\n \n         invert = self.backend.numpy.where(\n             invert > 0.5,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4aa6a672065c5cfdbc2f810873f1ecc39783f4a4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 19 | Files Changed: 1 | Hunks: 10 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 34 | Churn Cumulative: 193 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -23,14 +23,10 @@ class MixUp(BaseImagePreprocessingLayer):\n     Example:\n     ```python\n     (images, labels), _ = keras.datasets.cifar10.load_data()\n-    images, labels = images[:10], labels[:10]\n-    # Labels must be floating-point and one-hot encoded\n-    labels = tf.cast(tf.one_hot(labels, 10), tf.float32)\n-    mixup = keras.layers.MixUp(alpha=0.2)\n-    augmented_images, updated_labels = mixup(\n-        {'images': images, 'labels': labels}\n-    )\n-    # output == {'images': updated_images, 'labels': updated_labels}\n+    images, labels = images[:8], labels[:8]\n+    labels = keras.ops.cast(keras.ops.one_hot(labels.flatten(), 10), \"float32\")\n+    mix_up = keras.layers.MixUp(alpha=0.2)\n+    output = mix_up({\"images\": images, \"labels\": labels})\n     ```\n     \"\"\"\n \n@@ -62,7 +58,7 @@ class MixUp(BaseImagePreprocessingLayer):\n         )\n \n         mix_weight = self.backend.random.beta(\n-            (1,), self.alpha, self.alpha, seed=seed\n+            (batch_size,), self.alpha, self.alpha, seed=seed\n         )\n         return {\n             \"mix_weight\": mix_weight,\n@@ -79,12 +75,12 @@ class MixUp(BaseImagePreprocessingLayer):\n             dtype=self.compute_dtype,\n         )\n \n-        mixup_images = self.backend.cast(\n+        mix_up_images = self.backend.cast(\n             self.backend.numpy.take(images, permutation_order, axis=0),\n             dtype=self.compute_dtype,\n         )\n \n-        images = mix_weight * images + (1.0 - mix_weight) * mixup_images\n+        images = mix_weight * images + (1.0 - mix_weight) * mix_up_images\n \n         return images\n \n@@ -92,13 +88,13 @@ class MixUp(BaseImagePreprocessingLayer):\n         mix_weight = transformation[\"mix_weight\"]\n         permutation_order = transformation[\"permutation_order\"]\n \n-        labels_for_mixup = self.backend.numpy.take(\n+        labels_for_mix_up = self.backend.numpy.take(\n             labels, permutation_order, axis=0\n         )\n \n         mix_weight = self.backend.numpy.reshape(mix_weight, [-1, 1])\n \n-        labels = mix_weight * labels + (1.0 - mix_weight) * labels_for_mixup\n+        labels = mix_weight * labels + (1.0 - mix_weight) * labels_for_mix_up\n \n         return labels\n \n@@ -110,11 +106,11 @@ class MixUp(BaseImagePreprocessingLayer):\n     ):\n         permutation_order = transformation[\"permutation_order\"]\n         boxes, classes = bounding_boxes[\"boxes\"], bounding_boxes[\"classes\"]\n-        boxes_for_mixup = self.backend.numpy.take(boxes, permutation_order)\n-        classes_for_mixup = self.backend.numpy.take(classes, permutation_order)\n-        boxes = self.backend.numpy.concat([boxes, boxes_for_mixup], axis=1)\n+        boxes_for_mix_up = self.backend.numpy.take(boxes, permutation_order)\n+        classes_for_mix_up = self.backend.numpy.take(classes, permutation_order)\n+        boxes = self.backend.numpy.concat([boxes, boxes_for_mix_up], axis=1)\n         classes = self.backend.numpy.concat(\n-            [classes, classes_for_mixup], axis=1\n+            [classes, classes_for_mix_up], axis=1\n         )\n         return {\"boxes\": boxes, \"classes\": classes}\n \n@@ -126,13 +122,13 @@ class MixUp(BaseImagePreprocessingLayer):\n \n         mix_weight = self.backend.numpy.reshape(mix_weight, [-1, 1, 1, 1])\n \n-        segmentation_masks_for_mixup = self.backend.numpy.take(\n+        segmentation_masks_for_mix_up = self.backend.numpy.take(\n             segmentation_masks, permutation_order\n         )\n \n         segmentation_masks = (\n             mix_weight * segmentation_masks\n-            + (1.0 - mix_weight) * segmentation_masks_for_mixup\n+            + (1.0 - mix_weight) * segmentation_masks_for_mix_up\n         )\n \n         return segmentation_masks\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5fc7b6abd9f3ad2571fb088dbc4bc8704ffb459d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 206 | Lines Deleted: 0 | Files Changed: 5 | Hunks: 5 | Methods Changed: 14 | Complexity Δ (Sum/Max): 26/14 | Churn Δ: 206 | Churn Cumulative: 995 | Contributors (this commit): 7 | Commits (past 90d): 31 | Contributors (cumulative): 21 | DMM Complexity: 0.8521739130434782\n\nDIFF:\n@@ -164,6 +164,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_crop import (\n from keras.src.layers.preprocessing.image_preprocessing.random_flip import (\n     RandomFlip,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_grayscale import (\n+    RandomGrayscale,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_hue import (\n     RandomHue,\n )\n\n@@ -164,6 +164,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_crop import (\n from keras.src.layers.preprocessing.image_preprocessing.random_flip import (\n     RandomFlip,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_grayscale import (\n+    RandomGrayscale,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_hue import (\n     RandomHue,\n )\n\n@@ -108,6 +108,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_crop import (\n from keras.src.layers.preprocessing.image_preprocessing.random_flip import (\n     RandomFlip,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_grayscale import (\n+    RandomGrayscale,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_hue import (\n     RandomHue,\n )\n\n@@ -0,0 +1,103 @@\n+from keras.src import backend\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n+    BaseImagePreprocessingLayer,\n+)\n+\n+\n+@keras_export(\"keras.layers.RandomGrayscale\")\n+class RandomGrayscale(BaseImagePreprocessingLayer):\n+    \"\"\"Preprocessing layer for random conversion of RGB images to grayscale.\n+\n+    This layer randomly converts input images to grayscale with a specified\n+    factor. When applied, it maintains the original number of channels\n+    but sets all channels to the same grayscale value. This can be useful\n+    for data augmentation and training models to be robust to color\n+    variations.\n+\n+    The conversion preserves the perceived luminance of the original color\n+    image using standard RGB to grayscale conversion coefficients. Images\n+    that are not selected for conversion remain unchanged.\n+\n+    **Note:** This layer is safe to use inside a `tf.data` pipeline\n+    (independently of which backend you're using).\n+\n+    Args:\n+        factor: Float between 0 and 1, specifying the factor of\n+            converting each image to grayscale. Defaults to 0.5. A value of\n+            1.0 means all images will be converted, while 0.0 means no images\n+            will be converted.\n+        data_format: String, one of `\"channels_last\"` (default) or\n+            `\"channels_first\"`. The ordering of the dimensions in the inputs.\n+            `\"channels_last\"` corresponds to inputs with shape\n+            `(batch, height, width, channels)` while `\"channels_first\"`\n+            corresponds to inputs with shape\n+            `(batch, channels, height, width)`.\n+\n+    Input shape:\n+        3D (unbatched) or 4D (batched) tensor with shape:\n+        `(..., height, width, channels)`, in `\"channels_last\"` format,\n+        or `(..., channels, height, width)`, in `\"channels_first\"` format.\n+\n+    Output shape:\n+        Same as input shape. The output maintains the same number of channels\n+        as the input, even for grayscale-converted images where all channels\n+        will have the same value.\n+    \"\"\"\n+\n+    def __init__(self, factor=0.5, data_format=None, **kwargs):\n+        super().__init__(**kwargs)\n+        if factor < 0 or factor > 1:\n+            raise ValueError(\n+                \"`factor` should be between 0 and 1. \"\n+                f\"Received: factor={factor}\"\n+            )\n+        self.factor = factor\n+        self.data_format = backend.standardize_data_format(data_format)\n+        self.random_generator = self.backend.random.SeedGenerator()\n+\n+    def get_random_transformation(self, images, training=True, seed=None):\n+        random_values = self.backend.random.uniform(\n+            shape=(self.backend.core.shape(images)[0],),\n+            minval=0,\n+            maxval=1,\n+            seed=self.random_generator,\n+        )\n+        should_apply = self.backend.numpy.expand_dims(\n+            random_values < self.factor, axis=[1, 2, 3]\n+        )\n+        return should_apply\n+\n+    def transform_images(self, images, transformations=None, **kwargs):\n+        should_apply = (\n+            transformations\n+            if transformations is not None\n+            else self.get_random_transformation(images)\n+        )\n+\n+        grayscale_images = self.backend.image.rgb_to_grayscale(\n+            images, data_format=self.data_format\n+        )\n+        return self.backend.numpy.where(should_apply, grayscale_images, images)\n+\n+    def compute_output_shape(self, input_shape):\n+        return input_shape\n+\n+    def compute_output_spec(self, inputs, **kwargs):\n+        return inputs\n+\n+    def transform_bounding_boxes(self, bounding_boxes, **kwargs):\n+        return bounding_boxes\n+\n+    def transform_labels(self, labels, transformations=None, **kwargs):\n+        return labels\n+\n+    def transform_segmentation_masks(\n+        self, segmentation_masks, transformations=None, **kwargs\n+    ):\n+        return segmentation_masks\n+\n+    def get_config(self):\n+        config = super().get_config()\n+        config.update({\"factor\": self.factor})\n+        return config\n\n@@ -0,0 +1,94 @@\n+import numpy as np\n+import pytest\n+from absl.testing import parameterized\n+from tensorflow import data as tf_data\n+\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import ops\n+from keras.src import testing\n+\n+\n+class RandomGrayscaleTest(testing.TestCase):\n+    @pytest.mark.requires_trainable_backend\n+    def test_layer(self):\n+        self.run_layer_test(\n+            layers.RandomGrayscale,\n+            init_kwargs={\n+                \"factor\": 0.5,\n+                \"data_format\": \"channels_last\",\n+            },\n+            input_shape=(1, 2, 2, 3),\n+            supports_masking=False,\n+            expected_output_shape=(1, 2, 2, 3),\n+        )\n+\n+        self.run_layer_test(\n+            layers.RandomGrayscale,\n+            init_kwargs={\n+                \"factor\": 0.5,\n+                \"data_format\": \"channels_first\",\n+            },\n+            input_shape=(1, 3, 2, 2),\n+            supports_masking=False,\n+            expected_output_shape=(1, 3, 2, 2),\n+        )\n+\n+    @parameterized.named_parameters(\n+        (\"channels_last\", \"channels_last\"), (\"channels_first\", \"channels_first\")\n+    )\n+    def test_grayscale_conversion(self, data_format):\n+        if data_format == \"channels_last\":\n+            xs = np.random.uniform(0, 255, size=(2, 4, 4, 3)).astype(np.float32)\n+            layer = layers.RandomGrayscale(factor=1.0, data_format=data_format)\n+            transformed = ops.convert_to_numpy(layer(xs))\n+            self.assertEqual(transformed.shape[-1], 3)\n+            for img in transformed:\n+                r, g, b = img[:, :, 0], img[:, :, 1], img[:, :, 2]\n+                self.assertTrue(np.allclose(r, g) and np.allclose(g, b))\n+        else:\n+            xs = np.random.uniform(0, 255, size=(2, 3, 4, 4)).astype(np.float32)\n+            layer = layers.RandomGrayscale(factor=1.0, data_format=data_format)\n+            transformed = ops.convert_to_numpy(layer(xs))\n+            self.assertEqual(transformed.shape[1], 3)\n+            for img in transformed:\n+                r, g, b = img[0], img[1], img[2]\n+                self.assertTrue(np.allclose(r, g) and np.allclose(g, b))\n+\n+    def test_invalid_factor(self):\n+        with self.assertRaises(ValueError):\n+            layers.RandomGrayscale(factor=-0.1)\n+\n+        with self.assertRaises(ValueError):\n+            layers.RandomGrayscale(factor=1.1)\n+\n+    def test_tf_data_compatibility(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            input_data = np.random.random((2, 8, 8, 3)) * 255\n+        else:\n+            input_data = np.random.random((2, 3, 8, 8)) * 255\n+\n+        layer = layers.RandomGrayscale(factor=0.5, data_format=data_format)\n+        ds = tf_data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+\n+        for output in ds.take(1):\n+            output_array = output.numpy()\n+            self.assertEqual(output_array.shape, input_data.shape)\n+\n+    def test_grayscale_with_single_color_image(self):\n+        test_cases = [\n+            (np.full((1, 4, 4, 3), 128, dtype=np.float32), \"channels_last\"),\n+            (np.full((1, 3, 4, 4), 128, dtype=np.float32), \"channels_first\"),\n+        ]\n+\n+        for xs, data_format in test_cases:\n+            layer = layers.RandomGrayscale(factor=1.0, data_format=data_format)\n+            transformed = ops.convert_to_numpy(layer(xs))\n+\n+            if data_format == \"channels_last\":\n+                unique_vals = np.unique(transformed[0, :, :, 0])\n+                self.assertEqual(len(unique_vals), 1)\n+            else:\n+                unique_vals = np.unique(transformed[0, 0, :, :])\n+                self.assertEqual(len(unique_vals), 1)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#60aa8d4a2ccd861e13152755b6610a0d579082d6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 107 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -57,11 +57,13 @@ class RandomGrayscale(BaseImagePreprocessingLayer):\n         self.random_generator = self.backend.random.SeedGenerator()\n \n     def get_random_transformation(self, images, training=True, seed=None):\n+        if seed is None:\n+            seed = self._get_seed_generator(self.backend._backend)\n         random_values = self.backend.random.uniform(\n             shape=(self.backend.core.shape(images)[0],),\n             minval=0,\n             maxval=1,\n-            seed=self.random_generator,\n+            seed=seed,\n         )\n         should_apply = self.backend.numpy.expand_dims(\n             random_values < self.factor, axis=[1, 2, 3]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d96f9102e79d5e4a0eca2e2eb138d991c95fd364", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 109 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -54,7 +54,7 @@ class RandomGrayscale(BaseImagePreprocessingLayer):\n             )\n         self.factor = factor\n         self.data_format = backend.standardize_data_format(data_format)\n-        self.random_generator = self.backend.random.SeedGenerator()\n+        self.generator = self.backend.random.SeedGenerator()\n \n     def get_random_transformation(self, images, training=True, seed=None):\n         if seed is None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4c05e0cd2dfd385fb9db204885ddf51635b9e9b7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 114 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -45,7 +45,7 @@ class RandomGrayscale(BaseImagePreprocessingLayer):\n         will have the same value.\n     \"\"\"\n \n-    def __init__(self, factor=0.5, data_format=None, **kwargs):\n+    def __init__(self, factor=0.5, data_format=None, seed=None, **kwargs):\n         super().__init__(**kwargs)\n         if factor < 0 or factor > 1:\n             raise ValueError(\n@@ -54,7 +54,8 @@ class RandomGrayscale(BaseImagePreprocessingLayer):\n             )\n         self.factor = factor\n         self.data_format = backend.standardize_data_format(data_format)\n-        self.generator = self.backend.random.SeedGenerator()\n+        self.seed = seed\n+        self.generator = self.backend.random.SeedGenerator(seed)\n \n     def get_random_transformation(self, images, training=True, seed=None):\n         if seed is None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d8afc055d0935f566a10a121527788324260012c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 24 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 29 | Churn Cumulative: 281 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2,26 +2,6 @@ from keras.src.api_export import keras_export\n from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n     BaseImagePreprocessingLayer,\n )\n-from keras.src.random import SeedGenerator\n-\n-\n-def transform_value_range(images, original_range, target_range):\n-    if (\n-        original_range[0] == target_range[0]\n-        and original_range[1] == target_range[1]\n-    ):\n-        return images\n-\n-    original_min_value, original_max_value = original_range\n-    target_min_value, target_max_value = target_range\n-\n-    # images in the [0, 1] scale\n-    images = (images - original_min_value) / (\n-        original_max_value - original_min_value\n-    )\n-\n-    scale_factor = target_max_value - target_min_value\n-    return (images * scale_factor) + target_min_value\n \n \n @keras_export(\"keras.layers.RandomHue\")\n@@ -70,7 +50,7 @@ class RandomHue(BaseImagePreprocessingLayer):\n         self._set_factor(factor)\n         self.value_range = value_range\n         self.seed = seed\n-        self.generator = SeedGenerator(seed)\n+        self.generator = self.backend.random.SeedGenerator(seed)\n \n     def get_random_transformation(self, data, training=True, seed=None):\n         if isinstance(data, dict):\n@@ -107,7 +87,8 @@ class RandomHue(BaseImagePreprocessingLayer):\n         return {\"factor\": invert * factor * 0.5}\n \n     def transform_images(self, images, transformation=None, training=True):\n-        images = transform_value_range(images, self.value_range, (0, 1))\n+        images = self.backend.cast(images, self.compute_dtype)\n+        images = self._transform_value_range(images, self.value_range, (0, 1))\n         adjust_factors = transformation[\"factor\"]\n         adjust_factors = self.backend.cast(adjust_factors, images.dtype)\n         adjust_factors = self.backend.numpy.expand_dims(adjust_factors, -1)\n@@ -144,8 +125,8 @@ class RandomHue(BaseImagePreprocessingLayer):\n         )\n \n         images = self.backend.numpy.clip(images, 0, 1)\n-        images = transform_value_range(images, (0, 1), self.value_range)\n-\n+        images = self._transform_value_range(images, (0, 1), self.value_range)\n+        images = self.backend.cast(images, self.compute_dtype)\n         return images\n \n     def transform_labels(self, labels, transformation, training=True):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2b6c8002f04c8a472c1b2c8ecf2df951d741ffeb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 183 | Lines Deleted: 13 | Files Changed: 5 | Hunks: 14 | Methods Changed: 10 | Complexity Δ (Sum/Max): 11/7 | Churn Δ: 196 | Churn Cumulative: 2479 | Contributors (this commit): 11 | Commits (past 90d): 25 | Contributors (cumulative): 25 | DMM Complexity: 0.6438356164383562\n\nDIFF:\n@@ -1,6 +1,7 @@\n import numpy as np\n \n from keras.src import backend\n+from keras.src import ops\n from keras.src import tree\n from keras.src.api_export import keras_export\n \n@@ -115,15 +116,20 @@ def check_data_cardinality(data):\n \n \n def class_weight_to_sample_weights(y, class_weight):\n-    sample_weight = np.ones(shape=(y.shape[0],), dtype=backend.floatx())\n-    if len(y.shape) > 1:\n-        if y.shape[-1] != 1:\n-            y = np.argmax(y, axis=-1)\n+    # Convert to numpy to ensure consistent handling of operations\n+    # (e.g., np.round()) across frameworks like TensorFlow, JAX, and PyTorch\n+\n+    y_numpy = ops.convert_to_numpy(y)\n+    sample_weight = np.ones(shape=(y_numpy.shape[0],), dtype=backend.floatx())\n+    if len(y_numpy.shape) > 1:\n+        if y_numpy.shape[-1] != 1:\n+            y_numpy = np.argmax(y_numpy, axis=-1)\n         else:\n-            y = np.squeeze(y, axis=-1)\n-    y = np.round(y).astype(\"int32\")\n-    for i in range(y.shape[0]):\n-        sample_weight[i] = class_weight.get(int(y[i]), 1.0)\n+            y_numpy = np.squeeze(y_numpy, axis=-1)\n+    y_numpy = np.round(y_numpy).astype(\"int32\")\n+\n+    for i in range(y_numpy.shape[0]):\n+        sample_weight[i] = class_weight.get(int(y_numpy[i]), 1.0)\n     return sample_weight\n \n \n\n@@ -0,0 +1,107 @@\n+import numpy as np\n+import pytest\n+from absl.testing import parameterized\n+\n+from keras.src import backend\n+from keras.src import testing\n+from keras.src.trainers.data_adapters.data_adapter_utils import (\n+    class_weight_to_sample_weights,\n+)\n+\n+\n+class TestClassWeightToSampleWeights(testing.TestCase):\n+    @parameterized.named_parameters(\n+        [\n+            # Simple case, where y is flat\n+            (\n+                \"simple_class_labels\",\n+                np.array([0, 1, 0, 2]),\n+                {0: 1.0, 1: 2.0, 2: 3.0},\n+                np.array([1.0, 2.0, 1.0, 3.0]),\n+            ),\n+            # Testing with one-hot encoded labels,\n+            # so basically the argmax statement\n+            (\n+                \"one_hot_encoded_labels\",\n+                np.array([[1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1]]),\n+                {0: 1.0, 1: 2.0, 2: 3.0},\n+                np.array([1.0, 2.0, 1.0, 3.0]),\n+            ),\n+            # 3 is not mapped, so it's assigned the default weight (1)\n+            (\n+                \"unmapped_class\",\n+                np.array([0, 3, 0, 2]),\n+                {0: 1.0, 1: 2.0, 2: 3.0},\n+                np.array([1.0, 1.0, 1.0, 3.0]),\n+            ),\n+            (\n+                \"multi_dimensional_input\",\n+                np.array([[0], [1], [0], [2]]),\n+                {0: 1.0, 1: 2.0, 2: 3.0},\n+                np.array([1.0, 2.0, 1.0, 3.0]),\n+            ),\n+            (\n+                \"all_unmapped\",\n+                np.array([0, 1, 0, 2]),\n+                {},\n+                np.array([1.0, 1.0, 1.0, 1.0]),\n+            ),\n+        ]\n+    )\n+    def test_class_weight_to_sample_weights(self, y, class_weight, expected):\n+        self.assertAllClose(\n+            class_weight_to_sample_weights(y, class_weight), expected\n+        )\n+\n+    @pytest.mark.skipif(backend.backend() != \"torch\", reason=\"torch only\")\n+    def test_class_weight_to_sample_weights_torch_specific(self):\n+        import torch\n+\n+        y = torch.from_numpy(np.array([0, 1, 0, 2]))\n+        self.assertAllClose(\n+            class_weight_to_sample_weights(y, {0: 1.0, 1: 2.0, 2: 3.0}),\n+            np.array([1.0, 2.0, 1.0, 3.0]),\n+        )\n+        y_one_hot = torch.from_numpy(\n+            np.array([[1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1]])\n+        )\n+        self.assertAllClose(\n+            class_weight_to_sample_weights(y_one_hot, {0: 1.0, 1: 2.0, 2: 3.0}),\n+            np.array([1.0, 2.0, 1.0, 3.0]),\n+        )\n+\n+    @pytest.mark.skipif(backend.backend() != \"jax\", reason=\"jax only\")\n+    def test_class_weight_to_sample_weights_jax_specific(self):\n+        import jax\n+\n+        y = jax.numpy.asarray(np.array([0, 1, 0, 2]))\n+        self.assertAllClose(\n+            class_weight_to_sample_weights(y, {0: 1.0, 1: 2.0, 2: 3.0}),\n+            np.array([1.0, 2.0, 1.0, 3.0]),\n+        )\n+        y_one_hot = jax.numpy.asarray(\n+            np.array([[1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1]])\n+        )\n+        self.assertAllClose(\n+            class_weight_to_sample_weights(y_one_hot, {0: 1.0, 1: 2.0, 2: 3.0}),\n+            np.array([1.0, 2.0, 1.0, 3.0]),\n+        )\n+\n+    @pytest.mark.skipif(\n+        backend.backend() != \"tensorflow\", reason=\"tensorflow only\"\n+    )\n+    def test_class_weight_to_sample_weights_tf_specific(self):\n+        import tensorflow as tf\n+\n+        y = tf.convert_to_tensor(np.array([0, 1, 0, 2]))\n+        self.assertAllClose(\n+            class_weight_to_sample_weights(y, {0: 1.0, 1: 2.0, 2: 3.0}),\n+            np.array([1.0, 2.0, 1.0, 3.0]),\n+        )\n+        y_one_hot = tf.convert_to_tensor(\n+            np.array([[1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1]])\n+        )\n+        self.assertAllClose(\n+            class_weight_to_sample_weights(y_one_hot, {0: 1.0, 1: 2.0, 2: 3.0}),\n+            np.array([1.0, 2.0, 1.0, 3.0]),\n+        )\n\n@@ -236,7 +236,7 @@ class PyDatasetAdapter(DataAdapter):\n \n     def _infinite_generator(self):\n         for i in itertools.count():\n-            yield self.py_dataset[i]\n+            yield self._standardize_batch(self.py_dataset[i])\n \n     def _finite_generator(self):\n         indices = range(self.py_dataset.num_batches)\n@@ -245,18 +245,18 @@ class PyDatasetAdapter(DataAdapter):\n             random.shuffle(indices)\n \n         for i in indices:\n-            yield self.py_dataset[i]\n+            yield self._standardize_batch(self.py_dataset[i])\n \n     def _infinite_enqueuer_generator(self):\n         self.enqueuer.start()\n         for batch in self.enqueuer.get():\n-            yield batch\n+            yield self._standardize_batch(batch)\n \n     def _finite_enqueuer_generator(self):\n         self.enqueuer.start()\n         num_batches = self.py_dataset.num_batches\n         for i, batch in enumerate(self.enqueuer.get()):\n-            yield batch\n+            yield self._standardize_batch(batch)\n             if i >= num_batches - 1:\n                 self.enqueuer.stop()\n                 return\n\n@@ -217,10 +217,41 @@ class PyDatasetAdapterTest(testing.TestCase):\n         else:\n             self.assertAllClose(sample_order, expected_order)\n \n-    # TODO: test class_weight\n     # TODO: test sample weights\n     # TODO: test inference mode (single output)\n \n+    def test_class_weight(self):\n+        x = np.random.randint(1, 100, (4, 5))\n+        y = np.array([0, 1, 2, 1])\n+        class_w = {0: 2, 1: 1, 2: 3}\n+        py_dataset = ExamplePyDataset(x, y, batch_size=2)\n+        adapter = py_dataset_adapter.PyDatasetAdapter(\n+            py_dataset, shuffle=False, class_weight=class_w\n+        )\n+        if backend.backend() == \"numpy\":\n+            gen = adapter.get_numpy_iterator()\n+        elif backend.backend() == \"tensorflow\":\n+            gen = adapter.get_tf_dataset()\n+        elif backend.backend() == \"jax\":\n+            gen = adapter.get_jax_iterator()\n+        elif backend.backend() == \"torch\":\n+            gen = adapter.get_torch_dataloader()\n+\n+        for index, batch in enumerate(gen):\n+            # Batch is a tuple of (x, y, class_weight)\n+            self.assertLen(batch, 3)\n+            # Let's verify the data and class weights match for each element\n+            # of the batch (2 elements in each batch)\n+            for sub_elem in range(2):\n+                self.assertTrue(\n+                    np.array_equal(batch[0][sub_elem], x[index * 2 + sub_elem])\n+                )\n+                self.assertEqual(batch[1][sub_elem], y[index * 2 + sub_elem])\n+                class_key = np.int32(batch[1][sub_elem])\n+                self.assertEqual(batch[2][sub_elem], class_w[class_key])\n+\n+        self.assertEqual(index, 1)  # 2 batches\n+\n     def test_speedup(self):\n         x = np.random.random((40, 4))\n         y = np.random.random((40, 2))\n\n@@ -522,17 +522,37 @@ class TestTrainer(testing.TestCase):\n                 \"testcase_name\": \"py_dataset\",\n                 \"dataset_type\": \"py_dataset\",\n             },\n+            {\n+                \"testcase_name\": \"py_dataset_cw\",\n+                \"dataset_type\": \"py_dataset\",\n+                \"fit_kwargs\": {\"class_weight\": {0: 1, 1: 2}},\n+            },\n             {\n                 \"testcase_name\": \"py_dataset_infinite\",\n                 \"dataset_type\": \"py_dataset\",\n                 \"dataset_kwargs\": {\"infinite\": True},\n                 \"fit_kwargs\": {\"steps_per_epoch\": 20},\n             },\n+            {\n+                \"testcase_name\": \"py_dataset_infinite_cw\",\n+                \"dataset_type\": \"py_dataset\",\n+                \"dataset_kwargs\": {\"infinite\": True},\n+                \"fit_kwargs\": {\n+                    \"steps_per_epoch\": 20,\n+                    \"class_weight\": {0: 1, 1: 2},\n+                },\n+            },\n             {\n                 \"testcase_name\": \"py_dataset_multithreading\",\n                 \"dataset_type\": \"py_dataset\",\n                 \"dataset_kwargs\": {\"workers\": 2},\n             },\n+            {\n+                \"testcase_name\": \"py_dataset_multithreading_cw\",\n+                \"dataset_type\": \"py_dataset\",\n+                \"dataset_kwargs\": {\"workers\": 2},\n+                \"fit_kwargs\": {\"class_weight\": {0: 1, 1: 2}},\n+            },\n             {\n                 \"testcase_name\": \"py_dataset_multithreading_infinite\",\n                 \"dataset_type\": \"py_dataset\",\n@@ -544,6 +564,12 @@ class TestTrainer(testing.TestCase):\n                 \"dataset_type\": \"py_dataset\",\n                 \"dataset_kwargs\": {\"workers\": 2, \"use_multiprocessing\": True},\n             },\n+            {\n+                \"testcase_name\": \"py_dataset_multiprocessing_cw\",\n+                \"dataset_type\": \"py_dataset\",\n+                \"dataset_kwargs\": {\"workers\": 2, \"use_multiprocessing\": True},\n+                \"fit_kwargs\": {\"class_weight\": {0: 1, 1: 2}},\n+            },\n             {\n                 \"testcase_name\": \"py_dataset_multiprocessing_infinite\",\n                 \"dataset_type\": \"py_dataset\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
