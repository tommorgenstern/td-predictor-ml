{"custom_id": "keras#070e0cdde57a7fd1f98151ed08dfd4015c0b1572", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 51 | Lines Deleted: 16 | Files Changed: 2 | Hunks: 7 | Methods Changed: 8 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 67 | Churn Cumulative: 6916 | Contributors (this commit): 9 | Commits (past 90d): 43 | Contributors (cumulative): 17 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1708,7 +1708,7 @@ class RandomHeight(base_layer.BaseRandomLayer):\n @keras_export('keras.layers.RandomWidth',\n               'keras.layers.experimental.preprocessing.RandomWidth',\n               v1=[])\n-class RandomWidth(base_layer.BaseRandomLayer):\n+class RandomWidth(BaseImageAugmentationLayer):\n   \"\"\"A preprocessing layer which randomly varies image width during training.\n \n   This layer will randomly adjusts the width of a batch of images of a\n@@ -1768,19 +1768,23 @@ class RandomWidth(base_layer.BaseRandomLayer):\n     self.interpolation = interpolation\n     self._interpolation_method = image_utils.get_interpolation(interpolation)\n     self.seed = seed\n+    self.auto_vectorize = False\n \n-  def call(self, inputs, training=True):\n-    inputs = utils.ensure_tensor(inputs)\n-    def random_width_inputs(inputs):\n-      \"\"\"Inputs width-adjusted with random ops.\"\"\"\n+  def _batch_augment(self, inputs):\n+    images = self.augment_image(inputs['images'])\n+    result = {'images': images}\n+    # to-do augment bbox to clip bbox to resized width value\n+    return result\n+\n+  def augment_image(self, image, transformation=None):\n+    if transformation is None:\n+      transformation = self.get_random_transformation(image)\n+    # The batch dimension of the input=image is not modified. The output would\n+    # be accurate for both unbatched and batched input\n+    inputs = utils.ensure_tensor(image)\n     inputs_shape = tf.shape(inputs)\n     img_hd = inputs_shape[H_AXIS]\n-      img_wd = tf.cast(inputs_shape[W_AXIS], tf.float32)\n-      width_factor = self._random_generator.random_uniform(\n-          shape=[],\n-          minval=(1.0 + self.width_lower),\n-          maxval=(1.0 + self.width_upper))\n-      adjusted_width = tf.cast(width_factor * img_wd, tf.int32)\n+    adjusted_width = transformation['width']\n     adjusted_size = tf.stack([img_hd, adjusted_width])\n     output = tf.image.resize(\n         images=inputs, size=adjusted_size, method=self._interpolation_method)\n@@ -1791,10 +1795,18 @@ class RandomWidth(base_layer.BaseRandomLayer):\n     output.set_shape(output_shape)\n     return output\n \n-    if training:\n-      return random_width_inputs(inputs)\n-    else:\n-      return inputs\n+  def get_random_transformation(self,\n+                                image=None,\n+                                label=None,\n+                                bounding_box=None):\n+    inputs_shape = tf.shape(image)\n+    img_wd = tf.cast(inputs_shape[W_AXIS], tf.float32)\n+    width_factor = self._random_generator.random_uniform(\n+        shape=[],\n+        minval=(1.0 + self.width_lower),\n+        maxval=(1.0 + self.width_upper))\n+    adjusted_width = tf.cast(width_factor * img_wd, tf.int32)\n+    return {'width': adjusted_width}\n \n   def compute_output_shape(self, input_shape):\n     input_shape = tf.TensorShape(input_shape).as_list()\n@@ -1809,4 +1821,3 @@ class RandomWidth(base_layer.BaseRandomLayer):\n     }\n     base_config = super(RandomWidth, self).get_config()\n     return dict(list(base_config.items()) + list(config.items()))\n-\n\n@@ -1859,6 +1859,30 @@ class RandomWidthTest(test_combinations.TestCase):\n         img_out = layer(img, training=True)\n         self.assertEqual(img_out.shape[1], 3)\n \n+  @test_utils.run_v2_only\n+  def test_batched_input(self):\n+    # need (maxval - minval) * rnd + minval = 0.6\n+    mock_factor = 0.6\n+    with test_utils.use_gpu():\n+      img = np.random.random((12, 8, 5, 3))\n+      layer = image_preprocessing.RandomWidth(.4)\n+      with tf.compat.v1.test.mock.patch.object(\n+          layer._random_generator, 'random_uniform', return_value=mock_factor):\n+        img_out = layer(img, training=True)\n+        self.assertEqual(img_out.shape[2], 3)\n+\n+  @test_utils.run_v2_only\n+  def test_augment_image(self):\n+    # need (maxval - minval) * rnd + minval = 0.6\n+    mock_factor = 0.6\n+    with test_utils.use_gpu():\n+      img = np.random.random((8, 5, 3))\n+      layer = image_preprocessing.RandomWidth(.4)\n+      with tf.compat.v1.test.mock.patch.object(\n+          layer._random_generator, 'random_uniform', return_value=mock_factor):\n+        img_out = layer.augment_image(img, transformation=None)\n+        self.assertEqual(img_out.shape[1], 3)\n+\n   @test_utils.run_v2_only\n   def test_output_dtypes(self):\n     inputs = np.array([[[1], [2]], [[3], [4]]], dtype='float64')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b6087bf947d3a78a2cc8b41f9827a628dfb3ef79", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 49 | Lines Deleted: 16 | Files Changed: 2 | Hunks: 8 | Methods Changed: 7 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 65 | Churn Cumulative: 6981 | Contributors (this commit): 9 | Commits (past 90d): 45 | Contributors (cumulative): 17 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1598,7 +1598,7 @@ class RandomBrightness(BaseImageAugmentationLayer):\n @keras_export('keras.layers.RandomHeight',\n               'keras.layers.experimental.preprocessing.RandomHeight',\n               v1=[])\n-class RandomHeight(base_layer.BaseRandomLayer):\n+class RandomHeight(BaseImageAugmentationLayer):\n   \"\"\"A preprocessing layer which randomly varies image height during training.\n \n   This layer adjusts the height of a batch of images by a random factor.\n@@ -1662,34 +1662,43 @@ class RandomHeight(base_layer.BaseRandomLayer):\n     self._interpolation_method = image_utils.get_interpolation(interpolation)\n     self.seed = seed\n \n-  def call(self, inputs, training=True):\n-    inputs = utils.ensure_tensor(inputs)\n-\n-    def random_height_inputs(inputs):\n-      \"\"\"Inputs height-adjusted with random ops.\"\"\"\n-      inputs_shape = tf.shape(inputs)\n-      img_hd = tf.cast(inputs_shape[H_AXIS], tf.float32)\n-      img_wd = inputs_shape[W_AXIS]\n+  def get_random_transformation(self,\n+                                image=None,\n+                                label=None,\n+                                bounding_box=None):\n     height_factor = self._random_generator.random_uniform(\n         shape=[],\n         minval=(1.0 + self.height_lower),\n         maxval=(1.0 + self.height_upper))\n+    inputs_shape = tf.shape(image)\n+    img_hd = tf.cast(inputs_shape[H_AXIS], tf.float32)\n     adjusted_height = tf.cast(height_factor * img_hd, tf.int32)\n+    return {'height': adjusted_height}\n+\n+  def _batch_augment(self, inputs):\n+    images = self.augment_image(inputs['images'], transformation=None)\n+    result = {'images': images}\n+    # to-do augment bbox to clip bbox to resized height value\n+    return result\n+\n+  def augment_image(self, image, transformation=None):\n+    if transformation is None:\n+      transformation = self.get_random_transformation(image)\n+    # The batch dimension of the input=image is not modified. The output would\n+    # be accurate for both unbatched and batched input\n+    inputs_shape = tf.shape(image)\n+    img_wd = inputs_shape[W_AXIS]\n+    adjusted_height = transformation['height']\n     adjusted_size = tf.stack([adjusted_height, img_wd])\n     output = tf.image.resize(\n-          images=inputs, size=adjusted_size, method=self._interpolation_method)\n+        images=image, size=adjusted_size, method=self._interpolation_method)\n     # tf.resize will output float32 in many cases regardless of input type.\n     output = tf.cast(output, self.compute_dtype)\n-      output_shape = inputs.shape.as_list()\n+    output_shape = list(image.shape)\n     output_shape[H_AXIS] = None\n     output.set_shape(output_shape)\n     return output\n \n-    if training:\n-      return random_height_inputs(inputs)\n-    else:\n-      return inputs\n-\n   def compute_output_shape(self, input_shape):\n     input_shape = tf.TensorShape(input_shape).as_list()\n     input_shape[H_AXIS] = None\n\n@@ -1751,6 +1751,30 @@ class RandomHeightTest(test_combinations.TestCase):\n         img_out = layer(img, training=True)\n         self.assertEqual(img_out.shape[0], 3)\n \n+  @test_utils.run_v2_only\n+  def test_batched_input(self):\n+    # need (maxval - minval) * rnd + minval = 0.6\n+    mock_factor = 0.6\n+    with test_utils.use_gpu():\n+      images = np.random.random((5, 5, 8, 3))\n+      layer = image_preprocessing.RandomHeight(.4)\n+      with tf.compat.v1.test.mock.patch.object(\n+          layer._random_generator, 'random_uniform', return_value=mock_factor):\n+        img_out = layer(images, training=True)\n+        self.assertEqual(img_out.shape[1], 3)\n+\n+  @test_utils.run_v2_only\n+  def test_augment_image(self):\n+    # need (maxval - minval) * rnd + minval = 0.6\n+    mock_factor = 0.6\n+    with test_utils.use_gpu():\n+      img = np.random.random((5, 8, 3))\n+      layer = image_preprocessing.RandomHeight(.4)\n+      with tf.compat.v1.test.mock.patch.object(\n+          layer._random_generator, 'random_uniform', return_value=mock_factor):\n+        img_out = layer.augment_image(img, transformation=None)\n+        self.assertEqual(img_out.shape[0], 3)\n+\n   @test_utils.run_v2_only\n   def test_output_dtypes(self):\n     inputs = np.array([[[1], [2]], [[3], [4]]], dtype='float64')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c3a27a6642c03c6380aca22c6e3d73d0b29bb271", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 13 | Files Changed: 3 | Hunks: 11 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 39 | Churn Cumulative: 2566 | Contributors (this commit): 15 | Commits (past 90d): 39 | Contributors (cumulative): 18 | DMM Complexity: 0.0\n\nDIFF:\n@@ -16,6 +16,7 @@\n # pylint: disable=g-bad-import-order\n \n from keras.utils.data_utils import get_file\n+from keras.utils.dataset_utils import split_dataset\n from keras.utils.generic_utils import Progbar\n from keras.utils.image_dataset import image_dataset_from_directory\n from keras.utils.text_dataset import text_dataset_from_directory\n\n@@ -21,12 +21,10 @@ import multiprocessing\n import os\n import time\n import warnings\n-from random import Random\n+import random\n \n import numpy as np\n-from tensorflow.python.util.tf_export import keras_export\n \n-@keras_export('keras.utils.split_dataset')\n def split_dataset(dataset,\n                   left_size=None,\n                   right_size=None,\n@@ -66,11 +64,11 @@ def split_dataset(dataset,\n \n   dataset_as_list = _convert_dataset_to_list(dataset,dataset_type_spec)\n \n-  if seed is None:\n-    seed = np.random.randint(1e6)\n-\n   if shuffle:\n-    Random(seed).shuffle(dataset_as_list)\n+    if seed is None:\n+      seed = random.randint(0,1e6)\n+    random.seed(seed)\n+    random.shuffle(dataset_as_list)\n \n   total_length = len(dataset_as_list)\n \n@@ -271,14 +269,14 @@ def _restore_dataset_from_list(dataset_as_list,dataset_type_spec,\n   if dataset_type_spec  in [tuple,list]:\n     return tuple(np.array(sample) for sample in zip(*dataset_as_list))\n   elif dataset_type_spec == tf.data.Dataset:\n-    if type(original_dataset.element_spec) is dict:\n-      restored_dataset = dict()\n+    if isinstance(original_dataset.element_spec,dict):\n+      restored_dataset = {}\n       for d in dataset_as_list:\n         for k, v in d.items():\n           if k not in restored_dataset:\n-            restored_dataset[k] = [np.array(v)]\n+            restored_dataset[k] = [v]\n           else:\n-            restored_dataset[k].append(np.array(v))\n+            restored_dataset[k].append(v)\n       return restored_dataset\n     else:\n       return tuple(np.array(sample) for sample in zip(*dataset_as_list))\n@@ -616,8 +614,8 @@ def check_validation_split_arg(validation_split, subset, shuffle, seed):\n   Args:\n     validation_split: float between 0 and 1, fraction of data to reserve for\n       validation.\n-    subset: One of \"training\", \"validation\" or \"both\". Only used if `validation_split`\n-      is set.\n+    subset: One of \"training\", \"validation\" or \"both\". Only used if \n+      `validation_split` is set.\n     shuffle: Whether to shuffle the data. Either True or False.\n     seed: random seed for shuffling and transformations.\n   \"\"\"\n\n@@ -248,6 +248,20 @@ class SplitDatasetTest(tf.test.TestCase):\n       else:\n         self.assertEqual(list(right_split)[i-3],list(dataset)[i])\n         \n+    # test with dict of text arrays\n+    dict_samples = {'txt_feature':['abb','bb','cc','d','e','f','g','h','i','j'],\n+                    'label':[1,2,3,4,5,6,7,8,9,10]}\n+    dataset = tf.data.Dataset.from_tensor_slices(dict_samples)\n+    left_split,right_split=dataset_utils.split_dataset(dataset,left_size=0.45,\n+                                                       right_size=0.55)\n+    self.assertEqual(len(list(left_split)),4)\n+    self.assertEqual(len(list(right_split)),6)\n+    for i in range(10):\n+      if i < 4:\n+        self.assertEqual(list(left_split)[i],list(dataset)[i])\n+      else:\n+        self.assertEqual(list(right_split)[i-4],list(dataset)[i])\n+\n   def test_list_dataset(self):\n     dataset = [np.ones(shape=(10,10,10)) for _ in range(10)]\n     left_split,right_split = dataset_utils.split_dataset(dataset,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4960f1eea7f4f9fdf05bca10bb03cc3e487ef2bc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 37 | Lines Deleted: 24 | Files Changed: 2 | Hunks: 23 | Methods Changed: 12 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 61 | Churn Cumulative: 2491 | Contributors (this commit): 3 | Commits (past 90d): 35 | Contributors (cumulative): 4 | DMM Complexity: 0.5384615384615384\n\nDIFF:\n@@ -66,7 +66,7 @@ def split_dataset(dataset,\n \n   if shuffle:\n     if seed is None:\n-      seed = random.randint(0,1e6)\n+      seed = random.randint(0, int(1e6))\n     random.seed(seed)\n     random.shuffle(dataset_as_list)\n \n@@ -77,7 +77,9 @@ def split_dataset(dataset,\n   left_split = list(dataset_as_list[:left_size])\n   right_split = list(dataset_as_list[-right_size:])\n \n-  left_split = _restore_dataset_from_list(left_split,dataset_type_spec,dataset)\n+  left_split = _restore_dataset_from_list(left_split,\n+                                          dataset_type_spec,\n+                                          dataset)\n   right_split = _restore_dataset_from_list(right_split, dataset_type_spec,\n                                            dataset)\n \n@@ -263,7 +265,8 @@ def _get_next_sample(dataset_iterator,\n           data_size_warning_flag = False\n     yield sample\n \n-def _restore_dataset_from_list(dataset_as_list,dataset_type_spec,\n+def _restore_dataset_from_list(dataset_as_list,\n+                               dataset_type_spec,\n                                original_dataset):\n   \"\"\"Restore the dataset from the list of arrays.\"\"\"\n   if dataset_type_spec  in [tuple, list]:\n@@ -378,15 +381,15 @@ def _rescale_dataset_split_sizes(left_size,right_size,total_length):\n \n def _get_type_spec(dataset):\n   \"\"\"Get the type spec of the dataset.\"\"\"\n-  if isinstance(dataset,(tuple)):\n+  if isinstance(dataset, tuple):\n     return tuple\n-  elif isinstance(dataset,(list)):\n+  elif isinstance(dataset, list):\n     return list\n-  elif isinstance(dataset,(np.ndarray)):\n+  elif isinstance(dataset, np.ndarray):\n     return np.ndarray\n   elif isinstance(dataset, dict):\n     return dict\n-  elif isinstance(dataset,(tf.data.Dataset)):\n+  elif isinstance(dataset, tf.data.Dataset):\n     return tf.data.Dataset\n   else:\n     return None\n\n@@ -40,7 +40,8 @@ class SplitDatasetTest(tf.test.TestCase):\n \n     # test with different shapes\n     dataset = [np.ones(shape=(5, 3)), np.ones(shape=(5, ))]\n-    left_split,right_split = dataset_utils.split_dataset(dataset,left_size=0.3)\n+    left_split, right_split = dataset_utils.split_dataset(dataset,\n+                                                          left_size=0.3)\n \n     self.assertEqual(np.array(list(left_split)).shape, (2, 2))\n     self.assertEqual(np.array(list(right_split)).shape, (3, 2))\n@@ -115,7 +116,8 @@ class SplitDatasetTest(tf.test.TestCase):\n     self.assertEqual(np.array(list(right_split)[0][1]).shape, ())\n \n   def test_batched_tf_dataset_of_vectors(self):\n-    dataset = tf.data.Dataset.from_tensor_slices(np.ones(shape=(100,32, 32,1)))\n+    vectors = np.ones(shape=(100, 32, 32, 1))\n+    dataset = tf.data.Dataset.from_tensor_slices(vectors)\n     dataset = dataset.batch(10)\n     left_split, right_split = dataset_utils.split_dataset(dataset, left_size=2)\n \n@@ -129,8 +131,8 @@ class SplitDatasetTest(tf.test.TestCase):\n     self.assertAllEqual(list(dataset), list(left_split)+list(right_split))\n \n   def test_batched_tf_dataset_of_tuple_of_vectors(self):\n-    dataset = tf.data.Dataset.from_tensor_slices((np.random.rand(10,32,32),\n-                                                  np.random.rand(10,32,32)))\n+    tuple_of_vectors = (np.random.rand(10, 32, 32), np.random.rand(10, 32, 32))\n+    dataset = tf.data.Dataset.from_tensor_slices(tuple_of_vectors)\n     dataset = dataset.batch(2)\n     left_split, right_split = dataset_utils.split_dataset(dataset, left_size=4)\n \n@@ -169,7 +171,8 @@ class SplitDatasetTest(tf.test.TestCase):\n                     'labels': np.random.rand(10,)}\n     dataset = tf.data.Dataset.from_tensor_slices(dict_samples)\n     dataset = dataset.batch(1)\n-    left_split,right_split=dataset_utils.split_dataset(dataset,right_size=0.3)\n+    left_split, right_split = dataset_utils.split_dataset(dataset,\n+                                                          right_size=0.3)\n \n     self.assertAllEqual(np.array(list(left_split)).shape, (7,))\n     self.assertAllEqual(np.array(list(right_split)).shape, (3,))\n@@ -185,9 +188,11 @@ class SplitDatasetTest(tf.test.TestCase):\n         self.assertEqual(list(right_split)[i-7], list(dataset)[i])\n \n   def test_unbatched_tf_dataset_of_vectors(self):\n-    dataset = tf.data.Dataset.from_tensor_slices(np.ones(shape=(100,16, 16,3)))\n+    vectors = np.ones(shape=(100, 16, 16, 3))\n+    dataset = tf.data.Dataset.from_tensor_slices(vectors)\n \n-    left_split,right_split=dataset_utils.split_dataset(dataset,left_size=0.25)\n+    left_split, right_split = dataset_utils.split_dataset(dataset,\n+                                                          left_size=0.25)\n \n     self.assertAllEqual(np.array(list(left_split)).shape, (25, 16, 16, 3))\n     self.assertAllEqual(np.array(list(right_split)).shape, (75, 16, 16, 3))\n@@ -214,7 +219,8 @@ class SplitDatasetTest(tf.test.TestCase):\n     # test with tuple of np arrays with different shapes\n     X, Y = (np.random.rand(5, 3, 3), np.random.rand(5,))\n     dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n-    left_split,right_split=dataset_utils.split_dataset(dataset,left_size=0.5)\n+    left_split, right_split = dataset_utils.split_dataset(dataset,\n+                                                          left_size=0.5)\n \n     self.assertEqual(len(list(left_split)), 2)\n     self.assertEqual(len(list(right_split)), 3)\n@@ -239,7 +245,8 @@ class SplitDatasetTest(tf.test.TestCase):\n     dict_samples = {'images': np.random.rand(10, 16, 16, 3),\n                     'labels': np.random.rand(10,)}\n     dataset = tf.data.Dataset.from_tensor_slices(dict_samples)\n-    left_split,right_split=dataset_utils.split_dataset(dataset,left_size=0.3)\n+    left_split, right_split = dataset_utils.split_dataset(dataset,\n+                                                          left_size=0.3)\n     self.assertEqual(len(list(left_split)), 3)\n     self.assertEqual(len(list(right_split)), 7)\n     for i in range(10):\n@@ -249,10 +256,12 @@ class SplitDatasetTest(tf.test.TestCase):\n         self.assertEqual(list(right_split)[i-3], list(dataset)[i])\n \n     # test with dict of text arrays\n-    dict_samples = {'txt_feature':['abb','bb','cc','d','e','f','g','h','i','j'],\n+    txt_feature = ['abb', 'bb', 'cc', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n+    dict_samples = {'txt_feature': txt_feature,\n                     'label': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n     dataset = tf.data.Dataset.from_tensor_slices(dict_samples)\n-    left_split,right_split=dataset_utils.split_dataset(dataset,left_size=0.45,\n+    left_split, right_split = dataset_utils.split_dataset(dataset,\n+                                                          left_size=0.45,\n                                                           right_size=0.55)\n     self.assertEqual(len(list(left_split)), 4)\n     self.assertEqual(len(list(right_split)), 6)\n@@ -281,27 +290,27 @@ class SplitDatasetTest(tf.test.TestCase):\n   def test_invalid_dataset(self):\n     with self.assertRaisesRegex(TypeError,\n                                 '`dataset` must be either a tf.data.Dataset '\n-                               f'object or a list/tuple of arrays. Received '\n+                                'object or a list/tuple of arrays. Received '\n                                 ': <class \\'NoneType\\'>'):\n       dataset_utils.split_dataset(dataset=None, left_size=5)\n     with self.assertRaisesRegex(TypeError,\n                                 '`dataset` must be either a tf.data.Dataset '\n-                               f'object or a list/tuple of arrays. Received '\n+                                'object or a list/tuple of arrays. Received '\n                                 ': <class \\'int\\'>'):\n       dataset_utils.split_dataset(dataset=1, left_size=5)\n     with self.assertRaisesRegex(TypeError,\n                                 '`dataset` must be either a tf.data.Dataset '\n-                               f'object or a list/tuple of arrays. Received '\n+                                'object or a list/tuple of arrays. Received '\n                                 ': <class \\'float\\'>'):\n       dataset_utils.split_dataset(dataset=float(1.2), left_size=5)\n     with self.assertRaisesRegex(TypeError,\n                                 '`dataset` must be either a tf.data.Dataset '\n-                               f'object or a list/tuple of arrays. Received '\n+                                'object or a list/tuple of arrays. Received '\n                                 ': <class \\'dict\\'>'):\n       dataset_utils.split_dataset(dataset=dict({}), left_size=5)\n     with self.assertRaisesRegex(TypeError,\n                                 '`dataset` must be either a tf.data.Dataset '\n-                               f'object or a list/tuple of arrays. Received '\n+                                'object or a list/tuple of arrays. Received '\n                                 ': <class \\'float\\'>'):\n       dataset_utils.split_dataset(dataset=float('INF'), left_size=5)\n \n@@ -442,7 +451,8 @@ class SplitDatasetTest(tf.test.TestCase):\n     assert y_test.shape == (10000,)\n \n     dataset = (x_train[:100], y_train[:100])\n-    left_split,right_split = dataset_utils.split_dataset(dataset,left_size=0.8)\n+    left_split, right_split = dataset_utils.split_dataset(dataset,\n+                                                          left_size=0.8)\n \n     self.assertIsInstance(left_split, tf.data.Dataset)\n     self.assertIsInstance(right_split, tf.data.Dataset)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6ffb8d1ba2f40e34e99d4cddb5e104c3d0e5a898", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 127 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 6 | Methods Changed: 7 | Complexity Δ (Sum/Max): 17/9 | Churn Δ: 129 | Churn Cumulative: 3300 | Contributors (this commit): 36 | Commits (past 90d): 4 | Contributors (cumulative): 43 | DMM Complexity: 0.839622641509434\n\nDIFF:\n@@ -21,6 +21,7 @@ import weakref\n \n from keras.utils import io_utils\n from keras.utils import tf_inspect\n+from keras.utils.vis_utils import get_layer_index_bound_by_layer_name\n import numpy as np\n \n import tensorflow.compat.v2 as tf\n@@ -121,7 +122,8 @@ def print_summary(model,\n                   positions=None,\n                   print_fn=None,\n                   expand_nested=False,\n-                  show_trainable=False):\n+                  show_trainable=False,\n+                  layer_range=None):\n   \"\"\"Prints a summary of a model.\n \n   Args:\n@@ -140,6 +142,14 @@ def print_summary(model,\n           If not provided, defaults to `False`.\n       show_trainable: Whether to show if a layer is trainable.\n           If not provided, defaults to `False`.\n+      layer_range: input of type`list` containing two `str` items, which is the\n+        starting layer name and ending layer name (both inclusive) indicating\n+        the range of layers to be printed in summary. It\n+        also accepts regex patterns instead of exact name. In such case, start\n+        predicate will be the first element it matches to `layer_range[0]`\n+        and the end predicate will be the last element it matches to\n+        `layer_range[1]`. By default `None` which considers all layers of\n+        model.\n   \"\"\"\n   if print_fn is None:\n     print_fn = io_utils.print_msg\n@@ -200,6 +210,21 @@ def print_summary(model,\n     positions.append(line_length)\n     to_display.append('Trainable')\n \n+  if layer_range is not None:\n+    if len(layer_range) != 2:\n+      raise ValueError(\n+          'layer_range must be of shape (2,). Received: '\n+          f'layer_range = {layer_range} of length {len(layer_range)}')\n+    if (not isinstance(layer_range[0], str) or\n+        not isinstance(layer_range[1], str)):\n+      raise ValueError(\n+          'layer_range should contain string type only. '\n+          f'Received: {layer_range}')\n+    layer_range = get_layer_index_bound_by_layer_name(model, layer_range)\n+    if layer_range[0] < 0 or layer_range[1] > len(model.layers):\n+      raise ValueError('Both values in layer_range should be in range (0, '\n+                       f'{len(model.layers)}. Received: {layer_range}')\n+\n   def print_row(fields, positions, nested_level=0):\n     left_to_print = [str(x) for x in fields]\n     while any(left_to_print):\n@@ -334,7 +359,9 @@ def print_summary(model,\n                '|' * nested_level)\n \n   layers = model.layers\n-  for layer in layers:\n+  for i, layer in enumerate(layers):\n+    if (layer_range) and (i < layer_range[0] or i > layer_range[1]):\n+      continue\n     print_layer(layer)\n   print_fn('=' * line_length)\n \n\n@@ -370,6 +370,104 @@ class LayerUtilsTest(tf.test.TestCase):\n     except ImportError:\n       pass\n \n+  def test_print_summary_layer_range(self):\n+    model = keras.Sequential()\n+    model.add(\n+        keras.layers.Conv2D(\n+            filters=2, kernel_size=(2, 3), input_shape=(3, 5, 5), name='conv'))\n+    model.add(keras.layers.Flatten(name='flat'))\n+    model.add(keras.layers.Dense(5, name='dense'))\n+\n+    file_name = 'model_1.txt'\n+    temp_dir = self.get_temp_dir()\n+    self.addCleanup(shutil.rmtree, temp_dir, ignore_errors=True)\n+    fpath = os.path.join(temp_dir, file_name)\n+    writer = open(fpath, 'w')\n+\n+    def print_to_file(text):\n+      print(text, file=writer)\n+\n+    try:\n+      layer_utils.print_summary(model, print_fn=print_to_file, layer_range=[\"conv\", \"flat\"])\n+      self.assertTrue(tf.io.gfile.exists(fpath))\n+      writer.close()\n+      reader = open(fpath, 'r')\n+      lines = reader.readlines()\n+      reader.close()\n+      self.assertEqual(len(lines), 13)\n+    except ImportError:\n+      pass\n+\n+  def test_print_summary_layer_range_with_expand_nested(self):\n+    shape = (None, None, 3)\n+\n+    def make_model():\n+      x = inputs = keras.Input(shape)\n+      x = keras.layers.Conv2D(3, 1)(x)\n+      x = keras.layers.BatchNormalization()(x)\n+      return keras.Model(inputs, x, name=\"2nd_inner\")\n+\n+    x = inner_inputs = keras.Input(shape)\n+    x = make_model()(x)\n+    inner_model = keras.Model(inner_inputs, x, name=\"1st_inner\")\n+\n+    inputs = keras.Input(shape)\n+    model = keras.Model(inputs, inner_model(inputs))\n+\n+    file_name = 'model_2.txt'\n+    temp_dir = self.get_temp_dir()\n+    self.addCleanup(shutil.rmtree, temp_dir, ignore_errors=True)\n+    fpath = os.path.join(temp_dir, file_name)\n+    writer = open(fpath, 'w')\n+\n+    def print_to_file(text):\n+      print(text, file=writer)\n+\n+    try:\n+      layer_utils.print_summary(\n+          model, print_fn=print_to_file, expand_nested=True,\n+          layer_range=[\"1st_inner\", \"1st_inner\"])\n+      layer_utils.print_summary(\n+          model, expand_nested=True, layer_range=[\"1st_inner\", \"1st_inner\"])\n+      self.assertTrue(tf.io.gfile.exists(fpath))\n+      writer.close()\n+      reader = open(fpath, 'r')\n+      lines = reader.readlines()\n+      reader.close()\n+      check_str = (\n+          'Model: \"model\"\\n'\n+          '_________________________________________________________________\\n'\n+          ' Layer (type)                Output Shape              Param #   \\n'\n+          '=================================================================\\n'\n+          ' 1st_inner (Functional)      (None, None, None, 3)     24        \\n'\n+          '|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n'\n+          '| input_4 (InputLayer)      [(None, None, None, 3)]   0         |\\n'\n+          '|                                                               |\\n'\n+          '| 2nd_inner (Functional)    (None, None, None, 3)     24        |\\n'\n+          '||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\\n'\n+          '|| input_5 (InputLayer)    [(None, None, None, 3)]   0         ||\\n'\n+          '||                                                             ||\\n'\n+          '|| conv2d (Conv2D)         (None, None, None, 3)     12        ||\\n'\n+          '||                                                             ||\\n'\n+          '|| batch_normalization (BatchN  (None, None, None, 3)  12      ||\\n'\n+          '|| ormalization)                                               ||\\n'\n+          '|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n'\n+          '¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\\n'\n+          '=================================================================\\n'\n+          'Total params: 24\\n'\n+          'Trainable params: 18\\n'\n+          'Non-trainable params: 6\\n'\n+          '_________________________________________________________________\\n')\n+\n+      fin_str = ''\n+      for line in lines:\n+        fin_str += line\n+      print(fin_str)\n+      self.assertIn(fin_str, check_str)\n+      self.assertEqual(len(lines), 23)\n+    except ImportError:\n+      pass\n+\n   def test_property_cache(self):\n     test_counter = collections.Counter()\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#932c53e230b546fd6e0d93766f461ed8e1e2ba5a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 13 | Files Changed: 11 | Hunks: 12 | Methods Changed: 11 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 26 | Churn Cumulative: 14124 | Contributors (this commit): 40 | Commits (past 90d): 78 | Contributors (cumulative): 71 | DMM Complexity: None\n\nDIFF:\n@@ -213,7 +213,7 @@ def MobileNet(input_shape=None,\n     if depth_multiplier != 1:\n       raise ValueError('If imagenet weights are being loaded, '\n                        'depth multiplier must be 1.  '\n-                       'Received depth_multiplier={depth_multiplier}')\n+                       f'Received depth_multiplier={depth_multiplier}')\n \n     if alpha not in [0.25, 0.50, 0.75, 1.0]:\n       raise ValueError('If imagenet weights are being loaded, '\n\n@@ -147,8 +147,8 @@ class MultiHeadSelfAttention(tf.keras.layers.Layer):\n     self.embed_dim = embed_dim\n     self.num_heads = num_heads\n     if embed_dim % num_heads != 0:\n-      raise ValueError('embedding dimension = {embed_dim} should be divisible'\n-                       'by number of heads = {num_heads}')\n+      raise ValueError(f'embedding dimension = {embed_dim} should be divisible'\n+                       f'by number of heads = {num_heads}')\n     self.projection_dim = embed_dim // num_heads\n     self.query_dense = tf.keras.layers.Dense(embed_dim)\n     self.key_dense = tf.keras.layers.Dense(embed_dim)\n\n@@ -113,7 +113,7 @@ class LayoutMap(collections.abc.MutableMapping):\n                        'not use duplicated keys.')\n     if not isinstance(layout, dtensor.Layout):\n       raise ValueError(f'{layout} should be a dtensor.Layout type, '\n-                       'got {type(layout)}')\n+                       f'got {type(layout)}')\n \n     self._layout_map[key] = layout\n \n\n@@ -112,7 +112,7 @@ class LazyInitVariable(resource_variable_ops.BaseResourceVariable):\n         initial_value, \"graph\") and initial_value.graph.building_function:\n       raise ValueError(f\"Argument `initial_value` ({initial_value}) could not \"\n                        \"be lifted out of a `tf.function`. \"\n-                       \"(Tried to create variable with name='{name}'). \"\n+                       f\"(Tried to create variable with name='{name}'). \"\n                        \"To avoid this error, when constructing `tf.Variable`s \"\n                        \"inside of `tf.function` you can create the \"\n                        \"`initial_value` tensor in a \"\n\n@@ -2677,7 +2677,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     \"\"\"\n     if not self._inbound_nodes:\n       raise RuntimeError(f'The layer {self.name} has never been called '\n-                         'and thus has no defined {attr_name}.')\n+                         f'and thus has no defined {attr_name}.')\n     if not len(self._inbound_nodes) > node_index:\n       raise ValueError(f'Asked to get {attr_name} at node '\n                        f'{node_index}, but the layer has only '\n\n@@ -233,7 +233,7 @@ class DropoutWrapper(_RNNCellWrapper):\n           if const_prob < 0 or const_prob > 1:\n             raise ValueError(\n                 f\"Parameter {attr} must be between 0 and 1. \"\n-                \"Received {const_prob}\")\n+                f\"Received {const_prob}\")\n           setattr(self, \"_%s\" % attr, float(const_prob))\n         else:\n           setattr(self, \"_%s\" % attr, tensor_prob)\n\n@@ -268,7 +268,7 @@ class DropoutWrapper(_RNNCellWrapperV1):\n           if const_prob < 0 or const_prob > 1:\n             raise ValueError(\n                 f\"Parameter {attr} must be between 0 and 1. \"\n-                \"Received {const_prob}\")\n+                f\"Received {const_prob}\")\n           setattr(self, \"_%s\" % attr, float(const_prob))\n         else:\n           setattr(self, \"_%s\" % attr, tensor_prob)\n\n@@ -940,7 +940,7 @@ class LSTMCell(LayerRNNCell):\n     if inputs_shape[-1] is None:\n       raise ValueError(\n           \"Expected inputs.shape[-1] to be known, \"\n-          \"received shape: {inputs_shape}\")\n+          f\"received shape: {inputs_shape}\")\n     _check_supported_dtypes(self.dtype)\n     input_depth = inputs_shape[-1]\n     h_depth = self._num_units if self._num_proj is None else self._num_proj\n\n@@ -1187,7 +1187,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n     params = self.weights\n     if len(params) != len(weights):\n       raise ValueError(\n-          \"You called `set_weights(weights)` on optimizer {self._name} \"\n+          f\"You called `set_weights(weights)` on optimizer {self._name} \"\n           f\"with a  weight list of length {str(len(weights))}, \"\n           f\"but the optimizer was expecting {str(len(params))} \"\n           f\"weights. Provided weights: {str(weights)[:50]}...\")\n\n@@ -58,7 +58,7 @@ def _supervised_signature_def(\n     ValueError: If inputs or outputs is `None`.\n   \"\"\"\n   if inputs is None or not inputs:\n-    raise ValueError('f{method_name} `inputs` cannot be None or empty.')\n+    raise ValueError(f'{method_name} `inputs` cannot be None or empty.')\n \n   signature_inputs = {key: tf.compat.v1.saved_model.build_tensor_info(tensor)\n                       for key, tensor in inputs.items()}\n\n@@ -152,13 +152,13 @@ def audio_dataset_from_directory(\n     if not isinstance(sampling_rate, int):\n       raise ValueError(\n           '`sampling_rate` should have an integer value. '\n-          'Received: sampling_rate={sampling_rate}'\n+          f'Received: sampling_rate={sampling_rate}'\n       )\n \n     if sampling_rate <= 0:\n       raise ValueError(\n           f'`sampling_rate` should be higher than 0. '\n-          'Received: sampling_rate={sampling_rate}'\n+          f'Received: sampling_rate={sampling_rate}'\n       )\n \n     if tfio is None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f2c912542158cc91eb0ca1e275ce51db01b4f685", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 3307 | Contributors (this commit): 10 | Commits (past 90d): 2 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -349,7 +349,7 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n     Returns:\n       The integer size of the voculary, including optional mask and oov indices.\n     \"\"\"\n-    return int(self.lookup_table.size().numpy()) + self._token_start_index()\n+    return self.lookup_table.size() + self._token_start_index()\n \n   def vocab_size(self):\n     logging.warning(\"vocab_size is deprecated, please use vocabulary_size.\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#40872596b3a7e8c0f1c9556844ce9c1dcce1dfaa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 81 | Lines Deleted: 16 | Files Changed: 2 | Hunks: 8 | Methods Changed: 10 | Complexity Δ (Sum/Max): 8/5 | Churn Δ: 97 | Churn Cumulative: 7078 | Contributors (this commit): 9 | Commits (past 90d): 47 | Contributors (cumulative): 17 | DMM Complexity: 1.0\n\nDIFF:\n@@ -444,7 +444,7 @@ class BaseImageAugmentationLayer(base_layer.BaseRandomLayer):\n @keras_export('keras.layers.RandomCrop',\n               'keras.layers.experimental.preprocessing.RandomCrop',\n               v1=[])\n-class RandomCrop(base_layer.BaseRandomLayer):\n+class RandomCrop(BaseImageAugmentationLayer):\n   \"\"\"A preprocessing layer which randomly crops images during training.\n \n   During training, this layer will randomly choose a location to crop images\n@@ -486,31 +486,56 @@ class RandomCrop(base_layer.BaseRandomLayer):\n     self.seed = seed\n \n   def call(self, inputs, training=True):\n-    inputs = utils.ensure_tensor(inputs, dtype=self.compute_dtype)\n+    inputs = self._ensure_inputs_are_compute_dtype(inputs)\n+    inputs, is_dict = self._format_inputs(inputs)\n     if training:\n-      input_shape = tf.shape(inputs)\n-      h_diff = input_shape[H_AXIS] - self.height\n-      w_diff = input_shape[W_AXIS] - self.width\n-      return tf.cond(\n-          tf.reduce_all((h_diff >= 0, w_diff >= 0)),\n-          lambda: self._random_crop(inputs),\n-          lambda: self._resize(inputs))\n+      images = inputs['images']\n+      if images.shape.rank == 3:\n+        return self._format_output(self._augment(inputs), is_dict)\n+      elif images.shape.rank == 4:\n+        return self._format_output(self._batch_augment(inputs), is_dict)\n       else:\n-      return self._resize(inputs)\n+        raise ValueError('Image augmentation layers are expecting inputs to be '\n+                         'rank 3 (HWC) or 4D (NHWC) tensors. Got shape: '\n+                         f'{images.shape}')\n+    else:\n+      output = inputs\n+      output['images'] = self._resize(inputs['images'])\n+      # self._resize() returns valid results for both batched and unbatched\n+      # input\n+      return self._format_output(output, is_dict)\n \n-  def _random_crop(self, inputs):\n-    input_shape = tf.shape(inputs)\n+  def get_random_transformation(self,\n+                                image=None,\n+                                label=None,\n+                                bounding_box=None):\n+    input_shape = tf.shape(image)\n     h_diff = input_shape[H_AXIS] - self.height\n     w_diff = input_shape[W_AXIS] - self.width\n     dtype = input_shape.dtype\n     rands = self._random_generator.random_uniform([2], 0, dtype.max, dtype)\n     h_start = rands[0] % (h_diff + 1)\n     w_start = rands[1] % (w_diff + 1)\n-    return tf.image.crop_to_bounding_box(inputs, h_start, w_start,\n-                                         self.height, self.width)\n+    return {'top': h_start, 'left': w_start}\n \n-  def _resize(self, inputs):\n-    outputs = image_utils.smart_resize(inputs, [self.height, self.width])\n+  def augment_image(self, image, transformation=None):\n+    if transformation is None:\n+      transformation = self.get_random_transformation(image)\n+    input_shape = tf.shape(image)\n+    h_diff = input_shape[H_AXIS] - self.height\n+    w_diff = input_shape[W_AXIS] - self.width\n+    return tf.cond(\n+        tf.reduce_all((h_diff >= 0, w_diff >= 0)),\n+        lambda: self._crop(image, transformation), lambda: self._resize(image))\n+\n+  def _crop(self, image, transformation):\n+    top = transformation['top']\n+    left = transformation['left']\n+    return tf.image.crop_to_bounding_box(image, top, left, self.height,\n+                                         self.width)\n+\n+  def _resize(self, image):\n+    outputs = image_utils.smart_resize(image, [self.height, self.width])\n     # smart_resize will always output float32, so we need to re-cast.\n     return tf.cast(outputs, self.compute_dtype)\n \n\n@@ -423,6 +423,46 @@ class RandomCropTest(test_combinations.TestCase):\n         actual_output = layer(inp, training=True)\n         self.assertAllClose(inp[2:10, 2:10, :], actual_output)\n \n+  def test_batched_input(self):\n+    np.random.seed(1337)\n+    inp = np.random.random((20, 16, 16, 3))\n+    mock_offset = [2, 2]\n+    with test_utils.use_gpu():\n+      layer = image_preprocessing.RandomCrop(8, 8)\n+      with tf.compat.v1.test.mock.patch.object(\n+          layer._random_generator, 'random_uniform', return_value=mock_offset):\n+        actual_output = layer(inp, training=True)\n+        self.assertAllClose(inp[:, 2:10, 2:10, :], actual_output)\n+\n+  def test_augment_image(self):\n+    np.random.seed(1337)\n+    inp = np.random.random((16, 16, 3))\n+    mock_offset = [2, 2]\n+    with test_utils.use_gpu():\n+      layer = image_preprocessing.RandomCrop(8, 8)\n+      with tf.compat.v1.test.mock.patch.object(\n+          layer._random_generator, 'random_uniform', return_value=mock_offset):\n+        actual_output = layer.augment_image(inp)\n+        self.assertAllClose(inp[2:10, 2:10, :], actual_output)\n+\n+  def test_training_false(self):\n+    np.random.seed(1337)\n+    height, width = 4, 6\n+    inp = np.random.random((12, 8, 16, 3))\n+    inp_dict = {'images': inp}\n+    with test_utils.use_gpu():\n+      layer = image_preprocessing.RandomCrop(height, width)\n+      # test wih tensor input\n+      actual_output = layer(inp, training=False)\n+      resized_inp = tf.image.resize(inp, size=[4, 8])\n+      expected_output = resized_inp[:, :, 1:7, :]\n+      self.assertAllClose(expected_output, actual_output)\n+      # test with dictionary input\n+      actual_output = layer(inp_dict, training=False)\n+      resized_inp = tf.image.resize(inp, size=[4, 8])\n+      expected_output = resized_inp[:, :, 1:7, :]\n+      self.assertAllClose(expected_output, actual_output['images'])\n+\n   @test_utils.run_v2_only\n   def test_uint8_input(self):\n     inputs = keras.Input((128, 128, 3), batch_size=2, dtype=tf.uint8)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b7449e59ba5e6617461f9974206b3af15e3ba475", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 113 | Lines Deleted: 176 | Files Changed: 7 | Hunks: 49 | Methods Changed: 36 | Complexity Δ (Sum/Max): -26/3 | Churn Δ: 289 | Churn Cumulative: 16777 | Contributors (this commit): 63 | Commits (past 90d): 37 | Contributors (cumulative): 106 | DMM Complexity: 0.5172413793103449\n\nDIFF:\n@@ -2956,7 +2956,8 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     return True\n \n   def _init_call_fn_args(self, expects_training_arg=None):\n-    self._call_spec = layer_utils.CallFunctionSpec(self.call)\n+    self._call_spec = layer_utils.CallFunctionSpec(\n+        tf_inspect.getfullargspec(self.call))\n     if expects_training_arg is not None:\n       self._call_spec.expects_training_arg = expects_training_arg\n \n\n@@ -29,8 +29,10 @@ from keras.saving.saved_model import constants\n from keras.saving.saved_model import json_utils\n from keras.saving.saved_model import utils\n from keras.saving.saved_model.serialized_attributes import CommonEndpoints\n+from keras.utils import layer_utils\n from keras.utils import generic_utils\n from keras.utils import metrics_utils\n+from keras.utils import tf_inspect\n from keras.utils.generic_utils import LazyLoader\n import tensorflow.compat.v1.logging as logging\n import tensorflow.compat.v2 as tf\n@@ -810,7 +812,10 @@ def _finalize_saved_model_layers(layers):\n     layer_call = getattr(\n         _get_keras_attr(layer), 'call_and_return_conditional_losses', None)\n     if layer_call and layer_call.concrete_functions:\n-      layer.call = utils.use_wrapped_call(layer, layer_call, return_method=True)\n+      call_spec = layer_utils.CallFunctionSpec(\n+          tf_inspect.getfullargspec(layer_call))\n+      layer.call = utils.use_wrapped_call(layer, layer_call, call_spec,\n+                                          return_method=True)\n       expects_training_arg = layer._serialized_attributes['metadata'][\n           'expects_training_arg']\n       if 'training' in layer_call.function_spec.arg_names:\n\n@@ -31,8 +31,8 @@ from keras.saving.saved_model import constants\n from keras.saving.saved_model import load as keras_load\n from keras.saving.saved_model import serialized_attributes\n from keras.saving.saved_model import utils\n+from keras.utils import layer_utils\n from keras.utils import tf_contextlib\n-from keras.utils import tf_inspect\n from keras.utils import tf_utils\n from keras.utils import version_utils\n from keras.utils.generic_utils import LazyLoader\n@@ -261,6 +261,7 @@ def _replace_child_layer_functions(layer, serialization_cache):\n       child_layer.call = utils.use_wrapped_call(\n           child_layer,\n           serialized_fns['call_and_return_conditional_losses'],\n+          child_layer._call_spec,\n           default_training_value=False)\n \n   def replace_metric_functions(child_layer, serialized_fns):\n@@ -402,18 +403,26 @@ class LayerCallCollection:\n \n     self.layer_call_method = _get_layer_call_method(layer)\n     self._expects_training_arg = utils.layer_uses_training_bool(layer)\n-    self._training_arg_index = utils.get_training_arg_index(\n-        self.layer_call_method)\n+    self._call_spec = layer._call_spec  # pylint: disable=protected-access\n+\n+    # Create new call spec if the layer itself does not accept a training arg,\n+    # but one of its child layers does. When this layer's call functions are\n+    # traced, they will be traced with an added `training` keyword argument.\n+    if not self.layer._expects_training_arg and self._expects_training_arg:  # pylint: disable=protected-access\n+      arg_spec = utils.set_training_arg_spec(self._call_spec.full_argspec,\n+                                             False)\n+      self._call_spec = layer_utils.CallFunctionSpec(arg_spec)\n \n     self._layer_inputs = self._get_layer_inputs(layer)\n     self._functions = weakref.WeakValueDictionary()\n \n     # Get the input argument name from the args.\n-    arg_spec = tf_inspect.getfullargspec(self.layer_call_method)\n-    args = arg_spec.args\n-    if utils.call_is_method(self.layer_call_method):\n-      args = args[1:]\n-    self._input_arg_name = args[0] if args else 'inputs'\n+    if self._call_spec.arg_names:\n+      self._input_arg_name = self._call_spec.arg_names[0]\n+    else:\n+      # Layer could be defined with only varargs, in which case use a default\n+      # name.\n+      self._input_arg_name = 'inputs'\n \n   def _get_layer_inputs(self, layer):\n     \"\"\"Inspects layer object and returns the inferred input signature.\n@@ -467,7 +476,9 @@ class LayerCallCollection:\n       if self._expects_training_arg:\n \n         def trace_with_training(value, fn=fn):\n-          utils.set_training_arg(value, self._training_arg_index, args, kwargs)\n+          nonlocal args, kwargs\n+          args, kwargs = self._call_spec.set_arg_value(  # pylint: disable=protected-access\n+              'training', value, args, kwargs, inputs_in_args=True)\n           add_trace_to_queue(fn, args, kwargs, value)\n \n         trace_with_training(True)\n@@ -476,28 +487,24 @@ class LayerCallCollection:\n         add_trace_to_queue(fn, args, kwargs)\n \n   def training_arg_was_passed(self, args, kwargs):\n-    if not self.layer._expects_training_arg and self._expects_training_arg:  # pylint: disable=protected-access\n-      return (utils.get_training_arg(self._training_arg_index, args, kwargs)\n-              is not None)\n-    else:\n-      return self.layer._call_spec.arg_was_passed(  # pylint: disable=protected-access\n+    return self._call_spec.arg_was_passed(  # pylint: disable=protected-access\n         'training',\n         args,\n         kwargs,\n         inputs_in_args=True)\n \n   def get_training_arg_value(self, args, kwargs):\n-    if not self.layer._expects_training_arg and self._expects_training_arg:  # pylint: disable=protected-access\n-      return utils.get_training_arg(self._training_arg_index, args, kwargs)\n-    else:\n-      return self.layer._call_spec.get_arg_value(  # pylint: disable=protected-access\n+    try:\n+      return self._call_spec.get_arg_value(  # pylint: disable=protected-access\n           'training',\n           args,\n           kwargs,\n           inputs_in_args=True)\n+    except KeyError:  # Training is not in args or kwargs.\n+      return None\n \n   def get_input_arg_value(self, args, kwargs):\n-    return self.layer._call_spec.get_arg_value(  # pylint: disable=protected-access\n+    return self._call_spec.get_arg_value(  # pylint: disable=protected-access\n         self._input_arg_name,\n         args,\n         kwargs,\n@@ -506,25 +513,7 @@ class LayerCallCollection:\n   def _maybe_wrap_with_training_arg(self, call_fn, match_layer_training_arg):\n     \"\"\"Wraps call function with added training argument if necessary.\"\"\"\n     if not self.layer._expects_training_arg and self._expects_training_arg:  # pylint: disable=protected-access\n-      # Add training arg to wrapper function.\n-      arg_spec = tf_inspect.getfullargspec(call_fn)\n-      args = arg_spec.args + ['training']\n-      defaults = list(arg_spec.defaults or [])\n-      defaults.append(False)\n-      new_arg_spec = tf_inspect.FullArgSpec(\n-          args=args,\n-          varargs=arg_spec.varargs,\n-          varkw=arg_spec.varkw,\n-          defaults=defaults,\n-          kwonlyargs=arg_spec.kwonlyargs,\n-          kwonlydefaults=arg_spec.kwonlydefaults,\n-          annotations=arg_spec.annotations)\n-\n-      # Set new training arg index\n-      self._training_arg_index = len(args) - 1\n-      if utils.call_is_method(call_fn):\n-        self._training_arg_index -= 1\n-\n+      # Add training arg to wrapper function.  # pylint: disable=protected-access\n       def wrap_with_training_arg(*args, **kwargs):\n         if match_layer_training_arg:\n           # Remove the training value, since the original call_fn does not\n@@ -532,13 +521,15 @@ class LayerCallCollection:\n           # propagated using the call context created in LayerCall.\n           args = list(args)\n           kwargs = kwargs.copy()\n-          utils.remove_training_arg(self._training_arg_index, args, kwargs)\n+          args, kwargs = self._call_spec.set_arg_value(  # pylint: disable=protected-access\n+              'training', None, args, kwargs, inputs_in_args=True,\n+              pop_kwarg_if_none=True)\n         return call_fn(*args, **kwargs)\n \n       return tf.__internal__.decorator.make_decorator(\n           target=call_fn,\n           decorator_func=wrap_with_training_arg,\n-          decorator_argspec=new_arg_spec)\n+          decorator_argspec=self._call_spec.full_argspec)\n \n     return call_fn\n \n@@ -623,7 +614,6 @@ class LayerCall:\n     self.call_collection = call_collection\n     self.wrapped_call = tf.function(\n         layer_call_wrapper(call_collection, call_fn, name))\n-    self.original_layer_call = call_collection.layer_call_method\n \n   def _maybe_trace(self, args, kwargs):\n     # Trigger traces of other call functions + extra training-arg traces.\n@@ -696,7 +686,7 @@ def _append_activity_regularizer_loss(layer, call_fn_with_losses,\n def _create_call_fn_decorator(layer, wrapped_call):\n   call_fn = _get_layer_call_method(layer)\n   fn, arg_spec = utils.maybe_add_training_arg(\n-      call_fn,\n+      layer._call_spec,  # pylint: disable=protected-access\n       wrapped_call,\n       layer._expects_training_arg,  # pylint: disable=protected-access\n       default_training_value=False)\n\n@@ -564,8 +564,16 @@ class TestSavedModelFormatAllModes(test_combinations.TestCase):\n   def testTrainingDefaults(self):\n     def assert_training_default(fn, default_value):\n       arg_spec = tf_inspect.getfullargspec(fn)\n-      index = len(arg_spec.args) - arg_spec.args.index('training')\n-      self.assertEqual(arg_spec.defaults[-index], default_value)\n+      fn_defaults = arg_spec.defaults or []\n+      defaults = dict()\n+      # The call arg defaults are an n-tuple of the last n elements of the args\n+      # list. (n = # of elements that have a default argument)\n+      for i in range(-1 * len(fn_defaults), 0):\n+        defaults[arg_spec.args[i]] = fn_defaults[i]\n+      # The default training arg will be any (non-None) default specified in the\n+      # method signature, or None if no value is specified.\n+      defaults.update(arg_spec.kwonlydefaults or {})\n+      self.assertEqual(defaults['training'], default_value)\n \n     class LayerWithTrainingRequiredArg(keras.engine.base_layer.Layer):\n \n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Utility functions shared between SavedModel saving/loading implementations.\"\"\"\n \n-\n+import copy\n import inspect as _inspect\n import itertools\n import threading\n@@ -23,8 +23,8 @@ import types\n from keras import backend\n from keras.engine import base_layer_utils\n from keras.utils import control_flow_util\n+from keras.utils import layer_utils\n from keras.utils import tf_contextlib\n-from keras.utils import tf_inspect\n from keras.utils.generic_utils import LazyLoader\n \n import tensorflow.compat.v2 as tf\n@@ -37,7 +37,8 @@ training_lib = LazyLoader(\n # pylint:enable=g-inconsistent-quotes\n \n \n-def use_wrapped_call(layer, call_fn, default_training_value=None,\n+def use_wrapped_call(layer, call_fn, call_spec,\n+                     default_training_value=None,\n                      return_method=False):\n   \"\"\"Creates fn that adds the losses returned by call_fn & returns the outputs.\n \n@@ -45,6 +46,7 @@ def use_wrapped_call(layer, call_fn, default_training_value=None,\n     layer: A Keras layer object\n     call_fn: tf.function that takes layer inputs (and possibly a training arg),\n       and returns a tuple of (outputs, list of losses).\n+    call_spec: The `CallFunctionSpec` for the layer's call function.\n     default_training_value: Default value of the training kwarg. If `None`, the\n       default is `tf.keras.backend.learning_phase()`.\n     return_method: Whether to return a method bound to the layer.\n@@ -54,14 +56,10 @@ def use_wrapped_call(layer, call_fn, default_training_value=None,\n     call_fn are added to the layer losses.\n   \"\"\"\n   expects_training_arg = layer_uses_training_bool(layer)\n-  if hasattr(call_fn, 'original_layer_call'):  # call_fn is a LayerCall object\n-    original_call = call_fn.original_layer_call\n-    # In Python 3, callable objects are not compatible with inspect.getargspec\n-    call_fn = call_fn.__call__\n-  else:\n-    original_call = call_fn\n+\n   fn, arg_spec = maybe_add_training_arg(\n-      original_call, call_fn, expects_training_arg, default_training_value)\n+      call_spec,\n+      call_fn, expects_training_arg, default_training_value)\n \n   def return_outputs_and_add_losses(*args, **kwargs):\n     \"\"\"Returns the outputs from the layer call function, and adds the losses.\"\"\"\n@@ -130,14 +128,15 @@ def list_all_layers_and_sublayers(obj):\n \n \n def maybe_add_training_arg(\n-    original_call, wrapped_call, expects_training_arg, default_training_value):\n+    call_spec, wrapped_call, expects_training_arg,\n+    default_training_value):\n   \"\"\"Decorate call and optionally adds training argument.\n \n   If a layer expects a training argument, this function ensures that 'training'\n   is present in the layer args or kwonly args, with the default training value.\n \n   Args:\n-    original_call: Original call function.\n+    call_spec: CallFunctionSpec of the layer.\n     wrapped_call: Wrapped call function.\n     expects_training_arg: Whether to include 'training' argument.\n     default_training_value: Default value of the training kwarg to include in\n@@ -151,139 +150,58 @@ def maybe_add_training_arg(\n   \"\"\"\n   if not expects_training_arg:\n     return wrapped_call, None\n+\n+  arg_spec = set_training_arg_spec(call_spec.full_argspec,\n+                                   default_training_value)\n+  call_spec = layer_utils.CallFunctionSpec(arg_spec)\n+\n   def wrap_with_training_arg(*args, **kwargs):\n     \"\"\"Wrap the `wrapped_call` function, and set training argument.\"\"\"\n-    training_arg_index = get_training_arg_index(original_call)\n-    training = get_training_arg(training_arg_index, args, kwargs)\n+    try:\n+      training = call_spec.get_arg_value('training', args, kwargs,\n+                                         inputs_in_args=True)\n+    except KeyError:\n+      training = None\n+\n     if training is None:\n-      training = default_training_value or backend.learning_phase()\n+      training = (default_training_value or\n+                  base_layer_utils.call_context().training or\n+                  backend.learning_phase())\n \n     args = list(args)\n     kwargs = kwargs.copy()\n \n     def replace_training_and_call(training):\n-      set_training_arg(training, training_arg_index, args, kwargs)\n-      return wrapped_call(*args, **kwargs)\n+      new_args, new_kwargs = call_spec.set_arg_value('training', training, args, kwargs, inputs_in_args=True)\n+      return wrapped_call(*new_args, **new_kwargs)\n \n     return control_flow_util.smart_cond(\n         training, lambda: replace_training_and_call(True),\n         lambda: replace_training_and_call(False))\n \n-  # Create arg spec for decorated function. If 'training' is not defined in the\n-  # args of the original arg spec, then add it to kwonlyargs.\n-  arg_spec = tf_inspect.getfullargspec(original_call)\n-  defaults = list(arg_spec.defaults) if arg_spec.defaults is not None else []\n+  return wrap_with_training_arg, arg_spec\n \n-  kwonlyargs = arg_spec.kwonlyargs\n-  kwonlydefaults = arg_spec.kwonlydefaults or {}\n-  # Add training arg if it does not exist, or set the default training value.\n-  if 'training' not in arg_spec.args:\n-    kwonlyargs.append('training')\n-    kwonlydefaults['training'] = default_training_value\n-  else:\n+\n+def set_training_arg_spec(arg_spec, default_training_value):\n+  \"\"\"Set `training=DEFAULT` argument in an ArgSpec.\"\"\"\n+  if 'training' in arg_spec.args:\n+    # If `training` is already in the args list, try to set the default value.\n     index = arg_spec.args.index('training')\n     training_default_index = len(arg_spec.args) - index\n+    defaults = list(arg_spec.defaults) if arg_spec.defaults is not None else []\n     if (arg_spec.defaults and\n         len(arg_spec.defaults) >= training_default_index and\n         defaults[-training_default_index] is None):\n       defaults[-training_default_index] = default_training_value\n+      return arg_spec._replace(defaults=defaults)\n+  elif 'training' not in arg_spec.kwonlyargs:\n+    kwonlyargs = arg_spec.kwonlyargs + ['training']\n+    kwonlydefaults = copy.copy(arg_spec.kwonlydefaults) or {}\n+    kwonlydefaults['training'] = default_training_value\n+    return arg_spec._replace(kwonlyargs=kwonlyargs,\n+                             kwonlydefaults=kwonlydefaults)\n \n-  decorator_argspec = tf_inspect.FullArgSpec(\n-      args=arg_spec.args,\n-      varargs=arg_spec.varargs,\n-      varkw=arg_spec.varkw,\n-      defaults=defaults,\n-      kwonlyargs=kwonlyargs,\n-      kwonlydefaults=kwonlydefaults,\n-      annotations=arg_spec.annotations)\n-  return wrap_with_training_arg, decorator_argspec\n-\n-\n-def get_training_arg_index(call_fn):\n-  \"\"\"Returns the index of 'training' in the layer call function arguments.\n-\n-  Args:\n-    call_fn: Call function.\n-\n-  Returns:\n-    - n: index of 'training' in the call function arguments.\n-    - -1: if 'training' is not found in the arguments, but layer.call accepts\n-          variable keyword arguments\n-    - None: if layer doesn't expect a training argument.\n-  \"\"\"\n-  argspec = tf_inspect.getfullargspec(call_fn)\n-  if argspec.varargs:\n-    # When there are variable args, training must be a keyword arg.\n-    if 'training' in argspec.kwonlyargs or argspec.varkw:\n-      return -1\n-    return None\n-  else:\n-    # Try to find 'training' in the list of args or kwargs.\n-    arg_list = argspec.args\n-    if call_is_method(call_fn):\n-      arg_list = arg_list[1:]\n-\n-    if 'training' in arg_list:\n-      return arg_list.index('training')\n-    elif 'training' in argspec.kwonlyargs or argspec.varkw:\n-      return -1\n-    return None\n-\n-\n-def call_is_method(call_fn):\n-  \"\"\"Check if call_fn is a method regardless of pre/post-binding decoration.\n-\n-  E.g. decoration after instance creation/method binding\n-  self.call = @tf.function(self.call).\n-\n-  Or decoration in the class definition before binding:\n-  class Foo(Layer):\n-    @decorator\n-    def call(self, ...):\n-      pass\n-\n-  Args:\n-    call_fn: The fn to check\n-\n-  Returns:\n-    True if the fn is a bound method, or a bound method that was decorated\n-    after binding. Else False.\n-  \"\"\"\n-  # tf_inspect checks if a call_fn is either an undecorated bound method,\n-  # or a bound method that was decorated after the method was bound\n-  # to an instance. E.g. in the case of\n-  # self.call = @tf.function(self.call).\n-  #\n-  # _inspect checks if the method is bound, and returns true even if the method\n-  # was decorated before binding occurred.\n-  # e.g. this would happen in the case of\n-  # class Foo(Layer):\n-  #   @decorator\n-  #   def call(self, ...):\n-  #     pass\n-  return tf_inspect.ismethod(call_fn) or _inspect.ismethod(call_fn)\n-\n-\n-def set_training_arg(training, index, args, kwargs):\n-  if index is None or index < 0 or len(args) <= index:  # index is invalid\n-    kwargs['training'] = training\n-  else:\n-    args[index] = training\n-  return args, kwargs\n-\n-\n-def get_training_arg(index, args, kwargs):\n-  if index is None or index < 0 or len(args) <= index:  # index is invalid\n-    return kwargs.get('training', None)\n-  else:\n-    return args[index]\n-\n-\n-def remove_training_arg(index, args, kwargs):\n-  if index is None or index < 0 or len(args) <= index:  # index is invalid\n-    kwargs.pop('training', None)\n-  else:\n-    args.pop(index)\n+  return arg_spec\n \n \n class SaveOptionsContext(threading.local):\n\n@@ -124,7 +124,6 @@ def trace_model_call(model, input_signature=None):\n     model_kwargs = {}\n   else:\n     model_args, model_kwargs = model_call_inputs(model)\n-    input_signature = model_args  # store\n \n     if model_args is None:\n       raise_model_input_error(model)\n@@ -132,7 +131,9 @@ def trace_model_call(model, input_signature=None):\n   @tf.function\n   def _wrapped_model(*args, **kwargs):\n     \"\"\"A concrete tf.function that wraps the model's call function.\"\"\"\n-    kwargs['training'] = False\n+    args, kwargs = model._call_spec.set_arg_value(  # pylint: disable=protected-access\n+        'training', False, args, kwargs, inputs_in_args=True)\n+\n     with base_layer_utils.call_context().enter(\n         model, inputs=None, build_graph=False, training=False, saving=True):\n       outputs = model(*args, **kwargs)\n\n@@ -518,15 +518,15 @@ def filter_empty_layer_containers(layer_list):\n class CallFunctionSpec:\n   \"\"\"Caches the spec and provides utilities for handling call function args.\"\"\"\n \n-  def __init__(self, fn):\n+  def __init__(self, full_argspec):\n     \"\"\"Initialies a `CallFunctionSpec`.\n \n     Args:\n-      fn: the call function of a layer.\n+      full_argspec: the FullArgSpec of a call function of a layer.\n     \"\"\"\n-    self._full_argspec = tf_inspect.getfullargspec(fn)\n+    self._full_argspec = full_argspec\n \n-    self._arg_names = self._full_argspec.args\n+    self._arg_names = list(self._full_argspec.args)\n     # Scrub `self` that appears if a decorator was applied.\n     if self._arg_names and self._arg_names[0] == 'self':\n       self._arg_names = self._arg_names[1:]\n@@ -556,6 +556,7 @@ class CallFunctionSpec:\n   @property\n   def arg_names(self):\n     \"\"\"List of names of args and kwonlyargs.\"\"\"\n+    # `arg_names` is not accurate if the layer has variable positional args.\n     return self._arg_names\n \n   @arg_names.setter\n@@ -566,6 +567,7 @@ class CallFunctionSpec:\n   @cached_per_instance\n   def arg_positions(self):\n     \"\"\"Returns a dict mapping arg names to their index positions.\"\"\"\n+    # `arg_positions` is not accurate if the layer has variable positional args.\n     call_fn_arg_positions = dict()\n     for pos, arg in enumerate(self._arg_names):\n       call_fn_arg_positions[arg] = pos\n@@ -632,6 +634,9 @@ class CallFunctionSpec:\n     Returns:\n       The value of the argument with name `arg_name`, extracted from `args` or\n       `kwargs`.\n+\n+    Raises:\n+      KeyError if the value of `arg_name` cannot be found.\n     \"\"\"\n     if arg_name in kwargs:\n       return kwargs[arg_name]\n@@ -664,7 +669,16 @@ class CallFunctionSpec:\n     Returns:\n       The updated `(args, kwargs)`.\n     \"\"\"\n+    if self.full_argspec.varargs:\n+      try:\n+        arg_pos = self.full_argspec.args.index(arg_name)\n+        if self.full_argspec.args[0] == 'self':\n+          arg_pos -= 1\n+      except ValueError:\n+        arg_pos = None\n+    else:\n       arg_pos = self.arg_positions.get(arg_name, None)\n+\n     if arg_pos is not None:\n       if not inputs_in_args:\n         # Ignore `inputs` arg.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
