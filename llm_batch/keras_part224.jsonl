{"custom_id": "keras#63c48ff2044ae754084dbf5afeded86efeb7184a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 35 | Files Changed: 1 | Hunks: 12 | Methods Changed: 1 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 59 | Churn Cumulative: 5949 | Contributors (this commit): 78 | Commits (past 90d): 30 | Contributors (cumulative): 78 | DMM Complexity: 1.0\n\nDIFF:\n@@ -61,22 +61,19 @@ def _standardize_input_data(data, names, shapes=None,\n     if data is None:\n         return [None for _ in range(len(names))]\n     if isinstance(data, dict):\n-        for key, value in data.items():\n-            if value.__class__.__name__ == 'DataFrame':\n-                data[key] = value.values\n-        arrays = []\n-        for name in names:\n-            if name not in data:\n+        try:\n+            arrays = [data[name].values if data[name].__class__.__name__ == 'DataFrame' else data[name]\n+                      for name in names]\n+\n+        except KeyError as e:\n             raise ValueError('No data provided for \"' +\n-                                 name + '\". Need data for each key in: ' +\n+                             e.args[0] + '\". Need data for each key in: ' +\n                              str(names))\n-            arrays.append(data[name])\n+\n     elif isinstance(data, list):\n-        for key, value in enumerate(data):\n-            if value.__class__.__name__ == 'DataFrame':\n-                data[key] = value.values\n-        if len(data) != len(names):\n-            if data and hasattr(data[0], 'shape'):\n+        arrays = [x.values if x.__class__.__name__ == 'DataFrame' else x for x in data]\n+        if len(arrays) != len(names):\n+            if arrays and hasattr(arrays[0], 'shape'):\n                 raise ValueError('Error when checking model ' +\n                                  exception_prefix +\n                                  ': the list of Numpy arrays '\n@@ -84,12 +81,12 @@ def _standardize_input_data(data, names, shapes=None,\n                                  'is not the size the model expected. '\n                                  'Expected to see ' + str(len(names)) +\n                                  ' array(s), but instead got '\n-                                 'the following list of ' + str(len(data)) +\n-                                 ' arrays: ' + str(data)[:200] +\n+                                 'the following list of ' + str(len(arrays)) +\n+                                 ' arrays: ' + str(arrays)[:200] +\n                                  '...')\n             else:\n                 if len(names) == 1:\n-                    data = [np.asarray(data)]\n+                    arrays = [np.asarray(arrays)]\n                 else:\n                     raise ValueError(\n                         'Error when checking model ' +\n@@ -100,8 +97,7 @@ def _standardize_input_data(data, names, shapes=None,\n                         'a list of ' + str(len(names)) +\n                         ' Numpy arrays instead. '\n                         'The list you passed was: ' +\n-                        str(data)[:200])\n-        arrays = data\n+                        str(arrays)[:200])\n     else:\n         if data.__class__.__name__ == 'DataFrame':\n             # test if data is a DataFrame, without pandas installed\n@@ -122,36 +118,29 @@ def _standardize_input_data(data, names, shapes=None,\n         arrays = [data]\n \n     # Make arrays at least 2D.\n-    for i in range(len(names)):\n-        array = arrays[i]\n-        if len(array.shape) == 1:\n-            array = np.expand_dims(array, 1)\n-            arrays[i] = array\n+    arrays = [np.expand_dims(array, 1) if array.ndim == 1 else array for array in arrays]\n \n     # Check shapes compatibility.\n     if shapes:\n+        start = 0 if check_batch_axis else 1\n         for i in range(len(names)):\n-            if shapes[i] is None:\n-                continue\n-            array = arrays[i]\n-            if len(array.shape) != len(shapes[i]):\n+            if shapes[i] is not None:\n+                array_shape = arrays[i].shape\n+                if arrays[i].ndim != len(shapes[i]):\n                     raise ValueError('Error when checking ' + exception_prefix +\n                                      ': expected ' + names[i] +\n                                      ' to have ' + str(len(shapes[i])) +\n                                      ' dimensions, but got array with shape ' +\n-                                 str(array.shape))\n-            for j, (dim, ref_dim) in enumerate(zip(array.shape, shapes[i])):\n-                if not j and not check_batch_axis:\n-                    # skip the first axis\n-                    continue\n-                if ref_dim:\n-                    if ref_dim != dim:\n+                                     str(array_shape))\n+\n+                for dim, ref_dim in zip(array_shape[start:], shapes[i][start:]):\n+                    if ref_dim != dim and ref_dim:\n                         raise ValueError(\n                             'Error when checking ' + exception_prefix +\n                             ': expected ' + names[i] +\n                             ' to have shape ' + str(shapes[i]) +\n                             ' but got array with shape ' +\n-                            str(array.shape))\n+                            str(array_shape))\n     return arrays\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5c224403d3948983035682a1f71bc2e0e64cbb87", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 55 | Files Changed: 1 | Hunks: 5 | Methods Changed: 7 | Complexity Δ (Sum/Max): -10/0 | Churn Δ: 62 | Churn Cumulative: 1573 | Contributors (this commit): 21 | Commits (past 90d): 9 | Contributors (cumulative): 21 | DMM Complexity: 0.0\n\nDIFF:\n@@ -486,7 +486,7 @@ def test_warnings():\n \n \n @keras_test\n-def test_sparse_input_target_fit():\n+def test_sparse_inputs_targets():\n     test_inputs = [sparse.random(6, 3, density=0.25).tocsr() for _ in range(2)]\n     test_outputs = [sparse.random(6, i, density=0.25).tocsr() for i in range(3, 5)]\n     in1 = Input(shape=(3,))\n@@ -494,33 +494,10 @@ def test_sparse_input_target_fit():\n     out1 = Dropout(0.5, name='dropout')(in1)\n     out2 = Dense(4, name='dense_1')(in2)\n     model = Model([in1, in2], [out1, out2])\n-    model.compile('rmsprop', 'mse')\n-    model.fit(test_inputs, test_outputs, epochs=1, batch_size=2, validation_split=0.2)\n-\n-\n-@keras_test\n-def test_sparse_input_target_evaluate():\n-    test_inputs = [sparse.random(6, 3, density=0.25).tocsr() for _ in range(2)]\n-    test_outputs = [sparse.random(6, i, density=0.25).tocsr() for i in range(3, 5)]\n-    in1 = Input(shape=(3,))\n-    in2 = Input(shape=(3,))\n-    out1 = Dropout(0.5, name='dropout')(in1)\n-    out2 = Dense(4, name='dense_1')(in2)\n-    model = Model([in1, in2], [out1, out2])\n-    model.compile('rmsprop', 'mse')\n-    model.evaluate(test_inputs, test_outputs, batch_size=2)\n-\n-\n-@keras_test\n-def test_sparse_input_predict():\n-    test_inputs = [sparse.random(6, 3, density=0.25).tocsr() for _ in range(2)]\n-    in1 = Input(shape=(3,))\n-    in2 = Input(shape=(3,))\n-    out1 = Dropout(0.5, name='dropout')(in1)\n-    out2 = Dense(4, name='dense_1')(in2)\n-    model = Model([in1, in2], [out1, out2])\n-    model.compile('rmsprop', 'mse')\n     model.predict(test_inputs, batch_size=2)\n+    model.compile('rmsprop', 'mse')\n+    model.fit(test_inputs, test_outputs, epochs=1, batch_size=2, validation_split=0.5)\n+    model.evaluate(test_inputs, test_outputs, batch_size=2)\n \n \n @pytest.mark.skipif(K.backend() != 'tensorflow', reason='sparse operations supported only by TensorFlow')\n@@ -533,35 +510,10 @@ def test_sparse_placeholder_fit():\n     out1 = Dropout(0.5, name='dropout')(in1)\n     out2 = Dense(4, name='dense_1')(in2)\n     model = Model([in1, in2], [out1, out2])\n-    model.compile('rmsprop', 'mse')\n-    model.fit(test_inputs, test_outputs, epochs=1, batch_size=2, validation_split=0.2)\n-\n-\n-@pytest.mark.skipif(K.backend() != 'tensorflow', reason='sparse operations supported only by TensorFlow')\n-@keras_test\n-def test_sparse_placeholder_evaluate():\n-    test_inputs = [sparse.random(6, 3, density=0.25).tocsr() for _ in range(2)]\n-    test_outputs = [sparse.random(6, i, density=0.25).tocsr() for i in range(3, 5)]\n-    in1 = Input(shape=(3,))\n-    in2 = Input(shape=(3,), sparse=True)\n-    out1 = Dropout(0.5, name='dropout')(in1)\n-    out2 = Dense(4, name='dense_1')(in2)\n-    model = Model([in1, in2], [out1, out2])\n-    model.compile('rmsprop', 'mse')\n-    model.evaluate(test_inputs, test_outputs, batch_size=2)\n-\n-\n-@pytest.mark.skipif(K.backend() != 'tensorflow', reason='sparse operations supported only by TensorFlow')\n-@keras_test\n-def test_sparse_placeholder_predict():\n-    test_inputs = [sparse.random(6, 3, density=0.25).tocsr() for _ in range(2)]\n-    in1 = Input(shape=(3,))\n-    in2 = Input(shape=(3,), sparse=True)\n-    out1 = Dropout(0.5, name='dropout')(in1)\n-    out2 = Dense(4, name='dense_1')(in2)\n-    model = Model([in1, in2], [out1, out2])\n-    model.compile('rmsprop', 'mse')\n     model.predict(test_inputs, batch_size=2)\n+    model.compile('rmsprop', 'mse')\n+    model.fit(test_inputs, test_outputs, epochs=1, batch_size=2, validation_split=0.5)\n+    model.evaluate(test_inputs, test_outputs, batch_size=2)\n \n \n @keras_test\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0d99a49057a58af7843f25e27dee64f581801415", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 6 | Methods Changed: 1 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 21 | Churn Cumulative: 270 | Contributors (this commit): 12 | Commits (past 90d): 4 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -11,6 +11,7 @@ has at least ~100k characters. ~1M is better.\n '''\n \n from __future__ import print_function\n+from keras.callbacks import LambdaCallback\n from keras.models import Sequential\n from keras.layers import Dense, Activation\n from keras.layers import LSTM\n@@ -69,19 +70,14 @@ def sample(preds, temperature=1.0):\n     probas = np.random.multinomial(1, preds, 1)\n     return np.argmax(probas)\n \n-# train the model, output generated text after each iteration\n-for iteration in range(1, 60):\n+\n+def on_epoch_end(epoch, logs):\n+    # Function invoked at end of each epoch. Prints generated text.\n     print()\n-    print('-' * 50)\n-    print('Iteration', iteration)\n-    model.fit(x, y,\n-              batch_size=128,\n-              epochs=1)\n+    print('----- Generating text after Epoch: %d' % epoch)\n \n     start_index = random.randint(0, len(text) - maxlen - 1)\n-\n     for diversity in [0.2, 0.5, 1.0, 1.2]:\n-        print()\n         print('----- diversity:', diversity)\n \n         generated = ''\n@@ -105,3 +101,10 @@ for iteration in range(1, 60):\n             sys.stdout.write(next_char)\n             sys.stdout.flush()\n         print()\n+\n+print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n+\n+model.fit(x, y,\n+          batch_size=128,\n+          epochs=60,\n+          callbacks=[print_callback])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a2e26b12e2c12eaa1d15debfe697e1354c54b6ed", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1383 | Contributors (this commit): 20 | Commits (past 90d): 12 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -141,6 +141,7 @@ PAGES = [\n             layers.Activation,\n             layers.Dropout,\n             layers.Flatten,\n+            layers.Input,\n             layers.Reshape,\n             layers.Permute,\n             layers.RepeatVector,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e32c5b4b9e3068ec213f90489e0dd7487c9d191b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 9111 | Contributors (this commit): 48 | Commits (past 90d): 14 | Contributors (cumulative): 48 | DMM Complexity: None\n\nDIFF:\n@@ -668,7 +668,7 @@ class RNN(Layer):\n                              'a `batch_input_shape` '\n                              'argument to your first layer.\\n'\n                              '- If using the functional API, specify '\n-                             'the time dimension by passing a '\n+                             'the batch size by passing a '\n                              '`batch_shape` argument to your Input layer.')\n         # initialize state if None\n         if self.states[0] is None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#322592521db2b7a285d54b31a6f307db580169a8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 2721 | Contributors (this commit): 45 | Commits (past 90d): 13 | Contributors (cumulative): 45 | DMM Complexity: None\n\nDIFF:\n@@ -392,6 +392,11 @@ class ImageDataGenerator(object):\n         fill_mode: points outside the boundaries are filled according to the\n             given mode ('constant', 'nearest', 'reflect' or 'wrap'). Default\n             is 'nearest'.\n+            Points outside the boundaries of the input are filled according to the given mode:\n+                'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k)\n+                'nearest':  aaaaaaaa|abcd|dddddddd\n+                'reflect':  abcddcba|abcd|dcbaabcd\n+                'wrap':  abcdabcd|abcd|abcdabcd\n         cval: value used for points outside the boundaries when fill_mode is\n             'constant'. Default is 0.\n         horizontal_flip: whether to randomly flip images horizontally.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#04c11f8c13b1182b43eaed36dbfdedb23efd38b9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 158 | Lines Deleted: 10 | Files Changed: 59 | Hunks: 70 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 168 | Churn Cumulative: 103167 | Contributors (this commit): 466 | Commits (past 90d): 270 | Contributors (cumulative): 1127 | DMM Complexity: None\n\nDIFF:\n@@ -1,4 +1,7 @@\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n import six\n import warnings\n from . import backend as K\n\n@@ -10,8 +10,9 @@\n - [Torch DenseNets](https://github.com/liuzhuang13/DenseNet/blob/master/models/densenet.lua)\n - [TensorNets](https://github.com/taehoonlee/tensornets/blob/master/tensornets/densenets.py)\n \"\"\"\n-from __future__ import print_function\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n import os\n \n\n@@ -1,3 +1,7 @@\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n import json\n import warnings\n import numpy as np\n\n@@ -13,8 +13,9 @@ https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-model\n    Residual Connections on Learning](https://arxiv.org/abs/1602.07261)\n \n \"\"\"\n-from __future__ import print_function\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n import os\n import warnings\n\n@@ -10,8 +10,9 @@ and that the input preprocessing function is also different (same as Xception).\n - [Rethinking the Inception Architecture for Computer Vision](http://arxiv.org/abs/1512.00567)\n \n \"\"\"\n-from __future__ import print_function\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n import os\n import warnings\n\n@@ -7,8 +7,9 @@\n \n Adapted from code contributed by BigMoyan.\n \"\"\"\n-from __future__ import print_function\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n import os\n import warnings\n\n@@ -6,8 +6,9 @@\n - [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)\n \n \"\"\"\n-from __future__ import print_function\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n import os\n import warnings\n\n@@ -6,8 +6,9 @@\n - [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)\n \n \"\"\"\n-from __future__ import print_function\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n import os\n import warnings\n\n@@ -17,8 +17,9 @@ due to its reliance on `SeparableConvolution` layers.\n - [Xception: Deep Learning with Depthwise Separable Convolutions](https://arxiv.org/abs/1610.02357)\n \n \"\"\"\n-from __future__ import print_function\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n import os\n import warnings\n\n@@ -1,4 +1,7 @@\n+from __future__ import absolute_import\n+from __future__ import division\n from __future__ import print_function\n+\n import cntk as C\n import numpy as np\n from .common import floatx, epsilon, image_dim_ordering, image_data_format\n\n@@ -1,3 +1,7 @@\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n import numpy as np\n \n # the type of float to use throughout the session.\n\n@@ -1,3 +1,7 @@\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n import tensorflow as tf\n from tensorflow.python.training import moving_averages\n from tensorflow.python.ops import tensor_array_ops\n\n@@ -1,3 +1,7 @@\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n from collections import defaultdict\n from contextlib import contextmanager\n import theano\n\n@@ -1,4 +1,5 @@\n from __future__ import absolute_import\n+from __future__ import division\n from __future__ import print_function\n \n import os\n\n@@ -1,4 +1,7 @@\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n import six\n from . import backend as K\n from .utils.generic_utils import serialize_keras_object\n\n@@ -1,3 +1,7 @@\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n from ..utils.data_utils import get_file\n import numpy as np\n \n\n@@ -1,5 +1,8 @@\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n import sys\n from six.moves import cPickle\n \n\n@@ -1,4 +1,7 @@\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n from .cifar import load_batch\n from ..utils.data_utils import get_file\n from .. import backend as K\n\n@@ -1,4 +1,7 @@\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n from .cifar import load_batch\n from ..utils.data_utils import get_file\n from .. import backend as K\n\n@@ -1,3 +1,7 @@\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n import gzip\n import os\n \n\n@@ -1,4 +1,7 @@\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n from ..utils.data_utils import get_file\n from ..preprocessing.sequence import _remove_long_seq\n import numpy as np\n\n@@ -1,3 +1,7 @@\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n from ..utils.data_utils import get_file\n import numpy as np\n \n\n@@ -1,5 +1,8 @@\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n from ..utils.data_utils import get_file\n from ..preprocessing.sequence import _remove_long_seq\n from six.moves import zip\n\n@@ -1,6 +1,7 @@\n # -*- coding: utf-8 -*-\n-from __future__ import print_function\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n import warnings\n import copy\n\n@@ -1,4 +1,7 @@\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n import numpy as np\n import six\n from . import backend as K\n\n@@ -1,5 +1,7 @@\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n from .. import activations\n from .. import initializers\n\n@@ -1,5 +1,7 @@\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n from .. import backend as K\n from .. import activations\n\n@@ -1,5 +1,7 @@\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n from .. import backend as K\n from .. import activations\n\n@@ -1,6 +1,7 @@\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n from __future__ import division\n+from __future__ import print_function\n \n import numpy as np\n \n\n@@ -1,3 +1,7 @@\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n from .. import backend as K\n from .. import initializers\n from .. import regularizers\n\n@@ -1,4 +1,6 @@\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n from .. import backend as K\n from .. import initializers\n\n@@ -1,5 +1,7 @@\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n from .. import backend as K\n from .. import activations\n\n@@ -1,3 +1,7 @@\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n from ..engine.topology import Layer\n from .. import backend as K\n \n\n@@ -1,5 +1,7 @@\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n from ..engine import Layer\n from .. import backend as K\n\n@@ -1,5 +1,7 @@\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n from ..engine import Layer, InputSpec\n from .. import initializers\n\n@@ -1,5 +1,7 @@\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n from .. import backend as K\n from ..engine import Layer\n\n@@ -1,5 +1,8 @@\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n import numpy as np\n import warnings\n \n\n@@ -1,5 +1,7 @@\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n import copy\n from ..engine import Layer\n\n@@ -1,5 +1,9 @@\n \"\"\"Interface converters for Keras 1 support in Keras 2.\n \"\"\"\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n import six\n import warnings\n import functools\n\n@@ -1,3 +1,7 @@\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n import numpy as np\n import types as python_types\n import warnings\n\n@@ -1,3 +1,7 @@\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n from .layers import Merge\n \n \n\n@@ -1,4 +1,7 @@\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n import six\n from . import backend as K\n from .utils.generic_utils import deserialize_keras_object\n\n@@ -1,4 +1,7 @@\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n import six\n from . import backend as K\n from .losses import mean_squared_error\n\n@@ -1,5 +1,6 @@\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n+from __future__ import division\n from __future__ import print_function\n \n import warnings\n\n@@ -1,4 +1,7 @@\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n import six\n import copy\n from six.moves import zip\n\n@@ -1,8 +1,10 @@\n \"\"\"Fairly basic set of tools for real-time data augmentation on image data.\n+\n Can easily be extended to include new transformations,\n new preprocessing methods, etc...\n \"\"\"\n from __future__ import absolute_import\n+from __future__ import division\n from __future__ import print_function\n \n import numpy as np\n\n@@ -1,5 +1,7 @@\n # -*- coding: utf-8 -*-\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n import numpy as np\n import random\n\n@@ -1,10 +1,9 @@\n # -*- coding: utf-8 -*-\n \"\"\"Utilities for text input preprocessing.\n-\n-May benefit from a fast Cython rewrite.\n \"\"\"\n from __future__ import absolute_import\n from __future__ import division\n+from __future__ import print_function\n \n import string\n import sys\n\n@@ -1,4 +1,7 @@\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n import six\n from . import backend as K\n from .utils.generic_utils import serialize_keras_object\n\n@@ -1,3 +1,7 @@\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n from six.moves import range\n import numpy as np\n from .. import backend as K\n\n@@ -1,5 +1,6 @@\n \"\"\"Utilities for file download and caching.\"\"\"\n from __future__ import absolute_import\n+from __future__ import division\n from __future__ import print_function\n \n import hashlib\n\n@@ -1,5 +1,7 @@\n \"\"\"Python utilities required by Keras.\"\"\"\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n import binascii\n import numpy as np\n\n@@ -1,5 +1,6 @@\n \"\"\"Utilities related to disk I/O.\"\"\"\n from __future__ import absolute_import\n+from __future__ import division\n from __future__ import print_function\n \n import numpy as np\n\n@@ -1,3 +1,5 @@\n+from __future__ import absolute_import\n+from __future__ import division\n from __future__ import print_function\n \n from .conv_utils import convert_kernel\n\n@@ -1,5 +1,7 @@\n \"\"\"Numpy-related utilities.\"\"\"\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n import numpy as np\n \n\n@@ -1,4 +1,8 @@\n \"\"\"Utilities related to Keras unit tests.\"\"\"\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n import numpy as np\n from numpy.testing import assert_allclose\n import six\n\n@@ -1,3 +1,7 @@\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n from ..layers.merge import concatenate\n from .. import backend as K\n from ..layers.core import Lambda\n\n@@ -1,4 +1,8 @@\n \"\"\"Utilities related to model visualization.\"\"\"\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n import os\n \n try:\n\n@@ -1,4 +1,6 @@\n from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n \n import copy\n import types\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b197ba91d7bd3c390b67cd67da2eb381b25a22b2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 3 | Churn Cumulative: 1432 | Contributors (this commit): 7 | Commits (past 90d): 2 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -354,8 +354,6 @@ class LocallyConnected2D(Layer):\n             return (input_shape[0], rows, cols, self.filters)\n \n     def call(self, inputs):\n-        _, _, filters = self.kernel_shape\n-\n         output = K.local_conv2d(inputs,\n                                 self.kernel,\n                                 self.kernel_size,\n@@ -364,7 +362,6 @@ class LocallyConnected2D(Layer):\n                                 self.data_format)\n \n         if self.use_bias:\n-            if self.data_format == 'channels_first' or self.data_format == 'channels_last':\n             output = K.bias_add(output, self.bias, data_format=self.data_format)\n \n         output = self.activation(output)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cb6adf8da72c2d685b3a0a192165949c9da7b0e7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 33 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 33 | Churn Cumulative: 582 | Contributors (this commit): 13 | Commits (past 90d): 3 | Contributors (cumulative): 17 | DMM Complexity: 0.6190476190476191\n\nDIFF:\n@@ -124,6 +124,8 @@ class Tokenizer(object):\n         lower: boolean. Whether to convert the texts to lowercase.\n         split: character or string to use for token splitting.\n         char_level: if True, every character will be treated as a token.\n+        oov_token: if given, it will be added to word_index and used to\n+            replace out-of-vocabulary words during text_to_sequence calls\n \n     By default, all punctuation is removed, turning the texts into\n     space-separated sequences of words\n@@ -138,6 +140,7 @@ class Tokenizer(object):\n                  lower=True,\n                  split=' ',\n                  char_level=False,\n+                 oov_token=None,\n                  **kwargs):\n         # Legacy support\n         if 'nb_words' in kwargs:\n@@ -155,6 +158,7 @@ class Tokenizer(object):\n         self.num_words = num_words\n         self.document_count = 0\n         self.char_level = char_level\n+        self.oov_token = oov_token\n \n     def fit_on_texts(self, texts):\n         \"\"\"Updates internal vocabulary based on a list of texts.\n@@ -189,6 +193,11 @@ class Tokenizer(object):\n         # note that index 0 is reserved, never assigned to an existing word\n         self.word_index = dict(list(zip(sorted_voc, list(range(1, len(sorted_voc) + 1)))))\n \n+        if self.oov_token is not None:\n+            i = self.word_index.get(self.oov_token)\n+            if i is None:\n+                self.word_index[self.oov_token] = len(self.word_index) + 1\n+\n         self.index_docs = {}\n         for w, c in list(self.word_docs.items()):\n             self.index_docs[self.word_index[w]] = c\n@@ -256,6 +265,10 @@ class Tokenizer(object):\n                         continue\n                     else:\n                         vect.append(i)\n+                elif self.oov_token is not None:\n+                    i = self.word_index.get(self.oov_token)\n+                    if i is not None:\n+                        vect.append(i)\n             yield vect\n \n     def texts_to_matrix(self, texts, mode='binary'):\n\n@@ -67,5 +67,25 @@ def test_tokenizer_unicode():\n     assert len(tokenizer.word_counts) == 5\n \n \n+def test_tokenizer_oov_flag():\n+    \"\"\"\n+    Test of Out of Vocabulary (OOV) flag in Tokenizer\n+    \"\"\"\n+    x_train = ['This text has only known words']\n+    x_test = ['This text has some unknown words']  # 2 OOVs: some, unknown\n+\n+    # Defalut, without OOV flag\n+    tokenizer =  Tokenizer()\n+    tokenizer.fit_on_texts(x_train)\n+    x_test_seq = tokenizer.texts_to_sequences(x_test)\n+    assert len(x_test_seq[0]) == 4  # discards 2 OOVs\n+\n+    # With OOV feature\n+    tokenizer =  Tokenizer(oov_token='<unk>')\n+    tokenizer.fit_on_texts(x_train)\n+    x_test_seq = tokenizer.texts_to_sequences(x_test)\n+    assert len(x_test_seq[0]) == 6  # OOVs marked in place\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#35e10e91172c2fb716d5a6ec489ae71e0f488ca3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 49 | Lines Deleted: 68 | Files Changed: 1 | Hunks: 9 | Methods Changed: 1 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 117 | Churn Cumulative: 6069 | Contributors (this commit): 78 | Commits (past 90d): 32 | Contributors (cumulative): 78 | DMM Complexity: 1.0\n\nDIFF:\n@@ -61,88 +61,69 @@ def _standardize_input_data(data, names, shapes=None,\n         return []\n     if data is None:\n         return [None for _ in range(len(names))]\n+\n     if isinstance(data, dict):\n         try:\n-            arrays = [data[name].values if data[name].__class__.__name__ == 'DataFrame' else data[name]\n-                      for name in names]\n-\n+            data = [data[x].values if data[x].__class__.__name__ == 'DataFrame' else data[x] for x in names]\n+            data = [np.expand_dims(x, 1) if x.ndim == 1 else x for x in data]\n         except KeyError as e:\n-            raise ValueError('No data provided for \"' +\n-                             e.args[0] + '\". Need data for each key in: ' +\n-                             str(names))\n-\n-    elif isinstance(data, list):\n-        arrays = [x.values if x.__class__.__name__ == 'DataFrame' else x for x in data]\n-        if len(arrays) != len(names):\n-            if arrays and hasattr(arrays[0], 'shape'):\n-                raise ValueError('Error when checking model ' +\n-                                 exception_prefix +\n-                                 ': the list of Numpy arrays '\n-                                 'that you are passing to your model '\n-                                 'is not the size the model expected. '\n-                                 'Expected to see ' + str(len(names)) +\n-                                 ' array(s), but instead got '\n-                                 'the following list of ' + str(len(arrays)) +\n-                                 ' arrays: ' + str(arrays)[:200] +\n-                                 '...')\n-            else:\n-                if len(names) == 1:\n-                    arrays = [np.asarray(arrays)]\n-                else:\n             raise ValueError(\n-                        'Error when checking model ' +\n-                        exception_prefix +\n-                        ': you are passing a list as '\n-                        'input to your model, '\n-                        'but the model expects '\n-                        'a list of ' + str(len(names)) +\n-                        ' Numpy arrays instead. '\n-                        'The list you passed was: ' +\n-                        str(arrays)[:200])\n+                'No data provided for \"' + e.args[0] + '\". Need data '\n+                'for each key in: ' + str(names))\n+    elif isinstance(data, list):\n+        data = [x.values if x.__class__.__name__ == 'DataFrame' else x for x in data]\n+        data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data]\n     else:\n-        if data.__class__.__name__ == 'DataFrame':\n-            # test if data is a DataFrame, without pandas installed\n-            data = data.values\n-        if not hasattr(data, 'shape'):\n-            raise TypeError('Error when checking model ' +\n-                            exception_prefix +\n-                            ': data should be a Numpy array, '\n-                            'or list/dict of Numpy arrays. '\n-                            'Found: ' + str(data)[:200] + '...')\n-        if len(names) > 1:\n-            # Case: model expects multiple inputs but only received\n-            # a single Numpy array.\n-            raise ValueError('The model expects ' + str(len(names)) + ' ' +\n-                             exception_prefix +\n-                             ' arrays, but only received one array. '\n-                             'Found: array with shape ' + str(data.shape))\n-        arrays = [data]\n+        data = data.values if data.__class__.__name__ == 'DataFrame' else data\n+        data = [np.expand_dims(data, 1)] if data.ndim == 1 else [data]\n \n-    # Make arrays at least 2D.\n-    arrays = [np.expand_dims(array, 1) if array.ndim == 1 else array for array in arrays]\n+    if len(data) != len(names):\n+        if data and hasattr(data[0], 'shape'):\n+            raise ValueError(\n+                'Error when checking model ' + exception_prefix +\n+                ': the list of Numpy arrays that you are passing to '\n+                'your model is not the size the model expected. '\n+                'Expected to see ' + str(len(names)) + ' array(s), '\n+                'but instead got the following list of ' +\n+                str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n+        elif len(names) > 1:\n+            raise ValueError(\n+                'Error when checking model ' + exception_prefix +\n+                ': you are passing a list as input to your model, '\n+                'but the model expects a list of ' + str(len(names)) +\n+                ' Numpy arrays instead. The list you passed was: ' +\n+                str(data)[:200])\n+        elif len(data) == 1 and not hasattr(data[0], 'shape'):\n+            raise TypeError(\n+                'Error when checking model ' + exception_prefix +\n+                ': data should be a Numpy array, or list/dict of '\n+                'Numpy arrays. Found: ' + str(data)[:200] + '...')\n+        elif len(names) == 1:\n+            data = [np.asarray(data)]\n \n     # Check shapes compatibility.\n     if shapes:\n-        start = 0 if check_batch_axis else 1\n         for i in range(len(names)):\n             if shapes[i] is not None:\n-                array_shape = arrays[i].shape\n-                if arrays[i].ndim != len(shapes[i]):\n-                    raise ValueError('Error when checking ' + exception_prefix +\n-                                     ': expected ' + names[i] +\n-                                     ' to have ' + str(len(shapes[i])) +\n-                                     ' dimensions, but got array with shape ' +\n-                                     str(array_shape))\n-\n-                for dim, ref_dim in zip(array_shape[start:], shapes[i][start:]):\n+                data_shape = data[i].shape\n+                shape = shapes[i]\n+                if data[i].ndim != len(shape):\n+                    raise ValueError(\n+                        'Error when checking ' + exception_prefix +\n+                        ': expected ' + names[i] + ' to have ' +\n+                        str(len(shape)) + ' dimensions, but got array '\n+                        'with shape ' + str(data_shape))\n+                if not check_batch_axis:\n+                    data_shape = data_shape[1:]\n+                    shape = shape[1:]\n+                for dim, ref_dim in zip(data_shape, shape):\n                     if ref_dim != dim and ref_dim:\n                         raise ValueError(\n                             'Error when checking ' + exception_prefix +\n-                            ': expected ' + names[i] +\n-                            ' to have shape ' + str(shapes[i]) +\n-                            ' but got array with shape ' +\n-                            str(array_shape))\n-    return arrays\n+                            ': expected ' + names[i] + ' to have shape ' +\n+                            str(shape) + ' but got array with shape ' +\n+                            str(data_shape))\n+    return data\n \n \n def _standardize_sample_or_class_weights(x_weight, output_names, weight_type):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f6eda660f7bc3ec9b7b2423b47e4804a31fcff8b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 95 | Lines Deleted: 18 | Files Changed: 37 | Hunks: 57 | Methods Changed: 3 | Complexity Δ (Sum/Max): -5/0 | Churn Δ: 113 | Churn Cumulative: 79133 | Contributors (this commit): 366 | Commits (past 90d): 194 | Contributors (cumulative): 758 | DMM Complexity: None\n\nDIFF:\n@@ -1,3 +1,5 @@\n+\"\"\"Built-in activation functions.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n@@ -38,11 +40,14 @@ def elu(x, alpha=1.0):\n \n \n def selu(x):\n-    \"\"\"Scaled Exponential Linear Unit. (Klambauer et al., 2017)\n+    \"\"\"Scaled Exponential Linear Unit. (Klambauer et al., 2017).\n \n     # Arguments\n         x: A tensor or variable to compute the activation function for.\n \n+    # Returns\n+        Tensor with the same shape and dtype as `x`.\n+\n     # Note\n         - To be used together with the initialization \"lecun_normal\".\n         - To be used together with the dropout variant \"AlphaDropout\".\n@@ -102,12 +107,12 @@ def get(identifier):\n         return deserialize(identifier)\n     elif callable(identifier):\n         if isinstance(identifier, Layer):\n-            warnings.warn((\n+            warnings.warn(\n                 'Do not pass a layer instance (such as {identifier}) as the '\n                 'activation argument of another layer. Instead, advanced '\n                 'activation layers should be used just like any other '\n-                'layer in a model.'\n-            ).format(identifier=identifier.__class__.__name__))\n+                'layer in a model.'.format(\n+                    identifier=identifier.__class__.__name__))\n         return identifier\n     else:\n         raise ValueError('Could not interpret '\n\n@@ -1,3 +1,5 @@\n+\"\"\"Callbacks: utilities called at certain points during model training.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n@@ -815,6 +817,7 @@ class ReduceLROnPlateau(Callback):\n     of epochs, the learning rate is reduced.\n \n     # Example\n+\n     ```python\n     reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                                   patience=5, min_lr=0.001)\n@@ -928,6 +931,7 @@ class CSVLogger(Callback):\n     including 1D iterables such as np.ndarray.\n \n     # Example\n+\n     ```python\n     csv_logger = CSVLogger('training.log')\n     model.fit(X_train, Y_train, callbacks=[csv_logger])\n@@ -1020,6 +1024,7 @@ class LambdaCallback(Callback):\n         on_train_end: called at the end of model training.\n \n     # Example\n+\n     ```python\n     # Print the batch number at the beginning of every batch.\n     batch_print_callback = LambdaCallback(\n\n@@ -1,3 +1,5 @@\n+\"\"\"Constraints: functions that impose constraints on weight values.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,3 +1,5 @@\n+\"\"\"Boston housing price regression dataset.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,4 +1,6 @@\n # -*- coding: utf-8 -*-\n+\"\"\"Utilities common to CIFAR10 and CIFAR100 datasets.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,3 +1,5 @@\n+\"\"\"CIFAR10 small images classification dataset.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,3 +1,5 @@\n+\"\"\"CIFAR100 small images classification dataset.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,3 +1,5 @@\n+\"\"\"Fashion-MNIST dataset.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,3 +1,5 @@\n+\"\"\"IMDB sentiment classification dataset.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,3 +1,5 @@\n+\"\"\"MNIST handwritten digits dataset.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,11 +1,12 @@\n # -*- coding: utf-8 -*-\n+\"\"\"Reuters topic classification dataset.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n from ..utils.data_utils import get_file\n from ..preprocessing.sequence import _remove_long_seq\n-from six.moves import zip\n import numpy as np\n import json\n import warnings\n\n@@ -1,4 +1,6 @@\n # -*- coding: utf-8 -*-\n+\"\"\"Topology-related part of the Keras engine.\n+\"\"\"\n from __future__ import print_function\n from __future__ import absolute_import\n from __future__ import division\n\n@@ -1,4 +1,6 @@\n # -*- coding: utf-8 -*-\n+\"\"\"Training-related part of the Keras engine.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n@@ -6,7 +8,6 @@ from __future__ import print_function\n import warnings\n import copy\n import numpy as np\n-import six\n \n from keras.utils import Sequence\n from keras.utils import GeneratorEnqueuer\n\n@@ -1,3 +1,5 @@\n+\"\"\"Built-in weight initializers.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,4 +1,6 @@\n # -*- coding: utf-8 -*-\n+\"\"\"Advanced activation layers.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,4 +1,6 @@\n # -*- coding: utf-8 -*-\n+\"\"\"Convolutional layers.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,4 +1,6 @@\n # -*- coding: utf-8 -*-\n+\"\"\"Convolutional-recurrent layers.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,4 +1,6 @@\n # -*- coding: utf-8 -*-\n+\"\"\"Core Keras layers.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,3 +1,5 @@\n+\"\"\"Recurrent layers backed by cuDNN.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,3 +1,5 @@\n+\"\"\"Embedding layer.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,4 +1,6 @@\n # -*- coding: utf-8 -*-\n+\"\"\"Locally-connected layers.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,3 +1,5 @@\n+\"\"\"Layers that can merge several inputs into one.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,4 +1,6 @@\n # -*- coding: utf-8 -*-\n+\"\"\"Noise regularization layers.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,4 +1,6 @@\n # -*- coding: utf-8 -*-\n+\"\"\"Normalization layers.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,4 +1,6 @@\n # -*- coding: utf-8 -*-\n+\"\"\"Pooling layers.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,4 +1,6 @@\n # -*- coding: utf-8 -*-\n+\"\"\"Recurrent layers and their base classes.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n@@ -618,8 +620,7 @@ class RNN(Layer):\n             return output\n \n     def _standardize_args(self, inputs, initial_state, constants):\n-        \"\"\"Brings the arguments of `__call__` that can contain input tensors to\n-        standard format.\n+        \"\"\"Standardize `__call__` to a single list of tensor inputs.\n \n         When running a model loaded from file, the input tensors\n         `initial_state` and `constants` can be passed to `RNN.__call__` as part\n@@ -775,11 +776,11 @@ class SimpleRNNCell(Layer):\n             (ie. \"linear\" activation: `a(x) = x`).\n         use_bias: Boolean, whether the layer uses a bias vector.\n         kernel_initializer: Initializer for the `kernel` weights matrix,\n-            used for the linear transformation of the inputs.\n+            used for the linear transformation of the inputs\n             (see [initializers](../initializers.md)).\n         recurrent_initializer: Initializer for the `recurrent_kernel`\n             weights matrix,\n-            used for the linear transformation of the recurrent state.\n+            used for the linear transformation of the recurrent state\n             (see [initializers](../initializers.md)).\n         bias_initializer: Initializer for the bias vector\n             (see [initializers](../initializers.md)).\n@@ -933,11 +934,11 @@ class SimpleRNN(RNN):\n             (ie. \"linear\" activation: `a(x) = x`).\n         use_bias: Boolean, whether the layer uses a bias vector.\n         kernel_initializer: Initializer for the `kernel` weights matrix,\n-            used for the linear transformation of the inputs.\n+            used for the linear transformation of the inputs\n             (see [initializers](../initializers.md)).\n         recurrent_initializer: Initializer for the `recurrent_kernel`\n             weights matrix,\n-            used for the linear transformation of the recurrent state.\n+            used for the linear transformation of the recurrent state\n             (see [initializers](../initializers.md)).\n         bias_initializer: Initializer for the bias vector\n             (see [initializers](../initializers.md)).\n@@ -1146,11 +1147,11 @@ class GRUCell(Layer):\n             (see [activations](../activations.md)).\n         use_bias: Boolean, whether the layer uses a bias vector.\n         kernel_initializer: Initializer for the `kernel` weights matrix,\n-            used for the linear transformation of the inputs.\n+            used for the linear transformation of the inputs\n             (see [initializers](../initializers.md)).\n         recurrent_initializer: Initializer for the `recurrent_kernel`\n             weights matrix,\n-            used for the linear transformation of the recurrent state.\n+            used for the linear transformation of the recurrent state\n             (see [initializers](../initializers.md)).\n         bias_initializer: Initializer for the bias vector\n             (see [initializers](../initializers.md)).\n@@ -1386,11 +1387,11 @@ class GRU(RNN):\n             (see [activations](../activations.md)).\n         use_bias: Boolean, whether the layer uses a bias vector.\n         kernel_initializer: Initializer for the `kernel` weights matrix,\n-            used for the linear transformation of the inputs.\n+            used for the linear transformation of the inputs\n             (see [initializers](../initializers.md)).\n         recurrent_initializer: Initializer for the `recurrent_kernel`\n             weights matrix,\n-            used for the linear transformation of the recurrent state.\n+            used for the linear transformation of the recurrent state\n             (see [initializers](../initializers.md)).\n         bias_initializer: Initializer for the bias vector\n             (see [initializers](../initializers.md)).\n@@ -1623,11 +1624,11 @@ class LSTMCell(Layer):\n             (see [activations](../activations.md)).\n         use_bias: Boolean, whether the layer uses a bias vector.\n         kernel_initializer: Initializer for the `kernel` weights matrix,\n-            used for the linear transformation of the inputs.\n+            used for the linear transformation of the inputs\n             (see [initializers](../initializers.md)).\n         recurrent_initializer: Initializer for the `recurrent_kernel`\n             weights matrix,\n-            used for the linear transformation of the recurrent state.\n+            used for the linear transformation of the recurrent state\n             (see [initializers](../initializers.md)).\n         bias_initializer: Initializer for the bias vector\n             (see [initializers](../initializers.md)).\n\n@@ -1,4 +1,6 @@\n # -*- coding: utf-8 -*-\n+\"\"\"Layers that augment the functionality of a base layer.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,3 +1,5 @@\n+\"\"\"Built-in loss functions.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,3 +1,5 @@\n+\"\"\"Built-in metrics.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,4 +1,6 @@\n # -*- coding: utf-8 -*-\n+\"\"\"Sequential model class and model-related utilities.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,3 +1,5 @@\n+\"\"\"Built-in optimizer classes.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,4 +1,6 @@\n # -*- coding: utf-8 -*-\n+\"\"\"Utilities for preprocessing sequence data.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,3 +1,5 @@\n+\"\"\"Built-in regularizers.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,3 +1,5 @@\n+\"\"\"Utilities used in convolutional layers.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,3 +1,5 @@\n+\"\"\"Utilities related to layer/model functionality.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,3 +1,5 @@\n+\"\"\"Multi-GPU training utilities.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n@@ -1,3 +1,5 @@\n+\"\"\"Wrapper for using the Scikit-Learn API with Keras models.\n+\"\"\"\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
