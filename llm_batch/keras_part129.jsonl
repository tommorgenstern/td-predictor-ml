{"custom_id": "keras#78988b5cd67d066bb4c9c6c29b636331e4f78c4d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 7 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 4081 | Contributors (this commit): 25 | Commits (past 90d): 21 | Contributors (cumulative): 25 | DMM Complexity: 0.3333333333333333\n\nDIFF:\n@@ -1456,21 +1456,23 @@ class Merge(Layer):\n         else:\n             mode = config['mode']\n \n-        output_shape_type = config.pop('output_shape_type')\n+        output_shape_type = config.pop('output_shape_type', None)\n         if output_shape_type == 'function':\n             output_shape = globals()[config['output_shape']]\n         elif output_shape_type == 'lambda':\n-            output_shape = func_load(config['output_shape'], globs=globals())\n+            output_shape = func_load(config['output_shape'],\n+                                     globs=globals())\n         else:\n-            output_shape = config['output_shape']\n+            output_shape = config.get('output_shape')\n \n-        output_mask_type = config.pop('output_mask_type')\n+        output_mask_type = config.pop('output_mask_type', None)\n         if output_mask_type == 'function':\n             output_mask = globals()[config['output_mask']]\n         elif output_mask_type == 'lambda':\n-            output_mask = func_load(config['output_mask'], globs=globals())\n+            output_mask = func_load(config['output_mask'],\n+                                    globs=globals())\n         else:\n-            output_mask = config['output_mask']\n+            output_mask = config.get('output_mask')\n \n         config['mode'] = mode\n         config['output_shape'] = output_shape\n@@ -1479,7 +1481,8 @@ class Merge(Layer):\n \n \n def merge(inputs, mode='sum', concat_axis=-1,\n-          dot_axes=-1, output_shape=None, output_mask=None, arguments={}, name=None):\n+          dot_axes=-1, output_shape=None, output_mask=None,\n+          arguments={}, name=None):\n     '''Functional merge, to apply to Keras tensors (NOT layers).\n     Returns a Keras tensor.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#149946c706042e0db96664aa8c7bb0d61c224d9d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 9655 | Contributors (this commit): 50 | Commits (past 90d): 21 | Contributors (cumulative): 59 | DMM Complexity: None\n\nDIFF:\n@@ -1587,7 +1587,7 @@ class ZeroPadding3D(Layer):\n         padding: tuple of int (length 3)\n             How many zeros to add at the beginning and end of\n             the 3 padding dimensions (axis 3, 4 and 5).\n-            Currentl only symmetric padding is supported.\n+            Currently only symmetric padding is supported.\n         dim_ordering: 'th' or 'tf'.\n             In 'th' mode, the channels dimension (the depth)\n             is at index 1, in 'tf' mode is it at index 4.\n\n@@ -653,7 +653,7 @@ class LSTM(Recurrent):\n     # References\n         - [Long short-term memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf) (original 1997 paper)\n         - [Learning to forget: Continual prediction with LSTM](http://www.mitpressjournals.org/doi/pdf/10.1162/089976600300015015)\n-        - [Supervised sequence labelling with recurrent neural networks](http://www.cs.toronto.edu/~graves/preprint.pdf)\n+        - [Supervised sequence labeling with recurrent neural networks](http://www.cs.toronto.edu/~graves/preprint.pdf)\n         - [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)\n     '''\n     def __init__(self, output_dim,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cb4f93913eb871a5e234db0c31f885daff87ecdf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 116 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -67,7 +67,7 @@ def _obtain_input_shape(input_shape, default_size, min_size, dim_ordering, inclu\n             if input_shape is not None:\n                 if len(input_shape) != 3:\n                     raise ValueError('`input_shape` must be a tuple of three integers.')\n-                if input_shape[1] != 3:\n+                if input_shape[0] != 3:\n                     raise ValueError('The input must have 3 channels; got '\n                                      '`input_shape=' + str(input_shape) + '`')\n                 if ((input_shape[1] is not None and input_shape[1] < min_size) or\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5430844453f5153f16dbd9d762d6a5a4106ba23f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 175 | Lines Deleted: 52 | Files Changed: 2 | Hunks: 28 | Methods Changed: 13 | Complexity Δ (Sum/Max): 9/10 | Churn Δ: 227 | Churn Cumulative: 1827 | Contributors (this commit): 20 | Commits (past 90d): 6 | Contributors (cumulative): 24 | DMM Complexity: 0.26\n\nDIFF:\n@@ -12,6 +12,7 @@ import scipy.ndimage as ndi\n from six.moves import range\n import os\n import threading\n+import warnings\n \n from .. import backend as K\n \n@@ -59,7 +60,7 @@ def random_shear(x, intensity, row_index=1, col_index=2, channel_index=0,\n def random_zoom(x, zoom_range, row_index=1, col_index=2, channel_index=0,\n                 fill_mode='nearest', cval=0.):\n     if len(zoom_range) != 2:\n-        raise Exception('zoom_range should be a tuple or list of two floats. '\n+        raise ValueError('zoom_range should be a tuple or list of two floats. '\n                          'Received arg: ', zoom_range)\n \n     if zoom_range[0] == 1 and zoom_range[1] == 1:\n@@ -120,8 +121,19 @@ def flip_axis(x, axis):\n \n def array_to_img(x, dim_ordering='default', scale=True):\n     from PIL import Image\n+    x = np.asarray(x)\n+    if x.ndim != 3:\n+        raise ValueError('Expected image array to have rank 3 (single image). '\n+                         'Got array with shape:', x.shape)\n+\n     if dim_ordering == 'default':\n         dim_ordering = K.image_dim_ordering()\n+    if dim_ordering not in {'th', 'tf'}:\n+        raise ValueError('Invalid dim_ordering:', dim_ordering)\n+\n+    # Original Numpy array x has format (height, width, channel)\n+    # or (channel, height, width)\n+    # but target PIL image has format (width, height, channel)\n     if dim_ordering == 'th':\n         x = x.transpose(1, 2, 0)\n     if scale:\n@@ -137,15 +149,17 @@ def array_to_img(x, dim_ordering='default', scale=True):\n         # grayscale\n         return Image.fromarray(x[:, :, 0].astype('uint8'), 'L')\n     else:\n-        raise Exception('Unsupported channel number: ', x.shape[2])\n+        raise ValueError('Unsupported channel number: ', x.shape[2])\n \n \n def img_to_array(img, dim_ordering='default'):\n     if dim_ordering == 'default':\n         dim_ordering = K.image_dim_ordering()\n-    if dim_ordering not in ['th', 'tf']:\n-        raise Exception('Unknown dim_ordering: ', dim_ordering)\n-    # image has dim_ordering (height, width, channel)\n+    if dim_ordering not in {'th', 'tf'}:\n+        raise ValueError('Unknown dim_ordering: ', dim_ordering)\n+    # Numpy array x has format (height, width, channel)\n+    # or (channel, height, width)\n+    # but original PIL image has format (width, height, channel)\n     x = np.asarray(img, dtype='float32')\n     if len(x.shape) == 3:\n         if dim_ordering == 'th':\n@@ -156,7 +170,7 @@ def img_to_array(img, dim_ordering='default'):\n         else:\n             x = x.reshape((x.shape[0], x.shape[1], 1))\n     else:\n-        raise Exception('Unsupported image shape: ', x.shape)\n+        raise ValueError('Unsupported image shape: ', x.shape)\n     return x\n \n \n@@ -211,8 +225,8 @@ class ImageDataGenerator(object):\n         horizontal_flip: whether to randomly flip images horizontally.\n         vertical_flip: whether to randomly flip images vertically.\n         rescale: rescaling factor. If None or 0, no rescaling is applied,\n-            otherwise we multiply the data by the value provided (before applying\n-            any other transformation).\n+            otherwise we multiply the data by the value provided\n+            (before applying any other transformation).\n         dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n             (the depth) is at index 1, in 'tf' mode it is at index 3.\n             It defaults to the `image_dim_ordering` value found in your\n@@ -246,7 +260,7 @@ class ImageDataGenerator(object):\n         self.rescale = rescale\n \n         if dim_ordering not in {'tf', 'th'}:\n-            raise Exception('dim_ordering should be \"tf\" (channel after row and '\n+            raise ValueError('dim_ordering should be \"tf\" (channel after row and '\n                              'column) or \"th\" (channel before row and column). '\n                              'Received arg: ', dim_ordering)\n         self.dim_ordering = dim_ordering\n@@ -264,7 +278,7 @@ class ImageDataGenerator(object):\n         elif len(zoom_range) == 2:\n             self.zoom_range = [zoom_range[0], zoom_range[1]]\n         else:\n-            raise Exception('zoom_range should be a float or '\n+            raise ValueError('zoom_range should be a float or '\n                              'a tuple or list of two floats. '\n                              'Received arg: ', zoom_range)\n \n@@ -300,15 +314,31 @@ class ImageDataGenerator(object):\n             x /= (np.std(x, axis=img_channel_index, keepdims=True) + 1e-7)\n \n         if self.featurewise_center:\n+            if self.mean is not None:\n                 x -= self.mean\n+            else:\n+                warnings.warn('This ImageDataGenerator specifies '\n+                              '`featurewise_center`, but it hasn\\'t'\n+                              'been fit on any training data. Fit it '\n+                              'first by calling `.fit(numpy_data)`.')\n         if self.featurewise_std_normalization:\n+            if self.std is not None:\n                 x /= (self.std + 1e-7)\n-\n+            else:\n+                warnings.warn('This ImageDataGenerator specifies '\n+                              '`featurewise_std_normalization`, but it hasn\\'t'\n+                              'been fit on any training data. Fit it '\n+                              'first by calling `.fit(numpy_data)`.')\n         if self.zca_whitening:\n+            if self.principal_components is not None:\n                 flatx = np.reshape(x, (x.size))\n                 whitex = np.dot(flatx, self.principal_components)\n                 x = np.reshape(whitex, (x.shape[0], x.shape[1], x.shape[2]))\n-\n+            else:\n+                warnings.warn('This ImageDataGenerator specifies '\n+                              '`zca_whitening`, but it hasn\\'t'\n+                              'been fit on any training data. Fit it '\n+                              'first by calling `.fit(numpy_data)`.')\n         return x\n \n     def random_transform(self, x):\n@@ -384,12 +414,28 @@ class ImageDataGenerator(object):\n         and zca_whitening.\n \n         # Arguments\n-            X: Numpy array, the data to fit on.\n-            augment: whether to fit on randomly augmented samples\n-            rounds: if `augment`,\n+            X: Numpy array, the data to fit on. Should have rank 4.\n+                In case of grayscale data,\n+                the channels axis should have value 1, and in case\n+                of RGB data, it should have value 3.\n+            augment: Whether to fit on randomly augmented samples\n+            rounds: If `augment`,\n                 how many augmentation passes to do over the data\n             seed: random seed.\n         '''\n+        X = np.asarray(X)\n+        if X.ndim != 4:\n+            raise ValueError('Input to `.fit()` should have rank 4. '\n+                             'Got array with shape: ' + str(X.shape))\n+        if X.shape[self.channel_index] not in {1, 3}:\n+            raise ValueError(\n+                'Expected input to be images (as Numpy array) '\n+                'following the dimension ordering convention \"' + self.dim_ordering + '\" '\n+                '(channels on axis ' + str(self.channel_index) + '), i.e. expected '\n+                'either 1 or 3 channels on axis ' + str(self.channel_index) + '. '\n+                'However, it was passed an array with shape ' + str(X.shape) +\n+                ' (' + str(X.shape[self.channel_index]) + ' channels).')\n+\n         if seed is not None:\n             np.random.seed(seed)\n \n@@ -402,12 +448,18 @@ class ImageDataGenerator(object):\n             X = aX\n \n         if self.featurewise_center:\n-            self.mean = np.mean(X, axis=0)\n+            self.mean = np.mean(X, axis=(0, self.row_index, self.col_index))\n+            broadcast_shape = [1, 1, 1]\n+            broadcast_shape[self.channel_index - 1] = X.shape[self.channel_index]\n+            self.mean = np.reshape(self.mean, broadcast_shape)\n             X -= self.mean\n \n         if self.featurewise_std_normalization:\n-            self.std = np.std(X, axis=0)\n-            X /= (self.std + 1e-7)\n+            self.std = np.std(X, axis=(0, self.row_index, self.col_index))\n+            broadcast_shape = [1, 1, 1]\n+            broadcast_shape[self.channel_index - 1] = X.shape[self.channel_index]\n+            self.std = np.reshape(self.std, broadcast_shape)\n+            X /= (self.std + K.epsilon())\n \n         if self.zca_whitening:\n             flatX = np.reshape(X, (X.shape[0], X.shape[1] * X.shape[2] * X.shape[3]))\n@@ -468,13 +520,25 @@ class NumpyArrayIterator(Iterator):\n                  dim_ordering='default',\n                  save_to_dir=None, save_prefix='', save_format='jpeg'):\n         if y is not None and len(X) != len(y):\n-            raise Exception('X (images tensor) and y (labels) '\n+            raise ValueError('X (images tensor) and y (labels) '\n                              'should have the same length. '\n                              'Found: X.shape = %s, y.shape = %s' % (np.asarray(X).shape, np.asarray(y).shape))\n         if dim_ordering == 'default':\n             dim_ordering = K.image_dim_ordering()\n-        self.X = X\n-        self.y = y\n+        self.X = np.asarray(X)\n+        if self.X.ndim != 4:\n+            raise ValueError('Input data in `NumpyArrayIterator` '\n+                             'should have rank 4. You passed an array '\n+                             'with shape', self.X.shape)\n+        channels_axis = 3 if dim_ordering == 'tf' else 1\n+        if self.X.shape[channels_axis] not in {1, 3}:\n+            raise ValueError('NumpyArrayIterator is set to use the '\n+                             'dimension ordering convention \"' + dim_ordering + '\" '\n+                             '(channels on axis ' + str(channels_axis) + '), i.e. expected '\n+                             'either 1 or 3 channels on axis ' + str(channels_axis) + '. '\n+                             'However, it was passed an array with shape ' + str(self.X.shape) +\n+                             ' (' + str(self.X.shape[channels_axis]) + ' channels).')\n+        self.y = np.asarray(y)\n         self.image_data_generator = image_data_generator\n         self.dim_ordering = dim_ordering\n         self.save_to_dir = save_to_dir\n@@ -600,7 +664,9 @@ class DirectoryIterator(Iterator):\n         # build batch of image data\n         for i, j in enumerate(index_array):\n             fname = self.filenames[j]\n-            img = load_img(os.path.join(self.directory, fname), grayscale=grayscale, target_size=self.target_size)\n+            img = load_img(os.path.join(self.directory, fname),\n+                           grayscale=grayscale,\n+                           target_size=self.target_size)\n             x = img_to_array(img, dim_ordering=self.dim_ordering)\n             x = self.image_data_generator.random_transform(x)\n             x = self.image_data_generator.standardize(x)\n\n@@ -1,5 +1,5 @@\n import pytest\n-from keras.preprocessing.image import *\n+from keras.preprocessing import image\n from PIL import Image\n import numpy as np\n import os\n@@ -33,10 +33,10 @@ class TestImage:\n         for test_images in self.all_test_images:\n             img_list = []\n             for im in test_images:\n-                img_list.append(img_to_array(im)[None, ...])\n+                img_list.append(image.img_to_array(im)[None, ...])\n \n             images = np.vstack(img_list)\n-            generator = ImageDataGenerator(\n+            generator = image.ImageDataGenerator(\n                 featurewise_center=True,\n                 samplewise_center=True,\n                 featurewise_std_normalization=True,\n@@ -61,34 +61,91 @@ class TestImage:\n                 break\n             shutil.rmtree(tmp_folder)\n \n-    def test_img_flip(self):\n-        x = np.array(range(4)).reshape([1, 1, 2, 2])\n-        assert (flip_axis(x, 0) == x).all()\n-        assert (flip_axis(x, 1) == x).all()\n-        assert (flip_axis(x, 2) == [[[[2, 3], [0, 1]]]]).all()\n-        assert (flip_axis(x, 3) == [[[[1, 0], [3, 2]]]]).all()\n+    def test_image_data_generator_invalid_data(self):\n+        generator = image.ImageDataGenerator(\n+            featurewise_center=True,\n+            samplewise_center=True,\n+            featurewise_std_normalization=True,\n+            samplewise_std_normalization=True,\n+            zca_whitening=True,\n+            dim_ordering='tf')\n+        # Test fit with invalid data\n+        with pytest.raises(ValueError):\n+            x = np.random.random((3, 10, 10))\n+            generator.fit(x)\n+        with pytest.raises(ValueError):\n+            x = np.random.random((32, 3, 10, 10))\n+            generator.fit(x)\n+        with pytest.raises(ValueError):\n+            x = np.random.random((32, 10, 10, 4))\n+            generator.fit(x)\n+        # Test flow with invalid data\n+        with pytest.raises(ValueError):\n+            x = np.random.random((32, 10, 10, 4))\n+            generator.flow(np.arange(x.shape[0]))\n+        with pytest.raises(ValueError):\n+            x = np.random.random((32, 10, 10))\n+            generator.flow(np.arange(x.shape[0]))\n+        with pytest.raises(ValueError):\n+            x = np.random.random((32, 3, 10, 10))\n+            generator.flow(np.arange(x.shape[0]))\n \n-        dim_ordering_and_col_index = (('tf', 2), ('th', 3))\n-        for dim_ordering, col_index in dim_ordering_and_col_index:\n-            image_generator_th = ImageDataGenerator(\n-                featurewise_center=False,\n-                samplewise_center=False,\n-                featurewise_std_normalization=False,\n-                samplewise_std_normalization=False,\n-                zca_whitening=False,\n-                rotation_range=0,\n-                width_shift_range=0,\n-                height_shift_range=0,\n-                shear_range=0,\n-                zoom_range=0,\n-                channel_shift_range=0,\n-                horizontal_flip=True,\n-                vertical_flip=False,\n-                dim_ordering=dim_ordering).flow(x, [1])\n-            for i in range(10):\n-                potentially_flipped_x, _ = next(image_generator_th)\n-                assert ((potentially_flipped_x == x).all() or\n-                        (potentially_flipped_x == flip_axis(x, col_index)).all())\n+    def test_image_data_generator_fit(self):\n+        generator = image.ImageDataGenerator(\n+            featurewise_center=True,\n+            samplewise_center=True,\n+            featurewise_std_normalization=True,\n+            samplewise_std_normalization=True,\n+            zca_whitening=True,\n+            dim_ordering='tf')\n+        # Test grayscale\n+        x = np.random.random((32, 10, 10, 1))\n+        generator.fit(x)\n+        # Test RBG\n+        x = np.random.random((32, 10, 10, 3))\n+        generator.fit(x)\n+        generator = image.ImageDataGenerator(\n+            featurewise_center=True,\n+            samplewise_center=True,\n+            featurewise_std_normalization=True,\n+            samplewise_std_normalization=True,\n+            zca_whitening=True,\n+            dim_ordering='th')\n+        # Test grayscale\n+        x = np.random.random((32, 1, 10, 10))\n+        generator.fit(x)\n+        # Test RBG\n+        x = np.random.random((32, 3, 10, 10))\n+        generator.fit(x)\n+\n+    def test_img_utils(self):\n+        height, width = 10, 8\n+\n+        # Test th dim ordering\n+        x = np.random.random((3, height, width))\n+        img = image.array_to_img(x, dim_ordering='th')\n+        assert img.size == (width, height)\n+        x = image.img_to_array(img, dim_ordering='th')\n+        assert x.shape == (3, height, width)\n+        # Test 2D\n+        x = np.random.random((1, height, width))\n+        img = image.array_to_img(x, dim_ordering='th')\n+        assert img.size == (width, height)\n+        x = image.img_to_array(img, dim_ordering='th')\n+        assert x.shape == (1, height, width)\n+\n+        # Test tf dim ordering\n+        x = np.random.random((height, width, 3))\n+        img = image.array_to_img(x, dim_ordering='tf')\n+        assert img.size == (width, height)\n+        x = image.img_to_array(img, dim_ordering='tf')\n+        assert x.shape == (height, width, 3)\n+        # Test 2D\n+        x = np.random.random((height, width, 1))\n+        img = image.array_to_img(x, dim_ordering='tf')\n+        assert img.size == (width, height)\n+        x = image.img_to_array(img, dim_ordering='tf')\n+        assert x.shape == (height, width, 1)\n \n \n if __name__ == '__main__':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#90c4895a7a5b8246b8f3927a6a8304d660bfa5fd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 37 | Contributors (this commit): 4 | Commits (past 90d): 6 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -225,7 +225,7 @@ class ConvLSTM2D(ConvRecurrent2D):\n             nb_row: Number of rows in the convolution kernel.\n             nb_col: Number of columns in the convolution kernel.\n             border_mode: 'valid' or 'same'.\n-            sub_sample: tuple of length 2. Factor by which to subsample output.\n+            subsample: tuple of length 2. Factor by which to subsample output.\n                 Also called strides elsewhere.\n             dim_ordering: 'tf' if the feature are at the last dimension or 'th'\n             stateful : Boolean (default False). If True, the last state\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fbd12f7d4436e26aa9fb78a9acdfcb5862e3486e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 17 | Files Changed: 1 | Hunks: 8 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 45 | Churn Cumulative: 3450 | Contributors (this commit): 44 | Commits (past 90d): 24 | Contributors (cumulative): 44 | DMM Complexity: 0.14285714285714285\n\nDIFF:\n@@ -1145,11 +1145,13 @@ def rnn(step_function, inputs, initial_states,\n                     time step.\n                 states: list of tensors.\n             Returns:\n-                output: tensor with shape (samples, output_dim) (no time dimension),\n+                output: tensor with shape (samples, output_dim)\n+                    (no time dimension).\n                 new_states: list of tensors, same length and shapes\n                     as 'states'. The first state in the list must be the\n                     output tensor at the previous timestep.\n-        initial_states: tensor with shape (samples, output_dim) (no time dimension),\n+        initial_states: tensor with shape (samples, output_dim)\n+            (no time dimension),\n             containing the initial values for the states used in\n             the step function.\n         go_backwards: boolean. If True, do the iteration over\n@@ -1173,7 +1175,8 @@ def rnn(step_function, inputs, initial_states,\n             the step function, of shape (samples, ...).\n     '''\n     ndim = len(inputs.get_shape())\n-    assert ndim >= 3, 'Input should be at least 3D.'\n+    if ndim < 3:\n+        raise ValueError('Input should be at least 3D.')\n     axes = [1, 0] + list(range(2, ndim))\n     inputs = tf.transpose(inputs, (axes))\n \n@@ -1189,8 +1192,8 @@ def rnn(step_function, inputs, initial_states,\n \n     if unroll:\n         if not inputs.get_shape()[0]:\n-            raise Exception('Unrolling requires a fixed number of timesteps.')\n-\n+            raise ValueError('Unrolling requires a '\n+                             'fixed number of timesteps.')\n         states = initial_states\n         successive_states = []\n         successive_outputs = []\n@@ -1207,13 +1210,18 @@ def rnn(step_function, inputs, initial_states,\n             for input, mask_t in zip(input_list, mask_list):\n                 output, new_states = step_function(input, states + constants)\n \n-                # tf.select needs its condition tensor to be the same shape as its two\n-                # result tensors, but in our case the condition (mask) tensor is\n-                # (nsamples, 1), and A and B are (nsamples, ndimensions). So we need to\n-                # broadcast the mask to match the shape of A and B. That's what the\n-                # tile call does, is just repeat the mask along its second dimension\n-                # ndimensions times.\n-                tiled_mask_t = tf.tile(mask_t, tf.pack([1, tf.shape(output)[1]]))\n+                # tf.select needs its condition tensor\n+                # to be the same shape as its two\n+                # result tensors, but in our case\n+                # the condition (mask) tensor is\n+                # (nsamples, 1), and A and B are (nsamples, ndimensions).\n+                # So we need to\n+                # broadcast the mask to match the shape of A and B.\n+                # That's what the tile call does,\n+                # it just repeats the mask along its second dimension\n+                # n times.\n+                tiled_mask_t = tf.tile(mask_t,\n+                                       tf.pack([1, tf.shape(output)[1]]))\n \n                 if len(successive_outputs) == 0:\n                     prev_output = zeros_like(output)\n@@ -1225,9 +1233,11 @@ def rnn(step_function, inputs, initial_states,\n                 return_states = []\n                 for state, new_state in zip(states, new_states):\n                     # (see earlier comment for tile explanation)\n-                    tiled_mask_t = tf.tile(mask_t, tf.pack([1, tf.shape(new_state)[1]]))\n-                    return_states.append(tf.select(tiled_mask_t, new_state, state))\n-\n+                    tiled_mask_t = tf.tile(mask_t,\n+                                           tf.pack([1, tf.shape(new_state)[1]]))\n+                    return_states.append(tf.select(tiled_mask_t,\n+                                                   new_state,\n+                                                   state))\n                 states = return_states\n                 successive_outputs.append(output)\n                 successive_states.append(states)\n@@ -1270,7 +1280,7 @@ def rnn(step_function, inputs, initial_states,\n                                  'as its first state at time `t` '\n                                  'the output at time `t-1`).')\n             if go_backwards:\n-                mask = tf.reverse(mask, [True] + [False] * (ndim - 2))\n+                mask = tf.reverse(mask, [True] + [False] * (ndim - 1))\n \n             mask_ta = tensor_array_ops.TensorArray(\n                 dtype=tf.bool,\n@@ -1286,7 +1296,8 @@ def rnn(step_function, inputs, initial_states,\n                                                    tuple(constants))\n                 for state, new_state in zip(states, new_states):\n                     new_state.set_shape(state.get_shape())\n-                tiled_mask_t = tf.tile(mask_t, tf.pack([1, tf.shape(output)[1]]))\n+                tiled_mask_t = tf.tile(mask_t,\n+                                       tf.pack([1, tf.shape(output)[1]]))\n                 output = tf.select(tiled_mask_t, output, states[0])\n                 new_states = [tf.select(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\n                 output_ta_t = output_ta_t.write(time, output)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#93b7dd99158ddbe99a299606d55f495629556c90", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 2523 | Contributors (this commit): 33 | Commits (past 90d): 18 | Contributors (cumulative): 39 | DMM Complexity: 0.5\n\nDIFF:\n@@ -553,6 +553,7 @@ class TensorBoard(Callback):\n             summary_value.tag = name\n             self.writer.add_summary(summary, epoch)\n         self.writer.flush()\n+        self.writer.close()\n \n \n class ReduceLROnPlateau(Callback):\n\n@@ -190,10 +190,10 @@ def test_ReduceLROnPlateau():\n                     reason=\"Requires tensorflow backend\")\n def test_TensorBoard():\n     import shutil\n-    import tensorflow as tf\n-    import keras.backend.tensorflow_backend as KTF\n+\n     filepath = './logs'\n-    (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=train_samples,\n+    (X_train, y_train), (X_test, y_test) = get_test_data(\n+        nb_train=train_samples,\n         nb_test=test_samples,\n         input_shape=(input_dim,),\n         classification=True,\n@@ -209,9 +209,11 @@ def test_TensorBoard():\n         i = 0\n         while 1:\n             if train:\n-                yield (X_train[i * batch_size: (i + 1) * batch_size], y_train[i * batch_size: (i + 1) * batch_size])\n+                yield (X_train[i * batch_size: (i + 1) * batch_size],\n+                       y_train[i * batch_size: (i + 1) * batch_size])\n             else:\n-                yield (X_test[i * batch_size: (i + 1) * batch_size], y_test[i * batch_size: (i + 1) * batch_size])\n+                yield (X_test[i * batch_size: (i + 1) * batch_size],\n+                       y_test[i * batch_size: (i + 1) * batch_size])\n             i += 1\n             i = i % max_batch_index\n \n@@ -235,7 +237,7 @@ def test_TensorBoard():\n \n     # fit with validation data\n     model.fit(X_train, y_train, batch_size=batch_size,\n-              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=2)\n+              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=3)\n \n     # fit with validation data and accuracy\n     model.fit(X_train, y_train, batch_size=batch_size,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ad5e29a2b79c62e296e954813db357f87a00d970", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 1944 | Contributors (this commit): 34 | Commits (past 90d): 13 | Contributors (cumulative): 34 | DMM Complexity: 1.0\n\nDIFF:\n@@ -401,11 +401,13 @@ class RemoteMonitor(Callback):\n     def __init__(self,\n                  root='http://localhost:9000',\n                  path='/publish/epoch/end/',\n-                 field='data'):\n+                 field='data',\n+                 headers={'Accept': 'application/json', 'Content-Type': 'application/json'}):\n         super(RemoteMonitor, self).__init__()\n         self.root = root\n         self.path = path\n         self.field = field\n+        self.headers = headers\n \n     def on_epoch_end(self, epoch, logs={}):\n         import requests\n@@ -415,7 +417,8 @@ class RemoteMonitor(Callback):\n             send[k] = v\n         try:\n             requests.post(self.root + self.path,\n-                          {self.field: json.dumps(send)})\n+                          {self.field: json.dumps(send)},\n+                          headers=self.headers)\n         except:\n             print('Warning: could not reach RemoteMonitor '\n                   'root server at ' + str(self.root))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1fd2108bcfa906ed61accaeca5b9238b96afad07", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 7949 | Contributors (this commit): 53 | Commits (past 90d): 11 | Contributors (cumulative): 53 | DMM Complexity: None\n\nDIFF:\n@@ -151,7 +151,7 @@ def load_model(filepath, custom_objects={}):\n         return model\n     training_config = json.loads(training_config.decode('utf-8'))\n     optimizer_config = training_config['optimizer_config']\n-    optimizer = optimizer_from_config(optimizer_config)\n+    optimizer = optimizer_from_config(optimizer_config, custom_objects=custom_objects)\n \n     # recover loss functions and metrics\n     loss = deserialize(training_config['loss'])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e1208f5b9f0897c6d975d3dca67ad2188b021da2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 8 | Churn Cumulative: 1357 | Contributors (this commit): 19 | Commits (past 90d): 5 | Contributors (cumulative): 19 | DMM Complexity: 0.0\n\nDIFF:\n@@ -227,6 +227,10 @@ class ImageDataGenerator(object):\n         rescale: rescaling factor. If None or 0, no rescaling is applied,\n             otherwise we multiply the data by the value provided\n             (before applying any other transformation).\n+        preprocessing_function: function that will be implied on each input.\n+            The function will run before any other modification on it.\n+            The function should take one argument: one image (Numpy tensor with rank 3),\n+            and should output a Numpy tensor with the same shape.\n         dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n             (the depth) is at index 1, in 'tf' mode it is at index 3.\n             It defaults to the `image_dim_ordering` value found in your\n@@ -250,6 +254,7 @@ class ImageDataGenerator(object):\n                  horizontal_flip=False,\n                  vertical_flip=False,\n                  rescale=None,\n+                 preprocessing_function=None,\n                  dim_ordering='default'):\n         if dim_ordering == 'default':\n             dim_ordering = K.image_dim_ordering()\n@@ -258,6 +263,7 @@ class ImageDataGenerator(object):\n         self.std = None\n         self.principal_components = None\n         self.rescale = rescale\n+        self.preprocessing_function = preprocessing_function\n \n         if dim_ordering not in {'tf', 'th'}:\n             raise ValueError('dim_ordering should be \"tf\" (channel after row and '\n@@ -304,6 +310,8 @@ class ImageDataGenerator(object):\n             save_to_dir=save_to_dir, save_prefix=save_prefix, save_format=save_format)\n \n     def standardize(self, x):\n+        if self.preprocessing_function:\n+            x = self.preprocessing_function(x)\n         if self.rescale:\n             x *= self.rescale\n         # x is a single image, so it doesn't have image number at index 0\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#52e2f3ed640aadafa0df8ec6cfd783584fa69ada", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 9 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 23 | Churn Cumulative: 401 | Contributors (this commit): 8 | Commits (past 90d): 1 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -1,14 +1,10 @@\n '''Train a simple deep CNN on the CIFAR10 small images dataset.\n \n-GPU run command:\n+GPU run command with Theano backend (with TensorFlow, the GPU is automatically used):\n     THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python cifar10_cnn.py\n \n It gets down to 0.65 test logloss in 25 epochs, and down to 0.55 after 50 epochs.\n (it's still underfitting at that point, though).\n-\n-Note: the data was pickled with Python 2, and some encoding issues might prevent you\n-from loading it in Python 3. You might have to load it in Python 2,\n-save it in a different format, load it in Python 3 and repickle it.\n '''\n \n from __future__ import print_function\n@@ -27,16 +23,16 @@ data_augmentation = True\n \n # input image dimensions\n img_rows, img_cols = 32, 32\n-# the CIFAR10 images are RGB\n+# The CIFAR10 images are RGB.\n img_channels = 3\n \n-# the data, shuffled and split between train and test sets\n+# The data, shuffled and split between train and test sets:\n (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n print('X_train shape:', X_train.shape)\n print(X_train.shape[0], 'train samples')\n print(X_test.shape[0], 'test samples')\n \n-# convert class vectors to binary class matrices\n+# Convert class vectors to binary class matrices.\n Y_train = np_utils.to_categorical(y_train, nb_classes)\n Y_test = np_utils.to_categorical(y_test, nb_classes)\n \n@@ -64,7 +60,7 @@ model.add(Dropout(0.5))\n model.add(Dense(nb_classes))\n model.add(Activation('softmax'))\n \n-# let's train the model using SGD + momentum (how original).\n+# Let's train the model using SGD + momentum:\n sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n model.compile(loss='categorical_crossentropy',\n               optimizer=sgd,\n@@ -84,8 +80,7 @@ if not data_augmentation:\n               shuffle=True)\n else:\n     print('Using real-time data augmentation.')\n-\n-    # this will do preprocessing and realtime data augmentation\n+    # This will do preprocessing and realtime data augmentation:\n     datagen = ImageDataGenerator(\n         featurewise_center=False,  # set input mean to 0 over the dataset\n         samplewise_center=False,  # set each sample mean to 0\n@@ -98,11 +93,11 @@ else:\n         horizontal_flip=True,  # randomly flip images\n         vertical_flip=False)  # randomly flip images\n \n-    # compute quantities required for featurewise normalization\n-    # (std, mean, and principal components if ZCA whitening is applied)\n+    # Compute quantities required for featurewise normalization\n+    # (std, mean, and principal components if ZCA whitening is applied).\n     datagen.fit(X_train)\n \n-    # fit the model on the batches generated by datagen.flow()\n+    # Fit the model on the batches generated by datagen.flow().\n     model.fit_generator(datagen.flow(X_train, Y_train,\n                         batch_size=batch_size),\n                         samples_per_epoch=X_train.shape[0],\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4491212da4430181cd4d35cee5d341de87b3ac0d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1111 | Contributors (this commit): 19 | Commits (past 90d): 6 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -1,4 +1,3 @@\n-import sys\n import pytest\n from numpy.testing import assert_allclose\n import numpy as np\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#825adad18d1cd14d8270c6017f805bf3fa15f4c3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 2894 | Contributors (this commit): 43 | Commits (past 90d): 14 | Contributors (cumulative): 43 | DMM Complexity: None\n\nDIFF:\n@@ -1380,6 +1380,7 @@ def deconv2d(x, kernel, output_shape, strides=(1, 1),\n     th_border_mode = _preprocess_border_mode(border_mode)\n     np_kernel = kernel.eval()\n     filter_shape = _preprocess_conv2d_filter_shape(dim_ordering, filter_shape)\n+    filter_shape = tuple(filter_shape[i] for i in (1, 0, 2, 3))\n \n     op = T.nnet.abstract_conv.AbstractConv2d_gradInputs(imshp=output_shape,\n                                                         kshp=filter_shape,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#302eef7bad0c8e61b23f55a3af762b86edf2c80c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 53 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 10/5 | Churn Δ: 53 | Churn Cumulative: 7508 | Contributors (this commit): 62 | Commits (past 90d): 45 | Contributors (cumulative): 108 | DMM Complexity: 1.0\n\nDIFF:\n@@ -845,6 +845,25 @@ def repeat(x, n):\n     return tf.tile(x, pattern)\n \n \n+def arange(start, stop=None, step=1, dtype='int32'):\n+    '''Creates a 1-D tensor containing a sequence of integers.\n+\n+    The function arguments use the same convention as\n+    Theano's arange: if only one argument is provided,\n+    it is in fact the \"stop\" argument.\n+\n+    The default type of the returned tensor is 'int32' to\n+    match TensorFlow's default.\n+    '''\n+    # Match the behavior of numpy and Theano by returning an empty seqence.\n+    if stop is None and start < 0:\n+        start = 0\n+    result = tf.range(start, limit=stop, delta=step, name='arange')\n+    if dtype != 'int32':\n+        result = cast(result, dtype)\n+    return result\n+\n+\n def tile(x, n):\n     if not hasattr(n, 'shape') and not hasattr(n, '__len__') and not hasattr(n, '_shape'):\n         n = [n]\n\n@@ -550,6 +550,19 @@ def repeat(x, n):\n     return T.extra_ops.repeat(x, n, axis=1)\n \n \n+def arange(start, stop=None, step=1, dtype='int32'):\n+    '''Creates a 1-D tensor containing a sequence of integers.\n+\n+    The function arguments use the same convention as\n+    Theano's arange: if only one argument is provided,\n+    it is in fact the \"stop\" argument.\n+\n+    The default type of the returned tensor is 'int32' to\n+    match TensorFlow's default.\n+    '''\n+    return T.arange(start, stop=stop, step=step, dtype=dtype)\n+\n+\n def tile(x, n):\n     return T.tile(x, n)\n \n\n@@ -910,6 +910,27 @@ class TestBackend(object):\n             assert p1 < p2\n             assert 9e-38 < p2 <= 1e-37\n \n+    def test_arange(self):\n+        for test_value in (-20, 0, 1, 10):\n+            t_a = KTF.arange(test_value)\n+            a = KTF.eval(t_a)\n+            assert(np.array_equal(a, np.arange(test_value)))\n+            t_b = KTH.arange(test_value)\n+            b = KTH.eval(t_b)\n+            assert(np.array_equal(b, np.arange(test_value)))\n+            assert(np.array_equal(a, b))\n+            assert(KTF.dtype(t_a) == KTH.dtype(t_b), 'default dtypes are equal')\n+        for start, stop, step in ((0, 5, 1), (-5, 5, 2), (0, 1, 2)):\n+            a = KTF.eval(KTF.arange(start, stop, step))\n+            assert(np.array_equal(a, np.arange(start, stop, step)))\n+            b = KTH.eval(KTH.arange(start, stop, step))\n+            assert(np.array_equal(b, np.arange(start, stop, step)))\n+            assert(np.array_equal(a, b))\n+        for dtype in ('int32', 'int64', 'float32', 'float64'):\n+            for backend in (KTF, KTH):\n+                t = backend.arange(10, dtype=dtype)\n+                assert(backend.dtype(t) == dtype)\n+\n \n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#08566f22c725cc5b4435a534caefc1476e930552", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 1847 | Contributors (this commit): 21 | Commits (past 90d): 8 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -435,12 +435,12 @@ class ImageDataGenerator(object):\n         if X.ndim != 4:\n             raise ValueError('Input to `.fit()` should have rank 4. '\n                              'Got array with shape: ' + str(X.shape))\n-        if X.shape[self.channel_index] not in {1, 3}:\n+        if X.shape[self.channel_index] not in {1, 3, 4}:\n             raise ValueError(\n                 'Expected input to be images (as Numpy array) '\n                 'following the dimension ordering convention \"' + self.dim_ordering + '\" '\n                 '(channels on axis ' + str(self.channel_index) + '), i.e. expected '\n-                'either 1 or 3 channels on axis ' + str(self.channel_index) + '. '\n+                'either 1, 3 or 4 channels on axis ' + str(self.channel_index) + '. '\n                 'However, it was passed an array with shape ' + str(X.shape) +\n                 ' (' + str(X.shape[self.channel_index]) + ' channels).')\n \n@@ -539,11 +539,11 @@ class NumpyArrayIterator(Iterator):\n                              'should have rank 4. You passed an array '\n                              'with shape', self.X.shape)\n         channels_axis = 3 if dim_ordering == 'tf' else 1\n-        if self.X.shape[channels_axis] not in {1, 3}:\n+        if self.X.shape[channels_axis] not in {1, 3, 4}:\n             raise ValueError('NumpyArrayIterator is set to use the '\n                              'dimension ordering convention \"' + dim_ordering + '\" '\n                              '(channels on axis ' + str(channels_axis) + '), i.e. expected '\n-                             'either 1 or 3 channels on axis ' + str(channels_axis) + '. '\n+                             'either 1, 3 or 4 channels on axis ' + str(channels_axis) + '. '\n                              'However, it was passed an array with shape ' + str(self.X.shape) +\n                              ' (' + str(self.X.shape[channels_axis]) + ' channels).')\n         self.y = np.asarray(y)\n\n@@ -77,11 +77,11 @@ class TestImage:\n             x = np.random.random((32, 3, 10, 10))\n             generator.fit(x)\n         with pytest.raises(ValueError):\n-            x = np.random.random((32, 10, 10, 4))\n+            x = np.random.random((32, 10, 10, 5))\n             generator.fit(x)\n         # Test flow with invalid data\n         with pytest.raises(ValueError):\n-            x = np.random.random((32, 10, 10, 4))\n+            x = np.random.random((32, 10, 10, 5))\n             generator.flow(np.arange(x.shape[0]))\n         with pytest.raises(ValueError):\n             x = np.random.random((32, 10, 10))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4871208f0294682de886d06ce26ec50bd792be60", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 4411 | Contributors (this commit): 30 | Commits (past 90d): 7 | Contributors (cumulative): 30 | DMM Complexity: None\n\nDIFF:\n@@ -429,7 +429,7 @@ class GRU(Recurrent):\n         dropout_U: float between 0 and 1. Fraction of the input units to drop for recurrent connections.\n \n     # References\n-        - [On the Properties of Neural Machine Translation: Encoder–Decoder Approaches](http://www.aclweb.org/anthology/W14-4012)\n+        - [On the Properties of Neural Machine Translation: Encoder-Decoder Approaches](http://www.aclweb.org/anthology/W14-4012)\n         - [Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling](http://arxiv.org/pdf/1412.3555v1.pdf)\n         - [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)\n     '''\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
