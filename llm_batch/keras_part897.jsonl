{"custom_id": "keras#dfaca0e1e8ffc14d68c81e07840049e9953db4ac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 20 | Churn Cumulative: 1772 | Contributors (this commit): 22 | Commits (past 90d): 31 | Contributors (cumulative): 22 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1109,9 +1109,23 @@ def mod(x1, x2):\n \n \n def moveaxis(x, source, destination):\n-    raise NotImplementedError(\n-        \"`moveaxis` is not supported with openvino backend\"\n-    )\n+    x = get_ov_output(x)\n+    if isinstance(source, int):\n+        source = [source]\n+    if isinstance(destination, int):\n+        destination = [destination]\n+\n+    ndim = x.get_partial_shape().rank.get_length()\n+    source = [axis if axis >= 0 else axis + ndim for axis in source]\n+    destination = [axis if axis >= 0 else axis + ndim for axis in destination]\n+\n+    axes = list(range(ndim))\n+    for src, dst in zip(source, destination):\n+        axes.remove(src)\n+        axes.insert(dst, src)\n+\n+    axes_const = ov_opset.constant(axes, Type.i32).output(0)\n+    return OpenVINOKerasTensor(ov_opset.transpose(x, axes_const).output(0))\n \n \n def nan_to_num(x, nan=0.0, posinf=None, neginf=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e19a2edc8415236dc3ba3409bda2016be2a6e6c9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 154 | Lines Deleted: 1 | Files Changed: 8 | Hunks: 18 | Methods Changed: 9 | Complexity Δ (Sum/Max): 15/4 | Churn Δ: 155 | Churn Cumulative: 3102 | Contributors (this commit): 22 | Commits (past 90d): 13 | Contributors (cumulative): 61 | DMM Complexity: 0.8260869565217391\n\nDIFF:\n@@ -17,11 +17,17 @@ from keras.src.backend.config import image_data_format as image_data_format\n from keras.src.backend.config import (\n     is_flash_attention_enabled as is_flash_attention_enabled,\n )\n+from keras.src.backend.config import max_epochs as max_epochs\n+from keras.src.backend.config import max_steps_per_epoch as max_steps_per_epoch\n from keras.src.backend.config import set_epsilon as set_epsilon\n from keras.src.backend.config import set_floatx as set_floatx\n from keras.src.backend.config import (\n     set_image_data_format as set_image_data_format,\n )\n+from keras.src.backend.config import set_max_epochs as set_max_epochs\n+from keras.src.backend.config import (\n+    set_max_steps_per_epoch as set_max_steps_per_epoch,\n+)\n from keras.src.dtype_policies.dtype_policy import dtype_policy as dtype_policy\n from keras.src.dtype_policies.dtype_policy import (\n     set_dtype_policy as set_dtype_policy,\n\n@@ -17,11 +17,17 @@ from keras.src.backend.config import image_data_format as image_data_format\n from keras.src.backend.config import (\n     is_flash_attention_enabled as is_flash_attention_enabled,\n )\n+from keras.src.backend.config import max_epochs as max_epochs\n+from keras.src.backend.config import max_steps_per_epoch as max_steps_per_epoch\n from keras.src.backend.config import set_epsilon as set_epsilon\n from keras.src.backend.config import set_floatx as set_floatx\n from keras.src.backend.config import (\n     set_image_data_format as set_image_data_format,\n )\n+from keras.src.backend.config import set_max_epochs as set_max_epochs\n+from keras.src.backend.config import (\n+    set_max_steps_per_epoch as set_max_steps_per_epoch,\n+)\n from keras.src.dtype_policies.dtype_policy import dtype_policy as dtype_policy\n from keras.src.dtype_policies.dtype_policy import (\n     set_dtype_policy as set_dtype_policy,\n\n@@ -15,6 +15,10 @@ _IMAGE_DATA_FORMAT = \"channels_last\"\n # Default backend: TensorFlow.\n _BACKEND = \"tensorflow\"\n \n+# Cap run duration for debugging.\n+_MAX_EPOCHS = None\n+_MAX_STEPS_PER_EPOCH = None\n+\n \n @keras_export([\"keras.config.floatx\", \"keras.backend.floatx\"])\n def floatx():\n@@ -304,7 +308,10 @@ if \"KERAS_BACKEND\" in os.environ:\n     _backend = os.environ[\"KERAS_BACKEND\"]\n     if _backend:\n         _BACKEND = _backend\n-\n+if \"KERAS_MAX_EPOCHS\" in os.environ:\n+    _MAX_EPOCHS = int(os.environ[\"KERAS_MAX_EPOCHS\"])\n+if \"KERAS_MAX_STEPS_PER_EPOCH\" in os.environ:\n+    _MAX_STEPS_PER_EPOCH = int(os.environ[\"KERAS_MAX_STEPS_PER_EPOCH\"])\n \n if _BACKEND != \"tensorflow\":\n     # If we are not running on the tensorflow backend, we should stop tensorflow\n@@ -333,3 +340,66 @@ def backend():\n \n     \"\"\"\n     return _BACKEND\n+\n+\n+@keras_export([\"keras.config.set_max_epochs\"])\n+def set_max_epochs(max_epochs):\n+    \"\"\"Limit the maximum number of epochs for any call to fit.\n+\n+    This will cap the number of epochs for any training run using `model.fit()`.\n+    This is purely for debugging, and can also be set via the `KERAS_MAX_EPOCHS`\n+    environment variable to quickly run a script without modifying its source.\n+\n+    Args:\n+        max_epochs: The integer limit on the number of epochs or `None`. If\n+            `None`, no limit is applied.\n+    \"\"\"\n+    global _MAX_EPOCHS\n+    _MAX_EPOCHS = max_epochs\n+\n+\n+@keras_export([\"keras.config.set_max_steps_per_epoch\"])\n+def set_max_steps_per_epoch(max_steps_per_epoch):\n+    \"\"\"Limit the maximum number of steps for any call to fit/evaluate/predict.\n+\n+    This will cap the number of steps for single epoch of a call to `fit()`,\n+    `evaluate()`, or `predict()`. This is purely for debugging, and can also be\n+    set via the `KERAS_MAX_STEPS_PER_EPOCH` environment variable to quickly run\n+    a scrip without modifying its source.\n+\n+    Args:\n+        max_epochs: The integer limit on the number of epochs or `None`. If\n+            `None`, no limit is applied.\n+    \"\"\"\n+    global _MAX_STEPS_PER_EPOCH\n+    _MAX_STEPS_PER_EPOCH = max_steps_per_epoch\n+\n+\n+@keras_export([\"keras.config.max_epochs\"])\n+def max_epochs():\n+    \"\"\"Get the maximum number of epochs for any call to fit.\n+\n+    Retrieves the limit on the number of epochs set by\n+    `keras.config.set_max_epochs` or the `KERAS_MAX_EPOCHS` environment\n+    variable.\n+\n+    Returns:\n+        The integer limit on the number of epochs or `None`, if no limit has\n+        been set.\n+    \"\"\"\n+    return _MAX_EPOCHS\n+\n+\n+@keras_export([\"keras.config.max_steps_per_epoch\"])\n+def max_steps_per_epoch():\n+    \"\"\"Get the maximum number of steps for any call to fit/evaluate/predict.\n+\n+    Retrieves the limit on the number of epochs set by\n+    `keras.config.set_max_steps_per_epoch` or the `KERAS_MAX_STEPS_PER_EPOCH`\n+    environment variable.\n+\n+    Args:\n+        max_epochs: The integer limit on the number of epochs or `None`. If\n+            `None`, no limit is applied.\n+    \"\"\"\n+    return _MAX_STEPS_PER_EPOCH\n\n@@ -1,5 +1,6 @@\n import collections\n import itertools\n+import warnings\n from functools import partial\n \n import jax\n@@ -9,6 +10,7 @@ from keras.src import backend\n from keras.src import callbacks as callbacks_module\n from keras.src import optimizers as optimizers_module\n from keras.src import tree\n+from keras.src.backend import config\n from keras.src.backend import distribution_lib as jax_distribution_lib\n from keras.src.distribution import distribution_lib\n from keras.src.trainers import trainer as base_trainer\n@@ -341,6 +343,11 @@ class JAXTrainer(base_trainer.Trainer):\n         validation_freq=1,\n     ):\n         self._assert_compile_called(\"fit\")\n+        # Possibly cap epochs for debugging runs.\n+        max_epochs = config.max_epochs()\n+        if max_epochs and max_epochs < epochs:\n+            warnings.warn(\"Limiting epochs to %d\" % max_epochs)\n+            epochs = max_epochs\n         # TODO: respect compiled trainable state\n         self._eval_epoch_iterator = None\n         if validation_split and validation_data is None:\n\n@@ -9,6 +9,7 @@ from keras.src import callbacks as callbacks_module\n from keras.src import metrics as metrics_module\n from keras.src import optimizers as optimizers_module\n from keras.src import tree\n+from keras.src.backend import config\n from keras.src.losses import loss as loss_module\n from keras.src.trainers import trainer as base_trainer\n from keras.src.trainers.data_adapters import array_slicing\n@@ -309,6 +310,11 @@ class TensorFlowTrainer(base_trainer.Trainer):\n         validation_freq=1,\n     ):\n         self._assert_compile_called(\"fit\")\n+        # Possibly cap epochs for debugging runs.\n+        max_epochs = config.max_epochs()\n+        if max_epochs and max_epochs < epochs:\n+            warnings.warn(\"Limiting epochs to %d\" % max_epochs)\n+            epochs = max_epochs\n         # TODO: respect compiled trainable state\n         self._eval_epoch_iterator = None\n         if validation_split and validation_data is None:\n\n@@ -8,6 +8,7 @@ from keras.src import backend\n from keras.src import callbacks as callbacks_module\n from keras.src import optimizers as optimizers_module\n from keras.src import tree\n+from keras.src.backend import config\n from keras.src.trainers import trainer as base_trainer\n from keras.src.trainers.data_adapters import array_slicing\n from keras.src.trainers.data_adapters import data_adapter_utils\n@@ -187,6 +188,11 @@ class TorchTrainer(base_trainer.Trainer):\n             raise ValueError(\n                 \"You must call `compile()` before calling `fit()`.\"\n             )\n+        # Possibly cap epochs for debugging runs.\n+        max_epochs = config.max_epochs()\n+        if max_epochs and max_epochs < epochs:\n+            warnings.warn(\"Limiting epochs to %d\" % max_epochs)\n+            epochs = max_epochs\n \n         # TODO: respect compiled trainable state\n         self._eval_epoch_iterator = None\n\n@@ -42,6 +42,7 @@ or until there is no data\n import contextlib\n import warnings\n \n+from keras.src.backend import config\n from keras.src.trainers import data_adapters\n \n \n@@ -57,6 +58,14 @@ class EpochIterator:\n         class_weight=None,\n         steps_per_execution=1,\n     ):\n+        # Possibly cap steps_per_epoch for debugging runs.\n+        max_steps_per_epoch = config.max_steps_per_epoch()\n+        if max_steps_per_epoch:\n+            if not steps_per_epoch or max_steps_per_epoch < steps_per_epoch:\n+                warnings.warn(\n+                    \"Limiting steps_per_epoch to %d\" % max_steps_per_epoch\n+                )\n+                steps_per_epoch = max_steps_per_epoch\n         self.steps_per_epoch = steps_per_epoch\n         self.steps_per_execution = steps_per_execution\n         self._current_iterator = None\n\n@@ -14,6 +14,7 @@ from keras.src import models\n from keras.src import ops\n from keras.src import optimizers\n from keras.src import testing\n+from keras.src.backend import config\n from keras.src.backend.common.symbolic_scope import in_symbolic_scope\n from keras.src.callbacks.callback import Callback\n from keras.src.optimizers.rmsprop import RMSprop\n@@ -1506,6 +1507,48 @@ class TestTrainer(testing.TestCase):\n             )\n             self.assertAllClose(model.evaluate(x, y), model_2.evaluate(x, y))\n \n+    @pytest.mark.requires_trainable_backend\n+    def test_max_epochs_and_steps(self):\n+        batch_size = 8\n+        epochs = 4\n+        num_batches = 10\n+        data_size = num_batches * batch_size\n+        x, y = np.ones((data_size, 4)), np.ones((data_size, 1))\n+        model = ExampleModel(units=1)\n+        model.compile(\n+            loss=\"mse\",\n+            optimizer=\"sgd\",\n+            metrics=[EpochAgnosticMeanSquaredError()],\n+        )\n+        step_observer = StepObserver()\n+        model.fit(\n+            x=x,\n+            y=y,\n+            batch_size=batch_size,\n+            epochs=epochs,\n+            callbacks=[step_observer],\n+            verbose=0,\n+        )\n+        self.assertEqual(step_observer.epoch_begin_count, epochs)\n+        self.assertEqual(step_observer.begin_count, num_batches * epochs)\n+        try:\n+            config.set_max_epochs(2)\n+            config.set_max_steps_per_epoch(3)\n+            step_observer = StepObserver()\n+            model.fit(\n+                x=x,\n+                y=y,\n+                batch_size=batch_size,\n+                epochs=epochs,\n+                callbacks=[step_observer],\n+                verbose=0,\n+            )\n+            self.assertEqual(step_observer.epoch_begin_count, 2)\n+            self.assertEqual(step_observer.begin_count, 6)\n+        finally:\n+            config.set_max_epochs(None)\n+            config.set_max_steps_per_epoch(None)\n+\n     @parameterized.named_parameters(\n         named_product(\n             steps_per_epoch_test=[\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cf08b92ad0b3378ee3f86c6e1e34fb8aae175bc2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 16 | Files Changed: 4 | Hunks: 14 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 22 | Churn Cumulative: 4810 | Contributors (this commit): 22 | Commits (past 90d): 39 | Contributors (cumulative): 57 | DMM Complexity: 0.0\n\nDIFF:\n@@ -920,12 +920,10 @@ def not_equal(x1, x2):\n     return jnp.not_equal(x1, x2)\n \n \n-@sparse.elementwise_unary(linear=False)\n def ones_like(x, dtype=None):\n     return jnp.ones_like(x, dtype=dtype)\n \n \n-@sparse.elementwise_unary(linear=True)\n def zeros_like(x, dtype=None):\n     return jnp.zeros_like(x, dtype=dtype)\n \n\n@@ -1840,12 +1840,10 @@ def not_equal(x1, x2):\n     return tf.not_equal(x1, x2)\n \n \n-@sparse.elementwise_unary\n def ones_like(x, dtype=None):\n     return tf.ones_like(x, dtype=dtype)\n \n \n-@sparse.elementwise_unary\n def zeros_like(x, dtype=None):\n     return tf.zeros_like(x, dtype=dtype)\n \n\n@@ -4516,8 +4516,7 @@ class OnesLike(Operation):\n     def compute_output_spec(self, x, dtype=None):\n         if dtype is None:\n             dtype = x.dtype\n-        sparse = getattr(x, \"sparse\", False)\n-        return KerasTensor(x.shape, dtype=dtype, sparse=sparse)\n+        return KerasTensor(x.shape, dtype=dtype)\n \n \n @keras_export([\"keras.ops.ones_like\", \"keras.ops.numpy.ones_like\"])\n@@ -4543,8 +4542,7 @@ class ZerosLike(Operation):\n     def compute_output_spec(self, x, dtype=None):\n         if dtype is None:\n             dtype = x.dtype\n-        sparse = getattr(x, \"sparse\", False)\n-        return KerasTensor(x.shape, dtype=dtype, sparse=sparse)\n+        return KerasTensor(x.shape, dtype=dtype)\n \n \n @keras_export(\n\n@@ -5141,7 +5141,6 @@ class SparseTest(testing.TestCase):\n         \"imag\",\n         \"log1p\",\n         \"negative\",\n-        \"ones_like\",\n         \"real\",\n         \"round\",\n         \"sign\",\n@@ -5151,7 +5150,6 @@ class SparseTest(testing.TestCase):\n         \"square\",\n         \"tan\",\n         \"tanh\",\n-        \"zeros_like\",\n     ]\n     ELEMENTWISE_UNARY_OPS_TESTS = [\n         {\n@@ -5333,11 +5331,10 @@ class SparseTest(testing.TestCase):\n             x = np.array([[1, 0.5, -0.7], [0.9, 0.2, -1]])\n         x = create_sparse_tensor(x)\n         x_np = backend.convert_to_numpy(x)\n-        expected = np_op(x_np) * backend.convert_to_numpy(knp.ones_like(x))\n \n-        self.assertAllClose(op_function(x), expected)\n+        self.assertAllClose(op_function(x), np_op(x_np))\n         self.assertSameSparseness(op_function(x), x)\n-        self.assertAllClose(op_class()(x), expected)\n+        self.assertAllClose(op_class()(x), np_op(x_np))\n         self.assertSameSparseness(op_class()(x), x)\n \n     @parameterized.named_parameters(ELEMENTWISE_UNARY_OPS_TESTS)\n@@ -5350,11 +5347,10 @@ class SparseTest(testing.TestCase):\n             x = np.array([[1, 0.5, -0.7], [0.9, 0.2, -1]])\n         x = create_indexed_slices(x)\n         x_np = backend.convert_to_numpy(x)\n-        expected = np_op(x_np) * backend.convert_to_numpy(knp.ones_like(x))\n \n-        self.assertAllClose(op_function(x), expected)\n+        self.assertAllClose(op_function(x), np_op(x_np))\n         self.assertSameSparseness(op_function(x), x)\n-        self.assertAllClose(op_class()(x), expected)\n+        self.assertAllClose(op_class()(x), np_op(x_np))\n         self.assertSameSparseness(op_class()(x), x)\n \n     @parameterized.named_parameters(OTHER_UNARY_OPS_TESTS)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c949e759095950ab65445e0e6ae46d1bd179d6c9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 1788 | Contributors (this commit): 22 | Commits (past 90d): 32 | Contributors (cumulative): 22 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1211,7 +1211,21 @@ def ones_like(x, dtype=None):\n \n \n def outer(x1, x2):\n-    raise NotImplementedError(\"`outer` is not supported with openvino backend\")\n+    x1 = get_ov_output(x1)\n+    x2 = get_ov_output(x2)\n+\n+    x1, x2 = _align_operand_types(x1, x2, \"outer()\")\n+\n+    new_shape_x1 = ov_opset.constant([-1, 1], Type.i32).output(0)\n+    new_shape_x2 = ov_opset.constant([1, -1], Type.i32).output(0)\n+\n+    # Reshape directly from original tensors\n+    x1_reshaped = ov_opset.reshape(x1, new_shape_x1, False).output(0)\n+    x2_reshaped = ov_opset.reshape(x2, new_shape_x2, False).output(0)\n+\n+    result = ov_opset.multiply(x1_reshaped, x2_reshaped).output(0)\n+\n+    return OpenVINOKerasTensor(result)\n \n \n def pad(x, pad_width, mode=\"constant\", constant_values=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c2b1993615bd6822b7bcf0e02e6a4740cb73a2cc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 373 | Contributors (this commit): 5 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -209,7 +209,7 @@ class EinsumDense(Layer):\n     def call(self, inputs, training=None):\n         x = ops.einsum(self.equation, inputs, self.kernel)\n         if self.bias is not None:\n-            x += self.bias\n+            x = ops.add(x, self.bias)\n         if self.activation is not None:\n             x = self.activation(x)\n         return x\n@@ -518,7 +518,7 @@ class EinsumDense(Layer):\n             lora_x = ops.matmul(lora_x, self.lora_kernel_b)\n             x = ops.add(x, (self.lora_alpha / self.lora_rank) * lora_x)\n         if self.bias is not None:\n-            x += self.bias\n+            x = ops.add(x, self.bias)\n         if self.activation is not None:\n             x = self.activation(x)\n         return x\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c6187c1fb31c5e2b777d908b5b3eb4a333bd3dcf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 15 | Churn Cumulative: 1803 | Contributors (this commit): 22 | Commits (past 90d): 33 | Contributors (cumulative): 22 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1344,13 +1344,16 @@ def split(x, indices_or_sections, axis=0):\n \n \n def stack(x, axis=0):\n-    assert isinstance(x, list), \"`stack` is supported only for `x` list\"\n-    elems = []\n+    if isinstance(x, tuple):\n+        x = list(x)\n+    assert isinstance(x, list), \"`stack` supports only `x` as list or tuple\"\n+    elems = [get_ov_output(e) for e in x]\n+    ref = elems[0]\n+    for i in range(1, len(elems)):\n+        ref, elems[i] = _align_operand_types(ref, elems[i], \"stack()\")\n+    elems[0] = ref\n     const_axis = ov_opset.constant(axis, Type.i32).output(0)\n-    for elem in x:\n-        elem = get_ov_output(elem)\n-        elem = ov_opset.unsqueeze(elem, const_axis).output(0)\n-        elems.append(elem)\n+    elems = [ov_opset.unsqueeze(e, const_axis).output(0) for e in elems]\n     res = ov_opset.concat(elems, axis).output(0)\n     return OpenVINOKerasTensor(res)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#df58e70c5f6b41abd316983d827abff6d065e942", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 8 | Churn Cumulative: 113 | Contributors (this commit): 5 | Commits (past 90d): 1 | Contributors (cumulative): 5 | DMM Complexity: 0.0\n\nDIFF:\n@@ -350,14 +350,6 @@ class LinalgOpsCorrectnessTest(testing.TestCase):\n     def test_eig(self):\n         x = np.random.rand(2, 3, 3)\n         x = x @ x.transpose((0, 2, 1))\n-        if backend.backend() == \"jax\":\n-            import jax\n-\n-            if jax.default_backend() == \"gpu\":\n-                # eig not implemented for jax on gpu backend\n-                with self.assertRaises(NotImplementedError):\n-                    linalg.eig(x)\n-                return\n         w, v = map(ops.convert_to_numpy, linalg.eig(x))\n         x_reconstructed = (v * w[..., None, :]) @ v.transpose((0, 2, 1))\n         self.assertAllClose(x_reconstructed, x, atol=1e-4)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8f67babc2587d62cda31102119f507d45d8b2897", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 668 | Contributors (this commit): 11 | Commits (past 90d): 7 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -1203,8 +1203,8 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n             scope = backend.get_stateless_scope()\n             if scope.collect_losses:\n                 for x in losses:\n-                    scope.add_loss(loss)\n-                    self._loss_ids.add(id(loss))\n+                    scope.add_loss(x)\n+                    self._loss_ids.add(id(x))\n         else:\n             self._losses.extend(losses)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c52d71e55dfaeae7367905b821708f07731dbe3c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 49 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 7/5 | Churn Δ: 51 | Churn Cumulative: 2553 | Contributors (this commit): 24 | Commits (past 90d): 37 | Contributors (cumulative): 30 | DMM Complexity: 0.0\n\nDIFF:\n@@ -450,8 +450,13 @@ def convert_to_tensor(x, dtype=None, sparse=None, ragged=None):\n def convert_to_numpy(x):\n     if isinstance(x, np.ndarray):\n         return x\n-    elif isinstance(x, (int, float, list, tuple)):\n+    elif isinstance(x, (int, float)):\n         return np.array(x)\n+    elif isinstance(x, (list, tuple)):\n+        x_new = []\n+        for elem in x:\n+            x_new.append(convert_to_numpy(elem))\n+        return np.array(x_new)\n     elif np.isscalar(x):\n         return x\n     elif isinstance(x, ov.Tensor):\n\n@@ -1340,7 +1340,49 @@ def sort(x, axis=-1):\n \n \n def split(x, indices_or_sections, axis=0):\n-    raise NotImplementedError(\"`split` is not supported with openvino backend\")\n+    x = get_ov_output(x)\n+    axis_tensor = ov_opset.constant(axis, dtype=Type.i32).output(0)\n+\n+    shape_tensor = ov_opset.shape_of(x)\n+    axis_i32 = ov_opset.constant([axis], dtype=Type.i32)\n+    dim_at_axis_tensor = ov_opset.gather(\n+        shape_tensor, axis_i32, ov_opset.constant(0, dtype=Type.i32)\n+    )\n+\n+    if isinstance(indices_or_sections, int):\n+        num_splits = indices_or_sections\n+        splits = ov_opset.split(x, axis_tensor, num_splits=num_splits)\n+        result = []\n+        for i in range(num_splits):\n+            result.append(OpenVINOKerasTensor(splits.output(i)))\n+        return result\n+\n+    if isinstance(indices_or_sections, (list, tuple, np.ndarray)):\n+        indices = list(indices_or_sections)\n+        split_lengths = []\n+        split_lengths.append(indices[0])\n+        for i in range(1, len(indices)):\n+            split_lengths.append(indices[i] - indices[i - 1])\n+\n+        last_index_tensor = ov_opset.constant(indices[-1], dtype=Type.i64)\n+        remaining_length_tensor = ov_opset.subtract(\n+            dim_at_axis_tensor, last_index_tensor\n+        )\n+\n+        length_parts = []\n+        length_parts.append(ov_opset.constant(split_lengths, dtype=Type.i64))\n+        length_parts.append(remaining_length_tensor)\n+        length_tensor = ov_opset.concat(length_parts, axis=0)\n+\n+        splits = ov_opset.variadic_split(x, axis_tensor, length_tensor)\n+        result = []\n+        for i in range(len(split_lengths) + 1):\n+            result.append(OpenVINOKerasTensor(splits.output(i)))\n+        return result\n+\n+    raise TypeError(\n+        f\"unsupported type of indices_or_sections: {type(indices_or_sections)}\"\n+    )\n \n \n def stack(x, axis=0):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3bedb9a970394879360fcb1c0264f3ffdc634a77", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 675 | Contributors (this commit): 11 | Commits (past 90d): 8 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1417,8 +1417,11 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n     def add_metric(self, *args, **kwargs):\n         # Permanently disabled\n         raise NotImplementedError(\n-            \"Layer `add_metric()` method is deprecated\"\n-            \" add your metric in `Model.compile(metrics=[...]).`\"\n+            \"Layer `add_metric()` method is deprecated. \"\n+            \"Add your metric in `Model.compile(metrics=[...])`, \"\n+            \"or create metric trackers in init() or build() \"\n+            \"when subclassing the layer or model, then call \"\n+            \"`metric.update_state()` whenever necessary.\"\n         )\n \n     def count_params(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a9ff3a79ac2a74dcf1be621e8ec71f7ff7d48fc7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 96 | Lines Deleted: 0 | Files Changed: 11 | Hunks: 13 | Methods Changed: 11 | Complexity Δ (Sum/Max): 13/5 | Churn Δ: 96 | Churn Cumulative: 9980 | Contributors (this commit): 47 | Commits (past 90d): 122 | Contributors (cumulative): 142 | DMM Complexity: 1.0\n\nDIFF:\n@@ -195,6 +195,7 @@ from keras.src.ops.numpy import isclose as isclose\n from keras.src.ops.numpy import isfinite as isfinite\n from keras.src.ops.numpy import isinf as isinf\n from keras.src.ops.numpy import isnan as isnan\n+from keras.src.ops.numpy import kaiser as kaiser\n from keras.src.ops.numpy import left_shift as left_shift\n from keras.src.ops.numpy import less as less\n from keras.src.ops.numpy import less_equal as less_equal\n\n@@ -85,6 +85,7 @@ from keras.src.ops.numpy import isclose as isclose\n from keras.src.ops.numpy import isfinite as isfinite\n from keras.src.ops.numpy import isinf as isinf\n from keras.src.ops.numpy import isnan as isnan\n+from keras.src.ops.numpy import kaiser as kaiser\n from keras.src.ops.numpy import left_shift as left_shift\n from keras.src.ops.numpy import less as less\n from keras.src.ops.numpy import less_equal as less_equal\n\n@@ -195,6 +195,7 @@ from keras.src.ops.numpy import isclose as isclose\n from keras.src.ops.numpy import isfinite as isfinite\n from keras.src.ops.numpy import isinf as isinf\n from keras.src.ops.numpy import isnan as isnan\n+from keras.src.ops.numpy import kaiser as kaiser\n from keras.src.ops.numpy import left_shift as left_shift\n from keras.src.ops.numpy import less as less\n from keras.src.ops.numpy import less_equal as less_equal\n\n@@ -85,6 +85,7 @@ from keras.src.ops.numpy import isclose as isclose\n from keras.src.ops.numpy import isfinite as isfinite\n from keras.src.ops.numpy import isinf as isinf\n from keras.src.ops.numpy import isnan as isnan\n+from keras.src.ops.numpy import kaiser as kaiser\n from keras.src.ops.numpy import left_shift as left_shift\n from keras.src.ops.numpy import less as less\n from keras.src.ops.numpy import less_equal as less_equal\n\n@@ -47,6 +47,11 @@ def hamming(x):\n     return jnp.hamming(x)\n \n \n+def kaiser(x, beta):\n+    x = convert_to_tensor(x)\n+    return jnp.kaiser(x, beta)\n+\n+\n def bincount(x, weights=None, minlength=0, sparse=False):\n     # Note: bincount is never tracable / jittable because the output shape\n     # depends on the values in x.\n\n@@ -315,6 +315,11 @@ def hamming(x):\n     return np.hamming(x).astype(config.floatx())\n \n \n+def kaiser(x, beta):\n+    x = convert_to_tensor(x)\n+    return np.kaiser(x, beta).astype(config.floatx())\n+\n+\n def bincount(x, weights=None, minlength=0, sparse=False):\n     if sparse:\n         raise ValueError(\"Unsupported value `sparse=True` with numpy backend\")\n\n@@ -481,6 +481,10 @@ def hamming(x):\n     )\n \n \n+def kaiser(x, beta):\n+    raise NotImplementedError(\"`kaiser` is not supported with openvino backend\")\n+\n+\n def bincount(x, weights=None, minlength=0, sparse=False):\n     if x is None:\n         raise ValueError(\"input x is None\")\n\n@@ -151,6 +151,11 @@ def hamming(x):\n     return tf.signal.hamming_window(x, periodic=False)\n \n \n+def kaiser(x, beta):\n+    x = convert_to_tensor(x, dtype=tf.int32)\n+    return tf.signal.kaiser_window(x, beta=beta)\n+\n+\n def bincount(x, weights=None, minlength=0, sparse=False):\n     x = convert_to_tensor(x)\n     dtypes_to_resolve = [x.dtype]\n\n@@ -440,6 +440,11 @@ def hamming(x):\n     return torch.signal.windows.hamming(x)\n \n \n+def kaiser(x, beta):\n+    x = convert_to_tensor(x)\n+    return torch.signal.windows.kaiser(x, beta=beta)\n+\n+\n def bincount(x, weights=None, minlength=0, sparse=False):\n     if sparse:\n         raise ValueError(\"Unsupported value `sparse=True` with torch backend\")\n\n@@ -1270,6 +1270,44 @@ def hamming(x):\n     return backend.numpy.hamming(x)\n \n \n+class Kaiser(Operation):\n+    def __init__(self, beta):\n+        super().__init__()\n+        self.beta = beta\n+\n+    def call(self, x):\n+        return backend.numpy.kaiser(x, self.beta)\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=backend.floatx())\n+\n+\n+@keras_export([\"keras.ops.kaiser\", \"keras.ops.numpy.kaiser\"])\n+def kaiser(x, beta):\n+    \"\"\"Kaiser window function.\n+\n+    The Kaiser window is defined as:\n+    `w[n] = I0(beta * sqrt(1 - (2n / (N - 1) - 1)^2)) / I0(beta)`\n+    where I0 is the modified zeroth-order Bessel function of the first kind.\n+\n+    Args:\n+        x: Scalar or 1D Tensor. The window length.\n+        beta: Float. Shape parameter for the Kaiser window.\n+\n+    Returns:\n+        A 1D tensor containing the Kaiser window values.\n+\n+    Example:\n+    >>> x = keras.ops.convert_to_tensor(5)\n+    >>> keras.ops.kaiser(x, beta=14.0)\n+    array([7.7268669e-06, 1.6493219e-01, 1.0000000e+00, 1.6493219e-01,\n+       7.7268669e-06], dtype=float32)\n+    \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return Kaiser(beta).symbolic_call(x)\n+    return backend.numpy.kaiser(x, beta)\n+\n+\n class Bincount(Operation):\n     def __init__(self, weights=None, minlength=0, sparse=False):\n         super().__init__()\n\n@@ -1232,6 +1232,11 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n         x = np.random.randint(1, 100 + 1)\n         self.assertEqual(knp.hamming(x).shape[0], x)\n \n+    def test_kaiser(self):\n+        x = np.random.randint(1, 100 + 1)\n+        beta = float(np.random.randint(10, 20 + 1))\n+        self.assertEqual(knp.kaiser(x, beta).shape[0], x)\n+\n     def test_bitwise_invert(self):\n         x = KerasTensor((None, 3))\n         self.assertEqual(knp.bitwise_invert(x).shape, (None, 3))\n@@ -3620,6 +3625,13 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase):\n \n         self.assertAllClose(knp.Hamming()(x), np.hamming(x))\n \n+    def test_kaiser(self):\n+        x = np.random.randint(1, 100 + 1)\n+        beta = float(np.random.randint(10, 20 + 1))\n+        self.assertAllClose(knp.kaiser(x, beta), np.kaiser(x, beta))\n+\n+        self.assertAllClose(knp.Kaiser(beta)(x), np.kaiser(x, beta))\n+\n     @parameterized.named_parameters(\n         named_product(sparse_input=(False, True), sparse_arg=(False, True))\n     )\n@@ -5627,6 +5639,24 @@ class NumpyDtypeTest(testing.TestCase):\n             expected_dtype,\n         )\n \n+    @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n+    def test_kaiser(self, dtype):\n+        import jax.numpy as jnp\n+\n+        x = knp.ones((), dtype=dtype)\n+        beta = knp.ones((), dtype=dtype)\n+        x_jax = jnp.ones((), dtype=dtype)\n+        beta_jax = jnp.ones((), dtype=dtype)\n+        expected_dtype = standardize_dtype(jnp.kaiser(x_jax, beta_jax).dtype)\n+\n+        self.assertEqual(\n+            standardize_dtype(knp.kaiser(x, beta).dtype), expected_dtype\n+        )\n+        self.assertEqual(\n+            standardize_dtype(knp.Kaiser(beta).symbolic_call(x).dtype),\n+            expected_dtype,\n+        )\n+\n     @parameterized.named_parameters(named_product(dtype=INT_DTYPES))\n     def test_bincount(self, dtype):\n         import jax.numpy as jnp\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#37a0920a3d83efcb6754fe7f09d991484198f17a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 243 | Lines Deleted: 124 | Files Changed: 7 | Hunks: 28 | Methods Changed: 16 | Complexity Δ (Sum/Max): -6/17 | Churn Δ: 367 | Churn Cumulative: 552 | Contributors (this commit): 9 | Commits (past 90d): 10 | Contributors (cumulative): 22 | DMM Complexity: 1.0\n\nDIFF:\n@@ -7,6 +7,7 @@ from keras.src.callbacks.history import History\n from keras.src.callbacks.lambda_callback import LambdaCallback\n from keras.src.callbacks.learning_rate_scheduler import LearningRateScheduler\n from keras.src.callbacks.model_checkpoint import ModelCheckpoint\n+from keras.src.callbacks.monitor_callback import MonitorCallback\n from keras.src.callbacks.progbar_logger import ProgbarLogger\n from keras.src.callbacks.reduce_lr_on_plateau import ReduceLROnPlateau\n from keras.src.callbacks.remote_monitor import RemoteMonitor\n\n@@ -1,14 +1,12 @@\n import warnings\n \n-from keras.src import ops\n from keras.src.api_export import keras_export\n-from keras.src.callbacks.callback import Callback\n-from keras.src.trainers import compile_utils\n+from keras.src.callbacks.monitor_callback import MonitorCallback\n from keras.src.utils import io_utils\n \n \n @keras_export(\"keras.callbacks.EarlyStopping\")\n-class EarlyStopping(Callback):\n+class EarlyStopping(MonitorCallback):\n     \"\"\"Stop training when a monitored metric has stopped improving.\n \n     Assuming the goal of a training is to minimize the loss. With this, the\n@@ -76,72 +74,20 @@ class EarlyStopping(Callback):\n         restore_best_weights=False,\n         start_from_epoch=0,\n     ):\n-        super().__init__()\n-\n-        self.monitor = monitor\n+        super().__init__(monitor, mode, min_delta=min_delta)\n         self.patience = patience\n         self.verbose = verbose\n         self.baseline = baseline\n-        self.min_delta = abs(min_delta)\n         self.wait = 0\n         self.stopped_epoch = 0\n         self.restore_best_weights = restore_best_weights\n         self.best_weights = None\n         self.start_from_epoch = start_from_epoch\n \n-        if mode not in [\"auto\", \"min\", \"max\"]:\n-            warnings.warn(\n-                f\"EarlyStopping mode {mode} is unknown, fallback to auto mode.\",\n-                stacklevel=2,\n-            )\n-            mode = \"auto\"\n-        self.mode = mode\n-        self.monitor_op = None\n-\n-    def _set_monitor_op(self):\n-        if self.mode == \"min\":\n-            self.monitor_op = ops.less\n-        elif self.mode == \"max\":\n-            self.monitor_op = ops.greater\n-        else:\n-            metric_name = self.monitor.removeprefix(\"val_\")\n-            if metric_name == \"loss\":\n-                self.monitor_op = ops.less\n-            if hasattr(self.model, \"metrics\"):\n-                all_metrics = []\n-                for m in self.model.metrics:\n-                    if isinstance(\n-                        m,\n-                        (\n-                            compile_utils.CompileMetrics,\n-                            compile_utils.MetricsList,\n-                        ),\n-                    ):\n-                        all_metrics.extend(m.metrics)\n-                for m in all_metrics:\n-                    if m.name == metric_name:\n-                        if hasattr(m, \"_direction\"):\n-                            if m._direction == \"up\":\n-                                self.monitor_op = ops.greater\n-                            else:\n-                                self.monitor_op = ops.less\n-        if self.monitor_op is None:\n-            raise ValueError(\n-                f\"EarlyStopping callback received monitor={self.monitor} \"\n-                \"but Keras isn't able to automatically determine whether \"\n-                \"that metric should be maximized or minimized. \"\n-                \"Pass `mode='max'` in order to do early stopping based \"\n-                \"on the highest metric value, or pass `mode='min'` \"\n-                \"in order to use the lowest value.\"\n-            )\n-        if self.monitor_op == ops.less:\n-            self.min_delta *= -1\n-\n     def on_train_begin(self, logs=None):\n         # Allow instances to be re-used\n         self.wait = 0\n         self.stopped_epoch = 0\n-        self.best = None\n         self.best_weights = None\n         self.best_epoch = 0\n \n@@ -206,8 +152,3 @@ class EarlyStopping(Callback):\n                 stacklevel=2,\n             )\n         return monitor_value\n-\n-    def _is_improvement(self, monitor_value, reference_value):\n-        if reference_value is None:\n-            return True\n-        return self.monitor_op(monitor_value - self.min_delta, reference_value)\n\n@@ -6,13 +6,13 @@ import numpy as np\n \n from keras.src import backend\n from keras.src.api_export import keras_export\n-from keras.src.callbacks.callback import Callback\n+from keras.src.callbacks.monitor_callback import MonitorCallback\n from keras.src.utils import file_utils\n from keras.src.utils import io_utils\n \n \n @keras_export(\"keras.callbacks.ModelCheckpoint\")\n-class ModelCheckpoint(Callback):\n+class ModelCheckpoint(MonitorCallback):\n     \"\"\"Callback to save the Keras model or model weights at some frequency.\n \n     `ModelCheckpoint` callback is used in conjunction with training using\n@@ -105,9 +105,8 @@ class ModelCheckpoint(Callback):\n             decision to overwrite the current save file is made based on either\n             the maximization or the minimization of the monitored quantity.\n             For `val_acc`, this should be `\"max\"`, for `val_loss` this should be\n-            `\"min\"`, etc. In `\"auto\"` mode, the mode is set to `\"max\"` if the\n-            quantities monitored are `\"acc\"` or start with `\"fmeasure\"` and are\n-            set to `\"min\"` for the rest of the quantities.\n+            `\"min\"`, etc. In `\"auto\"` mode, the direction is automatically\n+            inferred from the name of the monitored quantity.\n         save_weights_only: if `True`, then only the model's weights will be\n             saved (`model.save_weights(filepath)`), else the full model is\n             saved (`model.save(filepath)`).\n@@ -136,8 +135,7 @@ class ModelCheckpoint(Callback):\n         save_freq=\"epoch\",\n         initial_value_threshold=None,\n     ):\n-        super().__init__()\n-        self.monitor = monitor\n+        super().__init__(monitor, mode, initial_value_threshold)\n         self.verbose = verbose\n         self.filepath = file_utils.path_to_string(filepath)\n         self.save_best_only = save_best_only\n@@ -145,33 +143,6 @@ class ModelCheckpoint(Callback):\n         self.save_freq = save_freq\n         self._batches_seen_since_last_saving = 0\n         self._last_batch_seen = 0\n-        self.best = initial_value_threshold\n-\n-        if mode not in [\"auto\", \"min\", \"max\"]:\n-            warnings.warn(\n-                f\"ModelCheckpoint mode '{mode}' is unknown, \"\n-                \"fallback to auto mode.\",\n-                stacklevel=2,\n-            )\n-            mode = \"auto\"\n-\n-        if mode == \"min\":\n-            self.monitor_op = np.less\n-            if self.best is None:\n-                self.best = np.inf\n-        elif mode == \"max\":\n-            self.monitor_op = np.greater\n-            if self.best is None:\n-                self.best = -np.inf\n-        else:\n-            if \"acc\" in self.monitor or self.monitor.startswith(\"fmeasure\"):\n-                self.monitor_op = np.greater\n-                if self.best is None:\n-                    self.best = -np.inf\n-            else:\n-                self.monitor_op = np.less\n-                if self.best is None:\n-                    self.best = np.inf\n \n         if self.save_freq != \"epoch\" and not isinstance(self.save_freq, int):\n             raise ValueError(\n@@ -205,6 +176,10 @@ class ModelCheckpoint(Callback):\n         self._current_epoch = epoch\n \n     def on_epoch_end(self, epoch, logs=None):\n+        if self.monitor_op is None:\n+            # Delay setup until the model's metrics are all built\n+            self._set_monitor_op()\n+\n         if self.save_freq == \"epoch\":\n             self._save_model(epoch=epoch, batch=None, logs=logs)\n \n@@ -262,7 +237,7 @@ class ModelCheckpoint(Callback):\n                 )\n                 return True\n             else:\n-                if self.monitor_op(current, self.best):\n+                if self._is_improvement(current, self.best):\n                     if self.verbose > 0:\n                         io_utils.print_msg(\n                             f\"\\nEpoch {epoch + 1}: {self.monitor} \"\n\n@@ -164,7 +164,7 @@ class ModelCheckpointTest(testing.TestCase):\n         # Case 5: metric not available.\n         cbks = [\n             callbacks.ModelCheckpoint(\n-                filepath, monitor=\"unknown\", save_best_only=True\n+                filepath, monitor=\"unknown\", save_best_only=True, mode=\"min\"\n             )\n         ]\n         with pytest.warns(UserWarning):\n@@ -453,6 +453,37 @@ class ModelCheckpointTest(testing.TestCase):\n         )\n         self.assertFalse(os.path.exists(filepath))\n \n+        # Case 15: ModelCheckpoint doesn't save model if auc was max earlier in\n+        # auto mode\n+        mode = \"auto\"\n+        monitor = \"val_auc\"\n+        initial_value_threshold = 1\n+        save_best_only = True\n+        cbks = [\n+            callbacks.ModelCheckpoint(\n+                filepath,\n+                monitor=monitor,\n+                save_best_only=save_best_only,\n+                initial_value_threshold=initial_value_threshold,\n+                mode=mode,\n+            )\n+        ]\n+        model.compile(\n+            loss=\"categorical_crossentropy\",\n+            optimizer=\"sgd\",\n+            metrics=[metrics.AUC()],\n+        )\n+        model.fit(\n+            x_train,\n+            y_train,\n+            batch_size=BATCH_SIZE,\n+            validation_data=(x_test, y_test),\n+            callbacks=cbks,\n+            epochs=1,\n+            verbose=0,\n+        )\n+        self.assertFalse(os.path.exists(filepath))\n+\n     @pytest.mark.skipif(\n         h5py is None,\n         reason=\"`h5py` is a required dependency for `ModelCheckpoint` tests.\",\n\n@@ -0,0 +1,104 @@\n+import warnings\n+\n+from keras.src import ops\n+from keras.src.callbacks.callback import Callback\n+from keras.src.trainers import compile_utils\n+\n+\n+class MonitorCallback(Callback):\n+    \"\"\"Base class for callbacks that monitor a quantity and evaluates\n+    improvements.\n+\n+    This class provides common functionality for callbacks that monitor a\n+    metric during training to determine whether a condition has been met,\n+    such as improvement over time. It encapsulates logic for selecting\n+    the comparison operation based on a `monitor` value and `mode`, and\n+    computing whether a new value is an improvement.\n+\n+    It is intended to be subclassed by other callbacks like `ModelCheckpoint`,\n+    `EarlyStopping`, or `ReduceLROnPlateau`, and is not meant to be used\n+    directly.\n+\n+    Arguments:\n+        monitor: Quantity to be monitored. Defaults to `\"val_loss\"`.\n+        mode: One of `{\"auto\", \"min\", \"max\"}`. In `min` mode, training will aim\n+            to minimize the monitored quantity; in `'max'` mode it will aim to\n+            maximize it.; in `\"auto\"` mode, the direction is automatically\n+            inferred from the name of the monitored quantity. Defaults to\n+            `\"auto\"`.\n+        baseline: Floating point initial \"best\" value of the metric to be\n+            monitored. If `None` (default), the first monitored value will be\n+            used.\n+        min_delta: Minimum change in the monitored quantity to qualify as an\n+            improvement, i.e. an absolute change of less than min_delta, will\n+            count as no improvement. Defaults to `0`.\n+\n+    Raises:\n+        ValueError: If `mode='auto'` is selected and the direction of the metric\n+        cannot be inferred.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        monitor=\"val_loss\",\n+        mode=\"auto\",\n+        baseline=None,\n+        min_delta=0,\n+    ):\n+        super().__init__()\n+        if mode not in [\"auto\", \"min\", \"max\"]:\n+            warnings.warn(\n+                f\"{self.__class__.__name__} mode '{mode}' is unknown, fallback \"\n+                \"to auto mode.\",\n+                stacklevel=2,\n+            )\n+            mode = \"auto\"\n+        self.monitor = monitor\n+        self.mode = mode\n+        self.best = baseline\n+        self.min_delta = abs(min_delta)\n+        self.monitor_op = None\n+\n+    def _set_monitor_op(self):\n+        if self.mode == \"min\":\n+            self.monitor_op = ops.less\n+        elif self.mode == \"max\":\n+            self.monitor_op = ops.greater\n+        else:\n+            metric_name = self.monitor.removeprefix(\"val_\")\n+            if metric_name == \"loss\":\n+                self.monitor_op = ops.less\n+            if hasattr(self.model, \"metrics\"):\n+                all_metrics = []\n+                for m in self.model.metrics:\n+                    if isinstance(\n+                        m,\n+                        (\n+                            compile_utils.CompileMetrics,\n+                            compile_utils.MetricsList,\n+                        ),\n+                    ):\n+                        all_metrics.extend(m.metrics)\n+                for m in all_metrics:\n+                    if m.name == metric_name:\n+                        if hasattr(m, \"_direction\"):\n+                            if m._direction == \"up\":\n+                                self.monitor_op = ops.greater\n+                            else:\n+                                self.monitor_op = ops.less\n+            if self.monitor_op is None:\n+                raise ValueError(\n+                    f\"{self.__class__.__name__} callback received \"\n+                    f\"monitor={self.monitor}, but Keras isn't able to \"\n+                    \"automatically determine whether that metric should be \"\n+                    \"maximized or minimized. Pass `mode='max'` in order to \"\n+                    \"monitor based on the highest metric value, or pass \"\n+                    \"`mode='min'` in order to use the lowest value.\"\n+                )\n+        if self.monitor_op == ops.less:\n+            self.min_delta *= -1\n+\n+    def _is_improvement(self, monitor_value, reference_value):\n+        if reference_value is None:\n+            return True\n+        return self.monitor_op(monitor_value - self.min_delta, reference_value)\n\n@@ -0,0 +1,86 @@\n+import numpy as np\n+import pytest\n+\n+from keras.src import callbacks\n+from keras.src import layers\n+from keras.src import metrics\n+from keras.src import models\n+from keras.src import ops\n+from keras.src import testing\n+\n+\n+class MonitorCallbackTest(testing.TestCase):\n+    @pytest.mark.requires_trainable_backend\n+    def test_monitor_op_logic(self):\n+        x_train = np.random.random((10, 5))\n+        y_train = np.random.random((10, 1))\n+        x_test = np.random.random((10, 5))\n+        y_test = np.random.random((10, 1))\n+        model = models.Sequential(\n+            (\n+                layers.Dense(1, activation=\"relu\"),\n+                layers.Dense(1, activation=\"relu\"),\n+            )\n+        )\n+        model.compile(\n+            loss=\"mae\",\n+            optimizer=\"adam\",\n+            metrics=[\n+                \"mse\",\n+                \"acc\",\n+                \"accuracy\",\n+                \"hinge\",\n+                metrics.F1Score(name=\"f1_score\"),\n+            ],\n+        )\n+\n+        cases = [\n+            (\"max\", \"val_mse\", \"max\"),\n+            (\"min\", \"val_loss\", \"min\"),\n+            (\"auto\", \"val_mse\", \"min\"),\n+            (\"auto\", \"loss\", \"min\"),\n+            (\"auto\", \"acc\", \"max\"),\n+            (\"auto\", \"val_accuracy\", \"max\"),\n+            (\"auto\", \"hinge\", \"min\"),\n+            (\"auto\", \"f1_score\", \"max\"),\n+        ]\n+        for mode, monitor, expected_mode in cases:\n+            monitor_callback = callbacks.MonitorCallback(monitor, mode)\n+            monitor_callback.set_model(model)\n+            model.fit(\n+                x_train,\n+                y_train,\n+                batch_size=5,\n+                validation_data=(x_test, y_test),\n+                epochs=2,\n+                verbose=0,\n+            )\n+            monitor_callback._set_monitor_op()\n+            if expected_mode == \"max\":\n+                monitor_op = ops.greater\n+            else:\n+                monitor_op = ops.less\n+            self.assertEqual(monitor_callback.monitor_op, monitor_op)\n+\n+        with self.assertRaises(ValueError):\n+            monitor = \"unknown\"\n+            monitor_callback = callbacks.MonitorCallback(monitor)\n+            monitor_callback.set_model(model)\n+            model.fit(\n+                x_train,\n+                y_train,\n+                batch_size=5,\n+                validation_data=(x_test, y_test),\n+                epochs=2,\n+                verbose=0,\n+            )\n+            monitor_callback._set_monitor_op()\n+\n+    @pytest.mark.requires_trainable_backend\n+    def test_min_delta(self):\n+        monitor_callback = callbacks.MonitorCallback(mode=\"max\", min_delta=0.5)\n+        monitor_callback._set_monitor_op()\n+        self.assertTrue(monitor_callback._is_improvement(0.75, 0))\n+        self.assertTrue(monitor_callback._is_improvement(0.5, None))\n+        self.assertFalse(monitor_callback._is_improvement(0.5, 0))\n+        self.assertFalse(monitor_callback._is_improvement(0.2, 0.5))\n\n@@ -4,12 +4,12 @@ import numpy as np\n \n from keras.src import backend\n from keras.src.api_export import keras_export\n-from keras.src.callbacks.callback import Callback\n+from keras.src.callbacks.monitor_callback import MonitorCallback\n from keras.src.utils import io_utils\n \n \n @keras_export(\"keras.callbacks.ReduceLROnPlateau\")\n-class ReduceLROnPlateau(Callback):\n+class ReduceLROnPlateau(MonitorCallback):\n     \"\"\"Reduce learning rate when a metric has stopped improving.\n \n     Models often benefit from reducing the learning rate by a factor\n@@ -57,9 +57,7 @@ class ReduceLROnPlateau(Callback):\n         min_lr=0.0,\n         **kwargs,\n     ):\n-        super().__init__()\n-\n-        self.monitor = monitor\n+        super().__init__(monitor, mode, min_delta=min_delta)\n         if factor >= 1.0:\n             raise ValueError(\n                 \"ReduceLROnPlateau does not support a factor >= 1.0. \"\n@@ -68,34 +66,14 @@ class ReduceLROnPlateau(Callback):\n \n         self.factor = factor\n         self.min_lr = min_lr\n-        self.min_delta = min_delta\n         self.patience = patience\n         self.verbose = verbose\n         self.cooldown = cooldown\n         self.cooldown_counter = 0  # Cooldown counter.\n         self.wait = 0\n-        self.best = 0\n-        self.mode = mode\n-        self.monitor_op = None\n-        self._reset()\n \n     def _reset(self):\n         \"\"\"Resets wait counter and cooldown counter.\"\"\"\n-        if self.mode not in {\"auto\", \"min\", \"max\"}:\n-            warnings.warn(\n-                f\"Learning rate reduction mode {self.mode} is unknown, \"\n-                \"fallback to auto mode.\",\n-                stacklevel=2,\n-            )\n-            self.mode = \"auto\"\n-        if self.mode == \"min\" or (\n-            self.mode == \"auto\" and \"acc\" not in self.monitor\n-        ):\n-            self.monitor_op = lambda a, b: np.less(a, b - self.min_delta)\n-            self.best = np.inf\n-        else:\n-            self.monitor_op = lambda a, b: np.greater(a, b + self.min_delta)\n-            self.best = -np.inf\n         self.cooldown_counter = 0\n         self.wait = 0\n \n@@ -103,6 +81,9 @@ class ReduceLROnPlateau(Callback):\n         self._reset()\n \n     def on_epoch_end(self, epoch, logs=None):\n+        if self.monitor_op is None:\n+            # Delay setup until the model's metrics are all built\n+            self._set_monitor_op()\n         logs = logs or {}\n         logs[\"learning_rate\"] = float(\n             backend.convert_to_numpy(self.model.optimizer.learning_rate)\n@@ -121,7 +102,7 @@ class ReduceLROnPlateau(Callback):\n                 self.cooldown_counter -= 1\n                 self.wait = 0\n \n-            if self.monitor_op(current, self.best):\n+            if self._is_improvement(current, self.best):\n                 self.best = current\n                 self.wait = 0\n             elif not self.in_cooldown():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
