{"custom_id": "keras#5fc333d8ae2363e262aa1221f852920cf32fc44a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 4 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -60,7 +60,7 @@ class Adamax(optimizer.Optimizer):\n       learning_rate: A `tf.Tensor`, floating point value, a schedule that is a\n         `tf.keras.optimizers.schedules.LearningRateSchedule`, or a callable\n         that takes no arguments and returns the actual value to use. The\n-        learning rate. Defaults to 0.001.\n+        learning rate. Defaults to `0.001`.\n       beta_1: A float value or a constant float tensor. The exponential decay\n         rate for the 1st moment estimates.\n       beta_2: A float value or a constant float tensor. The exponential decay\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#37b9eec44210290cfc2588ea9be386e31e8406bb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 8 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -77,16 +77,16 @@ class Ftrl(optimizer.Optimizer):\n       learning_rate: A `Tensor`, floating point value, a schedule that is a\n         `tf.keras.optimizers.schedules.LearningRateSchedule`, or a callable that\n         takes no arguments and returns the actual value to use. The learning\n-        rate.  Defaults to 0.001.\n+        rate.  Defaults to `0.001`.\n       learning_rate_power: A float value, must be less or equal to zero.\n         Controls how the learning rate decreases during training. Use zero for a\n         fixed learning rate.\n       initial_accumulator_value: The starting value for accumulators. Only zero\n         or positive values are allowed.\n       l1_regularization_strength: A float value, must be greater than or equal\n-        to zero. Defaults to 0.0.\n+        to zero. Defaults to `0.0`.\n       l2_regularization_strength: A float value, must be greater than or equal\n-        to zero. Defaults to 0.0.\n+        to zero. Defaults to `0.0`.\n       l2_shrinkage_regularization_strength: A float value, must be greater than\n         or equal to zero. This differs from L2 above in that the L2 above is a\n         stabilization penalty, whereas this L2 shrinkage is a magnitude penalty.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#94e5ae89864d5353f05d91a318654ed8802ba984", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 8 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 83 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -44,17 +44,18 @@ class Adam(optimizer_v2.OptimizerV2):\n       learning_rate: A `Tensor`, floating point value, or a schedule that is a\n         `tf.keras.optimizers.schedules.LearningRateSchedule`, or a callable\n         that takes no arguments and returns the actual value to use, The\n-        learning rate. Defaults to 0.001.\n+        learning rate. Defaults to `0.001`.\n       beta_1: A float value or a constant float tensor, or a callable\n         that takes no arguments and returns the actual value to use. The\n-        exponential decay rate for the 1st moment estimates. Defaults to 0.9.\n+        exponential decay rate for the 1st moment estimates. Defaults to `0.9`.\n       beta_2: A float value or a constant float tensor, or a callable\n         that takes no arguments and returns the actual value to use, The\n-        exponential decay rate for the 2nd moment estimates. Defaults to 0.999.\n+        exponential decay rate for the 2nd moment estimates. Defaults to\n+        `0.999`.\n       epsilon: A small constant for numerical stability. This epsilon is\n         \"epsilon hat\" in the Kingma and Ba paper (in the formula just before\n         Section 2.1), not the epsilon in Algorithm 1 of the paper. Defaults to\n-        1e-7.\n+        `1e-7`.\n       amsgrad: Boolean. Whether to apply AMSGrad variant of this algorithm from\n         the paper \"On the Convergence of Adam and beyond\". Defaults to `False`.\n       name: Optional name for the operations created when applying gradients.\n@@ -364,19 +365,19 @@ class NonFusedAdam(optimizer_v2.OptimizerV2):\n           learning_rate: A `Tensor`, floating point value, or a schedule that is\n             a `tf.keras.optimizers.schedules.LearningRateSchedule`, or a\n             callable that takes no arguments and returns the actual value to\n-            use, The learning rate. Defaults to 0.001.\n+            use, The learning rate. Defaults to `0.001`.\n           beta_1: A float value or a constant float tensor, or a callable that\n             takes no arguments and returns the actual value to use. The\n             exponential decay rate for the 1st moment estimates. Defaults to\n-            0.9.\n+            `0.9`.\n           beta_2: A float value or a constant float tensor, or a callable that\n             takes no arguments and returns the actual value to use, The\n             exponential decay rate for the 2nd moment estimates. Defaults to\n-            0.999.\n+            `0.999`.\n           epsilon: A small constant for numerical stability. This epsilon is\n             \"epsilon hat\" in the Kingma and Ba paper (in the formula just before\n             Section 2.1), not the epsilon in Algorithm 1 of the paper. Defaults\n-            to 1e-7.\n+            to `1e-7`.\n           amsgrad: Boolean. Whether to apply AMSGrad variant of this algorithm\n             from the paper \"On the Convergence of Adam and beyond\". Defaults to\n             `False`.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e5d9ea94e38badb79e3cda006be449aed87f9e8e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 70 | Contributors (this commit): 4 | Commits (past 90d): 1 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -81,9 +81,9 @@ class Ftrl(optimizer_v2.OptimizerV2):\n       initial_accumulator_value: The starting value for accumulators.\n         Only zero or positive values are allowed.\n       l1_regularization_strength: A float value, must be greater than or\n-        equal to zero. Defaults to 0.0.\n+        equal to zero. Defaults to `0.0`.\n       l2_regularization_strength: A float value, must be greater than or\n-        equal to zero. Defaults to 0.0.\n+        equal to zero. Defaults to `0.0`.\n       name: Optional name prefix for the operations created when applying\n         gradients.  Defaults to `\"Ftrl\"`.\n       l2_shrinkage_regularization_strength: A float value, must be greater than\n@@ -91,7 +91,7 @@ class Ftrl(optimizer_v2.OptimizerV2):\n         stabilization penalty, whereas this L2 shrinkage is a magnitude penalty.\n         When input is sparse shrinkage will only happen on the active weights.\n       beta: A float value, representing the beta value from the paper.\n-        Defaults to 0.0.\n+        Defaults to `0.0`.\n       **kwargs: keyword arguments. Allowed arguments are `clipvalue`,\n         `clipnorm`, `global_clipnorm`.\n         If `clipvalue` (float) is set, the gradient of each weight\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4b7f5c1f2cdef5db4c083dca706dd70b03c9c78a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 11 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -37,17 +37,18 @@ class Nadam(optimizer.Optimizer):\n       learning_rate: A `tf.Tensor`, floating point value, a schedule that is a\n         `tf.keras.optimizers.schedules.LearningRateSchedule`, or a callable\n         that takes no arguments and returns the actual value to use. The\n-        learning rate. Defaults to 0.001.\n+        learning rate. Defaults to `0.001`.\n       beta_1: A float value or a constant float tensor, or a callable\n         that takes no arguments and returns the actual value to use. The\n-        exponential decay rate for the 1st moment estimates. Defaults to 0.9.\n+        exponential decay rate for the 1st moment estimates. Defaults to `0.9`.\n       beta_2: A float value or a constant float tensor, or a callable\n         that takes no arguments and returns the actual value to use. The\n-        exponential decay rate for the 2nd moment estimates. Defaults to 0.999.\n+        exponential decay rate for the 2nd moment estimates. Defaults to\n+        `0.999`.\n       epsilon: A small constant for numerical stability. This epsilon is\n         \"epsilon hat\" in the Kingma and Ba paper (in the formula just before\n         Section 2.1), not the epsilon in Algorithm 1 of the paper. Defaults to\n-        1e-7.\n+        `1e-7`.\n       {{base_optimizer_keyword_args}}\n \n     Reference:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a1cfd61d782dafa18fcdc5758c6efd31f382fd92", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 443 | Contributors (this commit): 3 | Commits (past 90d): 6 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -412,7 +412,7 @@ def deserialize_keras_object(\n       `keras.utils.register_keras_serializable(package, name)` API. The key has\n       the format of '{package}>{name}', where `package` and `name` are the\n       arguments passed to `register_keras_serializable()`. If `name` is not\n-      provided, it defaults to the class name. If `registered_name` successfully\n+      provided, it uses the class name. If `registered_name` successfully\n       resolves to a class (that was registered), the `class_name` and `config`\n       values in the dict will not be used. `registered_name` is only used for\n       non-built-in classes.\n@@ -485,7 +485,7 @@ def deserialize_keras_object(\n         safe_mode: Boolean, whether to disallow unsafe `lambda` deserialization.\n             When `safe_mode=False`, loading an object has the potential to\n             trigger arbitrary code execution. This argument is only\n-            applicable to the Keras v3 model format. Defaults to True.\n+            applicable to the Keras v3 model format. Defaults to `True`.\n \n     Returns:\n       The object described by the `config` dictionary.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d29e2abbb9c21ae8011c2ed6e1119e9fd76d6da1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 1866 | Contributors (this commit): 13 | Commits (past 90d): 4 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -41,11 +41,11 @@ def split_dataset(\n         left_size: If float (in the range `[0, 1]`), it signifies\n           the fraction of the data to pack in the left dataset. If integer, it\n           signifies the number of samples to pack in the left dataset. If\n-          `None`, it defaults to the complement to `right_size`.\n+          `None`, it uses the complement to `right_size`. Defaults to `None`.\n         right_size: If float (in the range `[0, 1]`), it signifies\n           the fraction of the data to pack in the right dataset. If integer, it\n           signifies the number of samples to pack in the right dataset. If\n-          `None`, it defaults to the complement to `left_size`.\n+          `None`, it uses the complement to `left_size`. Defaults to `None`.\n         shuffle: Boolean, whether to shuffle the data before splitting it.\n         seed: A random seed for shuffling.\n \n@@ -130,10 +130,10 @@ def _convert_dataset_to_list(\n         dataset_type_spec : the type of the dataset\n         data_size_warning_flag (bool, optional): If set to True, a warning will\n           be issued if the dataset takes longer than 10 seconds to iterate.\n-          Defaults to True.\n+          Defaults to `True`.\n         ensure_shape_similarity (bool, optional): If set to True, the shape of\n           the first sample will be used to validate the shape of rest of the\n-          samples. Defaults to True.\n+          samples. Defaults to `True`.\n \n     Returns:\n         List: A list of tuples/NumPy arrays.\n@@ -254,10 +254,10 @@ def _get_next_sample(\n         dataset_iterator : An `iterator` object.\n         ensure_shape_similarity (bool, optional): If set to True, the shape of\n           the first sample will be used to validate the shape of rest of the\n-          samples. Defaults to True.\n+          samples. Defaults to `True`.\n         data_size_warning_flag (bool, optional): If set to True, a warning will\n           be issued if the dataset takes longer than 10 seconds to iterate.\n-          Defaults to True.\n+          Defaults to `True`.\n         start_time (float): the start time of the dataset iteration. this is\n           used only if `data_size_warning_flag` is set to true.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5ca36f1b4753d1e8e864a76602dbdad2b7ee4768", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 788 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -105,12 +105,12 @@ class FeatureSpace(base_layer.Layer):\n             \"crossed\" by hashing their combined value into\n             a fixed-length vector.\n         crossing_dim: Default vector size for hashing crossed features.\n-            Defaults to 32.\n+            Defaults to `32`.\n         hashing_dim: Default vector size for hashing features of type\n-            `\"integer_hashed\"` and `\"string_hashed\"`. Defaults to 32.\n+            `\"integer_hashed\"` and `\"string_hashed\"`. Defaults to `32`.\n         num_discretization_bins: Default number of bins to be used for\n             discretizing features of type `\"float_discretized\"`.\n-            Defaults to 32.\n+            Defaults to `32`.\n \n     **Available feature types:**\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#901950201d867c85ec34f4d0c9201aea2c15a65d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 37 | Lines Deleted: 11 | Files Changed: 3 | Hunks: 10 | Methods Changed: 7 | Complexity Δ (Sum/Max): 6/4 | Churn Δ: 48 | Churn Cumulative: 522 | Contributors (this commit): 2 | Commits (past 90d): 9 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -213,7 +213,29 @@ def load_model(\n     It is recommended that you use layer attributes to\n     access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.\n     \"\"\"\n-    if str(filepath).endswith(\".keras\") and zipfile.is_zipfile(filepath):\n+    is_keras_zip = str(filepath).endswith(\".keras\") and zipfile.is_zipfile(\n+        filepath\n+    )\n+\n+    # Support for remote zip files\n+    if (\n+        saving_lib.is_remote_path(filepath)\n+        and not tf.io.gfile.isdir(filepath)\n+        and not is_keras_zip\n+    ):\n+        local_path = os.path.join(\n+            saving_lib.get_temp_dir(), os.path.basename(filepath)\n+        )\n+\n+        # Copy from remote to temporary local directory\n+        tf.io.gfile.copy(filepath, local_path, overwrite=True)\n+\n+        # Switch filepath to local zipfile for loading model\n+        if zipfile.is_zipfile(local_path):\n+            filepath = local_path\n+            is_keras_zip = True\n+\n+    if is_keras_zip:\n         if kwargs:\n             raise ValueError(\n                 \"The following argument(s) are not supported \"\n\n@@ -157,12 +157,10 @@ def save_model(model, filepath, weights_format=\"h5\"):\n         }\n     )\n     # TODO(rameshsampath): Need a better logic for local vs remote path\n-    if re.match(r\"^(/cns|/cfs|.*://).*$\", filepath):\n+    if is_remote_path(filepath):\n         # Remote path. Zip to local drive and copy to remote\n-        is_remote_path = True\n-        zip_filepath = os.path.join(_get_temp_dir(), \"tmp_model.keras\")\n+        zip_filepath = os.path.join(get_temp_dir(), \"tmp_model.keras\")\n     else:\n-        is_remote_path = False\n         zip_filepath = filepath\n     try:\n         with zipfile.ZipFile(zip_filepath, \"w\") as zf:\n@@ -199,7 +197,7 @@ def save_model(model, filepath, weights_format=\"h5\"):\n             weights_store.close()\n             asset_store.close()\n \n-        if is_remote_path:\n+        if is_remote_path(filepath):\n             # Using tf.io.gfile context manager doesn't close zip file when\n             # writing to GCS. Hence writing to local and copying to filepath.\n             tf.io.gfile.copy(zip_filepath, filepath, overwrite=True)\n@@ -337,6 +335,12 @@ def load_weights_only(model, filepath, skip_mismatch=False):\n         archive.close()\n \n \n+def is_remote_path(filepath):\n+    if re.match(r\"^(/cns|/cfs|/gcs|.*://).*$\", str(filepath)):\n+        return True\n+    return False\n+\n+\n def _write_to_zip_recursively(zipfile_to_save, system_path, zip_path):\n     if not tf.io.gfile.isdir(system_path):\n         zipfile_to_save.write(system_path, zip_path)\n@@ -532,7 +536,7 @@ class DiskIOStore:\n         self.archive = archive\n         self.tmp_dir = None\n         if self.archive:\n-            self.tmp_dir = _get_temp_dir()\n+            self.tmp_dir = get_temp_dir()\n             if self.mode == \"r\":\n                 self.archive.extractall(path=self.tmp_dir)\n             self.working_dir = tf.io.gfile.join(self.tmp_dir, self.root_path)\n@@ -542,7 +546,7 @@ class DiskIOStore:\n             if mode == \"r\":\n                 self.working_dir = root_path\n             else:\n-                self.tmp_dir = _get_temp_dir()\n+                self.tmp_dir = get_temp_dir()\n                 self.working_dir = tf.io.gfile.join(\n                     self.tmp_dir, self.root_path\n                 )\n@@ -667,7 +671,7 @@ class NpzIOStore:\n         self.f.close()\n \n \n-def _get_temp_dir():\n+def get_temp_dir():\n     temp_dir = tempfile.mkdtemp()\n     testfile = tempfile.TemporaryFile(dir=temp_dir)\n     testfile.close()\n\n@@ -543,8 +543,8 @@ class SavingV3Test(tf.test.TestCase, parameterized.TestCase):\n             # Mock Remote Path check to true to test gfile copy logic\n             mock_re_match.return_value = True\n             model._save_experimental(temp_filepath)\n-            mock_re_match.assert_called_once()\n-            mock_copy.assert_called_once()\n+            mock_re_match.assert_called()\n+            mock_copy.assert_called()\n             self.assertIn(str(temp_filepath), mock_re_match.call_args.args)\n             self.assertIn(str(temp_filepath), mock_copy.call_args.args)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9603567415ce44e45775b101dc290c9c7f2c53e3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 11063 | Contributors (this commit): 40 | Commits (past 90d): 8 | Contributors (cumulative): 40 | DMM Complexity: None\n\nDIFF:\n@@ -3830,8 +3830,8 @@ class BaseRandomLayer(Layer):\n           force_generator: boolean, default to False, whether to force the\n             RandomGenerator to use the code branch of tf.random.Generator.\n           rng_type: string, the rng type that will be passed to backend\n-            RandomGenerator. `None`, will allow RandomGenerator\n-            to choose types by itself. Valid values are \"stateful\", \"stateless\",\n+            RandomGenerator. `None` will allow RandomGenerator to choose\n+            types by itself. Valid values are \"stateful\", \"stateless\",\n             \"legacy_stateful\". Defaults to `None`.\n           **kwargs: other keyword arguments that will be passed to the parent\n             *class\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6ce7aacdb1a1afc190d747b8ad809164f49f9f8e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 659 | Contributors (this commit): 10 | Commits (past 90d): 2 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -189,9 +189,9 @@ class RandomUniform(tf.compat.v1.random_uniform_initializer):\n \n     Args:\n       minval: A python scalar or a scalar tensor. Lower bound of the range of\n-        random values to generate.\n+        random values to generate. Defaults to `-0.05`.\n       maxval: A python scalar or a scalar tensor. Upper bound of the range of\n-        random values to generate. Float default is 1. Defaults to `1.`.\n+        random values to generate. Defaults to `0.05`.\n       seed: A Python integer. Used to create random seeds. See\n         `tf.compat.v1.set_random_seed` for behavior.\n       dtype: Default data type, used if no `dtype` argument is provided when\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0e61e2c98ece2a82d78415650c9cacfc005a12a1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 285 | Contributors (this commit): 7 | Commits (past 90d): 2 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -83,8 +83,8 @@ class Conv3D(Conv):\n         `channels_last` corresponds to inputs with shape `batch_shape +\n         (spatial_dim1, spatial_dim2, spatial_dim3, channels)` while\n         `channels_first` corresponds to inputs with shape `batch_shape +\n-        (channels, spatial_dim1, spatial_dim2, spatial_dim3)`. When unspecified, uses\n-        `image_data_format` value found in your Keras config file at\n+        (channels, spatial_dim1, spatial_dim2, spatial_dim3)`. When unspecified,\n+        uses `image_data_format` value found in your Keras config file at\n         `~/.keras/keras.json` (if exists) else 'channels_last'. Note that the\n         `channels_first` format is currently not supported by TensorFlow on CPU.\n         Defaults to 'channels_first'.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e04a1c469423b9dfd6286e65172bfee1184367d2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 276 | Contributors (this commit): 5 | Commits (past 90d): 2 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -70,9 +70,8 @@ class SeparableConv2D(SeparableConv):\n         `(batch_size, height, width, channels)` while `channels_first`\n         corresponds to inputs with shape\n         `(batch_size, channels, height, width)`.\n-        When unspecified, uses\n-        `image_data_format` value found in your Keras config file at\n-         `~/.keras/keras.json` (if exists) else 'channels_last'.\n+        When unspecified, uses `image_data_format` value found in your Keras\n+        config file at `~/.keras/keras.json` (if exists) else 'channels_last'.\n         Defaults to 'channels_last'.\n       dilation_rate: An integer or tuple/list of 2 integers, specifying\n         the dilation rate to use for dilated convolution.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#09b09d2c67d6fbdc4366549bb222613653f9c1b3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 287 | Contributors (this commit): 7 | Commits (past 90d): 3 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -87,7 +87,7 @@ class Conv3D(Conv):\n         uses `image_data_format` value found in your Keras config file at\n         `~/.keras/keras.json` (if exists) else 'channels_last'. Note that the\n         `channels_first` format is currently not supported by TensorFlow on CPU.\n-        Defaults to 'channels_first'.\n+        Defaults to 'channels_last'.\n       dilation_rate: an integer or tuple/list of 3 integers, specifying the\n         dilation rate to use for dilated convolution. Can be a single integer to\n         specify the same value for all spatial dimensions. Currently, specifying\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#71fee88e07219d1213fbc15b255c6b3fa398be72", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 183 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -65,11 +65,11 @@ class ReLU(Layer):\n       Same shape as the input.\n \n     Args:\n-      max_value: Float >= 0. Maximum activation value. None\n-        means unlimited. Defaults to `None`.\n+      max_value: Float >= 0. Maximum activation value. None means unlimited.\n+        Defaults to `None`.\n       negative_slope: Float >= 0. Negative slope coefficient. Defaults to `0.`.\n-      threshold: Float >= 0. Threshold value for thresholded activation. Default\n-        to 0.\n+      threshold: Float >= 0. Threshold value for thresholded activation.\n+        Defaults to `0.`.\n     \"\"\"\n \n     def __init__(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c56f664e339f8c1e91a0e9b45fc39762b93c08b9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 25 | Files Changed: 1 | Hunks: 13 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 49 | Churn Cumulative: 64 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -36,42 +36,41 @@ _ALLOWED_INITIALIZER_KWARGS = [_PARTITION_SHAPE, _PARTITION_OFFSET, _LAYOUT]\n class Initializer:\n     \"\"\"Initializer base class: all Keras initializers inherit from this class.\n \n-    Initializers should implement a `__call__` method with the following\n+    Initializers should implement a `__call__()` method with the following\n     signature:\n \n     ```python\n     def __call__(self, shape, dtype=None, **kwargs):\n         # returns a tensor of shape `shape` and dtype `dtype`\n         # containing values drawn from a distribution of your choice.\n+        return tf.random.uniform(shape=shape, dtype=dtype)\n     ```\n \n-    Optionally, you an also implement the method `get_config` and the class\n-    method `from_config` in order to support serialization -- just like with\n+    Optionally, you an also implement the method `get_config()` and the class\n+    method `from_config()` in order to support serialization -- just like with\n     any Keras object.\n \n     Here's a simple example: a random normal initializer.\n \n     ```python\n-    import tensorflow as tf\n-\n-    class ExampleRandomNormal(tf.keras.initializers.Initializer):\n-\n+    class ExampleRandomNormal(Initializer):\n         def __init__(self, mean, stddev):\n             self.mean = mean\n             self.stddev = stddev\n \n         def __call__(self, shape, dtype=None, **kwargs):\n             return tf.random.normal(\n-            shape, mean=self.mean, stddev=self.stddev, dtype=dtype)\n+                shape, mean=self.mean, stddev=self.stddev, dtype=dtype\n+            )\n \n         def get_config(self):  # To support serialization\n             return {\"mean\": self.mean, \"stddev\": self.stddev}\n     ```\n \n-    Note that we don't have to implement `from_config` in the example above\n+    Note that we don't have to implement `from_config()` in the example above\n     since the constructor arguments of the class the keys in the config returned\n-    by `get_config` are the same. In this case, the default `from_config` works\n-    fine.\n+    by `get_config` are the same. In this case, the default `from_config()`\n+    works fine.\n     \"\"\"\n \n     def __call__(self, shape, dtype=None, **kwargs):\n@@ -107,10 +106,10 @@ class Initializer:\n         ```\n \n         Args:\n-          config: A Python dictionary, the output of `get_config`.\n+            config: A Python dictionary, the output of `get_config()`.\n \n         Returns:\n-          A `tf.keras.initializers.Initializer` instance.\n+            An `Initializer` instance.\n         \"\"\"\n         config.pop(\"dtype\", None)\n         return cls(**config)\n@@ -153,9 +152,9 @@ class Zeros(Initializer):\n         Args:\n             shape: Shape of the tensor.\n             dtype: Optional dtype of the tensor. Only numeric or boolean dtypes\n-            are supported. If not specified, `tf.keras.backend.floatx()` is\n-            used, which default to `float32` unless you configured it otherwise\n-            (via `tf.keras.backend.set_floatx(float_dtype)`).\n+                are supported. If not specified, `keras.backend.floatx()` is\n+                used, which defaults to `float32` unless you configured it\n+                otherwise (via `keras.backend.set_floatx(float_dtype)`).\n             **kwargs: Additional keyword arguments.\n         \"\"\"\n         _validate_kwargs(self.__class__.__name__, kwargs)\n@@ -195,9 +194,9 @@ class Ones(Initializer):\n         Args:\n             shape: Shape of the tensor.\n             dtype: Optional dtype of the tensor. Only numeric or boolean dtypes\n-            are supported. If not specified, `tf.keras.backend.floatx()` is\n-            used, which default to `float32` unless you configured it otherwise\n-            (via `tf.keras.backend.set_floatx(float_dtype)`).\n+                are supported. If not specified, `keras.backend.floatx()` is\n+                used, which defaults to `float32` unless you configured it\n+                otherwise (via `keras.backend.set_floatx(float_dtype)`).\n             **kwargs: Additional keyword arguments.\n         \"\"\"\n         _validate_kwargs(self.__class__.__name__, kwargs)\n@@ -249,9 +248,9 @@ class Constant(Initializer):\n         Args:\n             shape: Shape of the tensor.\n             dtype: Optional dtype of the tensor. If not specified,\n-           `tf.keras.backend.floatx()` is used,\n-           which default to `float32` unless you configured it otherwise\n-           (via `tf.keras.backend.set_floatx(float_dtype)`).\n+                `keras.backend.floatx()` is used,\n+                which defaults to `float32` unless you configured it\n+                otherwise (via `keras.backend.set_floatx(float_dtype)`).\n                 **kwargs: Additional keyword arguments.\n         \"\"\"\n         _validate_kwargs(self.__class__.__name__, kwargs)\n@@ -567,9 +566,9 @@ class VarianceScaling(Initializer):\n \n     Args:\n         scale: Scaling factor (positive float).\n-      mode: One of \"fan_in\", \"fan_out\", \"fan_avg\".\n-      distribution: Random distribution to use. One of \"truncated_normal\",\n-        \"untruncated_normal\" and  \"uniform\".\n+        mode: One of `\"fan_in\"`, `\"fan_out\"`, `\"fan_avg\"`.\n+        distribution: Random distribution to use. One of `\"truncated_normal\"`,\n+            `\"untruncated_normal\"`, or `\"uniform\"`.\n         seed: A Python integer. Used to make the behavior of the initializer\n             deterministic. Note that a seeded initializer will produce the same\n             random values across multiple calls.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#44e91ce16fd27658623c6e0bf114ae897e7c11c5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 45 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 16 | Methods Changed: 6 | Complexity Δ (Sum/Max): 13/10 | Churn Δ: 52 | Churn Cumulative: 3917 | Contributors (this commit): 18 | Commits (past 90d): 6 | Contributors (cumulative): 19 | DMM Complexity: 0.0\n\nDIFF:\n@@ -19,8 +19,8 @@ import tensorflow.compat.v2 as tf\n from absl.testing import parameterized\n \n from keras import backend\n+from keras import mixed_precision\n from keras.dtensor import integration_test_utils\n-from keras.dtensor import test_util\n from keras.optimizers import adam\n from keras.utils import tf_utils\n \n@@ -30,6 +30,7 @@ from keras.utils import tf_utils\n from tensorflow.python.distribute.experimental import (\n     mirrored_strategy as dtensor_mirrored_strategy,\n )\n+from tensorflow.dtensor.python.tests import test_util\n \n \n class TrainingTest(test_util.DTensorBaseTest):\n@@ -40,23 +41,41 @@ class TrainingTest(test_util.DTensorBaseTest):\n         global_ids = test_util.create_device_ids_array((2,))\n         local_device_ids = np.ravel(global_ids).tolist()\n         mesh_dict = {\n-            \"CPU\": tf.experimental.dtensor.Mesh(\n+            device: tf.experimental.dtensor.Mesh(\n                 [\"batch\"],\n                 global_ids,\n                 local_device_ids,\n-                test_util.create_device_list((2,), \"CPU\"),\n+                test_util.create_device_list((2,), device),\n             )\n+            for device in (\"CPU\", \"GPU\", \"TPU\")\n         }\n         self.mesh = self.configTestMesh(mesh_dict)\n \n+    def tearDown(self):\n+        super().tearDown()\n+        # clean up the mixed precision setting if any.\n+        mixed_precision.set_global_policy(\"float32\")\n+\n     @parameterized.product(\n         run_eagerly=[True, False],\n         jit_compile=[True, False],\n         optimizer_creator=[lambda: adam.Adam(), lambda: \"adam\"],\n+        enable_mixed_precision=[True, False],\n     )\n-    def test_model_fit(self, run_eagerly, jit_compile, optimizer_creator):\n+    def test_model_fit(\n+        self,\n+        run_eagerly,\n+        jit_compile,\n+        optimizer_creator,\n+        enable_mixed_precision,\n+    ):\n         if run_eagerly and jit_compile:\n             self.skipTest(\"run_eagerly can't run with jit_compile\")\n+        if enable_mixed_precision and self.mesh.device_type() != \"GPU\":\n+            self.skipTest(\"Only run mixed_precision on GPU for performance\")\n+\n+        if enable_mixed_precision:\n+            mixed_precision.set_global_policy(\"mixed_float16\")\n         dtensor_strategy = dtensor_mirrored_strategy.MirroredStrategy(\n             mesh=self.mesh\n         )\n@@ -89,6 +108,9 @@ class TrainingTest(test_util.DTensorBaseTest):\n             np.random.uniform(size=(batch_size, 28, 28, 1)).astype(np.float32)\n         )\n         self.assertEqual(prediction.shape, (batch_size, 10))\n+        if enable_mixed_precision:\n+            self.assertEqual(prediction.dtype, tf.float16)\n+        else:\n             self.assertEqual(prediction.dtype, tf.float32)\n \n \n\n@@ -18,6 +18,7 @@ import tensorflow.compat.v2 as tf\n \n from keras import backend\n from keras import optimizers\n+from keras.dtensor import utils as dtensor_utils\n from keras.optimizers import optimizer\n from keras.optimizers import utils as optimizer_utils\n from keras.optimizers.legacy import optimizer_v2\n@@ -1282,7 +1283,19 @@ class LossScaleOptimizerV3(\n         experimental_aggregate_gradients = kwargs.pop(\n             \"experimental_aggregate_gradients\", True\n         )\n-        if not skip_gradients_aggregation and experimental_aggregate_gradients:\n+        run_with_dtensor = (\n+            # `_run_with_dtensor` is for dtensor based strategy scope, and\n+            # `_mesh` is when user explicitly specify the mesh setting for\n+            # optimizer.\n+            self._optimizer._run_with_dtensor\n+            or self._optimizer._mesh\n+        )\n+\n+        if (\n+            not skip_gradients_aggregation\n+            and experimental_aggregate_gradients\n+            and not run_with_dtensor\n+        ):\n             # We must aggregate the gradients here instead of in\n             # self.optimizer.apply_gradients, so that any NaN or Inf gradients\n             # are propagated to each replica. If any replica has a NaN or Inf\n@@ -1549,17 +1562,20 @@ def strategy_supports_loss_scaling():\n     # variable replica for each compute replica, this works fine, but otherwise\n     # issues will occur.\n     # TODO(reedwm): Support all strategies.\n-    return isinstance(\n+    return (\n+        isinstance(\n             strategy,\n             (\n                 tf.distribute.MultiWorkerMirroredStrategy,\n-            tf.compat.v1.distribute.experimental.MultiWorkerMirroredStrategy,\n+                tf.compat.v1.distribute.experimental.MultiWorkerMirroredStrategy,  # noqa: E501\n                 tf.distribute.OneDeviceStrategy,\n                 tf.compat.v1.distribute.OneDeviceStrategy,\n                 tf.distribute.MirroredStrategy,\n                 tf.compat.v1.distribute.MirroredStrategy,\n             ),\n         )\n+        or dtensor_utils.running_with_dtensor_strategy()\n+    )\n \n \n def _raise_if_strategy_unsupported():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e24cf471b5b51a822b78e01ebab00ac74d333fa7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 17 | Churn Cumulative: 21383 | Contributors (this commit): 144 | Commits (past 90d): 16 | Contributors (cumulative): 144 | DMM Complexity: 0.0\n\nDIFF:\n@@ -4352,10 +4352,13 @@ def inject_functional_model_class(cls):\n \n \n def is_functional_model_init_params(args, kwargs):\n-    return (\n-        len(args) == 2\n-        or len(args) == 1\n-        and \"outputs\" in kwargs\n-        or \"inputs\" in kwargs\n-        and \"outputs\" in kwargs\n-    )\n+    # Both inputs and outputs in args\n+    if len(args) == 2:\n+        return True\n+    # Both inputs in args, outputs in kwargs\n+    if len(args) == 1 and \"outputs\" in kwargs:\n+        return True\n+    # Both in kwargs\n+    if \"inputs\" in kwargs and \"outputs\" in kwargs:\n+        return True\n+    return False\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b87b65658c89d8b2978290be0c8709c69c7d35c1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 11061 | Contributors (this commit): 25 | Commits (past 90d): 14 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -5651,7 +5651,7 @@ def categorical_focal_crossentropy(\n     )\n \n     if from_logits:\n-        output = softmax(output, axis=axis)\n+        output = tf.nn.softmax(output, axis=axis)\n \n     # Adjust the predictions so that the probability of\n     # each class for every sample adds up to 1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c225ac74adbe8fbc9d91d4775b04981bc2cc9364", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 6 | Churn Cumulative: 127 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -248,6 +248,12 @@ class SidecarEvaluator:\n                     # iteration value.\n                     self.model.optimizer.iterations.assign(self._iterations)\n             except (tf.errors.OpError,) as e:\n+                if isinstance(e, tf.errors.UnavailableError):\n+                    # With distribute training, worker preemption can result in\n+                    # `UnavailableError`. Raise this to be handled outside the\n+                    # evaluation loop.\n+                    raise e\n+\n                 # A couple errors can happen here with the coordinator racing to\n                 # write checkpoint:\n                 # 1) OpError: open failed for <file path>: No such file or\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5a77d20459d4cb4267ab6ca22ad92222b0ac9510", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 44 | Lines Deleted: 45 | Files Changed: 4 | Hunks: 11 | Methods Changed: 7 | Complexity Δ (Sum/Max): 1/8 | Churn Δ: 89 | Churn Cumulative: 13884 | Contributors (this commit): 41 | Commits (past 90d): 15 | Contributors (cumulative): 69 | DMM Complexity: 1.0\n\nDIFF:\n@@ -38,7 +38,6 @@ from keras.engine import input_spec\n from keras.engine import keras_tensor\n from keras.engine import node as node_module\n from keras.mixed_precision import autocast_variable\n-from keras.mixed_precision import loss_scale_optimizer\n from keras.mixed_precision import policy\n from keras.saving import serialization_lib\n from keras.saving.legacy.saved_model import layer_serialization\n@@ -2705,37 +2704,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n \n     def _set_dtype_policy(self, dtype):\n         \"\"\"Sets self._dtype_policy.\"\"\"\n-        if isinstance(dtype, policy.Policy):\n-            self._dtype_policy = dtype\n-        elif isinstance(dtype, dict):\n-            self._dtype_policy = policy.deserialize(dtype)\n-        elif isinstance(dtype, str) and dtype in (\n-            \"mixed_float16\",\n-            \"mixed_bfloat16\",\n-        ):\n-            # The isinstance check is required since np.dtype raises an error if\n-            # compared to a non-dtype string.\n-            self._dtype_policy = policy.Policy(dtype)\n-        elif dtype:\n-            self._dtype_policy = policy.Policy(tf.as_dtype(dtype).name)\n-        else:\n-            self._dtype_policy = policy.global_policy()\n-        if (\n-            self._dtype_policy.name == \"mixed_float16\"\n-            and not loss_scale_optimizer.strategy_supports_loss_scaling()\n-        ):\n-            # Although only loss scaling doesn't support certain strategies, to\n-            # avoid confusion, we disallow the 'mixed_float16' policy with\n-            # unsupported strategies. This is because 'mixed_float16' requires\n-            # loss scaling for numeric stability.\n-            strategy = tf.distribute.get_strategy()\n-            raise ValueError(\n-                \"Mixed precision is not supported with the \"\n-                \"tf.distribute.Strategy: %s. Either stop using mixed \"\n-                'precision by removing the use of the \"%s\" policy or '\n-                \"use a different Strategy, e.g. a MirroredStrategy.\"\n-                % (strategy.__class__.__name__, self._dtype_policy.name)\n-            )\n+        self._dtype_policy = policy.get_policy(dtype)\n \n         # Performance optimization: cache the compute dtype as a Dtype object or\n         # None, so that str to Dtype conversion doesn't happen in\n\n@@ -466,10 +466,7 @@ class LayerTest(test_combinations.TestCase):\n         with strategy.scope(), self.assertRaisesRegex(\n             ValueError,\n             \"Mixed precision is not supported with the \"\n-            \"tf.distribute.Strategy: CentralStorageStrategy. Either \"\n-            \"stop using mixed precision by removing the use of the \"\n-            '\"mixed_float16\" policy or use a different Strategy, e.g. '\n-            \"a MirroredStrategy.\",\n+            \"tf.distribute.Strategy: CentralStorageStrategy.\",\n         ):\n             mp_test_util.MultiplyLayer(dtype=\"mixed_float16\")\n         # Non-mixed policies are fine\n\n@@ -21,6 +21,7 @@ import tensorflow.compat.v2 as tf\n from keras import backend\n from keras.engine import base_layer_utils\n from keras.mixed_precision import device_compatibility_check\n+from keras.mixed_precision import loss_scale_optimizer\n from keras.saving import serialization_lib\n \n # isort: off\n@@ -191,7 +192,7 @@ class Policy:\n         if isinstance(name, tf.DType):\n             raise TypeError(\n                 \"'name' must be a string, not a DType. \"\n-                \"Instead, pass DType.name. Got: %s\" % (name.name,)\n+                f\"Instead, pass DType.name. Received: name={name.name}\"\n             )\n         elif not isinstance(name, str):\n             raise TypeError(f\"'name' must be a string, but got: {name}\")\n@@ -246,12 +247,11 @@ class Policy:\n         try:\n             dtype = tf.as_dtype(name).name\n         except TypeError:\n-            error = (\n-                \"Cannot convert value %s to a mixed precision Policy. \"\n+            raise ValueError(\n+                f\"Cannot convert value {name} to a mixed precision Policy. \"\n                 \"Valid policies include 'mixed_float16', 'mixed_bfloat16', \"\n-                \"and the name of any dtype such as 'float32'.\" % (name,)\n+                \"and the name of any dtype such as 'float32'.\"\n             )\n-            raise ValueError(error)\n         return dtype, dtype\n \n     @property\n@@ -440,7 +440,7 @@ def set_global_policy(policy):\n         raise ValueError(\n             \"set_global_policy can only be used to set the global \"\n             'policy to floating-point policies, such as \"float32\" and '\n-            '\"mixed_float16\", but got policy: %s' % (policy.name,)\n+            f'\"mixed_float16\", but got policy: {policy.name}'\n         )\n     _global_policy = policy\n     tf.__internal__.train.set_using_mixed_precision_policy(is_mixed_policy)\n@@ -465,6 +465,41 @@ def policy_scope(policy):\n         set_global_policy(old_policy)\n \n \n+def get_policy(identifier):\n+    if isinstance(identifier, Policy):\n+        dtype_policy = identifier\n+    elif isinstance(identifier, dict):\n+        dtype_policy = deserialize(identifier)\n+    elif isinstance(identifier, str) and identifier in (\n+        \"mixed_float16\",\n+        \"mixed_bfloat16\",\n+    ):\n+        # The isinstance check is required since np.dtype raises an error if\n+        # compared to a non-dtype string.\n+        dtype_policy = Policy(identifier)\n+    elif identifier:\n+        dtype_policy = Policy(tf.as_dtype(identifier).name)\n+    else:\n+        dtype_policy = global_policy()\n+    if (\n+        dtype_policy.name == \"mixed_float16\"\n+        and not loss_scale_optimizer.strategy_supports_loss_scaling()\n+    ):\n+        # Although only loss scaling doesn't support certain strategies, to\n+        # avoid confusion, we disallow the 'mixed_float16' policy with\n+        # unsupported strategies. This is because 'mixed_float16' requires\n+        # loss scaling for numeric stability.\n+        strategy = tf.distribute.get_strategy()\n+        raise ValueError(\n+            \"Mixed precision is not supported with the \"\n+            f\"tf.distribute.Strategy: {strategy.__class__.__name__}. \"\n+            \"Either stop using mixed precision by removing the use of \"\n+            f\"the {dtype_policy.name} policy or \"\n+            \"use a different Strategy, e.g. a MirroredStrategy.\"\n+        )\n+    return dtype_policy\n+\n+\n def _is_convertible_to_dtype(dtype):\n     try:\n         tf.as_dtype(dtype)\n\n@@ -75,9 +75,7 @@ class PolicyTest(tf.test.TestCase, parameterized.TestCase):\n \n         # Test passing a DType\n         with self.assertRaisesRegex(\n-            TypeError,\n-            \"'name' must be a string, not a DType. \"\n-            \"Instead, pass DType.name. Got: float16\",\n+            TypeError, \"'name' must be a string, not a DType. \"\n         ):\n             mp_policy.Policy(tf.float16)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
