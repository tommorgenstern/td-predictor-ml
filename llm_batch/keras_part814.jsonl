{"custom_id": "keras#61d85f33c42cc898536bb8ee04cadbca11019a4f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 103 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 4 | Methods Changed: 9 | Complexity Δ (Sum/Max): 9/7 | Churn Δ: 103 | Churn Cumulative: 182 | Contributors (this commit): 3 | Commits (past 90d): 8 | Contributors (cumulative): 7 | DMM Complexity: 0.9358974358974359\n\nDIFF:\n@@ -204,6 +204,12 @@ def istft(\n     x = _get_complex_tensor_from_tuple(x)\n     dtype = jnp.real(x).dtype\n \n+    if len(x.shape) < 2:\n+        raise ValueError(\n+            f\"Input `x` must have at least 2 dimensions. \"\n+            f\"Received shape: {x.shape}\"\n+        )\n+\n     expected_output_len = fft_length + sequence_stride * (x.shape[-2] - 1)\n     l_pad = (fft_length - sequence_length) // 2\n     r_pad = fft_length - sequence_length - l_pad\n\n@@ -101,6 +101,15 @@ class LinalgOpsDynamicShapeTest(testing.TestCase):\n         self.assertEqual(q.shape, qref_shape)\n         self.assertEqual(r.shape, rref_shape)\n \n+    def test_qr_invalid_mode(self):\n+        # backend agnostic error message\n+        x = np.array([[1, 2], [3, 4]])\n+        invalid_mode = \"invalid_mode\"\n+        with self.assertRaisesRegex(\n+            ValueError, \"Expected one of {'reduced', 'complete'}.\"\n+        ):\n+            linalg.qr(x, mode=invalid_mode)\n+\n     def test_solve(self):\n         a = KerasTensor([None, 20, 20])\n         b = KerasTensor([None, 20, 5])\n\n@@ -1,5 +1,6 @@\n import math\n \n+import jax.numpy as jnp\n import numpy as np\n import pytest\n import scipy.signal\n@@ -1256,3 +1257,90 @@ class ISTFTTest(testing.TestCase):\n         expected_shape = real_part.shape[:-1] + (None,)\n \n         self.assertEqual(output_spec.shape, expected_shape)\n+\n+\n+class TestMathErrors(testing.TestCase):\n+\n+    @pytest.mark.skipif(\n+        backend.backend() != \"jax\", reason=\"Testing Jax errors only\"\n+    )\n+    def test_segment_sum_no_num_segments(self):\n+        data = jnp.array([1, 2, 3, 4])\n+        segment_ids = jnp.array([0, 0, 1, 1])\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"Argument `num_segments` must be set when using the JAX backend.\",\n+        ):\n+            kmath.segment_sum(data, segment_ids)\n+\n+    @pytest.mark.skipif(\n+        backend.backend() != \"jax\", reason=\"Testing Jax errors only\"\n+    )\n+    def test_segment_max_no_num_segments(self):\n+        data = jnp.array([1, 2, 3, 4])\n+        segment_ids = jnp.array([0, 0, 1, 1])\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"Argument `num_segments` must be set when using the JAX backend.\",\n+        ):\n+            kmath.segment_max(data, segment_ids)\n+\n+    def test_stft_invalid_input_type(self):\n+        # backend agnostic error message\n+        x = np.array([1, 2, 3, 4])\n+        sequence_length = 2\n+        sequence_stride = 1\n+        fft_length = 4\n+        with self.assertRaisesRegex(TypeError, \"`float32` or `float64`\"):\n+            kmath.stft(x, sequence_length, sequence_stride, fft_length)\n+\n+    def test_invalid_fft_length(self):\n+        # backend agnostic error message\n+        x = np.array([1.0, 2.0, 3.0, 4.0])\n+        sequence_length = 4\n+        sequence_stride = 1\n+        fft_length = 2\n+        with self.assertRaisesRegex(ValueError, \"`fft_length` must equal or\"):\n+            kmath.stft(x, sequence_length, sequence_stride, fft_length)\n+\n+    def test_stft_invalid_window(self):\n+        # backend agnostic error message\n+        x = np.array([1.0, 2.0, 3.0, 4.0])\n+        sequence_length = 2\n+        sequence_stride = 1\n+        fft_length = 4\n+        window = \"invalid_window\"\n+        with self.assertRaisesRegex(ValueError, \"If a string is passed to\"):\n+            kmath.stft(\n+                x, sequence_length, sequence_stride, fft_length, window=window\n+            )\n+\n+    def test_stft_invalid_window_shape(self):\n+        # backend agnostic error message\n+        x = np.array([1.0, 2.0, 3.0, 4.0])\n+        sequence_length = 2\n+        sequence_stride = 1\n+        fft_length = 4\n+        window = np.ones((sequence_length + 1))\n+        with self.assertRaisesRegex(ValueError, \"The shape of `window` must\"):\n+            kmath.stft(\n+                x, sequence_length, sequence_stride, fft_length, window=window\n+            )\n+\n+    def test_istft_invalid_window_shape_2D_inputs(self):\n+        # backend agnostic error message\n+        x = (np.array([[1.0, 2.0]]), np.array([[3.0, 4.0]]))\n+        sequence_length = 2\n+        sequence_stride = 1\n+        fft_length = 4\n+        incorrect_window = np.ones((sequence_length + 1,))\n+        with self.assertRaisesRegex(\n+            ValueError, \"The shape of `window` must be equal to\"\n+        ):\n+            kmath.istft(\n+                x,\n+                sequence_length,\n+                sequence_stride,\n+                fft_length,\n+                window=incorrect_window,\n+            )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9f4da5159a098256dfbccd2c926107953a6812e5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 51 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -234,7 +234,8 @@ def is_tensor(x):\n \n \n def shape(x):\n-    return x.shape\n+    # Convert from `torch.Size` to plain tuple.\n+    return tuple(x.shape)\n \n \n def cast(x, dtype):\n\n@@ -338,10 +338,12 @@ class CoreOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(x, y)\n \n     def test_shape(self):\n-        x = np.ones((2, 3, 7, 1))\n+        x = ops.ones((2, 3, 7, 1))\n+        self.assertEqual(core.shape(x).__class__, tuple)\n         self.assertAllEqual(core.shape(x), (2, 3, 7, 1))\n \n         x = KerasTensor((None, 3, None, 1))\n+        self.assertEqual(core.shape(x).__class__, tuple)\n         self.assertAllEqual(core.shape(x), (None, 3, None, 1))\n \n     @pytest.mark.skipif(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f01e99a6b6b728187373ef0b57a485a0059fcd05", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 22 | Churn Cumulative: 646 | Contributors (this commit): 6 | Commits (past 90d): 14 | Contributors (cumulative): 11 | DMM Complexity: 0.0\n\nDIFF:\n@@ -252,6 +252,12 @@ def conv(\n         # If kernel's in_channel does not match input's channels,  it indicates\n         # convolution is broken down into groups.\n         return _conv_xla()\n+    if data_format == \"channels_first\" and len(inputs.shape) == 5:\n+        inputs = convert_to_tensor(inputs)\n+        if inputs.device.split(\":\")[-2] == \"CPU\":\n+            inputs = tf.transpose(inputs, perm=(0, 2, 3, 4, 1))\n+            data_format = \"channels_last\"\n+            return tf.transpose(_conv(), perm=(0, 4, 1, 2, 3))\n     return _conv()\n \n \n\n@@ -1445,23 +1445,29 @@ class NNOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         )\n         self.assertAllClose(outputs, expected)\n \n-    @parameterized.product(strides=(1, (1, 1, 1), 2), padding=(\"valid\", \"same\"))\n-    def test_conv_3d(self, strides, padding):\n-        if backend.config.image_data_format() == \"channels_last\":\n+    @parameterized.product(\n+        strides=(1, (1, 1, 1), 2),\n+        padding=(\"valid\", \"same\"),\n+        data_format=(\"channels_first\", \"channels_last\"),\n+    )\n+    def test_conv_3d(self, strides, padding, data_format):\n+        if data_format == \"channels_last\":\n             input_shape = (2, 8, 8, 8, 3)\n         else:\n             input_shape = (2, 3, 8, 8, 8)\n         inputs_3d = np.arange(3072, dtype=float).reshape(input_shape)\n         kernel = np.arange(162, dtype=float).reshape([3, 3, 3, 3, 2])\n \n-        outputs = knn.conv(inputs_3d, kernel, strides, padding=padding)\n+        outputs = knn.conv(\n+            inputs_3d, kernel, strides, padding=padding, data_format=data_format\n+        )\n         expected = np_conv3d(\n             inputs_3d,\n             kernel,\n             bias_weights=np.zeros((2,)),\n             strides=strides,\n             padding=padding,\n-            data_format=backend.config.image_data_format(),\n+            data_format=data_format,\n             dilation_rate=1,\n             groups=1,\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1b8f7b7bffdfb7b66fd0bc98b46e5ce1582fb811", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 5 | Files Changed: 3 | Hunks: 7 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 28 | Churn Cumulative: 1688 | Contributors (this commit): 7 | Commits (past 90d): 10 | Contributors (cumulative): 11 | DMM Complexity: 0.0\n\nDIFF:\n@@ -538,14 +538,23 @@ class GRU(RNN):\n         if tree.is_nested(mask):\n             mask = mask[0]\n         if self.use_cudnn in (\"auto\", True):\n-            if not self.dropout and not self.recurrent_dropout:\n+            if not self.recurrent_dropout:\n                 try:\n+                    if self.dropout:\n+                        dp_mask = self.cell.get_dropout_mask(sequences[:, 0, :])\n+                        dp_mask = ops.expand_dims(dp_mask, axis=1)\n+                        dp_mask = ops.broadcast_to(\n+                            dp_mask, ops.shape(sequences)\n+                        )\n+                        dp_sequences = sequences * dp_mask\n+                    else:\n+                        dp_sequences = sequences\n                     # Backends are allowed to specify (optionally) optimized\n                     # implementation of the inner GRU loop. In the case of\n                     # TF for instance, it will leverage cuDNN when feasible, and\n                     # it will raise NotImplementedError otherwise.\n                     out = backend.gru(\n-                        sequences,\n+                        dp_sequences,\n                         initial_state,\n                         mask,\n                         kernel=self.cell.kernel,\n\n@@ -518,14 +518,24 @@ class LSTM(RNN):\n             mask = mask[0]\n \n         if self.use_cudnn in (\"auto\", True):\n-            if not self.dropout and not self.recurrent_dropout:\n+            if not self.recurrent_dropout:\n                 try:\n+                    if self.dropout:\n+                        dp_mask = self.cell.get_dropout_mask(sequences[:, 0, :])\n+                        dp_mask = ops.expand_dims(dp_mask, axis=1)\n+                        dp_mask = ops.broadcast_to(\n+                            dp_mask, ops.shape(sequences)\n+                        )\n+                        dp_sequences = sequences * dp_mask\n+                    else:\n+                        dp_sequences = sequences\n+\n                     # Backends are allowed to specify (optionally) optimized\n                     # implementation of the inner LSTM loop. In the case of\n                     # TF for instance, it will leverage cuDNN when feasible, and\n                     # it will raise NotImplementedError otherwise.\n                     out = backend.lstm(\n-                        sequences,\n+                        dp_sequences,\n                         initial_state[0],\n                         initial_state[1],\n                         mask,\n\n@@ -84,7 +84,6 @@ def build(root_path, is_nightly=False, rc_index=None):\n     try:\n         copy_source_to_build_directory(root_path)\n         move_tf_keras_directory()\n-        print(os.getcwd())\n \n         from keras.src.version import __version__  # noqa: E402\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e85c12b394a8ccef21fb78ff46d6fea77ccca74e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 18 | Churn Cumulative: 56 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: 0.9230769230769231\n\nDIFF:\n@@ -112,18 +112,32 @@ def make_layer_label(layer, **kwargs):\n             output_shape = tree.map_structure(lambda x: x.shape, layer.output)\n         except (ValueError, AttributeError):\n             pass\n+\n+        def format_shape(shape):\n+            if shape is not None:\n+                if isinstance(shape, dict):\n+                    shape_str = \", \".join(\n+                        [f\"{k}: {v}\" for k, v in shape.items()]\n+                    )\n+                else:\n+                    shape_str = f\"{shape}\"\n+                shape_str = shape_str.replace(\"}\", \"\").replace(\"{\", \"\")\n+            else:\n+                shape_str = \"?\"\n+            return shape_str\n+\n         if class_name != \"InputLayer\":\n             cols.append(\n                 (\n                     '<td bgcolor=\"white\"><font point-size=\"14\">'\n-                    f'Input shape: <b>{input_shape or \"?\"}</b>'\n+                    f\"Input shape: <b>{format_shape(input_shape)}</b>\"\n                     \"</font></td>\"\n                 )\n             )\n         cols.append(\n             (\n                 '<td bgcolor=\"white\"><font point-size=\"14\">'\n-                f'Output shape: <b>{output_shape or \"?\"}</b>'\n+                f\"Output shape: <b>{format_shape(output_shape)}</b>\"\n                 \"</font></td>\"\n             )\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9a69ecefe1f671ee8a051d88dac221b8f7c9124f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 16 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -8,7 +8,7 @@ from keras.src.backend.torch.core import convert_to_tensor\n \n \n def cholesky(x):\n-    return torch.cholesky(x)\n+    return torch.linalg.cholesky(x)\n \n \n def det(x):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e4f509297584d72f951459047df9349d5734002c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 33 | Lines Deleted: 26 | Files Changed: 3 | Hunks: 7 | Methods Changed: 3 | Complexity Δ (Sum/Max): -1/4 | Churn Δ: 59 | Churn Cumulative: 1176 | Contributors (this commit): 5 | Commits (past 90d): 27 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1950,6 +1950,10 @@ def take(x, indices, axis=None):\n \n \n def take_along_axis(x, indices, axis=None):\n+    from keras.src.ops.operation_utils import (\n+        compute_take_along_axis_output_shape,\n+    )\n+\n     x = convert_to_tensor(x)\n     indices = convert_to_tensor(indices, \"int64\")\n     if axis is None:\n@@ -1959,7 +1963,13 @@ def take_along_axis(x, indices, axis=None):\n                 f\"Received: indices.shape={indices.shape}\"\n             )\n         return take_along_axis(tf.reshape(x, [-1]), indices, 0)\n-    rank = tf.rank(x)\n+\n+    # Compute the static output shape as later on, all shapes manipulations\n+    # use dynamic shapes.\n+    static_output_shape = compute_take_along_axis_output_shape(\n+        x.shape, indices.shape, axis\n+    )\n+    rank = x.ndim\n     static_axis = axis\n     axis = axis + rank if axis < 0 else axis\n \n@@ -1981,9 +1991,6 @@ def take_along_axis(x, indices, axis=None):\n     x = tf.broadcast_to(x, x_shape)\n     indices = tf.broadcast_to(indices, indices_shape)\n \n-    # Save indices shape so we can restore it later.\n-    possible_result_shape = indices.shape\n-\n     # Correct the indices using \"fill\" mode which is the same as in jax\n     indices = tf.where(indices < 0, indices + x_shape[static_axis], indices)\n \n@@ -1998,7 +2005,7 @@ def take_along_axis(x, indices, axis=None):\n     result = tf.gather(x, indices, batch_dims=1)\n     result = tf.reshape(result, indices_shape)\n     result = swapaxes(result, static_axis, -1)\n-    result.set_shape(possible_result_shape)\n+    result.set_shape(static_output_shape)\n     return result\n \n \n\n@@ -4859,28 +4859,9 @@ class TakeAlongAxis(Operation):\n         return backend.numpy.take_along_axis(x, indices, axis=self.axis)\n \n     def compute_output_spec(self, x, indices):\n-        x_shape = list(x.shape)\n-        indices_shape = list(indices.shape)\n-        if self.axis is None:\n-            x_shape = [None] if None in x_shape else [int(np.prod(x_shape))]\n-\n-        if len(x_shape) != len(indices_shape):\n-            raise ValueError(\n-                \"`x` and `indices` must have the same number of dimensions, \"\n-                f\"but receive shape {x_shape} and {indices_shape}.\"\n+        output_shape = operation_utils.compute_take_along_axis_output_shape(\n+            x.shape, indices.shape, self.axis\n         )\n-\n-        del x_shape[self.axis]\n-        del indices_shape[self.axis]\n-        output_shape = broadcast_shapes(x_shape, indices_shape)\n-        size_on_axis = indices.shape[self.axis]\n-        if self.axis == -1:\n-            output_shape = output_shape + [size_on_axis]\n-        elif self.axis >= 0:\n-            output_shape.insert(self.axis, size_on_axis)\n-        else:\n-            output_shape.insert(self.axis + 1, size_on_axis)\n-\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n \n\n@@ -349,6 +349,25 @@ def compute_transpose_output_shape(input_shape, axes):\n     return tuple(input_shape[ax] for ax in axes)\n \n \n+def compute_take_along_axis_output_shape(input_shape, indices_shape, axis):\n+    input_shape = list(input_shape)\n+    indices_shape = list(indices_shape)\n+    if axis is None:\n+        input_shape = (\n+            [None] if None in input_shape else [int(np.prod(input_shape))]\n+        )\n+\n+    if len(input_shape) != len(indices_shape):\n+        raise ValueError(\n+            \"`x` and `indices` must have the same number of dimensions, \"\n+            f\"but receive shape {input_shape} and {indices_shape}.\"\n+        )\n+\n+    input_shape[axis] = indices_shape[axis]\n+    output_shape = broadcast_shapes(input_shape, indices_shape)\n+    return output_shape\n+\n+\n def reduce_shape(shape, axis=None, keepdims=False):\n     shape = list(shape)\n     if axis is None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#84094ecbea3114c49f0be3a6a6cda9257a16bb6a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 572 | Contributors (this commit): 25 | Commits (past 90d): 3 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -43,6 +43,7 @@ setup(\n         \"h5py\",\n         \"optree\",\n         \"ml-dtypes\",\n+        \"packaging\",\n     ],\n     # Supported Python versions\n     python_requires=\">=3.9\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#76118ac5a8a244a5772eba588849d073020539d5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 74 | Lines Deleted: 9 | Files Changed: 3 | Hunks: 7 | Methods Changed: 5 | Complexity Δ (Sum/Max): 15/8 | Churn Δ: 83 | Churn Cumulative: 187 | Contributors (this commit): 4 | Commits (past 90d): 8 | Contributors (cumulative): 8 | DMM Complexity: 0.7307692307692307\n\nDIFF:\n@@ -635,16 +635,31 @@ def _get_save_spec(model):\n     if not shapes_dict:\n         return None\n \n+    def make_tensor_spec(structure):\n+        # We need to turn wrapper structures like TrackingDict or _DictWrapper\n+        # into plain Python structures because they don't work with jax2tf/JAX.\n+        if isinstance(structure, dict):\n+            return {k: make_tensor_spec(v) for k, v in structure.items()}\n+        if isinstance(structure, (list, tuple)):\n+            if all(isinstance(d, (int, type(None))) for d in structure):\n+                return tf.TensorSpec(\n+                    shape=(None,) + structure[1:], dtype=model.input_dtype\n+                )\n+            result = [make_tensor_spec(v) for v in structure]\n+            return tuple(result) if isinstance(structure, tuple) else result\n+        else:\n+            raise ValueError(\n+                f\"Unsupported type {type(structure)} for {structure}\"\n+            )\n+\n     if len(shapes_dict) == 1:\n-        shape = list(shapes_dict.values())[0]\n-        shape = (None,) + shape[1:]\n-        return tf.TensorSpec(shape=shape, dtype=model.input_dtype)\n+        value = list(shapes_dict.values())[0]\n+        return make_tensor_spec(value)\n \n     specs = {}\n-    for key, shape in shapes_dict.items():\n+    for key, value in shapes_dict.items():\n         key = key.rstrip(\"_shape\")\n-        shape = (None,) + shape[1:]\n-        specs[key] = tf.TensorSpec(shape=shape, dtype=model.input_dtype)\n+        specs[key] = make_tensor_spec(value)\n \n     return specs\n \n\n@@ -95,6 +95,56 @@ class ExportArchiveTest(testing.TestCase, parameterized.TestCase):\n         # Test with a different batch size\n         revived_model.serve(tf.random.normal((6, 10)))\n \n+    @parameterized.named_parameters(\n+        named_product(struct_type=[\"tuple\", \"array\", \"dict\"])\n+    )\n+    def test_model_with_input_structure(self, struct_type):\n+\n+        class TupleModel(models.Model):\n+\n+            def call(self, inputs):\n+                x, y = inputs\n+                return ops.add(x, y)\n+\n+        class ArrayModel(models.Model):\n+\n+            def call(self, inputs):\n+                x = inputs[0]\n+                y = inputs[1]\n+                return ops.add(x, y)\n+\n+        class DictModel(models.Model):\n+\n+            def call(self, inputs):\n+                x = inputs[\"x\"]\n+                y = inputs[\"y\"]\n+                return ops.add(x, y)\n+\n+        if struct_type == \"tuple\":\n+            model = TupleModel()\n+            ref_input = (tf.random.normal((3, 10)), tf.random.normal((3, 10)))\n+        elif struct_type == \"array\":\n+            model = ArrayModel()\n+            ref_input = [tf.random.normal((3, 10)), tf.random.normal((3, 10))]\n+        elif struct_type == \"dict\":\n+            model = DictModel()\n+            ref_input = {\n+                \"x\": tf.random.normal((3, 10)),\n+                \"y\": tf.random.normal((3, 10)),\n+            }\n+\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"exported_model\")\n+        ref_output = model(tree.map_structure(ops.convert_to_tensor, ref_input))\n+\n+        export_lib.export_model(model, temp_filepath)\n+        revived_model = tf.saved_model.load(temp_filepath)\n+        self.assertAllClose(ref_output, revived_model.serve(ref_input))\n+        # Test with a different batch size\n+        bigger_input = tree.map_structure(\n+            lambda x: tf.concat([x, x], axis=0), ref_input\n+        )\n+        revived_model.serve(bigger_input)\n+\n     @parameterized.named_parameters(\n         named_product(model_type=[\"sequential\", \"functional\", \"subclass\"])\n     )\n\n@@ -1350,10 +1350,10 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n     def __setattr__(self, name, value):\n         # Track Variables, Layers, Metrics, SeedGenerators.\n         name, value = self._setattr_hook(name, value)\n-        if hasattr(self, \"_tracker\"):\n-            value = self._tracker.track(value)\n-        elif name != \"_tracker\":\n+        if name != \"_tracker\":\n+            if not hasattr(self, \"_tracker\"):\n                 self._initialize_tracker()\n+            value = self._tracker.track(value)\n         return super().__setattr__(name, value)\n \n     def _check_super_called(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0ecc82c4b0fc2e50963648fd536029d2e32f45fa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 62 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -130,7 +130,8 @@ class Trainer:\n                 wrapped in a `LossScaleOptimizer`, which will dynamically\n                 scale the loss to prevent underflow.\n         \"\"\"\n-        self.optimizer = optimizers.get(optimizer)\n+        optimizer = optimizers.get(optimizer)\n+        self.optimizer = optimizer\n         if (\n             auto_scale_loss\n             and self.dtype_policy.name == \"mixed_float16\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#702cd6f549736ab80d57501c34252f0d210358b0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 24 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -359,7 +359,9 @@ class SavingTest(testing.TestCase):\n         )\n         self.assertEqual(\n             config_dict[\"compile_config\"][\"optimizer\"],\n-            \"adam\",\n+            keras.src.saving.serialize_keras_object(\n+                keras.src.optimizers.get(\"adam\")\n+            ),\n         )\n         self.assertEqual(\n             config_dict[\"compile_config\"][\"loss\"][\"config\"],\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6d98b50c5826740c1dceb0d698fbf7b0f64e5b94", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 13 | Churn Cumulative: 73 | Contributors (this commit): 3 | Commits (past 90d): 7 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -79,8 +79,8 @@ def convert_to_numpy(x):\n     if isinstance(x, jax_sparse.JAXSparse):\n         x = x.todense()\n     if is_tensor(x) and x.dtype == \"bfloat16\":\n-        return np.asarray(x, ml_dtypes.bfloat16)\n-    return np.asarray(x)\n+        return np.array(x, dtype=ml_dtypes.bfloat16)\n+    return np.array(x)\n \n \n def is_tensor(x):\n\n@@ -128,7 +128,7 @@ def convert_to_numpy(x):\n         x = tf.convert_to_tensor(x)\n     elif isinstance(x, tf.RaggedTensor):\n         x = x.to_tensor()\n-    return np.asarray(x)\n+    return np.array(x)\n \n \n def is_tensor(x):\n\n@@ -633,6 +633,13 @@ class CoreOpsDtypeTest(testing.TestCase, parameterized.TestCase):\n                 expected_dtype,\n             )\n \n+    def test_convert_to_numpy(self):\n+        x = ops.array([1, 2, 3], dtype=\"float32\")\n+        y = ops.convert_to_numpy(x)\n+        self.assertIsInstance(y, np.ndarray)\n+        # Test assignment -- should not fail.\n+        y[0] = 1.0\n+\n \n class CoreOpsCallsTests(testing.TestCase):\n     def test_scatter_basic_call(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#89b8acb7bc8f0cc7e83ea37d2f2de293b07e8889", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 16 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -212,7 +212,9 @@ class LayerNormalization(Layer):\n             variance = ops.var(inputs, axis=self.axis, keepdims=True)\n             inv = ops.rsqrt(variance + self.epsilon)\n \n-            outputs = inputs * inv * ops.cast(self.gamma, inputs.dtype)\n+            outputs = (\n+                inputs * inv * ops.cast(_broadcast(self.gamma), inputs.dtype)\n+            )\n         else:\n             # Calculate the mean & variance along self.axis (layer activations).\n             mean, variance = ops.moments(inputs, axes=self.axis, keepdims=True)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d84c6ee3e935c3dad6540224ca6768156233aef8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 74 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 5 | DMM Complexity: 0.3333333333333333\n\nDIFF:\n@@ -324,7 +324,9 @@ class ExportArchive:\n \n         if input_signature:\n             if backend.backend() == \"tensorflow\":\n-                decorated_fn = tf.function(fn, input_signature=input_signature)\n+                decorated_fn = tf.function(\n+                    fn, input_signature=input_signature, autograph=False\n+                )\n             else:  # JAX backend\n \n                 # 1. Create a stateless wrapper for `fn`\n\n@@ -146,7 +146,7 @@ class UpSampling2D(Layer):\n         if data_format == \"channels_first\":\n             x = ops.transpose(x, [0, 2, 3, 1])\n         # https://github.com/keras-team/keras/issues/294\n-        # Use `ops.repeat` for `nearest` interpolation\n+        # Use `ops.repeat` for `nearest` interpolation to enable XLA\n         if interpolation == \"nearest\":\n             x = ops.repeat(x, height_factor, axis=1)\n             x = ops.repeat(x, width_factor, axis=2)\n@@ -158,9 +158,10 @@ class UpSampling2D(Layer):\n             # since when running under torchdynamo, `new_shape`\n             # will be traced as a symbolic variable (specifically\n             # a `FakeTensor`) which does not have a `tolist()` method.\n+            shape = ops.shape(x)\n             new_shape = (\n-                x.shape[1] * height_factor,\n-                x.shape[2] * width_factor,\n+                shape[1] * height_factor,\n+                shape[2] * width_factor,\n             )\n             x = ops.image.resize(x, new_shape, interpolation=interpolation)\n         if data_format == \"channels_first\":\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2b1ce141de7e2d1b9691d303325ab709fb80a2f8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 19 | Files Changed: 1 | Hunks: 6 | Methods Changed: 1 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 21 | Churn Cumulative: 39 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -185,7 +185,6 @@ def compute_output_spec(fn, *args, **kwargs):\n \n         output_spec = None\n         if has_none:\n-            try:\n             ms_args_1, ms_kwargs_1 = tree.map_structure(\n                 lambda x: convert_keras_tensor_to_jax(x, fill_value=83),\n                 (maybe_symbolic_args, maybe_symbolic_kwargs),\n@@ -228,24 +227,10 @@ def compute_output_spec(fn, *args, **kwargs):\n                 else:\n                     return x1\n \n-                output_spec = tree.map_structure(\n+            return tree.map_structure(\n                 convert_jax_specs_to_keras_tensor, jax_out_1, jax_out_2\n             )\n-            except Exception as e:\n-                if \"[JAX RNG]\" in str(e):\n-                    raise e\n-                # Errors can happen when the filled dimensions\n-                # are not compatible with the function\n-                # (or when the function contains a bug).\n-                # In such cases we don't want to confuse users\n-                # with random filled dimensions and the like,\n-                # so we rerun a pass on the dynamic shapes,\n-                # which will likely error out when JAX tries to\n-                # validate shapes as fully static.\n-                # The error message will be much easier to understand.\n-                pass\n \n-        if output_spec is None:\n         maybe_symbolic_args, maybe_symbolic_kwargs = tree.map_structure(\n             convert_keras_tensor_to_jax,\n             (maybe_symbolic_args, maybe_symbolic_kwargs),\n@@ -261,12 +246,10 @@ def compute_output_spec(fn, *args, **kwargs):\n                 return KerasTensor(x.shape, x.dtype, sparse=True)\n             return x\n \n-            output_spec = tree.map_structure(\n+        return tree.map_structure(\n             convert_jax_spec_to_keras_tensor, jax_out\n         )\n \n-    return output_spec\n-\n \n def cond(pred, true_fn, false_fn):\n     return jax.lax.cond(pred, true_fun=true_fn, false_fun=false_fn)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2198cfc1dee26ca78ac36e5b483284e393daa15d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 16 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -192,7 +192,7 @@ class StringLookup(IndexLookup):\n            [0., 0., 1., 0., 0.],\n            [0., 0., 0., 1., 0.],\n            [0., 0., 0., 0., 1.],\n-           [1., 0., 0., 0., 0.]], dtype=float32)\n+           [1., 0., 0., 0., 0.]], dtype=int64)\n \n     **Multi-hot output**\n \n@@ -204,7 +204,7 @@ class StringLookup(IndexLookup):\n     >>> layer = StringLookup(vocabulary=vocab, output_mode='multi_hot')\n     >>> layer(data)\n     array([[0., 1., 0., 1., 1.],\n-           [1., 0., 1., 0., 1.]], dtype=float32)\n+           [1., 0., 1., 0., 1.]], dtype=int64)\n \n     **Token count output**\n \n@@ -216,7 +216,7 @@ class StringLookup(IndexLookup):\n     >>> layer = StringLookup(vocabulary=vocab, output_mode='count')\n     >>> layer(data)\n     array([[0., 1., 0., 1., 2.],\n-           [2., 0., 1., 0., 1.]], dtype=float32)\n+           [2., 0., 1., 0., 1.]], dtype=int64)\n \n     **TF-IDF output**\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8cb1829d1eccd60c3bb2e45037ca4b558926a243", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 104 | Lines Deleted: 100 | Files Changed: 4 | Hunks: 25 | Methods Changed: 15 | Complexity Δ (Sum/Max): -12/2 | Churn Δ: 204 | Churn Cumulative: 314 | Contributors (this commit): 3 | Commits (past 90d): 12 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -203,10 +203,7 @@ def compute_output_spec(fn, *args, **kwargs):\n \n             def merge_shapes(shape1, shape2):\n                 return tuple(\n-                    [\n-                        d1 if d1 == d2 else None\n-                        for d1, d2 in zip(shape1, shape2)\n-                    ]\n+                    [d1 if d1 == d2 else None for d1, d2 in zip(shape1, shape2)]\n                 )\n \n             def convert_jax_specs_to_keras_tensor(x1, x2):\n@@ -246,9 +243,7 @@ def compute_output_spec(fn, *args, **kwargs):\n                 return KerasTensor(x.shape, x.dtype, sparse=True)\n             return x\n \n-        return tree.map_structure(\n-            convert_jax_spec_to_keras_tensor, jax_out\n-        )\n+        return tree.map_structure(convert_jax_spec_to_keras_tensor, jax_out)\n \n \n def cond(pred, true_fn, false_fn):\n\n@@ -102,13 +102,7 @@ class Functional(Function, Model):\n     def __init__(self, inputs, outputs, name=None, **kwargs):\n         if isinstance(inputs, dict):\n             for k, v in inputs.items():\n-                if not isinstance(v, backend.KerasTensor):\n-                    raise ValueError(\n-                        \"When providing `inputs` as a dict, all values in the \"\n-                        f\"dict must be KerasTensors. Received: inputs={inputs} \"\n-                        f\"including invalid value {v} of type {type(v)}\"\n-                    )\n-                if k != v.name:\n+                if isinstance(v, backend.KerasTensor) and k != v.name:\n                     warnings.warn(\n                         \"When providing `inputs` as a dict, all keys in the \"\n                         \"dict must match the names of the corresponding \"\n@@ -116,47 +110,26 @@ class Functional(Function, Model):\n                         f\"which has name '{v.name}'. Change the tensor name to \"\n                         f\"'{k}' (via `Input(..., name='{k}')`)\"\n                     )\n-        elif isinstance(inputs, (list, tuple)):\n-            for x in inputs:\n+\n+        trainable = kwargs.pop(\"trainable\", None)\n+        flat_inputs = tree.flatten(inputs)\n+        flat_outputs = tree.flatten(outputs)\n+        for x in flat_inputs:\n             if not isinstance(x, backend.KerasTensor):\n                 raise ValueError(\n-                        \"When providing `inputs` as a list/tuple, all values \"\n-                        f\"in the list/tuple must be KerasTensors. Received: \"\n-                        f\"inputs={inputs} including invalid value {x} of type \"\n-                        f\"{type(x)}\"\n+                    \"All `inputs` values must be KerasTensors. Received: \"\n+                    f\"inputs={inputs} including invalid value {x} of \"\n+                    f\"type {type(x)}\"\n                 )\n-        elif not isinstance(inputs, backend.KerasTensor):\n-            raise ValueError(\n-                f\"Unrecognized type for `inputs`: {inputs} \"\n-                f\"(of type {type(inputs)})\"\n-            )\n-        if isinstance(outputs, dict):\n-            for k, v in outputs.items():\n-                if not isinstance(v, backend.KerasTensor):\n-                    raise ValueError(\n-                        \"When providing `outputs` as a dict, all values in the \"\n-                        f\"dict must be KerasTensors. Received: \"\n-                        f\"outputs={outputs} including invalid value {v} of \"\n-                        f\"type {type(v)}\"\n-                    )\n-        elif isinstance(outputs, (list, tuple)):\n-            for x in outputs:\n+        for x in flat_outputs:\n             if not isinstance(x, backend.KerasTensor):\n                 raise ValueError(\n-                        \"When providing `outputs` as a list/tuple, all values \"\n-                        f\"in the list/tuple must be KerasTensors. Received: \"\n+                    \"All `outputs` values must be KerasTensors. Received: \"\n                     f\"outputs={outputs} including invalid value {x} of \"\n                     f\"type {type(x)}\"\n                 )\n-        elif not isinstance(outputs, backend.KerasTensor):\n-            raise ValueError(\n-                f\"Unrecognized type for `outputs`: {outputs} \"\n-                f\"(of type {type(outputs)})\"\n-            )\n \n-        trainable = kwargs.pop(\"trainable\", None)\n-\n-        if not all([is_input_keras_tensor(t) for t in tree.flatten(inputs)]):\n+        if not all(is_input_keras_tensor(t) for t in flat_inputs):\n             inputs, outputs = clone_graph_nodes(inputs, outputs)\n \n         Function.__init__(self, inputs, outputs, name=name, **kwargs)\n@@ -228,36 +201,7 @@ class Functional(Function, Model):\n     def _assert_input_compatibility(self, *args):\n         return super(Model, self)._assert_input_compatibility(*args)\n \n-    def _flatten_to_reference_inputs(self, inputs, allow_extra_keys=True):\n-        if isinstance(inputs, dict):\n-            ref_inputs = self._inputs_struct\n-            if not tree.is_nested(ref_inputs):\n-                ref_inputs = [self._inputs_struct]\n-            if isinstance(ref_inputs, dict):\n-                # In the case that the graph is constructed with dict input\n-                # tensors, We will use the original dict key to map with the\n-                # keys in the input data. Note that the model.inputs is using\n-                # tree.flatten to process the input tensors, which means the\n-                # dict input tensors are ordered by their keys.\n-                ref_input_names = sorted(ref_inputs.keys())\n-            else:\n-                ref_input_names = [\n-                    inp._keras_history.operation.name for inp in ref_inputs\n-                ]\n-            # Raise an warning if there are more input data comparing to input\n-            # tensor\n-            if not allow_extra_keys and len(inputs) > len(ref_input_names):\n-                warnings.warn(\n-                    \"Input dict contained keys {} which did not match any \"\n-                    \"model input. They will be ignored by the model.\".format(\n-                        [n for n in inputs.keys() if n not in ref_input_names]\n-                    ),\n-                    stacklevel=2,\n-                )\n-            # Flatten in the order `Input`s were passed during Model\n-            # construction.\n-            return [inputs[n] for n in ref_input_names]\n-        # Otherwise both ref inputs and inputs will already be in same order.\n+    def _flatten_to_reference_inputs(self, inputs):\n         return tree.flatten(inputs)\n \n     def _convert_inputs_to_tensors(self, flat_inputs):\n@@ -328,7 +272,18 @@ class Functional(Function, Model):\n                 x[0] = None\n             return tuple(x)\n \n+        def make_spec_for_tensor(x):\n+            return InputSpec(\n+                shape=shape_with_no_batch_size(x.shape),\n+                allow_last_axis_squeeze=True,\n+                name=x._keras_history[0].name,\n+            )\n+\n         if isinstance(self._inputs_struct, dict):\n+            if all(\n+                isinstance(x, backend.KerasTensor)\n+                for x in self._inputs_struct.values()\n+            ):\n                 # Case where `_nested_inputs` is a plain dict of Inputs.\n                 names = sorted(self._inputs_struct.keys())\n                 return [\n@@ -341,17 +296,8 @@ class Functional(Function, Model):\n                     )\n                     for name in names\n                 ]\n-        else:\n-            # Single input, or list/tuple of inputs.\n-            # The data may be passed as a dict keyed by input name.\n-            return [\n-                InputSpec(\n-                    shape=shape_with_no_batch_size(x.shape),\n-                    allow_last_axis_squeeze=True,\n-                    name=x._keras_history[0].name,\n-                )\n-                for x in self._inputs\n-            ]\n+            return None  # Deeply nested dict: skip checks.\n+        return [make_spec_for_tensor(x) for x in self.inputs]\n \n     @input_spec.setter\n     def input_spec(self, value):\n@@ -424,12 +370,9 @@ class Functional(Function, Model):\n             return [operation.name, new_node_index, tensor_index]\n \n         def map_tensors(tensors):\n-            if isinstance(tensors, dict):\n-                return {k: get_tensor_config(v) for k, v in tensors.items()}\n-            if isinstance(tensors, (list, tuple)):\n-                return [get_tensor_config(v) for v in tensors]\n-            else:\n+            if isinstance(tensors, backend.KerasTensor):\n                 return [get_tensor_config(tensors)]\n+            return tree.map_structure(get_tensor_config, tensors)\n \n         config[\"input_layers\"] = map_tensors(self._inputs_struct)\n         config[\"output_layers\"] = map_tensors(self._outputs_struct)\n@@ -563,16 +506,20 @@ def functional_from_config(cls, config, custom_objects=None):\n         return layer_output_tensors[tensor_index]\n \n     def map_tensors(tensors):\n+        if (\n+            isinstance(tensors, list)\n+            and len(tensors) == 3\n+            and isinstance(tensors[0], str)\n+        ):\n+            # Leaf\n+            return get_tensor(*tensors)\n         if isinstance(tensors, dict):\n-            return {k: get_tensor(*v) for k, v in tensors.items()}\n-        else:\n-            tensor_list = [get_tensor(*v) for v in tensors]\n-            if len(tensor_list) == 1:\n-                return tensor_list[0]\n-            return tensor_list\n+            return {k: map_tensors(v) for k, v in tensors.items()}\n+        return [map_tensors(v) for v in tensors]\n \n     input_tensors = map_tensors(config[\"input_layers\"])\n     output_tensors = map_tensors(config[\"output_layers\"])\n+\n     return cls(\n         inputs=input_tensors,\n         outputs=output_tensors,\n\n@@ -1,3 +1,4 @@\n+import os\n import warnings\n \n import numpy as np\n@@ -5,6 +6,7 @@ import pytest\n \n from keras.src import backend\n from keras.src import layers\n+from keras.src import saving\n from keras.src import testing\n from keras.src.layers.core.input_layer import Input\n from keras.src.layers.input_spec import InputSpec\n@@ -93,9 +95,14 @@ class FunctionalTest(testing.TestCase):\n         outputs = layers.Dense(4)(x)\n \n         with self.assertRaisesRegex(\n-            ValueError, \"all values in the dict must be KerasTensors\"\n+            ValueError, \"All `inputs` values must be KerasTensors\"\n         ):\n-            model = Functional({\"aa\": [input_a], \"bb\": input_b}, outputs)\n+            model = Functional({\"a\": \"input_a\", \"b\": input_b}, outputs)\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \"All `outputs` values must be KerasTensors\"\n+        ):\n+            model = Functional({\"a\": input_a, \"b\": input_b}, \"outputs\")\n \n         model = Functional({\"a\": input_a, \"b\": input_b}, outputs)\n \n@@ -372,6 +379,59 @@ class FunctionalTest(testing.TestCase):\n         self.assertEqual(partial_model_4.layers[1].name, \"dense1\")\n         self.assertEqual(partial_model_4.layers[2].name, \"dense2\")\n \n+    def test_deeply_nested_model(self):\n+        i1, i2, i3 = Input((1,)), Input((2,)), Input((3,))\n+        o1, o2, o3 = (\n+            layers.Dense(1)(i1),\n+            layers.Dense(2)(i2),\n+            layers.Dense(3)(i3),\n+        )\n+        model = Model(\n+            {\"1\": i1, \"others\": {\"2\": i2, \"3\": i3}},\n+            {\"1\": o1, \"others\": {\"2\": o2, \"3\": o3}},\n+        )\n+        out_eager = model(\n+            {\n+                \"1\": np.ones((2, 1)),\n+                \"others\": {\"2\": np.ones((2, 2)), \"3\": np.ones((2, 3))},\n+            }\n+        )\n+        out_symbolic = model(\n+            {\n+                \"1\": Input((1,), batch_size=2),\n+                \"others\": {\n+                    \"2\": Input((2,), batch_size=2),\n+                    \"3\": Input((3,), batch_size=2),\n+                },\n+            }\n+        )\n+        for out in [out_eager, out_symbolic]:\n+            self.assertIsInstance(out, dict)\n+            self.assertEqual(set(out.keys()), {\"1\", \"others\"})\n+            self.assertEqual(out[\"1\"].shape, (2, 1))\n+            self.assertIsInstance(out[\"others\"], dict)\n+            self.assertEqual(set(out[\"others\"].keys()), {\"2\", \"3\"})\n+            self.assertEqual(out[\"others\"][\"2\"].shape, (2, 2))\n+            self.assertEqual(out[\"others\"][\"3\"].shape, (2, 3))\n+\n+        # Test serialization boundaries\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"deeply_nested.keras\")\n+        model.save(temp_filepath)\n+        loaded_model = saving.load_model(temp_filepath)\n+        new_out_eager = loaded_model(\n+            {\n+                \"1\": np.ones((2, 1)),\n+                \"others\": {\"2\": np.ones((2, 2)), \"3\": np.ones((2, 3))},\n+            }\n+        )\n+        self.assertAllClose(out_eager[\"1\"], new_out_eager[\"1\"])\n+        self.assertAllClose(\n+            out_eager[\"others\"][\"2\"], new_out_eager[\"others\"][\"2\"]\n+        )\n+        self.assertAllClose(\n+            out_eager[\"others\"][\"3\"], new_out_eager[\"others\"][\"3\"]\n+        )\n+\n     def test_add_loss(self):\n         # TODO\n         pass\n\n@@ -88,10 +88,12 @@ class Function(Operation):\n \n     @property\n     def inputs(self):\n+        \"\"\"Flat list of the symbolic inputs of the Function.\"\"\"\n         return self._inputs\n \n     @property\n     def outputs(self):\n+        \"\"\"Flat list of the symbolic outputs of the Function.\"\"\"\n         return self._outputs\n \n     def compute_output_spec(self, inputs):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
