{"custom_id": "keras#f56b478ef6f2a3994fd319956e70445e33daf02a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 9153 | Contributors (this commit): 49 | Commits (past 90d): 20 | Contributors (cumulative): 49 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1045,6 +1045,8 @@ class SimpleRNN(RNN):\n         self.activity_regularizer = regularizers.get(activity_regularizer)\n \n     def call(self, inputs, mask=None, training=None, initial_state=None):\n+        self.cell._dropout_mask = None\n+        self.cell._recurrent_dropout_mask = None\n         return super(SimpleRNN, self).call(inputs,\n                                            mask=mask,\n                                            training=training,\n@@ -1512,6 +1514,8 @@ class GRU(RNN):\n         self.activity_regularizer = regularizers.get(activity_regularizer)\n \n     def call(self, inputs, mask=None, training=None, initial_state=None):\n+        self.cell._dropout_mask = None\n+        self.cell._recurrent_dropout_mask = None\n         return super(GRU, self).call(inputs,\n                                      mask=mask,\n                                      training=training,\n@@ -2020,6 +2024,8 @@ class LSTM(RNN):\n         self.activity_regularizer = regularizers.get(activity_regularizer)\n \n     def call(self, inputs, mask=None, training=None, initial_state=None):\n+        self.cell._dropout_mask = None\n+        self.cell._recurrent_dropout_mask = None\n         return super(LSTM, self).call(inputs,\n                                       mask=mask,\n                                       training=training,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3a431ea52d090fb3ef8a1e0e5d7f796d9a42e097", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 61 | Lines Deleted: 115 | Files Changed: 1 | Hunks: 11 | Methods Changed: 26 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 176 | Churn Cumulative: 926 | Contributors (this commit): 8 | Commits (past 90d): 4 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -8,6 +8,28 @@ from keras import applications\n from keras import backend as K\n \n \n+def clean_run(model_fn):\n+    if K.backend() == 'cntk':\n+        # Create model in a subprocess so that the memory consumed by InceptionResNetV2 will be\n+        # released back to the system after this test (to deal with OOM error on CNTK backend)\n+        # TODO: remove the use of multiprocessing from these tests once a memory clearing mechanism\n+        # is implemented in the CNTK backend\n+        def target(queue):\n+            model = model_fn()\n+            queue.put(model.output_shape)\n+        queue = Queue()\n+        p = Process(target=target, args=(queue,))\n+        p.start()\n+        p.join()\n+        # The error in a subprocess won't propagate to the main process, so we check if the model\n+        # is successfully created by checking if the output shape has been put into the queue\n+        assert not queue.empty(), 'Model creation failed.'\n+        return queue.get_nowait()\n+    else:\n+        model = model_fn()\n+        return model.output_shape\n+\n+\n @keras_test\n def test_resnet50():\n     model = applications.ResNet50(weights=None)\n@@ -175,87 +197,40 @@ def test_inceptionv3_variable_input_channels():\n \n @keras_test\n def test_inceptionresnetv2():\n-    # Create model in a subprocess so that the memory consumed by InceptionResNetV2 will be\n-    # released back to the system after this test (to deal with OOM error on CNTK backend)\n-    # TODO: remove the use of multiprocessing from these tests once a memory clearing mechanism\n-    # is implemented in the CNTK backend\n-    def target(queue):\n-        model = applications.InceptionResNetV2(weights=None)\n-        queue.put(model.output_shape)\n-    queue = Queue()\n-    p = Process(target=target, args=(queue,))\n-    p.start()\n-    p.join()\n-\n-    # The error in a subprocess won't propagate to the main process, so we check if the model\n-    # is successfully created by checking if the output shape has been put into the queue\n-    assert not queue.empty(), 'Model creation failed.'\n-    model_output_shape = queue.get_nowait()\n-    assert model_output_shape == (None, 1000)\n+    def model_fn():\n+        return applications.InceptionResNetV2(weights=None)\n+    output_shape = clean_run(model_fn)\n+    assert output_shape == (None, 1000)\n \n \n @keras_test\n def test_inceptionresnetv2_notop():\n-    def target(queue):\n-        model = applications.InceptionResNetV2(weights=None, include_top=False)\n-        queue.put(model.output_shape)\n-\n-    global_image_data_format = K.image_data_format()\n-    queue = Queue()\n-\n-    K.set_image_data_format('channels_first')\n-    p = Process(target=target, args=(queue,))\n-    p.start()\n-    p.join()\n-    K.set_image_data_format(global_image_data_format)\n-    assert not queue.empty(), 'Model creation failed.'\n-    model_output_shape = queue.get_nowait()\n-    assert model_output_shape == (None, 1536, None, None)\n-\n-    K.set_image_data_format('channels_last')\n-    p = Process(target=target, args=(queue,))\n-    p.start()\n-    p.join()\n-    K.set_image_data_format(global_image_data_format)\n-    assert not queue.empty(), 'Model creation failed.'\n-    model_output_shape = queue.get_nowait()\n-    assert model_output_shape == (None, None, None, 1536)\n+    def model_fn():\n+        return applications.InceptionResNetV2(weights=None, include_top=False)\n+    output_shape = clean_run(model_fn)\n+    if K.image_data_format() == 'channels_first':\n+        assert output_shape == (None, 1536, None, None)\n+    else:\n+        assert output_shape == (None, None, None, 1536)\n \n \n @keras_test\n def test_inceptionresnetv2_pooling():\n-    def target(queue):\n-        model = applications.InceptionResNetV2(weights=None, include_top=False, pooling='avg')\n-        queue.put(model.output_shape)\n-    queue = Queue()\n-    p = Process(target=target, args=(queue,))\n-    p.start()\n-    p.join()\n-    assert not queue.empty(), 'Model creation failed.'\n-    model_output_shape = queue.get_nowait()\n-    assert model_output_shape == (None, 1536)\n+    def model_fn():\n+        return applications.InceptionResNetV2(weights=None, include_top=False, pooling='avg')\n+    output_shape = clean_run(model_fn)\n+    assert output_shape == (None, 1536)\n \n \n @keras_test\n def test_inceptionresnetv2_variable_input_channels():\n-    def target(queue, input_shape):\n-        model = applications.InceptionResNetV2(weights=None, include_top=False, input_shape=input_shape)\n-        queue.put(model.output_shape)\n+    def model_fn(input_shape):\n+        return applications.InceptionResNetV2(weights=None, include_top=False, input_shape=input_shape)\n+    output_shape = clean_run(lambda: model_fn((None, None, 1)))\n+    assert output_shape == (None, None, None, 1536)\n \n-    queue = Queue()\n-    p = Process(target=target, args=(queue, (None, None, 1)))\n-    p.start()\n-    p.join()\n-    assert not queue.empty(), 'Model creation failed.'\n-    model_output_shape = queue.get_nowait()\n-    assert model_output_shape == (None, None, None, 1536)\n-\n-    p = Process(target=target, args=(queue, (None, None, 4)))\n-    p.start()\n-    p.join()\n-    assert not queue.empty(), 'Model creation failed.'\n-    model_output_shape = queue.get_nowait()\n-    assert model_output_shape == (None, None, None, 1536)\n+    output_shape = clean_run(lambda: model_fn((None, None, 4)))\n+    assert output_shape == (None, None, None, 1536)\n \n \n @keras_test\n@@ -317,16 +292,10 @@ def test_mobilenet_image_size():\n     applications.DenseNet201],\n     ids=['DenseNet121', 'DenseNet169', 'DenseNet201'])\n def test_densenet(fun):\n-    def target(queue):\n-        model = fun(weights=None)\n-        queue.put(model.output_shape)\n-    queue = Queue()\n-    p = Process(target=target, args=(queue,))\n-    p.start()\n-    p.join()\n-    assert not queue.empty(), 'Model creation failed.'\n-    model_output_shape = queue.get_nowait()\n-    assert model_output_shape == (None, 1000)\n+    def model_fn():\n+        return fun(weights=None)\n+    output_shape = clean_run(model_fn)\n+    assert output_shape == (None, 1000)\n \n \n @keras_test\n@@ -336,16 +305,10 @@ def test_densenet(fun):\n     (applications.DenseNet201, 1920)],\n     ids=['DenseNet121', 'DenseNet169', 'DenseNet201'])\n def test_densenet_no_top(fun, dim):\n-    def target(queue):\n-        model = fun(weights=None, include_top=False)\n-        queue.put(model.output_shape)\n-    queue = Queue()\n-    p = Process(target=target, args=(queue,))\n-    p.start()\n-    p.join()\n-    assert not queue.empty(), 'Model creation failed.'\n-    model_output_shape = queue.get_nowait()\n-    assert model_output_shape == (None, None, None, dim)\n+    def model_fn():\n+        return fun(weights=None, include_top=False)\n+    output_shape = clean_run(model_fn)\n+    assert output_shape == (None, None, None, dim)\n \n \n @keras_test\n@@ -355,16 +318,10 @@ def test_densenet_no_top(fun, dim):\n     (applications.DenseNet201, 1920)],\n     ids=['DenseNet121', 'DenseNet169', 'DenseNet201'])\n def test_densenet_pooling(fun, dim):\n-    def target(queue):\n-        model = fun(weights=None, include_top=False, pooling='avg')\n-        queue.put(model.output_shape)\n-    queue = Queue()\n-    p = Process(target=target, args=(queue,))\n-    p.start()\n-    p.join()\n-    assert not queue.empty(), 'Model creation failed.'\n-    model_output_shape = queue.get_nowait()\n-    assert model_output_shape == (None, None, None, dim)\n+    def model_fn():\n+        return fun(weights=None, include_top=False, pooling='avg')\n+    output_shape = clean_run(model_fn)\n+    assert output_shape == (None, None, None, dim)\n \n \n @keras_test\n@@ -374,24 +331,13 @@ def test_densenet_pooling(fun, dim):\n     (applications.DenseNet201, 1920)],\n     ids=['DenseNet121', 'DenseNet169', 'DenseNet201'])\n def test_densenet_variable_input_channels(fun, dim):\n-    def target(queue, input_shape):\n-        model = fun(weights=None, include_top=False, input_shape=input_shape)\n-        queue.put(model.output_shape)\n+    def model_fn(input_shape):\n+        return fun(weights=None, include_top=False, input_shape=input_shape)\n+    output_shape = clean_run(lambda: model_fn((None, None, 1)))\n+    assert output_shape == (None, None, None, dim)\n \n-    queue = Queue()\n-    p = Process(target=target, args=(queue, (None, None, 1)))\n-    p.start()\n-    p.join()\n-    assert not queue.empty(), 'Model creation failed.'\n-    model_output_shape = queue.get_nowait()\n-    assert model_output_shape == (None, None, None, dim)\n-\n-    p = Process(target=target, args=(queue, (None, None, 4)))\n-    p.start()\n-    p.join()\n-    assert not queue.empty(), 'Model creation failed.'\n-    model_output_shape = queue.get_nowait()\n-    assert model_output_shape == (None, None, None, dim)\n+    output_shape = clean_run(lambda: model_fn((None, None, 4)))\n+    assert output_shape == (None, None, None, dim)\n \n \n @keras_test\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a5ecde595c47f35fd7293d52eba48efd687ca94e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 8 | Churn Cumulative: 1155 | Contributors (this commit): 29 | Commits (past 90d): 20 | Contributors (cumulative): 36 | DMM Complexity: 1.0\n\nDIFF:\n@@ -327,7 +327,7 @@ class Progbar(object):\n         info = ' - %.0fs' % (now - self.start)\n         if self.verbose == 1:\n             if (not force and (now - self.last_update) < self.interval and\n-                    current < self.target):\n+                    (self.target is not None and current < self.target)):\n                 return\n \n             prev_total_width = self.total_width\n\n@@ -16,8 +16,12 @@ from keras import regularizers\n def test_progbar():\n     n = 2\n     input_arr = np.random.random((n, n, n))\n-    bar = Progbar(n)\n \n+    bar = Progbar(n)\n+    for i, arr in enumerate(input_arr):\n+        bar.update(i, list(arr))\n+\n+    bar = Progbar(None)\n     for i, arr in enumerate(input_arr):\n         bar.update(i, list(arr))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#97031ed8f6afaf26a21dd98bb0bfdb4cacc65ca2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 155 | Lines Deleted: 13 | Files Changed: 2 | Hunks: 9 | Methods Changed: 8 | Complexity Δ (Sum/Max): 19/11 | Churn Δ: 168 | Churn Cumulative: 1327 | Contributors (this commit): 19 | Commits (past 90d): 10 | Contributors (cumulative): 24 | DMM Complexity: 0.26605504587155965\n\nDIFF:\n@@ -264,6 +264,7 @@ class Bidirectional(Wrapper):\n             self.backward_layer.initial_weights = weights[nw // 2:]\n         self.stateful = layer.stateful\n         self.return_sequences = layer.return_sequences\n+        self.return_state = layer.return_state\n         self.supports_masking = True\n \n     def get_weights(self):\n@@ -275,24 +276,50 @@ class Bidirectional(Wrapper):\n         self.backward_layer.set_weights(weights[nw // 2:])\n \n     def compute_output_shape(self, input_shape):\n-        if self.merge_mode in ['sum', 'ave', 'mul']:\n-            return self.forward_layer.compute_output_shape(input_shape)\n-        elif self.merge_mode == 'concat':\n-            shape = list(self.forward_layer.compute_output_shape(input_shape))\n-            shape[-1] *= 2\n-            return tuple(shape)\n-        elif self.merge_mode is None:\n-            return [self.forward_layer.compute_output_shape(input_shape)] * 2\n+        output_shape = self.forward_layer.compute_output_shape(input_shape)\n+        if self.return_state:\n+            state_shape = output_shape[1:]\n+            output_shape = output_shape[0]\n \n-    def call(self, inputs, training=None, mask=None):\n+        if self.merge_mode == 'concat':\n+            output_shape = list(output_shape)\n+            output_shape[-1] *= 2\n+            output_shape = tuple(output_shape)\n+        elif self.merge_mode is None:\n+            output_shape = [output_shape] * 2\n+\n+        if self.return_state:\n+            if self.merge_mode is None:\n+                return output_shape + state_shape * 2\n+            return [output_shape] + state_shape * 2\n+        return output_shape\n+\n+    def call(self, inputs, training=None, mask=None, initial_state=None):\n         kwargs = {}\n         if has_arg(self.layer.call, 'training'):\n             kwargs['training'] = training\n         if has_arg(self.layer.call, 'mask'):\n             kwargs['mask'] = mask\n \n+        if initial_state is not None and has_arg(self.layer.call, 'initial_state'):\n+            if not isinstance(initial_state, list):\n+                raise ValueError(\n+                    'When passing `initial_state` to a Bidirectional RNN, the state '\n+                    'should be a list containing the states of the underlying RNNs. '\n+                    'Found: ' + str(initial_state))\n+            forward_state = initial_state[:len(initial_state) // 2]\n+            backward_state = initial_state[len(initial_state) // 2:]\n+            y = self.forward_layer.call(inputs, initial_state=forward_state, **kwargs)\n+            y_rev = self.backward_layer.call(inputs, initial_state=backward_state, **kwargs)\n+        else:\n             y = self.forward_layer.call(inputs, **kwargs)\n             y_rev = self.backward_layer.call(inputs, **kwargs)\n+\n+        if self.return_state:\n+            states = y[1:] + y_rev[1:]\n+            y = y[0]\n+            y_rev = y_rev[0]\n+\n         if self.return_sequences:\n             y_rev = K.reverse(y_rev, 1)\n         if self.merge_mode == 'concat':\n@@ -314,6 +341,11 @@ class Bidirectional(Wrapper):\n                     out._uses_learning_phase = True\n             else:\n                 output._uses_learning_phase = True\n+\n+        if self.return_state:\n+            if self.merge_mode is None:\n+                return output + states\n+            return [output] + states\n         return output\n \n     def reset_states(self):\n\n@@ -6,7 +6,7 @@ from keras.layers import wrappers, Input\n from keras import layers\n from keras.models import Sequential, Model, model_from_json\n from keras import backend as K\n-from keras.engine.topology import _object_list_uid\n+from keras.engine.topology import _object_list_uid, _to_list\n \n \n @keras_test\n@@ -199,9 +199,6 @@ def test_Bidirectional():\n         outputs = wrappers.Bidirectional(rnn(output_dim, dropout=dropout_rate,\n                                              recurrent_dropout=dropout_rate),\n                                          merge_mode=mode)(inputs)\n-        if dropout_rate and K.backend() == 'tensorflow':\n-            # Dropout is disabled with CNTK/Theano.\n-            assert outputs._uses_learning_phase\n         model = Model(inputs, outputs)\n         model.compile(loss='mse', optimizer='sgd')\n         model.fit(x, y, epochs=1, batch_size=1)\n@@ -215,5 +212,118 @@ def test_Bidirectional():\n         model.fit(x, y, epochs=1, batch_size=1)\n \n \n+@keras_test\n+@pytest.mark.parametrize('merge_mode', ['sum', 'mul', 'ave', 'concat', None])\n+def test_Bidirectional_merged_value(merge_mode):\n+    rnn = layers.LSTM\n+    samples = 2\n+    dim = 5\n+    timesteps = 3\n+    units = 3\n+    X = [np.random.rand(samples, timesteps, dim)]\n+\n+    if merge_mode == 'sum':\n+        merge_func = lambda y, y_rev: y + y_rev\n+    elif merge_mode == 'mul':\n+        merge_func = lambda y, y_rev: y * y_rev\n+    elif merge_mode == 'ave':\n+        merge_func = lambda y, y_rev: (y + y_rev) / 2\n+    elif merge_mode == 'concat':\n+        merge_func = lambda y, y_rev: np.concatenate((y, y_rev), axis=-1)\n+    else:\n+        merge_func = lambda y, y_rev: [y, y_rev]\n+\n+    # basic case\n+    inputs = Input((timesteps, dim))\n+    layer = wrappers.Bidirectional(rnn(units, return_sequences=True), merge_mode=merge_mode)\n+    f_merged = K.function([inputs], _to_list(layer(inputs)))\n+    f_forward = K.function([inputs], [layer.forward_layer.call(inputs)])\n+    f_backward = K.function([inputs], [K.reverse(layer.backward_layer.call(inputs), 1)])\n+\n+    y_merged = f_merged(X)\n+    y_expected = _to_list(merge_func(f_forward(X)[0], f_backward(X)[0]))\n+    assert len(y_merged) == len(y_expected)\n+    for x1, x2 in zip(y_merged, y_expected):\n+        assert_allclose(x1, x2, atol=1e-5)\n+\n+    # test return_state\n+    inputs = Input((timesteps, dim))\n+    layer = wrappers.Bidirectional(rnn(units, return_state=True), merge_mode=merge_mode)\n+    f_merged = K.function([inputs], layer(inputs))\n+    f_forward = K.function([inputs], layer.forward_layer.call(inputs))\n+    f_backward = K.function([inputs], layer.backward_layer.call(inputs))\n+    n_states = len(layer.layer.states)\n+\n+    y_merged = f_merged(X)\n+    y_forward = f_forward(X)\n+    y_backward = f_backward(X)\n+    y_expected = _to_list(merge_func(y_forward[0], y_backward[0]))\n+    assert len(y_merged) == len(y_expected) + n_states * 2\n+    for x1, x2 in zip(y_merged, y_expected):\n+        assert_allclose(x1, x2, atol=1e-5)\n+\n+    # test if the state of a BiRNN is the concatenation of the underlying RNNs\n+    y_merged = y_merged[-n_states * 2:]\n+    y_forward = y_forward[-n_states:]\n+    y_backward = y_backward[-n_states:]\n+    for state_birnn, state_inner in zip(y_merged, y_forward + y_backward):\n+        assert_allclose(state_birnn, state_inner, atol=1e-5)\n+\n+\n+@keras_test\n+@pytest.mark.skipif(K.backend() == 'theano', reason='Not supported.')\n+@pytest.mark.parametrize('merge_mode', ['sum', 'concat', None])\n+def test_Bidirectional_dropout(merge_mode):\n+    rnn = layers.LSTM\n+    samples = 2\n+    dim = 5\n+    timesteps = 3\n+    units = 3\n+    X = [np.random.rand(samples, timesteps, dim)]\n+\n+    inputs = Input((timesteps, dim))\n+    wrapped = wrappers.Bidirectional(rnn(units, dropout=0.2, recurrent_dropout=0.2),\n+                                     merge_mode=merge_mode)\n+    outputs = _to_list(wrapped(inputs, training=True))\n+    assert all(not getattr(x, '_uses_learning_phase') for x in outputs)\n+\n+    inputs = Input((timesteps, dim))\n+    wrapped = wrappers.Bidirectional(rnn(units, dropout=0.2, return_state=True),\n+                                     merge_mode=merge_mode)\n+    outputs = _to_list(wrapped(inputs))\n+    assert all(x._uses_learning_phase for x in outputs)\n+\n+    model = Model(inputs, outputs)\n+    assert model.uses_learning_phase\n+    y1 = _to_list(model.predict(X))\n+    y2 = _to_list(model.predict(X))\n+    for x1, x2 in zip(y1, y2):\n+        assert_allclose(x1, x2, atol=1e-5)\n+\n+\n+@keras_test\n+def test_Bidirectional_state_reuse():\n+    rnn = layers.LSTM\n+    samples = 2\n+    dim = 5\n+    timesteps = 3\n+    units = 3\n+\n+    inputs = Input((timesteps, dim))\n+    layer = wrappers.Bidirectional(rnn(units, return_state=True, return_sequences=True))\n+    outputs = layer(inputs)\n+    output, state = outputs[0], outputs[1:]\n+\n+    # test passing invalid initial_state: passing a tensor\n+    with pytest.raises(ValueError):\n+        output = wrappers.Bidirectional(rnn(units))(output, initial_state=state[0])\n+\n+    # test valid usage: passing a list\n+    output = wrappers.Bidirectional(rnn(units))(output, initial_state=state)\n+    model = Model(inputs, output)\n+    inputs = np.random.rand(samples, timesteps, dim)\n+    outputs = model.predict(inputs)\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c3e844e7063efc14f6a8364cc04df4526b57352e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 20 | Churn Cumulative: 1175 | Contributors (this commit): 29 | Commits (past 90d): 21 | Contributors (cumulative): 37 | DMM Complexity: 1.0\n\nDIFF:\n@@ -327,7 +327,7 @@ class Progbar(object):\n         info = ' - %.0fs' % (now - self.start)\n         if self.verbose == 1:\n             if (not force and (now - self.last_update) < self.interval and\n-                    (self.target is not None and current < self.target)):\n+                    self.target is not None and current < self.target):\n                 return\n \n             prev_total_width = self.total_width\n\n@@ -14,16 +14,16 @@ from keras import regularizers\n \n @keras_test\n def test_progbar():\n-    n = 2\n-    input_arr = np.random.random((n, n, n))\n+    values_s = [None,\n+                [['key1', 1], ['key2', 1e-4]],\n+                [['key3', 1], ['key2', 1e-4]]]\n \n-    bar = Progbar(n)\n-    for i, arr in enumerate(input_arr):\n-        bar.update(i, list(arr))\n-\n-    bar = Progbar(None)\n-    for i, arr in enumerate(input_arr):\n-        bar.update(i, list(arr))\n+    for target in (len(values_s) - 1, None):\n+        for verbose in (0, 1, 2):\n+            bar = Progbar(target, width=30, verbose=verbose, interval=0.05)\n+            for force in (False, True):\n+                for current, values in enumerate(values_s):\n+                    bar.update(current, values=values, force=force)\n \n \n def test_custom_objects_scope():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#24246ea53157f7e9faef74db3e4c06642a50509d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 50 | Lines Deleted: 69 | Files Changed: 6 | Hunks: 18 | Methods Changed: 14 | Complexity Δ (Sum/Max): -3/1 | Churn Δ: 119 | Churn Cumulative: 23301 | Contributors (this commit): 122 | Commits (past 90d): 47 | Contributors (cumulative): 171 | DMM Complexity: 0.8461538461538461\n\nDIFF:\n@@ -258,6 +258,7 @@ class Layer(object):\n     def __init__(self, **kwargs):\n         self.input_spec = None\n         self.supports_masking = False\n+        self.stateful = False\n \n         # These properties will be set upon call of self.build()\n         self._trainable_weights = []\n@@ -283,7 +284,6 @@ class Layer(object):\n                           'dtype',\n                           'name',\n                           'trainable',\n-                          'updatable',\n                           'weights',\n                           'input_dtype',  # legacy\n                           }\n@@ -297,7 +297,6 @@ class Layer(object):\n         self.name = name\n \n         self.trainable = kwargs.get('trainable', True)\n-        self.updatable = kwargs.get('updatable', True)\n         if 'input_shape' in kwargs or 'batch_input_shape' in kwargs:\n             # In this case we will later create an input layer\n             # to insert before the current layer\n@@ -345,6 +344,8 @@ class Layer(object):\n \n     @property\n     def updates(self):\n+        if not self.trainable and not self.stateful:\n+            return []\n         return self._updates\n \n     @property\n@@ -1157,6 +1158,8 @@ class Layer(object):\n         self._per_input_updates[inputs_hash] += updates\n \n     def get_updates_for(self, inputs):\n+        if not self.trainable and not self.stateful:\n+            return []\n         if inputs is not None:\n             inputs_hash = _object_list_uid(inputs)\n         else:\n@@ -1508,7 +1511,6 @@ class Container(Layer):\n \n         self.supports_masking = False\n         self.trainable = True\n-        self.updatable = True\n         self._per_input_losses = {}\n         self._per_input_updates = {}\n \n@@ -1896,13 +1898,11 @@ class Container(Layer):\n         # Returns\n             A list of update ops.\n         \"\"\"\n-        if not self.updatable:\n+        if not self.trainable and not self.stateful:\n             return []\n         updates = []\n         for layer in self.layers:\n             if hasattr(layer, 'updates'):\n-                if hasattr(layer, 'updatable') and not layer.updatable:\n-                    continue\n                 # Collect updates that are dependent on inputs\n                 # that are part of the model.\n                 for node_index, node in enumerate(layer._inbound_nodes):\n@@ -1971,10 +1971,7 @@ class Container(Layer):\n         \"\"\"\n         state_updates = []\n         for layer in self.layers:\n-            if getattr(layer, 'stateful', False):\n-                if hasattr(layer, 'updates'):\n-                    if hasattr(layer, 'updatable') and not layer.updatable:\n-                        continue\n+            if layer.stateful:\n                 state_updates += layer.updates\n         return state_updates\n \n\n@@ -94,6 +94,8 @@ class Merge(Layer):\n         self.supports_masking = True\n         self.uses_learning_phase = False\n         self.input_spec = None  # Compatible with anything.\n+        self.stateful = False\n+        self.trainable = True\n         if not name:\n             prefix = self.__class__.__name__.lower()\n             name = prefix + '_' + str(K.get_uid(prefix))\n\n@@ -392,7 +392,6 @@ class Sequential(Model):\n         self.inputs = []  # List of input tensors\n         self.outputs = []  # List of length 1: the output tensor (unique).\n         self._trainable = True\n-        self._updatable = True\n         self._initial_weights = None\n \n         # Model attributes.\n@@ -557,7 +556,6 @@ class Sequential(Model):\n         self.model = Model(self.inputs, self.outputs[0],\n                            name=self.name + '_model')\n         self.model.trainable = self.trainable\n-        self.model.updatable = self.updatable\n \n         # mirror model attributes\n         self.supports_masking = self.model.supports_masking\n@@ -631,16 +629,6 @@ class Sequential(Model):\n             self.model.trainable = value\n         self._trainable = value\n \n-    @property\n-    def updatable(self):\n-        return self._updatable\n-\n-    @updatable.setter\n-    def updatable(self, value):\n-        if self.built:\n-            self.model.updatable = value\n-        self._updatable = value\n-\n     @property\n     def trainable_weights(self):\n         if not self.trainable:\n\n@@ -763,47 +763,5 @@ def test_multi_output_mask():\n     assert K.int_shape(z)[1:] == (16, 16, 3)\n \n \n-@keras_test\n-def test_model_updatable_attribute():\n-    val_a = np.random.random((10, 4))\n-    val_out = np.random.random((10, 4))\n-\n-    a = Input(shape=(4,))\n-    layer = layers.BatchNormalization(input_shape=(4,))\n-    b = layer(a)\n-    model = Model(a, b)\n-\n-    model.trainable = False\n-    model.updatable = False\n-\n-    assert not model.updatable\n-    assert not model.updates\n-\n-    model.compile('sgd', 'mse')\n-    assert not model.updates\n-\n-    x1 = model.predict(val_a)\n-    model.train_on_batch(val_a, val_out)\n-    x2 = model.predict(val_a)\n-    assert_allclose(x1, x2, atol=1e-7)\n-\n-    model.updatable = True\n-    model.compile('sgd', 'mse')\n-    assert model.updates\n-\n-    model.train_on_batch(val_a, val_out)\n-    x2 = model.predict(val_a)\n-    assert np.abs(np.sum(x1 - x2)) > 1e-5\n-\n-    layer.updatable = False\n-    model.compile('sgd', 'mse')\n-    assert not model.updates\n-\n-    x1 = model.predict(val_a)\n-    model.train_on_batch(val_a, val_out)\n-    x2 = model.predict(val_a)\n-    assert_allclose(x1, x2, atol=1e-7)\n-\n-\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n@@ -184,5 +184,44 @@ def test_shared_batchnorm():\n     new_model.train_on_batch(x, x)\n \n \n+@keras_test\n+def test_that_trainable_disables_updates():\n+    val_a = np.random.random((10, 4))\n+    val_out = np.random.random((10, 4))\n+\n+    a = Input(shape=(4,))\n+    layer = normalization.BatchNormalization(input_shape=(4,))\n+    b = layer(a)\n+    model = Model(a, b)\n+\n+    model.trainable = False\n+    assert not model.updates\n+\n+    model.compile('sgd', 'mse')\n+    assert not model.updates\n+\n+    x1 = model.predict(val_a)\n+    model.train_on_batch(val_a, val_out)\n+    x2 = model.predict(val_a)\n+    assert_allclose(x1, x2, atol=1e-7)\n+\n+    model.trainable = True\n+    model.compile('sgd', 'mse')\n+    assert model.updates\n+\n+    model.train_on_batch(val_a, val_out)\n+    x2 = model.predict(val_a)\n+    assert np.abs(np.sum(x1 - x2)) > 1e-5\n+\n+    layer.trainable = False\n+    model.compile('sgd', 'mse')\n+    assert not model.updates\n+\n+    x1 = model.predict(val_a)\n+    model.train_on_batch(val_a, val_out)\n+    x2 = model.predict(val_a)\n+    assert_allclose(x1, x2, atol=1e-7)\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n@@ -368,7 +368,7 @@ def test_clone_sequential_model():\n \n \n @keras_test\n-def test_sequential_updatable_attribute():\n+def test_sequential_update_disabling():\n     val_a = np.random.random((10, 4))\n     val_out = np.random.random((10, 4))\n \n@@ -376,9 +376,6 @@ def test_sequential_updatable_attribute():\n     model.add(keras.layers.BatchNormalization(input_shape=(4,)))\n \n     model.trainable = False\n-    model.updatable = False\n-\n-    assert not model.updatable\n     assert not model.updates\n \n     model.compile('sgd', 'mse')\n@@ -390,7 +387,7 @@ def test_sequential_updatable_attribute():\n     x2 = model.predict(val_a)\n     assert_allclose(x1, x2, atol=1e-7)\n \n-    model.updatable = True\n+    model.trainable = True\n     model.compile('sgd', 'mse')\n     assert model.updates\n     assert model.model.updates\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#76c5b616f2cac0d4d1852049d98ab8a067142373", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 8 | Methods Changed: 2 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 25 | Churn Cumulative: 6157 | Contributors (this commit): 79 | Commits (past 90d): 38 | Contributors (cumulative): 79 | DMM Complexity: 0.0\n\nDIFF:\n@@ -871,22 +871,35 @@ class Model(Container):\n                     metric_name_prefix = 'weighted_' if weights is not None else ''\n \n                     for metric in metrics:\n-                        if metric == 'accuracy' or metric == 'acc':\n-                            # custom handling of accuracy\n+                        if metric in ('accuracy', 'acc', 'crossentropy', 'ce'):\n+                            # custom handling of accuracy/crossentropy\n                             # (because of class mode duality)\n                             output_shape = self._internal_output_shapes[i]\n                             if (output_shape[-1] == 1 or\n                                self.loss_functions[i] == losses.binary_crossentropy):\n-                                # case: binary accuracy\n+                                # case: binary accuracy/crossentropy\n+                                if metric in ('accuracy', 'acc'):\n                                     acc_fn = metrics_module.binary_accuracy\n+                                elif metric in ('crossentropy', 'ce'):\n+                                    acc_fn = metrics_module.binary_crossentropy\n                             elif self.loss_functions[i] == losses.sparse_categorical_crossentropy:\n-                                # case: categorical accuracy with sparse targets\n+                                # case: categorical accuracy/crossentropy with sparse targets\n+                                if metric in ('accuracy', 'acc'):\n                                     acc_fn = metrics_module.sparse_categorical_accuracy\n+                                elif metric in ('crossentropy', 'ce'):\n+                                    acc_fn = metrics_module.sparse_categorical_crossentropy\n                             else:\n+                                # case: categorical accuracy/crossentropy\n+                                if metric in ('accuracy', 'acc'):\n                                     acc_fn = metrics_module.categorical_accuracy\n-\n+                                elif metric in ('crossentropy', 'ce'):\n+                                    acc_fn = metrics_module.categorical_crossentropy\n+                            if metric in ('accuracy', 'acc'):\n+                                    suffix = 'acc'\n+                            elif metric in ('crossentropy', 'ce'):\n+                                    suffix = 'ce'\n                             weighted_metric_fn = _weighted_masked_objective(acc_fn)\n-                            metric_name = metric_name_prefix + 'acc'\n+                            metric_name = metric_name_prefix + suffix\n                         else:\n                             metric_fn = metrics_module.get(metric)\n                             weighted_metric_fn = _weighted_masked_objective(metric_fn)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f3f9e020119736920b5bf3adc91fd658e1910775", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 7 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 21 | Churn Cumulative: 161 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -28,6 +28,9 @@ from keras import backend as K\n from keras.datasets import mnist\n import numpy as np\n import matplotlib.pyplot as plt\n+from PIL import Image\n+\n+np.random.seed(1337)\n \n # MNIST dataset\n (x_train, _), (x_test, _) = mnist.load_data()\n@@ -115,26 +118,32 @@ decoder.summary()\n autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n autoencoder.summary()\n \n-# Mean Square Error (MSE) loss function, Adam optimizer\n autoencoder.compile(loss='mse', optimizer='adam')\n \n # Train the autoencoder\n autoencoder.fit(x_train_noisy,\n                 x_train,\n                 validation_data=(x_test_noisy, x_test),\n-                epochs=10,\n+                epochs=30,\n                 batch_size=batch_size)\n \n # Predict the Autoencoder output from corrupted test images\n x_decoded = autoencoder.predict(x_test_noisy)\n \n # Display the 1st 8 corrupted and denoised images\n-imgs = np.concatenate([x_test_noisy[:8], x_decoded[:8]])\n-imgs = imgs.reshape((4, 4, image_size, image_size))\n+rows, cols = 10, 30\n+num = rows * cols\n+imgs = np.concatenate([x_test[:num], x_test_noisy[:num], x_decoded[:num]])\n+imgs = imgs.reshape((rows * 3, cols, image_size, image_size))\n+imgs = np.vstack(np.split(imgs, rows, axis=1))\n+imgs = imgs.reshape((rows * 3, -1, image_size, image_size))\n imgs = np.vstack([np.hstack(i) for i in imgs])\n+imgs = (imgs * 255).astype(np.uint8)\n plt.figure()\n plt.axis('off')\n-plt.title('Corrupted Input: top 2 rows, Output is Denoised Input: last 2 rows')\n+plt.title('Original images: top rows, '\n+          'Corrupted Input: middle rows, '\n+          'Denoised Input:  third rows')\n plt.imshow(imgs, interpolation='none', cmap='gray')\n-plt.savefig('corrupted_and_denoised.png')\n+Image.fromarray(imgs).save('corrupted_and_denoised.png')\n plt.show()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6f09be91e695d74f19aac084808b998ecf6eb24e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 2746 | Contributors (this commit): 46 | Commits (past 90d): 17 | Contributors (cumulative): 46 | DMM Complexity: 0.0\n\nDIFF:\n@@ -749,8 +749,9 @@ class ImageDataGenerator(object):\n         if self.zca_whitening:\n             flat_x = np.reshape(x, (x.shape[0], x.shape[1] * x.shape[2] * x.shape[3]))\n             num_examples = flat_x.shape[0]\n-            u, s, vt = linalg.svd(flat_x / np.sqrt(num_examples))\n-            s_expand = np.hstack((s, np.zeros(vt.shape[0] - num_examples, dtype=flat_x.dtype)))\n+            _, s, vt = linalg.svd(flat_x / np.sqrt(num_examples))\n+            s_expand = np.hstack((s, np.zeros(vt.shape[0] - num_examples,\n+                                              dtype=flat_x.dtype)))\n             self.principal_components = (vt.T / np.sqrt(s_expand ** 2 + self.zca_epsilon)).dot(vt)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f9e53abe1fddb4581e3962a305334bd7cd7dfdf6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 972 | Contributors (this commit): 14 | Commits (past 90d): 6 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -286,12 +286,12 @@ class Bidirectional(Wrapper):\n             output_shape[-1] *= 2\n             output_shape = tuple(output_shape)\n         elif self.merge_mode is None:\n-            output_shape = [output_shape] * 2\n+            output_shape = [output_shape, copy.copy(output_shape)]\n \n         if self.return_state:\n             if self.merge_mode is None:\n-                return output_shape + state_shape * 2\n-            return [output_shape] + state_shape * 2\n+                return output_shape + state_shape + copy.copy(state_shape)\n+            return [output_shape] + state_shape + copy.copy(state_shape)\n         return output_shape\n \n     def call(self, inputs, training=None, mask=None, initial_state=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b7f930f81bcc363eac8fc91d4bc390f2974e76f6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 9961 | Contributors (this commit): 82 | Commits (past 90d): 20 | Contributors (cumulative): 82 | DMM Complexity: None\n\nDIFF:\n@@ -803,6 +803,7 @@ class Sequential(Model):\n \n         # Raises\n             ValueError: In case of invalid arguments for\n+                `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n \n         # Example\n             ```python\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#311f4542636fb070842c67da52dcea6c482bf6e9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2193 | Contributors (this commit): 26 | Commits (past 90d): 7 | Contributors (cumulative): 26 | DMM Complexity: None\n\nDIFF:\n@@ -405,7 +405,7 @@ class Adam(Optimizer):\n         beta_2: float, 0 < beta < 1. Generally close to 1.\n         epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n         decay: float >= 0. Learning rate decay over each update.\n-        amsgrad: boolean. Weather to apply the AMSGrad variant of this\n+        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n             algorithm from the paper \"On the Convergence of Adam and\n             Beyond\".\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ab25382a2fe7c0684089918ae0fdbfcecd4065d4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 251 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -139,7 +139,7 @@ plt.title('Input')\n plt.show()\n \n \n-def create_model(stateful: bool):\n+def create_model(stateful):\n     model = Sequential()\n     model.add(LSTM(20,\n               input_shape=(lahead, 1),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e1a1e880d53fbbec97e8c3dfe1c82281a5761d44", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1347 | Contributors (this commit): 15 | Commits (past 90d): 15 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -171,7 +171,7 @@ def get_file(fname,\n         Path to the downloaded file\n     \"\"\"\n     if cache_dir is None:\n-        cache_dir = os.path.expanduser(os.path.join('~', '.keras'))\n+        cache_dir = os.path.join(os.path.expanduser('~'), '.keras')\n     if md5_hash is not None and file_hash is None:\n         file_hash = md5_hash\n         hash_algorithm = 'md5'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fa6de5a45e6d80216b4b57aeaf7d750f5d088747", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 534 | Contributors (this commit): 8 | Commits (past 90d): 8 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -24,13 +24,16 @@ def _preprocess_numpy_input(x, data_format, mode):\n     # Arguments\n         x: Input array, 3D or 4D.\n         data_format: Data format of the image array.\n-        mode: One of \"caffe\", \"tf\".\n+        mode: One of \"caffe\", \"tf\" or \"torch\".\n             - caffe: will convert the images from RGB to BGR,\n                 then will zero-center each color channel with\n                 respect to the ImageNet dataset,\n                 without scaling.\n             - tf: will scale pixels between -1 and 1,\n                 sample-wise.\n+            - torch: will scale pixels between 0 and 1 and then\n+                will normalize each channel with respect to the\n+                ImageNet dataset.\n \n     # Returns\n         Preprocessed Numpy array.\n@@ -92,13 +95,16 @@ def _preprocess_symbolic_input(x, data_format, mode):\n     # Arguments\n         x: Input tensor, 3D or 4D.\n         data_format: Data format of the image tensor.\n-        mode: One of \"caffe\", \"tf\".\n+        mode: One of \"caffe\", \"tf\" or \"torch\".\n             - caffe: will convert the images from RGB to BGR,\n                 then will zero-center each color channel with\n                 respect to the ImageNet dataset,\n                 without scaling.\n             - tf: will scale pixels between -1 and 1,\n                 sample-wise.\n+            - torch: will scale pixels between 0 and 1 and then\n+                will normalize each channel with respect to the\n+                ImageNet dataset.\n \n     # Returns\n         Preprocessed tensor.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bbad459960173ecfe97b5aa2035410998a195002", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 932 | Contributors (this commit): 8 | Commits (past 90d): 5 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -1,4 +1,5 @@\n import pytest\n+import os\n from multiprocessing import Process, Queue\n from keras.utils.test_utils import keras_test\n from keras.utils.test_utils import layer_test\n@@ -8,6 +9,11 @@ from keras import applications\n from keras import backend as K\n \n \n+pytestmark = pytest.mark.skipif(\n+    os.environ['CORE_CHANGED'] == 'False' and os.environ['APP_CHANGED'] == 'False',\n+    reason='runs only when the relevant files have been modified')\n+\n+\n def clean_run(model_fn):\n     if K.backend() == 'cntk':\n         # Create model in a subprocess so that the memory consumed by InceptionResNetV2 will be\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ca8172a50fd4d6a3e22960d60dae3bf112721dbd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 20 | Churn Cumulative: 1155 | Contributors (this commit): 3 | Commits (past 90d): 11 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -38,12 +38,12 @@ from .imagenet_utils import decode_predictions\n from .imagenet_utils import _obtain_input_shape\n \n \n-DENSENET121_WEIGHT_PATH = 'https://github.com/taehoonlee/deep-learning-models/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels.h5'\n-DENSENET121_WEIGHT_PATH_NO_TOP = 'https://github.com/taehoonlee/deep-learning-models/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5'\n-DENSENET169_WEIGHT_PATH = 'https://github.com/taehoonlee/deep-learning-models/releases/download/densenet/densenet169_weights_tf_dim_ordering_tf_kernels.h5'\n-DENSENET169_WEIGHT_PATH_NO_TOP = 'https://github.com/taehoonlee/deep-learning-models/releases/download/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5'\n-DENSENET201_WEIGHT_PATH = 'https://github.com/taehoonlee/deep-learning-models/releases/download/densenet/densenet201_weights_tf_dim_ordering_tf_kernels.h5'\n-DENSENET201_WEIGHT_PATH_NO_TOP = 'https://github.com/taehoonlee/deep-learning-models/releases/download/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5'\n+DENSENET121_WEIGHT_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.8/densenet121_weights_tf_dim_ordering_tf_kernels.h5'\n+DENSENET121_WEIGHT_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.8/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5'\n+DENSENET169_WEIGHT_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.8/densenet169_weights_tf_dim_ordering_tf_kernels.h5'\n+DENSENET169_WEIGHT_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.8/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5'\n+DENSENET201_WEIGHT_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.8/densenet201_weights_tf_dim_ordering_tf_kernels.h5'\n+DENSENET201_WEIGHT_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.8/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5'\n \n \n def dense_block(x, blocks, name):\n\n@@ -60,10 +60,10 @@ from ..applications.inception_v3 import preprocess_input\n from ..applications.imagenet_utils import decode_predictions\n from .. import backend as K\n \n-NASNET_MOBILE_WEIGHT_PATH = 'https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-mobile.h5'\n-NASNET_MOBILE_WEIGHT_PATH_NO_TOP = 'https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-mobile-no-top.h5'\n-NASNET_LARGE_WEIGHT_PATH = 'https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-large.h5'\n-NASNET_LARGE_WEIGHT_PATH_NO_TOP = 'https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-large-no-top.h5'\n+NASNET_MOBILE_WEIGHT_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.8/NASNet-mobile.h5'\n+NASNET_MOBILE_WEIGHT_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.8/NASNet-mobile-no-top.h5'\n+NASNET_LARGE_WEIGHT_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.8/NASNet-large.h5'\n+NASNET_LARGE_WEIGHT_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.8/NASNet-large-no-top.h5'\n \n \n def NASNet(input_shape=None,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
