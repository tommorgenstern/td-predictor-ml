{"custom_id": "keras#9bcf324da2176c832662feedc3e16873676b02da", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 273 | Lines Deleted: 0 | Files Changed: 5 | Hunks: 5 | Methods Changed: 17 | Complexity Δ (Sum/Max): 31/18 | Churn Δ: 273 | Churn Cumulative: 1071 | Contributors (this commit): 7 | Commits (past 90d): 31 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -173,6 +173,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_hue import (\n from keras.src.layers.preprocessing.image_preprocessing.random_rotation import (\n     RandomRotation,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_saturation import (\n+    RandomSaturation,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_translation import (\n     RandomTranslation,\n )\n\n@@ -173,6 +173,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_hue import (\n from keras.src.layers.preprocessing.image_preprocessing.random_rotation import (\n     RandomRotation,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_saturation import (\n+    RandomSaturation,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_translation import (\n     RandomTranslation,\n )\n\n@@ -117,6 +117,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_hue import (\n from keras.src.layers.preprocessing.image_preprocessing.random_rotation import (\n     RandomRotation,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_saturation import (\n+    RandomSaturation,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_translation import (\n     RandomTranslation,\n )\n\n@@ -0,0 +1,167 @@\n+from keras.src.api_export import keras_export\n+from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n+    BaseImagePreprocessingLayer,\n+)\n+from keras.src.random import SeedGenerator\n+\n+\n+@keras_export(\"keras.layers.RandomSaturation\")\n+class RandomSaturation(BaseImagePreprocessingLayer):\n+    \"\"\"Randomly adjusts the saturation on given images.\n+\n+    This layer will randomly increase/reduce the saturation for the input RGB\n+    images.\n+\n+    Args:\n+        factor: A tuple of two floats or a single float.\n+            `factor` controls the extent to which the image saturation\n+            is impacted. `factor=0.5` makes this layer perform a no-op\n+            operation. `factor=0.0` makes the image fully grayscale.\n+            `factor=1.0` makes the image fully saturated. Values should\n+            be between `0.0` and `1.0`. If a tuple is used, a `factor`\n+            is sampled between the two values for every image augmented.\n+            If a single float is used, a value between `0.0` and the passed\n+            float is sampled. To ensure the value is always the same,\n+            pass a tuple with two identical floats: `(0.5, 0.5)`.\n+        value_range: the range of values the incoming images will have.\n+            Represented as a two-number tuple written `[low, high]`. This is\n+            typically either `[0, 1]` or `[0, 255]` depending on how your\n+            preprocessing pipeline is set up.\n+        seed: Integer. Used to create a random seed.\n+\n+    Example:\n+    ```python\n+    (images, labels), _ = keras.datasets.cifar10.load_data()\n+    images = images.astype(\"float32\")\n+    random_saturation = keras.layers.RandomSaturation(factor=0.2)\n+    augmented_images = random_saturation(images)\n+    ```\n+    \"\"\"\n+\n+    _VALUE_RANGE_VALIDATION_ERROR = (\n+        \"The `value_range` argument should be a list of two numbers. \"\n+    )\n+\n+    def __init__(\n+        self,\n+        factor,\n+        value_range=(0, 255),\n+        data_format=None,\n+        seed=None,\n+        **kwargs,\n+    ):\n+        super().__init__(data_format=data_format, **kwargs)\n+        self._set_factor(factor)\n+        self._set_value_range(value_range)\n+        self.seed = seed\n+        self.generator = SeedGenerator(seed)\n+\n+    def _set_value_range(self, value_range):\n+        if not isinstance(value_range, (tuple, list)):\n+            raise ValueError(\n+                self._VALUE_RANGE_VALIDATION_ERROR\n+                + f\"Received: value_range={value_range}\"\n+            )\n+        if len(value_range) != 2:\n+            raise ValueError(\n+                self._VALUE_RANGE_VALIDATION_ERROR\n+                + f\"Received: value_range={value_range}\"\n+            )\n+        self.value_range = sorted(value_range)\n+\n+    def get_random_transformation(self, data, training=True, seed=None):\n+        if isinstance(data, dict):\n+            images = data[\"images\"]\n+        else:\n+            images = data\n+        images_shape = self.backend.shape(images)\n+        rank = len(images_shape)\n+        if rank == 3:\n+            batch_size = 1\n+        elif rank == 4:\n+            batch_size = images_shape[0]\n+        else:\n+            raise ValueError(\n+                \"Expected the input image to be rank 3 or 4. Received: \"\n+                f\"inputs.shape={images_shape}\"\n+            )\n+\n+        if seed is None:\n+            seed = self._get_seed_generator(self.backend._backend)\n+\n+        factor = self.backend.random.uniform(\n+            (batch_size,),\n+            minval=self.factor[0],\n+            maxval=self.factor[1],\n+            seed=seed,\n+        )\n+        factor = factor / (1 - factor)\n+        return {\"factor\": factor}\n+\n+    def transform_images(self, images, transformation=None, training=True):\n+        def _apply_random_saturation(images, transformation):\n+            adjust_factors = transformation[\"factor\"]\n+            adjust_factors = self.backend.cast(\n+                adjust_factors, self.compute_dtype\n+            )\n+            adjust_factors = self.backend.numpy.reshape(\n+                adjust_factors, self.backend.shape(adjust_factors) + (1, 1)\n+            )\n+            images = self.backend.image.rgb_to_hsv(\n+                images, data_format=self.data_format\n+            )\n+            if self.data_format == \"channels_first\":\n+                s_channel = self.backend.numpy.multiply(\n+                    images[:, 1, :, :], adjust_factors\n+                )\n+                s_channel = self.backend.numpy.clip(\n+                    s_channel, self.value_range[0], self.value_range[1]\n+                )\n+                images = self.backend.numpy.stack(\n+                    [images[:, 0, :, :], s_channel, images[:, 2, :, :]], axis=1\n+                )\n+            else:\n+                s_channel = self.backend.numpy.multiply(\n+                    images[..., 1], adjust_factors\n+                )\n+                s_channel = self.backend.numpy.clip(\n+                    s_channel, self.value_range[0], self.value_range[1]\n+                )\n+                images = self.backend.numpy.stack(\n+                    [images[..., 0], s_channel, images[..., 2]], axis=-1\n+                )\n+            images = self.backend.image.hsv_to_rgb(\n+                images, data_format=self.data_format\n+            )\n+            return images\n+\n+        if training:\n+            images = _apply_random_saturation(images, transformation)\n+        return images\n+\n+    def transform_labels(self, labels, transformation, training=True):\n+        return labels\n+\n+    def transform_segmentation_masks(\n+        self, segmentation_masks, transformation, training=True\n+    ):\n+        return segmentation_masks\n+\n+    def transform_bounding_boxes(\n+        self, bounding_boxes, transformation, training=True\n+    ):\n+        return bounding_boxes\n+\n+    def get_config(self):\n+        config = super().get_config()\n+        config.update(\n+            {\n+                \"factor\": self.factor,\n+                \"value_range\": self.value_range,\n+                \"seed\": self.seed,\n+            }\n+        )\n+        return config\n+\n+    def compute_output_shape(self, input_shape):\n+        return input_shape\n\n@@ -0,0 +1,97 @@\n+import numpy as np\n+import pytest\n+from tensorflow import data as tf_data\n+\n+import keras\n+from keras.src import backend\n+from keras.src import layers\n+from keras.src import testing\n+\n+\n+class RandomSaturationTest(testing.TestCase):\n+    @pytest.mark.requires_trainable_backend\n+    def test_layer(self):\n+        self.run_layer_test(\n+            layers.RandomSaturation,\n+            init_kwargs={\n+                \"factor\": 0.75,\n+                \"seed\": 1,\n+            },\n+            input_shape=(8, 3, 4, 3),\n+            supports_masking=False,\n+            expected_output_shape=(8, 3, 4, 3),\n+        )\n+\n+    def test_random_saturation_value_range(self):\n+        image = keras.random.uniform(shape=(3, 3, 3), minval=0, maxval=1)\n+\n+        layer = layers.RandomSaturation(0.2)\n+        adjusted_image = layer(image)\n+\n+        self.assertTrue(keras.ops.numpy.all(adjusted_image >= 0))\n+        self.assertTrue(keras.ops.numpy.all(adjusted_image <= 1))\n+\n+    def test_random_saturation_no_op(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            inputs = np.random.random((2, 8, 8, 3))\n+        else:\n+            inputs = np.random.random((2, 3, 8, 8))\n+\n+        layer = layers.RandomSaturation((0.5, 0.5))\n+        output = layer(inputs, training=False)\n+        self.assertAllClose(inputs, output, atol=1e-3, rtol=1e-5)\n+\n+    def test_random_saturation_full_grayscale(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            inputs = np.random.random((2, 8, 8, 3))\n+        else:\n+            inputs = np.random.random((2, 3, 8, 8))\n+        layer = layers.RandomSaturation(factor=(0.0, 0.0))\n+        result = layer(inputs)\n+\n+        if data_format == \"channels_last\":\n+            self.assertAllClose(result[..., 0], result[..., 1])\n+            self.assertAllClose(result[..., 1], result[..., 2])\n+        else:\n+            self.assertAllClose(result[:, 0, :, :], result[:, 1, :, :])\n+            self.assertAllClose(result[:, 1, :, :], result[:, 2, :, :])\n+\n+    def test_random_saturation_full_saturation(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            inputs = np.random.random((2, 8, 8, 3))\n+        else:\n+            inputs = np.random.random((2, 3, 8, 8))\n+        layer = layers.RandomSaturation(factor=(1.0, 1.0))\n+        result = layer(inputs)\n+\n+        hsv = backend.image.rgb_to_hsv(result)\n+        s_channel = hsv[..., 1]\n+\n+        self.assertAllClose(\n+            keras.ops.numpy.max(s_channel), layer.value_range[1]\n+        )\n+\n+    def test_random_saturation_randomness(self):\n+        image = keras.random.uniform(shape=(3, 3, 3), minval=0, maxval=1)[:5]\n+\n+        layer = layers.RandomSaturation(0.2)\n+        adjusted_images = layer(image)\n+\n+        self.assertNotAllClose(adjusted_images, image)\n+\n+    def test_tf_data_compatibility(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            input_data = np.random.random((2, 8, 8, 3))\n+        else:\n+            input_data = np.random.random((2, 3, 8, 8))\n+        layer = layers.RandomSaturation(\n+            factor=0.5, data_format=data_format, seed=1337\n+        )\n+\n+        ds = tf_data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n+        for output in ds.take(1):\n+            output.numpy()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c0a1f2490c9ebd8e182d1e373be73d287e89e2e3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 6 | Churn Cumulative: 173 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -99,7 +99,7 @@ class RandomSaturation(BaseImagePreprocessingLayer):\n         return {\"factor\": factor}\n \n     def transform_images(self, images, transformation=None, training=True):\n-        def _apply_random_saturation(images, transformation):\n+        if training:\n             adjust_factors = transformation[\"factor\"]\n             adjust_factors = self.backend.cast(\n                 adjust_factors, self.compute_dtype\n@@ -135,10 +135,6 @@ class RandomSaturation(BaseImagePreprocessingLayer):\n             )\n         return images\n \n-        if training:\n-            images = _apply_random_saturation(images, transformation)\n-        return images\n-\n     def transform_labels(self, labels, transformation, training=True):\n         return labels\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ed1442ed5004fcd81656998400bc8592e1d0632c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 101 | Lines Deleted: 62 | Files Changed: 4 | Hunks: 18 | Methods Changed: 15 | Complexity Δ (Sum/Max): 3/5 | Churn Δ: 163 | Churn Cumulative: 944 | Contributors (this commit): 3 | Commits (past 90d): 9 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,42 +1,7 @@\n+try:\n     import sklearn\n-from packaging.version import parse as parse_version\n-from sklearn import get_config\n-\n-sklearn_version = parse_version(parse_version(sklearn.__version__).base_version)\n-\n-if sklearn_version < parse_version(\"1.6\"):\n-\n-    def patched_more_tags(estimator, expected_failed_checks):\n-        import copy\n-\n-        from sklearn.utils._tags import _safe_tags\n-\n-        original_tags = copy.deepcopy(_safe_tags(estimator))\n-\n-        def patched_more_tags(self):\n-            original_tags.update({\"_xfail_checks\": expected_failed_checks})\n-            return original_tags\n-\n-        estimator.__class__._more_tags = patched_more_tags\n-        return estimator\n-\n-    def parametrize_with_checks(\n-        estimators,\n-        *,\n-        legacy: bool = True,\n-        expected_failed_checks=None,\n-    ):\n-        # legacy is not supported and ignored\n-        from sklearn.utils.estimator_checks import parametrize_with_checks  # noqa: F401, I001\n-\n-        estimators = [\n-            patched_more_tags(estimator, expected_failed_checks(estimator))\n-            for estimator in estimators\n-        ]\n-\n-        return parametrize_with_checks(estimators)\n-else:\n-    from sklearn.utils.estimator_checks import parametrize_with_checks  # noqa: F401, I001\n+except ImportError:\n+    sklearn = None\n \n \n def _validate_data(estimator, *args, **kwargs):\n@@ -59,9 +24,6 @@ def _validate_data(estimator, *args, **kwargs):\n \n \n def type_of_target(y, input_name=\"\", *, raise_unknown=False):\n-    # fix for raise_unknown which is introduced in scikit-learn 1.6\n-    from sklearn.utils.multiclass import type_of_target\n-\n     def _raise_or_return(target_type):\n         \"\"\"Depending on the value of raise_unknown, either raise an error or\n         return 'unknown'.\n@@ -72,7 +34,9 @@ def type_of_target(y, input_name=\"\", *, raise_unknown=False):\n         else:\n             return target_type\n \n-    target_type = type_of_target(y, input_name=input_name)\n+    target_type = sklearn.utils.multiclass.type_of_target(\n+        y, input_name=input_name\n+    )\n     return _raise_or_return(target_type)\n \n \n@@ -86,7 +50,7 @@ def _routing_enabled():\n \n     TODO: remove when the config key is no longer available in scikit-learn\n     \"\"\"\n-    return get_config().get(\"enable_metadata_routing\", False)\n+    return sklearn.get_config().get(\"enable_metadata_routing\", False)\n \n \n def _raise_for_params(params, owner, method):\n\n@@ -3,6 +3,9 @@\n from contextlib import contextmanager\n \n import pytest\n+import sklearn\n+from packaging.version import parse as parse_version\n+from sklearn.utils.estimator_checks import parametrize_with_checks\n \n import keras\n from keras.src.backend import floatx\n@@ -13,7 +16,45 @@ from keras.src.models import Model\n from keras.src.wrappers import SKLearnClassifier\n from keras.src.wrappers import SKLearnRegressor\n from keras.src.wrappers import SKLearnTransformer\n-from keras.src.wrappers.fixes import parametrize_with_checks\n+\n+\n+def wrapped_parametrize_with_checks(\n+    estimators,\n+    *,\n+    legacy: bool = True,\n+    expected_failed_checks=None,\n+):\n+    \"\"\"Wrapped `parametrize_with_checks` handling backwards compat.\"\"\"\n+    sklearn_version = parse_version(\n+        parse_version(sklearn.__version__).base_version\n+    )\n+\n+    if sklearn_version >= parse_version(\"1.6\"):\n+        return parametrize_with_checks(\n+            estimators,\n+            legacy=legacy,\n+            expected_failed_checks=expected_failed_checks,\n+        )\n+\n+    def patched_more_tags(estimator, expected_failed_checks):\n+        import copy\n+\n+        original_tags = copy.deepcopy(sklearn.utils._tags._safe_tags(estimator))\n+\n+        def patched_more_tags(self):\n+            original_tags.update({\"_xfail_checks\": expected_failed_checks})\n+            return original_tags\n+\n+        estimator.__class__._more_tags = patched_more_tags\n+        return estimator\n+\n+    estimators = [\n+        patched_more_tags(estimator, expected_failed_checks(estimator))\n+        for estimator in estimators\n+    ]\n+\n+    # legacy is not supported and ignored\n+    return parametrize_with_checks(estimators)\n \n \n def dynamic_model(X, y, loss, layers=[10]):\n@@ -80,7 +121,7 @@ EXPECTED_FAILED_CHECKS = {\n }\n \n \n-@parametrize_with_checks(\n+@wrapped_parametrize_with_checks(\n     estimators=[\n         SKLearnClassifier(\n             model=dynamic_model,\n\n@@ -1,14 +1,6 @@\n import copy\n \n import numpy as np\n-from sklearn.base import BaseEstimator\n-from sklearn.base import ClassifierMixin\n-from sklearn.base import RegressorMixin\n-from sklearn.base import TransformerMixin\n-from sklearn.base import check_is_fitted\n-from sklearn.pipeline import make_pipeline\n-from sklearn.preprocessing import OneHotEncoder\n-from sklearn.utils.metadata_routing import MetadataRequest\n \n from keras.src.api_export import keras_export\n from keras.src.models.cloning import clone_model\n@@ -18,6 +10,28 @@ from keras.src.wrappers.fixes import _validate_data\n from keras.src.wrappers.fixes import type_of_target\n from keras.src.wrappers.utils import TargetReshaper\n from keras.src.wrappers.utils import _check_model\n+from keras.src.wrappers.utils import assert_sklearn_installed\n+\n+try:\n+    import sklearn\n+    from sklearn.base import BaseEstimator\n+    from sklearn.base import ClassifierMixin\n+    from sklearn.base import RegressorMixin\n+    from sklearn.base import TransformerMixin\n+except ImportError:\n+    sklearn = None\n+\n+    class BaseEstimator:\n+        pass\n+\n+    class ClassifierMixin:\n+        pass\n+\n+    class RegressorMixin:\n+        pass\n+\n+    class TransformerMixin:\n+        pass\n \n \n class SKLBase(BaseEstimator):\n@@ -64,6 +78,7 @@ class SKLBase(BaseEstimator):\n         model_kwargs=None,\n         fit_kwargs=None,\n     ):\n+        assert_sklearn_installed(self.__class__.__name__)\n         self.model = model\n         self.warm_start = warm_start\n         self.model_kwargs = model_kwargs\n@@ -119,7 +134,9 @@ class SKLBase(BaseEstimator):\n                 \"sklearn.set_config(enable_metadata_routing=True).\"\n             )\n \n-        self._metadata_request = MetadataRequest(owner=self.__class__.__name__)\n+        self._metadata_request = sklearn.utils.metadata_routing.MetadataRequest(\n+            owner=self.__class__.__name__\n+        )\n         for param, alias in kwargs.items():\n             self._metadata_request.score.add_request(param=param, alias=alias)\n         return self\n@@ -155,7 +172,7 @@ class SKLBase(BaseEstimator):\n \n     def predict(self, X):\n         \"\"\"Predict using the model.\"\"\"\n-        check_is_fitted(self)\n+        sklearn.base.check_is_fitted(self)\n         X = _validate_data(self, X, reset=False)\n         raw_output = self.model_.predict(X)\n         return self._reverse_process_target(raw_output)\n@@ -267,8 +284,9 @@ class SKLearnClassifier(ClassifierMixin, SKLBase):\n                 f\" Target type: {target_type}\"\n             )\n         if reset:\n-            self._target_encoder = make_pipeline(\n-                TargetReshaper(), OneHotEncoder(sparse_output=False)\n+            self._target_encoder = sklearn.pipeline.make_pipeline(\n+                TargetReshaper(),\n+                sklearn.preprocessing.OneHotEncoder(sparse_output=False),\n             ).fit(y)\n             self.classes_ = np.unique(y)\n             if len(self.classes_) == 1:\n@@ -454,7 +472,7 @@ class SKLearnTransformer(TransformerMixin, SKLBase):\n             X_transformed: array-like, shape=(n_samples, n_features)\n                 The transformed data.\n         \"\"\"\n-        check_is_fitted(self)\n+        sklearn.base.check_is_fitted(self)\n         X = _validate_data(self, X, reset=False)\n         return self.model_.predict(X)\n \n\n@@ -1,7 +1,23 @@\n+try:\n+    import sklearn\n     from sklearn.base import BaseEstimator\n     from sklearn.base import TransformerMixin\n-from sklearn.base import check_is_fitted\n-from sklearn.utils._array_api import get_namespace\n+except ImportError:\n+    sklearn = None\n+\n+    class BaseEstimator:\n+        pass\n+\n+    class TransformerMixin:\n+        pass\n+\n+\n+def assert_sklearn_installed(symbol_name):\n+    if sklearn is None:\n+        raise ImportError(\n+            f\"{symbol_name} requires `scikit-learn` to be installed. \"\n+            \"Run `pip install scikit-learn` to install it.\"\n+        )\n \n \n def _check_model(model):\n@@ -64,8 +80,8 @@ class TargetReshaper(TransformerMixin, BaseEstimator):\n                 is passed, it will be squeezed back to 1D. Otherwise, it\n                 will eb left untouched.\n         \"\"\"\n-        check_is_fitted(self)\n-        xp, _ = get_namespace(y)\n+        sklearn.base.check_is_fitted(self)\n+        xp, _ = sklearn.utils._array_api.get_namespace(y)\n         if self.ndim_ == 1 and y.ndim == 2:\n             return xp.squeeze(y, axis=1)\n         return y\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4c7c4b5d28a2964e78104f4a9ad45882e6f593c0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 158 | Lines Deleted: 22 | Files Changed: 4 | Hunks: 33 | Methods Changed: 14 | Complexity Δ (Sum/Max): 17/9 | Churn Δ: 180 | Churn Cumulative: 785 | Contributors (this commit): 5 | Commits (past 90d): 17 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3,6 +3,7 @@ from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing\n     BaseImagePreprocessingLayer,\n )\n from keras.src.random import SeedGenerator\n+from keras.src.utils import backend_utils\n \n \n @keras_export(\"keras.layers.MixUp\")\n@@ -66,36 +67,40 @@ class MixUp(BaseImagePreprocessingLayer):\n         }\n \n     def transform_images(self, images, transformation=None, training=True):\n+        def _mix_up_input(images, transformation):\n             images = self.backend.cast(images, self.compute_dtype)\n             mix_weight = transformation[\"mix_weight\"]\n             permutation_order = transformation[\"permutation_order\"]\n-\n             mix_weight = self.backend.cast(\n                 self.backend.numpy.reshape(mix_weight, [-1, 1, 1, 1]),\n                 dtype=self.compute_dtype,\n             )\n-\n             mix_up_images = self.backend.cast(\n                 self.backend.numpy.take(images, permutation_order, axis=0),\n                 dtype=self.compute_dtype,\n             )\n-\n             images = mix_weight * images + (1.0 - mix_weight) * mix_up_images\n+            return images\n \n+        if training:\n+            images = _mix_up_input(images, transformation)\n         return images\n \n     def transform_labels(self, labels, transformation, training=True):\n+        def _mix_up_labels(labels, transformation):\n             mix_weight = transformation[\"mix_weight\"]\n             permutation_order = transformation[\"permutation_order\"]\n-\n             labels_for_mix_up = self.backend.numpy.take(\n                 labels, permutation_order, axis=0\n             )\n-\n             mix_weight = self.backend.numpy.reshape(mix_weight, [-1, 1])\n+            labels = (\n+                mix_weight * labels + (1.0 - mix_weight) * labels_for_mix_up\n+            )\n+            return labels\n \n-        labels = mix_weight * labels + (1.0 - mix_weight) * labels_for_mix_up\n-\n+        if training:\n+            labels = _mix_up_labels(labels, transformation)\n         return labels\n \n     def transform_bounding_boxes(\n@@ -104,33 +109,58 @@ class MixUp(BaseImagePreprocessingLayer):\n         transformation,\n         training=True,\n     ):\n+        def _mix_up_bounding_boxes(bounding_boxes, transformation):\n+            if backend_utils.in_tf_graph():\n+                self.backend.set_backend(\"tensorflow\")\n+\n             permutation_order = transformation[\"permutation_order\"]\n-        boxes, classes = bounding_boxes[\"boxes\"], bounding_boxes[\"classes\"]\n-        boxes_for_mix_up = self.backend.numpy.take(boxes, permutation_order)\n-        classes_for_mix_up = self.backend.numpy.take(classes, permutation_order)\n-        boxes = self.backend.numpy.concat([boxes, boxes_for_mix_up], axis=1)\n-        classes = self.backend.numpy.concat(\n-            [classes, classes_for_mix_up], axis=1\n+\n+            boxes, labels = bounding_boxes[\"boxes\"], bounding_boxes[\"labels\"]\n+            boxes_for_mix_up = self.backend.numpy.take(\n+                boxes, permutation_order, axis=0\n             )\n-        return {\"boxes\": boxes, \"classes\": classes}\n+\n+            labels_for_mix_up = self.backend.numpy.take(\n+                labels, permutation_order, axis=0\n+            )\n+            boxes = self.backend.numpy.concatenate(\n+                [boxes, boxes_for_mix_up], axis=1\n+            )\n+\n+            labels = self.backend.numpy.concatenate(\n+                [labels, labels_for_mix_up], axis=0\n+            )\n+\n+            self.backend.reset()\n+\n+            return {\"boxes\": boxes, \"labels\": labels}\n+\n+        if training:\n+            bounding_boxes = _mix_up_bounding_boxes(\n+                bounding_boxes, transformation\n+            )\n+        return bounding_boxes\n \n     def transform_segmentation_masks(\n         self, segmentation_masks, transformation, training=True\n     ):\n+        def _mix_up_segmentation_masks(segmentation_masks, transformation):\n             mix_weight = transformation[\"mix_weight\"]\n             permutation_order = transformation[\"permutation_order\"]\n-\n             mix_weight = self.backend.numpy.reshape(mix_weight, [-1, 1, 1, 1])\n-\n             segmentation_masks_for_mix_up = self.backend.numpy.take(\n                 segmentation_masks, permutation_order\n             )\n-\n             segmentation_masks = (\n                 mix_weight * segmentation_masks\n                 + (1.0 - mix_weight) * segmentation_masks_for_mix_up\n             )\n+            return segmentation_masks\n \n+        if training:\n+            segmentation_masks = _mix_up_segmentation_masks(\n+                segmentation_masks, transformation\n+            )\n         return segmentation_masks\n \n     def compute_output_shape(self, input_shape):\n\n@@ -2,8 +2,10 @@ import numpy as np\n import pytest\n from tensorflow import data as tf_data\n \n+from keras.src import backend\n from keras.src import layers\n from keras.src import testing\n+from keras.src.backend import convert_to_tensor\n \n \n class MixUpTest(testing.TestCase):\n@@ -21,6 +23,14 @@ class MixUpTest(testing.TestCase):\n             run_training_check=not testing.tensorflow_uses_gpu(),\n         )\n \n+    def test_mix_up_inference(self):\n+        seed = 3481\n+        layer = layers.MixUp(alpha=0.2)\n+        np.random.seed(seed)\n+        inputs = np.random.randint(0, 255, size=(224, 224, 3))\n+        output = layer(inputs, training=False)\n+        self.assertAllClose(inputs, output)\n+\n     def test_mix_up_basic_functionality(self):\n         image = np.random.random((64, 64, 3))\n         mix_up_layer = layers.MixUp(alpha=1)\n@@ -63,3 +73,85 @@ class MixUpTest(testing.TestCase):\n         ds = tf_data.Dataset.from_tensor_slices(input_data).batch(2).map(layer)\n         for output in ds.take(1):\n             output.numpy()\n+\n+    def test_mix_up_bounding_boxes(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            image_shape = (10, 8, 3)\n+        else:\n+            image_shape = (3, 10, 8)\n+        input_image = np.random.random(image_shape)\n+        bounding_boxes = {\n+            \"boxes\": np.array(\n+                [\n+                    [2, 1, 4, 3],\n+                    [6, 4, 8, 6],\n+                ]\n+            ),\n+            \"labels\": np.array([1, 2]),\n+        }\n+        input_data = {\"images\": input_image, \"bounding_boxes\": bounding_boxes}\n+\n+        expected_boxes = [[2, 1, 4, 3, 6, 4, 8, 6], [6, 4, 8, 6, 2, 1, 4, 3]]\n+\n+        random_flip_layer = layers.MixUp(\n+            data_format=data_format,\n+            seed=42,\n+            bounding_box_format=\"xyxy\",\n+        )\n+\n+        transformation = {\n+            \"mix_weight\": convert_to_tensor([0.5, 0.5]),\n+            \"permutation_order\": convert_to_tensor([1, 0]),\n+        }\n+        output = random_flip_layer.transform_bounding_boxes(\n+            input_data[\"bounding_boxes\"],\n+            transformation=transformation,\n+            training=True,\n+        )\n+        self.assertAllClose(output[\"boxes\"], expected_boxes)\n+\n+    def test_mix_up_tf_data_bounding_boxes(self):\n+        data_format = backend.config.image_data_format()\n+        if data_format == \"channels_last\":\n+            image_shape = (1, 10, 8, 3)\n+        else:\n+            image_shape = (1, 3, 10, 8)\n+        input_image = np.random.random(image_shape)\n+        bounding_boxes = {\n+            \"boxes\": np.array(\n+                [\n+                    [\n+                        [2, 1, 4, 3],\n+                        [6, 4, 8, 6],\n+                    ]\n+                ]\n+            ),\n+            \"labels\": np.array([[1, 2]]),\n+        }\n+\n+        input_data = {\"images\": input_image, \"bounding_boxes\": bounding_boxes}\n+        expected_boxes = [[2, 1, 4, 3, 6, 4, 8, 6], [6, 4, 8, 6, 2, 1, 4, 3]]\n+\n+        ds = tf_data.Dataset.from_tensor_slices(input_data)\n+        layer = layers.MixUp(\n+            data_format=data_format,\n+            seed=42,\n+            bounding_box_format=\"xyxy\",\n+        )\n+\n+        transformation = {\n+            \"mix_weight\": convert_to_tensor([0.5, 0.5]),\n+            \"permutation_order\": convert_to_tensor([1, 0]),\n+        }\n+        ds = ds.map(\n+            lambda x: layer.transform_bounding_boxes(\n+                x[\"bounding_boxes\"],\n+                transformation=transformation,\n+                training=True,\n+            )\n+        )\n+\n+        output = next(iter(ds))\n+        expected_boxes = np.array(expected_boxes)\n+        self.assertAllClose(output[\"boxes\"], expected_boxes)\n\n@@ -87,17 +87,18 @@ class RandomHue(BaseImagePreprocessingLayer):\n         return {\"factor\": invert * factor * 0.5}\n \n     def transform_images(self, images, transformation=None, training=True):\n+        def _apply_random_hue(images, transformation):\n             images = self.backend.cast(images, self.compute_dtype)\n-        images = self._transform_value_range(images, self.value_range, (0, 1))\n+            images = self._transform_value_range(\n+                images, self.value_range, (0, 1)\n+            )\n             adjust_factors = transformation[\"factor\"]\n             adjust_factors = self.backend.cast(adjust_factors, images.dtype)\n             adjust_factors = self.backend.numpy.expand_dims(adjust_factors, -1)\n             adjust_factors = self.backend.numpy.expand_dims(adjust_factors, -1)\n-\n             images = self.backend.image.rgb_to_hsv(\n                 images, data_format=self.data_format\n             )\n-\n             if self.data_format == \"channels_first\":\n                 h_channel = images[:, 0, :, :] + adjust_factors\n                 h_channel = self.backend.numpy.where(\n@@ -123,12 +124,17 @@ class RandomHue(BaseImagePreprocessingLayer):\n             images = self.backend.image.hsv_to_rgb(\n                 images, data_format=self.data_format\n             )\n-\n             images = self.backend.numpy.clip(images, 0, 1)\n-        images = self._transform_value_range(images, (0, 1), self.value_range)\n+            images = self._transform_value_range(\n+                images, (0, 1), self.value_range\n+            )\n             images = self.backend.cast(images, self.compute_dtype)\n             return images\n \n+        if training:\n+            images = _apply_random_hue(images, transformation)\n+        return images\n+\n     def transform_labels(self, labels, transformation, training=True):\n         return labels\n \n\n@@ -23,6 +23,14 @@ class RandomHueTest(testing.TestCase):\n             expected_output_shape=(8, 3, 4, 3),\n         )\n \n+    def test_random_hue_inference(self):\n+        seed = 3481\n+        layer = layers.RandomHue(0.2, [0, 1.0])\n+        np.random.seed(seed)\n+        inputs = np.random.randint(0, 255, size=(224, 224, 3))\n+        output = layer(inputs, training=False)\n+        self.assertAllClose(inputs, output)\n+\n     def test_random_hue_value_range(self):\n         image = keras.random.uniform(shape=(3, 3, 3), minval=0, maxval=1)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#72ca0a0c05cae0ebfeb57aec79a1da5f8f84b17f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 27 | Churn Cumulative: 65 | Contributors (this commit): 4 | Commits (past 90d): 1 | Contributors (cumulative): 4 | DMM Complexity: 0.25\n\nDIFF:\n@@ -131,6 +131,9 @@ class GRUCell(Layer, DropoutRNNCell):\n \n         self.dropout = min(1.0, max(0.0, dropout))\n         self.recurrent_dropout = min(1.0, max(0.0, recurrent_dropout))\n+        if self.recurrent_dropout != 0.0:\n+            self.implementation = 1\n+        self.dropout_mask_count = 3\n         self.seed = seed\n         self.seed_generator = backend.random.SeedGenerator(seed=seed)\n \n@@ -181,9 +184,6 @@ class GRUCell(Layer, DropoutRNNCell):\n             states[0] if tree.is_nested(states) else states\n         )  # previous state\n \n-        dp_mask = self.get_dropout_mask(inputs)\n-        rec_dp_mask = self.get_recurrent_dropout_mask(h_tm1)\n-\n         if self.use_bias:\n             if not self.reset_after:\n                 input_bias, recurrent_bias = self.bias, None\n@@ -193,12 +193,13 @@ class GRUCell(Layer, DropoutRNNCell):\n                     for e in ops.split(self.bias, self.bias.shape[0], axis=0)\n                 )\n \n-        if training and 0.0 < self.dropout < 1.0:\n-            inputs = inputs * dp_mask\n-        if training and 0.0 < self.recurrent_dropout < 1.0:\n-            h_tm1 = h_tm1 * rec_dp_mask\n-\n         if self.implementation == 1:\n+            if training and 0.0 < self.dropout < 1.0:\n+                dp_mask = self.get_dropout_mask(inputs)\n+                inputs_z = inputs * dp_mask[0]\n+                inputs_r = inputs * dp_mask[1]\n+                inputs_h = inputs * dp_mask[2]\n+            else:\n                 inputs_z = inputs\n                 inputs_r = inputs\n                 inputs_h = inputs\n@@ -214,6 +215,12 @@ class GRUCell(Layer, DropoutRNNCell):\n                 x_r += input_bias[self.units : self.units * 2]\n                 x_h += input_bias[self.units * 2 :]\n \n+            if training and 0.0 < self.recurrent_dropout < 1.0:\n+                rec_dp_mask = self.get_recurrent_dropout_mask(h_tm1)\n+                h_tm1_z = h_tm1 * rec_dp_mask[0]\n+                h_tm1_r = h_tm1 * rec_dp_mask[1]\n+                h_tm1_h = h_tm1 * rec_dp_mask[2]\n+            else:\n                 h_tm1_z = h_tm1\n                 h_tm1_r = h_tm1\n                 h_tm1_h = h_tm1\n@@ -246,6 +253,10 @@ class GRUCell(Layer, DropoutRNNCell):\n \n             hh = self.activation(x_h + recurrent_h)\n         else:\n+            if training and 0.0 < self.dropout < 1.0:\n+                dp_mask = self.get_dropout_mask(inputs)\n+                inputs = inputs * dp_mask[0]\n+\n             # inputs projected by all gate matrices at once\n             matrix_x = ops.matmul(inputs, self.kernel)\n             if self.use_bias:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#eb8d13c5b37289f59eb328adbe48467b8ee67fc2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 12 | Files Changed: 1 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 30 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -69,9 +69,7 @@ class Poisson(reduction_metrics.MeanMetricWrapper):\n         name: (Optional) string name of the metric instance.\n         dtype: (Optional) data type of the metric result.\n \n-    Example:\n-\n-    Example:\n+    Examples:\n \n     >>> m = keras.metrics.Poisson()\n     >>> m.update_state([[0, 1], [0, 0]], [[1, 1], [0, 0]])\n@@ -119,9 +117,7 @@ class BinaryCrossentropy(reduction_metrics.MeanMetricWrapper):\n             e.g. `label_smoothing=0.2` means that we will use\n             a value of 0.1 for label \"0\" and 0.9 for label \"1\".\n \n-    Example:\n-\n-    Example:\n+    Examples:\n \n     >>> m = keras.metrics.BinaryCrossentropy()\n     >>> m.update_state([[0, 1], [0, 0]], [[0.6, 0.4], [0.4, 0.6]])\n@@ -195,9 +191,7 @@ class CategoricalCrossentropy(reduction_metrics.MeanMetricWrapper):\n         axis: (Optional) Defaults to `-1`.\n             The dimension along which entropy is computed.\n \n-    Example:\n-\n-    Example:\n+    Examples:\n \n     >>> # EPSILON = 1e-7, y = y_true, y` = y_pred\n     >>> # y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON)\n@@ -282,9 +276,7 @@ class SparseCategoricalCrossentropy(reduction_metrics.MeanMetricWrapper):\n         axis: (Optional) Defaults to `-1`.\n             The dimension along which entropy is computed.\n \n-    Example:\n-\n-    Example:\n+    Examples:\n \n     >>> # y_true = one_hot(y_true) = [[0, 1, 0], [0, 0, 1]]\n     >>> # logits = log(y_pred)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a62e0ef0c8d940e091b399bc0c05176d2a508735", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 45 | Lines Deleted: 10 | Files Changed: 4 | Hunks: 11 | Methods Changed: 6 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 55 | Churn Cumulative: 197 | Contributors (this commit): 4 | Commits (past 90d): 5 | Contributors (cumulative): 14 | DMM Complexity: 0.6944444444444444\n\nDIFF:\n@@ -133,6 +133,7 @@ class GRUCell(Layer, DropoutRNNCell):\n         self.recurrent_dropout = min(1.0, max(0.0, recurrent_dropout))\n         if self.recurrent_dropout != 0.0:\n             self.implementation = 1\n+        if self.implementation == 1:\n             self.dropout_mask_count = 3\n         self.seed = seed\n         self.seed_generator = backend.random.SeedGenerator(seed=seed)\n@@ -255,7 +256,7 @@ class GRUCell(Layer, DropoutRNNCell):\n         else:\n             if training and 0.0 < self.dropout < 1.0:\n                 dp_mask = self.get_dropout_mask(inputs)\n-                inputs = inputs * dp_mask[0]\n+                inputs = inputs * dp_mask\n \n             # inputs projected by all gate matrices at once\n             matrix_x = ops.matmul(inputs, self.kernel)\n\n@@ -10,6 +10,16 @@ from keras.src import testing\n class GRUTest(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_basics(self):\n+        self.run_layer_test(\n+            layers.GRU,\n+            init_kwargs={\"units\": 3, \"dropout\": 0.5},\n+            input_shape=(3, 2, 4),\n+            call_kwargs={\"training\": True},\n+            expected_output_shape=(3, 3),\n+            expected_num_trainable_weights=3,\n+            expected_num_non_trainable_weights=0,\n+            supports_masking=True,\n+        )\n         self.run_layer_test(\n             layers.GRU,\n             init_kwargs={\"units\": 3, \"dropout\": 0.5, \"recurrent_dropout\": 0.5},\n\n@@ -113,6 +113,7 @@ class LSTMCell(Layer, DropoutRNNCell):\n             )\n         implementation = kwargs.pop(\"implementation\", 2)\n         super().__init__(**kwargs)\n+        self.implementation = implementation\n         self.units = units\n         self.activation = activations.get(activation)\n         self.recurrent_activation = activations.get(recurrent_activation)\n@@ -132,13 +133,16 @@ class LSTMCell(Layer, DropoutRNNCell):\n \n         self.dropout = min(1.0, max(0.0, dropout))\n         self.recurrent_dropout = min(1.0, max(0.0, recurrent_dropout))\n+        if self.recurrent_dropout != 0.0:\n+            self.implementation = 1\n+        if self.implementation == 1:\n+            self.dropout_mask_count = 4\n         self.seed = seed\n         self.seed_generator = backend.random.SeedGenerator(seed=seed)\n \n         self.unit_forget_bias = unit_forget_bias\n         self.state_size = [self.units, self.units]\n         self.output_size = self.units\n-        self.implementation = implementation\n \n     def build(self, input_shape):\n         super().build(input_shape)\n@@ -228,15 +232,14 @@ class LSTMCell(Layer, DropoutRNNCell):\n         h_tm1 = states[0]  # previous memory state\n         c_tm1 = states[1]  # previous carry state\n \n-        dp_mask = self.get_dropout_mask(inputs)\n-        rec_dp_mask = self.get_recurrent_dropout_mask(h_tm1)\n-\n-        if training and 0.0 < self.dropout < 1.0:\n-            inputs = inputs * dp_mask\n-        if training and 0.0 < self.recurrent_dropout < 1.0:\n-            h_tm1 = h_tm1 * rec_dp_mask\n-\n         if self.implementation == 1:\n+            if training and 0.0 < self.dropout < 1.0:\n+                dp_mask = self.get_dropout_mask(inputs)\n+                inputs_i = inputs * dp_mask[0]\n+                inputs_f = inputs * dp_mask[1]\n+                inputs_c = inputs * dp_mask[2]\n+                inputs_o = inputs * dp_mask[3]\n+            else:\n                 inputs_i = inputs\n                 inputs_f = inputs\n                 inputs_c = inputs\n@@ -253,6 +256,13 @@ class LSTMCell(Layer, DropoutRNNCell):\n                 x_c += b_c\n                 x_o += b_o\n \n+            if training and 0.0 < self.recurrent_dropout < 1.0:\n+                rec_dp_mask = self.get_recurrent_dropout_mask(h_tm1)\n+                h_tm1_i = h_tm1 * rec_dp_mask[0]\n+                h_tm1_f = h_tm1 * rec_dp_mask[1]\n+                h_tm1_c = h_tm1 * rec_dp_mask[2]\n+                h_tm1_o = h_tm1 * rec_dp_mask[3]\n+            else:\n                 h_tm1_i = h_tm1\n                 h_tm1_f = h_tm1\n                 h_tm1_c = h_tm1\n@@ -261,6 +271,10 @@ class LSTMCell(Layer, DropoutRNNCell):\n             h_tm1 = (h_tm1_i, h_tm1_f, h_tm1_c, h_tm1_o)\n             c, o = self._compute_carry_and_output(x, h_tm1, c_tm1)\n         else:\n+            if training and 0.0 < self.dropout < 1.0:\n+                dp_mask = self.get_dropout_mask(inputs)\n+                inputs = inputs * dp_mask\n+\n             z = ops.matmul(inputs, self.kernel)\n \n             z += ops.matmul(h_tm1, self.recurrent_kernel)\n\n@@ -10,6 +10,16 @@ from keras.src import testing\n class LSTMTest(testing.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_basics(self):\n+        self.run_layer_test(\n+            layers.LSTM,\n+            init_kwargs={\"units\": 3, \"dropout\": 0.5},\n+            input_shape=(3, 2, 4),\n+            call_kwargs={\"training\": True},\n+            expected_output_shape=(3, 3),\n+            expected_num_trainable_weights=3,\n+            expected_num_non_trainable_weights=0,\n+            supports_masking=True,\n+        )\n         self.run_layer_test(\n             layers.LSTM,\n             init_kwargs={\"units\": 3, \"dropout\": 0.5, \"recurrent_dropout\": 0.5},\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e3cf0432c41caa63b605e103908c90cdd0193659", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 284 | Contributors (this commit): 7 | Commits (past 90d): 4 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -275,7 +275,7 @@ class ExportSavedModelTest(testing.TestCase):\n             is_static=(True, False),\n             jax2tf_kwargs=(\n                 None,\n-                {\"enable_xla\": False, \"native_serialization\": False},\n+                {\"enable_xla\": True, \"native_serialization\": True},\n             ),\n         )\n     )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9a3e173ddea5dd37724b76f5671f28f8dd2d609d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 282 | Contributors (this commit): 6 | Commits (past 90d): 6 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -240,12 +240,11 @@ class PyDatasetAdapterTest(testing.TestCase):\n         for index, batch in enumerate(gen):\n             # Batch is a tuple of (x, y, class_weight)\n             self.assertLen(batch, 3)\n+            batch = [backend.convert_to_numpy(x) for x in batch]\n             # Let's verify the data and class weights match for each element\n             # of the batch (2 elements in each batch)\n             for sub_elem in range(2):\n-                self.assertTrue(\n-                    np.array_equal(batch[0][sub_elem], x[index * 2 + sub_elem])\n-                )\n+                self.assertAllEqual(batch[0][sub_elem], x[index * 2 + sub_elem])\n                 self.assertEqual(batch[1][sub_elem], y[index * 2 + sub_elem])\n                 class_key = np.int32(batch[1][sub_elem])\n                 self.assertEqual(batch[2][sub_elem], class_w[class_key])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#84b531c5c37ef5e6fc51a96383f5b15900fd69cc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 262 | Contributors (this commit): 4 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,3 +1,4 @@\n+from keras.src import ops\n from keras.src.api_export import keras_export\n from keras.src.layers.preprocessing.image_preprocessing.base_image_preprocessing_layer import (  # noqa: E501\n     BaseImagePreprocessingLayer,\n@@ -114,6 +115,8 @@ class MixUp(BaseImagePreprocessingLayer):\n                 self.backend.set_backend(\"tensorflow\")\n \n             permutation_order = transformation[\"permutation_order\"]\n+            # Make sure we are on cpu for torch tensors.\n+            permutation_order = ops.convert_to_numpy(permutation_order)\n \n             boxes, labels = bounding_boxes[\"boxes\"], bounding_boxes[\"labels\"]\n             boxes_for_mix_up = self.backend.numpy.take(\n@@ -146,6 +149,8 @@ class MixUp(BaseImagePreprocessingLayer):\n     ):\n         def _mix_up_segmentation_masks(segmentation_masks, transformation):\n             mix_weight = transformation[\"mix_weight\"]\n+            # Make sure we are on cpu for torch tensors.\n+            mix_weight = ops.convert_to_numpy(mix_weight)\n             permutation_order = transformation[\"permutation_order\"]\n             mix_weight = self.backend.numpy.reshape(mix_weight, [-1, 1, 1, 1])\n             segmentation_masks_for_mix_up = self.backend.numpy.take(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
