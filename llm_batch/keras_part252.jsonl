{"custom_id": "keras#4e829712a2c6153d4cb0c34507fa3f5a7814a2a9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 8 | Methods Changed: 5 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 24 | Churn Cumulative: 1645 | Contributors (this commit): 25 | Commits (past 90d): 9 | Contributors (cumulative): 25 | DMM Complexity: 1.0\n\nDIFF:\n@@ -67,6 +67,7 @@ import inspect\n import os\n import shutil\n \n+import keras\n from keras import utils\n from keras import layers\n from keras.layers import advanced_activations\n@@ -377,7 +378,7 @@ def get_function_signature(function, method=True):\n         args = args[:-len(defaults)]\n     else:\n         kwargs = []\n-    st = '%s.%s(' % (function.__module__, function.__name__)\n+    st = '%s.%s(' % (clean_module_name(function.__module__), function.__name__)\n \n     for a in args:\n         st += str(a) + ', '\n@@ -392,7 +393,7 @@ def get_function_signature(function, method=True):\n \n     if not method:\n         # Prepend the module name.\n-        signature = function.__module__ + '.' + signature\n+        signature = clean_module_name(function.__module__) + '.' + signature\n     return post_process_signature(signature)\n \n \n@@ -403,7 +404,7 @@ def get_class_signature(cls):\n     except (TypeError, AttributeError):\n         # in case the class inherits from object and does not\n         # define __init__\n-        class_signature = cls.__module__ + '.' + cls.__name__ + '()'\n+        class_signature = clean_module_name(cls.__module__) + '.' + cls.__name__ + '()'\n     return post_process_signature(class_signature)\n \n \n@@ -419,17 +420,24 @@ def post_process_signature(signature):\n     return signature\n \n \n+def clean_module_name(name):\n+    if name.startswith('keras_applications'):\n+        name = name.replace('keras_applications', 'keras.applications')\n+    if name.startswith('keras_preprocessing'):\n+        name = name.replace('keras_preprocessing', 'keras.preprocessing')\n+    assert name[:6] == 'keras.', 'Invalid module name: %s' % name\n+    return name\n+\n+\n def class_to_docs_link(cls):\n-    module_name = cls.__module__\n-    assert module_name[:6] == 'keras.'\n+    module_name = clean_module_name(cls.__module__)\n     module_name = module_name[6:]\n     link = ROOT + module_name.replace('.', '/') + '#' + cls.__name__.lower()\n     return link\n \n \n def class_to_source_link(cls):\n-    module_name = cls.__module__\n-    assert module_name[:6] == 'keras.'\n+    module_name = clean_module_name(cls.__module__)\n     path = module_name.replace('.', '/')\n     path += '.py'\n     line = inspect.getsourcelines(cls)[-1]\n@@ -620,7 +628,7 @@ if __name__ == '__main__':\n     with open('sources/index.md', 'w') as f:\n         f.write(index)\n \n-    print('Starting autogeneration.')\n+    print('Generating docs for Keras %s.' % keras.__version__)\n     for page_data in PAGES:\n         blocks = []\n         classes = page_data.get('classes', [])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#67e242d926b577f440217d9d10b890f54bb875c3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 1650 | Contributors (this commit): 26 | Commits (past 90d): 10 | Contributors (cumulative): 26 | DMM Complexity: None\n\nDIFF:\n@@ -158,6 +158,9 @@ PAGES = [\n             layers.Lambda,\n             layers.ActivityRegularization,\n             layers.Masking,\n+            layers.SpatialDropout1D,\n+            layers.SpatialDropout2D,\n+            layers.SpatialDropout3D,\n         ],\n     },\n     {\n@@ -193,6 +196,8 @@ PAGES = [\n             layers.GlobalAveragePooling1D,\n             layers.GlobalMaxPooling2D,\n             layers.GlobalAveragePooling2D,\n+            layers.GlobalMaxPooling3D,\n+            layers.GlobalAveragePooling3D,\n         ],\n     },\n     {\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3eab6103e0069d261c3e3586c12d5aaf0a331429", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 27 | Churn Cumulative: 3997 | Contributors (this commit): 12 | Commits (past 90d): 7 | Contributors (cumulative): 13 | DMM Complexity: 0.1\n\nDIFF:\n@@ -226,6 +226,8 @@ class Sequential(Model):\n             for layer in self._layers:\n                 x = layer(x)\n             self.outputs = [x]\n+            if self._layers:\n+                self._layers[0].batch_input_shape = batch_shape\n \n         if self.inputs:\n             self._init_graph_network(self.inputs,\n\n@@ -397,5 +397,30 @@ def test_sequential_update_disabling():\n     assert np.abs(np.sum(x1 - x2)) > 1e-5\n \n \n+@keras_test\n+def test_sequential_deferred_build():\n+    model = keras.models.Sequential()\n+    model.add(keras.layers.Dense(3))\n+    model.add(keras.layers.Dense(3))\n+    model.compile('sgd', 'mse')\n+\n+    assert model.built is False\n+    assert len(model.layers) == 2\n+    assert len(model.weights) == 0\n+\n+    model.train_on_batch(\n+        np.random.random((2, 4)), np.random.random((2, 3)))\n+\n+    assert model.built is True\n+    assert len(model.layers) == 2\n+    assert len(model.weights) == 4\n+\n+    config = model.get_config()\n+    new_model = keras.models.Sequential.from_config(config)\n+    assert new_model.built is True\n+    assert len(new_model.layers) == 2\n+    assert len(new_model.weights) == 4\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#29a22a8d59b5e2c4282f1e7f664d82595049eb9d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 43 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 9 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 46 | Churn Cumulative: 1742 | Contributors (this commit): 20 | Commits (past 90d): 5 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -83,11 +83,21 @@ else:\n         featurewise_std_normalization=False,  # divide inputs by std of the dataset\n         samplewise_std_normalization=False,  # divide each input by its std\n         zca_whitening=False,  # apply ZCA whitening\n+        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n         rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n         width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n         height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n+        shear_range=0.,  # set range for random shear\n+        zoom_range=0.,  # set range for random zoom\n+        channel_shift_range=0.,  # set range for random channel shifts\n+        fill_mode='nearest',  # set mode for filling points outside the input boundaries\n+        cval=0.,  # value used for fill_mode = \"constant\"\n         horizontal_flip=True,  # randomly flip images\n-        vertical_flip=False)  # randomly flip images\n+        vertical_flip=False,  # randomly flip images\n+        rescale=None,  # set rescaling factor (applied before any other transformation)\n+        preprocessing_function=None,  # set function that will be applied on each input\n+        data_format=None,  # image data format, either \"channels_first\" or \"channels_last\"\n+        validation_split=0.0)  # fraction of images reserved for validation (strictly between 0 and 1)\n \n     # Compute quantities required for feature-wise normalization\n     # (std, mean, and principal components if ZCA whitening is applied).\n\n@@ -204,11 +204,21 @@ else:\n         featurewise_std_normalization=False,  # divide inputs by dataset std\n         samplewise_std_normalization=False,  # divide each input by its std\n         zca_whitening=False,  # apply ZCA whitening\n+        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n         rotation_range=0,  # randomly rotate images in 0 to 180 degrees\n         width_shift_range=0.1,  # randomly shift images horizontally\n         height_shift_range=0.1,  # randomly shift images vertically\n+        shear_range=0.,  # set range for random shear\n+        zoom_range=0.,  # set range for random zoom\n+        channel_shift_range=0.,  # set range for random channel shifts\n+        fill_mode='nearest',  # set mode for filling points outside the input boundaries\n+        cval=0.,  # value used for fill_mode = \"constant\"\n         horizontal_flip=True,  # randomly flip images\n-        vertical_flip=False)  # randomly flip images\n+        vertical_flip=False,  # randomly flip images\n+        rescale=None,  # set rescaling factor (applied before any other transformation)\n+        preprocessing_function=None,  # set function that will be applied on each input\n+        data_format=None,  # image data format, either \"channels_first\" or \"channels_last\"\n+        validation_split=0.0)  # fraction of images reserved for validation (strictly between 0 and 1)\n \n     # Compute quantities required for feature-wise normalization\n     # (std, mean, and principal components if ZCA whitening is applied).\n\n@@ -384,16 +384,36 @@ else:\n         samplewise_std_normalization=False,\n         # apply ZCA whitening\n         zca_whitening=False,\n+        # epsilon for ZCA whitening\n+        zca_epsilon=1e-06,\n         # randomly rotate images in the range (deg 0 to 180)\n         rotation_range=0,\n         # randomly shift images horizontally\n         width_shift_range=0.1,\n         # randomly shift images vertically\n         height_shift_range=0.1,\n+        # set range for random shear\n+        shear_range=0.,\n+        # set range for random zoom\n+        zoom_range=0.,\n+        # set range for random channel shifts\n+        channel_shift_range=0.,\n+        # set mode for filling points outside the input boundaries\n+        fill_mode='nearest',\n+        # value used for fill_mode = \"constant\"\n+        cval=0.,\n         # randomly flip images\n         horizontal_flip=True,\n         # randomly flip images\n-        vertical_flip=False)\n+        vertical_flip=False,\n+        # set rescaling factor (applied before any other transformation)\n+        rescale=None,\n+        # set function that will be applied on each input\n+        preprocessing_function=None,\n+        # image data format, either \"channels_first\" or \"channels_last\"\n+        data_format=None,\n+        # fraction of images reserved for validation (strictly between 0 and 1)\n+        validation_split=0.0)\n \n     # Compute quantities required for featurewise normalization\n     # (std, mean, and principal components if ZCA whitening is applied).\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a40f33556caef1ab0a3f75758f194728c804dcd3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 6 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 22 | Churn Cumulative: 2254 | Contributors (this commit): 31 | Commits (past 90d): 2 | Contributors (cumulative): 31 | DMM Complexity: None\n\nDIFF:\n@@ -276,11 +276,16 @@ class RMSprop(Optimizer):\n class Adagrad(Optimizer):\n     \"\"\"Adagrad optimizer.\n \n+    Adagrad is an optimizer with parameter-specific learning rates,\n+    which are adapted relative to how frequently a parameter gets\n+    updated during training. The more updates a parameter receives,\n+    the smaller the updates.\n+\n     It is recommended to leave the parameters of this optimizer\n     at their default values.\n \n     # Arguments\n-        lr: float >= 0. Learning rate.\n+        lr: float >= 0. Initial learning rate.\n         epsilon: float >= 0. If `None`, defaults to `K.epsilon()`.\n         decay: float >= 0. Learning rate decay over each update.\n \n@@ -335,15 +340,24 @@ class Adagrad(Optimizer):\n class Adadelta(Optimizer):\n     \"\"\"Adadelta optimizer.\n \n+    Adadelta is a more robust extension of Adagrad\n+    that adapts learning rates based on a moving window of gradient updates,\n+    instead of accumulating all past gradients. This way, Adadelta continues\n+    learning even when many updates have been done. Compared to Adagrad, in the\n+    original version of Adadelta you don't have to set an initial learning\n+    rate. In this version, initial learning rate and decay factor can\n+    be set, as in most other Keras optimizers.\n+\n     It is recommended to leave the parameters of this optimizer\n     at their default values.\n \n     # Arguments\n-        lr: float >= 0. Learning rate.\n+        lr: float >= 0. Initial learning rate, defaults to 1.\n             It is recommended to leave it at the default value.\n-        rho: float >= 0.\n+        rho: float >= 0. Adadelta decay factor, corresponding to fraction of\n+            gradient to keep at each time step.\n         epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n-        decay: float >= 0. Learning rate decay over each update.\n+        decay: float >= 0. Initial learning rate decay.\n \n     # References\n         - [Adadelta - an adaptive learning rate method](http://arxiv.org/abs/1212.5701)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8e5b8533ea819d0252d08f45648782ecd543ac70", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 45 | Lines Deleted: 43 | Files Changed: 3 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/9 | Churn Δ: 88 | Churn Cumulative: 3368 | Contributors (this commit): 26 | Commits (past 90d): 8 | Contributors (cumulative): 31 | DMM Complexity: None\n\nDIFF:\n@@ -19,6 +19,7 @@ from .input_layer import InputLayer\n from .. import backend as K\n from ..utils.io_utils import ask_to_proceed_with_overwrite\n from ..utils.layer_utils import print_summary as print_layer_summary\n+from ..utils.layer_utils import get_source_inputs\n from ..utils.generic_utils import has_arg\n from ..utils.generic_utils import to_list\n from ..utils.generic_utils import object_list_uid\n@@ -1270,49 +1271,6 @@ class Network(Layer):\n                                    print_fn=print_fn)\n \n \n-def get_source_inputs(tensor, layer=None, node_index=None):\n-    \"\"\"Returns the list of input tensors necessary to compute `tensor`.\n-\n-    Output will always be a list of tensors\n-    (potentially with 1 element).\n-\n-    # Arguments\n-        tensor: The tensor to start from.\n-        layer: Origin layer of the tensor. Will be\n-            determined via tensor._keras_history if not provided.\n-        node_index: Origin node index of the tensor.\n-\n-    # Returns\n-        List of input tensors.\n-    \"\"\"\n-    if not hasattr(tensor, '_keras_history'):\n-        return tensor\n-\n-    if layer is None or node_index:\n-        layer, node_index, _ = tensor._keras_history\n-    if not layer._inbound_nodes:\n-        return [tensor]\n-    else:\n-        node = layer._inbound_nodes[node_index]\n-        if not node.inbound_layers:\n-            # Reached an Input layer, stop recursion.\n-            return node.input_tensors\n-        else:\n-            source_tensors = []\n-            for i in range(len(node.inbound_layers)):\n-                x = node.input_tensors[i]\n-                layer = node.inbound_layers[i]\n-                node_index = node.node_indices[i]\n-                previous_sources = get_source_inputs(x,\n-                                                     layer,\n-                                                     node_index)\n-                # Avoid input redundancy.\n-                for x in previous_sources:\n-                    if x not in source_tensors:\n-                        source_tensors.append(x)\n-            return source_tensors\n-\n-\n def _make_node_key(layer_name, node_index):\n     return layer_name + '_ib-' + str(node_index)\n \n\n@@ -18,6 +18,7 @@ from .generic_utils import serialize_keras_object\n from .generic_utils import deserialize_keras_object\n from .generic_utils import Progbar\n from .layer_utils import convert_all_kernels_in_model\n+from .layer_utils import get_source_inputs\n from .layer_utils import print_summary\n from .vis_utils import plot_model\n from .np_utils import to_categorical\n\n@@ -246,3 +246,46 @@ def convert_dense_weights_data_format(dense,\n             ki = np.transpose(ki, (1, 2, 0))  # first -> last\n         kernel[:, i] = np.reshape(ki, (np.prod(previous_feature_map_shape),))\n     dense.set_weights([kernel, bias])\n+\n+\n+def get_source_inputs(tensor, layer=None, node_index=None):\n+    \"\"\"Returns the list of input tensors necessary to compute `tensor`.\n+\n+    Output will always be a list of tensors\n+    (potentially with 1 element).\n+\n+    # Arguments\n+        tensor: The tensor to start from.\n+        layer: Origin layer of the tensor. Will be\n+            determined via tensor._keras_history if not provided.\n+        node_index: Origin node index of the tensor.\n+\n+    # Returns\n+        List of input tensors.\n+    \"\"\"\n+    if not hasattr(tensor, '_keras_history'):\n+        return tensor\n+\n+    if layer is None or node_index:\n+        layer, node_index, _ = tensor._keras_history\n+    if not layer._inbound_nodes:\n+        return [tensor]\n+    else:\n+        node = layer._inbound_nodes[node_index]\n+        if not node.inbound_layers:\n+            # Reached an Input layer, stop recursion.\n+            return node.input_tensors\n+        else:\n+            source_tensors = []\n+            for i in range(len(node.inbound_layers)):\n+                x = node.input_tensors[i]\n+                layer = node.inbound_layers[i]\n+                node_index = node.node_indices[i]\n+                previous_sources = get_source_inputs(x,\n+                                                     layer,\n+                                                     node_index)\n+                # Avoid input redundancy.\n+                for x in previous_sources:\n+                    if x not in source_tensors:\n+                        source_tensors.append(x)\n+            return source_tensors\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a68c516e731faba8efa884603bb06d17ad494d69", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/2 | Churn Δ: 13 | Churn Cumulative: 7507 | Contributors (this commit): 37 | Commits (past 90d): 26 | Contributors (cumulative): 47 | DMM Complexity: None\n\nDIFF:\n@@ -109,11 +109,12 @@ def in_test_phase(x, alt, training=None):\n \n \n def _convert_string_dtype(dtype):\n-    # cntk only support float32 and float64\n     if dtype == 'float32':\n         return np.float32\n     elif dtype == 'float64':\n         return np.float64\n+    elif dtype == 'float16':\n+        return np.float16\n     else:\n         # cntk only running with float,\n         # try to cast to float to run the model\n@@ -125,10 +126,12 @@ def _convert_dtype_string(dtype):\n         return 'float32'\n     elif dtype == np.float64:\n         return 'float64'\n+    elif dtype == np.float16:\n+        return 'float16'\n     else:\n         raise ValueError('CNTK Backend: Unsupported dtype: %s. '\n-                         'CNTK only supports float32 and '\n-                         'float64.' % dtype)\n+                         'CNTK only supports float32, float64, and '\n+                         'float16.' % dtype)\n \n \n def variable(value, dtype=None, name=None, constraint=None):\n\n@@ -1767,10 +1767,6 @@ class TestBackend(object):\n     def test_dtype(self):\n         assert K.dtype(K.variable(1, dtype='float64')) == 'float64'\n         assert K.dtype(K.variable(1, dtype='float32')) == 'float32'\n-        if K.backend() == 'cntk':\n-            with pytest.raises(ValueError):\n-                K.variable(1, dtype='float16')\n-        else:\n         assert K.dtype(K.variable(1, dtype='float16')) == 'float16'\n \n     def test_variable_support_bool_dtype(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#52f608cbe7cf685bd9f92fcedc3ef02ba4292dc6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 20 | Churn Cumulative: 2082 | Contributors (this commit): 24 | Commits (past 90d): 8 | Contributors (cumulative): 24 | DMM Complexity: 1.0\n\nDIFF:\n@@ -7,7 +7,7 @@ import scipy.sparse as sparse\n \n import keras\n from keras import losses\n-from keras.layers import Activation, Dense, Dropout, Conv2D\n+from keras.layers import Activation, Dense, Dropout, Conv2D, Concatenate\n from keras.engine import Input\n from keras.engine.training import Model\n from keras.engine import training_utils\n@@ -1456,11 +1456,29 @@ def test_dynamic_set_inputs():\n     assert preds2.shape == (1, 8)\n \n     model3 = Model(inputs=model.inputs, outputs=model.outputs)\n+    with pytest.raises(ValueError):\n+        model3._set_inputs(model.inputs)\n+\n     model3.inputs = None\n     model3._set_inputs(model.inputs)\n     preds3 = model3.predict([np.random.random((1, 32))])\n     assert preds3.shape == (1, 16)\n \n+    model3.inputs = None\n+    model3._set_inputs(model.input)\n+    preds3 = model3.predict(np.random.random((1, 32)))\n+    assert preds3.shape == (1, 16)\n+\n+    aux_input = Input(shape=(5,), name='aux_input')\n+    aux_model = Dense(3)(aux_input)\n+    model4 = Model(inputs=model.inputs + [aux_input],\n+                   outputs=Concatenate()(model.outputs + [aux_model]))\n+    model4.inputs = None\n+    model4._set_inputs(model.inputs + [aux_input])\n+    preds4 = model4.predict([np.random.random((1, 32)),\n+                             np.random.random((1, 5))])\n+    assert preds4.shape == (1, 19)\n+\n \n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2d183db0372e5ac2a686608cb9da0a9bd4319764", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 12977 | Contributors (this commit): 121 | Commits (past 90d): 35 | Contributors (cumulative): 137 | DMM Complexity: None\n\nDIFF:\n@@ -1085,7 +1085,7 @@ def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n     elif ndim(beta) == ndim(x) and shape(beta)[0] == 1:\n         beta = _reshape_dummy_dim(beta, [0])\n \n-    return (x - mean) / (C.sqrt(var) + epsilon) * gamma + beta\n+    return (x - mean) / C.sqrt(var + epsilon) * gamma + beta\n \n \n def concatenate(tensors, axis=-1):\n\n@@ -1854,7 +1854,7 @@ def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n     \"\"\"Applies batch normalization on x given mean, var, beta and gamma.\n \n     I.e. returns:\n-    `output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta`\n+    `output = (x - mean) / sqrt(var + epsilon) * gamma + beta`\n \n     # Arguments\n         x: Input tensor or variable.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6aace3052716e24fad3ff7f168c9de49e61e1982", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 10975 | Contributors (this commit): 58 | Commits (past 90d): 8 | Contributors (cumulative): 58 | DMM Complexity: None\n\nDIFF:\n@@ -2326,7 +2326,7 @@ class Cropping2D(Layer):\n         # now model.output_shape == (None, 24, 20, 3)\n         model.add(Conv2D(64, (3, 3), padding='same'))\n         model.add(Cropping2D(cropping=((2, 2), (2, 2))))\n-        # now model.output_shape == (None, 20, 16. 64)\n+        # now model.output_shape == (None, 20, 16, 64)\n     ```\n     \"\"\"\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ffa99d69f7bfa42d060c26032793dc650002419b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 8 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 12093 | Contributors (this commit): 62 | Commits (past 90d): 15 | Contributors (cumulative): 70 | DMM Complexity: 0.25\n\nDIFF:\n@@ -807,7 +807,7 @@ class Conv2DTranspose(Conv2D):\n             padding=self.padding,\n             data_format=self.data_format)\n \n-        if self.bias:\n+        if self.use_bias:\n             outputs = K.bias_add(\n                 outputs,\n                 self.bias,\n@@ -1034,7 +1034,7 @@ class Conv3DTranspose(Conv3D):\n                                      padding=self.padding,\n                                      data_format=self.data_format)\n \n-        if self.bias:\n+        if self.use_bias:\n             outputs = K.bias_add(\n                 outputs,\n                 self.bias,\n@@ -1278,7 +1278,7 @@ class _SeparableConv(_Conv):\n                 padding=self.padding,\n                 dilation_rate=self.dilation_rate)\n \n-        if self.bias:\n+        if self.use_bias:\n             outputs = K.bias_add(\n                 outputs,\n                 self.bias,\n@@ -1737,7 +1737,7 @@ class DepthwiseConv2D(Conv2D):\n             dilation_rate=self.dilation_rate,\n             data_format=self.data_format)\n \n-        if self.bias:\n+        if self.use_bias:\n             outputs = K.bias_add(\n                 outputs,\n                 self.bias,\n\n@@ -226,6 +226,7 @@ def test_conv2d_transpose():\n         model = Sequential([convolutional.Conv2DTranspose(filters=filters,\n                                                           kernel_size=3,\n                                                           padding=padding,\n+                                                          use_bias=True,\n                                                           batch_input_shape=(None, None, 5, None))])\n \n \n@@ -269,6 +270,7 @@ def test_separable_conv_1d():\n                        'pointwise_constraint': 'unit_norm',\n                        'depthwise_constraint': 'unit_norm',\n                        'strides': 1,\n+                       'use_bias': True,\n                        'depth_multiplier': multiplier},\n                input_shape=(num_samples, stack_size, num_step))\n \n@@ -364,6 +366,7 @@ def test_depthwise_conv_2d():\n                        'bias_regularizer': 'l2',\n                        'activity_regularizer': 'l2',\n                        'depthwise_constraint': 'unit_norm',\n+                       'use_bias': True,\n                        'strides': strides,\n                        'depth_multiplier': multiplier},\n                input_shape=(num_samples, stack_size, num_row, num_col))\n@@ -521,6 +524,7 @@ def test_conv3d_transpose():\n                        'activity_regularizer': 'l2',\n                        'kernel_constraint': 'max_norm',\n                        'bias_constraint': 'max_norm',\n+                       'use_bias': True,\n                        'strides': strides},\n                input_shape=(None, stack_size, num_depth, num_row, num_col),\n                fixed_batch_size=True)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2ec486ba338684e066198c88cfbb55af4a34dd4f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 2167 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -174,8 +174,8 @@ class Network(Layer):\n                               'they cannot be the output of '\n                               'a previous non-Input layer. '\n                               'Here, a tensor specified as '\n-                          'input to \"' + self.name +\n-                          '\" was not an Input tensor, '\n+                              'input to your model '\n+                              'was not an Input tensor, '\n                               'it was generated by layer ' +\n                               layer.name + '.\\n'\n                               'Note that input tensors are '\n@@ -188,7 +188,7 @@ class Network(Layer):\n                 cls_name = self.__class__.__name__\n                 raise ValueError('Output tensors to a ' + cls_name +\n                                  ' must be '\n-                                 'the output of a TensorFlow `Layer` '\n+                                 'the output of a Keras `Layer` '\n                                  '(thus holding past layer metadata). '\n                                  'Found: ' + str(x))\n         self._base_init(name=name)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5fcd832b5c5025b164c99f0bd46cb94d707b93d3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 8490 | Contributors (this commit): 89 | Commits (past 90d): 11 | Contributors (cumulative): 89 | DMM Complexity: None\n\nDIFF:\n@@ -1125,7 +1125,7 @@ class Model(Network):\n \n         # Arguments\n             x: The input data, as a Numpy array\n-                (or list of Numpy arrays if the model has multiple outputs).\n+                (or list of Numpy arrays if the model has multiple inputs).\n             batch_size: Integer. If unspecified, it will default to 32.\n             verbose: Verbosity mode, 0 or 1.\n             steps: Total number of steps (batches of samples)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a2d11d4724d3cf4a0b18a7fe8448723d92e1c716", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 5 | Hunks: 6 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 19306 | Contributors (this commit): 144 | Commits (past 90d): 54 | Contributors (cumulative): 215 | DMM Complexity: None\n\nDIFF:\n@@ -10,7 +10,7 @@ models are more common in this domain.\n # Summary of the algorithm\n \n - We start with input sequences from a domain (e.g. English sentences)\n-    and correspding target sequences from another domain\n+    and corresponding target sequences from another domain\n     (e.g. French sentences).\n - An encoder LSTM turns input sequences to 2 state vectors\n     (we keep the last LSTM state and discard the outputs).\n\n@@ -2736,7 +2736,7 @@ def rnn(step_function, inputs, initial_states,\n                 states: List of tensors.\n             Returns:\n                 outputs: Tensor with shape (samples, ...) (no time dimension),\n-                new_states: Tist of tensors, same length and shapes\n+                new_states: List of tensors, same length and shapes\n                     as 'states'.\n         inputs: Tensor of temporal data of shape (samples, time, ...)\n             (at least 3D).\n\n@@ -1323,7 +1323,7 @@ def rnn(step_function, inputs, initial_states,\n                 states: List of tensors.\n             Returns:\n                 outputs: Tensor with shape (samples, ...) (no time dimension),\n-                new_states: Tist of tensors, same length and shapes\n+                new_states: List of tensors, same length and shapes\n                     as 'states'.\n         inputs: Tensor of temporal data of shape (samples, time, ...)\n             (at least 3D).\n\n@@ -131,7 +131,7 @@ class Network(Layer):\n         # Entries are unique. Includes input and output layers.\n         self._layers = []\n \n-        # Used only in conjonction with graph-networks\n+        # Used only in conjunction with graph-networks\n         self._outbound_nodes = []\n         self._inbound_nodes = []\n \n@@ -524,7 +524,7 @@ class Network(Layer):\n                 or a single instance if the model has only one input.\n         \"\"\"\n         if not self._is_graph_network:\n-            # TODO: support it in subclassd networks after inputs are set.\n+            # TODO: support it in subclassed networks after inputs are set.\n             return None\n \n         specs = []\n\n@@ -833,7 +833,7 @@ def _need_convert_kernel(original_backend):\n     The convolution operation is implemented differently in different backends.\n     While TH implements convolution, TF and CNTK implement the correlation operation.\n     So the channel axis needs to be flipped when we're loading TF weights onto a TH model,\n-    or vice verca. However, there's no conversion required between TF and CNTK.\n+    or vice versa. However, there's no conversion required between TF and CNTK.\n \n     # Arguments\n         original_backend: Keras backend the weights were trained with, as a string.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ebdc1c8759f65768212b7e7113b5cae82e9df3d4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 14 | Churn Cumulative: 14070 | Contributors (this commit): 121 | Commits (past 90d): 33 | Contributors (cumulative): 142 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2611,12 +2611,12 @@ class Function(object):\n                 # `callable_fn` only supports exact matches.\n                 array_vals.append(\n                     np.asarray(value,\n-                               dtype=tensor.dtype.base_dtype.name))\n+                               dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n         if self.feed_dict:\n             for key in sorted(self.feed_dict.keys()):\n                 array_vals.append(\n                     np.asarray(self.feed_dict[key],\n-                               dtype=key.dtype.base_dtype.name))\n+                               dtype=tf.as_dtype(key.dtype).as_numpy_dtype))\n \n         # Refresh callable if anything has changed.\n         if (self._callable_fn is None or\n\n@@ -530,6 +530,16 @@ class TestBackend(object):\n         assert output == [21.]\n         assert KTF.get_session().run(fetches=[x, y]) == [30., 40.]\n \n+    def test_function_tf_string_input(self):\n+        # Test functions with string inputs.\n+\n+        x_placeholder = KTF.placeholder(shape=(), dtype=\"string\")\n+        x_identity = KTF.identity(x_placeholder)\n+\n+        f = KTF.function(inputs=[x_placeholder], outputs=[x_identity])\n+        output = f([b'test'])\n+        assert output == [b'test']\n+\n     def test_rnn(self):\n         # implement a simple RNN\n         num_samples = 4\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#86c00074ab67b7fcbcf14cb8fe1498e3612f92e9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2173 | Contributors (this commit): 4 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -1261,7 +1261,7 @@ class Network(Layer):\n         \"\"\"\n         if not self.built:\n             raise ValueError(\n-                'This model has never been called, this its weights '\n+                'This model has never been called, thus its weights '\n                 'have not yet been created, so no summary can be displayed. '\n                 'Build the model first '\n                 '(e.g. by calling it on some test data).')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#df03bb5b1cc9fd297b0f19e08d916a4faedea267", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 60 | Files Changed: 1 | Hunks: 9 | Methods Changed: 6 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 86 | Churn Cumulative: 1736 | Contributors (this commit): 26 | Commits (past 90d): 8 | Contributors (cumulative): 26 | DMM Complexity: 0.0\n\nDIFF:\n@@ -341,32 +341,6 @@ PAGES = [\n ROOT = 'http://keras.io/'\n \n \n-def get_earliest_class_that_defined_member(member, cls):\n-    ancestors = get_classes_ancestors([cls])\n-    result = None\n-    for ancestor in ancestors:\n-        if member in dir(ancestor):\n-            result = ancestor\n-    if not result:\n-        return cls\n-    return result\n-\n-\n-def get_classes_ancestors(classes):\n-    ancestors = []\n-    for cls in classes:\n-        ancestors += cls.__bases__\n-    filtered_ancestors = []\n-    for ancestor in ancestors:\n-        if ancestor.__name__ in ['object']:\n-            continue\n-        filtered_ancestors.append(ancestor)\n-    if filtered_ancestors:\n-        return filtered_ancestors + get_classes_ancestors(filtered_ancestors)\n-    else:\n-        return filtered_ancestors\n-\n-\n def get_function_signature(function, method=True):\n     wrapped = getattr(function, '_original_function', None)\n     if wrapped is None:\n@@ -414,7 +388,7 @@ def get_class_signature(cls):\n \n \n def post_process_signature(signature):\n-    parts = re.split('\\.(?!\\d)', signature)\n+    parts = re.split(r'\\.(?!\\d)', signature)\n     if len(parts) >= 4:\n         if parts[1] == 'layers':\n             signature = 'keras.layers.' + '.'.join(parts[3:])\n@@ -459,7 +433,7 @@ def code_snippet(snippet):\n \n \n def count_leading_spaces(s):\n-    ws = re.search('\\S', s)\n+    ws = re.search(r'\\S', s)\n     if ws:\n         return ws.start()\n     else:\n@@ -596,7 +570,6 @@ for subdir, dirs, fnames in os.walk('templates'):\n             shutil.copy(fpath, new_fpath)\n \n \n-# Take care of index page.\n def read_file(path):\n     with open(path) as f:\n         return f.read()\n@@ -617,8 +590,7 @@ def render_function(function, method=True):\n     subblocks = []\n     signature = get_function_signature(function, method=method)\n     signature = signature.replace(function.__module__ + '.', '')\n-    level = 3\n-    subblocks.append('#' * level + ' ' + function.__name__ + '\\n')\n+    subblocks.append('### ' + function.__name__ + '\\n')\n     subblocks.append(code_snippet(signature))\n     docstring = function.__doc__\n     if docstring:\n@@ -626,6 +598,26 @@ def render_function(function, method=True):\n     return '\\n\\n'.join(subblocks)\n \n \n+def read_page_data(page_data, type):\n+    assert type in ['classes', 'functions']\n+    data = page_data.get(type, [])\n+    for module in page_data.get('all_module_{}'.format(type), []):\n+        module_data = []\n+        for name in dir(module):\n+            if name[0] == '_' or name in EXCLUDE:\n+                continue\n+            module_member = getattr(module, name)\n+            if (inspect.isclass(module_member) and type == 'classes' or\n+               inspect.isfunction(module_member) and type == 'functions'):\n+                instance = module_member\n+                if module.__name__ in instance.__module__:\n+                    if instance not in module_data:\n+                        module_data.append(instance)\n+        module_data.sort(key=lambda x: id(x))\n+        data += module_data\n+    return data\n+\n+\n if __name__ == '__main__':\n     readme = read_file('../README.md')\n     index = read_file('templates/index.md')\n@@ -635,22 +627,9 @@ if __name__ == '__main__':\n \n     print('Generating docs for Keras %s.' % keras.__version__)\n     for page_data in PAGES:\n-        blocks = []\n-        classes = page_data.get('classes', [])\n-        for module in page_data.get('all_module_classes', []):\n-            module_classes = []\n-            for name in dir(module):\n-                if name[0] == '_' or name in EXCLUDE:\n-                    continue\n-                module_member = getattr(module, name)\n-                if inspect.isclass(module_member):\n-                    cls = module_member\n-                    if cls.__module__ == module.__name__:\n-                        if cls not in module_classes:\n-                            module_classes.append(cls)\n-            module_classes.sort(key=lambda x: id(x))\n-            classes += module_classes\n+        classes = read_page_data(page_data, 'classes')\n \n+        blocks = []\n         for element in classes:\n             if not isinstance(element, (list, tuple)):\n                 element = (element, [])\n@@ -675,20 +654,7 @@ if __name__ == '__main__':\n                     [render_function(method, method=True) for method in methods]))\n             blocks.append('\\n'.join(subblocks))\n \n-        functions = page_data.get('functions', [])\n-        for module in page_data.get('all_module_functions', []):\n-            module_functions = []\n-            for name in dir(module):\n-                if name[0] == '_' or name in EXCLUDE:\n-                    continue\n-                module_member = getattr(module, name)\n-                if inspect.isfunction(module_member):\n-                    function = module_member\n-                    if module.__name__ in function.__module__:\n-                        if function not in module_functions:\n-                            module_functions.append(function)\n-            module_functions.sort(key=lambda x: id(x))\n-            functions += module_functions\n+        functions = read_page_data(page_data, 'functions')\n \n         for function in functions:\n             blocks.append(render_function(function, method=False))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e3e4f0b504cc12330de8b40f94da572d53cf7de5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 427 | Files Changed: 2 | Hunks: 3 | Methods Changed: 6 | Complexity Δ (Sum/Max): -58/5 | Churn Δ: 430 | Churn Cumulative: 980 | Contributors (this commit): 11 | Commits (past 90d): 6 | Contributors (cumulative): 13 | DMM Complexity: 0.9632352941176471\n\nDIFF:\n@@ -4,319 +4,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import json\n-import warnings\n-import numpy as np\n+from keras_applications import imagenet_utils\n \n-from ..utils.data_utils import get_file\n-from .. import backend as K\n-\n-CLASS_INDEX = None\n-CLASS_INDEX_PATH = 'https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json'\n-\n-# Global tensor of imagenet mean for preprocessing symbolic inputs\n-_IMAGENET_MEAN = None\n-\n-\n-def _preprocess_numpy_input(x, data_format, mode):\n-    \"\"\"Preprocesses a Numpy array encoding a batch of images.\n-\n-    # Arguments\n-        x: Input array, 3D or 4D.\n-        data_format: Data format of the image array.\n-        mode: One of \"caffe\", \"tf\" or \"torch\".\n-            - caffe: will convert the images from RGB to BGR,\n-                then will zero-center each color channel with\n-                respect to the ImageNet dataset,\n-                without scaling.\n-            - tf: will scale pixels between -1 and 1,\n-                sample-wise.\n-            - torch: will scale pixels between 0 and 1 and then\n-                will normalize each channel with respect to the\n-                ImageNet dataset.\n-\n-    # Returns\n-        Preprocessed Numpy array.\n-    \"\"\"\n-    if not issubclass(x.dtype.type, np.floating):\n-        x = x.astype(K.floatx(), copy=False)\n-\n-    if mode == 'tf':\n-        x /= 127.5\n-        x -= 1.\n-        return x\n-\n-    if mode == 'torch':\n-        x /= 255.\n-        mean = [0.485, 0.456, 0.406]\n-        std = [0.229, 0.224, 0.225]\n-    else:\n-        if data_format == 'channels_first':\n-            # 'RGB'->'BGR'\n-            if x.ndim == 3:\n-                x = x[::-1, ...]\n-            else:\n-                x = x[:, ::-1, ...]\n-        else:\n-            # 'RGB'->'BGR'\n-            x = x[..., ::-1]\n-        mean = [103.939, 116.779, 123.68]\n-        std = None\n-\n-    # Zero-center by mean pixel\n-    if data_format == 'channels_first':\n-        if x.ndim == 3:\n-            x[0, :, :] -= mean[0]\n-            x[1, :, :] -= mean[1]\n-            x[2, :, :] -= mean[2]\n-            if std is not None:\n-                x[0, :, :] /= std[0]\n-                x[1, :, :] /= std[1]\n-                x[2, :, :] /= std[2]\n-        else:\n-            x[:, 0, :, :] -= mean[0]\n-            x[:, 1, :, :] -= mean[1]\n-            x[:, 2, :, :] -= mean[2]\n-            if std is not None:\n-                x[:, 0, :, :] /= std[0]\n-                x[:, 1, :, :] /= std[1]\n-                x[:, 2, :, :] /= std[2]\n-    else:\n-        x[..., 0] -= mean[0]\n-        x[..., 1] -= mean[1]\n-        x[..., 2] -= mean[2]\n-        if std is not None:\n-            x[..., 0] /= std[0]\n-            x[..., 1] /= std[1]\n-            x[..., 2] /= std[2]\n-    return x\n-\n-\n-def _preprocess_symbolic_input(x, data_format, mode):\n-    \"\"\"Preprocesses a tensor encoding a batch of images.\n-\n-    # Arguments\n-        x: Input tensor, 3D or 4D.\n-        data_format: Data format of the image tensor.\n-        mode: One of \"caffe\", \"tf\" or \"torch\".\n-            - caffe: will convert the images from RGB to BGR,\n-                then will zero-center each color channel with\n-                respect to the ImageNet dataset,\n-                without scaling.\n-            - tf: will scale pixels between -1 and 1,\n-                sample-wise.\n-            - torch: will scale pixels between 0 and 1 and then\n-                will normalize each channel with respect to the\n-                ImageNet dataset.\n-\n-    # Returns\n-        Preprocessed tensor.\n-    \"\"\"\n-    global _IMAGENET_MEAN\n-\n-    if mode == 'tf':\n-        x /= 127.5\n-        x -= 1.\n-        return x\n-\n-    if mode == 'torch':\n-        x /= 255.\n-        mean = [0.485, 0.456, 0.406]\n-        std = [0.229, 0.224, 0.225]\n-    else:\n-        if data_format == 'channels_first':\n-            # 'RGB'->'BGR'\n-            if K.ndim(x) == 3:\n-                x = x[::-1, ...]\n-            else:\n-                x = x[:, ::-1, ...]\n-        else:\n-            # 'RGB'->'BGR'\n-            x = x[..., ::-1]\n-        mean = [103.939, 116.779, 123.68]\n-        std = None\n-\n-    if _IMAGENET_MEAN is None:\n-        _IMAGENET_MEAN = K.constant(-np.array(mean))\n-\n-    # Zero-center by mean pixel\n-    if K.dtype(x) != K.dtype(_IMAGENET_MEAN):\n-        x = K.bias_add(x, K.cast(_IMAGENET_MEAN, K.dtype(x)), data_format)\n-    else:\n-        x = K.bias_add(x, _IMAGENET_MEAN, data_format)\n-    if std is not None:\n-        x /= std\n-    return x\n-\n-\n-def preprocess_input(x, data_format=None, mode='caffe'):\n-    \"\"\"Preprocesses a tensor or Numpy array encoding a batch of images.\n-\n-    # Arguments\n-        x: Input Numpy or symbolic tensor, 3D or 4D.\n-            The preprocessed data is written over the input data\n-            if the data types are compatible. To avoid this\n-            behaviour, `numpy.copy(x)` can be used.\n-        data_format: Data format of the image tensor/array.\n-        mode: One of \"caffe\", \"tf\" or \"torch\".\n-            - caffe: will convert the images from RGB to BGR,\n-                then will zero-center each color channel with\n-                respect to the ImageNet dataset,\n-                without scaling.\n-            - tf: will scale pixels between -1 and 1,\n-                sample-wise.\n-            - torch: will scale pixels between 0 and 1 and then\n-                will normalize each channel with respect to the\n-                ImageNet dataset.\n-\n-    # Returns\n-        Preprocessed tensor or Numpy array.\n-\n-    # Raises\n-        ValueError: In case of unknown `data_format` argument.\n-    \"\"\"\n-    if data_format is None:\n-        data_format = K.image_data_format()\n-    if data_format not in {'channels_first', 'channels_last'}:\n-        raise ValueError('Unknown data_format ' + str(data_format))\n-\n-    if isinstance(x, np.ndarray):\n-        return _preprocess_numpy_input(x, data_format=data_format, mode=mode)\n-    else:\n-        return _preprocess_symbolic_input(x, data_format=data_format,\n-                                          mode=mode)\n-\n-\n-def decode_predictions(preds, top=5):\n-    \"\"\"Decodes the prediction of an ImageNet model.\n-\n-    # Arguments\n-        preds: Numpy tensor encoding a batch of predictions.\n-        top: Integer, how many top-guesses to return.\n-\n-    # Returns\n-        A list of lists of top class prediction tuples\n-        `(class_name, class_description, score)`.\n-        One list of tuples per sample in batch input.\n-\n-    # Raises\n-        ValueError: In case of invalid shape of the `pred` array\n-            (must be 2D).\n-    \"\"\"\n-    global CLASS_INDEX\n-    if len(preds.shape) != 2 or preds.shape[1] != 1000:\n-        raise ValueError('`decode_predictions` expects '\n-                         'a batch of predictions '\n-                         '(i.e. a 2D array of shape (samples, 1000)). '\n-                         'Found array with shape: ' + str(preds.shape))\n-    if CLASS_INDEX is None:\n-        fpath = get_file('imagenet_class_index.json',\n-                         CLASS_INDEX_PATH,\n-                         cache_subdir='models',\n-                         file_hash='c2c37ea517e94d9795004a39431a14cb')\n-        with open(fpath) as f:\n-            CLASS_INDEX = json.load(f)\n-    results = []\n-    for pred in preds:\n-        top_indices = pred.argsort()[-top:][::-1]\n-        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n-        result.sort(key=lambda x: x[2], reverse=True)\n-        results.append(result)\n-    return results\n-\n-\n-def _obtain_input_shape(input_shape,\n-                        default_size,\n-                        min_size,\n-                        data_format,\n-                        require_flatten,\n-                        weights=None):\n-    \"\"\"Internal utility to compute/validate a model's input shape.\n-\n-    # Arguments\n-        input_shape: Either None (will return the default network input shape),\n-            or a user-provided shape to be validated.\n-        default_size: Default input width/height for the model.\n-        min_size: Minimum input width/height accepted by the model.\n-        data_format: Image data format to use.\n-        require_flatten: Whether the model is expected to\n-            be linked to a classifier via a Flatten layer.\n-        weights: One of `None` (random initialization)\n-            or 'imagenet' (pre-training on ImageNet).\n-            If weights='imagenet' input channels must be equal to 3.\n-\n-    # Returns\n-        An integer shape tuple (may include None entries).\n-\n-    # Raises\n-        ValueError: In case of invalid argument values.\n-    \"\"\"\n-    if weights != 'imagenet' and input_shape and len(input_shape) == 3:\n-        if data_format == 'channels_first':\n-            if input_shape[0] not in {1, 3}:\n-                warnings.warn(\n-                    'This model usually expects 1 or 3 input channels. '\n-                    'However, it was passed an input_shape with ' +\n-                    str(input_shape[0]) + ' input channels.')\n-            default_shape = (input_shape[0], default_size, default_size)\n-        else:\n-            if input_shape[-1] not in {1, 3}:\n-                warnings.warn(\n-                    'This model usually expects 1 or 3 input channels. '\n-                    'However, it was passed an input_shape with ' +\n-                    str(input_shape[-1]) + ' input channels.')\n-            default_shape = (default_size, default_size, input_shape[-1])\n-    else:\n-        if data_format == 'channels_first':\n-            default_shape = (3, default_size, default_size)\n-        else:\n-            default_shape = (default_size, default_size, 3)\n-    if weights == 'imagenet' and require_flatten:\n-        if input_shape is not None:\n-            if input_shape != default_shape:\n-                raise ValueError('When setting`include_top=True` '\n-                                 'and loading `imagenet` weights, '\n-                                 '`input_shape` should be ' +\n-                                 str(default_shape) + '.')\n-        return default_shape\n-    if input_shape:\n-        if data_format == 'channels_first':\n-            if input_shape is not None:\n-                if len(input_shape) != 3:\n-                    raise ValueError(\n-                        '`input_shape` must be a tuple of three integers.')\n-                if input_shape[0] != 3 and weights == 'imagenet':\n-                    raise ValueError('The input must have 3 channels; got '\n-                                     '`input_shape=' + str(input_shape) + '`')\n-                if ((input_shape[1] is not None and input_shape[1] < min_size) or\n-                   (input_shape[2] is not None and input_shape[2] < min_size)):\n-                    raise ValueError('Input size must be at least ' +\n-                                     str(min_size) + 'x' + str(min_size) + '; got '\n-                                     '`input_shape=' + str(input_shape) + '`')\n-        else:\n-            if input_shape is not None:\n-                if len(input_shape) != 3:\n-                    raise ValueError(\n-                        '`input_shape` must be a tuple of three integers.')\n-                if input_shape[-1] != 3 and weights == 'imagenet':\n-                    raise ValueError('The input must have 3 channels; got '\n-                                     '`input_shape=' + str(input_shape) + '`')\n-                if ((input_shape[0] is not None and input_shape[0] < min_size) or\n-                   (input_shape[1] is not None and input_shape[1] < min_size)):\n-                    raise ValueError('Input size must be at least ' +\n-                                     str(min_size) + 'x' + str(min_size) + '; got '\n-                                     '`input_shape=' + str(input_shape) + '`')\n-    else:\n-        if require_flatten:\n-            input_shape = default_shape\n-        else:\n-            if data_format == 'channels_first':\n-                input_shape = (3, None, None)\n-            else:\n-                input_shape = (None, None, 3)\n-    if require_flatten:\n-        if None in input_shape:\n-            raise ValueError('If `include_top` is True, '\n-                             'you should specify a static `input_shape`. '\n-                             'Got `input_shape=' + str(input_shape) + '`')\n-    return input_shape\n+preprocess_input = imagenet_utils.preprocess_input\n+decode_predictions = imagenet_utils.decode_predictions\n\n@@ -108,117 +108,5 @@ def test_decode_predictions():\n         utils.decode_predictions(np.ones((2, 100)))\n \n \n-def test_obtain_input_shape():\n-    # input_shape and default_size are not identical.\n-    with pytest.raises(ValueError):\n-        utils._obtain_input_shape(\n-            input_shape=(224, 224, 3),\n-            default_size=299,\n-            min_size=139,\n-            data_format='channels_last',\n-            require_flatten=True,\n-            weights='imagenet')\n-\n-    # Test invalid use cases\n-    for data_format in ['channels_last', 'channels_first']:\n-\n-        # test warning\n-        shape = (139, 139)\n-        input_shape = shape + (99,) if data_format == 'channels_last' else (99,) + shape\n-        with pytest.warns(UserWarning):\n-            utils._obtain_input_shape(\n-                input_shape=input_shape,\n-                default_size=None,\n-                min_size=139,\n-                data_format=data_format,\n-                require_flatten=False,\n-                weights='fake_weights')\n-\n-        # input_shape is smaller than min_size.\n-        shape = (100, 100)\n-        input_shape = shape + (3,) if data_format == 'channels_last' else (3,) + shape\n-        with pytest.raises(ValueError):\n-            utils._obtain_input_shape(\n-                input_shape=input_shape,\n-                default_size=None,\n-                min_size=139,\n-                data_format=data_format,\n-                require_flatten=False)\n-\n-        # shape is 1D.\n-        shape = (100,)\n-        input_shape = shape + (3,) if data_format == 'channels_last' else (3,) + shape\n-        with pytest.raises(ValueError):\n-            utils._obtain_input_shape(\n-                input_shape=input_shape,\n-                default_size=None,\n-                min_size=139,\n-                data_format=data_format,\n-                require_flatten=False)\n-\n-        # the number of channels is 5 not 3.\n-        shape = (100, 100)\n-        input_shape = shape + (5,) if data_format == 'channels_last' else (5,) + shape\n-        with pytest.raises(ValueError):\n-            utils._obtain_input_shape(\n-                input_shape=input_shape,\n-                default_size=None,\n-                min_size=139,\n-                data_format=data_format,\n-                require_flatten=False)\n-\n-        # require_flatten=True with dynamic input shape.\n-        with pytest.raises(ValueError):\n-            utils._obtain_input_shape(\n-                input_shape=None,\n-                default_size=None,\n-                min_size=139,\n-                data_format='channels_first',\n-                require_flatten=True)\n-\n-    # test include top\n-    assert utils._obtain_input_shape(\n-        input_shape=(3, 200, 200),\n-        default_size=None,\n-        min_size=139,\n-        data_format='channels_first',\n-        require_flatten=True) == (3, 200, 200)\n-\n-    assert utils._obtain_input_shape(\n-        input_shape=None,\n-        default_size=None,\n-        min_size=139,\n-        data_format='channels_last',\n-        require_flatten=False) == (None, None, 3)\n-\n-    assert utils._obtain_input_shape(\n-        input_shape=None,\n-        default_size=None,\n-        min_size=139,\n-        data_format='channels_first',\n-        require_flatten=False) == (3, None, None)\n-\n-    assert utils._obtain_input_shape(\n-        input_shape=None,\n-        default_size=None,\n-        min_size=139,\n-        data_format='channels_last',\n-        require_flatten=False) == (None, None, 3)\n-\n-    assert utils._obtain_input_shape(\n-        input_shape=(150, 150, 3),\n-        default_size=None,\n-        min_size=139,\n-        data_format='channels_last',\n-        require_flatten=False) == (150, 150, 3)\n-\n-    assert utils._obtain_input_shape(\n-        input_shape=(3, None, None),\n-        default_size=None,\n-        min_size=139,\n-        data_format='channels_first',\n-        require_flatten=False) == (3, None, None)\n-\n-\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
