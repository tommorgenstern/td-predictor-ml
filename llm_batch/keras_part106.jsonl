{"custom_id": "keras#6a8815de0cec97480e2f0ce4769ceaf1121274bd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 23 | Churn Cumulative: 4234 | Contributors (this commit): 23 | Commits (past 90d): 31 | Contributors (cumulative): 29 | DMM Complexity: 0.4\n\nDIFF:\n@@ -1356,9 +1356,19 @@ class Merge(Layer):\n             masks = [K.expand_dims(m, 0) for m in mask if m is not None]\n             return K.all(K.concatenate(masks, axis=0), axis=0, keepdims=False)\n         elif self.mode == 'concat':\n-            masks = [K.ones_like(inputs[i][:-1]) if m is None else m for i, m in zip(inputs, mask)]\n-            expanded_dims = [K.expand_dims(m) for m in masks]\n-            concatenated = K.concatenate(expanded_dims, axis=self.concat_axis)\n+            # Make a list of masks while making sure the dimensionality of each mask \n+            # is the same as the corresponding input.\n+            masks = []\n+            for input_i, mask_i in zip(inputs, mask):\n+                if mask_i is None:\n+                    # Input is unmasked. Append all 1s to masks, but cast it to uint8 first\n+                    masks.append(K.cast(K.ones_like(input_i), 'uint8'))\n+                elif K.ndim(mask_i) < K.ndim(input_i):\n+                    # Mask is smaller than the input, expand it\n+                    masks.append(K.expand_dims(mask_i))\n+                else:\n+                    masks.append(mask_i)\n+            concatenated = K.concatenate(masks, axis=self.concat_axis)\n             return K.all(concatenated, axis=-1, keepdims=False)\n         elif self.mode in ['cos', 'dot']:\n             return None\n\n@@ -100,9 +100,10 @@ def test_merge_mask_2d():\n     masked_a = Masking(mask_value=0)(input_a)\n     masked_b = Masking(mask_value=0)(input_b)\n \n-    # two different types of merging\n+    # three different types of merging\n     merged_sum = merge([masked_a, masked_b], mode='sum')\n     merged_concat = merge([masked_a, masked_b], mode='concat', concat_axis=1)\n+    merged_concat_mixed = merge([masked_a, input_b], mode='concat', concat_axis=1)\n \n     # test sum\n     model_sum = Model([input_a, input_b], [merged_sum])\n@@ -114,6 +115,10 @@ def test_merge_mask_2d():\n     model_concat.compile(loss='mse', optimizer='sgd')\n     model_concat.fit([rand(2, 3), rand(2, 3)], [rand(2, 6)], nb_epoch=1)\n \n+    # test concatenation with masked and non-masked inputs\n+    model_concat = Model([input_a, input_b], [merged_concat_mixed])\n+    model_concat.compile(loss='mse', optimizer='sgd')\n+    model_concat.fit([rand(2,3), rand(2,3)], [rand(2,6)], nb_epoch=1)\n \n @keras_test\n def test_merge_mask_3d():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b6d23b2e2dfc90480519ab52047006b1936fda02", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 2351 | Contributors (this commit): 27 | Commits (past 90d): 37 | Contributors (cumulative): 27 | DMM Complexity: 1.0\n\nDIFF:\n@@ -859,7 +859,11 @@ def set_value(x, value):\n     '''Sets the value of a tensor variable,\n     from a Numpy array.\n     '''\n-    tf.assign(x, np.asarray(value)).op.run(session=get_session())\n+    value = np.asarray(value)\n+    tf_dtype = _convert_string_dtype(x.dtype.name.split('_')[0])\n+    assign_placeholder = tf.placeholder(tf_dtype, shape=value.shape)\n+    assign_op = x.assign(assign_placeholder)\n+    get_session().run(assign_op, feed_dict={assign_placeholder: value})\n \n \n def batch_set_value(tuples):\n@@ -870,8 +874,15 @@ def batch_set_value(tuples):\n             `value` should be a Numpy array.\n     '''\n     if tuples:\n-        ops = [tf.assign(x, np.asarray(value)) for x, value in tuples]\n-        get_session().run(ops)\n+        assign_ops = []\n+        feed_dict = {}\n+        for x, value in tuples:\n+            value = np.asarray(value)\n+            tf_dtype = _convert_string_dtype(x.dtype.name.split('_')[0])\n+            assign_placeholder = tf.placeholder(tf_dtype, shape=value.shape)\n+            assign_ops.append(x.assign(assign_placeholder))\n+            feed_dict[assign_placeholder] = value\n+        get_session().run(assign_ops, feed_dict=feed_dict)\n \n \n def print_tensor(x, message=''):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cb4de1f859aaae833aafa9330d84d9a0d56136c5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 589 | Contributors (this commit): 14 | Commits (past 90d): 3 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -125,6 +125,8 @@ class Embedding(Layer):\n         return (input_shape[0], input_length, self.output_dim)\n \n     def call(self, x, mask=None):\n+        if K.dtype(x) != 'int32':\n+            x = K.cast(x, 'int32')\n         if 0. < self.dropout < 1.:\n             retain_p = 1. - self.dropout\n             B = K.random_binomial((self.input_dim,), p=retain_p) * (1. / retain_p)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d06e3753b01a8f59f8dc4109495e0d11880557d8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 406 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -80,6 +80,7 @@ total_variation_weight = 1.\n style_weight = 1.\n content_weight = 0.025\n \n+\n # dimensions of the generated picture.\n img_width = 400\n img_height = 400\n@@ -88,13 +89,21 @@ assert img_height == img_width, 'Due to the use of the Gram matrix, width and he\n # util function to open, resize and format pictures into appropriate tensors\n def preprocess_image(image_path):\n     img = imresize(imread(image_path), (img_width, img_height))\n-    img = img.transpose((2, 0, 1)).astype('float64')\n+    img = img[:, :, ::-1].astype('float64')\n+    img[:, :, 0] -= 103.939\n+    img[:, :, 1] -= 116.779\n+    img[:, :, 2] -= 123.68\n+    img = img.transpose((2, 0, 1))\n     img = np.expand_dims(img, axis=0)\n     return img\n \n # util function to convert a tensor into a valid image\n def deprocess_image(x):\n     x = x.transpose((1, 2, 0))\n+    x[:, :, 0] += 103.939\n+    x[:, :, 1] += 116.779\n+    x[:, :, 2] += 123.68\n+    x = x[:, :, ::-1]\n     x = np.clip(x, 0, 255).astype('uint8')\n     return x\n \n@@ -275,6 +284,9 @@ evaluator = Evaluator()\n # run scipy-based optimization (L-BFGS) over the pixels of the generated image\n # so as to minimize the neural style loss\n x = np.random.uniform(0, 255, (1, 3, img_width, img_height))\n+x[0, 0, :, :] -= 103.939\n+x[0, 1, :, :] -= 116.779\n+x[0, 2, :, :] -= 123.68\n for i in range(10):\n     print('Start of iteration', i)\n     start_time = time.time()\n@@ -282,7 +294,7 @@ for i in range(10):\n                                      fprime=evaluator.grads, maxfun=20)\n     print('Current loss value:', min_val)\n     # save current generated image\n-    img = deprocess_image(x.reshape((3, img_width, img_height)))\n+    img = deprocess_image(x.copy().reshape((3, img_width, img_height)))\n     fname = result_prefix + '_at_iteration_%d.png' % i\n     imsave(fname, img)\n     end_time = time.time()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#70866c0154b2efd7351ff5403590b80d7d46a045", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 1628 | Contributors (this commit): 23 | Commits (past 90d): 12 | Contributors (cumulative): 23 | DMM Complexity: None\n\nDIFF:\n@@ -9,6 +9,7 @@ import warnings\n from collections import deque\n from .utils.generic_utils import Progbar\n from keras import backend as K\n+from pkg_resources import parse_version\n \n \n class CallbackList(object):\n@@ -478,7 +479,7 @@ class TensorBoard(Callback):\n                                          layer.output)\n         self.merged = tf.merge_all_summaries()\n         if self.write_graph:\n-            if tf.__version__ >= '0.8.0':\n+            if parse_version(tf.__version__) >= parse_version('0.8.0'):\n                 self.writer = tf.train.SummaryWriter(self.log_dir,\n                                                      self.sess.graph)\n             else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cce65ce34d62aee957d51fcdd50e23a974ec15e9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 1 | Files Changed: 3 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 7 | Churn Cumulative: 3360 | Contributors (this commit): 31 | Commits (past 90d): 44 | Contributors (cumulative): 35 | DMM Complexity: 0.0\n\nDIFF:\n@@ -88,6 +88,7 @@ EXCLUDE = {\n     'Wrapper',\n     'get_session',\n     'set_session',\n+    'CallbackList',\n }\n \n PAGES = [\n\n@@ -1,6 +1,6 @@\n '''This example demonstrates the use of Convolution1D for text classification.\n \n-Gets to 0.88 test accuracy after 2 epochs. \n+Gets to 0.89 test accuracy after 2 epochs.\n 90s/epoch on Intel i5 2.4Ghz CPU.\n 10s/epoch on Tesla K40 GPU.\n \n\n@@ -92,12 +92,16 @@ def _convert_string_dtype(dtype):\n         return tf.float32\n     elif dtype == 'float64':\n         return tf.float64\n+    elif dtype == 'int16':\n+        return tf.int16\n     elif dtype == 'int32':\n         return tf.int32\n     elif dtype == 'int64':\n         return tf.int64\n     elif dtype == 'uint8':\n         return tf.int8\n+    elif dtype == 'uint16':\n+        return tf.uint16\n     else:\n         raise ValueError('Unsupported dtype:', dtype)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a9fc2bed49c7988ccd6d365c1542818172b64ffe", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 8 | Churn Cumulative: 3277 | Contributors (this commit): 19 | Commits (past 90d): 32 | Contributors (cumulative): 20 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2411,7 +2411,10 @@ class Container(Layer):\n         '''\n         import h5py\n         f = h5py.File(filepath, mode='r')\n+        if 'layer_names' not in f.attrs and 'model_weights' in f:\n+            f = f['model_weights']\n         self.load_weights_from_hdf5_group(f)\n+        if hasattr(f, 'close'):\n             f.close()\n \n     def load_weights_from_hdf5_group(self, f):\n\n@@ -29,7 +29,6 @@ def test_sequential_model_saving():\n     save_model(model, fname)\n \n     new_model = load_model(fname)\n-    os.remove(fname)\n \n     out2 = new_model.predict(x)\n     assert_allclose(out, out2, atol=1e-05)\n@@ -43,6 +42,10 @@ def test_sequential_model_saving():\n     out2 = new_model.predict(x)\n     assert_allclose(out, out2, atol=1e-05)\n \n+    # test load_weights on model file\n+    model.load_weights(fname)\n+    os.remove(fname)\n+\n \n @keras_test\n def test_sequential_model_saving_2():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6c42da2abfe2e4d5eef9bf7ba3b318b8fe4154e8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 3111 | Contributors (this commit): 19 | Commits (past 90d): 29 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -2429,12 +2429,6 @@ class Container(Layer):\n             flattened_layers = self.flattened_layers\n         else:\n             flattened_layers = self.layers\n-        filtered_layers = []\n-        for layer in flattened_layers:\n-            weights = layer.trainable_weights + layer.non_trainable_weights\n-            if weights:\n-                filtered_layers.append(layer)\n-        flattened_layers = filtered_layers\n \n         if 'nb_layers' in f.attrs:\n             # legacy format\n@@ -2443,7 +2437,7 @@ class Container(Layer):\n                 raise Exception('You are trying to load a weight file '\n                                 'containing ' + str(nb_layers) +\n                                 ' layers into a model with ' +\n-                                str(len(flattened_layers)) + '.')\n+                                str(len(flattened_layers)) + ' layers.')\n \n             for k in range(nb_layers):\n                 g = f['layer_{}'.format(k)]\n@@ -2451,6 +2445,13 @@ class Container(Layer):\n                 flattened_layers[k].set_weights(weights)\n         else:\n             # new file format\n+            filtered_layers = []\n+            for layer in flattened_layers:\n+                weights = layer.trainable_weights + layer.non_trainable_weights\n+                if weights:\n+                    filtered_layers.append(layer)\n+            flattened_layers = filtered_layers\n+\n             layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]\n             filtered_layer_names = []\n             for name in layer_names:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cef9e28a6c79684f34b3c53cadf07370ea9f33f1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 4308 | Contributors (this commit): 28 | Commits (past 90d): 9 | Contributors (cumulative): 28 | DMM Complexity: None\n\nDIFF:\n@@ -139,7 +139,10 @@ class Recurrent(Layer):\n         To enable statefulness:\n             - specify `stateful=True` in the layer constructor.\n             - specify a fixed batch size for your model, by passing\n+                if sequential model:\n                   a `batch_input_shape=(...)` to the first layer in your model.\n+                else for functional model with 1 or more Input layers:\n+                  a `batch_shape=(...)` to all the first layers in your model.\n                 This is the expected shape of your inputs *including the batch size*.\n                 It should be a tuple of integers, e.g. `(32, 10, 100)`.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#257ace722c04c1448f2e178330d51b9a11925b9f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 151 | Contributors (this commit): 4 | Commits (past 90d): 6 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -39,7 +39,7 @@ x_decoded_mean = decoder_mean(h_decoded)\n \n \n def vae_loss(x, x_decoded_mean):\n-    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)\n+    xent_loss = original_dim * objectives.binary_crossentropy(x, x_decoded_mean)\n     kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n     return xent_loss + kl_loss\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c725f8d354ef7f6c535aa33581a9928e66f0a6a9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 216 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 4 | Complexity Δ (Sum/Max): 8/8 | Churn Δ: 216 | Churn Cumulative: 216 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,216 @@\n+'''This script demonstrates how to build a deep residual network\n+using the Keras functional API.\n+\n+get_resne50 returns the deep residual network model (50 layers)\n+\n+Please visit Kaiming He's GitHub homepage:\n+https://github.com/KaimingHe\n+for more information.\n+\n+The related paper is\n+\"Deep Residual Learning for Image Recognition\"\n+Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n+http://arxiv.org/abs/1512.03385\n+\n+Pretrained weights were converted from Kaiming He's caffe model directly.\n+\n+For now we provide weights for the tensorflow backend only,\n+thus use 'tf' dim_ordering (e.g. input_shape=(224, 224, 3) for 224*224 color image)\n+would accelerate the computation, but we also provide weights for 'th' dim_ordering for compatibility.\n+please donwload them at:\n+http://pan.baidu.com/s/1o8pO2q2 ('th' dim ordering, For China)\n+http://pan.baidu.com/s/1pLanuTt ('tf' dim ordering, For China)\n+\n+https://drive.google.com/open?id=0B4ChsjFJvew3NVQ2U041Q0xHRHM ('th' dim ordering, For other countries)\n+https://drive.google.com/open?id=0B4ChsjFJvew3NWN5THdxcTdSWmc ('tf' dim ordering, For other countries)\n+\n+@author: BigMoyan, University of Electronic Science and Technology of China\n+'''\n+from keras.layers import merge\n+from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n+from keras.layers.core import Dense, Activation, Flatten\n+from keras.layers.normalization import BatchNormalization\n+from keras.models import Model\n+from keras.layers import Input\n+from keras.preprocessing.image import load_img, img_to_array\n+import keras.backend as K\n+import numpy as np\n+\n+# The names of layers in resnet50 are generated with the following format\n+# [type][stage][block]_branch[branch][layer]\n+# type: 'res' for conv layer, 'bn' and 'scale' for BN layer\n+# stage: from '2' to '5', current stage number\n+# block: 'a','b','c'... for different blocks in a stage\n+# branch: '1' for shortcut and '2' for main path\n+# layer: 'a','b','c'... for different layers in a block\n+\n+def identity_block(input_tensor, kernel_size, filters, stage, block):\n+    \"\"\"\n+    the identity_block is the block that has no conv layer at shortcut\n+    params:\n+        input_tensor: input tensor\n+        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n+        filters: list of integers, the nb_filters of 3 conv layer at main path\n+        stage: integer, current stage label, used for generating layer names\n+        block: 'a','b'..., current block label, used for generating layer names\n+    \"\"\"\n+    dim_ordering = K.image_dim_ordering()\n+    nb_filter1, nb_filter2, nb_filter3 = filters\n+    if dim_ordering == 'tf':\n+        axis = 3\n+    else:\n+        axis = 1\n+    conv_name_base = 'res' + str(stage) + block + '_branch'\n+    bn_name_base = 'bn' + str(stage) + block + '_branch'\n+\n+    out = Convolution2D(nb_filter1, 1, 1, dim_ordering=dim_ordering, name=conv_name_base + '2a')(input_tensor)\n+    out = BatchNormalization(axis=axis, name=bn_name_base + '2a')(out)\n+    out = Activation('relu')(out)\n+\n+    out = out = Convolution2D(nb_filter2, kernel_size, kernel_size, border_mode='same',\n+                              dim_ordering=dim_ordering, name=conv_name_base + '2b')(out)\n+    out = BatchNormalization(axis=axis, name=bn_name_base + '2b')(out)\n+    out = Activation('relu')(out)\n+\n+    out = Convolution2D(nb_filter3, 1, 1, dim_ordering=dim_ordering, name=conv_name_base + '2c')(out)\n+    out = BatchNormalization(axis=axis, name=bn_name_base + '2c')(out)\n+\n+    out = merge([out, input_tensor], mode='sum')\n+    out = Activation('relu')(out)\n+    return out\n+\n+\n+def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n+    \"\"\"\n+    conv_block is the block that has a conv layer at shortcut\n+    params:\n+        input_tensor: input tensor\n+        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n+        filters: list of integers, the nb_filters of 3 conv layer at main path\n+        stage: integer, current stage label, used for generating layer names\n+        block: 'a','b'..., current block label, used for generating layer names\n+\n+    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n+    And the shortcut should has subsample=(2,2) as well\n+    \"\"\"\n+    nb_filter1, nb_filter2, nb_filter3 = filters\n+    dim_ordering = K.image_dim_ordering()\n+    if dim_ordering == 'tf':\n+        axis = 3\n+    else:\n+        axis = 1\n+    conv_name_base = 'res' + str(stage) + block + '_branch'\n+    bn_name_base = 'bn' + str(stage) + block + '_branch'\n+\n+    out = Convolution2D(nb_filter1, 1, 1, subsample=strides,\n+                        dim_ordering=dim_ordering, name=conv_name_base + '2a')(input_tensor)\n+    out = BatchNormalization(axis=axis, name=bn_name_base + '2a')(out)\n+    out = Activation('relu')(out)\n+\n+    out = Convolution2D(nb_filter2, kernel_size, kernel_size, border_mode='same',\n+                        dim_ordering=dim_ordering, name=conv_name_base + '2b')(out)\n+    out = BatchNormalization(axis=axis, name=bn_name_base + '2b')(out)\n+    out = Activation('relu')(out)\n+\n+    out = Convolution2D(nb_filter3, 1, 1, dim_ordering=dim_ordering, name=conv_name_base + '2c')(out)\n+    out = BatchNormalization(axis=axis, name=bn_name_base + '2c')(out)\n+\n+    shortcut = Convolution2D(nb_filter3, 1, 1, subsample=strides,\n+                             dim_ordering=dim_ordering, name=conv_name_base + '1')(input_tensor)\n+    shortcut = BatchNormalization(axis=axis, name=bn_name_base + '1')(shortcut)\n+\n+    out = merge([out, shortcut], mode='sum')\n+    out = Activation('relu')(out)\n+    return out\n+\n+\n+def read_img(img_path):\n+    \"\"\"\n+    this function returns preprocessed image\n+    \"\"\"\n+    dim_ordering = K.image_dim_ordering()\n+    mean = (103.939, 116.779, 123.68)\n+    img = load_img(img_path, target_size=(224, 224))\n+    img = img_to_array(img, dim_ordering=dim_ordering)\n+\n+    # decenterize\n+    img[0, :, :] -= mean[0]\n+    img[1, :, :] -= mean[1]\n+    img[2, :, :] -= mean[2]\n+\n+    # 'RGB'->'BGR'\n+    if dim_ordering == 'th':\n+        img = img[::-1, :, :]\n+    else:\n+        img = img[:, :, ::-1]\n+\n+    # expand dim for test\n+    img = np.expand_dims(img, axis=0)\n+    return img\n+\n+\n+def get_resnet50():\n+    \"\"\"\n+    this function returns the 50-layer residual network model\n+    you should load pretrained weights if you want to use it directly.\n+    Note that since the pretrained weights is converted from caffemodel\n+    the order of channels for input image should be 'BGR' (the channel order of caffe)\n+    \"\"\"\n+    if K.image_dim_ordering() == 'tf':\n+        inp = Input(shape=(224, 224, 3))\n+        axis = 3\n+    else:\n+        inp = Input(shape=(3, 224, 224))\n+        axis = 1\n+\n+    dim_ordering = K.image_dim_ordering()\n+    out = ZeroPadding2D((3, 3), dim_ordering=dim_ordering)(inp)\n+    out = Convolution2D(64, 7, 7, subsample=(2, 2), dim_ordering=dim_ordering, name='conv1')(out)\n+    out = BatchNormalization(axis=axis, name='bn_conv1')(out)\n+    out = Activation('relu')(out)\n+    out = MaxPooling2D((3, 3), strides=(2, 2), dim_ordering=dim_ordering)(out)\n+\n+    out = conv_block(out, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n+    out = identity_block(out, 3, [64, 64, 256], stage=2, block='b')\n+    out = identity_block(out, 3, [64, 64, 256], stage=2, block='c')\n+\n+    out = conv_block(out, 3, [128, 128, 512], stage=3, block='a')\n+    out = identity_block(out, 3, [128, 128, 512], stage=3, block='b')\n+    out = identity_block(out, 3, [128, 128, 512], stage=3, block='c')\n+    out = identity_block(out, 3, [128, 128, 512], stage=3, block='d')\n+\n+    out = conv_block(out, 3, [256, 256, 1024], stage=4, block='a')\n+    out = identity_block(out, 3, [256, 256, 1024], stage=4, block='b')\n+    out = identity_block(out, 3, [256, 256, 1024], stage=4, block='c')\n+    out = identity_block(out, 3, [256, 256, 1024], stage=4, block='d')\n+    out = identity_block(out, 3, [256, 256, 1024], stage=4, block='e')\n+    out = identity_block(out, 3, [256, 256, 1024], stage=4, block='f')\n+\n+    out = conv_block(out, 3, [512, 512, 2048], stage=5, block='a')\n+    out = identity_block(out, 3, [512, 512, 2048], stage=5, block='b')\n+    out = identity_block(out, 3, [512, 512, 2048], stage=5, block='c')\n+\n+    out = AveragePooling2D((7, 7), dim_ordering=dim_ordering)(out)\n+    out = Flatten()(out)\n+    out = Dense(1000, activation='softmax', name='fc1000')(out)\n+\n+    model = Model(inp, out)\n+\n+    return model\n+\n+\n+if __name__ == '__main__':\n+    K.set_image_dim_ordering('tf')\n+    weights_file = K.image_dim_ordering() + '_dim_ordering_resnet50.h5'\n+    resnet_model = get_resnet50()\n+    resnet_model.load_weights(weights_file)\n+    test_img1 = read_img('cat.jpg')\n+    test_img2 = read_img('airplane.jpg')\n+    # you may download synset_words from address given at the begining of this file\n+    class_table = open('synset_words', 'r')\n+    lines = class_table.readlines()\n+    print \"result for test 1 is\"\n+    print lines[np.argmax(resnet_model.predict(test_img1)[0])]\n+    print \"result for test 2 is\"\n+    print lines[np.argmax(resnet_model.predict(test_img2)[0])]\n+    class_table.close()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#99f564e9724d3456fc5b48b9dcd6254c83611242", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 167 | Lines Deleted: 76 | Files Changed: 13 | Hunks: 86 | Methods Changed: 33 | Complexity Δ (Sum/Max): 17/6 | Churn Δ: 243 | Churn Cumulative: 19040 | Contributors (this commit): 95 | Commits (past 90d): 88 | Contributors (cumulative): 142 | DMM Complexity: 0.6428571428571429\n\nDIFF:\n@@ -53,8 +53,21 @@ model.compile(loss='categorical_crossentropy',\n               metrics=['accuracy'])\n \n history = model.fit(X_train, Y_train,\n-                    batch_size=batch_size, nb_epoch=nb_epoch,\n+                    batch_size=batch_size, nb_epoch=3,\n                     verbose=1, validation_data=(X_test, Y_test))\n score = model.evaluate(X_test, Y_test, verbose=0)\n print('Test score:', score[0])\n print('Test accuracy:', score[1])\n+\n+model.save('tmp.h5')\n+\n+from keras.models import load_model\n+model = load_model('tmp.h5')\n+\n+score = model.evaluate(X_test, Y_test, verbose=0)\n+print('Test score:', score[0])\n+print('Test accuracy:', score[1])\n+\n+model.fit(X_train, Y_train,\n+            batch_size=batch_size, nb_epoch=3,\n+            verbose=1, validation_data=(X_test, Y_test))\n\n@@ -1,14 +1,14 @@\n '''This script demonstrates how to build a deep residual network\n using the Keras functional API.\n \n-get_resne50 returns the deep residual network model (50 layers)\n+get_resnet50() returns the deep residual network model (50 layers)\n \n Please visit Kaiming He's GitHub homepage:\n https://github.com/KaimingHe\n for more information.\n \n The related paper is\n-\"Deep Residual Learning for Image Recognition\"\n+'Deep Residual Learning for Image Recognition'\n Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n http://arxiv.org/abs/1512.03385\n \n@@ -17,12 +17,14 @@ Pretrained weights were converted from Kaiming He's caffe model directly.\n For now we provide weights for the tensorflow backend only,\n thus use 'tf' dim_ordering (e.g. input_shape=(224, 224, 3) for 224*224 color image)\n would accelerate the computation, but we also provide weights for 'th' dim_ordering for compatibility.\n-please donwload them at:\n-http://pan.baidu.com/s/1o8pO2q2 ('th' dim ordering, For China)\n-http://pan.baidu.com/s/1pLanuTt ('tf' dim ordering, For China)\n+You can set your default dim ordering in your Keras config file at ~/.keras/keras.json\n \n-https://drive.google.com/open?id=0B4ChsjFJvew3NVQ2U041Q0xHRHM ('th' dim ordering, For other countries)\n-https://drive.google.com/open?id=0B4ChsjFJvew3NWN5THdxcTdSWmc ('tf' dim ordering, For other countries)\n+please donwload them at:\n+http://pan.baidu.com/s/1o8pO2q2 ('th' dim ordering, for China)\n+http://pan.baidu.com/s/1pLanuTt ('tf' dim ordering, for China)\n+\n+https://drive.google.com/open?id=0B4ChsjFJvew3NVQ2U041Q0xHRHM ('th' dim ordering, for other countries)\n+https://drive.google.com/open?id=0B4ChsjFJvew3NWN5THdxcTdSWmc ('tf' dim ordering, for other countries)\n \n @author: BigMoyan, University of Electronic Science and Technology of China\n '''\n@@ -44,36 +46,37 @@ import numpy as np\n # branch: '1' for shortcut and '2' for main path\n # layer: 'a','b','c'... for different layers in a block\n \n+\n def identity_block(input_tensor, kernel_size, filters, stage, block):\n-    \"\"\"\n-    the identity_block is the block that has no conv layer at shortcut\n-    params:\n+    '''The identity_block is the block that has no conv layer at shortcut\n+\n+    # Arguments\n         input_tensor: input tensor\n         kernel_size: defualt 3, the kernel size of middle conv layer at main path\n         filters: list of integers, the nb_filters of 3 conv layer at main path\n         stage: integer, current stage label, used for generating layer names\n         block: 'a','b'..., current block label, used for generating layer names\n-    \"\"\"\n+    '''\n     dim_ordering = K.image_dim_ordering()\n     nb_filter1, nb_filter2, nb_filter3 = filters\n     if dim_ordering == 'tf':\n-        axis = 3\n+        bn_axis = 3\n     else:\n-        axis = 1\n+        bn_axis = 1\n     conv_name_base = 'res' + str(stage) + block + '_branch'\n     bn_name_base = 'bn' + str(stage) + block + '_branch'\n \n     out = Convolution2D(nb_filter1, 1, 1, dim_ordering=dim_ordering, name=conv_name_base + '2a')(input_tensor)\n-    out = BatchNormalization(axis=axis, name=bn_name_base + '2a')(out)\n+    out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(out)\n     out = Activation('relu')(out)\n \n     out = out = Convolution2D(nb_filter2, kernel_size, kernel_size, border_mode='same',\n                               dim_ordering=dim_ordering, name=conv_name_base + '2b')(out)\n-    out = BatchNormalization(axis=axis, name=bn_name_base + '2b')(out)\n+    out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(out)\n     out = Activation('relu')(out)\n \n     out = Convolution2D(nb_filter3, 1, 1, dim_ordering=dim_ordering, name=conv_name_base + '2c')(out)\n-    out = BatchNormalization(axis=axis, name=bn_name_base + '2c')(out)\n+    out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(out)\n \n     out = merge([out, input_tensor], mode='sum')\n     out = Activation('relu')(out)\n@@ -81,9 +84,9 @@ def identity_block(input_tensor, kernel_size, filters, stage, block):\n \n \n def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n-    \"\"\"\n-    conv_block is the block that has a conv layer at shortcut\n-    params:\n+    '''conv_block is the block that has a conv layer at shortcut\n+\n+    # Arguments\n         input_tensor: input tensor\n         kernel_size: defualt 3, the kernel size of middle conv layer at main path\n         filters: list of integers, the nb_filters of 3 conv layer at main path\n@@ -92,32 +95,32 @@ def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2))\n \n     Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n     And the shortcut should has subsample=(2,2) as well\n-    \"\"\"\n+    '''\n     nb_filter1, nb_filter2, nb_filter3 = filters\n     dim_ordering = K.image_dim_ordering()\n     if dim_ordering == 'tf':\n-        axis = 3\n+        bn_axis = 3\n     else:\n-        axis = 1\n+        bn_axis = 1\n     conv_name_base = 'res' + str(stage) + block + '_branch'\n     bn_name_base = 'bn' + str(stage) + block + '_branch'\n \n     out = Convolution2D(nb_filter1, 1, 1, subsample=strides,\n                         dim_ordering=dim_ordering, name=conv_name_base + '2a')(input_tensor)\n-    out = BatchNormalization(axis=axis, name=bn_name_base + '2a')(out)\n+    out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(out)\n     out = Activation('relu')(out)\n \n     out = Convolution2D(nb_filter2, kernel_size, kernel_size, border_mode='same',\n                         dim_ordering=dim_ordering, name=conv_name_base + '2b')(out)\n-    out = BatchNormalization(axis=axis, name=bn_name_base + '2b')(out)\n+    out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(out)\n     out = Activation('relu')(out)\n \n     out = Convolution2D(nb_filter3, 1, 1, dim_ordering=dim_ordering, name=conv_name_base + '2c')(out)\n-    out = BatchNormalization(axis=axis, name=bn_name_base + '2c')(out)\n+    out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(out)\n \n     shortcut = Convolution2D(nb_filter3, 1, 1, subsample=strides,\n                              dim_ordering=dim_ordering, name=conv_name_base + '1')(input_tensor)\n-    shortcut = BatchNormalization(axis=axis, name=bn_name_base + '1')(shortcut)\n+    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n \n     out = merge([out, shortcut], mode='sum')\n     out = Activation('relu')(out)\n@@ -125,48 +128,46 @@ def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2))\n \n \n def read_img(img_path):\n-    \"\"\"\n-    this function returns preprocessed image\n-    \"\"\"\n+    '''This function returns a preprocessed image\n+    '''\n     dim_ordering = K.image_dim_ordering()\n     mean = (103.939, 116.779, 123.68)\n     img = load_img(img_path, target_size=(224, 224))\n     img = img_to_array(img, dim_ordering=dim_ordering)\n \n-    # decenterize\n+    if dim_ordering == 'th':\n         img[0, :, :] -= mean[0]\n         img[1, :, :] -= mean[1]\n         img[2, :, :] -= mean[2]\n-\n         # 'RGB'->'BGR'\n-    if dim_ordering == 'th':\n         img = img[::-1, :, :]\n     else:\n+        img[:, :, 0] -= mean[0]\n+        img[:, :, 1] -= mean[1]\n+        img[:, :, 2] -= mean[2]\n         img = img[:, :, ::-1]\n \n-    # expand dim for test\n     img = np.expand_dims(img, axis=0)\n     return img\n \n \n def get_resnet50():\n-    \"\"\"\n-    this function returns the 50-layer residual network model\n+    '''This function returns the 50-layer residual network model\n     you should load pretrained weights if you want to use it directly.\n     Note that since the pretrained weights is converted from caffemodel\n     the order of channels for input image should be 'BGR' (the channel order of caffe)\n-    \"\"\"\n+    '''\n     if K.image_dim_ordering() == 'tf':\n         inp = Input(shape=(224, 224, 3))\n-        axis = 3\n+        bn_axis = 3\n     else:\n         inp = Input(shape=(3, 224, 224))\n-        axis = 1\n+        bn_axis = 1\n \n     dim_ordering = K.image_dim_ordering()\n     out = ZeroPadding2D((3, 3), dim_ordering=dim_ordering)(inp)\n     out = Convolution2D(64, 7, 7, subsample=(2, 2), dim_ordering=dim_ordering, name='conv1')(out)\n-    out = BatchNormalization(axis=axis, name='bn_conv1')(out)\n+    out = BatchNormalization(axis=bn_axis, name='bn_conv1')(out)\n     out = Activation('relu')(out)\n     out = MaxPooling2D((3, 3), strides=(2, 2), dim_ordering=dim_ordering)(out)\n \n@@ -200,17 +201,19 @@ def get_resnet50():\n \n \n if __name__ == '__main__':\n-    K.set_image_dim_ordering('tf')\n     weights_file = K.image_dim_ordering() + '_dim_ordering_resnet50.h5'\n     resnet_model = get_resnet50()\n     resnet_model.load_weights(weights_file)\n-    test_img1 = read_img('cat.jpg')\n-    test_img2 = read_img('airplane.jpg')\n-    # you may download synset_words from address given at the begining of this file\n-    class_table = open('synset_words', 'r')\n+\n+    # you may download synset_words from the address given at the begining of this file\n+    class_table = open('synset_words.txt', 'r')\n     lines = class_table.readlines()\n-    print \"result for test 1 is\"\n+\n+    test_img1 = read_img('cat.jpg')\n+    print 'result for test 1 is'\n     print lines[np.argmax(resnet_model.predict(test_img1)[0])]\n-    print \"result for test 2 is\"\n+\n+    test_img2 = read_img('elephant.jpg')\n+    print 'result for test 2 is'\n     print lines[np.argmax(resnet_model.predict(test_img2)[0])]\n     class_table.close()\n\n@@ -11,6 +11,7 @@ from .common import get_uid\n from .common import cast_to_floatx\n from .common import image_dim_ordering\n from .common import set_image_dim_ordering\n+from .common import is_keras_tensor\n \n _keras_base_dir = os.path.expanduser('~')\n if not os.access(_keras_base_dir, os.W_OK):\n@@ -60,3 +61,10 @@ elif _BACKEND == 'tensorflow':\n     from .tensorflow_backend import *\n else:\n     raise Exception('Unknown backend: ' + str(_BACKEND))\n+\n+\n+def backend():\n+    '''Publicly accessible method\n+    for determining the current backend.\n+    '''\n+    return _BACKEND\n\n@@ -69,3 +69,10 @@ def get_uid(prefix=''):\n def reset_uids():\n     global _UID_PREFIXES\n     _UID_PREFIXES = defaultdict(int)\n+\n+\n+def is_keras_tensor(x):\n+    if hasattr(x, '_keras_shape'):\n+        return True\n+    else:\n+        return False\n\n@@ -696,10 +696,10 @@ class Layer(object):\n                           ' outbound layers. '\n                           'This will cause part of your model '\n                           'to be disconnected.')\n-        if not shape:\n         if hasattr(K, 'int_shape'):\n+            # auto-infered shape takes priority\n             shape = K.int_shape(input_tensor)\n-            else:\n+        elif not shape:\n             raise Exception('`set_input` needs to know the shape '\n                             'of the `input_tensor` it receives, but '\n                             'Keras was not able to infer it automatically.'\n@@ -830,6 +830,10 @@ class Layer(object):\n                             'ill-defined for the layer. ' +\n                             'Use `get_output_shape_at(node_index)` instead.')\n \n+    @property\n+    def weights(self):\n+        return self.trainable_weights + self.non_trainable_weights\n+\n     def set_weights(self, weights):\n         '''Sets the weights of the layer, from Numpy arrays.\n \n@@ -845,7 +849,7 @@ class Layer(object):\n             raise Exception('You called `set_weights(weights)` on layer \"' + self.name +\n                             '\" with a  weight list of length ' + str(len(weights)) +\n                             ', but the layer was expecting ' + str(len(params)) +\n-                            ' weights. Provided weights: ' + str(weights))\n+                            ' weights. Provided weights: ' + str(weights)[:50] + '...')\n         if not params:\n             return\n         weight_value_tuples = []\n\n@@ -254,11 +254,12 @@ class Convolution2D(Layer):\n     '''\n     def __init__(self, nb_filter, nb_row, nb_col,\n                  init='glorot_uniform', activation='linear', weights=None,\n-                 border_mode='valid', subsample=(1, 1), dim_ordering=K.image_dim_ordering(),\n+                 border_mode='valid', subsample=(1, 1), dim_ordering='default',\n                  W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n                  W_constraint=None, b_constraint=None,\n                  bias=True, **kwargs):\n-\n+        if dim_ordering == 'default':\n+            dim_ordering = K.image_dim_ordering()\n         if border_mode not in {'valid', 'same'}:\n             raise Exception('Invalid border mode for Convolution2D:', border_mode)\n         self.nb_filter = nb_filter\n@@ -526,10 +527,12 @@ class AtrousConvolution2D(Convolution2D):\n     def __init__(self, nb_filter, nb_row, nb_col,\n                  init='glorot_uniform', activation='linear', weights=None,\n                  border_mode='valid', subsample=(1, 1),\n-                 atrous_rate=(1, 1), dim_ordering=K.image_dim_ordering(),\n+                 atrous_rate=(1, 1), dim_ordering='default',\n                  W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n                  W_constraint=None, b_constraint=None,\n                  bias=True, **kwargs):\n+        if dim_ordering == 'default':\n+            dim_ordering = K.image_dim_ordering()\n \n         if border_mode not in {'valid', 'same'}:\n             raise Exception('Invalid border mode for AtrousConv2D:', border_mode)\n@@ -668,7 +671,7 @@ class SeparableConvolution2D(Layer):\n     def __init__(self, nb_filter, nb_row, nb_col,\n                  init='glorot_uniform', activation='linear', weights=None,\n                  border_mode='valid', subsample=(1, 1),\n-                 depth_multiplier=1, dim_ordering=K.image_dim_ordering(),\n+                 depth_multiplier=1, dim_ordering='default',\n                  depthwise_regularizer=None, pointwise_regularizer=None,\n                  b_regularizer=None, activity_regularizer=None,\n                  depthwise_constraint=None, pointwise_constraint=None,\n@@ -679,6 +682,9 @@ class SeparableConvolution2D(Layer):\n             raise Exception('SeparableConv2D is only available '\n                             'with TensorFlow for the time being.')\n \n+        if dim_ordering == 'default':\n+            dim_ordering = K.image_dim_ordering()\n+\n         if border_mode not in {'valid', 'same'}:\n             raise Exception('Invalid border mode for SeparableConv2D:', border_mode)\n \n@@ -879,10 +885,13 @@ class Convolution3D(Layer):\n \n     def __init__(self, nb_filter, kernel_dim1, kernel_dim2, kernel_dim3,\n                  init='glorot_uniform', activation='linear', weights=None,\n-                 border_mode='valid', subsample=(1, 1, 1), dim_ordering=K.image_dim_ordering(),\n+                 border_mode='valid', subsample=(1, 1, 1), dim_ordering='default',\n                  W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n                  W_constraint=None, b_constraint=None,\n                  bias=True, **kwargs):\n+        if dim_ordering == 'default':\n+            dim_ordering = K.image_dim_ordering()\n+\n         if border_mode not in {'valid', 'same'}:\n             raise Exception('Invalid border mode for Convolution3D:', border_mode)\n         self.nb_filter = nb_filter\n@@ -1074,7 +1083,9 @@ class UpSampling2D(Layer):\n         `(samples, upsampled_rows, upsampled_cols, channels)` if dim_ordering='tf'.\n     '''\n \n-    def __init__(self, size=(2, 2), dim_ordering=K.image_dim_ordering(), **kwargs):\n+    def __init__(self, size=(2, 2), dim_ordering='default', **kwargs):\n+        if dim_ordering == 'default':\n+            dim_ordering = K.image_dim_ordering()\n         self.size = tuple(size)\n         assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n         self.dim_ordering = dim_ordering\n@@ -1131,7 +1142,9 @@ class UpSampling3D(Layer):\n         `(samples, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)` if dim_ordering='tf'.\n     '''\n \n-    def __init__(self, size=(2, 2, 2), dim_ordering=K.image_dim_ordering(), **kwargs):\n+    def __init__(self, size=(2, 2, 2), dim_ordering='default', **kwargs):\n+        if dim_ordering == 'default':\n+            dim_ordering = K.image_dim_ordering()\n         self.size = tuple(size)\n         assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n         self.dim_ordering = dim_ordering\n@@ -1222,8 +1235,10 @@ class ZeroPadding2D(Layer):\n         (samples, depth, first_padded_axis, second_padded_axis)\n     '''\n \n-    def __init__(self, padding=(1, 1), dim_ordering=K.image_dim_ordering(), **kwargs):\n+    def __init__(self, padding=(1, 1), dim_ordering='default', **kwargs):\n         super(ZeroPadding2D, self).__init__(**kwargs)\n+        if dim_ordering == 'default':\n+            dim_ordering = K.image_dim_ordering()\n         self.padding = tuple(padding)\n         assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n         self.dim_ordering = dim_ordering\n@@ -1280,8 +1295,10 @@ class ZeroPadding3D(Layer):\n         (samples, depth, first_padded_axis, second_padded_axis, third_axis_to_pad)\n     '''\n \n-    def __init__(self, padding=(1, 1, 1), dim_ordering=K.image_dim_ordering(), **kwargs):\n+    def __init__(self, padding=(1, 1, 1), dim_ordering='default', **kwargs):\n         super(ZeroPadding3D, self).__init__(**kwargs)\n+        if dim_ordering == 'default':\n+            dim_ordering = K.image_dim_ordering()\n         self.padding = tuple(padding)\n         assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n         self.dim_ordering = dim_ordering\n\n@@ -75,7 +75,7 @@ class LocallyConnected1D(Layer):\n                  W_constraint=None, b_constraint=None,\n                  bias=True, input_dim=None, input_length=None, **kwargs):\n         if border_mode != 'valid':\n-            raise Exception('Invalid border mode for Convolution2D '\n+            raise Exception('Invalid border mode for LocallyConnected1D '\n                             '(only \"valid\" is supported):', border_mode)\n         self.nb_filter = nb_filter\n         self.filter_length = filter_length\n@@ -251,12 +251,14 @@ class LocallyConnected2D(Layer):\n     def __init__(self, nb_filter, nb_row, nb_col,\n                  init='glorot_uniform', activation='linear', weights=None,\n                  border_mode='valid', subsample=(1, 1),\n-                 dim_ordering=K.image_dim_ordering(),\n+                 dim_ordering='default',\n                  W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n                  W_constraint=None, b_constraint=None,\n                  bias=True, **kwargs):\n+        if dim_ordering == 'default':\n+            dim_ordering = K.image_dim_ordering()\n         if border_mode != 'valid':\n-            raise Exception('Invalid border mode for Convolution2D '\n+            raise Exception('Invalid border mode for LocallyConnected2D '\n                             '(only \"valid\" is supported):', border_mode)\n         self.nb_filter = nb_filter\n         self.nb_row = nb_row\n\n@@ -114,8 +114,10 @@ class _Pooling2D(Layer):\n     '''\n \n     def __init__(self, pool_size=(2, 2), strides=None, border_mode='valid',\n-                 dim_ordering=K.image_dim_ordering(), **kwargs):\n+                 dim_ordering='default', **kwargs):\n         super(_Pooling2D, self).__init__(**kwargs)\n+        if dim_ordering == 'default':\n+            dim_ordering = K.image_dim_ordering()\n         self.pool_size = tuple(pool_size)\n         if strides is None:\n             strides = self.pool_size\n@@ -199,7 +201,7 @@ class MaxPooling2D(_Pooling2D):\n     '''\n \n     def __init__(self, pool_size=(2, 2), strides=None, border_mode='valid',\n-                 dim_ordering=K.image_dim_ordering(), **kwargs):\n+                 dim_ordering='default', **kwargs):\n         super(MaxPooling2D, self).__init__(pool_size, strides, border_mode,\n                                            dim_ordering, **kwargs)\n \n@@ -241,7 +243,7 @@ class AveragePooling2D(_Pooling2D):\n     '''\n \n     def __init__(self, pool_size=(2, 2), strides=None, border_mode='valid',\n-                 dim_ordering=K.image_dim_ordering(), **kwargs):\n+                 dim_ordering='default', **kwargs):\n         super(AveragePooling2D, self).__init__(pool_size, strides, border_mode,\n                                                dim_ordering, **kwargs)\n \n@@ -257,8 +259,10 @@ class _Pooling3D(Layer):\n     '''\n \n     def __init__(self, pool_size=(2, 2, 2), strides=None, border_mode='valid',\n-                 dim_ordering=K.image_dim_ordering(), **kwargs):\n+                 dim_ordering='default', **kwargs):\n         super(_Pooling3D, self).__init__(**kwargs)\n+        if dim_ordering == 'default':\n+            dim_ordering = K.image_dim_ordering()\n         self.pool_size = tuple(pool_size)\n         if strides is None:\n             strides = self.pool_size\n@@ -344,7 +348,7 @@ class MaxPooling3D(_Pooling3D):\n     '''\n \n     def __init__(self, pool_size=(2, 2, 2), strides=None, border_mode='valid',\n-                 dim_ordering=K.image_dim_ordering(), **kwargs):\n+                 dim_ordering='default', **kwargs):\n         super(MaxPooling3D, self).__init__(pool_size, strides, border_mode,\n                                            dim_ordering, **kwargs)\n \n@@ -384,7 +388,7 @@ class AveragePooling3D(_Pooling3D):\n     '''\n \n     def __init__(self, pool_size=(2, 2, 2), strides=None, border_mode='valid',\n-                 dim_ordering=K.image_dim_ordering(), **kwargs):\n+                 dim_ordering='default', **kwargs):\n         super(AveragePooling3D, self).__init__(pool_size, strides, border_mode,\n                                                dim_ordering, **kwargs)\n \n\n@@ -337,6 +337,7 @@ class Sequential(Model):\n             self.inbound_nodes[0].output_tensors = self.outputs\n             self.inbound_nodes[0].output_shapes = [self.outputs[0]._keras_shape]\n         self.built = False\n+        self._flattened_layers = None\n \n     def call(self, x, mask=None):\n         if not self.built:\n@@ -467,7 +468,7 @@ class Sequential(Model):\n         '''\n         # support for legacy behavior\n         for layer in self.flattened_layers:\n-            nb_param = len(layer.get_weights())\n+            nb_param = len(layer.weights)\n             layer.set_weights(weights[:nb_param])\n             weights = weights[nb_param:]\n \n\n@@ -118,8 +118,10 @@ def flip_axis(x, axis):\n     return x\n \n \n-def array_to_img(x, dim_ordering=K.image_dim_ordering(), scale=True):\n+def array_to_img(x, dim_ordering='default', scale=True):\n     from PIL import Image\n+    if dim_ordering == 'default':\n+        dim_ordering = K.image_dim_ordering()\n     if dim_ordering == 'th':\n         x = x.transpose(1, 2, 0)\n     if scale:\n@@ -136,7 +138,9 @@ def array_to_img(x, dim_ordering=K.image_dim_ordering(), scale=True):\n         raise Exception('Unsupported channel number: ', x.shape[2])\n \n \n-def img_to_array(img, dim_ordering=K.image_dim_ordering()):\n+def img_to_array(img, dim_ordering='default'):\n+    if dim_ordering == 'default':\n+        dim_ordering = K.image_dim_ordering()\n     if dim_ordering not in ['th', 'tf']:\n         raise Exception('Unknown dim_ordering: ', dim_ordering)\n     # image has dim_ordering (height, width, channel)\n@@ -222,7 +226,9 @@ class ImageDataGenerator(object):\n                  horizontal_flip=False,\n                  vertical_flip=False,\n                  rescale=None,\n-                 dim_ordering=K.image_dim_ordering()):\n+                 dim_ordering='default'):\n+        if dim_ordering == 'default':\n+            dim_ordering = K.image_dim_ordering()\n         self.__dict__.update(locals())\n         self.mean = None\n         self.std = None\n@@ -446,12 +452,14 @@ class NumpyArrayIterator(Iterator):\n \n     def __init__(self, X, y, image_data_generator,\n                  batch_size=32, shuffle=False, seed=None,\n-                 dim_ordering=K.image_dim_ordering(),\n+                 dim_ordering='default',\n                  save_to_dir=None, save_prefix='', save_format='jpeg'):\n         if y is not None and len(X) != len(y):\n             raise Exception('X (images tensor) and y (labels) '\n                             'should have the same length. '\n                             'Found: X.shape = %s, y.shape = %s' % (np.asarray(X).shape, np.asarray(y).shape))\n+        if dim_ordering == 'default':\n+            dim_ordering = K.image_dim_ordering()\n         self.X = X\n         self.y = y\n         self.image_data_generator = image_data_generator\n@@ -493,10 +501,12 @@ class DirectoryIterator(Iterator):\n \n     def __init__(self, directory, image_data_generator,\n                  target_size=(256, 256), color_mode='rgb',\n-                 dim_ordering=K.image_dim_ordering,\n+                 dim_ordering='default',\n                  classes=None, class_mode='categorical',\n                  batch_size=32, shuffle=True, seed=None,\n                  save_to_dir=None, save_prefix='', save_format='jpeg'):\n+        if dim_ordering == 'default':\n+            dim_ordering = K.image_dim_ordering()\n         self.directory = directory\n         self.image_data_generator = image_data_generator\n         self.target_size = tuple(target_size)\n\n@@ -37,11 +37,12 @@ else:\n     from six.moves.urllib.request import urlretrieve\n \n \n-def get_file(fname, origin, untar=False, md5_hash=None):\n+def get_file(fname, origin, untar=False,\n+             md5_hash=None, cache_subdir='datasets'):\n     datadir_base = os.path.expanduser(os.path.join('~', '.keras'))\n     if not os.access(datadir_base, os.W_OK):\n         datadir_base = os.path.join('/tmp', '.keras')\n-    datadir = os.path.join(datadir_base, 'datasets')\n+    datadir = os.path.join(datadir_base, cache_subdir)\n     if not os.path.exists(datadir):\n         os.makedirs(datadir)\n \n\n@@ -1,6 +1,7 @@\n from __future__ import print_function\n \n from .generic_utils import get_from_module\n+from .np_utils import convert_kernel\n from ..layers import *\n from ..models import Model, Sequential, Graph\n from .. import backend as K\n@@ -97,3 +98,22 @@ def print_summary(layers, relevant_nodes=None, line_length=100, positions=[.33,\n \n     print('Total params: %s' % total_params)\n     print('_' * line_length)\n+\n+\n+def convert_all_kernels_in_model(model):\n+    # Note: SeparableConvolution not included\n+    # since only supported by TF.\n+    conv_classes = {\n+        'Convolution1D',\n+        'Convolution2D',\n+        'Convolution3D',\n+        'AtrousConvolution2D',\n+        'Deconvolution2D',\n+    }\n+    to_assign = []\n+    for layer in model.layers:\n+        if layer.__class__.__name__ in conv_classes:\n+            original_w = K.get_value(layer.W)\n+            converted_w = convert_kernel(original_w)\n+            to_assign.append((layer.W, converted_w))\n+    K.batch_set_value(to_assign)\n\n@@ -121,6 +121,7 @@ def conv_output_length(input_length, filter_size, border_mode, stride, dilation=\n         output_length = input_length - dilated_filter_size + 1\n     return (output_length + stride - 1) // stride\n \n+\n def conv_input_length(output_length, filter_size, border_mode, stride):\n     if output_length is None:\n         return None\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
