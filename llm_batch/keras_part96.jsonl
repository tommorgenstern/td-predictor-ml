{"custom_id": "keras#34d8cce6bca15c9fe2b30d5cc333db882558f789", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 156 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -3,7 +3,7 @@ with pixel-by-pixel sequential MNIST in\n \"A Simple Way to Initialize Recurrent Networks of Rectified Linear Units\"\n by Quoc V. Le, Navdeep Jaitly, Geoffrey E. Hinton\n \n-arXiv:1504.00941v2 [cs.NE] 7 Apr 201\n+arXiv:1504.00941v2 [cs.NE] 7 Apr 2015\n http://arxiv.org/pdf/1504.00941v2.pdf\n \n Optimizer is replaced with RMSprop which yields more stable and steady\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#24501d4361606d6305e9eaeadaf1cd1bbb8dfab6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 10408 | Contributors (this commit): 44 | Commits (past 90d): 31 | Contributors (cumulative): 44 | DMM Complexity: None\n\nDIFF:\n@@ -669,10 +669,10 @@ class ActivityRegularization(Layer):\n         self.l1 = l1\n         self.l2 = l2\n \n+        super(ActivityRegularization, self).__init__(**kwargs)\n         activity_regularizer = ActivityRegularizer(l1=l1, l2=l2)\n         activity_regularizer.set_layer(self)\n         self.regularizers = [activity_regularizer]\n-        super(ActivityRegularization, self).__init__(**kwargs)\n \n     def get_config(self):\n         config = {'l1': self.l1,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#32b10a8832bd0a0f3ae9e362ef9a77ee8b9b739c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 1862 | Contributors (this commit): 9 | Commits (past 90d): 34 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -84,9 +84,6 @@ def standardize_input_data(data, names, shapes=None, check_batch_dim=True,\n     # check shapes compatibility\n     if shapes:\n         for i in range(len(names)):\n-            if not i and not check_batch_dim:\n-                # skip the first axis\n-                continue\n             array = arrays[i]\n             if len(array.shape) != len(shapes[i]):\n                 raise Exception('Error when checking ' + exception_prefix +\n@@ -94,7 +91,10 @@ def standardize_input_data(data, names, shapes=None, check_batch_dim=True,\n                                 ' to have ' + str(len(shapes[i])) +\n                                 ' dimensions, but got array with shape ' +\n                                 str(array.shape))\n-            for dim, ref_dim in zip(array.shape, shapes[i]):\n+            for j, (dim, ref_dim) in enumerate(zip(array.shape, shapes[i])):\n+                if not j and not check_batch_dim:\n+                    # skip the first axis\n+                    continue\n                 if ref_dim:\n                     if ref_dim != dim:\n                         raise Exception('Error when checking ' + exception_prefix +\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1529c9c438ccc5c8f0168ebb4ae45fcf382b3c2f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 7582 | Contributors (this commit): 44 | Commits (past 90d): 22 | Contributors (cumulative): 44 | DMM Complexity: 0.0\n\nDIFF:\n@@ -11,9 +11,8 @@ from .legacy.models import Graph\n def model_from_config(config, custom_objects={}):\n     from keras.utils.layer_utils import layer_from_config\n     if isinstance(config, list):\n-        raise Exception('model_fom_config expects a dictionary.'\n-                        'To load an old-style config use the appropiate'\n-                        '`load_config` method on Sequential or Graph')\n+        raise Exception('`model_fom_config` expects a dictionary, not a list. '\n+                        'Maybe you meant to use `Sequential.from_config(config)`?')\n     return layer_from_config(config, custom_objects=custom_objects)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5156673e1761a3ef8ad0d6d355d15554a8ea10a8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 18 | Churn Cumulative: 7600 | Contributors (this commit): 44 | Commits (past 90d): 23 | Contributors (cumulative): 44 | DMM Complexity: 1.0\n\nDIFF:\n@@ -724,7 +724,7 @@ class Sequential(Model):\n         return copy.deepcopy(config)\n \n     @classmethod\n-    def from_config(cls, config):\n+    def from_config(cls, config, layer_cache={}):\n         '''Supports legacy formats\n         '''\n         from keras.utils.layer_utils import layer_from_config\n@@ -743,8 +743,20 @@ class Sequential(Model):\n                 return new_config\n             return conf\n \n+        # the model we will return\n         model = cls()\n \n+        def get_or_create_layer(layer_data):\n+            if layer_data['class_name'] == 'Sequential':\n+                return Sequential.from_config(layer_data['config'],\n+                                              layer_cache=layer_cache)\n+            name = layer_data['config'].get('name')\n+            if name in layer_cache:\n+                return layer_cache[name]\n+            layer = layer_from_config(layer_data)\n+            layer_cache[name] = layer\n+            return layer\n+\n         first_layer = config[0]\n         first_layer = normalize_legacy_config(first_layer)\n         if first_layer['class_name'] == 'Merge':\n@@ -757,11 +769,11 @@ class Sequential(Model):\n             merge = Merge.from_config(first_layer_config)\n             model.add(merge)\n         else:\n-            layer = layer_from_config(first_layer)\n+            layer = get_or_create_layer(first_layer)\n             model.add(layer)\n \n         for conf in config[1:]:\n             conf = normalize_legacy_config(conf)\n-            layer = layer_from_config(conf)\n+            layer = get_or_create_layer(conf)\n             model.add(layer)\n         return model\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1f5d5b391baf169c8bc7f963bf95dc5dfa20a6db", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2753 | Contributors (this commit): 12 | Commits (past 90d): 36 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -2358,7 +2358,7 @@ class Container(Layer):\n \n         if hasattr(self, 'optimizer'):\n             model_config['optimizer'] = self.optimizer.get_config()\n-            model_config['loss'] = self.loss.__class__.__name__\n+            model_config['loss'] = getattr(self.loss, '__name__', self.loss)\n             model_config['sample_weight_mode'] = self.sample_weight_mode\n \n         if hasattr(self, 'loss_weights'):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#33ddeb5cbee659db7a73c2f13a08ef5b066d079b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 8 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 26 | Churn Cumulative: 2779 | Contributors (this commit): 12 | Commits (past 90d): 37 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1600,7 +1600,7 @@ class Container(Layer):\n         nodes_depths = {}  # map {node: depth value}\n         layers_depths = {}  # map {layer: depth value}\n \n-        def make_node_key(node, depth):\n+        def make_node_marker(node, depth):\n             return str(id(node)) + '-' + str(depth)\n \n         def build_map_of_graph(tensor, seen_nodes=set(), depth=0,\n@@ -1624,7 +1624,7 @@ class Container(Layer):\n             node = layer.inbound_nodes[node_index]\n \n             # prevent cycles\n-            seen_nodes.add(make_node_key(node, depth))\n+            seen_nodes.add(make_node_marker(node, depth))\n \n             node_key = layer.name + '_ib-' + str(node_index)\n             # update container_nodes\n@@ -1636,11 +1636,12 @@ class Container(Layer):\n             else:\n                 nodes_depths[node] = max(depth, node_depth)\n             # update layers_depths\n-            layer_depth = layers_depths.get(layer)\n-            if layer_depth is None:\n-                layers_depths[layer] = depth\n+            previously_seen_depth = layers_depths.get(layer)\n+            if previously_seen_depth is None:\n+                current_depth = depth\n             else:\n-                layers_depths[layer] = max(depth, layer_depth)\n+                current_depth = max(depth, previously_seen_depth)\n+            layers_depths[layer] = current_depth\n \n             # propagate to all previous tensors connected to this node\n             for i in range(len(node.inbound_layers)):\n@@ -1649,9 +1650,10 @@ class Container(Layer):\n                 node_index = node.node_indices[i]\n                 tensor_index = node.tensor_indices[i]\n                 next_node = layer.inbound_nodes[node_index]\n-                node_key = make_node_key(next_node, depth + 1)\n-                if node_key not in seen_nodes:\n-                    build_map_of_graph(x, seen_nodes, depth + 1,\n+                # use node_marker to prevent cycles\n+                node_marker = make_node_marker(next_node, current_depth + 1)\n+                if node_marker not in seen_nodes:\n+                    build_map_of_graph(x, seen_nodes, current_depth + 1,\n                                        layer, node_index, tensor_index)\n \n         for x in self.outputs:\n@@ -2186,9 +2188,9 @@ class Container(Layer):\n         # the graph reconstruction process\n         created_layers = {}\n \n+        def process_layer(layer_data):\n             # iterate over saved layers, instantiate them,\n             # then call them on appropriate inputs to create graph nodes\n-        for layer_data in config['layers']:\n             layer_name = layer_data['name']\n \n             # instantiate layer\n@@ -2213,6 +2215,10 @@ class Container(Layer):\n                         layer(input_tensors[0])\n                     else:\n                         layer(input_tensors)\n+\n+        for layer_data in config['layers']:\n+            process_layer(layer_data)\n+\n         name = config.get('name')\n         input_tensors = []\n         output_tensors = []\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#88d523e01b68a87298d14dac1d2cee864bf5a22a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 40 | Lines Deleted: 15 | Files Changed: 2 | Hunks: 11 | Methods Changed: 5 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 55 | Churn Cumulative: 788 | Contributors (this commit): 9 | Commits (past 90d): 9 | Contributors (cumulative): 10 | DMM Complexity: 0.0\n\nDIFF:\n@@ -19,7 +19,13 @@ class BatchNormalization(Layer):\n                 using Theano conventions (samples, channels, rows, cols)\n                 then you should set `axis` to `1` to normalize along\n                 the channels axis.\n+                During training we use per-batch statistics to normalize\n+                the data, and during testing we use running averages\n+                computed during the training phase.\n             - 1: sample-wise normalization. This mode assumes a 2D input.\n+            - 2: feature-wise normalization, like mode 0, but\n+                using per-batch statistics to normalize the data during both\n+                testing and training.\n         axis: integer, axis along which to normalize in mode 0. For instance,\n             if your input tensor has shape (samples, channels, rows, cols),\n             set axis to 1 to normalize per feature map (channels axis).\n@@ -78,9 +84,12 @@ class BatchNormalization(Layer):\n         if self.initial_weights is not None:\n             self.set_weights(self.initial_weights)\n             del self.initial_weights\n+        self.built = True\n+        self.called_with = None\n \n     def call(self, x, mask=None):\n-        if self.mode == 0:\n+        if self.mode == 0 or self.mode == 2:\n+            assert self.built, 'Layer must be built before being called'\n             input_shape = self.input_spec[0].shape\n \n             reduction_axes = list(range(len(input_shape)))\n@@ -96,6 +105,23 @@ class BatchNormalization(Layer):\n             brodcast_std = K.reshape(std, broadcast_shape)\n             mean_update = self.momentum * self.running_mean + (1 - self.momentum) * mean\n             std_update = self.momentum * self.running_std + (1 - self.momentum) * std\n+\n+            if self.mode == 2:\n+                x_normed = (x - brodcast_mean) / (brodcast_std + self.epsilon)\n+                out = K.reshape(self.gamma, broadcast_shape) * x_normed + K.reshape(self.beta, broadcast_shape)\n+            else:\n+                # mode 0\n+                if self.called_with not in {None, x}:\n+                    raise Exception('You are attempting to share a '\n+                                    'same `BatchNormalization` layer across '\n+                                    'different data flows. '\n+                                    'This is not possible. '\n+                                    'You should use `mode=2` in '\n+                                    '`BatchNormalization`, which has '\n+                                    'a similar behavior but is shareable '\n+                                    '(see docs for a description of '\n+                                    'the behavior).')\n+                self.called_with = x\n                 self.updates = [(self.running_mean, mean_update),\n                                 (self.running_std, std_update)]\n                 x_normed = (x - brodcast_mean) / (brodcast_std + self.epsilon)\n\n@@ -24,22 +24,22 @@ def basic_batchnorm_test():\n                input_shape=(3, 4, 2))\n \n \n-def test_batchnorm_mode_0():\n+def test_batchnorm_mode_0_or_2():\n+    for mode in [0, 2]:\n         model = Sequential()\n-    norm_m0 = normalization.BatchNormalization(mode=0, input_shape=(10,))\n+        norm_m0 = normalization.BatchNormalization(mode=mode, input_shape=(10,))\n         model.add(norm_m0)\n         model.compile(loss='mse', optimizer='sgd')\n \n         # centered on 5.0, variance 10.0\n         X = np.random.normal(loc=5.0, scale=10.0, size=(1000, 10))\n         model.fit(X, X, nb_epoch=5, verbose=0)\n-    out = norm_m0.call(K.variable(X))\n-    out -= norm_m0.beta\n-    out /= norm_m0.gamma\n-    np_out = K.function([K.learning_phase()], [out])([1.])[0]\n+        out = model.predict(X)\n+        out -= K.eval(norm_m0.beta)\n+        out /= K.eval(norm_m0.gamma)\n \n-    assert_allclose(np_out.mean(), 0.0, atol=1e-1)\n-    assert_allclose(np_out.std(), 1.0, atol=1e-1)\n+        assert_allclose(out.mean(), 0.0, atol=1e-1)\n+        assert_allclose(out.std(), 1.0, atol=1e-1)\n \n \n def test_batchnorm_mode_0_convnet():\n@@ -51,13 +51,12 @@ def test_batchnorm_mode_0_convnet():\n     # centered on 5.0, variance 10.0\n     X = np.random.normal(loc=5.0, scale=10.0, size=(1000, 3, 4, 4))\n     model.fit(X, X, nb_epoch=5, verbose=0)\n-    out = norm_m0.call(K.variable(X))\n-    out -= K.reshape(norm_m0.beta, (1, 3, 1, 1))\n-    out /= K.reshape(norm_m0.gamma, (1, 3, 1, 1))\n-    np_out = K.function([K.learning_phase()], [out])([1.])[0]\n+    out = model.predict(X)\n+    out -= np.reshape(K.eval(norm_m0.beta), (1, 3, 1, 1))\n+    out /= np.reshape(K.eval(norm_m0.gamma), (1, 3, 1, 1))\n \n-    assert_allclose(np.mean(np_out, axis=(0, 2, 3)), 0.0, atol=1e-1)\n-    assert_allclose(np.std(np_out, axis=(0, 2, 3)), 1.0, atol=1e-1)\n+    assert_allclose(np.mean(out, axis=(0, 2, 3)), 0.0, atol=1e-1)\n+    assert_allclose(np.std(out, axis=(0, 2, 3)), 1.0, atol=1e-1)\n \n \n def test_batchnorm_mode_1():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#594cbed03ba6a822cd4f5db7505539d820feeece", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 20 | Churn Cumulative: 3533 | Contributors (this commit): 12 | Commits (past 90d): 44 | Contributors (cumulative): 13 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1567,12 +1567,28 @@ class Container(Layer):\n                 raise Exception('Output tensors to a ' + cls_name + ' must be '\n                                 'Keras tensors. Found: ' + str(x))\n         # build self.output_layers:\n+        masks = []\n         for x in self.outputs:\n             layer, node_index, tensor_index = x._keras_history\n             self.output_layers.append(layer)\n             self.output_layers_node_indices.append(node_index)\n             self.output_layers_tensor_indices.append(tensor_index)\n-        # build self.output_layers:\n+\n+            # also fill in the output mask cache\n+            node = layer.inbound_nodes[node_index]\n+            mask = node.output_masks[tensor_index]\n+            masks.append(mask)\n+\n+        # output mask cache\n+        mask_cache_key = ','.join([str(id(x)) for x in self.inputs])\n+        mask_cache_key += '_' + ','.join([str(id(x)) for x in masks])\n+        if len(masks) == 1:\n+            mask = masks[0]\n+        else:\n+            mask = masks\n+        self._output_mask_cache[mask_cache_key] = mask\n+\n+        # build self.input_layers:\n         for x in self.inputs:\n             layer, node_index, tensor_index = x._keras_history\n             # it's supposed to be an input layer, so only one node\n\n@@ -515,8 +515,6 @@ def test_sequential_regression():\n                            name='embed_1'))\n     branch_1.add(LSTM(32, name='lstm_1'))\n \n-    branch_1.add(BatchNormalization())\n-\n     branch_2 = Sequential(name='branch_2')\n     branch_2.add(Dense(32, input_shape=(8,), name='dense_2'))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#601f3e7cdb750a3cc9481c548327d4e09da4ea5a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 1 | Churn Cumulative: 612 | Contributors (this commit): 9 | Commits (past 90d): 7 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -64,6 +64,7 @@ class BatchNormalization(Layer):\n         self.axis = axis\n         self.momentum = momentum\n         self.initial_weights = weights\n+        if self.mode == 0:\n             self.uses_learning_phase = True\n         super(BatchNormalization, self).__init__(**kwargs)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d9db73a791cb88c223786d5f23f9a0faf0cc4204", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 276 | Contributors (this commit): 6 | Commits (past 90d): 4 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -29,7 +29,7 @@ Five digits inverted:\n from __future__ import print_function\n from keras.models import Sequential\n from keras.engine.training import slice_X\n-from keras.layers import Activation, TimeDistributedDense, RepeatVector, recurrent\n+from keras.layers import Activation, TimeDistributed, Dense, RepeatVector, recurrent\n import numpy as np\n from six.moves import range\n \n@@ -139,7 +139,7 @@ for _ in range(LAYERS):\n     model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n \n # For each of step of the output sequence, decide which character should be chosen\n-model.add(TimeDistributedDense(len(chars)))\n+model.add(TimeDistributed(Dense(len(chars))))\n model.add(Activation('softmax'))\n \n model.compile(loss='categorical_crossentropy',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9c56b91548980f9c3aa8a5a4c7b41db3ed7f76bc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 2803 | Contributors (this commit): 13 | Commits (past 90d): 39 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -1327,9 +1327,9 @@ class Merge(Layer):\n \n         if isinstance(self.mode, python_types.LambdaType):\n             if py3:\n-                mode = marshal.dumps(self.mode.__code__)\n+                mode = marshal.dumps(self.mode.__code__).decode('raw_unicode_escape')\n             else:\n-                mode = marshal.dumps(self.mode.func_code)\n+                mode = marshal.dumps(self.mode.func_code).decode('raw_unicode_escape')\n             mode_type = 'lambda'\n         elif callable(self.mode):\n             mode = self.mode.__name__\n@@ -1365,7 +1365,7 @@ class Merge(Layer):\n         if mode_type == 'function':\n             mode = globals()[config['mode']]\n         elif mode_type == 'lambda':\n-            mode = marshal.loads(config['mode'])\n+            mode = marshal.loads(config['mode'].encode('raw_unicode_escape'))\n             mode = python_types.FunctionType(mode, globals())\n         else:\n             mode = config['mode']\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#91b930298ba30394b35a52830317c29989568199", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 18 | Churn Cumulative: 2821 | Contributors (this commit): 13 | Commits (past 90d): 40 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1060,10 +1060,14 @@ class Merge(Layer):\n             and return a single tensor.\n         concat_axis: integer, axis to use in mode `concat`.\n         dot_axes: integer or tuple of integers, axes to use in mode `dot`.\n-        output_shape: shape tuple (tuple of integers), or lambda/function\n-            to compute output_shape (only if merge mode is a lambda/function).\n-            If the latter case, it should take as input a list of shape tuples\n-            (1:1 mapping to input tensors) and return a single shape tuple.\n+        output_shape: either a shape tuple (tuple of integers), or a lambda/function\n+            to compute `output_shape` (only if merge mode is a lambda/function).\n+            If the argument is a tuple,\n+            it should be expected output shape, *not* including the batch size\n+            (same convention as the `input_shape` argument in layers).\n+            If the argument is callable, it should take as input a list of shape tuples\n+            (1:1 mapping to input tensors) and return a single shape tuple, including the\n+            batch size (same convention as the `get_output_shape_for` method of layers).\n         node_indices: optional list of integers containing\n             the output node index for each input layer\n             (in case some input layers have multiple output nodes).\n@@ -1110,7 +1114,6 @@ class Merge(Layer):\n                 node_indices = [0 for _ in range(len(layers))]\n             self._arguments_validation(layers, mode,\n                                        concat_axis, dot_axes,\n-                                       output_shape,\n                                        node_indices, tensor_indices)\n             self.built = True\n             self.add_inbound_node(layers, node_indices, tensor_indices)\n@@ -1118,7 +1121,7 @@ class Merge(Layer):\n             self.built = False\n \n     def _arguments_validation(self, layers, mode, concat_axis, dot_axes,\n-                              output_shape, node_indices, tensor_indices):\n+                              node_indices, tensor_indices):\n         '''Validates user-passed arguments and raises exceptions\n         as appropriate.\n         '''\n@@ -1259,7 +1262,6 @@ class Merge(Layer):\n                 tensor_indices.append(tensor_index)\n             self._arguments_validation(layers, self.mode,\n                                        self.concat_axis, self.dot_axes,\n-                                       self._output_shape,\n                                        node_indices, tensor_indices)\n             self.built = True\n             self.add_inbound_node(layers, node_indices, tensor_indices)\n@@ -1277,7 +1279,7 @@ class Merge(Layer):\n                 output_shape = self._output_shape(input_shape)\n                 return output_shape\n             elif self._output_shape is not None:\n-                return self._output_shape\n+                return (input_shape[0],) + self._output_shape\n             else:\n                 # TODO: consider shape auto-inference with TF\n                 raise Exception('The Merge layer ' + self.name +\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#80bfec725315e68762155cd47e8e9abf45c644f8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2823 | Contributors (this commit): 13 | Commits (past 90d): 41 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -1279,7 +1279,7 @@ class Merge(Layer):\n                 output_shape = self._output_shape(input_shape)\n                 return output_shape\n             elif self._output_shape is not None:\n-                return (input_shape[0],) + self._output_shape\n+                return (input_shape[0],) + tuple(self._output_shape)\n             else:\n                 # TODO: consider shape auto-inference with TF\n                 raise Exception('The Merge layer ' + self.name +\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#882b5a1d8918c0778626c6305409c1db7d520e88", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 514 | Contributors (this commit): 7 | Commits (past 90d): 7 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -41,8 +41,8 @@ class WeightRegularizer(Regularizer):\n \n     def get_config(self):\n         return {'name': self.__class__.__name__,\n-                'l1': self.l1,\n-                'l2': self.l2}\n+                'l1': float(self.l1),\n+                'l2': float(self.l2)}\n \n \n class ActivityRegularizer(Regularizer):\n@@ -68,8 +68,8 @@ class ActivityRegularizer(Regularizer):\n \n     def get_config(self):\n         return {'name': self.__class__.__name__,\n-                'l1': self.l1,\n-                'l2': self.l2}\n+                'l1': float(self.l1),\n+                'l2': float(self.l2)}\n \n \n def l1(l=0.01):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#273f0dda9d259e574160cd660f28113c9ce2cafc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 8 | Churn Cumulative: 393 | Contributors (this commit): 10 | Commits (past 90d): 5 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -48,6 +48,12 @@ def binary_crossentropy(y_true, y_pred):\n     return K.mean(K.binary_crossentropy(y_pred, y_true), axis=-1)\n \n \n+def kullback_leibler_divergence(y_true, y_pred):\n+    y_true = K.clip(y_true, K.epsilon(), 1)\n+    y_pred = K.clip(y_pred, K.epsilon(), 1)\n+    return K.sum(y_true * K.log(y_true / y_pred), axis=-1)\n+\n+\n def poisson(y_true, y_pred):\n     return K.mean(y_pred - y_true * K.log(y_pred + K.epsilon()), axis=-1)\n \n@@ -63,6 +69,7 @@ mse = MSE = mean_squared_error\n mae = MAE = mean_absolute_error\n mape = MAPE = mean_absolute_percentage_error\n msle = MSLE = mean_squared_logarithmic_error\n+kld = KLD = kullback_leibler_divergence\n cosine = cosine_proximity\n \n from .utils.generic_utils import get_from_module\n\n@@ -12,6 +12,7 @@ allobj = [objectives.mean_squared_error,\n           objectives.squared_hinge,\n           objectives.hinge, objectives.categorical_crossentropy,\n           objectives.binary_crossentropy,\n+          objectives.kullback_leibler_divergence,\n           objectives.poisson,\n           objectives.cosine_proximity]\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#76cae0ec4463d350379e1da312386d97996040c4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 1749 | Contributors (this commit): 25 | Commits (past 90d): 29 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -782,7 +782,7 @@ def dropout(x, level, seed=None):\n     if level < 0. or level >= 1:\n         raise Exception('Dropout level must be in interval [0, 1[.')\n     if seed is None:\n-        seed = np.random.randint(10e6)\n+        seed = np.random.randint(1, 10e6)\n     rng = RandomStreams(seed=seed)\n     retain_prob = 1. - level\n     x *= rng.binomial(x.shape, p=retain_prob, dtype=x.dtype)\n@@ -1027,20 +1027,20 @@ def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n \n def random_normal(shape, mean=0.0, std=1.0, dtype=_FLOATX, seed=None):\n     if seed is None:\n-        seed = np.random.randint(10e6)\n+        seed = np.random.randint(1, 10e6)\n     rng = RandomStreams(seed=seed)\n     return rng.normal(size=shape, avg=mean, std=std, dtype=dtype)\n \n \n def random_uniform(shape, low=0.0, high=1.0, dtype=_FLOATX, seed=None):\n     if seed is None:\n-        seed = np.random.randint(10e6)\n+        seed = np.random.randint(1, 10e6)\n     rng = RandomStreams(seed=seed)\n     return rng.uniform(shape, low=low, high=high, dtype=dtype)\n \n \n def random_binomial(shape, p=0.0, dtype=_FLOATX, seed=None):\n     if seed is None:\n-        seed = np.random.randint(10e6)\n+        seed = np.random.randint(1, 10e6)\n     rng = RandomStreams(seed=seed)\n     return rng.binomial(shape, p=p, dtype=dtype)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5a71090476da28a7258ed8653bf89d831d03cf22", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 8 | Methods Changed: 5 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 15 | Churn Cumulative: 1724 | Contributors (this commit): 23 | Commits (past 90d): 11 | Contributors (cumulative): 27 | DMM Complexity: 0.4\n\nDIFF:\n@@ -192,7 +192,7 @@ class ProgbarLogger(Callback):\n             if k in logs:\n                 self.log_values.append((k, logs[k]))\n         if self.verbose:\n-            self.progbar.update(self.seen, self.log_values)\n+            self.progbar.update(self.seen, self.log_values, force=True)\n \n \n class History(Callback):\n\n@@ -34,24 +34,28 @@ def make_tuple(*args):\n \n \n class Progbar(object):\n-    def __init__(self, target, width=30, verbose=1):\n+    def __init__(self, target, width=30, verbose=1, interval=0.01):\n         '''\n             @param target: total number of steps expected\n+            @param interval: minimum visual progress update interval (in seconds)\n         '''\n         self.width = width\n         self.target = target\n         self.sum_values = {}\n         self.unique_values = []\n         self.start = time.time()\n+        self.last_update = 0\n+        self.interval = interval\n         self.total_width = 0\n         self.seen_so_far = 0\n         self.verbose = verbose\n \n-    def update(self, current, values=[]):\n+    def update(self, current, values=[], force=False):\n         '''\n             @param current: index of current step\n             @param values: list of tuples (name, value_for_last_step).\n             The progress bar will display averages for these values.\n+            @param force: force visual progress update\n         '''\n         for k, v in values:\n             if k not in self.sum_values:\n@@ -64,6 +68,9 @@ class Progbar(object):\n \n         now = time.time()\n         if self.verbose == 1:\n+            if not force and (now - self.last_update) < self.interval:\n+                return\n+\n             prev_total_width = self.total_width\n             sys.stdout.write(\"\\b\" * prev_total_width)\n             sys.stdout.write(\"\\r\")\n@@ -127,6 +134,8 @@ class Progbar(object):\n                         info += ' %.4e' % avg\n                 sys.stdout.write(info + \"\\n\")\n \n+        self.last_update = now\n+\n     def add(self, n, values=[]):\n         self.update(self.seen_so_far + n, values)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#90f441a6a0ed4334cac53760289061818a68b7c1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 14703 | Contributors (this commit): 56 | Commits (past 90d): 32 | Contributors (cumulative): 69 | DMM Complexity: None\n\nDIFF:\n@@ -972,8 +972,10 @@ class TimeDistributedDense(Layer):\n \n     # Input shape\n         3D tensor with shape `(nb_sample, time_dimension, input_dim)`.\n+\n     # Output shape\n         3D tensor with shape `(nb_sample, time_dimension, output_dim)`.\n+\n     # Arguments\n         output_dim: int > 0.\n         init: name of initialization function for the weights of the layer\n\n@@ -85,11 +85,9 @@ class Recurrent(Layer):\n             If set to \"cpu\", the RNN will use\n             an implementation that uses fewer, larger matrix products,\n             thus running faster on CPU but consuming more memory.\n-\n             If set to \"mem\", the RNN will use more matrix products,\n             but smaller ones, thus running slower (may actually be faster on GPU)\n             while consuming less memory.\n-\n             If set to \"gpu\" (LSTM/GRU only), the RNN will combine the input gate,\n             the forget gate and the output gate into a single matrix,\n             enabling more time-efficient parallelization on the GPU. Note: RNN\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#973ece98096c87871f72d17909f7c2883fa973c3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 92 | Lines Deleted: 23 | Files Changed: 4 | Hunks: 39 | Methods Changed: 19 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 115 | Churn Cumulative: 4577 | Contributors (this commit): 33 | Commits (past 90d): 28 | Contributors (cumulative): 40 | DMM Complexity: 1.0\n\nDIFF:\n@@ -9,6 +9,8 @@ from .common import set_epsilon\n from .common import set_floatx\n from .common import get_uid\n from .common import cast_to_floatx\n+from .common import image_dim_ordering\n+from .common import set_image_dim_ordering\n \n _keras_base_dir = os.path.expanduser('~')\n if not os.access(_keras_base_dir, os.W_OK):\n@@ -28,24 +30,27 @@ if os.path.exists(_config_path):\n     assert type(_epsilon) == float\n     _backend = _config.get('backend', _BACKEND)\n     assert _backend in {'theano', 'tensorflow'}\n+    _image_dim_ordering = _config.get('image_dim_ordering', image_dim_ordering())\n+    assert _image_dim_ordering in {'tf', 'th'}\n \n     set_floatx(_floatx)\n     set_epsilon(_epsilon)\n     _BACKEND = _backend\n-else:\n-    # save config file, for easy edition\n+\n+# save config file\n _config = {'floatx': floatx(),\n            'epsilon': epsilon(),\n-               'backend': _BACKEND}\n+           'backend': _BACKEND,\n+           'image_dim_ordering': image_dim_ordering()}\n with open(_config_path, 'w') as f:\n-        # add new line in order for bash 'cat' display the content correctly\n-        f.write(json.dumps(_config) + '\\n')\n+    f.write(json.dumps(_config, indent=4))\n \n if 'KERAS_BACKEND' in os.environ:\n     _backend = os.environ['KERAS_BACKEND']\n     assert _backend in {'theano', 'tensorflow'}\n     _BACKEND = _backend\n \n+# import backend\n if _BACKEND == 'theano':\n     sys.stderr.write('Using Theano backend.\\n')\n     from .theano_backend import *\n\n@@ -4,13 +4,20 @@ import numpy as np\n _FLOATX = 'float32'\n _EPSILON = 10e-8\n _UID_PREFIXES = {}\n+_IMAGE_DIM_ORDERING = 'th'\n \n \n def epsilon():\n+    '''Returns the value of the fuzz\n+    factor used in numeric expressions.\n+    '''\n     return _EPSILON\n \n \n def set_epsilon(e):\n+    '''Sets the value of the fuzz\n+    factor used in numeric expressions.\n+    '''\n     global _EPSILON\n     _EPSILON = e\n \n@@ -26,8 +33,7 @@ def set_floatx(floatx):\n     global _FLOATX\n     if floatx not in {'float16', 'float32', 'float64'}:\n         raise Exception('Unknown floatx type: ' + str(floatx))\n-    floatx = str(floatx)\n-    _FLOATX = floatx\n+    _FLOATX = str(floatx)\n \n \n def cast_to_floatx(x):\n@@ -36,6 +42,23 @@ def cast_to_floatx(x):\n     return np.asarray(x, dtype=_FLOATX)\n \n \n+def image_dim_ordering():\n+    '''Returns the image dimension ordering\n+    convention ('th' or 'tf').\n+    '''\n+    return _IMAGE_DIM_ORDERING\n+\n+\n+def set_image_dim_ordering(dim_ordering):\n+    '''Sets the value of the image dimension\n+    ordering convention ('th' or 'tf').\n+    '''\n+    global _IMAGE_DIM_ORDERING\n+    if dim_ordering not in {'tf', 'th'}:\n+        raise Exception('Unknown dim_ordering:', dim_ordering)\n+    _IMAGE_DIM_ORDERING = str(dim_ordering)\n+\n+\n def get_uid(prefix=''):\n     if prefix not in _UID_PREFIXES:\n         _UID_PREFIXES[prefix] = 1\n\n@@ -238,6 +238,9 @@ class Convolution2D(Layer):\n             applied to the bias.\n         dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n             (the depth) is at index 1, in 'tf' mode is it at index 3.\n+            It defaults to the `image_dim_ordering` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"th\".\n         bias: whether to include a bias (i.e. make the layer affine rather than linear).\n \n     # Input shape\n@@ -255,7 +258,7 @@ class Convolution2D(Layer):\n     '''\n     def __init__(self, nb_filter, nb_row, nb_col,\n                  init='glorot_uniform', activation='linear', weights=None,\n-                 border_mode='valid', subsample=(1, 1), dim_ordering='th',\n+                 border_mode='valid', subsample=(1, 1), dim_ordering=K.image_dim_ordering(),\n                  W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n                  W_constraint=None, b_constraint=None,\n                  bias=True, **kwargs):\n@@ -421,6 +424,9 @@ class Convolution3D(Layer):\n             applied to the bias.\n         dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n             (the depth) is at index 1, in 'tf' mode is it at index 4.\n+            It defaults to the `image_dim_ordering` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"th\".\n         bias: whether to include a bias (i.e. make the layer affine rather than linear).\n \n     # Input shape\n@@ -439,7 +445,7 @@ class Convolution3D(Layer):\n \n     def __init__(self, nb_filter, kernel_dim1, kernel_dim2, kernel_dim3,\n                  init='glorot_uniform', activation='linear', weights=None,\n-                 border_mode='valid', subsample=(1, 1, 1), dim_ordering='th',\n+                 border_mode='valid', subsample=(1, 1, 1), dim_ordering=K.image_dim_ordering(),\n                  W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n                  W_constraint=None, b_constraint=None,\n                  bias=True, **kwargs):\n@@ -686,7 +692,7 @@ class _Pooling2D(Layer):\n     '''\n \n     def __init__(self, pool_size=(2, 2), strides=None, border_mode='valid',\n-                 dim_ordering='th', **kwargs):\n+                 dim_ordering=K.image_dim_ordering(), **kwargs):\n         super(_Pooling2D, self).__init__(**kwargs)\n         self.pool_size = tuple(pool_size)\n         if strides is None:\n@@ -752,6 +758,9 @@ class MaxPooling2D(_Pooling2D):\n             Note: 'same' will only work with TensorFlow for the time being.\n         dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n             (the depth) is at index 1, in 'tf' mode is it at index 3.\n+            It defaults to the `image_dim_ordering` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"th\".\n \n     # Input shape\n         4D tensor with shape:\n@@ -767,7 +776,7 @@ class MaxPooling2D(_Pooling2D):\n     '''\n \n     def __init__(self, pool_size=(2, 2), strides=None, border_mode='valid',\n-                 dim_ordering='th', **kwargs):\n+                 dim_ordering=K.image_dim_ordering(), **kwargs):\n         super(MaxPooling2D, self).__init__(pool_size, strides, border_mode,\n                                            dim_ordering, **kwargs)\n \n@@ -790,6 +799,9 @@ class AveragePooling2D(_Pooling2D):\n             Note: 'same' will only work with TensorFlow for the time being.\n         dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n             (the depth) is at index 1, in 'tf' mode is it at index 3.\n+            It defaults to the `image_dim_ordering` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"th\".\n \n     # Input shape\n         4D tensor with shape:\n@@ -805,7 +817,7 @@ class AveragePooling2D(_Pooling2D):\n     '''\n \n     def __init__(self, pool_size=(2, 2), strides=None, border_mode='valid',\n-                 dim_ordering='th', **kwargs):\n+                 dim_ordering=K.image_dim_ordering(), **kwargs):\n         super(AveragePooling2D, self).__init__(pool_size, strides, border_mode,\n                                                dim_ordering, **kwargs)\n \n@@ -821,7 +833,7 @@ class _Pooling3D(Layer):\n     '''\n \n     def __init__(self, pool_size=(2, 2, 2), strides=None, border_mode='valid',\n-                 dim_ordering='th', **kwargs):\n+                 dim_ordering=K.image_dim_ordering(), **kwargs):\n         super(_Pooling3D, self).__init__(**kwargs)\n         self.pool_size = tuple(pool_size)\n         if strides is None:\n@@ -892,6 +904,9 @@ class MaxPooling3D(_Pooling3D):\n         border_mode: 'valid' or 'same'.\n         dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n             (the depth) is at index 1, in 'tf' mode is it at index 4.\n+            It defaults to the `image_dim_ordering` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"th\".\n \n     # Input shape\n         5D tensor with shape:\n@@ -907,7 +922,7 @@ class MaxPooling3D(_Pooling3D):\n     '''\n \n     def __init__(self, pool_size=(2, 2, 2), strides=None, border_mode='valid',\n-                 dim_ordering='th', **kwargs):\n+                 dim_ordering=K.image_dim_ordering(), **kwargs):\n         if K._BACKEND != 'theano':\n             raise Exception(self.__class__.__name__ +\n                             ' is currently only working with Theano backend.')\n@@ -934,6 +949,9 @@ class AveragePooling3D(_Pooling3D):\n         border_mode: 'valid' or 'same'.\n         dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n             (the depth) is at index 1, in 'tf' mode is it at index 4.\n+            It defaults to the `image_dim_ordering` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"th\".\n \n     # Input shape\n         5D tensor with shape:\n@@ -949,7 +967,7 @@ class AveragePooling3D(_Pooling3D):\n     '''\n \n     def __init__(self, pool_size=(2, 2, 2), strides=None, border_mode='valid',\n-                 dim_ordering='th', **kwargs):\n+                 dim_ordering=K.image_dim_ordering(), **kwargs):\n         if K._BACKEND != 'theano':\n             raise Exception(self.__class__.__name__ +\n                             ' is currently only working with Theano backend.')\n@@ -1003,6 +1021,9 @@ class UpSampling2D(Layer):\n         dim_ordering: 'th' or 'tf'.\n             In 'th' mode, the channels dimension (the depth)\n             is at index 1, in 'tf' mode is it at index 3.\n+            It defaults to the `image_dim_ordering` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"th\".\n \n     # Input shape\n         4D tensor with shape:\n@@ -1017,7 +1038,7 @@ class UpSampling2D(Layer):\n         `(samples, upsampled_rows, upsampled_cols, channels)` if dim_ordering='tf'.\n     '''\n \n-    def __init__(self, size=(2, 2), dim_ordering='th', **kwargs):\n+    def __init__(self, size=(2, 2), dim_ordering=K.image_dim_ordering(), **kwargs):\n         self.size = tuple(size)\n         assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n         self.dim_ordering = dim_ordering\n@@ -1059,6 +1080,9 @@ class UpSampling3D(Layer):\n         dim_ordering: 'th' or 'tf'.\n             In 'th' mode, the channels dimension (the depth)\n             is at index 1, in 'tf' mode is it at index 4.\n+            It defaults to the `image_dim_ordering` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"th\".\n \n     # Input shape\n         5D tensor with shape:\n@@ -1073,7 +1097,7 @@ class UpSampling3D(Layer):\n         `(samples, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)` if dim_ordering='tf'.\n     '''\n \n-    def __init__(self, size=(2, 2, 2), dim_ordering='th', **kwargs):\n+    def __init__(self, size=(2, 2, 2), dim_ordering=K.image_dim_ordering(), **kwargs):\n         if K._BACKEND != 'theano':\n             raise Exception(self.__class__.__name__ +\n                             ' is currently only working with Theano backend.') \n@@ -1151,6 +1175,12 @@ class ZeroPadding2D(Layer):\n         padding: tuple of int (length 2)\n             How many zeros to add at the beginning and end of\n             the 2 padding dimensions (axis 3 and 4).\n+        dim_ordering: 'th' or 'tf'.\n+            In 'th' mode, the channels dimension (the depth)\n+            is at index 1, in 'tf' mode is it at index 3.\n+            It defaults to the `image_dim_ordering` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"th\".\n \n     # Input shape\n         4D tensor with shape:\n@@ -1161,7 +1191,7 @@ class ZeroPadding2D(Layer):\n         (samples, depth, first_padded_axis, second_padded_axis)\n     '''\n \n-    def __init__(self, padding=(1, 1), dim_ordering='th', **kwargs):\n+    def __init__(self, padding=(1, 1), dim_ordering=K.image_dim_ordering(), **kwargs):\n         super(ZeroPadding2D, self).__init__(**kwargs)\n         self.padding = tuple(padding)\n         assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n@@ -1205,6 +1235,12 @@ class ZeroPadding3D(Layer):\n         padding: tuple of int (length 3)\n             How many zeros to add at the beginning and end of\n             the 3 padding dimensions (axis 3, 4 and 5).\n+        dim_ordering: 'th' or 'tf'.\n+            In 'th' mode, the channels dimension (the depth)\n+            is at index 1, in 'tf' mode is it at index 4.\n+            It defaults to the `image_dim_ordering` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"th\".\n \n     # Input shape\n         5D tensor with shape:\n@@ -1215,7 +1251,7 @@ class ZeroPadding3D(Layer):\n         (samples, depth, first_padded_axis, second_padded_axis, third_axis_to_pad)\n     '''\n \n-    def __init__(self, padding=(1, 1, 1), dim_ordering='th', **kwargs):\n+    def __init__(self, padding=(1, 1, 1), dim_ordering=K.image_dim_ordering(), **kwargs):\n         if K._BACKEND != 'theano':\n             raise Exception(self.__class__.__name__ +\n                             ' is currently only working with Theano backend.')\n\n@@ -1,4 +1,4 @@\n-'''Fairly basic set of tools for realtime data augmentation on image data.\n+'''Fairly basic set of tools for real-time data augmentation on image data.\n Can easily be extended to include new transformations,\n new preprocessing methods, etc...\n '''\n@@ -12,6 +12,8 @@ from six.moves import range\n import os\n import threading\n \n+from .. import backend as K\n+\n \n def random_rotation(x, rg, row_index=1, col_index=2, channel_index=0,\n                     fill_mode='nearest', cval=0.):\n@@ -115,7 +117,7 @@ def flip_axis(x, axis):\n     return x\n \n \n-def array_to_img(x, dim_ordering='th', scale=True):\n+def array_to_img(x, dim_ordering=K.image_dim_ordering(), scale=True):\n     from PIL import Image\n     if dim_ordering == 'th':\n         x = x.transpose(1, 2, 0)\n@@ -134,7 +136,7 @@ def array_to_img(x, dim_ordering='th', scale=True):\n \n \n # only used by tests/keras/preprocessing/test_image.py to convert PIL.Image to numpy array\n-def img_to_array(img, dim_ordering='th'):\n+def img_to_array(img, dim_ordering=K.image_dim_ordering()):\n     if dim_ordering not in ['th', 'tf']:\n         raise Exception('Unknown dim_ordering: ', dim_ordering)\n     # image has dim_ordering (height, width, channel)\n@@ -194,6 +196,9 @@ class ImageDataGenerator(object):\n         vertical_flip: whether to randomly flip images vertically.\n         dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n             (the depth) is at index 1, in 'tf' mode it is at index 3.\n+            It defaults to the `image_dim_ordering` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"th\".\n     '''\n     def __init__(self,\n                  featurewise_center=False,\n@@ -211,7 +216,7 @@ class ImageDataGenerator(object):\n                  cval=0.,\n                  horizontal_flip=False,\n                  vertical_flip=False,\n-                 dim_ordering='th'):\n+                 dim_ordering=K.image_dim_ordering()):\n         self.__dict__.update(locals())\n         self.mean = None\n         self.std = None\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
