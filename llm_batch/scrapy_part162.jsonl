{"custom_id": "scrapy#52e2eb6b703fbef709bdb5250758466e17862eee", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 55 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 4 | Methods Changed: 5 | Complexity Δ (Sum/Max): 10/6 | Churn Δ: 56 | Churn Cumulative: 309 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,5 +1,6 @@\n from cssselect import GenericTranslator, HTMLTranslator\n-from cssselect.xpath import XPathExpr, ExpressionError\n+from cssselect.xpath import _unicode_safe_getattr, XPathExpr, ExpressionError\n+from cssselect.parser import FunctionalPseudoElement\n from scrapy.selector import XPathSelector, HtmlXPathSelector, XmlXPathSelector\n \n \n@@ -57,6 +58,33 @@ class TranslatorMixin(object):\n         value = function.arguments[0].value\n         return ScrapyXPathExpr.from_xpath(xpath, attribute=value)\n \n+    def xpath_pseudo_element(self, xpath, pseudo_element):\n+        if isinstance(pseudo_element, FunctionalPseudoElement):\n+            method = 'xpath_%s_functional_pseudo_element' % (\n+                pseudo_element.name.replace('-', '_'))\n+            method = _unicode_safe_getattr(self, method, None)\n+            if not method:\n+                raise ExpressionError(\n+                    \"The functional pseudo-element ::%s() is unknown\"\n+                % pseudo_element.name)\n+            xpath = method(xpath, pseudo_element)\n+        else:\n+            method = 'xpath_%s_simple_pseudo_element' % (\n+                pseudo_element.replace('-', '_'))\n+            method = _unicode_safe_getattr(self, method, None)\n+            if not method:\n+                raise ExpressionError(\n+                    \"The pseudo-element ::%s is unknown\"\n+                    % pseudo_element)\n+            xpath = method(xpath)\n+        return xpath\n+\n+    def xpath_attribute_functional_pseudo_element(self, xpath, arguments):\n+        return self.xpath_attribute_function(xpath, arguments)\n+\n+    def xpath_text_simple_pseudo_element(self, xpath):\n+        return self.xpath_text_pseudo(xpath)\n+\n \n class ScrapyGenericTranslator(TranslatorMixin, GenericTranslator):\n     pass\n\n@@ -60,6 +60,16 @@ class TranslatorMixinTest(unittest.TestCase):\n         for css, xpath in cases:\n             self.assertEqual(self.c2x(css), xpath, css)\n \n+    def test_attribute_function2(self):\n+        cases = [\n+            ('::attribute(name)', u'descendant-or-self::*/@name'),\n+            ('a::attribute(name)', u'descendant-or-self::a/@name'),\n+            ('a ::attribute(name)', u'descendant-or-self::a/descendant-or-self::*/@name'),\n+            ('a > ::attribute(name)', u'descendant-or-self::a/*/@name'),\n+        ]\n+        for css, xpath in cases:\n+            self.assertEqual(self.c2x(css), xpath, css)\n+\n     def test_text_pseudo_element(self):\n         cases = [\n             (':text', u'descendant-or-self::text()'),\n@@ -77,6 +87,22 @@ class TranslatorMixinTest(unittest.TestCase):\n         for css, xpath in cases:\n             self.assertEqual(self.c2x(css), xpath, css)\n \n+    def test_text_pseudo_element2(self):\n+        cases = [\n+            ('::text', u'descendant-or-self::text()'),\n+            ('p::text', u'descendant-or-self::p/text()'),\n+            ('p ::text', u'descendant-or-self::p/descendant-or-self::text()'),\n+            ('#id::text', u\"descendant-or-self::*[@id = 'id']/text()\"),\n+            ('p#id::text', u\"descendant-or-self::p[@id = 'id']/text()\"),\n+            ('p#id ::text', u\"descendant-or-self::p[@id = 'id']/descendant-or-self::text()\"),\n+            ('p#id > ::text', u\"descendant-or-self::p[@id = 'id']/*/text()\"),\n+            ('p#id ~ ::text', u\"descendant-or-self::p[@id = 'id']/following-sibling::*/text()\"),\n+            ('a[href]::text', u'descendant-or-self::a[@href]/text()'),\n+            ('a[href] ::text', u'descendant-or-self::a[@href]/descendant-or-self::text()'),\n+            ('p:text, a::text', u\"descendant-or-self::p/text() | descendant-or-self::a/text()\"),\n+        ]\n+        for css, xpath in cases:\n+            self.assertEqual(self.c2x(css), xpath, css)\n \n class HTMLCSSSelectorTest(unittest.TestCase):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#ea579bca0456f4e0da656af7c39d09b793f417ef", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 60 | Lines Deleted: 56 | Files Changed: 2 | Hunks: 15 | Methods Changed: 15 | Complexity Δ (Sum/Max): 2/4 | Churn Δ: 116 | Churn Cumulative: 425 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -46,18 +46,6 @@ class TranslatorMixin(object):\n         xpath = super(TranslatorMixin, self).xpath_element(selector)\n         return ScrapyXPathExpr.from_xpath(xpath)\n \n-    def xpath_text_pseudo(self, xpath):\n-        \"\"\"Support selecting text nodes using :text pseudo-element\"\"\"\n-        return ScrapyXPathExpr.from_xpath(xpath, textnode=True)\n-\n-    def xpath_attribute_function(self, xpath, function):\n-        if function.argument_types() not in (['STRING'], ['IDENT']):\n-            raise ExpressionError(\n-                \"Expected a single string or ident for :contains(), got %r\"\n-                % function.arguments)\n-        value = function.arguments[0].value\n-        return ScrapyXPathExpr.from_xpath(xpath, attribute=value)\n-\n     def xpath_pseudo_element(self, xpath, pseudo_element):\n         if isinstance(pseudo_element, FunctionalPseudoElement):\n             method = 'xpath_%s_functional_pseudo_element' % (\n@@ -79,11 +67,17 @@ class TranslatorMixin(object):\n             xpath = method(xpath)\n         return xpath\n \n-    def xpath_attribute_functional_pseudo_element(self, xpath, arguments):\n-        return self.xpath_attribute_function(xpath, arguments)\n+    def xpath_attr_functional_pseudo_element(self, xpath, function):\n+        if function.argument_types() not in (['STRING'], ['IDENT']):\n+            raise ExpressionError(\n+                \"Expected a single string or ident for ::attr(), got %r\"\n+                % function.arguments)\n+        return ScrapyXPathExpr.from_xpath(xpath,\n+            attribute=function.arguments[0].value)\n \n     def xpath_text_simple_pseudo_element(self, xpath):\n-        return self.xpath_text_pseudo(xpath)\n+        \"\"\"Support selecting text nodes using ::text pseudo-element\"\"\"\n+        return ScrapyXPathExpr.from_xpath(xpath, textnode=True)\n \n \n class ScrapyGenericTranslator(TranslatorMixin, GenericTranslator):\n\n@@ -5,6 +5,9 @@ from twisted.trial import unittest\n from scrapy.http import TextResponse, HtmlResponse, XmlResponse\n from scrapy.selector import CSSSelector, XmlCSSSelector, HtmlCSSSelector\n from scrapy.selector.csssel import ScrapyHTMLTranslator\n+from cssselect.parser import SelectorSyntaxError\n+from cssselect.xpath import ExpressionError\n+\n \n HTMLBODY = '''\n <html>\n@@ -50,44 +53,26 @@ class TranslatorMixinTest(unittest.TestCase):\n         self.tr = self.tr_cls()\n         self.c2x = self.tr.css_to_xpath\n \n-    def test_attribute_function(self):\n+    def test_attr_function(self):\n         cases = [\n-            (':attribute(name)', u'descendant-or-self::*/@name'),\n-            ('a:attribute(name)', u'descendant-or-self::a/@name'),\n-            ('a :attribute(name)', u'descendant-or-self::a/descendant-or-self::*/@name'),\n-            ('a > :attribute(name)', u'descendant-or-self::a/*/@name'),\n+            ('::attr(name)', u'descendant-or-self::*/@name'),\n+            ('a::attr(href)', u'descendant-or-self::a/@href'),\n+            ('a ::attr(img)', u'descendant-or-self::a/descendant-or-self::*/@img'),\n+            ('a > ::attr(class)', u'descendant-or-self::a/*/@class'),\n         ]\n         for css, xpath in cases:\n             self.assertEqual(self.c2x(css), xpath, css)\n \n-    def test_attribute_function2(self):\n+    def test_attr_function_exception(self):\n         cases = [\n-            ('::attribute(name)', u'descendant-or-self::*/@name'),\n-            ('a::attribute(name)', u'descendant-or-self::a/@name'),\n-            ('a ::attribute(name)', u'descendant-or-self::a/descendant-or-self::*/@name'),\n-            ('a > ::attribute(name)', u'descendant-or-self::a/*/@name'),\n+            ('::attr(12)', ExpressionError),\n+            ('::attr(34test)', ExpressionError),\n+            ('::attr(@href)', SelectorSyntaxError),\n         ]\n-        for css, xpath in cases:\n-            self.assertEqual(self.c2x(css), xpath, css)\n+        for css, exc in cases:\n+            self.assertRaises(exc, self.c2x, css)\n \n     def test_text_pseudo_element(self):\n-        cases = [\n-            (':text', u'descendant-or-self::text()'),\n-            ('p:text', u'descendant-or-self::p/text()'),\n-            ('p :text', u'descendant-or-self::p/descendant-or-self::text()'),\n-            ('#id:text', u\"descendant-or-self::*[@id = 'id']/text()\"),\n-            ('p#id:text', u\"descendant-or-self::p[@id = 'id']/text()\"),\n-            ('p#id :text', u\"descendant-or-self::p[@id = 'id']/descendant-or-self::text()\"),\n-            ('p#id > :text', u\"descendant-or-self::p[@id = 'id']/*/text()\"),\n-            ('p#id ~ :text', u\"descendant-or-self::p[@id = 'id']/following-sibling::*/text()\"),\n-            ('a[href]:text', u'descendant-or-self::a[@href]/text()'),\n-            ('a[href] :text', u'descendant-or-self::a[@href]/descendant-or-self::text()'),\n-            ('p:text, a:text', u\"descendant-or-self::p/text() | descendant-or-self::a/text()\"),\n-        ]\n-        for css, xpath in cases:\n-            self.assertEqual(self.c2x(css), xpath, css)\n-\n-    def test_text_pseudo_element2(self):\n         cases = [\n             ('::text', u'descendant-or-self::text()'),\n             ('p::text', u'descendant-or-self::p/text()'),\n@@ -99,11 +84,36 @@ class TranslatorMixinTest(unittest.TestCase):\n             ('p#id ~ ::text', u\"descendant-or-self::p[@id = 'id']/following-sibling::*/text()\"),\n             ('a[href]::text', u'descendant-or-self::a[@href]/text()'),\n             ('a[href] ::text', u'descendant-or-self::a[@href]/descendant-or-self::text()'),\n-            ('p:text, a::text', u\"descendant-or-self::p/text() | descendant-or-self::a/text()\"),\n+            ('p::text, a::text', u\"descendant-or-self::p/text() | descendant-or-self::a/text()\"),\n         ]\n         for css, xpath in cases:\n             self.assertEqual(self.c2x(css), xpath, css)\n \n+    def test_pseudo_function_exception(self):\n+        cases = [\n+            ('::attribute(12)', ExpressionError),\n+            ('::text()', ExpressionError),\n+            ('::attr(@href)', SelectorSyntaxError),\n+        ]\n+        for css, exc in cases:\n+            self.assertRaises(exc, self.c2x, css)\n+\n+    def test_unknown_pseudo_element(self):\n+        cases = [\n+            ('::text-node', ExpressionError),\n+        ]\n+        for css, exc in cases:\n+            self.assertRaises(exc, self.c2x, css)\n+\n+    def test_unknown_pseudo_class(self):\n+        cases = [\n+            (':text', ExpressionError),\n+            (':attribute(name)', ExpressionError),\n+        ]\n+        for css, exc in cases:\n+            self.assertRaises(exc, self.c2x, css)\n+\n+\n class HTMLCSSSelectorTest(unittest.TestCase):\n \n     hcs_cls = HtmlCSSSelector\n@@ -123,21 +133,21 @@ class HTMLCSSSelectorTest(unittest.TestCase):\n \n     def test_text_pseudo_element(self):\n         self.assertEqual(self.x('#p-b2'), [u'<b id=\"p-b2\">guy</b>'])\n-        self.assertEqual(self.x('#p-b2:text'), [u'guy'])\n-        self.assertEqual(self.x('#p-b2 :text'), [u'guy'])\n-        self.assertEqual(self.x('#paragraph:text'), [u'lorem ipsum text'])\n-        self.assertEqual(self.x('#paragraph :text'), [u'lorem ipsum text', u'hi', u'there', u'guy'])\n-        self.assertEqual(self.x('p:text'), [u'lorem ipsum text'])\n-        self.assertEqual(self.x('p :text'), [u'lorem ipsum text', u'hi', u'there', u'guy'])\n+        self.assertEqual(self.x('#p-b2::text'), [u'guy'])\n+        self.assertEqual(self.x('#p-b2 ::text'), [u'guy'])\n+        self.assertEqual(self.x('#paragraph::text'), [u'lorem ipsum text'])\n+        self.assertEqual(self.x('#paragraph ::text'), [u'lorem ipsum text', u'hi', u'there', u'guy'])\n+        self.assertEqual(self.x('p::text'), [u'lorem ipsum text'])\n+        self.assertEqual(self.x('p ::text'), [u'lorem ipsum text', u'hi', u'there', u'guy'])\n \n     def test_attribute_function(self):\n-        self.assertEqual(self.x('#p-b2:attribute(id)'), [u'p-b2'])\n-        self.assertEqual(self.x('.cool-footer:attribute(class)'), [u'cool-footer'])\n-        self.assertEqual(self.x('.cool-footer :attribute(id)'), [u'foobar-div', u'foobar-span'])\n-        self.assertEqual(self.x('map[name=\"dummymap\"] :attribute(shape)'), [u'circle', u'default'])\n+        self.assertEqual(self.x('#p-b2::attr(id)'), [u'p-b2'])\n+        self.assertEqual(self.x('.cool-footer::attr(class)'), [u'cool-footer'])\n+        self.assertEqual(self.x('.cool-footer ::attr(id)'), [u'foobar-div', u'foobar-span'])\n+        self.assertEqual(self.x('map[name=\"dummymap\"] ::attr(shape)'), [u'circle', u'default'])\n \n     def test_nested_selector(self):\n-        self.assertEqual(self.hcs.select('p').select('b:text').extract(),\n+        self.assertEqual(self.hcs.select('p').select('b::text').extract(),\n                          [u'hi', u'guy'])\n         self.assertEqual(self.hcs.select('div').select('area:last-child').extract(),\n                          [u'<area shape=\"default\" id=\"area-nohref\">'])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#6d598f0d94a7b8e8f121e1149c91151ef7c47060", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 29 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -16,6 +16,7 @@ class SelectorList(list):\n     def extract(self):\n         return [x.extract() for x in self]\n \n+    @deprecated(use_instead='SelectorList.extract')\n     def extract_unquoted(self):\n         return [x.extract_unquoted() for x in self]\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#bf37f7857210cf225f4de7df31560105a26d2d2f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 414 | Files Changed: 11 | Hunks: 41 | Methods Changed: 30 | Complexity Δ (Sum/Max): -55/0 | Churn Δ: 419 | Churn Cumulative: 2883 | Contributors (this commit): 6 | Commits (past 90d): 12 | Contributors (cumulative): 25 | DMM Complexity: 0.09090909090909091\n\nDIFF:\n@@ -30,13 +30,6 @@ except ImportError:\n else:\n     optional_features.add('boto')\n \n-try:\n-    import libxml2\n-except ImportError:\n-    pass\n-else:\n-    optional_features.add('libxml2')\n-\n try:\n     import django\n except ImportError:\n\n@@ -6,6 +6,7 @@ import twisted\n import scrapy\n from scrapy.command import ScrapyCommand\n \n+\n class Command(ScrapyCommand):\n \n     def syntax(self):\n@@ -21,11 +22,7 @@ class Command(ScrapyCommand):\n \n     def run(self, args, opts):\n         if opts.verbose:\n-            try:\n             import lxml.etree\n-            except ImportError:\n-                lxml_version = libxml2_version = \"(lxml not available)\"\n-            else:\n             lxml_version = \".\".join(map(str, lxml.etree.LXML_VERSION))\n             libxml2_version = \".\".join(map(str, lxml.etree.LIBXML_VERSION))\n             print \"Scrapy  : %s\" % scrapy.__version__\n\n@@ -10,14 +10,10 @@ from scrapy import signals\n from scrapy.exceptions import NotConfigured\n from scrapy.utils.trackref import live_refs\n \n+\n class MemoryDebugger(object):\n \n     def __init__(self, stats):\n-        try:\n-            import libxml2\n-            self.libxml2 = libxml2\n-        except ImportError:\n-            self.libxml2 = None\n         self.stats = stats\n \n     @classmethod\n@@ -25,18 +21,10 @@ class MemoryDebugger(object):\n         if not crawler.settings.getbool('MEMDEBUG_ENABLED'):\n             raise NotConfigured\n         o = cls(crawler.stats)\n-        crawler.signals.connect(o.engine_started, signals.engine_started)\n         crawler.signals.connect(o.engine_stopped, signals.engine_stopped)\n         return o\n \n-    def engine_started(self):\n-        if self.libxml2:\n-            self.libxml2.debugMemory(1)\n-\n     def engine_stopped(self):\n-        if self.libxml2:\n-            self.libxml2.cleanupParser()\n-            self.stats.set_value('memdebug/libxml2_leaked_bytes', self.libxml2.debugMemory(1))\n         gc.collect()\n         self.stats.set_value('memdebug/gc_garbage_count', len(gc.garbage))\n         for cls, wdict in live_refs.iteritems():\n\n@@ -1,29 +1,7 @@\n \"\"\"\n-XPath selectors\n-\n-To select the backend explicitly use the SCRAPY_SELECTORS_BACKEND environment\n-variable.\n-\n-Two backends are currently available: lxml (default) and libxml2.\n-\n+Selectors\n \"\"\"\n-import os\n-\n-\n-backend = os.environ.get('SCRAPY_SELECTORS_BACKEND')\n-if backend == 'libxml2':\n-    from scrapy.selector.libxml2sel import *\n-elif backend == 'lxml':\n from scrapy.selector.lxmlsel import *\n-else:\n-    try:\n-        import lxml\n-    except ImportError:\n-        import libxml2\n-        from scrapy.selector.libxml2sel import *\n-    else:\n-        from scrapy.selector.lxmlsel import *\n-\n from scrapy.selector.csssel import *\n from scrapy.selector.list import SelectorList\n \n\n@@ -1,82 +0,0 @@\n-\"\"\"\n-This module contains a simple class (Libxml2Document) which provides cache and\n-garbage collection to libxml2 documents (xmlDoc).\n-\"\"\"\n-\n-import weakref\n-from scrapy.utils.trackref import object_ref\n-from scrapy import optional_features\n-\n-if 'libxml2' in optional_features:\n-    import libxml2\n-    xml_parser_options = libxml2.XML_PARSE_RECOVER + \\\n-                         libxml2.XML_PARSE_NOERROR + \\\n-                         libxml2.XML_PARSE_NOWARNING\n-\n-    html_parser_options = libxml2.HTML_PARSE_RECOVER + \\\n-                          libxml2.HTML_PARSE_NOERROR + \\\n-                          libxml2.HTML_PARSE_NOWARNING\n-\n-\n-_UTF8_ENCODINGS = set(('utf-8', 'UTF-8', 'utf8', 'UTF8'))\n-def _body_as_utf8(response):\n-    if response.encoding in _UTF8_ENCODINGS:\n-        return response.body\n-    else:\n-        return response.body_as_unicode().encode('utf-8')\n-\n-\n-def xmlDoc_from_html(response):\n-    \"\"\"Return libxml2 doc for HTMLs\"\"\"\n-    utf8body = _body_as_utf8(response) or ' '\n-    try:\n-        lxdoc = libxml2.htmlReadDoc(utf8body, response.url, 'utf-8', \\\n-            html_parser_options)\n-    except TypeError:  # libxml2 doesn't parse text with null bytes\n-        lxdoc = libxml2.htmlReadDoc(utf8body.replace(\"\\x00\", \"\"), response.url, \\\n-            'utf-8', html_parser_options)\n-    return lxdoc\n-\n-\n-def xmlDoc_from_xml(response):\n-    \"\"\"Return libxml2 doc for XMLs\"\"\"\n-    utf8body = _body_as_utf8(response) or ' '\n-    try:\n-        lxdoc = libxml2.readDoc(utf8body, response.url, 'utf-8', \\\n-            xml_parser_options)\n-    except TypeError:  # libxml2 doesn't parse text with null bytes\n-        lxdoc = libxml2.readDoc(utf8body.replace(\"\\x00\", \"\"), response.url, \\\n-            'utf-8', xml_parser_options)\n-    return lxdoc\n-\n-\n-class Libxml2Document(object_ref):\n-\n-    cache = weakref.WeakKeyDictionary()\n-    __slots__ = ['xmlDoc', 'xpathContext', '__weakref__']\n-\n-    def __new__(cls, response, factory=xmlDoc_from_html):\n-        cache = cls.cache.setdefault(response, {})\n-        if factory not in cache:\n-            obj = object_ref.__new__(cls)\n-            obj.xmlDoc = factory(response)\n-            obj.xpathContext = obj.xmlDoc.xpathNewContext()\n-            cache[factory] = obj\n-        return cache[factory]\n-\n-    def __del__(self):\n-        # we must call both cleanup functions, so we try/except all exceptions\n-        # to make sure one doesn't prevent the other from being called\n-        # this call sometimes raises a \"NoneType is not callable\" TypeError\n-        # so the try/except block silences them\n-        try:\n-            self.xmlDoc.freeDoc()\n-        except:\n-            pass\n-        try:\n-            self.xpathContext.xpathFreeContext()\n-        except:\n-            pass\n-\n-    def __str__(self):\n-        return \"<Libxml2Document %s>\" % self.xmlDoc.name\n\n@@ -1,118 +0,0 @@\n-\"\"\"\n-XPath selectors based on libxml2\n-\"\"\"\n-\n-from scrapy import optional_features\n-if 'libxml2' in optional_features:\n-    import libxml2\n-\n-from scrapy.http import TextResponse\n-from scrapy.utils.python import unicode_to_str\n-from scrapy.utils.misc import extract_regex\n-from scrapy.utils.trackref import object_ref\n-from scrapy.utils.decorator import deprecated\n-from .libxml2document import Libxml2Document, xmlDoc_from_html, xmlDoc_from_xml\n-from .list import SelectorList\n-\n-\n-__all__ = ['HtmlXPathSelector', 'XmlXPathSelector', 'XPathSelector']\n-\n-\n-class XPathSelector(object_ref):\n-\n-    __slots__ = ['doc', 'xmlNode', 'expr', '__weakref__']\n-\n-    def __init__(self, response=None, text=None, node=None, parent=None, expr=None):\n-        if parent is not None:\n-            self.doc = parent.doc\n-            self.xmlNode = node\n-        elif response:\n-            self.doc = Libxml2Document(response, factory=self._get_libxml2_doc)\n-            self.xmlNode = self.doc.xmlDoc\n-        elif text:\n-            response = TextResponse(url='about:blank', \\\n-                body=unicode_to_str(text, 'utf-8'), encoding='utf-8')\n-            self.doc = Libxml2Document(response, factory=self._get_libxml2_doc)\n-            self.xmlNode = self.doc.xmlDoc\n-        self.expr = expr\n-\n-    def select(self, xpath):\n-        if hasattr(self.xmlNode, 'xpathEval'):\n-            self.doc.xpathContext.setContextNode(self.xmlNode)\n-            xpath = unicode_to_str(xpath, 'utf-8')\n-            try:\n-                xpath_result = self.doc.xpathContext.xpathEval(xpath)\n-            except libxml2.xpathError:\n-                raise ValueError(\"Invalid XPath: %s\" % xpath)\n-            if hasattr(xpath_result, '__iter__'):\n-                return SelectorList([self.__class__(node=node, parent=self, \\\n-                    expr=xpath) for node in xpath_result])\n-            else:\n-                return SelectorList([self.__class__(node=xpath_result, \\\n-                    parent=self, expr=xpath)])\n-        else:\n-            return SelectorList([])\n-\n-    def re(self, regex):\n-        return extract_regex(regex, self.extract())\n-\n-    def extract(self):\n-        if isinstance(self.xmlNode, basestring):\n-            text = unicode(self.xmlNode, 'utf-8', errors='ignore')\n-        elif hasattr(self.xmlNode, 'serialize'):\n-            if isinstance(self.xmlNode, libxml2.xmlDoc):\n-                data = self.xmlNode.getRootElement().serialize('utf-8')\n-                text = unicode(data, 'utf-8', errors='ignore') if data else u''\n-            elif isinstance(self.xmlNode, libxml2.xmlAttr):\n-                # serialization doesn't work sometimes for xmlAttr types\n-                text = unicode(self.xmlNode.content, 'utf-8', errors='ignore')\n-            else:\n-                data = self.xmlNode.serialize('utf-8')\n-                text = unicode(data, 'utf-8', errors='ignore') if data else u''\n-        else:\n-            try:\n-                text = unicode(self.xmlNode, 'utf-8', errors='ignore')\n-            except TypeError:  # catched when self.xmlNode is a float - see tests\n-                text = unicode(self.xmlNode)\n-        return text\n-\n-    def extract_unquoted(self):\n-        \"\"\"Get unescaped contents from the text node (no entities, no CDATA)\"\"\"\n-        # TODO: this function should be deprecated. but what would be use instead?\n-        if self.select('self::text()'):\n-            return unicode(self.xmlNode.getContent(), 'utf-8', errors='ignore')\n-        else:\n-            return u''\n-\n-    def register_namespace(self, prefix, uri):\n-        self.doc.xpathContext.xpathRegisterNs(prefix, uri)\n-\n-    def _get_libxml2_doc(self, response):\n-        return xmlDoc_from_html(response)\n-\n-    def __nonzero__(self):\n-        return bool(self.extract())\n-\n-    def __str__(self):\n-        data = repr(self.extract()[:40])\n-        return \"<%s xpath=%r data=%s>\" % (type(self).__name__, self.expr, data)\n-\n-    __repr__ = __str__\n-\n-    @deprecated(use_instead='XPathSelector.select')\n-    def __call__(self, xpath):\n-        return self.select(xpath)\n-\n-    @deprecated(use_instead='XPathSelector.select')\n-    def x(self, xpath):\n-        return self.select(xpath)\n-\n-\n-class XmlXPathSelector(XPathSelector):\n-    __slots__ = ()\n-    _get_libxml2_doc = staticmethod(xmlDoc_from_xml)\n-\n-\n-class HtmlXPathSelector(XPathSelector):\n-    __slots__ = ()\n-    _get_libxml2_doc = staticmethod(xmlDoc_from_html)\n\n@@ -1,20 +0,0 @@\n-from twisted.trial import unittest\n-\n-from scrapy.utils.test import libxml2debug\n-from scrapy import optional_features\n-\n-\n-class Libxml2Test(unittest.TestCase):\n-\n-    skip = 'libxml2' not in optional_features\n-\n-    @libxml2debug\n-    def test_libxml2_bug_2_6_27(self):\n-        # this test will fail in version 2.6.27 but passes on 2.6.29+\n-        import libxml2\n-        html = \"<td>1<b>2</b>3</td>\"\n-        node = libxml2.htmlParseDoc(html, 'utf-8')\n-        result = [str(r) for r in node.xpathEval('//text()')]\n-        self.assertEquals(result, ['1', '2', '3'])\n-        node.freeDoc()\n-\n\n@@ -10,7 +10,7 @@ from twisted.trial import unittest\n from scrapy.http import TextResponse, HtmlResponse, XmlResponse\n from scrapy.selector import XmlXPathSelector, HtmlXPathSelector, \\\n     XPathSelector\n-from scrapy.utils.test import libxml2debug\n+\n \n class XPathSelectorTestCase(unittest.TestCase):\n \n@@ -18,7 +18,6 @@ class XPathSelectorTestCase(unittest.TestCase):\n     hxs_cls = HtmlXPathSelector\n     xxs_cls = XmlXPathSelector\n \n-    @libxml2debug\n     def test_selector_simple(self):\n         \"\"\"Simple selector tests\"\"\"\n         body = \"<p><input name='a'value='1'/><input name='b'value='2'/></p>\"\n@@ -43,14 +42,12 @@ class XPathSelectorTestCase(unittest.TestCase):\n         self.assertEqual([x.extract() for x in xpath.select(\"concat(//input[@name='a']/@value, //input[@name='b']/@value)\")],\n                          [u'12'])\n \n-    @libxml2debug\n     def test_selector_unicode_query(self):\n         body = u\"<p><input name='\\xa9' value='1'/></p>\"\n         response = TextResponse(url=\"http://example.com\", body=body, encoding='utf8')\n         xpath = self.hxs_cls(response)\n         self.assertEqual(xpath.select(u'//input[@name=\"\\xa9\"]/@value').extract(), [u'1'])\n \n-    @libxml2debug\n     def test_selector_same_type(self):\n         \"\"\"Test XPathSelector returning the same type in x() method\"\"\"\n         text = '<p>test<p>'\n@@ -59,7 +56,6 @@ class XPathSelectorTestCase(unittest.TestCase):\n         assert isinstance(self.hxs_cls(text=text).select(\"//p\")[0],\n                           self.hxs_cls)\n \n-    @libxml2debug\n     def test_selector_boolean_result(self):\n         body = \"<p><input name='a'value='1'/><input name='b'value='2'/></p>\"\n         response = TextResponse(url=\"http://example.com\", body=body)\n@@ -67,7 +63,6 @@ class XPathSelectorTestCase(unittest.TestCase):\n         self.assertEquals(xs.select(\"//input[@name='a']/@name='a'\").extract(), [u'1'])\n         self.assertEquals(xs.select(\"//input[@name='a']/@name='n'\").extract(), [u'0'])\n \n-    @libxml2debug\n     def test_selector_xml_html(self):\n         \"\"\"Test that XML and HTML XPathSelector's behave differently\"\"\"\n \n@@ -80,7 +75,6 @@ class XPathSelectorTestCase(unittest.TestCase):\n         self.assertEqual(self.hxs_cls(text=text).select(\"//div\").extract(),\n                          [u'<div><img src=\"a.jpg\"><p>Hello</p></div>'])\n \n-    @libxml2debug\n     def test_selector_nested(self):\n         \"\"\"Nested selector tests\"\"\"\n         body = \"\"\"<body>\n@@ -109,13 +103,11 @@ class XPathSelectorTestCase(unittest.TestCase):\n         self.assertEqual(divtwo.select(\"./li\").extract(),\n                          [])\n \n-    @libxml2debug\n     def test_dont_strip(self):\n         hxs = self.hxs_cls(text='<div>fff: <a href=\"#\">zzz</a></div>')\n         self.assertEqual(hxs.select(\"//text()\").extract(),\n             [u'fff: ', u'zzz'])\n \n-    @libxml2debug\n     def test_selector_namespaces_simple(self):\n         body = \"\"\"\n         <test xmlns:somens=\"http://scrapy.org\">\n@@ -131,7 +123,6 @@ class XPathSelectorTestCase(unittest.TestCase):\n         self.assertEqual(x.select(\"//somens:a/text()\").extract(),\n                          [u'take this'])\n \n-    @libxml2debug\n     def test_selector_namespaces_multiple(self):\n         body = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n <BrowseNode xmlns=\"http://webservices.amazon.com/AWSECommerceService/2005-10-05\"\n@@ -155,7 +146,6 @@ class XPathSelectorTestCase(unittest.TestCase):\n         self.assertEqual(x.select(\"//p:SecondTestTag\").select(\"./xmlns:price/text()\")[0].extract(), '90')\n         self.assertEqual(x.select(\"//p:SecondTestTag/xmlns:material/text()\").extract()[0], 'iron')\n \n-    @libxml2debug\n     def test_selector_re(self):\n         body = \"\"\"<div>Name: Mary\n                     <ul>\n@@ -177,14 +167,12 @@ class XPathSelectorTestCase(unittest.TestCase):\n         self.assertEqual(x.select(\"//ul/li\").re(\"Age: (\\d+)\"),\n                          [\"10\", \"20\"])\n \n-    @libxml2debug\n     def test_selector_re_intl(self):\n         body = \"\"\"<div>Evento: cumplea\\xc3\\xb1os</div>\"\"\"\n         response = HtmlResponse(url=\"http://example.com\", body=body, encoding='utf-8')\n         x = self.hxs_cls(response)\n         self.assertEqual(x.select(\"//div\").re(\"Evento: (\\w+)\"), [u'cumplea\\xf1os'])\n \n-    @libxml2debug\n     def test_selector_over_text(self):\n         hxs = self.hxs_cls(text='<root>lala</root>')\n         self.assertEqual(hxs.extract(),\n@@ -199,7 +187,6 @@ class XPathSelectorTestCase(unittest.TestCase):\n                          [u'<root>lala</root>'])\n \n \n-    @libxml2debug\n     def test_selector_invalid_xpath(self):\n         response = XmlResponse(url=\"http://example.com\", body=\"<html></html>\")\n         x = self.hxs_cls(response)\n@@ -213,7 +200,6 @@ class XPathSelectorTestCase(unittest.TestCase):\n         else:\n             raise AssertionError(\"A invalid XPath does not raise an exception\")\n \n-    @libxml2debug\n     def test_http_header_encoding_precedence(self):\n         # u'\\xa3'     = pound symbol in unicode\n         # u'\\xc2\\xa3' = pound symbol in utf-8\n@@ -233,14 +219,12 @@ class XPathSelectorTestCase(unittest.TestCase):\n         self.assertEquals(x.select(\"//span[@id='blank']/text()\").extract(),\n                           [u'\\xa3'])\n \n-    @libxml2debug\n     def test_empty_bodies(self):\n         # shouldn't raise errors\n         r1 = TextResponse('http://www.example.com', body='')\n         self.hxs_cls(r1).select('//text()').extract()\n         self.xxs_cls(r1).select('//text()').extract()\n \n-    @libxml2debug\n     def test_null_bytes(self):\n         # shouldn't raise errors\n         r1 = TextResponse('http://www.example.com', \\\n@@ -249,7 +233,6 @@ class XPathSelectorTestCase(unittest.TestCase):\n         self.hxs_cls(r1).select('//text()').extract()\n         self.xxs_cls(r1).select('//text()').extract()\n \n-    @libxml2debug\n     def test_badly_encoded_body(self):\n         # \\xe9 alone isn't valid utf8 sequence\n         r1 = TextResponse('http://www.example.com', \\\n@@ -258,7 +241,6 @@ class XPathSelectorTestCase(unittest.TestCase):\n         self.hxs_cls(r1).select('//text()').extract()\n         self.xxs_cls(r1).select('//text()').extract()\n \n-    @libxml2debug\n     def test_select_on_unevaluable_nodes(self):\n         r = self.hxs_cls(text=u'<span class=\"big\">some text</span>')\n         # Text node\n@@ -270,7 +252,6 @@ class XPathSelectorTestCase(unittest.TestCase):\n         self.assertEquals(x1.extract(), [u'big'])\n         self.assertEquals(x1.select('.//text()').extract(), [])\n \n-    @libxml2debug\n     def test_select_on_text_nodes(self):\n         r = self.hxs_cls(text=u'<div><b>Options:</b>opt1</div><div><b>Other</b>opt2</div>')\n         x1 = r.select(\"//div/descendant::text()[preceding-sibling::b[contains(text(), 'Options')]]\")\n@@ -279,7 +260,6 @@ class XPathSelectorTestCase(unittest.TestCase):\n         x1 = r.select(\"//div/descendant::text()/preceding-sibling::b[contains(text(), 'Options')]\")\n         self.assertEquals(x1.extract(), [u'<b>Options:</b>'])\n \n-    @libxml2debug\n     def test_nested_select_on_text_nodes(self):\n         # FIXME: does not work with lxml backend [upstream]\n         r = self.hxs_cls(text=u'<div><b>Options:</b>opt1</div><div><b>Other</b>opt2</div>')\n@@ -289,7 +269,6 @@ class XPathSelectorTestCase(unittest.TestCase):\n         self.assertEquals(x2.extract(), [u'<b>Options:</b>'])\n     test_nested_select_on_text_nodes.skip = True\n \n-    @libxml2debug\n     def test_weakref_slots(self):\n         \"\"\"Check that classes are using slots and are weak-referenceable\"\"\"\n         for cls in [self.xs_cls, self.hxs_cls, self.xxs_cls]:\n\n@@ -1,98 +0,0 @@\n-\"\"\"\n-Selectors tests, specific for libxml2 backend\n-\"\"\"\n-\n-from twisted.trial import unittest\n-from scrapy import optional_features\n-\n-\n-from scrapy.http import TextResponse, HtmlResponse, XmlResponse\n-from scrapy.selector.libxml2sel import XmlXPathSelector, HtmlXPathSelector, \\\n-    XPathSelector\n-from scrapy.selector.libxml2document import Libxml2Document\n-from scrapy.utils.test import libxml2debug\n-from scrapy.tests import test_selector\n-\n-\n-class Libxml2XPathSelectorTestCase(test_selector.XPathSelectorTestCase):\n-\n-    xs_cls = XPathSelector\n-    hxs_cls = HtmlXPathSelector\n-    xxs_cls = XmlXPathSelector\n-\n-    skip = 'libxml2' not in optional_features\n-\n-    @libxml2debug\n-    def test_null_bytes(self):\n-        hxs = HtmlXPathSelector(text='<root>la\\x00la</root>')\n-        self.assertEqual(hxs.extract(),\n-                         u'<html><body><root>lala</root></body></html>')\n-\n-        xxs = XmlXPathSelector(text='<root>la\\x00la</root>')\n-        self.assertEqual(xxs.extract(),\n-                         u'<root>lala</root>')\n-\n-    @libxml2debug\n-    def test_unquote(self):\n-        xmldoc = '\\n'.join((\n-            '<root>',\n-            '  lala',\n-            '  <node>',\n-            '    blabla&amp;more<!--comment-->a<b>test</b>oh',\n-            '    <![CDATA[lalalal&ppppp<b>PPPP</b>ppp&amp;la]]>',\n-            '  </node>',\n-            '  pff',\n-            '</root>'))\n-        xxs = XmlXPathSelector(text=xmldoc)\n-\n-        self.assertEqual(xxs.extract_unquoted(), u'')\n-\n-        self.assertEqual(xxs.select('/root').extract_unquoted(), [u''])\n-        self.assertEqual(xxs.select('/root/text()').extract_unquoted(), [\n-            u'\\n  lala\\n  ',\n-            u'\\n  pff\\n'])\n-\n-        self.assertEqual(xxs.select('//*').extract_unquoted(), [u'', u'', u''])\n-        self.assertEqual(xxs.select('//text()').extract_unquoted(), [\n-            u'\\n  lala\\n  ',\n-            u'\\n    blabla&more',\n-            u'a',\n-            u'test',\n-            u'oh\\n    ',\n-            u'lalalal&ppppp<b>PPPP</b>ppp&amp;la',\n-            u'\\n  ',\n-            u'\\n  pff\\n'])\n-\n-\n-class Libxml2DocumentTest(unittest.TestCase):\n-\n-    skip = 'libxml2' not in optional_features\n-\n-    @libxml2debug\n-    def test_response_libxml2_caching(self):\n-        r1 = HtmlResponse('http://www.example.com', body='<html><head></head><body></body></html>')\n-        r2 = r1.copy()\n-\n-        doc1 = Libxml2Document(r1)\n-        doc2 = Libxml2Document(r1)\n-        doc3 = Libxml2Document(r2)\n-\n-        # make sure it's cached\n-        assert doc1 is doc2\n-        assert doc1.xmlDoc is doc2.xmlDoc\n-        assert doc1 is not doc3\n-        assert doc1.xmlDoc is not doc3.xmlDoc\n-\n-        # don't leave libxml2 documents in memory to avoid wrong libxml2 leaks reports\n-        del doc1, doc2, doc3\n-\n-    @libxml2debug\n-    def test_null_char(self):\n-        # make sure bodies with null char ('\\x00') don't raise a TypeError exception\n-        self.body_content = 'test problematic \\x00 body'\n-        response = TextResponse('http://example.com/catalog/product/blabla-123',\n-                            headers={'Content-Type': 'text/plain; charset=utf-8'}, body=self.body_content)\n-        Libxml2Document(response)\n-\n-if __name__ == \"__main__\":\n-    unittest.main()\n\n@@ -39,6 +39,7 @@ class LxmlXPathSelectorTestCase(test_selector.XPathSelectorTestCase):\n         xxs.remove_namespaces()\n         self.assertEqual(len(xxs.select(\"//link/@type\")), 2)\n \n+\n class Libxml2DocumentTest(unittest.TestCase):\n \n     def test_caching(self):\n@@ -53,9 +54,6 @@ class Libxml2DocumentTest(unittest.TestCase):\n         assert doc1 is doc2\n         assert doc1 is not doc3\n \n-        # don't leave documents in memory to avoid wrong libxml2 leaks reports\n-        del doc1, doc2, doc3\n-\n     def test_null_char(self):\n         # make sure bodies with null char ('\\x00') don't raise a TypeError exception\n         self.body_content = 'test problematic \\x00 body'\n\n@@ -6,30 +6,6 @@ import os\n \n from twisted.trial.unittest import SkipTest\n \n-def libxml2debug(testfunction):\n-    \"\"\"Decorator for debugging libxml2 memory leaks inside a function.\n-    \n-    We've found libxml2 memory leaks are something very weird, and can happen\n-    sometimes depending on the order where tests are run. So this decorator\n-    enables libxml2 memory leaks debugging only when the environment variable\n-    LIBXML2_DEBUGLEAKS is set.\n-\n-    \"\"\"\n-    try:\n-        import libxml2\n-    except ImportError:\n-        return testfunction\n-    def newfunc(*args, **kwargs):\n-        libxml2.debugMemory(1)\n-        testfunction(*args, **kwargs)\n-        libxml2.cleanupParser()\n-        leaked_bytes = libxml2.debugMemory(0) \n-        assert leaked_bytes == 0, \"libxml2 memory leak detected: %d bytes\" % leaked_bytes\n-\n-    if 'LIBXML2_DEBUGLEAKS' in os.environ:\n-        return newfunc\n-    else:\n-        return testfunction\n \n def assert_aws_environ():\n     \"\"\"Asserts the current environment is suitable for running AWS testsi.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c3d28cc4128d2eb387c5c89e36fb5f4261546bd6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 280 | Lines Deleted: 230 | Files Changed: 7 | Hunks: 17 | Methods Changed: 49 | Complexity Δ (Sum/Max): 9/43 | Churn Δ: 510 | Churn Cumulative: 1645 | Contributors (this commit): 5 | Commits (past 90d): 14 | Contributors (cumulative): 16 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,17 +1,6 @@\n \"\"\"\n Selectors\n \"\"\"\n+from scrapy.selector.unified import *\n from scrapy.selector.lxmlsel import *\n from scrapy.selector.csssel import *\n-from scrapy.selector.list import SelectorList\n-\n-\n-class XPathSelectorList(SelectorList):\n-\n-    def __init__(self, *a, **kw):\n-        import warnings\n-        from scrapy.exceptions import ScrapyDeprecationWarning\n-        warnings.warn('XPathSelectorList is deprecated, use '\n-                      'scrapy.selector.SelectorList instead',\n-                      category=ScrapyDeprecationWarning, stacklevel=1)\n-        super(XPathSelectorList, self).__init__(*a, **kw)\n\n@@ -1,110 +1,16 @@\n-from cssselect import GenericTranslator, HTMLTranslator\n-from cssselect.xpath import _unicode_safe_getattr, XPathExpr, ExpressionError\n-from cssselect.parser import FunctionalPseudoElement\n-from scrapy.selector import XPathSelector, HtmlXPathSelector, XmlXPathSelector\n+from .unified import Selector\n \n \n-class ScrapyXPathExpr(XPathExpr):\n+class CSSSelector(Selector):\n \n-    textnode = False\n-    attribute = None\n-\n-    @classmethod\n-    def from_xpath(cls, xpath, textnode=False, attribute=None):\n-        x = cls(path=xpath.path, element=xpath.element, condition=xpath.condition)\n-        x.textnode = textnode\n-        x.attribute = attribute\n-        return x\n-\n-    def __str__(self):\n-        path = super(ScrapyXPathExpr, self).__str__()\n-        if self.textnode:\n-            if path == '*':\n-                path = 'text()'\n-            elif path.endswith('::*/*'):\n-                path = path[:-3] + 'text()'\n-            else:\n-                path += '/text()'\n-\n-        if self.attribute is not None:\n-            if path.endswith('::*/*'):\n-                path = path[:-2]\n-            path += '/@%s' % self.attribute\n-\n-        return path\n-\n-    def join(self, combiner, other):\n-        super(ScrapyXPathExpr, self).join(combiner, other)\n-        self.textnode = other.textnode\n-        self.attribute = other.attribute\n-        return self\n-\n-\n-class TranslatorMixin(object):\n-\n-    def xpath_element(self, selector):\n-        xpath = super(TranslatorMixin, self).xpath_element(selector)\n-        return ScrapyXPathExpr.from_xpath(xpath)\n-\n-    def xpath_pseudo_element(self, xpath, pseudo_element):\n-        if isinstance(pseudo_element, FunctionalPseudoElement):\n-            method = 'xpath_%s_functional_pseudo_element' % (\n-                pseudo_element.name.replace('-', '_'))\n-            method = _unicode_safe_getattr(self, method, None)\n-            if not method:\n-                raise ExpressionError(\n-                    \"The functional pseudo-element ::%s() is unknown\"\n-                % pseudo_element.name)\n-            xpath = method(xpath, pseudo_element)\n-        else:\n-            method = 'xpath_%s_simple_pseudo_element' % (\n-                pseudo_element.replace('-', '_'))\n-            method = _unicode_safe_getattr(self, method, None)\n-            if not method:\n-                raise ExpressionError(\n-                    \"The pseudo-element ::%s is unknown\"\n-                    % pseudo_element)\n-            xpath = method(xpath)\n-        return xpath\n-\n-    def xpath_attr_functional_pseudo_element(self, xpath, function):\n-        if function.argument_types() not in (['STRING'], ['IDENT']):\n-            raise ExpressionError(\n-                \"Expected a single string or ident for ::attr(), got %r\"\n-                % function.arguments)\n-        return ScrapyXPathExpr.from_xpath(xpath,\n-            attribute=function.arguments[0].value)\n-\n-    def xpath_text_simple_pseudo_element(self, xpath):\n-        \"\"\"Support selecting text nodes using ::text pseudo-element\"\"\"\n-        return ScrapyXPathExpr.from_xpath(xpath, textnode=True)\n-\n-\n-class ScrapyGenericTranslator(TranslatorMixin, GenericTranslator):\n-    pass\n-\n-\n-class ScrapyHTMLTranslator(TranslatorMixin, HTMLTranslator):\n-    pass\n-\n-\n-class CSSSelectorMixin(object):\n+    default_contenttype = 'html'\n \n     def select(self, css):\n-        xpath = self._css2xpath(css)\n-        return super(CSSSelectorMixin, self).select(xpath)\n-\n-    def _css2xpath(self, css):\n-        return self.translator.css_to_xpath(css)\n+        return self.css(css)\n \n \n-class CSSSelector(CSSSelectorMixin, XPathSelector):\n-    translator = ScrapyHTMLTranslator()\n+HtmlCSSSelector = CSSSelector\n \n \n-class HtmlCSSSelector(CSSSelectorMixin, HtmlXPathSelector):\n-    translator = ScrapyHTMLTranslator()\n-\n-\n-class XmlCSSSelector(CSSSelectorMixin, XmlXPathSelector):\n-    translator = ScrapyGenericTranslator()\n+class XmlCSSSelector(CSSSelector):\n+    default_contenttype = 'xml'\n\n@@ -0,0 +1,88 @@\n+from cssselect import GenericTranslator, HTMLTranslator\n+from cssselect.xpath import _unicode_safe_getattr, XPathExpr, ExpressionError\n+from cssselect.parser import FunctionalPseudoElement\n+\n+\n+class ScrapyXPathExpr(XPathExpr):\n+\n+    textnode = False\n+    attribute = None\n+\n+    @classmethod\n+    def from_xpath(cls, xpath, textnode=False, attribute=None):\n+        x = cls(path=xpath.path, element=xpath.element, condition=xpath.condition)\n+        x.textnode = textnode\n+        x.attribute = attribute\n+        return x\n+\n+    def __str__(self):\n+        path = super(ScrapyXPathExpr, self).__str__()\n+        if self.textnode:\n+            if path == '*':\n+                path = 'text()'\n+            elif path.endswith('::*/*'):\n+                path = path[:-3] + 'text()'\n+            else:\n+                path += '/text()'\n+\n+        if self.attribute is not None:\n+            if path.endswith('::*/*'):\n+                path = path[:-2]\n+            path += '/@%s' % self.attribute\n+\n+        return path\n+\n+    def join(self, combiner, other):\n+        super(ScrapyXPathExpr, self).join(combiner, other)\n+        self.textnode = other.textnode\n+        self.attribute = other.attribute\n+        return self\n+\n+\n+class TranslatorMixin(object):\n+\n+    def xpath_element(self, selector):\n+        xpath = super(TranslatorMixin, self).xpath_element(selector)\n+        return ScrapyXPathExpr.from_xpath(xpath)\n+\n+    def xpath_pseudo_element(self, xpath, pseudo_element):\n+        if isinstance(pseudo_element, FunctionalPseudoElement):\n+            method = 'xpath_%s_functional_pseudo_element' % (\n+                pseudo_element.name.replace('-', '_'))\n+            method = _unicode_safe_getattr(self, method, None)\n+            if not method:\n+                raise ExpressionError(\n+                    \"The functional pseudo-element ::%s() is unknown\"\n+                % pseudo_element.name)\n+            xpath = method(xpath, pseudo_element)\n+        else:\n+            method = 'xpath_%s_simple_pseudo_element' % (\n+                pseudo_element.replace('-', '_'))\n+            method = _unicode_safe_getattr(self, method, None)\n+            if not method:\n+                raise ExpressionError(\n+                    \"The pseudo-element ::%s is unknown\"\n+                    % pseudo_element)\n+            xpath = method(xpath)\n+        return xpath\n+\n+    def xpath_attr_functional_pseudo_element(self, xpath, function):\n+        if function.argument_types() not in (['STRING'], ['IDENT']):\n+            raise ExpressionError(\n+                \"Expected a single string or ident for ::attr(), got %r\"\n+                % function.arguments)\n+        return ScrapyXPathExpr.from_xpath(xpath,\n+            attribute=function.arguments[0].value)\n+\n+    def xpath_text_simple_pseudo_element(self, xpath):\n+        \"\"\"Support selecting text nodes using ::text pseudo-element\"\"\"\n+        return ScrapyXPathExpr.from_xpath(xpath, textnode=True)\n+\n+\n+class ScrapyGenericTranslator(TranslatorMixin, GenericTranslator):\n+    pass\n+\n+\n+class ScrapyHTMLTranslator(TranslatorMixin, HTMLTranslator):\n+    pass\n+\n\n@@ -1,25 +0,0 @@\n-from scrapy.utils.python import flatten\n-from scrapy.utils.decorator import deprecated\n-\n-\n-class SelectorList(list):\n-\n-    def __getslice__(self, i, j):\n-        return self.__class__(list.__getslice__(self, i, j))\n-\n-    def select(self, xpath):\n-        return self.__class__(flatten([x.select(xpath) for x in self]))\n-\n-    def re(self, regex):\n-        return flatten([x.re(regex) for x in self])\n-\n-    def extract(self):\n-        return [x.extract() for x in self]\n-\n-    @deprecated(use_instead='SelectorList.extract')\n-    def extract_unquoted(self):\n-        return [x.extract_unquoted() for x in self]\n-\n-    @deprecated(use_instead='SelectorList.select')\n-    def x(self, xpath):\n-        return self.select(xpath)\n\n@@ -1,106 +1,34 @@\n \"\"\"\n XPath selectors based on lxml\n \"\"\"\n-\n-from lxml import etree\n-\n-from scrapy.utils.misc import extract_regex\n-from scrapy.utils.trackref import object_ref\n-from scrapy.utils.python import unicode_to_str\n-from scrapy.utils.decorator import deprecated\n-from scrapy.http import TextResponse\n-from .lxmldocument import LxmlDocument\n-from .list import SelectorList\n+from .unified import Selector, SelectorList\n \n \n-__all__ = ['HtmlXPathSelector', 'XmlXPathSelector', 'XPathSelector']\n+__all__ = ['HtmlXPathSelector', 'XmlXPathSelector', 'XPathSelector',\n+           'XPathSelectorList']\n \n \n-class XPathSelector(object_ref):\n-\n-    __slots__ = ['response', 'text', 'namespaces', '_expr', '_root', '__weakref__']\n-    _parser = etree.HTMLParser\n-    _tostring_method = 'html'\n-\n-    def __init__(self, response=None, text=None, namespaces=None, _root=None, _expr=None):\n-        if text is not None:\n-            response = TextResponse(url='about:blank', encoding='utf-8',\n-                                    body=unicode_to_str(text, 'utf-8'))\n-        if response is not None:\n-            _root = LxmlDocument(response, self._parser)\n-\n-        self.namespaces = namespaces\n-        self.response = response\n-        self._root = _root\n-        self._expr = _expr\n-\n-    def select(self, xpath):\n-        try:\n-            xpathev = self._root.xpath\n-        except AttributeError:\n-            return SelectorList([])\n-\n-        try:\n-            result = xpathev(xpath, namespaces=self.namespaces)\n-        except etree.XPathError:\n-            raise ValueError(\"Invalid XPath: %s\" % xpath)\n-\n-        if type(result) is not list:\n-            result = [result]\n-\n-        result = [self.__class__(_root=x, _expr=xpath, namespaces=self.namespaces)\n-                  for x in result]\n-        return SelectorList(result)\n-\n-    def re(self, regex):\n-        return extract_regex(regex, self.extract())\n-\n-    def extract(self):\n-        try:\n-            return etree.tostring(self._root, method=self._tostring_method, \\\n-                encoding=unicode, with_tail=False)\n-        except (AttributeError, TypeError):\n-            if self._root is True:\n-                return u'1'\n-            elif self._root is False:\n-                return u'0'\n-            else:\n-                return unicode(self._root)\n-\n-    def register_namespace(self, prefix, uri):\n-        if self.namespaces is None:\n-            self.namespaces = {}\n-        self.namespaces[prefix] = uri\n-\n-    def remove_namespaces(self):\n-        for el in self._root.iter('*'):\n-            if el.tag.startswith('{'):\n-                el.tag = el.tag.split('}', 1)[1]\n-            # loop on element attributes also\n-            for an in el.attrib.keys():\n-                if an.startswith('{'):\n-                    el.attrib[an.split('}', 1)[1]] = el.attrib.pop(an)\n-\n-    def __nonzero__(self):\n-        return bool(self.extract())\n-\n-    def __str__(self):\n-        data = repr(self.extract()[:40])\n-        return \"<%s xpath=%r data=%s>\" % (type(self).__name__, self._expr, data)\n-    __repr__ = __str__\n-\n-    @deprecated(use_instead='XPathSelector.extract')\n-    def extract_unquoted(self):\n-        return self.extract()\n+class XPathSelector(Selector):\n+    __slots__ = ()\n+    default_contenttype = 'xml'\n \n \n class XmlXPathSelector(XPathSelector):\n     __slots__ = ()\n-    _parser = etree.XMLParser\n-    _tostring_method = 'xml'\n+    default_contenttype = 'xml'\n \n \n class HtmlXPathSelector(XPathSelector):\n     __slots__ = ()\n-    _parser = etree.HTMLParser\n-    _tostring_method = 'html'\n+    default_contenttype = 'html'\n+\n+\n+class XPathSelectorList(SelectorList):\n+\n+    def __init__(self, *a, **kw):\n+        import warnings\n+        from scrapy.exceptions import ScrapyDeprecationWarning\n+        warnings.warn('XPathSelectorList is deprecated, use '\n+                      'scrapy.selector.SelectorList instead',\n+                      category=ScrapyDeprecationWarning, stacklevel=1)\n+        super(XPathSelectorList, self).__init__(*a, **kw)\n\n@@ -0,0 +1,164 @@\n+\"\"\"\n+XPath selectors based on lxml\n+\"\"\"\n+\n+from lxml import etree\n+\n+from scrapy.utils.misc import extract_regex\n+from scrapy.utils.trackref import object_ref\n+from scrapy.utils.python import unicode_to_str, flatten\n+from scrapy.utils.decorator import deprecated\n+from scrapy.http import HtmlResponse, XmlResponse\n+from .lxmldocument import LxmlDocument\n+from .csstranslator import ScrapyHTMLTranslator, ScrapyGenericTranslator\n+\n+\n+__all__ = ['Selector', 'SelectorList']\n+\n+_ctgroup = {\n+    'html': {'_parser': etree.HTMLParser,\n+             '_csstranslator': ScrapyHTMLTranslator(),\n+             '_tostring_method': 'html'},\n+    'xml': {'_parser': etree.XMLParser,\n+            '_csstranslator': ScrapyGenericTranslator(),\n+            '_tostring_method': 'xml'},\n+}\n+\n+\n+def _ct(response, ct):\n+    if ct is None:\n+        return 'xml' if isinstance(response, XmlResponse) else 'html'\n+    elif ct in ('xml', 'html'):\n+        return ct\n+    else:\n+        raise ValueError('Invalid contenttype: %s' % ct)\n+\n+\n+def _response_from_text(text, ct):\n+    rt = XmlResponse if ct == 'xml' else HtmlResponse\n+    return rt(url='about:blank', encoding='utf-8',\n+              body=unicode_to_str(text, 'utf-8'))\n+\n+\n+class Selector(object_ref):\n+\n+    __slots__ = ['response', 'text', 'namespaces', 'contenttype', '_expr', '_root',\n+                 '__weakref__', '_parser', '_csstranslator', '_tostring_method']\n+\n+    default_contenttype = None\n+\n+    def __init__(self, response=None, text=None, namespaces=None, contenttype=None,\n+                 _root=None, _expr=None):\n+\n+        self.contenttype = ct = self.default_contenttype or _ct(contenttype)\n+        self._parser = _ctgroup[ct]['_parser']\n+        self._csstranslator = _ctgroup[ct]['_csstranslator']\n+        self._tostring_method = _ctgroup[ct]['_tostring_method']\n+\n+        if text is not None:\n+            response = _response_from_text(text, ct)\n+\n+        if response is not None:\n+            _root = LxmlDocument(response, self._parser)\n+\n+        self.response = response\n+        self.namespaces = namespaces\n+        self._root = _root\n+        self._expr = _expr\n+\n+    def xpath(self, query):\n+        try:\n+            xpathev = self._root.xpath\n+        except AttributeError:\n+            return SelectorList([])\n+\n+        try:\n+            result = xpathev(query, namespaces=self.namespaces)\n+        except etree.XPathError:\n+            raise ValueError(\"Invalid XPath: %s\" % query)\n+\n+        if type(result) is not list:\n+            result = [result]\n+\n+        result = [self.__class__(_root=x, _expr=query,\n+                                 namespaces=self.namespaces,\n+                                 contenttype=self.contenttype)\n+                  for x in result]\n+        return SelectorList(result)\n+\n+    def css(self, query):\n+        return self.xpath(self._css2xpath(query))\n+\n+    def _css2xpath(self, query):\n+        return self._csstranslator.css_to_xpath(query)\n+\n+    def re(self, regex):\n+        return extract_regex(regex, self.extract())\n+\n+    def extract(self):\n+        try:\n+            return etree.tostring(self._root,\n+                                  method=self._tostring_method,\n+                                  encoding=unicode,\n+                                  with_tail=False)\n+        except (AttributeError, TypeError):\n+            if self._root is True:\n+                return u'1'\n+            elif self._root is False:\n+                return u'0'\n+            else:\n+                return unicode(self._root)\n+\n+    def register_namespace(self, prefix, uri):\n+        if self.namespaces is None:\n+            self.namespaces = {}\n+        self.namespaces[prefix] = uri\n+\n+    def remove_namespaces(self):\n+        for el in self._root.iter('*'):\n+            if el.tag.startswith('{'):\n+                el.tag = el.tag.split('}', 1)[1]\n+            # loop on element attributes also\n+            for an in el.attrib.keys():\n+                if an.startswith('{'):\n+                    el.attrib[an.split('}', 1)[1]] = el.attrib.pop(an)\n+\n+    def __nonzero__(self):\n+        return bool(self.extract())\n+\n+    def __str__(self):\n+        data = repr(self.extract()[:40])\n+        return \"<%s xpath=%r data=%s>\" % (type(self).__name__, self._expr, data)\n+    __repr__ = __str__\n+\n+    # Deprecated api\n+    @deprecated(use_instead='.xpath()')\n+    def select(self, xpath):\n+        return self.xpath(xpath)\n+\n+    @deprecated(use_instead='.extract()')\n+    def extract_unquoted(self):\n+        return self.extract()\n+\n+\n+class SelectorList(list):\n+\n+    def __getslice__(self, i, j):\n+        return self.__class__(list.__getslice__(self, i, j))\n+\n+    def select(self, xpath):\n+        return self.__class__(flatten([x.select(xpath) for x in self]))\n+\n+    def re(self, regex):\n+        return flatten([x.re(regex) for x in self])\n+\n+    def extract(self):\n+        return [x.extract() for x in self]\n+\n+    @deprecated(use_instead='SelectorList.extract')\n+    def extract_unquoted(self):\n+        return [x.extract_unquoted() for x in self]\n+\n+    @deprecated(use_instead='SelectorList.select')\n+    def x(self, xpath):\n+        return self.select(xpath)\n\n@@ -4,7 +4,7 @@ Selector tests for cssselect backend\n from twisted.trial import unittest\n from scrapy.http import TextResponse, HtmlResponse, XmlResponse\n from scrapy.selector import CSSSelector, XmlCSSSelector, HtmlCSSSelector\n-from scrapy.selector.csssel import ScrapyHTMLTranslator\n+from scrapy.selector.csstranslator import ScrapyHTMLTranslator\n from cssselect.parser import SelectorSyntaxError\n from cssselect.xpath import ExpressionError\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
