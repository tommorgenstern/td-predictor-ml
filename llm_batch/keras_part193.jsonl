{"custom_id": "keras#219d6ee5be04fc12307fb9d21227185966f53063", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 21 | Churn Cumulative: 5487 | Contributors (this commit): 56 | Commits (past 90d): 27 | Contributors (cumulative): 65 | DMM Complexity: 1.0\n\nDIFF:\n@@ -444,13 +444,12 @@ def _weighted_masked_objective(fn):\n             #  to the number of unmasked samples.\n             score_array /= K.mean(mask)\n \n+        # apply sample weighting\n+        if weights is not None:\n             # reduce score_array to same ndim as weight array\n             ndim = K.ndim(score_array)\n             weight_ndim = K.ndim(weights)\n             score_array = K.mean(score_array, axis=list(range(weight_ndim, ndim)))\n-\n-        # apply sample weighting\n-        if weights is not None:\n             score_array *= weights\n             score_array /= K.mean(K.cast(K.not_equal(weights, 0), K.floatx()))\n         return K.mean(score_array)\n\n@@ -6,7 +6,9 @@ import scipy.sparse as sparse\n \n from keras.layers import Dense, Dropout\n from keras.engine.topology import Input\n-from keras.engine.training import Model, _check_loss_and_target_compatibility\n+from keras.engine.training import Model\n+from keras.engine.training import _check_loss_and_target_compatibility\n+from keras.engine.training import _weighted_masked_objective\n from keras.models import Sequential\n from keras import backend as K\n from keras.utils import Sequence\n@@ -27,6 +29,18 @@ class RandomSequence(Sequence):\n             np.random.random((self.batch_size, 3))]\n \n \n+@keras_test\n+def test_weighted_masked_objective():\n+    a = Input(shape=(3,), name='input_a')\n+\n+    # weighted_masked_objective\n+    def mask_dummy(y_true=None, y_pred=None, weight=None):\n+        return K.placeholder(y_true.shape)\n+\n+    weighted_function = _weighted_masked_objective(K.categorical_crossentropy)\n+    weighted_function(a, a, None)\n+\n+\n @keras_test\n def test_model_methods():\n     a = Input(shape=(3,), name='input_a')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1b539993aa751c0a3c48f67f27c1210bfe152fba", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 7 | Methods Changed: 2 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 34 | Churn Cumulative: 5521 | Contributors (this commit): 56 | Commits (past 90d): 29 | Contributors (cumulative): 65 | DMM Complexity: 0.8181818181818182\n\nDIFF:\n@@ -387,21 +387,25 @@ def _slice_arrays(arrays, start=None, stop=None):\n     # Returns\n         A slice of the array(s).\n     \"\"\"\n-    if isinstance(arrays, list):\n+    if arrays is None:\n+        return [None]\n+    elif isinstance(arrays, list):\n         if hasattr(start, '__len__'):\n             # hdf5 datasets only support list objects as indices\n             if hasattr(start, 'shape'):\n                 start = start.tolist()\n-            return [x[start] for x in arrays]\n+            return [None if x is None else x[start] for x in arrays]\n         else:\n-            return [x[start:stop] for x in arrays]\n+            return [None if x is None else x[start:stop] for x in arrays]\n     else:\n         if hasattr(start, '__len__'):\n             if hasattr(start, 'shape'):\n                 start = start.tolist()\n             return arrays[start]\n-        else:\n+        elif hasattr(start, '__getitem__'):\n             return arrays[start:stop]\n+        else:\n+            return [None]\n \n \n def _weighted_masked_objective(fn):\n\n@@ -9,6 +9,7 @@ from keras.engine.topology import Input\n from keras.engine.training import Model\n from keras.engine.training import _check_loss_and_target_compatibility\n from keras.engine.training import _weighted_masked_objective\n+from keras.engine.training import _slice_arrays\n from keras.models import Sequential\n from keras import backend as K\n from keras.utils import Sequence\n@@ -29,6 +30,27 @@ class RandomSequence(Sequence):\n             np.random.random((self.batch_size, 3))]\n \n \n+@keras_test\n+def test_slice_arrays():\n+    input_a = np.random.random((10, 3))\n+    _slice_arrays(None)\n+    _slice_arrays(input_a, 0)\n+    _slice_arrays(input_a, 0, 1)\n+    _slice_arrays(input_a, stop=2)\n+    input_a = [None, [1, 1], None, [1, 1]]\n+    _slice_arrays(input_a, 0)\n+    _slice_arrays(input_a, 0, 1)\n+    _slice_arrays(input_a, stop=2)\n+    input_a = [None]\n+    _slice_arrays(input_a, 0)\n+    _slice_arrays(input_a, 0, 1)\n+    _slice_arrays(input_a, stop=2)\n+    input_a = None\n+    _slice_arrays(input_a, 0)\n+    _slice_arrays(input_a, 0, 1)\n+    _slice_arrays(input_a, stop=2)\n+\n+\n @keras_test\n def test_weighted_masked_objective():\n     a = Input(shape=(3,), name='input_a')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#60cf7ca6b28967b9ab9b41a959520532028eeaa5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 8 | Files Changed: 7 | Hunks: 8 | Methods Changed: 10 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 21081 | Contributors (this commit): 132 | Commits (past 90d): 70 | Contributors (cumulative): 178 | DMM Complexity: None\n\nDIFF:\n@@ -17,7 +17,7 @@ def load_data(path='imdb.npz', num_words=None, skip_top=0,\n         num_words: max number of words to include. Words are ranked\n             by how often they occur (in the training set) and only\n             the most frequent words are kept\n-        skip_top: skip the top N most frequently occuring words\n+        skip_top: skip the top N most frequently occurring words\n             (which may not be informative).\n         maxlen: truncate sequences after this length.\n         seed: random seed for sample shuffling.\n\n@@ -18,7 +18,7 @@ def load_data(path='reuters.npz', num_words=None, skip_top=0,\n         num_words: max number of words to include. Words are ranked\n             by how often they occur (in the training set) and only\n             the most frequent words are kept\n-        skip_top: skip the top N most frequently occuring words\n+        skip_top: skip the top N most frequently occurring words\n             (which may not be informative).\n         maxlen: truncate sequences after this length.\n         test_split: Fraction of the dataset to be used as test data.\n\n@@ -744,7 +744,7 @@ class Layer(object):\n                                     str(mask))\n             # masking not explicitly supported: return None as mask\n             return None\n-        # if masking is explictly supported, by default\n+        # if masking is explicitly supported, by default\n         # carry over the input mask\n         return mask\n \n@@ -1529,7 +1529,7 @@ class Container(Layer):\n         # every time the Container is called on a set on input tensors,\n         # we compute the output tensors,\n         # output masks and output shapes in one pass,\n-        # then cache them here. When of of these output is queried later,\n+        # then cache them here. When one of these output is queried later,\n         # we retrieve it from there instead of recomputing it.\n         self._output_mask_cache = {}\n         self._output_tensor_cache = {}\n\n@@ -137,7 +137,7 @@ class BatchNormalization(Layer):\n \n         def normalize_inference():\n             if needs_broadcasting:\n-                # In this case we must explictly broadcast all parameters.\n+                # In this case we must explicitly broadcast all parameters.\n                 broadcast_moving_mean = K.reshape(self.moving_mean,\n                                                   broadcast_shape)\n                 broadcast_moving_variance = K.reshape(self.moving_variance,\n\n@@ -207,7 +207,7 @@ def load_model(filepath, custom_objects=None, compile=True):\n             obj: object, dict, or list.\n \n         # Returns\n-            The same structure, where occurences\n+            The same structure, where occurrences\n                 of a custom object name have been replaced\n                 with the custom object.\n         \"\"\"\n\n@@ -127,7 +127,7 @@ def skipgrams(sequence, vocabulary_size,\n             of word indices (integers). If using a `sampling_table`,\n             word indices are expected to match the rank\n             of the words in a reference dataset (e.g. 10 would encode\n-            the 10-th most frequently occuring token).\n+            the 10-th most frequently occurring token).\n             Note that index 0 is expected to be a non-word and will be skipped.\n         vocabulary_size: int. maximum possible word index + 1\n         window_size: int. actually half-window.\n\n@@ -886,7 +886,7 @@ class TestBackend(object):\n         check_two_tensor_operation('binary_crossentropy', (4, 2), (4, 2), BACKENDS, from_logits=True)\n         # cross_entropy call require the label is a valid probability distribution,\n         # otherwise it is garbage in garbage out...\n-        # due to the algo difference, we can't guranteen CNTK has the same result on the garbage input.\n+        # due to the algo difference, we can't guarantee CNTK has the same result on the garbage input.\n         # so create a seperate test case for valid lable input\n         check_two_tensor_operation('categorical_crossentropy', (4, 2), (4, 2), [KTH, KTF], from_logits=True)\n         check_cross_entropy_with_valid_probability_distribution()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fb97b6e0fa4d7338c6bf6cd722f3d67b117e76e4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 39 | Lines Deleted: 11 | Files Changed: 2 | Hunks: 8 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 50 | Churn Cumulative: 5571 | Contributors (this commit): 56 | Commits (past 90d): 31 | Contributors (cumulative): 65 | DMM Complexity: 1.0\n\nDIFF:\n@@ -200,7 +200,7 @@ def _standardize_sample_weights(sample_weight, output_names):\n                                                 'sample_weight')\n \n \n-def _check_array_lengths(inputs, targets, weights):\n+def _check_array_lengths(inputs, targets, weights=None):\n     \"\"\"Does user input validation for numpy arrays.\n \n     # Arguments\n@@ -211,29 +211,34 @@ def _check_array_lengths(inputs, targets, weights):\n     # Raises\n         ValueError: in case of incorrectly formatted data.\n     \"\"\"\n-    x_lengths = [x.shape[0] for x in inputs]\n-    y_lengths = [y.shape[0] for y in targets]\n-    w_lengths = [w.shape[0] for w in weights]\n-    set_x = set(x_lengths)\n+    def set_of_lengths(x):\n+        # return a set with the variation between\n+        # different shapes, with None => 0\n+        if x is None:\n+            return {0}\n+        else:\n+            return set([0 if y is None else y.shape[0] for y in x])\n+\n+    set_x = set_of_lengths(inputs)\n+    set_y = set_of_lengths(targets)\n+    set_w = set_of_lengths(weights)\n     if len(set_x) > 1:\n         raise ValueError('All input arrays (x) should have '\n                          'the same number of samples. Got array shapes: ' +\n                          str([x.shape for x in inputs]))\n-    set_y = set(y_lengths)\n     if len(set_y) > 1:\n         raise ValueError('All target arrays (y) should have '\n                          'the same number of samples. Got array shapes: ' +\n                          str([y.shape for y in targets]))\n-    set_w = set(w_lengths)\n-    if len(set_w) > 1:\n-        raise ValueError('All sample_weight arrays should have '\n-                         'the same number of samples. Got array shapes: ' +\n-                         str([w.shape for w in weights]))\n     if set_x and set_y and list(set_x)[0] != list(set_y)[0]:\n         raise ValueError('Input arrays should have '\n                          'the same number of samples as target arrays. '\n                          'Found ' + str(list(set_x)[0]) + ' input samples '\n                          'and ' + str(list(set_y)[0]) + ' target samples.')\n+    if len(set_w) > 1:\n+        raise ValueError('All sample_weight arrays should have '\n+                         'the same number of samples. Got array shapes: ' +\n+                         str([w.shape for w in weights]))\n     if set_y and set_w and list(set_y)[0] != list(set_w)[0]:\n         raise ValueError('Sample_weight arrays should have '\n                          'the same number of samples as target arrays. Got ' +\n\n@@ -7,8 +7,10 @@ import scipy.sparse as sparse\n from keras.layers import Dense, Dropout\n from keras.engine.topology import Input\n from keras.engine.training import Model\n+from keras.engine.training import Model\n from keras.engine.training import _check_loss_and_target_compatibility\n from keras.engine.training import _weighted_masked_objective\n+from keras.engine.training import _check_array_lengths\n from keras.engine.training import _slice_arrays\n from keras.models import Sequential\n from keras import backend as K\n@@ -30,6 +32,27 @@ class RandomSequence(Sequence):\n             np.random.random((self.batch_size, 3))]\n \n \n+@keras_test\n+def test_check_array_lengths():\n+    _check_array_lengths(None, None, None)\n+    a_np = np.random.random((4, 3, 3))\n+    _check_array_lengths(a_np, a_np, a_np)\n+    _check_array_lengths([a_np, a_np], [a_np, a_np], [a_np, a_np])\n+    _check_array_lengths([None], [None], [None])\n+\n+    b_np = np.random.random((3, 4))\n+    with pytest.raises(ValueError):\n+        _check_array_lengths(a_np, None, None)\n+    with pytest.raises(ValueError):\n+        _check_array_lengths(a_np, a_np, None)\n+    with pytest.raises(ValueError):\n+        _check_array_lengths([a_np], [None], None)\n+    with pytest.raises(ValueError):\n+        _check_array_lengths([a_np], [b_np], None)\n+    with pytest.raises(ValueError):\n+        _check_array_lengths([a_np], None, [b_np])\n+\n+\n @keras_test\n def test_slice_arrays():\n     input_a = np.random.random((10, 3))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1aa9e9199b3db9554426c9f8cf9efbfb2f3d7963", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 19 | Churn Cumulative: 2190 | Contributors (this commit): 4 | Commits (past 90d): 5 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1567,6 +1567,17 @@ class Function(object):\n         else:\n             self.metrics_func = None\n \n+    @staticmethod\n+    def _is_input_shape_compatible(input, placeholder):\n+        if hasattr(input, 'shape') and hasattr(placeholder, 'shape'):\n+            num_dynamic = get_num_dynamic_axis(placeholder)\n+            input_shape = input.shape[num_dynamic:]\n+            placeholder_shape = placeholder.shape\n+            for i, p in zip(input_shape, placeholder_shape):\n+                if i != p and p != C.InferredDimension:\n+                    return False\n+        return True\n+\n     def __call__(self, inputs):\n         assert type(inputs) in {list, tuple}\n         feed_dict = {}\n@@ -1576,6 +1587,14 @@ class Function(object):\n                value.dtype != np.float32 and\n                value.dtype != np.float64):\n                 value = value.astype(np.float32)\n+            # in current version cntk can't support input with variable\n+            # length. Will support it in next release.\n+            if not self._is_input_shape_compatible(value, tensor):\n+                raise ValueError('CNTK backend: The placeholder has been resolved '\n+                                 'to shape `%s`, but input shape is `%s`. Currently '\n+                                 'CNTK can not take variable length inputs. Please '\n+                                 'pass inputs that have a static shape.'\n+                                 % (tensor.shape, value.shape))\n             feed_dict[tensor] = value\n \n         updated = []\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7dcd2982b2faf08018d0fe22426834072a4ddb58", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 15 | Files Changed: 2 | Hunks: 11 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 51 | Churn Cumulative: 9077 | Contributors (this commit): 59 | Commits (past 90d): 36 | Contributors (cumulative): 64 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2637,10 +2637,25 @@ class Container(Layer):\n         \"\"\"\n         return yaml.dump(self._updated_config(), **kwargs)\n \n-    def summary(self, line_length=None, positions=None):\n-        print_layer_summary(self,\n+    def summary(self, line_length=None, positions=None, print_fn=print):\n+        \"\"\"Prints a string summary of the network.\n+\n+        # Arguments\n+            line_length: Total length of printed lines\n+                (e.g. set this to adapt the display to different\n+                terminal window sizes).\n+            positions: Relative or absolute positions of log elements\n+                in each line. If not provided,\n+                defaults to `[.33, .55, .67, 1.]`.\n+            print_fn: Print function to use.\n+                It will be called on each line of the summary.\n+                You can set it to a custom function\n+                in order to capture the string summary.\n+        \"\"\"\n+        return print_layer_summary(self,\n                                    line_length=line_length,\n-                            positions=positions)\n+                                   positions=positions,\n+                                   print_fn=print_fn)\n \n \n def get_source_inputs(tensor, layer=None, node_index=None):\n\n@@ -5,14 +5,20 @@ from .. import backend as K\n import numpy as np\n \n \n-def print_summary(model, line_length=None, positions=None):\n+def print_summary(model, line_length=None, positions=None, print_fn=print):\n     \"\"\"Prints a summary of a model.\n \n     # Arguments\n         model: Keras model instance.\n-        line_length: total length of printed lines\n-        positions: relative or absolute positions of log elements in each line.\n+        line_length: Total length of printed lines\n+            (e.g. set this to adapt the display to different\n+            terminal window sizes).\n+        positions: Relative or absolute positions of log elements in each line.\n             If not provided, defaults to `[.33, .55, .67, 1.]`.\n+        print_fn: Print function to use.\n+            It will be called on each line of the summary.\n+            You can set it to a custom function\n+            in order to capture the string summary.\n     \"\"\"\n     if model.__class__.__name__ == 'Sequential':\n         sequential_like = True\n@@ -51,11 +57,11 @@ def print_summary(model, line_length=None, positions=None):\n             line += str(fields[i])\n             line = line[:positions[i]]\n             line += ' ' * (positions[i] - len(line))\n-        print(line)\n+        print_fn(line)\n \n-    print('_' * line_length)\n+    print_fn('_' * line_length)\n     print_row(to_display, positions)\n-    print('=' * line_length)\n+    print_fn('=' * line_length)\n \n     def print_layer_summary(layer):\n         try:\n@@ -108,19 +114,19 @@ def print_summary(model, line_length=None, positions=None):\n         else:\n             print_layer_summary_with_connections(layers[i])\n         if i == len(layers) - 1:\n-            print('=' * line_length)\n+            print_fn('=' * line_length)\n         else:\n-            print('_' * line_length)\n+            print_fn('_' * line_length)\n \n     trainable_count = int(\n         np.sum([K.count_params(p) for p in set(model.trainable_weights)]))\n     non_trainable_count = int(\n         np.sum([K.count_params(p) for p in set(model.non_trainable_weights)]))\n \n-    print('Total params: {:,}'.format(trainable_count + non_trainable_count))\n-    print('Trainable params: {:,}'.format(trainable_count))\n-    print('Non-trainable params: {:,}'.format(non_trainable_count))\n-    print('_' * line_length)\n+    print_fn('Total params: {:,}'.format(trainable_count + non_trainable_count))\n+    print_fn('Trainable params: {:,}'.format(trainable_count))\n+    print_fn('Non-trainable params: {:,}'.format(non_trainable_count))\n+    print_fn('_' * line_length)    \n \n \n def convert_all_kernels_in_model(model):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5a7f6b0e74673eae86c07fc642018745443bb335", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 8 | Files Changed: 3 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 14 | Churn Cumulative: 10800 | Contributors (this commit): 104 | Commits (past 90d): 36 | Contributors (cumulative): 121 | DMM Complexity: 1.0\n\nDIFF:\n@@ -550,7 +550,7 @@ def dtype(x):\n         'float32_ref'\n     ```\n     \"\"\"\n-    return x.dtype.name\n+    return x.dtype.base_dtype.name\n \n \n def eval(x):\n\n@@ -75,7 +75,6 @@ class Embedding(Layer):\n                  mask_zero=False,\n                  input_length=None,\n                  **kwargs):\n-        kwargs['dtype'] = 'int32'\n         if 'input_shape' not in kwargs:\n             if input_length:\n                 kwargs['input_shape'] = (input_length,)\n@@ -98,7 +97,8 @@ class Embedding(Layer):\n             initializer=self.embeddings_initializer,\n             name='embeddings',\n             regularizer=self.embeddings_regularizer,\n-            constraint=self.embeddings_constraint)\n+            constraint=self.embeddings_constraint,\n+            dtype=self.dtype)\n         self.built = True\n \n     def compute_mask(self, inputs, mask=None):\n\n@@ -219,8 +219,7 @@ class RMSprop(Optimizer):\n \n     def get_updates(self, params, constraints, loss):\n         grads = self.get_gradients(loss, params)\n-        shapes = [K.get_variable_shape(p) for p in params]\n-        accumulators = [K.zeros(shape) for shape in shapes]\n+        accumulators = [K.zeros(K.get_variable_shape(p), dtype=K.dtype(p)) for p in params]\n         self.weights = accumulators\n         self.updates = []\n \n@@ -413,9 +412,8 @@ class Adam(Optimizer):\n         lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n                      (1. - K.pow(self.beta_1, t)))\n \n-        shapes = [K.get_variable_shape(p) for p in params]\n-        ms = [K.zeros(shape) for shape in shapes]\n-        vs = [K.zeros(shape) for shape in shapes]\n+        ms = [K.zeros(K.get_variable_shape(p), dtype=K.dtype(p)) for p in params]\n+        vs = [K.zeros(K.get_variable_shape(p), dtype=K.dtype(p)) for p in params]\n         self.weights = [self.iterations] + ms + vs\n \n         for p, g, m, v in zip(params, grads, ms, vs):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#21c5e5479b5dce27c6b1c3971fd02d2eb96353d7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 1147 | Contributors (this commit): 16 | Commits (past 90d): 5 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -286,7 +286,8 @@ PAGES = [\n         'page': 'utils.md',\n         'all_module_functions': [utils],\n         'classes': [utils.CustomObjectScope,\n-                    utils.HDF5Matrix]\n+                    utils.HDF5Matrix,\n+                    utils.Sequence]\n     },\n ]\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#598954d2c8e3f972817a413caf45d31c5458de33", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 11 | Files Changed: 1 | Hunks: 11 | Methods Changed: 9 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 22 | Churn Cumulative: 8095 | Contributors (this commit): 83 | Commits (past 90d): 28 | Contributors (cumulative): 83 | DMM Complexity: None\n\nDIFF:\n@@ -1153,7 +1153,7 @@ def max(x, axis=None, keepdims=False):\n         A tensor with maximum values of `x`.\n     \"\"\"\n     axis = _normalize_axis(axis, ndim(x))\n-    return tf.reduce_max(x, reduction_indices=axis, keep_dims=keepdims)\n+    return tf.reduce_max(x, axis=axis, keep_dims=keepdims)\n \n \n def min(x, axis=None, keepdims=False):\n@@ -1171,7 +1171,7 @@ def min(x, axis=None, keepdims=False):\n         A tensor with miminum values of `x`.\n     \"\"\"\n     axis = _normalize_axis(axis, ndim(x))\n-    return tf.reduce_min(x, reduction_indices=axis, keep_dims=keepdims)\n+    return tf.reduce_min(x, axis=axis, keep_dims=keepdims)\n \n \n def sum(x, axis=None, keepdims=False):\n@@ -1189,7 +1189,7 @@ def sum(x, axis=None, keepdims=False):\n         A tensor with sum of `x`.\n     \"\"\"\n     axis = _normalize_axis(axis, ndim(x))\n-    return tf.reduce_sum(x, reduction_indices=axis, keep_dims=keepdims)\n+    return tf.reduce_sum(x, axis=axis, keep_dims=keepdims)\n \n \n def prod(x, axis=None, keepdims=False):\n@@ -1207,7 +1207,7 @@ def prod(x, axis=None, keepdims=False):\n         A tensor with the product of elements of `x`.\n     \"\"\"\n     axis = _normalize_axis(axis, ndim(x))\n-    return tf.reduce_prod(x, reduction_indices=axis, keep_dims=keepdims)\n+    return tf.reduce_prod(x, axis=axis, keep_dims=keepdims)\n \n \n def cumsum(x, axis=0):\n@@ -1255,10 +1255,10 @@ def var(x, axis=None, keepdims=False):\n     axis = _normalize_axis(axis, ndim(x))\n     if x.dtype.base_dtype == tf.bool:\n         x = tf.cast(x, floatx())\n-    m = tf.reduce_mean(x, reduction_indices=axis, keep_dims=True)\n+    m = tf.reduce_mean(x, axis=axis, keep_dims=True)\n     devs_squared = tf.square(x - m)\n     return tf.reduce_mean(devs_squared,\n-                          reduction_indices=axis,\n+                          axis=axis,\n                           keep_dims=keepdims)\n \n \n@@ -1296,7 +1296,7 @@ def mean(x, axis=None, keepdims=False):\n     axis = _normalize_axis(axis, ndim(x))\n     if x.dtype.base_dtype == tf.bool:\n         x = tf.cast(x, floatx())\n-    return tf.reduce_mean(x, reduction_indices=axis, keep_dims=keepdims)\n+    return tf.reduce_mean(x, axis=axis, keep_dims=keepdims)\n \n \n def any(x, axis=None, keepdims=False):\n@@ -1312,7 +1312,7 @@ def any(x, axis=None, keepdims=False):\n     \"\"\"\n     axis = _normalize_axis(axis, ndim(x))\n     x = tf.cast(x, tf.bool)\n-    return tf.reduce_any(x, reduction_indices=axis, keep_dims=keepdims)\n+    return tf.reduce_any(x, axis=axis, keep_dims=keepdims)\n \n \n def all(x, axis=None, keepdims=False):\n@@ -1328,7 +1328,7 @@ def all(x, axis=None, keepdims=False):\n     \"\"\"\n     axis = _normalize_axis(axis, ndim(x))\n     x = tf.cast(x, tf.bool)\n-    return tf.reduce_all(x, reduction_indices=axis, keep_dims=keepdims)\n+    return tf.reduce_all(x, axis=axis, keep_dims=keepdims)\n \n \n def argmax(x, axis=-1):\n@@ -2741,13 +2741,13 @@ def categorical_crossentropy(output, target, from_logits=False):\n     if not from_logits:\n         # scale preds so that the class probas of each sample sum to 1\n         output /= tf.reduce_sum(output,\n-                                reduction_indices=len(output.get_shape()) - 1,\n+                                axis=len(output.get_shape()) - 1,\n                                 keep_dims=True)\n         # manual computation of crossentropy\n         epsilon = _to_tensor(_EPSILON, output.dtype.base_dtype)\n         output = tf.clip_by_value(output, epsilon, 1. - epsilon)\n         return - tf.reduce_sum(target * tf.log(output),\n-                               reduction_indices=len(output.get_shape()) - 1)\n+                               axis=len(output.get_shape()) - 1)\n     else:\n         return tf.nn.softmax_cross_entropy_with_logits(labels=target,\n                                                        logits=output)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f6c1730cf33b338b12ffe891ae83dedcb243c25f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 2732 | Contributors (this commit): 54 | Commits (past 90d): 18 | Contributors (cumulative): 54 | DMM Complexity: 0.0\n\nDIFF:\n@@ -873,8 +873,12 @@ class ReduceLROnPlateau(Callback):\n         logs['lr'] = K.get_value(self.model.optimizer.lr)\n         current = logs.get(self.monitor)\n         if current is None:\n-            warnings.warn('Learning Rate Plateau Reducing requires %s available!' %\n-                          self.monitor, RuntimeWarning)\n+            warnings.warn(\n+                'Reduce LR on plateau conditioned on metric `%s` '\n+                'which is not available. Available metrics are: %s' %\n+                (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n+            )\n+\n         else:\n             if self.in_cooldown():\n                 self.cooldown_counter -= 1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a85263fb3edee30623f7c9c1ffb6505b4f983d14", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 460 | Contributors (this commit): 8 | Commits (past 90d): 2 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -79,7 +79,8 @@ decoder_deconv_1 = Conv2DTranspose(filters,\n                                    padding='same',\n                                    strides=1,\n                                    activation='relu')\n-decoder_deconv_2 = Conv2DTranspose(filters, num_conv,\n+decoder_deconv_2 = Conv2DTranspose(filters,\n+                                   kernel_size=num_conv,\n                                    padding='same',\n                                    strides=1,\n                                    activation='relu')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fb9dbdb10c75f3a3539b77713c65c75c6c297247", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): -2/1 | Churn Δ: 14 | Churn Cumulative: 13856 | Contributors (this commit): 111 | Commits (past 90d): 41 | Contributors (cumulative): 126 | DMM Complexity: 0.0\n\nDIFF:\n@@ -908,14 +908,8 @@ class Model(Container):\n         self.test_function = None\n         self.predict_function = None\n \n-        # Collected trainable weights and sort them deterministically.\n+        # Collected trainable weights, sorted in topological order.\n         trainable_weights = self.trainable_weights\n-        # Sort weights by name.\n-        if trainable_weights:\n-            if K.backend() == 'theano':\n-                trainable_weights.sort(key=lambda x: x.name if x.name else x.auto_name)\n-            else:\n-                trainable_weights.sort(key=lambda x: x.name)\n         self._collected_trainable_weights = trainable_weights\n \n     def _make_train_function(self):\n\n@@ -288,7 +288,13 @@ def load_model(filepath, custom_objects=None, compile=True):\n                                       optimizer_weights_group.attrs['weight_names']]\n             optimizer_weight_values = [optimizer_weights_group[n] for n in\n                                        optimizer_weight_names]\n+            try:\n                 model.optimizer.set_weights(optimizer_weight_values)\n+            except ValueError:\n+                warnings.warn('Error in loading the saved optimizer '\n+                              'state. As a result, your model is '\n+                              'starting with a freshly initialized '\n+                              'optimizer.')\n     return model\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#49a7c7376d0057ab85e00f1ee3387ce36797e994", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 738 | Lines Deleted: 0 | Files Changed: 6 | Hunks: 7 | Methods Changed: 17 | Complexity Δ (Sum/Max): 63/50 | Churn Δ: 738 | Churn Cumulative: 16366 | Contributors (this commit): 106 | Commits (past 90d): 58 | Contributors (cumulative): 168 | DMM Complexity: 0.5748031496062992\n\nDIFF:\n@@ -3,3 +3,4 @@ from .vgg19 import VGG19\n from .resnet50 import ResNet50\n from .inception_v3 import InceptionV3\n from .xception import Xception\n+from .mobilenet import MobileNet\n\n@@ -0,0 +1,616 @@\n+\"\"\"MobileNet v1 models for Keras.\n+\n+MobileNet is a general architecture and can be used for multiple use cases.\n+Depending on the use case, it can use different input layer size and\n+different width factors. This allows different width models to reduce\n+the number of multiply-adds and thereby reduce inference cost on mobile devices.\n+\n+MobileNets support any input size greater than 32 x 32, with larger image sizes\n+offering better performance. The number of parameters and number of multiply-adds\n+can be modified by using the `alpha` parameter, which increases/decreases the number\n+of filters in each layer. By altering the image size and `alpha` parameter,\n+all 16 models from the paper can be built, with ImageNet weights provided.\n+\n+The paper demonstrates the performance of MobileNets using `alpha` values of\n+1.0 (also called 100 % MobileNet), 0.75, 0.5 and 0.25. For each of these `alpha`\n+values, weights for 4 different input image sizes are provided (224, 192, 160, 128).\n+\n+The following table describes the size and accuracy of the 100% MobileNet on size 224 x 224\n+-----------------------------------------------------------------------------------------\n+Width Multiplier (alpha) | ImageNet Accuracy | Million Multiply-Adds | Million Parameters\n+-----------------------------------------------------------------------------------------\n+|   1.0 MobileNet-224    |      70.6 %       |          529          |        4.2       |\n+|   0.75 MobileNet-224   |      68.4 %       |          325          |        2.6       |\n+|   0.50 MobileNet-224   |      63.7 %       |          149          |        1.3       |\n+|   0.25 MobileNet-224   |      50.6 %       |          41           |        0.5       |\n+-----------------------------------------------------------------------------------------\n+\n+The following table describes the performance of the 100 % MobileNet on various input sizes\n+-----------------------------------------------------------------------------------------\n+        Resolution       | ImageNet Accuracy | Million Multiply-Adds | Million Parameters\n+-----------------------------------------------------------------------------------------\n+|   1.0 MobileNet-224    |      70.6 %       |          529          |        4.2       |\n+|   1.0 MobileNet-192    |      69.1 %       |          529          |        4.2       |\n+|   1.0 MobileNet-160    |      67.2 %       |          529          |        4.2       |\n+|   1.0 MobileNet-128    |      64.4 %       |          529          |        4.2       |\n+-----------------------------------------------------------------------------------------\n+\n+The weights for all 16 models are obtained and translated from Tensorflow checkpoints\n+found in https://github.com/tensorflow/models/blob/master/slim/nets/mobilenet_v1.md\n+\n+# Reference\n+- [MobileNets: Efficient Convolutional Neural Networks for\n+   Mobile Vision Applications](https://arxiv.org/pdf/1704.04861.pdf))\n+\"\"\"\n+from __future__ import print_function\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import warnings\n+\n+from ..models import Model\n+from ..layers import Input\n+from ..layers import Activation\n+from ..layers import Dropout\n+from ..layers import Reshape\n+from ..layers import BatchNormalization\n+from ..layers import Convolution2D\n+from ..layers import GlobalAveragePooling2D\n+from ..layers import GlobalMaxPooling2D\n+from ..layers import Conv2D\n+from .. import initializers\n+from .. import regularizers\n+from .. import constraints\n+from ..utils import conv_utils\n+from ..utils.data_utils import get_file\n+from ..engine.topology import get_source_inputs\n+from ..engine import InputSpec\n+from ..applications.imagenet_utils import _obtain_input_shape\n+from ..applications.imagenet_utils import preprocess_input\n+from ..applications.imagenet_utils import decode_predictions\n+from .. import backend as K\n+\n+\n+BASE_WEIGHT_PATH = 'https://github.com/titu1994/MobileNetworks/releases/download/v1.0/'\n+\n+\n+def relu6(x):\n+    return K.relu(x, max_value=6)\n+\n+\n+class DepthwiseConv2D(Conv2D):\n+    \"\"\"Depthwise separable 2D convolution.\n+    Depthwise Separable convolutions consists in performing\n+    just the first step in a depthwise spatial convolution\n+    (which acts on each input channel separately).\n+    The `depth_multiplier` argument controls how many\n+    output channels are generated per input channel in the depthwise step.\n+\n+    # Arguments\n+        kernel_size: An integer or tuple/list of 2 integers, specifying the\n+            width and height of the 2D convolution window.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+        strides: An integer or tuple/list of 2 integers,\n+            specifying the strides of the convolution along the width and height.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+            Specifying any stride value != 1 is incompatible with specifying\n+            any `dilation_rate` value != 1.\n+        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n+        depth_multiplier: The number of depthwise convolution output channels\n+            for each input channel.\n+            The total number of depthwise convolution output\n+            channels will be equal to `filters_in * depth_multiplier`.\n+        data_format: A string,\n+            one of `channels_last` (default) or `channels_first`.\n+            The ordering of the dimensions in the inputs.\n+            `channels_last` corresponds to inputs with shape\n+            `(batch, height, width, channels)` while `channels_first`\n+            corresponds to inputs with shape\n+            `(batch, channels, height, width)`.\n+            It defaults to the `image_data_format` value found in your\n+            Keras config file at `~/.keras/keras.json`.\n+            If you never set it, then it will be \"channels_last\".\n+        activation: Activation function to use\n+            (see [activations](../activations.md)).\n+            If you don't specify anything, no activation is applied\n+            (ie. \"linear\" activation: `a(x) = x`).\n+        use_bias: Boolean, whether the layer uses a bias vector.\n+        depthwise_initializer: Initializer for the depthwise kernel matrix\n+            (see [initializers](../initializers.md)).\n+        bias_initializer: Initializer for the bias vector\n+            (see [initializers](../initializers.md)).\n+        depthwise_regularizer: Regularizer function applied to\n+            the depthwise kernel matrix\n+            (see [regularizer](../regularizers.md)).\n+        bias_regularizer: Regularizer function applied to the bias vector\n+            (see [regularizer](../regularizers.md)).\n+        activity_regularizer: Regularizer function applied to\n+            the output of the layer (its \"activation\").\n+            (see [regularizer](../regularizers.md)).\n+        depthwise_constraint: Constraint function applied to\n+            the depthwise kernel matrix\n+            (see [constraints](../constraints.md)).\n+        bias_constraint: Constraint function applied to the bias vector\n+            (see [constraints](../constraints.md)).\n+\n+    # Input shape\n+        4D tensor with shape:\n+        `[batch, channels, rows, cols]` if data_format='channels_first'\n+        or 4D tensor with shape:\n+        `[batch, rows, cols, channels]` if data_format='channels_last'.\n+\n+    # Output shape\n+        4D tensor with shape:\n+        `[batch, filters, new_rows, new_cols]` if data_format='channels_first'\n+        or 4D tensor with shape:\n+        `[batch, new_rows, new_cols, filters]` if data_format='channels_last'.\n+        `rows` and `cols` values might have changed due to padding.\n+    \"\"\"\n+\n+    def __init__(self,\n+                 kernel_size,\n+                 strides=(1, 1),\n+                 padding='valid',\n+                 depth_multiplier=1,\n+                 data_format=None,\n+                 activation=None,\n+                 use_bias=True,\n+                 depthwise_initializer='glorot_uniform',\n+                 bias_initializer='zeros',\n+                 depthwise_regularizer=None,\n+                 bias_regularizer=None,\n+                 activity_regularizer=None,\n+                 depthwise_constraint=None,\n+                 bias_constraint=None,\n+                 **kwargs):\n+        super(DepthwiseConv2D, self).__init__(\n+            filters=None,\n+            kernel_size=kernel_size,\n+            strides=strides,\n+            padding=padding,\n+            data_format=data_format,\n+            activation=activation,\n+            use_bias=use_bias,\n+            bias_regularizer=bias_regularizer,\n+            activity_regularizer=activity_regularizer,\n+            bias_constraint=bias_constraint,\n+            **kwargs)\n+        self.depth_multiplier = depth_multiplier\n+        self.depthwise_initializer = initializers.get(depthwise_initializer)\n+        self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\n+        self.depthwise_constraint = constraints.get(depthwise_constraint)\n+        self.bias_initializer = initializers.get(bias_initializer)\n+\n+    def build(self, input_shape):\n+        if len(input_shape) < 4:\n+            raise ValueError('Inputs to `DepthwiseConv2D` should have rank 4. '\n+                             'Received input shape:', str(input_shape))\n+        if self.data_format == 'channels_first':\n+            channel_axis = 1\n+        else:\n+            channel_axis = 3\n+        if input_shape[channel_axis] is None:\n+            raise ValueError('The channel dimension of the inputs to '\n+                             '`DepthwiseConv2D` '\n+                             'should be defined. Found `None`.')\n+        input_dim = int(input_shape[channel_axis])\n+        depthwise_kernel_shape = (self.kernel_size[0],\n+                                  self.kernel_size[1],\n+                                  input_dim,\n+                                  self.depth_multiplier)\n+\n+        self.depthwise_kernel = self.add_weight(\n+            shape=depthwise_kernel_shape,\n+            initializer=self.depthwise_initializer,\n+            name='depthwise_kernel',\n+            regularizer=self.depthwise_regularizer,\n+            constraint=self.depthwise_constraint)\n+\n+        if self.use_bias:\n+            self.bias = self.add_weight(shape=(input_dim * self.depth_multiplier,),\n+                                        initializer=self.bias_initializer,\n+                                        name='bias',\n+                                        regularizer=self.bias_regularizer,\n+                                        constraint=self.bias_constraint)\n+        else:\n+            self.bias = None\n+        # Set input spec.\n+        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n+        self.built = True\n+\n+    def call(self, inputs, training=None):\n+        outputs = K.depthwise_conv2d(\n+            inputs,\n+            self.depthwise_kernel,\n+            strides=self.strides,\n+            padding=self.padding,\n+            dilation_rate=self.dilation_rate,\n+            data_format=self.data_format)\n+\n+        if self.bias:\n+            outputs = K.bias_add(\n+                outputs,\n+                self.bias,\n+                data_format=self.data_format)\n+\n+        if self.activation is not None:\n+            return self.activation(outputs)\n+\n+        return outputs\n+\n+    def compute_output_shape(self, input_shape):\n+        if self.data_format == 'channels_first':\n+            rows = input_shape[2]\n+            cols = input_shape[3]\n+            out_filters = input_shape[1] * self.depth_multiplier\n+        elif self.data_format == 'channels_last':\n+            rows = input_shape[1]\n+            cols = input_shape[2]\n+            out_filters = input_shape[3] * self.depth_multiplier\n+\n+        rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n+                                             self.padding,\n+                                             self.strides[0])\n+        cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n+                                             self.padding,\n+                                             self.strides[1])\n+\n+        if self.data_format == 'channels_first':\n+            return (input_shape[0], out_filters, rows, cols)\n+        elif self.data_format == 'channels_last':\n+            return (input_shape[0], rows, cols, out_filters)\n+\n+    def get_config(self):\n+        config = super(DepthwiseConv2D, self).get_config()\n+        config.pop('filters')\n+        config.pop('kernel_initializer')\n+        config.pop('kernel_regularizer')\n+        config.pop('kernel_constraint')\n+        config['depth_multiplier'] = self.depth_multiplier\n+        config['depthwise_initializer'] = initializers.serialize(self.depthwise_initializer)\n+        config['depthwise_regularizer'] = regularizers.serialize(self.depthwise_regularizer)\n+        config['depthwise_constraint'] = constraints.serialize(self.depthwise_constraint)\n+        return config\n+\n+\n+def MobileNet(input_shape=None,\n+              alpha=1.0,\n+              depth_multiplier=1,\n+              dropout=1e-3,\n+              include_top=True,\n+              weights='imagenet',\n+              input_tensor=None,\n+              pooling=None,\n+              classes=1000):\n+    \"\"\"\n+    Instantiate the MobileNet architecture.\n+    Note that only TensorFlow is supported for now,\n+    therefore it only works with the data format\n+    `image_data_format='channels_last'` in your Keras config\n+    at `~/.keras/keras.json`.\n+\n+    To load a MobileNet model via `load_model`, import the custom\n+    objects `relu6` and `DepthwiseConv2D` and pass them to the\n+    `custom_objects` parameter.\n+    E.g.\n+    model = load_model('mobilenet.h5', custom_objects={\n+                       'relu6': mobilenet.relu6,\n+                       'DepthwiseConv2D': mobilenet.DepthwiseConv2D})\n+\n+    # Arguments\n+        input_shape: optional shape tuple, only to be specified\n+            if `include_top` is False (otherwise the input shape\n+            has to be `(224, 224, 3)` (with `channels_last` data format)\n+            or (3, 224, 224) (with `channels_first` data format).\n+            It should have exactly 3 inputs channels,\n+            and width and height should be no smaller than 32.\n+            E.g. `(200, 200, 3)` would be one valid value.\n+        alpha: controls the width of the network.\n+            - If `alpha` < 1.0, proportionally decreases the number\n+                of filters in each layer.\n+            - If `alpha` > 1.0, proportionally increases the number\n+                of filters in each layer.\n+            - If `alpha` = 1, default number of filters from the paper\n+                 are used at each layer.\n+        depth_multiplier: depth multiplier for depthwise convolution\n+            (also called the resolution multiplier)\n+        dropout: dropout rate\n+        include_top: whether to include the fully-connected\n+            layer at the top of the network.\n+        weights: `None` (random initialization) or\n+            `imagenet` (ImageNet weights)\n+        input_tensor: optional Keras tensor (i.e. output of\n+            `layers.Input()`)\n+            to use as image input for the model.\n+        pooling: Optional pooling mode for feature extraction\n+            when `include_top` is `False`.\n+            - `None` means that the output of the model\n+                will be the 4D tensor output of the\n+                last convolutional layer.\n+            - `avg` means that global average pooling\n+                will be applied to the output of the\n+                last convolutional layer, and thus\n+                the output of the model will be a\n+                2D tensor.\n+            - `max` means that global max pooling will\n+                be applied.\n+        classes: optional number of classes to classify images\n+            into, only to be specified if `include_top` is True, and\n+            if no `weights` argument is specified.\n+\n+    # Returns\n+        A Keras model instance.\n+\n+    # Raises\n+        ValueError: in case of invalid argument for `weights`,\n+            or invalid input shape.\n+        RuntimeError: If attempting to run this model with a\n+            backend that does not support separable convolutions.\n+    \"\"\"\n+\n+    if K.backend() != 'tensorflow':\n+        raise RuntimeError('Only Tensorflow backend is currently supported, '\n+                           'as other backends do not support depthwise convolution.')\n+\n+    if weights not in {'imagenet', None}:\n+        raise ValueError('The `weights` argument should be either '\n+                         '`None` (random initialization) or `imagenet` '\n+                         '(pre-training on ImageNet).')\n+\n+    if weights == 'imagenet' and include_top and classes != 1000:\n+        raise ValueError('If using `weights` as ImageNet with `include_top`'\n+                         ' as true, `classes` should be 1000')\n+\n+    if weights == 'imagenet' and depth_multiplier != 1:\n+        if depth_multiplier != 1:\n+            raise ValueError('If imagenet weights are being loaded, '\n+                             'depth multiplier must be 1')\n+\n+        if alpha not in [0.25, 0.50, 0.75, 1.0]:\n+            raise ValueError('If imagenet weights are being loaded, alpha can be one of'\n+                             '`0.25`, `0.50`, `0.75` or `1.0` only.')\n+\n+        rows, cols = (0, 1) if K.image_data_format() == 'channels_last' else (1, 2)\n+        rows = int(input_shape[rows])\n+        cols = int(input_shape[cols])\n+\n+        if rows != cols or rows not in [128, 160, 192, 224]:\n+            raise ValueError('If imagenet weights are being loaded,'\n+                             'image must have a square shape (one of '\n+                             '(128,128), (160,160), (192,192), or (224, 224)).'\n+                             'Image shape provided = (%d, %d)' % (rows, cols))\n+\n+    if K.image_data_format() != 'channels_last':\n+        warnings.warn('The MobileNet family of models is only available '\n+                      'for the input data format \"channels_last\" '\n+                      '(width, height, channels). '\n+                      'However your settings specify the default '\n+                      'data format \"channels_first\" (channels, width, height). '\n+                      'You should set `image_data_format=\"channels_last\"` in your Keras '\n+                      'config located at ~/.keras/keras.json. '\n+                      'The model being returned right now will expect inputs '\n+                      'to follow the \"channels_last\" data format.')\n+        K.set_image_data_format('channels_last')\n+        old_data_format = 'channels_first'\n+    else:\n+        old_data_format = None\n+\n+    # Determine proper input shape. Note, include_top is False by default, as\n+    # input shape can be anything larger than 32x32 and the same number of parameters\n+    # will be used.\n+    input_shape = _obtain_input_shape(input_shape,\n+                                      default_size=224,\n+                                      min_size=32,\n+                                      data_format=K.image_data_format(),\n+                                      include_top=False)\n+\n+    if input_tensor is None:\n+        img_input = Input(shape=input_shape)\n+    else:\n+        if not K.is_keras_tensor(input_tensor):\n+            img_input = Input(tensor=input_tensor, shape=input_shape)\n+        else:\n+            img_input = input_tensor\n+\n+    x = _conv_block(img_input, 32, alpha, strides=(2, 2))\n+    x = _depthwise_conv_block(x, 64, alpha, depth_multiplier, id=1)\n+\n+    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier, strides=(2, 2), id=2)\n+    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier, id=3)\n+\n+    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier, strides=(2, 2), id=4)\n+    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier, id=5)\n+\n+    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, strides=(2, 2), id=6)\n+    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, id=7)\n+    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, id=8)\n+    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, id=9)\n+    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, id=10)\n+    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, id=11)\n+\n+    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier, strides=(2, 2), id=12)\n+    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier, id=13)\n+\n+    if include_top:\n+        if K.image_data_format() == 'channels_first':\n+            shape = (int(1024 * alpha), 1, 1)\n+        else:\n+            shape = (1, 1, int(1024 * alpha))\n+\n+        x = GlobalAveragePooling2D()(x)\n+        x = Reshape(shape, name='reshape_1')(x)\n+        x = Dropout(dropout, name='dropout')(x)\n+        x = Convolution2D(classes, (1, 1), padding='same', name='conv_preds')(x)\n+        x = Activation('softmax', name='act_softmax')(x)\n+        x = Reshape((classes,), name='reshape_2')(x)\n+    else:\n+        if pooling == 'avg':\n+            x = GlobalAveragePooling2D()(x)\n+        elif pooling == 'max':\n+            x = GlobalMaxPooling2D()(x)\n+\n+    # Ensure that the model takes into account\n+    # any potential predecessors of `input_tensor`.\n+    if input_tensor is not None:\n+        inputs = get_source_inputs(input_tensor)\n+    else:\n+        inputs = img_input\n+\n+    rows, cols = (0, 1) if K.image_data_format() == 'channels_last' else (1, 2)\n+    if input_shape[rows] is None:\n+        size = 'None'\n+    else:\n+        size = str(input_shape[rows])\n+\n+    # Create model.\n+    model = Model(inputs, x, name='mobilenet_%0.2f_%s' % (alpha, size))\n+\n+    # load weights\n+    if weights == 'imagenet':\n+        if K.image_data_format() == 'channels_first':\n+            raise AttributeError('Weights for Channels Last format are not available')\n+\n+        if alpha == 1.0:\n+            alpha_text = '1_0'\n+        elif alpha == 0.75:\n+            alpha_text = '7_5'\n+        elif alpha == 0.50:\n+            alpha_text = '5_0'\n+        else:\n+            alpha_text = '2_5'\n+\n+        if include_top:\n+            model_name = 'mobilenet_%s_%d_tf.h5' % (alpha_text, rows)\n+            weigh_path = BASE_WEIGHT_PATH + model_name\n+            weights_path = get_file(model_name,\n+                                    weigh_path,\n+                                    cache_subdir='models')\n+        else:\n+            model_name = 'mobilenet_%s_%d_tf_no_top.h5' % (alpha_text, rows)\n+            weigh_path = BASE_WEIGHT_PATH + model_name\n+            weights_path = get_file(model_name,\n+                                    weigh_path,\n+                                    cache_subdir='models')\n+\n+        model.load_weights(weights_path)\n+\n+    if old_data_format:\n+        K.set_image_data_format(old_data_format)\n+\n+    return model\n+\n+\n+def _conv_block(input, filters, alpha, kernel=(3, 3), strides=(1, 1)):\n+    \"\"\"Adds an initial convolution layer (with batch normalization and relu6).\n+\n+    # Arguments\n+        input: Input tensor of shape `(rows, cols, 3)`\n+            (with `channels_last` data format) or\n+            (3, rows, cols) (with `channels_first` data format).\n+            It should have exactly 3 inputs channels,\n+            and width and height should be no smaller than 32.\n+            E.g. `(224, 224, 3)` would be one valid value.\n+        filters: Integer, the dimensionality of the output space\n+            (i.e. the number output of filters in the convolution).\n+        alpha: controls the width of the network.\n+            - If `alpha` < 1.0, proportionally decreases the number\n+                of filters in each layer.\n+            - If `alpha` > 1.0, proportionally increases the number\n+                of filters in each layer.\n+            - If `alpha` = 1, default number of filters from the paper\n+                 are used at each layer.\n+        kernel: An integer or tuple/list of 2 integers, specifying the\n+            width and height of the 2D convolution window.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+        strides: An integer or tuple/list of 2 integers,\n+            specifying the strides of the convolution along the width and height.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+            Specifying any stride value != 1 is incompatible with specifying\n+            any `dilation_rate` value != 1.\n+\n+    # Input shape\n+        4D tensor with shape:\n+        `(samples, channels, rows, cols)` if data_format='channels_first'\n+        or 4D tensor with shape:\n+        `(samples, rows, cols, channels)` if data_format='channels_last'.\n+\n+    # Output shape\n+        4D tensor with shape:\n+        `(samples, filters, new_rows, new_cols)` if data_format='channels_first'\n+        or 4D tensor with shape:\n+        `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n+        `rows` and `cols` values might have changed due to stride.\n+    \"\"\"\n+    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n+    filters = int(filters * alpha)\n+\n+    x = Convolution2D(filters, kernel, padding='same', use_bias=False, strides=strides,\n+                      name='conv1')(input)\n+    x = BatchNormalization(axis=channel_axis, name='conv1_bn')(x)\n+    x = Activation(relu6, name='conv1_relu')(x)\n+\n+    return x\n+\n+\n+def _depthwise_conv_block(input, pointwise_conv_filters, alpha,\n+                          depth_multiplier=1, strides=(1, 1), id=1):\n+    \"\"\"\n+    Adds a depthwise convolution block (depthwise conv, batch normalization, relu6,\n+    pointwise convolution, batch normalization and relu6).\n+\n+    # Arguments\n+        input: Input tensor of shape `(rows, cols, channels)`\n+            (with `channels_last` data format) or\n+            (channels, rows, cols) (with `channels_first` data format).\n+        pointwise_conv_filters: Integer, the dimensionality of the output space\n+            (i.e. the number output of filters in the pointwise convolution).\n+        alpha: controls the width of the network.\n+            - If `alpha` < 1.0, proportionally decreases the number\n+                of filters in each layer.\n+            - If `alpha` > 1.0, proportionally increases the number\n+                of filters in each layer.\n+            - If `alpha` = 1, default number of filters from the paper\n+                 are used at each layer.\n+        depth_multiplier: The number of depthwise convolution output channels\n+            for each input channel.\n+            The total number of depthwise convolution output\n+            channels will be equal to `filters_in * depth_multiplier`.\n+        strides: An integer or tuple/list of 2 integers,\n+            specifying the strides of the convolution along the width and height.\n+            Can be a single integer to specify the same value for\n+            all spatial dimensions.\n+            Specifying any stride value != 1 is incompatible with specifying\n+            any `dilation_rate` value != 1.\n+        id: Integer, a unique identification designating  the block number.\n+\n+    # Input shape\n+        4D tensor with shape:\n+        `(batch, channels, rows, cols)` if data_format='channels_first'\n+        or 4D tensor with shape:\n+        `(batch, rows, cols, channels)` if data_format='channels_last'.\n+\n+    # Output shape\n+        4D tensor with shape:\n+        `(batch, filters, new_rows, new_cols)` if data_format='channels_first'\n+        or 4D tensor with shape:\n+        `(batch, new_rows, new_cols, filters)` if data_format='channels_last'.\n+        `rows` and `cols` values might have changed due to stride.\n+    \"\"\"\n+    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n+    pointwise_conv_filters = int(pointwise_conv_filters * alpha)\n+\n+    x = DepthwiseConv2D(kernel_size=(3, 3), padding='same', depth_multiplier=depth_multiplier,\n+                        strides=strides, use_bias=False, name='conv_dw_%d' % id)(input)\n+    x = BatchNormalization(axis=channel_axis, name='conv_dw_%d_bn' % id)(x)\n+    x = Activation(relu6, name='conv_dw_%d_relu' % id)(x)\n+\n+    x = Convolution2D(pointwise_conv_filters, (1, 1), padding='same', use_bias=False, strides=(1, 1),\n+                      name='conv_pw_%d' % id)(x)\n+    x = BatchNormalization(axis=channel_axis, name='conv_pw_%d_bn' % id)(x)\n+    x = Activation(relu6, name='conv_pw_%d_relu' % id)(x)\n+\n+    return x\n\n@@ -1352,6 +1352,16 @@ def conv2d(x, kernel, strides=(1, 1), padding='valid',\n     return _postprocess_conv2d_output(x, data_format)\n \n \n+def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n+                     padding='valid', data_format=None, dilation_rate=(1, 1)):\n+    raise NotImplementedError\n+\n+\n+def depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid',\n+                     data_format=None, dilation_rate=(1, 1)):\n+    raise NotImplementedError\n+\n+\n def conv3d(x, kernel, strides=(1, 1, 1), padding='valid',\n            data_format=None, dilation_rate=(1, 1, 1)):\n     if data_format is None:\n\n@@ -3211,6 +3211,41 @@ def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n     return _postprocess_conv2d_output(x, data_format)\n \n \n+def depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid',\n+                     data_format=None, dilation_rate=(1, 1)):\n+    \"\"\"2D convolution with separable filters.\n+\n+    # Arguments\n+        x: input tensor\n+        depthwise_kernel: convolution kernel for the depthwise convolution.\n+        strides: strides tuple (length 2).\n+        padding: string, `\"same\"` or `\"valid\"`.\n+        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n+        dilation_rate: tuple of integers,\n+            dilation rates for the separable convolution.\n+\n+    # Returns\n+        Output tensor.\n+\n+    # Raises\n+        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n+    \"\"\"\n+    if data_format is None:\n+        data_format = image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n+\n+    x = _preprocess_conv2d_input(x, data_format)\n+    padding = _preprocess_padding(padding)\n+    strides = (1,) + strides + (1,)\n+\n+    x = tf.nn.depthwise_conv2d(x, depthwise_kernel,\n+                               strides=strides,\n+                               padding=padding,\n+                               rate=dilation_rate)\n+    return _postprocess_conv2d_output(x, data_format)\n+\n+\n def conv3d(x, kernel, strides=(1, 1, 1), padding='valid',\n            data_format=None, dilation_rate=(1, 1, 1)):\n     \"\"\"3D convolution.\n\n@@ -1919,6 +1919,11 @@ def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n     raise NotImplementedError\n \n \n+def depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid',\n+                     data_format=None, dilation_rate=(1, 1)):\n+    raise NotImplementedError\n+\n+\n def conv3d(x, kernel, strides=(1, 1, 1),\n            padding='valid', data_format=None,\n            dilation_rate=(1, 1, 1)):\n\n@@ -1,5 +1,8 @@\n import pytest\n from keras.utils.test_utils import keras_test\n+from keras.utils.test_utils import layer_test\n+from keras.utils.generic_utils import CustomObjectScope\n+from keras.models import Sequential\n from keras import applications\n from keras import backend as K\n \n@@ -166,5 +169,73 @@ def test_inceptionv3_pooling():\n     assert model.output_shape == (None, 2048)\n \n \n+@keras_test\n+@pytest.mark.skipif((K.backend() != 'tensorflow'),\n+                    reason=\"MobileNets are supported only on Tensorflow\")\n+def test_mobilenet():\n+    model = applications.MobileNet(weights=None)\n+    assert model.output_shape == (None, 1000)\n+\n+\n+@keras_test\n+@pytest.mark.skipif((K.backend() != 'tensorflow'),\n+                    reason=\"MobileNets are supported only on Tensorflow\")\n+def test_mobilenet_no_top():\n+    model = applications.MobileNet(weights=None, include_top=False)\n+    assert model.output_shape == (None, None, None, 1024)\n+\n+\n+@keras_test\n+@pytest.mark.skipif((K.backend() != 'tensorflow'),\n+                    reason=\"MobileNets are supported only on Tensorflow\")\n+def test_mobilenet_pooling():\n+    model = applications.MobileNet(weights=None, include_top=False, pooling='avg')\n+    assert model.output_shape == (None, 1024)\n+\n+\n+@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TF backend')\n+@keras_test\n+def test_depthwise_conv_2d():\n+    _convolution_paddings = ['valid', 'same']\n+    num_samples = 2\n+    stack_size = 3\n+    num_row = 7\n+    num_col = 6\n+\n+    with CustomObjectScope({'relu6': applications.mobilenet.relu6,\n+                            'DepthwiseConv2D': applications.mobilenet.DepthwiseConv2D}):\n+        for padding in _convolution_paddings:\n+            for strides in [(1, 1), (2, 2)]:\n+                for multiplier in [1, 2]:\n+                    if padding == 'same' and strides != (1, 1):\n+                        continue\n+\n+                    layer_test(applications.mobilenet.DepthwiseConv2D,\n+                               kwargs={'kernel_size': (3, 3),\n+                                       'padding': padding,\n+                                       'strides': strides,\n+                                       'depth_multiplier': multiplier},\n+                               input_shape=(num_samples, num_row, num_col, stack_size))\n+\n+        layer_test(applications.mobilenet.DepthwiseConv2D,\n+                   kwargs={'kernel_size': 3,\n+                           'padding': padding,\n+                           'data_format': 'channels_first',\n+                           'activation': None,\n+                           'depthwise_regularizer': 'l2',\n+                           'bias_regularizer': 'l2',\n+                           'activity_regularizer': 'l2',\n+                           'depthwise_constraint': 'unit_norm',\n+                           'strides': strides,\n+                           'depth_multiplier': multiplier},\n+                   input_shape=(num_samples, stack_size, num_row, num_col))\n+\n+        # Test invalid use case\n+        with pytest.raises(ValueError):\n+            model = Sequential([applications.mobilenet.DepthwiseConv2D(kernel_size=3,\n+                                                                       padding=padding,\n+                                                                       batch_input_shape=(None, None, 5, None))])\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
