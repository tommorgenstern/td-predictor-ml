{"custom_id": "scrapy#569156be190fb7e86108c29001d6233a6698a510", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 35 | Lines Deleted: 0 | Files Changed: 5 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): -85/0 | Churn Δ: 35 | Churn Cumulative: 795 | Contributors (this commit): 15 | Commits (past 90d): 5 | Contributors (cumulative): 34 | DMM Complexity: None\n\nDIFF:\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.linkextractors` is deprecated, \"\n+              \"use `scrapy.linkextractors` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.linkextractors import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.linkextractors.htmlparser` is deprecated, \"\n+              \"use `scrapy.linkextractors.htmlparser` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.linkextractors.htmlparser import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.linkextractors.lxmlhtml` is deprecated, \"\n+              \"use `scrapy.linkextractors.lxmlhtml` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.linkextractors.lxmlhtml import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.linkextractors.regex` is deprecated, \"\n+              \"use `scrapy.linkextractors.regex` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.linkextractors.regex import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.linkextractors.sgml` is deprecated, \"\n+              \"use `scrapy.linkextractors.sgml` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.linkextractors.sgml import *\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#b47228ada8ac583f123434686e8d3493505c7127", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 5 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 83/68 | Churn Δ: 6 | Churn Cumulative: 6 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n\n\n\n@@ -1,8 +1,8 @@\n import unittest\n from functools import partial\n \n-from scrapy.contrib.loader import ItemLoader\n-from scrapy.contrib.loader.processor import Join, Identity, TakeFirst, \\\n+from scrapy.loader import ItemLoader\n+from scrapy.loader.processor import Join, Identity, TakeFirst, \\\n     Compose, MapCompose, SelectJmes\n from scrapy.item import Item, Field\n from scrapy.selector import Selector\n\n@@ -2,7 +2,7 @@ from queuelib.tests import test_queue as t\n from scrapy.squeue import MarshalFifoDiskQueue, MarshalLifoDiskQueue, PickleFifoDiskQueue, PickleLifoDiskQueue\n from scrapy.item import Item, Field\n from scrapy.http import Request\n-from scrapy.contrib.loader import ItemLoader\n+from scrapy.loader import ItemLoader\n \n class TestItem(Item):\n     name = Field()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#d7e60f3c718bb9fbfd4151825b009a0a1d042fc4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): -70/0 | Churn Δ: 21 | Churn Cumulative: 394 | Contributors (this commit): 12 | Commits (past 90d): 4 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.loader` is deprecated, \"\n+              \"use `scrapy.loader` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.loader import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.loader.common` is deprecated, \"\n+              \"use `scrapy.loader.common` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.loader.common import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.loader.processor` is deprecated, \"\n+              \"use `scrapy.loader.processor` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.loader.processor import *\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#8021df18d4f1703ad6b40c6e42e08aa627d629ae", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 7 | Files Changed: 8 | Hunks: 6 | Methods Changed: 0 | Complexity Δ (Sum/Max): 84/51 | Churn Δ: 14 | Churn Cumulative: 384 | Contributors (this commit): 18 | Commits (past 90d): 20 | Contributors (cumulative): 30 | DMM Complexity: None\n\nDIFF:\n\n@@ -21,7 +21,7 @@ except ImportError:\n \n from twisted.internet import defer, threads\n \n-from scrapy.contrib.pipeline.media import MediaPipeline\n+from scrapy.pipelines.media import MediaPipeline\n from scrapy.exceptions import NotConfigured, IgnoreRequest\n from scrapy.http import Request\n from scrapy.utils.misc import md5sum\n\n@@ -17,8 +17,8 @@ from PIL import Image\n from scrapy.utils.misc import md5sum\n from scrapy.http import Request\n from scrapy.exceptions import DropItem\n-#TODO: from scrapy.contrib.pipeline.media import MediaPipeline\n-from scrapy.contrib.pipeline.files import FileException, FilesPipeline\n+#TODO: from scrapy.pipelines.media import MediaPipeline\n+from scrapy.pipelines.files import FileException, FilesPipeline\n \n \n class NoimagesDrop(DropItem):\n\n\n@@ -159,7 +159,7 @@ HTTPCACHE_DBM_MODULE = 'anydbm'\n HTTPCACHE_POLICY = 'scrapy.contrib.httpcache.DummyPolicy'\n HTTPCACHE_GZIP = False\n \n-ITEM_PROCESSOR = 'scrapy.contrib.pipeline.ItemPipelineManager'\n+ITEM_PROCESSOR = 'scrapy.pipelines.ItemPipelineManager'\n \n ITEM_PIPELINES = {}\n ITEM_PIPELINES_BASE = {}\n\n@@ -8,7 +8,7 @@ from shutil import rmtree\n from twisted.trial import unittest\n from twisted.internet import defer\n \n-from scrapy.contrib.pipeline.files import FilesPipeline, FSFilesStore\n+from scrapy.pipelines.files import FilesPipeline, FSFilesStore\n from scrapy.item import Item, Field\n from scrapy.http import Request, Response\n from scrapy.settings import Settings\n\n@@ -9,7 +9,7 @@ from twisted.trial import unittest\n from scrapy.item import Item, Field\n from scrapy.http import Request, Response\n from scrapy.settings import Settings\n-from scrapy.contrib.pipeline.images import ImagesPipeline\n+from scrapy.pipelines.images import ImagesPipeline\n \n skip = False\n try:\n\n@@ -8,7 +8,7 @@ from twisted.internet.defer import Deferred, inlineCallbacks\n from scrapy.http import Request, Response\n from scrapy.spider import Spider\n from scrapy.utils.request import request_fingerprint\n-from scrapy.contrib.pipeline.media import MediaPipeline\n+from scrapy.pipelines.media import MediaPipeline\n from scrapy.utils.signal import disconnect_all\n from scrapy import signals\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c97a69c9071677b0ff7974e8fd1ef42acb9e207a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 0 | Files Changed: 4 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): -114/0 | Churn Δ: 28 | Churn Cumulative: 2293 | Contributors (this commit): 15 | Commits (past 90d): 13 | Contributors (cumulative): 31 | DMM Complexity: None\n\nDIFF:\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.pipeline` is deprecated, \"\n+              \"use `scrapy.pipelines` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.pipelines import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.pipeline.files` is deprecated, \"\n+              \"use `scrapy.pipelines.files` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.pipelines.files import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.pipeline.images` is deprecated, \"\n+              \"use `scrapy.pipelines.images` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.pipelines.images import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.pipeline.media` is deprecated, \"\n+              \"use `scrapy.pipelines.media` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.pipelines.media import *\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#180272c09272c2dd47af65d5fb4cb914b051623a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 10 | Files Changed: 12 | Hunks: 6 | Methods Changed: 0 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 20 | Churn Cumulative: 394 | Contributors (this commit): 17 | Commits (past 90d): 22 | Contributors (cumulative): 34 | DMM Complexity: None\n\nDIFF:\n@@ -224,11 +224,11 @@ SPIDER_MIDDLEWARES = {}\n \n SPIDER_MIDDLEWARES_BASE = {\n     # Engine side\n-    'scrapy.contrib.spidermiddleware.httperror.HttpErrorMiddleware': 50,\n-    'scrapy.contrib.spidermiddleware.offsite.OffsiteMiddleware': 500,\n-    'scrapy.contrib.spidermiddleware.referer.RefererMiddleware': 700,\n-    'scrapy.contrib.spidermiddleware.urllength.UrlLengthMiddleware': 800,\n-    'scrapy.contrib.spidermiddleware.depth.DepthMiddleware': 900,\n+    'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware': 50,\n+    'scrapy.spidermiddlewares.offsite.OffsiteMiddleware': 500,\n+    'scrapy.spidermiddlewares.referer.RefererMiddleware': 700,\n+    'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware': 800,\n+    'scrapy.spidermiddlewares.depth.DepthMiddleware': 900,\n     # Spider side\n }\n \n\n\n\n\n\n\n\n@@ -1,6 +1,6 @@\n from unittest import TestCase\n \n-from scrapy.contrib.spidermiddleware.depth import DepthMiddleware\n+from scrapy.spidermiddlewares.depth import DepthMiddleware\n from scrapy.http import Response, Request\n from scrapy.spider import Spider\n from scrapy.statscol import StatsCollector\n\n@@ -8,7 +8,7 @@ from scrapy.utils.test import get_crawler\n from tests.mockserver import MockServer\n from scrapy.http import Response, Request\n from scrapy.spider import Spider\n-from scrapy.contrib.spidermiddleware.httperror import HttpErrorMiddleware, HttpError\n+from scrapy.spidermiddlewares.httperror import HttpErrorMiddleware, HttpError\n from scrapy.settings import Settings\n \n \n\n@@ -4,7 +4,7 @@ from six.moves.urllib.parse import urlparse\n \n from scrapy.http import Response, Request\n from scrapy.spider import Spider\n-from scrapy.contrib.spidermiddleware.offsite import OffsiteMiddleware\n+from scrapy.spidermiddlewares.offsite import OffsiteMiddleware\n from scrapy.utils.test import get_crawler\n \n class TestOffsiteMiddleware(TestCase):\n\n@@ -2,7 +2,7 @@ from unittest import TestCase\n \n from scrapy.http import Response, Request\n from scrapy.spider import Spider\n-from scrapy.contrib.spidermiddleware.referer import RefererMiddleware\n+from scrapy.spidermiddlewares.referer import RefererMiddleware\n \n \n class TestRefererMiddleware(TestCase):\n\n@@ -1,6 +1,6 @@\n from unittest import TestCase\n \n-from scrapy.contrib.spidermiddleware.urllength import UrlLengthMiddleware\n+from scrapy.spidermiddlewares.urllength import UrlLengthMiddleware\n from scrapy.http import Response, Request\n from scrapy.spider import Spider\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#b2a15ddbf3ad39464670d847a26efc613a4f8a1f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 35 | Lines Deleted: 0 | Files Changed: 6 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): -60/0 | Churn Δ: 35 | Churn Cumulative: 558 | Contributors (this commit): 11 | Commits (past 90d): 14 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.spidermiddleware.depth` is deprecated, \"\n+              \"use `scrapy.spidermiddlewares.depth` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.spidermiddlewares.depth import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.spidermiddleware.httperror` is deprecated, \"\n+              \"use `scrapy.spidermiddlewares.httperror` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.spidermiddlewares.httperror import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.spidermiddleware.offsite` is deprecated, \"\n+              \"use `scrapy.spidermiddlewares.offsite` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.spidermiddlewares.offsite import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.spidermiddleware.referer` is deprecated, \"\n+              \"use `scrapy.spidermiddlewares.referer` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.spidermiddlewares.referer import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.spidermiddleware.urllength` is deprecated, \"\n+              \"use `scrapy.spidermiddlewares.urllength` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.spidermiddlewares.urllength import *\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#fe4b260ef4579219aa53b5215f80da5a5daf5c3a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 77 | Lines Deleted: 0 | Files Changed: 11 | Hunks: 11 | Methods Changed: 0 | Complexity Δ (Sum/Max): -227/0 | Churn Δ: 77 | Churn Cumulative: 2975 | Contributors (this commit): 18 | Commits (past 90d): 24 | Contributors (cumulative): 53 | DMM Complexity: None\n\nDIFF:\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.closespider` is deprecated, \"\n+              \"use `scrapy.extensions.closespider` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.extensions.closespider import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.corestats` is deprecated, \"\n+              \"use `scrapy.extensions.corestats` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.extensions.corestats import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.debug` is deprecated, \"\n+              \"use `scrapy.extensions.debug` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.extensions.debug import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.feedexport` is deprecated, \"\n+              \"use `scrapy.extensions.feedexport` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.extensions.feedexport import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.httpcache` is deprecated, \"\n+              \"use `scrapy.extensions.httpcache` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.extensions.httpcache import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.logstats` is deprecated, \"\n+              \"use `scrapy.extensions.logstats` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.extensions.logstats import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.memdebug` is deprecated, \"\n+              \"use `scrapy.extensions.memdebug` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.extensions.memdebug import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.memusage` is deprecated, \"\n+              \"use `scrapy.extensions.memusage` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.extensions.memusage import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.spiderstate` is deprecated, \"\n+              \"use `scrapy.extensions.spiderstate` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.extensions.spiderstate import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.statsmailer` is deprecated, \"\n+              \"use `scrapy.extensions.statsmailer` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.extensions.statsmailer import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.throttle` is deprecated, \"\n+              \"use `scrapy.extensions.throttle` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.extensions.throttle import *\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#645cdcbf9e6bbffd7fa7655091e64d67567c7f2f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 4 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 46/46 | Churn Δ: 8 | Churn Cumulative: 100 | Contributors (this commit): 6 | Commits (past 90d): 7 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -1,7 +1,7 @@\n import warnings\n from scrapy.exceptions import ScrapyDeprecationWarning\n warnings.warn(\"Module `scrapy.contrib.loader.processor` is deprecated, \"\n-              \"use `scrapy.loader.processor` instead\",\n+              \"use `scrapy.loader.processors` instead\",\n               ScrapyDeprecationWarning, stacklevel=2)\n \n-from scrapy.loader.processor import *\n+from scrapy.loader.processors import *\n\n@@ -14,7 +14,7 @@ from scrapy.utils.misc import arg_to_iter, extract_regex\n from scrapy.utils.python import flatten\n \n from .common import wrap_loader_context\n-from .processor import Identity\n+from .processors import Identity\n \n \n class ItemLoader(object):\n\n\n@@ -2,7 +2,7 @@ import unittest\n from functools import partial\n \n from scrapy.loader import ItemLoader\n-from scrapy.loader.processor import Join, Identity, TakeFirst, \\\n+from scrapy.loader.processors import Join, Identity, TakeFirst, \\\n     Compose, MapCompose, SelectJmes\n from scrapy.item import Item, Field\n from scrapy.selector import Selector\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#7a7c539116df18e43b6e46b510af0d28a19f5084", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 5 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 660 | Contributors (this commit): 10 | Commits (past 90d): 10 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -1,6 +1,6 @@\n from w3lib.url import file_uri_to_path\n from scrapy.responsetypes import responsetypes\n-from scrapy.utils.decorator import defers\n+from scrapy.utils.decorators import defers\n \n class FileDownloadHandler(object):\n \n\n@@ -8,7 +8,7 @@ import six\n \n from scrapy.item import Item\n from scrapy.selector import Selector\n-from scrapy.utils.decorator import deprecated\n+from scrapy.utils.decorators import deprecated\n from scrapy.utils.deprecate import create_deprecated_class\n from scrapy.utils.misc import arg_to_iter, extract_regex\n from scrapy.utils.python import flatten\n\n@@ -8,7 +8,7 @@ import six\n from scrapy.utils.misc import extract_regex\n from scrapy.utils.trackref import object_ref\n from scrapy.utils.python import unicode_to_str, flatten, iflatten\n-from scrapy.utils.decorator import deprecated\n+from scrapy.utils.decorators import deprecated\n from scrapy.http import HtmlResponse, XmlResponse\n from .lxmldocument import LxmlDocument\n from .csstranslator import ScrapyHTMLTranslator, ScrapyGenericTranslator\n\n\n@@ -13,7 +13,7 @@ from twisted.web import http\n from twisted.web.http import RESPONSES\n from w3lib import html\n \n-from scrapy.utils.decorator import deprecated\n+from scrapy.utils.decorators import deprecated\n \n \n @deprecated\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#593b4ef56462b0de9224d05db6d91423e40acf85", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): -9/0 | Churn Δ: 7 | Churn Cumulative: 95 | Contributors (this commit): 4 | Commits (past 90d): 1 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.utils.decorator` is deprecated, \"\n+              \"use `scrapy.utils.decorators` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.utils.decorators import *\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#f5bdf64f9cfd3802cc4d074878ce1d93f72a15db", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 15/15 | Churn Δ: 6 | Churn Cumulative: 329 | Contributors (this commit): 17 | Commits (past 90d): 12 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -215,8 +215,8 @@ RETRY_PRIORITY_ADJUST = -1\n ROBOTSTXT_OBEY = False\n \n SCHEDULER = 'scrapy.core.scheduler.Scheduler'\n-SCHEDULER_DISK_QUEUE = 'scrapy.squeue.PickleLifoDiskQueue'\n-SCHEDULER_MEMORY_QUEUE = 'scrapy.squeue.LifoMemoryQueue'\n+SCHEDULER_DISK_QUEUE = 'scrapy.squeues.PickleLifoDiskQueue'\n+SCHEDULER_MEMORY_QUEUE = 'scrapy.squeues.LifoMemoryQueue'\n \n SPIDER_LOADER_CLASS = 'scrapy.spiderloader.SpiderLoader'\n \n\n\n@@ -1,5 +1,5 @@\n from queuelib.tests import test_queue as t\n-from scrapy.squeue import MarshalFifoDiskQueue, MarshalLifoDiskQueue, PickleFifoDiskQueue, PickleLifoDiskQueue\n+from scrapy.squeues import MarshalFifoDiskQueue, MarshalLifoDiskQueue, PickleFifoDiskQueue, PickleLifoDiskQueue\n from scrapy.item import Item, Field\n from scrapy.http import Request\n from scrapy.loader import ItemLoader\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#fc346cba4d45fb5faf52983b8a25e2a3f5aa12f6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 8 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 137 | Contributors (this commit): 5 | Commits (past 90d): 11 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -1,3 +0,0 @@\n-from scrapy.contrib.spiders.crawl import CrawlSpider, Rule\n-from scrapy.contrib.spiders.feed import XMLFeedSpider, CSVFeedSpider\n-from scrapy.contrib.spiders.sitemap import SitemapSpider\n\n@@ -0,0 +1,3 @@\n+from scrapy.spiders.crawl import CrawlSpider, Rule\n+from scrapy.spiders.feed import XMLFeedSpider, CSVFeedSpider\n+from scrapy.spiders.sitemap import SitemapSpider\n\n\n\n\n\n@@ -10,8 +10,8 @@ from scrapy import signals\n from scrapy.spider import Spider, BaseSpider\n from scrapy.settings import Settings\n from scrapy.http import Request, Response, TextResponse, XmlResponse, HtmlResponse\n-from scrapy.contrib.spiders.init import InitSpider\n-from scrapy.contrib.spiders import CrawlSpider, Rule, XMLFeedSpider, \\\n+from scrapy.spiders.init import InitSpider\n+from scrapy.spiders import CrawlSpider, Rule, XMLFeedSpider, \\\n     CSVFeedSpider, SitemapSpider\n from scrapy.linkextractors import LinkExtractor\n from scrapy.exceptions import ScrapyDeprecationWarning\n\n@@ -3,7 +3,7 @@ from scrapy.http import Request\n from scrapy.item import BaseItem\n from scrapy.utils.spider import iterate_spider_output, iter_spider_classes\n \n-from scrapy.contrib.spiders import CrawlSpider\n+from scrapy.spiders import CrawlSpider\n \n \n class MyBaseSpider(CrawlSpider):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#78dcd4e1e71501da3e4e13780b6c6b89738d61c5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): -6/0 | Churn Δ: 7 | Churn Cumulative: 99 | Contributors (this commit): 4 | Commits (past 90d): 1 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.squeue` is deprecated, \"\n+              \"use `scrapy.squeues` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.squeues import *\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#e262c5b8d5225897dda7976d2376c0ac29bf73ac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 35 | Lines Deleted: 0 | Files Changed: 5 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): -90/0 | Churn Δ: 35 | Churn Cumulative: 525 | Contributors (this commit): 11 | Commits (past 90d): 9 | Contributors (cumulative): 26 | DMM Complexity: None\n\nDIFF:\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.spiders` is deprecated, \"\n+              \"use `scrapy.spiders` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.spiders import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.spiders.crawl` is deprecated, \"\n+              \"use `scrapy.spiders.crawl` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.spiders.crawl import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.spiders.feed` is deprecated, \"\n+              \"use `scrapy.spiders.feed` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.spiders.feed import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.spiders.init` is deprecated, \"\n+              \"use `scrapy.spiders.init` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.spiders.init import *\n\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.contrib.spiders.sitemap` is deprecated, \"\n+              \"use `scrapy.spiders.sitemap` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.spiders.sitemap import *\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#54a4ce069c884fba8edec1fe1b850ec5634e93f9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 3 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 4 | Churn Cumulative: 331 | Contributors (this commit): 17 | Commits (past 90d): 13 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n\n@@ -100,7 +100,7 @@ DOWNLOADER_MIDDLEWARES_BASE = {\n \n DOWNLOADER_STATS = True\n \n-DUPEFILTER_CLASS = 'scrapy.dupefilter.RFPDupeFilter'\n+DUPEFILTER_CLASS = 'scrapy.dupefilters.RFPDupeFilter'\n \n try:\n     EDITOR = os.environ['EDITOR']\n\n@@ -1,7 +1,7 @@\n import hashlib\n import unittest\n \n-from scrapy.dupefilter import RFPDupeFilter\n+from scrapy.dupefilters import RFPDupeFilter\n from scrapy.http import Request\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#9a3e3ba505361efd12e49a42f1c77f5fa815b86a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 37 | Files Changed: 17 | Hunks: 14 | Methods Changed: 1 | Complexity Δ (Sum/Max): 49/27 | Churn Δ: 61 | Churn Cumulative: 415 | Contributors (this commit): 18 | Commits (past 90d): 32 | Contributors (cumulative): 36 | DMM Complexity: 0.0\n\nDIFF:\n@@ -90,16 +90,3 @@ class HttpCacheMiddleware(object):\n             self.storage.store_response(spider, request, response)\n         else:\n             self.stats.inc_value('httpcache/uncacheable', spider=spider)\n-\n-\n-from scrapy.contrib.httpcache import FilesystemCacheStorage as _FilesystemCacheStorage\n-class FilesystemCacheStorage(_FilesystemCacheStorage):\n-\n-    def __init__(self, *args, **kwargs):\n-        import warnings\n-        from scrapy.exceptions import ScrapyDeprecationWarning\n-        warnings.warn('Importing FilesystemCacheStorage from '\n-                      'scrapy.contrib.downloadermiddlware.httpcache is '\n-                      'deprecated, use scrapy.contrib.httpcache instead.',\n-                      category=ScrapyDeprecationWarning, stacklevel=1)\n-        super(FilesystemCacheStorage, self).__init__(*args, **kwargs)\n\n\n\n\n\n\n\n\n\n\n\n\n\n@@ -113,15 +113,15 @@ except KeyError:\n EXTENSIONS = {}\n \n EXTENSIONS_BASE = {\n-    'scrapy.contrib.corestats.CoreStats': 0,\n+    'scrapy.extensions.corestats.CoreStats': 0,\n     'scrapy.telnet.TelnetConsole': 0,\n-    'scrapy.contrib.memusage.MemoryUsage': 0,\n-    'scrapy.contrib.memdebug.MemoryDebugger': 0,\n-    'scrapy.contrib.closespider.CloseSpider': 0,\n-    'scrapy.contrib.feedexport.FeedExporter': 0,\n-    'scrapy.contrib.logstats.LogStats': 0,\n-    'scrapy.contrib.spiderstate.SpiderState': 0,\n-    'scrapy.contrib.throttle.AutoThrottle': 0,\n+    'scrapy.extensions.memusage.MemoryUsage': 0,\n+    'scrapy.extensions.memdebug.MemoryDebugger': 0,\n+    'scrapy.extensions.closespider.CloseSpider': 0,\n+    'scrapy.extensions.feedexport.FeedExporter': 0,\n+    'scrapy.extensions.logstats.LogStats': 0,\n+    'scrapy.extensions.spiderstate.SpiderState': 0,\n+    'scrapy.extensions.throttle.AutoThrottle': 0,\n }\n \n FEED_URI = None\n@@ -131,11 +131,11 @@ FEED_STORE_EMPTY = False\n FEED_EXPORT_FIELDS = None\n FEED_STORAGES = {}\n FEED_STORAGES_BASE = {\n-    '': 'scrapy.contrib.feedexport.FileFeedStorage',\n-    'file': 'scrapy.contrib.feedexport.FileFeedStorage',\n-    'stdout': 'scrapy.contrib.feedexport.StdoutFeedStorage',\n-    's3': 'scrapy.contrib.feedexport.S3FeedStorage',\n-    'ftp': 'scrapy.contrib.feedexport.FTPFeedStorage',\n+    '': 'scrapy.extensions.feedexport.FileFeedStorage',\n+    'file': 'scrapy.extensions.feedexport.FileFeedStorage',\n+    'stdout': 'scrapy.extensions.feedexport.StdoutFeedStorage',\n+    's3': 'scrapy.extensions.feedexport.S3FeedStorage',\n+    'ftp': 'scrapy.extensions.feedexport.FTPFeedStorage',\n }\n FEED_EXPORTERS = {}\n FEED_EXPORTERS_BASE = {\n@@ -151,12 +151,12 @@ FEED_EXPORTERS_BASE = {\n HTTPCACHE_ENABLED = False\n HTTPCACHE_DIR = 'httpcache'\n HTTPCACHE_IGNORE_MISSING = False\n-HTTPCACHE_STORAGE = 'scrapy.contrib.httpcache.FilesystemCacheStorage'\n+HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'\n HTTPCACHE_EXPIRATION_SECS = 0\n HTTPCACHE_IGNORE_HTTP_CODES = []\n HTTPCACHE_IGNORE_SCHEMES = ['file']\n HTTPCACHE_DBM_MODULE = 'anydbm'\n-HTTPCACHE_POLICY = 'scrapy.contrib.httpcache.DummyPolicy'\n+HTTPCACHE_POLICY = 'scrapy.extensions.httpcache.DummyPolicy'\n HTTPCACHE_GZIP = False\n \n ITEM_PROCESSOR = 'scrapy.pipelines.ItemPipelineManager'\n\n@@ -17,8 +17,8 @@ from scrapy.downloadermiddlewares.httpcache import HttpCacheMiddleware\n \n class _BaseTest(unittest.TestCase):\n \n-    storage_class = 'scrapy.contrib.httpcache.DbmCacheStorage'\n-    policy_class = 'scrapy.contrib.httpcache.RFC2616Policy'\n+    storage_class = 'scrapy.extensions.httpcache.DbmCacheStorage'\n+    policy_class = 'scrapy.extensions.httpcache.RFC2616Policy'\n \n     def setUp(self):\n         self.yesterday = email.utils.formatdate(time.time() - 86400)\n@@ -127,7 +127,7 @@ class DefaultStorageTest(_BaseTest):\n \n class DbmStorageTest(DefaultStorageTest):\n \n-    storage_class = 'scrapy.contrib.httpcache.DbmCacheStorage'\n+    storage_class = 'scrapy.extensions.httpcache.DbmCacheStorage'\n \n \n class DbmStorageWithCustomDbmModuleTest(DbmStorageTest):\n@@ -146,7 +146,7 @@ class DbmStorageWithCustomDbmModuleTest(DbmStorageTest):\n \n class FilesystemStorageTest(DefaultStorageTest):\n \n-    storage_class = 'scrapy.contrib.httpcache.FilesystemCacheStorage'\n+    storage_class = 'scrapy.extensions.httpcache.FilesystemCacheStorage'\n \n class FilesystemStorageGzipTest(FilesystemStorageTest):\n \n@@ -157,12 +157,12 @@ class FilesystemStorageGzipTest(FilesystemStorageTest):\n class LeveldbStorageTest(DefaultStorageTest):\n \n     pytest.importorskip('leveldb')\n-    storage_class = 'scrapy.contrib.httpcache.LeveldbCacheStorage'\n+    storage_class = 'scrapy.extensions.httpcache.LeveldbCacheStorage'\n \n \n class DummyPolicyTest(_BaseTest):\n \n-    policy_class = 'scrapy.contrib.httpcache.DummyPolicy'\n+    policy_class = 'scrapy.extensions.httpcache.DummyPolicy'\n \n     def test_middleware(self):\n         with self._middleware() as mw:\n@@ -254,7 +254,7 @@ class DummyPolicyTest(_BaseTest):\n \n class RFC2616PolicyTest(DefaultStorageTest):\n \n-    policy_class = 'scrapy.contrib.httpcache.RFC2616Policy'\n+    policy_class = 'scrapy.extensions.httpcache.RFC2616Policy'\n \n     def _process_requestresponse(self, mw, request, response):\n         try:\n\n@@ -16,7 +16,7 @@ from tests.mockserver import MockServer\n from w3lib.url import path_to_file_uri\n \n import scrapy\n-from scrapy.contrib.feedexport import (\n+from scrapy.extensions.feedexport import (\n     IFeedStorage, FileFeedStorage, FTPFeedStorage,\n     S3FeedStorage, StdoutFeedStorage\n )\n\n@@ -2,7 +2,7 @@ import os\n from datetime import datetime\n from twisted.trial import unittest\n \n-from scrapy.contrib.spiderstate import SpiderState\n+from scrapy.extensions.spiderstate import SpiderState\n from scrapy.spider import Spider\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#4ddf152be37db5e4307cb62f42389c5fc71b6814", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): -18/0 | Churn Δ: 7 | Churn Cumulative: 141 | Contributors (this commit): 5 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.dupefilter` is deprecated, \"\n+              \"use `scrapy.dupefilters` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.dupefilters import *\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#b827097c91eb27c5d747935155497cb87edcb816", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 4 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 376 | Contributors (this commit): 17 | Commits (past 90d): 17 | Contributors (cumulative): 22 | DMM Complexity: None\n\nDIFF:\n@@ -234,7 +234,7 @@ SPIDER_MIDDLEWARES_BASE = {\n \n SPIDER_MODULES = []\n \n-STATS_CLASS = 'scrapy.statscol.MemoryStatsCollector'\n+STATS_CLASS = 'scrapy.statscollectors.MemoryStatsCollector'\n STATS_DUMP = True\n \n STATSMAILER_RCPTS = []\n\n\n@@ -3,7 +3,7 @@ from unittest import TestCase\n from scrapy.spidermiddlewares.depth import DepthMiddleware\n from scrapy.http import Response, Request\n from scrapy.spider import Spider\n-from scrapy.statscol import StatsCollector\n+from scrapy.statscollectors import StatsCollector\n from scrapy.utils.test import get_crawler\n \n \n\n@@ -1,7 +1,7 @@\n import unittest\n \n from scrapy.spider import Spider\n-from scrapy.statscol import StatsCollector, DummyStatsCollector\n+from scrapy.statscollectors import StatsCollector, DummyStatsCollector\n from scrapy.utils.test import get_crawler\n \n class StatsCollectorTest(unittest.TestCase):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#62191de6eae7bbad227361dded8d4726da0e8a11", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): -21/0 | Churn Δ: 7 | Churn Cumulative: 94 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -0,0 +1,7 @@\n+import warnings\n+from scrapy.exceptions import ScrapyDeprecationWarning\n+warnings.warn(\"Module `scrapy.statscol` is deprecated, \"\n+              \"use `scrapy.statscollectors` instead\",\n+              ScrapyDeprecationWarning, stacklevel=2)\n+\n+from scrapy.statscollectors import *\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#3243a13b80519650644bd5e1d500aa7dfd69bfd1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 6 | Churn Cumulative: 193 | Contributors (this commit): 1 | Commits (past 90d): 10 | Contributors (cumulative): 1 | DMM Complexity: 0.0\n\nDIFF:\n@@ -10,7 +10,7 @@ from twisted.python.failure import Failure\n from twisted.python import log as twisted_log\n \n import scrapy\n-from scrapy.settings import overridden_settings\n+from scrapy.settings import overridden_settings, Settings\n from scrapy.exceptions import ScrapyDeprecationWarning\n \n logger = logging.getLogger(__name__)\n@@ -92,6 +92,10 @@ def configure_logging(settings=None):\n     observer.start()\n \n     dictConfig(DEFAULT_LOGGING)\n+\n+    if isinstance(settings, dict):\n+        settings = Settings(settings)\n+\n     if settings:\n         logging.root.setLevel(logging.NOTSET)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#353672d292492446cc0a8f95d2b06caa58965dbe", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 79 | Contributors (this commit): 5 | Commits (past 90d): 2 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -26,7 +26,10 @@ sys.path.append(path.join(path.dirname(path.dirname(__file__)), \"scrapy\"))\n \n # Add any Sphinx extension module names here, as strings. They can be extensions\n # coming with Sphinx (named 'sphinx.ext.*') or your custom ones.\n-extensions = ['scrapydocs']\n+extensions = [\n+    'scrapydocs',\n+    'sphinx.ext.autodoc'\n+]\n \n # Add any paths that contain templates here, relative to this directory.\n templates_path = ['_templates']\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#a2ce78db63c32212512d2f9223b42cf4eb051b8e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 43 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 44 | Churn Cumulative: 1254 | Contributors (this commit): 7 | Commits (past 90d): 16 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -89,6 +89,17 @@ class Crawler(object):\n \n \n class CrawlerRunner(object):\n+    \"\"\"\n+    This is a convenient helper class that keeps track of, manages and runs\n+    crawlers inside an already setup Twisted `reactor`_.\n+\n+    The CrawlerRunner object must be instantiated with a\n+    :class:`~scrapy.settings.Settings` object.\n+\n+    This class shouldn't be needed (since Scrapy is responsible of using it\n+    accordingly) unless writing scripts that manually handle the crawling\n+    process. See :ref:`run-from-script` for an example.\n+    \"\"\"\n \n     def __init__(self, settings):\n         if isinstance(settings, dict):\n@@ -106,6 +117,27 @@ class CrawlerRunner(object):\n         return self.spider_loader\n \n     def crawl(self, crawler_or_spidercls, *args, **kwargs):\n+        \"\"\"\n+        Run a crawler with the provided arguments.\n+\n+        It will call the given Crawler's :meth:`~Crawler.crawl` method, while\n+        keeping track of it so it can be stopped later.\n+\n+        If `crawler_or_spidercls` isn't a :class:`~scrapy.crawler.Crawler`\n+        instance, this method will try to create one using this parameter as\n+        the spider class given to it.\n+\n+        Returns a deferred that is fired when the crawling is finished.\n+\n+        :param crawler_or_spidercls: already created crawler, or a spider class\n+            or spider's name inside the project to create it\n+        :type crawler_or_spidercls: :class:`~scrapy.crawler.Crawler` instance,\n+            :class:`~scrapy.spider.Spider` subclass or string\n+\n+        :param list args: arguments to initialize the spider\n+\n+        :param dict kwargs: keyword arguments to initialize the spider\n+        \"\"\"\n         crawler = crawler_or_spidercls\n         if not isinstance(crawler_or_spidercls, Crawler):\n             crawler = self._create_crawler(crawler_or_spidercls)\n@@ -127,11 +159,21 @@ class CrawlerRunner(object):\n         return Crawler(spidercls, self.settings)\n \n     def stop(self):\n+        \"\"\"\n+        Stops simultaneously all the crawling jobs taking place.\n+\n+        Returns a deferred that is fired when they all have ended.\n+        \"\"\"\n         return defer.DeferredList([c.stop() for c in list(self.crawlers)])\n \n     @defer.inlineCallbacks\n     def join(self):\n-        \"\"\"Wait for all managed crawlers to complete\"\"\"\n+        \"\"\"\n+        join()\n+\n+        Returns a deferred that is fired when all managed :attr:`crawlers` have\n+        completed their executions.\n+        \"\"\"\n         while self._active:\n             yield defer.DeferredList(self._active)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#8f276b8e9c39cf69f8b2c3e981167109b3c159a5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 1262 | Contributors (this commit): 7 | Commits (past 90d): 17 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -101,12 +101,18 @@ class CrawlerRunner(object):\n     process. See :ref:`run-from-script` for an example.\n     \"\"\"\n \n+    crawlers = property(\n+        lambda self: self._crawlers,\n+        doc=\"Set of :class:`crawlers <scrapy.crawler.Crawler>` started by \"\n+            \":meth:`crawl` and managed by this class.\"\n+    )\n+\n     def __init__(self, settings):\n         if isinstance(settings, dict):\n             settings = Settings(settings)\n         self.settings = settings\n         self.spider_loader = _get_spider_loader(settings)\n-        self.crawlers = set()\n+        self._crawlers = set()\n         self._active = set()\n \n     @property\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#3a71504d35a5e5b9eacf29c63c9a317f5167e3db", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 29 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 30 | Churn Cumulative: 1292 | Contributors (this commit): 7 | Commits (past 90d): 18 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -185,7 +185,24 @@ class CrawlerRunner(object):\n \n \n class CrawlerProcess(CrawlerRunner):\n-    \"\"\"A class to run multiple scrapy crawlers in a process simultaneously\"\"\"\n+    \"\"\"\n+    A class to run multiple scrapy crawlers in a process simultaneously.\n+\n+    This class extends :class:`~scrapy.crawler.CrawlerRunner` by adding support\n+    for starting a Twisted `reactor`_ and handling shutdown signals, like the\n+    keyboard interrupt command Ctrl-C. It also configures top-level logging.\n+\n+    This utility should be a better fit than\n+    :class:`~scrapy.crawler.CrawlerRunner` if you aren't running another\n+    Twisted `reactor`_ within your application.\n+\n+    The CrawlerProcess object must be instantiated with a\n+    :class:`~scrapy.settings.Settings` object.\n+\n+    This class shouldn't be needed (since Scrapy is responsible of using it\n+    accordingly) unless writing scripts that manually handle the crawling\n+    process. See :ref:`run-from-script` for an example.\n+    \"\"\"\n \n     def __init__(self, settings):\n         super(CrawlerProcess, self).__init__(settings)\n@@ -209,6 +226,17 @@ class CrawlerProcess(CrawlerRunner):\n         reactor.callFromThread(self._stop_reactor)\n \n     def start(self, stop_after_crawl=True):\n+        \"\"\"\n+        This method starts a Twisted `reactor`_, adjusts its pool size to\n+        :setting:`REACTOR_THREADPOOL_MAXSIZE`, and installs a DNS cache based\n+        on :setting:`DNSCACHE_ENABLED` and :setting:`DNSCACHE_SIZE`.\n+\n+        If `stop_after_crawl` is True, the reactor will be stopped after all\n+        crawlers have finished, using :meth:`join`.\n+\n+        :param boolean stop_after_crawl: stop or not the reactor when all\n+            crawlers have finished\n+        \"\"\"\n         if stop_after_crawl:\n             d = self.join()\n             # Don't start the reactor if the deferreds are already fired\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
