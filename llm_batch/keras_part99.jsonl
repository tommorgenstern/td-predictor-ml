{"custom_id": "keras#b235f91cc74b8e4f76d81378ab546a762449f13c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 4297 | Contributors (this commit): 26 | Commits (past 90d): 13 | Contributors (cumulative): 26 | DMM Complexity: None\n\nDIFF:\n@@ -54,7 +54,7 @@ class Recurrent(Layer):\n         # as the first layer in a Sequential model\n         model = Sequential()\n         model.add(LSTM(32, input_shape=(10, 64)))\n-        # now model.output_shape == (None, 10, 32)\n+        # now model.output_shape == (None, 32)\n         # note: `None` is the batch dimension.\n \n         # the following is identical:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b6ca3ef051107f544b97cdb315eaf1b8e12665d9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 5 | Churn Cumulative: 1581 | Contributors (this commit): 21 | Commits (past 90d): 11 | Contributors (cumulative): 21 | DMM Complexity: 0.0\n\nDIFF:\n@@ -210,10 +210,7 @@ class History(Callback):\n     def on_epoch_end(self, epoch, logs={}):\n         self.epoch.append(epoch)\n         for k, v in logs.items():\n-            if k not in self.history:\n-                self.history[k] = []\n-            self.history[k].append(v)\n-\n+            self.history.setdefault(k, []).append(v)\n \n class ModelCheckpoint(Callback):\n     '''Save the model after every epoch.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#703c2925b3ead8d3f23fc9acee1d90b9c7d46835", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1647 | Contributors (this commit): 21 | Commits (past 90d): 28 | Contributors (cumulative): 21 | DMM Complexity: None\n\nDIFF:\n@@ -123,6 +123,7 @@ def shape(x):\n def int_shape(x):\n     '''Returns the shape of a tensor as a tuple of\n     integers or None entries.\n+    Note that this function only works with TensorFlow. \n     '''\n     shape = x.get_shape()\n     return tuple([i.__int__() for i in shape])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cb3469215ab78219a0ae58f566ddeba2fe6242fb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1926 | Contributors (this commit): 13 | Commits (past 90d): 41 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -778,6 +778,7 @@ class Model(Container):\n                 np.random.shuffle(index_array)\n \n             batches = make_batches(nb_train_sample, batch_size)\n+            epoch_logs = {}\n             for batch_index, (batch_start, batch_end) in enumerate(batches):\n                 batch_ids = index_array[batch_start:batch_end]\n                 try:\n@@ -802,7 +803,6 @@ class Model(Container):\n \n                 callbacks.on_batch_end(batch_index, batch_logs)\n \n-                epoch_logs = {}\n                 if batch_index == len(batches) - 1:  # last batch\n                     # validation\n                     if do_validation:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cdb5b09cd7f1f02d9eced2ad75b55cd56c679d34", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1190 | Contributors (this commit): 14 | Commits (past 90d): 17 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -532,7 +532,7 @@ class DirectoryIterator(Iterator):\n \n         if not classes:\n             classes = []\n-            for subdir in os.listdir(directory):\n+            for subdir in sorted(os.listdir(directory)):\n                 if os.path.isdir(os.path.join(directory, subdir)):\n                     classes.append(subdir)\n         self.nb_class = len(classes)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#258cf3b0f73642116b395656fe498df8d827efcd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 108 | Lines Deleted: 10 | Files Changed: 6 | Hunks: 15 | Methods Changed: 12 | Complexity Δ (Sum/Max): 16/12 | Churn Δ: 118 | Churn Cumulative: 18534 | Contributors (this commit): 77 | Commits (past 90d): 128 | Contributors (cumulative): 137 | DMM Complexity: 0.6271186440677966\n\nDIFF:\n@@ -354,6 +354,17 @@ def any(x, axis=None, keepdims=False):\n     return tf.cast(x, tf.uint8)\n \n \n+def all(x, axis=None, keepdims=False):\n+    '''Bitwise reduction (logical AND).\n+\n+    Returns an uint8 tensor\n+    '''\n+    axis = _normalize_axis(axis, ndim(x))\n+    x = tf.cast(x, tf.bool)\n+    x = tf.reduce_all(x, reduction_indices=axis, keep_dims=keepdims)\n+    return tf.cast(x, tf.uint8)\n+\n+\n def argmax(x, axis=-1):\n     '''Returns the index of the maximum value\n     along a tensor axis.\n\n@@ -210,6 +210,12 @@ def any(x, axis=None, keepdims=False):\n     return T.any(x, axis=axis, keepdims=keepdims)\n \n \n+def all(x, axis=None, keepdims=False):\n+    '''Bitwise reduction (logical AND).\n+    '''\n+    return T.all(x, axis=axis, keepdims=keepdims)\n+\n+\n def argmax(x, axis=-1):\n     return T.argmax(x, axis=axis, keepdims=False)\n \n\n@@ -1075,9 +1075,12 @@ class Merge(Layer):\n         tensor_indices: optional list of indices of output tensors\n             to consider for merging\n             (in case some input layer node returns multiple tensors).\n+        output_mask: mask or lambda/function to compute the output mask (only\n+            if merge mode is a lambda/function). If the latter case, it should\n+            take as input a list of masks and return a single mask.\n     '''\n     def __init__(self, layers=None, mode='sum', concat_axis=-1,\n-                 dot_axes=-1, output_shape=None,\n+                 dot_axes=-1, output_shape=None, output_mask=None,\n                  node_indices=None, tensor_indices=None, name=None):\n         self.layers = layers\n         self.mode = mode\n@@ -1087,6 +1090,7 @@ class Merge(Layer):\n             self.dot_axes = [self.dot_axes, ] * 2\n         self._output_shape = output_shape\n         self.node_indices = node_indices\n+        self._output_mask = output_mask\n \n         # layer parameters\n         self.inbound_nodes = []\n@@ -1095,7 +1099,7 @@ class Merge(Layer):\n         self.regularizers = []\n         self.trainable_weights = []\n         self.non_trainable_weights = []\n-        self.supports_masking = False\n+        self.supports_masking = True\n         self.uses_learning_phase = False\n         self.input_spec = None  # compatible with whatever\n         if not name:\n@@ -1316,14 +1320,31 @@ class Merge(Layer):\n         elif self.mode == 'cos':\n             return (input_shapes[0][0], 1)\n \n-    def compute_mask(self, input, mask=None):\n-        '''TODO: add mask merging support\n-        '''\n-        if mask is not None and any(mask):\n-            raise Exception('Merge does not support masking, ' +\n-                            'but was passed an input mask: ' + str(mask))\n+    def compute_mask(self, inputs, mask=None):\n+        if mask is None or not any([m is not None for m in mask]):\n             return None\n \n+        assert hasattr(mask, '__len__') and len(mask) == len(inputs)\n+\n+        if self.mode in ['sum', 'mul', 'ave']:\n+            masks = [K.expand_dims(m, 0) for m in mask if m is not None]\n+            return K.all(K.concatenate(masks, axis=0), axis=0, keepdims=False)\n+        elif self.mode == 'concat':\n+            masks = [K.ones_like(inputs[i][:-1]) if m is None else m for i, m in zip(inputs, mask)]\n+            expanded_dims = [K.expand_dims(m) for m in masks]\n+            concatenated = K.concatenate(expanded_dims, axis=self.concat_axis)\n+            return K.all(concatenated, axis=-1, keepdims=False)\n+        elif self.mode in ['cos', 'dot']:\n+            return None\n+        elif hasattr(self.mode, '__call__'):\n+            if hasattr(self._output_mask, '__call__'):\n+                return self._output_mask(mask)\n+            else:\n+                return self._output_mask\n+        else:\n+            # this should have been caught earlier\n+            raise Exception('Invalid merge mode: {}'.format(self.mode))\n+\n     def get_config(self):\n         py3 = sys.version_info[0] == 3\n \n@@ -1387,7 +1408,7 @@ class Merge(Layer):\n \n \n def merge(inputs, mode='sum', concat_axis=-1,\n-          dot_axes=-1, output_shape=None, name=None):\n+          dot_axes=-1, output_shape=None, output_mask=None, name=None):\n     '''Functional merge, to apply to Keras tensors (NOT layers).\n     Returns a Keras tensor.\n \n@@ -1437,6 +1458,7 @@ def merge(inputs, mode='sum', concat_axis=-1,\n                             concat_axis=concat_axis,\n                             dot_axes=dot_axes,\n                             output_shape=output_shape,\n+                            output_mask=output_mask,\n                             node_indices=node_indices,\n                             tensor_indices=tensor_indices,\n                             name=name)\n@@ -1446,6 +1468,7 @@ def merge(inputs, mode='sum', concat_axis=-1,\n                             concat_axis=concat_axis,\n                             dot_axes=dot_axes,\n                             output_shape=output_shape,\n+                            output_mask=output_mask,\n                             name=name)\n         return merge_layer(inputs)\n \n\n@@ -402,6 +402,8 @@ class Lambda(Layer):\n     def __init__(self, function, output_shape=None, arguments={}, **kwargs):\n         self.function = function\n         self.arguments = arguments\n+        self.supports_masking = True\n+\n         if output_shape is None:\n             self._output_shape = None\n         elif type(output_shape) in {tuple, list}:\n\n@@ -173,6 +173,9 @@ class TestBackend(object):\n         # does not work yet, wait for bool <-> int casting in TF (coming soon)\n         # check_single_tensor_operation('any', (4, 2))\n         # check_single_tensor_operation('any', (4, 2), axis=1, keepdims=True)\n+        #\n+        # check_single_tensor_operation('any', (4, 2))\n+        # check_single_tensor_operation('any', (4, 2), axis=1, keepdims=True)\n \n         check_single_tensor_operation('argmax', (4, 2))\n         check_single_tensor_operation('argmax', (4, 2), axis=1)\n\n@@ -1,6 +1,5 @@\n import pytest\n import numpy as np\n-from numpy.testing import assert_allclose\n \n from keras import backend as K\n from keras.layers import core\n@@ -84,6 +83,60 @@ def test_merge():\n     model.compile('rmsprop', 'mse')\n \n \n+def test_merge_mask_2d():\n+    from keras.layers import Input, merge, Masking\n+    from keras.models import Model\n+\n+    rand = lambda *shape: np.asarray(np.random.random(shape) > 0.5, dtype='int32')\n+\n+    # inputs\n+    input_a = Input(shape=(3,))\n+    input_b = Input(shape=(3,))\n+\n+    # masks\n+    masked_a = Masking(mask_value=0)(input_a)\n+    masked_b = Masking(mask_value=0)(input_b)\n+\n+    # two different types of merging\n+    merged_sum = merge([masked_a, masked_b], mode='sum')\n+    merged_concat = merge([masked_a, masked_b], mode='concat', concat_axis=1)\n+\n+    # test sum\n+    model_sum = Model([input_a, input_b], [merged_sum])\n+    model_sum.compile(loss='mse', optimizer='sgd')\n+    model_sum.fit([rand(2,3), rand(2,3)], [rand(2,3)], nb_epoch=1)\n+\n+    # test concatenation\n+    model_concat = Model([input_a, input_b], [merged_concat])\n+    model_concat.compile(loss='mse', optimizer='sgd')\n+    model_concat.fit([rand(2,3), rand(2,3)], [rand(2,6)], nb_epoch=1)\n+\n+\n+def test_merge_mask_3d():\n+    from keras.layers import Input, merge, Embedding, SimpleRNN\n+    from keras.models import Model\n+\n+    rand = lambda *shape: np.asarray(np.random.random(shape) > 0.5, dtype='int32')\n+\n+    # embeddings\n+    input_a = Input(shape=(3,), dtype='int32')\n+    input_b = Input(shape=(3,), dtype='int32')\n+    embedding = Embedding(3, 4, mask_zero=True)\n+    embedding_a = embedding(input_a)\n+    embedding_b = embedding(input_b)\n+\n+    # rnn\n+    rnn = SimpleRNN(3, return_sequences=True)\n+    rnn_a = rnn(embedding_a)\n+    rnn_b = rnn(embedding_b)\n+\n+    # concatenation\n+    merged_concat = merge([rnn_a, rnn_b], mode='concat', concat_axis=-1)\n+    model = Model([input_a, input_b], [merged_concat])\n+    model.compile(loss='mse', optimizer='sgd')\n+    model.fit([rand(2,3), rand(2,3)], [rand(2,3,6)])\n+\n+\n def test_dropout():\n     layer_test(core.Dropout,\n                kwargs={'p': 0.5},\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5bb5eb1657ea7517179b35f03949f4673b5c32d5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 39 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -26,7 +26,7 @@ def get_model(input_dim, nb_hidden, output_dim):\n     return model\n \n \n-def _test_optimizer(optimizer, target=0.9):\n+def _test_optimizer(optimizer, target=0.89):\n     model = get_model(X_train.shape[1], 10, y_train.shape[1])\n     model.compile(loss='categorical_crossentropy',\n                   optimizer=optimizer,\n@@ -35,7 +35,7 @@ def _test_optimizer(optimizer, target=0.9):\n                         validation_data=(X_test, y_test), verbose=2)\n     config = optimizer.get_config()\n     assert type(config) == dict\n-    assert history.history['val_acc'][-1] > target\n+    assert history.history['val_acc'][-1] >= target\n \n \n def test_sgd():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d266b75423780880ad222598c66d08efbccaa0b0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 203 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -23,7 +23,7 @@ path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/\n text = open(path).read().lower()\n print('corpus length:', len(text))\n \n-chars = set(text)\n+chars = sorted(list(set(text)))\n print('total chars:', len(chars))\n char_indices = dict((c, i) for i, c in enumerate(chars))\n indices_char = dict((i, c) for i, c in enumerate(chars))\n@@ -51,7 +51,6 @@ for i, sentence in enumerate(sentences):\n print('Build model...')\n model = Sequential()\n model.add(LSTM(512, return_sequences=True, input_shape=(maxlen, len(chars))))\n-model.add(Dropout(0.2))\n model.add(LSTM(512, return_sequences=False))\n model.add(Dropout(0.2))\n model.add(Dense(len(chars)))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9b3c2cf3489330320127458fde3b4e39420c0497", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1928 | Contributors (this commit): 14 | Commits (past 90d): 42 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -1080,7 +1080,7 @@ class Model(Container):\n \n     def evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None):\n         '''Returns the loss value and metrics values for the model\n-        in test mode. Computation in done in batches.\n+        in test mode. Computation is done in batches.\n \n         # Arguments\n             x: Numpy array of test data,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#89f6d374e98545c99742102e2d791cacb5d32c35", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 94 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -74,7 +74,7 @@ for i in range(epochs):\n print('Predicting')\n predicted_output = model.predict(cos, batch_size=batch_size)\n \n-print('Ploting Results')\n+print('Plotting Results')\n plt.subplot(2, 1, 1)\n plt.plot(expected_output)\n plt.title('Expected')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8166a55761025a4d66dbde543ec73415d192d603", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 801 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -209,7 +209,7 @@ def test_siamese_1():\n     loss = graph.test_on_batch({'input1': X_test_graph, 'input2': X2_test_graph, 'output1': y_test_graph})\n     loss = graph.train_on_batch({'input1': X_test_graph, 'input2': X2_test_graph, 'output1': y_test_graph})\n     loss = graph.evaluate({'input1': X_test_graph, 'input2': X2_test_graph, 'output1': y_test_graph})\n-    assert(loss < 3.0)\n+    assert(loss < 4.0)\n \n     # test serialization\n     config = graph.get_config()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3f6b38b34f2c2685829e0c24d31f56581b2f0097", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 11 | Churn Cumulative: 1939 | Contributors (this commit): 14 | Commits (past 90d): 43 | Contributors (cumulative): 14 | DMM Complexity: 0.0\n\nDIFF:\n@@ -234,6 +234,9 @@ def collect_metrics(metrics, output_names):\n \n \n def collect_trainable_weights(layer):\n+    '''Collects all `trainable_weights` attributes,\n+    excluding any sublayers where `trainable` is set the `False`.\n+    '''\n     trainable = getattr(layer, 'trainable', True)\n     if not trainable:\n         return []\n@@ -249,6 +252,9 @@ def collect_trainable_weights(layer):\n             weights += collect_trainable_weights(sublayer)\n     else:\n         weights += layer.trainable_weights\n+    # dedupe weights\n+    weights = list(set(weights))\n+    weights.sort(key=lambda x: x.name)\n     return weights\n \n \n@@ -663,10 +669,7 @@ class Model(Container):\n                 inputs = self.inputs + self.targets + self.sample_weights\n \n             # get trainable weights\n-            trainable_weights = []\n-            for layer in self.layers:\n-                trainable_weights += collect_trainable_weights(layer)\n-\n+            trainable_weights = collect_trainable_weights(self)\n             training_updates = self.optimizer.get_updates(trainable_weights, self.constraints, self.total_loss)\n             updates = self.updates + training_updates\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fffa6a80ca04738dfd66ea5f54cd6e1471e7b73f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 7620 | Contributors (this commit): 45 | Commits (past 90d): 21 | Contributors (cumulative): 45 | DMM Complexity: 0.2\n\nDIFF:\n@@ -82,6 +82,7 @@ class Sequential(Model):\n         self.inbound_nodes = []\n         self.outbound_nodes = []\n         self.built = False\n+        self._flattened_layers = None\n \n         if not name:\n             prefix = 'sequential_'\n@@ -155,6 +156,7 @@ class Sequential(Model):\n \n         self.layers.append(layer)\n         self.built = False\n+        self._flattened_layers = None\n \n     def call(self, x, mask=None):\n         if not self.built:\n@@ -197,6 +199,8 @@ class Sequential(Model):\n \n     @property\n     def flattened_layers(self):\n+        if self._flattened_layers is not None:\n+            return self._flattened_layers\n         layers = []\n         if self.layers[0].__class__.__name__ == 'Merge':\n             merge = self.layers[0]\n@@ -218,6 +222,7 @@ class Sequential(Model):\n         for layer in self.layers[1:]:\n             if layer not in layers:\n                 layers.append(layer)\n+        self._flattened_layers = layers\n         return layers\n \n     def _gather_list_attr(self, attr):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4d404d1a5472bde5bef703bf8976022505d04ce9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 209 | Contributors (this commit): 8 | Commits (past 90d): 15 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -15,4 +15,4 @@ from . import objectives\n from . import optimizers\r\n from . import regularizers\r\n \r\n-__version__ = '1.0.4'\r\n+__version__ = '1.0.5'\r\n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='1.0.4',\n+      version='1.0.5',\n       description='Deep Learning for Python',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/fchollet/keras',\n-      download_url='https://github.com/fchollet/keras/tarball/1.0.4',\n+      download_url='https://github.com/fchollet/keras/tarball/1.0.5',\n       license='MIT',\n       install_requires=['theano', 'pyyaml', 'six'],\n       extras_require={\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6b90eff03c4fdb66f7532145ac68f03e3bec2d2a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 803 | Contributors (this commit): 1 | Commits (past 90d): 4 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -209,7 +209,7 @@ def test_siamese_1():\n     loss = graph.test_on_batch({'input1': X_test_graph, 'input2': X2_test_graph, 'output1': y_test_graph})\n     loss = graph.train_on_batch({'input1': X_test_graph, 'input2': X2_test_graph, 'output1': y_test_graph})\n     loss = graph.evaluate({'input1': X_test_graph, 'input2': X2_test_graph, 'output1': y_test_graph})\n-    assert(loss < 4.0)\n+    assert(loss < 5.0)\n \n     # test serialization\n     config = graph.get_config()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a1610eb2747e2020b9460b1f60e6e750d253fffb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 1941 | Contributors (this commit): 15 | Commits (past 90d): 44 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -623,7 +623,7 @@ class Model(Container):\n                 if metric == 'accuracy' or metric == 'acc':\n                     # custom handling of accuracy (because of class mode duality)\n                     output_shape = self.internal_output_shapes[i]\n-                    if output_shape[-1] == 1:\n+                    if output_shape[-1] == 1 or self.loss_functions[i] == objectives.binary_crossentropy:\n                         # case: binary accuracy\n                         self.metrics.append(metrics_module.binary_accuracy(y_true, y_pred))\n                     elif self.loss_functions[i] == objectives.sparse_categorical_crossentropy:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#439f2f3b2b7fc4b35f4fbea32fefbc15e136c6ba", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 10 | Churn Cumulative: 2895 | Contributors (this commit): 16 | Commits (past 90d): 38 | Contributors (cumulative): 16 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1593,19 +1593,19 @@ class Container(Layer):\n                 raise Exception('Output tensors to a ' + cls_name + ' must be '\n                                 'Keras tensors. Found: ' + str(x))\n         # build self.output_layers:\n-        masks = []\n         for x in self.outputs:\n             layer, node_index, tensor_index = x._keras_history\n             self.output_layers.append(layer)\n             self.output_layers_node_indices.append(node_index)\n             self.output_layers_tensor_indices.append(tensor_index)\n \n-            # also fill in the output mask cache\n+        # fill in the output mask cache\n+        masks = []\n+        for x in self.inputs:\n+            layer, node_index, tensor_index = x._keras_history\n             node = layer.inbound_nodes[node_index]\n             mask = node.output_masks[tensor_index]\n             masks.append(mask)\n-\n-        # output mask cache\n         mask_cache_key = ','.join([str(id(x)) for x in self.inputs])\n         mask_cache_key += '_' + ','.join([str(id(x)) for x in masks])\n         if len(masks) == 1:\n@@ -2105,6 +2105,8 @@ class Container(Layer):\n                         for x, s in zip(output_tensors, shapes):\n                             x._keras_shape = s\n                             x._uses_learning_phase = uses_learning_phase\n+\n+                    # update tensor_map\n                     for x, y, mask in zip(reference_output_tensors, output_tensors, output_masks):\n                         tensor_map[str(id(x))] = (y, mask)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3bc80d3db4365674003bd30af1e0cc7859b6184b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 77 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -19,7 +19,6 @@ def test_masking():\n     model.compile(loss='mse', optimizer='sgd')\n     y = model.predict(X)\n     history = model.fit(X, 4 * y, nb_epoch=1, batch_size=2, verbose=1)\n-    assert history.history['loss'][0] == 285.\n \n \n def test_loss_masking():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dc122c31ef31382c82ea5cc9c081d7f6ee3b0f5b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 22 | Churn Cumulative: 2994 | Contributors (this commit): 18 | Commits (past 90d): 41 | Contributors (cumulative): 19 | DMM Complexity: 0.14285714285714285\n\nDIFF:\n@@ -1608,6 +1608,12 @@ class Container(Layer):\n             masks.append(mask)\n         mask_cache_key = ','.join([str(id(x)) for x in self.inputs])\n         mask_cache_key += '_' + ','.join([str(id(x)) for x in masks])\n+        masks = []\n+        for x in self.outputs:\n+            layer, node_index, tensor_index = x._keras_history\n+            node = layer.inbound_nodes[node_index]\n+            mask = node.output_masks[tensor_index]\n+            masks.append(mask)\n         if len(masks) == 1:\n             mask = masks[0]\n         else:\n\n@@ -10,15 +10,16 @@ from keras import backend as K\n \n def test_masking():\n     np.random.seed(1337)\n-    X = np.array(\n-        [[[1, 1], [2, 1], [3, 1], [5, 5]],\n-         [[1, 5], [5, 0], [0, 0], [0, 0]]], dtype=np.int32)\n+    X = np.array([[[1], [1]],\n+                  [[0], [0]]])\n     model = Sequential()\n-    model.add(Masking(mask_value=0, input_shape=(4, 2)))\n+    model.add(Masking(mask_value=0, input_shape=(2, 1)))\n     model.add(TimeDistributedDense(1, init='one'))\n     model.compile(loss='mse', optimizer='sgd')\n-    y = model.predict(X)\n-    history = model.fit(X, 4 * y, nb_epoch=1, batch_size=2, verbose=1)\n+    y = np.array([[[1], [1]],\n+                  [[1], [1]]])\n+    loss = model.train_on_batch(X, y)\n+    assert loss == 0\n \n \n def test_loss_masking():\n@@ -39,4 +40,5 @@ def test_loss_masking():\n \n \n if __name__ == '__main__':\n-    pytest.main([__file__])\n+    # pytest.main([__file__])\n+    test_masking()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#885e6e621bea9cf9224853a974d0e2d83168a6fa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 96 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -40,5 +40,4 @@ def test_loss_masking():\n \n \n if __name__ == '__main__':\n-    # pytest.main([__file__])\n-    test_masking()\n+    pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#aa45dee5a474e1b0713eda858e55a2bf74a754fc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 1592 | Contributors (this commit): 22 | Commits (past 90d): 11 | Contributors (cumulative): 22 | DMM Complexity: 1.0\n\nDIFF:\n@@ -361,13 +361,14 @@ class RemoteMonitor(Callback):\n     # Arguments\n         root: root url to which the events will be sent (at the end\n             of every epoch). Events are sent to\n-            `root + '/publish/epoch/end/'`. Calls are HTTP POST,\n-            with a `data` argument which is a JSON-encoded dictionary\n-            of event data.\n+            `root + '/publish/epoch/end/'` by default. Calls are \n+            HTTP POST, with a `data` argument which is a \n+            JSON-encoded dictionary of event data.\n     '''\n-    def __init__(self, root='http://localhost:9000'):\n+    def __init__(self, root='http://localhost:9000', path='/publish/epoch/end/'):\n         super(RemoteMonitor, self).__init__()\n         self.root = root\n+        self.path = path\n \n     def on_epoch_end(self, epoch, logs={}):\n         import requests\n@@ -377,7 +378,7 @@ class RemoteMonitor(Callback):\n             send[k] = v\n \n         try:\n-            requests.post(self.root + '/publish/epoch/end/',\n+            requests.post(self.root + self.path,\n                           {'data': json.dumps(send)})\n         except:\n             print('Warning: could not reach RemoteMonitor '\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8d3f39852aa6596c41f6a2a901ee76501bc1741e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 5 | Churn Cumulative: 2906 | Contributors (this commit): 16 | Commits (past 90d): 40 | Contributors (cumulative): 16 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1161,7 +1161,6 @@ class Merge(Layer):\n             shape2 = input_shapes[1]\n             n1 = len(shape1)\n             n2 = len(shape2)\n-            if mode == 'dot':\n             if type(dot_axes) == int:\n                 if dot_axes < 0:\n                     dot_axes = [dot_axes % n1, dot_axes % n2]\n@@ -1305,7 +1304,7 @@ class Merge(Layer):\n                     break\n                 output_shape[self.concat_axis] += shape[self.concat_axis]\n             return tuple(output_shape)\n-        elif self.mode == 'dot':\n+        elif self.mode in ['dot', 'cos']:\n             shape1 = list(input_shapes[0])\n             shape2 = list(input_shapes[1])\n             dot_axes = [a - 1 for a in self.dot_axes]\n@@ -1317,8 +1316,6 @@ class Merge(Layer):\n             else:\n                 shape = tensordot_output.shape\n             return (shape1[0],) + shape\n-        elif self.mode == 'cos':\n-            return (input_shapes[0][0], 1)\n \n     def compute_mask(self, inputs, mask=None):\n         if mask is None or not any([m is not None for m in mask]):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c20e34a8b0f66e59a2761a42412814da726359dc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 94 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -35,6 +35,7 @@ if os.path.exists(_config_path):\n \n     set_floatx(_floatx)\n     set_epsilon(_epsilon)\n+    set_image_dim_ordering(_image_dim_ordering)\n     _BACKEND = _backend\n \n # save config file\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#229f13a8648596b1a2cbf96c92e087f821a8d6df", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 13343 | Contributors (this commit): 56 | Commits (past 90d): 54 | Contributors (cumulative): 65 | DMM Complexity: None\n\nDIFF:\n@@ -1318,7 +1318,7 @@ class Merge(Layer):\n             return (shape1[0],) + shape\n \n     def compute_mask(self, inputs, mask=None):\n-        if mask is None or not any([m is not None for m in mask]):\n+        if mask is None or all([m is None for m in mask]):\n             return None\n \n         assert hasattr(mask, '__len__') and len(mask) == len(inputs)\n\n@@ -402,7 +402,7 @@ class Lambda(Layer):\n     def __init__(self, function, output_shape=None, arguments={}, **kwargs):\n         self.function = function\n         self.arguments = arguments\n-        self.supports_masking = True\n+        self.supports_masking = False\n \n         if output_shape is None:\n             self._output_shape = None\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#835a02c037384b4ccf0e5b2425c6dd7469bf702d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 501 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 8 | Complexity Δ (Sum/Max): 68/58 | Churn Δ: 501 | Churn Cumulative: 512 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 4 | DMM Complexity: 0.4645390070921986\n\nDIFF:\n@@ -3,6 +3,7 @@ from ..engine import Layer, Input, InputLayer, Merge, merge, InputSpec\n from .core import *\n from .convolutional import *\n from .pooling import *\n+from .local import *\n from .recurrent import *\n from .normalization import *\n from .embeddings import *\n\n@@ -0,0 +1,421 @@\n+# -*- coding: utf-8 -*-\n+from __future__ import absolute_import\n+\n+from keras import backend as K\n+from keras.layers import activations, initializations, regularizers, constraints\n+from keras.engine import Layer, InputSpec\n+from ..utils.np_utils import conv_output_length\n+\n+\n+class LocallyConnected1D(Layer):\n+    '''LocallyConnected1D layer works almost the same as Convolution1D layer,\n+    except that weights are unshared, that is, a different set of filters is\n+    applied at each different patch of the input. When using this layer as the\n+    first layer in a model, either provide the keyword argument `input_dim`\n+    (int, e.g. 128 for sequences of 128-dimensional vectors), or `input_shape`\n+    (tuple of integers, e.g. (10, 128) for sequences of 10 vectors of\n+    128-dimensional vectors). Also, you will need to fix shape of the previous\n+    layer, since the weights can only be defined with determined output shape.\n+\n+    # Example\n+    ```python\n+        # apply a unshared weight convolution 1d of length 3 to a sequence with\n+        # 10 timesteps, with 64 output filters\n+        model = Sequential()\n+        model.add(LocallyConnected1D(64, 3, input_shape=(10, 32)))\n+        # now model.output_shape == (None, 8, 64)\n+        # add a new conv1d on top\n+        model.add(LocallyConnected1D(32, 3))\n+        # now model.output_shape == (None, 6, 32)\n+    ```\n+    # Arguments\n+        nb_filter: Dimensionality of the output.\n+        filter_length: The extension (spatial or temporal) of each filter.\n+        init: name of initialization function for the weights of the layer\n+            (see [initializations](../initializations.md)),\n+            or alternatively, Theano function to use for weights initialization.\n+            This parameter is only relevant if you don't pass a `weights` argument.\n+        activation: name of activation function to use\n+            (see [activations](../activations.md)),\n+            or alternatively, elementwise Theano function.\n+            If you don't specify anything, no activation is applied\n+            (ie. \"linear\" activation: a(x) = x).\n+        weights: list of numpy arrays to set as initial weights.\n+        border_mode: Only support 'valid'. Please make good use of\n+            ZeroPadding1D to achieve same output length.\n+        subsample_length: factor by which to subsample output.\n+        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n+            (eg. L1 or L2 regularization), applied to the main weights matrix.\n+        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n+            applied to the bias.\n+        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n+            applied to the network output.\n+        W_constraint: instance of the [constraints](../constraints.md) module\n+            (eg. maxnorm, nonneg), applied to the main weights matrix.\n+        b_constraint: instance of the [constraints](../constraints.md) module,\n+            applied to the bias.\n+        bias: whether to include a bias (i.e. make the layer affine rather than linear).\n+        input_dim: Number of channels/dimensions in the input.\n+            Either this argument or the keyword argument `input_shape`must be\n+            provided when using this layer as the first layer in a model.\n+        input_length: Length of input sequences, when it is constant.\n+            This argument is required if you are going to connect\n+            `Flatten` then `Dense` layers upstream\n+            (without it, the shape of the dense outputs cannot be computed).\n+    # Input shape\n+        3D tensor with shape: `(samples, steps, input_dim)`.\n+    # Output shape\n+        3D tensor with shape: `(samples, new_steps, nb_filter)`.\n+        `steps` value might have changed due to padding.\n+    '''\n+    def __init__(self, nb_filter, filter_length,\n+                 init='uniform', activation='linear', weights=None,\n+                 border_mode='valid', subsample_length=1,\n+                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n+                 W_constraint=None, b_constraint=None,\n+                 bias=True, input_dim=None, input_length=None, **kwargs):\n+        if border_mode != 'valid':\n+            raise Exception('Invalid border mode for Convolution2D '\n+                            '(only \"valid\" is supported):', border_mode)\n+        self.nb_filter = nb_filter\n+        self.filter_length = filter_length\n+        self.init = initializations.get(init, dim_ordering='th')\n+        self.activation = activations.get(activation)\n+\n+        self.border_mode = border_mode\n+        self.subsample_length = subsample_length\n+\n+        self.W_regularizer = regularizers.get(W_regularizer)\n+        self.b_regularizer = regularizers.get(b_regularizer)\n+        self.activity_regularizer = regularizers.get(activity_regularizer)\n+\n+        self.W_constraint = constraints.get(W_constraint)\n+        self.b_constraint = constraints.get(b_constraint)\n+\n+        self.bias = bias\n+        self.input_spec = [InputSpec(ndim=3)]\n+        self.initial_weights = weights\n+        self.input_dim = input_dim\n+        self.input_length = input_length\n+        if self.input_dim:\n+            kwargs['input_shape'] = (self.input_length, self.input_dim)\n+        super(LocallyConnected1D, self).__init__(**kwargs)\n+\n+    def build(self, input_shape):\n+        input_dim = input_shape[2]\n+        _, output_length, nb_filter = self.get_output_shape_for(input_shape)\n+\n+        self.W_shape = (output_length, self.filter_length * input_dim, nb_filter)\n+        self.W = self.init(self.W_shape, name='{}_W'.format(self.name))\n+        if self.bias:\n+            self.b = K.zeros((output_length, self.nb_filter), name='{}_b'.format(self.name))\n+            self.trainable_weights = [self.W, self.b]\n+        else:\n+            self.trainable_weights = [self.W]\n+\n+        self.regularizers = []\n+        if self.W_regularizer:\n+            self.W_regularizer.set_param(self.W)\n+            self.regularizers.append(self.W_regularizer)\n+        if self.b_regularizer:\n+            self.b_regularizer.set_param(self.b)\n+            self.regularizers.append(self.b_regularizer)\n+        if self.activity_regularizer:\n+            self.activity_regularizer.set_layer(self)\n+            self.regularizers.append(self.activity_regularizer)\n+\n+        self.constraints = {}\n+        if self.W_constraint:\n+            self.constraints[self.W] = self.W_constraint\n+        if self.b_constraint:\n+            self.constraints[self.b] = self.b_constraint\n+\n+        if self.initial_weights is not None:\n+            self.set_weights(self.initial_weights)\n+            del self.initial_weights\n+\n+    def get_output_shape_for(self, input_shape):\n+        length = conv_output_length(input_shape[1],\n+                                    self.filter_length,\n+                                    self.border_mode,\n+                                    self.subsample_length)\n+        return (input_shape[0], length, self.nb_filter)\n+\n+    def call(self, x, mask=None):\n+        stride = self.subsample_length\n+        output_length, feature_dim, nb_filter = self.W_shape\n+\n+        xs = []\n+        for i in range(output_length):\n+            slice_length = slice(i * stride, i * stride + self.filter_length)\n+            xs.append(K.reshape(x[:, slice_length, :], (1, -1, feature_dim)))\n+        x_aggregate = K.concatenate(xs, axis=0)\n+        # (output_length, batch_size, nb_filter)\n+        output = K.batch_dot(x_aggregate, self.W)\n+        output = K.permute_dimensions(output, (1, 0, 2))\n+\n+        if self.bias:\n+            output += K.reshape(self.b, (1, output_length, nb_filter))\n+\n+        output = self.activation(output)\n+        return output\n+\n+    def get_config(self):\n+        config = {'nb_filter': self.nb_filter,\n+                  'filter_length': self.filter_length,\n+                  'init': self.init.__name__,\n+                  'activation': self.activation.__name__,\n+                  'border_mode': self.border_mode,\n+                  'subsample_length': self.subsample_length,\n+                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n+                  'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n+                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n+                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n+                  'b_constraint': self.b_constraint.get_config() if self.b_constraint else None,\n+                  'bias': self.bias,\n+                  'input_dim': self.input_dim,\n+                  'input_length': self.input_length}\n+        base_config = super(LocallyConnected1D, self).get_config()\n+        return dict(list(base_config.items()) + list(config.items()))\n+\n+\n+class LocallyConnected2D(Layer):\n+    '''LocallyConnected2D layer works almost the same as Convolution2D layer,\n+    except that weights are unshared, that is, a different set of filters is\n+    applied at each different patch of the input. When using this layer as the\n+    first layer in a model, provide the keyword argument `input_shape` (tuple\n+    of integers, does not include the sample axis), e.g.\n+    `input_shape=(3, 128, 128)` for 128x128 RGB pictures. Also, you will need\n+    to fix shape of the previous layer, since the weights can only be defined\n+    with determined output shape.\n+\n+    # Examples\n+    ```python\n+        # apply a 3x3 unshared weights convolution with 64 output filters on a 32x32 image:\n+        model = Sequential()\n+        model.add(LocallyConnected2D(64, 3, 3, input_shape=(3, 32, 32)))\n+        # now model.output_shape == (None, 64, 30, 30)\n+        # notice that this layer will consume (30*30)*(3*3*3*64) + (30*30)*64 parameters\n+\n+        # add a 3x3 unshared weights convolution on top, with 32 output filters:\n+        model.add(LocallyConnected2D(32, 3, 3))\n+        # now model.output_shape == (None, 32, 28, 28)\n+    ```\n+\n+    # Arguments\n+        nb_filter: Number of convolution filters to use.\n+        nb_row: Number of rows in the convolution kernel.\n+        nb_col: Number of columns in the convolution kernel.\n+        init: name of initialization function for the weights of the layer\n+            (see [initializations](../initializations.md)), or alternatively,\n+            Theano function to use for weights initialization.\n+            This parameter is only relevant if you don't pass\n+            a `weights` argument.\n+        activation: name of activation function to use\n+            (see [activations](../activations.md)),\n+            or alternatively, elementwise Theano function.\n+            If you don't specify anything, no activation is applied\n+            (ie. \"linear\" activation: a(x) = x).\n+        weights: list of numpy arrays to set as initial weights.\n+        border_mode: Only support 'valid'. Please make good use of\n+            ZeroPadding2D to achieve same output shape.\n+        subsample: tuple of length 2. Factor by which to subsample output.\n+            Also called strides elsewhere.\n+        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n+            (eg. L1 or L2 regularization), applied to the main weights matrix.\n+        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n+            applied to the bias.\n+        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n+            applied to the network output.\n+        W_constraint: instance of the [constraints](../constraints.md) module\n+            (eg. maxnorm, nonneg), applied to the main weights matrix.\n+        b_constraint: instance of the [constraints](../constraints.md) module,\n+            applied to the bias.\n+        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n+            (the depth) is at index 1, in 'tf' mode is it at index 3.\n+        bias: whether to include a bias (i.e. make the layer affine rather than linear).\n+\n+    # Input shape\n+        4D tensor with shape:\n+        `(samples, channels, rows, cols)` if dim_ordering='th'\n+        or 4D tensor with shape:\n+        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n+\n+    # Output shape\n+        4D tensor with shape:\n+        `(samples, nb_filter, new_rows, new_cols)` if dim_ordering='th'\n+        or 4D tensor with shape:\n+        `(samples, new_rows, new_cols, nb_filter)` if dim_ordering='tf'.\n+        `rows` and `cols` values might have changed due to padding.\n+    '''\n+    def __init__(self, nb_filter, nb_row, nb_col,\n+                 init='glorot_uniform', activation='linear', weights=None,\n+                 border_mode='valid', subsample=(1, 1),\n+                 dim_ordering=K.image_dim_ordering(),\n+                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n+                 W_constraint=None, b_constraint=None,\n+                 bias=True, **kwargs):\n+        if border_mode != 'valid':\n+            raise Exception('Invalid border mode for Convolution2D '\n+                            '(only \"valid\" is supported):', border_mode)\n+        self.nb_filter = nb_filter\n+        self.nb_row = nb_row\n+        self.nb_col = nb_col\n+        self.init = initializations.get(init, dim_ordering=dim_ordering)\n+        self.activation = activations.get(activation)\n+\n+        self.border_mode = border_mode\n+        self.subsample = tuple(subsample)\n+        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n+        self.dim_ordering = dim_ordering\n+\n+        self.W_regularizer = regularizers.get(W_regularizer)\n+        self.b_regularizer = regularizers.get(b_regularizer)\n+        self.activity_regularizer = regularizers.get(activity_regularizer)\n+\n+        self.W_constraint = constraints.get(W_constraint)\n+        self.b_constraint = constraints.get(b_constraint)\n+\n+        self.bias = bias\n+        self.input_spec = [InputSpec(ndim=4)]\n+        self.initial_weights = weights\n+        super(LocallyConnected2D, self).__init__(**kwargs)\n+\n+    def build(self, input_shape):\n+        output_shape = self.get_output_shape_for(input_shape)\n+        if self.dim_ordering == 'th':\n+            _, nb_filter, output_row, output_col = output_shape\n+            input_filter = input_shape[1]\n+        elif self.dim_ordering == 'tf':\n+            _, output_row, output_col, nb_filter = output_shape\n+            input_filter = input_shape[3]\n+        else:\n+            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+\n+        self.output_row = output_row\n+        self.output_col = output_col\n+        self.W_shape = (output_row * output_col, self.nb_row * self.nb_col * input_filter, nb_filter)\n+        self.W = self.init(self.W_shape, name='{}_W'.format(self.name))\n+\n+        if self.bias:\n+            self.b = K.zeros((output_row, output_col, nb_filter), name='{}_b'.format(self.name))\n+            self.trainable_weights = [self.W, self.b]\n+        else:\n+            self.trainable_weights = [self.W]\n+\n+        self.regularizers = []\n+        if self.W_regularizer:\n+            self.W_regularizer.set_param(self.W)\n+            self.regularizers.append(self.W_regularizer)\n+        if self.bias and self.b_regularizer:\n+            self.b_regularizer.set_param(self.b)\n+            self.regularizers.append(self.b_regularizer)\n+        if self.activity_regularizer:\n+            self.activity_regularizer.set_layer(self)\n+            self.regularizers.append(self.activity_regularizer)\n+\n+        self.constraints = {}\n+        if self.W_constraint:\n+            self.constraints[self.W] = self.W_constraint\n+        if self.bias and self.b_constraint:\n+            self.constraints[self.b] = self.b_constraint\n+\n+        if self.initial_weights is not None:\n+            self.set_weights(self.initial_weights)\n+            del self.initial_weights\n+\n+    def get_output_shape_for(self, input_shape):\n+        if self.dim_ordering == 'th':\n+            rows = input_shape[2]\n+            cols = input_shape[3]\n+        elif self.dim_ordering == 'tf':\n+            rows = input_shape[1]\n+            cols = input_shape[2]\n+        else:\n+            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+\n+        rows = conv_output_length(rows, self.nb_row,\n+                                  self.border_mode, self.subsample[0])\n+        cols = conv_output_length(cols, self.nb_col,\n+                                  self.border_mode, self.subsample[1])\n+\n+        if self.dim_ordering == 'th':\n+            return (input_shape[0], self.nb_filter, rows, cols)\n+        elif self.dim_ordering == 'tf':\n+            return (input_shape[0], rows, cols, self.nb_filter)\n+        else:\n+            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+\n+    def call(self, x, mask=None):\n+        stride_row, stride_col = self.subsample\n+        _, feature_dim, nb_filter = self.W_shape\n+\n+        if self.dim_ordering == 'th':\n+            if K._backend == 'theano':\n+                output = []\n+                for i in range(self.output_row):\n+                    for j in range(self.output_col):\n+                        slice_row = slice(i * stride_row,\n+                                          i * stride_row + self.nb_row)\n+                        slice_col = slice(j * stride_col,\n+                                          j * stride_col + self.nb_col)\n+                        x_flatten = K.reshape(x[:, :, slice_row, slice_col], (1, -1, feature_dim))\n+                        output.append(K.dot(x_flatten, self.W[i * self.output_col + j, :, :]))\n+                output = K.concatenate(output, axis=0)\n+            else:\n+                xs = []\n+                for i in range(self.output_row):\n+                    for j in range(self.output_col):\n+                        slice_row = slice(i * stride_row,\n+                                          i * stride_row + self.nb_row)\n+                        slice_col = slice(j * stride_col,\n+                                          j * stride_col + self.nb_col)\n+                        xs.append(K.reshape(x[:, :, slice_row, slice_col], (1, -1, feature_dim)))\n+                x_aggregate = K.concatenate(xs, axis=0)\n+                output = K.batch_dot(x_aggregate, self.W)\n+            output = K.reshape(output, (self.output_row, self.output_col, -1, nb_filter))\n+            output = K.permute_dimensions(output, (2, 3, 0, 1))\n+        elif self.dim_ordering == 'tf':\n+            xs = []\n+            for i in range(self.output_row):\n+                for j in range(self.output_col):\n+                    slice_row = slice(i * stride_row,\n+                                      i * stride_row + self.nb_row)\n+                    slice_col = slice(j * stride_col,\n+                                      j * stride_col + self.nb_col)\n+                    xs.append(K.reshape(x[:, slice_row, slice_col, :], (1, -1, feature_dim)))\n+            x_aggregate = K.concatenate(xs, axis=0)\n+            output = K.batch_dot(x_aggregate, self.W)\n+            output = K.reshape(output, (self.output_row, self.output_col, -1, nb_filter))\n+            output = K.permute_dimensions(output, (2, 0, 1, 3))\n+        else:\n+            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+\n+        if self.bias:\n+            if self.dim_ordering == 'th':\n+                output += K.reshape(self.b, (1, nb_filter, self.output_row, self.output_col))\n+            elif self.dim_ordering == 'tf':\n+                output += K.reshape(self.b, (1, self.output_row, self.output_col, nb_filter))\n+            else:\n+                raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+\n+        output = self.activation(output)\n+        return output\n+\n+    def get_config(self):\n+        config = {'nb_filter': self.nb_filter,\n+                  'nb_row': self.nb_row,\n+                  'nb_col': self.nb_col,\n+                  'init': self.init.__name__,\n+                  'activation': self.activation.__name__,\n+                  'border_mode': self.border_mode,\n+                  'subsample': self.subsample,\n+                  'dim_ordering': self.dim_ordering,\n+                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n+                  'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n+                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n+                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n+                  'b_constraint': self.b_constraint.get_config() if self.b_constraint else None,\n+                  'bias': self.bias}\n+        base_config = super(LocallyConnected2D, self).get_config()\n+        return dict(list(base_config.items()) + list(config.items()))\n\n@@ -0,0 +1,79 @@\n+import pytest\n+import numpy as np\n+from numpy.testing import assert_allclose\n+\n+from keras.utils.test_utils import layer_test\n+from keras import backend as K\n+from keras.layers import local\n+\n+\n+def test_locallyconnected_1d():\n+    nb_samples = 2\n+    nb_steps = 8\n+    input_dim = 5\n+    filter_length = 3\n+    nb_filter = 4\n+\n+    for border_mode in ['valid']:\n+        for subsample_length in [1]:\n+            if border_mode == 'same' and subsample_length != 1:\n+                continue\n+            layer_test(local.LocallyConnected1D,\n+                       kwargs={'nb_filter': nb_filter,\n+                               'filter_length': filter_length,\n+                               'border_mode': border_mode,\n+                               'subsample_length': subsample_length},\n+                       input_shape=(nb_samples, nb_steps, input_dim))\n+\n+            layer_test(local.LocallyConnected1D,\n+                       kwargs={'nb_filter': nb_filter,\n+                               'filter_length': filter_length,\n+                               'border_mode': border_mode,\n+                               'W_regularizer': 'l2',\n+                               'b_regularizer': 'l2',\n+                               'activity_regularizer': 'activity_l2',\n+                               'subsample_length': subsample_length},\n+                       input_shape=(nb_samples, nb_steps, input_dim))\n+\n+\n+def test_locallyconnected_2d():\n+    nb_samples = 8\n+    nb_filter = 3\n+    stack_size = 4\n+    nb_row = 6\n+    nb_col = 10\n+\n+    for border_mode in ['valid']:\n+        for subsample in [(1, 1), (2, 2)]:\n+            if border_mode == 'same' and subsample != (1, 1):\n+                continue\n+\n+            layer_test(local.LocallyConnected2D,\n+                       kwargs={'nb_filter': nb_filter,\n+                               'nb_row': 3,\n+                               'nb_col': 3,\n+                               'border_mode': border_mode,\n+                               'W_regularizer': 'l2',\n+                               'b_regularizer': 'l2',\n+                               'activity_regularizer': 'activity_l2',\n+                               'subsample': subsample,\n+                               'dim_ordering': 'tf'},\n+                       input_shape=(nb_samples, nb_row, nb_col, stack_size))\n+\n+            layer_test(local.LocallyConnected2D,\n+                       kwargs={'nb_filter': nb_filter,\n+                               'nb_row': 3,\n+                               'nb_col': 3,\n+                               'border_mode': border_mode,\n+                               'W_regularizer': 'l2',\n+                               'b_regularizer': 'l2',\n+                               'activity_regularizer': 'activity_l2',\n+                               'subsample': subsample,\n+                               'dim_ordering': 'th'},\n+                       input_shape=(nb_samples, stack_size, nb_row, nb_col))\n+\n+\n+if __name__ == '__main__':\n+    # pytest.main([__file__])\n+    test_locallyconnected_1d()\n+    test_locallyconnected_2d()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
