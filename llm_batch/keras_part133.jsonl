{"custom_id": "keras#c4579a9c43a5d9f0401eed4da6ca03315685ac2b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 20 | Churn Cumulative: 3075 | Contributors (this commit): 46 | Commits (past 90d): 20 | Contributors (cumulative): 46 | DMM Complexity: None\n\nDIFF:\n@@ -493,16 +493,16 @@ def _old_batch_normalization(x, mean, var, beta, gamma, epsilon=1e-3):\n                 shuffle_pattern = list(range(ndim))\n                 shuffle_pattern[1] = shuffle_pattern[axis]\n                 shuffle_pattern[axis] = 1\n-                x = x.dimshuffle(shuffle_pattern)\n-                mean = mean.dimshuffle(shuffle_pattern)\n-                var = var.dimshuffle(shuffle_pattern)\n-                beta = beta.dimshuffle(shuffle_pattern)\n-                gamma = gamma.dimshuffle(shuffle_pattern)\n-            normed = theano.sandbox.cuda.dnn.dnn_batch_normalization_test(x, gamma, beta, mean, var,\n-                                                                          'spatial', epsilon)\n-            if axis != 1:\n-                normed = normed.dimshuffle(shuffle_pattern)\n-            return normed\n+                return theano.sandbox.cuda.dnn.dnn_batch_normalization_test(\n+                    x.dimshuffle(shuffle_pattern),\n+                    gamma.dimshuffle(shuffle_pattern),\n+                    beta.dimshuffle(shuffle_pattern),\n+                    mean.dimshuffle(shuffle_pattern),\n+                    var.dimshuffle(shuffle_pattern),\n+                    'spatial', epsilon).dimshuffle(shuffle_pattern)\n+            else:\n+                return theano.sandbox.cuda.dnn.dnn_batch_normalization_test(\n+                    x, gamma, beta, mean, var, 'spatial', epsilon)\n         except AttributeError:\n             pass\n         except ValueError:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3f12d7ae44436f5cef1e8475a7b5100b63d27c59", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 24 | Churn Cumulative: 2569 | Contributors (this commit): 36 | Commits (past 90d): 22 | Contributors (cumulative): 43 | DMM Complexity: 0.85\n\nDIFF:\n@@ -246,17 +246,20 @@ class ModelCheckpoint(Callback):\n         save_weights_only: if True, then only the model's weights will be\n             saved (`model.save_weights(filepath)`), else the full model\n             is saved (`model.save(filepath)`).\n+        period: Interval (number of epochs) between checkpoints.\n \n     '''\n     def __init__(self, filepath, monitor='val_loss', verbose=0,\n                  save_best_only=False, save_weights_only=False,\n-                 mode='auto'):\n+                 mode='auto', period=1):\n         super(ModelCheckpoint, self).__init__()\n         self.monitor = monitor\n         self.verbose = verbose\n         self.filepath = filepath\n         self.save_best_only = save_best_only\n         self.save_weights_only = save_weights_only\n+        self.period = period\n+        self.epochs_since_last_save = 0\n \n         if mode not in ['auto', 'min', 'max']:\n             warnings.warn('ModelCheckpoint mode %s is unknown, '\n@@ -279,6 +282,9 @@ class ModelCheckpoint(Callback):\n                 self.best = np.Inf\n \n     def on_epoch_end(self, epoch, logs={}):\n+        self.epochs_since_last_save += 1\n+        if self.epochs_since_last_save >= self.period:\n+            self.epochs_since_last_save = 0\n             filepath = self.filepath.format(epoch=epoch, **logs)\n             if self.save_best_only:\n                 current = logs.get(self.monitor)\n\n@@ -79,6 +79,22 @@ def test_ModelCheckpoint():\n     assert os.path.exists(filepath)\n     os.remove(filepath)\n \n+    # case 5\n+    save_best_only = False\n+    period = 2\n+    mode = 'auto'\n+    filepath = 'checkpoint.{epoch:02d}.h5'\n+    cbks = [callbacks.ModelCheckpoint(filepath, monitor=monitor,\n+                                      save_best_only=save_best_only, mode=mode,\n+                                      period=period)]\n+    model.fit(X_train, y_train, batch_size=batch_size,\n+              validation_data=(X_test, y_test), callbacks=cbks, nb_epoch=4)\n+    assert os.path.exists(filepath.format(epoch=1))\n+    assert os.path.exists(filepath.format(epoch=3))\n+    assert not os.path.exists(filepath.format(epoch=0))\n+    assert not os.path.exists(filepath.format(epoch=2))\n+    os.remove(filepath.format(epoch=1))\n+    os.remove(filepath.format(epoch=3))\n \n def test_EarlyStopping():\n     (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=train_samples,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ef1da479ecfdad853d0cae965459fe2cdd3936a2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 23 | Churn Cumulative: 711 | Contributors (this commit): 15 | Commits (past 90d): 6 | Contributors (cumulative): 15 | DMM Complexity: 0.0\n\nDIFF:\n@@ -101,22 +101,31 @@ def print_summary(layers, relevant_nodes=None,\n         else:\n             print('_' * line_length)\n \n+    trainable_count, non_trainable_count = count_total_params(layers, layer_set=None)\n+\n+    print('Total params: {:,}'.format(trainable_count + non_trainable_count))\n+    print('Trainable params: {:,}'.format(trainable_count))\n+    print('Non-trainable params: {:,}'.format(non_trainable_count))\n+    print('_' * line_length)\n+\n+\n def count_total_params(layers, layer_set=None):\n     if layer_set is None:\n         layer_set = set()\n-        total_params = 0\n+    trainable_count = 0\n+    non_trainable_count = 0\n     for layer in layers:\n         if layer in layer_set:\n             continue\n         layer_set.add(layer)\n         if type(layer) in (Model, Sequential):\n-                total_params += count_total_params(layer.layers, layer_set)\n+            t, nt = count_total_params(layer.layers, layer_set)\n+            trainable_count += t\n+            non_trainable_count += nt\n         else:\n-                total_params += layer.count_params()\n-        return total_params\n-\n-    print('Total params: %s' % count_total_params(layers))\n-    print('_' * line_length)\n+            trainable_count += sum([K.count_params(p) for p in layer.trainable_weights])\n+            non_trainable_count += sum([K.count_params(p) for p in layer.non_trainable_weights])\n+    return trainable_count, non_trainable_count\n \n \n def convert_all_kernels_in_model(model):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#518fa3aa44ad3ffaa3ecd8a11a91530b019cfe2b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 10 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 27 | Churn Cumulative: 562 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -81,7 +81,7 @@ class LocallyConnected1D(Layer):\n                  W_constraint=None, b_constraint=None,\n                  bias=True, input_dim=None, input_length=None, **kwargs):\n         if border_mode != 'valid':\n-            raise Exception('Invalid border mode for LocallyConnected1D '\n+            raise ValueError('Invalid border mode for LocallyConnected1D '\n                              '(only \"valid\" is supported):', border_mode)\n         self.nb_filter = nb_filter\n         self.filter_length = filter_length\n@@ -110,8 +110,9 @@ class LocallyConnected1D(Layer):\n     def build(self, input_shape):\n         input_dim = input_shape[2]\n         _, output_length, nb_filter = self.get_output_shape_for(input_shape)\n-        self.W_shape = (output_length, self.filter_length * input_dim, nb_filter)\n-\n+        self.W_shape = (output_length,\n+                        self.filter_length * input_dim,\n+                        nb_filter)\n         self.W = self.add_weight(self.W_shape,\n                                  initializer=self.init,\n                                  name='{}_W'.format(self.name),\n@@ -257,7 +258,7 @@ class LocallyConnected2D(Layer):\n         if dim_ordering == 'default':\n             dim_ordering = K.image_dim_ordering()\n         if border_mode != 'valid':\n-            raise Exception('Invalid border mode for LocallyConnected2D '\n+            raise ValueError('Invalid border mode for LocallyConnected2D '\n                              '(only \"valid\" is supported):', border_mode)\n         self.nb_filter = nb_filter\n         self.nb_row = nb_row\n@@ -267,7 +268,8 @@ class LocallyConnected2D(Layer):\n \n         self.border_mode = border_mode\n         self.subsample = tuple(subsample)\n-        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n+        if dim_ordering not in {'tf', 'th'}:\n+            raise ValueError('dim_ordering must be in {tf, th}.')\n         self.dim_ordering = dim_ordering\n \n         self.W_regularizer = regularizers.get(W_regularizer)\n@@ -291,12 +293,13 @@ class LocallyConnected2D(Layer):\n             _, output_row, output_col, nb_filter = output_shape\n             input_filter = input_shape[3]\n         else:\n-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n \n         self.output_row = output_row\n         self.output_col = output_col\n-        self.W_shape = (output_row * output_col, self.nb_row * self.nb_col * input_filter, nb_filter)\n-\n+        self.W_shape = (output_row * output_col,\n+                        self.nb_row * self.nb_col * input_filter,\n+                        nb_filter)\n         self.W = self.add_weight(self.W_shape,\n                                  initializer=self.init,\n                                  name='{}_W'.format(self.name),\n@@ -324,7 +327,7 @@ class LocallyConnected2D(Layer):\n             rows = input_shape[1]\n             cols = input_shape[2]\n         else:\n-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n \n         rows = conv_output_length(rows, self.nb_row,\n                                   self.border_mode, self.subsample[0])\n@@ -335,8 +338,6 @@ class LocallyConnected2D(Layer):\n             return (input_shape[0], self.nb_filter, rows, cols)\n         elif self.dim_ordering == 'tf':\n             return (input_shape[0], rows, cols, self.nb_filter)\n-        else:\n-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n \n     def call(self, x, mask=None):\n         stride_row, stride_col = self.subsample\n@@ -381,15 +382,13 @@ class LocallyConnected2D(Layer):\n             output = K.reshape(output, (self.output_row, self.output_col, -1, nb_filter))\n             output = K.permute_dimensions(output, (2, 0, 1, 3))\n         else:\n-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n \n         if self.bias:\n             if self.dim_ordering == 'th':\n                 output += K.reshape(self.b, (1, nb_filter, self.output_row, self.output_col))\n             elif self.dim_ordering == 'tf':\n                 output += K.reshape(self.b, (1, self.output_row, self.output_col, nb_filter))\n-            else:\n-                raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n \n         output = self.activation(output)\n         return output\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5e1a5d07c468c37dadac7d19bcb9ff622b11ad82", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 18 | Files Changed: 2 | Hunks: 15 | Methods Changed: 4 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 43 | Churn Cumulative: 1252 | Contributors (this commit): 7 | Commits (past 90d): 11 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -269,7 +269,7 @@ class LocallyConnected2D(Layer):\n         self.border_mode = border_mode\n         self.subsample = tuple(subsample)\n         if dim_ordering not in {'tf', 'th'}:\n-            raise ValueError('dim_ordering must be in {tf, th}.')\n+            raise ValueError('`dim_ordering` must be in {tf, th}.')\n         self.dim_ordering = dim_ordering\n \n         self.W_regularizer = regularizers.get(W_regularizer)\n\n@@ -20,7 +20,8 @@ class _Pooling1D(Layer):\n         self.stride = stride\n         self.st = (self.stride, 1)\n         self.pool_size = (pool_length, 1)\n-        assert border_mode in {'valid', 'same'}, 'border_mode must be in {valid, same}'\n+        if border_mode not in {'valid', 'same'}:\n+            raise ValueError('`border_mode` must be in {valid, same}.')\n         self.border_mode = border_mode\n         self.input_spec = [InputSpec(ndim=3)]\n \n@@ -119,9 +120,11 @@ class _Pooling2D(Layer):\n         if strides is None:\n             strides = self.pool_size\n         self.strides = tuple(strides)\n-        assert border_mode in {'valid', 'same'}, 'border_mode must be in {valid, same}'\n+        if border_mode not in {'valid', 'same'}:\n+            raise ValueError('`border_mode` must be in {valid, same}.')\n         self.border_mode = border_mode\n-        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n+        if dim_ordering not in {'tf', 'th'}:\n+            raise ValueError('`dim_ordering` must be in {tf, th}.')\n         self.dim_ordering = dim_ordering\n         self.input_spec = [InputSpec(ndim=4)]\n \n@@ -133,7 +136,7 @@ class _Pooling2D(Layer):\n             rows = input_shape[1]\n             cols = input_shape[2]\n         else:\n-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n \n         rows = conv_output_length(rows, self.pool_size[0],\n                                   self.border_mode, self.strides[0])\n@@ -144,15 +147,14 @@ class _Pooling2D(Layer):\n             return (input_shape[0], input_shape[1], rows, cols)\n         elif self.dim_ordering == 'tf':\n             return (input_shape[0], rows, cols, input_shape[3])\n-        else:\n-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n \n     def _pooling_function(self, inputs, pool_size, strides,\n                           border_mode, dim_ordering):\n         raise NotImplementedError\n \n     def call(self, x, mask=None):\n-        output = self._pooling_function(inputs=x, pool_size=self.pool_size,\n+        output = self._pooling_function(inputs=x,\n+                                        pool_size=self.pool_size,\n                                         strides=self.strides,\n                                         border_mode=self.border_mode,\n                                         dim_ordering=self.dim_ordering)\n@@ -204,7 +206,8 @@ class MaxPooling2D(_Pooling2D):\n     def _pooling_function(self, inputs, pool_size, strides,\n                           border_mode, dim_ordering):\n         output = K.pool2d(inputs, pool_size, strides,\n-                          border_mode, dim_ordering, pool_mode='max')\n+                          border_mode, dim_ordering,\n+                          pool_mode='max')\n         return output\n \n \n@@ -262,9 +265,11 @@ class _Pooling3D(Layer):\n         if strides is None:\n             strides = self.pool_size\n         self.strides = tuple(strides)\n-        assert border_mode in {'valid', 'same'}, 'border_mode must be in {valid, same}'\n+        if border_mode not in {'valid', 'same'}:\n+            raise ValueError('`border_mode` must be in {valid, same}.')\n         self.border_mode = border_mode\n-        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n+        if dim_ordering not in {'tf', 'th'}:\n+            raise ValueError('`dim_ordering` must be in {tf, th}.')\n         self.dim_ordering = dim_ordering\n         self.input_spec = [InputSpec(ndim=5)]\n \n@@ -278,7 +283,7 @@ class _Pooling3D(Layer):\n             len_dim2 = input_shape[2]\n             len_dim3 = input_shape[3]\n         else:\n-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n \n         len_dim1 = conv_output_length(len_dim1, self.pool_size[0],\n                                       self.border_mode, self.strides[0])\n@@ -286,13 +291,14 @@ class _Pooling3D(Layer):\n                                       self.border_mode, self.strides[1])\n         len_dim3 = conv_output_length(len_dim3, self.pool_size[2],\n                                       self.border_mode, self.strides[2])\n-\n         if self.dim_ordering == 'th':\n-            return (input_shape[0], input_shape[1], len_dim1, len_dim2, len_dim3)\n+            return (input_shape[0],\n+                    input_shape[1],\n+                    len_dim1, len_dim2, len_dim3)\n         elif self.dim_ordering == 'tf':\n-            return (input_shape[0], len_dim1, len_dim2, len_dim3, input_shape[4])\n-        else:\n-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+            return (input_shape[0],\n+                    len_dim1, len_dim2, len_dim3,\n+                    input_shape[4])\n \n     def _pooling_function(self, inputs, pool_size, strides,\n                           border_mode, dim_ordering):\n@@ -390,7 +396,8 @@ class AveragePooling3D(_Pooling3D):\n     def _pooling_function(self, inputs, pool_size, strides,\n                           border_mode, dim_ordering):\n         output = K.pool3d(inputs, pool_size, strides,\n-                          border_mode, dim_ordering, pool_mode='avg')\n+                          border_mode, dim_ordering,\n+                          pool_mode='avg')\n         return output\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0fd0218ef0b513131970b2fe6b6e33f5b90f32a6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 27 | Files Changed: 8 | Hunks: 23 | Methods Changed: 13 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 48 | Churn Cumulative: 13246 | Contributors (this commit): 74 | Commits (past 90d): 52 | Contributors (cumulative): 107 | DMM Complexity: 1.0\n\nDIFF:\n@@ -69,7 +69,7 @@ def Xception(include_top=True, weights='imagenet',\n                          '`None` (random initialization) or `imagenet` '\n                          '(pre-training on ImageNet).')\n     if K.backend() != 'tensorflow':\n-        raise Exception('The Xception model is only available with '\n+        raise RuntimeError('The Xception model is only available with '\n                            'the TensorFlow backend.')\n     if K.image_dim_ordering() != 'tf':\n         warnings.warn('The Xception model is only available for the '\n\n@@ -395,7 +395,7 @@ class Convolution2D(Layer):\n             stack_size = input_shape[3]\n             self.W_shape = (self.nb_row, self.nb_col, stack_size, self.nb_filter)\n         else:\n-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n         self.W = self.add_weight(self.W_shape,\n                                  initializer=self.init,\n                                  name='{}_W'.format(self.name),\n@@ -934,7 +934,7 @@ class SeparableConvolution2D(Layer):\n             depthwise_shape = (self.nb_row, self.nb_col, stack_size, self.depth_multiplier)\n             pointwise_shape = (1, 1, self.depth_multiplier * stack_size, self.nb_filter)\n         else:\n-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n \n         self.depthwise_kernel = self.add_weight(depthwise_shape,\n                                                 initializer=self.init,\n\n@@ -105,7 +105,7 @@ class ConvRecurrent2D(Layer):\n             rows = input_shape[2]\n             cols = input_shape[3]\n         else:\n-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n \n         rows = conv_output_length(rows, self.nb_row,\n                                   self.border_mode, self.subsample[0])\n@@ -119,15 +119,11 @@ class ConvRecurrent2D(Layer):\n             elif self.dim_ordering == 'tf':\n                 return (input_shape[0], input_shape[1],\n                         rows, cols, self.nb_filter)\n-            else:\n-                raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n         else:\n             if self.dim_ordering == 'th':\n                 return (input_shape[0], self.nb_filter, rows, cols)\n             elif self.dim_ordering == 'tf':\n                 return (input_shape[0], rows, cols, self.nb_filter)\n-            else:\n-                raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n \n     def step(self, x, states):\n         raise NotImplementedError\n@@ -310,7 +306,7 @@ class ConvLSTM2D(ConvRecurrent2D):\n             self.W_shape = (self.nb_row, self.nb_col,\n                             stack_size, self.nb_filter)\n         else:\n-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+            raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n \n         if self.dim_ordering == 'th':\n             self.W_shape1 = (self.nb_filter, self.nb_filter,\n@@ -318,8 +314,6 @@ class ConvLSTM2D(ConvRecurrent2D):\n         elif self.dim_ordering == 'tf':\n             self.W_shape1 = (self.nb_row, self.nb_col,\n                              self.nb_filter, self.nb_filter)\n-        else:\n-            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n \n         if self.stateful:\n             self.reset_states()\n@@ -378,7 +372,7 @@ class ConvLSTM2D(ConvRecurrent2D):\n         input_shape = self.input_spec[0].shape\n         output_shape = self.get_output_shape_for(input_shape)\n         if not input_shape[0]:\n-            raise Exception('If a RNN is stateful, a complete ' +\n+            raise ValueError('If a RNN is stateful, a complete ' +\n                              'input_shape must be provided ' +\n                              '(including batch size).')\n \n@@ -417,7 +411,7 @@ class ConvLSTM2D(ConvRecurrent2D):\n             elif self.dim_ordering == 'tf':\n                 conv_out = conv_out + K.reshape(b, (1, 1, 1, self.nb_filter))\n             else:\n-                raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n+                raise ValueError('Invalid dim_ordering:', self.dim_ordering)\n \n         return conv_out\n \n\n@@ -327,7 +327,7 @@ class SimpleRNN(Recurrent):\n         assert self.stateful, 'Layer must be stateful.'\n         input_shape = self.input_spec[0].shape\n         if not input_shape[0]:\n-            raise Exception('If a RNN is stateful, it needs to know '\n+            raise ValueError('If a RNN is stateful, it needs to know '\n                              'its batch size. Specify the batch size '\n                              'of your input tensors: \\n'\n                              '- If using a Sequential model, '\n@@ -521,7 +521,7 @@ class GRU(Recurrent):\n         assert self.stateful, 'Layer must be stateful.'\n         input_shape = self.input_spec[0].shape\n         if not input_shape[0]:\n-            raise Exception('If a RNN is stateful, a complete ' +\n+            raise ValueError('If a RNN is stateful, a complete ' +\n                              'input_shape must be provided (including batch size).')\n         if hasattr(self, 'states'):\n             K.set_value(self.states[0],\n@@ -576,7 +576,7 @@ class GRU(Recurrent):\n                 x_r = K.dot(x * B_W[1], self.W_r) + self.b_r\n                 x_h = K.dot(x * B_W[2], self.W_h) + self.b_h\n             else:\n-                raise Exception('Unknown `consume_less` mode.')\n+                raise ValueError('Unknown `consume_less` mode.')\n             z = self.inner_activation(x_z + K.dot(h_tm1 * B_U[0], self.U_z))\n             r = self.inner_activation(x_r + K.dot(h_tm1 * B_U[1], self.U_r))\n \n@@ -773,7 +773,7 @@ class LSTM(Recurrent):\n         assert self.stateful, 'Layer must be stateful.'\n         input_shape = self.input_spec[0].shape\n         if not input_shape[0]:\n-            raise Exception('If a RNN is stateful, a complete ' +\n+            raise ValueError('If a RNN is stateful, a complete ' +\n                              'input_shape must be provided (including batch size).')\n         if hasattr(self, 'states'):\n             K.set_value(self.states[0],\n@@ -836,7 +836,7 @@ class LSTM(Recurrent):\n                 x_c = K.dot(x * B_W[2], self.W_c) + self.b_c\n                 x_o = K.dot(x * B_W[3], self.W_o) + self.b_o\n             else:\n-                raise Exception('Unknown `consume_less` mode.')\n+                raise ValueError('Unknown `consume_less` mode.')\n \n             i = self.inner_activation(x_i + K.dot(h_tm1 * B_U[0], self.U_i))\n             f = self.inner_activation(x_f + K.dot(h_tm1 * B_U[1], self.U_f))\n\n@@ -49,7 +49,7 @@ class Optimizer(object):\n         allowed_kwargs = {'clipnorm', 'clipvalue'}\n         for k in kwargs:\n             if k not in allowed_kwargs:\n-                raise Exception('Unexpected keyword argument '\n+                raise TypeError('Unexpected keyword argument '\n                                 'passed to optimizer: ' + str(k))\n         self.__dict__.update(kwargs)\n         self.updates = []\n@@ -85,7 +85,7 @@ class Optimizer(object):\n         param_values = K.batch_get_value(params)\n         for pv, p, w in zip(param_values, params, weights):\n             if pv.shape != w.shape:\n-                raise Exception('Optimizer weight shape ' +\n+                raise ValueError('Optimizer weight shape ' +\n                                  str(pv.shape) +\n                                  ' not compatible with '\n                                  'provided weight shape ' + str(w.shape))\n\n@@ -179,13 +179,13 @@ class Tokenizer(object):\n             if self.word_index:\n                 nb_words = len(self.word_index) + 1\n             else:\n-                raise Exception('Specify a dimension (nb_words argument), '\n+                raise ValueError('Specify a dimension (nb_words argument), '\n                                  'or fit on some text data first.')\n         else:\n             nb_words = self.nb_words\n \n         if mode == 'tfidf' and not self.document_count:\n-            raise Exception('Fit the Tokenizer on some data '\n+            raise ValueError('Fit the Tokenizer on some data '\n                              'before using tfidf mode.')\n \n         X = np.zeros((len(sequences), nb_words))\n@@ -214,5 +214,5 @@ class Tokenizer(object):\n                     idf = np.log(1 + self.document_count / (1 + self.index_docs.get(j, 0)))\n                     X[i][j] = tf * idf\n                 else:\n-                    raise Exception('Unknown vectorization mode: ' + str(mode))\n+                    raise ValueError('Unknown vectorization mode:', mode)\n         return X\n\n@@ -35,8 +35,8 @@ class EigenvalueRegularizer(Regularizer):\n         self.k = k\n \n     def __call__(self, x):\n-        if K.ndim(x) > 2:\n-            raise Exception('EigenvalueRegularizer '\n+        if K.ndim(x) != 2:\n+            raise ValueError('EigenvalueRegularizer '\n                              'is only available for tensors of rank 2.')\n         covariance = K.dot(K.transpose(x), x)\n         dim1, dim2 = K.eval(K.shape(covariance))\n\n@@ -86,7 +86,7 @@ def convert_kernel(kernel, dim_ordering='default'):\n                 for j in range(h):\n                     new_kernel[i, j, :, :] = kernel[w - i - 1, h - j - 1, :, :]\n         else:\n-            raise Exception('Invalid dim_ordering: ' + str(dim_ordering))\n+            raise ValueError('Invalid dim_ordering:', dim_ordering)\n     elif kernel.ndim == 5:\n         # conv 3d\n         # TH kernel shape: (out_depth, input_depth, kernel_dim1, kernel_dim2, kernel_dim3)\n@@ -114,7 +114,7 @@ def convert_kernel(kernel, dim_ordering='default'):\n                                                            z - k - 1,\n                                                            :, :]\n         else:\n-            raise Exception('Invalid dim_ordering: ' + str(dim_ordering))\n+            raise ValueError('Invalid dim_ordering:', dim_ordering)\n     else:\n         raise ValueError('Invalid kernel shape:', kernel.shape)\n     return new_kernel\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c6eea03c8db29b1d8aee492246b9a4135ddee7c5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 82 | Lines Deleted: 82 | Files Changed: 2 | Hunks: 68 | Methods Changed: 30 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 164 | Churn Cumulative: 6934 | Contributors (this commit): 49 | Commits (past 90d): 34 | Contributors (cumulative): 54 | DMM Complexity: None\n\nDIFF:\n@@ -168,18 +168,18 @@ class Node(object):\n             output_shapes = to_list(outbound_layer.get_output_shape_for(input_shapes))\n \n         if not output_tensors or output_tensors[0] is None:\n-            raise Exception('The `call` method of layer \"' +\n+            raise TypeError('The `call` method of layer \"' +\n                             outbound_layer.name +\n                             '\" should return a tensor. Found: ' +\n                             str(output_tensors[0]))\n         if len(output_tensors) != len(output_shapes):\n-            raise Exception('The `get_output_shape_for` method of layer \"' +\n+            raise ValueError('The `get_output_shape_for` method of layer \"' +\n                              outbound_layer.name +\n                              '\"\" should return one shape tuple per '\n                              'output tensor of the layer. Found: ' +\n                              str(output_shapes))\n         if len(output_tensors) != len(output_masks):\n-            raise Exception('The `compute_mask` method of layer \"' +\n+            raise ValueError('The `compute_mask` method of layer \"' +\n                              outbound_layer.name +\n                              '\" should return one mask tensor per '\n                              'output tensor of the layer. Found: ' +\n@@ -652,12 +652,12 @@ class Layer(object):\n                 if isinstance(input_mask, list):\n                     if any(input_mask):\n                         raise ValueError('Layer ' + self.name +\n-                                         ' does not support masking, ' +\n+                                         ' does not support masking, '\n                                          'but was passed an input_mask: ' +\n                                          str(input_mask))\n                 else:\n                     raise ValueError('Layer ' + self.name +\n-                                     ' does not support masking, ' +\n+                                     ' does not support masking, '\n                                      'but was passed an input_mask: ' +\n                                      str(input_mask))\n             # masking not explicitly supported: return None as mask\n@@ -687,10 +687,10 @@ class Layer(object):\n             attr_name: Human-readable attribute name, for error messages.\n         '''\n         if not self.inbound_nodes:\n-            raise Exception('The layer has never been called ' +\n+            raise RuntimeError('The layer has never been called '\n                                'and thus has no defined ' + attr_name + '.')\n         if not len(self.inbound_nodes) > node_index:\n-            raise Exception('Asked to get ' + attr_name +\n+            raise ValueError('Asked to get ' + attr_name +\n                              ' at node ' + str(node_index) +\n                              ', but the layer has only ' +\n                              str(len(self.inbound_nodes)) + ' inbound nodes.')\n@@ -749,13 +749,13 @@ class Layer(object):\n         to one incoming layer).\n         '''\n         if len(self.inbound_nodes) > 1:\n-            raise Exception('Layer ' + self.name +\n-                            ' has multiple inbound nodes, ' +\n+            raise AttributeError('Layer ' + self.name +\n+                                 ' has multiple inbound nodes, '\n                                  'hence the notion of \"layer input\" '\n                                  'is ill-defined. '\n                                  'Use `get_input_at(node_index)` instead.')\n         elif not self.inbound_nodes:\n-            raise Exception('Layer ' + self.name +\n+            raise AttributeError('Layer ' + self.name +\n                                  ' is not connected, no input to return.')\n         return self._get_node_attribute_at_index(0, 'input_tensors',\n                                                  'input')\n@@ -767,11 +767,11 @@ class Layer(object):\n         to one incoming layer).\n         '''\n         if len(self.inbound_nodes) == 0:\n-            raise Exception('Layer ' + self.name +\n+            raise AttributeError('Layer ' + self.name +\n                                  ' has no inbound nodes.')\n         if len(self.inbound_nodes) > 1:\n-            raise Exception('Layer ' + self.name +\n-                            ' has multiple inbound nodes, ' +\n+            raise AttributeError('Layer ' + self.name +\n+                                 ' has multiple inbound nodes, '\n                                  'hence the notion of \"layer output\" '\n                                  'is ill-defined. '\n                                  'Use `get_output_at(node_index)` instead.')\n@@ -785,7 +785,7 @@ class Layer(object):\n         to one incoming layer).\n         '''\n         if len(self.inbound_nodes) != 1:\n-            raise Exception('Layer ' + self.name +\n+            raise AttributeError('Layer ' + self.name +\n                                  ' has multiple inbound nodes, ' +\n                                  'hence the notion of \"layer input mask\" '\n                                  'is ill-defined. '\n@@ -800,8 +800,8 @@ class Layer(object):\n         to one incoming layer).\n         '''\n         if len(self.inbound_nodes) != 1:\n-            raise Exception('Layer ' + self.name +\n-                            ' has multiple inbound nodes, ' +\n+            raise AttributeError('Layer ' + self.name +\n+                                 ' has multiple inbound nodes, '\n                                  'hence the notion of \"layer output mask\" '\n                                  'is ill-defined. '\n                                  'Use `get_output_mask_at(node_index)` instead.')\n@@ -815,7 +815,7 @@ class Layer(object):\n         or if all inbound nodes have the same input shape.\n         '''\n         if not self.inbound_nodes:\n-            raise Exception('The layer has never been called ' +\n+            raise AttributeError('The layer has never been called '\n                                  'and thus has no defined input shape.')\n         all_input_shapes = set([str(node.input_shapes) for node in self.inbound_nodes])\n         if len(all_input_shapes) == 1:\n@@ -825,11 +825,11 @@ class Layer(object):\n             else:\n                 return input_shapes\n         else:\n-            raise Exception('The layer \"' + str(self.name) +\n-                            ' has multiple inbound nodes, ' +\n-                            'with different input shapes. Hence ' +\n-                            'the notion of \"input shape\" is ' +\n-                            'ill-defined for the layer. ' +\n+            raise AttributeError('The layer \"' + str(self.name) +\n+                                 ' has multiple inbound nodes, '\n+                                 'with different input shapes. Hence '\n+                                 'the notion of \"input shape\" is '\n+                                 'ill-defined for the layer. '\n                                  'Use `get_input_shape_at(node_index)` instead.')\n \n     @property\n@@ -839,7 +839,7 @@ class Layer(object):\n         or if all inbound nodes have the same output shape.\n         '''\n         if not self.inbound_nodes:\n-            raise Exception('The layer has never been called ' +\n+            raise AttributeError('The layer has never been called '\n                                  'and thus has no defined output shape.')\n         all_output_shapes = set([str(node.output_shapes) for node in self.inbound_nodes])\n         if len(all_output_shapes) == 1:\n@@ -849,11 +849,11 @@ class Layer(object):\n             else:\n                 return output_shapes\n         else:\n-            raise Exception('The layer \"' + str(self.name) +\n-                            ' has multiple inbound nodes, ' +\n-                            'with different output shapes. Hence ' +\n-                            'the notion of \"output shape\" is ' +\n-                            'ill-defined for the layer. ' +\n+            raise AttributeError('The layer \"' + str(self.name) +\n+                                 ' has multiple inbound nodes, '\n+                                 'with different output shapes. Hence '\n+                                 'the notion of \"output shape\" is '\n+                                 'ill-defined for the layer. '\n                                  'Use `get_output_shape_at(node_index)` instead.')\n \n     def add_loss(self, losses, inputs=None):\n@@ -1007,7 +1007,7 @@ class Layer(object):\n             if self.__class__.__name__ == 'Sequential':\n                 self.build()\n             else:\n-                raise Exception('You tried to call `count_params` on ' +\n+                raise RuntimeError('You tried to call `count_params` on ' +\n                                    self.name + ', but the layer isn\\'t built. '\n                                    'You can build it manually via: `' +\n                                    self.name + '.build(batch_input_shape)`.')\n@@ -1401,9 +1401,9 @@ class Merge(Layer):\n             raise TypeError('Merge can only be called on a list of tensors, '\n                             'not a single tensor. Received: ' + str(inputs))\n         if self.built:\n-            raise Exception('A Merge layer cannot be used more than once, '\n-                            'please use ' +\n-                            'the \"merge\" function instead: ' +\n+            raise RuntimeError('A Merge layer cannot be used more than once, '\n+                               'please use '\n+                               'the \"merge\" function instead: '\n                                '`merged_tensor = merge([tensor_1, tensor2])`.')\n \n         all_keras_tensors = True\n@@ -1716,7 +1716,7 @@ class Container(Layer):\n         # Check for redundancy in inputs.\n         inputs_set = set(self.inputs)\n         if len(inputs_set) != len(self.inputs):\n-            raise Exception('The list of inputs passed to the model '\n+            raise ValueError('The list of inputs passed to the model '\n                              'is redundant. All inputs should only appear once.'\n                              ' Found: ' + str(self.inputs))\n \n@@ -1752,7 +1752,7 @@ class Container(Layer):\n             # Check that x is a Keras tensor.\n             if not hasattr(x, '_keras_history'):\n                 cls_name = self.__class__.__name__\n-                raise Exception('Input tensors to a ' + cls_name + ' ' +\n+                raise TypeError('Input tensors to a ' + cls_name + ' ' +\n                                 'must be Keras tensors. Found: ' + str(x) +\n                                 ' (missing Keras metadata).')\n             # Check that x is an input tensor.\n@@ -1775,7 +1775,7 @@ class Container(Layer):\n         for x in self.outputs:\n             if not hasattr(x, '_keras_history'):\n                 cls_name = self.__class__.__name__\n-                raise Exception('Output tensors to a ' + cls_name + ' must be '\n+                raise TypeError('Output tensors to a ' + cls_name + ' must be '\n                                 'Keras tensors. Found: ' + str(x))\n         # Build self.output_layers:\n         for x in self.outputs:\n@@ -1947,7 +1947,7 @@ class Container(Layer):\n                 if layer:\n                     for x in node.input_tensors:\n                         if x not in computable_tensors:\n-                            raise Exception(\n+                            raise RuntimeError(\n                                 'Graph disconnected: '\n                                 'cannot obtain value for tensor ' +\n                                 str(x) + ' at layer \"' + layer.name + '\". '\n@@ -1967,9 +1967,9 @@ class Container(Layer):\n         all_names = [layer.name for layer in self.layers]\n         for name in all_names:\n             if all_names.count(name) != 1:\n-                raise Exception('The name \"' + name + '\" is used ' +\n+                raise RuntimeError('The name \"' + name + '\" is used ' +\n                                    str(all_names.count(name)) +\n-                                ' times in the model. ' +\n+                                   ' times in the model. '\n                                    'All layer names should be unique.')\n \n         # Layer parameters.\n@@ -2015,7 +2015,7 @@ class Container(Layer):\n         # without the container being notified of it.\n         if index is not None:\n             if len(self.layers) <= index:\n-                raise Exception('Was asked to retrieve layer at index ' +\n+                raise ValueError('Was asked to retrieve layer at index ' +\n                                  str(index) + ' but model only has ' +\n                                  str(len(self.layers)) + ' layers.')\n             else:\n@@ -2027,7 +2027,7 @@ class Container(Layer):\n             if layer.name == name:\n                 return layer\n         if not layer:\n-            raise Exception('No such layer: ' + name)\n+            raise ValueError('No such layer: ' + name)\n \n     @property\n     def updates(self):\n@@ -2098,7 +2098,7 @@ class Container(Layer):\n         for layer in self.layers:\n             for key, value in layer.constraints.items():\n                 if key in cons and cons[key] != value:\n-                    raise Exception('Received multiple constraints '\n+                    raise ValueError('Received multiple constraints '\n                                      'for one weight tensor: ' + str(key))\n                 cons[key] = value\n         return cons\n@@ -2226,7 +2226,7 @@ class Container(Layer):\n     def get_output_shape_for(self, input_shape):\n         input_shapes = to_list(input_shape)\n         if len(input_shapes) != len(self.input_layers):\n-            raise Exception('Invalid input_shape argument ' +\n+            raise ValueError('Invalid input_shape argument ' +\n                              str(input_shape) + ': model has ' +\n                              str(len(self.input_layers)) + ' tensor inputs.')\n \n@@ -2678,7 +2678,7 @@ class Container(Layer):\n             # Legacy format.\n             nb_layers = f.attrs['nb_layers']\n             if nb_layers != len(flattened_layers):\n-                raise Exception('You are trying to load a weight file '\n+                raise ValueError('You are trying to load a weight file '\n                                  'containing ' + str(nb_layers) +\n                                  ' layers into a model with ' +\n                                  str(len(flattened_layers)) + ' layers.')\n@@ -2705,7 +2705,7 @@ class Container(Layer):\n                     filtered_layer_names.append(name)\n             layer_names = filtered_layer_names\n             if len(layer_names) != len(flattened_layers):\n-                raise Exception('You are trying to load a weight file '\n+                raise ValueError('You are trying to load a weight file '\n                                  'containing ' + str(len(layer_names)) +\n                                  ' layers into a model with ' +\n                                  str(len(flattened_layers)) + ' layers.')\n@@ -2720,7 +2720,7 @@ class Container(Layer):\n                 layer = flattened_layers[k]\n                 symbolic_weights = layer.weights\n                 if len(weight_values) != len(symbolic_weights):\n-                    raise Exception('Layer #' + str(k) +\n+                    raise ValueError('Layer #' + str(k) +\n                                      ' (named \"' + layer.name +\n                                      '\" in the current model) was found to '\n                                      'correspond to layer ' + name +\n@@ -2755,8 +2755,8 @@ class Container(Layer):\n             flattened_layers = self.layers\n \n         if 'nb_layers' in f.attrs:\n-                raise Exception('The weight file you are trying to load is' +\n-                                ' in a legacy format that does not support' +\n+                raise ValueError('The weight file you are trying to load is'\n+                                 ' in a legacy format that does not support'\n                                  ' name-based weight loading.')\n         else:\n             # New file format.\n@@ -2779,7 +2779,7 @@ class Container(Layer):\n                 for layer in index.get(name, []):\n                     symbolic_weights = layer.weights\n                     if len(weight_values) != len(symbolic_weights):\n-                        raise Exception('Layer #' + str(k) +\n+                        raise ValueError('Layer #' + str(k) +\n                                          ' (named \"' + layer.name +\n                                          '\") expects ' +\n                                          str(len(symbolic_weights)) +\n\n@@ -36,14 +36,14 @@ def standardize_input_data(data, names, shapes=None,\n         arrays = []\n         for name in names:\n             if name not in data:\n-                raise Exception('No data provided for \"' +\n+                raise ValueError('No data provided for \"' +\n                                  name + '\". Need data for each key in: ' +\n                                  str(data.keys()))\n             arrays.append(data[name])\n     elif isinstance(data, list):\n         if len(data) != len(names):\n             if len(data) > 0 and hasattr(data[0], 'shape'):\n-                raise Exception('Error when checking ' + exception_prefix +\n+                raise ValueError('Error when checking ' + exception_prefix +\n                                  ': the list of Numpy arrays '\n                                  'that you are passing to your model '\n                                  'is not the size the model expected. '\n@@ -56,7 +56,7 @@ def standardize_input_data(data, names, shapes=None,\n                 if len(names) == 1:\n                     data = [np.asarray(data)]\n                 else:\n-                    raise Exception('Error when checking ' + exception_prefix +\n+                    raise ValueError('Error when checking ' + exception_prefix +\n                                      ': you are passing a list as '\n                                      'input to your model, '\n                                      'but the model expects '\n@@ -67,14 +67,14 @@ def standardize_input_data(data, names, shapes=None,\n         arrays = data\n     else:\n         if not hasattr(data, 'shape'):\n-            raise Exception('Error when checking ' + exception_prefix +\n+            raise TypeError('Error when checking ' + exception_prefix +\n                             ': data should be a Numpy array, '\n                             'or list/dict of Numpy arrays. '\n                             'Found: ' + str(data)[:200] + '...')\n         if len(names) != 1:\n             # case: model expects multiple inputs but only received\n             # a single Numpy array\n-            raise Exception('The model expects ' + str(len(names)) +\n+            raise ValueError('The model expects ' + str(len(names)) +\n                              ' input arrays, but only received one array. '\n                              'Found: array with shape ' + str(data.shape))\n         arrays = [data]\n@@ -93,7 +93,7 @@ def standardize_input_data(data, names, shapes=None,\n                 continue\n             array = arrays[i]\n             if len(array.shape) != len(shapes[i]):\n-                raise Exception('Error when checking ' + exception_prefix +\n+                raise ValueError('Error when checking ' + exception_prefix +\n                                  ': expected ' + names[i] +\n                                  ' to have ' + str(len(shapes[i])) +\n                                  ' dimensions, but got array with shape ' +\n@@ -104,7 +104,7 @@ def standardize_input_data(data, names, shapes=None,\n                     continue\n                 if ref_dim:\n                     if ref_dim != dim:\n-                        raise Exception('Error when checking ' + exception_prefix +\n+                        raise ValueError('Error when checking ' + exception_prefix +\n                                          ': expected ' + names[i] +\n                                          ' to have shape ' + str(shapes[i]) +\n                                          ' but got array with shape ' +\n@@ -124,7 +124,7 @@ def standardize_sample_or_class_weights(x_weight, output_names, weight_type):\n             return [x_weight]\n     if isinstance(x_weight, list):\n         if len(x_weight) != len(output_names):\n-            raise Exception('Provided `' + weight_type + '` was a list of ' +\n+            raise ValueError('Provided `' + weight_type + '` was a list of ' +\n                              str(len(x_weight)) +\n                              ' elements, but the model has ' +\n                              str(len(output_names)) + ' outputs. '\n@@ -137,7 +137,7 @@ def standardize_sample_or_class_weights(x_weight, output_names, weight_type):\n             x_weights.append(x_weight.get(name))\n         return x_weights\n     else:\n-        raise Exception('The model has multiple outputs, so `' +\n+        raise TypeError('The model has multiple outputs, so `' +\n                         weight_type + '` '\n                         'should be either a list of a dict. '\n                         'Provided `' + weight_type +\n@@ -163,23 +163,23 @@ def check_array_lengths(X, Y, W):\n     w_lengths = [w.shape[0] for w in W]\n     set_x = set(x_lengths)\n     if len(set_x) != 1:\n-        raise Exception('All input arrays (x) should have '\n+        raise ValueError('All input arrays (x) should have '\n                          'the same number of samples.')\n     set_y = set(y_lengths)\n     if len(set_y) != 1:\n-        raise Exception('All target arrays (y) should have '\n+        raise ValueError('All target arrays (y) should have '\n                          'the same number of samples.')\n     set_w = set(w_lengths)\n     if len(set_w) != 1:\n-        raise Exception('All sample_weight arrays should have '\n+        raise ValueError('All sample_weight arrays should have '\n                          'the same number of samples.')\n     if list(set_x)[0] != list(set_y)[0]:\n-        raise Exception('Input arrays should have '\n+        raise ValueError('Input arrays should have '\n                          'the same number of samples as target arrays. Found ' +\n                          str(list(set_x)[0]) + ' input samples and ' +\n                          str(list(set_y)[0]) + ' target samples.')\n     if list(set_x)[0] != list(set_w)[0]:\n-        raise Exception('Sample_weight arrays should have '\n+        raise ValueError('Sample_weight arrays should have '\n                          'the same number of samples as input arrays. Found ' +\n                          str(list(set_x)[0]) + ' input samples and ' +\n                          str(list(set_w)[0]) + ' target samples.')\n@@ -192,7 +192,7 @@ def check_loss_and_target_compatibility(targets, losses, output_shapes):\n     for y, loss, shape in zip(targets, losses, output_shapes):\n         if loss.__name__ == 'categorical_crossentropy':\n             if y.shape[-1] == 1:\n-                raise Exception('You are passing a target array of shape ' + str(y.shape) +\n+                raise ValueError('You are passing a target array of shape ' + str(y.shape) +\n                                  ' while using as loss `categorical_crossentropy`. '\n                                  '`categorical_crossentropy` expects '\n                                  'targets to be binary matrices (1s and 0s) '\n@@ -210,7 +210,7 @@ def check_loss_and_target_compatibility(targets, losses, output_shapes):\n         if loss.__name__ in key_losses:\n             for target_dim, out_dim in zip(y.shape[1:], shape[1:]):\n                 if out_dim is not None and target_dim != out_dim:\n-                    raise Exception('A target array with shape ' + str(y.shape) +\n+                    raise ValueError('A target array with shape ' + str(y.shape) +\n                                      ' was passed for an output of shape ' + str(shape) +\n                                      ' while using as loss `' + loss.__name__ + '`. '\n                                      'This loss expects '\n@@ -330,11 +330,11 @@ def standardize_weights(y, sample_weight=None, class_weight=None,\n     '''\n     if sample_weight_mode is not None:\n         if sample_weight_mode != 'temporal':\n-            raise Exception('\"sample_weight_mode '\n+            raise ValueError('\"sample_weight_mode '\n                              'should be None or \"temporal\". '\n                              'Found: ' + str(sample_weight_mode))\n         if len(y.shape) < 3:\n-            raise Exception('Found a sample_weight array for '\n+            raise ValueError('Found a sample_weight array for '\n                              'an input with shape ' +\n                              str(y.shape) + '. '\n                              'Timestep-wise sample weighting (use of '\n@@ -342,13 +342,13 @@ def standardize_weights(y, sample_weight=None, class_weight=None,\n                              'outputs that are at least 3D, i.e. that have '\n                              'a time dimension.')\n         if sample_weight is not None and len(sample_weight.shape) != 2:\n-            raise Exception('Found a sample_weight array with shape ' +\n+            raise ValueError('Found a sample_weight array with shape ' +\n                              str(sample_weight.shape) + '. '\n                              'In order to use timestep-wise sample weighting, '\n                              'you should pass a 2D sample_weight array.')\n     else:\n         if sample_weight is not None and len(sample_weight.shape) != 1:\n-            raise Exception('Found a sample_weight array with shape ' +\n+            raise ValueError('Found a sample_weight array with shape ' +\n                              str(sample_weight.shape) + '. '\n                              'In order to use timestep-wise sample weights, '\n                              'you should specify sample_weight_mode=\"temporal\" '\n@@ -363,7 +363,7 @@ def standardize_weights(y, sample_weight=None, class_weight=None,\n         return sample_weight\n     elif isinstance(class_weight, dict):\n         if len(y.shape) > 2:\n-            raise Exception('class_weight not supported for '\n+            raise ValueError('class_weight not supported for '\n                              '3+ dimensional targets.')\n         if y.shape[1] > 1:\n             y_classes = y.argmax(axis=1)\n@@ -686,7 +686,7 @@ class Model(Container):\n \n     def _make_train_function(self):\n         if not hasattr(self, 'train_function'):\n-            raise Exception('You must compile your model before using it.')\n+            raise RuntimeError('You must compile your model before using it.')\n         if self.train_function is None:\n             if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                 inputs = self.inputs + self.targets + self.sample_weights + [K.learning_phase()]\n@@ -706,7 +706,7 @@ class Model(Container):\n \n     def _make_test_function(self):\n         if not hasattr(self, 'test_function'):\n-            raise Exception('You must compile your model before using it.')\n+            raise RuntimeError('You must compile your model before using it.')\n         if self.test_function is None:\n             if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                 inputs = self.inputs + self.targets + self.sample_weights + [K.learning_phase()]\n@@ -818,7 +818,7 @@ class Model(Container):\n                     else:\n                         ins_batch = slice_X(ins, batch_ids)\n                 except TypeError:\n-                    raise Exception('TypeError while preparing batch. '\n+                    raise TypeError('TypeError while preparing batch. '\n                                     'If using HDF5 input data, '\n                                     'pass shuffle=\"batch\".')\n                 batch_logs = {}\n@@ -948,7 +948,7 @@ class Model(Container):\n                                sample_weight=None, class_weight=None,\n                                check_batch_dim=True, batch_size=None):\n         if not hasattr(self, 'optimizer'):\n-            raise Exception('You must compile a model before training/testing.'\n+            raise RuntimeError('You must compile a model before training/testing.'\n                                ' Use `model.compile(optimizer, loss)`.')\n \n         output_shapes = []\n@@ -978,7 +978,7 @@ class Model(Container):\n         check_loss_and_target_compatibility(y, self.loss_functions, self.internal_output_shapes)\n         if self.stateful and batch_size:\n             if x[0].shape[0] % batch_size != 0:\n-                raise Exception('In a stateful network, '\n+                raise ValueError('In a stateful network, '\n                                  'you should only pass inputs with '\n                                  'a number of samples that can be '\n                                  'divided by the batch size. Found: ' +\n@@ -1169,7 +1169,7 @@ class Model(Container):\n                                    check_batch_dim=False)\n         if self.stateful:\n             if x[0].shape[0] > batch_size and x[0].shape[0] % batch_size != 0:\n-                raise Exception('In a stateful network, '\n+                raise ValueError('In a stateful network, '\n                                  'you should only pass inputs with '\n                                  'a number of samples that can be '\n                                  'divided by the batch size. Found: ' +\n@@ -1360,7 +1360,7 @@ class Model(Container):\n         val_gen = (hasattr(validation_data, 'next') or\n                    hasattr(validation_data, '__next__'))\n         if val_gen and not nb_val_samples:\n-            raise Exception('When using a generator for validation data, '\n+            raise ValueError('When using a generator for validation data, '\n                              'you must specify a value for \"nb_val_samples\".')\n \n         out_labels = self.metrics_names\n@@ -1395,7 +1395,7 @@ class Model(Container):\n             elif len(validation_data) == 3:\n                 val_x, val_y, val_sample_weight = validation_data\n             else:\n-                raise Exception('validation_data should be a tuple '\n+                raise ValueError('validation_data should be a tuple '\n                                  '(val_x, val_y, val_sample_weight) '\n                                  'or (val_x, val_y). Found: ' + str(validation_data))\n             val_x, val_y, val_sample_weights = self._standardize_user_data(val_x, val_y, val_sample_weight)\n@@ -1423,7 +1423,7 @@ class Model(Container):\n \n                 if not hasattr(generator_output, '__len__'):\n                     _stop.set()\n-                    raise Exception('output of generator should be a tuple '\n+                    raise ValueError('output of generator should be a tuple '\n                                      '(x, y, sample_weight) '\n                                      'or (x, y). Found: ' + str(generator_output))\n                 if len(generator_output) == 2:\n@@ -1433,7 +1433,7 @@ class Model(Container):\n                     x, y, sample_weight = generator_output\n                 else:\n                     _stop.set()\n-                    raise Exception('output of generator should be a tuple '\n+                    raise ValueError('output of generator should be a tuple '\n                                      '(x, y, sample_weight) '\n                                      'or (x, y). Found: ' + str(generator_output))\n                 # build batch logs\n@@ -1554,7 +1554,7 @@ class Model(Container):\n \n             if not hasattr(generator_output, '__len__'):\n                 _stop.set()\n-                raise Exception('output of generator should be a tuple '\n+                raise ValueError('output of generator should be a tuple '\n                                  '(x, y, sample_weight) '\n                                  'or (x, y). Found: ' + str(generator_output))\n             if len(generator_output) == 2:\n@@ -1564,7 +1564,7 @@ class Model(Container):\n                 x, y, sample_weight = generator_output\n             else:\n                 _stop.set()\n-                raise Exception('output of generator should be a tuple '\n+                raise ValueError('output of generator should be a tuple '\n                                  '(x, y, sample_weight) '\n                                  'or (x, y). Found: ' + str(generator_output))\n             try:\n@@ -1645,7 +1645,7 @@ class Model(Container):\n                     x, y, sample_weight = generator_output\n                 else:\n                     _stop.set()\n-                    raise Exception('output of generator should be a tuple '\n+                    raise ValueError('output of generator should be a tuple '\n                                      '(x, y, sample_weight) '\n                                      'or (x, y). Found: ' + str(generator_output))\n             else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
