{"custom_id": "keras#7f91062eea8d23f6407a2c3bc253e82e48a52e30", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 55 | Lines Deleted: 56 | Files Changed: 2 | Hunks: 40 | Methods Changed: 13 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 111 | Churn Cumulative: 413 | Contributors (this commit): 1 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -15,6 +15,7 @@\n \n import tensorflow.compat.v2 as tf\n \n+from keras.initializers import TruncatedNormal\n from keras.layers.rnn import Wrapper\n \n # isort: off\n@@ -25,30 +26,30 @@ from tensorflow.python.util.tf_export import keras_export\n @keras_export(\"keras.layers.SpectralNormalization\", v1=[])\n class SpectralNormalization(Wrapper):\n     \"\"\"Performs spectral normalization on weights.\n+\n     This wrapper controls the Lipschitz constant of the layer by\n     constraining its spectral norm, which can stabilize the training of GANs.\n     See [Spectral Normalization for GAN](https://arxiv.org/abs/1802.05957).\n+\n+    Args:\n+      layer: a `tf.keras.layers.Layer` instance that\n+        has either `kernel` or `embeddings` attribute.\n+      power_iterations: `int`, the number of iterations during normalization.\n+\n+    Examples:\n       Wrap `tf.keras.layers.Conv2D`:\n       >>> x = np.random.rand(1, 10, 10, 1)\n       >>> conv2d = SpectralNormalization(tf.keras.layers.Conv2D(2, 2))\n       >>> y = conv2d(x)\n       >>> y.shape\n       TensorShape([1, 9, 9, 2])\n+\n       Wrap `tf.keras.layers.Dense`:\n       >>> x = np.random.rand(1, 10, 10, 1)\n       >>> dense = SpectralNormalization(tf.keras.layers.Dense(10))\n       >>> y = dense(x)\n       >>> y.shape\n       TensorShape([1, 10, 10, 10])\n-    Args:\n-      layer: A `tf.keras.layers.Layer` instance that\n-        has either `kernel` or `embeddings` attribute.\n-      power_iterations: `int`, the number of iterations during normalization.\n-    Raises:\n-      AssertionError: If not initialized with a `Layer` instance.\n-      ValueError: If initialized with negative `power_iterations`.\n-      AttributeError: If `layer` does not has `kernel` or `embeddings`\n-        attribute.\n     \"\"\"\n \n     def __init__(self, layer, power_iterations=1, **kwargs):\n@@ -56,13 +57,11 @@ class SpectralNormalization(Wrapper):\n         if power_iterations <= 0:\n             raise ValueError(\n                 \"`power_iterations` should be greater than zero, got \"\n-                \"`power_iterations={}`\".format(power_iterations)\n+                f\"`power_iterations={power_iterations}`\"\n             )\n         self.power_iterations = power_iterations\n-        self._initialized = False\n \n     def build(self, input_shape):\n-        \"\"\"Build `Layer`\"\"\"\n         super().build(input_shape)\n         input_shape = tf.TensorShape(input_shape)\n         self.input_spec = tf.keras.layers.InputSpec(\n@@ -70,30 +69,26 @@ class SpectralNormalization(Wrapper):\n         )\n \n         if hasattr(self.layer, \"kernel\"):\n-            self.w = self.layer.kernel\n+            self.kernel = self.layer.kernel\n         elif hasattr(self.layer, \"embeddings\"):\n-            self.w = self.layer.embeddings\n+            self.kernel = self.layer.embeddings\n         else:\n-            raise AttributeError(\n-                \"{} object has no attribute 'kernel' nor \"\n-                \"'embeddings'\".format(type(self.layer).__name__)\n+            raise ValueError(\n+                f\"{type(self.layer).__name__} object has no attribute 'kernel' \"\n+                \"nor 'embeddings'\"\n             )\n \n-        self.w_shape = self.w.shape.as_list()\n+        self.kernel_shape = self.kernel.shape.as_list()\n \n-        self.u = self.add_weight(\n-            shape=(1, self.w_shape[-1]),\n-            initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n+        self.sn_u = self.add_weight(\n+            shape=(1, self.self.kernel_shape[-1]),\n+            initializer=TruncatedNormal(stddev=0.02),\n             trainable=False,\n             name=\"sn_u\",\n-            dtype=self.w.dtype,\n+            dtype=self.kernel.dtype,\n         )\n \n-    def call(self, inputs, training=None):\n-        \"\"\"Call `Layer`\"\"\"\n-        if training is None:\n-            training = tf.keras.backend.learning_phase()\n-\n+    def call(self, inputs, training=False):\n         if training:\n             self.normalize_weights()\n \n@@ -107,12 +102,13 @@ class SpectralNormalization(Wrapper):\n \n     def normalize_weights(self):\n         \"\"\"Generate spectral normalized weights.\n-        This method will update the value of `self.w` with the\n+\n+        This method will update the value of `self.kernel` with the\n         spectral normalized value, so that the layer is ready for `call()`.\n         \"\"\"\n \n-        w = tf.reshape(self.w, [-1, self.w_shape[-1]])\n-        u = self.u\n+        w = tf.reshape(self.kernel, [-1, self.self.kernel_shape[-1]])\n+        u = self.sn_u\n \n         # check for zeroes weights\n         if not tf.reduce_all(tf.equal(w, 0.0)):\n@@ -122,9 +118,12 @@ class SpectralNormalization(Wrapper):\n             u = tf.stop_gradient(u)\n             v = tf.stop_gradient(v)\n             sigma = tf.matmul(tf.matmul(v, w), u, transpose_b=True)\n-            self.u.assign(tf.cast(u, self.u.dtype))\n-            self.w.assign(\n-                tf.cast(tf.reshape(self.w / sigma, self.w_shape), self.w.dtype)\n+            self.sn_u.assign(tf.cast(u, self.sn_u.dtype))\n+            self.kernel.assign(\n+                tf.cast(\n+                    tf.reshape(self.kernel / sigma, self.self.kernel_shape),\n+                    self.kernel.dtype,\n+                )\n             )\n \n     def get_config(self):\n\n@@ -26,13 +26,13 @@ class SpectralNormalizationTest(test_combinations.TestCase):\n     def test_basic_spectralnorm(self):\n         test_utils.layer_test(\n             keras.layers.SpectralNormalization,\n-            kwargs={\"layer\": tf.keras.layers.Dense(2), \"input_shape\": (3, 4)},\n+            kwargs={\"layer\": keras.layers.Dense(2), \"input_shape\": (3, 4)},\n             input_data=tf.random.uniform((10, 3, 4)),\n         )\n \n     @test_combinations.run_all_keras_modes\n     def test_from_to_config(self):\n-        base_layer = tf.keras.layers.Dense(1)\n+        base_layer = keras.layers.Dense(1)\n         sn = keras.layers.SpectralNormalization(base_layer)\n         config = sn.get_config()\n \n@@ -41,18 +41,18 @@ class SpectralNormalizationTest(test_combinations.TestCase):\n \n     @test_combinations.run_all_keras_modes\n     def test_save_load_model(self):\n-        base_layer = tf.keras.layers.Dense(1)\n+        base_layer = keras.layers.Dense(1)\n         input_shape = [1]\n \n-        inputs = tf.keras.layers.Input(shape=input_shape)\n+        inputs = keras.layers.Input(shape=input_shape)\n         sn_layer = keras.layers.SpectralNormalization(base_layer)\n-        model = tf.keras.models.Sequential(layers=[inputs, sn_layer])\n+        model = keras.models.Sequential(layers=[inputs, sn_layer])\n \n         # initialize model\n         model.predict(tf.random.uniform((2, 1)))\n \n         model.save(\"test.h5\")\n-        new_model = tf.keras.models.load_model(\"test.h5\")\n+        new_model = keras.models.load_model(\"test.h5\")\n \n         self.assertEqual(\n             model.layers[0].get_config(), new_model.layers[0].get_config()\n@@ -60,13 +60,13 @@ class SpectralNormalizationTest(test_combinations.TestCase):\n \n     @test_combinations.run_all_keras_modes\n     def test_normalization(self):\n-        inputs = tf.keras.layers.Input(shape=[2, 2, 1])\n+        inputs = keras.layers.Input(shape=[2, 2, 1])\n \n-        base_layer = tf.keras.layers.Conv2D(\n+        base_layer = keras.layers.Conv2D(\n             1, (2, 2), kernel_initializer=tf.constant_initializer(value=2)\n         )\n         sn_layer = keras.layers.SpectralNormalization(base_layer)\n-        model = tf.keras.models.Sequential(layers=[inputs, sn_layer])\n+        model = keras.models.Sequential(layers=[inputs, sn_layer])\n \n         weights = tf.squeeze(model.layers[0].w.numpy())\n         # This wrapper normalizes weights by the maximum eigen value\n@@ -88,7 +88,7 @@ class SpectralNormalizationTest(test_combinations.TestCase):\n     def test_apply_layer(self):\n         images = tf.ones((1, 2, 2, 1))\n         sn_wrapper = keras.layers.SpectralNormalization(\n-            tf.keras.layers.Conv2D(\n+            keras.layers.Conv2D(\n                 1, [2, 2], kernel_initializer=tf.constant_initializer(value=1)\n             ),\n             input_shape=(2, 2, 1),\n@@ -113,50 +113,50 @@ class SpectralNormalizationTest(test_combinations.TestCase):\n     def test_no_kernel(self):\n         with self.assertRaises(AttributeError):\n             keras.layers.SpectralNormalization(\n-                tf.keras.layers.MaxPooling2D(2, 2)\n+                keras.layers.MaxPooling2D(2, 2)\n             ).build((2, 2))\n \n     @test_combinations.run_all_keras_modes\n     @parameterized.parameters(\n         [\n-            (lambda: tf.keras.layers.Dense(2), [3, 2]),\n+            (lambda: keras.layers.Dense(2), [3, 2]),\n             (\n-                lambda: tf.keras.layers.Conv2D(3, (2, 2), padding=\"same\"),\n+                lambda: keras.layers.Conv2D(3, (2, 2), padding=\"same\"),\n                 [4, 4, 3],\n             ),\n-            (lambda: tf.keras.layers.Embedding(2, 10), [2]),\n+            (lambda: keras.layers.Embedding(2, 10), [2]),\n         ],\n     )\n     def test_model_build(self, base_layer_fn, input_shape):\n-        inputs = tf.keras.layers.Input(shape=input_shape)\n+        inputs = keras.layers.Input(shape=input_shape)\n         base_layer = base_layer_fn()\n         sn_layer = keras.layers.SpectralNormalization(base_layer)\n-        model = tf.keras.models.Sequential(layers=[inputs, sn_layer])\n+        model = keras.models.Sequential(layers=[inputs, sn_layer])\n         model.build()\n         self.assertTrue(hasattr(model.layers[0], \"u\"))\n \n     @test_combinations.run_all_keras_modes\n     @parameterized.parameters(\n         [\n-            (lambda: tf.keras.layers.Dense(2), [3, 2], [3, 2]),\n+            (lambda: keras.layers.Dense(2), [3, 2], [3, 2]),\n             (\n-                lambda: tf.keras.layers.Conv2D(3, (2, 2), padding=\"same\"),\n+                lambda: keras.layers.Conv2D(3, (2, 2), padding=\"same\"),\n                 [4, 4, 3],\n                 [4, 4, 3],\n             ),\n-            (lambda: tf.keras.layers.Embedding(2, 10), [2], [2, 10]),\n+            (lambda: keras.layers.Embedding(2, 10), [2], [2, 10]),\n         ],\n     )\n     def test_model_fit(self, base_layer_fn, input_shape, output_shape):\n-        inputs = tf.keras.layers.Input(shape=input_shape)\n+        inputs = keras.layers.Input(shape=input_shape)\n         base_layer = base_layer_fn()\n \n         sn_layer = keras.layers.SpectralNormalization(base_layer)\n-        model = tf.keras.models.Sequential(layers=[inputs, sn_layer])\n-        model.add(tf.keras.layers.Activation(\"relu\"))\n+        model = keras.models.Sequential(layers=[inputs, sn_layer])\n+        model.add(keras.layers.Activation(\"relu\"))\n \n         model.compile(\n-            optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n+            optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n             loss=\"mse\",\n         )\n         model.fit(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#33fc8600783631e98eabdc1a2604da934b1de58b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): -35/1 | Churn Δ: 15 | Churn Cumulative: 32314 | Contributors (this commit): 158 | Commits (past 90d): 18 | Contributors (cumulative): 181 | DMM Complexity: 0.0\n\nDIFF:\n@@ -928,9 +928,6 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n             \"method on your layer (%s).\" % self.__class__.__name__\n         )\n \n-    def _return_output_dtype(self):\n-        return self._compute_dtype\n-\n     @doc_controls.for_subclass_implementers\n     def compute_output_signature(self, input_signature):\n         \"\"\"Compute the output tensor signature of the layer based on the inputs.\n@@ -966,7 +963,12 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n             check_type_return_shape, input_signature\n         )\n         output_shape = self.compute_output_shape(input_shape)\n-        dtype = self._return_output_dtype()\n+\n+        try:\n+            dtype = self.output.dtype\n+        except AttributeError:\n+            dtype = self._compute_dtype\n+\n         if dtype is None:\n             input_dtypes = [s.dtype for s in tf.nest.flatten(input_signature)]\n             # Default behavior when self.dtype is None, is to use the first\n\n@@ -3295,11 +3295,6 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n             \"Provide either a layer name or layer index at `get_layer`.\"\n         )\n \n-    def _return_output_dtype(self):\n-        \"\"\"this method was implemented in order to\n-        fix a small bug in tf.keras.layer.Layer.compute_output_signature\"\"\"\n-        return self.get_layer(index=-1)._compute_dtype\n-\n     def get_weight_paths(self):\n         \"\"\"Retrieve all the variables and their paths for the model.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#002f12859a82a548a9b3b0b3c656d8e0368c3414", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 4553 | Contributors (this commit): 13 | Commits (past 90d): 4 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -2309,7 +2309,7 @@ class DTypeTest(test_combinations.TestCase):\n         # create a simple network\n         x = input_layer_lib.Input(shape=(32,), dtype=\"float32\")\n         dense_a = layers.Rescaling(scale=1.0 / 255)\n-        dense_b = layers.Activation('softmax', dtype=\"float64\")\n+        dense_b = layers.Activation(\"softmax\", dtype=\"float64\")\n         y = dense_b(dense_a(x))\n         network = functional.Functional(x, y)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5fbe19ecadbdf69acb13f1b3aac3c411b1427c83", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 200 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -33,7 +33,7 @@ class SpectralNormalization(Wrapper):\n \n     Args:\n       layer: a `tf.keras.layers.Layer` instance that\n-        has either `kernel` or `embeddings` attribute.\n+        has either a `kernel` or an `embeddings` attribute.\n       power_iterations: `int`, the number of iterations during normalization.\n \n     Examples:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#782a35a4d068d45a6903e04143c4b3692e603406", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 264 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -16,6 +16,7 @@\n \n import inspect\n import threading\n+import warnings\n \n # isort: off\n from tensorflow.python.util.tf_export import keras_export\n@@ -151,15 +152,17 @@ def register_keras_serializable(package=\"Custom\", name=None):\n             )\n \n         if registered_name in _GLOBAL_CUSTOM_OBJECTS:\n-            raise ValueError(\n+            warnings.warn(\n                 f\"{registered_name} has already been registered to \"\n-                f\"{_GLOBAL_CUSTOM_OBJECTS[registered_name]}\"\n+                f\"{_GLOBAL_CUSTOM_OBJECTS[registered_name]}. \"\n+                f\"Overwriting registration with {arg}.\"\n             )\n \n         if arg in _GLOBAL_CUSTOM_NAMES:\n-            raise ValueError(\n+            warnings.warn(\n                 f\"{arg} has already been registered to \"\n-                f\"{_GLOBAL_CUSTOM_NAMES[arg]}\"\n+                f\"{_GLOBAL_CUSTOM_NAMES[arg]}. \"\n+                f\"Overwriting registration with {registered_name}.\"\n             )\n         _GLOBAL_CUSTOM_OBJECTS[registered_name] = arg\n         _GLOBAL_CUSTOM_NAMES[arg] = registered_name\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c7d15d9953f67c7b0df0f67d06e3cb54799e6d96", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 114 | Lines Deleted: 28 | Files Changed: 2 | Hunks: 13 | Methods Changed: 8 | Complexity Δ (Sum/Max): 6/4 | Churn Δ: 142 | Churn Cumulative: 240 | Contributors (this commit): 1 | Commits (past 90d): 6 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -76,14 +76,29 @@ class ExportArchive(tf.__internal__.tracking.AutoTrackable):\n     )\n     export_archive.write_out(\"path/to/location\")\n     ```\n+\n+    **Note on resource tracking:**\n+\n+    `ExportArchive` is able to automatically track all `tf.Variables` used\n+    by its endpoints, so most of the time calling `.track(model)`\n+    is not strictly required. However, if your model uses lookup layers such\n+    as `IntegerLookup`, `StringLookup`, or `TextVectorization`,\n+    it will need to be tracked explicitly via `.track(model)`.\n+\n+    Explicit tracking is also required if you need to be able to access\n+    the properties `variables`, `trainable_variables`, or\n+    `non_trainable_variables` on the revived archive.\n     \"\"\"\n \n     def __init__(self):\n         self._endpoint_names = []\n         self._endpoint_signatures = {}\n-        self._trackables = []\n         self.tensorflow_version = tf.__version__\n+        self.variables = []\n+        self.trainable_variables = []\n+        self.non_trainable_variables = []\n \n+    @tf.__internal__.tracking.no_automatic_dependency_tracking\n     def track(self, layer):\n         \"\"\"Track the variables (and other resources) of a layer or model.\"\"\"\n         if not isinstance(layer, base_layer.Layer):\n@@ -93,17 +108,24 @@ class ExportArchive(tf.__internal__.tracking.AutoTrackable):\n                 f\"Received instead an object of type '{type(layer)}'. \"\n                 f\"Object received: {layer}\"\n             )\n-\n         if not layer.built:\n             raise ValueError(\n                 \"The layer provided has not yet been built. \"\n                 \"It must be built before export.\"\n             )\n \n-        self._trackables = list(layer._trackable_children().values())\n-        self.variables = list(layer.variables)\n-        self.trainable_variables = list(layer.trainable_variables)\n-        self.non_trainable_variables = list(layer.non_trainable_variables)\n+        # Layers in `_tracked` are not part of the trackables that get saved,\n+        # because we're creating the attribute in a\n+        # no_automatic_dependency_tracking scope.\n+        if not hasattr(self, \"_tracked\"):\n+            self._tracked = []\n+        self._tracked.append(layer)\n+\n+        # Variables in the lists below are actually part of the trackables\n+        # that get saved, because the lists are created in __init__.\n+        self.variables += layer.variables\n+        self.trainable_variables += layer.trainable_variables\n+        self.non_trainable_variables += layer.non_trainable_variables\n \n     def add_endpoint(self, name, fn, input_signature=None):\n         \"\"\"Register a new serving endpoint.\n@@ -313,10 +335,8 @@ class ExportArchive(tf.__internal__.tracking.AutoTrackable):\n             raise ValueError(\n                 \"No endpoints have been set yet. Call add_endpoint().\"\n             )\n-        if not self._trackables:\n-            tvs, ntvs = self._get_variables_used_by_endpoints()\n-            if tvs or ntvs:\n-                raise ValueError(\"No assets are being tracked. Call `track()`.\")\n+        self._filter_and_track_resources()\n+\n         signatures = {}\n         for name in self._endpoint_names:\n             signatures[name] = self._get_concrete_fn(name)\n@@ -328,7 +348,6 @@ class ExportArchive(tf.__internal__.tracking.AutoTrackable):\n         tf.saved_model.save(\n             self, filepath, options=options, signatures=signatures\n         )\n-\n         # Print out available endpoints\n         endpoints = \"\\n\\n\".join(\n             _print_signature(getattr(self, name), name)\n@@ -352,6 +371,25 @@ class ExportArchive(tf.__internal__.tracking.AutoTrackable):\n         fns = [self._get_concrete_fn(name) for name in self._endpoint_names]\n         return _list_variables_used_by_fns(fns)\n \n+    def _filter_and_track_resources(self):\n+        \"\"\"Track resources used by endpoints / referenced in `track()` calls.\"\"\"\n+        # Start by extracting variables from endpoints.\n+        fns = [self._get_concrete_fn(name) for name in self._endpoint_names]\n+        tvs, ntvs = _list_variables_used_by_fns(fns)\n+        self._all_variables = list(tvs + ntvs)\n+\n+        # Next, track lookup tables.\n+        # Hopefully, one day this will be automated at the tf.function level.\n+        self._misc_assets = []\n+        from keras.layers.preprocessing.index_lookup import IndexLookup\n+\n+        if hasattr(self, \"_tracked\"):\n+            for root in self._tracked:\n+                descendants = tf.train.TrackableView(root).descendants()\n+                for trackable in descendants:\n+                    if isinstance(trackable, IndexLookup):\n+                        self._misc_assets.append(trackable)\n+\n \n def export_model(model, filepath):\n     export_archive = ExportArchive()\n\n@@ -77,7 +77,9 @@ class ExportArchiveTest(tf.test.TestCase, parameterized.TestCase):\n             my_endpoint,\n         )\n         export_archive.write_out(temp_filepath)\n+\n         revived_model = tf.saved_model.load(temp_filepath)\n+        self.assertFalse(hasattr(revived_model, \"_tracked\"))\n         self.assertAllClose(\n             ref_output, revived_model.call(ref_input).numpy(), atol=1e-6\n         )\n@@ -211,6 +213,69 @@ class ExportArchiveTest(tf.test.TestCase, parameterized.TestCase):\n             atol=1e-6,\n         )\n \n+    def test_model_with_lookup_table(self):\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"exported_model\")\n+        text_vectorization = keras.layers.TextVectorization()\n+        text_vectorization.adapt([\"one two\", \"three four\", \"five six\"])\n+        model = keras.Sequential(\n+            [\n+                text_vectorization,\n+                keras.layers.Embedding(10, 32),\n+                keras.layers.Dense(1),\n+            ]\n+        )\n+        ref_input = tf.convert_to_tensor([\"one two three four\"])\n+        ref_output = model(ref_input).numpy()\n+\n+        export_lib.export_model(model, temp_filepath)\n+        revived_model = tf.saved_model.load(temp_filepath)\n+        self.assertAllClose(\n+            ref_output, revived_model.serve(ref_input).numpy(), atol=1e-6\n+        )\n+\n+    def test_track_multiple_layers(self):\n+        temp_filepath = os.path.join(self.get_temp_dir(), \"exported_model\")\n+        layer_1 = keras.layers.Dense(2)\n+        ref_input_1 = tf.random.normal((3, 4))\n+        ref_output_1 = layer_1(ref_input_1).numpy()\n+        layer_2 = keras.layers.Dense(3)\n+        ref_input_2 = tf.random.normal((3, 5))\n+        ref_output_2 = layer_2(ref_input_2).numpy()\n+\n+        export_archive = export_lib.ExportArchive()\n+        export_archive.add_endpoint(\n+            \"call_1\",\n+            layer_1.call,\n+            input_signature=[\n+                tf.TensorSpec(\n+                    shape=(None, 4),\n+                    dtype=tf.float32,\n+                ),\n+            ],\n+        )\n+        export_archive.add_endpoint(\n+            \"call_2\",\n+            layer_2.call,\n+            input_signature=[\n+                tf.TensorSpec(\n+                    shape=(None, 5),\n+                    dtype=tf.float32,\n+                ),\n+            ],\n+        )\n+        export_archive.write_out(temp_filepath)\n+        revived_layer = tf.saved_model.load(temp_filepath)\n+        self.assertAllClose(\n+            ref_output_1,\n+            revived_layer.call_1(ref_input_1).numpy(),\n+            atol=1e-6,\n+        )\n+        self.assertAllClose(\n+            ref_output_2,\n+            revived_layer.call_2(ref_input_2).numpy(),\n+            atol=1e-6,\n+        )\n+\n     def test_non_standard_layer_signature(self):\n         temp_filepath = os.path.join(self.get_temp_dir(), \"exported_layer\")\n \n@@ -373,23 +438,6 @@ class ExportArchiveTest(tf.test.TestCase, parameterized.TestCase):\n     def test_export_no_assets(self):\n         temp_filepath = os.path.join(self.get_temp_dir(), \"exported_model\")\n \n-        # Case where there are assets but they aren't tracked.\n-        model = keras.Sequential([keras.layers.Dense(2)])\n-        model(tf.random.normal((2, 3)))\n-        export_archive = export_lib.ExportArchive()\n-        export_archive.add_endpoint(\n-            \"call\",\n-            model.call,\n-            input_signature=[\n-                tf.TensorSpec(\n-                    shape=(None, 3),\n-                    dtype=tf.float32,\n-                )\n-            ],\n-        )\n-        with self.assertRaisesRegex(ValueError, \"No assets\"):\n-            export_archive.write_out(temp_filepath)\n-\n         # Case where there are legitimately no assets.\n         model = keras.Sequential([keras.layers.Flatten()])\n         model(tf.random.normal((2, 3)))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f973c7b695f1e8273dbb6dd0c7bf039d871ee932", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 6199 | Contributors (this commit): 12 | Commits (past 90d): 13 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -336,7 +336,7 @@ def Head(num_classes=1000, classifier_activation=None, name=None):\n       name: name prefix\n \n     Returns:\n-      Tensor of logits or softmax values as the output.\n+      Classification head function.\n     \"\"\"\n     if name is None:\n         name = str(backend.get_uid(\"head\"))\n\n@@ -841,7 +841,7 @@ def Head(num_classes=1000, name=None):\n       name: name prefix\n \n     Returns:\n-      Output logits tensor.\n+      Classification head function.\n     \"\"\"\n     if name is None:\n         name = str(backend.get_uid(\"head\"))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f25d744696a44e6fcdd48f68a2ba7736dbeedac4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 15 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 15 | Churn Cumulative: 4568 | Contributors (this commit): 13 | Commits (past 90d): 4 | Contributors (cumulative): 13 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2304,21 +2304,6 @@ class DTypeTest(test_combinations.TestCase):\n         self.assertEqual(network.dtype, \"float32\")\n         self.assertEqual(network(tf.constant(1, \"float64\")).dtype, \"float64\")\n \n-    @test_utils.enable_v2_dtype_behavior\n-    def test_compute_output_signature(self):\n-        # create a simple network\n-        x = input_layer_lib.Input(shape=(32,), dtype=\"float32\")\n-        dense_a = layers.Rescaling(scale=1.0 / 255)\n-        dense_b = layers.Activation(\"softmax\", dtype=\"float64\")\n-        y = dense_b(dense_a(x))\n-        network = functional.Functional(x, y)\n-\n-        output_signature = network.compute_output_signature(\n-            tf.TensorSpec(shape=[2, 32], dtype=\"float32\")\n-        )\n-        self.assertEqual(output_signature.shape, (2, 32))\n-        self.assertEqual(output_signature.dtype, \"float64\")\n-\n \n class AttrTrackingLayer(base_layer.Layer):\n     \"\"\"Count how many times `dynamic` and `stateful` are called.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a082df406499446bee56d7f8a59092b7fb8a47e0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1479 | Contributors (this commit): 35 | Commits (past 90d): 3 | Contributors (cumulative): 35 | DMM Complexity: None\n\nDIFF:\n@@ -282,8 +282,8 @@ def model_to_dot(\n                 return (\n                     str(shape)\n                     .replace(str(None), \"None\")\n-                    .replace(\"{\", \"\\{\")\n-                    .replace(\"}\", \"\\}\")\n+                    .replace(\"{\", r\"\\{\")\n+                    .replace(\"}\", r\"\\}\")\n                 )\n \n             try:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#17af3fcb1d21f950fff097e0534a6ae56bd25a46", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 94 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 4 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 94 | Churn Cumulative: 94 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,94 @@\n+\"\"\"Test Model inference and save/load with an ExtensionType.\"\"\"\n+\n+import typing\n+\n+import tensorflow.compat.v2 as tf\n+\n+import keras\n+from keras.engine.input_layer import Input\n+from keras.engine.training import Model\n+from keras.saving.saving_api import load_model\n+from keras.testing_infra import test_utils\n+\n+\n+class MaskedTensor(tf.experimental.BatchableExtensionType):\n+    \"\"\"Example subclass of ExtensionType, used for testing.\n+\n+    This version adds Keras required properties to MaskedTensor and its Spec\n+    class, to test Keras integration.\n+    \"\"\"\n+\n+    __name__ = \"tf.test.MaskedTensor.Spec\"\n+\n+    values: typing.Union[tf.Tensor, tf.RaggedTensor]\n+    mask: typing.Union[tf.Tensor, tf.RaggedTensor]\n+\n+    def __init__(self, values, mask):\n+        if isinstance(values, tf.RaggedTensor):\n+            assert isinstance(mask, tf.RaggedTensor)\n+            assert mask.dtype == tf.dtypes.bool\n+        else:\n+            values = tf.convert_to_tensor(values)\n+            mask = tf.convert_to_tensor(mask, tf.dtypes.bool)\n+        self.values = values\n+        self.mask = mask\n+\n+    # Required by assert_input_compatibility in keras/engine/input_spec.py\n+    @property\n+    def shape(self):\n+        return self.values.shape\n+\n+    @property\n+    def dtype(self):\n+        return self.values.dtype\n+\n+    class Spec:\n+\n+        # Required by KerasTensor.shape in keras/engine/keras_tensor.py\n+        @property\n+        def shape(self):\n+            return self.values._shape\n+\n+\n+class ExtensionTypeTest(tf.test.TestCase):\n+    @test_utils.run_v2_only\n+    def testKerasModel(self):\n+        mt_spec = MaskedTensor.Spec(\n+            tf.TensorSpec(shape=[None, 1], dtype=tf.dtypes.int32),\n+            tf.TensorSpec(shape=[None, 1], dtype=tf.dtypes.bool),\n+        )\n+        model_input = Input(type_spec=mt_spec)\n+        model_output = keras.layers.Lambda(\n+            lambda x: tf.identity(x, name=\"output\")\n+        )(model_input)\n+        model = Model(inputs=model_input, outputs=model_output)\n+        mt = MaskedTensor([[1], [2], [3]], [[True], [False], [True]])\n+        self.assertEqual(model(mt), mt)\n+        ds = tf.data.Dataset.from_tensors(mt)\n+        self.assertEqual(model.predict(ds), mt)\n+\n+        with self.subTest(\"keras save\"):\n+            path = self.create_tempdir().full_path\n+            model.save(path)\n+            loaded_model = load_model(path)\n+            self.assertEqual(loaded_model.input.type_spec, mt_spec)\n+            self.assertEqual(loaded_model(mt), mt)\n+\n+            loaded_fn = tf.saved_model.load(path)\n+            self.assertEqual(loaded_fn(mt), mt)\n+            with self.assertRaisesRegex(\n+                ValueError,\n+                \"Could not find matching concrete function to call \"\n+                \"loaded from the SavedModel\",\n+            ):\n+                loaded_fn(MaskedTensor([1, 2, 3], [True, False, True]))\n+\n+            # The serving_fn use flatten signature\n+            serving_fn = loaded_fn.signatures[\"serving_default\"]\n+            self.assertEqual(\n+                serving_fn(args_0=mt.values, args_0_1=mt.mask)[\"lambda\"], mt\n+            )\n+\n+\n+if __name__ == \"__main__\":\n+    tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e573e6dd11802f823eab707596e1686bf0c94b48", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 61 | Lines Deleted: 19 | Files Changed: 3 | Hunks: 18 | Methods Changed: 9 | Complexity Δ (Sum/Max): 43/37 | Churn Δ: 80 | Churn Cumulative: 24722 | Contributors (this commit): 152 | Commits (past 90d): 17 | Contributors (cumulative): 165 | DMM Complexity: 0.5945945945945946\n\nDIFF:\n@@ -13,6 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Tests for evaluation using Keras model and ParameterServerStrategy.\"\"\"\n+import threading\n import time\n \n import numpy as np\n@@ -23,6 +24,7 @@ from tensorflow.python.platform import tf_logging as logging\n import keras\n from keras.metrics import base_metric\n from keras.testing_infra import test_utils\n+from keras.utils import dataset_creator\n from keras.utils import tf_utils\n \n # isort: off\n@@ -212,13 +214,14 @@ class ExactEvaluationTest(tf.test.TestCase, parameterized.TestCase):\n \n     @tf.__internal__.distribute.combinations.generate(\n         tf.__internal__.test.combinations.combine(\n+            input_type=[\"dataset\", \"dataset_creator\", \"distributed_dataset\"],\n             eval_in_model_fit=[True, False],\n             use_auto=[True, False],\n             custom_metric=[True, False],\n         )\n     )\n     def testDistributedModelEvaluation(\n-        self, eval_in_model_fit, use_auto, custom_metric\n+        self, input_type, eval_in_model_fit, use_auto, custom_metric\n     ):\n \n         # Define dataset by batch size, number of shards, and batches per shard\n@@ -238,7 +241,8 @@ class ExactEvaluationTest(tf.test.TestCase, parameterized.TestCase):\n             def __call__(self, x, training=False):\n                 return tf.cast(x >= 0, tf.float32)\n \n-        def dataset_fn():\n+        def dataset_fn(input_context=None):\n+            del input_context\n             x = np.arange(num_examples)\n \n             def make_batch_with_n_true(n):\n@@ -318,16 +322,44 @@ class ExactEvaluationTest(tf.test.TestCase, parameterized.TestCase):\n                 pss_evaluation_shards=num_shards,\n             )\n \n-        dataset = dataset_fn()\n+        if input_type == \"dataset\":\n+            train_dataset = dataset_fn()\n+            val_dataset = dataset_fn()\n+        elif input_type == \"dataset_creator\":\n+            train_dataset = dataset_creator.DatasetCreator(dataset_fn)\n+            val_dataset = dataset_creator.DatasetCreator(dataset_fn)\n+        elif input_type == \"distributed_dataset\":\n+            train_dataset = self.strategy.experimental_distribute_dataset(\n+                dataset_fn()\n+            )\n+            val_dataset = self.strategy.experimental_distribute_dataset(\n+                dataset_fn()\n+            )\n+\n         metric_name = \"custom_acc\" if custom_metric else \"accuracy\"\n         expected_results = {metric_name: expected_acc}\n \n+        def kill_and_revive_in_thread(wait_secs=2):\n+            def _kill_and_revive_fn():\n+                time.sleep(wait_secs)\n+                logging.info(\"Killing 2 workers\")\n+                self._cluster.kill_task(\"worker\", 0)\n+                self._cluster.kill_task(\"worker\", 1)\n+                time.sleep(1)\n+                self._cluster.start_task(\"worker\", 0)\n+                self._cluster.start_task(\"worker\", 1)\n+\n+            restart_thread = threading.Thread(target=_kill_and_revive_fn)\n+            restart_thread.start()\n+            return restart_thread\n+\n         eval_results = {}\n         if eval_in_model_fit:\n+            kill_and_revive_in_thread()\n             history = model.fit(\n-                dataset,\n+                train_dataset,\n                 steps_per_epoch=1,\n-                validation_data=dataset,\n+                validation_data=val_dataset,\n             )\n             logging.info(\n                 \"History: params (%r), history (%r)\",\n@@ -341,8 +373,9 @@ class ExactEvaluationTest(tf.test.TestCase, parameterized.TestCase):\n             }\n         else:\n             # run a single train step to compile metrics\n-            model.fit(dataset, steps_per_epoch=1)\n-            eval_results = model.evaluate(dataset, return_dict=True)\n+            model.fit(train_dataset, steps_per_epoch=1)\n+            kill_and_revive_in_thread()\n+            eval_results = model.evaluate(val_dataset, return_dict=True)\n             eval_results = {\n                 metric: val.numpy() for metric, val in eval_results.items()\n             }\n\n@@ -1592,20 +1592,24 @@ class _ClusterCoordinatorExactEvalDataHandler(_ClusterCoordinatorDataHandler):\n         self, strategy, x, steps_per_epoch, class_weight, distribute\n     ):\n         if isinstance(x, dataset_creator.DatasetCreator):\n-            raise NotImplementedError(\n-                \"Using DatasetCreator with exact evaluation is not yet \"\n-                \"supported. Please use a tf.data.Dataset type.\"\n+\n+            def per_worker_dataset_fn():\n+                ddf = strategy.distribute_datasets_from_function(\n+                    x, options=x.input_options\n                 )\n+                return ddf\n+\n+            coordinator = self._model._cluster_coordinator\n+            self._dataset = coordinator.create_per_worker_dataset(\n+                per_worker_dataset_fn\n+            )\n+            logging.info(\"dataset element spec: %r\", self._dataset.element_spec)\n+            self._dataset = self._dataset.build()\n         else:\n             # TODO(b/268226218): Support DistributedDataset input\n-            if _is_distributed_dataset(x):\n-                assert strategy.extended._num_replicas_in_sync == 1, (\n-                    \"Multi-device workers not yet supported for exact \"\n-                    \"evaluation.\",\n-                )\n-                x = x._original_dataset\n-\n+            if not _is_distributed_dataset(x):\n                 self._warn_if_not_file_shardable(x)\n+                x = strategy.experimental_distribute_dataset(x)\n \n             coordinator = self._model._cluster_coordinator\n             self._dataset = coordinator.create_per_worker_dataset(x)\n\n@@ -1842,6 +1842,9 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         return self.compute_metrics(x, y, y_pred, sample_weight)\n \n     def _make_test_function_exact(self):\n+        if getattr(self, \"_shard_test_function\", None):\n+            return self._shard_test_function\n+\n         def step_function(batch):\n             def run_step(data):\n                 # TODO(b/272050910): Use sample_weight for weighted metrics.\n@@ -1886,11 +1889,13 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                 shard_test_function, reduce_retracing=True\n             )\n \n-        self.test_function = lambda *args: self._cluster_coordinator.schedule(\n+        self._shard_test_function = (\n+            lambda *args: self._cluster_coordinator.schedule(\n                 shard_test_function,\n                 args=args,\n             )\n-        return self.test_function\n+        )\n+        return self._shard_test_function\n \n     def make_test_function(self, force=False):\n         \"\"\"Creates a function that executes one step of evaluation.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cdb89b47d13fc4b882911eae3a366a395d823275", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 66 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 6 | Methods Changed: 7 | Complexity Δ (Sum/Max): 5/3 | Churn Δ: 73 | Churn Cumulative: 5086 | Contributors (this commit): 43 | Commits (past 90d): 6 | Contributors (cumulative): 53 | DMM Complexity: 0.9259259259259259\n\nDIFF:\n@@ -425,6 +425,11 @@ def print_summary(\n                 # we don't need any if we are printing the last column\n                 space = 2 if col != len(positions) - 1 else 0\n                 cutoff = end_pos - start_pos - space\n+                # Except for last col, offset by one to align the start of col\n+                if col != len(positions) - 1:\n+                    cutoff -= 1\n+                if col == 0:\n+                    cutoff -= nested_level\n                 fit_into_line = left_to_print[col][:cutoff]\n                 # For nicer formatting we line-break on seeing end of\n                 # tuple/dict etc.\n@@ -445,7 +450,8 @@ def print_summary(\n                 left_to_print[col] = left_to_print[col][cutoff:]\n \n                 # Pad out to the next position\n-                if nested_level:\n+                # Make space for nested_level for last column\n+                if nested_level and col == len(positions) - 1:\n                     line += \" \" * (positions[col] - len(line) - nested_level)\n                 else:\n                     line += \" \" * (positions[col] - len(line))\n\n@@ -106,6 +106,59 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n             layer_utils.print_summary(model)\n         self.assertIn(\"dense (Dense)\", printed.contents())\n \n+    def test_print_summary_format_long_names(self):\n+        shape = (8, 8, 3)\n+\n+        model = keras.Sequential(\n+            [\n+                keras.Input(shape),\n+                keras.layers.Conv2D(4, 3, name=\"Really-Long-name-test\"),\n+                keras.layers.Conv2D(4, 3, name=\"Another-long-name-test\"),\n+                keras.layers.Flatten(),\n+                keras.layers.Dense(2, name=\"long-name-test-output\"),\n+            ]\n+        )\n+        file_name = \"sequential.txt\"\n+        temp_dir = self.get_temp_dir()\n+        self.addCleanup(shutil.rmtree, temp_dir, ignore_errors=True)\n+        fpath = os.path.join(temp_dir, file_name)\n+        writer = open(fpath, \"w\")\n+\n+        def print_to_file(text):\n+            print(text, file=writer)\n+\n+        layer_utils.print_summary(model, print_fn=print_to_file)\n+        self.assertTrue(tf.io.gfile.exists(fpath))\n+        writer.close()\n+        reader = open(fpath, \"r\")\n+        lines = reader.readlines()\n+        reader.close()\n+        check_str = (\n+            'Model: \"sequential\"\\n'\n+            \"_________________________________________________________________\\n\"  # noqa: E501\n+            \" Layer (type)                Output Shape              Param #   \\n\"  # noqa: E501\n+            \"=================================================================\\n\"  # noqa: E501\n+            \" Really-Long-name-test (Con  (None, 6, 6, 4)           112       \\n\"  # noqa: E501\n+            \" v2D)                                                            \\n\"  # noqa: E501\n+            \"                                                                 \\n\"  # noqa: E501\n+            \" Another-long-name-test (Co  (None, 4, 4, 4)           148       \\n\"  # noqa: E501\n+            \" nv2D)                                                           \\n\"  # noqa: E501\n+            \"                                                                 \\n\"  # noqa: E501\n+            \" flatten (Flatten)           (None, 64)                0         \\n\"  # noqa: E501\n+            \"                                                                 \\n\"  # noqa: E501\n+            \" long-name-test-output (Den  (None, 2)                 130       \\n\"  # noqa: E501\n+            \" se)                                                             \\n\"  # noqa: E501\n+            \"                                                                 \\n\"  # noqa: E501\n+            \"=================================================================\\n\"  # noqa: E501\n+            \"Total params: 390 (1.52 KB)\\n\"\n+            \"Trainable params: 390 (1.52 KB)\\n\"\n+            \"Non-trainable params: 0 (0.00 Byte)\\n\"\n+            \"_________________________________________________________________\\n\"  # noqa: E501\n+        )\n+        fin_str = \"\".join(lines)\n+        self.assertIn(fin_str, check_str)\n+        self.assertEqual(len(lines), 20)\n+\n     def test_print_summary_expand_nested(self):\n         shape = (None, None, 3)\n \n@@ -157,8 +210,8 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n                 \"||                                                             ||\\n\"  # noqa: E501\n                 \"|| conv2d (Conv2D)           (None, None, None, 3)     12      ||\\n\"  # noqa: E501\n                 \"||                                                             ||\\n\"  # noqa: E501\n-                \"|| batch_normalization (BatchN  (None, None, None, 3)  12      ||\\n\"  # noqa: E501\n-                \"|| ormalization)                                               ||\\n\"  # noqa: E501\n+                \"|| batch_normalization (Bat  (None, None, None, 3)     12      ||\\n\"  # noqa: E501\n+                \"|| chNormalization)                                            ||\\n\"  # noqa: E501\n                 \"|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n\"  # noqa: E501\n                 \"¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\\n\"  # noqa: E501\n                 \"=================================================================\\n\"  # noqa: E501\n@@ -359,8 +412,8 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n                 \"||                                                                        ||\\n\"  # noqa: E501\n                 \"|| conv2d (Conv2D)           (None, None, None, 3)     12        N        ||\\n\"  # noqa: E501\n                 \"||                                                                        ||\\n\"  # noqa: E501\n-                \"|| batch_normalization (BatchN  (None, None, None, 3)  12      Y          ||\\n\"  # noqa: E501\n-                \"|| ormalization)                                                          ||\\n\"  # noqa: E501\n+                \"|| batch_normalization (Bat  (None, None, None, 3)     12        Y        ||\\n\"  # noqa: E501\n+                \"|| chNormalization)                                                       ||\\n\"  # noqa: E501\n                 \"|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n\"  # noqa: E501\n                 \"¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\\n\"  # noqa: E501\n                 \"============================================================================\\n\"  # noqa: E501\n@@ -469,8 +522,8 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n                 \"||                                                             ||\\n\"  # noqa: E501\n                 \"|| conv2d (Conv2D)           (None, None, None, 3)     12      ||\\n\"  # noqa: E501\n                 \"||                                                             ||\\n\"  # noqa: E501\n-                \"|| batch_normalization (BatchN  (None, None, None, 3)  12      ||\\n\"  # noqa: E501\n-                \"|| ormalization)                                               ||\\n\"  # noqa: E501\n+                \"|| batch_normalization (Bat  (None, None, None, 3)     12      ||\\n\"  # noqa: E501\n+                \"|| chNormalization)                                            ||\\n\"  # noqa: E501\n                 \"|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n\"  # noqa: E501\n                 \"¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\\n\"  # noqa: E501\n                 \"=================================================================\\n\"  # noqa: E501\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
