{"custom_id": "keras#f4f3567e156c6b964d17e24fa4a4073f00851463", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 611 | Contributors (this commit): 15 | Commits (past 90d): 15 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -154,7 +154,7 @@ def deserialize_keras_object(identifier, module_objects=None,\n             fn = module_objects.get(function_name)\n             if fn is None:\n                 raise ValueError('Unknown ' + printable_module_name,\n-                                 ':' + class_name)\n+                                 ':' + function_name)\n         return fn\n     else:\n         raise ValueError('Could not interpret serialized ' +\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8566ef777927d05dd41d4a0c80755ac2c17a2aef", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 10 | Files Changed: 3 | Hunks: 11 | Methods Changed: 11 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 24 | Churn Cumulative: 13097 | Contributors (this commit): 65 | Commits (past 90d): 124 | Contributors (cumulative): 74 | DMM Complexity: 1.0\n\nDIFF:\n@@ -656,6 +656,10 @@ class Layer(object):\n         # Returns\n             An input shape tuple.\n         \"\"\"\n+        if hasattr(self, 'get_output_shape_for'):\n+            msg = \"Class `{}.{}` defines `get_output_shape_for` but does not override `compute_output_shape`. \" + \\\n+                  \"If this is a Keras 1 layer, please implement `compute_output_shape` to support Keras 2.\"\n+            warnings.warn(msg.format(type(self).__module__, type(self).__name__), stacklevel=2)\n         return input_shape\n \n     def compute_mask(self, inputs, mask=None):\n\n@@ -726,7 +726,7 @@ class Model(Container):\n                                   'We assume this was done on purpose, '\n                                   'and we will not be expecting '\n                                   'any data to be passed to \"' + name +\n-                                  '\" during training.')\n+                                  '\" during training.', stacklevel=2)\n                 loss_functions.append(losses.get(loss.get(name)))\n         elif isinstance(loss, list):\n             if len(loss) != len(self.outputs):\n@@ -1391,7 +1391,7 @@ class Model(Container):\n         # Legacy support\n         if 'nb_epoch' in kwargs:\n             warnings.warn('The `nb_epoch` argument in `fit` '\n-                          'has been renamed `epochs`.')\n+                          'has been renamed `epochs`.', stacklevel=2)\n             epochs = kwargs.pop('nb_epoch')\n         if kwargs:\n             raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n\n@@ -83,7 +83,7 @@ def generate_legacy_interface(allowed_positional_args=None,\n                         signature += ', '\n                 signature += ')`'\n                 warnings.warn('Update your `' + object_name +\n-                              '` call to the Keras 2 API: ' + signature)\n+                              '` call to the Keras 2 API: ' + signature, stacklevel=2)\n             return func(*args, **kwargs)\n         return wrapper\n     return legacy_support\n@@ -122,7 +122,7 @@ def embedding_kwargs_preprocessor(args, kwargs):\n         kwargs.pop('dropout')\n         warnings.warn('The `dropout` argument is no longer support in `Embedding`. '\n                       'You can apply a `keras.layers.SpatialDropout1D` layer '\n-                      'right after the `Embedding` layer to get the same behavior.')\n+                      'right after the `Embedding` layer to get the same behavior.', stacklevel=3)\n     return args, kwargs, converted\n \n legacy_embedding_support = generate_legacy_interface(\n@@ -159,7 +159,7 @@ def recurrent_args_preprocessor(args, kwargs):\n             kwargs.pop('forget_bias_init')\n             warnings.warn('The `forget_bias_init` argument '\n                           'has been ignored. Use `unit_forget_bias=True` '\n-                          'instead to intialize with ones.')\n+                          'instead to intialize with ones.', stacklevel=3)\n     if 'input_dim' in kwargs:\n         input_length = kwargs.pop('input_length', None)\n         input_dim = kwargs.pop('input_dim')\n@@ -168,7 +168,7 @@ def recurrent_args_preprocessor(args, kwargs):\n         converted.append(('input_dim', 'input_shape'))\n         warnings.warn('The `input_dim` and `input_length` arguments '\n                       'in recurrent layers are deprecated. '\n-                      'Use `input_shape` instead.')\n+                      'Use `input_shape` instead.', stacklevel=3)\n     return args, kwargs, converted\n \n legacy_recurrent_support = generate_legacy_interface(\n@@ -459,7 +459,7 @@ def convlstm2d_args_preprocessor(args, kwargs):\n         else:\n             warnings.warn('The `forget_bias_init` argument '\n                           'has been ignored. Use `unit_forget_bias=True` '\n-                          'instead to intialize with ones.')\n+                          'instead to intialize with ones.', stacklevel=3)\n     args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n     return args, kwargs, converted + _converted\n \n@@ -502,7 +502,7 @@ def zeropadding2d_args_preprocessor(args, kwargs):\n             kwargs['padding'] = ((top_pad, bottom_pad), (left_pad, right_pad))\n             warnings.warn('The `padding` argument in the Keras 2 API no longer'\n                           'accepts dict types. You can now input argument as: '\n-                          '`padding=(top_pad, bottom_pad, left_pad, right_pad)`.')\n+                          '`padding=(top_pad, bottom_pad, left_pad, right_pad)`.', stacklevel=3)\n     elif len(args) == 2 and isinstance(args[1], dict):\n         if set(args[1].keys()) <= {'top_pad', 'bottom_pad',\n                                    'left_pad', 'right_pad'}:\n@@ -513,7 +513,7 @@ def zeropadding2d_args_preprocessor(args, kwargs):\n             args = (args[0], ((top_pad, bottom_pad), (left_pad, right_pad)))\n             warnings.warn('The `padding` argument in the Keras 2 API no longer'\n                           'accepts dict types. You can now input argument as: '\n-                          '`padding=((top_pad, bottom_pad), (left_pad, right_pad))`')\n+                          '`padding=((top_pad, bottom_pad), (left_pad, right_pad))`', stacklevel=3)\n     return args, kwargs, converted\n \n legacy_zeropadding2d_support = generate_legacy_interface(\n@@ -580,7 +580,7 @@ def generator_methods_args_preprocessor(args, kwargs):\n                               'Keras 1 argument `samples_per_epoch`. '\n                               '`steps_per_epoch` is the number of batches '\n                               'to draw from the generator at each epoch. '\n-                              'Update your method calls accordingly.')\n+                              'Update your method calls accordingly.', stacklevel=3)\n                 kwargs['steps_per_epoch'] = samples_per_epoch\n             converted.append(('samples_per_epoch', 'steps_per_epoch'))\n     return args, kwargs, converted\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5d512f82b58e95464dbcb074aa07e26e7775d3ca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 3 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 8654 | Contributors (this commit): 32 | Commits (past 90d): 66 | Contributors (cumulative): 38 | DMM Complexity: None\n\nDIFF:\n@@ -2,7 +2,7 @@\n \n We build a custom activation layer called 'Antirectifier',\n which modifies the shape of the tensor that passes through it.\n-We need to specify two methods: `get_output_shape_for` and `call`.\n+We need to specify two methods: `compute_output_shape` and `call`.\n \n Note that the same result can also be achieved via a Lambda layer.\n \n\n@@ -486,7 +486,7 @@ class Layer(object):\n             - If necessary, we `build` the layer to match\n                 the _keras_shape of the input(s).\n             - We update the _keras_shape of every input tensor with\n-                its new shape (obtained via self.get_output_shape_for).\n+                its new shape (obtained via self.compute_output_shape).\n                 This is done as part of _add_inbound_node().\n             - We update the _keras_history of the output tensor(s)\n                 with the current layer.\n@@ -1426,7 +1426,7 @@ class Container(Layer):\n         get_weights\n         set_weights\n         get_config\n-        get_output_shape_for\n+        compute_output_shape\n \n     # Class Methods\n         from_config\n@@ -2023,7 +2023,7 @@ class Container(Layer):\n             for i in range(len(input_shapes)):\n                 layer = self.input_layers[i]\n                 input_shape = input_shapes[i]\n-                # It's an input layer: get_output_shape_for is identity,\n+                # It's an input layer: compute_output_shape is identity,\n                 # and there is only one node and one tensor output.\n                 shape_key = layer.name + '_0_0'\n                 layers_to_output_shapes[shape_key] = input_shape\n\n@@ -46,7 +46,7 @@ class Merge(Layer):\n             (1:1 mapping to input tensors)\n             and return a single shape tuple, including the\n             batch size (same convention as the\n-            `get_output_shape_for` method of layers).\n+            `compute_output_shape` method of layers).\n         node_indices: Optional list of integers containing\n             the output node index for each input layer\n             (in case some input layers have multiple output nodes).\n@@ -418,7 +418,7 @@ def merge(inputs, mode='sum', concat_axis=-1,\n             If the latter case, it should take as input a list of shape tuples\n             (1:1 mapping to input tensors) and return a single shape tuple,\n             including the batch size\n-            (same convention as the `get_output_shape_for` method of layers).\n+            (same convention as the `compute_output_shape` method of layers).\n         node_indices: Optional list of integers containing\n             the output node index for each input layer\n             (in case some input layers have multiple output nodes).\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6dca6c2531c3194a7cb2d0aa9a8d2f4d060a6651", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 500 | Contributors (this commit): 4 | Commits (past 90d): 11 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -140,8 +140,8 @@ def ResNet50(include_top=True, weights='imagenet',\n     specified in your Keras config file.\n \n     # Arguments\n-        include_top: whether to include the 3 fully-connected\n-            layers at the top of the network.\n+        include_top: whether to include the fully-connected\n+            layer at the top of the network.\n         weights: one of `None` (random initialization)\n             or \"imagenet\" (pre-training on ImageNet).\n         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2b1c4779ff4005f91898eb0b320b97cb1efd1a1b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 21 | Files Changed: 2 | Hunks: 12 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 45 | Churn Cumulative: 1538 | Contributors (this commit): 8 | Commits (past 90d): 14 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -41,9 +41,10 @@ import numpy as np\n from scipy import ndimage\n import pylab\n from keras import backend as K\n-from keras.layers.convolutional import Convolution2D, MaxPooling2D\n+from keras.layers.convolutional import Conv2D, MaxPooling2D\n from keras.layers import Input, Dense, Activation\n-from keras.layers import Reshape, Lambda, merge\n+from keras.layers import Reshape, Lambda\n+from keras.layers.merge import add, concatenate\n from keras.models import Model\n from keras.layers.recurrent import GRU\n from keras.optimizers import SGD\n@@ -403,8 +404,8 @@ def train(run_name, start_epoch, stop_epoch, img_w):\n     val_words = int(words_per_epoch * (val_split))\n \n     # Network parameters\n-    conv_filterss = 16\n-    filter_size = 3\n+    conv_filters = 16\n+    kernel_size = (3, 3)\n     pool_size = 2\n     time_dense_size = 32\n     rnn_size = 512\n@@ -427,14 +428,16 @@ def train(run_name, start_epoch, stop_epoch, img_w):\n                                  )\n     act = 'relu'\n     input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n-    inner = Convolution2D(conv_filterss, filter_size, filter_size, border_mode='same',\n-                          activation=act, init='he_normal', name='conv1')(input_data)\n+    inner = Conv2D(conv_filters, kernel_size, padding='same',\n+                   activation=act, kernel_initializer='he_normal',\n+                   name='conv1')(input_data)\n     inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n-    inner = Convolution2D(conv_filterss, filter_size, filter_size, border_mode='same',\n-                          activation=act, init='he_normal', name='conv2')(inner)\n+    inner = Conv2D(conv_filters, kernel_size, padding='same',\n+                   activation=act, kernel_initializer='he_normal',\n+                   name='conv2')(inner)\n     inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n \n-    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filterss)\n+    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n     inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n \n     # cuts down input size going into RNN:\n@@ -442,17 +445,17 @@ def train(run_name, start_epoch, stop_epoch, img_w):\n \n     # Two layers of bidirecitonal GRUs\n     # GRU seems to work as well, if not better than LSTM:\n-    gru_1 = GRU(rnn_size, return_sequences=True, init='he_normal', name='gru1')(inner)\n-    gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, init='he_normal', name='gru1_b')(inner)\n-    gru1_merged = merge([gru_1, gru_1b], mode='sum')\n-    gru_2 = GRU(rnn_size, return_sequences=True, init='he_normal', name='gru2')(gru1_merged)\n-    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, init='he_normal', name='gru2_b')(gru1_merged)\n+    gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n+    gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n+    gru1_merged = add([gru_1, gru_1b])\n+    gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n+    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n \n     # transforms RNN output to character activations:\n-    inner = Dense(img_gen.get_output_size(), init='he_normal',\n-                  name='dense2')(merge([gru_2, gru_2b], mode='concat'))\n+    inner = Dense(img_gen.get_output_size(), kernel_initializer='he_normal',\n+                  name='dense2')(concatenate([gru_2, gru_2b]))\n     y_pred = Activation('softmax', name='softmax')(inner)\n-    Model(input=[input_data], output=y_pred).summary()\n+    Model(inputs=input_data, outputs=y_pred).summary()\n \n     labels = Input(name='the_labels', shape=[img_gen.absolute_max_string_len], dtype='float32')\n     input_length = Input(name='input_length', shape=[1], dtype='int64')\n@@ -464,7 +467,7 @@ def train(run_name, start_epoch, stop_epoch, img_w):\n     # clipnorm seems to speeds up convergence\n     sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n \n-    model = Model(input=[input_data, labels, input_length, label_length], output=[loss_out])\n+    model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n \n     # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n     model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n@@ -476,8 +479,8 @@ def train(run_name, start_epoch, stop_epoch, img_w):\n \n     viz_cb = VizCallback(run_name, test_func, img_gen.next_val())\n \n-    model.fit_generator(generator=img_gen.next_train(), samples_per_epoch=(words_per_epoch - val_words),\n-                        epochs=stop_epoch, validation_data=img_gen.next_val(), num_val_samples=val_words,\n+    model.fit_generator(generator=img_gen.next_train(), steps_per_epoch=(words_per_epoch - val_words),\n+                        epochs=stop_epoch, validation_data=img_gen.next_val(), validation_steps=val_words,\n                         callbacks=[viz_cb, img_gen], initial_epoch=start_epoch)\n \n \n\n@@ -430,7 +430,7 @@ def merge(inputs, mode='sum', concat_axis=-1,\n     warnings.warn('The `merge` function is deprecated '\n                   'and will be removed after 08/2017. '\n                   'Use instead layers from `keras.layers.merge`, '\n-                  'e.g. `sum`, `concatenate`, etc.', stacklevel=2)\n+                  'e.g. `add`, `concatenate`, etc.', stacklevel=2)\n     all_keras_tensors = True\n     for x in inputs:\n         if not hasattr(x, '_keras_history'):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2b3579ecfce5706e356673b573ccbee9496803d7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 4 | Files Changed: 3 | Hunks: 8 | Methods Changed: 5 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 18 | Churn Cumulative: 14777 | Contributors (this commit): 86 | Commits (past 90d): 74 | Contributors (cumulative): 102 | DMM Complexity: 0.2857142857142857\n\nDIFF:\n@@ -2021,7 +2021,8 @@ class Model(Container):\n \n     @interfaces.legacy_generator_methods_support\n     def predict_generator(self, generator, steps,\n-                          max_q_size=10, workers=1, pickle_safe=False):\n+                          max_q_size=10, workers=1,\n+                          pickle_safe=False, verbose=0):\n         \"\"\"Generates predictions for the input samples from a data generator.\n \n         The generator should return the same kind of data as accepted by\n@@ -2041,6 +2042,7 @@ class Model(Container):\n                 non picklable arguments to the generator\n                 as they can't be passed\n                 easily to children processes.\n+            verbose: verbosity mode, 0 or 1.\n \n         # Returns\n             Numpy array(s) of predictions.\n@@ -2060,6 +2062,9 @@ class Model(Container):\n             enqueuer = GeneratorEnqueuer(generator, pickle_safe=pickle_safe)\n             enqueuer.start(workers=workers, max_q_size=max_q_size)\n \n+            if verbose == 1:\n+                progbar = Progbar(target=steps)\n+\n             while steps_done < steps:\n                 generator_output = None\n                 while enqueuer.is_running():\n@@ -2097,6 +2102,8 @@ class Model(Container):\n                 for i, out in enumerate(outs):\n                     all_outs[i].append(out)\n                 steps_done += 1\n+                if verbose == 1:\n+                    progbar.update(steps_done)\n \n         finally:\n             if enqueuer is not None:\n\n@@ -1138,7 +1138,8 @@ class Sequential(Model):\n \n     @interfaces.legacy_generator_methods_support\n     def predict_generator(self, generator, steps,\n-                          max_q_size=10, workers=1, pickle_safe=False):\n+                          max_q_size=10, workers=1,\n+                          pickle_safe=False, verbose=0):\n         \"\"\"Generates predictions for the input samples from a data generator.\n \n         The generator should return the same kind of data as accepted by\n@@ -1155,6 +1156,7 @@ class Sequential(Model):\n                 relies on multiprocessing, you should not pass\n                 non picklable arguments to the generator\n                 as they can't be passed easily to children processes.\n+            verbose: verbosity mode, 0 or 1.\n \n         # Returns\n             A Numpy array of predictions.\n@@ -1164,7 +1166,8 @@ class Sequential(Model):\n         return self.model.predict_generator(generator, steps,\n                                             max_q_size=max_q_size,\n                                             workers=workers,\n-                                            pickle_safe=pickle_safe)\n+                                            pickle_safe=pickle_safe,\n+                                            verbose=verbose)\n \n     def get_config(self):\n         if isinstance(self.layers[0], legacy_layers.Merge):\n\n@@ -122,7 +122,7 @@ def test_sequential():\n \n     loss = model.evaluate(x_test, y_test)\n \n-    prediction = model.predict_generator(data_generator(x_test, y_test), 1, max_q_size=2)\n+    prediction = model.predict_generator(data_generator(x_test, y_test), 1, max_q_size=2, verbose=1)\n     gen_loss = model.evaluate_generator(data_generator(x_test, y_test, 50), 1, max_q_size=2)\n     pred_loss = K.eval(K.mean(losses.get(model.loss)(K.variable(y_test), K.variable(prediction))))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9c86aa21db0082a7296fb35e31ce2363d7a7f9f2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 702 | Contributors (this commit): 8 | Commits (past 90d): 17 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -46,9 +46,9 @@ class Wrapper(Layer):\n         return dict(list(base_config.items()) + list(config.items()))\n \n     @classmethod\n-    def from_config(cls, config):\n+    def from_config(cls, config, custom_objects=None):\n         from . import deserialize as deserialize_layer\n-        layer = deserialize_layer(config.pop('layer'))\n+        layer = deserialize_layer(config.pop('layer'), custom_objects=custom_objects)\n         return cls(layer, **config)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ae8bcdc291e3be3243839d4e890cc42a47c7b301", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 50 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 7 | Methods Changed: 7 | Complexity Δ (Sum/Max): 23/21 | Churn Δ: 51 | Churn Cumulative: 1234 | Contributors (this commit): 12 | Commits (past 90d): 13 | Contributors (cumulative): 14 | DMM Complexity: 0.9629629629629629\n\nDIFF:\n@@ -175,6 +175,31 @@ class KerasClassifier(BaseWrapper):\n     \"\"\"Implementation of the scikit-learn classifier API for Keras.\n     \"\"\"\n \n+    def fit(self, x, y, **kwargs):\n+        \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n+\n+        # Arguments\n+            x : array-like, shape `(n_samples, n_features)`\n+                Training samples where n_samples in the number of samples\n+                and n_features is the number of features.\n+            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n+                True labels for X.\n+            **kwargs: dictionary arguments\n+                Legal arguments are the arguments of `Sequential.fit`\n+\n+        # Returns\n+            history : object\n+                details about the training history at each epoch.\n+        \"\"\"\n+        y = np.array(y)\n+        if len(y.shape) != 1:\n+            self.classes_ = np.arange(y.shape[1])\n+        else:\n+            self.classes_ = np.unique(y)\n+            y = np.searchsorted(self.classes_, y)\n+        self.n_classes_ = len(self.classes_)\n+        return super(KerasClassifier, self).fit(x, y, **kwargs)\n+\n     def predict(self, x, **kwargs):\n         \"\"\"Returns the class predictions for the given test data.\n \n@@ -191,7 +216,8 @@ class KerasClassifier(BaseWrapper):\n                 Class predictions.\n         \"\"\"\n         kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n-        return self.model.predict_classes(x, **kwargs)\n+        classes = self.model.predict_classes(x, **kwargs)\n+        return self.classes_[classes]\n \n     def predict_proba(self, x, **kwargs):\n         \"\"\"Returns class probability estimates for the given test data.\n@@ -242,6 +268,7 @@ class KerasClassifier(BaseWrapper):\n                 compute accuracy. You should pass `metrics=[\"accuracy\"]` to\n                 the `.compile()` method of the model.\n         \"\"\"\n+        y = np.searchsorted(self.classes_, y)\n         kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n \n         loss_name = self.model.loss\n\n@@ -45,6 +45,7 @@ def test_clasify_build_fn():\n         batch_size=batch_size, epochs=epochs)\n \n     assert_classification_works(clf)\n+    assert_string_classification_works(clf)\n \n \n def test_clasify_class_build_fn():\n@@ -58,6 +59,7 @@ def test_clasify_class_build_fn():\n         batch_size=batch_size, epochs=epochs)\n \n     assert_classification_works(clf)\n+    assert_string_classification_works(clf)\n \n \n def test_clasify_inherit_class_build_fn():\n@@ -71,6 +73,7 @@ def test_clasify_inherit_class_build_fn():\n         batch_size=batch_size, epochs=epochs)\n \n     assert_classification_works(clf)\n+    assert_string_classification_works(clf)\n \n \n def assert_classification_works(clf):\n@@ -89,6 +92,25 @@ def assert_classification_works(clf):\n     assert np.allclose(np.sum(proba, axis=1), np.ones(num_test))\n \n \n+def assert_string_classification_works(clf):\n+    string_classes = ['cls{}'.format(x) for x in range(num_class)]\n+    str_y_train = np.array(string_classes)[y_train]\n+\n+    clf.fit(X_train, str_y_train, batch_size=batch_size, nb_epoch=epochs)\n+\n+    score = clf.score(X_train, str_y_train, batch_size=batch_size)\n+    assert np.isscalar(score) and np.isfinite(score)\n+\n+    preds = clf.predict(X_test, batch_size=batch_size)\n+    assert preds.shape == (num_test, )\n+    for prediction in np.unique(preds):\n+        assert prediction in string_classes\n+\n+    proba = clf.predict_proba(X_test, batch_size=batch_size)\n+    assert proba.shape == (num_test, num_class)\n+    assert np.allclose(np.sum(proba, axis=1), np.ones(num_test))\n+\n+\n def build_fn_reg(hidden_dims=50):\n     model = Sequential()\n     model.add(Dense(input_dim, input_shape=(input_dim,)))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#60deb6e2cfbfade95006f9b12ff89544ef1976b4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 76 | Lines Deleted: 11 | Files Changed: 2 | Hunks: 10 | Methods Changed: 9 | Complexity Δ (Sum/Max): 16/9 | Churn Δ: 87 | Churn Cumulative: 4905 | Contributors (this commit): 59 | Commits (past 90d): 54 | Contributors (cumulative): 62 | DMM Complexity: 0.46938775510204084\n\nDIFF:\n@@ -403,8 +403,7 @@ def gather(reference, indices):\n     \"\"\"\n     y = reference[indices]\n     if hasattr(reference, '_keras_shape') and hasattr(indices, '_keras_shape'):\n-        l = indices._keras_shape[0]\n-        y._keras_shape = (l,) + reference._keras_shape[1:]\n+        y._keras_shape = indices._keras_shape + reference._keras_shape[1:]\n     return y\n \n \n@@ -743,7 +742,9 @@ def repeat_elements(x, rep, axis):\n     y = T.repeat(x, rep, axis=axis)\n     if hasattr(x, '_keras_shape'):\n         y._keras_shape = list(x._keras_shape)\n-        y._keras_shape[axis] = x._keras_shape[axis] * rep\n+        repeat_dim = x._keras_shape[axis]\n+        if repeat_dim is not None:\n+                y._keras_shape[axis] = repeat_dim * rep\n         y._keras_shape = tuple(y._keras_shape)\n     return y\n \n@@ -821,21 +822,40 @@ def arange(start, stop=None, step=1, dtype='int32'):\n def tile(x, n):\n     y = T.tile(x, n)\n     if hasattr(x, '_keras_shape'):\n-        xshape = np.asarray(x._keras_shape)\n-        n = np.asarray(n)\n-        diff = len(xshape) - len(n)\n-        if diff > 0:\n-            n = np.append([1] * diff, n)\n+        if _is_explicit_shape(n):\n+            output_shape = x._keras_shape[:-len(n)]\n+            for i, j in zip(x._keras_shape, n):\n+                if i is None:\n+                    output_shape += (None,)\n                 else:\n-            xshape = np.append([1] * -diff, xshape)\n-        y._keras_shape = tuple(xshape * n)\n-\n+                    output_shape += (i * j,)\n+        elif type(n) is int:\n+            output_shape = x._keras_shape[:-1]\n+            if x._keras_shape[-1] is None:\n+                output_shape += (None,)\n+            else:\n+                output_shape += (x._keras_shape[-1] * n,)\n+        else:\n+            # symbolic n\n+            if n.ndim == 0:\n+                # n is a scalar\n+                output_shape = x._keras_shape[:-1] + (None,)\n+            elif hasattr(n, '_keras_shape'):\n+                # n is a vector\n+                n_size = n._keras_shape[0]\n+                output_shape = x._keras_shape[:-n_size] + (None,) * n_size\n+            else:\n+                output_shape = (None,) * x.ndim\n+        y._keras_shape = output_shape\n     return y\n \n \n def flatten(x):\n     y = T.flatten(x)\n     if hasattr(x, '_keras_shape'):\n+        if None in x._keras_shape:\n+            y._keras_shape = (None,)\n+        else:\n             y._keras_shape = (np.prod(x._keras_shape), )\n     return y\n \n@@ -846,6 +866,9 @@ def batch_flatten(x):\n     \"\"\"\n     y = T.reshape(x, (x.shape[0], T.prod(x.shape[1:])))\n     if hasattr(x, '_keras_shape'):\n+        if None in x._keras_shape[1:]:\n+            y._keras_shape = (x._keras_shape[0], None)\n+        else:\n             y._keras_shape = (x._keras_shape[0], np.prod(x._keras_shape[1:]))\n     return y\n \n\n@@ -131,6 +131,20 @@ class TestBackend(object):\n                                          'squeeze', {'axis': 2},\n                                          (4, 3, 1, 1))\n \n+    def test_none_shape_operations(self):\n+        # Test shape inference when input\n+        # shape has `None` entries\n+        if K.backend() == 'theano':\n+            x = KTH.placeholder((3, None, 4))\n+\n+            y = KTH.batch_flatten(x)\n+            if hasattr(y, '_keras_shape'):\n+                assert y._keras_shape == (3, None)\n+\n+            y = KTH.flatten(x)\n+            if hasattr(y, '_keras_shape'):\n+                assert y._keras_shape == (None, )\n+\n     def test_repeat_elements(self):\n         reps = 3\n         for ndims in [1, 2, 3]:\n@@ -153,6 +167,15 @@ class TestBackend(object):\n                 if hasattr(th_z, '_keras_shape'):\n                     assert th_z._keras_shape == th_rep.shape\n \n+                # test theano shape inference when\n+                # input shape has None entries\n+                if K.backend() == 'theano':\n+                    shape = list(shape)\n+                    shape[rep_axis] = None\n+                    x = K.placeholder(shape=shape)\n+                    y = K.repeat_elements(x, reps, axis=rep_axis)\n+                    assert y._keras_shape == tuple(shape)\n+\n     def test_tile(self):\n         shape = (3, 4)\n         arr = np.arange(np.prod(shape)).reshape(shape)\n@@ -167,6 +190,17 @@ class TestBackend(object):\n         if hasattr(th_z, '_keras_shape'):\n             assert th_z._keras_shape == th_rep.shape\n \n+        # test theano shape inference when\n+        # input shape has None entries\n+        if K.backend() == 'theano':\n+            x = K.placeholder(shape=(None, 4))\n+            n = 2\n+            y = KTH.tile(x, n)\n+            assert y._keras_shape == (None, 8)\n+            n = (4, 3)\n+            y = K.tile(x, n)\n+            assert y._keras_shape == (None, 12)\n+\n     def test_gather(self):\n         shape = (10, 2, 3)\n         ref = np.arange(np.prod(shape)).reshape(shape)\n@@ -185,6 +219,14 @@ class TestBackend(object):\n         if hasattr(th_z, '_keras_shape'):\n             assert th_z._keras_shape == th_result.shape\n \n+        # test theano shape inference when\n+        # input shape has None entries\n+        if K.backend() == 'theano':\n+            x = K.placeholder(shape=(None, 3, 4))\n+            indices = K.placeholder(shape=(5, 6), dtype='int32')\n+            y = K.gather(x, indices)\n+            assert y._keras_shape == (5, 6, 3, 4)\n+\n     def test_value_manipulation(self):\n         val = np.random.random((4, 2))\n         xth = KTH.variable(val)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3f45fa02ba23cfad3f2132dd1dd31f01e365cd6e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 770 | Contributors (this commit): 9 | Commits (past 90d): 10 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -21,13 +21,15 @@ def binary_accuracy(y_true, y_pred):\n \n \n def categorical_accuracy(y_true, y_pred):\n-    return K.equal(K.argmax(y_true, axis=-1),\n-                   K.argmax(y_pred, axis=-1))\n+    return K.cast(K.equal(K.argmax(y_true, axis=-1),\n+                          K.argmax(y_pred, axis=-1)),\n+                  K.floatx())\n \n \n def sparse_categorical_accuracy(y_true, y_pred):\n-    return K.equal(K.max(y_true, axis=-1),\n-                   K.cast(K.argmax(y_pred, axis=-1), K.floatx()))\n+    return K.cast(K.equal(K.max(y_true, axis=-1),\n+                          K.cast(K.argmax(y_pred, axis=-1), K.floatx())),\n+                  K.floatx())\n \n \n def top_k_categorical_accuracy(y_true, y_pred, k=5):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ec9c95fdbd60c2d86288858563c57b0007b24430", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -7/0 | Churn Δ: 2 | Churn Cumulative: 6493 | Contributors (this commit): 35 | Commits (past 90d): 27 | Contributors (cumulative): 35 | DMM Complexity: None\n\nDIFF:\n@@ -812,7 +812,7 @@ class GRU(Recurrent):\n                 if self.use_bias:\n                     x_z = K.bias_add(x_z, self.bias_z)\n                     x_r = K.bias_add(x_r, self.bias_r)\n-                    x_h = K.bias_add(x_r, self.bias_h)\n+                    x_h = K.bias_add(x_h, self.bias_h)\n             else:\n                 raise ValueError('Unknown `implementation` mode.')\n             z = self.recurrent_activation(x_z + K.dot(h_tm1 * rec_dp_mask[0],\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cb34ed881e83625239efea6c118dbbe653f01532", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 9065 | Contributors (this commit): 57 | Commits (past 90d): 30 | Contributors (cumulative): 57 | DMM Complexity: None\n\nDIFF:\n@@ -1030,7 +1030,7 @@ class Sequential(Model):\n             steps_per_epoch: Total number of steps (batches of samples)\n                 to yield from `generator` before declaring one epoch\n                 finished and starting the next epoch. It should typically\n-                be equal to the number of unique samples if your dataset\n+                be equal to the number of unique samples of your dataset\n                 divided by the batch size.\n             epochs: Integer, total number of iterations on the data.\n             verbose: Verbosity mode, 0, 1, or 2.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#22e3232e4d4e23dc284e77d2ca162dc67748ce42", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 4206 | Contributors (this commit): 39 | Commits (past 90d): 38 | Contributors (cumulative): 39 | DMM Complexity: None\n\nDIFF:\n@@ -1711,7 +1711,7 @@ class Model(Container):\n                 - a tuple (inputs, targets, sample_weights).\n                 All arrays should contain the same number of samples.\n                 The generator is expected to loop over its data\n-                indefinitely. An epoch finishes when `samples_per_epoch`\n+                indefinitely. An epoch finishes when `steps_per_epoch`\n                 samples have been seen by the model.\n             steps_per_epoch: Total number of steps (batches of samples)\n                 to yield from `generator` before declaring one epoch\n@@ -1760,7 +1760,7 @@ class Model(Container):\n                     f.close()\n \n             model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n-                                samples_per_epoch=10000, epochs=10)\n+                                steps_per_epoch=10000, epochs=10)\n         ```\n \n         # Raises\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b4f7340cc9be4ce23c768c26a612df287c5bb883", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2124 | Contributors (this commit): 24 | Commits (past 90d): 14 | Contributors (cumulative): 24 | DMM Complexity: None\n\nDIFF:\n@@ -708,7 +708,7 @@ class Iterator(object):\n                     index_array = np.random.permutation(n)\n \n             current_index = (self.batch_index * batch_size) % n\n-            if n >= current_index + batch_size:\n+            if n > current_index + batch_size:\n                 current_batch_size = batch_size\n                 self.batch_index += 1\n             else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bd9214a5470ace245a6915d4e6d448401360e5cf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 2353 | Contributors (this commit): 18 | Commits (past 90d): 46 | Contributors (cumulative): 21 | DMM Complexity: 0.3333333333333333\n\nDIFF:\n@@ -315,6 +315,8 @@ def get_classes_ancestors(classes):\n \n \n def get_function_signature(function, method=True):\n+    signature = getattr(function, '_legacy_support_signature', None)\n+    if signature is None:\n         signature = inspect.getargspec(function)\n     defaults = signature.defaults\n     if method:\n\n@@ -3,6 +3,7 @@\n import six\n import warnings\n import functools\n+import inspect\n import numpy as np\n \n \n@@ -85,6 +86,7 @@ def generate_legacy_interface(allowed_positional_args=None,\n                 warnings.warn('Update your `' + object_name +\n                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n             return func(*args, **kwargs)\n+        wrapper._legacy_support_signature = inspect.getargspec(func)\n         return wrapper\n     return legacy_support\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c0d185b467a569cc066372dd37837fbdb3641e6a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 8 | Files Changed: 3 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 14 | Churn Cumulative: 8717 | Contributors (this commit): 66 | Commits (past 90d): 75 | Contributors (cumulative): 75 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1136,8 +1136,7 @@ def any(x, axis=None, keepdims=False):\n     \"\"\"\n     axis = _normalize_axis(axis, ndim(x))\n     x = tf.cast(x, tf.bool)\n-    x = tf.reduce_any(x, reduction_indices=axis, keep_dims=keepdims)\n-    return tf.cast(x, tf.uint8)\n+    return tf.reduce_any(x, reduction_indices=axis, keep_dims=keepdims)\n \n \n def all(x, axis=None, keepdims=False):\n@@ -1153,8 +1152,7 @@ def all(x, axis=None, keepdims=False):\n     \"\"\"\n     axis = _normalize_axis(axis, ndim(x))\n     x = tf.cast(x, tf.bool)\n-    x = tf.reduce_all(x, reduction_indices=axis, keep_dims=keepdims)\n-    return tf.cast(x, tf.uint8)\n+    return tf.reduce_all(x, reduction_indices=axis, keep_dims=keepdims)\n \n \n def argmax(x, axis=-1):\n\n@@ -197,8 +197,8 @@ class Concatenate(_Merge):\n         for input_i, mask_i in zip(inputs, mask):\n             if mask_i is None:\n                 # Input is unmasked. Append all 1s to masks,\n-                # but cast it to uint8 first\n-                masks.append(K.cast(K.ones_like(input_i), 'uint8'))\n+                # but cast it to bool first\n+                masks.append(K.cast(K.ones_like(input_i), 'bool'))\n             elif K.ndim(mask_i) < K.ndim(input_i):\n                 # Mask is smaller than the input, expand it\n                 masks.append(K.expand_dims(mask_i))\n\n@@ -297,8 +297,8 @@ class Merge(Layer):\n             for input_i, mask_i in zip(inputs, mask):\n                 if mask_i is None:\n                     # Input is unmasked. Append all 1s to masks,\n-                    # but cast it to uint8 first\n-                    masks.append(K.cast(K.ones_like(input_i), 'uint8'))\n+                    # but cast it to bool first\n+                    masks.append(K.cast(K.ones_like(input_i), 'bool'))\n                 elif K.ndim(mask_i) < K.ndim(input_i):\n                     # Mask is smaller than the input, expand it\n                     masks.append(K.expand_dims(mask_i))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#31d821d8785979f071c578ffaa20dda79914f49c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 24 | Churn Cumulative: 168 | Contributors (this commit): 10 | Commits (past 90d): 2 | Contributors (cumulative): 10 | DMM Complexity: 0.0\n\nDIFF:\n@@ -4,18 +4,28 @@ from . import backend as K\n from .utils.generic_utils import deserialize_keras_object\n \n \n-def softmax(x):\n+def softmax(x, axis=-1):\n+    \"\"\"Softmax activation function.\n+\n+    # Arguments\n+        x : Tensor.\n+        axis: Integer, axis along which the softmax normalization is applied.\n+\n+    # Returns\n+        Tensor, output of softmax transformation.\n+\n+    # Raises\n+        ValueError: In case `dim(x) == 1`.\n+    \"\"\"\n     ndim = K.ndim(x)\n     if ndim == 2:\n         return K.softmax(x)\n-    elif ndim == 3:\n-        e = K.exp(x - K.max(x, axis=-1, keepdims=True))\n-        s = K.sum(e, axis=-1, keepdims=True)\n+    elif ndim > 2:\n+        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n+        s = K.sum(e, axis=axis, keepdims=True)\n         return e / s\n     else:\n-        raise ValueError('Cannot apply softmax to a tensor '\n-                         'that is not 2D or 3D. '\n-                         'Here, ndim=' + str(ndim))\n+        raise ValueError('Cannot apply softmax to a tensor that is 1D')\n \n \n def elu(x, alpha=1.0):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#576f8fe8e6a21b7094316d36c315c2f6bdb487cc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 304 | Contributors (this commit): 10 | Commits (past 90d): 17 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -18,4 +18,4 @@ from . import losses\n from . import optimizers\r\n from . import regularizers\r\n \r\n-__version__ = '2.0.1'\r\n+__version__ = '2.0.2'\r\n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='2.0.1',\n+      version='2.0.2',\n       description='Deep Learning for Python',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/fchollet/keras',\n-      download_url='https://github.com/fchollet/keras/tarball/2.0.1',\n+      download_url='https://github.com/fchollet/keras/tarball/2.0.2',\n       license='MIT',\n       install_requires=['theano', 'pyyaml', 'six'],\n       extras_require={\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#330ffa41dd949fdf48cc11f76fb410bf3551657c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 9635 | Contributors (this commit): 38 | Commits (past 90d): 41 | Contributors (cumulative): 38 | DMM Complexity: None\n\nDIFF:\n@@ -257,7 +257,7 @@ class Conv1D(_Conv):\n             any `dilation_rate` value != 1.\n         padding: One of `\"valid\"`, `\"causal\"` or `\"same\"` (case-insensitive).\n             `\"causal\"` results in causal (dilated) convolutions, e.g. output[t]\n-            depends solely on input[:t-1]. Useful when modeling temporal data\n+            does not depend on input[t+1:]. Useful when modeling temporal data\n             where the model should not violate the temporal order.\n             See [WaveNet: A Generative Model for Raw Audio, section 2.1](https://arxiv.org/abs/1609.03499).\n         dilation_rate: an integer or tuple/list of a single integer, specifying\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#15785660d63a889348ef79fed56e377c66f80d8e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 2 | Churn Cumulative: 4817 | Contributors (this commit): 60 | Commits (past 90d): 48 | Contributors (cumulative): 60 | DMM Complexity: 0.0\n\nDIFF:\n@@ -712,6 +712,8 @@ def concatenate(tensors, axis=-1):\n def reshape(x, shape):\n     y = T.reshape(x, shape)\n     if _is_explicit_shape(shape):\n+        if -1 in shape:\n+            shape = tuple(x if x != -1 else None for x in shape)\n         y._keras_shape = shape\n         if hasattr(x, '_uses_learning_phase'):\n             y._uses_learning_phase = x._uses_learning_phase\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
