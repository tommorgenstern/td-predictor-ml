{"custom_id": "keras#80ca7a7a06058076fde5ee36f8ac1f2ca30f8996", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 65 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 7 | Methods Changed: 7 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 73 | Churn Cumulative: 5228 | Contributors (this commit): 4 | Commits (past 90d): 25 | Contributors (cumulative): 7 | DMM Complexity: 0.9583333333333334\n\nDIFF:\n@@ -648,6 +648,10 @@ class IndexLookup(base_preprocessing_layer.CombinerPreprocessingLayer):\n       else:\n         lookup_values = lookup_result\n         input_values = inputs\n+      # tf.where needs rank > 0.\n+      if input_values.shape.rank == 0:\n+        input_values = self._expand_dims(input_values, -1)\n+        lookup_values = self._expand_dims(lookup_values, -1)\n       oov_indices = tf.where(tf.equal(lookup_values, -1))\n       oov_inputs = tf.compat.v1.gather_nd(input_values, oov_indices)\n       msg = tf.strings.format(\n@@ -665,20 +669,14 @@ class IndexLookup(base_preprocessing_layer.CombinerPreprocessingLayer):\n         return self._encode_output(lookup_result)\n \n   def _encode_output(self, lookup_result):\n-    def expand_dims(inputs, axis):\n-      if tf_utils.is_sparse(inputs):\n-        return tf.sparse.expand_dims(inputs, axis)\n-      else:\n-        return tf.compat.v1.expand_dims(inputs, axis)\n-\n     original_shape = lookup_result.shape\n     # In all cases, we should uprank scalar input to a single sample.\n     if lookup_result.shape.rank == 0:\n-      lookup_result = expand_dims(lookup_result, -1)\n+      lookup_result = self._expand_dims(lookup_result, -1)\n     # One hot will unprank only if the final output dimension is not already 1.\n     if self.output_mode == ONE_HOT:\n       if lookup_result.shape[-1] != 1:\n-        lookup_result = expand_dims(lookup_result, -1)\n+        lookup_result = self._expand_dims(lookup_result, -1)\n \n     # TODO(b/190445202): remove output rank restriction.\n     if lookup_result.shape.rank > 2:\n@@ -708,6 +706,12 @@ class IndexLookup(base_preprocessing_layer.CombinerPreprocessingLayer):\n   def _convert_to_ndarray(self, x):\n     return np.array(x) if isinstance(x, (list, tuple)) else x\n \n+  def _expand_dims(self, inputs, axis):\n+    if tf_utils.is_sparse(inputs):\n+      return tf.sparse.expand_dims(inputs, axis)\n+    else:\n+      return tf.compat.v1.expand_dims(inputs, axis)\n+\n   def _oov_start_index(self):\n     return 1 if self.mask_token is not None and self.output_mode == INT else 0\n \n\n@@ -707,6 +707,42 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     output_dataset = model.predict(input_array)\n     self.assertAllEqual(expected_output, output_dataset)\n \n+  def test_int_output_rank_one(self):\n+    vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n+    input_data = np.array([\"earth\", \"wind\", \"and\", \"fire\"])\n+    expected_output = [2, 3, 4, 5]\n+\n+    inputs = keras.Input(shape=(None,), dtype=tf.string)\n+    layer = index_lookup.IndexLookup(\n+        max_tokens=None,\n+        num_oov_indices=1,\n+        mask_token=\"\",\n+        oov_token=\"[OOV]\",\n+        dtype=tf.string)\n+    layer.set_vocabulary(vocab_data)\n+    outputs = layer(inputs)\n+    model = keras.Model(inputs=inputs, outputs=outputs)\n+    output_dataset = model(input_data)\n+    self.assertAllEqual(expected_output, output_dataset)\n+\n+  def test_int_output_rank_zero(self):\n+    vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n+    input_data = tf.constant(\"earth\")\n+    expected_output = 2\n+\n+    inputs = keras.Input(shape=(), dtype=tf.string)\n+    layer = index_lookup.IndexLookup(\n+        max_tokens=None,\n+        num_oov_indices=1,\n+        mask_token=\"\",\n+        oov_token=\"[OOV]\",\n+        dtype=tf.string)\n+    layer.set_vocabulary(vocab_data)\n+    outputs = layer(inputs)\n+    model = keras.Model(inputs=inputs, outputs=outputs)\n+    output_dataset = model(input_data)\n+    self.assertAllEqual(expected_output, output_dataset)\n+\n   def test_int_output_shape(self):\n     input_data = keras.Input(batch_size=16, shape=(4,), dtype=tf.string)\n     layer = index_lookup.IndexLookup(\n@@ -888,6 +924,23 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     output_dataset = model.predict(input_array)\n     self.assertAllEqual(expected_output, output_dataset)\n \n+  def test_one_hot_output_rank_zero_no_oov(self):\n+    \"\"\"Check binary output when pad_to_max_tokens=False.\"\"\"\n+    vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n+    input_data = tf.constant(\"earth\")\n+    expected_output = [1, 0, 0, 0]\n+\n+    layer = index_lookup.IndexLookup(\n+        max_tokens=None,\n+        num_oov_indices=0,\n+        mask_token=\"\",\n+        oov_token=\"[OOV]\",\n+        output_mode=index_lookup.ONE_HOT,\n+        dtype=tf.string)\n+    layer.set_vocabulary(vocab_data)\n+    output_data = layer(input_data)\n+    self.assertAllEqual(expected_output, output_data)\n+\n   def test_one_hot_output_shape(self):\n     inputs = keras.Input(batch_size=16, shape=(1,), dtype=tf.string)\n     layer = index_lookup.IndexLookup(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#12f79e3ab1855768df04a5f37bd87a35e53f216c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 7110 | Contributors (this commit): 92 | Commits (past 90d): 16 | Contributors (cumulative): 92 | DMM Complexity: None\n\nDIFF:\n@@ -482,8 +482,8 @@ class CallbackList:\n     \"\"\"Calls the `on_train_begin` methods of its callbacks.\n \n     Args:\n-        logs: Dict. Currently no data is passed to this argument for this method\n-          but that may change in the future.\n+        logs: Dict. Currently, no data is passed via this argument\n+          for this method, but that may change in the future.\n     \"\"\"\n     logs = self._process_logs(logs)\n     for callback in self.callbacks:\n@@ -493,8 +493,8 @@ class CallbackList:\n     \"\"\"Calls the `on_train_end` methods of its callbacks.\n \n     Args:\n-        logs: Dict. Currently no data is passed to this argument for this method\n-          but that may change in the future.\n+        logs: Dict. Currently, no data is passed via this argument\n+          for this method, but that may change in the future.\n     \"\"\"\n     logs = self._process_logs(logs)\n     for callback in self.callbacks:\n@@ -515,8 +515,8 @@ class CallbackList:\n     \"\"\"Calls the `on_test_end` methods of its callbacks.\n \n     Args:\n-        logs: Dict. Currently no data is passed to this argument for this method\n-          but that may change in the future.\n+        logs: Dict. Currently, no data is passed via this argument\n+          for this method, but that may change in the future.\n     \"\"\"\n     logs = self._process_logs(logs)\n     for callback in self.callbacks:\n@@ -537,8 +537,8 @@ class CallbackList:\n     \"\"\"Calls the `on_predict_end` methods of its callbacks.\n \n     Args:\n-        logs: Dict. Currently no data is passed to this argument for this method\n-          but that may change in the future.\n+        logs: Dict. Currently, no data is passed via this argument\n+          for this method, but that may change in the future.\n     \"\"\"\n     logs = self._process_logs(logs)\n     for callback in self.callbacks:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b1030b2e6db8d7d5bf91e43f57f63e2576e06ed2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 7 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 18 | Churn Cumulative: 15307 | Contributors (this commit): 103 | Commits (past 90d): 20 | Contributors (cumulative): 104 | DMM Complexity: 0.0\n\nDIFF:\n@@ -37,7 +37,7 @@ from keras.mixed_precision import policy\n from keras.saving import hdf5_format\n from keras.saving import save\n from keras.saving import saving_utils\n-from keras.saving.pickle_utils import pack_model\n+from keras.saving.pickle_utils import deserialize_model_from_bytecode, serialize_model_as_bytecode\n from keras.saving.saved_model import json_utils\n from keras.saving.saved_model import model_serialization\n from keras.utils import generic_utils\n@@ -323,12 +323,11 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     super(Model, self).__setattr__(name, value)\n \n   def __reduce__(self):\n-    return pack_model(self)\n+    return (deserialize_model_from_bytecode, *serialize_model_as_bytecode(self))\n \n   def __deepcopy__(self, memo):\n     if self.built:\n-      deserializer, serialized = pack_model(self)\n-      new = deserializer(*serialized)\n+      new = deserialize_model_from_bytecode(*serialize_model_as_bytecode(self))\n       memo[id(self)] = new\n     else:\n       deserializer, serialized, *rest = super(Model, self).__reduce__()\n\n@@ -27,7 +27,7 @@ from numpy import asarray\n from keras.saving.save import load_model\n \n \n-def unpack_model(packed_keras_model):\n+def deserialize_model_from_bytecode(packed_keras_model):\n   \"\"\"Reconstruct a Model from the result of pack_model.\n \n   Args:\n@@ -49,15 +49,14 @@ def unpack_model(packed_keras_model):\n   return model\n \n \n-def pack_model(model):\n-  \"\"\"Pack a Keras Model into a numpy array for pickling.\n+def serialize_model_as_bytecode(model):\n+  \"\"\"Pack a Keras Model into a bytes for pickling.\n \n   Args:\n       model (tf.keras.Model): a Keras Model instance.\n \n   Returns:\n-      tuple: an unpacking function (unpack_model) and it's arguments,\n-      as per Python's pickle protocol.\n+      tuple: a tuple of arguments for deserialize_from_bytecode.\n   \"\"\"\n   temp_dir = f\"ram://{uuid4()}\"\n   model.save(temp_dir)\n@@ -72,4 +71,4 @@ def pack_model(model):\n           archive.addfile(tarinfo=info, fileobj=f)\n   tf.io.gfile.rmtree(temp_dir)\n   b.seek(0)\n-  return unpack_model, (asarray(memoryview(b.read())), )\n+  return (asarray(memoryview(b.read())), )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f1c5826dbfdbc62ae6eea599d939b9da2f70f1ab", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 73 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -31,7 +31,6 @@ class TestPickleProtocol(keras_parameterized.TestCase):\n   \"\"\"Tests pickle protoocol support.\n   \"\"\"\n \n-  @keras_parameterized.run_all_keras_modes\n   def test_pickle_model(self):\n     \"\"\"Test copy.copy, copy.deepcopy and pickle on Functional Model.\"\"\"\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#07df258970d52cd5c85056078c845eabc4fa0013", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 6 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 89 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 1 | DMM Complexity: 0.0\n\nDIFF:\n@@ -22,15 +22,15 @@ import pickle\n import numpy as np\n \n from keras import keras_parameterized\n+from keras import testing_utils\n from keras import layers as layers_module\n-from keras.engine import input_layer\n-from keras.engine import training as training_module\n \n \n class TestPickleProtocol(keras_parameterized.TestCase):\n   \"\"\"Tests pickle protoocol support.\n   \"\"\"\n \n+  @keras_parameterized.run_with_all_model_types\n   def test_pickle_model(self):\n     \"\"\"Test copy.copy, copy.deepcopy and pickle on Functional Model.\"\"\"\n \n@@ -42,13 +42,12 @@ class TestPickleProtocol(keras_parameterized.TestCase):\n       return model\n \n     # create model\n-    x = input_layer.Input((3,))\n-    y = layers_module.Dense(2)(x)\n-    original_model = training_module.Model(x, y)\n-    model = original_model\n-    original_weights = model.get_weights()\n+    layers = [layers_module.Dense(2)]\n+    original_model = testing_utils.get_model_from_layers(layers, input_shape=(3,))\n+    original_weights = original_model.get_weights()\n+\n     # roundtrip without compiling\n-    model = roundtrip(model)\n+    model = roundtrip(original_model)\n     # compile\n     model.compile(optimizer='sgd', loss='mse')\n     # roundtrip compiled but not trained\n@@ -65,6 +64,7 @@ class TestPickleProtocol(keras_parameterized.TestCase):\n     # check that the original model has not been changed\n     final_weights = original_model.get_weights()\n     self.assertAllClose(original_weights, final_weights)\n+    # but that the weights on the trained model are different\n     self.assertNotAllClose(original_weights, model.get_weights())\n \n if __name__ == '__main__':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#472877be4e2f348527053e302e415913d20baf28", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 2 | Churn Cumulative: 15221 | Contributors (this commit): 103 | Commits (past 90d): 18 | Contributors (cumulative): 103 | DMM Complexity: None\n\nDIFF:\n@@ -323,7 +323,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     super(Model, self).__setattr__(name, value)\n \n   def __reduce__(self):\n-    return (deserialize_model_from_bytecode, *serialize_model_as_bytecode(self))\n+    return (deserialize_model_from_bytecode, serialize_model_as_bytecode(self))\n \n   def __deepcopy__(self, memo):\n     if self.built:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8ddbf3408a7eaa4a94683cfc5fcafd8608961527", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 6 | Churn Cumulative: 15316 | Contributors (this commit): 103 | Commits (past 90d): 23 | Contributors (cumulative): 104 | DMM Complexity: 1.0\n\nDIFF:\n@@ -323,7 +323,11 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     super(Model, self).__setattr__(name, value)\n \n   def __reduce__(self):\n+    if self.built:\n       return (deserialize_model_from_bytecode, serialize_model_as_bytecode(self))\n+    else:\n+      deserializer, serialized, *_ = super(Model, self).__reduce__()\n+      return (deserializer, serialized)\n \n   def __deepcopy__(self, memo):\n     if self.built:\n\n@@ -37,7 +37,7 @@ class TestPickleProtocol(keras_parameterized.TestCase):\n     def roundtrip(model):\n       model = copy.copy(model)\n       model = copy.deepcopy(model)\n-      for protocol in range(5):  # support up to protocol version 5\n+      for protocol in range(pickle.HIGHEST_PROTOCOL):\n         model = pickle.loads(pickle.dumps(model, protocol=protocol))\n       return model\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#644b84faad19794bcd309634af2320fc2c436fee", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 96 | Contributors (this commit): 1 | Commits (past 90d): 4 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -27,17 +27,17 @@ from numpy import asarray\n from keras.saving.save import load_model\n \n \n-def deserialize_model_from_bytecode(packed_keras_model):\n-  \"\"\"Reconstruct a Model from the result of pack_model.\n+def deserialize_model_from_bytecode(serialized_model):\n+  \"\"\"Reconstruct a Model from the result of serialize_model_as_bytecode.\n \n   Args:\n-      packed_keras_model (np.array): return value from pack_model.\n+      packed_keras_model (np.array): return value from serialize_model_as_bytecode.\n \n   Returns:\n       keras.Model: a Keras Model instance.\n   \"\"\"\n   temp_dir = f\"ram://{uuid4()}\"\n-  b = BytesIO(packed_keras_model)\n+  b = BytesIO(serialized_model)\n   with tarfile.open(fileobj=b, mode=\"r\") as archive:\n     for fname in archive.getnames():\n       dest_path = os.path.join(temp_dir, fname)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#79260c6a09476c78c84cc6bc19f99835ce2122e7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 15233 | Contributors (this commit): 103 | Commits (past 90d): 20 | Contributors (cumulative): 103 | DMM Complexity: 0.0\n\nDIFF:\n@@ -326,14 +326,18 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     if self.built:\n       return (deserialize_model_from_bytecode, serialize_model_as_bytecode(self))\n     else:\n-      deserializer, serialized, *_ = super(Model, self).__reduce__()\n-      return (deserializer, serialized)\n+      # SavedModel (and hence serialize_model_as_bytecode) only support built models\n+      # but if the model is not built, it can be serialized as a plain Python object\n+      # so call up the MRO to get an implementation of __reduce__,\n+      # possibly landing at object.__reduce__\n+      return super(Model, self).__reduce__()\n \n   def __deepcopy__(self, memo):\n     if self.built:\n       new = deserialize_model_from_bytecode(*serialize_model_as_bytecode(self))\n       memo[id(self)] = new\n     else:\n+      # See comment in __reduce__ for explanation \n       deserializer, serialized, *rest = super(Model, self).__reduce__()\n       new = deserializer(*serialized)\n       memo[id(self)] = new\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2f18a826fca72db9dd3b63d8cdf6bee6808bef89", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 109 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -28,13 +28,13 @@ from keras.saving.save import load_model\n \n \n def deserialize_model_from_bytecode(serialized_model):\n-  \"\"\"Reconstruct a Model from the result of serialize_model_as_bytecode.\n+  \"\"\"Reconstruct a Model from the output of `serialize_model_as_bytecode`.\n \n   Args:\n-      packed_keras_model (np.array): return value from serialize_model_as_bytecode.\n+      serialized_model (np.array): return value from `serialize_model_as_bytecode`.\n \n   Returns:\n-      keras.Model: a Keras Model instance.\n+      keras.Model: Keras Model instance.\n   \"\"\"\n   temp_dir = f\"ram://{uuid4()}\"\n   b = BytesIO(serialized_model)\n@@ -50,13 +50,14 @@ def deserialize_model_from_bytecode(serialized_model):\n \n \n def serialize_model_as_bytecode(model):\n-  \"\"\"Pack a Keras Model into a bytes for pickling.\n+  \"\"\"Convert a Keras Model into a bytecode representation for pickling.\n \n   Args:\n-      model (tf.keras.Model): a Keras Model instance.\n+      model (tf.keras.Model): Keras Model instance.\n \n   Returns:\n-      tuple: a tuple of arguments for deserialize_from_bytecode.\n+      tuple: tuple of arguments that can be sent to\n+          `deserialize_from_bytecode`.\n   \"\"\"\n   temp_dir = f\"ram://{uuid4()}\"\n   model.save(temp_dir)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#df8c58dd68b068cd93b6329640816c1af85366ed", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 99 | Contributors (this commit): 1 | Commits (past 90d): 5 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -23,7 +23,6 @@ import numpy as np\n \n from keras import keras_parameterized\n from keras import testing_utils\n-from keras import layers as layers_module\n \n \n class TestPickleProtocol(keras_parameterized.TestCase):\n@@ -37,13 +36,14 @@ class TestPickleProtocol(keras_parameterized.TestCase):\n     def roundtrip(model):\n       model = copy.copy(model)\n       model = copy.deepcopy(model)\n-      for protocol in range(pickle.HIGHEST_PROTOCOL):\n+      for protocol in range(pickle.HIGHEST_PROTOCOL+1):\n         model = pickle.loads(pickle.dumps(model, protocol=protocol))\n       return model\n \n     # create model\n-    layers = [layers_module.Dense(2)]\n-    original_model = testing_utils.get_model_from_layers(layers, input_shape=(3,))\n+    original_model = testing_utils.get_small_mlp(\n+      num_hidden=1, num_classes=2, input_dim=3\n+    )\n     original_weights = original_model.get_weights()\n \n     # roundtrip without compiling\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c76113b8f032b3c46ac88c2601915ea8e155c053", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 601 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -49,7 +49,7 @@ class BatchNormalizationBase(Layer):\n   - `beta` is a learned offset factor (initialized as 0), which\n   can be disabled by passing `center=False` to the constructor.\n \n-  **During inference** (i.e. when using `evaluate()` or `predict()` or when\n+  **During inference** (i.e. when using `evaluate()` or `predict()`) or when\n   calling the layer/model with the argument `training=False` (which is the\n   default), the layer normalizes its output using a moving average of the\n   mean and standard deviation of the batches it has seen during training. That\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6225b70e56ba6e96e7e37ca2a750accf0c46aa3f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 33 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 7 | Methods Changed: 3 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 36 | Churn Cumulative: 4190 | Contributors (this commit): 30 | Commits (past 90d): 5 | Contributors (cumulative): 33 | DMM Complexity: 0.68\n\nDIFF:\n@@ -34,6 +34,7 @@ import typing\n import urllib\n import weakref\n import zipfile\n+from six.moves.urllib.parse import urlsplit\n \n import numpy as np\n from six.moves.urllib.request import urlopen\n@@ -145,8 +146,8 @@ def _extract_archive(file_path, path='.', archive_format='auto'):\n \n \n @keras_export('keras.utils.get_file')\n-def get_file(fname,\n-             origin,\n+def get_file(fname=None,\n+             origin=None,\n              untar=False,\n              md5_hash=None,\n              file_hash=None,\n@@ -177,7 +178,8 @@ def get_file(fname,\n \n   Args:\n       fname: Name of the file. If an absolute path `/path/to/file.txt` is\n-          specified the file will be saved at that location.\n+          specified the file will be saved at that location. If `None`, the\n+          name of the file at `origin` will be used.\n       origin: Original URL of the file.\n       untar: Deprecated in favor of `extract` argument.\n           boolean, whether the file should be decompressed\n@@ -203,6 +205,10 @@ def get_file(fname,\n   Returns:\n       Path to the downloaded file\n   \"\"\"\n+  if origin is None:\n+    raise ValueError('Please specify the \"origin\" argument (URL of the file '\n+                     'to download).')\n+\n   if cache_dir is None:\n     cache_dir = os.path.join(os.path.expanduser('~'), '.keras')\n   if md5_hash is not None and file_hash is None:\n@@ -215,9 +221,14 @@ def get_file(fname,\n   _makedirs_exist_ok(datadir)\n \n   fname = path_to_string(fname)\n+  if not fname:\n+    fname = os.path.basename(urlsplit(origin).path)\n+    if not fname:\n+      raise ValueError(\"Invalid origin '{}'\".format(origin))\n \n   if untar:\n     untar_fpath = os.path.join(datadir, fname)\n+    if not untar_fpath.endswith('.tar.gz'):\n       fpath = untar_fpath + '.tar.gz'\n   else:\n     fpath = os.path.join(datadir, fname)\n\n@@ -84,6 +84,25 @@ class TestGetFileAndValidateIt(tf.test.TestCase):\n     self.assertTrue(os.path.exists(path))\n     self.assertTrue(keras.utils.data_utils.validate_file(path, hashval_sha256))\n     self.assertTrue(keras.utils.data_utils.validate_file(path, hashval_md5))\n+    os.remove(path)\n+\n+    for file_path, extract in [(text_file_path, False), (tar_file_path, True),\n+                               (zip_file_path, True)]:\n+      origin = urllib.parse.urljoin(\n+          'file://', urllib.request.pathname2url(os.path.abspath(file_path)))\n+      hashval_sha256 = keras.utils.data_utils._hash_file(file_path)\n+      path = keras.utils.data_utils.get_file(\n+          origin=origin,\n+          file_hash=hashval_sha256,\n+          extract=extract,\n+          cache_subdir=dest_dir)\n+      self.assertTrue(os.path.exists(path))\n+      self.assertTrue(\n+          keras.utils.data_utils.validate_file(path, hashval_sha256))\n+      os.remove(path)\n+\n+    with self.assertRaisesRegexp(ValueError, 'Please specify the \"origin\".*'):\n+      _ = keras.utils.data_utils.get_file()\n \n \n class TestSequence(keras.utils.data_utils.Sequence):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a5a6a53eceb4bb0957fcbe577f56941ae8062d8f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 418 | Lines Deleted: 430 | Files Changed: 99 | Hunks: 372 | Methods Changed: 261 | Complexity Δ (Sum/Max): -7/0 | Churn Δ: 848 | Churn Cumulative: 199728 | Contributors (this commit): 409 | Commits (past 90d): 441 | Contributors (cumulative): 974 | DMM Complexity: 0.06666666666666667\n\nDIFF:\n@@ -77,7 +77,7 @@ def softmax(x, axis=-1):\n   \"\"\"\n   if x.shape.rank > 1:\n     if isinstance(axis, int):\n-      output = tf.compat.v1.math.softmax(x, axis=axis)\n+      output = tf.nn.softmax(x, axis=axis)\n     else:\n       # nn.softmax does not support tuple axis.\n       e = tf.exp(x - tf.reduce_max(x, axis=axis, keepdims=True))\n@@ -511,7 +511,7 @@ def serialize(activation):\n # Add additional globals so that deserialize can find these common activation\n # functions\n leaky_relu = tf.nn.leaky_relu\n-log_softmax = tf.compat.v1.math.log_softmax\n+log_softmax = tf.nn.log_softmax\n relu6 = tf.nn.relu6\n silu = tf.nn.silu\n \n\n@@ -249,7 +249,7 @@ class ApiCompatibilityTest(tf.test.TestCase):\n         # Remove files.\n         for key in only_in_expected:\n           filepath = _KeyToFilePath(key, api_version)\n-          tf.compat.v1.gfile.Remove(filepath)\n+          tf.io.gfile.remove(filepath)\n \n         # If the files are only in actual (current library), these are new\n         # modules. Write them to files. Also record all updates in files.\n\n@@ -1389,7 +1389,7 @@ def shape(x):\n   <KerasTensor: shape=(3,) dtype=int32 inferred_value=[2, 4, 5] ...>\n \n   \"\"\"\n-  return tf.compat.v1.shape(x)\n+  return tf.shape(x)\n \n \n @keras_export('keras.backend.int_shape')\n@@ -1655,7 +1655,7 @@ def zeros_like(x, dtype=None, name=None):\n   # array([[ 0.,  0.,  0.], [ 0.,  0.,  0.]], dtype=float32)\n   ```\n   \"\"\"\n-  return tf.compat.v1.zeros_like(x, dtype=dtype, name=name)\n+  return tf.zeros_like(x, dtype=dtype, name=name)\n \n \n @keras_export('keras.backend.ones_like')\n@@ -1682,7 +1682,7 @@ def ones_like(x, dtype=None, name=None):\n          [1.,  1.,  1.]], dtype=float32)\n \n   \"\"\"\n-  return tf.compat.v1.ones_like(x, dtype=dtype, name=name)\n+  return tf.ones_like(x, dtype=dtype, name=name)\n \n \n def identity(x, name=None):\n@@ -1953,14 +1953,14 @@ def dot(x, y):\n   \"\"\"\n   if ndim(x) is not None and (ndim(x) > 2 or ndim(y) > 2):\n     x_shape = []\n-    for i, s in zip(int_shape(x), tf.unstack(tf.compat.v1.shape(x))):\n+    for i, s in zip(int_shape(x), tf.unstack(tf.shape(x))):\n       if i is not None:\n         x_shape.append(i)\n       else:\n         x_shape.append(s)\n     x_shape = tuple(x_shape)\n     y_shape = []\n-    for i, s in zip(int_shape(y), tf.unstack(tf.compat.v1.shape(y))):\n+    for i, s in zip(int_shape(y), tf.unstack(tf.shape(y))):\n       if i is not None:\n         y_shape.append(i)\n       else:\n@@ -2095,11 +2095,11 @@ def batch_dot(x, y, axes=None):\n \n   # if rank is 2, expand to 3.\n   if x_ndim == 2:\n-    x = tf.compat.v1.expand_dims(x, 1)\n+    x = tf.expand_dims(x, 1)\n     a0 += 1\n     x_ndim += 1\n   if y_ndim == 2:\n-    y = tf.compat.v1.expand_dims(y, 2)\n+    y = tf.expand_dims(y, 2)\n     y_ndim += 1\n \n   # bring x's dimension to be reduced to last axis.\n@@ -2144,7 +2144,7 @@ def batch_dot(x, y, axes=None):\n   result = tf.matmul(x, y)\n \n   # if inputs were squashed, we have to reshape the matmul output.\n-  output_shape = tf.compat.v1.shape(result)\n+  output_shape = tf.shape(result)\n   do_reshape = False\n \n   if x_squashed:\n@@ -2163,9 +2163,9 @@ def batch_dot(x, y, axes=None):\n \n   # if the inputs were originally rank 2, we remove the added 1 dim.\n   if orig_x_ndim == 2:\n-    result = tf.compat.v1.squeeze(result, 1)\n+    result = tf.squeeze(result, 1)\n   elif orig_y_ndim == 2:\n-    result = tf.compat.v1.squeeze(result, -1)\n+    result = tf.squeeze(result, -1)\n \n   return result\n \n@@ -2472,7 +2472,7 @@ def argmax(x, axis=-1):\n   Returns:\n       A tensor.\n   \"\"\"\n-  return tf.compat.v1.argmax(x, axis)\n+  return tf.argmax(x, axis)\n \n \n @keras_export('keras.backend.argmin')\n@@ -2488,7 +2488,7 @@ def argmin(x, axis=-1):\n   Returns:\n       A tensor.\n   \"\"\"\n-  return tf.compat.v1.argmin(x, axis)\n+  return tf.argmin(x, axis)\n \n \n @keras_export('keras.backend.square')\n@@ -2880,7 +2880,7 @@ def _broadcast_normalize_batch_in_training(x,\n     if axis in reduction_axes:\n       target_shape.append(1)\n     else:\n-      target_shape.append(tf.compat.v1.shape(x)[axis])\n+      target_shape.append(tf.shape(x)[axis])\n   target_shape = tf.stack(target_shape)\n \n   broadcast_mean = tf.reshape(mean, target_shape)\n@@ -3263,8 +3263,8 @@ def repeat_elements(x, rep, axis):\n \n   # Repeating\n   auxiliary_axis = axis + 1\n-  x_shape = tf.compat.v1.shape(x)\n-  x_rep = tf.compat.v1.expand_dims(x, axis=auxiliary_axis)\n+  x_shape = tf.shape(x)\n+  x_rep = tf.expand_dims(x, axis=auxiliary_axis)\n   reps = np.ones(len(x.shape) + 1)\n   reps[auxiliary_axis] = rep\n   x_rep = tf.tile(x_rep, reps)\n@@ -3315,7 +3315,7 @@ def repeat(x, n):\n \n   \"\"\"\n   assert ndim(x) == 2\n-  x = tf.compat.v1.expand_dims(x, 1)\n+  x = tf.expand_dims(x, 1)\n   pattern = tf.stack([1, n, 1])\n   return tf.tile(x, pattern)\n \n@@ -3446,7 +3446,7 @@ def expand_dims(x, axis=-1):\n   Returns:\n       A tensor with expanded dimensions.\n   \"\"\"\n-  return tf.compat.v1.expand_dims(x, axis)\n+  return tf.expand_dims(x, axis)\n \n \n @keras_export('keras.backend.squeeze')\n@@ -3462,7 +3462,7 @@ def squeeze(x, axis):\n   Returns:\n       A tensor with the same data as `x` but reduced dimensions.\n   \"\"\"\n-  return tf.compat.v1.squeeze(x, [axis])\n+  return tf.squeeze(x, [axis])\n \n \n @keras_export('keras.backend.temporal_padding')\n@@ -4216,7 +4216,7 @@ def rnn(step_function,\n   flatted_inputs = tf.nest.flatten(inputs)\n   time_steps = flatted_inputs[0].shape[0]\n   batch = flatted_inputs[0].shape[1]\n-  time_steps_t = tf.compat.v1.shape(flatted_inputs[0])[0]\n+  time_steps_t = tf.shape(flatted_inputs[0])[0]\n \n   for input_ in flatted_inputs:\n     input_.shape.with_rank_at_least(3)\n@@ -4245,7 +4245,7 @@ def rnn(step_function,\n       raise ValueError('input_t is expected to be tensor, but got %s' % input_t)\n     rank_diff = len(input_t.shape) - len(mask_t.shape)\n     for _ in range(rank_diff):\n-      mask_t = tf.compat.v1.expand_dims(mask_t, -1)\n+      mask_t = tf.expand_dims(mask_t, -1)\n     multiples = [1] * fixed_dim + input_t.shape.as_list()[fixed_dim:]\n     return tf.tile(mask_t, multiples)\n \n@@ -4419,7 +4419,7 @@ def rnn(step_function,\n     if masking_fn is not None:\n       # Mask for the T output will be base on the output of T - 1. In the case\n       # T = 0, a zero filled tensor will be used.\n-      flat_zero_output = tuple(tf.compat.v1.zeros_like(o)\n+      flat_zero_output = tuple(tf.zeros_like(o)\n                                for o in tf.nest.flatten(output_time_zero))\n       def _step(time, output_ta_t, prev_output, *states):\n         \"\"\"RNN step function.\n@@ -4582,12 +4582,12 @@ def switch(condition, then_expression, else_expression):\n     if cond_ndim > 1:\n       ndim_diff = expr_ndim - cond_ndim\n       cond_shape = tf.concat(\n-          [tf.compat.v1.shape(condition), [1] * ndim_diff], axis=0)\n+          [tf.shape(condition), [1] * ndim_diff], axis=0)\n       condition = tf.reshape(condition, cond_shape)\n-      expr_shape = tf.compat.v1.shape(then_expression)\n+      expr_shape = tf.shape(then_expression)\n       shape_diff = expr_shape - cond_shape\n       tile_shape = tf.where(shape_diff > 0, expr_shape,\n-                                      tf.compat.v1.ones_like(expr_shape))\n+                            tf.ones_like(expr_shape))\n       condition = tf.tile(condition, tile_shape)\n     x = tf.where(condition, then_expression, else_expression)\n   return x\n@@ -4756,7 +4756,7 @@ def softmax(x, axis=-1):\n   Returns:\n       A tensor.\n   \"\"\"\n-  return tf.compat.v1.math.softmax(x, axis=axis)\n+  return tf.nn.softmax(x, axis=axis)\n \n \n @keras_export('keras.backend.softplus')\n@@ -4997,7 +4997,7 @@ def binary_crossentropy(target, output, from_logits=False):\n     from_logits = True\n \n   if from_logits:\n-    return tf.compat.v1.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n+    return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n \n   if (not isinstance(output, (tf.__internal__.EagerTensor, tf.Variable)) and\n       output.op.type == 'Sigmoid') and not hasattr(output, '_keras_history'):\n@@ -5006,7 +5006,7 @@ def binary_crossentropy(target, output, from_logits=False):\n     # to prevent collapsing zero when training.\n     assert len(output.op.inputs) == 1\n     output = output.op.inputs[0]\n-    return tf.compat.v1.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n+    return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n \n   epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\n   output = tf.clip_by_value(output, epsilon_, 1. - epsilon_)\n@@ -5430,9 +5430,9 @@ def separable_conv1d(x,\n   else:\n     spatial_start_dim = 2\n     strides = (1, 1) + strides * 2\n-  x = tf.compat.v1.expand_dims(x, spatial_start_dim)\n-  depthwise_kernel = tf.compat.v1.expand_dims(depthwise_kernel, 0)\n-  pointwise_kernel = tf.compat.v1.expand_dims(pointwise_kernel, 0)\n+  x = tf.expand_dims(x, spatial_start_dim)\n+  depthwise_kernel = tf.expand_dims(depthwise_kernel, 0)\n+  pointwise_kernel = tf.expand_dims(pointwise_kernel, 0)\n   dilation_rate = (1,) + dilation_rate\n \n   x = tf.compat.v1.nn.separable_conv2d(\n@@ -5444,7 +5444,7 @@ def separable_conv1d(x,\n       rate=dilation_rate,\n       data_format=tf_data_format)\n \n-  x = tf.compat.v1.squeeze(x, [spatial_start_dim])\n+  x = tf.squeeze(x, [spatial_start_dim])\n \n   if data_format == 'channels_first' and tf_data_format == 'NWC':\n     x = tf.compat.v1.transpose(x, (0, 2, 1))  # NWC -> NCW\n@@ -5645,7 +5645,7 @@ def conv3d_transpose(x,\n     output_shape = (output_shape[0], output_shape[2], output_shape[3],\n                     output_shape[4], output_shape[1])\n   if output_shape[0] is None:\n-    output_shape = (tf.compat.v1.shape(x)[0],) + tuple(output_shape[1:])\n+    output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])\n     output_shape = tf.stack(list(output_shape))\n \n   padding = _preprocess_padding(padding)\n@@ -6165,13 +6165,13 @@ def ctc_label_dense_to_sparse(labels, label_lengths):\n   Returns:\n       A sparse tensor representation of the labels.\n   \"\"\"\n-  label_shape = tf.compat.v1.shape(labels)\n+  label_shape = tf.shape(labels)\n   num_batches_tns = tf.stack([label_shape[0]])\n   max_num_labels_tns = tf.stack([label_shape[1]])\n \n   def range_less_than(old_input, current_input):\n-    return tf.compat.v1.expand_dims(\n-        tf.range(tf.compat.v1.shape(old_input)[1]), 0) < tf.fill(\n+    return tf.expand_dims(\n+        tf.range(tf.shape(old_input)[1]), 0) < tf.fill(\n             max_num_labels_tns, current_input)\n \n   init = tf.cast(\n@@ -6221,15 +6221,15 @@ def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n           CTC loss of each element.\n   \"\"\"\n   label_length = tf.cast(\n-      tf.compat.v1.squeeze(label_length, axis=-1), tf.int32)\n+      tf.squeeze(label_length, axis=-1), tf.int32)\n   input_length = tf.cast(\n-      tf.compat.v1.squeeze(input_length, axis=-1), tf.int32)\n+      tf.squeeze(input_length, axis=-1), tf.int32)\n   sparse_labels = tf.cast(\n       ctc_label_dense_to_sparse(y_true, label_length), tf.int32)\n \n   y_pred = tf.math.log(tf.compat.v1.transpose(y_pred, perm=[1, 0, 2]) + epsilon())\n \n-  return tf.compat.v1.expand_dims(\n+  return tf.expand_dims(\n       tf.compat.v1.nn.ctc_loss(\n           inputs=y_pred, labels=sparse_labels, sequence_length=input_length), 1)\n \n\n@@ -1531,7 +1531,7 @@ class BackendNNOpsTest(tf.test.TestCase, parameterized.TestCase):\n     # 3D NHC case\n     val = np.random.random((10, 5, 3))\n     x = backend.variable(val)\n-    mean, var = tf.compat.v1.nn.moments(x, (0, 1), None, None, False)\n+    mean, var = tf.nn.moments(x, (0, 1), None, None, False)\n     normed = backend.batch_normalization(\n         x, mean, var, beta, gamma, axis=-1, epsilon=1e-3)\n     self.assertEqual(normed.shape.as_list(), [10, 5, 3])\n@@ -1539,7 +1539,7 @@ class BackendNNOpsTest(tf.test.TestCase, parameterized.TestCase):\n     # 4D NHWC case\n     val = np.random.random((10, 5, 5, 3))\n     x = backend.variable(val)\n-    mean, var = tf.compat.v1.nn.moments(x, (0, 1, 2), None, None, False)\n+    mean, var = tf.nn.moments(x, (0, 1, 2), None, None, False)\n     normed = backend.batch_normalization(\n         x, mean, var, beta, gamma, axis=-1, epsilon=1e-3)\n     self.assertEqual(normed.shape.as_list(), [10, 5, 5, 3])\n@@ -1549,7 +1549,7 @@ class BackendNNOpsTest(tf.test.TestCase, parameterized.TestCase):\n       # Eager CPU kernel for NCHW does not exist.\n       val = np.random.random((10, 3, 5, 5))\n       x = backend.variable(val)\n-      mean, var = tf.compat.v1.nn.moments(x, (0, 2, 3), None, None, False)\n+      mean, var = tf.nn.moments(x, (0, 2, 3), None, None, False)\n       normed = backend.batch_normalization(\n           x, mean, var, beta, gamma, axis=1, epsilon=1e-3)\n       self.assertEqual(normed.shape.as_list(), [10, 3, 5, 5])\n\n@@ -32,7 +32,7 @@ def save_and_load_benchmark(app):\n   model_name = app.__name__\n \n   tmp_dir = tf.compat.v1.test.get_temp_dir()\n-  tf.compat.v1.gfile.MakeDirs(tmp_dir)\n+  tf.io.gfile.makedirs(tmp_dir)\n   save_dir = tempfile.mkdtemp(dir=tmp_dir)\n \n   total_save_time = 0\n\n@@ -2004,7 +2004,7 @@ def keras_model_summary(name, data, step=None):\n \n   with tf.summary.experimental.summary_scope(name, 'graph_keras_model',\n                                     [data, step]) as (tag, _):\n-    with tf.compat.v1.device('cpu:0'):\n+    with tf.device('cpu:0'):\n       tensor = tf.constant(json_string, dtype=tf.string)\n     return tf.summary.write(\n         tag=tag, tensor=tensor, step=step, metadata=summary_metadata)\n@@ -2521,20 +2521,20 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n \n   def _log_weight_as_image(self, weight, weight_name, epoch):\n     \"\"\"Logs a weight as a TensorBoard image.\"\"\"\n-    w_img = tf.compat.v1.squeeze(weight)\n+    w_img = tf.squeeze(weight)\n     shape = backend.int_shape(w_img)\n     if len(shape) == 1:  # Bias case\n       w_img = tf.reshape(w_img, [1, shape[0], 1, 1])\n     elif len(shape) == 2:  # Dense layer kernel case\n       if shape[0] > shape[1]:\n-        w_img = tf.compat.v1.transpose(w_img)\n+        w_img = tf.transpose(w_img)\n         shape = backend.int_shape(w_img)\n       w_img = tf.reshape(w_img, [1, shape[0], shape[1], 1])\n     elif len(shape) == 3:  # ConvNet case\n       if backend.image_data_format() == 'channels_last':\n         # Switch to channels_first to display every kernel as a separate\n         # image.\n-        w_img = tf.compat.v1.transpose(w_img, perm=[2, 0, 1])\n+        w_img = tf.transpose(w_img, perm=[2, 0, 1])\n         shape = backend.int_shape(w_img)\n       w_img = tf.reshape(w_img, [shape[0], shape[1], shape[2], 1])\n \n\n@@ -288,7 +288,7 @@ class RadialConstraint(Constraint):\n     while_condition = lambda index, *args: backend.less(index, start)\n \n     def body_fn(i, array):\n-      return i + 1, tf.compat.v1.pad(\n+      return i + 1, tf.pad(\n           array,\n           padding,\n           constant_values=kernel[start + i, start + i])\n\n@@ -54,9 +54,9 @@ class OptimizerTest(tf.test.TestCase, parameterized.TestCase):\n \n     @tf.function\n     def optimize():\n-      with tf.compat.v1.device(distribution.extended.worker_devices[0]):\n+      with tf.device(distribution.extended.worker_devices[0]):\n         v1 = tf.convert_to_tensor([1., 1.])\n-      with tf.compat.v1.device(distribution.extended.worker_devices[1]):\n+      with tf.device(distribution.extended.worker_devices[1]):\n         v2 = tf.convert_to_tensor([2., 2.])\n       grads = PerReplica([v1, v2])\n       def step_fn(grads):\n\n@@ -1985,7 +1985,7 @@ class TestDistributionStrategyWithKerasModels(tf.test.TestCase,\n \n     def custom_transform(grads_and_vars):\n       # Always set gradients to 1.\n-      return [(tf.compat.v1.ones_like(g), v) for g, v in grads_and_vars]\n+      return [(tf.ones_like(g), v) for g, v in grads_and_vars]\n \n     x, y = np.ones((10, 1)), np.ones((10, 1))\n \n@@ -2277,8 +2277,8 @@ class TestDistributionStrategyWithKerasModels(tf.test.TestCase,\n \n       def call(self, inputs):\n         indices = tf.where(tf.not_equal(inputs, 0))\n-        values = tf.compat.v1.gather_nd(inputs, indices)\n-        shape = tf.compat.v1.shape(inputs, out_type='int64')\n+        values = tf.gather_nd(inputs, indices)\n+        shape = tf.shape(inputs, out_type='int64')\n         return tf.SparseTensor(indices, values, dense_shape=shape)\n \n     model = keras.Sequential([ToSparse()])\n@@ -2485,8 +2485,8 @@ def _functional_with_layer_reuse(input_shape, num_classes, l1, l2):\n   logits = base_model(inputs)\n   model = keras.Model(inputs=inputs, outputs=logits)\n   # Reuse sequential layer and create new nodes.\n-  zero_logits = base_model(tf.compat.v1.zeros_like(inputs))\n-  one_logits = base_model(tf.compat.v1.ones_like(inputs))\n+  zero_logits = base_model(tf.zeros_like(inputs))\n+  one_logits = base_model(tf.ones_like(inputs))\n   # L2 loss.\n   l2_loss = tf.reduce_mean(\n       tf.reduce_sum(tf.square(logits - zero_logits), -1))\n\n@@ -42,7 +42,7 @@ class MirroredStrategyOptimizerV2Test(tf.test.TestCase, parameterized.TestCase):\n   def testKerasOptimizerWithUnequalInput(self, distribution):\n     with distribution.scope():\n       var = tf.Variable(\n-          2.0, name='var', aggregation=tf.compat.v1.VariableAggregation.SUM)\n+          2.0, name='var', aggregation=tf.VariableAggregation.SUM)\n       optimizer = adam.Adam(learning_rate=0.01, beta_1=0.2, beta_2=0.2)\n       all_vars = []\n \n\n@@ -534,7 +534,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n                  constraint=None,\n                  use_resource=None,\n                  synchronization=tf.VariableSynchronization.AUTO,\n-                 aggregation=tf.compat.v1.VariableAggregation.NONE,\n+                 aggregation=tf.VariableAggregation.NONE,\n                  **kwargs):\n     \"\"\"Adds a new variable to the layer.\n \n@@ -2465,7 +2465,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         for output in output_list:\n           activity_loss = self._activity_regularizer(output)\n           batch_size = tf.cast(\n-              tf.compat.v1.shape(output)[0], activity_loss.dtype)\n+              tf.shape(output)[0], activity_loss.dtype)\n           # Make activity regularization strength batch-agnostic.\n           mean_activity_loss = activity_loss / batch_size\n           self.add_loss(mean_activity_loss)\n\n@@ -44,7 +44,7 @@ class DynamicLayer(base_layer.Layer):\n \n   def call(self, inputs):\n     samples = tf.TensorArray(\n-        dtype=tf.float32, size=tf.compat.v1.shape(inputs)[0])\n+        dtype=tf.float32, size=tf.shape(inputs)[0])\n     for idx, sample in enumerate(inputs):\n       samples = samples.write(idx, tf.square(sample))\n     return samples.stack()\n@@ -309,8 +309,8 @@ class BaseLayerTest(keras_parameterized.TestCase):\n     class LearningPhaseLayer(base_layer.Layer):\n \n       def call(self, inputs):\n-        return backend.in_train_phase(lambda: tf.compat.v1.ones_like(inputs),\n-                                      lambda: tf.compat.v1.zeros_like(inputs))\n+        return backend.in_train_phase(lambda: tf.ones_like(inputs),\n+                                      lambda: tf.zeros_like(inputs))\n \n     def get_learning_phase_value():\n       model = sequential.Sequential([LearningPhaseLayer(input_shape=(1,))])\n@@ -363,8 +363,8 @@ class BaseLayerTest(keras_parameterized.TestCase):\n         if training is None:\n           training = backend.learning_phase()\n         return control_flow_util.smart_cond(\n-            training, lambda: tf.compat.v1.ones_like(inputs),\n-            lambda: tf.compat.v1.zeros_like(inputs))\n+            training, lambda: tf.ones_like(inputs),\n+            lambda: tf.zeros_like(inputs))\n \n     return TrainingLayer()\n \n\n@@ -46,7 +46,7 @@ def make_variable(name,\n                   use_resource=None,\n                   collections=None,\n                   synchronization=tf.VariableSynchronization.AUTO,\n-                  aggregation=tf.compat.v1.VariableAggregation.NONE,\n+                  aggregation=tf.VariableAggregation.NONE,\n                   partitioner=None):  # pylint: disable=unused-argument\n   \"\"\"Temporary util to create a variable (relies on `variable_scope.variable`).\n \n@@ -105,12 +105,15 @@ def make_variable(name,\n       initializer = initializer()\n     init_val = functools.partial(initializer, shape, dtype=dtype)\n     variable_dtype = dtype.base_dtype\n+\n+  variable_shape = tf.TensorShape(shape)\n+\n   if use_resource is None:\n     use_resource = True\n-\n-  # TODO(apassos,rohanj) figure out how to remove collections from here so we\n-  # can remove the V1.\n-  variable_shape = tf.TensorShape(shape)\n+  # In theory, in `use_resource` is True and `collections` is empty\n+  # (that is to say, in TF2), we can use tf.Variable.\n+  # However, this breaks legacy (Estimator) checkpoints\n+  # because it changes variable names. Remove this when V1 is fully deprecated.\n   return tf.compat.v1.Variable(\n       initial_value=init_val,\n       name=name,\n\n@@ -209,7 +209,7 @@ class LossesContainer(Container):\n         if tf_utils.is_ragged(y_t):\n           batch_dim = y_t.nrows()\n         else:\n-          batch_dim = tf.compat.v1.shape(y_t)[0]\n+          batch_dim = tf.shape(y_t)[0]\n \n       if metric_obj is not None:\n         metric_obj.update_state(loss_metric_value, sample_weight=batch_dim)\n\n@@ -380,9 +380,9 @@ class LossesContainerTest(keras_parameterized.TestCase):\n     v_t = tf.constant([[3., 4.], [1., 2.], [3., 5.]])\n     v_p = tf.constant([[3.1, 4.], [1., 2.], [3., 5.]])\n \n-    y_t = tf.compat.v1.expand_dims(\n+    y_t = tf.expand_dims(\n         tf.RaggedTensor.from_row_splits(v_t, [0, 2, 3]), 0)\n-    y_p = tf.compat.v1.expand_dims(\n+    y_p = tf.expand_dims(\n         tf.RaggedTensor.from_row_splits(v_p, [0, 2, 3]), 0)\n     loss_container(y_t, y_p)\n \n\n@@ -41,7 +41,7 @@ class ControlFlowLayer2(base_layer.Layer):\n \n   def call(self, inputs):\n     samples = tf.TensorArray(\n-        dtype=tf.float32, size=tf.compat.v1.shape(inputs)[0])\n+        dtype=tf.float32, size=tf.shape(inputs)[0])\n     i = 0\n     for sample in inputs:\n       samples = samples.write(i, tf.square(sample))\n\n@@ -349,7 +349,7 @@ class TensorLikeDataAdapter(DataAdapter):\n     ))\n \n     def grab_batch(i, data):\n-      return tf.nest.map_structure(lambda d: tf.compat.v1.gather(d, i, axis=0), data)\n+      return tf.nest.map_structure(lambda d: tf.gather(d, i, axis=0), data)\n \n     dataset = dataset.map(\n         grab_batch, num_parallel_calls=tf.data.AUTOTUNE)\n\n@@ -727,7 +727,7 @@ class NetworkConstructionTest(keras_parameterized.TestCase):\n         return inputs\n \n       def compute_mask(self, inputs, mask=None):\n-        return tf.compat.v1.ones_like(inputs)\n+        return tf.ones_like(inputs)\n \n     if tf.executing_eagerly():\n       a = tf.constant([2] * 32)\n@@ -736,7 +736,7 @@ class NetworkConstructionTest(keras_parameterized.TestCase):\n       b = MaskedLayer().apply(a)\n       self.assertTrue(hasattr(b, '_keras_mask'))\n       self.assertAllEqual(\n-          self.evaluate(tf.compat.v1.ones_like(mask)),\n+          self.evaluate(tf.ones_like(mask)),\n           self.evaluate(getattr(b, '_keras_mask')))\n       self.assertAllEqual(self.evaluate(a * mask), self.evaluate(b))\n     else:\n\n@@ -188,7 +188,7 @@ class KerasTensor(object):\n       # allows us to specify partially-unspecified shape values.\n       #\n       # See the comment on value extraction inside `from_tensor` for more info.\n-      inferred_value = tf.compat.v1.shape(\n+      inferred_value = tf.shape(\n           tf.compat.v1.placeholder(\n               shape=self._inferred_value, dtype=tf.int32))\n       if self.type_spec.shape.rank == 0:\n\n@@ -70,7 +70,7 @@ class PartialBatchPaddingHandler(object):\n       missing_count = (self.padded_batch_size -\n                        self.get_real_batch_size(batch))\n       padding = backend.stack([[0, missing_count]] + [[0, 0]] * (rank - 1))\n-      return tf.compat.v1.pad(batch, padding, 'constant')\n+      return tf.pad(batch, padding, 'constant')\n \n     if len(dataset_batch_elements) == 1:\n       return _pad(dataset_batch_elements[0])\n\n@@ -2893,7 +2893,7 @@ def _multi_worker_concat(v, strategy):\n   # v might not have the same shape on different replicas\n   if _is_per_replica_instance(v):\n     shapes = tf.concat([\n-        tf.expand_dims(tf.compat.v1.shape(single_value)[0], axis=0)\n+        tf.expand_dims(tf.shape(single_value)[0], axis=0)\n         for single_value in v.values\n     ],\n                               axis=0)\n@@ -2901,7 +2901,7 @@ def _multi_worker_concat(v, strategy):\n   else:\n     # v is a tensor. This may happen when, say, we have 2x1 multi-worker.\n     all_shapes = strategy.gather(\n-        tf.expand_dims(tf.compat.v1.shape(v)[0], axis=0), axis=0)\n+        tf.expand_dims(tf.shape(v)[0], axis=0), axis=0)\n \n   replicas = tf.split(\n       replicas,\n\n@@ -125,8 +125,8 @@ class TrainingTest(keras_parameterized.TestCase):\n     class ReturnTraining(layers_module.Layer):\n \n       def call(self, inputs):\n-        return backend.in_train_phase(lambda: tf.compat.v1.ones_like(inputs),\n-                                      lambda: tf.compat.v1.zeros_like(inputs))\n+        return backend.in_train_phase(lambda: tf.ones_like(inputs),\n+                                      lambda: tf.zeros_like(inputs))\n \n     model = sequential.Sequential([ReturnTraining(input_shape=(2,))])\n     model.compile(\n@@ -157,8 +157,8 @@ class TrainingTest(keras_parameterized.TestCase):\n \n       def call(self, inputs, training=None):\n         return backend.in_train_phase(\n-            lambda: tf.compat.v1.ones_like(inputs),\n-            lambda: tf.compat.v1.zeros_like(inputs),\n+            lambda: tf.ones_like(inputs),\n+            lambda: tf.zeros_like(inputs),\n             training=training)\n \n     model = sequential.Sequential([ReturnTraining(input_shape=(2,))])\n@@ -213,8 +213,8 @@ class TrainingTest(keras_parameterized.TestCase):\n \n       def call(self, inputs, training=None):\n         return backend.in_train_phase(\n-            lambda: tf.compat.v1.ones_like(inputs),\n-            lambda: tf.compat.v1.zeros_like(inputs),\n+            lambda: tf.ones_like(inputs),\n+            lambda: tf.zeros_like(inputs),\n             training=training)\n \n     class ReturnTraining(layers_module.Layer):\n@@ -3543,7 +3543,7 @@ class TestTrainingWithMetrics(keras_parameterized.TestCase):\n       def update_state(self, y_true, y_pred, sample_weight=None):\n         self.l2_sum.assign_add(\n             tf.reduce_sum(tf.square(y_true - y_pred)))\n-        self.sample_count.assign_add(tf.compat.v1.shape(y_true)[0])\n+        self.sample_count.assign_add(tf.shape(y_true)[0])\n \n       def reset_state(self):\n         self.sample_count.assign(0)\n\n@@ -98,7 +98,7 @@ def handle_partial_sample_weights(outputs, sample_weights, sample_weight_modes,\n     if sw is None:\n       as_numpy = isinstance(outputs[i], np.ndarray)\n       output = outputs[i]\n-      output_shape = output.shape if as_numpy else tf.compat.v1.shape(output)\n+      output_shape = output.shape if as_numpy else tf.shape(output)\n \n       is_temporal = (\n           sample_weight_modes is not None and\n\n@@ -108,7 +108,7 @@ class _BaseFeaturesLayer(Layer):\n       Reshaped dense tensor.\n     \"\"\"\n     num_elements = column.variable_shape.num_elements()\n-    target_shape = self._target_shape(tf.compat.v1.shape(tensor), num_elements)\n+    target_shape = self._target_shape(tf.shape(tensor), num_elements)\n     return tf.reshape(tensor, shape=target_shape)\n \n   def _verify_and_concat_tensors(self, output_tensors):\n\n@@ -92,7 +92,7 @@ class SequenceFeatureColumnIntegrationTest(tf.test.TestCase):\n     seq_input, _ = sequence_input_layer(features)\n     dense_input_layer = dense_features.DenseFeatures(ctx_cols)\n     ctx_input = dense_input_layer(features)\n-    ctx_input = backend.repeat(ctx_input, tf.compat.v1.shape(seq_input)[1])\n+    ctx_input = backend.repeat(ctx_input, tf.shape(seq_input)[1])\n     concatenated_input = merge.concatenate([seq_input, ctx_input])\n \n     rnn_layer = recurrent.RNN(recurrent.SimpleRNNCell(10))\n\n@@ -214,13 +214,13 @@ class KPLTest(tf.test.TestCase, parameterized.TestCase):\n \n       @tf.function\n       def serve_fn(raw_features):\n-        raw_features = tf.compat.v1.expand_dims(raw_features, axis=0)\n+        raw_features = tf.expand_dims(raw_features, axis=0)\n         transformed_features = model.feature_ps(raw_features)\n         outputs = model(transformed_features)\n-        outputs = tf.compat.v1.squeeze(outputs, axis=0)\n+        outputs = tf.squeeze(outputs, axis=0)\n         outputs = tf.cast(tf.greater(outputs, 0.5), tf.int64)\n         decoded_outputs = model.label_inverse_lookup_layer(outputs)\n-        return tf.compat.v1.squeeze(decoded_outputs, axis=0)\n+        return tf.squeeze(decoded_outputs, axis=0)\n \n       # serving does NOT have batch dimension\n       return serve_fn.get_concrete_function(\n\n@@ -244,7 +244,7 @@ class Conv(Layer):\n     input_shape = inputs.shape\n \n     if self._is_causal:  # Apply causal padding to inputs for Conv1D.\n-      inputs = tf.compat.v1.pad(inputs, self._compute_causal_padding(inputs))\n+      inputs = tf.pad(inputs, self._compute_causal_padding(inputs))\n \n     outputs = self._convolution_op(inputs, self.kernel)\n \n@@ -995,7 +995,7 @@ class Conv1DTranspose(Conv1D):\n     self.built = True\n \n   def call(self, inputs):\n-    inputs_shape = tf.compat.v1.shape(inputs)\n+    inputs_shape = tf.shape(inputs)\n     batch_size = inputs_shape[0]\n     if self.data_format == 'channels_first':\n       t_axis = 2\n@@ -1266,7 +1266,7 @@ class Conv2DTranspose(Conv2D):\n     self.built = True\n \n   def call(self, inputs):\n-    inputs_shape = tf.compat.v1.shape(inputs)\n+    inputs_shape = tf.shape(inputs)\n     batch_size = inputs_shape[0]\n     if self.data_format == 'channels_first':\n       h_axis, w_axis = 2, 3\n@@ -1576,7 +1576,7 @@ class Conv3DTranspose(Conv3D):\n     self.built = True\n \n   def call(self, inputs):\n-    inputs_shape = tf.compat.v1.shape(inputs)\n+    inputs_shape = tf.shape(inputs)\n     batch_size = inputs_shape[0]\n     if self.data_format == 'channels_first':\n       d_axis, h_axis, w_axis = 2, 3, 4\n@@ -1621,7 +1621,7 @@ class Conv3DTranspose(Conv3D):\n       strides = (1, stride_d, stride_h, stride_w, 1)\n \n     output_shape_tensor = tf.stack(output_shape)\n-    outputs = tf.compat.v1.nn.conv3d_transpose(\n+    outputs = tf.nn.conv3d_transpose(\n         inputs,\n         self.kernel,\n         output_shape_tensor,\n@@ -2039,7 +2039,7 @@ class SeparableConv1D(SeparableConv):\n \n   def call(self, inputs):\n     if self.padding == 'causal':\n-      inputs = tf.compat.v1.pad(inputs, self._compute_causal_padding(inputs))\n+      inputs = tf.pad(inputs, self._compute_causal_padding(inputs))\n     if self.data_format == 'channels_last':\n       strides = (1,) + self.strides * 2 + (1,)\n       spatial_start_dim = 1\n@@ -2049,9 +2049,9 @@ class SeparableConv1D(SeparableConv):\n \n     # Explicitly broadcast inputs and kernels to 4D.\n     # TODO(fchollet): refactor when a native separable_conv1d op is available.\n-    inputs = tf.compat.v1.expand_dims(inputs, spatial_start_dim)\n-    depthwise_kernel = tf.compat.v1.expand_dims(self.depthwise_kernel, 0)\n-    pointwise_kernel = tf.compat.v1.expand_dims(self.pointwise_kernel, 0)\n+    inputs = tf.expand_dims(inputs, spatial_start_dim)\n+    depthwise_kernel = tf.expand_dims(self.depthwise_kernel, 0)\n+    pointwise_kernel = tf.expand_dims(self.pointwise_kernel, 0)\n     dilation_rate = (1,) + self.dilation_rate\n \n     if self.padding == 'causal':\n@@ -2073,7 +2073,7 @@ class SeparableConv1D(SeparableConv):\n           self.bias,\n           data_format=conv_utils.convert_data_format(self.data_format, ndim=4))\n \n-    outputs = tf.compat.v1.squeeze(outputs, [spatial_start_dim])\n+    outputs = tf.squeeze(outputs, [spatial_start_dim])\n \n     if self.activation is not None:\n       return self.activation(outputs)\n\n@@ -107,7 +107,7 @@ class Masking(Layer):\n         tf.not_equal(inputs, self.mask_value), axis=-1, keepdims=True)\n     outputs = inputs * tf.cast(boolean_mask, inputs.dtype)\n     # Compute the mask and outputs simultaneously.\n-    outputs._keras_mask = tf.compat.v1.squeeze(boolean_mask, axis=-1)  # pylint: disable=protected-access\n+    outputs._keras_mask = tf.squeeze(boolean_mask, axis=-1)  # pylint: disable=protected-access\n     return outputs\n \n   def compute_output_shape(self, input_shape):\n@@ -192,7 +192,7 @@ class Dropout(Layer):\n     if self.noise_shape is None:\n       return None\n \n-    concrete_inputs_shape = tf.compat.v1.shape(inputs)\n+    concrete_inputs_shape = tf.shape(inputs)\n     noise_shape = []\n     for i, value in enumerate(self.noise_shape):\n       noise_shape.append(concrete_inputs_shape[i] if value is None else value)\n@@ -203,7 +203,7 @@ class Dropout(Layer):\n       training = K.learning_phase()\n \n     def dropped_inputs():\n-      return tf.compat.v1.nn.dropout(\n+      return tf.nn.dropout(\n           inputs,\n           noise_shape=self._get_noise_shape(inputs),\n           seed=self.seed,\n@@ -263,7 +263,7 @@ class SpatialDropout1D(Dropout):\n     self.input_spec = InputSpec(ndim=3)\n \n   def _get_noise_shape(self, inputs):\n-    input_shape = tf.compat.v1.shape(inputs)\n+    input_shape = tf.shape(inputs)\n     noise_shape = (input_shape[0], 1, input_shape[2])\n     return noise_shape\n \n@@ -320,7 +320,7 @@ class SpatialDropout2D(Dropout):\n     self.input_spec = InputSpec(ndim=4)\n \n   def _get_noise_shape(self, inputs):\n-    input_shape = tf.compat.v1.shape(inputs)\n+    input_shape = tf.shape(inputs)\n     if self.data_format == 'channels_first':\n       return (input_shape[0], input_shape[1], 1, 1)\n     elif self.data_format == 'channels_last':\n@@ -378,7 +378,7 @@ class SpatialDropout3D(Dropout):\n     self.input_spec = InputSpec(ndim=5)\n \n   def _get_noise_shape(self, inputs):\n-    input_shape = tf.compat.v1.shape(inputs)\n+    input_shape = tf.shape(inputs)\n     if self.data_format == 'channels_first':\n       return (input_shape[0], input_shape[1], 1, 1, 1)\n     elif self.data_format == 'channels_last':\n@@ -532,7 +532,7 @@ class Reshape(Layer):\n \n   def call(self, inputs):\n     result = tf.reshape(\n-        inputs, (tf.compat.v1.shape(inputs)[0],) + self.target_shape)\n+        inputs, (tf.shape(inputs)[0],) + self.target_shape)\n     if not tf.executing_eagerly():\n       # Set the static shape for the result since it might lost during array_ops\n       # reshape, eg, some `None` dim in the result could be inferred.\n@@ -595,7 +595,7 @@ class Permute(Layer):\n     return tf.TensorShape(output_shape)\n \n   def call(self, inputs):\n-    return tf.compat.v1.transpose(inputs, perm=(0,) + self.dims)\n+    return tf.transpose(inputs, perm=(0,) + self.dims)\n \n   def get_config(self):\n     config = {'dims': self.dims}\n@@ -648,7 +648,7 @@ class Flatten(Layer):\n         permutation = [0]\n         permutation.extend(range(2, rank))\n         permutation.append(1)\n-        inputs = tf.compat.v1.transpose(inputs, perm=permutation)\n+        inputs = tf.transpose(inputs, perm=permutation)\n \n     if tf.executing_eagerly():\n       # Full static shape is guaranteed to be available.\n\n@@ -264,9 +264,9 @@ class CuDNNGRU(_CuDNNRNN):\n \n   def _process_batch(self, inputs, initial_state):\n     if not self.time_major:\n-      inputs = tf.compat.v1.transpose(inputs, perm=(1, 0, 2))\n+      inputs = tf.transpose(inputs, perm=(1, 0, 2))\n     input_h = initial_state[0]\n-    input_h = tf.compat.v1.expand_dims(input_h, axis=0)\n+    input_h = tf.expand_dims(input_h, axis=0)\n \n     params = recurrent_v2._canonical_to_params(    # pylint: disable=protected-access\n         weights=[\n@@ -304,7 +304,7 @@ class CuDNNGRU(_CuDNNRNN):\n       if self.time_major:\n         output = outputs\n       else:\n-        output = tf.compat.v1.transpose(outputs, perm=(1, 0, 2))\n+        output = tf.transpose(outputs, perm=(1, 0, 2))\n     else:\n       output = outputs[-1]\n     return output, [h]\n@@ -460,11 +460,11 @@ class CuDNNLSTM(_CuDNNRNN):\n \n   def _process_batch(self, inputs, initial_state):\n     if not self.time_major:\n-      inputs = tf.compat.v1.transpose(inputs, perm=(1, 0, 2))\n+      inputs = tf.transpose(inputs, perm=(1, 0, 2))\n     input_h = initial_state[0]\n     input_c = initial_state[1]\n-    input_h = tf.compat.v1.expand_dims(input_h, axis=0)\n-    input_c = tf.compat.v1.expand_dims(input_c, axis=0)\n+    input_h = tf.expand_dims(input_h, axis=0)\n+    input_c = tf.expand_dims(input_c, axis=0)\n \n     params = recurrent_v2._canonical_to_params(    # pylint: disable=protected-access\n         weights=[\n@@ -506,7 +506,7 @@ class CuDNNLSTM(_CuDNNRNN):\n       if self.time_major:\n         output = outputs\n       else:\n-        output = tf.compat.v1.transpose(outputs, perm=(1, 0, 2))\n+        output = tf.transpose(outputs, perm=(1, 0, 2))\n     else:\n       output = outputs[-1]\n     return output, [h, c]\n\n@@ -103,11 +103,11 @@ class CuDNNTest(keras_parameterized.TestCase):\n \n     model = keras.models.Sequential()\n     model.add(\n-        keras.layers.Lambda(lambda t: tf.compat.v1.transpose(t, [1, 0, 2])))\n+        keras.layers.Lambda(lambda t: tf.transpose(t, [1, 0, 2])))\n     layer = layer_class(units, time_major=True, return_sequences=True)\n     model.add(layer)\n     model.add(\n-        keras.layers.Lambda(lambda t: tf.compat.v1.transpose(t, [1, 0, 2])))\n+        keras.layers.Lambda(lambda t: tf.transpose(t, [1, 0, 2])))\n     model.compile(loss='categorical_crossentropy',\n                   optimizer=RMSprop(learning_rate=0.001))\n     model.fit(\n\n@@ -123,10 +123,10 @@ class BaseDenseAttention(Layer):\n         scores -= 1.e9 * tf.cast(padding_mask, dtype=scores.dtype)\n     if training is None:\n       training = backend.learning_phase()\n-    weights = tf.compat.v1.math.softmax(scores)\n+    weights = tf.nn.softmax(scores)\n \n     def dropped_weights():\n-      return tf.compat.v1.nn.dropout(weights, rate=self.dropout)\n+      return tf.nn.dropout(weights, rate=self.dropout)\n \n     weights = control_flow_util.smart_cond(training, dropped_weights,\n                                            lambda: tf.identity(weights))\n@@ -147,15 +147,15 @@ class BaseDenseAttention(Layer):\n     scores = self._calculate_scores(query=q, key=k)\n     if v_mask is not None:\n       # Mask of shape [batch_size, 1, Tv].\n-      v_mask = tf.compat.v1.expand_dims(v_mask, axis=-2)\n+      v_mask = tf.expand_dims(v_mask, axis=-2)\n     if self.causal:\n       # Creates a lower triangular mask, so position i cannot attend to\n       # positions j>i. This prevents the flow of information from the future\n       # into the past.\n-      scores_shape = tf.compat.v1.shape(scores)\n+      scores_shape = tf.shape(scores)\n       # causal_mask_shape = [1, Tq, Tv].\n       causal_mask_shape = tf.concat(\n-          [tf.compat.v1.ones_like(scores_shape[:-2]), scores_shape[-2:]],\n+          [tf.ones_like(scores_shape[:-2]), scores_shape[-2:]],\n           axis=0)\n       causal_mask = _lower_triangular_mask(causal_mask_shape)\n     else:\n@@ -165,7 +165,7 @@ class BaseDenseAttention(Layer):\n         scores=scores, value=v, scores_mask=scores_mask, training=training)\n     if q_mask is not None:\n       # Mask of shape [batch_size, Tq, 1].\n-      q_mask = tf.compat.v1.expand_dims(q_mask, axis=-1)\n+      q_mask = tf.expand_dims(q_mask, axis=-1)\n       result *= tf.cast(q_mask, dtype=result.dtype)\n     if return_attention_scores:\n       return result, attention_scores\n@@ -322,7 +322,7 @@ class Attention(BaseDenseAttention):\n       self.scale = self.add_weight(\n           name='scale',\n           shape=(),\n-          initializer=tf.compat.v1.ones_initializer(),\n+          initializer='ones',\n           dtype=self.dtype,\n           trainable=True)\n     else:\n@@ -459,13 +459,12 @@ class AdditiveAttention(BaseDenseAttention):\n   def build(self, input_shape):\n     v_shape = tf.TensorShape(input_shape[1])\n     dim = v_shape[-1]\n-    if isinstance(dim, tf.compat.v1.Dimension):\n-      dim = dim.value\n+    dim = tf.compat.dimension_value(dim)\n     if self.use_scale:\n       self.scale = self.add_weight(\n           name='scale',\n           shape=[dim],\n-          initializer=tf.compat.v1.glorot_uniform_initializer(),\n+          initializer='glorot_uniform',\n           dtype=self.dtype,\n           trainable=True)\n     else:\n@@ -483,9 +482,9 @@ class AdditiveAttention(BaseDenseAttention):\n     \"\"\"\n     # Reshape tensors to enable broadcasting.\n     # Reshape into [batch_size, Tq, 1, dim].\n-    q_reshaped = tf.compat.v1.expand_dims(query, axis=-2)\n+    q_reshaped = tf.expand_dims(query, axis=-2)\n     # Reshape into [batch_size, 1, Tv, dim].\n-    k_reshaped = tf.compat.v1.expand_dims(key, axis=-3)\n+    k_reshaped = tf.expand_dims(key, axis=-3)\n     if self.use_scale:\n       scale = self.scale\n     else:\n\n@@ -147,10 +147,10 @@ class BaseDenseAttentionTest(tf.test.TestCase, parameterized.TestCase):\n \n     # Expected Tensor of shape `[batch_size, tq, tv]`.\n     expected_scores_shape = [batch_size, tq, tv]\n-    self.assertAllEqual(expected_scores_shape, tf.compat.v1.shape(actual_scores))\n+    self.assertAllEqual(expected_scores_shape, tf.shape(actual_scores))\n     # Expected Tensor of shape `[batch_size, tq, dim]`.\n     expected_shape = [batch_size, tq, dim]\n-    self.assertAllEqual(expected_shape, tf.compat.v1.shape(actual))\n+    self.assertAllEqual(expected_shape, tf.shape(actual))\n \n   def test_serialization(self):\n     # Test serialization with causal\n@@ -248,7 +248,7 @@ class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n     actual = attention_layer([q, v], mask=[None, v_mask])\n \n     expected_shape = [1, 2, 4]\n-    self.assertAllEqual(expected_shape, tf.compat.v1.shape(actual))\n+    self.assertAllEqual(expected_shape, tf.shape(actual))\n \n   def test_shape_with_key(self):\n     # Query tensor of shape [1, 2, 4]\n@@ -267,7 +267,7 @@ class AttentionTest(tf.test.TestCase, parameterized.TestCase):\n     actual = attention_layer([q, v, k], mask=[None, v_mask])\n \n     expected_shape = [1, 2, 4]\n-    self.assertAllEqual(expected_shape, tf.compat.v1.shape(actual))\n+    self.assertAllEqual(expected_shape, tf.shape(actual))\n \n   def test_multi_dim(self):\n     # Query tensor of shape [1, 1, 1]\n@@ -590,7 +590,7 @@ class AdditiveAttentionTest(tf.test.TestCase, parameterized.TestCase):\n     actual = attention_layer([q, v], mask=[None, v_mask])\n \n     expected_shape = [1, 2, 4]\n-    self.assertAllEqual(expected_shape, tf.compat.v1.shape(actual))\n+    self.assertAllEqual(expected_shape, tf.shape(actual))\n \n   def test_shape_no_scale(self):\n     # Query tensor of shape [1, 2, 4]\n@@ -605,7 +605,7 @@ class AdditiveAttentionTest(tf.test.TestCase, parameterized.TestCase):\n     actual = attention_layer([q, v], mask=[None, v_mask])\n \n     expected_shape = [1, 2, 4]\n-    self.assertAllEqual(expected_shape, tf.compat.v1.shape(actual))\n+    self.assertAllEqual(expected_shape, tf.shape(actual))\n \n   def test_shape_with_key(self):\n     # Query tensor of shape [1, 2, 4]\n@@ -624,7 +624,7 @@ class AdditiveAttentionTest(tf.test.TestCase, parameterized.TestCase):\n     actual = attention_layer([q, v, k], mask=[None, v_mask])\n \n     expected_shape = [1, 2, 4]\n-    self.assertAllEqual(expected_shape, tf.compat.v1.shape(actual))\n+    self.assertAllEqual(expected_shape, tf.shape(actual))\n \n   def test_multi_dim(self):\n     # Query tensor of shape [1, 1, 1]\n\n@@ -286,10 +286,10 @@ class GRUV2Test(keras_parameterized.TestCase):\n                         reset_after=True)\n       if time_major:\n         converted_input = keras.layers.Lambda(\n-            lambda t: tf.compat.v1.transpose(t, [1, 0, 2]))(inputs)\n+            lambda t: tf.transpose(t, [1, 0, 2]))(inputs)\n         outputs = layer(converted_input)\n         outputs = keras.layers.Lambda(\n-            lambda t: tf.compat.v1.transpose(t, [1, 0, 2]))(outputs)\n+            lambda t: tf.transpose(t, [1, 0, 2]))(outputs)\n       else:\n         outputs = layer(inputs)\n       return keras.models.Model(inputs, outputs)\n@@ -721,7 +721,7 @@ class GRUGraphRewriteTest(keras_parameterized.TestCase):\n     # TF model does not work with scalar model output, specially during\n     # aggregation.\n     runtime = keras.layers.Lambda(\n-        lambda x: tf.compat.v1.expand_dims(x, axis=-1))(runtime)\n+        lambda x: tf.expand_dims(x, axis=-1))(runtime)\n     model = keras.models.Model(inputs=inputs, outputs=[outputs, runtime])\n     self._test_runtime_with_model(model)\n \n@@ -743,7 +743,7 @@ class GRUGraphRewriteTest(keras_parameterized.TestCase):\n     # TF model does not work with scalar model output, specially during\n     # aggregation.\n     runtime = keras.layers.Lambda(\n-        lambda x: tf.compat.v1.expand_dims(x, axis=-1))(runtime)\n+        lambda x: tf.expand_dims(x, axis=-1))(runtime)\n     model = keras.models.Model(inputs=inputs, outputs=[outputs, runtime])\n \n     (x_train, y_train), _ = testing_utils.get_test_data(\n@@ -798,7 +798,7 @@ class GRUGraphRewriteTest(keras_parameterized.TestCase):\n     a = tf.constant(0)\n     b = tf.constant(1)\n     # Will always run the GRU layer.\n-    outputs, runtime = tf.compat.v1.cond(\n+    outputs, runtime = tf.cond(\n         tf.less(a, b),\n         lambda: layer(inputs),\n         lambda: (zeros, dummy_runtime))\n@@ -807,7 +807,7 @@ class GRUGraphRewriteTest(keras_parameterized.TestCase):\n     # TF model does not work with scalar model output, specially during\n     # aggregation.\n     runtime = keras.layers.Lambda(\n-        lambda x: tf.compat.v1.expand_dims(x, axis=-1))(runtime)\n+        lambda x: tf.expand_dims(x, axis=-1))(runtime)\n     model = keras.models.Model(inputs=inputs, outputs=[outputs, runtime])\n     self._test_runtime_with_model(model)\n \n\n@@ -804,7 +804,7 @@ def make_2d(tensor, split_dim):\n     Tensor of shape\n     `(d0 * ... * d(split_dim-1), d(split_dim) * ... * d(N-1))`.\n   \"\"\"\n-  shape = tf.compat.v1.shape(tensor)\n+  shape = tf.shape(tensor)\n   in_dims = shape[:split_dim]\n   out_dims = shape[split_dim:]\n \n\n@@ -440,10 +440,10 @@ class LSTMV2Test(keras_parameterized.TestCase):\n                         go_backwards=go_backwards)\n       if time_major:\n         converted_input = keras.layers.Lambda(\n-            lambda t: tf.compat.v1.transpose(t, [1, 0, 2]))(inputs)\n+            lambda t: tf.transpose(t, [1, 0, 2]))(inputs)\n         outputs = layer(converted_input)\n         outputs = keras.layers.Lambda(\n-            lambda t: tf.compat.v1.transpose(t, [1, 0, 2]))(outputs)\n+            lambda t: tf.transpose(t, [1, 0, 2]))(outputs)\n       else:\n         outputs = layer(inputs)\n       return keras.models.Model(inputs, outputs)\n@@ -899,7 +899,7 @@ class LSTMGraphRewriteTest(keras_parameterized.TestCase):\n     # TF model does not work with scalar model output, specially during\n     # aggregation.\n     runtime = keras.layers.Lambda(\n-        lambda x: tf.compat.v1.expand_dims(x, axis=-1))(runtime)\n+        lambda x: tf.expand_dims(x, axis=-1))(runtime)\n     model = keras.models.Model(inputs=inputs, outputs=[outputs, runtime])\n     self._test_runtime_with_model(model)\n \n@@ -921,7 +921,7 @@ class LSTMGraphRewriteTest(keras_parameterized.TestCase):\n     # TF model does not work with scalar model output, specially during\n     # aggregation.\n     runtime = keras.layers.Lambda(\n-        lambda x: tf.compat.v1.expand_dims(x, axis=-1))(runtime)\n+        lambda x: tf.expand_dims(x, axis=-1))(runtime)\n     model = keras.models.Model(inputs=inputs, outputs=[outputs, runtime])\n \n     (x_train, y_train), _ = testing_utils.get_test_data(\n@@ -976,7 +976,7 @@ class LSTMGraphRewriteTest(keras_parameterized.TestCase):\n     a = tf.constant(0)\n     b = tf.constant(1)\n     # Will always run the lstm layer.\n-    outputs, runtime = tf.compat.v1.cond(\n+    outputs, runtime = tf.cond(\n         tf.less(a, b),\n         lambda: layer(inputs),\n         lambda: (zeros, dummy_runtime))\n@@ -985,7 +985,7 @@ class LSTMGraphRewriteTest(keras_parameterized.TestCase):\n     # TF model does not work with scalar model output, specially during\n     # aggregation.\n     runtime = keras.layers.Lambda(\n-        lambda x: tf.compat.v1.expand_dims(x, axis=-1))(runtime)\n+        lambda x: tf.expand_dims(x, axis=-1))(runtime)\n     model = keras.models.Model(inputs=inputs, outputs=[outputs, runtime])\n     self._test_runtime_with_model(model)\n \n\n@@ -126,7 +126,7 @@ class _Merge(Layer):\n         for x in inputs:\n           x_ndim = backend.ndim(x)\n           for _ in range(max_ndim - x_ndim):\n-            x = tf.compat.v1.expand_dims(x, axis=1)\n+            x = tf.expand_dims(x, axis=1)\n           reshaped_inputs.append(x)\n         return self._merge_function(reshaped_inputs)\n       else:\n@@ -136,22 +136,22 @@ class _Merge(Layer):\n         for x in inputs:\n           x_ndim = backend.ndim(x)\n           if x_ndim is None:\n-            x_shape = tf.compat.v1.shape(x)\n+            x_shape = tf.shape(x)\n             batch_size = x_shape[0]\n             new_shape = backend.concatenate(\n                 [x_shape[1:],\n-                 tf.compat.v1.expand_dims(batch_size, axis=-1)])\n+                 tf.expand_dims(batch_size, axis=-1)])\n             x_transposed = tf.reshape(\n                 x,\n                 tf.stack(\n                     [batch_size, tf.reduce_prod(x_shape[1:])], axis=0))\n-            x_transposed = tf.compat.v1.transpose(x_transposed, perm=(1, 0))\n+            x_transposed = tf.transpose(x_transposed, perm=(1, 0))\n             x_transposed = tf.reshape(x_transposed, new_shape)\n             reshaped_inputs.append(x_transposed)\n             transposed = True\n           elif x_ndim > 1:\n             dims = list(range(1, x_ndim)) + [0]\n-            reshaped_inputs.append(tf.compat.v1.transpose(x, perm=dims))\n+            reshaped_inputs.append(tf.transpose(x, perm=dims))\n             transposed = True\n           else:\n             # We don't transpose inputs if they are 1D vectors or scalars.\n@@ -161,18 +161,18 @@ class _Merge(Layer):\n         if transposed:\n           # If inputs have been transposed, we have to transpose the output too.\n           if y_ndim is None:\n-            y_shape = tf.compat.v1.shape(y)\n-            y_ndim = tf.compat.v1.shape(y_shape)[0]\n+            y_shape = tf.shape(y)\n+            y_ndim = tf.shape(y_shape)[0]\n             batch_size = y_shape[y_ndim - 1]\n             new_shape = backend.concatenate([\n-                tf.compat.v1.expand_dims(batch_size, axis=-1), y_shape[:y_ndim - 1]\n+                tf.expand_dims(batch_size, axis=-1), y_shape[:y_ndim - 1]\n             ])\n             y = tf.reshape(y, (-1, batch_size))\n-            y = tf.compat.v1.transpose(y, perm=(1, 0))\n+            y = tf.transpose(y, perm=(1, 0))\n             y = tf.reshape(y, new_shape)\n           elif y_ndim > 1:\n             dims = [y_ndim - 1] + list(range(y_ndim - 1))\n-            y = tf.compat.v1.transpose(y, perm=dims)\n+            y = tf.transpose(y, perm=dims)\n         return y\n     else:\n       return self._merge_function(inputs)\n@@ -208,7 +208,7 @@ class _Merge(Layer):\n                        'should have the same length.')\n     if all(m is None for m in mask):\n       return None\n-    masks = [tf.compat.v1.expand_dims(m, axis=0) for m in mask if m is not None]\n+    masks = [tf.expand_dims(m, axis=0) for m in mask if m is not None]\n     return backend.all(\n         backend.concatenate(masks, axis=0), axis=0, keepdims=False)\n \n@@ -554,10 +554,10 @@ class Concatenate(_Merge):\n     for input_i, mask_i in zip(inputs, mask):\n       if mask_i is None:\n         # Input is unmasked. Append all 1s to masks,\n-        masks.append(tf.compat.v1.ones_like(input_i, dtype='bool'))\n+        masks.append(tf.ones_like(input_i, dtype='bool'))\n       elif backend.ndim(mask_i) < backend.ndim(input_i):\n         # Mask is smaller than the input, expand it\n-        masks.append(tf.compat.v1.expand_dims(mask_i, axis=-1))\n+        masks.append(tf.expand_dims(mask_i, axis=-1))\n       else:\n         masks.append(mask_i)\n     concatenated = backend.concatenate(masks, axis=self.axis)\n\n@@ -426,7 +426,7 @@ class MultiHeadAttention(Layer):\n       # (<batch_dims>, num_heads, <query_attention_dims, key_attention_dims>)\n       mask_expansion_axes = [-len(self._attention_axes) * 2 - 1]\n       for _ in range(len(attention_scores.shape) - len(attention_mask.shape)):\n-        attention_mask = tf.compat.v1.expand_dims(\n+        attention_mask = tf.expand_dims(\n             attention_mask, axis=mask_expansion_axes)\n     return self._softmax(attention_scores, attention_mask)\n \n\n@@ -61,7 +61,7 @@ class GaussianNoise(Layer):\n \n     def noised():\n       return inputs + backend.random_normal(\n-          shape=tf.compat.v1.shape(inputs),\n+          shape=tf.shape(inputs),\n           mean=0.,\n           stddev=self.stddev,\n           dtype=inputs.dtype)\n@@ -114,7 +114,7 @@ class GaussianDropout(Layer):\n       def noised():\n         stddev = np.sqrt(self.rate / (1.0 - self.rate))\n         return inputs * backend.random_normal(\n-            shape=tf.compat.v1.shape(inputs),\n+            shape=tf.shape(inputs),\n             mean=1.0,\n             stddev=stddev,\n             dtype=inputs.dtype)\n@@ -170,7 +170,7 @@ class AlphaDropout(Layer):\n     self.supports_masking = True\n \n   def _get_noise_shape(self, inputs):\n-    return self.noise_shape if self.noise_shape else tf.compat.v1.shape(inputs)\n+    return self.noise_shape if self.noise_shape else tf.shape(inputs)\n \n   def call(self, inputs, training=None):\n     if 0. < self.rate < 1.:\n\n@@ -433,7 +433,7 @@ class BatchNormalizationBase(Layer):\n           initializer=self.moving_mean_initializer,\n           synchronization=tf.VariableSynchronization.ON_READ,\n           trainable=False,\n-          aggregation=tf.compat.v1.VariableAggregation.MEAN,\n+          aggregation=tf.VariableAggregation.MEAN,\n           experimental_autocast=False)\n \n       self.moving_variance = self.add_weight(\n@@ -443,7 +443,7 @@ class BatchNormalizationBase(Layer):\n           initializer=self.moving_variance_initializer,\n           synchronization=tf.VariableSynchronization.ON_READ,\n           trainable=False,\n-          aggregation=tf.compat.v1.VariableAggregation.MEAN,\n+          aggregation=tf.VariableAggregation.MEAN,\n           experimental_autocast=False)\n \n       if self.renorm:\n@@ -462,7 +462,7 @@ class BatchNormalizationBase(Layer):\n               initializer=moving_stddev_initializer,\n               synchronization=tf.VariableSynchronization.ON_READ,\n               trainable=False,\n-              aggregation=tf.compat.v1.VariableAggregation.MEAN,\n+              aggregation=tf.VariableAggregation.MEAN,\n               experimental_autocast=False)\n \n         # Create variables to maintain the moving mean and standard deviation.\n@@ -483,7 +483,7 @@ class BatchNormalizationBase(Layer):\n               initializer=initializer,\n               synchronization=tf.VariableSynchronization.ON_READ,\n               trainable=False,\n-              aggregation=tf.compat.v1.VariableAggregation.MEAN,\n+              aggregation=tf.VariableAggregation.MEAN,\n               experimental_autocast=False)\n           return var\n \n@@ -509,7 +509,7 @@ class BatchNormalizationBase(Layer):\n         decay = tf.cast(decay, variable.dtype.base_dtype)\n       update_delta = (variable - tf.cast(value, variable.dtype)) * decay\n       if inputs_size is not None:\n-        update_delta = tf.compat.v1.where(inputs_size > 0, update_delta,\n+        update_delta = tf.where(inputs_size > 0, update_delta,\n                                 backend.zeros_like(update_delta))\n       return update_delta\n \n@@ -539,7 +539,7 @@ class BatchNormalizationBase(Layer):\n     if self._support_zero_size_input():\n       # Keras assumes that batch dimension is the first dimension for Batch\n       # Normalization.\n-      input_batch_size = tf.compat.v1.shape(inputs)[0]\n+      input_batch_size = tf.shape(inputs)[0]\n     else:\n       input_batch_size = None\n \n@@ -564,7 +564,7 @@ class BatchNormalizationBase(Layer):\n       if self._bessels_correction_test_only:\n         return variance\n       sample_size = tf.cast(\n-          tf.compat.v1.size(inputs) / tf.compat.v1.size(variance), variance.dtype)\n+          tf.size(inputs) / tf.size(variance), variance.dtype)\n       if remove:\n         factor = (sample_size -\n                   tf.cast(1.0, variance.dtype)) / sample_size\n@@ -651,8 +651,7 @@ class BatchNormalizationBase(Layer):\n     # initialized with this batch's moments.\n     renorm_mean = self.renorm_mean\n     # Avoid divide by zero early on in training.\n-    renorm_stddev = tf.maximum(self.renorm_stddev,\n-                                     tf.sqrt(self.epsilon))\n+    renorm_stddev = tf.maximum(self.renorm_stddev, tf.sqrt(self.epsilon))\n     # Compute the corrections for batch renorm.\n     r = stddev / renorm_stddev\n     d = (mean - renorm_mean) / renorm_stddev\n@@ -672,9 +671,9 @@ class BatchNormalizationBase(Layer):\n       d = tf.minimum(d, dmax)\n     # When not training, use r=1, d=0.\n     r = control_flow_util.smart_cond(training, lambda: r,\n-                                     lambda: tf.compat.v1.ones_like(r))\n+                                     lambda: tf.ones_like(r))\n     d = control_flow_util.smart_cond(training, lambda: d,\n-                                     lambda: tf.compat.v1.zeros_like(d))\n+                                     lambda: tf.zeros_like(d))\n \n     def _update_renorm_variable(var, value, inputs_size):\n       \"\"\"Updates a moving average and weight, returns the unbiased value.\"\"\"\n@@ -705,7 +704,7 @@ class BatchNormalizationBase(Layer):\n     return (r, d, out_mean, out_variance)\n \n   def _calculate_mean_and_var(self, inputs, reduction_axes, keep_dims):\n-    return tf.compat.v1.nn.moments(inputs, reduction_axes, keep_dims=keep_dims)\n+    return tf.nn.moments(inputs, reduction_axes, keepdims=keep_dims)\n \n   def _moments(self, inputs, reduction_axes, keep_dims):\n     mean, variance = self._calculate_mean_and_var(inputs, reduction_axes,\n@@ -713,10 +712,9 @@ class BatchNormalizationBase(Layer):\n     # TODO(b/129279393): Support zero batch input in non DistributionStrategy\n     # code as well.\n     if self._support_zero_size_input():\n-      input_batch_size = tf.compat.v1.shape(inputs)[0]\n-      mean = tf.compat.v1.where(input_batch_size > 0, mean,\n-                             backend.zeros_like(mean))\n-      variance = tf.compat.v1.where(input_batch_size > 0, variance,\n+      input_batch_size = tf.shape(inputs)[0]\n+      mean = tf.where(input_batch_size > 0, mean, backend.zeros_like(mean))\n+      variance = tf.where(input_batch_size > 0, variance,\n                           backend.zeros_like(variance))\n     return mean, variance\n \n@@ -738,14 +736,13 @@ class BatchNormalizationBase(Layer):\n     if self.virtual_batch_size is not None:\n       # Virtual batches (aka ghost batches) can be simulated by reshaping the\n       # Tensor and reusing the existing batch norm implementation\n-      original_shape = tf.compat.v1.shape(inputs)\n+      original_shape = tf.shape(inputs)\n       original_shape = tf.concat(\n           [tf.constant([-1]), original_shape[1:]], axis=0)\n       expanded_shape = tf.concat([\n           tf.constant([self.virtual_batch_size, -1]),\n           original_shape[1:]\n-      ],\n-                                        axis=0)\n+      ], axis=0)\n \n       # Will cause errors if virtual_batch_size does not divide the batch size\n       inputs = tf.reshape(inputs, expanded_shape)\n@@ -803,12 +800,12 @@ class BatchNormalizationBase(Layer):\n       mean, variance = self.moving_mean, self.moving_variance\n     else:\n       if self.adjustment:\n-        adj_scale, adj_bias = self.adjustment(tf.compat.v1.shape(inputs))\n+        adj_scale, adj_bias = self.adjustment(tf.shape(inputs))\n         # Adjust only during training.\n         adj_scale = control_flow_util.smart_cond(\n-            training, lambda: adj_scale, lambda: tf.compat.v1.ones_like(adj_scale))\n+            training, lambda: adj_scale, lambda: tf.ones_like(adj_scale))\n         adj_bias = control_flow_util.smart_cond(\n-            training, lambda: adj_bias, lambda: tf.compat.v1.zeros_like(adj_bias))\n+            training, lambda: adj_bias, lambda: tf.zeros_like(adj_bias))\n         scale, offset = _compose_transforms(adj_scale, adj_bias, scale, offset)\n \n       # Some of the computations here are not necessary when training==False\n@@ -843,7 +840,7 @@ class BatchNormalizationBase(Layer):\n       if self._support_zero_size_input():\n         # Keras assumes that batch dimension is the first dimension for Batch\n         # Normalization.\n-        input_batch_size = tf.compat.v1.shape(inputs)[0]\n+        input_batch_size = tf.shape(inputs)[0]\n       else:\n         input_batch_size = None\n \n@@ -916,32 +913,21 @@ class BatchNormalizationBase(Layer):\n \n   def get_config(self):\n     config = {\n-        'axis':\n-            self.axis,\n-        'momentum':\n-            self.momentum,\n-        'epsilon':\n-            self.epsilon,\n-        'center':\n-            self.center,\n-        'scale':\n-            self.scale,\n-        'beta_initializer':\n-            initializers.serialize(self.beta_initializer),\n-        'gamma_initializer':\n-            initializers.serialize(self.gamma_initializer),\n+        'axis': self.axis,\n+        'momentum': self.momentum,\n+        'epsilon': self.epsilon,\n+        'center': self.center,\n+        'scale': self.scale,\n+        'beta_initializer': initializers.serialize(self.beta_initializer),\n+        'gamma_initializer': initializers.serialize(self.gamma_initializer),\n         'moving_mean_initializer':\n             initializers.serialize(self.moving_mean_initializer),\n         'moving_variance_initializer':\n             initializers.serialize(self.moving_variance_initializer),\n-        'beta_regularizer':\n-            regularizers.serialize(self.beta_regularizer),\n-        'gamma_regularizer':\n-            regularizers.serialize(self.gamma_regularizer),\n-        'beta_constraint':\n-            constraints.serialize(self.beta_constraint),\n-        'gamma_constraint':\n-            constraints.serialize(self.gamma_constraint)\n+        'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n+        'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n+        'beta_constraint': constraints.serialize(self.beta_constraint),\n+        'gamma_constraint': constraints.serialize(self.gamma_constraint)\n     }\n     # Only add TensorFlow-specific parameters if they are set, so as to preserve\n     # model compatibility with external Keras.\n@@ -1114,8 +1100,8 @@ class SyncBatchNormalization(BatchNormalizationBase):\n             keepdims=True,\n             name='variance')\n       if not keep_dims:\n-        mean = tf.compat.v1.squeeze(mean, axes)\n-        variance = tf.compat.v1.squeeze(variance, axes)\n+        mean = tf.squeeze(mean, axes)\n+        variance = tf.squeeze(variance, axes)\n       if x.dtype == tf.float16:\n         return (tf.cast(mean, tf.float16),\n                 tf.cast(variance, tf.float16))\n\n@@ -280,7 +280,7 @@ class LayerNormalization(Layer):\n         inputs = tf.cast(inputs, 'float32')\n \n       # Calculate the moments on the last axis (layer activations).\n-      mean, variance = tf.compat.v1.nn.moments(inputs, self.axis, keep_dims=True)\n+      mean, variance = tf.nn.moments(inputs, self.axis, keepdims=True)\n \n       scale, offset = _broadcast(self.gamma), _broadcast(self.beta)\n \n@@ -297,7 +297,7 @@ class LayerNormalization(Layer):\n       # Collapse dims before self.axis, and dims in self.axis\n       pre_dim, in_dim = (1, 1)\n       axis = sorted(self.axis)\n-      tensor_shape = tf.compat.v1.shape(inputs)\n+      tensor_shape = tf.shape(inputs)\n       for dim in range(0, ndims):\n         dim_tensor = tensor_shape[dim]\n         if dim < axis[0]:\n\n@@ -64,14 +64,14 @@ class Pooling1D(Layer):\n \n   def call(self, inputs):\n     pad_axis = 2 if self.data_format == 'channels_last' else 3\n-    inputs = tf.compat.v1.expand_dims(inputs, pad_axis)\n+    inputs = tf.expand_dims(inputs, pad_axis)\n     outputs = self.pool_function(\n         inputs,\n         self.pool_size + (1,),\n         strides=self.strides + (1,),\n         padding=self.padding,\n         data_format=self.data_format)\n-    return tf.compat.v1.squeeze(outputs, pad_axis)\n+    return tf.squeeze(outputs, pad_axis)\n \n   def compute_output_shape(self, input_shape):\n     input_shape = tf.TensorShape(input_shape).as_list()\n@@ -636,7 +636,7 @@ class AveragePooling2D(Pooling2D):\n                data_format=None,\n                **kwargs):\n     super(AveragePooling2D, self).__init__(\n-        tf.compat.v1.nn.avg_pool,\n+        tf.nn.avg_pool,\n         pool_size=pool_size, strides=strides,\n         padding=padding, data_format=data_format, **kwargs)\n \n@@ -691,7 +691,7 @@ class Pooling3D(Layer):\n       # TF does not support `channels_first` with 3D pooling operations,\n       # so we must handle this case manually.\n       # TODO(fchollet): remove this when TF pooling is feature-complete.\n-      inputs = tf.compat.v1.transpose(inputs, (0, 2, 3, 4, 1))\n+      inputs = tf.transpose(inputs, (0, 2, 3, 4, 1))\n \n     outputs = self.pool_function(\n         inputs,\n@@ -700,7 +700,7 @@ class Pooling3D(Layer):\n         padding=self.padding.upper())\n \n     if self.data_format == 'channels_first':\n-      outputs = tf.compat.v1.transpose(outputs, (0, 4, 1, 2, 3))\n+      outputs = tf.transpose(outputs, (0, 4, 1, 2, 3))\n     return outputs\n \n   def compute_output_shape(self, input_shape):\n@@ -970,7 +970,7 @@ class GlobalAveragePooling1D(GlobalPooling1D):\n     steps_axis = 1 if self.data_format == 'channels_last' else 2\n     if mask is not None:\n       mask = tf.cast(mask, inputs[0].dtype)\n-      mask = tf.compat.v1.expand_dims(\n+      mask = tf.expand_dims(\n           mask, 2 if self.data_format == 'channels_last' else 1)\n       inputs *= mask\n       return backend.sum(\n\n@@ -52,7 +52,7 @@ class BenchmarkAdapt(tf.test.Benchmark):\n     for _ in range(num_repeats):\n       ds = tf.data.Dataset.range(num_elements)\n       ds = ds.map(\n-          lambda x: tf.compat.v1.expand_dims(tf.cast(x, tf.float32), -1))\n+          lambda x: tf.expand_dims(tf.cast(x, tf.float32), -1))\n       ds = ds.batch(batch_size)\n \n       starts.append(time.time())\n@@ -79,7 +79,7 @@ class BenchmarkAdapt(tf.test.Benchmark):\n     for _ in range(num_repeats):\n       ds = tf.data.Dataset.range(num_elements)\n       ds = ds.map(\n-          lambda x: tf.compat.v1.expand_dims(tf.cast(x, tf.float32), -1))\n+          lambda x: tf.expand_dims(tf.cast(x, tf.float32), -1))\n       ds = ds.batch(batch_size)\n \n       starts.append(time.time())\n\n@@ -33,7 +33,7 @@ BATCH_SIZE = 32\n \n def rotate(inputs):\n   \"\"\"rotate image.\"\"\"\n-  inputs_shape = tf.compat.v1.shape(inputs)\n+  inputs_shape = tf.shape(inputs)\n   batch_size = inputs_shape[0]\n   img_hd = tf.cast(inputs_shape[1], tf.float32)\n   img_wd = tf.cast(inputs_shape[2], tf.float32)\n@@ -47,7 +47,7 @@ def rotate(inputs):\n \n def zoom(inputs):\n   \"\"\"zoom image.\"\"\"\n-  inputs_shape = tf.compat.v1.shape(inputs)\n+  inputs_shape = tf.shape(inputs)\n   batch_size = inputs_shape[0]\n   img_hd = tf.cast(inputs_shape[1], tf.float32)\n   img_wd = tf.cast(inputs_shape[2], tf.float32)\n\n@@ -32,11 +32,11 @@ def reduce_fn(state, values):\n   # If this is the first iteration, we pick the first value to be 'k',\n   # which helps with precision - we assume that k is close to an average\n   # value and calculate mean and variance with respect to that.\n-  k = tf.compat.v1.cond(tf.equal(n, 0), lambda: values[0], lambda: k)\n+  k = tf.cond(tf.equal(n, 0), lambda: values[0], lambda: k)\n \n   sum_v = tf.reduce_sum(values, axis=0)\n   sum_v2 = tf.reduce_sum(tf.square(values), axis=0)\n-  ones = tf.compat.v1.ones_like(values, dtype=tf.int32)\n+  ones = tf.ones_like(values, dtype=tf.int32)\n   batch_size = tf.reduce_sum(ones, axis=0)\n   batch_size_f = tf.cast(batch_size, tf.float32)\n \n@@ -62,7 +62,7 @@ class BenchmarkAdapt(tf.test.Benchmark):\n     for _ in range(num_repeats):\n       ds = tf.data.Dataset.range(num_elements)\n       ds = ds.map(\n-          lambda x: tf.compat.v1.expand_dims(tf.cast(x, tf.float32), -1))\n+          lambda x: tf.expand_dims(tf.cast(x, tf.float32), -1))\n       ds = ds.batch(batch_size)\n \n       starts.append(time.time())\n@@ -90,7 +90,7 @@ class BenchmarkAdapt(tf.test.Benchmark):\n     for _ in range(num_repeats):\n       ds = tf.data.Dataset.range(num_elements)\n       ds = ds.map(\n-          lambda x: tf.compat.v1.expand_dims(tf.cast(x, tf.float32), -1))\n+          lambda x: tf.expand_dims(tf.cast(x, tf.float32), -1))\n       ds = ds.batch(batch_size)\n \n       starts.append(time.time())\n\n@@ -43,7 +43,7 @@ def embedding_varlen(batch_size, max_length):\n       shape=(None,), ragged=True, name=\"weight\", dtype=tf.float32)\n   embedded_data = keras.layers.Embedding(embedding_size, 256)(data_input)\n   weighted_embedding = tf.multiply(\n-      embedded_data, tf.compat.v1.expand_dims(weight_input, -1))\n+      embedded_data, tf.expand_dims(weight_input, -1))\n   reduced_embedding = tf.reduce_sum(weighted_embedding, axis=1)\n   model = keras.Model([data_input, weight_input], reduced_embedding)\n \n\n@@ -134,7 +134,7 @@ class CategoryCrossing(base_layer.Layer):\n     if isinstance(inp, (list, tuple, np.ndarray)):\n       inp = tf.convert_to_tensor(inp)\n     if inp.shape.rank == 1:\n-      inp = tf.compat.v1.expand_dims(inp, axis=-1)\n+      inp = tf.expand_dims(inp, axis=-1)\n     return inp\n \n   def call(self, inputs):\n\n@@ -179,7 +179,7 @@ class CategoryEncoding(base_layer.Layer):\n       if tf_utils.is_sparse(inputs):\n         return tf.sparse.expand_dims(inputs, axis)\n       else:\n-        return tf.compat.v1.expand_dims(inputs, axis)\n+        return tf.expand_dims(inputs, axis)\n \n     original_shape = inputs.shape\n     # In all cases, we should uprank scalar input to a single sample.\n@@ -241,7 +241,7 @@ def sparse_bincount(inputs, out_depth, binary_output, count_weights=None):\n     output_shape = (out_depth,)\n   else:\n     result = tf.cast(result, backend.floatx())\n-    batch_size = tf.compat.v1.shape(result)[0]\n+    batch_size = tf.shape(result)[0]\n     output_shape = (batch_size, out_depth)\n   result = tf.SparseTensor(\n       indices=result.indices,\n\n@@ -46,13 +46,13 @@ def summarize(values, epsilon):\n \n   values = tf.reshape(values, [-1])\n   values = tf.sort(values)\n-  elements = tf.cast(tf.compat.v1.size(values), tf.float32)\n+  elements = tf.cast(tf.size(values), tf.float32)\n   num_buckets = 1. / epsilon\n   increment = tf.cast(elements / num_buckets, tf.int32)\n   start = increment\n   step = tf.maximum(increment, 1)\n   boundaries = values[start::step]\n-  weights = tf.compat.v1.ones_like(boundaries)\n+  weights = tf.ones_like(boundaries)\n   weights = weights * tf.cast(step, tf.float32)\n   return tf.stack([boundaries, weights])\n \n\n@@ -174,8 +174,8 @@ class Hashing(base_layer.Layer):\n       values = tf.as_string(values)\n     values = str_to_hash_bucket(values, num_available_bins, name='hash')\n     if mask is not None:\n-      values = tf.add(values, tf.compat.v1.ones_like(values))\n-      values = tf.compat.v1.where(mask, tf.compat.v1.zeros_like(values), values)\n+      values = tf.add(values, tf.ones_like(values))\n+      values = tf.where(mask, tf.zeros_like(values), values)\n     return values\n \n   def _get_string_to_hash_bucket_fn(self):\n\n@@ -146,7 +146,7 @@ class CenterCrop(base_layer.Layer):\n \n   def call(self, inputs):\n     inputs = tf.convert_to_tensor(inputs)\n-    inputs_shape = tf.compat.v1.shape(inputs)\n+    inputs_shape = tf.shape(inputs)\n     unbatched = inputs.shape.rank == 3\n     img_hd = inputs_shape[H_AXIS]\n     img_wd = inputs_shape[W_AXIS]\n@@ -154,12 +154,12 @@ class CenterCrop(base_layer.Layer):\n     img_wd_diff = img_wd - self.target_width\n     checks = []\n     checks.append(\n-        tf.compat.v1.assert_non_negative(\n+        tf.debugging.assert_non_negative(\n             img_hd_diff,\n             message='The crop height {} should not be greater than input '\n             'height.'.format(self.target_height)))\n     checks.append(\n-        tf.compat.v1.assert_non_negative(\n+        tf.debugging.assert_non_negative(\n             img_wd_diff,\n             message='The crop width {} should not be greater than input '\n             'width.'.format(self.target_width)))\n@@ -232,7 +232,7 @@ class RandomCrop(base_layer.Layer):\n \n     def random_cropped_inputs():\n       \"\"\"Cropped inputs with stateless random ops.\"\"\"\n-      shape = tf.compat.v1.shape(inputs)\n+      shape = tf.shape(inputs)\n       if unbatched:\n         crop_size = tf.stack([self.height, self.width, shape[-1]])\n       else:\n@@ -243,7 +243,7 @@ class RandomCrop(base_layer.Layer):\n       with tf.control_dependencies([check]):\n         limit = shape - crop_size + 1\n         offset = stateless_random_ops.stateless_random_uniform(\n-            tf.compat.v1.shape(shape),\n+            tf.shape(shape),\n             dtype=crop_size.dtype,\n             maxval=crop_size.dtype.max,\n             seed=self._rng.make_seeds()[:, 0]) % limit\n@@ -252,7 +252,7 @@ class RandomCrop(base_layer.Layer):\n     # TODO(b/143885775): Share logic with Resize and CenterCrop.\n     def resize_and_center_cropped_inputs():\n       \"\"\"Deterministically resize to shorter side and center crop.\"\"\"\n-      input_shape = tf.compat.v1.shape(inputs)\n+      input_shape = tf.shape(inputs)\n       input_height_t = input_shape[H_AXIS]\n       input_width_t = input_shape[W_AXIS]\n       ratio_cond = (input_height_t / input_width_t > (self.height / self.width))\n@@ -550,7 +550,7 @@ class RandomTranslation(base_layer.Layer):\n \n     def random_translated_inputs():\n       \"\"\"Translated inputs with random ops.\"\"\"\n-      inputs_shape = tf.compat.v1.shape(inputs)\n+      inputs_shape = tf.shape(inputs)\n       batch_size = inputs_shape[0]\n       img_hd = tf.cast(inputs_shape[H_AXIS], tf.float32)\n       img_wd = tf.cast(inputs_shape[W_AXIS], tf.float32)\n@@ -612,7 +612,7 @@ def get_translation_matrix(translations, name=None):\n       to `transform`.\n   \"\"\"\n   with backend.name_scope(name or 'translation_matrix'):\n-    num_translations = tf.compat.v1.shape(translations)[0]\n+    num_translations = tf.shape(translations)[0]\n     # The translation matrix looks like:\n     #     [[1 0 -dx]\n     #      [0 1 -dy]\n@@ -696,7 +696,7 @@ def transform(images,\n   \"\"\"\n   with backend.name_scope(name or 'transform'):\n     if output_shape is None:\n-      output_shape = tf.compat.v1.shape(images)[1:3]\n+      output_shape = tf.shape(images)[1:3]\n       if not tf.executing_eagerly():\n         output_shape_value = tf.get_static_value(output_shape)\n         if output_shape_value is not None:\n@@ -748,7 +748,7 @@ def get_rotation_matrix(angles, image_height, image_width, name=None):\n     y_offset = ((image_height - 1) - (tf.sin(angles) *\n                                       (image_width - 1) + tf.cos(angles) *\n                                       (image_height - 1))) / 2.0\n-    num_angles = tf.compat.v1.shape(angles)[0]\n+    num_angles = tf.shape(angles)[0]\n     return tf.concat(\n         values=[\n             tf.cos(angles)[:, None],\n@@ -845,7 +845,7 @@ class RandomRotation(base_layer.Layer):\n \n     def random_rotated_inputs():\n       \"\"\"Rotated inputs with random ops.\"\"\"\n-      inputs_shape = tf.compat.v1.shape(inputs)\n+      inputs_shape = tf.shape(inputs)\n       batch_size = inputs_shape[0]\n       img_hd = tf.cast(inputs_shape[H_AXIS], tf.float32)\n       img_wd = tf.cast(inputs_shape[W_AXIS], tf.float32)\n@@ -992,7 +992,7 @@ class RandomZoom(base_layer.Layer):\n \n     def random_zoomed_inputs():\n       \"\"\"Zoomed inputs with random ops.\"\"\"\n-      inputs_shape = tf.compat.v1.shape(inputs)\n+      inputs_shape = tf.shape(inputs)\n       batch_size = inputs_shape[0]\n       img_hd = tf.cast(inputs_shape[H_AXIS], tf.float32)\n       img_wd = tf.cast(inputs_shape[W_AXIS], tf.float32)\n@@ -1060,7 +1060,7 @@ def get_zoom_matrix(zooms, image_height, image_width, name=None):\n        where `k = c0 x + c1 y + 1`.\n   \"\"\"\n   with backend.name_scope(name or 'zoom_matrix'):\n-    num_zooms = tf.compat.v1.shape(zooms)[0]\n+    num_zooms = tf.shape(zooms)[0]\n     # The zoom matrix looks like:\n     #     [[zx 0 0]\n     #      [0 zy 0]\n@@ -1216,7 +1216,7 @@ class RandomHeight(base_layer.Layer):\n \n     def random_height_inputs():\n       \"\"\"Inputs height-adjusted with random ops.\"\"\"\n-      inputs_shape = tf.compat.v1.shape(inputs)\n+      inputs_shape = tf.shape(inputs)\n       img_hd = tf.cast(inputs_shape[H_AXIS], tf.float32)\n       img_wd = inputs_shape[W_AXIS]\n       height_factor = self._rng.uniform(\n@@ -1314,7 +1314,7 @@ class RandomWidth(base_layer.Layer):\n \n     def random_width_inputs():\n       \"\"\"Inputs width-adjusted with random ops.\"\"\"\n-      inputs_shape = tf.compat.v1.shape(inputs)\n+      inputs_shape = tf.shape(inputs)\n       img_hd = inputs_shape[H_AXIS]\n       img_wd = tf.cast(inputs_shape[W_AXIS], tf.float32)\n       width_factor = self._rng.uniform(\n\n@@ -271,7 +271,7 @@ class IndexLookup(base_preprocessing_layer.CombinerPreprocessingLayer):\n         # the actual data.\n         initializer = _NullInitializer(self._key_dtype, self._value_dtype)\n       else:\n-        if not tf.compat.v1.gfile.Exists(vocabulary):\n+        if not tf.io.gfile.exists(vocabulary):\n           raise ValueError(\"Vocabulary file %s does not exist.\" % (vocabulary,))\n         self._static_vocabulary_path = vocabulary\n         num_tokens = table_utils.num_tokens_in_file(vocabulary)\n@@ -319,7 +319,7 @@ class IndexLookup(base_preprocessing_layer.CombinerPreprocessingLayer):\n       if not self.pad_to_max_tokens or max_tokens is None:\n         initializer = lambda shape, dtype: [0]\n       else:\n-        initializer = tf.compat.v1.zeros_initializer\n+        initializer = \"zeros\"\n \n       # We are adding these here instead of in build() since they do not depend\n       # on the input shape at all.\n@@ -653,13 +653,13 @@ class IndexLookup(base_preprocessing_layer.CombinerPreprocessingLayer):\n         input_values = self._expand_dims(input_values, -1)\n         lookup_values = self._expand_dims(lookup_values, -1)\n       oov_indices = tf.where(tf.equal(lookup_values, -1))\n-      oov_inputs = tf.compat.v1.gather_nd(input_values, oov_indices)\n+      oov_inputs = tf.gather_nd(input_values, oov_indices)\n       msg = tf.strings.format(\n           \"When `num_oov_indices=0` all inputs should be in vocabulary, \"\n           \"found OOV values {}, consider setting `num_oov_indices=1`.\",\n           (oov_inputs,))\n       assertion = tf.Assert(\n-          tf.equal(tf.compat.v1.size(oov_indices), 0), [msg])\n+          tf.equal(tf.size(oov_indices), 0), [msg])\n       lookup_checks.append(assertion)\n \n     with tf.control_dependencies(lookup_checks):\n\n@@ -2148,7 +2148,7 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n     # TODO(b/149526183): Can't clear session when TF2 is disabled.\n     if tf.__internal__.tf2.enabled():\n       keras.backend.clear_session()\n-    tf.compat.v1.gfile.Remove(vocab_file)\n+    tf.io.gfile.remove(vocab_file)\n \n     loaded_model = keras.models.load_model(\n         output_path, custom_objects={\"IndexLookup\": index_lookup.IndexLookup})\n@@ -2219,7 +2219,7 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n     # TODO(b/149526183): Can't clear session when TF2 is disabled.\n     if tf.__internal__.tf2.enabled():\n       keras.backend.clear_session()\n-    tf.compat.v1.gfile.Remove(vocab_file)\n+    tf.io.gfile.remove(vocab_file)\n \n     loaded_model = keras.models.load_model(\n         output_path, custom_objects={\"IndexLookup\": index_lookup.IndexLookup})\n@@ -2291,7 +2291,7 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n     # TODO(b/149526183): Can't clear session when TF2 is disabled.\n     if tf.__internal__.tf2.enabled():\n       keras.backend.clear_session()\n-    tf.compat.v1.gfile.Remove(vocab_file)\n+    tf.io.gfile.remove(vocab_file)\n \n     loaded_model = keras.models.load_model(\n         output_path, custom_objects={\"IndexLookup\": index_lookup.IndexLookup})\n\n@@ -162,19 +162,19 @@ class Normalization(base_preprocessing_layer.PreprocessingLayer):\n           name='mean',\n           shape=mean_and_var_shape,\n           dtype=self.dtype,\n-          initializer=tf.compat.v1.zeros_initializer,\n+          initializer='zeros',\n           trainable=False)\n       self.adapt_variance = self.add_weight(\n           name='variance',\n           shape=mean_and_var_shape,\n           dtype=self.dtype,\n-          initializer=tf.compat.v1.ones_initializer,\n+          initializer='ones',\n           trainable=False)\n       self.count = self.add_weight(\n           name='count',\n           shape=(),\n           dtype=tf.int64,\n-          initializer=tf.compat.v1.zeros_initializer,\n+          initializer='zeros',\n           trainable=False)\n       self.finalize_state()\n     else:\n@@ -200,9 +200,9 @@ class Normalization(base_preprocessing_layer.PreprocessingLayer):\n     data = self._standardize_inputs(data)\n     data = tf.cast(data, self.adapt_mean.dtype)\n     batch_mean, batch_variance = tf.nn.moments(data, axes=self._reduce_axis)\n-    batch_shape = tf.compat.v1.shape(data, out_type=self.count.dtype)\n+    batch_shape = tf.shape(data, out_type=self.count.dtype)\n     if self._reduce_axis:\n-      batch_reduce_shape = tf.compat.v1.gather(batch_shape, self._reduce_axis)\n+      batch_reduce_shape = tf.gather(batch_shape, self._reduce_axis)\n       batch_count = tf.reduce_prod(batch_reduce_shape)\n     else:\n       batch_count = 1\n@@ -228,9 +228,9 @@ class Normalization(base_preprocessing_layer.PreprocessingLayer):\n     if self.input_mean is not None or not self.built:\n       return\n \n-    self.adapt_mean.assign(tf.compat.v1.zeros_like(self.adapt_mean))\n-    self.adapt_variance.assign(tf.compat.v1.ones_like(self.adapt_variance))\n-    self.count.assign(tf.compat.v1.zeros_like(self.count))\n+    self.adapt_mean.assign(tf.zeros_like(self.adapt_mean))\n+    self.adapt_variance.assign(tf.ones_like(self.adapt_variance))\n+    self.count.assign(tf.zeros_like(self.count))\n \n   def finalize_state(self):\n     if self.input_mean is not None or not self.built:\n\n@@ -81,7 +81,7 @@ class Reduction(Layer):\n     # TODO(momernick): Add checks for this and a decent error message if the\n     # weight shape isn't compatible.\n     if weights.shape.rank + 1 == inputs.shape.rank:\n-      weights = tf.compat.v1.expand_dims(weights, -1)\n+      weights = tf.expand_dims(weights, -1)\n \n     weighted_inputs = tf.multiply(inputs, weights)\n \n\n@@ -82,10 +82,10 @@ class TableHandler(object):\n       oov_indices = tf.strings.to_hash_bucket_fast(\n           inputs, num_buckets=num_oov_elements)\n \n-    oov_values = tf.compat.v1.gather(self.oov_tokens, oov_indices)\n+    oov_values = tf.gather(self.oov_tokens, oov_indices)\n     oov_locations = tf.equal(lookups, self.table._default_value)  # pylint: disable=protected-access\n \n-    return tf.compat.v1.where(oov_locations, oov_values, lookups)\n+    return tf.where(oov_locations, oov_values, lookups)\n \n   def _lookup_and_mask(self, inputs):\n     \"\"\"Return a lookup with any location with the mask_token masked to 0.\"\"\"\n\n@@ -373,7 +373,7 @@ class TextVectorization(base_preprocessing_layer.CombinerPreprocessingLayer):\n \n     if isinstance(data, tf.Tensor):\n       if data.shape.rank == 1:\n-        data = tf.compat.v1.expand_dims(data, axis=-1)\n+        data = tf.expand_dims(data, axis=-1)\n       self.build(data.shape)\n       preprocessed_inputs = self._preprocess(data)\n     elif isinstance(data, tf.data.Dataset):\n@@ -383,10 +383,10 @@ class TextVectorization(base_preprocessing_layer.CombinerPreprocessingLayer):\n         raise ValueError(\"The dataset passed to 'adapt' must contain a single \"\n                          \"tensor value.\")\n       if shape.rank == 0:\n-        data = data.map(lambda tensor: tf.compat.v1.expand_dims(tensor, 0))\n+        data = data.map(lambda tensor: tf.expand_dims(tensor, 0))\n         shape = tf.compat.v1.data.get_output_shapes(data)\n       if shape.rank == 1:\n-        data = data.map(lambda tensor: tf.compat.v1.expand_dims(tensor, -1))\n+        data = data.map(lambda tensor: tf.expand_dims(tensor, -1))\n       self.build(tf.compat.v1.data.get_output_shapes(data))\n       preprocessed_inputs = data.map(self._preprocess)\n     else:\n@@ -515,7 +515,7 @@ class TextVectorization(base_preprocessing_layer.CombinerPreprocessingLayer):\n       # so can be squeezed out. We do this here instead of after splitting for\n       # performance reasons - it's more expensive to squeeze a ragged tensor.\n       if inputs.shape.ndims > 1:\n-        inputs = tf.compat.v1.squeeze(inputs, axis=-1)\n+        inputs = tf.squeeze(inputs, axis=-1)\n       if self._split == SPLIT_ON_WHITESPACE:\n         # This treats multiple whitespaces as one whitespace, and strips leading\n         # and trailing whitespace.\n@@ -565,6 +565,6 @@ class TextVectorization(base_preprocessing_layer.CombinerPreprocessingLayer):\n \n       padding, _ = tf.required_space_to_batch_paddings(\n           output_tensor.shape, output_shape)\n-      return tf.compat.v1.pad(output_tensor, padding)\n+      return tf.pad(output_tensor, padding)\n \n     return lookup_data\n\n@@ -634,7 +634,7 @@ class RNN(Layer):\n       # batch size and dtype.\n       inputs = tf.nest.flatten(inputs)[0]\n \n-    input_shape = tf.compat.v1.shape(inputs)\n+    input_shape = tf.shape(inputs)\n     batch_size = input_shape[1] if self.time_major else input_shape[0]\n     dtype = inputs.dtype\n     if get_initial_state_fn:\n@@ -1150,14 +1150,14 @@ class DropoutRNNCellMixin(object):\n \n   def _create_dropout_mask(self, inputs, training, count=1):\n     return _generate_dropout_mask(\n-        tf.compat.v1.ones_like(inputs),\n+        tf.ones_like(inputs),\n         self.dropout,\n         training=training,\n         count=count)\n \n   def _create_recurrent_dropout_mask(self, inputs, training, count=1):\n     return _generate_dropout_mask(\n-        tf.compat.v1.ones_like(inputs),\n+        tf.ones_like(inputs),\n         self.recurrent_dropout,\n         training=training,\n         count=count)\n@@ -2993,7 +2993,7 @@ def _is_multiple_state(state_size):\n \n def _generate_zero_filled_state_for_cell(cell, inputs, batch_size, dtype):\n   if inputs is not None:\n-    batch_size = tf.compat.v1.shape(inputs)[0]\n+    batch_size = tf.shape(inputs)[0]\n     dtype = inputs.dtype\n   return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\n \n\n@@ -273,7 +273,7 @@ class RNNTest(keras_parameterized.TestCase):\n     # Test basic case.\n     x = keras.Input((time_step, embedding_dim))\n     time_major_x = keras.layers.Lambda(\n-        lambda t: tf.compat.v1.transpose(t, [1, 0, 2]))(x)\n+        lambda t: tf.transpose(t, [1, 0, 2]))(x)\n     layer = keras.layers.SimpleRNN(\n         units, time_major=True, return_sequences=True)\n     self.assertEqual(\n@@ -283,7 +283,7 @@ class RNNTest(keras_parameterized.TestCase):\n     y = layer(time_major_x)\n     self.assertEqual(layer.output_shape, (time_step, None, units))\n \n-    y = keras.layers.Lambda(lambda t: tf.compat.v1.transpose(t, [1, 0, 2]))(y)\n+    y = keras.layers.Lambda(lambda t: tf.transpose(t, [1, 0, 2]))(y)\n \n     model = keras.models.Model(x, y)\n     model.compile(\n@@ -297,14 +297,14 @@ class RNNTest(keras_parameterized.TestCase):\n     # Test stacking.\n     x = keras.Input((time_step, embedding_dim))\n     time_major_x = keras.layers.Lambda(\n-        lambda t: tf.compat.v1.transpose(t, [1, 0, 2]))(x)\n+        lambda t: tf.transpose(t, [1, 0, 2]))(x)\n     cell_units = [10, 8, 6]\n     cells = [keras.layers.SimpleRNNCell(cell_units[i]) for i in range(3)]\n     layer = keras.layers.RNN(cells, time_major=True, return_sequences=True)\n     y = layer(time_major_x)\n     self.assertEqual(layer.output_shape, (time_step, None, cell_units[-1]))\n \n-    y = keras.layers.Lambda(lambda t: tf.compat.v1.transpose(t, [1, 0, 2]))(y)\n+    y = keras.layers.Lambda(lambda t: tf.transpose(t, [1, 0, 2]))(y)\n     model = keras.models.Model(x, y)\n     model.compile(\n         optimizer='rmsprop',\n@@ -317,11 +317,11 @@ class RNNTest(keras_parameterized.TestCase):\n     # Test masking.\n     x = keras.Input((time_step, embedding_dim))\n     time_major = keras.layers.Lambda(\n-        lambda t: tf.compat.v1.transpose(t, [1, 0, 2]))(x)\n+        lambda t: tf.transpose(t, [1, 0, 2]))(x)\n     mask = keras.layers.Masking()(time_major)\n     rnn = keras.layers.SimpleRNN(\n         units, time_major=True, return_sequences=True)(mask)\n-    y = keras.layers.Lambda(lambda t: tf.compat.v1.transpose(t, [1, 0, 2]))(rnn)\n+    y = keras.layers.Lambda(lambda t: tf.transpose(t, [1, 0, 2]))(rnn)\n     model = keras.models.Model(x, y)\n     model.compile(\n         optimizer='rmsprop',\n@@ -349,12 +349,12 @@ class RNNTest(keras_parameterized.TestCase):\n     y_np_1 = model.predict(x_np)\n \n     time_major = keras.layers.Lambda(\n-        lambda t: tf.compat.v1.transpose(t, [1, 0, 2]))(x)\n+        lambda t: tf.transpose(t, [1, 0, 2]))(x)\n     rnn_2 = keras.layers.SimpleRNN(\n         units, time_major=True, return_sequences=True)\n     y_2 = rnn_2(time_major)\n     y_2 = keras.layers.Lambda(\n-        lambda t: tf.compat.v1.transpose(t, [1, 0, 2]))(y_2)\n+        lambda t: tf.transpose(t, [1, 0, 2]))(y_2)\n \n     model_2 = keras.models.Model(x, y_2)\n     rnn_2.set_weights(rnn_1.get_weights())\n@@ -593,7 +593,7 @@ class RNNTest(keras_parameterized.TestCase):\n     update_1 = tf.compat.v1.assign_add(cells[0].kernel,\n                                        x[0, 0, 0] * cells[0].kernel)\n     update_2 = tf.compat.v1.assign_add(cells[0].kernel,\n-                                    tf.compat.v1.ones_like(cells[0].kernel))\n+                                       tf.ones_like(cells[0].kernel))\n     # TODO(b/128682878): Remove when RNNCells are __call__'d.\n     with base_layer_utils.call_context().enter(layer, x, True, None):\n       cells[0].add_update(update_1, inputs=x)\n@@ -1043,7 +1043,7 @@ class RNNTest(keras_parameterized.TestCase):\n       self.assertEqual(initial_state.shape.as_list(), [None, 5])\n       self.assertEqual(initial_state.dtype, inputs.dtype)\n \n-      batch = tf.compat.v1.shape(inputs)[0]\n+      batch = tf.shape(inputs)[0]\n       dtype = inputs.dtype\n       initial_state = cell.get_initial_state(None, batch, dtype)\n       self.assertEqual(initial_state.shape.as_list(), [None, 5])\n@@ -1834,7 +1834,7 @@ class Minimal2DRNNCell(keras.layers.Layer):\n   def call(self, inputs, states):\n     prev_output = states[0]\n     h = tf.einsum('bij,ijkl->bkl', inputs, self.kernel)\n-    h += tf.compat.v1.expand_dims(self.bias, axis=0)\n+    h += tf.expand_dims(self.bias, axis=0)\n     output = h + tf.einsum('bij,ijkl->bkl', prev_output,\n                                          self.recurring_kernel)\n     return output, [output]\n\n@@ -612,13 +612,13 @@ def gpu_gru(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major,\n             go_backwards, sequence_lengths):\n   \"\"\"GRU with CuDNN implementation which is only available for GPU.\"\"\"\n   if not time_major and mask is None:\n-    inputs = tf.compat.v1.transpose(inputs, perm=(1, 0, 2))\n+    inputs = tf.transpose(inputs, perm=(1, 0, 2))\n     seq_axis, batch_axis = (0, 1)\n   else:\n     seq_axis, batch_axis = (0, 1) if time_major else (1, 0)\n   # For init_h, cuDNN expects one more dim of num_layers before or after batch\n   # dim for time major or batch major inputs respectively\n-  init_h = tf.compat.v1.expand_dims(init_h, axis=seq_axis)\n+  init_h = tf.expand_dims(init_h, axis=seq_axis)\n \n   weights = tf.split(kernel, 3, axis=1)\n   weights += tf.split(recurrent_kernel, 3, axis=1)\n@@ -679,8 +679,8 @@ def gpu_gru(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major,\n \n   last_output = outputs[-1]\n   if not time_major and mask is None:\n-    outputs = tf.compat.v1.transpose(outputs, perm=[1, 0, 2])\n-  h = tf.compat.v1.squeeze(h, axis=seq_axis)\n+    outputs = tf.transpose(outputs, perm=[1, 0, 2])\n+  h = tf.squeeze(h, axis=seq_axis)\n \n   # In the case of variable length input, the cudnn kernel will fill zeros for\n   # the output, whereas the default keras behavior is to bring over the previous\n@@ -785,7 +785,7 @@ def gru_with_backend_selection(inputs, init_h, kernel, recurrent_kernel, bias,\n           sequence_lengths=sequence_lengths,\n           zero_output_for_mask=zero_output_for_mask)\n \n-    return tf.compat.v1.cond(\n+    return tf.cond(\n         is_cudnn_supported_inputs(mask, time_major),\n         true_fn=cudnn_gru_fn,\n         false_fn=standard_gru_fn)\n@@ -1236,7 +1236,8 @@ class LSTM(recurrent.DropoutRNNCellMixin, recurrent.LSTM):\n           can_use_gpu = (\n               # Either user specified GPU or unspecified but GPU is available.\n               (device_type == _GPU_DEVICE_NAME or\n-               (device_type is None and tf.config.list_logical_devices('GPU'))) and\n+               (device_type is None\n+                and tf.config.list_logical_devices('GPU'))) and\n               (mask is None or\n                is_cudnn_supported_inputs(mask, self.time_major)))\n           # Under eager context, check the device placement and prefer the\n@@ -1298,7 +1299,7 @@ def _canonical_to_params(weights, biases, shape, transpose_weights=False):\n     The converted weights that can be feed to CuDNN ops as param.\n   \"\"\"\n   def convert(w):\n-    return tf.compat.v1.transpose(w) if transpose_weights else w\n+    return tf.transpose(w) if transpose_weights else w\n \n   weights = [tf.reshape(convert(x), shape) for x in weights]\n   biases = [tf.reshape(x, shape) for x in biases]\n@@ -1428,20 +1429,20 @@ def gpu_lstm(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask,\n       value is for testing purpose and should not be used by user.\n   \"\"\"\n   if not time_major and mask is None:\n-    inputs = tf.compat.v1.transpose(inputs, perm=(1, 0, 2))\n+    inputs = tf.transpose(inputs, perm=(1, 0, 2))\n     seq_axis, batch_axis = (0, 1)\n   else:\n     seq_axis, batch_axis = (0, 1) if time_major else (1, 0)\n   # For init_h and init_c, cuDNN expects one more dim of num_layers before or\n   # after batch dim for time major or batch major inputs respectively\n-  init_h = tf.compat.v1.expand_dims(init_h, axis=seq_axis)\n-  init_c = tf.compat.v1.expand_dims(init_c, axis=seq_axis)\n+  init_h = tf.expand_dims(init_h, axis=seq_axis)\n+  init_c = tf.expand_dims(init_c, axis=seq_axis)\n \n   weights = tf.split(kernel, 4, axis=1)\n   weights += tf.split(recurrent_kernel, 4, axis=1)\n   # CuDNN has an extra set of bias for inputs, we disable them (setting to 0),\n   # so that mathematically it is same as the canonical LSTM implementation.\n-  full_bias = tf.concat((tf.compat.v1.zeros_like(bias), bias), 0)\n+  full_bias = tf.concat((tf.zeros_like(bias), bias), 0)\n \n   if tf.sysconfig.get_build_info()['is_rocm_build']:\n     # ROCm MIOpen's weight sequence for LSTM is different from both canonical\n@@ -1500,9 +1501,9 @@ def gpu_lstm(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask,\n \n   last_output = outputs[-1]\n   if not time_major and mask is None:\n-    outputs = tf.compat.v1.transpose(outputs, perm=[1, 0, 2])\n-  h = tf.compat.v1.squeeze(h, axis=seq_axis)\n-  c = tf.compat.v1.squeeze(c, axis=seq_axis)\n+    outputs = tf.transpose(outputs, perm=[1, 0, 2])\n+  h = tf.squeeze(h, axis=seq_axis)\n+  c = tf.squeeze(c, axis=seq_axis)\n \n   # In the case of variable length input, the cudnn kernel will fill zeros for\n   # the output, whereas the default keras behavior is to bring over the previous\n@@ -1612,7 +1613,7 @@ def lstm_with_backend_selection(inputs, init_h, init_c, kernel,\n           sequence_lengths=sequence_lengths,\n           zero_output_for_mask=zero_output_for_mask)\n \n-    return tf.compat.v1.cond(\n+    return tf.cond(\n         is_cudnn_supported_inputs(mask, time_major),\n         true_fn=cudnn_lstm_fn,\n         false_fn=stardard_lstm_fn)\n@@ -1672,7 +1673,7 @@ def is_sequence_right_padded(mask):\n   Returns:\n     boolean scalar tensor, whether the mask is strictly right padded.\n   \"\"\"\n-  max_seq_length = tf.compat.v1.shape(mask)[1]\n+  max_seq_length = tf.shape(mask)[1]\n   count_of_true = tf.reduce_sum(tf.cast(mask, tf.int32), axis=1)\n   right_padded_mask = tf.sequence_mask(\n       count_of_true, maxlen=max_seq_length)\n@@ -1694,7 +1695,7 @@ def has_fully_masked_sequence(mask):\n \n def is_cudnn_supported_inputs(mask, time_major):\n   if time_major:\n-    mask = tf.compat.v1.transpose(mask)\n+    mask = tf.transpose(mask)\n \n   return tf.logical_and(\n       is_sequence_right_padded(mask),\n@@ -1747,7 +1748,7 @@ def _get_context_device_type():\n \n \n def _runtime(runtime_name):\n-  with tf.compat.v1.device('/cpu:0'):\n+  with tf.device('/cpu:0'):\n     return tf.constant(\n         runtime_name, dtype=tf.float32, name='runtime')\n \n\n@@ -70,7 +70,7 @@ def _multiple_ops_in_middle():\n \n def _shape_op_inference():\n   inputs = keras.Input(shape=(10,))\n-  x = tf.compat.v1.shape(inputs)\n+  x = tf.shape(inputs)\n   x = tf.ones(x)\n   assert x.shape.as_list() == [None, 10]\n   outputs = keras.layers.Dense(10)(x)\n@@ -79,7 +79,7 @@ def _shape_op_inference():\n \n def _shape_op_known_batch_size():\n   inputs = keras.Input(batch_size=2, shape=(10,))\n-  x = tf.compat.v1.shape(inputs)\n+  x = tf.shape(inputs)\n   x = tf.ones(x)\n   assert x.shape.as_list() == [2, 10]\n   outputs = keras.layers.Dense(10)(x)\n@@ -94,7 +94,7 @@ def _shape_op_known_batch_size():\n \n def _shape_op_slice_and_range():\n   inputs = keras.Input(shape=(10,))\n-  batch_size = tf.compat.v1.shape(inputs)[0]\n+  batch_size = tf.shape(inputs)[0]\n   x = tf.range(batch_size * 2)\n   assert x.shape.as_list() == [None]\n   x = tf.reshape(x, (batch_size, 2))\n@@ -105,7 +105,7 @@ def _shape_op_slice_and_range():\n \n def _shape_op_slice_and_range_known_dim():\n   inputs = keras.Input(batch_size=2, shape=(10,))\n-  batch_size = tf.compat.v1.shape(inputs)[0]\n+  batch_size = tf.shape(inputs)[0]\n   x = tf.range(batch_size * 3)\n   assert x.shape.as_list() == [6]\n   x = tf.reshape(x, (batch_size, 3))\n@@ -125,7 +125,7 @@ def _int32_manipulation_too_big_for_shape():\n   # won't crash when manipulating int32 tensors that are too large\n   # to represent shapes.\n   inputs = keras.Input(batch_size=2, shape=(10,))\n-  batch_size = tf.compat.v1.shape(inputs)[0]\n+  batch_size = tf.shape(inputs)[0]\n   num_features = 3 * 1024 * 16\n   x = tf.range(batch_size * num_features, dtype='int32')\n   assert x.shape.as_list() == [inputs.shape[0] * num_features]\n@@ -146,7 +146,7 @@ def _int32_manipulation_at_max_shape_dims_limit():\n   # won't crash when manipulating int32 tensors that are at the limit\n   # of the max tensor size Keras can try inferring values for.\n   inputs = keras.Input(batch_size=2, shape=(10,))\n-  batch_size = tf.compat.v1.shape(inputs)[0]\n+  batch_size = tf.shape(inputs)[0]\n   num_features = int(keras_tensor._MAX_TENSOR_RANK / int(inputs.shape[0]))\n   x = tf.range(batch_size * num_features, dtype='int32')\n   assert x.shape.as_list() == [keras_tensor._MAX_TENSOR_RANK]\n@@ -739,7 +739,7 @@ class InputInEagerTest(keras_parameterized.TestCase):\n   def test_size(self):\n     x = keras.Input(shape=(3,))\n     self.assertAllEqual(x.get_shape().as_list(), [None, 3])\n-    sz = tf.compat.v1.size(x)\n+    sz = tf.size(x)\n \n     # This is now a graph tensor, and should be able to continue in graphland\n     self.assertIn('Size', sz.name)\n\n@@ -251,8 +251,7 @@ class TimeDistributed(Wrapper):\n         input_length = tf_utils.convert_shapes(input_shape)\n         input_length = tf.nest.flatten(input_length)[1]\n         if not input_length:\n-          input_length = tf.nest.map_structure(lambda x: tf.compat.v1.shape(x)[1],\n-                                            inputs)\n+          input_length = tf.nest.map_structure(lambda x: tf.shape(x)[1], inputs)\n           input_length = generic_utils.to_list(tf.nest.flatten(input_length))[0]\n \n         inner_input_shape = tf.nest.map_structure(\n\n@@ -734,12 +734,12 @@ class BidirectionalTest(tf.test.TestCase, parameterized.TestCase):\n \n     # Switch to time-major.\n     if time_major:\n-      inputs = tf.compat.v1.transpose(inputs, [1, 0, 2])\n-      mask = tf.compat.v1.transpose(mask, [1, 0])\n+      inputs = tf.transpose(inputs, [1, 0, 2])\n+      mask = tf.transpose(mask, [1, 0])\n \n     keras_outputs = layer(inputs, mask=mask)\n     if time_major:\n-      keras_outputs = tf.compat.v1.transpose(keras_outputs, [1, 0, 2])\n+      keras_outputs = tf.transpose(keras_outputs, [1, 0, 2])\n \n     # expect the first element in batch has 1 step and second element in batch\n     # has 2 steps.\n\n@@ -1255,7 +1255,7 @@ def _ragged_tensor_apply_loss(loss_fn, y_true, y_pred, y_pred_extra_dim=False):\n   def _wrapper(inputs, ragged_output):\n     _, y_pred = inputs\n     if isinstance(y_pred, tf.RaggedTensor):\n-      return tf.compat.v1.cond(\n+      return tf.cond(\n           rt_is_equiv_dense(y_pred),\n           lambda: _call_loss(_convert_to_dense(inputs), ragged_output),\n           lambda: _call_loss(inputs, ragged_output))\n@@ -1656,7 +1656,7 @@ def categorical_crossentropy(y_true,\n       label_smoothing, dtype=backend.floatx())\n \n   def _smooth_labels():\n-    num_classes = tf.cast(tf.compat.v1.shape(y_true)[-1], y_pred.dtype)\n+    num_classes = tf.cast(tf.shape(y_true)[-1], y_pred.dtype)\n     return y_true * (1.0 - label_smoothing) + (label_smoothing / num_classes)\n \n   y_true = tf.__internal__.smart_cond.smart_cond(label_smoothing, _smooth_labels,\n\n@@ -270,7 +270,7 @@ class Metric(base_layer.Layer, metaclass=abc.ABCMeta):\n       self,\n       name,\n       shape=(),\n-      aggregation=tf.compat.v1.VariableAggregation.SUM,\n+      aggregation=tf.VariableAggregation.SUM,\n       synchronization=tf.VariableSynchronization.ON_READ,\n       initializer=None,\n       dtype=None):\n@@ -347,11 +347,11 @@ class Reduce(Metric):\n     super(Reduce, self).__init__(name=name, dtype=dtype)\n     self.reduction = reduction\n     self.total = self.add_weight(\n-        'total', initializer=tf.compat.v1.zeros_initializer)\n+        'total', initializer='zeros')\n     if reduction in [metrics_utils.Reduction.SUM_OVER_BATCH_SIZE,\n                      metrics_utils.Reduction.WEIGHTED_MEAN]:\n       self.count = self.add_weight(\n-          'count', initializer=tf.compat.v1.zeros_initializer)\n+          'count', initializer='zeros')\n \n   def update_state(self, values, sample_weight=None):\n     \"\"\"Accumulates statistics for computing the metric.\n@@ -406,10 +406,10 @@ class Reduce(Metric):\n \n     # Update `count` for reductions that require a denominator.\n     if self.reduction == metrics_utils.Reduction.SUM_OVER_BATCH_SIZE:\n-      num_values = tf.cast(tf.compat.v1.size(values), self._dtype)\n+      num_values = tf.cast(tf.size(values), self._dtype)\n     elif self.reduction == metrics_utils.Reduction.WEIGHTED_MEAN:\n       if sample_weight is None:\n-        num_values = tf.cast(tf.compat.v1.size(values), self._dtype)\n+        num_values = tf.cast(tf.size(values), self._dtype)\n       else:\n         num_values = tf.reduce_sum(sample_weight)\n     else:\n@@ -1586,8 +1586,8 @@ class SensitivitySpecificityBase(Metric, metaclass=abc.ABCMeta):\n     Returns maximal dependent value, if no value satiesfies the constraint 0.0.\n     \"\"\"\n     feasible = tf.where(predicate(constrained, self.value))\n-    feasible_exists = tf.greater(tf.compat.v1.size(feasible), 0)\n-    max_dependent = tf.reduce_max(tf.compat.v1.gather(dependent, feasible))\n+    feasible_exists = tf.greater(tf.size(feasible), 0)\n+    max_dependent = tf.reduce_max(tf.gather(dependent, feasible))\n \n     return tf.where(feasible_exists, max_dependent, 0.0)\n \n@@ -2312,13 +2312,13 @@ class AUC(Metric):\n         dtp, tf.maximum(dp, 0), name='prec_slope')\n     intercept = self.true_positives[1:] - tf.multiply(prec_slope, p[1:])\n \n-    safe_p_ratio = tf.compat.v1.where(\n+    safe_p_ratio = tf.where(\n         tf.logical_and(p[:self.num_thresholds - 1] > 0, p[1:] > 0),\n         tf.math.divide_no_nan(\n             p[:self.num_thresholds - 1],\n             tf.maximum(p[1:], 0),\n             name='recall_relative_ratio'),\n-        tf.compat.v1.ones_like(p[1:]))\n+        tf.ones_like(p[1:]))\n \n     pr_auc_increment = tf.math.divide_no_nan(\n         prec_slope * (dtp + intercept * tf.math.log(safe_p_ratio)),\n@@ -3107,7 +3107,7 @@ class MeanTensor(Metric):\n                        'shape. Expected shape (set during the first call): {}. '\n                        'Got: {}'.format(self._shape, values.shape))\n \n-    num_values = tf.compat.v1.ones_like(values)\n+    num_values = tf.ones_like(values)\n     if sample_weight is not None:\n       sample_weight = tf.cast(sample_weight, self._dtype)\n \n@@ -3489,7 +3489,7 @@ def sparse_categorical_accuracy(y_true, y_pred):\n   # If the shape of y_true is (num_samples, 1), squeeze to (num_samples,)\n   if (y_true_rank is not None) and (y_pred_rank is not None) and (len(\n       backend.int_shape(y_true)) == len(backend.int_shape(y_pred))):\n-    y_true = tf.compat.v1.squeeze(y_true, [-1])\n+    y_true = tf.squeeze(y_true, [-1])\n   y_pred = tf.compat.v1.argmax(y_pred, axis=-1)\n \n   # If the predicted output and actual output types don't match, force cast them\n\n@@ -803,7 +803,7 @@ class SensitivityAtSpecificityTest(tf.test.TestCase, parameterized.TestCase):\n     pred_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.01, 0.02, 0.25, 0.26, 0.26]\n     label_values = [0, 0, 0, 0, 0, 2, 2, 2, 2, 2]\n \n-    y_pred = tf.compat.v1.transpose([pred_values] * 3)\n+    y_pred = tf.transpose([pred_values] * 3)\n     y_true = tf.one_hot(label_values, depth=3)\n     self.evaluate(tf.compat.v1.variables_initializer(s_obj.variables))\n     result = s_obj(y_true, y_pred)\n@@ -915,7 +915,7 @@ class SpecificityAtSensitivityTest(tf.test.TestCase, parameterized.TestCase):\n     pred_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.01, 0.02, 0.25, 0.26, 0.26]\n     label_values = [0, 0, 0, 0, 0, 2, 2, 2, 2, 2]\n \n-    y_pred = tf.compat.v1.transpose([pred_values] * 3)\n+    y_pred = tf.transpose([pred_values] * 3)\n     y_true = tf.one_hot(label_values, depth=3)\n     self.evaluate(tf.compat.v1.variables_initializer(s_obj.variables))\n     result = s_obj(y_true, y_pred)\n@@ -1026,7 +1026,7 @@ class PrecisionAtRecallTest(tf.test.TestCase, parameterized.TestCase):\n     pred_values = [0.0, 0.1, 0.2, 0.5, 0.6, 0.2, 0.5, 0.6, 0.8, 0.9]\n     label_values = [0, 0, 0, 0, 0, 2, 2, 2, 2, 2]\n \n-    y_pred = tf.compat.v1.transpose([pred_values] * 3)\n+    y_pred = tf.transpose([pred_values] * 3)\n     y_true = tf.one_hot(label_values, depth=3)\n     self.evaluate(tf.compat.v1.variables_initializer(s_obj.variables))\n     result = s_obj(y_true, y_pred)\n@@ -1148,7 +1148,7 @@ class RecallAtPrecisionTest(tf.test.TestCase, parameterized.TestCase):\n     label_values = [0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 2]\n     # precisions: [1/2, 6/11, 1/2, 5/9, 5/8, 5/7, 2/3, 3/5, 3/5, 2/3, 1/2, 1].\n     # recalls:    [1,   1,    5/6, 5/6, 5/6, 5/6, 2/3, 1/2, 1/2, 1/3, 1/6, 1/6].\n-    y_pred = tf.compat.v1.transpose([pred_values] * 3)\n+    y_pred = tf.transpose([pred_values] * 3)\n     y_true = tf.one_hot(label_values, depth=3)\n     self.evaluate(tf.compat.v1.variables_initializer(s_obj.variables))\n     result = s_obj(y_true, y_pred)\n\n@@ -1276,7 +1276,7 @@ class MeanRelativeErrorTest(tf.test.TestCase):\n     y_pred = tf.constant([2, 4], dtype=tf.float32)\n     y_true = tf.constant([1, 3])\n \n-    mre_obj = metrics.MeanRelativeError(normalizer=tf.compat.v1.zeros_like(y_true))\n+    mre_obj = metrics.MeanRelativeError(normalizer=tf.zeros_like(y_true))\n     self.evaluate(tf.compat.v1.variables_initializer(mre_obj.variables))\n \n     result = mre_obj(y_true, y_pred)\n\n@@ -38,7 +38,7 @@ maybe_distribute = tf.__internal__.test.combinations.combine(distribution=[\n \n \n def get_var(val, dtype, name=None):\n-  return tf.compat.v1.Variable(val, use_resource=True, dtype=dtype, name=name)\n+  return tf.Variable(val, dtype=dtype, name=name)\n \n \n def set_cpu_logical_devices_to_at_least(num):\n\n@@ -188,7 +188,7 @@ def _op_in_graph_mode(tensor):\n \n def _assign_if_finite(var, value):\n   \"\"\"Assigns a value to a variable if the value is finite.\"\"\"\n-  return tf.compat.v1.cond(\n+  return tf.cond(\n       tf.math.is_finite(value), lambda: _op_in_graph_mode(var.assign(value)),\n       tf.no_op)\n \n@@ -231,16 +231,15 @@ class _DynamicLossScaleState(tf.__internal__.tracking.Trackable):\n     Raises:\n       RuntimeError: If a weight with `name` has already been added.\n     \"\"\"\n-    variable = tf.compat.v1.Variable(\n+    variable = tf.Variable(\n         initial_value=initial_value,\n         name=name,\n         dtype=dtype,\n         trainable=False,\n-        use_resource=True,\n         synchronization=tf.VariableSynchronization.AUTO,\n         # Set aggregation to NONE, as loss scaling variables should never be\n         # aggregated.\n-        aggregation=tf.compat.v1.VariableAggregation.NONE)\n+        aggregation=tf.VariableAggregation.NONE)\n     if tf.executing_eagerly():\n       graph_key = None\n     else:\n@@ -343,7 +342,7 @@ class _DynamicLossScaleState(tf.__internal__.tracking.Trackable):\n             _assign_if_finite(self.current_loss_scale, new_loss_scale),\n             self.counter.assign(0))\n \n-      return tf.compat.v1.cond(\n+      return tf.cond(\n           self.counter + 1 >= self.growth_steps,\n           incr_loss_scale,\n           lambda: _op_in_graph_mode(self.counter.assign_add(1)))\n@@ -357,7 +356,8 @@ class _DynamicLossScaleState(tf.__internal__.tracking.Trackable):\n           self.counter.assign(0),\n           self.current_loss_scale.assign(new_loss_scale))\n \n-    update_op = tf.compat.v1.cond(is_finite, update_if_finite_grads,\n+    update_op = tf.cond(is_finite,\n+                        update_if_finite_grads,\n                         update_if_not_finite_grads)\n     should_apply_gradients = is_finite\n     return update_op, should_apply_gradients\n\n@@ -310,7 +310,7 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n         rep_id = (tf.distribute.get_replica_context()\n                   .replica_id_in_sync_group)\n         # The last element of last replica's gradient is NaN.\n-        return tf.compat.v1.cond(\n+        return tf.cond(\n             tf.constant(rep_id == 0), lambda: var * 2.,\n             lambda: var * tf.constant([1., float('NaN')]))\n       run_fn = lambda: opt.minimize(loss, var_list=[var])\n\n@@ -856,7 +856,7 @@ class ApplicationModelTest(keras_parameterized.TestCase):\n   )\n   def test_application_model(self, app):\n     # Run on CPU since model weights may exhaust GPU memory\n-    with policy.policy_scope('mixed_float16'), tf.compat.v1.device('/CPU:0'):\n+    with policy.policy_scope('mixed_float16'), tf.device('/CPU:0'):\n       app(weights=None)\n \n \n\n@@ -84,7 +84,7 @@ def create_identity_with_nan_gradients_fn(have_nan_gradients):\n     \"\"\"Function whose gradient is NaN iff `have_nan_gradients` is True.\"\"\"\n     x = tf.identity(x)\n     def grad(dx):\n-      return tf.compat.v1.cond(\n+      return tf.cond(\n           have_nan_gradients,\n           lambda: dx * float('NaN'),\n           lambda: dx\n\n@@ -323,7 +323,7 @@ class TestModelCloning(keras_parameterized.TestCase):\n           return inputs\n \n     inputs = keras.layers.Input(shape=(3))\n-    t = tf.sequence_mask(tf.compat.v1.shape(inputs)[1])\n+    t = tf.sequence_mask(tf.shape(inputs)[1])\n     model = keras.models.Model(inputs, LayerWithTensorKwarg()(inputs, t))\n     model.add_loss(tf.reduce_sum(model.outputs))\n \n\n@@ -153,7 +153,7 @@ class AdamOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n         # it (i.e. they have GPU kernels).\n         var = tf.Variable([[1.0], [2.0]])\n         indices = tf.constant([0, 1], dtype=index_dtype)\n-        g_sum = lambda: tf.reduce_sum(tf.compat.v1.gather(var, indices))  # pylint: disable=cell-var-from-loop\n+        g_sum = lambda: tf.reduce_sum(tf.gather(var, indices))  # pylint: disable=cell-var-from-loop\n         optimizer = adam.Adam(3.0)\n         minimize_op = optimizer.minimize(g_sum, var_list=[var])\n         self.evaluate(tf.compat.v1.global_variables_initializer())\n@@ -605,7 +605,7 @@ class NonFusedAdamOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n         # it (i.e. they have GPU kernels).\n         var = tf.Variable([[1.0], [2.0]])\n         indices = tf.constant([0, 1], dtype=index_dtype)\n-        g_sum = lambda: tf.reduce_sum(tf.compat.v1.gather(var, indices))  # pylint: disable=cell-var-from-loop\n+        g_sum = lambda: tf.reduce_sum(tf.gather(var, indices))  # pylint: disable=cell-var-from-loop\n         optimizer = adam.NonFusedAdam(3.0)\n         minimize_op = optimizer.minimize(g_sum, var_list=[var])\n         self.evaluate(tf.compat.v1.global_variables_initializer())\n\n@@ -147,7 +147,7 @@ class Adamax(optimizer_v2.OptimizerV2):\n \n     # m_t = beta1 * m + (1 - beta1) * g_t\n     m = self.get_slot(var, 'm')\n-    m_slice = tf.compat.v1.gather(m, indices, axis=coefficients['zero'])\n+    m_slice = tf.gather(m, indices, axis=coefficients['zero'])\n     m_t_slice = (m_slice * coefficients['beta_1_t'] +\n                  grad * coefficients['one_minus_beta_1_t'])\n     with tf.control_dependencies([m_t_slice]):\n@@ -155,7 +155,7 @@ class Adamax(optimizer_v2.OptimizerV2):\n \n     # u_t = max(beta2 * u, abs(g_t))\n     v = self.get_slot(var, 'v')\n-    v_slice = tf.compat.v1.gather(v, indices, axis=coefficients['zero'])\n+    v_slice = tf.gather(v, indices, axis=coefficients['zero'])\n     v_t_slice = tf.maximum(v_slice * coefficients['beta_2_t'],\n                                  tf.abs(grad))\n     with tf.control_dependencies([v_t_slice]):\n\n@@ -123,7 +123,7 @@ class AdamaxOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n         # it (i.e. they have GPU kernels).\n         var = tf.Variable([[1.0], [2.0]])\n         indices = tf.constant([0, 1], dtype=index_dtype)\n-        g_sum = lambda: tf.reduce_sum(tf.compat.v1.gather(var, indices))  # pylint: disable=cell-var-from-loop\n+        g_sum = lambda: tf.reduce_sum(tf.gather(var, indices))  # pylint: disable=cell-var-from-loop\n         optimizer = adamax.Adamax(3.0)\n         minimize_op = optimizer.minimize(g_sum, var_list=[var])\n         self.evaluate(tf.compat.v1.global_variables_initializer())\n\n@@ -284,7 +284,7 @@ class PiecewiseConstantDecay(LearningRateSchedule):\n       # The default isn't needed here because our conditions are mutually\n       # exclusive and exhaustive, but tf.case requires it.\n       default = lambda: values[0]\n-      return tf.compat.v1.case(pred_fn_pairs, default, exclusive=True)\n+      return tf.case(pred_fn_pairs, default, exclusive=True)\n \n   def get_config(self):\n     return {\n@@ -742,7 +742,7 @@ class CosineDecayRestarts(LearningRateSchedule):\n \n         return i_restart, completed_fraction\n \n-      i_restart, completed_fraction = tf.compat.v1.cond(\n+      i_restart, completed_fraction = tf.cond(\n           tf.equal(t_mul, 1.0),\n           lambda: compute_step(completed_fraction, geometric=False),\n           lambda: compute_step(completed_fraction, geometric=True))\n\n@@ -54,7 +54,7 @@ class LRDecayTest(keras_parameterized.TestCase):\n       self.assertAllClose(self.evaluate(decayed_lr), expected, 1e-6)\n \n   def testVariables(self):\n-    step = tf.compat.v1.Variable(1)\n+    step = tf.Variable(1)\n \n     decayed_lr = tf.compat.v1.train.exponential_decay(\n         .1, step, 3, 0.96, staircase=True)\n\n@@ -87,7 +87,7 @@ class Nadam(optimizer_v2.OptimizerV2):\n           dtype=var_dtype,\n           initializer='ones',\n           trainable=False,\n-          aggregation=tf.compat.v1.VariableAggregation.ONLY_FIRST_REPLICA)\n+          aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA)\n       self._weights.append(self._m_cache)\n     # Separate for-loops to respect the ordering of slot variables from v1.\n     for var in var_list:\n@@ -178,7 +178,7 @@ class Nadam(optimizer_v2.OptimizerV2):\n \n     with tf.control_dependencies([m_t]):\n       m_t = self._resource_scatter_add(m, indices, m_scaled_g_values)\n-      m_t_slice = tf.compat.v1.gather(m_t, indices)\n+      m_t_slice = tf.gather(m_t, indices)\n \n     m_t_prime = m_t_slice / coefficients['one_minus_m_schedule_next']\n     m_t_bar = (coefficients['one_minus_m_t'] * g_prime +\n@@ -191,7 +191,7 @@ class Nadam(optimizer_v2.OptimizerV2):\n \n     with tf.control_dependencies([v_t]):\n       v_t = self._resource_scatter_add(v, indices, v_scaled_g_values)\n-      v_t_slice = tf.compat.v1.gather(v_t, indices)\n+      v_t_slice = tf.gather(v_t, indices)\n \n     v_t_prime = v_t_slice / coefficients['v_t_prime_denominator']\n     v_prime_sqrt_plus_eps = tf.sqrt(v_t_prime) + coefficients['epsilon']\n\n@@ -58,7 +58,7 @@ def _deduplicate_indexed_slices(values, indices):\n   unique_indices, new_index_positions = tf.unique(indices)\n   summed_values = tf.math.unsorted_segment_sum(\n       values, new_index_positions,\n-      tf.compat.v1.shape(unique_indices)[0])\n+      tf.shape(unique_indices)[0])\n   return (summed_values, unique_indices)\n \n \n@@ -87,7 +87,7 @@ def name_scope_only_in_function_or_graph(name):\n     `name_scope*` context manager.\n   \"\"\"\n   if not tf.executing_eagerly():\n-    return tf.compat.v1.name_scope(name)\n+    return tf.name_scope(name)\n   else:\n     return NullContextmanager()\n \n@@ -930,7 +930,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n     apply_state = {}\n     for var_device, var_dtype in keys:\n       apply_state[(var_device, var_dtype)] = {}\n-      with tf.compat.v1.device(var_device):\n+      with tf.device(var_device):\n         self._prepare_local(var_device, var_dtype, apply_state)\n \n     return apply_state\n@@ -964,7 +964,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n               shape=[],\n               trainable=False,\n               initializer=value,\n-              aggregation=tf.compat.v1.VariableAggregation.ONLY_FIRST_REPLICA)\n+              aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA)\n     self._hypers_created = True\n \n   @property\n@@ -977,7 +977,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n             shape=[],\n             dtype=tf.int64,\n             trainable=False,\n-            aggregation=tf.compat.v1.VariableAggregation.ONLY_FIRST_REPLICA)\n+            aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA)\n       self._weights.append(self._iterations)\n     return self._iterations\n \n@@ -1153,7 +1153,7 @@ class OptimizerV2(tf.__internal__.tracking.Trackable):\n                  initializer=\"zeros\",\n                  trainable=None,\n                  synchronization=tf.VariableSynchronization.AUTO,\n-                 aggregation=tf.compat.v1.VariableAggregation.NONE):\n+                 aggregation=tf.VariableAggregation.NONE):\n \n     if dtype is None:\n       dtype = tf.float32\n\n@@ -251,7 +251,7 @@ class RMSprop(optimizer_v2.OptimizerV2):\n                                use_locking=self._use_locking)\n       with tf.control_dependencies([rms_t]):\n         rms_t = self._resource_scatter_add(rms, indices, rms_scaled_g_values)\n-        rms_slice = tf.compat.v1.gather(rms_t, indices)\n+        rms_slice = tf.gather(rms_t, indices)\n       denom_slice = rms_slice\n       if self.centered:\n         mg = self.get_slot(var, \"mg\")\n@@ -260,7 +260,7 @@ class RMSprop(optimizer_v2.OptimizerV2):\n                                 use_locking=self._use_locking)\n         with tf.control_dependencies([mg_t]):\n           mg_t = self._resource_scatter_add(mg, indices, mg_scaled_g_values)\n-          mg_slice = tf.compat.v1.gather(mg_t, indices)\n+          mg_slice = tf.gather(mg_t, indices)\n           denom_slice = rms_slice - tf.square(mg_slice)\n       var_update = self._resource_scatter_add(\n           var, indices, coefficients[\"neg_lr_t\"] * grad / (\n\n@@ -541,7 +541,7 @@ class SlotColocationTest(tf.test.TestCase, parameterized.TestCase):\n   @parameterized.parameters([True, False])\n   @test_util.run_gpu_only\n   def testRunMinimizeOnGPUForCPUVariables(self, use_resource):\n-    with tf.compat.v1.device(\"/device:CPU:0\"):\n+    with tf.device(\"/device:CPU:0\"):\n       if use_resource:\n         var0 = tf.Variable([1.0, 2.0], dtype=tf.float32)\n         var1 = tf.Variable([3.0, 4.0], dtype=tf.float32)\n@@ -564,7 +564,7 @@ class SlotColocationTest(tf.test.TestCase, parameterized.TestCase):\n     # Slot variables are created the first time optimizer is used on some\n     # variable. This tests that slot variables will be colocated with the base\n     # variable.\n-    with tf.compat.v1.device(\"/device:GPU:0\"):\n+    with tf.device(\"/device:GPU:0\"):\n       # Note that for eager execution, minimize expects a function instead of a\n       # Tensor.\n       opt_op = opt.minimize(loss, [var0, var1])\n\n@@ -208,7 +208,7 @@ def labels_to_dataset(labels, label_mode, num_classes):\n   label_ds = tf.data.Dataset.from_tensor_slices(labels)\n   if label_mode == 'binary':\n     label_ds = label_ds.map(\n-        lambda x: tf.compat.v1.expand_dims(tf.cast(x, 'float32'), axis=-1))\n+        lambda x: tf.expand_dims(tf.cast(x, 'float32'), axis=-1))\n   elif label_mode == 'categorical':\n     label_ds = label_ds.map(lambda x: tf.one_hot(x, num_classes))\n   return label_ds\n\n@@ -112,7 +112,7 @@ def smart_resize(x, size, interpolation='bilinear'):\n           'Expected an image array with shape `(height, width, channels)`, '\n           'or `(batch_size, height, width, channels)` but '\n           'got input with incorrect rank, of shape %s' % (img.shape,))\n-  shape = tf.compat.v1.shape(img)\n+  shape = tf.shape(img)\n   height, width = shape[-3], shape[-2]\n   target_height, target_width = size\n   if img.shape.rank is not None:\n\n@@ -225,6 +225,6 @@ def timeseries_dataset_from_array(\n def sequences_from_indices(array, indices_ds, start_index, end_index):\n   dataset = tf.data.Dataset.from_tensors(array[start_index : end_index])\n   dataset = tf.data.Dataset.zip((dataset.repeat(), indices_ds)).map(\n-      lambda steps, inds: tf.compat.v1.gather(steps, inds),  # pylint: disable=unnecessary-lambda\n+      lambda steps, inds: tf.gather(steps, inds),  # pylint: disable=unnecessary-lambda\n       num_parallel_calls=tf.data.AUTOTUNE)\n   return dataset\n\n@@ -98,7 +98,7 @@ def save_model_to_hdf5(model, filepath, overwrite=True, include_optimizer=True):\n     # Try creating dir if not exist\n     dirpath = os.path.dirname(filepath)\n     if not os.path.exists(dirpath):\n-      tf.compat.v1.gfile.MakeDirs(dirpath)\n+      tf.io.gfile.makedirs(dirpath)\n \n     f = h5py.File(filepath, mode='w')\n     opened_new_file = True\n\n@@ -466,7 +466,7 @@ class TestWeightSavingAndLoadingTFFormat(tf.test.TestCase, parameterized.TestCas\n       ref_y_after_train = model.predict(train_x)\n       for v in model.variables:\n         self.evaluate(\n-            v.assign(tf.random.normal(shape=tf.compat.v1.shape(v))))\n+            v.assign(tf.random.normal(shape=tf.shape(v))))\n \n       self.addCleanup(shutil.rmtree, temp_dir)\n \n@@ -526,7 +526,7 @@ class TestWeightSavingAndLoadingTFFormat(tf.test.TestCase, parameterized.TestCas\n           tf.train.latest_checkpoint(temp_dir))\n       for v in model.variables:\n         self.evaluate(\n-            v.assign(tf.random.normal(shape=tf.compat.v1.shape(v))))\n+            v.assign(tf.random.normal(shape=tf.shape(v))))\n \n       self.addCleanup(shutil.rmtree, temp_dir)\n \n\n@@ -67,10 +67,10 @@ class SparseDense(keras.layers.Dense):\n \n   def call(self, inputs):\n     input_shape = tf.stack(\n-        (tf.reduce_prod(tf.compat.v1.shape(inputs)[:-1]),\n+        (tf.reduce_prod(tf.shape(inputs)[:-1]),\n          self.kernel.shape[0]))\n     output_shape = tf.concat(\n-        (tf.compat.v1.shape(inputs)[:-1], [self.kernel.shape[1]]), -1)\n+        (tf.shape(inputs)[:-1], [self.kernel.shape[1]]), -1)\n     x = tf.sparse.reshape(inputs, input_shape)\n     return tf.reshape(\n         self.activation(\n\n@@ -425,7 +425,7 @@ def load_from_saved_model(saved_model_path, custom_objects=None):\n def _get_or_create_variables_dir(export_dir):\n   \"\"\"Return variables sub-directory, or create one if it doesn't exist.\"\"\"\n   variables_dir = _get_variables_dir(export_dir)\n-  tf.compat.v1.gfile.MakeDirs(variables_dir)\n+  tf.io.gfile.makedirs(variables_dir)\n   return variables_dir\n \n \n@@ -447,7 +447,7 @@ def _get_or_create_assets_dir(export_dir):\n   \"\"\"Return assets sub-directory, or create one if it doesn't exist.\"\"\"\n   assets_destination_dir = _get_assets_dir(export_dir)\n \n-  tf.compat.v1.gfile.MakeDirs(assets_destination_dir)\n+  tf.io.gfile.makedirs(assets_destination_dir)\n \n   return assets_destination_dir\n \n\n@@ -928,7 +928,7 @@ def device(should_use_gpu):\n     dev = '/device:GPU:0'\n   else:\n     dev = '/device:CPU:0'\n-  with tf.compat.v1.device(dev):\n+  with tf.device(dev):\n     yield\n \n \n\n@@ -159,7 +159,7 @@ class VariablesToConstantsTest(tf.test.TestCase):\n           tf.TensorSpec(shape=(20), dtype=tf.int32)\n       ])\n       def func(self, x):\n-        return tf.compat.v1.gather(self.shared_weights, x)\n+        return tf.gather(self.shared_weights, x)\n \n     model = EmbeddingModel()\n     root, output_func = self._freezeModel(model.func)\n\n@@ -77,8 +77,8 @@ class ToSparse(Layer):\n \n   def call(self, inputs):\n     indices = tf.where(tf.not_equal(inputs, 0))\n-    values = tf.compat.v1.gather_nd(inputs, indices)\n-    shape = tf.compat.v1.shape(inputs, out_type=tf.int64)\n+    values = tf.gather_nd(inputs, indices)\n+    shape = tf.shape(inputs, out_type=tf.int64)\n     return tf.SparseTensor(indices, values, dense_shape=shape)\n \n \n\n@@ -100,7 +100,7 @@ def smart_cond(pred, true_fn=None, false_fn=None, name=None):  # pylint: disable\n     TypeError: If `true_fn` or `false_fn` is not callable.\n   \"\"\"\n   if isinstance(pred, tf.Variable):\n-    return tf.compat.v1.cond(\n+    return tf.cond(\n         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n   return tf.__internal__.smart_cond.smart_cond(\n       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\n@@ -488,11 +488,11 @@ def squeeze_batch_dims(inp, op, inner_rank):\n \n     inner_shape = shape[-inner_rank:]\n     if not inner_shape.is_fully_defined():\n-      inner_shape = tf.compat.v1.shape(inp)[-inner_rank:]\n+      inner_shape = tf.shape(inp)[-inner_rank:]\n \n     batch_shape = shape[:-inner_rank]\n     if not batch_shape.is_fully_defined():\n-      batch_shape = tf.compat.v1.shape(inp)[:-inner_rank]\n+      batch_shape = tf.shape(inp)[:-inner_rank]\n \n     if isinstance(inner_shape, tf.TensorShape):\n       inp_reshaped = tf.reshape(inp, [-1] + inner_shape.as_list())\n@@ -504,7 +504,7 @@ def squeeze_batch_dims(inp, op, inner_rank):\n \n     out_inner_shape = out_reshaped.shape[-inner_rank:]\n     if not out_inner_shape.is_fully_defined():\n-      out_inner_shape = tf.compat.v1.shape(out_reshaped)[-inner_rank:]\n+      out_inner_shape = tf.shape(out_reshaped)[-inner_rank:]\n \n     out = tf.reshape(\n         out_reshaped, tf.concat((batch_shape, out_inner_shape), axis=-1))\n\n@@ -24,7 +24,7 @@ def _to_matrix(u):\n     raise ValueError('The input tensor should have rank 1 or 2. Given rank: {}'\n                      .format(u_rank))\n   if u_rank == 1:\n-    return tf.compat.v1.expand_dims(u, 0)\n+    return tf.expand_dims(u, 0)\n   return u\n \n \n@@ -40,9 +40,9 @@ def _align_matrices(x, y):\n         'vs {}.'.format(y_shape[1], x_shape[1]))\n \n   x_tile = tf.tile(\n-      tf.compat.v1.expand_dims(x_matrix, 1), [1, y_shape[0], 1])\n+      tf.expand_dims(x_matrix, 1), [1, y_shape[0], 1])\n   y_tile = tf.tile(\n-      tf.compat.v1.expand_dims(y_matrix, 0), [x_shape[0], 1, 1])\n+      tf.expand_dims(y_matrix, 0), [x_shape[0], 1, 1])\n   return x_tile, y_tile\n \n \n\n@@ -140,13 +140,13 @@ class DistributeKplTestUtils(tf.test.TestCase):\n \n     @tf.function\n     def serve_fn(raw_features):\n-      raw_features = tf.compat.v1.expand_dims(raw_features, axis=0)\n+      raw_features = tf.expand_dims(raw_features, axis=0)\n       transformed_features = model.feature_mapper(raw_features)\n       outputs = model(transformed_features)\n-      outputs = tf.compat.v1.squeeze(outputs, axis=0)\n+      outputs = tf.squeeze(outputs, axis=0)\n       outputs = tf.cast(tf.greater(outputs, 0.5), tf.int64)\n       decoded_outputs = model.label_inverse_lookup_layer(outputs)\n-      return tf.compat.v1.squeeze(decoded_outputs, axis=0)\n+      return tf.squeeze(decoded_outputs, axis=0)\n \n     model.feature_mapper = feature_mapper\n     model.label_inverse_lookup_layer = label_inverse_lookup_layer\n\n@@ -123,25 +123,25 @@ def remove_squeezable_dimensions(\n       rank_diff = predictions_rank - labels_rank\n       if (rank_diff == expected_rank_diff + 1 and\n           predictions_shape.dims[-1].is_compatible_with(1)):\n-        predictions = tf.compat.v1.squeeze(predictions, [-1])\n+        predictions = tf.squeeze(predictions, [-1])\n       elif (rank_diff == expected_rank_diff - 1 and\n             labels_shape.dims[-1].is_compatible_with(1)):\n-        labels = tf.compat.v1.squeeze(labels, [-1])\n+        labels = tf.squeeze(labels, [-1])\n       return labels, predictions\n \n     # Use dynamic rank.\n     rank_diff = tf.rank(predictions) - tf.rank(labels)\n     if (predictions_rank is None) or (\n         predictions_shape.dims[-1].is_compatible_with(1)):\n-      predictions = tf.compat.v1.cond(\n+      predictions = tf.cond(\n           tf.equal(expected_rank_diff + 1, rank_diff),\n-          lambda: tf.compat.v1.squeeze(predictions, [-1]),\n+          lambda: tf.squeeze(predictions, [-1]),\n           lambda: predictions)\n     if (labels_rank is None) or (\n         labels_shape.dims[-1].is_compatible_with(1)):\n-      labels = tf.compat.v1.cond(\n+      labels = tf.cond(\n           tf.equal(expected_rank_diff - 1, rank_diff),\n-          lambda: tf.compat.v1.squeeze(labels, [-1]),\n+          lambda: tf.squeeze(labels, [-1]),\n           lambda: labels)\n     return labels, predictions\n \n@@ -190,10 +190,10 @@ def squeeze_or_expand_dimensions(y_pred, y_true=None, sample_weight=None):\n       rank_diff = tf.rank(y_pred) - tf.rank(y_true)\n       squeeze_dims = lambda: remove_squeezable_dimensions(  # pylint: disable=g-long-lambda\n           y_true, y_pred)\n-      is_last_dim_1 = tf.equal(1, tf.compat.v1.shape(y_pred)[-1])\n-      maybe_squeeze_dims = lambda: tf.compat.v1.cond(  # pylint: disable=g-long-lambda\n+      is_last_dim_1 = tf.equal(1, tf.shape(y_pred)[-1])\n+      maybe_squeeze_dims = lambda: tf.cond(  # pylint: disable=g-long-lambda\n           is_last_dim_1, squeeze_dims, lambda: (y_true, y_pred))\n-      y_true, y_pred = tf.compat.v1.cond(\n+      y_true, y_pred = tf.cond(\n           tf.equal(1, rank_diff), maybe_squeeze_dims, squeeze_dims)\n \n   if sample_weight is None:\n@@ -207,29 +207,29 @@ def squeeze_or_expand_dimensions(y_pred, y_true=None, sample_weight=None):\n   if (y_pred_rank is not None) and (weights_rank is not None):\n     # Use static rank.\n     if weights_rank - y_pred_rank == 1:\n-      sample_weight = tf.compat.v1.squeeze(sample_weight, [-1])\n+      sample_weight = tf.squeeze(sample_weight, [-1])\n     elif y_pred_rank - weights_rank == 1:\n-      sample_weight = tf.compat.v1.expand_dims(sample_weight, [-1])\n+      sample_weight = tf.expand_dims(sample_weight, [-1])\n     return y_pred, y_true, sample_weight\n \n   # Use dynamic rank.\n   weights_rank_tensor = tf.rank(sample_weight)\n   rank_diff = weights_rank_tensor - tf.rank(y_pred)\n-  maybe_squeeze_weights = lambda: tf.compat.v1.squeeze(sample_weight, [-1])\n+  maybe_squeeze_weights = lambda: tf.squeeze(sample_weight, [-1])\n \n   def _maybe_expand_weights():\n-    expand_weights = lambda: tf.compat.v1.expand_dims(sample_weight, [-1])\n-    return tf.compat.v1.cond(\n+    expand_weights = lambda: tf.expand_dims(sample_weight, [-1])\n+    return tf.cond(\n         tf.equal(rank_diff, -1), expand_weights, lambda: sample_weight)\n \n   def _maybe_adjust_weights():\n-    return tf.compat.v1.cond(\n+    return tf.cond(\n         tf.equal(rank_diff, 1), maybe_squeeze_weights,\n         _maybe_expand_weights)\n \n   # squeeze or expand last dim of `sample_weight` if its rank differs by 1\n   # from the new rank of `y_pred`.\n-  sample_weight = tf.compat.v1.cond(\n+  sample_weight = tf.cond(\n       tf.equal(weights_rank_tensor, 0), lambda: sample_weight,\n       _maybe_adjust_weights)\n   return y_pred, y_true, sample_weight\n@@ -253,7 +253,7 @@ def _safe_mean(losses, num_present):\n def _num_elements(losses):\n   \"\"\"Computes the number of elements in `losses` tensor.\"\"\"\n   with backend.name_scope('num_elements') as scope:\n-    return tf.cast(tf.compat.v1.size(losses, name=scope), dtype=losses.dtype)\n+    return tf.cast(tf.size(losses, name=scope), dtype=losses.dtype)\n \n \n def reduce_weighted_loss(weighted_losses,\n\n@@ -37,7 +37,7 @@ class RemoveSqueezableTest(tf.test.TestCase):\n         y: (2, (sequence={1, 2}), 3, 1)\n     \"\"\"\n     x = tf.ragged.constant([[[1, 2, 3]], [[4, 5, 6], [7, 8, 9]]])\n-    y = tf.compat.v1.expand_dims(x, axis=-1)\n+    y = tf.expand_dims(x, axis=-1)\n     self.assertEqual(x.shape.ndims, 3)\n     self.assertEqual(y.shape.ndims, 4)\n     _, y_p = losses_utils.remove_squeezable_dimensions(x, y)\n@@ -68,7 +68,7 @@ class RemoveSqueezableTestGraphOnly(tf.test.TestCase):\n       y = tf.compat.v1.placeholder_with_default([[1.], [2.], [3.]], shape=None)\n       _, y_p = losses_utils.remove_squeezable_dimensions(x, y)\n       y_p.shape.assert_is_compatible_with(x.shape)\n-      self.assertAllEqual(tf.compat.v1.shape(x), tf.compat.v1.shape(y_p))\n+      self.assertAllEqual(tf.shape(x), tf.shape(y_p))\n       x_p, _ = losses_utils.remove_squeezable_dimensions(y, x)\n       x_p.shape.assert_is_compatible_with(x.shape)\n \n\n@@ -371,7 +371,7 @@ def _update_confusion_matrix_variables_optimized(\n   if label_weights is None:\n     label_weights = 1.0\n   else:\n-    label_weights = tf.compat.v1.expand_dims(label_weights, 0)\n+    label_weights = tf.expand_dims(label_weights, 0)\n     label_weights = tf.__internal__.ops.broadcast_weights(label_weights,\n                                                             y_pred)\n     if not multi_label:\n@@ -637,7 +637,7 @@ def update_confusion_matrix_variables(variables_to_update,\n         label_weights=label_weights,\n         thresholds_with_epsilon=thresholds_with_epsilon)\n \n-  pred_shape = tf.compat.v1.shape(y_pred)\n+  pred_shape = tf.shape(y_pred)\n   num_predictions = pred_shape[0]\n   if y_pred.shape.ndims == 1:\n     num_labels = 1\n@@ -648,8 +648,8 @@ def update_confusion_matrix_variables(variables_to_update,\n \n   # Reshape predictions and labels, adding a dim for thresholding.\n   if multi_label:\n-    predictions_extra_dim = tf.compat.v1.expand_dims(y_pred, 0)\n-    labels_extra_dim = tf.compat.v1.expand_dims(\n+    predictions_extra_dim = tf.expand_dims(y_pred, 0)\n+    labels_extra_dim = tf.expand_dims(\n         tf.cast(y_true, dtype=tf.bool), 0)\n   else:\n     # Flatten predictions and labels when not multilabel.\n@@ -689,7 +689,7 @@ def update_confusion_matrix_variables(variables_to_update,\n     weights_tiled = None\n \n   if label_weights is not None and not multi_label:\n-    label_weights = tf.compat.v1.expand_dims(label_weights, 0)\n+    label_weights = tf.expand_dims(label_weights, 0)\n     label_weights = tf.__internal__.ops.broadcast_weights(label_weights,\n                                                             y_pred)\n     label_weights_tiled = tf.tile(\n@@ -750,7 +750,7 @@ def _filter_top_k(x, k):\n   \"\"\"\n   _, top_k_idx = tf.math.top_k(x, k, sorted=False)\n   top_k_mask = tf.reduce_sum(\n-      tf.one_hot(top_k_idx, tf.compat.v1.shape(x)[-1], axis=-1), axis=-2)\n+      tf.one_hot(top_k_idx, tf.shape(x)[-1], axis=-1), axis=-2)\n   return x * top_k_mask + NEG_INF * (1 - top_k_mask)\n \n \n@@ -797,13 +797,13 @@ def ragged_assert_compatible_and_get_flat_values(values, mask=None):\n       assertion_list_for_mask = _assert_splits_match(\n           [nested_row_split_list[0], mask.nested_row_splits])\n       with tf.control_dependencies(assertion_list_for_mask):\n-        mask = tf.compat.v1.expand_dims(mask.flat_values, -1)\n+        mask = tf.expand_dims(mask.flat_values, -1)\n \n     # values has at least 1 element.\n     flat_values = []\n     for value in values:\n       with tf.control_dependencies(assertion_list):\n-        flat_values.append(tf.compat.v1.expand_dims(value.flat_values, -1))\n+        flat_values.append(tf.expand_dims(value.flat_values, -1))\n \n     values = flat_values[0] if to_be_stripped else flat_values\n \n\n@@ -184,7 +184,7 @@ def multi_gpu_model(model, gpus, cpu_merge=True, cpu_relocation=False):\n     Returns:\n       Slice `i` of `data`.\n     \"\"\"\n-    shape = tf.compat.v1.shape(data)\n+    shape = tf.shape(data)\n     batch_size = shape[:1]\n     input_shape = shape[1:]\n     step = batch_size // parts\n@@ -200,7 +200,7 @@ def multi_gpu_model(model, gpus, cpu_merge=True, cpu_relocation=False):\n   # Relocate the model definition under CPU device scope if needed\n   if cpu_relocation:\n     from keras.models import clone_model  # pylint: disable=g-import-not-at-top\n-    with tf.compat.v1.device('/cpu:0'):\n+    with tf.device('/cpu:0'):\n       model = clone_model(model)\n \n   all_outputs = [[] for _ in range(len(model.outputs))]\n@@ -208,7 +208,7 @@ def multi_gpu_model(model, gpus, cpu_merge=True, cpu_relocation=False):\n   # Place a copy of the model on each GPU,\n   # each getting a slice of the inputs.\n   for i, gpu_id in enumerate(target_gpu_ids):\n-    with tf.compat.v1.device('/gpu:%d' % gpu_id):\n+    with tf.device('/gpu:%d' % gpu_id):\n       with backend.name_scope('replica_%d' % gpu_id):\n         inputs = []\n         # Retrieve a slice of the input.\n@@ -250,7 +250,7 @@ def multi_gpu_model(model, gpus, cpu_merge=True, cpu_relocation=False):\n     output_names.append(n)\n \n   # Merge outputs under expected scope.\n-  with tf.compat.v1.device('/cpu:0' if cpu_merge else '/gpu:%d' % target_gpu_ids[0]):\n+  with tf.device('/cpu:0' if cpu_merge else '/gpu:%d' % target_gpu_ids[0]):\n     merged = []\n     for name, outputs in zip(output_names, all_outputs):\n       merged.append(concatenate(outputs, axis=0, name=name))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
