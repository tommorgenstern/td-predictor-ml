{"custom_id": "keras#56c492cbcce975fbcf55a5c60a6e8151a1b9e433", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1048 | Contributors (this commit): 9 | Commits (past 90d): 32 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -12,10 +12,10 @@ def get_session():\n     global _SESSION\n     if _SESSION is None:\n         if not os.environ.get('OMP_NUM_THREADS'):\n-            _SESSION = tf.Session('')\n+            _SESSION = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n         else:\n             nb_thread = int(os.environ.get('OMP_NUM_THREADS'))\n-            _SESSION = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=nb_thread))\n+            _SESSION = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=nb_thread, allow_soft_placement=True))\n     return _SESSION\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b50624debd66721081248af7c39eeab28e4e06bf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 28 | Churn Cumulative: 922 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: 0.1111111111111111\n\nDIFF:\n@@ -52,6 +52,33 @@ class BaseWrapper(object):\n     def __init__(self, build_fn=None, **sk_params):\n         self.build_fn = build_fn\n         self.sk_params = sk_params\n+        self.check_params(sk_params)\n+\n+    def check_params(self, params):\n+        '''Check user's typo in params' name to avoid unwanted usage of\n+        default values\n+\n+        # Arguments\n+            params: dictionary\n+                The parameters to be checked\n+        '''\n+        legal_params_fns = [Sequential.fit, Sequential.predict,\n+                            Sequential.predict_classes, Sequential.evaluate]\n+        if self.build_fn is None:\n+            legal_params_fns.append(self.__call__)\n+        elif not isinstance(self.build_fn, types.FunctionType):\n+            legal_params_fns.append(self.build_fn.__call__)\n+        else:\n+            legal_params_fns.append(self.build_fn)\n+\n+        legal_params = []\n+        for fn in legal_params_fns:\n+            legal_params += inspect.getargspec(fn)[0]\n+        legal_params = set(legal_params)\n+\n+        for params_name in params:\n+            if params_name not in legal_params:\n+                assert False, '{} is not a legal parameter'.format(params_name)\n \n     def get_params(self, deep=True):\n         '''Get parameters for this estimator.\n@@ -79,6 +106,7 @@ class BaseWrapper(object):\n         # Returns\n             self\n         '''\n+        self.check_params(params)\n         self.sk_params.update(params)\n         return self\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#126b82056140ab46b7af08b31f2f310aaefb9b8f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 1051 | Contributors (this commit): 10 | Commits (past 90d): 33 | Contributors (cumulative): 10 | DMM Complexity: 0.0\n\nDIFF:\n@@ -469,6 +469,9 @@ def rnn(step_function, inputs, initial_states,\n         mask = tf.cast(tf.transpose(mask, axes), tf.bool)\n         mask_list = tf.unpack(mask)\n \n+        if go_backwards:\n+            mask_list.reverse()\n+\n         for input, mask_t in zip(input_list, mask_list):\n             output, new_states = step_function(input, states + constants)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#71d46b715372c6aa626670e7ec0855f8b9a2366e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 926 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -55,8 +55,8 @@ class BaseWrapper(object):\n         self.check_params(sk_params)\n \n     def check_params(self, params):\n-        '''Check user's typo in params' name to avoid unwanted usage of\n-        default values\n+        '''Check for user typos in \"params\" keys to avoid\n+        unwanted usage of default values\n \n         # Arguments\n             params: dictionary\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8606edf3bf8477204b1054a50f9323ea2cd67416", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 13 | Files Changed: 3 | Hunks: 9 | Methods Changed: 8 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 40 | Churn Cumulative: 7348 | Contributors (this commit): 51 | Commits (past 90d): 145 | Contributors (cumulative): 66 | DMM Complexity: 0.0\n\nDIFF:\n@@ -402,7 +402,7 @@ class Function(object):\n         return updated[:len(self.outputs)]\n \n \n-def function(inputs, outputs, updates=[]):\n+def function(inputs, outputs, updates=[], **kwargs):\n     return Function(inputs, outputs, updates=updates)\n \n \n\n@@ -449,8 +449,8 @@ class Function(object):\n         return self.function(*inputs)\n \n \n-def function(inputs, outputs, updates=[]):\n-    return Function(inputs, outputs, updates=updates)\n+def function(inputs, outputs, updates=[], **kwargs):\n+    return Function(inputs, outputs, updates=updates, **kwargs)\n \n \n def gradients(loss, variables):\n\n@@ -471,7 +471,8 @@ class Sequential(Model, containers.Sequential):\n     '''\n     def compile(self, optimizer, loss,\n                 class_mode=\"categorical\",\n-                sample_weight_mode=None):\n+                sample_weight_mode=None,\n+                **kwargs):\n         '''Configure the learning process.\n \n         # Arguments\n@@ -485,6 +486,8 @@ class Sequential(Model, containers.Sequential):\n             sample_weight_mode: if you need to do timestep-wise\n                 sample weighting (2D weights), set this to \"temporal\".\n                 \"None\" defaults to sample-wise weights (1D).\n+            kwargs: for Theano backend, these are passed into K.function.\n+                Ignored for Tensorflow backend.\n         '''\n         self.optimizer = optimizers.get(optimizer)\n         self.sample_weight_mode = sample_weight_mode\n@@ -544,11 +547,18 @@ class Sequential(Model, containers.Sequential):\n             test_ins = [self.X_test, self.y, self.weights]\n             predict_ins = [self.X_test]\n \n-        self._train = K.function(train_ins, [train_loss], updates=updates)\n-        self._train_with_acc = K.function(train_ins, [train_loss, train_accuracy], updates=updates)\n-        self._predict = K.function(predict_ins, [self.y_test], updates=self.state_updates)\n-        self._test = K.function(test_ins, [test_loss], updates=self.state_updates)\n-        self._test_with_acc = K.function(test_ins, [test_loss, test_accuracy], updates=self.state_updates)\n+        self._train = K.function(train_ins, [train_loss],\n+                                 updates=updates, **kwargs)\n+        self._train_with_acc = K.function(train_ins,\n+                                          [train_loss, train_accuracy],\n+                                          updates=updates, **kwargs)\n+        self._predict = K.function(predict_ins, [self.y_test],\n+                                   updates=self.state_updates, **kwargs)\n+        self._test = K.function(test_ins, [test_loss],\n+                                updates=self.state_updates, **kwargs)\n+        self._test_with_acc = K.function(test_ins,\n+                                         [test_loss, test_accuracy],\n+                                         updates=self.state_updates, **kwargs)\n \n     def fit(self, X, y, batch_size=128, nb_epoch=100, verbose=1, callbacks=[],\n             validation_split=0., validation_data=None, shuffle=True,\n@@ -1173,7 +1183,7 @@ class Graph(Model, containers.Graph):\n \n     Inherits from `containers.Graph`.\n     '''\n-    def compile(self, optimizer, loss, sample_weight_modes={}):\n+    def compile(self, optimizer, loss, sample_weight_modes={}, **kwargs):\n         '''Configure the learning process.\n \n         # Arguments\n@@ -1188,6 +1198,8 @@ class Graph(Model, containers.Graph):\n                 timestep-wise loss weighting on one of your graph outputs,\n                 you will need to set the sample weight mode for this output\n                 to \"temporal\".\n+            kwargs: for Theano backend, these are passed into K.function.\n+                Ignored for Tensorflow backend.\n         '''\n         assert type(loss) is dict, 'The \"loss\" argument should be a dictionary.'\n         assert type(sample_weight_modes) is dict, 'The \"sample_weight_modes\" argument should be a dictionary.'\n@@ -1236,10 +1248,12 @@ class Graph(Model, containers.Graph):\n         updates += self.updates\n         self.loss = loss\n \n-        self._train = K.function(train_ins, [train_loss], updates=updates)\n-        self._test = K.function(test_ins, [test_loss], updates=self.state_updates)\n+        self._train = K.function(train_ins, [train_loss],\n+                                 updates=updates, **kwargs)\n+        self._test = K.function(test_ins, [test_loss],\n+                                updates=self.state_updates, **kwargs)\n         self._predict = K.function(inputs=ins, outputs=ys_test,\n-                                   updates=self.state_updates)\n+                                   updates=self.state_updates, **kwargs)\n \n     def fit(self, data, batch_size=128, nb_epoch=100, verbose=1, callbacks=[],\n             validation_split=0., validation_data=None, shuffle=True,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e73cf505a799966d2215901388a12cc089ec7727", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 14 | Churn Cumulative: 2397 | Contributors (this commit): 19 | Commits (past 90d): 72 | Contributors (cumulative): 26 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,6 +1,7 @@\n import tensorflow as tf\n import numpy as np\n import os\n+import warnings\n from .common import _FLOATX, _EPSILON\n \n # INTERNAL UTILS\n@@ -403,6 +404,12 @@ class Function(object):\n \n \n def function(inputs, outputs, updates=[], **kwargs):\n+    if len(kwargs) > 0:\n+        msg = [\n+            \"Expected no kwargs, you passed %s\" % len(kwargs),\n+            \"kwargs passed to function are ignored with Tensorflow backend\"\n+        ]\n+        warnings.warn('\\n'.join(msg))\n     return Function(inputs, outputs, updates=updates)\n \n \n\n@@ -3,6 +3,7 @@ from theano import tensor as T\n from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n from theano.tensor.signal import pool\n from theano.tensor.nnet import conv3d2d\n+import inspect\n import numpy as np\n from .common import _FLOATX, _EPSILON\n \n@@ -450,6 +451,12 @@ class Function(object):\n \n \n def function(inputs, outputs, updates=[], **kwargs):\n+    if len(kwargs) > 0:\n+        function_args = inspect.getargspec(theano.function)[0]\n+        for key in kwargs.keys():\n+            if key not in function_args:\n+                msg = \"Invalid argument '%s' passed to K.function\" % key\n+                raise ValueError(msg)\n     return Function(inputs, outputs, updates=updates, **kwargs)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ef1e959505e7838e5d655af9fa67f1487e09eca7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 8 | Churn Cumulative: 8199 | Contributors (this commit): 45 | Commits (past 90d): 70 | Contributors (cumulative): 50 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1722,6 +1722,10 @@ class Siamese(Layer):\n                     self.constraints.append(c)\n         super(Siamese, self).__init__()\n \n+    @property\n+    def input_shape(self):\n+        return [layer.output_shape for layer in self.inputs]\n+\n     @property\n     def output_shape(self):\n         if self.merge_mode is None:\n\n@@ -149,6 +149,6 @@ def to_graph(model, **kwargs):\n     return ModelToDot()(model, **kwargs)\n \n \n-def plot(model, to_file='model.png'):\n-    graph = to_graph(model)\n+def plot(model, to_file='model.png', **kwargs):\n+    graph = to_graph(model, **kwargs)\n     graph.write_png(to_file)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9c9318ff6b01d83ff75eb112cb4c344cce5d59a9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 265 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -21,6 +21,7 @@ from scipy.optimize import fmin_l_bfgs_b\n import time\n import argparse\n import h5py\n+import os\n \n from keras.models import Sequential\n from keras.layers.convolutional import Convolution2D, ZeroPadding2D, MaxPooling2D\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#524090e6007b4ad0290e04f7101821972bc1026a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 63 | Lines Deleted: 56 | Files Changed: 2 | Hunks: 33 | Methods Changed: 11 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 119 | Churn Cumulative: 468 | Contributors (this commit): 15 | Commits (past 90d): 10 | Contributors (cumulative): 16 | DMM Complexity: 0.0\n\nDIFF:\n@@ -4,19 +4,20 @@ import numpy as np\n import random\n from six.moves import range\n \n-def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.):\n-    \"\"\"\n-        Pad each sequence to the same length:\n+\n+def pad_sequences(sequences, maxlen=None, dtype='int32',\n+                  padding='pre', truncating='pre', value=0.):\n+    '''Pads each sequence to the same length:\n     the length of the longest sequence.\n \n     If maxlen is provided, any sequence longer\n-        than maxlen is truncated to maxlen. Truncation happens off either the beginning (default) or\n+    than maxlen is truncated to maxlen.\n+    Truncation happens off either the beginning (default) or\n     the end of the sequence.\n \n     Supports post-padding and pre-padding (default).\n \n-        Parameters:\n-        -----------\n+    # Arguments\n         sequences: list of lists where each element is a sequence\n         maxlen: int, maximum length\n         dtype: type to cast the resulting sequence.\n@@ -25,10 +26,9 @@ def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncati\n             maxlen either in the beginning or in the end of the sequence\n         value: float, value to pad the sequences to the desired value.\n \n-        Returns:\n+    # Returns\n         x: numpy array with dimensions (number_of_sequences, maxlen)\n-\n-    \"\"\"\n+    '''\n     lengths = [len(s) for s in sequences]\n \n     nb_samples = len(sequences)\n@@ -52,26 +52,25 @@ def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncati\n         elif truncating == 'post':\n             trunc = s[:maxlen]\n         else:\n-            raise ValueError(\"Truncating type '%s' not understood\" % truncating)\n+            raise ValueError('Truncating type \"%s\" not understood' % truncating)\n \n         # check `trunc` has expected shape\n         trunc = np.asarray(trunc, dtype=dtype)\n         if trunc.shape[1:] != sample_shape:\n-            raise ValueError(\"Shape of sample %s of sequence at position %s is different from expected shape %s\"\n-                             % (trunc.shape[1:], idx, sample_shape))\n+            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n+                             (trunc.shape[1:], idx, sample_shape))\n \n         if padding == 'post':\n             x[idx, :len(trunc)] = trunc\n         elif padding == 'pre':\n             x[idx, -len(trunc):] = trunc\n         else:\n-            raise ValueError(\"Padding type '%s' not understood\" % padding)\n+            raise ValueError('Padding type \"%s\" not understood' % padding)\n     return x\n \n \n def make_sampling_table(size, sampling_factor=1e-5):\n-    '''\n-        This generates an array where the ith element\n+    '''This generates an array where the ith element\n     is the probability that a word of rank i would be sampled,\n     according to the sampling distribution used in word2vec.\n \n@@ -83,8 +82,7 @@ def make_sampling_table(size, sampling_factor=1e-5):\n        frequency(rank) ~ 1/(rank * (log(rank) + gamma) + 1/2 - 1/(12*rank))\n         where gamma is the Euler-Mascheroni constant.\n \n-        Parameters:\n-        -----------\n+    # Arguments\n         size: int, number of possible words to sample.\n     '''\n     gamma = 0.577\n@@ -99,28 +97,28 @@ def make_sampling_table(size, sampling_factor=1e-5):\n def skipgrams(sequence, vocabulary_size,\n               window_size=4, negative_samples=1., shuffle=True,\n               categorical=False, sampling_table=None):\n-    '''\n-        Take a sequence (list of indexes of words),\n+    '''Take a sequence (list of indexes of words),\n     returns couples of [word_index, other_word index] and labels (1s or 0s),\n     where label = 1 if 'other_word' belongs to the context of 'word',\n     and label=0 if 'other_word' is ramdomly sampled\n \n-        Paramaters:\n-        -----------\n+    # Arguments\n         vocabulary_size: int. maximum possible word index + 1\n-        window_size: int. actually half-window. The window of a word wi will be [i-window_size, i+window_size+1]\n-        negative_samples: float >= 0. 0 for no negative (=random) samples. 1 for same number as positive samples. etc.\n-        categorical: bool. if False, labels will be integers (eg. [0, 1, 1 .. ]),\n+        window_size: int. actually half-window.\n+            The window of a word wi will be [i-window_size, i+window_size+1]\n+        negative_samples: float >= 0. 0 for no negative (=random) samples.\n+            1 for same number as positive samples. etc.\n+        categorical: bool. if False, labels will be\n+            integers (eg. [0, 1, 1 .. ]),\n             if True labels will be categorical eg. [[1,0],[0,1],[0,1] .. ]\n \n-        Returns:\n-        --------\n+    # Returns\n         couples, lables: where `couples` are int pairs and\n             `labels` are either 0 or 1.\n \n-        Notes:\n-        ------\n-        By convention, index 0 in the vocabulary is a non-word and will be skipped.\n+    # Notes\n+        By convention, index 0 in the vocabulary is\n+        a non-word and will be skipped.\n     '''\n     couples = []\n     labels = []\n\n@@ -1,6 +1,5 @@\n # -*- coding: utf-8 -*-\n-'''\n-    These preprocessing utils would greatly benefit\n+'''These preprocessing utilities would greatly benefit\n from a fast Cython rewrite.\n '''\n from __future__ import absolute_import\n@@ -75,8 +74,7 @@ class Tokenizer(object):\n         self.char_level = char_level\n \n     def fit_on_texts(self, texts):\n-        '''\n-            required before using texts_to_sequences or texts_to_matrix\n+        '''Required before using texts_to_sequences or texts_to_matrix\n \n         # Arguments\n             texts: can be a list of strings,\n@@ -107,8 +105,7 @@ class Tokenizer(object):\n             self.index_docs[self.word_index[w]] = c\n \n     def fit_on_sequences(self, sequences):\n-        '''\n-            required before using sequences_to_matrix\n+        '''Required before using sequences_to_matrix\n         (if fit_on_texts was never called)\n         '''\n         self.document_count = len(sequences)\n@@ -122,8 +119,7 @@ class Tokenizer(object):\n                     self.index_docs[i] += 1\n \n     def texts_to_sequences(self, texts):\n-        '''\n-            Transform each text in texts in a sequence of integers.\n+        '''Transforms each text in texts in a sequence of integers.\n         Only top \"nb_words\" most frequent words will be taken into account.\n         Only words known by the tokenizer will be taken into account.\n \n@@ -135,12 +131,14 @@ class Tokenizer(object):\n         return res\n \n     def texts_to_sequences_generator(self, texts):\n-        '''\n-            Transform each text in texts in a sequence of integers.\n+        '''Transforms each text in texts in a sequence of integers.\n         Only top \"nb_words\" most frequent words will be taken into account.\n         Only words known by the tokenizer will be taken into account.\n \n         Yields individual sequences.\n+\n+        # Arguments:\n+            texts: list of strings.\n         '''\n         nb_words = self.nb_words\n         for text in texts:\n@@ -150,56 +148,67 @@ class Tokenizer(object):\n                 i = self.word_index.get(w)\n                 if i is not None:\n                     if nb_words and i >= nb_words:\n-                        pass\n+                        continue\n                     else:\n                         vect.append(i)\n             yield vect\n \n-    def texts_to_matrix(self, texts, mode=\"binary\"):\n-        '''\n-            modes: binary, count, tfidf, freq\n+    def texts_to_matrix(self, texts, mode='binary'):\n+        '''Convert a list of texts to a Numpy matrix,\n+        according to some vectorization mode.\n+\n+        # Arguments:\n+            texts: list of strings.\n+            modes: one of \"binary\", \"count\", \"tfidf\", \"freq\"\n         '''\n         sequences = self.texts_to_sequences(texts)\n         return self.sequences_to_matrix(sequences, mode=mode)\n \n-    def sequences_to_matrix(self, sequences, mode=\"binary\"):\n-        '''\n-            modes: binary, count, tfidf, freq\n+    def sequences_to_matrix(self, sequences, mode='binary'):\n+        '''Converts a list of sequences into a Numpy matrix,\n+        according to some vectorization mode.\n+\n+        # Arguments:\n+            sequences: list of sequences\n+                (a sequence is a list of integer word indices).\n+            modes: one of \"binary\", \"count\", \"tfidf\", \"freq\"\n         '''\n         if not self.nb_words:\n             if self.word_index:\n                 nb_words = len(self.word_index) + 1\n             else:\n-                raise Exception(\"Specify a dimension (nb_words argument), or fit on some text data first.\")\n+                raise Exception('Specify a dimension (nb_words argument), '\n+                                'or fit on some text data first.')\n         else:\n             nb_words = self.nb_words\n \n-        if mode == \"tfidf\" and not self.document_count:\n-            raise Exception(\"Fit the Tokenizer on some data before using tfidf mode.\")\n+        if mode == 'tfidf' and not self.document_count:\n+            raise Exception('Fit the Tokenizer on some data '\n+                            'before using tfidf mode.')\n \n         X = np.zeros((len(sequences), nb_words))\n         for i, seq in enumerate(sequences):\n             if not seq:\n-                pass\n+                continue\n             counts = {}\n             for j in seq:\n                 if j >= nb_words:\n-                    pass\n+                    continue\n                 if j not in counts:\n                     counts[j] = 1.\n                 else:\n                     counts[j] += 1\n             for j, c in list(counts.items()):\n-                if mode == \"count\":\n+                if mode == 'count':\n                     X[i][j] = c\n-                elif mode == \"freq\":\n+                elif mode == 'freq':\n                     X[i][j] = c / len(seq)\n-                elif mode == \"binary\":\n+                elif mode == 'binary':\n                     X[i][j] = 1\n-                elif mode == \"tfidf\":\n+                elif mode == 'tfidf':\n                     tf = np.log(c / len(seq))\n                     df = (1 + np.log(1 + self.index_docs.get(j, 0) / (1 + self.document_count)))\n                     X[i][j] = tf / df\n                 else:\n-                    raise Exception(\"Unknown vectorization mode: \" + str(mode))\n+                    raise Exception('Unknown vectorization mode: ' + str(mode))\n         return X\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cf3ab771d345a511b9f999aa7a75ac23b48570be", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 110 | Lines Deleted: 86 | Files Changed: 2 | Hunks: 32 | Methods Changed: 21 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 196 | Churn Cumulative: 658 | Contributors (this commit): 9 | Commits (past 90d): 16 | Contributors (cumulative): 11 | DMM Complexity: 0.9761904761904762\n\nDIFF:\n@@ -1,3 +1,7 @@\n+'''Fairly basic set of tools for realtime data augmentation on image data.\n+Can easily be extended to include new transformations,\n+new preprocessing methods, etc...\n+'''\n from __future__ import absolute_import\n \n import numpy as np\n@@ -12,12 +16,8 @@ import math\n from six.moves import range\n import threading\n \n-'''Fairly basic set of tools for realtime data augmentation on image data.\n-Can easily be extended to include new transformations, new preprocessing methods, etc...\n-'''\n \n-\n-def random_rotation(x, rg, fill_mode=\"nearest\", cval=0.):\n+def random_rotation(x, rg, fill_mode='nearest', cval=0.):\n     angle = random.uniform(-rg, rg)\n     x = ndimage.interpolation.rotate(x, angle,\n                                      axes=(1, 2),\n@@ -27,7 +27,7 @@ def random_rotation(x, rg, fill_mode=\"nearest\", cval=0.):\n     return x\n \n \n-def random_shift(x, wrg, hrg, fill_mode=\"nearest\", cval=0.):\n+def random_shift(x, wrg, hrg, fill_mode='nearest', cval=0.):\n     shift_x = shift_y = 0\n \n     if wrg:\n@@ -58,7 +58,7 @@ def random_barrel_transform(x, intensity):\n     pass\n \n \n-def random_shear(x, intensity, fill_mode=\"nearest\", cval=0.):\n+def random_shear(x, intensity, fill_mode='nearest', cval=0.):\n     shear = random.uniform(-intensity, intensity)\n     shear_matrix = np.array([[1.0, -math.sin(shear), 0.0],\n                             [0.0, math.cos(shear), 0.0],\n@@ -75,7 +75,7 @@ def random_channel_shift(x, rg):\n     pass\n \n \n-def random_zoom(x, rg, fill_mode=\"nearest\", cval=0.):\n+def random_zoom(x, rg, fill_mode='nearest', cval=0.):\n     zoom_w = random.uniform(1.-rg, 1.)\n     zoom_h = random.uniform(1.-rg, 1.)\n     x = ndimage.interpolation.zoom(x, zoom=(1., zoom_w, zoom_h),\n@@ -93,10 +93,10 @@ def array_to_img(x, scale=True):\n         x *= 255\n     if x.shape[2] == 3:\n         # RGB\n-        return Image.fromarray(x.astype(\"uint8\"), \"RGB\")\n+        return Image.fromarray(x.astype('uint8'), 'RGB')\n     else:\n         # grayscale\n-        return Image.fromarray(x[:, :, 0].astype(\"uint8\"), \"L\")\n+        return Image.fromarray(x[:, :, 0].astype('uint8'), 'L')\n \n \n def img_to_array(img):\n@@ -127,21 +127,33 @@ def list_pictures(directory, ext='jpg|jpeg|bmp|png'):\n \n class ImageDataGenerator(object):\n     '''Generate minibatches with\n-    realtime data augmentation.\n+    real-time data augmentation.\n+\n+    # Arguments\n+        featurewise_center: set input mean to 0 over the dataset.\n+        samplewise_center: set each sample mean to 0.\n+        featurewise_std_normalization: divide inputs by std of the dataset.\n+        samplewise_std_normalization: divide each input by its std.\n+        zca_whitening: apply ZCA whitening.\n+        rotation_range: degrees (0 to 180).\n+        width_shift_range: fraction of total width.\n+        height_shift_range: fraction of total height.\n+        shear_range: shear intensity (shear angle in radians).\n+        horizontal_flip: whether to randomly flip images horizontally.\n+        vertical_flip: whether to randomly flip images vertically.\n     '''\n     def __init__(self,\n-                 featurewise_center=True,  # set input mean to 0 over the dataset\n-                 samplewise_center=False,  # set each sample mean to 0\n-                 featurewise_std_normalization=True,  # divide inputs by std of the dataset\n-                 samplewise_std_normalization=False,  # divide each input by its std\n-                 zca_whitening=False,  # apply ZCA whitening\n-                 rotation_range=0.,  # degrees (0 to 180)\n-                 width_shift_range=0.,  # fraction of total width\n-                 height_shift_range=0.,  # fraction of total height\n-                 shear_range=0.,  # shear intensity (shear angle in radians)\n+                 featurewise_center=True,\n+                 samplewise_center=False,\n+                 featurewise_std_normalization=True,\n+                 samplewise_std_normalization=False,\n+                 zca_whitening=False,\n+                 rotation_range=0.,\n+                 width_shift_range=0.,\n+                 height_shift_range=0.,\n+                 shear_range=0.,\n                  horizontal_flip=False,\n                  vertical_flip=False):\n-\n         self.__dict__.update(locals())\n         self.mean = None\n         self.std = None\n@@ -172,26 +184,30 @@ class ImageDataGenerator(object):\n             else:\n                 b = 0\n             total_b += 1\n-            yield index_array[current_index: current_index + current_batch_size], current_index, current_batch_size\n+            yield (index_array[current_index: current_index + current_batch_size],\n+                   current_index, current_batch_size)\n \n     def flow(self, X, y, batch_size=32, shuffle=False, seed=None,\n-             save_to_dir=None, save_prefix=\"\", save_format=\"jpeg\"):\n+             save_to_dir=None, save_prefix='', save_format='jpeg'):\n         assert len(X) == len(y)\n         self.X = X\n         self.y = y\n         self.save_to_dir = save_to_dir\n         self.save_prefix = save_prefix\n         self.save_format = save_format\n-        self.flow_generator = self._flow_index(X.shape[0], batch_size, shuffle, seed)\n+        self.flow_generator = self._flow_index(X.shape[0], batch_size,\n+                                               shuffle, seed)\n         return self\n \n     def __iter__(self):\n-        # needed if we want to do something like for x, y in data_gen.flow(...):\n+        # needed if we want to do something like:\n+        # for x, y in data_gen.flow(...):\n         return self\n \n     def next(self):\n-        # for python 2.x\n-        # Keep under lock only the mechainsem which advance the indexing of each batch\n+        # for python 2.x.\n+        # Keeps under lock only the mechanism which advances\n+        # the indexing of each batch\n         # see # http://anandology.com/blog/using-iterators-and-generators/\n         with self.lock:\n             index_array, current_index, current_batch_size = next(self.flow_generator)\n@@ -199,21 +215,26 @@ class ImageDataGenerator(object):\n         bX = np.zeros(tuple([current_batch_size] + list(self.X.shape)[1:]))\n         for i, j in enumerate(index_array):\n             x = self.X[j]\n-            x = self.random_transform(x.astype(\"float32\"))\n+            x = self.random_transform(x.astype('float32'))\n             x = self.standardize(x)\n             bX[i] = x\n         if self.save_to_dir:\n             for i in range(current_batch_size):\n                 img = array_to_img(bX[i], scale=True)\n-                img.save(self.save_to_dir + \"/\" + self.save_prefix + \"_\" + str(current_index + i) + \".\" + self.save_format)\n+                img.save(self.save_to_dir + '/' + self.save_prefix + '_' + str(current_index + i) + '.' + self.save_format)\n         bY = self.y[index_array]\n         return bX, bY\n \n     def __next__(self):\n-        # for python 3.x\n+        # for python 3.x.\n         return self.next()\n \n     def standardize(self, x):\n+        if self.samplewise_center:\n+            x -= np.mean(x, axis=1, keepdims=True)\n+        if self.samplewise_std_normalization:\n+            x /= (np.std(x, axis=1, keepdims=True) + 1e-7)\n+\n         if self.featurewise_center:\n             x -= self.mean\n         if self.featurewise_std_normalization:\n@@ -224,11 +245,6 @@ class ImageDataGenerator(object):\n             whitex = np.dot(flatx, self.principal_components)\n             x = np.reshape(whitex, (x.shape[0], x.shape[1], x.shape[2]))\n \n-        if self.samplewise_center:\n-            x -= np.mean(x, axis=1, keepdims=True)\n-        if self.samplewise_std_normalization:\n-            x /= (np.std(x, axis=1, keepdims=True) + 1e-7)\n-\n         return x\n \n     def random_transform(self, x):\n@@ -251,10 +267,18 @@ class ImageDataGenerator(object):\n         return x\n \n     def fit(self, X,\n-            augment=False,  # fit on randomly augmented samples\n-            rounds=1,  # if augment, how many augmentation passes over the data do we use\n+            augment=False,\n+            rounds=1,\n             seed=None):\n-        '''Required for featurewise_center, featurewise_std_normalization and zca_whitening.\n+        '''Required for featurewise_center, featurewise_std_normalization\n+        and zca_whitening.\n+\n+        # Arguments\n+            X: Numpy array, the data to fit on.\n+            augment: whether to fit on randomly augmented samples\n+            rounds: if `augment`,\n+                how many augmentation passes to do over the data\n+            seed: random seed.\n         '''\n         X = np.copy(X)\n         if augment:\n\n@@ -1,59 +1,59 @@\n-# import pytest\n-# from keras.preprocessing.image import *\n-# from PIL import Image\n-# import numpy as np\n-# import os\n-# import shutil\n+import pytest\n+from keras.preprocessing.image import *\n+from PIL import Image\n+import numpy as np\n+import os\n+import shutil\n \n \n-# def setup_function(func):\n-#     os.mkdir('test_images')\n-#     os.mkdir('test_images/rgb')\n-#     os.mkdir('test_images/gsc')\n+def setup_function(func):\n+    os.mkdir('test_images')\n+    os.mkdir('test_images/rgb')\n+    os.mkdir('test_images/gsc')\n \n-#     img_w = img_h = 20\n-#     for n in range(8):\n-#         bias = np.random.rand(img_w, img_h, 1) * 64\n-#         variance = np.random.rand(img_w, img_h, 1) * (255-64)\n-#         imarray = np.random.rand(img_w, img_h, 3) * variance + bias\n-#         im = Image.fromarray(imarray.astype('uint8')).convert('RGBA')\n-#         im.save('test_images/rgb/rgb_test_image_'+str(n)+'.png')\n+    img_w = img_h = 20\n+    for n in range(8):\n+        bias = np.random.rand(img_w, img_h, 1) * 64\n+        variance = np.random.rand(img_w, img_h, 1) * (255-64)\n+        imarray = np.random.rand(img_w, img_h, 3) * variance + bias\n+        im = Image.fromarray(imarray.astype('uint8')).convert('RGBA')\n+        im.save('test_images/rgb/rgb_test_image_'+str(n)+'.png')\n \n-#         imarray = np.random.rand(img_w, img_h, 1) * variance + bias\n-#         im = Image.fromarray(imarray.astype('uint8').squeeze()).convert('L')\n-#         im.save('test_images/gsc/gsc_test_image_'+str(n)+'.png')\n+        imarray = np.random.rand(img_w, img_h, 1) * variance + bias\n+        im = Image.fromarray(imarray.astype('uint8').squeeze()).convert('L')\n+        im.save('test_images/gsc/gsc_test_image_'+str(n)+'.png')\n \n \n-# def teardown_function(func):\n-#     shutil.rmtree('test_images')\n+def teardown_function(func):\n+    shutil.rmtree('test_images')\n \n \n-# def test_image_data_generator():\n-#     for color_mode in ['gsc', 'rgb']:\n-#         file_list = list_pictures('test_images/' + color_mode)\n-#         img_list = []\n-#         for f in file_list:\n-#             img_list.append(img_to_array(load_img(f))[None, ...])\n+def test_image_data_generator():\n+    for color_mode in ['gsc', 'rgb']:\n+        file_list = list_pictures('test_images/' + color_mode)\n+        img_list = []\n+        for f in file_list:\n+            img_list.append(img_to_array(load_img(f))[None, ...])\n \n-#         images = np.vstack(img_list)\n-#         generator = ImageDataGenerator(\n-#             featurewise_center=True,\n-#             samplewise_center=True,\n-#             featurewise_std_normalization=True,\n-#             samplewise_std_normalization=True,\n-#             zca_whitening=True,\n-#             rotation_range=90.,\n-#             width_shift_range=10.,\n-#             height_shift_range=10.,\n-#             shear_range=0.5,\n-#             horizontal_flip=True,\n-#             vertical_flip=True)\n-#         generator.fit(images, augment=True)\n+        images = np.vstack(img_list)\n+        generator = ImageDataGenerator(\n+            featurewise_center=True,\n+            samplewise_center=True,\n+            featurewise_std_normalization=True,\n+            samplewise_std_normalization=True,\n+            zca_whitening=True,\n+            rotation_range=90.,\n+            width_shift_range=10.,\n+            height_shift_range=10.,\n+            shear_range=0.5,\n+            horizontal_flip=True,\n+            vertical_flip=True)\n+        generator.fit(images, augment=True)\n \n-#         for x, y in generator.flow(images, np.arange(images.shape[0]),\n-#                                    shuffle=True, save_to_dir='test_images'):\n-#             assert x.shape[1:] == images.shape[1:]\n-#             break\n+        for x, y in generator.flow(images, np.arange(images.shape[0]),\n+                                   shuffle=True, save_to_dir='test_images'):\n+            assert x.shape[1:] == images.shape[1:]\n+            break\n \n-# if __name__ == '__main__':\n-#     pytest.main([__file__])\n+if __name__ == '__main__':\n+    pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0c1af0901d2f7386a1ddb25c61e84794d4ca641e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 201 | Lines Deleted: 37 | Files Changed: 5 | Hunks: 52 | Methods Changed: 20 | Complexity Δ (Sum/Max): 35/35 | Churn Δ: 238 | Churn Cumulative: 5996 | Contributors (this commit): 43 | Commits (past 90d): 45 | Contributors (cumulative): 50 | DMM Complexity: 0.0\n\nDIFF:\n@@ -55,7 +55,7 @@ model.compile('adam', {'output': 'binary_crossentropy'})\n print('Train...')\n model.fit({'input': X_train, 'output': y_train},\n           batch_size=batch_size,\n-          nb_epoch=4)\n+          nb_epoch=4, show_accuracy=True)\n acc = accuracy(y_test,\n                np.round(np.array(model.predict({'input': X_test},\n                                                batch_size=batch_size)['output'])))\n\n@@ -71,8 +71,7 @@ model.add(Dense(1))\n model.add(Activation('sigmoid'))\n \n model.compile(loss='binary_crossentropy',\n-              optimizer='rmsprop',\n-              class_mode='binary')\n+              optimizer='rmsprop')\n model.fit(X_train, y_train, batch_size=batch_size,\n           nb_epoch=nb_epoch, show_accuracy=True,\n           validation_data=(X_test, y_test))\n\n@@ -38,7 +38,7 @@ print('Loading data...')\n print(len(X_train), 'train sequences')\n print(len(X_test), 'test sequences')\n \n-print(\"Pad sequences (samples x time)\")\n+print('Pad sequences (samples x time)')\n X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n print('X_train shape:', X_train.shape)\n@@ -54,10 +54,9 @@ model.add(Activation('sigmoid'))\n \n # try using different optimizers and different optimizer configs\n model.compile(loss='binary_crossentropy',\n-              optimizer='adam',\n-              class_mode=\"binary\")\n+              optimizer='adam')\n \n-print(\"Train...\")\n+print('Train...')\n model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=15,\n           validation_data=(X_test, y_test), show_accuracy=True)\n score, acc = model.evaluate(X_test, y_test,\n\n@@ -207,7 +207,10 @@ def model_from_config(config, custom_objects={}):\n                           class_mode=class_mode, sample_weight_mode=sample_weight_mode)\n         elif model_name == 'Graph':\n             sample_weight_modes = config.get('sample_weight_modes', {})\n-            model.compile(loss=loss, optimizer=optimizer, sample_weight_modes=sample_weight_modes)\n+            loss_weights = config.get('loss_weights', {})\n+            model.compile(loss=loss, optimizer=optimizer,\n+                          sample_weight_modes=sample_weight_modes,\n+                          loss_weights=loss_weights)\n     return model\n \n \n@@ -406,7 +409,7 @@ class Model(object):\n         `keras.models.model_from_config(config, custom_objects={})`.\n         '''\n         config = super(Model, self).get_config()\n-        for p in ['class_mode', 'sample_weight_mode', 'sample_weight_modes']:\n+        for p in ['sample_weight_mode', 'sample_weight_modes', 'loss_weights']:\n             if hasattr(self, p):\n                 config[p] = getattr(self, p)\n         if hasattr(self, 'optimizer'):\n@@ -470,7 +473,7 @@ class Sequential(Model, containers.Sequential):\n     Inherits from containers.Sequential.\n     '''\n     def compile(self, optimizer, loss,\n-                class_mode=\"categorical\",\n+                class_mode=None,\n                 sample_weight_mode=None,\n                 **kwargs):\n         '''Configure the learning process.\n@@ -480,15 +483,17 @@ class Sequential(Model, containers.Sequential):\n                 See [optimizers](optimizers.md).\n             loss: str (name of objective function) or objective function.\n                 See [objectives](objectives.md).\n-            class_mode: one of \"categorical\", \"binary\".\n-                This is only used for computing classification accuracy or\n-                using the predict_classes method.\n+            class_mode: deprecated argument,\n+                it is set automatically starting with Keras 0.3.3.\n             sample_weight_mode: if you need to do timestep-wise\n                 sample weighting (2D weights), set this to \"temporal\".\n                 \"None\" defaults to sample-wise weights (1D).\n             kwargs: for Theano backend, these are passed into K.function.\n                 Ignored for Tensorflow backend.\n         '''\n+        if class_mode is not None:\n+            warnings.warn('The \"class_mode\" argument is deprecated, please remove it from your code.')\n+\n         self.optimizer = optimizers.get(optimizer)\n         self.sample_weight_mode = sample_weight_mode\n \n@@ -510,25 +515,33 @@ class Sequential(Model, containers.Sequential):\n         else:\n             self.weights = K.placeholder(ndim=1)\n \n-        if hasattr(self.layers[-1], \"get_output_mask\"):\n+        if hasattr(self.layers[-1], 'get_output_mask'):\n             mask = self.layers[-1].get_output_mask()\n         else:\n             mask = None\n         train_loss = weighted_loss(self.y, self.y_train, self.weights, mask)\n         test_loss = weighted_loss(self.y, self.y_test, self.weights, mask)\n \n-        if class_mode == \"categorical\":\n+        # set class_mode, for accuracy computation:\n+        if self.output_shape[-1] == 1:\n+            class_mode = 'binary'\n+        else:\n+            class_mode = 'categorical'\n+        self.class_mode = class_mode\n+\n+        if class_mode == 'categorical':\n             train_accuracy = K.mean(K.equal(K.argmax(self.y, axis=-1),\n                                             K.argmax(self.y_train, axis=-1)))\n             test_accuracy = K.mean(K.equal(K.argmax(self.y, axis=-1),\n                                            K.argmax(self.y_test, axis=-1)))\n-\n-        elif class_mode == \"binary\":\n+        elif class_mode == 'binary':\n+            if self.loss.__name__ == 'categorical_crossentropy':\n+                warnings.warn('Your model output has shape ' + str(self.output_shape) +\n+                              ' (1-dimensional features), but you are using ' +\n+                              ' the `categorical_crossentropy` loss. You ' +\n+                              'almost certainly want to use `binary_crossentropy` instead.')\n             train_accuracy = K.mean(K.equal(self.y, K.round(self.y_train)))\n             test_accuracy = K.mean(K.equal(self.y, K.round(self.y_test)))\n-        else:\n-            raise Exception(\"Invalid class mode:\" + str(class_mode))\n-        self.class_mode = class_mode\n \n         for r in self.regularizers:\n             train_loss = r(train_loss)\n@@ -1183,7 +1196,8 @@ class Graph(Model, containers.Graph):\n \n     Inherits from `containers.Graph`.\n     '''\n-    def compile(self, optimizer, loss, sample_weight_modes={}, **kwargs):\n+    def compile(self, optimizer, loss, sample_weight_modes={},\n+                loss_weights={}, **kwargs):\n         '''Configure the learning process.\n \n         # Arguments\n@@ -1198,6 +1212,10 @@ class Graph(Model, containers.Graph):\n                 timestep-wise loss weighting on one of your graph outputs,\n                 you will need to set the sample weight mode for this output\n                 to \"temporal\".\n+            loss_weights: dictionary you can pass to specify a weight\n+                coefficient for each loss function (in a multi-output model).\n+                If no loss weight is specified for an output,\n+                the weight for this output's loss will be considered to be 1.\n             kwargs: for Theano backend, these are passed into K.function.\n                 Ignored for Tensorflow backend.\n         '''\n@@ -1205,6 +1223,7 @@ class Graph(Model, containers.Graph):\n         assert type(sample_weight_modes) is dict, 'The \"sample_weight_modes\" argument should be a dictionary.'\n \n         self.sample_weight_modes = sample_weight_modes\n+        self.loss_weights = loss_weights\n         ys = []\n         ys_train = []\n         ys_test = []\n@@ -1232,8 +1251,42 @@ class Graph(Model, containers.Graph):\n                 weight = K.placeholder(ndim=1)\n             weights.append(weight)\n             weighted_loss = weighted_objective(objectives.get(loss_fn))\n-            train_loss += weighted_loss(y, y_train, weight, mask)\n-            test_loss += weighted_loss(y, y_test, weight, mask)\n+            train_loss += loss_weights.get(output_name, 1.) * weighted_loss(y, y_train, weight, mask)\n+            test_loss += loss_weights.get(output_name, 1.) * weighted_loss(y, y_test, weight, mask)\n+\n+        # deal with accuracy computation\n+        if len(self.output_order) == 1:\n+            y = ys[0]\n+            y_train = ys_train[0]\n+            y_test = ys_test[0]\n+            # set class_mode, for accuracy computation:\n+            if self.outputs[self.output_order[0]].output_shape[-1] == 1:\n+                class_mode = 'binary'\n+            else:\n+                class_mode = 'categorical'\n+            self.class_mode = class_mode\n+\n+            if class_mode == 'categorical':\n+                train_accuracy = K.mean(K.equal(K.argmax(y, axis=-1),\n+                                                K.argmax(y_train, axis=-1)))\n+                test_accuracy = K.mean(K.equal(K.argmax(y, axis=-1),\n+                                               K.argmax(y_test, axis=-1)))\n+            elif class_mode == 'binary':\n+                is_categorical_xent = False\n+                loss_type = loss[self.output_order[0]]\n+                if loss_type == 'categorical_crossentropy':\n+                    is_categorical_xent = True\n+                if hasattr(loss_type, '__name__') and loss_type.__name__ == 'categorical_crossentropy':\n+                    is_categorical_xent = True\n+                if is_categorical_xent:\n+                    warnings.warn('Your model output has shape ' + str(self.output_shape) +\n+                                  ' (1-dimensional features), but you are using ' +\n+                                  ' the `categorical_crossentropy` loss. You ' +\n+                                  'almost certainly want to use `binary_crossentropy` instead.')\n+                train_accuracy = K.mean(K.equal(y, K.round(y_train)))\n+                test_accuracy = K.mean(K.equal(y, K.round(y_test)))\n+        else:\n+            self.class_mode = None\n \n         ins = [self.inputs[name].input for name in self.input_order]\n         train_ins = ins + ys + weights\n@@ -1250,13 +1303,20 @@ class Graph(Model, containers.Graph):\n \n         self._train = K.function(train_ins, [train_loss],\n                                  updates=updates, **kwargs)\n+        if self.class_mode:\n+            self._train_with_acc = K.function(train_ins, [train_loss, train_accuracy],\n+                                              updates=updates, **kwargs)\n         self._test = K.function(test_ins, [test_loss],\n                                 updates=self.state_updates, **kwargs)\n+        if self.class_mode:\n+            self._test_with_acc = K.function(test_ins, [test_loss, test_accuracy],\n+                                             updates=self.state_updates, **kwargs)\n         self._predict = K.function(inputs=ins, outputs=ys_test,\n                                    updates=self.state_updates, **kwargs)\n \n     def fit(self, data, batch_size=128, nb_epoch=100, verbose=1, callbacks=[],\n             validation_split=0., validation_data=None, shuffle=True,\n+            show_accuracy=False,\n             class_weight={}, sample_weight={}):\n         '''Train the model for a fixed number of epochs.\n \n@@ -1282,11 +1342,19 @@ class Graph(Model, containers.Graph):\n                 All arrays should contain the same number of samples.\n                 Will override validation_split.\n             shuffle: boolean. Whether to shuffle the samples at each epoch.\n+            show_accuracy: whether to log accuracy.\n+                Can only be used if your Graph has a single output (otherwise \"accuracy\"\n+                is ill-defined).\n             class_weight: dictionary mapping output names to\n                 class weight dictionaries.\n             sample_weight: dictionary mapping output names to\n                 numpy arrays of sample weights.\n         '''\n+        if show_accuracy:\n+            if len(self.output_order) != 1:\n+                raise Exception('In a Graph model, \"show_accuracy\" can only '\n+                                'be used if your Graph has exactly one output.'\n+                                ' Otherwise accuracy is ill-defined.')\n         X = [data[name] for name in self.input_order]\n         y = [standardize_y(data[name]) for name in self.output_order]\n         if len(set([len(a) for a in X] + [len(a) for a in y])) != 1:\n@@ -1315,6 +1383,11 @@ class Graph(Model, containers.Graph):\n             sample_weight_list, sample_weight_list_val = (slice_X(sample_weight_list, 0, split_at), slice_X(sample_weight_list, split_at))\n             val_ins = X_val + y_val + sample_weight_list_val\n \n+        if self.class_mode and show_accuracy:\n+            f = self._train_with_acc\n+            out_labels = ['loss', 'acc']\n+            metrics = ['loss', 'acc', 'val_loss', 'val_acc']\n+        else:\n             f = self._train\n             out_labels = ['loss']\n             metrics = ['loss', 'val_loss']\n@@ -1331,9 +1404,13 @@ class Graph(Model, containers.Graph):\n                             shuffle=shuffle, metrics=metrics)\n         return history\n \n-    def evaluate(self, data, batch_size=128, verbose=0, sample_weight={}):\n+    def evaluate(self, data, batch_size=128, show_accuracy=False,\n+                 verbose=0, sample_weight={}):\n         '''Compute the loss on some input data, batch by batch.\n \n+        Returns the loss over the data,\n+        or a tuple `(loss, accuracy)` if `show_accuracy=True`.\n+\n         Arguments: see `fit` method.\n         '''\n         sample_weight = [standardize_weights(data[name],\n@@ -1343,7 +1420,18 @@ class Graph(Model, containers.Graph):\n         if len(set([len(a) for a in ins])) != 1:\n             raise Exception('All input arrays and target arrays must have '\n                             'the same number of samples.')\n-        outs = self._test_loop(self._test, ins, batch_size, verbose)\n+        if show_accuracy:\n+            if len(self.output_order) != 1:\n+                raise Exception('In a Graph model, \"show_accuracy\" can only '\n+                                'be used if your Graph has exactly one output.'\n+                                ' Otherwise accuracy is ill-defined.')\n+            fn = self._test_with_acc\n+        else:\n+            fn = self._test\n+        outs = self._test_loop(fn, ins, batch_size, verbose)\n+        if show_accuracy:\n+            return outs\n+        else:\n             return outs[0]\n \n     def predict(self, data, batch_size=128, verbose=0):\n@@ -1359,9 +1447,13 @@ class Graph(Model, containers.Graph):\n         outs = self._predict_loop(self._predict, ins, batch_size, verbose)\n         return dict(zip(self.output_order, outs))\n \n-    def train_on_batch(self, data, class_weight={}, sample_weight={}):\n+    def train_on_batch(self, data, accuracy=False,\n+                       class_weight={}, sample_weight={}):\n         '''Single gradient update on a batch of samples.\n \n+        Returns the loss over the data,\n+        or a tuple `(loss, accuracy)` if `accuracy=True`.\n+\n         Arguments: see `fit` method.\n         '''\n         sample_weight = [standardize_weights(data[name],\n@@ -1372,10 +1464,19 @@ class Graph(Model, containers.Graph):\n         if len(set([len(a) for a in ins])) != 1:\n             raise Exception('All input arrays and target arrays must have '\n                             'the same number of samples.')\n+        if accuracy:\n+            if len(self.output_order) != 1:\n+                raise Exception('In a Graph model, \"accuracy\" can only '\n+                                'be used if your Graph has exactly one output.'\n+                                ' Otherwise accuracy is ill-defined.')\n+            return self._train_with_acc(ins)\n         return self._train(ins)\n \n-    def test_on_batch(self, data, sample_weight={}):\n-        '''Compute the loss on a single batch of samples.\n+    def test_on_batch(self, data, accuracy=False, sample_weight={}):\n+        '''Test the network on a single batch of samples.\n+\n+        If `accuracy`, it returns a tuple `(loss, accuracy)`,\n+        otherwise it returns the loss value.\n \n         Arguments: see `fit` method.\n         '''\n@@ -1386,6 +1487,12 @@ class Graph(Model, containers.Graph):\n         if len(set([len(a) for a in ins])) != 1:\n             raise Exception('All input arrays and target arrays must have '\n                             'the same number of samples.')\n+        if accuracy:\n+            if len(self.output_order) != 1:\n+                raise Exception('In a Graph model, \"accuracy\" can only '\n+                                'be used if your Graph has exactly one output.'\n+                                ' Otherwise accuracy is ill-defined.')\n+            return self._test_with_acc(ins)\n         return self._test(ins)\n \n     def predict_on_batch(self, data):\n@@ -1439,12 +1546,15 @@ class Graph(Model, containers.Graph):\n         self.set_weights(weights)\n         f.close()\n \n-    def evaluate_generator(self, generator, nb_val_samples,\n+    def evaluate_generator(self, generator, nb_val_samples, show_accuracy=False,\n                            verbose=1, **kwargs):\n         '''Evaluates the model on a generator. The generator should\n         return the same kind of data with every yield as accepted\n         by `evaluate`.\n \n+        If `show_accuracy`, it returns a tuple `(loss, accuracy)`,\n+        otherwise it returns the loss value.\n+\n         Arguments:\n             generator:\n                 generator yielding dictionaries of the kind accepted\n@@ -1453,11 +1563,19 @@ class Graph(Model, containers.Graph):\n             nb_val_samples:\n                 total number of samples to generate from `generator`\n                 to use in validation.\n+            show_accuracy: whether to log accuracy.\n+                Can only be used if your Graph has a single output (otherwise \"accuracy\"\n+                is ill-defined).\n \n-            Other argumens are as for `fit`.\n+            Other arguments are the same as for `fit`.\n         '''\n+        if show_accuracy:\n+            if len(self.output_order) != 1:\n+                raise Exception('In a Graph model, \"show_accuracy\" can only '\n+                                'be used if your Graph has exactly one output.'\n+                                ' Otherwise accuracy is ill-defined.')\n         done_samples = 0\n-        all_outs = []\n+        all_outs = None\n         weights = []\n         q, _stop = generator_queue(generator, **kwargs)\n \n@@ -1466,13 +1584,26 @@ class Graph(Model, containers.Graph):\n             do_samples = len(data[next(iter(data.keys()))])\n             outs = self.evaluate(data, batch_size=do_samples,\n                                  sample_weight=sample_weight,\n+                                 show_accuracy=show_accuracy,\n                                  verbose=verbose)\n+            if show_accuracy:\n+                if all_outs is None:\n+                    all_outs = [[] for _ in outs]\n+                for ox, out in enumerate(outs):\n+                    all_outs[ox].append(out)\n+            else:\n+                if all_outs is None:\n+                    all_outs = []\n                 all_outs.append(outs)\n \n             done_samples += do_samples\n             weights.append(do_samples)\n \n         _stop.set()\n+        if show_accuracy:\n+            return [np.average(outx, weights=weights)\n+                    for outx in all_outs]\n+        else:\n             return np.average(np.asarray(all_outs),\n                               weights=weights)\n \n@@ -1509,7 +1640,7 @@ class Graph(Model, containers.Graph):\n         return data, sample_weight\n \n     def fit_generator(self, generator, samples_per_epoch, nb_epoch,\n-                      verbose=1, callbacks=[],\n+                      verbose=1, show_accuracy=False, callbacks=[],\n                       validation_data=None, nb_val_samples=None,\n                       class_weight={},\n                       nb_worker=1, nb_val_worker=None):\n@@ -1532,6 +1663,9 @@ class Graph(Model, containers.Graph):\n                 going to the next epoch.\n             nb_epoch: integer, total number of iterations on the data.\n             verbose: verbosity mode, 0, 1, or 2.\n+            show_accuracy: whether to log accuracy.\n+                Can only be used if your Graph has a single output (otherwise \"accuracy\"\n+                is ill-defined).\n             callbacks: list of callbacks to be called during training.\n             validation_data: dictionary mapping input names and outputs names\n                 to appropriate numpy arrays to be used as\n@@ -1591,6 +1725,14 @@ class Graph(Model, containers.Graph):\n         if nb_val_worker is None:\n             nb_val_worker = nb_worker\n \n+        if show_accuracy:\n+            if len(self.output_order) != 1:\n+                raise Exception('In a Graph model, \"show_accuracy\" can only '\n+                                'be used if your Graph has exactly one output.'\n+                                ' Otherwise accuracy is ill-defined.')\n+            out_labels = ['loss', 'acc']\n+            metrics = ['loss', 'acc', 'val_loss', 'val_acc']\n+        else:\n             out_labels = ['loss']\n             metrics = ['loss', 'val_loss']\n         if not class_weight:\n@@ -1647,7 +1789,8 @@ class Graph(Model, containers.Graph):\n                 callbacks.on_batch_begin(batch_index, batch_logs)\n                 outs = self.train_on_batch(data,\n                                            sample_weight=sample_weight,\n-                                           class_weight=class_weight)\n+                                           class_weight=class_weight,\n+                                           accuracy=show_accuracy)\n                 if type(outs) != list:\n                     outs = [outs]\n                 for l, o in zip(out_labels, outs):\n@@ -1665,11 +1808,13 @@ class Graph(Model, containers.Graph):\n                         val_outs = self.evaluate_generator(validation_data,\n                                                            nb_val_samples,\n                                                            verbose=0,\n+                                                           show_accuracy=show_accuracy,\n                                                            nb_worker=nb_val_worker,\n                                                            wait_time=wait_time)\n                     else:\n                         val_outs = self.evaluate(data_val,\n                                                  sample_weight=sample_weight_val,\n+                                                 show_accuracy=show_accuracy,\n                                                  verbose=0)\n                     if type(val_outs) != list:\n                         val_outs = [val_outs]\n\n@@ -47,20 +47,28 @@ def test_graph_fit_generator():\n     graph.compile('rmsprop', {'output1': 'mse'})\n \n     graph.fit_generator(data_generator_graph(True), 1000, nb_epoch=4)\n-    graph.fit_generator(data_generator_graph(True), 1000, nb_epoch=4)\n-    graph.fit_generator(data_generator_graph(True), 1000, nb_epoch=4, validation_data={'input1': X_test_graph, 'output1': y_test_graph})\n-    graph.fit_generator(data_generator_graph(True), 1000, nb_epoch=4, validation_data={'input1': X_test_graph, 'output1': y_test_graph})\n+    graph.fit_generator(data_generator_graph(True), 1000, nb_epoch=4,\n+                        validation_data={'input1': X_test_graph, 'output1': y_test_graph})\n     graph.fit_generator(data_generator_graph(True), 1000, nb_epoch=4,\n                         validation_data=data_generator_graph(False), nb_val_samples=batch_size * 3)\n     graph.fit_generator(data_generator_graph(True), 1000, nb_epoch=4,\n                         validation_data=data_generator_graph(False), nb_val_samples=batch_size * 3)\n-\n     gen_loss = graph.evaluate_generator(data_generator_graph(True), 128, verbose=0)\n     assert(gen_loss < 3.)\n \n     loss = graph.evaluate({'input1': X_test_graph, 'output1': y_test_graph}, verbose=0)\n     assert(loss < 3.)\n \n+    # test show_accuracy\n+    graph.fit_generator(data_generator_graph(True), 1000, nb_epoch=4, show_accuracy=True)\n+    graph.fit_generator(data_generator_graph(True), 1000, nb_epoch=4,\n+                        validation_data={'input1': X_test_graph, 'output1': y_test_graph}, show_accuracy=True)\n+    graph.fit_generator(data_generator_graph(True), 1000, nb_epoch=4,\n+                        validation_data=data_generator_graph(False), nb_val_samples=batch_size * 3, show_accuracy=True)\n+    graph.fit_generator(data_generator_graph(True), 1000, nb_epoch=4,\n+                        validation_data=data_generator_graph(False), nb_val_samples=batch_size * 3, show_accuracy=True)\n+    gen_loss = graph.evaluate_generator(data_generator_graph(True), 128, verbose=0, show_accuracy=True)\n+\n \n def test_1o_1i():\n     # test a non-sequential graph with 1 input and 1 output\n@@ -88,6 +96,13 @@ def test_1o_1i():\n     loss = graph.evaluate({'input1': X_test_graph, 'output1': y_test_graph}, verbose=0)\n     assert(loss < 2.5)\n \n+    # test show_accuracy:\n+    graph.fit({'input1': X_train_graph, 'output1': y_train_graph},\n+              nb_epoch=1, show_accuracy=True)\n+    loss, acc = graph.test_on_batch({'input1': X_test_graph, 'output1': y_test_graph}, accuracy=True)\n+    loss, acc = graph.train_on_batch({'input1': X_test_graph, 'output1': y_test_graph}, accuracy=True)\n+    loss, acc = graph.evaluate({'input1': X_test_graph, 'output1': y_test_graph}, verbose=0, show_accuracy=True)\n+\n     # test validation split\n     graph.fit({'input1': X_train_graph, 'output1': y_train_graph},\n               validation_split=0.2, nb_epoch=1)\n@@ -281,6 +296,12 @@ def test_2o_1i_weights():\n     nloss = graph.evaluate({'input1': X_test_graph, 'output1': y_test_graph, 'output2': y2_test_graph})\n     assert(loss == nloss)\n \n+    # test loss weights\n+    graph.compile('rmsprop', {'output1': 'mse', 'output2': 'mse'},\n+                  loss_weights={'output1': 1., 'output2': 2.})\n+    graph.fit({'input1': X_train_graph, 'output1': y_train_graph, 'output2': y2_train_graph},\n+              nb_epoch=1)\n+\n \n def test_2o_1i_sample_weights():\n     # test a non-sequential graph with 1 input and 2 outputs with sample weights\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
