{"custom_id": "keras#4392d120d845adf25d96d353df1513aa8e1df0ad", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 8 | Churn Cumulative: 661 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -156,11 +156,9 @@ def test_class_weight_wrong_classes():\n     (x_train, y_train), (x_test, y_test), (sample_weight, class_weight, test_ids) = _get_test_data()\n \n     del class_weight[1]\n-    try:\n-        model.fit(x_train, y_train, epochs=0, verbose=0, class_weight=class_weight)\n-        assert False\n-    except ValueError:\n-        pass  # expected behavior is to raise a ValueError with a suitable message\n+    with pytest.raises(ValueError):\n+        model.fit(x_train, y_train,\n+                  epochs=0, verbose=0, class_weight=class_weight)\n \n \n if __name__ == '__main__':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fb05a6f188605068baaa03be348a50b228b0ff08", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 32 | Files Changed: 1 | Hunks: 5 | Methods Changed: 6 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 34 | Churn Cumulative: 916 | Contributors (this commit): 7 | Commits (past 90d): 9 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -4,7 +4,6 @@ from __future__ import print_function\n \n import hashlib\n import multiprocessing\n-import multiprocessing.managers\n import os\n import random\n import shutil\n@@ -353,37 +352,11 @@ class Sequence(object):\n         raise NotImplementedError\n \n \n-class HolderManager(multiprocessing.managers.BaseManager):\n-    \"\"\"Custom manager to share a Holder object.\"\"\"\n-    pass\n-\n-\n-class Holder(object):\n-    \"\"\"Object to encapsulate a Sequence.\n-\n-    This allows the Sequence to be shared across multiple workers.\n-\n-    # Arguments\n-        seq: Sequence object to be shared.\n-    \"\"\"\n-    def __init__(self, seq):\n-        self.seq = seq\n-\n-    def __getitem__(self, idx):\n-        return self.seq[idx]\n-\n-    def __len__(self):\n-        return len(self.seq)\n-\n-# Register the Holder class using the ListProxy (allows __len__ and __getitem__)\n-HolderManager.register('Holder', Holder, multiprocessing.managers.ListProxy)\n-\n-\n def get_index(ds, i):\n     \"\"\"Quick fix for Python2, otherwise, it cannot be pickled.\n \n     # Arguments\n-        ds: a Holder or Sequence object\n+        ds: a Sequence object\n         i: index\n \n     # Returns\n@@ -467,9 +440,7 @@ class OrderedEnqueuer(SequenceEnqueuer):\n     def __init__(self, sequence,\n                  use_multiprocessing=False,\n                  scheduling='sequential'):\n-        self.manager = HolderManager()\n-        self.manager.start()\n-        self.sequence = self.manager.Holder(sequence)\n+        self.sequence = sequence\n         self.use_multiprocessing = use_multiprocessing\n         self.scheduling = scheduling\n         self.workers = 0\n@@ -546,7 +517,6 @@ class OrderedEnqueuer(SequenceEnqueuer):\n         self.executor.close()\n         self.executor.join()\n         self.run_thread.join(timeout)\n-        self.manager.shutdown()\n \n \n class GeneratorEnqueuer(SequenceEnqueuer):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f120a56009606f4f07711511d1d7df2f85dfbc08", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 339 | Contributors (this commit): 12 | Commits (past 90d): 13 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -20,4 +20,4 @@ from . import regularizers\n # Importable from root because it's technically not a layer\r\n from .layers import Input\r\n \r\n-__version__ = '2.0.5'\r\n+__version__ = '2.0.6'\r\n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='2.0.5',\n+      version='2.0.6',\n       description='Deep Learning for Python',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/fchollet/keras',\n-      download_url='https://github.com/fchollet/keras/tarball/2.0.5',\n+      download_url='https://github.com/fchollet/keras/tarball/2.0.6',\n       license='MIT',\n       install_requires=['theano', 'pyyaml', 'six'],\n       extras_require={\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1fe7de405e9ede74b0c2a53cd99c396382cf4581", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 30 | Churn Cumulative: 705 | Contributors (this commit): 8 | Commits (past 90d): 1 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -187,6 +187,21 @@ class Add(_Merge):\n     It takes as input a list of tensors,\n     all of the same shape, and returns\n     a single tensor (also of the same shape).\n+\n+    # Examples\n+\n+    ```python\n+        import keras\n+\n+        input1 = keras.layers.Input(shape=(16,))\n+        x1 = keras.layers.Dense(8, activation='relu')(input1)\n+        input2 = keras.layers.Input(shape=(32,))\n+        x2 = keras.layers.Dense(8, activation='relu')(input2)\n+        added = keras.layers.Add()([x1, x2])  # equivalent to added = keras.layers.add([x1, x2])\n+\n+        out = keras.layers.Dense(4)(added)\n+        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n+    ```\n     \"\"\"\n \n     def _merge_function(self, inputs):\n@@ -451,6 +466,21 @@ def add(inputs, **kwargs):\n \n     # Returns\n         A tensor, the sum of the inputs.\n+\n+    # Examples\n+\n+    ```python\n+        import keras\n+\n+        input1 = keras.layers.Input(shape=(16,))\n+        x1 = keras.layers.Dense(8, activation='relu')(input1)\n+        input2 = keras.layers.Input(shape=(32,))\n+        x2 = keras.layers.Dense(8, activation='relu')(input2)\n+        added = keras.layers.add([x1, x2])\n+\n+        out = keras.layers.Dense(4)(added)\n+        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n+    ```\n     \"\"\"\n     return Add(**kwargs)(inputs)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#09b97e951a0d47e7d5f31a66804a8e76f389315b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 82 | Lines Deleted: 22 | Files Changed: 4 | Hunks: 16 | Methods Changed: 10 | Complexity Δ (Sum/Max): 9/12 | Churn Δ: 104 | Churn Cumulative: 9622 | Contributors (this commit): 47 | Commits (past 90d): 29 | Contributors (cumulative): 59 | DMM Complexity: 0.8\n\nDIFF:\n@@ -301,7 +301,7 @@ def constant(value, dtype=None, shape=None, name=None):\n     const = C.constant(np_value,\n                        dtype=dtype,\n                        name=_prepare_name(name, 'constant'))\n-    const._keras_shape = shape\n+    const._keras_shape = const.shape\n     const._uses_learning_phase = False\n     return const\n \n@@ -1216,6 +1216,13 @@ def rnn(step_function, inputs, initial_states,\n     if num_time_step is None and not has_seq_axis(inputs):\n         num_time_step = inputs.shape[0]\n \n+    initial = []\n+    for s in initial_states:\n+        if _get_dynamic_axis_num(s) == 0:\n+            initial.append(C.user_function(ConvertToBatch(s)))\n+        else:\n+            initial.append(s)\n+\n     need_convert = not has_seq_axis(inputs)\n     if need_convert:\n         inputs = C.to_sequence(inputs)\n@@ -1233,7 +1240,7 @@ def rnn(step_function, inputs, initial_states,\n                     constants[j] = C.sequence.broadcast_as(constants[j], inputs)\n             j += 1\n \n-    states = tuple(initial_states)\n+    states = tuple(initial)\n \n     with C.default_options(axis_offset=1):\n         def _recurrence(x, states):\n@@ -1256,20 +1263,21 @@ def rnn(step_function, inputs, initial_states,\n \n         final_output, final_states = _recurrence(inputs, states)\n         last_output = C.sequence.last(final_output)\n-        last_states = final_states\n+        last_states = [C.sequence.last(s) for s in final_states]\n \n     if need_convert:\n         final_output = C.sequence.unpack(final_output, 0, no_mask_output=True)\n-        last_states = [\n-            C.sequence.unpack(\n-                s, 0, no_mask_output=True) for s in last_states]\n         if num_time_step is not None and num_time_step is not C.FreeDimension:\n             final_output = _reshape_sequence(final_output, num_time_step)\n-            last_states = [\n-                _reshape_sequence(\n-                    _, num_time_step) for _ in last_states]\n \n-    return last_output, final_output, last_states\n+    f_stats = []\n+    for l_s, i_s in zip(last_states, initial_states):\n+        if _get_dynamic_axis_num(i_s) == 0 and _get_dynamic_axis_num(l_s) == 1:\n+            f_stats.append(C.user_function(ConvertToStatic(l_s, batch_size=i_s.shape[0])))\n+        else:\n+            f_stats.append(l_s)\n+\n+    return last_output, final_output, f_stats\n \n \n def has_seq_axis(x):\n@@ -2136,6 +2144,65 @@ class ReshapeBatch(C.ops.functions.UserFunction):\n                 (num_old_batch,) + self.from_shape))\n \n \n+class ConvertToBatch(C.ops.functions.UserFunction):\n+    \"\"\"Converts input first axis to CNTK batch axis.\n+\n+    We may introduce this operation in CNTK native\n+    implementation later.\n+\n+    # Arguments\n+        inputs: a cntk variable (parameter/constant)\n+        name: name of this node\n+    \"\"\"\n+\n+    def __init__(self, input, name='convert_to_batch'):\n+        super(ConvertToBatch, self).__init__([input], as_numpy=False, name=name)\n+\n+    def infer_outputs(self):\n+        batch_axis = C.Axis.default_batch_axis()\n+        return [\n+            C.output_variable(\n+                self.inputs[0].shape[1:],\n+                self.inputs[0].dtype,\n+                [batch_axis])]\n+\n+    def forward(self, arguments, device=None, outputs_to_retain=None):\n+        return None, C.cntk_py.Value(arguments.data())\n+\n+    def backward(self, state, root_gradients):\n+        return C.cntk_py.Value(root_gradients.data())\n+\n+\n+class ConvertToStatic(C.ops.functions.UserFunction):\n+    \"\"\"Converts input first axis to CNTK static axis.\n+\n+    We may introduce this operation in CNTK native\n+    implementation later.\n+\n+    # Arguments\n+        inputs: a cntk tensor which has batch axis\n+        batch_size: size of batch axis.\n+        name: name of this node.\n+    \"\"\"\n+\n+    def __init__(self, input, batch_size, name='convert_to_static'):\n+        super(ConvertToStatic, self).__init__([input], as_numpy=False, name=name)\n+        self.target_shape = (batch_size,) + input.shape\n+\n+    def infer_outputs(self):\n+        return [\n+            C.output_variable(\n+                self.target_shape,\n+                self.inputs[0].dtype,\n+                [])]\n+\n+    def forward(self, arguments, device=None, outputs_to_retain=None):\n+        return None, C.cntk_py.Value(arguments.data())\n+\n+    def backward(self, state, root_gradients):\n+        return C.cntk_py.Value(root_gradients.data())\n+\n+\n class LambdaFunc(C.ops.functions.UserFunction):\n     def __init__(self,\n                  arg,\n\n@@ -198,8 +198,6 @@ class Recurrent(Layer):\n         self.return_sequences = return_sequences\n         self.return_state = return_state\n         self.go_backwards = go_backwards\n-        if K.backend() == 'cntk' and stateful:\n-            raise ValueError('Stateful RNN is not currently supported with CNTK.')\n \n         self.stateful = stateful\n         self.unroll = unroll\n\n@@ -43,8 +43,6 @@ def test_convolutional_recurrent():\n             if data_format == 'channels_first' or return_sequences:\n                 continue\n \n-            # cntk doesn't support statefulness on LSTM yet, will enable it on cntk later\n-            if K.backend() != 'cntk':\n             # Tests for statefulness\n             model = Sequential()\n             kwargs = {'data_format': data_format,\n@@ -83,6 +81,9 @@ def test_convolutional_recurrent():\n             out5 = model.predict(np.ones_like(inputs))\n             assert(out4.max() != out5.max())\n \n+            # cntk doesn't support eval convolution with static\n+            # variable, will enable it later\n+            if K.backend() != 'cntk':\n                 # check regularizers\n                 kwargs = {'data_format': data_format,\n                           'return_sequences': return_sequences,\n\n@@ -51,7 +51,6 @@ def test_dynamic_behavior(layer_class):\n \n \n @rnn_test\n-@pytest.mark.skipif(K.backend() == 'cntk', reason='Stateful is not supported with CNTK')\n def test_stateful_invalid_use(layer_class):\n     layer = layer_class(units,\n                         stateful=True,\n@@ -101,7 +100,7 @@ def test_implementation_mode(layer_class):\n \n @rnn_test\n @pytest.mark.skipif((K.backend() == 'cntk'),\n-                    reason=\"cntk does not support stateful RNN yet\")\n+                    reason=\"cntk does not support mask on RNN yet\")\n def test_statefulness(layer_class):\n     model = Sequential()\n     model.add(embeddings.Embedding(embedding_num, embedding_dim,\n@@ -197,8 +196,7 @@ def test_masking_layer():\n \n @rnn_test\n def test_from_config(layer_class):\n-    # cntk does not support stateful yet.\n-    stateful_flags = (False, True) if K.backend() != 'cntk' else (False,)\n+    stateful_flags = (False, True)\n     for stateful in stateful_flags:\n         l1 = layer_class(units=1, stateful=stateful)\n         l2 = layer_class.from_config(l1.get_config())\n@@ -249,8 +247,6 @@ def test_specify_initial_state_non_keras_tensor(layer_class):\n \n \n @rnn_test\n-@pytest.mark.skipif((K.backend() == 'cntk'),\n-                    reason=\"cntk does not support stateful RNN yet\")\n def test_reset_states_with_values(layer_class):\n     num_states = 2 if layer_class is recurrent.LSTM else 1\n \n@@ -299,8 +295,6 @@ def test_specify_state_with_masking(layer_class):\n \n \n @rnn_test\n-@pytest.mark.skipif((K.backend() == 'cntk'),\n-                    reason=\"cntk does not support stateful RNN yet\")\n def test_return_state(layer_class):\n     num_states = 2 if layer_class is recurrent.LSTM else 1\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#99ba51555f1bac68742ee2b85f3d452c0531e343", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 451 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -154,9 +154,9 @@ def load_mask_labels():\n                                img_ncols:].reshape((img_nrows, img_ncols))\r\n \r\n     stack_axis = 0 if K.image_data_format() == 'channels_first' else -1\r\n-    style_mask = np.stack([style_mask_label == r for r in xrange(num_labels)],\r\n+    style_mask = np.stack([style_mask_label == r for r in range(num_labels)],\r\n                           axis=stack_axis)\r\n-    target_mask = np.stack([target_mask_label == r for r in xrange(num_labels)],\r\n+    target_mask = np.stack([target_mask_label == r for r in range(num_labels)],\r\n                            axis=stack_axis)\r\n \r\n     return (np.expand_dims(style_mask, axis=0),\r\n@@ -251,7 +251,7 @@ def style_loss(style_image, target_image, style_masks, target_masks):\n     assert 3 == K.ndim(style_image) == K.ndim(target_image)\r\n     assert 3 == K.ndim(style_masks) == K.ndim(target_masks)\r\n     loss = K.variable(0)\r\n-    for i in xrange(num_labels):\r\n+    for i in range(num_labels):\r\n         if K.image_data_format() == 'channels_first':\r\n             style_mask = style_masks[i, :, :]\r\n             target_mask = target_masks[i, :, :]\r\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9904bdf23344c3bafac00c1a71cac65a1f1d8d48", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 32 | Lines Deleted: 21 | Files Changed: 2 | Hunks: 22 | Methods Changed: 22 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 53 | Churn Cumulative: 10810 | Contributors (this commit): 77 | Commits (past 90d): 19 | Contributors (cumulative): 85 | DMM Complexity: 1.0\n\nDIFF:\n@@ -516,12 +516,12 @@ class Sequential(Model):\n         # Returns\n             A layer instance.\n         \"\"\"\n-        if self.model is None:\n+        if not self.built:\n             self.build()\n         return self.model.get_layer(name, index)\n \n     def call(self, inputs, mask=None):\n-        if self.model is None:\n+        if not self.built:\n             self.build()\n         return self.model.call(inputs, mask)\n \n@@ -560,7 +560,7 @@ class Sequential(Model):\n \n     @property\n     def uses_learning_phase(self):\n-        if self.model is None:\n+        if not self.built:\n             self.build()\n         return self.model.uses_learning_phase\n \n@@ -625,41 +625,41 @@ class Sequential(Model):\n \n     @property\n     def updates(self):\n-        if self.model is None:\n+        if not self.built:\n             self.build()\n         return self.model.updates\n \n     @property\n     def state_updates(self):\n-        if self.model is None:\n+        if not self.built:\n             self.build()\n         return self.model.state_updates\n \n     def get_updates_for(self, inputs):\n-        if self.model is None:\n+        if not self.built:\n             self.build()\n         return self.model.get_updates_for(inputs)\n \n     @property\n     def losses(self):\n-        if self.model is None:\n+        if not self.built:\n             self.build()\n         return self.model.losses\n \n     def get_losses_for(self, inputs):\n-        if self.model is None:\n+        if not self.built:\n             self.build()\n         return self.model.get_losses_for(inputs)\n \n     @property\n     def regularizers(self):\n-        if self.model is None:\n+        if not self.built:\n             self.build()\n         return self.model.regularizers\n \n     @property\n     def constraints(self):\n-        if self.model is None:\n+        if not self.built:\n             self.build()\n         return self.model.constraints\n \n@@ -678,7 +678,7 @@ class Sequential(Model):\n                 weights.append(layer.get_weights())\n             return weights\n \n-        if self.model is None:\n+        if not self.built:\n             self.build()\n         return self.model.get_weights()\n \n@@ -698,7 +698,7 @@ class Sequential(Model):\n                 layer.set_weights(weights[:nb_param])\n                 weights = weights[nb_param:]\n \n-        if self.model is None:\n+        if not self.built:\n             self.build()\n         self.model.set_weights(weights)\n \n@@ -847,7 +847,7 @@ class Sequential(Model):\n         if kwargs:\n             raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n \n-        if self.model is None:\n+        if not self.built:\n             raise RuntimeError('The model needs to be compiled '\n                                'before being used.')\n         return self.model.fit(x, y,\n@@ -883,7 +883,7 @@ class Sequential(Model):\n         # Raises\n             RuntimeError: if the model was never compiled.\n         \"\"\"\n-        if self.model is None:\n+        if not self.built:\n             raise RuntimeError('The model needs to be compiled '\n                                'before being used.')\n         return self.model.evaluate(x, y,\n@@ -904,7 +904,7 @@ class Sequential(Model):\n         # Returns\n             A Numpy array of predictions.\n         \"\"\"\n-        if self.model is None:\n+        if not self.built:\n             self.build()\n         return self.model.predict(x, batch_size=batch_size, verbose=verbose)\n \n@@ -918,7 +918,7 @@ class Sequential(Model):\n         # Returns\n             A Numpy array of predictions.\n         \"\"\"\n-        if self.model is None:\n+        if not self.built:\n             self.build()\n         return self.model.predict_on_batch(x)\n \n@@ -943,7 +943,7 @@ class Sequential(Model):\n         # Raises\n             RuntimeError: if the model was never compiled.\n         \"\"\"\n-        if self.model is None:\n+        if not self.built:\n             raise RuntimeError('The model needs to be compiled '\n                                'before being used.')\n         return self.model.train_on_batch(x, y,\n@@ -969,7 +969,7 @@ class Sequential(Model):\n         # Raises\n             RuntimeError: if the model was never compiled.\n         \"\"\"\n-        if self.model is None:\n+        if not self.built:\n             raise RuntimeError('The model needs to be compiled '\n                                'before being used.')\n         return self.model.test_on_batch(x, y,\n@@ -1100,7 +1100,7 @@ class Sequential(Model):\n                                 steps_per_epoch=1000, epochs=10)\n         ```\n         \"\"\"\n-        if self.model is None:\n+        if not self.built:\n             raise RuntimeError('The model needs to be compiled '\n                                'before being used.')\n         return self.model.fit_generator(generator,\n@@ -1147,7 +1147,7 @@ class Sequential(Model):\n         # Raises\n             RuntimeError: if the model was never compiled.\n         \"\"\"\n-        if self.model is None:\n+        if not self.built:\n             raise RuntimeError('The model needs to be compiled '\n                                'before being used.')\n         return self.model.evaluate_generator(generator,\n@@ -1181,7 +1181,7 @@ class Sequential(Model):\n         # Returns\n             A Numpy array of predictions.\n         \"\"\"\n-        if self.model is None:\n+        if not self.built:\n             self.build()\n         return self.model.predict_generator(generator, steps,\n                                             max_queue_size=max_queue_size,\n\n@@ -256,5 +256,16 @@ def test_sequential_count_params():\n     assert(n == model.count_params())\n \n \n+@keras_test\n+def test_rebuild_model():\n+    model = Sequential()\n+    model.add(Dense(128, input_shape=(784,)))\n+    model.add(Dense(64))\n+    assert(model.get_layer(index=-1).output_shape == (None, 64))\n+\n+    model.add(Dense(32))\n+    assert(model.get_layer(index=-1).output_shape == (None, 32))\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#26b58687708788182e8499788429738fa7d3bfc1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 385 | Contributors (this commit): 15 | Commits (past 90d): 4 | Contributors (cumulative): 15 | DMM Complexity: 0.0\n\nDIFF:\n@@ -114,7 +114,7 @@ def make_sampling_table(size, sampling_factor=1e-5):\n \n def skipgrams(sequence, vocabulary_size,\n               window_size=4, negative_samples=1., shuffle=True,\n-              categorical=False, sampling_table=None):\n+              categorical=False, sampling_table=None, seed=None):\n     \"\"\"Generates skipgram word pairs.\n \n     Takes a sequence (list of indexes of words),\n@@ -140,6 +140,7 @@ def skipgrams(sequence, vocabulary_size,\n             if True labels will be categorical eg. [[1,0],[0,1],[0,1] .. ]\n         sampling_table: 1D array of size `vocabulary_size` where the entry i\n             encodes the probabibily to sample a word of rank i.\n+        seed: random seed.\n \n     # Returns\n         couples, labels: where `couples` are int pairs and\n@@ -184,6 +185,7 @@ def skipgrams(sequence, vocabulary_size,\n             labels += [0] * num_negative_samples\n \n     if shuffle:\n+        if seed is None:\n             seed = random.randint(0, 10e6)\n         random.seed(seed)\n         random.shuffle(couples)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3efe0d28becd638744ad6725d1ade3166251b0a6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 22 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 22 | Churn Cumulative: 5722 | Contributors (this commit): 67 | Commits (past 90d): 32 | Contributors (cumulative): 71 | DMM Complexity: 0.8947368421052632\n\nDIFF:\n@@ -1874,6 +1874,9 @@ class Model(Container):\n                         for l, o in zip(out_labels, val_outs):\n                             epoch_logs['val_' + l] = o\n \n+                    if callback_model.stop_training:\n+                        break\n+\n                 callbacks.on_epoch_end(epoch, epoch_logs)\n                 epoch += 1\n                 if callback_model.stop_training:\n\n@@ -46,12 +46,31 @@ def test_TerminateOnNaN():\n     model.compile(loss='mean_squared_error',\n                   optimizer='rmsprop')\n \n+    # case 1 fit\n     history = model.fit(X_train, y_train, batch_size=batch_size,\n                         validation_data=(X_test, y_test), callbacks=cbks, epochs=20)\n     loss = history.history['loss']\n     assert len(loss) == 1\n     assert loss[0] == np.inf\n \n+    # case 2 fit_generator\n+    def data_generator():\n+        max_batch_index = len(X_train) // batch_size\n+        i = 0\n+        while 1:\n+            yield (X_train[i * batch_size: (i + 1) * batch_size],\n+                   y_train[i * batch_size: (i + 1) * batch_size])\n+            i += 1\n+            i = i % max_batch_index\n+    history = model.fit_generator(data_generator(),\n+                                  len(X_train),\n+                                  validation_data=(X_test, y_test),\n+                                  callbacks=cbks,\n+                                  epochs=20)\n+    loss = history.history['loss']\n+    assert len(loss) == 1\n+    assert loss[0] == np.inf or np.isnan(loss[0])\n+\n \n @keras_test\n def test_ModelCheckpoint(tmpdir):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#692e8e2023046c683b2b66f80b32b0c525570c52", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 37 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 6 | Complexity Δ (Sum/Max): 7/4 | Churn Δ: 39 | Churn Cumulative: 12516 | Contributors (this commit): 69 | Commits (past 90d): 13 | Contributors (cumulative): 72 | DMM Complexity: 0.896551724137931\n\nDIFF:\n@@ -637,8 +637,11 @@ class Lambda(Layer):\n         else:\n             shape = self._output_shape(input_shape)\n             if not isinstance(shape, (list, tuple)):\n-                raise ValueError('`output_shape` function must return a tuple.')\n-            return tuple(shape)\n+                raise ValueError('`output_shape` function must return a tuple or a list of tuples.')\n+            if isinstance(shape, list):\n+                if type(shape[0]) == int or shape[0] is None:\n+                    shape = tuple(shape)\n+            return shape\n \n     def call(self, inputs, mask=None):\n         arguments = self.arguments\n\n@@ -1,5 +1,6 @@\n import pytest\n import numpy as np\n+from numpy.testing import assert_allclose\n \n from keras import backend as K\n from keras import layers\n@@ -129,6 +130,37 @@ def test_lambda():\n                        'output_shape': antirectifier_output_shape},\n                input_shape=(3, 2))\n \n+    # test layer with multiple outputs\n+    def test_multiple_outputs():\n+        def func(x):\n+            return [x * 0.2, x * 0.3]\n+\n+        def output_shape(input_shape):\n+            return [input_shape, input_shape]\n+\n+        def mask(inputs, mask=None):\n+            return [None, None]\n+\n+        i = layers.Input(shape=(64, 64, 3))\n+        o = layers.Lambda(function=func,\n+                          output_shape=output_shape,\n+                          mask=mask)(i)\n+\n+        o1, o2 = o\n+        assert o1._keras_shape == (None, 64, 64, 3)\n+        assert o2._keras_shape == (None, 64, 64, 3)\n+\n+        model = Model(i, o)\n+\n+        x = np.random.random((4, 64, 64, 3))\n+        out1, out2 = model.predict(x)\n+        assert out1.shape == (4, 64, 64, 3)\n+        assert out2.shape == (4, 64, 64, 3)\n+        assert_allclose(out1, x * 0.2, atol=1e-4)\n+        assert_allclose(out2, x * 0.3, atol=1e-4)\n+\n+    test_multiple_outputs()\n+\n     # test serialization with function\n     def f(x):\n         return x + 1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#395a2edfd7741b5cdce7997bf8d4018d0e4b10d9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 86 | Lines Deleted: 28 | Files Changed: 2 | Hunks: 9 | Methods Changed: 6 | Complexity Δ (Sum/Max): 9/8 | Churn Δ: 114 | Churn Cumulative: 9539 | Contributors (this commit): 45 | Commits (past 90d): 25 | Contributors (cumulative): 51 | DMM Complexity: 0.20588235294117646\n\nDIFF:\n@@ -2398,10 +2398,52 @@ class Container(Layer):\n         # Raises\n             ValueError: In case of improperly formatted config dict.\n         \"\"\"\n-        # layer instances created during\n+        # Layer instances created during\n         # the graph reconstruction process\n         created_layers = {}\n \n+        # Dictionary mapping layer instances to\n+        # node data that specifies a layer call.\n+        # It acts as a queue that maintains any unprocessed\n+        # layer call until it becomes possible to process it\n+        # (i.e. until the input tensors to the call all exist).\n+        unprocessed_nodes = {}\n+\n+        def add_unprocessed_node(layer, node_data):\n+            if layer not in unprocessed_nodes:\n+                unprocessed_nodes[layer] = [node_data]\n+            else:\n+                unprocessed_nodes[layer].append(node_data)\n+\n+        def process_node(layer, node_data):\n+            input_tensors = []\n+            for input_data in node_data:\n+                inbound_layer_name = input_data[0]\n+                inbound_node_index = input_data[1]\n+                inbound_tensor_index = input_data[2]\n+                if len(input_data) == 3:\n+                    kwargs = {}\n+                elif len(input_data) == 4:\n+                    kwargs = input_data[3]\n+                else:\n+                    raise ValueError('Improperly formatted model config.')\n+                if inbound_layer_name not in created_layers:\n+                    add_unprocessed_node(layer, node_data)\n+                    continue\n+                inbound_layer = created_layers[inbound_layer_name]\n+                if len(inbound_layer.inbound_nodes) <= inbound_node_index:\n+                    add_unprocessed_node(layer, node_data)\n+                    continue\n+                inbound_node = inbound_layer.inbound_nodes[inbound_node_index]\n+                input_tensors.append(inbound_node.output_tensors[inbound_tensor_index])\n+            # Call layer on its inputs, thus creating the node\n+            # and building the layer if needed.\n+            if input_tensors:\n+                if len(input_tensors) == 1:\n+                    layer(input_tensors[0], **kwargs)\n+                else:\n+                    layer(input_tensors, **kwargs)\n+\n         def process_layer(layer_data):\n             \"\"\"Deserialize a layer, then call it on appropriate inputs.\n \n@@ -2415,6 +2457,7 @@ class Container(Layer):\n \n             # Instantiate layer.\n             from ..layers import deserialize as deserialize_layer\n+\n             layer = deserialize_layer(layer_data,\n                                       custom_objects=custom_objects)\n             created_layers[layer_name] = layer\n@@ -2422,32 +2465,25 @@ class Container(Layer):\n             # Gather layer inputs.\n             inbound_nodes_data = layer_data['inbound_nodes']\n             for node_data in inbound_nodes_data:\n-                input_tensors = []\n-                for input_data in node_data:\n-                    inbound_layer_name = input_data[0]\n-                    inbound_node_index = input_data[1]\n-                    inbound_tensor_index = input_data[2]\n-                    if len(input_data) == 3:\n-                        kwargs = {}\n-                    elif len(input_data) == 4:\n-                        kwargs = input_data[3]\n-                    else:\n-                        raise ValueError('Improperly formatted model config.')\n-                    if inbound_layer_name not in created_layers:\n-                        raise ValueError('Missing layer: ' + inbound_layer_name)\n-                    inbound_layer = created_layers[inbound_layer_name]\n-                    inbound_node = inbound_layer.inbound_nodes[inbound_node_index]\n-                    input_tensors.append(inbound_node.output_tensors[inbound_tensor_index])\n-                # Call layer on its inputs, thus creating the node\n-                # and building the layer if needed.\n-                if input_tensors:\n-                    if len(input_tensors) == 1:\n-                        layer(input_tensors[0], **kwargs)\n-                    else:\n-                        layer(input_tensors, **kwargs)\n+                # We don't process nodes (i.e. make layer calls)\n+                # on the fly because the inbound node may not yet exist,\n+                # in case of layer shared at different topological depths\n+                # (e.g. a model such as A(B(A(B(x)))))\n+                add_unprocessed_node(layer, node_data)\n \n+        # First, we create all layers and enqueue nodes to be processed\n         for layer_data in config['layers']:\n             process_layer(layer_data)\n+        # Then we process nodes in order of layer depth.\n+        # Nodes that cannot yet be processed (if the inbound node\n+        # does not yet exist) are re-enqueued, and the process\n+        # is repeated until all nodes are processed.\n+        while unprocessed_nodes:\n+            for layer_data in config['layers']:\n+                layer = created_layers[layer_data['name']]\n+                if layer in unprocessed_nodes:\n+                    for node_data in unprocessed_nodes.pop(layer):\n+                        process_node(layer, node_data)\n \n         name = config.get('name')\n         input_tensors = []\n\n@@ -575,7 +575,7 @@ def test_recursion_with_bn_and_loss():\n     model1.fit(x, y, verbose=0, epochs=1)\n     model2.fit(x, y, verbose=0, epochs=1)\n \n-\n+@keras_test\n def test_shared_layer_depth_is_correct():\n     # Basic outline here: we have a shared embedding layer, and two inputs that go through\n     # different depths of computation in the graph before the final output.  We need the computed\n@@ -583,9 +583,9 @@ def test_shared_layer_depth_is_correct():\n     # before anything else happens.  That's what we're testing.\n     from keras.layers import Embedding, Input, Dense, Concatenate\n     from keras.models import Model\n-    input1 = Input(shape=(10,), name=\"input1\")\n-    input2 = Input(shape=(10,), name=\"input2\")\n-    embedding_layer = Embedding(name=\"embedding\", input_dim=5, output_dim=10)\n+    input1 = Input(shape=(10,), name='input1')\n+    input2 = Input(shape=(10,), name='input2')\n+    embedding_layer = Embedding(name='embedding', input_dim=5, output_dim=10)\n     embedded_input1 = embedding_layer(input1)\n     embedded_input2 = embedding_layer(input2)\n     transformed_input2 = Dense(6)(Dense(5)(Dense(3)(embedded_input2)))\n@@ -603,5 +603,27 @@ def test_shared_layer_depth_is_correct():\n     assert input1_depth == input2_depth\n \n \n+@keras_test\n+def test_layer_sharing_at_heterogenous_depth():\n+    x_val = np.random.random((10, 5))\n+\n+    x = Input(shape=(5,))\n+    A = Dense(5, name='A')\n+    B = Dense(5, name='B')\n+    output = A(B(A(B(x))))\n+    M = Model(x, output)\n+\n+    output_val = M.predict(x_val)\n+\n+    config = M.get_config()\n+    weights = M.get_weights()\n+\n+    M2 = Model.from_config(config)\n+    M2.set_weights(weights)\n+\n+    output_val_2 = M2.predict(x_val)\n+    np.testing.assert_allclose(output_val, output_val_2, atol=1e-6)\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#29dc8ae6c8d1829cf5f4a1fe1a086070d917da77", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1412 | Contributors (this commit): 7 | Commits (past 90d): 7 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -575,6 +575,7 @@ def test_recursion_with_bn_and_loss():\n     model1.fit(x, y, verbose=0, epochs=1)\n     model2.fit(x, y, verbose=0, epochs=1)\n \n+\n @keras_test\n def test_shared_layer_depth_is_correct():\n     # Basic outline here: we have a shared embedding layer, and two inputs that go through\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e9aa6a5ebe3468f6413ef15ddde128725139abe9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 89 | Lines Deleted: 27 | Files Changed: 2 | Hunks: 11 | Methods Changed: 6 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 116 | Churn Cumulative: 3872 | Contributors (this commit): 56 | Commits (past 90d): 25 | Contributors (cumulative): 68 | DMM Complexity: 1.0\n\nDIFF:\n@@ -757,12 +757,13 @@ class TensorBoard(Callback):\n                 i = 0\n                 while i < val_size:\n                     step = min(self.batch_size, val_size - i)\n-                    batch_val = []\n-                    batch_val.append(val_data[0][i:i + step])\n-                    batch_val.append(val_data[1][i:i + step])\n-                    batch_val.append(val_data[2][i:i + step])\n                     if self.model.uses_learning_phase:\n-                        batch_val.append(val_data[3])\n+                        # do not slice the learning phase\n+                        batch_val = [x[i:i + step] for x in val_data[:-1]]\n+                        batch_val.append(val_data[-1])\n+                    else:\n+                        batch_val = [x[i:i + step] for x in val_data]\n+                    assert len(batch_val) == len(tensors)\n                     feed_dict = dict(zip(tensors, batch_val))\n                     result = self.sess.run([self.merged], feed_dict=feed_dict)\n                     summary_str = result[0]\n\n@@ -8,8 +8,8 @@ import shutil\n from keras import optimizers\n from keras import initializers\n from keras import callbacks\n-from keras.models import Sequential\n-from keras.layers.core import Dense, Dropout\n+from keras.models import Sequential, Model\n+from keras.layers import Input, Dense, Dropout, add\n from keras.layers.convolutional import Conv2D\n from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D\n from keras.utils.test_utils import get_test_data\n@@ -343,6 +343,7 @@ def test_TensorBoard(tmpdir):\n         i = 0\n         while 1:\n             if train:\n+                # simulate multi-input/output models\n                 yield (X_train[i * batch_size: (i + 1) * batch_size],\n                        y_train[i * batch_size: (i + 1) * batch_size])\n             else:\n@@ -351,18 +352,11 @@ def test_TensorBoard(tmpdir):\n             i += 1\n             i = i % max_batch_index\n \n-    def data_generator_graph(train):\n-        while 1:\n-            if train:\n-                yield {'X_vars': X_train, 'output': y_train}\n-            else:\n-                yield {'X_vars': X_test, 'output': y_test}\n-\n-    # case 1 Sequential\n-    model = Sequential()\n-    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n-    model.add(Dropout(0.1))\n-    model.add(Dense(num_class, activation='softmax'))\n+    inp = Input((input_dim,))\n+    hidden = Dense(num_hidden, activation='relu')(inp)\n+    hidden = Dropout(0.1)(hidden)\n+    output = Dense(num_class, activation='softmax')(hidden)\n+    model = Model(inputs=inp, outputs=output)\n     model.compile(loss='categorical_crossentropy',\n                   optimizer='sgd',\n                   metrics=['accuracy'])\n@@ -374,18 +368,14 @@ def test_TensorBoard(tmpdir):\n                                 batch_size=5)\n     cbks = [tsb]\n \n-    # fit with validation data\n+    # fit without validation data\n     model.fit(X_train, y_train, batch_size=batch_size,\n-              validation_data=(X_test, y_test), callbacks=cbks, epochs=3)\n+              callbacks=cbks, epochs=3)\n \n     # fit with validation data and accuracy\n     model.fit(X_train, y_train, batch_size=batch_size,\n-              validation_data=(X_test, y_test), callbacks=cbks, epochs=2)\n-\n-    # fit generator with validation data\n-    model.fit_generator(data_generator(True), len(X_train), epochs=2,\n               validation_data=(X_test, y_test),\n-                        callbacks=cbks)\n+              callbacks=cbks, epochs=2)\n \n     # fit generator without validation data\n     model.fit_generator(data_generator(True), len(X_train), epochs=2,\n@@ -396,10 +386,81 @@ def test_TensorBoard(tmpdir):\n                         validation_data=(X_test, y_test),\n                         callbacks=cbks)\n \n-    # fit generator without validation data and accuracy\n+    assert os.path.isdir(filepath)\n+    shutil.rmtree(filepath)\n+    assert not tmpdir.listdir()\n+\n+\n+@keras_test\n+@pytest.mark.skipif((K.backend() != 'tensorflow'),\n+                    reason='Requires tensorflow backend')\n+def test_TensorBoard_multi_input_output(tmpdir):\n+    np.random.seed(np.random.randint(1, 1e7))\n+    filepath = str(tmpdir / 'logs')\n+\n+    (X_train, y_train), (X_test, y_test) = get_test_data(\n+        num_train=train_samples,\n+        num_test=test_samples,\n+        input_shape=(input_dim,),\n+        classification=True,\n+        num_classes=num_class)\n+    y_test = np_utils.to_categorical(y_test)\n+    y_train = np_utils.to_categorical(y_train)\n+\n+    def data_generator(train):\n+        if train:\n+            max_batch_index = len(X_train) // batch_size\n+        else:\n+            max_batch_index = len(X_test) // batch_size\n+        i = 0\n+        while 1:\n+            if train:\n+                # simulate multi-input/output models\n+                yield ([X_train[i * batch_size: (i + 1) * batch_size]] * 2,\n+                       [y_train[i * batch_size: (i + 1) * batch_size]] * 2)\n+            else:\n+                yield ([X_test[i * batch_size: (i + 1) * batch_size]] * 2,\n+                       [y_test[i * batch_size: (i + 1) * batch_size]] * 2)\n+            i += 1\n+            i = i % max_batch_index\n+\n+    inp1 = Input((input_dim,))\n+    inp2 = Input((input_dim,))\n+    inp = add([inp1, inp2])\n+    hidden = Dense(num_hidden, activation='relu')(inp)\n+    hidden = Dropout(0.1)(hidden)\n+    output1 = Dense(num_class, activation='softmax')(hidden)\n+    output2 = Dense(num_class, activation='softmax')(hidden)\n+    model = Model(inputs=[inp1, inp2], outputs=[output1, output2])\n+    model.compile(loss='categorical_crossentropy',\n+                  optimizer='sgd',\n+                  metrics=['accuracy'])\n+\n+    tsb = callbacks.TensorBoard(log_dir=filepath, histogram_freq=1,\n+                                write_images=True, write_grads=True,\n+                                embeddings_freq=1,\n+                                embeddings_layer_names=['dense_1'],\n+                                batch_size=5)\n+    cbks = [tsb]\n+\n+    # fit without validation data\n+    model.fit([X_train] * 2, [y_train] * 2, batch_size=batch_size,\n+              callbacks=cbks, epochs=3)\n+\n+    # fit with validation data and accuracy\n+    model.fit([X_train] * 2, [y_train] * 2, batch_size=batch_size,\n+              validation_data=([X_test] * 2, [y_test] * 2),\n+              callbacks=cbks, epochs=2)\n+\n+    # fit generator without validation data\n     model.fit_generator(data_generator(True), len(X_train), epochs=2,\n                         callbacks=cbks)\n \n+    # fit generator with validation data and accuracy\n+    model.fit_generator(data_generator(True), len(X_train), epochs=2,\n+                        validation_data=([X_test] * 2, [y_test] * 2),\n+                        callbacks=cbks)\n+\n     assert os.path.isdir(filepath)\n     shutil.rmtree(filepath)\n     assert not tmpdir.listdir()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d9bf40bf8cb829bf620a97f484ade27912ba630e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 33 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 35 | Churn Cumulative: 2430 | Contributors (this commit): 33 | Commits (past 90d): 16 | Contributors (cumulative): 37 | DMM Complexity: 1.0\n\nDIFF:\n@@ -517,9 +517,9 @@ class ImageDataGenerator(object):\n                               'first by calling `.fit(numpy_data)`.')\n         if self.zca_whitening:\n             if self.principal_components is not None:\n-                flatx = np.reshape(x, (x.size))\n+                flatx = np.reshape(x, (-1, np.prod(x.shape[-3:])))\n                 whitex = np.dot(flatx, self.principal_components)\n-                x = np.reshape(whitex, (x.shape[0], x.shape[1], x.shape[2]))\n+                x = np.reshape(whitex, x.shape)\n             else:\n                 warnings.warn('This ImageDataGenerator specifies '\n                               '`zca_whitening`, but it hasn\\'t'\n\n@@ -228,6 +228,37 @@ class TestImage:\n         assert image.random_zoom(x, (5, 5)).shape == (2, 28, 28)\n         assert image.random_channel_shift(x, 20).shape == (2, 28, 28)\n \n+    def test_batch_standardize(self):\n+        # ImageDataGenerator.standardize should work on batches\n+        for test_images in self.all_test_images:\n+            img_list = []\n+            for im in test_images:\n+                img_list.append(image.img_to_array(im)[None, ...])\n+\n+            images = np.vstack(img_list)\n+            generator = image.ImageDataGenerator(\n+                featurewise_center=True,\n+                samplewise_center=True,\n+                featurewise_std_normalization=True,\n+                samplewise_std_normalization=True,\n+                zca_whitening=True,\n+                rotation_range=90.,\n+                width_shift_range=0.1,\n+                height_shift_range=0.1,\n+                shear_range=0.5,\n+                zoom_range=0.2,\n+                channel_shift_range=0.,\n+                fill_mode='nearest',\n+                cval=0.5,\n+                horizontal_flip=True,\n+                vertical_flip=True)\n+            generator.fit(images, augment=True)\n+\n+            transformed = np.copy(images)\n+            for i, im in enumerate(transformed):\n+                transformed[i] = generator.random_transform(im)\n+            transformed = generator.standardize(transformed)\n+\n \n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
