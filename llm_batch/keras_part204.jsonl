{"custom_id": "keras#1f6164695cc01a2920e3bfbd7368a85ec2a8a8aa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 244 | Contributors (this commit): 11 | Commits (past 90d): 6 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -10,7 +10,10 @@ setup(name='Keras',\n       url='https://github.com/fchollet/keras',\n       download_url='https://github.com/fchollet/keras/tarball/2.0.7',\n       license='MIT',\n-      install_requires=['theano', 'pyyaml', 'six'],\n+      install_requires=['numpy>=1.9.1',\n+                        'scipy>=0.14',\n+                        'six>=1.9.0',\n+                        'pyyaml'],\n       extras_require={\n           'h5py': ['h5py'],\n           'visualize': ['pydot>=1.2.0'],\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#27fa03a441962392ef4aefb3656833cc06b2d9a9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 2768 | Contributors (this commit): 57 | Commits (past 90d): 13 | Contributors (cumulative): 57 | DMM Complexity: None\n\nDIFF:\n@@ -748,8 +748,8 @@ class TensorBoard(Callback):\n         logs = logs or {}\n \n         if not self.validation_data and self.histogram_freq:\n-            raise ValueError(\"If printing histograms, validation_data must be \"\n-                             \"provided, and cannot be a generator.\")\n+            raise ValueError('If printing histograms, validation_data must be '\n+                             'provided, and cannot be a generator.')\n         if self.validation_data and self.histogram_freq:\n             if epoch % self.histogram_freq == 0:\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#05b234f993b7dba88e8f468a1c8aba272ee8a55a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 27 | Files Changed: 1 | Hunks: 20 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 53 | Churn Cumulative: 211 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -33,28 +33,21 @@ This example demonstrates how to train with input\n tensors, save the model weights, and then evaluate the\n model using the numpy based Keras API.\n \n-Gets to 99.1% test accuracy after 78 epochs\n-(there is still a lot of margin for parameter tuning).\n+Gets to ~99.1% validation accuracy after 5 epochs\n+(high variance from run to run: 98.9-99.3).\n '''\n-import os\n-import copy\n-import time\n-\n import numpy as np\n \n import tensorflow as tf\n+import keras\n from keras import backend as K\n-from keras.models import Model\n from keras import layers\n-from keras import objectives\n-from keras.utils import np_utils\n-from keras import objectives\n \n from tensorflow.contrib.learn.python.learn.datasets import mnist\n \n if K.backend() != 'tensorflow':\n     raise RuntimeError('This example can only run with the '\n-                       'TensorFlow backend for the time being, '\n+                       'TensorFlow backend, '\n                        'because it requires TFRecords, which '\n                        'are not supported on other platforms.')\n \n@@ -62,11 +55,11 @@ if K.backend() != 'tensorflow':\n def cnn_layers(x_train_input):\n     x = layers.Conv2D(32, (3, 3),\n                       activation='relu', padding='valid')(x_train_input)\n+    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n     x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n-    x = layers.Dropout(0.25)(x)\n     x = layers.Flatten()(x)\n-    x = layers.Dense(128, activation='relu')(x)\n+    x = layers.Dense(512, activation='relu')(x)\n     x = layers.Dropout(0.5)(x)\n     x_train_out = layers.Dense(classes,\n                                activation='softmax',\n@@ -78,7 +71,7 @@ sess = K.get_session()\n batch_size = 128\n batch_shape = (batch_size, 28, 28, 1)\n steps_per_epoch = 469\n-epochs = 78\n+epochs = 5\n classes = 10\n \n # The capacity variable controls the maximum queue size\n@@ -120,25 +113,27 @@ y_batch_shape = y_train_batch.get_shape().as_list()\n \n x_train_input = layers.Input(tensor=x_train_batch, batch_shape=x_batch_shape)\n x_train_out = cnn_layers(x_train_input)\n-train_model = Model(inputs=x_train_input, outputs=x_train_out)\n+train_model = keras.models.Model(inputs=x_train_input, outputs=x_train_out)\n \n-cce = objectives.categorical_crossentropy(y_train_batch, x_train_out)\n-train_model.add_loss(cce)\n-\n-# Do not pass the loss directly to model.compile()\n-# because it is not yet supported for Input Tensors.\n-train_model.compile(optimizer='rmsprop',\n-                    loss=None,\n-                    metrics=['accuracy'])\n+# Pass the target tensor `y_train_batch` to `compile`\n+# via the `target_tensors` keyword argument:\n+train_model.compile(optimizer=keras.optimizers.RMSprop(lr=2e-3, decay=1e-5),\n+                    loss='categorical_crossentropy',\n+                    metrics=['accuracy'],\n+                    target_tensors=[y_train_batch])\n train_model.summary()\n \n+# Fit the model using data from the TFRecord data tensors.\n coord = tf.train.Coordinator()\n threads = tf.train.start_queue_runners(sess, coord)\n+\n train_model.fit(epochs=epochs,\n                 steps_per_epoch=steps_per_epoch)\n \n+# Save the model weights.\n train_model.save_weights('saved_wt.h5')\n \n+# Clean up the TF session.\n coord.request_stop()\n coord.join(threads)\n K.clear_session()\n@@ -146,13 +141,17 @@ K.clear_session()\n # Second Session to test loading trained model without tensors\n x_test = np.reshape(data.validation.images, (data.validation.images.shape[0], 28, 28, 1))\n y_test = data.validation.labels\n-x_test_inp = layers.Input(batch_shape=(None,) + (x_test.shape[1:]))\n+x_test_inp = layers.Input(shape=(x_test.shape[1:]))\n test_out = cnn_layers(x_test_inp)\n-test_model = Model(inputs=x_test_inp, outputs=test_out)\n+test_model = keras.models.Model(inputs=x_test_inp, outputs=test_out)\n \n test_model.load_weights('saved_wt.h5')\n-test_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n+test_model.compile(optimizer='rmsprop',\n+                   loss='categorical_crossentropy',\n+                   metrics=['accuracy'])\n test_model.summary()\n \n-loss, acc = test_model.evaluate(x_test, np_utils.to_categorical(y_test), classes)\n+loss, acc = test_model.evaluate(x_test,\n+                                keras.utils.to_categorical(y_test),\n+                                classes)\n print('\\nTest accuracy: {0}'.format(acc))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c7dd36a1bab362de478f528078261439b803aaa7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 371 | Contributors (this commit): 14 | Commits (past 90d): 14 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -20,4 +20,4 @@ from . import regularizers\n # Importable from root because it's technically not a layer\r\n from .layers import Input\r\n \r\n-__version__ = '2.0.7'\r\n+__version__ = '2.0.8'\r\n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='2.0.7',\n+      version='2.0.8',\n       description='Deep Learning for Python',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/fchollet/keras',\n-      download_url='https://github.com/fchollet/keras/tarball/2.0.7',\n+      download_url='https://github.com/fchollet/keras/tarball/2.0.8',\n       license='MIT',\n       install_requires=['numpy>=1.9.1',\n                         'scipy>=0.14',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9e1dd0ac58ba5f1343af76a69a762cb75ca3315d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 213 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -111,7 +111,7 @@ y_train_batch = tf.one_hot(y_train_batch, classes)\n x_batch_shape = x_train_batch.get_shape().as_list()\n y_batch_shape = y_train_batch.get_shape().as_list()\n \n-x_train_input = layers.Input(tensor=x_train_batch, batch_shape=x_batch_shape)\n+x_train_input = layers.Input(tensor=x_train_batch)\n x_train_out = cnn_layers(x_train_input)\n train_model = keras.models.Model(inputs=x_train_input, outputs=x_train_out)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fa97c50dc1abddef0e0fdc21dcf2192b84ffca7e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 219 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -111,9 +111,9 @@ y_train_batch = tf.one_hot(y_train_batch, classes)\n x_batch_shape = x_train_batch.get_shape().as_list()\n y_batch_shape = y_train_batch.get_shape().as_list()\n \n-x_train_input = layers.Input(tensor=x_train_batch)\n-x_train_out = cnn_layers(x_train_input)\n-train_model = keras.models.Model(inputs=x_train_input, outputs=x_train_out)\n+model_input = layers.Input(tensor=x_train_batch)\n+model_output = cnn_layers(model_input)\n+train_model = keras.models.Model(inputs=model_input, outputs=model_output)\n \n # Pass the target tensor `y_train_batch` to `compile`\n # via the `target_tensors` keyword argument:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a82807fa9cd5fa6243bec6aaf062927304408e52", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2309 | Contributors (this commit): 35 | Commits (past 90d): 11 | Contributors (cumulative): 35 | DMM Complexity: None\n\nDIFF:\n@@ -333,7 +333,7 @@ def load_img(path, grayscale=False, target_size=None):\n     return img\n \n \n-def list_pictures(directory, ext='jpg|jpeg|bmp|png'):\n+def list_pictures(directory, ext='jpg|jpeg|bmp|png|ppm'):\n     return [os.path.join(root, f)\n             for root, _, files in os.walk(directory) for f in files\n             if re.match(r'([\\w]+\\.(?:' + ext + '))', f)]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5672db9b4104021faa8476985f36975d8d31be1d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 6722 | Contributors (this commit): 45 | Commits (past 90d): 7 | Contributors (cumulative): 45 | DMM Complexity: None\n\nDIFF:\n@@ -21,7 +21,7 @@ def _time_distributed_dense(x, w, b=None, dropout=None,\n         x: input tensor.\n         w: weight matrix.\n         b: optional bias vector.\n-        dropout: wether to apply dropout (same dropout mask\n+        dropout: whether to apply dropout (same dropout mask\n             for every temporal slice of the input).\n         input_dim: integer; optional dimensionality of the input.\n         output_dim: integer; optional dimensionality of the output.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fb7361ec2277598a6d8d25eb822c86d34194fdf2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 698 | Contributors (this commit): 13 | Commits (past 90d): 5 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -78,7 +78,7 @@ vae.fit(x_train,\n         shuffle=True,\n         epochs=epochs,\n         batch_size=batch_size,\n-        validation_data=(x_test, x_test))\n+        validation_data=(x_test, None))\n \n # build a model to project inputs on the latent space\n encoder = Model(x, z_mean)\n\n@@ -148,7 +148,7 @@ vae.fit(x_train,\n         shuffle=True,\n         epochs=epochs,\n         batch_size=batch_size,\n-        validation_data=(x_test, x_test))\n+        validation_data=(x_test, None))\n \n # build a model to project inputs on the latent space\n encoder = Model(x, z_mean)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#135efd66d00166ca6df32f218d086f98cc300f1e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 5400 | Contributors (this commit): 61 | Commits (past 90d): 30 | Contributors (cumulative): 61 | DMM Complexity: None\n\nDIFF:\n@@ -1437,11 +1437,13 @@ class Model(Container):\n                 If all inputs in the model are named,\n                 you can also pass a dictionary\n                 mapping input names to Numpy arrays.\n+                Can be `None` (default) if feeding from framework-native tensors.\n             y: Numpy array of target data,\n                 or list of Numpy arrays if the model has multiple outputs.\n                 If all outputs in the model are named,\n                 you can also pass a dictionary\n                 mapping output names to Numpy arrays.\n+                Can be `None` (default) if feeding from framework-native tensors.\n             batch_size: Integer or `None`.\n                 Number of samples per gradient update.\n                 If unspecified, it will default to 32.\n@@ -1597,7 +1599,7 @@ class Model(Container):\n                               steps_per_epoch=steps_per_epoch,\n                               validation_steps=validation_steps)\n \n-    def evaluate(self, x, y,\n+    def evaluate(self, x=None, y=None,\n                  batch_size=None,\n                  verbose=1,\n                  sample_weight=None,\n@@ -1612,11 +1614,13 @@ class Model(Container):\n                 If all inputs in the model are named,\n                 you can also pass a dictionary\n                 mapping input names to Numpy arrays.\n+                Can be `None` (default) if feeding from framework-native tensors.\n             y: Numpy array of target data,\n                 or list of Numpy arrays if the model has multiple outputs.\n                 If all outputs in the model are named,\n                 you can also pass a dictionary\n                 mapping output names to Numpy arrays.\n+                Can be `None` (default) if feeding from framework-native tensors.\n             batch_size: Integer. If unspecified, it will default to 32.\n             verbose: Verbosity mode, 0 or 1.\n             sample_weight: Array of weights to weight the contribution\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8fdd663a850d99701fd1bb9159f64bb73bd127d3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1274 | Contributors (this commit): 16 | Commits (past 90d): 4 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -330,5 +330,5 @@ class KerasRegressor(BaseWrapper):\n         kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n         loss = self.model.evaluate(x, y, **kwargs)\n         if isinstance(loss, list):\n-            return loss[0]\n-        return loss\n+            return -loss[0]\n+        return -loss\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5625d70ed9fbb0692ddde085009c8f2ef1111838", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 48 | Lines Deleted: 47 | Files Changed: 25 | Hunks: 47 | Methods Changed: 21 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 95 | Churn Cumulative: 55402 | Contributors (this commit): 270 | Commits (past 90d): 211 | Contributors (cumulative): 538 | DMM Complexity: None\n\nDIFF:\n@@ -125,7 +125,7 @@ for i in range(15):\n     if i >= 7:\n         ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n     else:\n-        ax.text(1, 3, 'Inital trajectory', fontsize=20)\n+        ax.text(1, 3, 'Initial trajectory', fontsize=20)\n \n     toplot = track[i, ::, ::, 0]\n \n\n@@ -80,7 +80,7 @@ def paint_text(text, w, h, rotate=False, ud=False, multi_fonts=False):\n     with cairo.Context(surface) as context:\n         context.set_source_rgb(1, 1, 1)  # White\n         context.paint()\n-        # this font list works in Centos 7\n+        # this font list works in CentOS 7\n         if multi_fonts:\n             fonts = ['Century Schoolbook', 'Courier', 'STIX', 'URW Chancery L', 'FreeMono']\n             context.select_font_face(np.random.choice(fonts), cairo.FONT_SLANT_NORMAL,\n\n@@ -1,4 +1,4 @@\n-'''Trains a LSTM on the IMDB sentiment classification task.\n+'''Trains an LSTM model on the IMDB sentiment classification task.\n The dataset is actually too small for LSTM to be of any advantage\n compared to simpler, much faster methods such as TF-IDF + LogReg.\n Notes:\n\n@@ -1,6 +1,6 @@\n \"\"\"This is an example of using Hierarchical RNN (HRNN) to classify MNIST digits.\n \n-HRNNs can learn across multiple levels of temporal hiearchy over a complex sequence.\n+HRNNs can learn across multiple levels of temporal hierarchy over a complex sequence.\n Usually, the first recurrent layer of an HRNN encodes a sentence (e.g. of word vectors)\n into a  sentence vector. The second recurrent layer then encodes a sequence of\n such vectors (encoded by the first layer) into a document vector. This\n\n@@ -105,7 +105,7 @@ if K.backend() == 'tensorflow':\n                        'Theano backend for the time being, '\r\n                        'because it requires taking the gradient '\r\n                        'of a gradient, which isn\\'t '\r\n-                       'supported for all TF ops.')\r\n+                       'supported for all TensorFlow ops.')\r\n \r\n # This example assume 'channels_first' data format.\r\n K.set_image_data_format('channels_first')\r\n\n@@ -1,7 +1,7 @@\n '''This script loads pre-trained word embeddings (GloVe embeddings)\n into a frozen Keras Embedding layer, and uses it to\n train a text classification model on the 20 Newsgroup dataset\n-(classication of newsgroup messages into 20 different categories).\n+(classification of newsgroup messages into 20 different categories).\n \n GloVe embedding data can be found at:\n http://nlp.stanford.edu/data/glove.6B.zip\n\n@@ -43,7 +43,7 @@ def identity_block(input_tensor, kernel_size, filters, stage, block):\n     # Arguments\n         input_tensor: input tensor\n         kernel_size: default 3, the kernel size of middle conv layer at main path\n-        filters: list of integers, the filterss of 3 conv layer at main path\n+        filters: list of integers, the filters of 3 conv layer at main path\n         stage: integer, current stage label, used for generating layer names\n         block: 'a','b'..., current block label, used for generating layer names\n \n@@ -81,7 +81,7 @@ def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2))\n     # Arguments\n         input_tensor: input tensor\n         kernel_size: default 3, the kernel size of middle conv layer at main path\n-        filters: list of integers, the filterss of 3 conv layer at main path\n+        filters: list of integers, the filters of 3 conv layer at main path\n         stage: integer, current stage label, used for generating layer names\n         block: 'a','b'..., current block label, used for generating layer names\n \n\n@@ -88,7 +88,7 @@ def in_train_phase(x, alt, training=None):\n \n def in_test_phase(x, alt):\n     global _LEARNING_PHASE\n-    # Similiar as in_train_phase, use element_select as workaround.\n+    # Similar as in_train_phase, use element_select as workaround.\n     if callable(x) and isinstance(x, C.cntk_py.Function) is False:\n         x = x()\n     if callable(alt) and isinstance(alt, C.cntk_py.Function) is False:\n@@ -700,7 +700,7 @@ def _normalize_axis(axis, x):\n \n     if nones > ndim:\n         raise ValueError('CNTK Backend: tensor with keras shape: `%s` has '\n-                         '%d cntk dynamic axis, this is not expected, plesae '\n+                         '%d cntk dynamic axis, this is not expected, please '\n                          'double check the keras shape history.' % (str(shape), nones))\n \n     # Current cntk does not support shape like (1, batch). so using the workaround\n@@ -1079,7 +1079,7 @@ def reshape(x, shape):\n                 return x\n             return C.user_function(ReshapeBatch(x, shape[1:]))\n         else:\n-            # no collaps, then first need to padding the shape\n+            # no collapse, then first need to padding the shape\n             if num_dynamic_axis >= len(shape):\n                 i = 0\n                 while i < len(shape):\n@@ -1194,7 +1194,7 @@ def _static_rnn(step_function, inputs, initial_states,\n         raise ValueError('CNTK Backend: the input of static rnn '\n                          'has shape `%s`, the second axis '\n                          'is not static. If you want to run '\n-                         'rnn with non-static axis, plesae try '\n+                         'rnn with non-static axis, please try '\n                          'dynamic rnn with sequence axis.' % shape)\n     if constants is None:\n         constants = []\n\n@@ -35,7 +35,7 @@ _GRAPH_LEARNING_PHASES = {}\n \n # This dictionary holds a mapping {graph: UID_DICT}.\n # each UID_DICT is a dictionary mapping name prefixes to a current index,\n-# used for generatic graph-specific string UIDs\n+# used for generic graph-specific string UIDs\n # for various names (e.g. layer names).\n _GRAPH_UID_DICTS = {}\n \n@@ -3591,10 +3591,10 @@ def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n \n \n # CTC\n-# tensorflow has a native implemenation, but it uses sparse tensors\n+# TensorFlow has a native implementation, but it uses sparse tensors\n # and therefore requires a wrapper for Keras. The functions below convert\n # dense to sparse tensors and also wraps up the beam search code that is\n-# in tensorflow's CTC implementation\n+# in TensorFlow's CTC implementation\n \n \n def ctc_label_dense_to_sparse(labels, label_lengths):\n\n@@ -1159,8 +1159,8 @@ def reverse(x, axes):\n     return x[slices]\n \n \n-def pattern_broadcast(x, broatcastable):\n-    return T.patternbroadcast(x, broatcastable)\n+def pattern_broadcast(x, broadcastable):\n+    return T.patternbroadcast(x, broadcastable)\n \n # VALUE MANIPULATION\n \n@@ -2249,7 +2249,7 @@ def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n # Theano implementation of CTC\n # Used with permission from Shawn Tan\n # https://github.com/shawntan/\n-# Note that tensorflow's native CTC code is significantly\n+# Note that TensorFlow's native CTC code is significantly\n # faster than this\n \n \n\n@@ -248,7 +248,7 @@ class ProgbarLogger(Callback):\n     # Arguments\n         count_mode: One of \"steps\" or \"samples\".\n             Whether the progress bar should\n-            count samples seens or steps (batches) seen.\n+            count samples seen or steps (batches) seen.\n \n     # Raises\n         ValueError: In case of invalid `count_mode`.\n\n@@ -616,7 +616,7 @@ class Layer(object):\n             else:\n                 output = output_ls_copy\n \n-            # Infering the output shape is only relevant for Theano.\n+            # Inferring the output shape is only relevant for Theano.\n             if all([s is not None for s in _to_list(input_shape)]):\n                 output_shape = self.compute_output_shape(input_shape)\n             else:\n\n@@ -503,7 +503,7 @@ class ConvLSTM2D(ConvRecurrent2D):\n                                   data_format=self.data_format)\n         return conv_out\n \n-    def reccurent_conv(self, x, w):\n+    def recurrent_conv(self, x, w):\n         conv_out = K.conv2d(x, w, strides=(1, 1),\n                             padding='same',\n                             data_format=self.data_format)\n@@ -524,13 +524,13 @@ class ConvLSTM2D(ConvRecurrent2D):\n                               padding=self.padding)\n         x_o = self.input_conv(inputs * dp_mask[3], self.kernel_o, self.bias_o,\n                               padding=self.padding)\n-        h_i = self.reccurent_conv(h_tm1 * rec_dp_mask[0],\n+        h_i = self.recurrent_conv(h_tm1 * rec_dp_mask[0],\n                                   self.recurrent_kernel_i)\n-        h_f = self.reccurent_conv(h_tm1 * rec_dp_mask[1],\n+        h_f = self.recurrent_conv(h_tm1 * rec_dp_mask[1],\n                                   self.recurrent_kernel_f)\n-        h_c = self.reccurent_conv(h_tm1 * rec_dp_mask[2],\n+        h_c = self.recurrent_conv(h_tm1 * rec_dp_mask[2],\n                                   self.recurrent_kernel_c)\n-        h_o = self.reccurent_conv(h_tm1 * rec_dp_mask[3],\n+        h_o = self.recurrent_conv(h_tm1 * rec_dp_mask[3],\n                                   self.recurrent_kernel_o)\n \n         i = self.recurrent_activation(x_i + h_i)\n\n@@ -36,7 +36,7 @@ class Masking(Layer):\n     # Example\n \n     Consider a Numpy data array `x` of shape `(samples, timesteps, features)`,\n-    to be fed to a LSTM layer.\n+    to be fed to an LSTM layer.\n     You want to mask timestep #3 and #5 because you lack data for\n     these timesteps. You can:\n \n\n@@ -4,6 +4,7 @@ from . import backend as K\n from .utils.generic_utils import deserialize_keras_object\n \n \n+# noinspection SpellCheckingInspection\n def mean_squared_error(y_true, y_pred):\n     return K.mean(K.square(y_pred - y_true), axis=-1)\n \n\n@@ -908,7 +908,7 @@ class DirectoryIterator(Iterator):\n             to use for random transformations and normalization.\n         target_size: tuple of integers, dimensions to resize input images to.\n         color_mode: One of `\"rgb\"`, `\"grayscale\"`. Color mode to read images.\n-        classes: Optional list of strings, names of sudirectories\n+        classes: Optional list of strings, names of subdirectories\n             containing images from each class (e.g. `[\"dogs\", \"cats\"]`).\n             It will be computed automatically if not set.\n         class_mode: Mode for yielding the targets:\n\n@@ -139,7 +139,7 @@ def skipgrams(sequence, vocabulary_size,\n             integers (eg. [0, 1, 1 .. ]),\n             if True labels will be categorical eg. [[1,0],[0,1],[0,1] .. ]\n         sampling_table: 1D array of size `vocabulary_size` where the entry i\n-            encodes the probabibily to sample a word of rank i.\n+            encodes the probability to sample a word of rank i.\n         seed: random seed.\n \n     # Returns\n\n@@ -206,7 +206,7 @@ def test_masked_temporal():\n     assert(np.abs(history.history['loss'][-1] - ground_truth) < 0.06)\n \n \n-@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TF backend')\n+@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TensorFlow backend')\n @keras_test\n def test_embedding_with_clipnorm():\n     model = Sequential()\n\n@@ -164,7 +164,7 @@ def test_vgg19_pooling_specified_input_shape():\n \n @keras_test\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n-                    reason='Requires tensorflow backend')\n+                    reason='Requires TensorFlow backend')\n def test_xception():\n     model = applications.Xception(weights=None)\n     assert model.output_shape == (None, 1000)\n@@ -172,7 +172,7 @@ def test_xception():\n \n @keras_test\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n-                    reason='Requires tensorflow backend')\n+                    reason='Requires TensorFlow backend')\n def test_xception_notop():\n     model = applications.Xception(weights=None, include_top=False)\n     assert model.output_shape == (None, None, None, 2048)\n@@ -180,7 +180,7 @@ def test_xception_notop():\n \n @keras_test\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n-                    reason='Requires tensorflow backend')\n+                    reason='Requires TensorFlow backend')\n def test_xception_pooling():\n     model = applications.Xception(weights=None, include_top=False, pooling='avg')\n     assert model.output_shape == (None, 2048)\n@@ -188,7 +188,7 @@ def test_xception_pooling():\n \n @keras_test\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n-                    reason='Requires tensorflow backend')\n+                    reason='Requires TensorFlow backend')\n def test_xception_variable_input_channels():\n     input_shape = (1, None, None) if K.image_data_format() == 'channels_first' else (None, None, 1)\n     model = applications.Xception(weights=None, include_top=False, input_shape=input_shape)\n\n@@ -22,7 +22,7 @@ try:\n     BACKENDS.append(KTF)\n except ImportError:\n     KTF = None\n-    warnings.warn('Could not import the Tensorflow backend.')\n+    warnings.warn('Could not import the TensorFlow backend.')\n \n try:\n     from keras.backend import theano_backend as KTH\n@@ -694,7 +694,7 @@ class TestBackend(object):\n         # cross_entropy call require the label is a valid probability distribution,\n         # otherwise it is garbage in garbage out...\n         # due to the algo difference, we can't guarantee CNTK has the same result on the garbage input.\n-        # so create a seperate test case for valid lable input\n+        # so create a separate test case for valid label input\n         check_two_tensor_operation('categorical_crossentropy', (4, 2), (4, 2), [KTH, KTF], from_logits=True)\n         xval = np.asarray([[0.26157712, 0.0432167], [-0.43380741, 0.30559841],\n                            [0.20225059, -0.38956559], [-0.13805378, 0.08506755]], dtype=np.float32)\n@@ -1028,7 +1028,7 @@ class TestBackend(object):\n                                        BACKENDS, cntk_dynamicity=True,\n                                        data_format=data_format)\n \n-        # Test invalid use casess\n+        # Test invalid use cases\n         for k in BACKENDS:\n             x = k.variable(np.random.random(x_shape))\n             b = k.variable(np.random.random(bias_shape))\n\n@@ -689,7 +689,7 @@ def test_shared_layer_depth_is_correct():\n \n \n @keras_test\n-def test_layer_sharing_at_heterogenous_depth():\n+def test_layer_sharing_at_heterogeneous_depth():\n     x_val = np.random.random((10, 5))\n \n     x = Input(shape=(5,))\n@@ -711,7 +711,7 @@ def test_layer_sharing_at_heterogenous_depth():\n \n \n @keras_test\n-def test_layer_sharing_at_heterogenous_depth_with_concat():\n+def test_layer_sharing_at_heterogeneous_depth_with_concat():\n     input_shape = (16, 9, 3)\n     input_layer = Input(shape=input_shape)\n \n\n@@ -417,7 +417,7 @@ def test_warnings():\n     assert all(['Sequence' not in str(w_.message) for w_ in w]), 'A warning was raised for Sequence.'\n \n \n-@pytest.mark.skipif(K.backend() != 'tensorflow', reason='sparse operations supported only by TF')\n+@pytest.mark.skipif(K.backend() != 'tensorflow', reason='sparse operations supported only by TensorFlow')\n @keras_test\n def test_sparse_input_validation_split():\n     test_input = sparse.random(6, 3, density=0.25).tocsr()\n@@ -478,7 +478,7 @@ def test_check_bad_shape():\n     assert 'targets to have the same shape' in str(exc)\n \n \n-@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TF backend')\n+@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TensorFlow backend')\n @keras_test\n def test_model_with_input_feed_tensor():\n     \"\"\"We test building a model with a TF variable as input.\n\n@@ -275,7 +275,7 @@ def test_sequential_regression():\n \n     branch_1_2 = models.Sequential([legacy_layers.Merge([branch_1, branch_2], mode='concat')], name='branch_1_2')\n     branch_1_2.add(layers.Dense(16, name='dense_1_2-0'))\n-    # test whether impromtu input_shape breaks the model\n+    # test whether impromptu input_shape breaks the model\n     branch_1_2.add(layers.Dense(16, input_shape=(16,), name='dense_1_2-1'))\n \n     model = models.Sequential([legacy_layers.Merge([branch_1_2, branch_3], mode='concat')], name='final')\n\n@@ -117,7 +117,7 @@ def test_clipvalue():\n \n @keras_test\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n-                    reason='Requires tensorflow backend')\n+                    reason='Requires TensorFlow backend')\n def test_tfoptimizer():\n     from keras import constraints\n     from tensorflow import train\n\n@@ -374,7 +374,7 @@ def test_CSVLogger(tmpdir):\n \n @keras_test\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n-                    reason='Requires tensorflow backend')\n+                    reason='Requires TensorFlow backend')\n def test_TensorBoard(tmpdir):\n     np.random.seed(np.random.randint(1, 1e7))\n     filepath = str(tmpdir / 'logs')\n@@ -448,7 +448,7 @@ def test_TensorBoard(tmpdir):\n \n @keras_test\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n-                    reason='Requires tensorflow backend')\n+                    reason='Requires TensorFlow backend')\n def test_TensorBoard_histogram_freq_must_have_validation_data(tmpdir):\n     np.random.seed(np.random.randint(1, 1e7))\n     filepath = str(tmpdir / 'logs')\n@@ -522,7 +522,7 @@ def test_TensorBoard_histogram_freq_must_have_validation_data(tmpdir):\n \n @keras_test\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n-                    reason='Requires tensorflow backend')\n+                    reason='Requires TensorFlow backend')\n def test_TensorBoard_multi_input_output(tmpdir):\n     np.random.seed(np.random.randint(1, 1e7))\n     filepath = str(tmpdir / 'logs')\n@@ -599,7 +599,7 @@ def test_TensorBoard_multi_input_output(tmpdir):\n \n @keras_test\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n-                    reason='Requires tensorflow backend')\n+                    reason='Requires TensorFlow backend')\n def test_TensorBoard_convnet(tmpdir):\n     np.random.seed(np.random.randint(1, 1e7))\n     filepath = str(tmpdir / 'logs')\n@@ -724,7 +724,7 @@ def test_LambdaCallback():\n \n @keras_test\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n-                    reason=\"Requires tensorflow backend\")\n+                    reason=\"Requires TensorFlow backend\")\n def test_TensorBoard_with_ReduceLROnPlateau(tmpdir):\n     import shutil\n     np.random.seed(np.random.randint(1, 1e7))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a379b4207ab98c7e6b11ceb0e012a348d7b951d5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 49 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 49 | Churn Cumulative: 129 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -6,3 +6,4 @@ from . import reuters\n from . import cifar10\n from . import cifar100\n from . import boston_housing\n+from . import fashion_mnist\n\n@@ -0,0 +1,37 @@\n+import gzip\n+import os\n+\n+from ..utils.data_utils import get_file\n+import numpy as np\n+\n+\n+def load_data():\n+    \"\"\"Loads the Fashion-MNIST dataset.\n+\n+    # Returns\n+        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n+    \"\"\"\n+    dirname = os.path.join('datasets', 'fashion-mnist')\n+    base = 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/'\n+    files = ['train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz',\n+             't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz']\n+\n+    paths = []\n+    for file in files:\n+        paths.append(get_file(file, origin=base + file, cache_subdir=dirname))\n+\n+    with gzip.open(paths[0], 'rb') as lbpath:\n+        y_train = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n+\n+    with gzip.open(paths[1], 'rb') as imgpath:\n+        x_train = np.frombuffer(imgpath.read(), np.uint8,\n+                                offset=16).reshape(len(y_train), 28, 28)\n+\n+    with gzip.open(paths[2], 'rb') as lbpath:\n+        y_test = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n+\n+    with gzip.open(paths[3], 'rb') as imgpath:\n+        x_test = np.frombuffer(imgpath.read(), np.uint8,\n+                               offset=16).reshape(len(y_test), 28, 28)\n+\n+    return (x_train, y_train), (x_test, y_test)\n\n@@ -8,6 +8,7 @@ from keras.datasets import reuters\n from keras.datasets import imdb\n from keras.datasets import mnist\n from keras.datasets import boston_housing\n+from keras.datasets import fashion_mnist\n \n \n def test_cifar():\n@@ -75,5 +76,15 @@ def test_boston_housing():\n         assert len(x_test) == len(y_test)\n \n \n+def test_fashion_mnist():\n+    # only run data download tests 20% of the time\n+    # to speed up frequent testing\n+    random.seed(time.time())\n+    if random.random() > 0.8:\n+        (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n+        assert len(x_train) == len(y_train) == 60000\n+        assert len(x_test) == len(y_test) == 10000\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#48b8676e64dfe4ca4b81cc4286300ae60f140dca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 9540 | Contributors (this commit): 77 | Commits (past 90d): 13 | Contributors (cumulative): 77 | DMM Complexity: None\n\nDIFF:\n@@ -804,7 +804,11 @@ class Sequential(Model):\n                 (if the model has multiple inputs).\n             y: labels, as a Numpy array.\n             batch_size: integer. Number of samples per gradient update.\n-            epochs: integer, the number of epochs to train the model.\n+            epochs: integer. Number of epochs to train the model.\n+                Note that in conjunction with initial_epoch, the parameter\n+                epochs is to be understood as \"final epoch\". The model is\n+                not trained for a number of steps given by epochs, but\n+                until the epoch epochs is reached.\n             verbose: 0 for no logging to stdout,\n                 1 for progress bar logging, 2 for one log line per epoch.\n             callbacks: list of `keras.callbacks.Callback` instances.\n@@ -831,8 +835,8 @@ class Sequential(Model):\n                 to apply a different weight to every timestep of every sample.\n                 In this case you should make sure to specify\n                 sample_weight_mode=\"temporal\" in compile().\n-            initial_epoch: epoch at which to start training\n-                (useful for resuming a previous training run)\n+            initial_epoch: Epoch at which to start training\n+                (useful for resuming a previous training run).\n \n         # Returns\n             A `History` object. Its `History.history` attribute is\n@@ -1055,6 +1059,10 @@ class Sequential(Model):\n                 be equal to the number of unique samples of your dataset\n                 divided by the batch size.\n             epochs: Integer, total number of iterations on the data.\n+                Note that in conjunction with initial_epoch, the parameter\n+                epochs is to be understood as \"final epoch\". The model is\n+                not trained for n steps given by epochs, but until the\n+                epoch epochs is reached.\n             verbose: Verbosity mode, 0, 1, or 2.\n             callbacks: List of callbacks to be called during training.\n             validation_data: This can be either\n@@ -1079,7 +1087,7 @@ class Sequential(Model):\n                 as they can't be passed\n                 easily to children processes.\n             initial_epoch: Epoch at which to start training\n-                (useful for resuming a previous training run)\n+                (useful for resuming a previous training run).\n \n         # Returns\n             A `History` object.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#813ce43d55b52c936d49d73b28b058d3f96cdd05", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 47 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 47 | Churn Cumulative: 1093 | Contributors (this commit): 12 | Commits (past 90d): 6 | Contributors (cumulative): 17 | DMM Complexity: 1.0\n\nDIFF:\n@@ -290,6 +290,21 @@ class Maximum(_Merge):\n         return output\n \n \n+class Minimum(_Merge):\n+    \"\"\"Layer that computes the minimum (element-wise) a list of inputs.\n+\n+    It takes as input a list of tensors,\n+    all of the same shape, and returns\n+    a single tensor (also of the same shape).\n+    \"\"\"\n+\n+    def _merge_function(self, inputs):\n+        output = inputs[0]\n+        for i in range(1, len(inputs)):\n+            output = K.minimum(output, inputs[i])\n+        return output\n+\n+\n class Concatenate(_Merge):\n     \"\"\"Layer that concatenates a list of inputs.\n \n@@ -586,6 +601,19 @@ def maximum(inputs, **kwargs):\n     return Maximum(**kwargs)(inputs)\n \n \n+def minimum(inputs, **kwargs):\n+    \"\"\"Functional interface to the `Minimum` layer.\n+\n+    # Arguments\n+        inputs: A list of input tensors (at least 2).\n+        **kwargs: Standard layer keyword arguments.\n+\n+    # Returns\n+        A tensor, the element-wise minimum of the inputs.\n+    \"\"\"\n+    return Minimum(**kwargs)(inputs)\n+\n+\n def concatenate(inputs, axis=-1, **kwargs):\n     \"\"\"Functional interface to the `Concatenate` layer.\n \n\n@@ -138,6 +138,25 @@ def test_merge_maximum():\n     assert_allclose(out, np.maximum(x1, x2), atol=1e-4)\n \n \n+@keras_test\n+def test_merge_minimum():\n+    i1 = layers.Input(shape=(4, 5))\n+    i2 = layers.Input(shape=(4, 5))\n+    o = layers.minimum([i1, i2])\n+    assert o._keras_shape == (None, 4, 5)\n+    model = models.Model([i1, i2], o)\n+\n+    max_layer = layers.Minimum()\n+    o2 = max_layer([i1, i2])\n+    assert max_layer.output_shape == (None, 4, 5)\n+\n+    x1 = np.random.random((2, 4, 5))\n+    x2 = np.random.random((2, 4, 5))\n+    out = model.predict([x1, x2])\n+    assert out.shape == (2, 4, 5)\n+    assert_allclose(out, np.minimum(x1, x2), atol=1e-4)\n+\n+\n @keras_test\n def test_merge_concatenate():\n     i1 = layers.Input(shape=(None, 5))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#073c9ff3e3baebffa9d33057c951eeb02c4c36a4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2643 | Contributors (this commit): 11 | Commits (past 90d): 21 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -57,7 +57,7 @@ def set_learning_phase(value):\n         raise ValueError('CNTK Backend: Set learning phase '\n                          'with value %s is not supported, '\n                          'expected 0 or 1.' % value)\n-    v = np.float32([value])\n+    v = np.asarray(value)\n     _LEARNING_PHASE.value = v\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b76571f636ba37a04d4f104d701a62a536dfa0b4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2313 | Contributors (this commit): 37 | Commits (past 90d): 11 | Contributors (cumulative): 37 | DMM Complexity: None\n\nDIFF:\n@@ -356,7 +356,7 @@ class ImageDataGenerator(object):\n         zoom_range: amount of zoom. if scalar z, zoom will be randomly picked\n             in the range [1-z, 1+z]. A sequence of two can be passed instead\n             to select this range.\n-        channel_shift_range: shift range for each channels.\n+        channel_shift_range: shift range for each channel.\n         fill_mode: points outside the boundaries are filled according to the\n             given mode ('constant', 'nearest', 'reflect' or 'wrap'). Default\n             is 'nearest'.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#19862b0b1d52e7636b30b0a0955ae4ecf2544edb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 442 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 8 | Complexity Δ (Sum/Max): 37/33 | Churn Δ: 442 | Churn Cumulative: 836 | Contributors (this commit): 7 | Commits (past 90d): 9 | Contributors (cumulative): 11 | DMM Complexity: 0.16591928251121077\n\nDIFF:\n@@ -2,5 +2,6 @@ from .vgg16 import VGG16\n from .vgg19 import VGG19\n from .resnet50 import ResNet50\n from .inception_v3 import InceptionV3\n+from .inception_resnet_v2 import InceptionResNetV2\n from .xception import Xception\n from .mobilenet import MobileNet\n\n@@ -0,0 +1,383 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"Inception-ResNet V2 model for Keras.\n+\n+Model naming and structure follows TF-slim implementation (which has some additional\n+layers and different number of filters from the original arXiv paper):\n+https://github.com/tensorflow/models/blob/master/slim/nets/inception_resnet_v2.py\n+\n+Pre-trained ImageNet weights are also converted from TF-slim, which can be found in:\n+https://github.com/tensorflow/models/tree/master/slim#pre-trained-models\n+\n+# Reference\n+- [Inception-v4, Inception-ResNet and the Impact of\n+   Residual Connections on Learning](https://arxiv.org/abs/1602.07261)\n+\n+\"\"\"\n+from __future__ import print_function\n+from __future__ import absolute_import\n+\n+import warnings\n+\n+from ..models import Model\n+from ..layers import Activation\n+from ..layers import AveragePooling2D\n+from ..layers import BatchNormalization\n+from ..layers import Concatenate\n+from ..layers import Conv2D\n+from ..layers import Dense\n+from ..layers import GlobalAveragePooling2D\n+from ..layers import GlobalMaxPooling2D\n+from ..layers import Input\n+from ..layers import Lambda\n+from ..layers import MaxPooling2D\n+from ..utils.data_utils import get_file\n+from ..engine.topology import get_source_inputs\n+from ..applications.imagenet_utils import _obtain_input_shape\n+from .. import backend as K\n+\n+\n+BASE_WEIGHT_URL = 'https://github.com/myutwo150/keras-inception-resnet-v2/releases/download/v0.1/'\n+\n+\n+def preprocess_input(x):\n+    \"\"\"Preprocesses a numpy array encoding a batch of images.\n+\n+    This function applies the \"Inception\" preprocessing which converts\n+    the RGB values from [0, 255] to [-1, 1]. Note that this preprocessing\n+    function is different from `imagenet_utils.preprocess_input()`.\n+\n+    # Arguments\n+        x: a 4D numpy array consists of RGB values within [0, 255].\n+\n+    # Returns\n+        Preprocessed array.\n+    \"\"\"\n+    x /= 255.\n+    x -= 0.5\n+    x *= 2.\n+    return x\n+\n+\n+def conv2d_bn(x,\n+              filters,\n+              kernel_size,\n+              strides=1,\n+              padding='same',\n+              activation='relu',\n+              use_bias=False,\n+              name=None):\n+    \"\"\"Utility function to apply conv + BN.\n+\n+    # Arguments\n+        x: input tensor.\n+        filters: filters in `Conv2D`.\n+        kernel_size: kernel size as in `Conv2D`.\n+        padding: padding mode in `Conv2D`.\n+        activation: activation in `Conv2D`.\n+        strides: strides in `Conv2D`.\n+        name: name of the ops; will become `name + '_ac'` for the activation\n+            and `name + '_bn'` for the batch norm layer.\n+\n+    # Returns\n+        Output tensor after applying `Conv2D` and `BatchNormalization`.\n+    \"\"\"\n+    x = Conv2D(filters,\n+               kernel_size,\n+               strides=strides,\n+               padding=padding,\n+               use_bias=use_bias,\n+               name=name)(x)\n+    if not use_bias:\n+        bn_axis = 1 if K.image_data_format() == 'channels_first' else 3\n+        bn_name = None if name is None else name + '_bn'\n+        x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n+    if activation is not None:\n+        ac_name = None if name is None else name + '_ac'\n+        x = Activation(activation, name=ac_name)(x)\n+    return x\n+\n+\n+def inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n+    \"\"\"Adds a Inception-ResNet block.\n+\n+    This function builds 3 types of Inception-ResNet blocks mentioned\n+    in the paper, controlled by the `block_type` argument (which is the\n+    block name used in the official TF-slim implementation):\n+        - Inception-ResNet-A: `block_type='block35'`\n+        - Inception-ResNet-B: `block_type='block17'`\n+        - Inception-ResNet-C: `block_type='block8'`\n+\n+    # Arguments\n+        x: input tensor.\n+        scale: scaling factor to scale the residuals (i.e., the output of\n+            passing `x` through an inception module) before adding them\n+            to the shortcut branch. Let `r` be the output from the residual branch,\n+            the output of this block will be `x + scale * r`.\n+        block_type: `'block35'`, `'block17'` or `'block8'`, determines\n+            the network structure in the residual branch.\n+        block_idx: an `int` used for generating layer names. The Inception-ResNet blocks\n+            are repeated many times in this network. We use `block_idx` to identify\n+            each of the repetitions. For example, the first Inception-ResNet-A block\n+            will have `block_type='block35', block_idx=0`, ane the layer names will have\n+            a common prefix `'block35_0'`.\n+        activation: activation function to use at the end of the block\n+            (see [activations](../activations.md)).\n+            When `activation=None`, no activation is applied\n+            (i.e., \"linear\" activation: `a(x) = x`).\n+\n+    # Returns\n+        Output tensor for the block.\n+\n+    # Raises\n+        ValueError: if `block_type` is not one of `'block35'`,\n+            `'block17'` or `'block8'`.\n+    \"\"\"\n+    if block_type == 'block35':\n+        branch_0 = conv2d_bn(x, 32, 1)\n+        branch_1 = conv2d_bn(x, 32, 1)\n+        branch_1 = conv2d_bn(branch_1, 32, 3)\n+        branch_2 = conv2d_bn(x, 32, 1)\n+        branch_2 = conv2d_bn(branch_2, 48, 3)\n+        branch_2 = conv2d_bn(branch_2, 64, 3)\n+        branches = [branch_0, branch_1, branch_2]\n+    elif block_type == 'block17':\n+        branch_0 = conv2d_bn(x, 192, 1)\n+        branch_1 = conv2d_bn(x, 128, 1)\n+        branch_1 = conv2d_bn(branch_1, 160, [1, 7])\n+        branch_1 = conv2d_bn(branch_1, 192, [7, 1])\n+        branches = [branch_0, branch_1]\n+    elif block_type == 'block8':\n+        branch_0 = conv2d_bn(x, 192, 1)\n+        branch_1 = conv2d_bn(x, 192, 1)\n+        branch_1 = conv2d_bn(branch_1, 224, [1, 3])\n+        branch_1 = conv2d_bn(branch_1, 256, [3, 1])\n+        branches = [branch_0, branch_1]\n+    else:\n+        raise ValueError('Unknown Inception-ResNet block type. '\n+                         'Expects \"block35\", \"block17\" or \"block8\", '\n+                         'but got: ' + str(block_type))\n+\n+    block_name = block_type + '_' + str(block_idx)\n+    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n+    mixed = Concatenate(axis=channel_axis, name=block_name + '_mixed')(branches)\n+    up = conv2d_bn(mixed,\n+                   K.int_shape(x)[channel_axis],\n+                   1,\n+                   activation=None,\n+                   use_bias=True,\n+                   name=block_name + '_conv')\n+\n+    x = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n+               output_shape=K.int_shape(x)[1:],\n+               arguments={'scale': scale},\n+               name=block_name)([x, up])\n+    if activation is not None:\n+        x = Activation(activation, name=block_name + '_ac')(x)\n+    return x\n+\n+\n+def InceptionResNetV2(include_top=True,\n+                      weights='imagenet',\n+                      input_tensor=None,\n+                      input_shape=None,\n+                      pooling=None,\n+                      classes=1000):\n+    \"\"\"Instantiates the Inception-ResNet v2 architecture.\n+\n+    Optionally loads weights pre-trained on ImageNet.\n+    Note that when using TensorFlow, for best performance you should\n+    set `\"image_data_format\": \"channels_last\"` in your Keras config\n+    at `~/.keras/keras.json`.\n+\n+    The model and the weights are compatible with both TensorFlow and Theano\n+    backends (but not CNTK). The data format convention used by the model is\n+    the one specified in your Keras config file.\n+\n+    Note that the default input image size for this model is 299x299, instead\n+    of 224x224 as in the VGG16 and ResNet models. Also, the input preprocessing\n+    function is different (i.e., do not use `imagenet_utils.preprocess_input()`\n+    with this model. Use `preprocess_input()` defined in this module instead).\n+\n+    # Arguments\n+        include_top: whether to include the fully-connected\n+            layer at the top of the network.\n+        weights: one of `None` (random initialization)\n+            or `'imagenet'` (pre-training on ImageNet).\n+        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n+            to use as image input for the model.\n+        input_shape: optional shape tuple, only to be specified\n+            if `include_top` is `False` (otherwise the input shape\n+            has to be `(299, 299, 3)` (with `'channels_last'` data format)\n+            or `(3, 299, 299)` (with `'channels_first'` data format).\n+            It should have exactly 3 inputs channels,\n+            and width and height should be no smaller than 139.\n+            E.g. `(150, 150, 3)` would be one valid value.\n+        pooling: Optional pooling mode for feature extraction\n+            when `include_top` is `False`.\n+            - `None` means that the output of the model will be\n+                the 4D tensor output of the last convolutional layer.\n+            - `'avg'` means that global average pooling\n+                will be applied to the output of the\n+                last convolutional layer, and thus\n+                the output of the model will be a 2D tensor.\n+            - `'max'` means that global max pooling will be applied.\n+        classes: optional number of classes to classify images\n+            into, only to be specified if `include_top` is `True`, and\n+            if no `weights` argument is specified.\n+\n+    # Returns\n+        A Keras `Model` instance.\n+\n+    # Raises\n+        ValueError: in case of invalid argument for `weights`,\n+            or invalid input shape.\n+        RuntimeError: If attempting to run this model with an unsupported backend.\n+    \"\"\"\n+    if K.backend() in {'cntk'}:\n+        raise RuntimeError(K.backend() + ' backend is currently unsupported for this model.')\n+\n+    if weights not in {'imagenet', None}:\n+        raise ValueError('The `weights` argument should be either '\n+                         '`None` (random initialization) or `imagenet` '\n+                         '(pre-training on ImageNet).')\n+\n+    if weights == 'imagenet' and include_top and classes != 1000:\n+        raise ValueError('If using `weights` as imagenet with `include_top`'\n+                         ' as true, `classes` should be 1000')\n+\n+    # Determine proper input shape\n+    input_shape = _obtain_input_shape(\n+        input_shape,\n+        default_size=299,\n+        min_size=139,\n+        data_format=K.image_data_format(),\n+        require_flatten=False,\n+        weights=weights)\n+\n+    if input_tensor is None:\n+        img_input = Input(shape=input_shape)\n+    else:\n+        if not K.is_keras_tensor(input_tensor):\n+            img_input = Input(tensor=input_tensor, shape=input_shape)\n+        else:\n+            img_input = input_tensor\n+\n+    # Stem block: 35 x 35 x 192\n+    x = conv2d_bn(img_input, 32, 3, strides=2, padding='valid')\n+    x = conv2d_bn(x, 32, 3, padding='valid')\n+    x = conv2d_bn(x, 64, 3)\n+    x = MaxPooling2D(3, strides=2)(x)\n+    x = conv2d_bn(x, 80, 1, padding='valid')\n+    x = conv2d_bn(x, 192, 3, padding='valid')\n+    x = MaxPooling2D(3, strides=2)(x)\n+\n+    # Mixed 5b (Inception-A block): 35 x 35 x 320\n+    branch_0 = conv2d_bn(x, 96, 1)\n+    branch_1 = conv2d_bn(x, 48, 1)\n+    branch_1 = conv2d_bn(branch_1, 64, 5)\n+    branch_2 = conv2d_bn(x, 64, 1)\n+    branch_2 = conv2d_bn(branch_2, 96, 3)\n+    branch_2 = conv2d_bn(branch_2, 96, 3)\n+    branch_pool = AveragePooling2D(3, strides=1, padding='same')(x)\n+    branch_pool = conv2d_bn(branch_pool, 64, 1)\n+    branches = [branch_0, branch_1, branch_2, branch_pool]\n+    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n+    x = Concatenate(axis=channel_axis, name='mixed_5b')(branches)\n+\n+    # 10x block35 (Inception-ResNet-A block): 35 x 35 x 320\n+    for block_idx in range(1, 11):\n+        x = inception_resnet_block(x,\n+                                   scale=0.17,\n+                                   block_type='block35',\n+                                   block_idx=block_idx)\n+\n+    # Mixed 6a (Reduction-A block): 17 x 17 x 1088\n+    branch_0 = conv2d_bn(x, 384, 3, strides=2, padding='valid')\n+    branch_1 = conv2d_bn(x, 256, 1)\n+    branch_1 = conv2d_bn(branch_1, 256, 3)\n+    branch_1 = conv2d_bn(branch_1, 384, 3, strides=2, padding='valid')\n+    branch_pool = MaxPooling2D(3, strides=2, padding='valid')(x)\n+    branches = [branch_0, branch_1, branch_pool]\n+    x = Concatenate(axis=channel_axis, name='mixed_6a')(branches)\n+\n+    # 20x block17 (Inception-ResNet-B block): 17 x 17 x 1088\n+    for block_idx in range(1, 21):\n+        x = inception_resnet_block(x,\n+                                   scale=0.1,\n+                                   block_type='block17',\n+                                   block_idx=block_idx)\n+\n+    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n+    branch_0 = conv2d_bn(x, 256, 1)\n+    branch_0 = conv2d_bn(branch_0, 384, 3, strides=2, padding='valid')\n+    branch_1 = conv2d_bn(x, 256, 1)\n+    branch_1 = conv2d_bn(branch_1, 288, 3, strides=2, padding='valid')\n+    branch_2 = conv2d_bn(x, 256, 1)\n+    branch_2 = conv2d_bn(branch_2, 288, 3)\n+    branch_2 = conv2d_bn(branch_2, 320, 3, strides=2, padding='valid')\n+    branch_pool = MaxPooling2D(3, strides=2, padding='valid')(x)\n+    branches = [branch_0, branch_1, branch_2, branch_pool]\n+    x = Concatenate(axis=channel_axis, name='mixed_7a')(branches)\n+\n+    # 10x block8 (Inception-ResNet-C block): 8 x 8 x 2080\n+    for block_idx in range(1, 10):\n+        x = inception_resnet_block(x,\n+                                   scale=0.2,\n+                                   block_type='block8',\n+                                   block_idx=block_idx)\n+    x = inception_resnet_block(x,\n+                               scale=1.,\n+                               activation=None,\n+                               block_type='block8',\n+                               block_idx=10)\n+\n+    # Final convolution block: 8 x 8 x 1536\n+    x = conv2d_bn(x, 1536, 1, name='conv_7b')\n+\n+    if include_top:\n+        # Classification block\n+        x = GlobalAveragePooling2D(name='avg_pool')(x)\n+        x = Dense(classes, activation='softmax', name='predictions')(x)\n+    else:\n+        if pooling == 'avg':\n+            x = GlobalAveragePooling2D()(x)\n+        elif pooling == 'max':\n+            x = GlobalMaxPooling2D()(x)\n+\n+    # Ensure that the model takes into account\n+    # any potential predecessors of `input_tensor`\n+    if input_tensor is not None:\n+        inputs = get_source_inputs(input_tensor)\n+    else:\n+        inputs = img_input\n+\n+    # Create model\n+    model = Model(inputs, x, name='inception_resnet_v2')\n+\n+    # Load weights\n+    if weights == 'imagenet':\n+        if K.image_data_format() == 'channels_first':\n+            if K.backend() == 'tensorflow':\n+                warnings.warn('You are using the TensorFlow backend, yet you '\n+                              'are using the Theano '\n+                              'image data format convention '\n+                              '(`image_data_format=\"channels_first\"`). '\n+                              'For best performance, set '\n+                              '`image_data_format=\"channels_last\"` in '\n+                              'your Keras config '\n+                              'at ~/.keras/keras.json.')\n+        if include_top:\n+            weights_filename = 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5'\n+            weights_path = get_file(weights_filename,\n+                                    BASE_WEIGHT_URL + weights_filename,\n+                                    cache_subdir='models',\n+                                    md5_hash='e693bd0210a403b3192acc6073ad2e96')\n+        else:\n+            weights_filename = 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n+            weights_path = get_file(weights_filename,\n+                                    BASE_WEIGHT_URL + weights_filename,\n+                                    cache_subdir='models',\n+                                    md5_hash='d19885ff4a710c122648d3b5c3b684e4')\n+        model.load_weights(weights_path)\n+\n+    return model\n\n@@ -234,6 +234,64 @@ def test_inceptionv3_variable_input_channels():\n     assert model.output_shape == (None, None, None, 2048)\n \n \n+@keras_test\n+@pytest.mark.skipif((K.backend() == 'cntk'),\n+                    reason='InceptionResNetV2 is not supported on CNTK')\n+def test_inceptionresnetv2():\n+    model = applications.InceptionResNetV2(weights=None)\n+    assert model.output_shape == (None, 1000)\n+\n+\n+@keras_test\n+@pytest.mark.skipif((K.backend() == 'cntk'),\n+                    reason='InceptionResNetV2 is not supported on CNTK')\n+def test_inceptionresnetv2_notop():\n+    global_image_data_format = K.image_data_format()\n+\n+    K.set_image_data_format('channels_first')\n+    model = applications.InceptionResNetV2(weights=None, include_top=False)\n+    assert model.output_shape == (None, 1536, None, None)\n+\n+    K.set_image_data_format('channels_last')\n+    model = applications.InceptionResNetV2(weights=None, include_top=False)\n+    assert model.output_shape == (None, None, None, 1536)\n+\n+    K.set_image_data_format(global_image_data_format)\n+\n+\n+@keras_test\n+@pytest.mark.skipif((K.backend() == 'cntk'),\n+                    reason='InceptionResNetV2 is not supported on CNTK')\n+def test_inceptionresnetv2_pooling():\n+    model = applications.InceptionResNetV2(weights=None, include_top=False, pooling='avg')\n+    assert model.output_shape == (None, 1536)\n+\n+\n+@keras_test\n+@pytest.mark.skipif((K.backend() == 'cntk'),\n+                    reason='InceptionResNetV2 is not supported on CNTK')\n+def test_inceptionresnetv2_variable_input_channels():\n+    global_image_data_format = K.image_data_format()\n+\n+    K.set_image_data_format('channels_first')\n+    input_shape = (1, None, None)\n+    model = applications.InceptionResNetV2(weights=None, include_top=False, input_shape=input_shape)\n+    assert model.output_shape == (None, 1536, None, None)\n+    input_shape = (4, None, None)\n+    model = applications.InceptionResNetV2(weights=None, include_top=False, input_shape=input_shape)\n+    assert model.output_shape == (None, 1536, None, None)\n+\n+    K.set_image_data_format('channels_last')\n+    input_shape = (None, None, 1)\n+    model = applications.InceptionResNetV2(weights=None, include_top=False, input_shape=input_shape)\n+    assert model.output_shape == (None, None, None, 1536)\n+    input_shape = (None, None, 4)\n+    model = applications.InceptionResNetV2(weights=None, include_top=False, input_shape=input_shape)\n+    assert model.output_shape == (None, None, None, 1536)\n+\n+    K.set_image_data_format(global_image_data_format)\n+\n+\n @keras_test\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n                     reason='MobileNets are supported only on TensorFlow')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
