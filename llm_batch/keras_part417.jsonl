{"custom_id": "keras#1cd4ace744345398ac3e6cc6cb3207be28614a95", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 7450 | Contributors (this commit): 103 | Commits (past 90d): 14 | Contributors (cumulative): 103 | DMM Complexity: None\n\nDIFF:\n@@ -1640,8 +1640,7 @@ class BackupAndRestore(Callback):\n   ...   def on_epoch_begin(self, epoch, logs=None):\n   ...     if epoch == 4:\n   ...       raise RuntimeError('Interrupting!')\n-  >>> callback = tf.keras.callbacks.experimental.BackupAndRestore(\n-  ... backup_dir=\"/tmp/backup\")\n+  >>> callback = tf.keras.callbacks.BackupAndRestore(backup_dir=\"/tmp/backup\")\n   >>> model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])\n   >>> model.compile(tf.keras.optimizers.SGD(), loss='mse')\n   >>> try:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#957a6214f450bc2d71ab2353bb156ed621acbde8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 22 | Churn Cumulative: 4173 | Contributors (this commit): 9 | Commits (past 90d): 14 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -318,6 +318,18 @@ class LossScaleOptimizerMetaclass(type):\n     elif isinstance(inner_optimizer, optimizer_experimental.Optimizer):\n       return LossScaleOptimizerV3(inner_optimizer, *args, **kwargs)\n \n+    # Raise TypeError because inner_optimizer is not an optimizer\n+    msg = (f'\"inner_optimizer\" must be an instance of '\n+           f'`tf.keras.optimizers.Optimizer` or '\n+           f'`tf.keras.optimizers.experimental.Optimizer`, but got: '\n+           f'{inner_optimizer}.')\n+    if isinstance(inner_optimizer, legacy_optimizer.OptimizerV2):\n+      msg += (' Please make sure \"inner_optimizer\" is not an instance of '\n+              '`tensorflow.python.keras.optimizers`, which is '\n+              'the legacy keras code and will be removed in future release. '\n+              'Please use the tf.keras public API instead.')\n+    raise TypeError(msg)\n+\n \n # TODO(b/215389169): Delete this class after `OptimizerV2` is deprecated.\n # pylint: disable=g-classes-have-attributes\n\n@@ -1294,11 +1294,19 @@ class LossScaleOptimizerTest(tf.test.TestCase, parameterized.TestCase):\n         '\"inner_optimizer\" is already wrapped by a LossScaleOptimizer.'):\n       create_lso(inner_opt)\n \n+  def testErrorWhenWrappingNonOptimizer(self):\n+    with self.assertRaisesRegex(\n+        TypeError,\n+        '\"inner_optimizer\" must be an instance of '\n+        '`tf.keras.optimizers.Optimizer` or '\n+        '`tf.keras.optimizers.experimental.Optimizer`, but got: 1'):\n+      loss_scale_optimizer.BaseLossScaleOptimizer(1)\n+\n   def testErrorWhenWrappingLegacyKerasOptimizers(self):\n     sgd = legacy_sgd.SGD()\n     with self.assertRaisesRegex(\n         TypeError, 'not an instance of `tensorflow.python.keras.optimizers`'):\n-      loss_scale_optimizer.LossScaleOptimizer(sgd)\n+      loss_scale_optimizer.BaseLossScaleOptimizer(sgd)\n \n   def testErrorWhenV3LsoWrapsV2Optimizer(self):\n     sgd = gradient_descent.SGD()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0bed8144b12fa0e2dff16309f19e541358391a1d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 599 | Contributors (this commit): 8 | Commits (past 90d): 6 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -108,7 +108,8 @@ def image_dataset_from_directory(directory,\n     seed: Optional random seed for shuffling and transformations.\n     validation_split: Optional float between 0 and 1,\n         fraction of data to reserve for validation.\n-    subset: One of \"training\" or \"validation\".\n+    subset: Subset of the data to return.\n+        One of \"training\" or \"validation\".\n         Only used if `validation_split` is set.\n     interpolation: String, the interpolation method used when resizing images.\n       Defaults to `bilinear`. Supports `bilinear`, `nearest`, `bicubic`,\n\n@@ -92,7 +92,8 @@ def text_dataset_from_directory(directory,\n     seed: Optional random seed for shuffling and transformations.\n     validation_split: Optional float between 0 and 1,\n         fraction of data to reserve for validation.\n-    subset: One of \"training\" or \"validation\".\n+    subset: Subset of the data to return.\n+        One of \"training\" or \"validation\".\n         Only used if `validation_split` is set.\n     follow_links: Whether to visits subdirectories pointed to by symlinks.\n         Defaults to False.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cb736ae293be4ee6cdadc1d2c6335277925d6f9f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 885 | Contributors (this commit): 8 | Commits (past 90d): 3 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -111,9 +111,10 @@ def remove_squeezable_dimensions(\n     Tuple of `labels` and `predictions`, possibly with last dim squeezed.\n   \"\"\"\n   with backend.name_scope(name or 'remove_squeezable_dimensions'):\n-    if not isinstance(predictions, tf.RaggedTensor):\n+    # tf.is_tensor returns True if predictions is a tensor or composite tensor.\n+    if not tf.is_tensor(predictions):\n       predictions = tf.convert_to_tensor(predictions)\n-    if not isinstance(labels, tf.RaggedTensor):\n+    if not tf.is_tensor(labels):\n       labels = tf.convert_to_tensor(labels)\n     predictions_shape = predictions.shape\n     predictions_rank = predictions_shape.ndims\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#373ad97c72ed1ac4b6898e85b2cfd7b016e4b469", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3946 | Lines Deleted: 394 | Files Changed: 2 | Hunks: 133 | Methods Changed: 110 | Complexity Δ (Sum/Max): 384/261 | Churn Δ: 4340 | Churn Cumulative: 13839 | Contributors (this commit): 65 | Commits (past 90d): 4 | Contributors (cumulative): 69 | DMM Complexity: 0.5897029702970297\n\nDIFF:\n@@ -15,33 +15,47 @@\n # pylint: disable=invalid-name\n # pylint: disable=g-import-not-at-top\n # pylint: disable=g-classes-have-attributes\n+# pylint: disable=g-direct-tensorflow-import\n \"\"\"Set of tools for real-time data augmentation on image data.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n+import collections\n+import io\n+import multiprocessing\n+import os\n+import pathlib\n+import threading\n+import warnings\n \n-from keras_preprocessing import image\n+from keras import backend\n+from keras.preprocessing.image_dataset import image_dataset_from_directory  # pylint: disable=unused-import\n+from keras.utils import data_utils\n import numpy as np\n+import tensorflow.compat.v2 as tf\n+from tensorflow.python.util.tf_export import keras_export\n+\n try:\n+  import scipy\n   from scipy import linalg  # pylint: disable=unused-import\n   from scipy import ndimage  # pylint: disable=unused-import\n except ImportError:\n   pass\n-from keras import backend\n-from keras.preprocessing.image_dataset import image_dataset_from_directory  # pylint: disable=unused-import\n-from keras.utils import data_utils\n-from keras.utils import tf_inspect\n-from tensorflow.python.platform import tf_logging\n-from tensorflow.python.util.tf_export import keras_export\n+try:\n+  from PIL import Image as pil_image\n+  from PIL import ImageEnhance\n+except ImportError:\n+  pil_image = None\n+  ImageEnhance = None\n \n-random_rotation = image.random_rotation\n-random_shift = image.random_shift\n-random_shear = image.random_shear\n-random_zoom = image.random_zoom\n-apply_channel_shift = image.apply_channel_shift\n-random_channel_shift = image.random_channel_shift\n-apply_brightness_shift = image.apply_brightness_shift\n-random_brightness = image.random_brightness\n-apply_affine_transform = image.apply_affine_transform\n+\n+if pil_image is not None:\n+  _PIL_INTERPOLATION_METHODS = {\n+      'nearest': pil_image.NEAREST,\n+      'bilinear': pil_image.BILINEAR,\n+      'bicubic': pil_image.BICUBIC,\n+      'hamming': pil_image.HAMMING,\n+      'box': pil_image.BOX,\n+      'lanczos': pil_image.LANCZOS,\n+  }\n \n \n @keras_export('keras.preprocessing.image.smart_resize', v1=[])\n@@ -89,13 +103,13 @@ def smart_resize(x, size, interpolation='bilinear'):\n   we resize the `(340, 340)` crop to `(200, 200)`.\n \n   Args:\n-    x: Input image or batch of images (as a tensor or NumPy array).\n-      Must be in format `(height, width, channels)` or\n-      `(batch_size, height, width, channels)`.\n+    x: Input image or batch of images (as a tensor or NumPy array). Must be in\n+      format `(height, width, channels)` or `(batch_size, height, width,\n+      channels)`.\n     size: Tuple of `(height, width)` integer. Target size.\n-    interpolation: String, interpolation to use for resizing.\n-      Defaults to `'bilinear'`. Supports `bilinear`, `nearest`, `bicubic`,\n-      `area`, `lanczos3`, `lanczos5`, `gaussian`, `mitchellcubic`.\n+    interpolation: String, interpolation to use for resizing. Defaults to\n+      `'bilinear'`. Supports `bilinear`, `nearest`, `bicubic`, `area`,\n+      `lanczos3`, `lanczos5`, `gaussian`, `mitchellcubic`.\n \n   Returns:\n     Array with shape `(size[0], size[1], channels)`. If the input image was a\n@@ -131,8 +145,7 @@ def smart_resize(x, size, interpolation='bilinear'):\n \n   crop_box_hstart = tf.cast(\n       tf.cast(height - crop_height, 'float32') / 2, 'int32')\n-  crop_box_wstart = tf.cast(\n-      tf.cast(width - crop_width, 'float32') / 2, 'int32')\n+  crop_box_wstart = tf.cast(tf.cast(width - crop_width, 'float32') / 2, 'int32')\n \n   if img.shape.rank == 4:\n     crop_box_start = tf.stack([0, crop_box_hstart, crop_box_wstart, 0])\n@@ -142,10 +155,7 @@ def smart_resize(x, size, interpolation='bilinear'):\n     crop_box_size = tf.stack([crop_height, crop_width, -1])\n \n   img = tf.slice(img, crop_box_start, crop_box_size)\n-  img = tf.image.resize(\n-      images=img,\n-      size=size,\n-      method=interpolation)\n+  img = tf.image.resize(images=img, size=size, method=interpolation)\n   # Apparent bug in resize_images_v2 may cause shape to be lost\n   if img.shape.rank is not None:\n     if img.shape.rank == 4:\n@@ -193,12 +203,44 @@ def array_to_img(x, data_format=None, scale=True, dtype=None):\n \n   if data_format is None:\n     data_format = backend.image_data_format()\n-  kwargs = {}\n-  if 'dtype' in tf_inspect.getfullargspec(image.array_to_img)[0]:\n   if dtype is None:\n     dtype = backend.floatx()\n-    kwargs['dtype'] = dtype\n-  return image.array_to_img(x, data_format=data_format, scale=scale, **kwargs)\n+  if pil_image is None:\n+    raise ImportError('Could not import PIL.Image. '\n+                      'The use of `array_to_img` requires PIL.')\n+  x = np.asarray(x, dtype=dtype)\n+  if x.ndim != 3:\n+    raise ValueError('Expected image array to have rank 3 (single image). '\n+                     f'Got array with shape: {x.shape}')\n+\n+  if data_format not in {'channels_first', 'channels_last'}:\n+    raise ValueError(f'Invalid data_format: {data_format}')\n+\n+  # Original Numpy array x has format (height, width, channel)\n+  # or (channel, height, width)\n+  # but target PIL image has format (width, height, channel)\n+  if data_format == 'channels_first':\n+    x = x.transpose(1, 2, 0)\n+  if scale:\n+    x = x - np.min(x)\n+    x_max = np.max(x)\n+    if x_max != 0:\n+      x /= x_max\n+    x *= 255\n+  if x.shape[2] == 4:\n+    # RGBA\n+    return pil_image.fromarray(x.astype('uint8'), 'RGBA')\n+  elif x.shape[2] == 3:\n+    # RGB\n+    return pil_image.fromarray(x.astype('uint8'), 'RGB')\n+  elif x.shape[2] == 1:\n+    # grayscale\n+    if np.max(x) > 255:\n+      # 32-bit signed integer grayscale image. PIL mode \"I\"\n+      return pil_image.fromarray(x[:, :, 0].astype('int32'), 'I')\n+    return pil_image.fromarray(x[:, :, 0].astype('uint8'), 'L')\n+  else:\n+    raise ValueError(f'Unsupported channel number: {x.shape[2]}')\n \n \n @keras_export('keras.utils.img_to_array',\n@@ -235,49 +277,59 @@ def img_to_array(img, data_format=None, dtype=None):\n \n   if data_format is None:\n     data_format = backend.image_data_format()\n-  kwargs = {}\n-  if 'dtype' in tf_inspect.getfullargspec(image.img_to_array)[0]:\n   if dtype is None:\n     dtype = backend.floatx()\n-    kwargs['dtype'] = dtype\n-  return image.img_to_array(img, data_format=data_format, **kwargs)\n+  if data_format not in {'channels_first', 'channels_last'}:\n+    raise ValueError(f'Unknown data_format: {data_format}')\n+  # Numpy array x has format (height, width, channel)\n+  # or (channel, height, width)\n+  # but original PIL image has format (width, height, channel)\n+  x = np.asarray(img, dtype=dtype)\n+  if len(x.shape) == 3:\n+    if data_format == 'channels_first':\n+      x = x.transpose(2, 0, 1)\n+  elif len(x.shape) == 2:\n+    if data_format == 'channels_first':\n+      x = x.reshape((1, x.shape[0], x.shape[1]))\n+    else:\n+      x = x.reshape((x.shape[0], x.shape[1], 1))\n+  else:\n+    raise ValueError(f'Unsupported image shape: {x.shape}')\n+  return x\n \n \n-@keras_export('keras.utils.save_img',\n-              'keras.preprocessing.image.save_img')\n-def save_img(path,\n-             x,\n-             data_format=None,\n-             file_format=None,\n-             scale=True,\n-             **kwargs):\n+@keras_export('keras.utils.save_img', 'keras.preprocessing.image.save_img')\n+def save_img(path, x, data_format=None, file_format=None, scale=True, **kwargs):\n   \"\"\"Saves an image stored as a Numpy array to a path or file object.\n \n   Args:\n       path: Path or file object.\n       x: Numpy array.\n-      data_format: Image data format,\n-          either \"channels_first\" or \"channels_last\".\n-      file_format: Optional file format override. If omitted, the\n-          format to use is determined from the filename extension.\n-          If a file object was used instead of a filename, this\n-          parameter should always be used.\n+      data_format: Image data format, either \"channels_first\" or\n+        \"channels_last\".\n+      file_format: Optional file format override. If omitted, the format to use\n+        is determined from the filename extension. If a file object was used\n+        instead of a filename, this parameter should always be used.\n       scale: Whether to rescale image values to be within `[0, 255]`.\n       **kwargs: Additional keyword arguments passed to `PIL.Image.save()`.\n   \"\"\"\n   if data_format is None:\n     data_format = backend.image_data_format()\n-  image.save_img(path,\n-                 x,\n-                 data_format=data_format,\n-                 file_format=file_format,\n-                 scale=scale, **kwargs)\n+  img = array_to_img(x, data_format=data_format, scale=scale)\n+  if img.mode == 'RGBA' and (file_format == 'jpg' or file_format == 'jpeg'):\n+    warnings.warn('The JPG format does not support '\n+                  'RGBA images, converting to RGB.')\n+    img = img.convert('RGB')\n+  img.save(path, format=file_format, **kwargs)\n \n \n-@keras_export('keras.utils.load_img',\n-              'keras.preprocessing.image.load_img')\n-def load_img(path, grayscale=False, color_mode='rgb', target_size=None,\n-             interpolation='nearest'):\n+@keras_export('keras.utils.load_img', 'keras.preprocessing.image.load_img')\n+def load_img(path,\n+             grayscale=False,\n+             color_mode='rgb',\n+             target_size=None,\n+             interpolation='nearest',\n+             keep_aspect_ratio=False):\n   \"\"\"Loads an image into PIL format.\n \n   Usage:\n@@ -292,16 +344,19 @@ def load_img(path, grayscale=False, color_mode='rgb', target_size=None,\n   Args:\n       path: Path to image file.\n       grayscale: DEPRECATED use `color_mode=\"grayscale\"`.\n-      color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n-          The desired image format.\n-      target_size: Either `None` (default to original size)\n-          or tuple of ints `(img_height, img_width)`.\n+      color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\". The desired\n+        image format.\n+      target_size: Either `None` (default to original size) or tuple of ints\n+        `(img_height, img_width)`.\n       interpolation: Interpolation method used to resample the image if the\n-          target size is different from that of the loaded image.\n-          Supported methods are \"nearest\", \"bilinear\", and \"bicubic\".\n-          If PIL version 1.1.3 or newer is installed, \"lanczos\" is also\n-          supported. If PIL version 3.4.0 or newer is installed, \"box\" and\n-          \"hamming\" are also supported. By default, \"nearest\" is used.\n+        target size is different from that of the loaded image. Supported\n+        methods are \"nearest\", \"bilinear\", and \"bicubic\". If PIL version 1.1.3\n+        or newer is installed, \"lanczos\" is also supported. If PIL version 3.4.0\n+        or newer is installed, \"box\" and \"hamming\" are also supported. By\n+        default, \"nearest\" is used.\n+      keep_aspect_ratio: Boolean, whether to resize images to a target\n+              size without aspect ratio distortion. The image is cropped in\n+              the center with target aspect ratio before resizing.\n \n   Returns:\n       A PIL Image instance.\n@@ -310,43 +365,267 @@ def load_img(path, grayscale=False, color_mode='rgb', target_size=None,\n       ImportError: if PIL is not available.\n       ValueError: if interpolation method is not supported.\n   \"\"\"\n-  return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n-                        target_size=target_size, interpolation=interpolation)\n+  if grayscale:\n+    warnings.warn('grayscale is deprecated. Please use '\n+                  'color_mode = \"grayscale\"')\n+    color_mode = 'grayscale'\n+  if pil_image is None:\n+    raise ImportError('Could not import PIL.Image. '\n+                      'The use of `load_img` requires PIL.')\n+  if isinstance(path, io.BytesIO):\n+    img = pil_image.open(path)\n+  elif isinstance(path, (pathlib.Path, bytes, str)):\n+    if isinstance(path, pathlib.Path):\n+      path = str(path.resolve())\n+    with open(path, 'rb') as f:\n+      img = pil_image.open(io.BytesIO(f.read()))\n+  else:\n+    raise TypeError('path should be path-like or io.BytesIO'\n+                    ', not {}'.format(type(path)))\n+\n+  if color_mode == 'grayscale':\n+    # if image is not already an 8-bit, 16-bit or 32-bit grayscale image\n+    # convert it to an 8-bit grayscale image.\n+    if img.mode not in ('L', 'I;16', 'I'):\n+      img = img.convert('L')\n+  elif color_mode == 'rgba':\n+    if img.mode != 'RGBA':\n+      img = img.convert('RGBA')\n+  elif color_mode == 'rgb':\n+    if img.mode != 'RGB':\n+      img = img.convert('RGB')\n+  else:\n+    raise ValueError('color_mode must be \"grayscale\", \"rgb\", or \"rgba\"')\n+  if target_size is not None:\n+    width_height_tuple = (target_size[1], target_size[0])\n+    if img.size != width_height_tuple:\n+      if interpolation not in _PIL_INTERPOLATION_METHODS:\n+        raise ValueError('Invalid interpolation method {} specified. Supported '\n+                         'methods are {}'.format(\n+                             interpolation,\n+                             ', '.join(_PIL_INTERPOLATION_METHODS.keys())))\n+      resample = _PIL_INTERPOLATION_METHODS[interpolation]\n+\n+      if keep_aspect_ratio:\n+        width, height = img.size\n+        target_width, target_height = width_height_tuple\n+\n+        crop_height = (width * target_height) // target_width\n+        crop_width = (height * target_width) // target_height\n+\n+        # Set back to input height / width\n+        # if crop_height / crop_width is not smaller.\n+        crop_height = min(height, crop_height)\n+        crop_width = min(width, crop_width)\n+\n+        crop_box_hstart = (height - crop_height) // 2\n+        crop_box_wstart = (width - crop_width) // 2\n+        crop_box_wend = crop_box_wstart + crop_width\n+        crop_box_hend = crop_box_hstart + crop_height\n+        crop_box = [\n+            crop_box_wstart, crop_box_hstart, crop_box_wend, crop_box_hend\n+        ]\n+        img = img.resize(width_height_tuple, resample, box=crop_box)\n+      else:\n+        img = img.resize(width_height_tuple, resample)\n+  return img\n \n \n @keras_export('keras.preprocessing.image.Iterator')\n-class Iterator(image.Iterator, data_utils.Sequence):\n-  pass\n+class Iterator(data_utils.Sequence):\n+  \"\"\"Base class for image data iterators.\n \n-\n-@keras_export('keras.preprocessing.image.DirectoryIterator')\n-class DirectoryIterator(image.DirectoryIterator, Iterator):  # pylint: disable=inconsistent-mro\n-  \"\"\"Iterator capable of reading images from a directory on disk.\n+  Every `Iterator` must implement the `_get_batches_of_transformed_samples`\n+  method.\n \n   Args:\n-      directory: Path to the directory to read images from.\n-          Each subdirectory in this directory will be\n-          considered to contain images from one class,\n-          or alternatively you could specify class subdirectories\n-          via the `classes` argument.\n-      image_data_generator: Instance of `ImageDataGenerator`\n-          to use for random transformations and normalization.\n-      target_size: tuple of integers, dimensions to resize input images to.\n-      color_mode: One of `\"rgb\"`, `\"rgba\"`, `\"grayscale\"`.\n-          Color mode to read images.\n-      classes: Optional list of strings, names of subdirectories\n-          containing images from each class (e.g. `[\"dogs\", \"cats\"]`).\n-          It will be computed automatically if not set.\n-      class_mode: Mode for yielding the targets:\n-          - `\"binary\"`: binary targets (if there are only two classes),\n-          - `\"categorical\"`: categorical targets,\n-          - `\"sparse\"`: integer targets,\n-          - `\"input\"`: targets are images identical to input images (mainly\n-              used to work with autoencoders),\n-          - `None`: no targets get yielded (only input images are yielded).\n+      n: Integer, total number of samples in the dataset to loop over.\n       batch_size: Integer, size of a batch.\n       shuffle: Boolean, whether to shuffle the data between epochs.\n-      seed: Random seed for data shuffling.\n+      seed: Random seeding for data shuffling.\n+  \"\"\"\n+  white_list_formats = ('png', 'jpg', 'jpeg', 'bmp', 'ppm', 'tif', 'tiff')\n+\n+  def __init__(self, n, batch_size, shuffle, seed):\n+    self.n = n\n+    self.batch_size = batch_size\n+    self.seed = seed\n+    self.shuffle = shuffle\n+    self.batch_index = 0\n+    self.total_batches_seen = 0\n+    self.lock = threading.Lock()\n+    self.index_array = None\n+    self.index_generator = self._flow_index()\n+\n+  def _set_index_array(self):\n+    self.index_array = np.arange(self.n)\n+    if self.shuffle:\n+      self.index_array = np.random.permutation(self.n)\n+\n+  def __getitem__(self, idx):\n+    if idx >= len(self):\n+      raise ValueError('Asked to retrieve element {idx}, '\n+                       'but the Sequence '\n+                       'has length {length}'.format(idx=idx, length=len(self)))\n+    if self.seed is not None:\n+      np.random.seed(self.seed + self.total_batches_seen)\n+    self.total_batches_seen += 1\n+    if self.index_array is None:\n+      self._set_index_array()\n+    index_array = self.index_array[self.batch_size * idx:self.batch_size *\n+                                   (idx + 1)]\n+    return self._get_batches_of_transformed_samples(index_array)\n+\n+  def __len__(self):\n+    return (self.n + self.batch_size - 1) // self.batch_size  # round up\n+\n+  def on_epoch_end(self):\n+    self._set_index_array()\n+\n+  def reset(self):\n+    self.batch_index = 0\n+\n+  def _flow_index(self):\n+    # Ensure self.batch_index is 0.\n+    self.reset()\n+    while 1:\n+      if self.seed is not None:\n+        np.random.seed(self.seed + self.total_batches_seen)\n+      if self.batch_index == 0:\n+        self._set_index_array()\n+\n+      if self.n == 0:\n+        # Avoiding modulo by zero error\n+        current_index = 0\n+      else:\n+        current_index = (self.batch_index * self.batch_size) % self.n\n+      if self.n > current_index + self.batch_size:\n+        self.batch_index += 1\n+      else:\n+        self.batch_index = 0\n+      self.total_batches_seen += 1\n+      yield self.index_array[current_index:current_index + self.batch_size]\n+\n+  def __iter__(self):\n+    # Needed if we want to do something like:\n+    # for x, y in data_gen.flow(...):\n+    return self\n+\n+  def __next__(self, *args, **kwargs):\n+    return self.next(*args, **kwargs)\n+\n+  def next(self):\n+    \"\"\"For python 2.x.\n+\n+    Returns:\n+        The next batch.\n+    \"\"\"\n+    with self.lock:\n+      index_array = next(self.index_generator)\n+    # The transformation of images is not under thread lock\n+    # so it can be done in parallel\n+    return self._get_batches_of_transformed_samples(index_array)\n+\n+  def _get_batches_of_transformed_samples(self, index_array):\n+    \"\"\"Gets a batch of transformed samples.\n+\n+    Args:\n+        index_array: Array of sample indices to include in batch.\n+    Returns:\n+        A batch of transformed samples.\n+    \"\"\"\n+    raise NotImplementedError\n+\n+\n+def _iter_valid_files(directory, white_list_formats, follow_links):\n+  \"\"\"Iterates on files with extension.\n+\n+  Args:\n+      directory: Absolute path to the directory\n+          containing files to be counted\n+      white_list_formats: Set of strings containing allowed extensions for\n+          the files to be counted.\n+      follow_links: Boolean, follow symbolic links to subdirectories.\n+  Yields:\n+      Tuple of (root, filename) with extension in `white_list_formats`.\n+  \"\"\"\n+\n+  def _recursive_list(subpath):\n+    return sorted(\n+        os.walk(subpath, followlinks=follow_links), key=lambda x: x[0])\n+\n+  for root, _, files in _recursive_list(directory):\n+    for fname in sorted(files):\n+      if fname.lower().endswith('.tiff'):\n+        warnings.warn('Using \".tiff\" files with multiple bands '\n+                      'will cause distortion. Please verify your output.')\n+      if fname.lower().endswith(white_list_formats):\n+        yield root, fname\n+\n+\n+def _list_valid_filenames_in_directory(directory, white_list_formats, split,\n+                                       class_indices, follow_links):\n+  \"\"\"Lists paths of files in `subdir` with extensions in `white_list_formats`.\n+\n+  Args:\n+      directory: absolute path to a directory containing the files to list.\n+          The directory name is used as class label\n+          and must be a key of `class_indices`.\n+      white_list_formats: set of strings containing allowed extensions for\n+          the files to be counted.\n+      split: tuple of floats (e.g. `(0.2, 0.6)`) to only take into\n+          account a certain fraction of files in each directory.\n+          E.g.: `segment=(0.6, 1.0)` would only account for last 40 percent\n+          of images in each directory.\n+      class_indices: dictionary mapping a class name to its index.\n+      follow_links: boolean, follow symbolic links to subdirectories.\n+\n+  Returns:\n+       classes: a list of class indices\n+       filenames: the path of valid files in `directory`, relative from\n+           `directory`'s parent (e.g., if `directory` is \"dataset/class1\",\n+          the filenames will be\n+          `[\"class1/file1.jpg\", \"class1/file2.jpg\", ...]`).\n+  \"\"\"\n+  dirname = os.path.basename(directory)\n+  if split:\n+    all_files = list(\n+        _iter_valid_files(directory, white_list_formats, follow_links))\n+    num_files = len(all_files)\n+    start, stop = int(split[0] * num_files), int(split[1] * num_files)\n+    valid_files = all_files[start:stop]\n+  else:\n+    valid_files = _iter_valid_files(directory, white_list_formats, follow_links)\n+  classes = []\n+  filenames = []\n+  for root, fname in valid_files:\n+    classes.append(class_indices[dirname])\n+    absolute_path = os.path.join(root, fname)\n+    relative_path = os.path.join(dirname,\n+                                 os.path.relpath(absolute_path, directory))\n+    filenames.append(relative_path)\n+\n+  return classes, filenames\n+\n+\n+class BatchFromFilesMixin():\n+  \"\"\"Adds methods related to getting batches from filenames.\n+\n+  It includes the logic to transform image files to batches.\n+  \"\"\"\n+\n+  def set_processing_attrs(self, image_data_generator, target_size, color_mode,\n+                           data_format, save_to_dir, save_prefix, save_format,\n+                           subset, interpolation, keep_aspect_ratio):\n+    \"\"\"Sets attributes to use later for processing files into a batch.\n+\n+    Args:\n+        image_data_generator: Instance of `ImageDataGenerator`\n+            to use for random transformations and normalization.\n+        target_size: tuple of integers, dimensions to resize input images\n+        to.\n+        color_mode: One of `\"rgb\"`, `\"rgba\"`, `\"grayscale\"`.\n+            Color mode to read images.\n         data_format: String, one of `channels_first`, `channels_last`.\n         save_to_dir: Optional directory where to save the pictures\n             being yielded, in a viewable format. This is useful\n@@ -364,10 +643,187 @@ class DirectoryIterator(image.DirectoryIterator, Iterator):  # pylint: disable=i\n             If PIL version 1.1.3 or newer is installed, \"lanczos\" is also\n             supported. If PIL version 3.4.0 or newer is installed, \"box\" and\n             \"hamming\" are also supported. By default, \"nearest\" is used.\n+        keep_aspect_ratio: Boolean, whether to resize images to a target size\n+            without aspect ratio distortion. The image is cropped in the center\n+            with target aspect ratio before resizing.\n+    \"\"\"\n+    self.image_data_generator = image_data_generator\n+    self.target_size = tuple(target_size)\n+    self.keep_aspect_ratio = keep_aspect_ratio\n+    if color_mode not in {'rgb', 'rgba', 'grayscale'}:\n+      raise ValueError('Invalid color mode:', color_mode,\n+                       '; expected \"rgb\", \"rgba\", or \"grayscale\".')\n+    self.color_mode = color_mode\n+    self.data_format = data_format\n+    if self.color_mode == 'rgba':\n+      if self.data_format == 'channels_last':\n+        self.image_shape = self.target_size + (4,)\n+      else:\n+        self.image_shape = (4,) + self.target_size\n+    elif self.color_mode == 'rgb':\n+      if self.data_format == 'channels_last':\n+        self.image_shape = self.target_size + (3,)\n+      else:\n+        self.image_shape = (3,) + self.target_size\n+    else:\n+      if self.data_format == 'channels_last':\n+        self.image_shape = self.target_size + (1,)\n+      else:\n+        self.image_shape = (1,) + self.target_size\n+    self.save_to_dir = save_to_dir\n+    self.save_prefix = save_prefix\n+    self.save_format = save_format\n+    self.interpolation = interpolation\n+    if subset is not None:\n+      validation_split = self.image_data_generator._validation_split  # pylint: disable=protected-access\n+      if subset == 'validation':\n+        split = (0, validation_split)\n+      elif subset == 'training':\n+        split = (validation_split, 1)\n+      else:\n+        raise ValueError('Invalid subset name: %s;'\n+                         'expected \"training\" or \"validation\"' % (subset,))\n+    else:\n+      split = None\n+    self.split = split\n+    self.subset = subset\n+\n+  def _get_batches_of_transformed_samples(self, index_array):\n+    \"\"\"Gets a batch of transformed samples.\n+\n+    Args:\n+        index_array: Array of sample indices to include in batch.\n+    Returns:\n+        A batch of transformed samples.\n+    \"\"\"\n+    batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n+    # build batch of image data\n+    # self.filepaths is dynamic, is better to call it once outside the loop\n+    filepaths = self.filepaths\n+    for i, j in enumerate(index_array):\n+      img = load_img(\n+          filepaths[j],\n+          color_mode=self.color_mode,\n+          target_size=self.target_size,\n+          interpolation=self.interpolation,\n+          keep_aspect_ratio=self.keep_aspect_ratio)\n+      x = img_to_array(img, data_format=self.data_format)\n+      # Pillow images should be closed after `load_img`,\n+      # but not PIL images.\n+      if hasattr(img, 'close'):\n+        img.close()\n+      if self.image_data_generator:\n+        params = self.image_data_generator.get_random_transform(x.shape)\n+        x = self.image_data_generator.apply_transform(x, params)\n+        x = self.image_data_generator.standardize(x)\n+      batch_x[i] = x\n+    # optionally save augmented images to disk for debugging purposes\n+    if self.save_to_dir:\n+      for i, j in enumerate(index_array):\n+        img = array_to_img(batch_x[i], self.data_format, scale=True)\n+        fname = '{prefix}_{index}_{hash}.{format}'.format(\n+            prefix=self.save_prefix,\n+            index=j,\n+            hash=np.random.randint(1e7),\n+            format=self.save_format)\n+        img.save(os.path.join(self.save_to_dir, fname))\n+    # build batch of labels\n+    if self.class_mode == 'input':\n+      batch_y = batch_x.copy()\n+    elif self.class_mode in {'binary', 'sparse'}:\n+      batch_y = np.empty(len(batch_x), dtype=self.dtype)\n+      for i, n_observation in enumerate(index_array):\n+        batch_y[i] = self.classes[n_observation]\n+    elif self.class_mode == 'categorical':\n+      batch_y = np.zeros((len(batch_x), len(self.class_indices)),\n+                         dtype=self.dtype)\n+      for i, n_observation in enumerate(index_array):\n+        batch_y[i, self.classes[n_observation]] = 1.\n+    elif self.class_mode == 'multi_output':\n+      batch_y = [output[index_array] for output in self.labels]\n+    elif self.class_mode == 'raw':\n+      batch_y = self.labels[index_array]\n+    else:\n+      return batch_x\n+    if self.sample_weight is None:\n+      return batch_x, batch_y\n+    else:\n+      return batch_x, batch_y, self.sample_weight[index_array]\n+\n+  @property\n+  def filepaths(self):\n+    \"\"\"List of absolute paths to image files.\"\"\"\n+    raise NotImplementedError(\n+        '`filepaths` property method has not been implemented in {}.'.format(\n+            type(self).__name__))\n+\n+  @property\n+  def labels(self):\n+    \"\"\"Class labels of every observation.\"\"\"\n+    raise NotImplementedError(\n+        '`labels` property method has not been implemented in {}.'.format(\n+            type(self).__name__))\n+\n+  @property\n+  def sample_weight(self):\n+    raise NotImplementedError(\n+        '`sample_weight` property method has not been implemented in {}.'\n+        .format(type(self).__name__))\n+\n+\n+@keras_export('keras.preprocessing.image.DirectoryIterator')\n+class DirectoryIterator(BatchFromFilesMixin, Iterator):\n+  \"\"\"Iterator capable of reading images from a directory on disk.\n+\n+  Args:\n+      directory: Path to the directory to read images from. Each subdirectory in\n+        this directory will be considered to contain images from one class, or\n+        alternatively you could specify class subdirectories via the `classes`\n+        argument.\n+      image_data_generator: Instance of `ImageDataGenerator` to use for random\n+        transformations and normalization.\n+      target_size: tuple of integers, dimensions to resize input images to.\n+      color_mode: One of `\"rgb\"`, `\"rgba\"`, `\"grayscale\"`. Color mode to read\n+        images.\n+      classes: Optional list of strings, names of subdirectories containing\n+        images from each class (e.g. `[\"dogs\", \"cats\"]`). It will be computed\n+        automatically if not set.\n+      class_mode: Mode for yielding the targets:\n+          - `\"binary\"`: binary targets (if there are only two classes),\n+          - `\"categorical\"`: categorical targets,\n+          - `\"sparse\"`: integer targets,\n+          - `\"input\"`: targets are images identical to input images (mainly used\n+            to work with autoencoders),\n+          - `None`: no targets get yielded (only input images are yielded).\n+      batch_size: Integer, size of a batch.\n+      shuffle: Boolean, whether to shuffle the data between epochs.\n+      seed: Random seed for data shuffling.\n+      data_format: String, one of `channels_first`, `channels_last`.\n+      save_to_dir: Optional directory where to save the pictures being yielded,\n+        in a viewable format. This is useful for visualizing the random\n+        transformations being applied, for debugging purposes.\n+      save_prefix: String prefix to use for saving sample images (if\n+        `save_to_dir` is set).\n+      save_format: Format to use for saving sample images (if `save_to_dir` is\n+        set).\n+      subset: Subset of data (`\"training\"` or `\"validation\"`) if\n+        validation_split is set in ImageDataGenerator.\n+      interpolation: Interpolation method used to resample the image if the\n+        target size is different from that of the loaded image. Supported\n+        methods are \"nearest\", \"bilinear\", and \"bicubic\". If PIL version 1.1.3\n+        or newer is installed, \"lanczos\" is also supported. If PIL version 3.4.0\n+        or newer is installed, \"box\" and \"hamming\" are also supported. By\n+        default, \"nearest\" is used.\n+      keep_aspect_ratio: Boolean, whether to resize images to a target size\n+          without aspect ratio distortion. The image is cropped in the center\n+          with target aspect ratio before resizing.\n       dtype: Dtype to use for generated arrays.\n   \"\"\"\n+  allowed_class_modes = {'categorical', 'binary', 'sparse', 'input', None}\n \n-  def __init__(self, directory, image_data_generator,\n+  def __init__(self,\n+               directory,\n+               image_data_generator,\n                target_size=(256, 256),\n                color_mode='rgb',\n                classes=None,\n@@ -382,66 +838,115 @@ class DirectoryIterator(image.DirectoryIterator, Iterator):  # pylint: disable=i\n                follow_links=False,\n                subset=None,\n                interpolation='nearest',\n+               keep_aspect_ratio=False,\n                dtype=None):\n     if data_format is None:\n       data_format = backend.image_data_format()\n-    kwargs = {}\n-    if 'dtype' in tf_inspect.getfullargspec(\n-        image.ImageDataGenerator.__init__)[0]:\n     if dtype is None:\n       dtype = backend.floatx()\n-      kwargs['dtype'] = dtype\n-    super(DirectoryIterator, self).__init__(\n-        directory, image_data_generator,\n-        target_size=target_size,\n-        color_mode=color_mode,\n-        classes=classes,\n-        class_mode=class_mode,\n-        batch_size=batch_size,\n-        shuffle=shuffle,\n-        seed=seed,\n-        data_format=data_format,\n-        save_to_dir=save_to_dir,\n-        save_prefix=save_prefix,\n-        save_format=save_format,\n-        follow_links=follow_links,\n-        subset=subset,\n-        interpolation=interpolation,\n-        **kwargs)\n+    super().set_processing_attrs(image_data_generator, target_size, color_mode,\n+                                 data_format, save_to_dir, save_prefix,\n+                                 save_format, subset, interpolation,\n+                                 keep_aspect_ratio)\n+    self.directory = directory\n+    self.classes = classes\n+    if class_mode not in self.allowed_class_modes:\n+      raise ValueError('Invalid class_mode: {}; expected one of: {}'\n+                       .format(class_mode, self.allowed_class_modes))\n+    self.class_mode = class_mode\n+    self.dtype = dtype\n+    # First, count the number of samples and classes.\n+    self.samples = 0\n+\n+    if not classes:\n+      classes = []\n+      for subdir in sorted(os.listdir(directory)):\n+        if os.path.isdir(os.path.join(directory, subdir)):\n+          classes.append(subdir)\n+    self.num_classes = len(classes)\n+    self.class_indices = dict(zip(classes, range(len(classes))))\n+\n+    pool = multiprocessing.pool.ThreadPool()\n+\n+    # Second, build an index of the images\n+    # in the different class subfolders.\n+    results = []\n+    self.filenames = []\n+    i = 0\n+    for dirpath in (os.path.join(directory, subdir) for subdir in classes):\n+      results.append(\n+          pool.apply_async(_list_valid_filenames_in_directory,\n+                           (dirpath, self.white_list_formats, self.split,\n+                            self.class_indices, follow_links)))\n+    classes_list = []\n+    for res in results:\n+      classes, filenames = res.get()\n+      classes_list.append(classes)\n+      self.filenames += filenames\n+    self.samples = len(self.filenames)\n+    self.classes = np.zeros((self.samples,), dtype='int32')\n+    for classes in classes_list:\n+      self.classes[i:i + len(classes)] = classes\n+      i += len(classes)\n+\n+    print('Found %d images belonging to %d classes.' %\n+          (self.samples, self.num_classes))\n+    pool.close()\n+    pool.join()\n+    self._filepaths = [\n+        os.path.join(self.directory, fname) for fname in self.filenames\n+    ]\n+    super().__init__(self.samples, batch_size, shuffle, seed)\n+\n+  @property\n+  def filepaths(self):\n+    return self._filepaths\n+\n+  @property\n+  def labels(self):\n+    return self.classes\n+\n+  @property  # mixin needs this property to work\n+  def sample_weight(self):\n+    # no sample weights will be returned\n+    return None\n \n \n @keras_export('keras.preprocessing.image.NumpyArrayIterator')\n-class NumpyArrayIterator(image.NumpyArrayIterator, Iterator):\n+class NumpyArrayIterator(Iterator):\n   \"\"\"Iterator yielding data from a Numpy array.\n \n   Args:\n-      x: Numpy array of input data or tuple.\n-          If tuple, the second elements is either\n-          another numpy array or a list of numpy arrays,\n-          each of which gets passed\n-          through as an output without any modifications.\n+      x: Numpy array of input data or tuple. If tuple, the second elements is\n+        either another numpy array or a list of numpy arrays, each of which gets\n+        passed through as an output without any modifications.\n       y: Numpy array of targets data.\n-      image_data_generator: Instance of `ImageDataGenerator`\n-          to use for random transformations and normalization.\n+      image_data_generator: Instance of `ImageDataGenerator` to use for random\n+        transformations and normalization.\n       batch_size: Integer, size of a batch.\n       shuffle: Boolean, whether to shuffle the data between epochs.\n       sample_weight: Numpy array of sample weights.\n       seed: Random seed for data shuffling.\n       data_format: String, one of `channels_first`, `channels_last`.\n-      save_to_dir: Optional directory where to save the pictures\n-          being yielded, in a viewable format. This is useful\n-          for visualizing the random transformations being\n-          applied, for debugging purposes.\n-      save_prefix: String prefix to use for saving sample\n-          images (if `save_to_dir` is set).\n-      save_format: Format to use for saving sample images\n-          (if `save_to_dir` is set).\n+      save_to_dir: Optional directory where to save the pictures being yielded,\n+        in a viewable format. This is useful for visualizing the random\n+        transformations being applied, for debugging purposes.\n+      save_prefix: String prefix to use for saving sample images (if\n+        `save_to_dir` is set).\n+      save_format: Format to use for saving sample images (if `save_to_dir` is\n+        set).\n       subset: Subset of data (`\"training\"` or `\"validation\"`) if\n         validation_split is set in ImageDataGenerator.\n+      ignore_class_split: Boolean (default: False), ignore difference\n+        in number of classes in labels across train and validation\n+        split (useful for non-classification tasks)\n       dtype: Dtype to use for the generated arrays.\n   \"\"\"\n \n-  def __init__(self, x, y, image_data_generator,\n+  def __init__(self,\n+               x,\n+               y,\n+               image_data_generator,\n                batch_size=32,\n                shuffle=False,\n                sample_weight=None,\n@@ -451,46 +956,153 @@ class NumpyArrayIterator(image.NumpyArrayIterator, Iterator):\n                save_prefix='',\n                save_format='png',\n                subset=None,\n+               ignore_class_split=False,\n                dtype=None):\n     if data_format is None:\n       data_format = backend.image_data_format()\n-    kwargs = {}\n-    if 'dtype' in tf_inspect.getfullargspec(\n-        image.NumpyArrayIterator.__init__)[0]:\n     if dtype is None:\n       dtype = backend.floatx()\n-      kwargs['dtype'] = dtype\n-    super(NumpyArrayIterator, self).__init__(\n-        x, y, image_data_generator,\n-        batch_size=batch_size,\n-        shuffle=shuffle,\n-        sample_weight=sample_weight,\n-        seed=seed,\n-        data_format=data_format,\n-        save_to_dir=save_to_dir,\n-        save_prefix=save_prefix,\n-        save_format=save_format,\n-        subset=subset,\n-        **kwargs)\n+    self.dtype = dtype\n+    if isinstance(x, tuple) or isinstance(x, list):\n+      if not isinstance(x[1], list):\n+        x_misc = [np.asarray(x[1])]\n+      else:\n+        x_misc = [np.asarray(xx) for xx in x[1]]\n+      x = x[0]\n+      for xx in x_misc:\n+        if len(x) != len(xx):\n+          raise ValueError('All of the arrays in `x` '\n+                           'should have the same length. '\n+                           'Found a pair with: len(x[0]) = %s, len(x[?]) = %s' %\n+                           (len(x), len(xx)))\n+    else:\n+      x_misc = []\n+\n+    if y is not None and len(x) != len(y):\n+      raise ValueError('`x` (images tensor) and `y` (labels) '\n+                       'should have the same length. '\n+                       'Found: x.shape = %s, y.shape = %s' %\n+                       (np.asarray(x).shape, np.asarray(y).shape))\n+    if sample_weight is not None and len(x) != len(sample_weight):\n+      raise ValueError('`x` (images tensor) and `sample_weight` '\n+                       'should have the same length. '\n+                       'Found: x.shape = %s, sample_weight.shape = %s' %\n+                       (np.asarray(x).shape, np.asarray(sample_weight).shape))\n+    if subset is not None:\n+      if subset not in {'training', 'validation'}:\n+        raise ValueError('Invalid subset name:', subset,\n+                         '; expected \"training\" or \"validation\".')\n+      split_idx = int(len(x) * image_data_generator._validation_split)\n+\n+      if (y is not None and not ignore_class_split and not np.array_equal(\n+          np.unique(y[:split_idx]), np.unique(y[split_idx:]))):\n+        raise ValueError('Training and validation subsets '\n+                         'have different number of classes after '\n+                         'the split. If your numpy arrays are '\n+                         'sorted by the label, you might want '\n+                         'to shuffle them.')\n+\n+      if subset == 'validation':\n+        x = x[:split_idx]\n+        x_misc = [np.asarray(xx[:split_idx]) for xx in x_misc]\n+        if y is not None:\n+          y = y[:split_idx]\n+      else:\n+        x = x[split_idx:]\n+        x_misc = [np.asarray(xx[split_idx:]) for xx in x_misc]\n+        if y is not None:\n+          y = y[split_idx:]\n+\n+    self.x = np.asarray(x, dtype=self.dtype)\n+    self.x_misc = x_misc\n+    if self.x.ndim != 4:\n+      raise ValueError(\n+          'Input data in `NumpyArrayIterator` '\n+          'should have rank 4. You passed an array '\n+          'with shape', self.x.shape)\n+    channels_axis = 3 if data_format == 'channels_last' else 1\n+    if self.x.shape[channels_axis] not in {1, 3, 4}:\n+      warnings.warn('NumpyArrayIterator is set to use the '\n+                    'data format convention \"' + data_format + '\" '\n+                    '(channels on axis ' + str(channels_axis) +\n+                    '), i.e. expected either 1, 3, or 4 '\n+                    'channels on axis ' + str(channels_axis) + '. '\n+                    'However, it was passed an array with shape ' +\n+                    str(self.x.shape) + ' (' +\n+                    str(self.x.shape[channels_axis]) + ' channels).')\n+    if y is not None:\n+      self.y = np.asarray(y)\n+    else:\n+      self.y = None\n+    if sample_weight is not None:\n+      self.sample_weight = np.asarray(sample_weight)\n+    else:\n+      self.sample_weight = None\n+    self.image_data_generator = image_data_generator\n+    self.data_format = data_format\n+    self.save_to_dir = save_to_dir\n+    self.save_prefix = save_prefix\n+    self.save_format = save_format\n+    super().__init__(x.shape[0], batch_size, shuffle, seed)\n+\n+  def _get_batches_of_transformed_samples(self, index_array):\n+    batch_x = np.zeros(\n+        tuple([len(index_array)] + list(self.x.shape)[1:]), dtype=self.dtype)\n+    for i, j in enumerate(index_array):\n+      x = self.x[j]\n+      params = self.image_data_generator.get_random_transform(x.shape)\n+      x = self.image_data_generator.apply_transform(\n+          x.astype(self.dtype), params)\n+      x = self.image_data_generator.standardize(x)\n+      batch_x[i] = x\n+\n+    if self.save_to_dir:\n+      for i, j in enumerate(index_array):\n+        img = array_to_img(batch_x[i], self.data_format, scale=True)\n+        fname = '{prefix}_{index}_{hash}.{format}'.format(\n+            prefix=self.save_prefix,\n+            index=j,\n+            hash=np.random.randint(1e4),\n+            format=self.save_format)\n+        img.save(os.path.join(self.save_to_dir, fname))\n+    batch_x_miscs = [xx[index_array] for xx in self.x_misc]\n+    output = (batch_x if not batch_x_miscs else [batch_x] + batch_x_miscs,)\n+    if self.y is None:\n+      return output[0]\n+    output += (self.y[index_array],)\n+    if self.sample_weight is not None:\n+      output += (self.sample_weight[index_array],)\n+    return output\n \n \n-class DataFrameIterator(image.DataFrameIterator, Iterator):  # pylint: disable=inconsistent-mro\n+def validate_filename(filename, white_list_formats):\n+  \"\"\"Check if a filename refers to a valid file.\n+\n+  Args:\n+      filename: String, absolute path to a file\n+      white_list_formats: Set, allowed file extensions\n+  Returns:\n+      A boolean value indicating if the filename is valid or not\n+  \"\"\"\n+  return (filename.lower().endswith(white_list_formats) and\n+          os.path.isfile(filename))\n+\n+\n+class DataFrameIterator(BatchFromFilesMixin, Iterator):\n   \"\"\"Iterator capable of reading images from a directory on disk as a dataframe.\n \n   Args:\n       dataframe: Pandas dataframe containing the filepaths relative to\n         `directory` (or absolute paths if `directory` is None) of the images in\n         a string column. It should include other column/s depending on the\n-        `class_mode`:\n-          - if `class_mode` is `\"categorical\"` (default value) it must include\n-              the `y_col` column with the class/es of each image. Values in\n-              column can be string/list/tuple if a single class or list/tuple if\n-              multiple classes.\n-          - if `class_mode` is `\"binary\"` or `\"sparse\"` it must include the\n-              given `y_col` column with class values as strings.\n-          - if `class_mode` is `\"raw\"` or `\"multi_output\"` it should contain the\n-              columns specified in `y_col`.\n-          - if `class_mode` is `\"input\"` or `None` no extra column is needed.\n+        `class_mode`: - if `class_mode` is `\"categorical\"` (default value) it\n+          must include the `y_col` column with the class/es of each image.\n+          Values in column can be string/list/tuple if a single class or\n+          list/tuple if multiple classes. - if `class_mode` is `\"binary\"` or\n+          `\"sparse\"` it must include the given `y_col` column with class values\n+          as strings. - if `class_mode` is `\"raw\"` or `\"multi_output\"` it should\n+          contain the columns specified in `y_col`. - if `class_mode` is\n+          `\"input\"` or `None` no extra column is needed.\n       directory: string, path to the directory to read images from. If `None`,\n         data in `x_col` column should be absolute paths.\n       image_data_generator: Instance of `ImageDataGenerator` to use for random\n@@ -516,9 +1128,9 @@ class DataFrameIterator(image.DataFrameIterator, Iterator):  # pylint: disable=i\n             with autoencoders),\n           - `\"multi_output\"`: list with the values of the different columns,\n           - `\"raw\"`: numpy array of values in `y_col` column(s),\n-          - `\"sparse\"`: 1D numpy array of integer labels,\n-          - `None`, no targets are returned (the generator will only yield\n-            batches of image data, which is useful to use in `model.predict()`).\n+          - `\"sparse\"`: 1D numpy array of integer labels, - `None`, no targets\n+            are returned (the generator will only yield batches of image data,\n+            which is useful to use in `model.predict()`).\n       batch_size: Integer, size of a batch.\n       shuffle: Boolean, whether to shuffle the data between epochs.\n       seed: Random seed for data shuffling.\n@@ -538,15 +1150,20 @@ class DataFrameIterator(image.DataFrameIterator, Iterator):  # pylint: disable=i\n         or newer is installed, \"lanczos\" is also supported. If PIL version 3.4.0\n         or newer is installed, \"box\" and \"hamming\" are also supported. By\n         default, \"nearest\" is used.\n+      keep_aspect_ratio: Boolean, whether to resize images to a target size\n+        without aspect ratio distortion. The image is cropped in the center\n+        with target aspect ratio before resizing.\n       dtype: Dtype to use for the generated arrays.\n       validate_filenames: Boolean, whether to validate image filenames in\n         `x_col`. If `True`, invalid images will be ignored. Disabling this\n-        option\n-      can lead to speed-up in the instantiation of this class. Default: `True`.\n+        option can lead to speed-up in the instantiation of this class. Default:\n+        `True`.\n   \"\"\"\n+  allowed_class_modes = {\n+      'binary', 'categorical', 'input', 'multi_output', 'raw', 'sparse', None\n+  }\n \n-  def __init__(\n-      self,\n+  def __init__(self,\n                dataframe,\n                directory=None,\n                image_data_generator=None,\n@@ -566,45 +1183,194 @@ class DataFrameIterator(image.DataFrameIterator, Iterator):  # pylint: disable=i\n                save_format='png',\n                subset=None,\n                interpolation='nearest',\n+               keep_aspect_ratio=False,\n                dtype='float32',\n                validate_filenames=True):\n-    super(DataFrameIterator, self).__init__(\n-        dataframe=dataframe,\n-        directory=directory,\n-        image_data_generator=image_data_generator,\n-        x_col=x_col,\n-        y_col=y_col,\n-        weight_col=weight_col,\n-        target_size=target_size,\n-        color_mode=color_mode,\n-        classes=classes,\n-        class_mode=class_mode,\n-        batch_size=batch_size,\n-        shuffle=shuffle,\n-        seed=seed,\n-        data_format=data_format,\n-        save_to_dir=save_to_dir,\n-        save_prefix=save_prefix,\n-        save_format=save_format,\n-        subset=subset,\n-        interpolation=interpolation,\n-        dtype=dtype,\n-        validate_filenames=validate_filenames\n-    )\n+    super().set_processing_attrs(image_data_generator, target_size, color_mode,\n+                                 data_format, save_to_dir, save_prefix,\n+                                 save_format, subset, interpolation,\n+                                 keep_aspect_ratio)\n+    df = dataframe.copy()\n+    self.directory = directory or ''\n+    self.class_mode = class_mode\n+    self.dtype = dtype\n+    # check that inputs match the required class_mode\n+    self._check_params(df, x_col, y_col, weight_col, classes)\n+    if validate_filenames:  # check which image files are valid and keep them\n+      df = self._filter_valid_filepaths(df, x_col)\n+    if class_mode not in ['input', 'multi_output', 'raw', None]:\n+      df, classes = self._filter_classes(df, y_col, classes)\n+      num_classes = len(classes)\n+      # build an index of all the unique classes\n+      self.class_indices = dict(zip(classes, range(len(classes))))\n+    # retrieve only training or validation set\n+    if self.split:\n+      num_files = len(df)\n+      start = int(self.split[0] * num_files)\n+      stop = int(self.split[1] * num_files)\n+      df = df.iloc[start:stop, :]\n+    # get labels for each observation\n+    if class_mode not in ['input', 'multi_output', 'raw', None]:\n+      self.classes = self.get_classes(df, y_col)\n+    self.filenames = df[x_col].tolist()\n+    self._sample_weight = df[weight_col].values if weight_col else None\n+\n+    if class_mode == 'multi_output':\n+      self._targets = [np.array(df[col].tolist()) for col in y_col]\n+    if class_mode == 'raw':\n+      self._targets = df[y_col].values\n+    self.samples = len(self.filenames)\n+    validated_string = 'validated' if validate_filenames else 'non-validated'\n+    if class_mode in ['input', 'multi_output', 'raw', None]:\n+      print(f'Found {self.samples} {validated_string} image filenames.')\n+    else:\n+      print(f'Found {self.samples} {validated_string} image filenames '\n+            f'belonging to {num_classes} classes.')\n+    self._filepaths = [\n+        os.path.join(self.directory, fname) for fname in self.filenames\n+    ]\n+    super().__init__(self.samples, batch_size, shuffle, seed)\n+\n+  def _check_params(self, df, x_col, y_col, weight_col, classes):\n+    # check class mode is one of the currently supported\n+    if self.class_mode not in self.allowed_class_modes:\n+      raise ValueError('Invalid class_mode: {}; expected one of: {}'.format(\n+          self.class_mode, self.allowed_class_modes))\n+    # check that y_col has several column names if class_mode is multi_output\n+    if (self.class_mode == 'multi_output') and not isinstance(y_col, list):\n+      raise TypeError(\n+          'If class_mode=\"{}\", y_col must be a list. Received {}.'.format(\n+              self.class_mode,\n+              type(y_col).__name__))\n+    # check that filenames/filepaths column values are all strings\n+    if not all(df[x_col].apply(lambda x: isinstance(x, str))):\n+      raise TypeError(\n+          'All values in column x_col={} must be strings.'.format(x_col))\n+    # check labels are string if class_mode is binary or sparse\n+    if self.class_mode in {'binary', 'sparse'}:\n+      if not all(df[y_col].apply(lambda x: isinstance(x, str))):\n+        raise TypeError('If class_mode=\"{}\", y_col=\"{}\" column '\n+                        'values must be strings.'.format(\n+                            self.class_mode, y_col))\n+    # check that if binary there are only 2 different classes\n+    if self.class_mode == 'binary':\n+      if classes:\n+        classes = set(classes)\n+        if len(classes) != 2:\n+          raise ValueError('If class_mode=\"binary\" there must be 2 '\n+                           'classes. {} class/es were given.'.format(\n+                               len(classes)))\n+      elif df[y_col].nunique() != 2:\n+        raise ValueError('If class_mode=\"binary\" there must be 2 classes. '\n+                         'Found {} classes.'.format(df[y_col].nunique()))\n+    # check values are string, list or tuple if class_mode is categorical\n+    if self.class_mode == 'categorical':\n+      types = (str, list, tuple)\n+      if not all(df[y_col].apply(lambda x: isinstance(x, types))):\n+        raise TypeError('If class_mode=\"{}\", y_col=\"{}\" column '\n+                        'values must be type string, list or tuple.'.format(\n+                            self.class_mode, y_col))\n+    # raise warning if classes are given but will be unused\n+    if classes and self.class_mode in {'input', 'multi_output', 'raw', None}:\n+      warnings.warn(\n+          '`classes` will be ignored given the class_mode=\"{}\"'.format(\n+              self.class_mode))\n+    # check that if weight column that the values are numerical\n+    if weight_col and not issubclass(df[weight_col].dtype.type, np.number):\n+      raise TypeError(\n+          'Column weight_col={} must be numeric.'.format(weight_col))\n+\n+  def get_classes(self, df, y_col):\n+    labels = []\n+    for label in df[y_col]:\n+      if isinstance(label, (list, tuple)):\n+        labels.append([self.class_indices[lbl] for lbl in label])\n+      else:\n+        labels.append(self.class_indices[label])\n+    return labels\n+\n+  @staticmethod\n+  def _filter_classes(df, y_col, classes):\n+    df = df.copy()\n+\n+    def remove_classes(labels, classes):\n+      if isinstance(labels, (list, tuple)):\n+        labels = [cls for cls in labels if cls in classes]\n+        return labels or None\n+      elif isinstance(labels, str):\n+        return labels if labels in classes else None\n+      else:\n+        raise TypeError(\n+            'Expect string, list or tuple but found {} in {} column '.format(\n+                type(labels), y_col))\n+\n+    if classes:\n+      # prepare for membership lookup\n+      classes = list(collections.OrderedDict.fromkeys(classes).keys())\n+      df[y_col] = df[y_col].apply(lambda x: remove_classes(x, classes))\n+    else:\n+      classes = set()\n+      for v in df[y_col]:\n+        if isinstance(v, (list, tuple)):\n+          classes.update(v)\n+        else:\n+          classes.add(v)\n+      classes = sorted(classes)\n+    return df.dropna(subset=[y_col]), classes\n+\n+  def _filter_valid_filepaths(self, df, x_col):\n+    \"\"\"Keep only dataframe rows with valid filenames.\n+\n+    Args:\n+        df: Pandas dataframe containing filenames in a column\n+        x_col: string, column in `df` that contains the filenames or filepaths\n+    Returns:\n+        absolute paths to image files\n+    \"\"\"\n+    filepaths = df[x_col].map(lambda fname: os.path.join(self.directory, fname))\n+    mask = filepaths.apply(validate_filename, args=(self.white_list_formats,))\n+    n_invalid = (~mask).sum()\n+    if n_invalid:\n+      warnings.warn('Found {} invalid image filename(s) in x_col=\"{}\". '\n+                    'These filename(s) will be ignored.'.format(\n+                        n_invalid, x_col))\n+    return df[mask]\n+\n+  @property\n+  def filepaths(self):\n+    return self._filepaths\n+\n+  @property\n+  def labels(self):\n+    if self.class_mode in {'multi_output', 'raw'}:\n+      return self._targets\n+    else:\n+      return self.classes\n+\n+  @property\n+  def sample_weight(self):\n+    return self._sample_weight\n+\n+\n+def flip_axis(x, axis):\n+  x = np.asarray(x).swapaxes(axis, 0)\n+  x = x[::-1, ...]\n+  x = x.swapaxes(0, axis)\n+  return x\n \n \n @keras_export('keras.preprocessing.image.ImageDataGenerator')\n-class ImageDataGenerator(image.ImageDataGenerator):\n+class ImageDataGenerator():\n   \"\"\"Generate batches of tensor image data with real-time data augmentation.\n \n    The data will be looped over (in batches).\n \n   Args:\n-      featurewise_center: Boolean.\n-          Set input mean to 0 over the dataset, feature-wise.\n+      featurewise_center: Boolean. Set input mean to 0 over the dataset,\n+        feature-wise.\n       samplewise_center: Boolean. Set each sample mean to 0.\n-      featurewise_std_normalization: Boolean.\n-          Divide inputs by std of the dataset, feature-wise.\n+      featurewise_std_normalization: Boolean. Divide inputs by std of the\n+        dataset, feature-wise.\n       samplewise_std_normalization: Boolean. Divide each input by its std.\n       zca_epsilon: epsilon for ZCA whitening. Default is 1e-6.\n       zca_whitening: Boolean. Apply ZCA whitening.\n@@ -612,61 +1378,51 @@ class ImageDataGenerator(image.ImageDataGenerator):\n       width_shift_range: Float, 1-D array-like or int\n           - float: fraction of total width, if < 1, or pixels if >= 1.\n           - 1-D array-like: random elements from the array.\n-          - int: integer number of pixels from interval\n-              `(-width_shift_range, +width_shift_range)`\n-          - With `width_shift_range=2` possible values\n-              are integers `[-1, 0, +1]`,\n-              same as with `width_shift_range=[-1, 0, +1]`,\n-              while with `width_shift_range=1.0` possible values are floats\n+          - int: integer number of pixels from interval `(-width_shift_range,\n+            +width_shift_range)` - With `width_shift_range=2` possible values\n+            are integers `[-1, 0, +1]`, same as with `width_shift_range=[-1, 0,\n+            +1]`, while with `width_shift_range=1.0` possible values are floats\n             in the interval [-1.0, +1.0).\n       height_shift_range: Float, 1-D array-like or int\n           - float: fraction of total height, if < 1, or pixels if >= 1.\n           - 1-D array-like: random elements from the array.\n-          - int: integer number of pixels from interval\n-              `(-height_shift_range, +height_shift_range)`\n-          - With `height_shift_range=2` possible values\n-              are integers `[-1, 0, +1]`,\n-              same as with `height_shift_range=[-1, 0, +1]`,\n-              while with `height_shift_range=1.0` possible values are floats\n+          - int: integer number of pixels from interval `(-height_shift_range,\n+            +height_shift_range)` - With `height_shift_range=2` possible values\n+            are integers `[-1, 0, +1]`, same as with `height_shift_range=[-1, 0,\n+            +1]`, while with `height_shift_range=1.0` possible values are floats\n             in the interval [-1.0, +1.0).\n-      brightness_range: Tuple or list of two floats. Range for picking\n-          a brightness shift value from.\n-      shear_range: Float. Shear Intensity\n-          (Shear angle in counter-clockwise direction in degrees)\n-      zoom_range: Float or [lower, upper]. Range for random zoom.\n-          If a float, `[lower, upper] = [1-zoom_range, 1+zoom_range]`.\n+      brightness_range: Tuple or list of two floats. Range for picking a\n+        brightness shift value from.\n+      shear_range: Float. Shear Intensity (Shear angle in counter-clockwise\n+        direction in degrees)\n+      zoom_range: Float or [lower, upper]. Range for random zoom. If a float,\n+        `[lower, upper] = [1-zoom_range, 1+zoom_range]`.\n       channel_shift_range: Float. Range for random channel shifts.\n-      fill_mode: One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}.\n-          Default is 'nearest'.\n-          Points outside the boundaries of the input are filled\n+      fill_mode: One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}. Default is\n+        'nearest'. Points outside the boundaries of the input are filled\n           according to the given mode:\n           - 'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k)\n           - 'nearest':  aaaaaaaa|abcd|dddddddd\n           - 'reflect':  abcddcba|abcd|dcbaabcd\n           - 'wrap':  abcdabcd|abcd|abcdabcd\n-      cval: Float or Int.\n-          Value used for points outside the boundaries\n-          when `fill_mode = \"constant\"`.\n+      cval: Float or Int. Value used for points outside the boundaries when\n+        `fill_mode = \"constant\"`.\n       horizontal_flip: Boolean. Randomly flip inputs horizontally.\n       vertical_flip: Boolean. Randomly flip inputs vertically.\n-      rescale: rescaling factor. Defaults to None.\n-          If None or 0, no rescaling is applied,\n-          otherwise we multiply the data by the value provided\n-          (after applying all other transformations).\n-      preprocessing_function: function that will be applied on each input.\n-          The function will run after the image is resized and augmented.\n-          The function should take one argument:\n-          one image (Numpy tensor with rank 3),\n-          and should output a Numpy tensor with the same shape.\n-      data_format: Image data format,\n-          either \"channels_first\" or \"channels_last\".\n-          \"channels_last\" mode means that the images should have shape\n-          `(samples, height, width, channels)`,\n-          \"channels_first\" mode means that the images should have shape\n-          `(samples, channels, height, width)`.\n-          It defaults to the `image_data_format` value found in your\n-          Keras config file at `~/.keras/keras.json`.\n-          If you never set it, then it will be \"channels_last\".\n+      rescale: rescaling factor. Defaults to None. If None or 0, no rescaling is\n+        applied, otherwise we multiply the data by the value provided (after\n+        applying all other transformations).\n+      preprocessing_function: function that will be applied on each input. The\n+        function will run after the image is resized and augmented.\n+          The function should take one argument: one image (Numpy tensor with\n+            rank 3), and should output a Numpy tensor with the same shape.\n+      data_format: Image data format, either \"channels_first\" or\n+        \"channels_last\". \"channels_last\" mode means that the images should have\n+        shape `(samples, height, width, channels)`, \"channels_first\" mode means\n+        that the images should have shape `(samples, channels, height, width)`.\n+        It defaults to the `image_data_format` value found in your Keras config\n+        file at `~/.keras/keras.json`. If you never set it, then it will be\n+        \"channels_last\".\n       validation_split: Float. Fraction of images reserved for validation\n         (strictly between 0 and 1).\n       dtype: Dtype to use for the generated arrays.\n@@ -797,38 +1553,99 @@ class ImageDataGenerator(image.ImageDataGenerator):\n                preprocessing_function=None,\n                data_format=None,\n                validation_split=0.0,\n+               interpolation_order=1,\n                dtype=None):\n     if data_format is None:\n       data_format = backend.image_data_format()\n-    kwargs = {}\n-    if 'dtype' in tf_inspect.getfullargspec(\n-        image.ImageDataGenerator.__init__)[0]:\n     if dtype is None:\n       dtype = backend.floatx()\n-      kwargs['dtype'] = dtype\n-    super(ImageDataGenerator, self).__init__(\n-        featurewise_center=featurewise_center,\n-        samplewise_center=samplewise_center,\n-        featurewise_std_normalization=featurewise_std_normalization,\n-        samplewise_std_normalization=samplewise_std_normalization,\n-        zca_whitening=zca_whitening,\n-        zca_epsilon=zca_epsilon,\n-        rotation_range=rotation_range,\n-        width_shift_range=width_shift_range,\n-        height_shift_range=height_shift_range,\n-        brightness_range=brightness_range,\n-        shear_range=shear_range,\n-        zoom_range=zoom_range,\n-        channel_shift_range=channel_shift_range,\n-        fill_mode=fill_mode,\n-        cval=cval,\n-        horizontal_flip=horizontal_flip,\n-        vertical_flip=vertical_flip,\n-        rescale=rescale,\n-        preprocessing_function=preprocessing_function,\n-        data_format=data_format,\n-        validation_split=validation_split,\n-        **kwargs)\n+\n+    self.featurewise_center = featurewise_center\n+    self.samplewise_center = samplewise_center\n+    self.featurewise_std_normalization = featurewise_std_normalization\n+    self.samplewise_std_normalization = samplewise_std_normalization\n+    self.zca_whitening = zca_whitening\n+    self.zca_epsilon = zca_epsilon\n+    self.rotation_range = rotation_range\n+    self.width_shift_range = width_shift_range\n+    self.height_shift_range = height_shift_range\n+    self.shear_range = shear_range\n+    self.zoom_range = zoom_range\n+    self.channel_shift_range = channel_shift_range\n+    self.fill_mode = fill_mode\n+    self.cval = cval\n+    self.horizontal_flip = horizontal_flip\n+    self.vertical_flip = vertical_flip\n+    self.rescale = rescale\n+    self.preprocessing_function = preprocessing_function\n+    self.dtype = dtype\n+    self.interpolation_order = interpolation_order\n+\n+    if data_format not in {'channels_last', 'channels_first'}:\n+      raise ValueError('`data_format` should be `\"channels_last\"` '\n+                       '(channel after row and column) or '\n+                       '`\"channels_first\"` (channel before row and column). '\n+                       'Received: %s' % data_format)\n+    self.data_format = data_format\n+    if data_format == 'channels_first':\n+      self.channel_axis = 1\n+      self.row_axis = 2\n+      self.col_axis = 3\n+    if data_format == 'channels_last':\n+      self.channel_axis = 3\n+      self.row_axis = 1\n+      self.col_axis = 2\n+    if validation_split and not 0 < validation_split < 1:\n+      raise ValueError('`validation_split` must be strictly between 0 and 1. '\n+                       ' Received: %s' % validation_split)\n+    self._validation_split = validation_split\n+\n+    self.mean = None\n+    self.std = None\n+    self.zca_whitening_matrix = None\n+\n+    if isinstance(zoom_range, (float, int)):\n+      self.zoom_range = [1 - zoom_range, 1 + zoom_range]\n+    elif (len(zoom_range) == 2 and\n+          all(isinstance(val, (float, int)) for val in zoom_range)):\n+      self.zoom_range = [zoom_range[0], zoom_range[1]]\n+    else:\n+      raise ValueError('`zoom_range` should be a float or '\n+                       'a tuple or list of two floats. '\n+                       'Received: %s' % (zoom_range,))\n+    if zca_whitening:\n+      if not featurewise_center:\n+        self.featurewise_center = True\n+        warnings.warn('This ImageDataGenerator specifies '\n+                      '`zca_whitening`, which overrides '\n+                      'setting of `featurewise_center`.')\n+      if featurewise_std_normalization:\n+        self.featurewise_std_normalization = False\n+        warnings.warn('This ImageDataGenerator specifies '\n+                      '`zca_whitening` '\n+                      'which overrides setting of'\n+                      '`featurewise_std_normalization`.')\n+    if featurewise_std_normalization:\n+      if not featurewise_center:\n+        self.featurewise_center = True\n+        warnings.warn('This ImageDataGenerator specifies '\n+                      '`featurewise_std_normalization`, '\n+                      'which overrides setting of '\n+                      '`featurewise_center`.')\n+    if samplewise_std_normalization:\n+      if not samplewise_center:\n+        self.samplewise_center = True\n+        warnings.warn('This ImageDataGenerator specifies '\n+                      '`samplewise_std_normalization`, '\n+                      'which overrides setting of '\n+                      '`samplewise_center`.')\n+    if brightness_range is not None:\n+      if (not isinstance(brightness_range, (tuple, list)) or\n+          len(brightness_range) != 2):\n+        raise ValueError(\n+            '`brightness_range should be tuple or list of two floats. '\n+            'Received: %s' % (brightness_range,))\n+    self.brightness_range = brightness_range\n \n   def flow(self,\n            x,\n@@ -840,6 +1657,7 @@ class ImageDataGenerator(image.ImageDataGenerator):\n            save_to_dir=None,\n            save_prefix='',\n            save_format='png',\n+           ignore_class_split=False,\n            subset=None):\n     \"\"\"Takes data & label arrays, generates batches of augmented data.\n \n@@ -861,9 +1679,11 @@ class ImageDataGenerator(image.ImageDataGenerator):\n           generated (useful for visualizing what you are doing).\n         save_prefix: Str (default: `''`). Prefix to use for filenames of saved\n           pictures (only relevant if `save_to_dir` is set).\n-        save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\",\n-            \"tif\", \"jpg\"\n-            (only relevant if `save_to_dir` is set). Default: \"png\".\n+        save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\", \"tif\",\n+          \"jpg\" (only relevant if `save_to_dir` is set). Default: \"png\".\n+        ignore_class_split: Boolean (default: False), ignore difference\n+          in number of classes in labels across train and validation\n+          split (useful for non-classification tasks)\n         subset: Subset of data (`\"training\"` or `\"validation\"`) if\n           `validation_split` is set in `ImageDataGenerator`.\n \n@@ -893,7 +1713,9 @@ class ImageDataGenerator(image.ImageDataGenerator):\n         save_to_dir=save_to_dir,\n         save_prefix=save_prefix,\n         save_format=save_format,\n-        subset=subset)\n+        ignore_class_split=ignore_class_split,\n+        subset=subset,\n+        dtype=self.dtype)\n \n   def flow_from_directory(self,\n                           directory,\n@@ -909,7 +1731,8 @@ class ImageDataGenerator(image.ImageDataGenerator):\n                           save_format='png',\n                           follow_links=False,\n                           subset=None,\n-                          interpolation='nearest'):\n+                          interpolation='nearest',\n+                          keep_aspect_ratio=False):\n     \"\"\"Takes the path to a directory & generates batches of augmented data.\n \n     Args:\n@@ -936,14 +1759,15 @@ class ImageDataGenerator(image.ImageDataGenerator):\n             Determines the type of label arrays that are returned:\n             - \"categorical\" will be 2D one-hot encoded labels,\n             - \"binary\" will be 1D binary labels,\n-            - \"sparse\" will be 1D integer labels,\n-            - \"input\"  will be images identical to input images (mainly used to\n-              work with autoencoders).\n-            - If None, no labels are returned (the generator will only yield\n-              batches of image data, which is useful to use with\n-              `model.predict()`).\n-            Please note that in case of class_mode None, the data still needs to\n-            reside in a subdirectory of `directory` for it to work correctly.\n+                \"sparse\" will be 1D integer labels,\n+            - \"input\" will be images identical\n+                to input images (mainly used to work with autoencoders).\n+            - If None, no labels are returned\n+              (the generator will only yield batches of image data,\n+              which is useful to use with `model.predict_generator()`).\n+              Please note that in case of class_mode None,\n+              the data still needs to reside in a subdirectory\n+              of `directory` for it to work correctly.\n         batch_size: Size of the batches of data (default: 32).\n         shuffle: Whether to shuffle the data (default: True) If set to False,\n           sorts the data in alphanumeric order.\n@@ -953,8 +1777,8 @@ class ImageDataGenerator(image.ImageDataGenerator):\n           generated (useful for visualizing what you are doing).\n         save_prefix: Str. Prefix to use for filenames of saved pictures (only\n           relevant if `save_to_dir` is set).\n-        save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\",\n-            \"tif\", \"jpg\"\n+        save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\", \"tif\",\n+          \"jpg\"\n             (only relevant if `save_to_dir` is set). Default: \"png\".\n         follow_links: Whether to follow symlinks inside\n             class subdirectories (default: False).\n@@ -966,6 +1790,9 @@ class ImageDataGenerator(image.ImageDataGenerator):\n           1.1.3 or newer is installed, `\"lanczos\"` is also supported. If PIL\n           version 3.4.0 or newer is installed, `\"box\"` and `\"hamming\"` are also\n           supported. By default, `\"nearest\"` is used.\n+        keep_aspect_ratio: Boolean, whether to resize images to a target\n+          size without aspect ratio distortion. The image is cropped in\n+          the center with target aspect ratio before resizing.\n \n     Returns:\n         A `DirectoryIterator` yielding tuples of `(x, y)`\n@@ -978,6 +1805,7 @@ class ImageDataGenerator(image.ImageDataGenerator):\n         self,\n         target_size=target_size,\n         color_mode=color_mode,\n+        keep_aspect_ratio=keep_aspect_ratio,\n         classes=classes,\n         class_mode=class_mode,\n         data_format=self.data_format,\n@@ -989,7 +1817,8 @@ class ImageDataGenerator(image.ImageDataGenerator):\n         save_format=save_format,\n         follow_links=follow_links,\n         subset=subset,\n-        interpolation=interpolation)\n+        interpolation=interpolation,\n+        dtype=self.dtype)\n \n   def flow_from_dataframe(self,\n                           dataframe,\n@@ -1020,15 +1849,15 @@ class ImageDataGenerator(image.ImageDataGenerator):\n \n     Args:\n         dataframe: Pandas dataframe containing the filepaths relative to\n-          `directory` (or absolute paths if `directory` is None) of the images\n-          in a string column. It should include other column/s\n+            `directory` (or absolute paths if `directory` is None) of the\n+            images in a string column. It should include other column/s\n             depending on the `class_mode`:\n-            - if `class_mode` is `\"categorical\"` (default value) it must include\n-              the `y_col` column with the class/es of each image. Values in\n-              column can be string/list/tuple if a single class or list/tuple if\n-              multiple classes.\n-            - if `class_mode` is `\"binary\"` or `\"sparse\"` it must include the\n-              given `y_col` column with class values as strings.\n+            - if `class_mode` is `\"categorical\"` (default value) it must\n+                include the `y_col` column with the class/es of each image.\n+                Values in column can be string/list/tuple if a single class\n+                or list/tuple if multiple classes.\n+            - if `class_mode` is `\"binary\"` or `\"sparse\"` it must include\n+                the given `y_col` column with class values as strings.\n             - if `class_mode` is `\"raw\"` or `\"multi_output\"` it should contain\n             the columns specified in `y_col`.\n             - if `class_mode` is `\"input\"` or `None` no extra column is needed.\n@@ -1059,10 +1888,9 @@ class ImageDataGenerator(image.ImageDataGenerator):\n               with autoencoders),\n             - `\"multi_output\"`: list with the values of the different columns,\n             - `\"raw\"`: numpy array of values in `y_col` column(s),\n-            - `\"sparse\"`: 1D numpy array of integer labels,\n-            - `None`, no targets are returned (the generator will only yield\n-              batches of image data, which is useful to use in\n-              `model.predict()`).\n+            - `\"sparse\"`: 1D numpy array of integer labels, - `None`, no targets\n+              are returned (the generator will only yield batches of image data,\n+              which is useful to use in `model.predict()`).\n         batch_size: size of the batches of data (default: 32).\n         shuffle: whether to shuffle the data (default: True)\n         seed: optional random seed for shuffling and transformations.\n@@ -1071,9 +1899,8 @@ class ImageDataGenerator(image.ImageDataGenerator):\n           generated (useful for visualizing what you are doing).\n         save_prefix: str. Prefix to use for filenames of saved pictures (only\n           relevant if `save_to_dir` is set).\n-        save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\",\n-            \"tif\", \"jpg\"\n-            (only relevant if `save_to_dir` is set). Default: \"png\".\n+        save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\", \"tif\",\n+          \"jpg\" (only relevant if `save_to_dir` is set). Default: \"png\".\n         subset: Subset of data (`\"training\"` or `\"validation\"`) if\n           `validation_split` is set in `ImageDataGenerator`.\n         interpolation: Interpolation method used to resample the image if the\n@@ -1095,21 +1922,21 @@ class ImageDataGenerator(image.ImageDataGenerator):\n         and `y` is a numpy array of corresponding labels.\n     \"\"\"\n     if 'has_ext' in kwargs:\n-      tf_logging.warning(\n+      warnings.warn(\n           'has_ext is deprecated, filenames in the dataframe have '\n           'to match the exact filenames in disk.', DeprecationWarning)\n     if 'sort' in kwargs:\n-      tf_logging.warning(\n+      warnings.warn(\n           'sort is deprecated, batches will be created in the'\n           'same order than the filenames provided if shuffle'\n           'is set to False.', DeprecationWarning)\n     if class_mode == 'other':\n-      tf_logging.warning(\n+      warnings.warn(\n           '`class_mode` \"other\" is deprecated, please use '\n           '`class_mode` \"raw\".', DeprecationWarning)\n       class_mode = 'raw'\n     if 'drop_duplicates' in kwargs:\n-      tf_logging.warning(\n+      warnings.warn(\n           'drop_duplicates is deprecated, you can drop duplicates '\n           'by using the pandas.DataFrame.drop_duplicates method.',\n           DeprecationWarning)\n@@ -1134,19 +1961,671 @@ class ImageDataGenerator(image.ImageDataGenerator):\n         save_format=save_format,\n         subset=subset,\n         interpolation=interpolation,\n-        validate_filenames=validate_filenames)\n+        validate_filenames=validate_filenames,\n+        dtype=self.dtype)\n+\n+  def standardize(self, x):\n+    \"\"\"Applies the normalization configuration in-place to a batch of inputs.\n+\n+    `x` is changed in-place since the function is mainly used internally\n+    to standardize images and feed them to your network. If a copy of `x`\n+    would be created instead it would have a significant performance cost.\n+    If you want to apply this method without changing the input in-place\n+    you can call the method creating a copy before:\n+\n+    standardize(np.copy(x))\n+\n+    Args:\n+        x: Batch of inputs to be normalized.\n+\n+    Returns:\n+        The inputs, normalized.\n+    \"\"\"\n+    if self.preprocessing_function:\n+      x = self.preprocessing_function(x)\n+    if self.rescale:\n+      x *= self.rescale\n+    if self.samplewise_center:\n+      x -= np.mean(x, keepdims=True)\n+    if self.samplewise_std_normalization:\n+      x /= (np.std(x, keepdims=True) + 1e-6)\n+\n+    if self.featurewise_center:\n+      if self.mean is not None:\n+        x -= self.mean\n+      else:\n+        warnings.warn('This ImageDataGenerator specifies '\n+                      '`featurewise_center`, but it hasn\\'t '\n+                      'been fit on any training data. Fit it '\n+                      'first by calling `.fit(numpy_data)`.')\n+    if self.featurewise_std_normalization:\n+      if self.std is not None:\n+        x /= (self.std + 1e-6)\n+      else:\n+        warnings.warn('This ImageDataGenerator specifies '\n+                      '`featurewise_std_normalization`, '\n+                      'but it hasn\\'t '\n+                      'been fit on any training data. Fit it '\n+                      'first by calling `.fit(numpy_data)`.')\n+    if self.zca_whitening:\n+      if self.zca_whitening_matrix is not None:\n+        flat_x = x.reshape(-1, np.prod(x.shape[-3:]))\n+        white_x = flat_x @ self.zca_whitening_matrix\n+        x = np.reshape(white_x, x.shape)\n+      else:\n+        warnings.warn('This ImageDataGenerator specifies '\n+                      '`zca_whitening`, but it hasn\\'t '\n+                      'been fit on any training data. Fit it '\n+                      'first by calling `.fit(numpy_data)`.')\n+    return x\n+\n+  def get_random_transform(self, img_shape, seed=None):\n+    \"\"\"Generates random parameters for a transformation.\n+\n+    Args:\n+        img_shape: Tuple of integers.\n+            Shape of the image that is transformed.\n+        seed: Random seed.\n+\n+    Returns:\n+        A dictionary containing randomly chosen parameters describing the\n+        transformation.\n+    \"\"\"\n+    img_row_axis = self.row_axis - 1\n+    img_col_axis = self.col_axis - 1\n+\n+    if seed is not None:\n+      np.random.seed(seed)\n+\n+    if self.rotation_range:\n+      theta = np.random.uniform(-self.rotation_range, self.rotation_range)\n+    else:\n+      theta = 0\n+\n+    if self.height_shift_range:\n+      try:  # 1-D array-like or int\n+        tx = np.random.choice(self.height_shift_range)\n+        tx *= np.random.choice([-1, 1])\n+      except ValueError:  # floating point\n+        tx = np.random.uniform(-self.height_shift_range,\n+                               self.height_shift_range)\n+      if np.max(self.height_shift_range) < 1:\n+        tx *= img_shape[img_row_axis]\n+    else:\n+      tx = 0\n+\n+    if self.width_shift_range:\n+      try:  # 1-D array-like or int\n+        ty = np.random.choice(self.width_shift_range)\n+        ty *= np.random.choice([-1, 1])\n+      except ValueError:  # floating point\n+        ty = np.random.uniform(-self.width_shift_range, self.width_shift_range)\n+      if np.max(self.width_shift_range) < 1:\n+        ty *= img_shape[img_col_axis]\n+    else:\n+      ty = 0\n+\n+    if self.shear_range:\n+      shear = np.random.uniform(-self.shear_range, self.shear_range)\n+    else:\n+      shear = 0\n+\n+    if self.zoom_range[0] == 1 and self.zoom_range[1] == 1:\n+      zx, zy = 1, 1\n+    else:\n+      zx, zy = np.random.uniform(self.zoom_range[0], self.zoom_range[1], 2)\n+\n+    flip_horizontal = (np.random.random() < 0.5) * self.horizontal_flip\n+    flip_vertical = (np.random.random() < 0.5) * self.vertical_flip\n+\n+    channel_shift_intensity = None\n+    if self.channel_shift_range != 0:\n+      channel_shift_intensity = np.random.uniform(-self.channel_shift_range,\n+                                                  self.channel_shift_range)\n+\n+    brightness = None\n+    if self.brightness_range is not None:\n+      brightness = np.random.uniform(self.brightness_range[0],\n+                                     self.brightness_range[1])\n+\n+    transform_parameters = {\n+        'theta': theta,\n+        'tx': tx,\n+        'ty': ty,\n+        'shear': shear,\n+        'zx': zx,\n+        'zy': zy,\n+        'flip_horizontal': flip_horizontal,\n+        'flip_vertical': flip_vertical,\n+        'channel_shift_intensity': channel_shift_intensity,\n+        'brightness': brightness\n+    }\n+\n+    return transform_parameters\n+\n+  def apply_transform(self, x, transform_parameters):\n+    \"\"\"Applies a transformation to an image according to given parameters.\n+\n+    Args:\n+        x: 3D tensor, single image.\n+        transform_parameters: Dictionary with string - parameter pairs\n+            describing the transformation.\n+            Currently, the following parameters\n+            from the dictionary are used:\n+            - `'theta'`: Float. Rotation angle in degrees.\n+            - `'tx'`: Float. Shift in the x direction.\n+            - `'ty'`: Float. Shift in the y direction.\n+            - `'shear'`: Float. Shear angle in degrees.\n+            - `'zx'`: Float. Zoom in the x direction.\n+            - `'zy'`: Float. Zoom in the y direction.\n+            - `'flip_horizontal'`: Boolean. Horizontal flip.\n+            - `'flip_vertical'`: Boolean. Vertical flip.\n+            - `'channel_shift_intensity'`: Float. Channel shift intensity.\n+            - `'brightness'`: Float. Brightness shift intensity.\n+\n+    Returns:\n+        A transformed version of the input (same shape).\n+    \"\"\"\n+    # x is a single image, so it doesn't have image number at index 0\n+    img_row_axis = self.row_axis - 1\n+    img_col_axis = self.col_axis - 1\n+    img_channel_axis = self.channel_axis - 1\n+\n+    x = apply_affine_transform(\n+        x,\n+        transform_parameters.get('theta', 0),\n+        transform_parameters.get('tx', 0),\n+        transform_parameters.get('ty', 0),\n+        transform_parameters.get('shear', 0),\n+        transform_parameters.get('zx', 1),\n+        transform_parameters.get('zy', 1),\n+        row_axis=img_row_axis,\n+        col_axis=img_col_axis,\n+        channel_axis=img_channel_axis,\n+        fill_mode=self.fill_mode,\n+        cval=self.cval,\n+        order=self.interpolation_order)\n+\n+    if transform_parameters.get('channel_shift_intensity') is not None:\n+      x = apply_channel_shift(x,\n+                              transform_parameters['channel_shift_intensity'],\n+                              img_channel_axis)\n+\n+    if transform_parameters.get('flip_horizontal', False):\n+      x = flip_axis(x, img_col_axis)\n+\n+    if transform_parameters.get('flip_vertical', False):\n+      x = flip_axis(x, img_row_axis)\n+\n+    if transform_parameters.get('brightness') is not None:\n+      x = apply_brightness_shift(x, transform_parameters['brightness'], False)\n+\n+    return x\n+\n+  def random_transform(self, x, seed=None):\n+    \"\"\"Applies a random transformation to an image.\n+\n+    Args:\n+        x: 3D tensor, single image.\n+        seed: Random seed.\n+\n+    Returns:\n+        A randomly transformed version of the input (same shape).\n+    \"\"\"\n+    params = self.get_random_transform(x.shape, seed)\n+    return self.apply_transform(x, params)\n+\n+  def fit(self, x, augment=False, rounds=1, seed=None):\n+    \"\"\"Fits the data generator to some sample data.\n+\n+    This computes the internal data stats related to the\n+    data-dependent transformations, based on an array of sample data.\n+\n+    Only required if `featurewise_center` or\n+    `featurewise_std_normalization` or `zca_whitening` are set to True.\n+\n+    When `rescale` is set to a value, rescaling is applied to\n+    sample data before computing the internal data stats.\n+\n+    Args:\n+        x: Sample data. Should have rank 4.\n+         In case of grayscale data,\n+         the channels axis should have value 1, in case\n+         of RGB data, it should have value 3, and in case\n+         of RGBA data, it should have value 4.\n+        augment: Boolean (default: False).\n+            Whether to fit on randomly augmented samples.\n+        rounds: Int (default: 1).\n+            If using data augmentation (`augment=True`),\n+            this is how many augmentation passes over the data to use.\n+        seed: Int (default: None). Random seed.\n+    \"\"\"\n+    x = np.asarray(x, dtype=self.dtype)\n+    if x.ndim != 4:\n+      raise ValueError('Input to `.fit()` should have rank 4. '\n+                       'Got array with shape: ' + str(x.shape))\n+    if x.shape[self.channel_axis] not in {1, 3, 4}:\n+      warnings.warn('Expected input to be images (as Numpy array) '\n+                    'following the data format convention \"' +\n+                    self.data_format + '\" (channels on axis ' +\n+                    str(self.channel_axis) + '), i.e. expected '\n+                    'either 1, 3 or 4 channels on axis ' +\n+                    str(self.channel_axis) + '. '\n+                    'However, it was passed an array with shape ' +\n+                    str(x.shape) + ' (' + str(x.shape[self.channel_axis]) +\n+                    ' channels).')\n+\n+    if seed is not None:\n+      np.random.seed(seed)\n+\n+    x = np.copy(x)\n+    if self.rescale:\n+      x *= self.rescale\n+\n+    if augment:\n+      ax = np.zeros(\n+          tuple([rounds * x.shape[0]] + list(x.shape)[1:]), dtype=self.dtype)\n+      for r in range(rounds):\n+        for i in range(x.shape[0]):\n+          ax[i + r * x.shape[0]] = self.random_transform(x[i])\n+      x = ax\n+\n+    if self.featurewise_center:\n+      self.mean = np.mean(x, axis=(0, self.row_axis, self.col_axis))\n+      broadcast_shape = [1, 1, 1]\n+      broadcast_shape[self.channel_axis - 1] = x.shape[self.channel_axis]\n+      self.mean = np.reshape(self.mean, broadcast_shape)\n+      x -= self.mean\n+\n+    if self.featurewise_std_normalization:\n+      self.std = np.std(x, axis=(0, self.row_axis, self.col_axis))\n+      broadcast_shape = [1, 1, 1]\n+      broadcast_shape[self.channel_axis - 1] = x.shape[self.channel_axis]\n+      self.std = np.reshape(self.std, broadcast_shape)\n+      x /= (self.std + 1e-6)\n+\n+    if self.zca_whitening:\n+      n = len(x)\n+      flat_x = np.reshape(x, (n, -1))\n+\n+      u, s, _ = np.linalg.svd(flat_x.T, full_matrices=False)\n+      s_inv = np.sqrt(n) / (s + self.zca_epsilon)\n+      self.zca_whitening_matrix = (u * s_inv).dot(u.T)\n \n \n-keras_export('keras.preprocessing.image.random_rotation', allow_multiple_exports=True)(random_rotation)\n-keras_export('keras.preprocessing.image.random_shift', allow_multiple_exports=True)(random_shift)\n-keras_export('keras.preprocessing.image.random_shear', allow_multiple_exports=True)(random_shear)\n-keras_export('keras.preprocessing.image.random_zoom', allow_multiple_exports=True)(random_zoom)\n-keras_export(\n-    'keras.preprocessing.image.apply_channel_shift', allow_multiple_exports=True)(apply_channel_shift)\n-keras_export(\n-    'keras.preprocessing.image.random_channel_shift', allow_multiple_exports=True)(random_channel_shift)\n-keras_export(\n-    'keras.preprocessing.image.apply_brightness_shift', allow_multiple_exports=True)(apply_brightness_shift)\n-keras_export('keras.preprocessing.image.random_brightness', allow_multiple_exports=True)(random_brightness)\n-keras_export(\n-    'keras.preprocessing.image.apply_affine_transform', allow_multiple_exports=True)(apply_affine_transform)\n+@keras_export('keras.preprocessing.image.random_rotation')\n+def random_rotation(x, rg, row_axis=1, col_axis=2, channel_axis=0,\n+                    fill_mode='nearest', cval=0., interpolation_order=1):\n+  \"\"\"Performs a random rotation of a Numpy image tensor.\n+\n+  Args:\n+      x: Input tensor. Must be 3D.\n+      rg: Rotation range, in degrees.\n+      row_axis: Index of axis for rows in the input tensor.\n+      col_axis: Index of axis for columns in the input tensor.\n+      channel_axis: Index of axis for channels in the input tensor.\n+      fill_mode: Points outside the boundaries of the input\n+          are filled according to the given mode\n+          (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n+      cval: Value used for points outside the boundaries\n+          of the input if `mode='constant'`.\n+      interpolation_order: int, order of spline interpolation.\n+          see `ndimage.interpolation.affine_transform`\n+\n+  Returns:\n+      Rotated Numpy image tensor.\n+  \"\"\"\n+  theta = np.random.uniform(-rg, rg)\n+  x = apply_affine_transform(x,\n+                             theta=theta,\n+                             row_axis=row_axis,\n+                             col_axis=col_axis,\n+                             channel_axis=channel_axis,\n+                             fill_mode=fill_mode,\n+                             cval=cval,\n+                             order=interpolation_order)\n+  return x\n+\n+\n+@keras_export('keras.preprocessing.image.random_shift')\n+def random_shift(x, wrg, hrg, row_axis=1, col_axis=2, channel_axis=0,\n+                 fill_mode='nearest', cval=0., interpolation_order=1):\n+  \"\"\"Performs a random spatial shift of a Numpy image tensor.\n+\n+  Args:\n+      x: Input tensor. Must be 3D.\n+      wrg: Width shift range, as a float fraction of the width.\n+      hrg: Height shift range, as a float fraction of the height.\n+      row_axis: Index of axis for rows in the input tensor.\n+      col_axis: Index of axis for columns in the input tensor.\n+      channel_axis: Index of axis for channels in the input tensor.\n+      fill_mode: Points outside the boundaries of the input\n+          are filled according to the given mode\n+          (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n+      cval: Value used for points outside the boundaries\n+          of the input if `mode='constant'`.\n+      interpolation_order: int, order of spline interpolation.\n+          see `ndimage.interpolation.affine_transform`\n+\n+  Returns:\n+      Shifted Numpy image tensor.\n+  \"\"\"\n+  h, w = x.shape[row_axis], x.shape[col_axis]\n+  tx = np.random.uniform(-hrg, hrg) * h\n+  ty = np.random.uniform(-wrg, wrg) * w\n+  x = apply_affine_transform(x,\n+                             tx=tx,\n+                             ty=ty,\n+                             row_axis=row_axis,\n+                             col_axis=col_axis,\n+                             channel_axis=channel_axis,\n+                             fill_mode=fill_mode,\n+                             cval=cval,\n+                             order=interpolation_order)\n+  return x\n+\n+\n+@keras_export('keras.preprocessing.image.random_shear')\n+def random_shear(x, intensity, row_axis=1, col_axis=2, channel_axis=0,\n+                 fill_mode='nearest', cval=0., interpolation_order=1):\n+  \"\"\"Performs a random spatial shear of a Numpy image tensor.\n+\n+  Args:\n+      x: Input tensor. Must be 3D.\n+      intensity: Transformation intensity in degrees.\n+      row_axis: Index of axis for rows in the input tensor.\n+      col_axis: Index of axis for columns in the input tensor.\n+      channel_axis: Index of axis for channels in the input tensor.\n+      fill_mode: Points outside the boundaries of the input\n+          are filled according to the given mode\n+          (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n+      cval: Value used for points outside the boundaries\n+          of the input if `mode='constant'`.\n+      interpolation_order: int, order of spline interpolation.\n+          see `ndimage.interpolation.affine_transform`\n+\n+  Returns:\n+      Sheared Numpy image tensor.\n+  \"\"\"\n+  shear = np.random.uniform(-intensity, intensity)\n+  x = apply_affine_transform(\n+      x,\n+      shear=shear,\n+      row_axis=row_axis,\n+      col_axis=col_axis,\n+      channel_axis=channel_axis,\n+      fill_mode=fill_mode,\n+      cval=cval,\n+      order=interpolation_order)\n+  return x\n+\n+\n+@keras_export('keras.preprocessing.image.random_zoom')\n+def random_zoom(x, zoom_range, row_axis=1, col_axis=2, channel_axis=0,\n+                fill_mode='nearest', cval=0., interpolation_order=1):\n+  \"\"\"Performs a random spatial zoom of a Numpy image tensor.\n+\n+  Args:\n+      x: Input tensor. Must be 3D.\n+      zoom_range: Tuple of floats; zoom range for width and height.\n+      row_axis: Index of axis for rows in the input tensor.\n+      col_axis: Index of axis for columns in the input tensor.\n+      channel_axis: Index of axis for channels in the input tensor.\n+      fill_mode: Points outside the boundaries of the input\n+          are filled according to the given mode\n+          (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n+      cval: Value used for points outside the boundaries\n+          of the input if `mode='constant'`.\n+      interpolation_order: int, order of spline interpolation.\n+          see `ndimage.interpolation.affine_transform`\n+\n+  Returns:\n+      Zoomed Numpy image tensor.\n+\n+  Raises:\n+      ValueError: if `zoom_range` isn't a tuple.\n+  \"\"\"\n+  if len(zoom_range) != 2:\n+    raise ValueError('`zoom_range` should be a tuple or list of two'\n+                     ' floats. Received: %s' % (zoom_range,))\n+\n+  if zoom_range[0] == 1 and zoom_range[1] == 1:\n+    zx, zy = 1, 1\n+  else:\n+    zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\n+  x = apply_affine_transform(\n+      x,\n+      zx=zx,\n+      zy=zy,\n+      row_axis=row_axis,\n+      col_axis=col_axis,\n+      channel_axis=channel_axis,\n+      fill_mode=fill_mode,\n+      cval=cval,\n+      order=interpolation_order)\n+  return x\n+\n+\n+@keras_export('keras.preprocessing.image.apply_channel_shift')\n+def apply_channel_shift(x, intensity, channel_axis=0):\n+  \"\"\"Performs a channel shift.\n+\n+  Args:\n+      x: Input tensor. Must be 3D.\n+      intensity: Transformation intensity.\n+      channel_axis: Index of axis for channels in the input tensor.\n+\n+  Returns:\n+      Numpy image tensor.\n+  \"\"\"\n+  x = np.rollaxis(x, channel_axis, 0)\n+  min_x, max_x = np.min(x), np.max(x)\n+  channel_images = [\n+      np.clip(x_channel + intensity, min_x, max_x) for x_channel in x]\n+  x = np.stack(channel_images, axis=0)\n+  x = np.rollaxis(x, 0, channel_axis + 1)\n+  return x\n+\n+\n+@keras_export('keras.preprocessing.image.random_channel_shift')\n+def random_channel_shift(x, intensity_range, channel_axis=0):\n+  \"\"\"Performs a random channel shift.\n+\n+  Args:\n+      x: Input tensor. Must be 3D.\n+      intensity_range: Transformation intensity.\n+      channel_axis: Index of axis for channels in the input tensor.\n+\n+  Returns:\n+      Numpy image tensor.\n+  \"\"\"\n+  intensity = np.random.uniform(-intensity_range, intensity_range)\n+  return apply_channel_shift(x, intensity, channel_axis=channel_axis)\n+\n+\n+@keras_export('keras.preprocessing.image.apply_brightness_shift')\n+def apply_brightness_shift(x, brightness, scale=True):\n+  \"\"\"Performs a brightness shift.\n+\n+  Args:\n+      x: Input tensor. Must be 3D.\n+      brightness: Float. The new brightness value.\n+      scale: Whether to rescale the image such that minimum and maximum values\n+          are 0 and 255 respectively. Default: True.\n+\n+  Returns:\n+      Numpy image tensor.\n+\n+  Raises:\n+      ImportError: if PIL is not available.\n+  \"\"\"\n+  if ImageEnhance is None:\n+    raise ImportError('Using brightness shifts requires PIL. '\n+                      'Install PIL or Pillow.')\n+  x_min, x_max = np.min(x), np.max(x)\n+  local_scale = (x_min < 0) or (x_max > 255)\n+  x = array_to_img(x, scale=local_scale or scale)\n+  x = imgenhancer_Brightness = ImageEnhance.Brightness(x)\n+  x = imgenhancer_Brightness.enhance(brightness)\n+  x = img_to_array(x)\n+  if not scale and local_scale:\n+    x = x / 255 * (x_max - x_min) + x_min\n+  return x\n+\n+\n+@keras_export('keras.preprocessing.image.random_brightness')\n+def random_brightness(x, brightness_range, scale=True):\n+  \"\"\"Performs a random brightness shift.\n+\n+  Args:\n+      x: Input tensor. Must be 3D.\n+      brightness_range: Tuple of floats; brightness range.\n+      scale: Whether to rescale the image such that minimum and maximum values\n+          are 0 and 255 respectively. Default: True.\n+\n+  Returns:\n+      Numpy image tensor.\n+\n+  Raises:\n+      ValueError if `brightness_range` isn't a tuple.\n+  \"\"\"\n+  if len(brightness_range) != 2:\n+    raise ValueError(\n+        '`brightness_range should be tuple or list of two floats. '\n+        'Received: %s' % (brightness_range,))\n+\n+  u = np.random.uniform(brightness_range[0], brightness_range[1])\n+  return apply_brightness_shift(x, u, scale)\n+\n+\n+def transform_matrix_offset_center(matrix, x, y):\n+  o_x = float(x) / 2 - 0.5\n+  o_y = float(y) / 2 - 0.5\n+  offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n+  reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n+  transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n+  return transform_matrix\n+\n+\n+@keras_export('keras.preprocessing.image.apply_affine_transform')\n+def apply_affine_transform(x, theta=0, tx=0, ty=0, shear=0, zx=1, zy=1,\n+                           row_axis=1, col_axis=2, channel_axis=0,\n+                           fill_mode='nearest', cval=0., order=1):\n+  \"\"\"Applies an affine transformation specified by the parameters given.\n+\n+  Args:\n+      x: 3D numpy array - a 2D image with one or more channels.\n+      theta: Rotation angle in degrees.\n+      tx: Width shift.\n+      ty: Heigh shift.\n+      shear: Shear angle in degrees.\n+      zx: Zoom in x direction.\n+      zy: Zoom in y direction\n+      row_axis: Index of axis for rows (aka Y axis) in the input\n+          image. Direction: left to right.\n+      col_axis: Index of axis for columns (aka X axis) in the input\n+          image. Direction: top to bottom.\n+      channel_axis: Index of axis for channels in the input image.\n+      fill_mode: Points outside the boundaries of the input\n+          are filled according to the given mode\n+          (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n+      cval: Value used for points outside the boundaries\n+          of the input if `mode='constant'`.\n+      order: int, order of interpolation\n+\n+  Returns:\n+      The transformed version of the input.\n+\n+  Raises:\n+      ImportError: if SciPy is not available.\n+  \"\"\"\n+  if scipy is None:\n+    raise ImportError('Image transformations require SciPy. '\n+                      'Install SciPy.')\n+\n+  # Input sanity checks:\n+  # 1. x must 2D image with one or more channels (i.e., a 3D tensor)\n+  # 2. channels must be either first or last dimension\n+  if np.unique([row_axis, col_axis, channel_axis]).size != 3:\n+    raise ValueError(\"'row_axis', 'col_axis', and 'channel_axis'\"\n+                     \" must be distinct\")\n+\n+  # shall we support negative indices?\n+  valid_indices = set([0, 1, 2])\n+  actual_indices = set([row_axis, col_axis, channel_axis])\n+  if actual_indices != valid_indices:\n+    raise ValueError(\n+        f'Invalid axis\\' indices: {actual_indices - valid_indices}')\n+\n+  if x.ndim != 3:\n+    raise ValueError('Input arrays must be multi-channel 2D images.')\n+  if channel_axis not in [0, 2]:\n+    raise ValueError('Channels are allowed and the first and last dimensions.')\n+\n+  transform_matrix = None\n+  if theta != 0:\n+    theta = np.deg2rad(theta)\n+    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n+                                [np.sin(theta), np.cos(theta), 0],\n+                                [0, 0, 1]])\n+    transform_matrix = rotation_matrix\n+\n+  if tx != 0 or ty != 0:\n+    shift_matrix = np.array([[1, 0, tx],\n+                             [0, 1, ty],\n+                             [0, 0, 1]])\n+    if transform_matrix is None:\n+      transform_matrix = shift_matrix\n+    else:\n+      transform_matrix = np.dot(transform_matrix, shift_matrix)\n+\n+  if shear != 0:\n+    shear = np.deg2rad(shear)\n+    shear_matrix = np.array([[1, -np.sin(shear), 0],\n+                             [0, np.cos(shear), 0],\n+                             [0, 0, 1]])\n+    if transform_matrix is None:\n+      transform_matrix = shear_matrix\n+    else:\n+      transform_matrix = np.dot(transform_matrix, shear_matrix)\n+\n+  if zx != 1 or zy != 1:\n+    zoom_matrix = np.array([[zx, 0, 0],\n+                            [0, zy, 0],\n+                            [0, 0, 1]])\n+    if transform_matrix is None:\n+      transform_matrix = zoom_matrix\n+    else:\n+      transform_matrix = np.dot(transform_matrix, zoom_matrix)\n+\n+  if transform_matrix is not None:\n+    h, w = x.shape[row_axis], x.shape[col_axis]\n+    transform_matrix = transform_matrix_offset_center(\n+        transform_matrix, h, w)\n+    x = np.rollaxis(x, channel_axis, 0)\n+\n+    # Matrix construction assumes that coordinates are x, y (in that order).\n+    # However, regular numpy arrays use y,x (aka i,j) indexing.\n+    # Possible solution is:\n+    #   1. Swap the x and y axes.\n+    #   2. Apply transform.\n+    #   3. Swap the x and y axes again to restore image-like data ordering.\n+    # Mathematically, it is equivalent to the following transformation:\n+    # M' = PMP, where P is the permutation matrix, M is the original\n+    # transformation matrix.\n+    if col_axis > row_axis:\n+      transform_matrix[:, [0, 1]] = transform_matrix[:, [1, 0]]\n+      transform_matrix[[0, 1]] = transform_matrix[[1, 0]]\n+    final_affine_matrix = transform_matrix[:2, :2]\n+    final_offset = transform_matrix[:2, 2]\n+\n+    channel_images = [ndimage.interpolation.affine_transform(  # pylint: disable=g-complex-comprehension\n+        x_channel,\n+        final_affine_matrix,\n+        final_offset,\n+        order=order,\n+        mode=fill_mode,\n+        cval=cval) for x_channel in x]\n+    x = np.stack(channel_images, axis=0)\n+    x = np.rollaxis(x, 0, channel_axis + 1)\n+  return x\n\n@@ -14,19 +14,22 @@\n # ==============================================================================\n \"\"\"Tests for image preprocessing utils.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n-\n+import io\n import os\n+import pathlib\n+import random\n import shutil\n import tempfile\n \n from absl.testing import parameterized\n-import numpy as np\n-from keras.testing_infra import test_combinations\n from keras import layers\n-from keras.testing_infra import test_utils\n from keras.engine import sequential\n-from keras.preprocessing import image as preprocessing_image\n+from keras.preprocessing import image\n+from keras.testing_infra import test_combinations\n+from keras.testing_infra import test_utils\n+import numpy as np\n+import pandas as pd\n+import tensorflow.compat.v2 as tf\n \n try:\n   import PIL  # pylint:disable=g-import-not-at-top\n@@ -34,22 +37,47 @@ except ImportError:\n   PIL = None\n \n \n-def _generate_test_images():\n+def _generate_test_images(include_rgba=False,\n+                          include_16bit=False,\n+                          include_32bit=False):\n   img_w = img_h = 20\n   rgb_images = []\n+  rgba_images = []\n   gray_images = []\n+  gray_images_16bit = []\n+  gray_images_32bit = []\n   for _ in range(8):\n     bias = np.random.rand(img_w, img_h, 1) * 64\n     variance = np.random.rand(img_w, img_h, 1) * (255 - 64)\n+    # RGB\n     imarray = np.random.rand(img_w, img_h, 3) * variance + bias\n-    im = preprocessing_image.array_to_img(imarray, scale=False)\n+    im = PIL.Image.fromarray(imarray.astype('uint8')).convert('RGB')\n     rgb_images.append(im)\n-\n+    # RGBA\n+    imarray = np.random.rand(img_w, img_h, 4) * variance + bias\n+    im = PIL.Image.fromarray(imarray.astype('uint8')).convert('RGBA')\n+    rgba_images.append(im)\n+    # 8-bit grayscale\n     imarray = np.random.rand(img_w, img_h, 1) * variance + bias\n-    im = preprocessing_image.array_to_img(imarray, scale=False)\n+    im = PIL.Image.fromarray(imarray.astype('uint8').squeeze()).convert('L')\n     gray_images.append(im)\n+    # 16-bit grayscale\n+    imarray = np.array(\n+        np.random.randint(-2147483648, 2147483647, (img_w, img_h)))\n+    im = PIL.Image.fromarray(imarray.astype('uint16'))\n+    gray_images_16bit.append(im)\n+    # 32-bit grayscale\n+    im = PIL.Image.fromarray(imarray.astype('uint32'))\n+    gray_images_32bit.append(im)\n \n-  return [rgb_images, gray_images]\n+  ret = [rgb_images, gray_images]\n+  if include_rgba:\n+    ret.append(rgba_images)\n+  if include_16bit:\n+    ret.append(gray_images_16bit)\n+  if include_32bit:\n+    ret.append(gray_images_32bit)\n+  return ret\n \n \n @test_utils.run_v2_only\n@@ -57,26 +85,23 @@ class TestImage(test_combinations.TestCase):\n \n   def test_smart_resize(self):\n     test_input = np.random.random((20, 40, 3))\n-    output = preprocessing_image.smart_resize(test_input, size=(50, 50))\n+    output = image.smart_resize(test_input, size=(50, 50))\n     self.assertIsInstance(output, np.ndarray)\n     self.assertListEqual(list(output.shape), [50, 50, 3])\n-    output = preprocessing_image.smart_resize(test_input, size=(10, 10))\n+    output = image.smart_resize(test_input, size=(10, 10))\n     self.assertListEqual(list(output.shape), [10, 10, 3])\n-    output = preprocessing_image.smart_resize(test_input, size=(100, 50))\n+    output = image.smart_resize(test_input, size=(100, 50))\n     self.assertListEqual(list(output.shape), [100, 50, 3])\n-    output = preprocessing_image.smart_resize(test_input, size=(5, 15))\n+    output = image.smart_resize(test_input, size=(5, 15))\n     self.assertListEqual(list(output.shape), [5, 15, 3])\n \n-  @parameterized.named_parameters(\n-      ('size1', (50, 50)),\n-      ('size2', (10, 10)),\n-      ('size3', (100, 50)),\n-      ('size4', (5, 15)))\n+  @parameterized.named_parameters(('size1', (50, 50)), ('size2', (10, 10)),\n+                                  ('size3', (100, 50)), ('size4', (5, 15)))\n   def test_smart_resize_tf_dataset(self, size):\n     test_input_np = np.random.random((2, 20, 40, 3))\n     test_ds = tf.data.Dataset.from_tensor_slices(test_input_np)\n \n-    resize = lambda img: preprocessing_image.smart_resize(img, size=size)\n+    resize = lambda img: image.smart_resize(img, size=size)\n     test_ds = test_ds.map(resize)\n     for sample in test_ds.as_numpy_iterator():\n       self.assertIsInstance(sample, np.ndarray)\n@@ -84,31 +109,36 @@ class TestImage(test_combinations.TestCase):\n \n   def test_smart_resize_batch(self):\n     img = np.random.random((2, 20, 40, 3))\n-    out = preprocessing_image.smart_resize(img, size=(20, 20))\n+    out = image.smart_resize(img, size=(20, 20))\n     self.assertListEqual(list(out.shape), [2, 20, 20, 3])\n     self.assertAllClose(out, img[:, :, 10:-10, :])\n \n   def test_smart_resize_errors(self):\n     with self.assertRaisesRegex(ValueError, 'a tuple of 2 integers'):\n-      preprocessing_image.smart_resize(\n-          np.random.random((20, 20, 2)), size=(10, 5, 3))\n+      image.smart_resize(np.random.random((20, 20, 2)), size=(10, 5, 3))\n     with self.assertRaisesRegex(ValueError, 'incorrect rank'):\n-      preprocessing_image.smart_resize(np.random.random((2, 4)), size=(10, 5))\n+      image.smart_resize(np.random.random((2, 4)), size=(10, 5))\n     with self.assertRaisesRegex(ValueError, 'incorrect rank'):\n-      preprocessing_image.smart_resize(\n-          np.random.random((2, 4, 4, 5, 3)), size=(10, 5))\n+      image.smart_resize(np.random.random((2, 4, 4, 5, 3)), size=(10, 5))\n \n-  def test_image_data_generator(self):\n+  def test_iterator_empty_directory(self):\n+    # Testing with different batch sizes\n+    for batch_size in [0, 32]:\n+      data_iterator = image.Iterator(0, batch_size, False, 0)\n+      ret = next(data_iterator.index_generator)\n+      self.assertEqual(ret.size, 0)\n+\n+  def test_image(self):\n     if PIL is None:\n       return  # Skip test if PIL is not available.\n \n     for test_images in _generate_test_images():\n       img_list = []\n       for im in test_images:\n-        img_list.append(preprocessing_image.img_to_array(im)[None, ...])\n+        img_list.append(image.img_to_array(im)[None, ...])\n \n       images = np.vstack(img_list)\n-      generator = preprocessing_image.ImageDataGenerator(\n+      generator = image.ImageDataGenerator(\n           featurewise_center=True,\n           samplewise_center=True,\n           featurewise_std_normalization=True,\n@@ -133,18 +163,16 @@ class TestImage(test_combinations.TestCase):\n       generator.fit(images, augment=True)\n \n       for x, _ in generator.flow(\n-          images,\n-          np.arange(images.shape[0]),\n-          shuffle=True):\n+          images, np.arange(images.shape[0]), shuffle=True):\n         self.assertEqual(x.shape[1:], images.shape[1:])\n         break\n \n-  def test_image_data_generator_with_split_value_error(self):\n+  def test_image_with_split_value_error(self):\n     with self.assertRaises(ValueError):\n-      preprocessing_image.ImageDataGenerator(validation_split=5)\n+      image.ImageDataGenerator(validation_split=5)\n \n-  def test_image_data_generator_invalid_data(self):\n-    generator = preprocessing_image.ImageDataGenerator(\n+  def test_image_invalid_data(self):\n+    generator = image.ImageDataGenerator(\n         featurewise_center=True,\n         samplewise_center=True,\n         featurewise_std_normalization=True,\n@@ -164,13 +192,12 @@ class TestImage(test_combinations.TestCase):\n     generator.flow(x)\n \n     with self.assertRaises(ValueError):\n-      generator = preprocessing_image.ImageDataGenerator(\n-          data_format='unknown')\n+      generator = image.ImageDataGenerator(data_format='unknown')\n \n-    generator = preprocessing_image.ImageDataGenerator(zoom_range=(2., 2.))\n+    generator = image.ImageDataGenerator(zoom_range=(2., 2.))\n \n-  def test_image_data_generator_fit(self):\n-    generator = preprocessing_image.ImageDataGenerator(\n+  def test_image_fit(self):\n+    generator = image.ImageDataGenerator(\n         featurewise_center=True,\n         samplewise_center=True,\n         featurewise_std_normalization=True,\n@@ -183,7 +210,7 @@ class TestImage(test_combinations.TestCase):\n     # Test RBG\n     x = np.random.random((32, 10, 10, 3))\n     generator.fit(x)\n-    generator = preprocessing_image.ImageDataGenerator(\n+    generator = image.ImageDataGenerator(\n         featurewise_center=True,\n         samplewise_center=True,\n         featurewise_std_normalization=True,\n@@ -211,9 +238,10 @@ class TestImage(test_combinations.TestCase):\n     for cl in range(num_classes):\n       class_directory = 'class-{}'.format(cl)\n       classpaths = [\n-          class_directory, os.path.join(class_directory, 'subfolder-1'),\n-          os.path.join(class_directory, 'subfolder-2'), os.path.join(\n-              class_directory, 'subfolder-1', 'sub-subfolder')\n+          class_directory,\n+          os.path.join(class_directory, 'subfolder-1'),\n+          os.path.join(class_directory, 'subfolder-2'),\n+          os.path.join(class_directory, 'subfolder-1', 'sub-subfolder')\n       ]\n       for path in classpaths:\n         os.mkdir(os.path.join(temp_dir, path))\n@@ -236,14 +264,13 @@ class TestImage(test_combinations.TestCase):\n \n     # Test image loading util\n     fname = os.path.join(temp_dir, filenames[0])\n-    _ = preprocessing_image.load_img(fname)\n-    _ = preprocessing_image.load_img(fname, grayscale=True)\n-    _ = preprocessing_image.load_img(fname, target_size=(10, 10))\n-    _ = preprocessing_image.load_img(fname, target_size=(10, 10),\n-                                     interpolation='bilinear')\n+    _ = image.load_img(fname)\n+    _ = image.load_img(fname, grayscale=True)\n+    _ = image.load_img(fname, target_size=(10, 10))\n+    _ = image.load_img(fname, target_size=(10, 10), interpolation='bilinear')\n \n     # create iterator\n-    generator = preprocessing_image.ImageDataGenerator()\n+    generator = image.ImageDataGenerator()\n     dir_iterator = generator.flow_from_directory(temp_dir)\n \n     # check number of classes and images\n@@ -267,7 +294,7 @@ class TestImage(test_combinations.TestCase):\n       return np.zeros_like(x)\n \n     # Test usage as Sequence\n-    generator = preprocessing_image.ImageDataGenerator(\n+    generator = image.ImageDataGenerator(\n         preprocessing_function=preprocessing_function)\n     dir_seq = generator.flow_from_directory(\n         str(temp_dir),\n@@ -320,8 +347,7 @@ class TestImage(test_combinations.TestCase):\n         count += 1\n \n     # create iterator\n-    generator = preprocessing_image.ImageDataGenerator(\n-        validation_split=validation_split)\n+    generator = image.ImageDataGenerator(validation_split=validation_split)\n \n     with self.assertRaises(ValueError):\n       generator.flow_from_directory(tmp_folder, subset='foo')\n@@ -368,32 +394,28 @@ class TestImage(test_combinations.TestCase):\n \n     # Test channels_first data format\n     x = np.random.random((3, height, width))\n-    img = preprocessing_image.array_to_img(\n-        x, data_format='channels_first')\n+    img = image.array_to_img(x, data_format='channels_first')\n     self.assertEqual(img.size, (width, height))\n-    x = preprocessing_image.img_to_array(\n-        img, data_format='channels_first')\n+    x = image.img_to_array(img, data_format='channels_first')\n     self.assertEqual(x.shape, (3, height, width))\n     # Test 2D\n     x = np.random.random((1, height, width))\n-    img = preprocessing_image.array_to_img(\n-        x, data_format='channels_first')\n+    img = image.array_to_img(x, data_format='channels_first')\n     self.assertEqual(img.size, (width, height))\n-    x = preprocessing_image.img_to_array(\n-        img, data_format='channels_first')\n+    x = image.img_to_array(img, data_format='channels_first')\n     self.assertEqual(x.shape, (1, height, width))\n \n     # Test channels_last data format\n     x = np.random.random((height, width, 3))\n-    img = preprocessing_image.array_to_img(x, data_format='channels_last')\n+    img = image.array_to_img(x, data_format='channels_last')\n     self.assertEqual(img.size, (width, height))\n-    x = preprocessing_image.img_to_array(img, data_format='channels_last')\n+    x = image.img_to_array(img, data_format='channels_last')\n     self.assertEqual(x.shape, (height, width, 3))\n     # Test 2D\n     x = np.random.random((height, width, 1))\n-    img = preprocessing_image.array_to_img(x, data_format='channels_last')\n+    img = image.array_to_img(x, data_format='channels_last')\n     self.assertEqual(img.size, (width, height))\n-    x = preprocessing_image.img_to_array(img, data_format='channels_last')\n+    x = image.img_to_array(img, data_format='channels_last')\n     self.assertEqual(x.shape, (height, width, 1))\n \n   def test_batch_standardize(self):\n@@ -404,10 +426,10 @@ class TestImage(test_combinations.TestCase):\n     for test_images in _generate_test_images():\n       img_list = []\n       for im in test_images:\n-        img_list.append(preprocessing_image.img_to_array(im)[None, ...])\n+        img_list.append(image.img_to_array(im)[None, ...])\n \n       images = np.vstack(img_list)\n-      generator = preprocessing_image.ImageDataGenerator(\n+      generator = image.ImageDataGenerator(\n           featurewise_center=True,\n           samplewise_center=True,\n           featurewise_std_normalization=True,\n@@ -433,15 +455,2066 @@ class TestImage(test_combinations.TestCase):\n \n   def test_img_transforms(self):\n     x = np.random.random((3, 200, 200))\n-    _ = preprocessing_image.random_rotation(x, 20)\n-    _ = preprocessing_image.random_shift(x, 0.2, 0.2)\n-    _ = preprocessing_image.random_shear(x, 2.)\n-    _ = preprocessing_image.random_zoom(x, (0.5, 0.5))\n-    _ = preprocessing_image.apply_channel_shift(x, 2, 2)\n-    _ = preprocessing_image.apply_affine_transform(x, 2)\n+    _ = image.random_rotation(x, 20)\n+    _ = image.random_shift(x, 0.2, 0.2)\n+    _ = image.random_shear(x, 2.)\n+    _ = image.random_zoom(x, (0.5, 0.5))\n+    _ = image.apply_channel_shift(x, 2, 2)\n+    _ = image.apply_affine_transform(x, 2)\n     with self.assertRaises(ValueError):\n-      preprocessing_image.random_zoom(x, (0, 0, 0))\n-    _ = preprocessing_image.random_channel_shift(x, 2.)\n+      image.random_zoom(x, (0, 0, 0))\n+    _ = image.random_channel_shift(x, 2.)\n+\n+\n+@test_utils.run_v2_only\n+class TestImageLoading(test_combinations.TestCase):\n+\n+  def test_validate_filename(self):\n+    tmpdir = self.create_tempdir()\n+    valid_extensions = ('png', 'jpg')\n+    filename = tmpdir.create_file('test.png').full_path\n+    self.assertTrue(image.validate_filename(str(filename), valid_extensions))\n+\n+    filename = tmpdir.create_file('test.PnG').full_path\n+    self.assertTrue(image.validate_filename(str(filename), valid_extensions))\n+\n+    filename = tmpdir.create_file('test.some_extension').full_path\n+    self.assertFalse(image.validate_filename(str(filename), valid_extensions))\n+    self.assertFalse(\n+        image.validate_filename('some_test_file.png', valid_extensions))\n+\n+  def test_load_img(self):\n+    tmpdir = self.create_tempdir()\n+    filename_rgb = os.path.join(tmpdir.full_path, 'rgb_utils.png')\n+    filename_rgba = os.path.join(tmpdir.full_path, 'rgba_utils.png')\n+    filename_grayscale_8bit = os.path.join(tmpdir.full_path,\n+                                           'grayscale_8bit_utils.png')\n+    filename_grayscale_16bit = os.path.join(tmpdir.full_path,\n+                                            'grayscale_16bit_utils.tiff')\n+    filename_grayscale_32bit = os.path.join(tmpdir.full_path,\n+                                            'grayscale_32bit_utils.tiff')\n+\n+    original_rgb_array = np.array(\n+        255 * np.random.rand(100, 100, 3), dtype=np.uint8)\n+    original_rgb = image.array_to_img(original_rgb_array, scale=False)\n+    original_rgb.save(filename_rgb)\n+\n+    original_rgba_array = np.array(\n+        255 * np.random.rand(100, 100, 4), dtype=np.uint8)\n+    original_rgba = image.array_to_img(original_rgba_array, scale=False)\n+    original_rgba.save(filename_rgba)\n+\n+    original_grayscale_8bit_array = np.array(\n+        255 * np.random.rand(100, 100, 1), dtype=np.uint8)\n+    original_grayscale_8bit = image.array_to_img(\n+        original_grayscale_8bit_array, scale=False)\n+    original_grayscale_8bit.save(filename_grayscale_8bit)\n+\n+    original_grayscale_16bit_array = np.array(\n+        np.random.randint(-2147483648, 2147483647, (100, 100, 1)),\n+        dtype=np.int16)\n+    original_grayscale_16bit = image.array_to_img(\n+        original_grayscale_16bit_array, scale=False, dtype='int16')\n+    original_grayscale_16bit.save(filename_grayscale_16bit)\n+\n+    original_grayscale_32bit_array = np.array(\n+        np.random.randint(-2147483648, 2147483647, (100, 100, 1)),\n+        dtype=np.int32)\n+    original_grayscale_32bit = image.array_to_img(\n+        original_grayscale_32bit_array, scale=False, dtype='int32')\n+    original_grayscale_32bit.save(filename_grayscale_32bit)\n+\n+    # Test that loaded image is exactly equal to original.\n+\n+    loaded_im = image.load_img(filename_rgb)\n+    loaded_im_array = image.img_to_array(loaded_im)\n+    self.assertEqual(loaded_im_array.shape, original_rgb_array.shape)\n+    self.assertAllClose(loaded_im_array, original_rgb_array)\n+\n+    loaded_im = image.load_img(filename_rgba, color_mode='rgba')\n+    loaded_im_array = image.img_to_array(loaded_im)\n+    self.assertEqual(loaded_im_array.shape, original_rgba_array.shape)\n+    self.assertAllClose(loaded_im_array, original_rgba_array)\n+\n+    loaded_im = image.load_img(filename_rgb, color_mode='grayscale')\n+    loaded_im_array = image.img_to_array(loaded_im)\n+    self.assertEqual(\n+        loaded_im_array.shape,\n+        (original_rgb_array.shape[0], original_rgb_array.shape[1], 1))\n+\n+    loaded_im = image.load_img(filename_grayscale_8bit, color_mode='grayscale')\n+    loaded_im_array = image.img_to_array(loaded_im)\n+    self.assertEqual(loaded_im_array.shape, original_grayscale_8bit_array.shape)\n+    self.assertAllClose(loaded_im_array, original_grayscale_8bit_array)\n+\n+    loaded_im = image.load_img(filename_grayscale_16bit, color_mode='grayscale')\n+    loaded_im_array = image.img_to_array(loaded_im, dtype='int16')\n+    self.assertEqual(loaded_im_array.shape,\n+                     original_grayscale_16bit_array.shape)\n+    self.assertAllClose(loaded_im_array, original_grayscale_16bit_array)\n+    # test casting int16 image to float32\n+    loaded_im_array = image.img_to_array(loaded_im)\n+    self.assertAllClose(loaded_im_array, original_grayscale_16bit_array)\n+\n+    loaded_im = image.load_img(filename_grayscale_32bit, color_mode='grayscale')\n+    loaded_im_array = image.img_to_array(loaded_im, dtype='int32')\n+    self.assertEqual(loaded_im_array.shape,\n+                     original_grayscale_32bit_array.shape)\n+    self.assertAllClose(loaded_im_array, original_grayscale_32bit_array)\n+    # test casting int32 image to float32\n+    loaded_im_array = image.img_to_array(loaded_im)\n+    self.assertAllClose(loaded_im_array, original_grayscale_32bit_array)\n+\n+    # Test that nothing is changed when target size is equal to original.\n+\n+    loaded_im = image.load_img(filename_rgb, target_size=(100, 100))\n+    loaded_im_array = image.img_to_array(loaded_im)\n+    self.assertEqual(loaded_im_array.shape, original_rgb_array.shape)\n+    self.assertAllClose(loaded_im_array, original_rgb_array)\n+\n+    loaded_im = image.load_img(\n+        filename_rgba, color_mode='rgba', target_size=(100, 100))\n+    loaded_im_array = image.img_to_array(loaded_im)\n+    self.assertEqual(loaded_im_array.shape, original_rgba_array.shape)\n+    self.assertAllClose(loaded_im_array, original_rgba_array)\n+\n+    loaded_im = image.load_img(\n+        filename_rgb, color_mode='grayscale', target_size=(100, 100))\n+    loaded_im_array = image.img_to_array(loaded_im)\n+    self.assertEqual(\n+        loaded_im_array.shape,\n+        (original_rgba_array.shape[0], original_rgba_array.shape[1], 1))\n+\n+    loaded_im = image.load_img(\n+        filename_grayscale_8bit, color_mode='grayscale', target_size=(100, 100))\n+    loaded_im_array = image.img_to_array(loaded_im)\n+    self.assertEqual(loaded_im_array.shape, original_grayscale_8bit_array.shape)\n+    self.assertAllClose(loaded_im_array, original_grayscale_8bit_array)\n+\n+    loaded_im = image.load_img(\n+        filename_grayscale_16bit,\n+        color_mode='grayscale',\n+        target_size=(100, 100))\n+    loaded_im_array = image.img_to_array(loaded_im, dtype='int16')\n+    self.assertEqual(loaded_im_array.shape,\n+                     original_grayscale_16bit_array.shape)\n+    self.assertAllClose(loaded_im_array, original_grayscale_16bit_array)\n+\n+    loaded_im = image.load_img(\n+        filename_grayscale_32bit,\n+        color_mode='grayscale',\n+        target_size=(100, 100))\n+    loaded_im_array = image.img_to_array(loaded_im, dtype='int32')\n+    self.assertEqual(loaded_im_array.shape,\n+                     original_grayscale_32bit_array.shape)\n+    self.assertAllClose(loaded_im_array, original_grayscale_32bit_array)\n+\n+    # Test down-sampling with bilinear interpolation.\n+\n+    loaded_im = image.load_img(filename_rgb, target_size=(25, 25))\n+    loaded_im_array = image.img_to_array(loaded_im)\n+    self.assertEqual(loaded_im_array.shape, (25, 25, 3))\n+\n+    loaded_im = image.load_img(\n+        filename_rgba, color_mode='rgba', target_size=(25, 25))\n+    loaded_im_array = image.img_to_array(loaded_im)\n+    self.assertEqual(loaded_im_array.shape, (25, 25, 4))\n+\n+    loaded_im = image.load_img(\n+        filename_rgb, color_mode='grayscale', target_size=(25, 25))\n+    loaded_im_array = image.img_to_array(loaded_im)\n+    self.assertEqual(loaded_im_array.shape, (25, 25, 1))\n+\n+    loaded_im = image.load_img(\n+        filename_grayscale_8bit, color_mode='grayscale', target_size=(25, 25))\n+    loaded_im_array = image.img_to_array(loaded_im)\n+    self.assertEqual(loaded_im_array.shape, (25, 25, 1))\n+\n+    loaded_im = image.load_img(\n+        filename_grayscale_16bit, color_mode='grayscale', target_size=(25, 25))\n+    loaded_im_array = image.img_to_array(loaded_im, dtype='int16')\n+    self.assertEqual(loaded_im_array.shape, (25, 25, 1))\n+\n+    loaded_im = image.load_img(\n+        filename_grayscale_32bit, color_mode='grayscale', target_size=(25, 25))\n+    loaded_im_array = image.img_to_array(loaded_im, dtype='int32')\n+    self.assertEqual(loaded_im_array.shape, (25, 25, 1))\n+\n+    # Test down-sampling with nearest neighbor interpolation.\n+\n+    loaded_im_nearest = image.load_img(\n+        filename_rgb, target_size=(25, 25), interpolation='nearest')\n+    loaded_im_array_nearest = image.img_to_array(loaded_im_nearest)\n+    self.assertEqual(loaded_im_array_nearest.shape, (25, 25, 3))\n+    self.assertTrue(np.any(loaded_im_array_nearest != loaded_im_array))\n+\n+    loaded_im_nearest = image.load_img(\n+        filename_rgba,\n+        color_mode='rgba',\n+        target_size=(25, 25),\n+        interpolation='nearest')\n+    loaded_im_array_nearest = image.img_to_array(loaded_im_nearest)\n+    self.assertEqual(loaded_im_array_nearest.shape, (25, 25, 4))\n+    self.assertTrue(np.any(loaded_im_array_nearest != loaded_im_array))\n+\n+    loaded_im = image.load_img(\n+        filename_grayscale_8bit,\n+        color_mode='grayscale',\n+        target_size=(25, 25),\n+        interpolation='nearest')\n+    loaded_im_array = image.img_to_array(loaded_im)\n+    self.assertEqual(loaded_im_array.shape, (25, 25, 1))\n+\n+    loaded_im = image.load_img(\n+        filename_grayscale_16bit,\n+        color_mode='grayscale',\n+        target_size=(25, 25),\n+        interpolation='nearest')\n+    loaded_im_array = image.img_to_array(loaded_im, dtype='int16')\n+    self.assertEqual(loaded_im_array.shape, (25, 25, 1))\n+\n+    loaded_im = image.load_img(\n+        filename_grayscale_32bit,\n+        color_mode='grayscale',\n+        target_size=(25, 25),\n+        interpolation='nearest')\n+    loaded_im_array = image.img_to_array(loaded_im, dtype='int32')\n+    self.assertEqual(loaded_im_array.shape, (25, 25, 1))\n+\n+    # Test different path type\n+    with open(filename_grayscale_32bit, 'rb') as f:\n+      path_ = io.BytesIO(f.read())  # io.Bytesio\n+    loaded_im = image.load_img(path_, color_mode='grayscale')\n+    loaded_im_array = image.img_to_array(loaded_im, dtype=np.int32)\n+    self.assertAllClose(loaded_im_array, original_grayscale_32bit_array)\n+\n+    path_ = filename_grayscale_32bit  # str\n+    loaded_im = image.load_img(path_, color_mode='grayscale')\n+    loaded_im_array = image.img_to_array(loaded_im, dtype=np.int32)\n+    self.assertAllClose(loaded_im_array, original_grayscale_32bit_array)\n+\n+    path_ = filename_grayscale_32bit.encode()  # bytes\n+    loaded_im = image.load_img(path_, color_mode='grayscale')\n+    loaded_im_array = image.img_to_array(loaded_im, dtype=np.int32)\n+    self.assertAllClose(loaded_im_array, original_grayscale_32bit_array)\n+\n+    path_ = pathlib.Path(\n+        os.path.join(tmpdir.full_path, 'grayscale_32bit_utils.tiff'))\n+    loaded_im = image.load_img(path_, color_mode='grayscale')\n+    loaded_im_array = image.img_to_array(loaded_im, dtype=np.int32)\n+    self.assertAllClose(loaded_im_array, original_grayscale_32bit_array)\n+\n+    # Check that exception is raised if interpolation not supported.\n+\n+    loaded_im = image.load_img(filename_rgb, interpolation='unsupported')\n+    with self.assertRaises(ValueError):\n+      loaded_im = image.load_img(\n+          filename_rgb, target_size=(25, 25), interpolation='unsupported')\n+\n+    # Check that the aspect ratio of a square is the same\n+\n+    filename_red_square = os.path.join(tmpdir.full_path, 'red_square_utils.png')\n+    arr = np.zeros((50, 100, 3), dtype=np.uint8)  # rectangle image 100x50\n+    arr[20:30, 45:55, 0] = 255  # red square 10x10\n+    red_square_array = np.array(arr)\n+    red_square = image.array_to_img(red_square_array, scale=False)\n+    red_square.save(filename_red_square)\n+\n+    loaded_im = image.load_img(\n+        filename_red_square, target_size=(25, 25), keep_aspect_ratio=True)\n+    loaded_im_array = image.img_to_array(loaded_im)\n+    self.assertEqual(loaded_im_array.shape, (25, 25, 3))\n+\n+    red_channel_arr = loaded_im_array[:, :, 0].astype(np.bool)\n+    square_width = np.sum(np.sum(red_channel_arr, axis=0))\n+    square_height = np.sum(np.sum(red_channel_arr, axis=1))\n+    aspect_ratio_result = square_width / square_height\n+\n+    # original square had 1:1 ratio\n+    self.assertNear(aspect_ratio_result, 1.0, 0.01)\n+\n+  def test_array_to_img_and_img_to_array(self):\n+    height, width = 10, 8\n+\n+    # Test the data format\n+    # Test RGB 3D\n+    x = np.random.random((3, height, width))\n+    img = image.array_to_img(x, data_format='channels_first')\n+    self.assertEqual(img.size, (width, height))\n+\n+    x = image.img_to_array(img, data_format='channels_first')\n+    self.assertEqual(x.shape, (3, height, width))\n+\n+    # Test RGBA 3D\n+    x = np.random.random((4, height, width))\n+    img = image.array_to_img(x, data_format='channels_first')\n+    self.assertEqual(img.size, (width, height))\n+\n+    x = image.img_to_array(img, data_format='channels_first')\n+    self.assertEqual(x.shape, (4, height, width))\n+\n+    # Test 2D\n+    x = np.random.random((1, height, width))\n+    img = image.array_to_img(x, data_format='channels_first')\n+    self.assertEqual(img.size, (width, height))\n+\n+    x = image.img_to_array(img, data_format='channels_first')\n+    self.assertEqual(x.shape, (1, height, width))\n+\n+    # grayscale 32-bit signed integer\n+    x = np.array(\n+        np.random.randint(-2147483648, 2147483647, (1, height, width)),\n+        dtype=np.int32)\n+    img = image.array_to_img(x, data_format='channels_first')\n+    self.assertEqual(img.size, (width, height))\n+\n+    x = image.img_to_array(img, data_format='channels_first')\n+    self.assertEqual(x.shape, (1, height, width))\n+\n+    # Test tf data format\n+    # Test RGB 3D\n+    x = np.random.random((height, width, 3))\n+    img = image.array_to_img(x, data_format='channels_last')\n+    self.assertEqual(img.size, (width, height))\n+\n+    x = image.img_to_array(img, data_format='channels_last')\n+    self.assertEqual(x.shape, (height, width, 3))\n+\n+    # Test RGBA 3D\n+    x = np.random.random((height, width, 4))\n+    img = image.array_to_img(x, data_format='channels_last')\n+    self.assertEqual(img.size, (width, height))\n+\n+    x = image.img_to_array(img, data_format='channels_last')\n+    self.assertEqual(x.shape, (height, width, 4))\n+\n+    # Test 2D\n+    x = np.random.random((height, width, 1))\n+    img = image.array_to_img(x, data_format='channels_last')\n+    self.assertEqual(img.size, (width, height))\n+\n+    x = image.img_to_array(img, data_format='channels_last')\n+    self.assertEqual(x.shape, (height, width, 1))\n+\n+    # grayscale 16-bit signed integer\n+    x = np.array(\n+        np.random.randint(-2147483648, 2147483647, (height, width, 1)),\n+        dtype=np.int16)\n+    img = image.array_to_img(x, data_format='channels_last')\n+    self.assertEqual(img.size, (width, height))\n+\n+    x = image.img_to_array(img, data_format='channels_last')\n+    self.assertEqual(x.shape, (height, width, 1))\n+\n+    # grayscale 32-bit signed integer\n+    x = np.array(\n+        np.random.randint(-2147483648, 2147483647, (height, width, 1)),\n+        dtype=np.int32)\n+    img = image.array_to_img(x, data_format='channels_last')\n+    self.assertEqual(img.size, (width, height))\n+\n+    x = image.img_to_array(img, data_format='channels_last')\n+    self.assertEqual(x.shape, (height, width, 1))\n+\n+    # Test invalid use case\n+    with self.assertRaises(ValueError):\n+      x = np.random.random((height, width))  # not 3D\n+      img = image.array_to_img(x, data_format='channels_first')\n+\n+    with self.assertRaises(ValueError):\n+      x = np.random.random((height, width, 3))\n+      # unknown data_format\n+      img = image.array_to_img(x, data_format='channels')\n+\n+    with self.assertRaises(ValueError):\n+      # neither RGB, RGBA, or gray-scale\n+      x = np.random.random((height, width, 5))\n+      img = image.array_to_img(x, data_format='channels_last')\n+\n+    with self.assertRaises(ValueError):\n+      x = np.random.random((height, width, 3))\n+      # unknown data_format\n+      img = image.img_to_array(x, data_format='channels')\n+\n+    with self.assertRaises(ValueError):\n+      # neither RGB, RGBA, or gray-scale\n+      x = np.random.random((height, width, 5, 3))\n+      img = image.img_to_array(x, data_format='channels_last')\n+\n+\n+@test_utils.run_v2_only\n+class TestDirectoryIterator(test_combinations.TestCase):\n+\n+  def test_directory_iterator(self):\n+    tmpdir = self.create_tempdir()\n+    all_test_images = _generate_test_images(\n+        include_rgba=True, include_16bit=True, include_32bit=True)\n+    num_classes = 2\n+\n+    # create folders and subfolders\n+    paths = []\n+    for cl in range(num_classes):\n+      class_directory = 'class-{}'.format(cl)\n+      classpaths = [\n+          class_directory,\n+          os.path.join(class_directory, 'subfolder-1'),\n+          os.path.join(class_directory, 'subfolder-2'),\n+          os.path.join(class_directory, 'subfolder-1', 'sub-subfolder')\n+      ]\n+      for path in classpaths:\n+        os.mkdir(os.path.join(tmpdir.full_path, path))\n+      paths.append(classpaths)\n+\n+    # save the images in the paths\n+    count = 0\n+    filenames = []\n+    for test_images in all_test_images:\n+      for im in test_images:\n+        # rotate image class\n+        im_class = count % num_classes\n+        # rotate subfolders\n+        classpaths = paths[im_class]\n+        filename = os.path.join(classpaths[count % len(classpaths)],\n+                                'image-{}.png'.format(count))\n+        filenames.append(filename)\n+        im.save(os.path.join(tmpdir.full_path, filename))\n+        count += 1\n+\n+    # create iterator\n+    generator = image.ImageDataGenerator()\n+    dir_iterator = generator.flow_from_directory(tmpdir.full_path)\n+\n+    # check number of classes and images\n+    self.assertLen(dir_iterator.class_indices, num_classes)\n+    self.assertLen(dir_iterator.classes, count)\n+    self.assertEqual(set(dir_iterator.filenames), set(filenames))\n+\n+    # Test invalid use cases\n+    with self.assertRaises(ValueError):\n+      generator.flow_from_directory(tmpdir.full_path, color_mode='cmyk')\n+    with self.assertRaises(ValueError):\n+      generator.flow_from_directory(tmpdir.full_path, class_mode='output')\n+\n+    def preprocessing_function(x):\n+      # This will fail if not provided by a Numpy array.\n+      # Note: This is made to enforce backward compatibility.\n+      self.assertEqual(x.shape, (26, 26, 3))\n+      self.assertIsInstance(x, np.ndarray)\n+\n+      return np.zeros_like(x)\n+\n+    # Test usage as Sequence\n+    generator = image.ImageDataGenerator(\n+        preprocessing_function=preprocessing_function)\n+    dir_seq = generator.flow_from_directory(\n+        tmpdir.full_path,\n+        target_size=(26, 26),\n+        color_mode='rgb',\n+        batch_size=3,\n+        class_mode='categorical')\n+    self.assertLen(dir_seq, np.ceil(count / 3.))\n+    x1, y1 = dir_seq[1]\n+    self.assertEqual(x1.shape, (3, 26, 26, 3))\n+    self.assertEqual(y1.shape, (3, num_classes))\n+    x1, y1 = dir_seq[5]\n+    self.assertTrue((x1 == 0).all())\n+\n+    with self.assertRaises(ValueError):\n+      x1, y1 = dir_seq[14]  # there are 40 images and batch size is 3\n+\n+  def test_directory_iterator_class_mode_input(self):\n+    tmpdir = self.create_tempdir()\n+    os.mkdir(os.path.join(tmpdir.full_path, 'class-1'))\n+    all_test_images = _generate_test_images(\n+        include_rgba=True, include_16bit=True, include_32bit=True)\n+\n+    # save the images in the paths\n+    count = 0\n+    for test_images in all_test_images:\n+      for im in test_images:\n+        filename = os.path.join(tmpdir, 'class-1', 'image-{}.png'.format(count))\n+        im.save(filename)\n+        count += 1\n+\n+    # create iterator\n+    generator = image.ImageDataGenerator()\n+    dir_iterator = generator.flow_from_directory(\n+        tmpdir.full_path, class_mode='input')\n+    batch = next(dir_iterator)\n+\n+    # check if input and output have the same shape\n+    self.assertEqual(batch[0].shape, batch[1].shape)\n+    # check if the input and output images are not the same numpy array\n+    input_img = batch[0][0]\n+    output_img = batch[1][0]\n+    output_img[0][0][0] += 1\n+    self.assertNotEqual(input_img[0][0][0], output_img[0][0][0])\n+\n+  @parameterized.parameters([\n+      (0.25, 30),\n+      (0.50, 20),\n+      (0.75, 10),\n+  ])\n+  def test_directory_iterator_with_validation_split(self, validation_split,\n+                                                    num_training):\n+    tmpdir = self.create_tempdir()\n+    all_test_images = _generate_test_images(\n+        include_rgba=True, include_16bit=True, include_32bit=True)\n+    num_classes = 2\n+\n+    # create folders and subfolders\n+    paths = []\n+    for cl in range(num_classes):\n+      class_directory = 'class-{}'.format(cl)\n+      classpaths = [\n+          class_directory,\n+          os.path.join(class_directory, 'subfolder-1'),\n+          os.path.join(class_directory, 'subfolder-2'),\n+          os.path.join(class_directory, 'subfolder-1', 'sub-subfolder')\n+      ]\n+      for path in classpaths:\n+        os.mkdir(os.path.join(tmpdir.full_path, path))\n+      paths.append(classpaths)\n+\n+    # save the images in the paths\n+    count = 0\n+    filenames = []\n+    for test_images in all_test_images:\n+      for im in test_images:\n+        # rotate image class\n+        im_class = count % num_classes\n+        # rotate subfolders\n+        classpaths = paths[im_class]\n+        filename = os.path.join(classpaths[count % len(classpaths)],\n+                                'image-{}.png'.format(count))\n+        filenames.append(filename)\n+        im.save(os.path.join(tmpdir.full_path, filename))\n+        count += 1\n+\n+    # create iterator\n+    generator = image.ImageDataGenerator(validation_split=validation_split)\n+\n+    with self.assertRaises(ValueError):\n+      generator.flow_from_directory(tmpdir.full_path, subset='foo')\n+\n+    train_iterator = generator.flow_from_directory(\n+        tmpdir.full_path, subset='training')\n+    self.assertEqual(train_iterator.samples, num_training)\n+\n+    valid_iterator = generator.flow_from_directory(\n+        tmpdir.full_path, subset='validation')\n+    self.assertEqual(valid_iterator.samples, count - num_training)\n+\n+    # check number of classes and images\n+    self.assertLen(train_iterator.class_indices, num_classes)\n+    self.assertLen(train_iterator.classes, num_training)\n+    self.assertLen(set(train_iterator.filenames) & set(filenames), num_training)\n+\n+\n+@test_utils.run_v2_only\n+class TestNumpyArrayIterator(test_combinations.TestCase):\n+\n+  def test_numpy_array_iterator(self):\n+    tmpdir = self.create_tempdir()\n+    all_test_images = _generate_test_images(include_rgba=True)\n+\n+    image_data_generator = image.ImageDataGenerator(\n+        featurewise_center=True,\n+        samplewise_center=True,\n+        featurewise_std_normalization=True,\n+        samplewise_std_normalization=True,\n+        zca_whitening=True,\n+        rotation_range=90.,\n+        width_shift_range=0.1,\n+        height_shift_range=0.1,\n+        shear_range=0.5,\n+        zoom_range=0.2,\n+        channel_shift_range=0.,\n+        brightness_range=(1, 5),\n+        fill_mode='nearest',\n+        cval=0.5,\n+        horizontal_flip=True,\n+        vertical_flip=True,\n+        interpolation_order=1)\n+\n+    for test_images in all_test_images:\n+      img_list = []\n+      for im in test_images:\n+        img_list.append(image.img_to_array(im)[None, ...])\n+      images = np.vstack(img_list)\n+      dsize = images.shape[0]\n+\n+      iterator = image.NumpyArrayIterator(\n+          images,\n+          np.arange(images.shape[0]),\n+          image_data_generator,\n+          shuffle=False,\n+          save_to_dir=tmpdir.full_path,\n+          batch_size=3)\n+      x, y = next(iterator)\n+      self.assertEqual(x.shape, images[:3].shape)\n+      self.assertEqual(list(y), [0, 1, 2])\n+\n+      # Test with sample weights\n+      iterator = image.NumpyArrayIterator(\n+          images,\n+          np.arange(images.shape[0]),\n+          image_data_generator,\n+          shuffle=False,\n+          sample_weight=np.arange(images.shape[0]) + 1,\n+          save_to_dir=tmpdir.full_path,\n+          batch_size=3)\n+      x, y, w = iterator.next()\n+      self.assertEqual(x.shape, images[:3].shape)\n+      self.assertEqual(list(y), [0, 1, 2])\n+      self.assertEqual(list(w), [1, 2, 3])\n+\n+      # Test with `shuffle=True`\n+      iterator = image.NumpyArrayIterator(\n+          images,\n+          np.arange(images.shape[0]),\n+          image_data_generator,\n+          shuffle=True,\n+          save_to_dir=tmpdir.full_path,\n+          batch_size=3,\n+          seed=42)\n+      x, y = iterator.next()\n+      self.assertEqual(x.shape, images[:3].shape)\n+      # Check that the sequence is shuffled.\n+      self.assertNotEqual(list(y), [0, 1, 2])\n+\n+      # Test without y\n+      iterator = image.NumpyArrayIterator(\n+          images,\n+          None,\n+          image_data_generator,\n+          shuffle=True,\n+          save_to_dir=tmpdir.full_path,\n+          batch_size=3)\n+      x = iterator.next()\n+      self.assertIsInstance(x, np.ndarray)\n+      self.assertEqual(x.shape, images[:3].shape)\n+\n+      # Test with a single miscellaneous input data array\n+      x_misc1 = np.random.random(dsize)\n+      iterator = image.NumpyArrayIterator((images, x_misc1),\n+                                          np.arange(dsize),\n+                                          image_data_generator,\n+                                          shuffle=False,\n+                                          batch_size=2)\n+      for i, (x, y) in enumerate(iterator):\n+        self.assertEqual(x[0].shape, images[:2].shape)\n+        self.assertTrue((x[1] == x_misc1[(i * 2):((i + 1) * 2)]).all())\n+        if i == 2:\n+          break\n+\n+      # Test with two miscellaneous inputs\n+      x_misc2 = np.random.random((dsize, 3, 3))\n+      iterator = image.NumpyArrayIterator((images, [x_misc1, x_misc2]),\n+                                          np.arange(dsize),\n+                                          image_data_generator,\n+                                          shuffle=False,\n+                                          batch_size=2)\n+      for i, (x, y) in enumerate(iterator):\n+        self.assertEqual(x[0].shape, images[:2].shape)\n+        self.assertTrue((x[1] == x_misc1[(i * 2):((i + 1) * 2)]).all())\n+        self.assertTrue((x[2] == x_misc2[(i * 2):((i + 1) * 2)]).all())\n+        if i == 2:\n+          break\n+\n+      # Test cases with `y = None`\n+      iterator = image.NumpyArrayIterator(\n+          images, None, image_data_generator, batch_size=3)\n+      x = iterator.next()\n+      self.assertIsInstance(x, np.ndarray)\n+      self.assertEqual(x.shape, images[:3].shape)\n+\n+      iterator = image.NumpyArrayIterator((images, x_misc1),\n+                                          None,\n+                                          image_data_generator,\n+                                          batch_size=3,\n+                                          shuffle=False)\n+      x = iterator.next()\n+      self.assertIsInstance(x, list)\n+      self.assertEqual(x[0].shape, images[:3].shape)\n+      self.assertTrue((x[1] == x_misc1[:3]).all())\n+\n+      iterator = image.NumpyArrayIterator((images, [x_misc1, x_misc2]),\n+                                          None,\n+                                          image_data_generator,\n+                                          batch_size=3,\n+                                          shuffle=False)\n+      x = iterator.next()\n+      self.assertIsInstance(x, list)\n+      self.assertEqual(x[0].shape, images[:3].shape)\n+      self.assertTrue((x[1] == x_misc1[:3]).all())\n+      self.assertTrue((x[2] == x_misc2[:3]).all())\n+\n+      # Test with validation split\n+      generator = image.ImageDataGenerator(validation_split=0.2)\n+      iterator = image.NumpyArrayIterator(images, None, generator, batch_size=3)\n+      x = iterator.next()\n+      self.assertIsInstance(x, np.ndarray)\n+      self.assertEqual(x.shape, images[:3].shape)\n+\n+      # Test some failure cases:\n+      x_misc_err = np.random.random((dsize + 1, 3, 3))\n+\n+      with self.assertRaisesRegex(ValueError, 'All of the arrays in'):\n+        image.NumpyArrayIterator((images, x_misc_err),\n+                                 np.arange(dsize),\n+                                 generator,\n+                                 batch_size=3)\n+\n+      with self.assertRaisesRegex(ValueError,\n+                                  r'`x` \\(images tensor\\) and `y` \\(labels\\)'):\n+        image.NumpyArrayIterator((images, x_misc1),\n+                                 np.arange(dsize + 1),\n+                                 generator,\n+                                 batch_size=3)\n+\n+      # Test `flow` behavior as Sequence\n+      seq = image.NumpyArrayIterator(\n+          images,\n+          np.arange(images.shape[0]),\n+          generator,\n+          shuffle=False,\n+          save_to_dir=tmpdir.full_path,\n+          batch_size=3)\n+      self.assertLen(seq, images.shape[0] // 3 + 1)\n+      x, y = seq[0]\n+      self.assertEqual(x.shape, images[:3].shape)\n+      self.assertEqual(list(y), [0, 1, 2])\n+\n+      # Test with `shuffle=True`\n+      seq = image.NumpyArrayIterator(\n+          images,\n+          np.arange(images.shape[0]),\n+          generator,\n+          shuffle=True,\n+          save_to_dir=tmpdir.full_path,\n+          batch_size=3,\n+          seed=123)\n+      x, y = seq[0]\n+      # Check that the sequence is shuffled.\n+      self.assertNotEqual(list(y), [0, 1, 2])\n+      # `on_epoch_end` should reshuffle the sequence.\n+      seq.on_epoch_end()\n+      _, y2 = seq[0]\n+      self.assertNotEqual(list(y), list(y2))\n+\n+    # test order_interpolation\n+    labels = np.array([[2, 2, 0, 2, 2], [1, 3, 2, 3, 1], [2, 1, 0, 1, 2],\n+                       [3, 1, 0, 2, 0], [3, 1, 3, 2, 1]])\n+    label_generator = image.ImageDataGenerator(\n+        rotation_range=90., interpolation_order=0)\n+    labels_gen = image.NumpyArrayIterator(\n+        labels[np.newaxis, ..., np.newaxis], None, label_generator, seed=123)\n+    self.assertTrue((np.unique(labels) == np.unique(next(labels_gen))).all())\n+\n+\n+@test_utils.run_v2_only\n+class TestDataFrameIterator(test_combinations.TestCase):\n+\n+  def test_dataframe_iterator(self):\n+    tmpdir = self.create_tempdir()\n+    all_test_images = _generate_test_images(include_rgba=True)\n+    num_classes = 2\n+\n+    # save the images in the tmpdir\n+    count = 0\n+    filenames = []\n+    filepaths = []\n+    filenames_without = []\n+    for test_images in all_test_images:\n+      for im in test_images:\n+        filename = 'image-{}.png'.format(count)\n+        filename_without = 'image-{}'.format(count)\n+        filenames.append(filename)\n+        filepaths.append(os.path.join(tmpdir.full_path, filename))\n+        filenames_without.append(filename_without)\n+        im.save(os.path.join(tmpdir.full_path, filename))\n+        count += 1\n+\n+    df = pd.DataFrame({\n+        'filename': filenames,\n+        'class': [str(random.randint(0, 1)) for _ in filenames],\n+        'filepaths': filepaths\n+    })\n+\n+    # create iterator\n+    iterator = image.DataFrameIterator(df, tmpdir.full_path)\n+    batch = next(iterator)\n+    self.assertLen(batch, 2)\n+    self.assertIsInstance(batch[0], np.ndarray)\n+    self.assertIsInstance(batch[1], np.ndarray)\n+    generator = image.ImageDataGenerator()\n+    df_iterator = generator.flow_from_dataframe(df, x_col='filepaths')\n+    df_iterator_dir = generator.flow_from_dataframe(df, tmpdir.full_path)\n+    df_sparse_iterator = generator.flow_from_dataframe(\n+        df, tmpdir.full_path, class_mode='sparse')\n+    self.assertFalse(np.isnan(df_sparse_iterator.classes).any())\n+    # check number of classes and images\n+    self.assertLen(df_iterator.class_indices, num_classes)\n+    self.assertLen(df_iterator.classes, count)\n+    self.assertEqual(set(df_iterator.filenames), set(filepaths))\n+    self.assertLen(df_iterator_dir.class_indices, num_classes)\n+    self.assertLen(df_iterator_dir.classes, count)\n+    self.assertEqual(set(df_iterator_dir.filenames), set(filenames))\n+    # test without shuffle\n+    _, batch_y = next(\n+        generator.flow_from_dataframe(\n+            df, tmpdir.full_path, shuffle=False, class_mode='sparse'))\n+    self.assertTrue(\n+        (batch_y == df['class'].astype('float')[:len(batch_y)]).all())\n+    # Test invalid use cases\n+    with self.assertRaises(ValueError):\n+      generator.flow_from_dataframe(df, tmpdir.full_path, color_mode='cmyk')\n+    with self.assertRaises(ValueError):\n+      generator.flow_from_dataframe(df, tmpdir.full_path, class_mode='output')\n+    with self.assertWarns(DeprecationWarning):\n+      generator.flow_from_dataframe(df, tmpdir.full_path, has_ext=True)\n+    with self.assertWarns(DeprecationWarning):\n+      generator.flow_from_dataframe(df, tmpdir.full_path, has_ext=False)\n+\n+    def preprocessing_function(x):\n+      # This will fail if not provided by a Numpy array.\n+      # Note: This is made to enforce backward compatibility.\n+\n+      self.assertEqual(x.shape, (26, 26, 3))\n+      self.assertIsInstance(x, np.ndarray)\n+\n+      return np.zeros_like(x)\n+\n+    # Test usage as Sequence\n+    generator = image.ImageDataGenerator(\n+        preprocessing_function=preprocessing_function)\n+    dir_seq = generator.flow_from_dataframe(\n+        df,\n+        tmpdir.full_path,\n+        target_size=(26, 26),\n+        color_mode='rgb',\n+        batch_size=3,\n+        class_mode='categorical')\n+    self.assertLen(dir_seq, np.ceil(count / 3))\n+    x1, y1 = dir_seq[1]\n+    self.assertEqual(x1.shape, (3, 26, 26, 3))\n+    self.assertEqual(y1.shape, (3, num_classes))\n+    x1, y1 = dir_seq[5]\n+    self.assertTrue((x1 == 0).all())\n+\n+    with self.assertRaises(ValueError):\n+      x1, y1 = dir_seq[9]\n+\n+  def test_dataframe_iterator_validate_filenames(self):\n+    tmpdir = self.create_tempdir()\n+    all_test_images = _generate_test_images(include_rgba=True)\n+    # save the images in the paths\n+    count = 0\n+    filenames = []\n+    for test_images in all_test_images:\n+      for im in test_images:\n+        filename = 'image-{}.png'.format(count)\n+        im.save(os.path.join(tmpdir.full_path, filename))\n+        filenames.append(filename)\n+        count += 1\n+    df = pd.DataFrame({'filename': filenames + ['test.jpp', 'test.jpg']})\n+    generator = image.ImageDataGenerator()\n+    df_iterator = generator.flow_from_dataframe(\n+        df, tmpdir.full_path, class_mode='input')\n+    self.assertLen(df_iterator.filenames, len(df['filename']) - 2)\n+    df_iterator = generator.flow_from_dataframe(\n+        df, tmpdir.full_path, class_mode='input', validate_filenames=False)\n+    self.assertLen(df_iterator.filenames, len(df['filename']))\n+\n+  def test_dataframe_iterator_sample_weights(self):\n+    tmpdir = self.create_tempdir()\n+    all_test_images = _generate_test_images(include_rgba=True)\n+    # save the images in the paths\n+    count = 0\n+    filenames = []\n+    for test_images in all_test_images:\n+      for im in test_images:\n+        filename = 'image-{}.png'.format(count)\n+        im.save(os.path.join(tmpdir.full_path, filename))\n+        filenames.append(filename)\n+        count += 1\n+    df = pd.DataFrame({'filename': filenames})\n+    df['weight'] = ([2, 5] * len(df))[:len(df)]\n+    generator = image.ImageDataGenerator()\n+    df_iterator = generator.flow_from_dataframe(\n+        df,\n+        tmpdir.full_path,\n+        x_col='filename',\n+        y_col=None,\n+        shuffle=False,\n+        batch_size=5,\n+        weight_col='weight',\n+        class_mode='input')\n+\n+    batch = next(df_iterator)\n+    self.assertLen(batch, 3)  # (x, y, weights)\n+    # check if input and output have the same shape and they're the same\n+    self.assertEqual(batch[0].all(), batch[1].all())\n+    # check if the input and output images are not the same numpy array\n+    input_img = batch[0][0]\n+    output_img = batch[1][0]\n+    output_img[0][0][0] += 1\n+    self.assertNotEqual(input_img[0][0][0], output_img[0][0][0])\n+    self.assertAllEqual(np.array([2, 5, 2, 5, 2]), batch[2])\n+\n+    # fail\n+    df['weight'] = (['2', '5'] * len(df))[:len(df)]\n+    with self.assertRaises(TypeError):\n+      image.ImageDataGenerator().flow_from_dataframe(\n+          df, weight_col='weight', class_mode='input')\n+\n+  def test_dataframe_iterator_class_mode_input(self):\n+    tmpdir = self.create_tempdir()\n+    all_test_images = _generate_test_images(include_rgba=True)\n+    # save the images in the paths\n+    count = 0\n+    filenames = []\n+    for test_images in all_test_images:\n+      for im in test_images:\n+        filename = 'image-{}.png'.format(count)\n+        im.save(os.path.join(tmpdir.full_path, filename))\n+        filenames.append(filename)\n+        count += 1\n+    df = pd.DataFrame({'filename': filenames})\n+    generator = image.ImageDataGenerator()\n+    df_autoencoder_iterator = generator.flow_from_dataframe(\n+        df, tmpdir.full_path, x_col='filename', y_col=None, class_mode='input')\n+\n+    batch = next(df_autoencoder_iterator)\n+\n+    # check if input and output have the same shape and they're the same\n+    self.assertAllClose(batch[0], batch[1])\n+    # check if the input and output images are not the same numpy array\n+    input_img = batch[0][0]\n+    output_img = batch[1][0]\n+    output_img[0][0][0] += 1\n+    self.assertNotEqual(input_img[0][0][0], output_img[0][0][0])\n+\n+    df_autoencoder_iterator = generator.flow_from_dataframe(\n+        df,\n+        tmpdir.full_path,\n+        x_col='filename',\n+        y_col='class',\n+        class_mode='input')\n+\n+    batch = next(df_autoencoder_iterator)\n+\n+    # check if input and output have the same shape and they're the same\n+    self.assertEqual(batch[0].all(), batch[1].all())\n+    # check if the input and output images are not the same numpy array\n+    input_img = batch[0][0]\n+    output_img = batch[1][0]\n+    output_img[0][0][0] += 1\n+    self.assertNotEqual(input_img[0][0][0], output_img[0][0][0])\n+\n+  def test_dataframe_iterator_class_mode_categorical_multi_label(self):\n+    tmpdir = self.create_tempdir()\n+    all_test_images = _generate_test_images(include_rgba=True)\n+    # save the images in the paths\n+    filenames = []\n+    count = 0\n+    for test_images in all_test_images:\n+      for im in test_images:\n+        filename = 'image-{}.png'.format(count)\n+        im.save(os.path.join(tmpdir.full_path, filename))\n+        filenames.append(filename)\n+        count += 1\n+    label_opt = ['a', 'b', ['a'], ['b'], ['a', 'b'], ['b', 'a']]\n+    df = pd.DataFrame({\n+        'filename': filenames,\n+        'class': [random.choice(label_opt) for _ in filenames[:-2]] +\n+                 ['b', 'a']\n+    })\n+    generator = image.ImageDataGenerator()\n+    df_iterator = generator.flow_from_dataframe(df, tmpdir.full_path)\n+    batch_x, batch_y = next(df_iterator)\n+    self.assertIsInstance(batch_x, np.ndarray)\n+    self.assertLen(batch_x.shape, 4)\n+    self.assertIsInstance(batch_y, np.ndarray)\n+    self.assertEqual(batch_y.shape, (len(batch_x), 2))\n+    for labels in batch_y:\n+      self.assertTrue(all(label in {0, 1} for label in labels))\n+\n+    # on first 3 batches\n+    df = pd.DataFrame({\n+        'filename':\n+            filenames,\n+        'class': [['b', 'a']] + ['b'] + [['c']] +\n+                 [random.choice(label_opt) for _ in filenames[:-3]]\n+    })\n+    generator = image.ImageDataGenerator()\n+    df_iterator = generator.flow_from_dataframe(\n+        df, tmpdir.full_path, shuffle=False)\n+    batch_x, batch_y = next(df_iterator)\n+    self.assertIsInstance(batch_x, np.ndarray)\n+    self.assertLen(batch_x.shape, 4)\n+    self.assertIsInstance(batch_y, np.ndarray)\n+    self.assertEqual(batch_y.shape, (len(batch_x), 3))\n+    for labels in batch_y:\n+      self.assertTrue(all(label in {0, 1} for label in labels))\n+    self.assertTrue((batch_y[0] == np.array([1, 1, 0])).all())\n+    self.assertTrue((batch_y[1] == np.array([0, 1, 0])).all())\n+    self.assertTrue((batch_y[2] == np.array([0, 0, 1])).all())\n+\n+  def test_dataframe_iterator_class_mode_multi_output(self):\n+    tmpdir = self.create_tempdir()\n+    all_test_images = _generate_test_images(include_rgba=True)\n+    # save the images in the paths\n+    filenames = []\n+    count = 0\n+    for test_images in all_test_images:\n+      for im in test_images:\n+        filename = 'image-{}.png'.format(count)\n+        im.save(os.path.join(tmpdir.full_path, filename))\n+        filenames.append(filename)\n+        count += 1\n+    # fit both outputs are a single number\n+    df = pd.DataFrame({\n+        'filename': filenames\n+    }).assign(\n+        output_0=np.random.uniform(size=len(filenames)),\n+        output_1=np.random.uniform(size=len(filenames)))\n+    df_iterator = image.ImageDataGenerator().flow_from_dataframe(\n+        df,\n+        y_col=['output_0', 'output_1'],\n+        directory=tmpdir.full_path,\n+        batch_size=3,\n+        shuffle=False,\n+        class_mode='multi_output')\n+    batch_x, batch_y = next(df_iterator)\n+    self.assertIsInstance(batch_x, np.ndarray)\n+    self.assertLen(batch_x.shape, 4)\n+    self.assertIsInstance(batch_y, list)\n+    self.assertLen(batch_y, 2)\n+    self.assertAllEqual(batch_y[0], np.array(df['output_0'].tolist()[:3]))\n+    self.assertAllEqual(batch_y[1], np.array(df['output_1'].tolist()[:3]))\n+    # if one of the outputs is a 1D array\n+    df['output_1'] = [\n+        np.random.uniform(size=(2, 2, 1)).flatten() for _ in range(len(df))\n+    ]\n+    df_iterator = image.ImageDataGenerator().flow_from_dataframe(\n+        df,\n+        y_col=['output_0', 'output_1'],\n+        directory=tmpdir.full_path,\n+        batch_size=3,\n+        shuffle=False,\n+        class_mode='multi_output')\n+    batch_x, batch_y = next(df_iterator)\n+    self.assertIsInstance(batch_x, np.ndarray)\n+    self.assertLen(batch_x.shape, 4)\n+    self.assertIsInstance(batch_y, list)\n+    self.assertLen(batch_y, 2)\n+    self.assertAllEqual(batch_y[0], np.array(df['output_0'].tolist()[:3]))\n+    self.assertAllEqual(batch_y[1], np.array(df['output_1'].tolist()[:3]))\n+    # if one of the outputs is a 2D array\n+    df['output_1'] = [np.random.uniform(size=(2, 2, 1)) for _ in range(len(df))]\n+    df_iterator = image.ImageDataGenerator().flow_from_dataframe(\n+        df,\n+        y_col=['output_0', 'output_1'],\n+        directory=tmpdir.full_path,\n+        batch_size=3,\n+        shuffle=False,\n+        class_mode='multi_output')\n+    batch_x, batch_y = next(df_iterator)\n+    self.assertIsInstance(batch_x, np.ndarray)\n+    self.assertLen(batch_x.shape, 4)\n+    self.assertIsInstance(batch_y, list)\n+    self.assertLen(batch_y, 2)\n+    self.assertAllEqual(batch_y[0], np.array(df['output_0'].tolist()[:3]))\n+    self.assertAllEqual(batch_y[1], np.array(df['output_1'].tolist()[:3]))\n+    # fail if single column\n+    with self.assertRaises(TypeError):\n+      image.ImageDataGenerator().flow_from_dataframe(\n+          df,\n+          y_col='output_0',\n+          directory=tmpdir.full_path,\n+          class_mode='multi_output')\n+\n+  def test_dataframe_iterator_class_mode_raw(self):\n+    tmpdir = self.create_tempdir()\n+    all_test_images = _generate_test_images(include_rgba=True)\n+    # save the images in the paths\n+    filenames = []\n+    count = 0\n+    for test_images in all_test_images:\n+      for im in test_images:\n+        filename = 'image-{}.png'.format(count)\n+        im.save(os.path.join(tmpdir.full_path, filename))\n+        filenames.append(filename)\n+        count += 1\n+    # case for 1D output\n+    df = pd.DataFrame({\n+        'filename': filenames\n+    }).assign(\n+        output_0=np.random.uniform(size=len(filenames)),\n+        output_1=np.random.uniform(size=len(filenames)))\n+    df_iterator = image.ImageDataGenerator().flow_from_dataframe(\n+        df,\n+        y_col='output_0',\n+        directory=tmpdir.full_path,\n+        batch_size=3,\n+        shuffle=False,\n+        class_mode='raw')\n+    batch_x, batch_y = next(df_iterator)\n+    self.assertIsInstance(batch_x, np.ndarray)\n+    self.assertLen(batch_x.shape, 4)\n+    self.assertIsInstance(batch_y, np.ndarray)\n+    self.assertEqual(batch_y.shape, (3,))\n+    self.assertAllEqual(batch_y, df['output_0'].values[:3])\n+    # case with a 2D output\n+    df_iterator = image.ImageDataGenerator().flow_from_dataframe(\n+        df,\n+        y_col=['output_0', 'output_1'],\n+        directory=tmpdir.full_path,\n+        batch_size=3,\n+        shuffle=False,\n+        class_mode='raw')\n+    batch_x, batch_y = next(df_iterator)\n+    self.assertIsInstance(batch_x, np.ndarray)\n+    self.assertLen(batch_x.shape, 4)\n+    self.assertIsInstance(batch_y, np.ndarray)\n+    self.assertEqual(batch_y.shape, (3, 2))\n+    self.assertAllEqual(batch_y, df[['output_0', 'output_1']].values[:3])\n+\n+  @parameterized.parameters([\n+      (0.25, 18),\n+      (0.50, 12),\n+      (0.75, 6),\n+  ])\n+  def test_dataframe_iterator_with_validation_split(self, validation_split,\n+                                                    num_training):\n+    tmpdir = self.create_tempdir()\n+    all_test_images = _generate_test_images(include_rgba=True)\n+    num_classes = 2\n+\n+    # save the images in the tmpdir\n+    count = 0\n+    filenames = []\n+    filenames_without = []\n+    for test_images in all_test_images:\n+      for im in test_images:\n+        filename = 'image-{}.png'.format(count)\n+        filename_without = 'image-{}'.format(count)\n+        filenames.append(filename)\n+        filenames_without.append(filename_without)\n+        im.save(os.path.join(tmpdir.full_path, filename))\n+        count += 1\n+\n+    df = pd.DataFrame({\n+        'filename': filenames,\n+        'class': [str(random.randint(0, 1)) for _ in filenames]\n+    })\n+    # create iterator\n+    generator = image.ImageDataGenerator(validation_split=validation_split)\n+    df_sparse_iterator = generator.flow_from_dataframe(\n+        df, tmpdir.full_path, class_mode='sparse')\n+    if np.isnan(next(df_sparse_iterator)[:][1]).any():\n+      raise ValueError('Invalid values.')\n+\n+    with self.assertRaises(ValueError):\n+      generator.flow_from_dataframe(df, tmpdir.full_path, subset='foo')\n+\n+    train_iterator = generator.flow_from_dataframe(\n+        df, tmpdir.full_path, subset='training')\n+    self.assertEqual(train_iterator.samples, num_training)\n+\n+    valid_iterator = generator.flow_from_dataframe(\n+        df, tmpdir.full_path, subset='validation')\n+    self.assertEqual(valid_iterator.samples, count - num_training)\n+\n+    # check number of classes and images\n+    self.assertLen(train_iterator.class_indices, num_classes)\n+    self.assertLen(train_iterator.classes, num_training)\n+    self.assertLen(set(train_iterator.filenames) & set(filenames), num_training)\n+\n+  def test_dataframe_iterator_with_custom_indexed_dataframe(self):\n+    tmpdir = self.create_tempdir()\n+    all_test_images = _generate_test_images(include_rgba=True)\n+    num_classes = 2\n+\n+    # save the images in the tmpdir\n+    count = 0\n+    filenames = []\n+    for test_images in all_test_images:\n+      for im in test_images:\n+        filename = 'image-{}.png'.format(count)\n+        filenames.append(filename)\n+        im.save(os.path.join(tmpdir.full_path, filename))\n+        count += 1\n+\n+    # create dataframes\n+    classes = np.random.randint(num_classes, size=len(filenames))\n+    classes = [str(c) for c in classes]\n+    df = pd.DataFrame({'filename': filenames, 'class': classes})\n+    df2 = pd.DataFrame({\n+        'filename': filenames,\n+        'class': classes\n+    },\n+                       index=np.arange(1,\n+                                       len(filenames) + 1))\n+    df3 = pd.DataFrame({\n+        'filename': filenames,\n+        'class': classes\n+    },\n+                       index=filenames)\n+\n+    # create iterators\n+    seed = 1\n+    generator = image.ImageDataGenerator()\n+    df_iterator = generator.flow_from_dataframe(df, tmpdir.full_path, seed=seed)\n+    df2_iterator = generator.flow_from_dataframe(\n+        df2, tmpdir.full_path, seed=seed)\n+    df3_iterator = generator.flow_from_dataframe(\n+        df3, tmpdir.full_path, seed=seed)\n+\n+    # Test all iterators return same pairs of arrays\n+    for _ in range(len(filenames)):\n+      a1, c1 = next(df_iterator)\n+      a2, c2 = next(df2_iterator)\n+      a3, c3 = next(df3_iterator)\n+      self.assertAllEqual(a1, a2)\n+      self.assertAllEqual(a1, a3)\n+      self.assertAllEqual(c1, c2)\n+      self.assertAllEqual(c1, c3)\n+\n+  def test_dataframe_iterator_n(self):\n+    tmpdir = self.create_tempdir()\n+    all_test_images = _generate_test_images(include_rgba=True)\n+\n+    # save the images in the tmpdir\n+    count = 0\n+    filenames = []\n+    for test_images in all_test_images:\n+      for im in test_images:\n+        filename = 'image-{}.png'.format(count)\n+        filenames.append(filename)\n+        im.save(os.path.join(tmpdir.full_path, filename))\n+        count += 1\n+\n+    # exclude first two items\n+    n_files = len(filenames)\n+    input_filenames = filenames[2:]\n+\n+    # create dataframes\n+    classes = np.random.randint(2, size=len(input_filenames))\n+    classes = [str(c) for c in classes]\n+    df = pd.DataFrame({'filename': input_filenames})\n+    df2 = pd.DataFrame({'filename': input_filenames, 'class': classes})\n+\n+    # create iterators\n+    generator = image.ImageDataGenerator()\n+    df_iterator = generator.flow_from_dataframe(\n+        df, tmpdir.full_path, class_mode=None)\n+    df2_iterator = generator.flow_from_dataframe(\n+        df2, tmpdir.full_path, class_mode='binary')\n+\n+    # Test the number of items in iterators\n+    self.assertEqual(df_iterator.n, n_files - 2)\n+    self.assertEqual(df2_iterator.n, n_files - 2)\n+\n+  def test_dataframe_iterator_absolute_path(self):\n+    tmpdir = self.create_tempdir()\n+    all_test_images = _generate_test_images(include_rgba=True)\n+\n+    # save the images in the tmpdir\n+    count = 0\n+    file_paths = []\n+    for test_images in all_test_images:\n+      for im in test_images:\n+        filename = 'image-{:0>5}.png'.format(count)\n+        file_path = os.path.join(tmpdir.full_path, filename)\n+        file_paths.append(file_path)\n+        im.save(file_path)\n+        count += 1\n+\n+    # prepare an image with a forbidden extension.\n+    file_path_fbd = os.path.join(tmpdir.full_path, 'image-forbid.fbd')\n+    shutil.copy(file_path, file_path_fbd)\n+\n+    # create dataframes\n+    classes = np.random.randint(2, size=len(file_paths))\n+    classes = [str(c) for c in classes]\n+    df = pd.DataFrame({'filename': file_paths})\n+    df2 = pd.DataFrame({'filename': file_paths, 'class': classes})\n+    df3 = pd.DataFrame({'filename': ['image-not-exist.png'] + file_paths})\n+    df4 = pd.DataFrame({'filename': file_paths + [file_path_fbd]})\n+\n+    # create iterators\n+    generator = image.ImageDataGenerator()\n+    df_iterator = generator.flow_from_dataframe(\n+        df, None, class_mode=None, shuffle=False, batch_size=1)\n+    df2_iterator = generator.flow_from_dataframe(\n+        df2, None, class_mode='binary', shuffle=False, batch_size=1)\n+    df3_iterator = generator.flow_from_dataframe(\n+        df3, None, class_mode=None, shuffle=False, batch_size=1)\n+    df4_iterator = generator.flow_from_dataframe(\n+        df4, None, class_mode=None, shuffle=False, batch_size=1)\n+\n+    validation_split = 0.2\n+    generator_split = image.ImageDataGenerator(\n+        validation_split=validation_split)\n+    df_train_iterator = generator_split.flow_from_dataframe(\n+        df,\n+        None,\n+        class_mode=None,\n+        shuffle=False,\n+        subset='training',\n+        batch_size=1)\n+    df_val_iterator = generator_split.flow_from_dataframe(\n+        df,\n+        None,\n+        class_mode=None,\n+        shuffle=False,\n+        subset='validation',\n+        batch_size=1)\n+\n+    # Test the number of items in iterators\n+    self.assertLen(file_paths, df_iterator.n)\n+    self.assertLen(file_paths, df2_iterator.n)\n+    self.assertLen(file_paths, df3_iterator.n)\n+    self.assertLen(file_paths, df4_iterator.n)\n+    self.assertEqual(df_val_iterator.n, int(validation_split * len(file_paths)))\n+    self.assertLen(file_paths, df_train_iterator.n + df_val_iterator.n)\n+\n+    # Test flow_from_dataframe\n+    for i in range(len(file_paths)):\n+      a1 = next(df_iterator)\n+      a2, _ = next(df2_iterator)\n+      a3 = next(df3_iterator)\n+      a4 = next(df4_iterator)\n+\n+      if i < df_val_iterator.n:\n+        a5 = next(df_val_iterator)\n+      else:\n+        a5 = next(df_train_iterator)\n+\n+      self.assertAllEqual(a1, a2)\n+      self.assertAllEqual(a1, a3)\n+      self.assertAllEqual(a1, a4)\n+      self.assertAllEqual(a1, a5)\n+\n+  def test_dataframe_iterator_with_subdirs(self):\n+    tmpdir = self.create_tempdir()\n+    all_test_images = _generate_test_images(include_rgba=True)\n+    num_classes = 2\n+\n+    # create folders and subfolders\n+    paths = []\n+    for cl in range(num_classes):\n+      class_directory = 'class-{}'.format(cl)\n+      classpaths = [\n+          class_directory,\n+          os.path.join(class_directory, 'subfolder-1'),\n+          os.path.join(class_directory, 'subfolder-2'),\n+          os.path.join(class_directory, 'subfolder-1', 'sub-subfolder')\n+      ]\n+      for path in classpaths:\n+        os.mkdir(os.path.join(tmpdir, path))\n+      paths.append(classpaths)\n+\n+    # save the images in the paths\n+    count = 0\n+    filenames = []\n+    for test_images in all_test_images:\n+      for im in test_images:\n+        # rotate image class\n+        im_class = count % num_classes\n+        # rotate subfolders\n+        classpaths = paths[im_class]\n+        filename = os.path.join(classpaths[count % len(classpaths)],\n+                                'image-{}.png'.format(count))\n+        filenames.append(filename)\n+        im.save(os.path.join(tmpdir.full_path, filename))\n+        count += 1\n+\n+    # create dataframe\n+    classes = np.random.randint(num_classes, size=len(filenames))\n+    classes = [str(c) for c in classes]\n+    df = pd.DataFrame({'filename': filenames, 'class': classes})\n+\n+    # create iterator\n+    generator = image.ImageDataGenerator()\n+    df_iterator = generator.flow_from_dataframe(\n+        df, tmpdir.full_path, class_mode='binary')\n+\n+    # Test the number of items in iterator\n+    self.assertLen(filenames, df_iterator.n)\n+    self.assertEqual(set(df_iterator.filenames), set(filenames))\n+\n+  def test_dataframe_iterator_classes_indices_order(self):\n+    tmpdir = self.create_tempdir()\n+    all_test_images = _generate_test_images(include_rgba=True)\n+    # save the images in the paths\n+    count = 0\n+    filenames = []\n+    for test_images in all_test_images:\n+      for im in test_images:\n+        filename = 'image-{}.png'.format(count)\n+        im.save(os.path.join(tmpdir.full_path, filename))\n+        filenames.append(filename)\n+        count += 1\n+\n+    # Test the class_indices without classes input\n+    generator = image.ImageDataGenerator()\n+    label_opt = ['a', 'b', ['a'], ['b'], ['a', 'b'], ['b', 'a']]\n+    df_f = pd.DataFrame({\n+        'filename': filenames,\n+        'class': ['a', 'b'] +\n+                 [random.choice(label_opt) for _ in filenames[:-2]]\n+    })\n+    flow_forward_iter = generator.flow_from_dataframe(df_f, tmpdir.full_path)\n+    label_rev = ['b', 'a', ['b'], ['a'], ['b', 'a'], ['a', 'b']]\n+    df_r = pd.DataFrame({\n+        'filename': filenames,\n+        'class': ['b', 'a'] +\n+                 [random.choice(label_rev) for _ in filenames[:-2]]\n+    })\n+    flow_backward_iter = generator.flow_from_dataframe(df_r, tmpdir.full_path)\n+\n+    # check class_indices\n+    self.assertEqual(flow_forward_iter.class_indices,\n+                     flow_backward_iter.class_indices)\n+\n+    # Test the class_indices with classes input\n+    generator_2 = image.ImageDataGenerator()\n+    df_f2 = pd.DataFrame([['data/A.jpg', 'A'], ['data/B.jpg', 'B']],\n+                         columns=['filename', 'class'])\n+    flow_forward = generator_2.flow_from_dataframe(df_f2, classes=['A', 'B'])\n+    df_b2 = pd.DataFrame([['data/A.jpg', 'A'], ['data/B.jpg', 'B']],\n+                         columns=['filename', 'class'])\n+    flow_backward = generator_2.flow_from_dataframe(df_b2, classes=['B', 'A'])\n+\n+    # check class_indices\n+    self.assertNotEqual(flow_forward.class_indices, flow_backward.class_indices)\n+\n+\n+@test_utils.run_v2_only\n+class TestImageDataGenerator(test_combinations.TestCase):\n+\n+  def test_image_data_generator(self):\n+    all_test_images = _generate_test_images(include_rgba=True)\n+    for test_images in all_test_images:\n+      img_list = []\n+      for im in test_images:\n+        img_list.append(image.img_to_array(im)[None, ...])\n+\n+      image.ImageDataGenerator(\n+          featurewise_center=True,\n+          samplewise_center=True,\n+          featurewise_std_normalization=True,\n+          samplewise_std_normalization=True,\n+          zca_whitening=True,\n+          rotation_range=90.,\n+          width_shift_range=0.1,\n+          height_shift_range=0.1,\n+          shear_range=0.5,\n+          zoom_range=0.2,\n+          channel_shift_range=0.,\n+          brightness_range=(1, 5),\n+          fill_mode='nearest',\n+          cval=0.5,\n+          horizontal_flip=True,\n+          vertical_flip=True,\n+          interpolation_order=1)\n+\n+  def test_image_data_generator_with_validation_split(self):\n+    all_test_images = _generate_test_images(include_rgba=True)\n+    for test_images in all_test_images:\n+      img_list = []\n+      for im in test_images:\n+        img_list.append(image.img_to_array(im)[None, ...])\n+\n+      images = np.vstack(img_list)\n+      labels = np.concatenate(\n+          [np.zeros((int(len(images) / 2),)),\n+           np.ones((int(len(images) / 2),))])\n+      generator = image.ImageDataGenerator(validation_split=0.5)\n+\n+      # training and validation sets would have different\n+      # number of classes, because labels are sorted\n+      with self.assertRaisesRegex(\n+          ValueError,\n+          'Training and validation subsets have different number of classes'):\n+        generator.flow(\n+            images, labels, shuffle=False, batch_size=10, subset='validation')\n+\n+      # test non categorical labels with validation split\n+      generator.flow(\n+          images,\n+          labels,\n+          shuffle=False,\n+          batch_size=10,\n+          ignore_class_split=True,\n+          subset='validation')\n+\n+      labels = np.concatenate([\n+          np.zeros((int(len(images) / 4),)),\n+          np.ones((int(len(images) / 4),)),\n+          np.zeros((int(len(images) / 4),)),\n+          np.ones((int(len(images) / 4),))\n+      ])\n+\n+      seq = generator.flow(\n+          images, labels, shuffle=False, batch_size=10, subset='validation')\n+\n+      _, y = seq[0]\n+      self.assertLen(np.unique(y), 2)\n+\n+      seq = generator.flow(\n+          images, labels, shuffle=False, batch_size=10, subset='training')\n+      _, y2 = seq[0]\n+      self.assertLen(np.unique(y2), 2)\n+\n+      with self.assertRaises(ValueError):\n+        generator.flow(\n+            images,\n+            np.arange(images.shape[0]),\n+            shuffle=False,\n+            batch_size=3,\n+            subset='foo')\n+\n+  def test_image_data_generator_with_split_value_error(self):\n+    with self.assertRaises(ValueError):\n+      image.ImageDataGenerator(validation_split=5)\n+\n+  def test_image_data_generator_invalid_data(self):\n+    generator = image.ImageDataGenerator(\n+        featurewise_center=True,\n+        samplewise_center=True,\n+        featurewise_std_normalization=True,\n+        samplewise_std_normalization=True,\n+        zca_whitening=True,\n+        data_format='channels_last')\n+    # Test fit with invalid data\n+    with self.assertRaises(ValueError):\n+      x = np.random.random((3, 10, 10))\n+      generator.fit(x)\n+\n+    # Test flow with invalid data\n+    with self.assertRaises(ValueError):\n+      x = np.random.random((32, 10, 10))\n+      generator.flow(np.arange(x.shape[0]))\n+\n+  def test_image_data_generator_fit(self):\n+    generator = image.ImageDataGenerator(\n+        featurewise_center=True,\n+        samplewise_center=True,\n+        featurewise_std_normalization=True,\n+        samplewise_std_normalization=True,\n+        zca_whitening=True,\n+        rotation_range=90.,\n+        width_shift_range=0.1,\n+        height_shift_range=0.1,\n+        shear_range=0.5,\n+        zoom_range=(0.2, 0.2),\n+        channel_shift_range=0.,\n+        brightness_range=(1, 5),\n+        fill_mode='nearest',\n+        cval=0.5,\n+        horizontal_flip=True,\n+        vertical_flip=True,\n+        interpolation_order=1,\n+        data_format='channels_last')\n+    x = np.random.random((32, 10, 10, 3))\n+    generator.fit(x, augment=True)\n+    # Test grayscale\n+    x = np.random.random((32, 10, 10, 1))\n+    generator.fit(x)\n+    # Test RBG\n+    x = np.random.random((32, 10, 10, 3))\n+    generator.fit(x)\n+    # Test more samples than dims\n+    x = np.random.random((32, 4, 4, 1))\n+    generator.fit(x)\n+    generator = image.ImageDataGenerator(\n+        featurewise_center=True,\n+        samplewise_center=True,\n+        featurewise_std_normalization=True,\n+        samplewise_std_normalization=True,\n+        zca_whitening=True,\n+        rotation_range=90.,\n+        width_shift_range=0.1,\n+        height_shift_range=0.1,\n+        shear_range=0.5,\n+        zoom_range=(0.2, 0.2),\n+        channel_shift_range=0.,\n+        brightness_range=(1, 5),\n+        fill_mode='nearest',\n+        cval=0.5,\n+        horizontal_flip=True,\n+        vertical_flip=True,\n+        interpolation_order=1,\n+        data_format='channels_first')\n+    x = np.random.random((32, 10, 10, 3))\n+    generator.fit(x, augment=True)\n+    # Test grayscale\n+    x = np.random.random((32, 1, 10, 10))\n+    generator.fit(x)\n+    # Test RBG\n+    x = np.random.random((32, 3, 10, 10))\n+    generator.fit(x)\n+    # Test more samples than dims\n+    x = np.random.random((32, 1, 4, 4))\n+    generator.fit(x)\n+\n+  def test_image_data_generator_flow(self):\n+    tmpdir = self.create_tempdir()\n+    all_test_images = _generate_test_images(include_rgba=True)\n+    for test_images in all_test_images:\n+      img_list = []\n+      for im in test_images:\n+        img_list.append(image.img_to_array(im)[None, ...])\n+\n+      images = np.vstack(img_list)\n+      dsize = images.shape[0]\n+      generator = image.ImageDataGenerator(\n+          featurewise_center=True,\n+          samplewise_center=True,\n+          featurewise_std_normalization=True,\n+          samplewise_std_normalization=True,\n+          zca_whitening=True,\n+          rotation_range=90.,\n+          width_shift_range=0.1,\n+          height_shift_range=0.1,\n+          shear_range=0.5,\n+          zoom_range=0.2,\n+          channel_shift_range=0.,\n+          brightness_range=(1, 5),\n+          fill_mode='nearest',\n+          cval=0.5,\n+          horizontal_flip=True,\n+          vertical_flip=True,\n+          interpolation_order=1)\n+\n+      generator.flow(\n+          images,\n+          np.arange(images.shape[0]),\n+          shuffle=False,\n+          save_to_dir=tmpdir.full_path,\n+          batch_size=3)\n+\n+      generator.flow(\n+          images,\n+          np.arange(images.shape[0]),\n+          shuffle=False,\n+          sample_weight=np.arange(images.shape[0]) + 1,\n+          save_to_dir=tmpdir.full_path,\n+          batch_size=3)\n+\n+      # Test with `shuffle=True`\n+      generator.flow(\n+          images,\n+          np.arange(images.shape[0]),\n+          shuffle=True,\n+          save_to_dir=tmpdir.full_path,\n+          batch_size=3,\n+          seed=42)\n+\n+      # Test without y\n+      generator.flow(\n+          images,\n+          None,\n+          shuffle=True,\n+          save_to_dir=tmpdir.full_path,\n+          batch_size=3)\n+\n+      # Test with a single miscellaneous input data array\n+      x_misc1 = np.random.random(dsize)\n+      generator.flow((images, x_misc1),\n+                     np.arange(dsize),\n+                     shuffle=False,\n+                     batch_size=2)\n+\n+      # Test with two miscellaneous inputs\n+      x_misc2 = np.random.random((dsize, 3, 3))\n+      generator.flow((images, [x_misc1, x_misc2]),\n+                     np.arange(dsize),\n+                     shuffle=False,\n+                     batch_size=2)\n+\n+      # Test cases with `y = None`\n+      generator.flow(images, None, batch_size=3)\n+      generator.flow((images, x_misc1), None, batch_size=3, shuffle=False)\n+      generator.flow((images, [x_misc1, x_misc2]),\n+                     None,\n+                     batch_size=3,\n+                     shuffle=False)\n+      generator = image.ImageDataGenerator(validation_split=0.2)\n+      generator.flow(images, batch_size=3)\n+\n+      # Test some failure cases:\n+      x_misc_err = np.random.random((dsize + 1, 3, 3))\n+      with self.assertRaisesRegex(ValueError, 'All of the arrays in'):\n+        generator.flow((images, x_misc_err), np.arange(dsize), batch_size=3)\n+\n+      with self.assertRaisesRegex(ValueError,\n+                                  r'`x` \\(images tensor\\) and `y` \\(labels\\)'):\n+        generator.flow((images, x_misc1), np.arange(dsize + 1), batch_size=3)\n+\n+      # Test `flow` behavior as Sequence\n+      generator.flow(\n+          images,\n+          np.arange(images.shape[0]),\n+          shuffle=False,\n+          save_to_dir=tmpdir.full_path,\n+          batch_size=3)\n+\n+      # Test with `shuffle=True`\n+      generator.flow(\n+          images,\n+          np.arange(images.shape[0]),\n+          shuffle=True,\n+          save_to_dir=tmpdir.full_path,\n+          batch_size=3,\n+          seed=123)\n+\n+    # test order_interpolation\n+    labels = np.array([[2, 2, 0, 2, 2], [1, 3, 2, 3, 1], [2, 1, 0, 1, 2],\n+                       [3, 1, 0, 2, 0], [3, 1, 3, 2, 1]])\n+\n+    label_generator = image.ImageDataGenerator(\n+        rotation_range=90., interpolation_order=0)\n+    label_generator.flow(x=labels[np.newaxis, ..., np.newaxis], seed=123)\n+\n+  def test_valid_args(self):\n+    with self.assertRaises(ValueError):\n+      image.ImageDataGenerator(brightness_range=0.1)\n+\n+  def test_batch_standardize(self):\n+    all_test_images = _generate_test_images(include_rgba=True)\n+    # ImageDataGenerator.standardize should work on batches\n+    for test_images in all_test_images:\n+      img_list = []\n+      for im in test_images:\n+        img_list.append(image.img_to_array(im)[None, ...])\n+\n+      images = np.vstack(img_list)\n+      generator = image.ImageDataGenerator(\n+          featurewise_center=True,\n+          samplewise_center=True,\n+          featurewise_std_normalization=True,\n+          samplewise_std_normalization=True,\n+          zca_whitening=True,\n+          rotation_range=90.,\n+          width_shift_range=0.1,\n+          height_shift_range=0.1,\n+          shear_range=0.5,\n+          zoom_range=0.2,\n+          channel_shift_range=0.,\n+          brightness_range=(1, 5),\n+          fill_mode='nearest',\n+          cval=0.5,\n+          horizontal_flip=True,\n+          vertical_flip=True)\n+      generator.fit(images, augment=True)\n+\n+      transformed = np.copy(images)\n+      for i, im in enumerate(transformed):\n+        transformed[i] = generator.random_transform(im)\n+      transformed = generator.standardize(transformed)\n+\n+  def test_deterministic_transform(self):\n+    x = np.ones((32, 32, 3))\n+    generator = image.ImageDataGenerator(\n+        rotation_range=90, fill_mode='constant')\n+    x = np.random.random((32, 32, 3))\n+    self.assertAllClose(\n+        generator.apply_transform(x, {'flip_vertical': True}), x[::-1, :, :])\n+    self.assertAllClose(\n+        generator.apply_transform(x, {'flip_horizontal': True}), x[:, ::-1, :])\n+    x = np.ones((3, 3, 3))\n+    x_rotated = np.array([[[0., 0., 0.], [1., 1., 1.], [0., 0., 0.]],\n+                          [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n+                          [[0., 0., 0.], [1., 1., 1.], [0., 0., 0.]]])\n+    self.assertAllClose(generator.apply_transform(x, {'theta': 45}), x_rotated)\n+\n+  def test_random_transforms(self):\n+    x = np.random.random((2, 28, 28))\n+    # Test get_random_transform with predefined seed\n+    seed = 1\n+    generator = image.ImageDataGenerator(\n+        rotation_range=90.,\n+        width_shift_range=0.1,\n+        height_shift_range=0.1,\n+        shear_range=0.5,\n+        zoom_range=0.2,\n+        channel_shift_range=0.1,\n+        brightness_range=(1, 5),\n+        horizontal_flip=True,\n+        vertical_flip=True)\n+    transform_dict = generator.get_random_transform(x.shape, seed)\n+    transform_dict2 = generator.get_random_transform(x.shape, seed * 2)\n+    self.assertNotEqual(transform_dict['theta'], 0)\n+    self.assertNotEqual(transform_dict['theta'], transform_dict2['theta'])\n+    self.assertNotEqual(transform_dict['tx'], 0)\n+    self.assertNotEqual(transform_dict['tx'], transform_dict2['tx'])\n+    self.assertNotEqual(transform_dict['ty'], 0)\n+    self.assertNotEqual(transform_dict['ty'], transform_dict2['ty'])\n+    self.assertNotEqual(transform_dict['shear'], 0)\n+    self.assertNotEqual(transform_dict['shear'], transform_dict2['shear'])\n+    self.assertNotEqual(transform_dict['zx'], 0)\n+    self.assertNotEqual(transform_dict['zx'], transform_dict2['zx'])\n+    self.assertNotEqual(transform_dict['zy'], 0)\n+    self.assertNotEqual(transform_dict['zy'], transform_dict2['zy'])\n+    self.assertNotEqual(transform_dict['channel_shift_intensity'], 0)\n+    self.assertNotEqual(transform_dict['channel_shift_intensity'],\n+                        transform_dict2['channel_shift_intensity'])\n+    self.assertNotEqual(transform_dict['brightness'], 0)\n+    self.assertNotEqual(transform_dict['brightness'],\n+                        transform_dict2['brightness'])\n+\n+    # Test get_random_transform without any randomness\n+    generator = image.ImageDataGenerator()\n+    transform_dict = generator.get_random_transform(x.shape, seed)\n+    self.assertEqual(transform_dict['theta'], 0)\n+    self.assertEqual(transform_dict['tx'], 0)\n+    self.assertEqual(transform_dict['ty'], 0)\n+    self.assertEqual(transform_dict['shear'], 0)\n+    self.assertEqual(transform_dict['zx'], 1)\n+    self.assertEqual(transform_dict['zy'], 1)\n+    self.assertIsNone(transform_dict['channel_shift_intensity'], None)\n+    self.assertIsNone(transform_dict['brightness'], None)\n+\n+  def test_fit_rescale(self):\n+    all_test_images = _generate_test_images(include_rgba=True)\n+    rescale = 1. / 255\n+\n+    for test_images in all_test_images:\n+      img_list = []\n+      for im in test_images:\n+        img_list.append(image.img_to_array(im)[None, ...])\n+      images = np.vstack(img_list)\n+\n+      # featurewise_center test\n+      generator = image.ImageDataGenerator(\n+          rescale=rescale, featurewise_center=True, dtype='float64')\n+      generator.fit(images)\n+      batch = generator.flow(images, batch_size=8).next()\n+      self.assertLess(abs(np.mean(batch)), 1e-6)\n+\n+      # featurewise_std_normalization test\n+      generator = image.ImageDataGenerator(\n+          rescale=rescale,\n+          featurewise_center=True,\n+          featurewise_std_normalization=True,\n+          dtype='float64')\n+      generator.fit(images)\n+      batch = generator.flow(images, batch_size=8).next()\n+      self.assertLess(abs(np.mean(batch)), 1e-6)\n+      self.assertLess(abs(1 - np.std(batch)), 1e-5)\n+\n+      # zca_whitening test\n+      generator = image.ImageDataGenerator(\n+          rescale=rescale,\n+          featurewise_center=True,\n+          zca_whitening=True,\n+          dtype='float64')\n+      generator.fit(images)\n+      batch = generator.flow(images, batch_size=8).next()\n+      batch = np.reshape(\n+          batch,\n+          (batch.shape[0], batch.shape[1] * batch.shape[2] * batch.shape[3]))\n+      # Y * Y_T = n * I, where Y = W * X\n+      identity = np.dot(batch, batch.T) / batch.shape[0]\n+      self.assertTrue(\n+          ((np.abs(identity) - np.identity(identity.shape[0])) < 1e-6).all())\n+\n+\n+@test_utils.run_v2_only\n+class TestAffineTransformations(test_combinations.TestCase):\n+\n+  def test_random_transforms(self):\n+    x = np.random.random((2, 28, 28))\n+    self.assertEqual(image.random_rotation(x, 45).shape, (2, 28, 28))\n+    self.assertEqual(image.random_shift(x, 1, 1).shape, (2, 28, 28))\n+    self.assertEqual(image.random_shear(x, 20).shape, (2, 28, 28))\n+    self.assertEqual(image.random_channel_shift(x, 20).shape, (2, 28, 28))\n+\n+  def test_deterministic_transform(self):\n+    x = np.ones((3, 3, 3))\n+    x_rotated = np.array([[[0., 0., 0.], [1., 1., 1.], [0., 0., 0.]],\n+                          [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n+                          [[0., 0., 0.], [1., 1., 1.], [0., 0., 0.]]])\n+    self.assertAllClose(\n+        image.apply_affine_transform(\n+            x,\n+            theta=45,\n+            row_axis=0,\n+            col_axis=1,\n+            channel_axis=2,\n+            fill_mode='constant'), x_rotated)\n+\n+  def test_matrix_center(self):\n+    x = np.expand_dims(np.array([\n+        [0, 1],\n+        [0, 0],\n+    ]), -1)\n+    x_rotated90 = np.expand_dims(np.array([\n+        [1, 0],\n+        [0, 0],\n+    ]), -1)\n+\n+    self.assertAllClose(\n+        image.apply_affine_transform(\n+            x, theta=90, row_axis=0, col_axis=1, channel_axis=2), x_rotated90)\n+\n+  def test_translation(self):\n+    x = np.array([\n+        [0, 0, 0, 0],\n+        [0, 1, 0, 0],\n+        [0, 0, 0, 0],\n+    ])\n+    x_up = np.array([\n+        [0, 1, 0, 0],\n+        [0, 0, 0, 0],\n+        [0, 0, 0, 0],\n+    ])\n+    x_dn = np.array([\n+        [0, 0, 0, 0],\n+        [0, 0, 0, 0],\n+        [0, 1, 0, 0],\n+    ])\n+    x_left = np.array([\n+        [0, 0, 0, 0],\n+        [1, 0, 0, 0],\n+        [0, 0, 0, 0],\n+    ])\n+    x_right = np.array([\n+        [0, 0, 0, 0],\n+        [0, 0, 1, 0],\n+        [0, 0, 0, 0],\n+    ])\n+\n+    # Channels first\n+    x_test = np.expand_dims(x, 0)\n+\n+    # Horizontal translation\n+    self.assertAllEqual(x_left,\n+                        np.squeeze(image.apply_affine_transform(x_test, tx=1)))\n+    self.assertAllEqual(x_right,\n+                        np.squeeze(image.apply_affine_transform(x_test, tx=-1)))\n+\n+    # change axes: x<->y\n+    self.assertAllEqual(\n+        x_left,\n+        np.squeeze(\n+            image.apply_affine_transform(x_test, ty=1, row_axis=2, col_axis=1)))\n+    self.assertAllEqual(\n+        x_right,\n+        np.squeeze(\n+            image.apply_affine_transform(x_test, ty=-1, row_axis=2,\n+                                         col_axis=1)))\n+\n+    # Vertical translation\n+    self.assertAllEqual(x_up,\n+                        np.squeeze(image.apply_affine_transform(x_test, ty=1)))\n+    self.assertAllEqual(x_dn,\n+                        np.squeeze(image.apply_affine_transform(x_test, ty=-1)))\n+\n+    # change axes: x<->y\n+    self.assertAllEqual(\n+        x_up,\n+        np.squeeze(\n+            image.apply_affine_transform(x_test, tx=1, row_axis=2, col_axis=1)))\n+    self.assertAllEqual(\n+        x_dn,\n+        np.squeeze(\n+            image.apply_affine_transform(x_test, tx=-1, row_axis=2,\n+                                         col_axis=1)))\n+\n+    # Channels last\n+    x_test = np.expand_dims(x, -1)\n+\n+    # Horizontal translation\n+    self.assertAllEqual(\n+        x_left,\n+        np.squeeze(\n+            image.apply_affine_transform(\n+                x_test, tx=1, row_axis=0, col_axis=1, channel_axis=2)))\n+    self.assertAllEqual(\n+        x_right,\n+        np.squeeze(\n+            image.apply_affine_transform(\n+                x_test, tx=-1, row_axis=0, col_axis=1, channel_axis=2)))\n+\n+    # change axes: x<->y\n+    self.assertAllEqual(\n+        x_left,\n+        np.squeeze(\n+            image.apply_affine_transform(\n+                x_test, ty=1, row_axis=1, col_axis=0, channel_axis=2)))\n+    self.assertAllEqual(\n+        x_right,\n+        np.squeeze(\n+            image.apply_affine_transform(\n+                x_test, ty=-1, row_axis=1, col_axis=0, channel_axis=2)))\n+\n+    # Vertical translation\n+    self.assertAllEqual(\n+        x_up,\n+        np.squeeze(\n+            image.apply_affine_transform(\n+                x_test, ty=1, row_axis=0, col_axis=1, channel_axis=2)))\n+    self.assertAllEqual(\n+        x_dn,\n+        np.squeeze(\n+            image.apply_affine_transform(\n+                x_test, ty=-1, row_axis=0, col_axis=1, channel_axis=2)))\n+\n+    # change axes: x<->y\n+    self.assertAllEqual(\n+        x_up,\n+        np.squeeze(\n+            image.apply_affine_transform(\n+                x_test, tx=1, row_axis=1, col_axis=0, channel_axis=2)))\n+    self.assertAllEqual(\n+        x_dn,\n+        np.squeeze(\n+            image.apply_affine_transform(\n+                x_test, tx=-1, row_axis=1, col_axis=0, channel_axis=2)))\n+\n+  def test_random_zoom(self):\n+    x = np.random.random((2, 28, 28))\n+    self.assertEqual(image.random_zoom(x, (5, 5)).shape, (2, 28, 28))\n+    self.assertAllClose(x, image.random_zoom(x, (1, 1)))\n+\n+  def test_random_zoom_error(self):\n+    with self.assertRaises(ValueError):\n+      image.random_zoom(0, zoom_range=[0])\n+\n+  def test_random_brightness_error(self):\n+    with self.assertRaises(ValueError):\n+      image.random_brightness(0, [0])\n+\n+  def test_random_brightness_scale(self):\n+    img = np.ones((1, 1, 3)) * 128\n+    zeros = np.zeros((1, 1, 3))\n+    must_be_128 = image.random_brightness(img, [1, 1], False)\n+    self.assertAllEqual(img, must_be_128)\n+    must_be_0 = image.random_brightness(img, [1, 1], True)\n+    self.assertAllEqual(zeros, must_be_0)\n+\n+  def test_random_brightness_scale_outside_range_positive(self):\n+    img = np.ones((1, 1, 3)) * 1024\n+    zeros = np.zeros((1, 1, 3))\n+    must_be_1024 = image.random_brightness(img, [1, 1], False)\n+    self.assertAllEqual(img, must_be_1024)\n+    must_be_0 = image.random_brightness(img, [1, 1], True)\n+    self.assertAllEqual(zeros, must_be_0)\n+\n+  def test_random_brightness_scale_outside_range_negative(self):\n+    img = np.ones((1, 1, 3)) * -1024\n+    zeros = np.zeros((1, 1, 3))\n+    must_be_neg_1024 = image.random_brightness(img, [1, 1], False)\n+    self.assertAllEqual(img, must_be_neg_1024)\n+    must_be_0 = image.random_brightness(img, [1, 1], True)\n+    self.assertAllEqual(zeros, must_be_0)\n \n \n if __name__ == '__main__':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
