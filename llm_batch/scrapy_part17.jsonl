{"custom_id": "scrapy#21c08e39f873ad8814a3b42e8854a7fa01eee0af", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 218 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -135,6 +135,7 @@ class ClusterWorker(pb.Root):\n         \n     def remote_set_master(self, master):\n         \"\"\"Set the master for this worker\"\"\"\n+        log.msg(\"ClusterWorker: ClusterMaster connected from %s:%s\" % master.broker.transport.client)\n         self.__master = master\n         return self.status()\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#1c742607525a1c193096e45fe7313ef9f5ec7ac7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 224 | Contributors (this commit): 1 | Commits (past 90d): 4 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -38,8 +38,8 @@ class ScrapyProcessProtocol(protocol.ProcessProtocol):\n     def __str__(self):\n         return \"<ScrapyProcess domain=%s, pid=%s, status=%s>\" % (self.domain, self.pid, self.status)\n \n-    def status(self):\n-        \"\"\"Return this scrapy process status as a dict.\n+    def info(self):\n+        \"\"\"Return this scrapy process info as a dict.\n         \n         The keys are: \n \n@@ -115,7 +115,7 @@ class ClusterWorker(pb.Root):\n         \"\"\"\n \n         status = {}\n-        status[\"running\"] = [self.running[k].status() for k in self.running.keys()]\n+        status[\"running\"] = [self.running[k].info() for k in self.running.keys()]\n         status[\"starttime\"] = self.starttime\n         status[\"timestamp\"] = datetime.datetime.utcnow()\n         status[\"maxproc\"] = self.maxproc\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#57848d46b2c059707505b63b8e79dc81471c619e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 7 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 15 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -1,9 +1,10 @@\n #!/usr/bin/python2.5\n \n+import sys\n+import pprint\n+\n from twisted.spread import pb\n from twisted.internet import reactor\n-from twisted.python import util\n-import sys\n \n factory = pb.PBClientFactory()\n reactor.connectTCP(\"localhost\", 8789, factory)\n@@ -11,15 +12,13 @@ d = factory.getRootObject()\n \n sys.argv.pop(0)\n \n-if not sys.argv:\n+if not sys.argv or sys.argv[0] == '--status':\n     d.addCallback(lambda object: object.callRemote(\"status\"))\n-elif sys.argv[0] == \"-s\":\n+elif sys.argv[0] == \"--stop\":\n     d.addCallback(lambda object: object.callRemote(\"stop\", sys.argv[1]))\n-elif sys.argv[0] == \"-r\":\n+elif sys.argv[0] == \"--run\":\n     d.addCallback(lambda object: object.callRemote(\"run\", sys.argv[1]))\n-elif sys.argv[0] == \"-t\":\n-    d.addCallback(lambda object: object.callRemote(\"statistics\"))\n \n-d.addCallbacks(callback = util.println, errback = lambda reason: 'error: '+str(reason.value))\n+d.addCallbacks(callback=pprint.pprint, errback=lambda reason:'error: ' + str(reason.value))\n d.addCallback(lambda _: reactor.stop())\n reactor.run()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#f7275f6b0efe7d7cb6216700b782f21ab766c641", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 56 | Contributors (this commit): 2 | Commits (past 90d): 9 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -20,7 +20,8 @@ def mysql_connect(db_uri, **kwargs):\n         if d['passwd'] is None:\n             del(d['passwd'])\n \n-        d.update(settings.get(\"MYSQL_CONNECTION_SETTINGS\"))\n+        d['charset'] = 'utf8'\n+        d.update(settings.get(\"MYSQL_CONNECTION_SETTINGS\", {}))\n         d.update(kwargs)\n         \n         dcopy = d.copy()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c913d6ffcf922f3dde5592b35c95a1813340a27b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 57 | Lines Deleted: 18 | Files Changed: 3 | Hunks: 12 | Methods Changed: 6 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 75 | Churn Cumulative: 299 | Contributors (this commit): 1 | Commits (past 90d): 7 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,13 @@\n+\"\"\"\n+This module contains pre-run hooks that can be attached to scrapy workers.\n+\n+Pre-run hooks must be callable objects (ie. functions) which implement this\n+interface:\n+\n+pre_hook(domain, spider_settings)\n+\n+domain is the domain to be scraped\n+spider_settings is the settings to use to scrape it\n+\n+Values returned from the pre-run hooks will be ignored.\n+\"\"\"\n\n@@ -0,0 +1,23 @@\n+\"\"\" \n+This module contains hooks for updating code via svn. Useful for running before\n+starting to crawl a domain, for example to update spider code \n+\"\"\"\n+\n+import pysvn\n+\n+from scrapy.conf import settings\n+from scrapy import log\n+\n+SVN_DIR = settings['SVN_DIR']\n+SVN_USER = settings['SVN_USER']\n+SVN_PASS = settings['SVN_PASS']\n+\n+def svnup(domain, spider_settings):\n+    c = pysvn.Client()\n+    c.callback_get_login = lambda x,y,z: (True, SVN_USER, SVN_PASS, False)\n+    try:\n+        r = c.update(SVN_DIR)\n+        log.msg(\"ClusterWorker: SVN code updated to revision %s (triggered by domain %s)\" % \\\n+                (r[0].number, domain), level=log.DEBUG)\n+    except pysvn.ClientError, e:\n+        log.msg(\"ClusterWorker: unable to update svn code - %s\" % e, level=log.WARNING)\n\n@@ -5,12 +5,14 @@ import datetime\n import cPickle as pickle\n \n from twisted.internet import protocol, reactor\n+from twisted.internet.error import ProcessDone\n from twisted.spread import pb\n \n from scrapy import log\n-from scrapy.core.exceptions import NotConfigured\n-from scrapy.conf import settings\n from scrapy.core.engine import scrapyengine\n+from scrapy.core.exceptions import NotConfigured\n+from scrapy.utils.misc import load_class\n+from scrapy.conf import settings\n \n class ScrapyProcessProtocol(protocol.ProcessProtocol):\n \n@@ -70,9 +72,14 @@ class ScrapyProcessProtocol(protocol.ProcessProtocol):\n         self.status = \"running\"\n         self.procman.update_master(self.domain, \"running\")\n \n-    def processEnded(self, reason):\n-        log.msg(\"ClusterWorker: finished domain=%s, pid=%d, log=%s\" % (self.domain, self.pid, self.logfile))\n-        log.msg(\"Reason type: %s. value: %s\" % (reason.type, reason.value) )\n+    def processEnded(self, status):\n+        if isinstance(status.value, ProcessDone):\n+            st = \"done\"\n+            er = \"\"\n+        else:\n+            st = \"terminated\"\n+            er = \", error=%s\" % str(status.value)\n+        log.msg(\"ClusterWorker: finished domain=%s, status=%s, pid=%d, log=%s%s\" % (self.domain, st, self.pid, self.logfile, er))\n         del self.procman.running[self.domain]\n         del self.procman.crawlers[self.pid]\n         self.procman.update_master(self.domain, \"scraped\")\n@@ -88,6 +95,7 @@ class ClusterWorker(pb.Root):\n         self.running = {} # dict of domain->ScrapyProcessControl \n         self.crawlers = {} # dict of pid->scrapy process remote pb connection\n         self.starttime = datetime.datetime.utcnow()\n+        self.prerun_hooks = [load_class(f) for f in settings.getlist('CLUSTER_WORKER_PRERUN_HOOKS', [])]\n         port = settings.getint('CLUSTER_WORKER_PORT')\n         scrapyengine.listenTCP(port, pb.PBServerFactory(self))\n         log.msg(\"Using sys.path: %s\" % repr(sys.path), level=log.DEBUG)\n@@ -150,7 +158,7 @@ class ClusterWorker(pb.Root):\n             d.addCallbacks(callback=_close, errback=lambda reason: log.msg(reason, log.ERROR))\n             return self.status(0, \"Stopped process %s\" % proc)\n         else:\n-            return self.status(1, \"%s: domain not running.\" % domain)\n+            return self.status(1, \"%s: domain not running\" % domain)\n \n     def remote_status(self):\n         \"\"\"Return worker status as a dict. For infomation about the keys see\n@@ -167,21 +175,16 @@ class ClusterWorker(pb.Root):\n                 scrapy_proc = ScrapyProcessProtocol(self, domain, logfile, spider_settings)\n                 args = [sys.executable, sys.argv[0], 'crawl', domain]\n                 self.running[domain] = scrapy_proc\n-                try:\n-                    import pysvn\n-                    c = pysvn.Client()\n-                    r = c.update(settings.get(\"CLUSTER_WORKER_SVNWORKDIR\", \".\"))\n-                    log.msg(\"Updated to revision %s.\" %r[0].number, level=log.DEBUG)\n-                except pysvn.ClientError, e:\n-                    log.msg(\"Unable to svn update: %s\" % e, level=log.WARNING)\n-                except ImportError:\n-                    log.msg(\"pysvn module not available.\", level=log.WARNING)\n+\n+                for prerun_hook in self.prerun_hooks:\n+                    prerun_hook(domain, spider_settings)\n+\n                 reactor.spawnProcess(scrapy_proc, sys.executable, args=args, env=scrapy_proc.env)\n-                return self.status(0, \"Started process %s.\" % scrapy_proc)\n+                return self.status(0, \"Started process %s\" % scrapy_proc)\n             else:\n-                return self.status(2, \"Domain %s already running.\" % domain )\n+                return self.status(2, \"Domain %s already running\" % domain )\n         else:\n-            return self.status(1, \"No free slot to run another process.\")\n+            return self.status(1, \"No free slot to run another process\")\n \n     def remote_register_crawler(self, pid, crawler):\n         \"\"\"Register the crawler to the list of crawlers managed by this worker\"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#4b03435ca00eb49e6422d1520a315da940417ebd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 266 | Contributors (this commit): 1 | Commits (past 90d): 6 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -97,7 +97,8 @@ class ClusterWorker(pb.Root):\n         self.starttime = datetime.datetime.utcnow()\n         self.prerun_hooks = [load_class(f) for f in settings.getlist('CLUSTER_WORKER_PRERUN_HOOKS', [])]\n         port = settings.getint('CLUSTER_WORKER_PORT')\n-        scrapyengine.listenTCP(port, pb.PBServerFactory(self))\n+        factory = pb.PBServerFactory(self, unsafeTracebacks=True)\n+        scrapyengine.listenTCP(port, factory)\n         log.msg(\"Using sys.path: %s\" % repr(sys.path), level=log.DEBUG)\n \n     def status(self, rcode=0, rstring=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#928112a989c60ab484e883324850c8c072582732", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 65 | Lines Deleted: 65 | Files Changed: 3 | Hunks: 41 | Methods Changed: 24 | Complexity Δ (Sum/Max): -5/0 | Churn Δ: 130 | Churn Cumulative: 1036 | Contributors (this commit): 1 | Commits (past 90d): 12 | Contributors (cumulative): 3 | DMM Complexity: 0.3076923076923077\n\nDIFF:\n@@ -11,6 +11,7 @@ from scrapy.core import signals\n from scrapy import log\n from scrapy.core.engine import scrapyengine\n from scrapy.core.exceptions import NotConfigured\n+from scrapy.contrib.pbcluster.worker.manager import ResponseCode\n from scrapy.conf import settings\n \n DEFAULT_PRIORITY = settings.getint(\"DEFAULT_PRIORITY\", 20)\n@@ -22,19 +23,19 @@ def my_import(name):\n         mod = getattr(mod, comp)\n     return mod\n \n-class ClusterMasterBroker(pb.Referenceable):\n+class ClusterNodeBroker(pb.Referenceable):\n \n     def __init__(self, remote, name, master):\n-        self.__remote = remote\n+        self._worker = remote\n         self.alive = False\n         self.name = name\n         self.master = master\n         self.available = True\n         try:\n-            deferred = self.__remote.callRemote(\"set_master\", self)\n+            deferred = self._worker.callRemote(\"set_master\", self)\n         except pb.DeadReferenceError:\n             self._set_status(None)\n-            log.msg(\"Lost connection to node %s.\" % (self.name), log.ERROR)\n+            log.msg(\"ClusterMaster: lost connection to node %s.\" % (self.name), log.ERROR)\n         else:\n             deferred.addCallbacks(callback=self._set_status, errback=lambda reason: log.msg(reason, log.ERROR))\n             \n@@ -86,49 +87,56 @@ class ClusterMasterBroker(pb.Referenceable):\n \n     def update_status(self):\n         try:\n-            deferred = self.__remote.callRemote(\"status\")\n+            deferred = self._worker.callRemote(\"status\")\n         except pb.DeadReferenceError:\n             self._set_status(None)\n-            log.msg(\"Lost connection to node %s.\" % (self.name), log.ERROR)\n+            log.msg(\"ClusterMaster: Lost connection to node %s.\" % (self.name), log.ERROR)\n         else:\n             deferred.addCallbacks(callback=self._set_status, errback=lambda reason: log.msg(reason, log.ERROR))\n \n     def stop(self, domain):\n         try:\n-            deferred = self.__remote.callRemote(\"stop\", domain)\n+            deferred = self._worker.callRemote(\"stop\", domain)\n         except pb.DeadReferenceError:\n             self._set_status(None)\n-            log.msg(\"Lost connection to node %s.\" % (self.name), log.ERROR)\n+            log.msg(\"ClusterMaster: Lost connection to node %s.\" % (self.name), log.ERROR)\n         else:\n             deferred.addCallbacks(callback=self._set_status, errback=lambda reason: log.msg(reason, log.ERROR))\n \n-    def run(self, pending):\n+    def run(self, domain_info):\n+        \"\"\"Run the given domain. \n+        \n+        domain_info keys:\n+        domain - the domain to run\n+        settings - the settings to use\n+        priority - the priority to use\n+        \"\"\"\n \n         def _run_errback(reason):\n             log.msg(reason, log.ERROR)\n-            self.master.loading.remove(pending['domain'])\n-            self.master.schedule([pending['domain']], pending['settings'], pending['priority'] - 1)\n-            log.msg(\"Domain %s rescheduled: lost connection to node.\" % pending['domain'], log.WARNING)\n+            self.master.loading.remove(domain_info['domain'])\n+            self.master.schedule([domain_info['domain']], domain_info['settings'], domain_info['priority'] - 1)\n+            log.msg(\"ClusterMaster: Domain %s rescheduled: lost connection to node.\" % domain_info['domain'], log.WARNING)\n             \n         def _run_callback(status):\n-            if status['callresponse'][0] == 1:\n+            if status['callresponse'][0] == ResponseCode.NO_FREE_SLOT:\n                 # slots are complete. Reschedule in master with priority reduced by one.\n                 # self.master.loading check should avoid this to happen\n-                self.master.loading.remove(pending['domain'])\n-                self.master.schedule([pending['domain']], pending['settings'], pending['priority'] - 1)\n-                log.msg(\"Domain %s rescheduled: no proc space in node.\" % pending['domain'], log.WARNING)\n-            elif status['callresponse'][0] == 2:\n+                self.master.loading.remove(domain_info['domain'])\n+                self.master.schedule([domain_info['domain']], domain_info['settings'], domain_info['priority'] - 1)\n+                log.msg(\"ClusterMaster: Domain %s rescheduled: no availble processes in worker\" % domain_info['domain'], log.WARNING)\n+            elif status['callresponse'][0] == ResponseCode.DOMAIN_ALREADY_RUNNING:\n                 # domain already running in node. Reschedule with same priority.\n                 # self.master.loading check should avoid this to happen\n-                self.master.loading.remove(pending['domain'])\n-                self.master.schedule([pending['domain']], pending['settings'], pending['priority'])\n-                log.msg(\"Domain %s rescheduled: already running in node.\" % pending['domain'], log.WARNING)\n+                self.master.loading.remove(domain_info['domain'])\n+                self.master.schedule([domain_info['domain']], domain_info['settings'], domain_info['priority'])\n+                log.msg(\"ClusterMaster: Domain %s rescheduled: already running in node.\" % domain_info['domain'], log.WARNING)\n \n         try:\n-            deferred = self.__remote.callRemote(\"run\", pending[\"domain\"], pending[\"settings\"])\n+            deferred = self._worker.callRemote(\"run\", domain_info[\"domain\"], domain_info[\"settings\"])\n         except pb.DeadReferenceError:\n             self._set_status(None)\n-            log.msg(\"Lost connection to node %s.\" % (self.name), log.ERROR)\n+            log.msg(\"ClusterMaster: Lost connection to node %s.\" % (self.name), log.ERROR)\n         else:\n             deferred.addCallbacks(callback=_run_callback, errback=_run_errback)\n         \n@@ -156,7 +164,7 @@ class ScrapyPBClientFactory(pb.PBClientFactory):\n     def clientConnectionLost(self, *args, **kargs):\n         pb.PBClientFactory.clientConnectionLost(self, *args, **kargs)\n         del self.master.nodes[self.nodename]\n-        log.msg(\"Lost connection to %s. Node removed\" % self.nodename )\n+        log.msg(\"ClusterMaster: Lost connection to %s. Node removed\" % self.nodename )\n \n class ClusterMaster(object):\n \n@@ -181,7 +189,7 @@ class ClusterMaster(object):\n         self.loading = []\n         self.nodes = {}\n         self.start_time = datetime.datetime.utcnow()\n-        # for more info about statistics see self.update_nodes() and ClusterMasterBroker.remote_update()\n+        # for more info about statistics see self.update_nodes() and ClusterNodeBroker.remote_update()\n         self.statistics = {\"domains\": {\"running\": set(), \"scraped\": {}, \"lost_count\": {}, \"lost\": set()}, \"scraped_count\": 0 }\n         self.global_settings = {}\n         # load cluster global settings\n@@ -200,16 +208,15 @@ class ClusterMaster(object):\n         \"\"\"Creates the remote reference for a worker node\"\"\"\n         server, port = hostport.split(\":\")\n         port = int(port)\n-        log.msg(\"Connecting to cluster worker %s...\" % name)\n-        log.msg(\"Server: %s, Port: %s\" % (server, port))\n+        log.msg(\"ClusterMaster: Connecting to worker %s (%s)...\" % (name, hostport))\n         factory = ScrapyPBClientFactory(self, name)\n         try:\n             reactor.connectTCP(server, port, factory)\n         except Exception, err:\n-            log.msg(\"Could not connect to node %s in %s: %s.\" % (name, hostport, err), log.ERROR)\n+            log.msg(\"ClusterMaster: Could not connect to worker %s (%s): %s\" % (name, hostport, err), log.ERROR)\n         else:\n             def _errback(_reason):\n-                log.msg(\"Could not connect to remote node %s (%s): %s.\" % (name, hostport, _reason), log.ERROR)\n+                log.msg(\"ClusterMaster: Could not connect to worker %s (%s): %s\" % (name, hostport, _reason), log.ERROR)\n \n             d = factory.getRootObject()\n             d.addCallbacks(callback=lambda obj: self.add_node(obj, name), errback=_errback)\n@@ -218,10 +225,10 @@ class ClusterMaster(object):\n         \"\"\"Update worker nodes statistics\"\"\"\n         for name, hostport in settings.get('CLUSTER_MASTER_NODES', {}).iteritems():\n             if name in self.nodes and self.nodes[name].alive:\n-                log.msg(\"Updating node. name: %s, host: %s\" % (name, hostport) )\n+                log.msg(\"ClusterMaster: Updating stats from worker node %s (%s)\" % (name, hostport))\n                 self.nodes[name].update_status()\n             else:\n-                log.msg(\"Reloading node. name: %s, host: %s\" % (name, hostport) )\n+                log.msg(\"ClusterMaster: Reloading worker node %s (%s)\" % (name, hostport))\n                 self.load_node(name, hostport)\n         \n         real_running = set(self.running.keys())\n@@ -232,9 +239,9 @@ class ClusterMaster(object):\n             \n     def add_node(self, cworker, name):\n         \"\"\"Add node given its node\"\"\"\n-        node = ClusterMasterBroker(cworker, name, self)\n+        node = ClusterNodeBroker(cworker, name, self)\n         self.nodes[name] = node\n-        log.msg(\"Added cluster worker %s\" % name)\n+        log.msg(\"ClusterMaster: Added cluster worker %s\" % name)\n \n     def disable_node(self, name):\n         self.nodes[name].available = False\n@@ -246,25 +253,21 @@ class ClusterMaster(object):\n         raise NotImplemented\n \n     def schedule(self, domains, spider_settings=None, priority=DEFAULT_PRIORITY):\n-        \"\"\"Schedule the domains passed\"\"\"\n-        i = 0\n-        for p in self.pending:\n-            if p['priority'] <= priority:\n-                i += 1\n-            else:\n-                break\n+        \"\"\"Schedule the given domains, with the given priority\"\"\"\n+        insert_pos = len([p for p in self.pending if ['priority'] <= priority])\n         for domain in domains:\n-            pd = self.find_inpending(domain)\n+            pd = self.get_first_pending(domain)\n             if pd: # domain already pending, so just change priority if new is higher\n                 if priority < pd['priority']:\n                     self.pending.remove(pd)\n                     pd['priority'] = priority\n-                    self.pending.insert(i, pd)\n+                    self.pending.insert(insert_pos, pd)\n             else:\n                 final_spider_settings = self.get_spider_groupsettings(domain)\n                 final_spider_settings.update(self.global_settings)\n                 final_spider_settings.update(spider_settings or {})\n-                self.pending.insert(i, {'domain': domain, 'settings': final_spider_settings, 'priority': priority})\n+                self.pending.insert(insert_pos, {'domain': domain, 'settings': final_spider_settings, 'priority': priority})\n+                log.msg(\"ClusterMaster: Scheduled domain=%s priority=%s\" % (domain, priority), log.DEBUG)\n \n     def stop(self, domains):\n         \"\"\"Stop the given domains\"\"\"\n@@ -281,17 +284,10 @@ class ClusterMaster(object):\n                 self.nodes[nodename].stop(domain)\n \n     def remove(self, domains):\n-        \"\"\"Remove all scheduled instances of the given domains (if it hasn't\n-        started yet). Otherwise use stop()\"\"\"\n+        \"\"\"Remove all scheduled instances of the given domains (if they haven't\n+        started yet). Otherwise use stop() to stop running domains\"\"\"\n \n-        for domain in domains:\n-            to_remove = []\n-            for p in self.pending:\n-                if p['domain'] == domain:\n-                    to_remove.append(p)\n-    \n-            for p in to_remove:\n-                self.pending.remove(p)\n+        self.pending = [p for p in self.pending if ['domain'] not in domains]\n \n     def discard(self, domains):\n         \"\"\"Stop and remove all running and pending instances of the given\n@@ -308,16 +304,13 @@ class ClusterMaster(object):\n                 d[proc['domain']] = node\n         return d\n \n-    @property\n-    def available_nodes(self):\n-        return (node for node in self.nodes.itervalues() if node.available)\n-\n-    def find_inpending(self, domain):\n+    def get_first_pending(self, domain):\n+        \"\"\"Return first pending instance of a given domain\"\"\"\n         for p in self.pending:\n             if domain == p['domain']:\n                 return p\n \n-    def print_pending(self, verbosity=1):\n+    def get_pending(self, verbosity=1):\n         if verbosity == 1:\n             pending = []\n             for p in self.pending:\n@@ -336,4 +329,4 @@ class ClusterMaster(object):\n     def _engine_stopped(self):\n         with open(settings[\"CLUSTER_MASTER_STATEFILE\"], \"w\") as f:\n             pickle.dump(self.pending, f)\n-            log.msg(\"Cluster master state saved in %s\" % settings[\"CLUSTER_MASTER_STATEFILE\"])\n+            log.msg(\"ClusterMaster: state saved in %s\" % settings[\"CLUSTER_MASTER_STATEFILE\"])\n\n@@ -227,7 +227,7 @@ class ClusterMasterWeb(ClusterMaster):\n             for d, n in self.nodes.iteritems():\n                 nodes_status[d] = n.status_as_dict(verbosity)\n             status[\"nodes\"] = nodes_status\n-            status[\"pending\"] = self.print_pending(verbosity)\n+            status[\"pending\"] = self.get_pending(verbosity)\n             status[\"loading\"] = self.loading\n             content = serialize(status, format)\n             return content\n\n@@ -157,9 +157,9 @@ class ClusterWorker(pb.Root):\n             def _close():\n                 proc.status = \"closing\"\n             d.addCallbacks(callback=_close, errback=lambda reason: log.msg(reason, log.ERROR))\n-            return self.status(0, \"Stopped process %s\" % proc)\n+            return self.status(ResponseCode.DOMAIN_STOPPED, \"Stopped process %s\" % proc)\n         else:\n-            return self.status(1, \"%s: domain not running\" % domain)\n+            return self.status(ResponseCode.DOMAIN_NOT_RUNNING, \"%s: domain not running\" % domain)\n \n     def remote_status(self):\n         \"\"\"Return worker status as a dict. For infomation about the keys see\n@@ -181,12 +181,19 @@ class ClusterWorker(pb.Root):\n                     prerun_hook(domain, spider_settings)\n \n                 reactor.spawnProcess(scrapy_proc, sys.executable, args=args, env=scrapy_proc.env)\n-                return self.status(0, \"Started process %s\" % scrapy_proc)\n+                return self.status(ResponseCode.DOMAIN_STARTED, \"Started process %s\" % scrapy_proc)\n             else:\n-                return self.status(2, \"Domain %s already running\" % domain )\n+                return self.status(ResponseCode.DOMAIN_ALREADY_RUNNING, \"Domain %s already running\" % domain )\n         else:\n-            return self.status(1, \"No free slot to run another process\")\n+            return self.status(ResponseCode.NO_FREE_SLOT, \"No free slot to run another domain\")\n \n     def remote_register_crawler(self, pid, crawler):\n         \"\"\"Register the crawler to the list of crawlers managed by this worker\"\"\"\n         self.crawlers[pid] = crawler\n+\n+class ResponseCode(object):\n+    DOMAIN_STARTED = 1\n+    DOMAIN_STOPPED = 2\n+    DOMAIN_ALREADY_RUNNING = 3\n+    DOMAIN_NOT_RUNNING = 4\n+    NO_FREE_SLOT = 5\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#3e1ad8d6530819afc09fc0ae9e356c8bff9cdfad", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 289 | Contributors (this commit): 1 | Commits (past 90d): 8 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -67,7 +67,7 @@ class ScrapyProcessProtocol(protocol.ProcessProtocol):\n \n     def connectionMade(self):\n         self.pid = self.transport.pid\n-        log.msg(\"ClusterWorker: started domain=%s, pid=%d, log=%s\" % (self.domain, self.pid, self.logfile))\n+        log.msg(\"ClusterWorker: started domain=%s pid=%d log=%s\" % (self.domain, self.pid, self.logfile))\n         self.transport.closeStdin()\n         self.status = \"running\"\n         self.procman.update_master(self.domain, \"running\")\n@@ -79,7 +79,7 @@ class ScrapyProcessProtocol(protocol.ProcessProtocol):\n         else:\n             st = \"terminated\"\n             er = \", error=%s\" % str(status.value)\n-        log.msg(\"ClusterWorker: finished domain=%s, status=%s, pid=%d, log=%s%s\" % (self.domain, st, self.pid, self.logfile, er))\n+        log.msg(\"ClusterWorker: finished domain=%s status=%s pid=%d log=%s%s\" % (self.domain, st, self.pid, self.logfile, er))\n         del self.procman.running[self.domain]\n         del self.procman.crawlers[self.pid]\n         self.procman.update_master(self.domain, \"scraped\")\n@@ -152,7 +152,7 @@ class ClusterWorker(pb.Root):\n         \"\"\"Stop a running domain\"\"\"\n         if domain in self.running:\n             proc = self.running[domain]\n-            log.msg(\"ClusterWorker: Sending shutdown signal to domain=%s, pid=%d\" % (domain, proc.pid))\n+            log.msg(\"ClusterWorker: Sending shutdown signal to domain=%s pid=%d\" % (domain, proc.pid))\n             d = self.crawlers[proc.pid].callRemote(\"stop\")\n             def _close():\n                 proc.status = \"closing\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#52596f350c0975f7af736665066182d4215b3608", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 12 | Files Changed: 1 | Hunks: 8 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 24 | Churn Cumulative: 313 | Contributors (this commit): 1 | Commits (past 90d): 9 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -16,8 +16,8 @@ from scrapy.conf import settings\n \n class ScrapyProcessProtocol(protocol.ProcessProtocol):\n \n-    def __init__(self, procman, domain, logfile=None, spider_settings=None):\n-        self.procman = procman\n+    def __init__(self, worker, domain, logfile=None, spider_settings=None):\n+        self.worker = worker\n         self.domain = domain\n         self.logfile = logfile\n         self.start_time = datetime.datetime.utcnow()\n@@ -70,7 +70,7 @@ class ScrapyProcessProtocol(protocol.ProcessProtocol):\n         log.msg(\"ClusterWorker: started domain=%s pid=%d log=%s\" % (self.domain, self.pid, self.logfile))\n         self.transport.closeStdin()\n         self.status = \"running\"\n-        self.procman.update_master(self.domain, \"running\")\n+        self.worker.update_master(self.domain, \"running\")\n \n     def processEnded(self, status):\n         if isinstance(status.value, ProcessDone):\n@@ -80,9 +80,9 @@ class ScrapyProcessProtocol(protocol.ProcessProtocol):\n             st = \"terminated\"\n             er = \", error=%s\" % str(status.value)\n         log.msg(\"ClusterWorker: finished domain=%s status=%s pid=%d log=%s%s\" % (self.domain, st, self.pid, self.logfile, er))\n-        del self.procman.running[self.domain]\n-        del self.procman.crawlers[self.pid]\n-        self.procman.update_master(self.domain, \"scraped\")\n+        del self.worker.running[self.domain]\n+        del self.worker.crawlers[self.pid]\n+        self.worker.update_master(self.domain, st)\n \n class ClusterWorker(pb.Root):\n \n@@ -135,9 +135,9 @@ class ClusterWorker(pb.Root):\n \n     def update_master(self, domain, domain_status):\n         try:\n-            deferred = self.__master.callRemote(\"update\", self.status(), domain, domain_status)\n+            deferred = self._master.callRemote(\"update\", self.status(), domain, domain_status)\n         except pb.DeadReferenceError:\n-            self.__master = None\n+            self._master = None\n             log.msg(\"Lost connection to master\", log.ERROR)\n         else:\n             deferred.addCallbacks(callback=lambda x: x, errback=lambda reason: log.msg(reason, log.ERROR))\n@@ -145,7 +145,7 @@ class ClusterWorker(pb.Root):\n     def remote_set_master(self, master):\n         \"\"\"Set the master for this worker\"\"\"\n         log.msg(\"ClusterWorker: ClusterMaster connected from %s:%s\" % master.broker.transport.client)\n-        self.__master = master\n+        self._master = master\n         return self.status()\n \n     def remote_stop(self, domain):\n@@ -173,13 +173,13 @@ class ClusterWorker(pb.Root):\n                 logfile = os.path.join(self.logdir, domain, time.strftime(\"%FT%T.log\"))\n                 if not os.path.exists(os.path.dirname(logfile)):\n                     os.makedirs(os.path.dirname(logfile))\n-                scrapy_proc = ScrapyProcessProtocol(self, domain, logfile, spider_settings)\n-                args = [sys.executable, sys.argv[0], 'crawl', domain]\n-                self.running[domain] = scrapy_proc\n \n                 for prerun_hook in self.prerun_hooks:\n                     prerun_hook(domain, spider_settings)\n \n+                scrapy_proc = ScrapyProcessProtocol(self, domain, logfile, spider_settings)\n+                args = [sys.executable, sys.argv[0], 'crawl', domain]\n+                self.running[domain] = scrapy_proc\n                 reactor.spawnProcess(scrapy_proc, sys.executable, args=args, env=scrapy_proc.env)\n                 return self.status(ResponseCode.DOMAIN_STARTED, \"Started process %s\" % scrapy_proc)\n             else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#874ac0c256e94596ee9606d96087c932d0e8dfc1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 110 | Lines Deleted: 94 | Files Changed: 2 | Hunks: 26 | Methods Changed: 28 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 204 | Churn Cumulative: 957 | Contributors (this commit): 1 | Commits (past 90d): 7 | Contributors (cumulative): 2 | DMM Complexity: 0.8333333333333334\n\nDIFF:\n@@ -14,8 +14,6 @@ from scrapy.core.exceptions import NotConfigured\n from scrapy.contrib.pbcluster.worker.manager import ResponseCode\n from scrapy.conf import settings\n \n-DEFAULT_PRIORITY = settings.getint(\"DEFAULT_PRIORITY\", 20)\n-\n def my_import(name):\n     mod = __import__(name)\n     components = name.split('.')\n@@ -35,9 +33,11 @@ class ClusterNodeBroker(pb.Referenceable):\n             deferred = self._worker.callRemote(\"set_master\", self)\n         except pb.DeadReferenceError:\n             self._set_status(None)\n-            log.msg(\"ClusterMaster: lost connection to node %s.\" % (self.name), log.ERROR)\n+            log.msg(\"ClusterMaster: Lost connection to node %s.\" % self.name, log.ERROR)\n         else:\n-            deferred.addCallbacks(callback=self._set_status, errback=lambda reason: log.msg(reason, log.ERROR))\n+            def _eb(failure):\n+                self._logfailure(\"Error while setting master to worker node\", failure)\n+            deferred.addCallbacks(callback=self._set_status, errback=_eb)\n             \n     def status_as_dict(self, verbosity=1):\n         if verbosity == 0:\n@@ -61,6 +61,85 @@ class ClusterNodeBroker(pb.Referenceable):\n             status[\"loadavg\"] = self.loadavg\n         return status\n         \n+    def update_status(self):\n+        \"\"\"Update status from this worker. This is called periodically.\"\"\"\n+        try:\n+            deferred = self._worker.callRemote(\"status\")\n+        except pb.DeadReferenceError:\n+            self._set_status(None)\n+            log.msg(\"ClusterMaster: Lost connection to worker=%s.\" % self.name, log.ERROR)\n+        else:\n+            def _eb(failure):\n+                self._logfailure(\"Error while updating status\", failure)\n+            deferred.addCallbacks(callback=self._set_status, errback=_eb)\n+\n+    def stop(self, domain):\n+        try:\n+            deferred = self._worker.callRemote(\"stop\", domain)\n+        except pb.DeadReferenceError:\n+            self._set_status(None)\n+            log.msg(\"ClusterMaster: Lost connection to worker=%s.\" % self.name, log.ERROR)\n+        else:\n+            def _eb(failure):\n+                self._logfailure(\"Error while stopping domain=%s\" % domain, failure)\n+            deferred.addCallbacks(callback=self._set_status, errback=_eb)\n+\n+    def run(self, domain_info):\n+        \"\"\"Run the given domain. \n+        \n+        domain_info is a dict of keys:\n+        domain - the domain to run\n+        settings - the settings to use\n+        priority - the priority to use\n+        \"\"\"\n+\n+        domain = domain_info['domain']\n+        dsettings  = domain_info['settings']\n+        priority = domain_info['priority']\n+\n+        def _run_errback(failure):\n+            self._logfailure(\"Error while running domain=%s\" % domain, failure)\n+            self.master.loading.remove(domain)\n+            newprio = priority - 1 # increase priority for reschedule\n+            self.master.schedule([domain], dsettings, newprio)\n+            \n+        def _run_callback(status):\n+            if status['callresponse'][0] == ResponseCode.NO_FREE_SLOT:\n+                log.msg(\"ClusterMaster: No available slots at worker=%s when trying to run domain=%s\" % (self.name, domain), log.WARNING)\n+                self.master.loading.remove(domain)\n+                newprio = priority - 1 # increase priority for rerunning asap\n+                self.master.schedule([domain], dsettings, newprio)\n+            elif status['callresponse'][0] == ResponseCode.DOMAIN_ALREADY_RUNNING:\n+                log.msg(\"ClusterMaster: Already running domain=%s at worker=%s\" % (domain, self.name), log.WARNING)\n+                self.master.loading.remove(domain)\n+                self.master.schedule([domain], dsettings, priority)\n+\n+        try:\n+            log.msg(\"ClusterMaster: Running domain=%s at worker=%s\" % (domain, self.name), log.DEBUG)\n+            deferred = self._worker.callRemote(\"run\", domain, dsettings)\n+        except pb.DeadReferenceError:\n+            self._set_status(None)\n+            log.msg(\"ClusterMaster: Lost connection to worker=%s.\" % self.name, log.ERROR)\n+        else:\n+            deferred.addCallbacks(callback=_run_callback, errback=_run_errback)\n+        \n+    def remote_update(self, worker_status, domain, domain_status):\n+        \"\"\"Called remotely form worker when domains finish to update status\"\"\"\n+        self._set_status(worker_status)\n+        if domain in self.master.loading and domain_status == \"running\":\n+            self.master.loading.remove(domain)\n+            self.master.statistics[\"domains\"][\"running\"].add(domain)\n+        elif domain_status in (\"done\", \"terminated\"):\n+            self.master.statistics[\"domains\"][\"running\"].remove(domain)\n+            self.master.statistics[\"domains\"][\"scraped\"][domain] = self.master.statistics[\"domains\"][\"scraped\"].get(domain, 0) + 1\n+            self.master.statistics[\"scraped_count\"] = self.master.statistics.get(\"scraped_count\", 0) + 1\n+            if domain in self.master.statistics[\"domains\"][\"lost\"]:\n+                self.master.statistics[\"domains\"][\"lost\"].remove(domain)\n+        log.msg(\"ClusterMaster: Changed status to <%s> for domain=%s at worker=%s\" % (domain_status, domain, self.name))\n+\n+    def _logfailure(self, msg, failure):\n+        log.msg(\"ClusterMaster: %s (worker=%s)\\n%s\" % (msg, self.name, failure), log.ERROR)\n+\n     def _set_status(self, status):\n         if not status:\n             self.alive = False\n@@ -85,72 +164,6 @@ class ClusterNodeBroker(pb.Referenceable):\n                     self.run(pending)\n                     self.master.loading.append(pending['domain'])\n \n-    def update_status(self):\n-        try:\n-            deferred = self._worker.callRemote(\"status\")\n-        except pb.DeadReferenceError:\n-            self._set_status(None)\n-            log.msg(\"ClusterMaster: Lost connection to node %s.\" % (self.name), log.ERROR)\n-        else:\n-            deferred.addCallbacks(callback=self._set_status, errback=lambda reason: log.msg(reason, log.ERROR))\n-\n-    def stop(self, domain):\n-        try:\n-            deferred = self._worker.callRemote(\"stop\", domain)\n-        except pb.DeadReferenceError:\n-            self._set_status(None)\n-            log.msg(\"ClusterMaster: Lost connection to node %s.\" % (self.name), log.ERROR)\n-        else:\n-            deferred.addCallbacks(callback=self._set_status, errback=lambda reason: log.msg(reason, log.ERROR))\n-\n-    def run(self, domain_info):\n-        \"\"\"Run the given domain. \n-        \n-        domain_info keys:\n-        domain - the domain to run\n-        settings - the settings to use\n-        priority - the priority to use\n-        \"\"\"\n-\n-        def _run_errback(reason):\n-            log.msg(reason, log.ERROR)\n-            self.master.loading.remove(domain_info['domain'])\n-            self.master.schedule([domain_info['domain']], domain_info['settings'], domain_info['priority'] - 1)\n-            log.msg(\"ClusterMaster: Domain %s rescheduled: lost connection to node.\" % domain_info['domain'], log.WARNING)\n-            \n-        def _run_callback(status):\n-            if status['callresponse'][0] == ResponseCode.NO_FREE_SLOT:\n-                # slots are complete. Reschedule in master with priority reduced by one.\n-                # self.master.loading check should avoid this to happen\n-                self.master.loading.remove(domain_info['domain'])\n-                self.master.schedule([domain_info['domain']], domain_info['settings'], domain_info['priority'] - 1)\n-                log.msg(\"ClusterMaster: Domain %s rescheduled: no availble processes in worker\" % domain_info['domain'], log.WARNING)\n-            elif status['callresponse'][0] == ResponseCode.DOMAIN_ALREADY_RUNNING:\n-                # domain already running in node. Reschedule with same priority.\n-                # self.master.loading check should avoid this to happen\n-                self.master.loading.remove(domain_info['domain'])\n-                self.master.schedule([domain_info['domain']], domain_info['settings'], domain_info['priority'])\n-                log.msg(\"ClusterMaster: Domain %s rescheduled: already running in node.\" % domain_info['domain'], log.WARNING)\n-\n-        try:\n-            deferred = self._worker.callRemote(\"run\", domain_info[\"domain\"], domain_info[\"settings\"])\n-        except pb.DeadReferenceError:\n-            self._set_status(None)\n-            log.msg(\"ClusterMaster: Lost connection to node %s.\" % (self.name), log.ERROR)\n-        else:\n-            deferred.addCallbacks(callback=_run_callback, errback=_run_errback)\n-        \n-    def remote_update(self, status, domain, domain_status):\n-        self._set_status(status)\n-        if domain in self.master.loading and domain_status == \"running\":\n-            self.master.loading.remove(domain)\n-            self.master.statistics[\"domains\"][\"running\"].add(domain)\n-        elif domain_status == \"scraped\":\n-            self.master.statistics[\"domains\"][\"running\"].remove(domain)\n-            self.master.statistics[\"domains\"][\"scraped\"][domain] = self.master.statistics[\"domains\"][\"scraped\"].get(domain, 0) + 1\n-            self.master.statistics[\"scraped_count\"] = self.master.statistics.get(\"scraped_count\", 0) + 1\n-            if domain in self.master.statistics[\"domains\"][\"lost\"]:\n-                self.master.statistics[\"domains\"][\"lost\"].remove(domain)\n \n class ScrapyPBClientFactory(pb.PBClientFactory):\n \n@@ -163,8 +176,9 @@ class ScrapyPBClientFactory(pb.PBClientFactory):\n         \n     def clientConnectionLost(self, *args, **kargs):\n         pb.PBClientFactory.clientConnectionLost(self, *args, **kargs)\n-        del self.master.nodes[self.nodename]\n-        log.msg(\"ClusterMaster: Lost connection to %s. Node removed\" % self.nodename )\n+        self.master.remove_node(self.nodename)\n+        log.msg(\"ClusterMaster: Lost connection to worker=%s. Node removed\" % self.nodename)\n+\n \n class ClusterMaster(object):\n \n@@ -172,7 +186,9 @@ class ClusterMaster(object):\n \n         if not settings.getbool('CLUSTER_MASTER_ENABLED'):\n             raise NotConfigured\n-        if not settings['CLUSTER_MASTER_STATEFILE']:\n+\n+        self.statefile = settings['CLUSTER_MASTER_STATEFILE']\n+        if not self.statefile:\n             raise NotConfigured(\"ClusterMaster: Missing CLUSTER_MASTER_STATEFILE setting\")\n \n         # import groups settings\n@@ -182,12 +198,14 @@ class ClusterMaster(object):\n             self.get_spider_groupsettings = lambda x: {}\n         # load pending domains\n         try:\n-            statefile = open(settings[\"CLUSTER_MASTER_STATEFILE\"], \"r\")\n+            statefile = open(self.statefile, \"r\")\n             self.pending = pickle.load(statefile)\n+            log.msg(\"ClusterMaster: Loaded state from %s\" % self.statefile)\n         except IOError:\n             self.pending = []\n         self.loading = []\n         self.nodes = {}\n+        self.nodesconf = settings.get('CLUSTER_MASTER_NODES', {})\n         self.start_time = datetime.datetime.utcnow()\n         # for more info about statistics see self.update_nodes() and ClusterNodeBroker.remote_update()\n         self.statistics = {\"domains\": {\"running\": set(), \"scraped\": {}, \"lost_count\": {}, \"lost\": set()}, \"scraped_count\": 0 }\n@@ -201,34 +219,32 @@ class ClusterMaster(object):\n         \n     def load_nodes(self):\n         \"\"\"Loads nodes listed in CLUSTER_MASTER_NODES setting\"\"\"\n-        for name, hostport in settings.get('CLUSTER_MASTER_NODES', {}).iteritems():\n+        for name, hostport in self.nodesconf.iteritems():\n             self.load_node(name, hostport)\n             \n     def load_node(self, name, hostport):\n         \"\"\"Creates the remote reference for a worker node\"\"\"\n         server, port = hostport.split(\":\")\n         port = int(port)\n-        log.msg(\"ClusterMaster: Connecting to worker %s (%s)...\" % (name, hostport))\n+        log.msg(\"ClusterMaster: Connecting to worker=%s (%s)...\" % (name, hostport))\n         factory = ScrapyPBClientFactory(self, name)\n         try:\n             reactor.connectTCP(server, port, factory)\n         except Exception, err:\n-            log.msg(\"ClusterMaster: Could not connect to worker %s (%s): %s\" % (name, hostport, err), log.ERROR)\n+            log.msg(\"ClusterMaster: Could not connect to worker=%s (%s): %s\" % (name, hostport, err), log.ERROR)\n         else:\n-            def _errback(_reason):\n-                log.msg(\"ClusterMaster: Could not connect to worker %s (%s): %s\" % (name, hostport, _reason), log.ERROR)\n+            def _eb(failure):\n+                self._logfailure(\"Error while loading worker node\", failure)\n \n             d = factory.getRootObject()\n-            d.addCallbacks(callback=lambda obj: self.add_node(obj, name), errback=_errback)\n+            d.addCallbacks(callback=lambda obj: self.add_node(obj, name), errback=_eb)\n \n     def update_nodes(self):\n         \"\"\"Update worker nodes statistics\"\"\"\n-        for name, hostport in settings.get('CLUSTER_MASTER_NODES', {}).iteritems():\n+        for name, hostport in self.nodesconf.iteritems():\n             if name in self.nodes and self.nodes[name].alive:\n-                log.msg(\"ClusterMaster: Updating stats from worker node %s (%s)\" % (name, hostport))\n                 self.nodes[name].update_status()\n             else:\n-                log.msg(\"ClusterMaster: Reloading worker node %s (%s)\" % (name, hostport))\n                 self.load_node(name, hostport)\n         \n         real_running = set(self.running.keys())\n@@ -241,7 +257,10 @@ class ClusterMaster(object):\n         \"\"\"Add node given its node\"\"\"\n         node = ClusterNodeBroker(cworker, name, self)\n         self.nodes[name] = node\n-        log.msg(\"ClusterMaster: Added cluster worker %s\" % name)\n+        log.msg(\"ClusterMaster: Added worker=%s\" % name)\n+\n+    def remove_node(self, nodename):\n+        del self.nodes[nodename]\n \n     def disable_node(self, name):\n         self.nodes[name].available = False\n@@ -249,10 +268,7 @@ class ClusterMaster(object):\n     def enable_node(self, name):\n         self.nodes[name].available = True\n \n-    def remove_node(self, nodename):\n-        raise NotImplemented\n-\n-    def schedule(self, domains, spider_settings=None, priority=DEFAULT_PRIORITY):\n+    def schedule(self, domains, spider_settings=None, priority=20):\n         \"\"\"Schedule the given domains, with the given priority\"\"\"\n         insert_pos = len([p for p in self.pending if ['priority'] <= priority])\n         for domain in domains:\n@@ -324,9 +340,9 @@ class ClusterMaster(object):\n \n     def _engine_started(self):\n         self.load_nodes()\n-        scrapyengine.addtask(self.update_nodes, settings.getint('CLUSTER_MASTER_POLL_INTERVAL'))\n+        scrapyengine.addtask(self.update_nodes, settings.getint('CLUSTER_MASTER_POLL_INTERVAL', 60))\n \n     def _engine_stopped(self):\n-        with open(settings[\"CLUSTER_MASTER_STATEFILE\"], \"w\") as f:\n+        with open(self.statefile, \"w\") as f:\n             pickle.dump(self.pending, f)\n-            log.msg(\"ClusterMaster: state saved in %s\" % settings[\"CLUSTER_MASTER_STATEFILE\"])\n+            log.msg(\"ClusterMaster: Saved state in %s\" % self.statefile)\n\n@@ -4,7 +4,7 @@ from pydispatch import dispatcher\n \n from scrapy.spider import spiders \n from scrapy.management.web import banner, webconsole_discover_module\n-from scrapy.contrib.pbcluster.master.manager import ClusterMaster, DEFAULT_PRIORITY\n+from scrapy.contrib.pbcluster.master.manager import ClusterMaster\n from scrapy.utils.serialization import serialize\n \n class ClusterMasterWeb(ClusterMaster):\n@@ -61,7 +61,7 @@ class ClusterMasterWeb(ClusterMaster):\n             else:\n                 sep = \"\\r\"\n                 domains = args[\"schedule\"]\n-            priority = int(args.get(\"priority\", [DEFAULT_PRIORITY])[0])\n+            priority = int(args.get(\"priority\", [20])[0])\n             \n             # spider settings\n             slist = args.get(\"settings\", [\"\"])[0].split(sep)\n@@ -164,7 +164,7 @@ class ClusterMasterWeb(ClusterMaster):\n         s += \"<br />\\n\"\n         \n         s += \"Priority:<br />\\n\"\n-        s += \"<input type='text' name='priority'>%s</input>\" % DEFAULT_PRIORITY\n+        s += \"<input type='text' name='priority'>%s</input>\" % 20\n         s += \"<br />\\n\"\n         \n         # spider settings\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
