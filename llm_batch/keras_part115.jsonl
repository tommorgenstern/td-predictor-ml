{"custom_id": "keras#8193287e08ccf163d99ddc9992f5e02cf70c4eab", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 1674 | Contributors (this commit): 26 | Commits (past 90d): 12 | Contributors (cumulative): 26 | DMM Complexity: None\n\nDIFF:\n@@ -315,11 +315,13 @@ class EarlyStopping(Callback):\n         patience: number of epochs with no improvement\n             after which training will be stopped.\n         verbose: verbosity mode.\n-        mode: one of {auto, min, max}. In 'min' mode,\n+        mode: one of {auto, min, max}. In `min` mode,\n             training will stop when the quantity\n-            monitored has stopped decreasing; in 'max'\n+            monitored has stopped decreasing; in `max`\n             mode it will stop when the quantity\n-            monitored has stopped increasing.\n+            monitored has stopped increasing; in `auto`\n+            mode, the direction is automatically inferred\n+            from the name of the monitored quantity.\n     '''\n     def __init__(self, monitor='val_loss', patience=0, verbose=0, mode='auto'):\n         super(EarlyStopping, self).__init__()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8af0264a77539a12e05a65ff1f1f43af1094c493", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 233 | Contributors (this commit): 9 | Commits (past 90d): 10 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -23,7 +23,7 @@ _keras_dir = os.path.join(_keras_base_dir, '.keras')\n if not os.path.exists(_keras_dir):\n     os.makedirs(_keras_dir)\n \n-_BACKEND = 'theano'\n+_BACKEND = 'tensorflow'\n _config_path = os.path.expanduser(os.path.join(_keras_dir, 'keras.json'))\n if os.path.exists(_config_path):\n     _config = json.load(open(_config_path))\n\n@@ -6,7 +6,7 @@ from collections import defaultdict\n _FLOATX = 'float32'\n _EPSILON = 10e-8\n _UID_PREFIXES = defaultdict(int)\n-_IMAGE_DIM_ORDERING = 'th'\n+_IMAGE_DIM_ORDERING = 'tf'\n _LEGACY_WEIGHT_ORDERING = False\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d90e1db50bfb5ba4327fca19e512d52d27a75bd0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 237 | Contributors (this commit): 9 | Commits (past 90d): 12 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -23,7 +23,7 @@ _keras_dir = os.path.join(_keras_base_dir, '.keras')\n if not os.path.exists(_keras_dir):\n     os.makedirs(_keras_dir)\n \n-_BACKEND = 'tensorflow'\n+_BACKEND = 'theano'\n _config_path = os.path.expanduser(os.path.join(_keras_dir, 'keras.json'))\n if os.path.exists(_config_path):\n     _config = json.load(open(_config_path))\n\n@@ -6,7 +6,7 @@ from collections import defaultdict\n _FLOATX = 'float32'\n _EPSILON = 10e-8\n _UID_PREFIXES = defaultdict(int)\n-_IMAGE_DIM_ORDERING = 'tf'\n+_IMAGE_DIM_ORDERING = 'th'\n _LEGACY_WEIGHT_ORDERING = False\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#82318263a1e270ff5412609964bfa31a886558e9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 48 | Lines Deleted: 45 | Files Changed: 8 | Hunks: 40 | Methods Changed: 22 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 93 | Churn Cumulative: 7888 | Contributors (this commit): 54 | Commits (past 90d): 126 | Contributors (cumulative): 112 | DMM Complexity: 1.0\n\nDIFF:\n@@ -23,7 +23,7 @@ _keras_dir = os.path.join(_keras_base_dir, '.keras')\n if not os.path.exists(_keras_dir):\n     os.makedirs(_keras_dir)\n \n-_BACKEND = 'theano'\n+_BACKEND = 'tensorflow'\n _config_path = os.path.expanduser(os.path.join(_keras_dir, 'keras.json'))\n if os.path.exists(_config_path):\n     _config = json.load(open(_config_path))\n\n@@ -6,7 +6,7 @@ from collections import defaultdict\n _FLOATX = 'float32'\n _EPSILON = 10e-8\n _UID_PREFIXES = defaultdict(int)\n-_IMAGE_DIM_ORDERING = 'th'\n+_IMAGE_DIM_ORDERING = 'tf'\n _LEGACY_WEIGHT_ORDERING = False\n \n \n\n@@ -844,7 +844,7 @@ def temporal_padding(x, padding=1):\n     return tf.pad(x, pattern)\n \n \n-def spatial_2d_padding(x, padding=(1, 1), dim_ordering='th'):\n+def spatial_2d_padding(x, padding=(1, 1), dim_ordering=_IMAGE_DIM_ORDERING):\n     '''Pads the 2nd and 3rd dimensions of a 4D tensor\n     with \"padding[0]\" and \"padding[1]\" (resp.) zeros left and right.\n     '''\n@@ -858,7 +858,7 @@ def spatial_2d_padding(x, padding=(1, 1), dim_ordering='th'):\n     return tf.pad(x, pattern)\n \n \n-def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='th'):\n+def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering=_IMAGE_DIM_ORDERING):\n     '''Pads 5D tensor with zeros for the depth, height, width dimension with\n     \"padding[0]\", \"padding[1]\" and \"padding[2]\" (resp.) zeros left and right\n \n\n@@ -573,7 +573,7 @@ def temporal_padding(x, padding=1):\n     return T.set_subtensor(output[:, padding:x.shape[1] + padding, :], x)\n \n \n-def spatial_2d_padding(x, padding=(1, 1), dim_ordering='th'):\n+def spatial_2d_padding(x, padding=(1, 1), dim_ordering=_IMAGE_DIM_ORDERING):\n     '''Pad the 2nd and 3rd dimensions of a 4D tensor\n     with \"padding[0]\" and \"padding[1]\" (resp.) zeros left and right.\n     '''\n@@ -604,7 +604,7 @@ def spatial_2d_padding(x, padding=(1, 1), dim_ordering='th'):\n     return T.set_subtensor(output[indices], x)\n \n \n-def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='th'):\n+def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering=_IMAGE_DIM_ORDERING):\n     '''Pad the 2nd, 3rd and 4th dimensions of a 5D tensor\n     with \"padding[0]\", \"padding[1]\" and \"padding[2]\" (resp.) zeros left and right.\n     '''\n@@ -1197,7 +1197,7 @@ def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n \n \n def conv3d(x, kernel, strides=(1, 1, 1),\n-           border_mode='valid', dim_ordering='th',\n+           border_mode='valid', dim_ordering=_IMAGE_DIM_ORDERING,\n            volume_shape=None, filter_shape=None):\n     '''\n     Run on cuDNN if available.\n@@ -1259,7 +1259,7 @@ def conv3d(x, kernel, strides=(1, 1, 1),\n \n \n def pool2d(x, pool_size, strides=(1, 1), border_mode='valid',\n-           dim_ordering='th', pool_mode='max'):\n+           dim_ordering=_IMAGE_DIM_ORDERING, pool_mode='max'):\n     if border_mode == 'same':\n         w_pad = pool_size[0] - 2 if pool_size[0] % 2 == 1 else pool_size[0] - 1\n         h_pad = pool_size[1] - 2 if pool_size[1] % 2 == 1 else pool_size[1] - 1\n@@ -1302,7 +1302,7 @@ def pool2d(x, pool_size, strides=(1, 1), border_mode='valid',\n \n \n def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n-           dim_ordering='th', pool_mode='max'):\n+           dim_ordering=_IMAGE_DIM_ORDERING, pool_mode='max'):\n     if border_mode == 'same':\n         # TODO: add implementation for border_mode=\"same\"\n         raise Exception('border_mode=\"same\" not supported with Theano.')\n\n@@ -16,7 +16,7 @@ def test_image_classification():\n     with convolutional hidden layer.\n     '''\n     np.random.seed(1337)\n-    input_shape = (3, 16, 16)\n+    input_shape = (16, 16, 3)\n     (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=500,\n                                                          nb_test=200,\n                                                          input_shape=input_shape,\n\n@@ -487,8 +487,8 @@ class TestBackend(object):\n                 kernel_th = KTH.variable(convert_kernel(kernel_val))\n                 kernel_tf = KTF.variable(kernel_val)\n \n-                zth = KTH.eval(KTH.conv2d(xth, kernel_th))\n-                ztf = KTF.eval(KTF.conv2d(xtf, kernel_tf))\n+                zth = KTH.eval(KTH.conv2d(xth, kernel_th, dim_ordering='th'))\n+                ztf = KTF.eval(KTF.conv2d(xtf, kernel_tf, dim_ordering='th'))\n \n                 assert zth.shape == ztf.shape\n                 assert_allclose(zth, ztf, atol=1e-05)\n@@ -531,8 +531,8 @@ class TestBackend(object):\n                 kernel_th = KTH.variable(convert_kernel(kernel_val))\n                 kernel_tf = KTF.variable(kernel_val)\n \n-                zth = KTH.eval(KTH.conv3d(xth, kernel_th))\n-                ztf = KTF.eval(KTF.conv3d(xtf, kernel_tf))\n+                zth = KTH.eval(KTH.conv3d(xth, kernel_th, dim_ordering='th'))\n+                ztf = KTF.eval(KTF.conv3d(xtf, kernel_tf, dim_ordering='th'))\n \n                 assert zth.shape == ztf.shape\n                 assert_allclose(zth, ztf, atol=1e-05)\n@@ -558,23 +558,23 @@ class TestBackend(object):\n         assert_allclose(zth, ztf, atol=1e-05)\n \n     def test_pool2d(self):\n-        check_single_tensor_operation('pool2d', (5, 3, 10, 12), pool_size=(2, 2),\n+        check_single_tensor_operation('pool2d', (5, 10, 12, 3), pool_size=(2, 2),\n                                       strides=(1, 1), border_mode='valid')\n \n-        check_single_tensor_operation('pool2d', (5, 3, 9, 11), pool_size=(2, 2),\n+        check_single_tensor_operation('pool2d', (5, 9, 11, 3), pool_size=(2, 2),\n                                       strides=(1, 1), border_mode='valid')\n \n-        check_single_tensor_operation('pool2d', (5, 3, 9, 11), pool_size=(2, 3),\n+        check_single_tensor_operation('pool2d', (5, 9, 11, 3), pool_size=(2, 3),\n                                       strides=(1, 1), border_mode='valid')\n \n     def test_pool3d(self):\n-        check_single_tensor_operation('pool3d', (5, 3, 10, 12, 5), pool_size=(2, 2, 2),\n+        check_single_tensor_operation('pool3d', (5, 10, 12, 5, 3), pool_size=(2, 2, 2),\n                                       strides=(1, 1, 1), border_mode='valid')\n \n-        check_single_tensor_operation('pool3d', (5, 3, 9, 11, 5), pool_size=(2, 2, 2),\n+        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), pool_size=(2, 2, 2),\n                                       strides=(1, 1, 1), border_mode='valid')\n \n-        check_single_tensor_operation('pool3d', (5, 3, 9, 11, 5), pool_size=(2, 3, 2),\n+        check_single_tensor_operation('pool3d', (5, 9, 11, 5, 3), pool_size=(2, 3, 2),\n                                       strides=(1, 1, 1), border_mode='valid')\n \n     def test_random_normal(self):\n\n@@ -75,7 +75,7 @@ def test_convolution_2d():\n                                'nb_col': 3,\n                                'border_mode': border_mode,\n                                'subsample': subsample},\n-                       input_shape=(nb_samples, stack_size, nb_row, nb_col))\n+                       input_shape=(nb_samples, nb_row, nb_col, stack_size))\n \n             layer_test(convolutional.Convolution2D,\n                        kwargs={'nb_filter': nb_filter,\n@@ -86,7 +86,7 @@ def test_convolution_2d():\n                                'b_regularizer': 'l2',\n                                'activity_regularizer': 'activity_l2',\n                                'subsample': subsample},\n-                       input_shape=(nb_samples, stack_size, nb_row, nb_col))\n+                       input_shape=(nb_samples, nb_row, nb_col, stack_size))\n \n \n @keras_test\n@@ -108,23 +108,23 @@ def test_deconvolution_2d():\n                        kwargs={'nb_filter': nb_filter,\n                                'nb_row': 3,\n                                'nb_col': 3,\n-                               'output_shape': (nb_samples, nb_filter, rows, cols),\n+                               'output_shape': (nb_samples, rows, cols, nb_filter),\n                                'border_mode': border_mode,\n                                'subsample': subsample},\n-                       input_shape=(nb_samples, stack_size, nb_row, nb_col),\n+                       input_shape=(nb_samples, nb_row, nb_col, stack_size),\n                        fixed_batch_size=True)\n \n             layer_test(convolutional.Deconvolution2D,\n                        kwargs={'nb_filter': nb_filter,\n                                'nb_row': 3,\n                                'nb_col': 3,\n-                               'output_shape': (nb_samples, nb_filter, rows, cols),\n+                               'output_shape': (nb_samples, rows, cols, nb_filter),\n                                'border_mode': border_mode,\n                                'W_regularizer': 'l2',\n                                'b_regularizer': 'l2',\n                                'activity_regularizer': 'activity_l2',\n                                'subsample': subsample},\n-                       input_shape=(nb_samples, stack_size, nb_row, nb_col),\n+                       input_shape=(nb_samples, nb_row, nb_col, stack_size),\n                        fixed_batch_size=True)\n \n \n@@ -151,7 +151,7 @@ def test_atrous_conv_2d():\n                                    'border_mode': border_mode,\n                                    'subsample': subsample,\n                                    'atrous_rate': atrous_rate},\n-                           input_shape=(nb_samples, stack_size, nb_row, nb_col))\n+                           input_shape=(nb_samples, nb_row, nb_col, stack_size))\n \n                 layer_test(convolutional.AtrousConv2D,\n                            kwargs={'nb_filter': nb_filter,\n@@ -163,7 +163,7 @@ def test_atrous_conv_2d():\n                                    'activity_regularizer': 'activity_l2',\n                                    'subsample': subsample,\n                                    'atrous_rate': atrous_rate},\n-                           input_shape=(nb_samples, stack_size, nb_row, nb_col))\n+                           input_shape=(nb_samples, nb_row, nb_col, stack_size))\n \n \n @pytest.mark.skipif(K._BACKEND != 'tensorflow', reason=\"Requires TF backend\")\n@@ -188,7 +188,7 @@ def test_separable_conv_2d():\n                                    'border_mode': border_mode,\n                                    'subsample': subsample,\n                                    'depth_multiplier': multiplier},\n-                           input_shape=(nb_samples, stack_size, nb_row, nb_col))\n+                           input_shape=(nb_samples, nb_row, nb_col, stack_size))\n \n                 layer_test(convolutional.SeparableConv2D,\n                            kwargs={'nb_filter': nb_filter,\n@@ -203,7 +203,7 @@ def test_separable_conv_2d():\n                                    'depthwise_constraint': 'unitnorm',\n                                    'subsample': subsample,\n                                    'depth_multiplier': multiplier},\n-                           input_shape=(nb_samples, stack_size, nb_row, nb_col))\n+                           input_shape=(nb_samples, nb_row, nb_col, stack_size))\n \n \n @keras_test\n@@ -239,7 +239,7 @@ def test_maxpooling_2d():\n                    kwargs={'strides': strides,\n                            'border_mode': 'valid',\n                            'pool_size': pool_size},\n-                   input_shape=(3, 4, 11, 12))\n+                   input_shape=(3, 11, 12, 4))\n \n \n @keras_test\n@@ -253,7 +253,7 @@ def test_averagepooling_2d():\n                            kwargs={'strides': strides,\n                                    'border_mode': border_mode,\n                                    'pool_size': pool_size},\n-                           input_shape=(3, 4, 11, 12))\n+                           input_shape=(3, 11, 12, 4))\n \n \n @keras_test\n@@ -281,8 +281,9 @@ def test_convolution_3d():\n                                'kernel_dim3': kernel_dim3,\n                                'border_mode': border_mode,\n                                'subsample': subsample},\n-                       input_shape=(nb_samples, stack_size,\n-                                    input_len_dim1, input_len_dim2, input_len_dim3))\n+                       input_shape=(nb_samples,\n+                                    input_len_dim1, input_len_dim2, input_len_dim3,\n+                                    stack_size))\n \n             layer_test(convolutional.Convolution3D,\n                        kwargs={'nb_filter': nb_filter,\n@@ -294,8 +295,9 @@ def test_convolution_3d():\n                                'b_regularizer': 'l2',\n                                'activity_regularizer': 'activity_l2',\n                                'subsample': subsample},\n-                       input_shape=(nb_samples, stack_size,\n-                                    input_len_dim1, input_len_dim2, input_len_dim3))\n+                       input_shape=(nb_samples,\n+                                    input_len_dim1, input_len_dim2, input_len_dim3,\n+                                    stack_size))\n \n \n @keras_test\n@@ -329,7 +331,7 @@ def test_zero_padding_2d():\n     input_nb_row = 11\n     input_nb_col = 12\n \n-    input = np.ones((nb_samples, stack_size, input_nb_row, input_nb_col))\n+    input = np.ones((nb_samples, input_nb_row, input_nb_col, stack_size))\n \n     # basic test\n     layer_test(convolutional.ZeroPadding2D,\n@@ -342,9 +344,9 @@ def test_zero_padding_2d():\n \n     out = K.eval(layer.output)\n     for offset in [0, 1, -1, -2]:\n+        assert_allclose(out[:, offset, :, :], 0.)\n         assert_allclose(out[:, :, offset, :], 0.)\n-        assert_allclose(out[:, :, :, offset], 0.)\n-    assert_allclose(out[:, :, 2:-2, 2:-2], 1.)\n+    assert_allclose(out[:, 2:-2, 2:-2, :], 1.)\n     layer.get_config()\n \n \n@@ -355,8 +357,9 @@ def test_zero_padding_3d():\n     input_len_dim2 = 11\n     input_len_dim3 = 12\n \n-    input = np.ones((nb_samples, stack_size, input_len_dim1,\n-                     input_len_dim2, input_len_dim3))\n+    input = np.ones((nb_samples,\n+                     input_len_dim1, input_len_dim2, input_len_dim3,\n+                     stack_size))\n \n     # basic test\n     layer_test(convolutional.ZeroPadding3D,\n@@ -368,10 +371,10 @@ def test_zero_padding_3d():\n     layer.set_input(K.variable(input), shape=input.shape)\n     out = K.eval(layer.output)\n     for offset in [0, 1, -1, -2]:\n+        assert_allclose(out[:, offset, :, :, :], 0.)\n         assert_allclose(out[:, :, offset, :, :], 0.)\n         assert_allclose(out[:, :, :, offset, :], 0.)\n-        assert_allclose(out[:, :, :, :, offset], 0.)\n-    assert_allclose(out[:, :, 2:-2, 2:-2, 2:-2], 1.)\n+    assert_allclose(out[:, 2:-2, 2:-2, 2:-2, :], 1.)\n     layer.get_config()\n \n \n\n@@ -43,10 +43,10 @@ def test_TimeDistributed():\n \n     # test with Convolution2D\n     model = Sequential()\n-    model.add(wrappers.TimeDistributed(convolutional.Convolution2D(5, 2, 2, border_mode='same'), input_shape=(2, 3, 4, 4)))\n+    model.add(wrappers.TimeDistributed(convolutional.Convolution2D(5, 2, 2, border_mode='same'), input_shape=(2, 4, 4, 3)))\n     model.add(core.Activation('relu'))\n     model.compile(optimizer='rmsprop', loss='mse')\n-    model.train_on_batch(np.random.random((1, 2, 3, 4, 4)), np.random.random((1, 2, 5, 4, 4)))\n+    model.train_on_batch(np.random.random((1, 2, 4, 4, 3)), np.random.random((1, 2, 4, 4, 5)))\n \n     model = model_from_json(model.to_json())\n     model.summary()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c58bcc2c02ff40e602a05e3eef243757d0f34acf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 7 | Files Changed: 2 | Hunks: 7 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 6074 | Contributors (this commit): 27 | Commits (past 90d): 27 | Contributors (cumulative): 34 | DMM Complexity: 1.0\n\nDIFF:\n@@ -475,11 +475,12 @@ class Deconvolution2D(Convolution2D):\n     def __init__(self, nb_filter, nb_row, nb_col, output_shape,\n                  init='glorot_uniform', activation='linear', weights=None,\n                  border_mode='valid', subsample=(1, 1),\n-                 dim_ordering=K.image_dim_ordering(),\n+                 dim_ordering='default',\n                  W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n                  W_constraint=None, b_constraint=None,\n                  bias=True, **kwargs):\n-\n+        if dim_ordering == 'default':\n+            dim_ordering = K.image_dim_ordering()\n         if border_mode not in {'valid', 'same'}:\n             raise Exception('Invalid border mode for Deconvolution2D:', border_mode)\n \n\n@@ -108,23 +108,25 @@ def test_deconvolution_2d():\n                        kwargs={'nb_filter': nb_filter,\n                                'nb_row': 3,\n                                'nb_col': 3,\n-                               'output_shape': (nb_samples, rows, cols, nb_filter),\n+                               'output_shape': (nb_samples, nb_filter, rows, cols),\n                                'border_mode': border_mode,\n-                               'subsample': subsample},\n-                       input_shape=(nb_samples, nb_row, nb_col, stack_size),\n+                               'subsample': subsample,\n+                               'dim_ordering': 'th'},\n+                       input_shape=(nb_samples, stack_size, nb_row, nb_col),\n                        fixed_batch_size=True)\n \n             layer_test(convolutional.Deconvolution2D,\n                        kwargs={'nb_filter': nb_filter,\n                                'nb_row': 3,\n                                'nb_col': 3,\n-                               'output_shape': (nb_samples, rows, cols, nb_filter),\n+                               'output_shape': (nb_samples, nb_filter, rows, cols),\n                                'border_mode': border_mode,\n+                               'dim_ordering': 'th',\n                                'W_regularizer': 'l2',\n                                'b_regularizer': 'l2',\n                                'activity_regularizer': 'activity_l2',\n                                'subsample': subsample},\n-                       input_shape=(nb_samples, nb_row, nb_col, stack_size),\n+                       input_shape=(nb_samples, stack_size, nb_row, nb_col),\n                        fixed_batch_size=True)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#672890b1c843206c6c55afd3f2304f895c131820", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 155 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 4 | Methods Changed: 5 | Complexity Δ (Sum/Max): 14/8 | Churn Δ: 155 | Churn Cumulative: 7128 | Contributors (this commit): 29 | Commits (past 90d): 36 | Contributors (cumulative): 42 | DMM Complexity: 0.5774647887323944\n\nDIFF:\n@@ -152,6 +152,7 @@ PAGES = [\n         'page': 'layers/convolutional.md',\n         'classes': [\n             convolutional.Convolution1D,\n+            convolutional.AtrousConvolution1D,\n             convolutional.Convolution2D,\n             convolutional.AtrousConvolution2D,\n             convolutional.SeparableConvolution2D,\n\n@@ -183,6 +183,123 @@ class Convolution1D(Layer):\n         return dict(list(base_config.items()) + list(config.items()))\n \n \n+class AtrousConvolution1D(Convolution1D):\n+    '''Atrous Convolution operator for filtering neighborhoods of one-dimensional inputs.\n+    A.k.a dilated convolution or convolution with holes.\n+    When using this layer as the first layer in a model,\n+    either provide the keyword argument `input_dim`\n+    (int, e.g. 128 for sequences of 128-dimensional vectors),\n+    or `input_shape` (tuples of integers, e.g. (10, 128) for sequences\n+    of 10 vectors of 128-dimensional vectors).\n+\n+    # Example\n+\n+    ```python\n+        # apply an atrous convolution 1d with atrous rate 2 of length 3 to a sequence with 10 timesteps,\n+        # with 64 output filters\n+        model = Sequential()\n+        model.add(AtrousConvolution1D(64, 3, atrous_rate=2, border_mode='same', input_shape=(10, 32)))\n+        # now model.output_shape == (None, 10, 64)\n+\n+        # add a new atrous conv1d on top\n+        model.add(AtrousConvolution1D(32, 3, atrous_rate=2, border_mode='same'))\n+        # now model.output_shape == (None, 10, 32)\n+    ```\n+\n+    # Arguments\n+        nb_filter: Number of convolution kernels to use\n+            (dimensionality of the output).\n+        filter_length: The extension (spatial or temporal) of each filter.\n+        init: name of initialization function for the weights of the layer\n+            (see [initializations](../initializations.md)),\n+            or alternatively, Theano function to use for weights initialization.\n+            This parameter is only relevant if you don't pass a `weights` argument.\n+        activation: name of activation function to use\n+            (see [activations](../activations.md)),\n+            or alternatively, elementwise Theano function.\n+            If you don't specify anything, no activation is applied\n+            (ie. \"linear\" activation: a(x) = x).\n+        weights: list of numpy arrays to set as initial weights.\n+        border_mode: 'valid' or 'same'.\n+        subsample_length: factor by which to subsample output.\n+        atrous_rate: Factor for kernel dilation. Also called filter_dilation\n+            elsewhere.\n+        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n+            (eg. L1 or L2 regularization), applied to the main weights matrix.\n+        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n+            applied to the bias.\n+        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n+            applied to the network output.\n+        W_constraint: instance of the [constraints](../constraints.md) module\n+            (eg. maxnorm, nonneg), applied to the main weights matrix.\n+        b_constraint: instance of the [constraints](../constraints.md) module,\n+            applied to the bias.\n+        bias: whether to include a bias\n+            (i.e. make the layer affine rather than linear).\n+        input_dim: Number of channels/dimensions in the input.\n+            Either this argument or the keyword argument `input_shape`must be\n+            provided when using this layer as the first layer in a model.\n+        input_length: Length of input sequences, when it is constant.\n+            This argument is required if you are going to connect\n+            `Flatten` then `Dense` layers upstream\n+            (without it, the shape of the dense outputs cannot be computed).\n+\n+    # Input shape\n+        3D tensor with shape: `(samples, steps, input_dim)`.\n+\n+    # Output shape\n+        3D tensor with shape: `(samples, new_steps, nb_filter)`.\n+        `steps` value might have changed due to padding.\n+    '''\n+    def __init__(self, nb_filter, filter_length,\n+                 init='uniform', activation='linear', weights=None,\n+                 border_mode='valid', subsample_length=1, atrous_rate=1,\n+                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n+                 W_constraint=None, b_constraint=None,\n+                 bias=True, **kwargs):\n+\n+        if border_mode not in {'valid', 'same'}:\n+            raise Exception('Invalid border mode for AtrousConv1D:', border_mode)\n+\n+        self.atrous_rate = int(atrous_rate)\n+\n+        super(AtrousConvolution1D, self).__init__(nb_filter, filter_length,\n+                                                  init=init, activation=activation,\n+                                                  weights=weights, border_mode=border_mode,\n+                                                  subsample_length=subsample_length,\n+                                                  W_regularizer=W_regularizer, b_regularizer=b_regularizer,\n+                                                  activity_regularizer=activity_regularizer,\n+                                                  W_constraint=W_constraint, b_constraint=b_constraint,\n+                                                  bias=bias, **kwargs)\n+\n+    def get_output_shape_for(self, input_shape):\n+        length = conv_output_length(input_shape[1],\n+                                    self.filter_length,\n+                                    self.border_mode,\n+                                    self.subsample[0],\n+                                    dilation=self.atrous_rate)\n+        return (input_shape[0], length, self.nb_filter)\n+\n+    def call(self, x, mask=None):\n+        x = K.expand_dims(x, -1) # add a dimension of the right\n+        x = K.permute_dimensions(x, (0, 2, 1, 3))\n+        output = K.conv2d(x, self.W, strides=self.subsample,\n+                          border_mode=self.border_mode,\n+                          dim_ordering='th',\n+                          filter_dilation=(self.atrous_rate, self.atrous_rate))\n+        if self.bias:\n+            output += K.reshape(self.b, (1, self.nb_filter, 1, 1))\n+        output = K.squeeze(output, 3) # remove the dummy 3rd dimension\n+        output = K.permute_dimensions(output, (0, 2, 1))\n+        output = self.activation(output)\n+        return output\n+\n+    def get_config(self):\n+        config = {'atrous_rate': self.atrous_rate}\n+        base_config = super(AtrousConvolution1D, self).get_config()\n+        return dict(list(base_config.items()) + list(config.items()))\n+\n+\n class Convolution2D(Layer):\n     '''Convolution operator for filtering windows of two-dimensional inputs.\n     When using this layer as the first layer in a model,\n@@ -1649,5 +1766,6 @@ Conv1D = Convolution1D\n Conv2D = Convolution2D\n Conv3D = Convolution3D\n Deconv2D = Deconvolution2D\n+AtrousConv1D = AtrousConvolution1D\n AtrousConv2D = AtrousConvolution2D\n SeparableConv2D = SeparableConvolution2D\n\n@@ -38,6 +38,42 @@ def test_convolution_1d():\n                        input_shape=(nb_samples, nb_steps, input_dim))\n \n \n+@keras_test\n+def test_atrous_conv_1d():\n+    nb_samples = 2\n+    nb_steps = 8\n+    input_dim = 2\n+    filter_length = 3\n+    nb_filter = 3\n+\n+    for border_mode in ['valid', 'same']:\n+        for subsample_length in [1, 2]:\n+            for atrous_rate in [1, 2]:\n+                if border_mode == 'same' and subsample_length != 1:\n+                    continue\n+                if subsample_length != 1 and atrous_rate != 1:\n+                    continue\n+\n+                layer_test(convolutional.AtrousConv1D,\n+                           kwargs={'nb_filter': nb_filter,\n+                                   'filter_length': filter_length,\n+                                   'border_mode': border_mode,\n+                                   'subsample_length': subsample_length,\n+                                   'atrous_rate': atrous_rate},\n+                           input_shape=(nb_samples, nb_steps, input_dim))\n+\n+                layer_test(convolutional.AtrousConv1D,\n+                           kwargs={'nb_filter': nb_filter,\n+                                   'filter_length': filter_length,\n+                                   'border_mode': border_mode,\n+                                   'W_regularizer': 'l2',\n+                                   'b_regularizer': 'l2',\n+                                   'activity_regularizer': 'activity_l2',\n+                                   'subsample_length': subsample_length,\n+                                   'atrous_rate': atrous_rate},\n+                           input_shape=(nb_samples, nb_steps, input_dim))\n+\n+\n @keras_test\n def test_maxpooling_1d():\n     for stride in [1, 2]:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9f6acd960c0a0c699c79ca1d571783e1692568fb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 13 | Files Changed: 2 | Hunks: 9 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 32 | Churn Cumulative: 8303 | Contributors (this commit): 46 | Commits (past 90d): 46 | Contributors (cumulative): 50 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2571,6 +2571,16 @@ class Container(Layer):\n                                     ' weights, but the saved weights have ' +\n                                     str(len(weight_values)) +\n                                     ' elements.')\n+                if layer.__class__.__name__ == 'Convolution1D':\n+                    # this is for backwards compatibility with\n+                    # the old Conv1D weights format.\n+                    w = weight_values[0]\n+                    shape = w.shape\n+                    if shape[:2] != (1, layer.filter_length) or shape[3] != layer.nb_filter:\n+                        # legacy shape: (self.nb_filter, input_dim, self.filter_length, 1)\n+                        assert shape[0] == layer.nb_filter and shape[2:] == (layer.filter_length, 1)\n+                        w = np.transpose(w, (3, 2, 1, 0))\n+                        weight_values[0] = w\n                 weight_value_tuples += zip(symbolic_weights, weight_values)\n             K.batch_set_value(weight_value_tuples)\n \n\n@@ -113,7 +113,7 @@ class Convolution1D(Layer):\n \n     def build(self, input_shape):\n         input_dim = input_shape[2]\n-        self.W_shape = (self.nb_filter, input_dim, self.filter_length, 1)\n+        self.W_shape = (1, self.filter_length, input_dim, self.nb_filter)\n         self.W = self.init(self.W_shape, name='{}_W'.format(self.name))\n         if self.bias:\n             self.b = K.zeros((self.nb_filter,), name='{}_b'.format(self.name))\n@@ -152,15 +152,13 @@ class Convolution1D(Layer):\n         return (input_shape[0], length, self.nb_filter)\n \n     def call(self, x, mask=None):\n-        x = K.expand_dims(x, -1)  # add a dimension of the right\n-        x = K.permute_dimensions(x, (0, 2, 1, 3))\n+        x = K.expand_dims(x, 1)  # add a dummy dimension\n         output = K.conv2d(x, self.W, strides=self.subsample,\n                           border_mode=self.border_mode,\n-                          dim_ordering='th')\n+                          dim_ordering='tf')\n+        output = K.squeeze(output, 1)  # remove the dummy dimension\n         if self.bias:\n-            output += K.reshape(self.b, (1, self.nb_filter, 1, 1))\n-        output = K.squeeze(output, 3)  # remove the dummy 3rd dimension\n-        output = K.permute_dimensions(output, (0, 2, 1))\n+            output += K.reshape(self.b, (1, 1, self.nb_filter))\n         output = self.activation(output)\n         return output\n \n@@ -281,16 +279,14 @@ class AtrousConvolution1D(Convolution1D):\n         return (input_shape[0], length, self.nb_filter)\n \n     def call(self, x, mask=None):\n-        x = K.expand_dims(x, -1) # add a dimension of the right\n-        x = K.permute_dimensions(x, (0, 2, 1, 3))\n+        x = K.expand_dims(x, 1)  # add a dummy dimension\n         output = K.conv2d(x, self.W, strides=self.subsample,\n                           border_mode=self.border_mode,\n-                          dim_ordering='th',\n+                          dim_ordering='tf',\n                           filter_dilation=(self.atrous_rate, self.atrous_rate))\n+        output = K.squeeze(output, 1)  # remove the dummy dimension\n         if self.bias:\n-            output += K.reshape(self.b, (1, self.nb_filter, 1, 1))\n-        output = K.squeeze(output, 3) # remove the dummy 3rd dimension\n-        output = K.permute_dimensions(output, (0, 2, 1))\n+            output += K.reshape(self.b, (1, 1, self.nb_filter))\n         output = self.activation(output)\n         return output\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#305b3bed747bb8dd358cf82d11bcb1aee5b6e517", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 8 | Files Changed: 3 | Hunks: 9 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 9603 | Contributors (this commit): 48 | Commits (past 90d): 62 | Contributors (cumulative): 60 | DMM Complexity: None\n\nDIFF:\n@@ -2576,10 +2576,10 @@ class Container(Layer):\n                     # the old Conv1D weights format.\n                     w = weight_values[0]\n                     shape = w.shape\n-                    if shape[:2] != (1, layer.filter_length) or shape[3] != layer.nb_filter:\n+                    if shape[:2] != (layer.filter_length, 1) or shape[3] != layer.nb_filter:\n                         # legacy shape: (self.nb_filter, input_dim, self.filter_length, 1)\n                         assert shape[0] == layer.nb_filter and shape[2:] == (layer.filter_length, 1)\n-                        w = np.transpose(w, (3, 2, 1, 0))\n+                        w = np.transpose(w, (2, 3, 1, 0))\n                         weight_values[0] = w\n                 weight_value_tuples += zip(symbolic_weights, weight_values)\n             K.batch_set_value(weight_value_tuples)\n\n@@ -113,7 +113,7 @@ class Convolution1D(Layer):\n \n     def build(self, input_shape):\n         input_dim = input_shape[2]\n-        self.W_shape = (1, self.filter_length, input_dim, self.nb_filter)\n+        self.W_shape = (self.filter_length, 1, input_dim, self.nb_filter)\n         self.W = self.init(self.W_shape, name='{}_W'.format(self.name))\n         if self.bias:\n             self.b = K.zeros((self.nb_filter,), name='{}_b'.format(self.name))\n@@ -152,11 +152,11 @@ class Convolution1D(Layer):\n         return (input_shape[0], length, self.nb_filter)\n \n     def call(self, x, mask=None):\n-        x = K.expand_dims(x, 1)  # add a dummy dimension\n+        x = K.expand_dims(x, 2)  # add a dummy dimension\n         output = K.conv2d(x, self.W, strides=self.subsample,\n                           border_mode=self.border_mode,\n                           dim_ordering='tf')\n-        output = K.squeeze(output, 1)  # remove the dummy dimension\n+        output = K.squeeze(output, 2)  # remove the dummy dimension\n         if self.bias:\n             output += K.reshape(self.b, (1, 1, self.nb_filter))\n         output = self.activation(output)\n@@ -279,12 +279,12 @@ class AtrousConvolution1D(Convolution1D):\n         return (input_shape[0], length, self.nb_filter)\n \n     def call(self, x, mask=None):\n-        x = K.expand_dims(x, 1)  # add a dummy dimension\n+        x = K.expand_dims(x, 2)  # add a dummy dimension\n         output = K.conv2d(x, self.W, strides=self.subsample,\n                           border_mode=self.border_mode,\n                           dim_ordering='tf',\n                           filter_dilation=(self.atrous_rate, self.atrous_rate))\n-        output = K.squeeze(output, 1)  # remove the dummy dimension\n+        output = K.squeeze(output, 2)  # remove the dummy dimension\n         if self.bias:\n             output += K.reshape(self.b, (1, 1, self.nb_filter))\n         output = self.activation(output)\n\n@@ -17,9 +17,10 @@ def test_convolution_1d():\n     nb_filter = 3\n \n     for border_mode in ['valid', 'same']:\n-        for subsample_length in [1]:\n+        for subsample_length in [1, 2]:\n             if border_mode == 'same' and subsample_length != 1:\n                 continue\n+\n             layer_test(convolutional.Convolution1D,\n                        kwargs={'nb_filter': nb_filter,\n                                'filter_length': filter_length,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ee2d08ff798ba8aa02e14db0aeec0cca613f428a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 7 | Churn Cumulative: 440 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -20,6 +20,13 @@ class Wrapper(Layer):\n         self.regularizers = getattr(self.layer, 'regularizers', [])\n         self.constraints = getattr(self.layer, 'constraints', {})\n \n+        # properly attribute the current layer to\n+        # regularizers that need access to it\n+        # (e.g. ActivityRegularizer).\n+        for regularizer in self.regularizers:\n+            if hasattr(regularizer, 'set_layer'):\n+                regularizer.set_layer(self)\n+\n     def get_weights(self):\n         weights = self.layer.get_weights()\n         return weights\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1dc5d43d3232c15247a5ddd1ed97e930e8ba1505", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 220 | Files Changed: 1 | Hunks: 1 | Methods Changed: 4 | Complexity Δ (Sum/Max): -8/0 | Churn Δ: 220 | Churn Cumulative: 542 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,220 +0,0 @@\n-'''This script demonstrates how to build a deep residual network\n-using the Keras functional API.\n-\n-get_resnet50() returns the deep residual network model (50 layers)\n-\n-Please visit Kaiming He's GitHub homepage:\n-https://github.com/KaimingHe\n-for more information.\n-\n-The related paper is\n-'Deep Residual Learning for Image Recognition'\n-Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n-http://arxiv.org/abs/1512.03385\n-\n-Pretrained weights were converted from Kaiming He's caffe model directly.\n-\n-For now we provide weights for the tensorflow backend only,\n-thus use 'tf' dim_ordering (e.g. input_shape=(224, 224, 3) for 224*224 color image)\n-would accelerate the computation, but we also provide weights for 'th' dim_ordering for compatibility.\n-You can set your default dim ordering in your Keras config file at ~/.keras/keras.json\n-\n-please donwload them at:\n-http://pan.baidu.com/s/1o8pO2q2 ('th' dim ordering, for China)\n-http://pan.baidu.com/s/1pLanuTt ('tf' dim ordering, for China)\n-\n-https://drive.google.com/open?id=0B4ChsjFJvew3NVQ2U041Q0xHRHM ('th' dim ordering, for other countries)\n-https://drive.google.com/open?id=0B4ChsjFJvew3NWN5THdxcTdSWmc ('tf' dim ordering, for other countries)\n-\n-@author: BigMoyan, University of Electronic Science and Technology of China\n-'''\n-from __future__ import print_function\n-from keras.layers import merge\n-from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n-from keras.layers.core import Dense, Activation, Flatten\n-from keras.layers.normalization import BatchNormalization\n-from keras.models import Model\n-from keras.layers import Input\n-from keras.preprocessing.image import load_img, img_to_array\n-import keras.backend as K\n-import numpy as np\n-\n-# The names of layers in resnet50 are generated with the following format\n-# [type][stage][block]_branch[branch][layer]\n-# type: 'res' for conv layer, 'bn' and 'scale' for BN layer\n-# stage: from '2' to '5', current stage number\n-# block: 'a','b','c'... for different blocks in a stage\n-# branch: '1' for shortcut and '2' for main path\n-# layer: 'a','b','c'... for different layers in a block\n-\n-\n-def identity_block(input_tensor, kernel_size, filters, stage, block):\n-    '''The identity_block is the block that has no conv layer at shortcut\n-\n-    # Arguments\n-        input_tensor: input tensor\n-        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n-        filters: list of integers, the nb_filters of 3 conv layer at main path\n-        stage: integer, current stage label, used for generating layer names\n-        block: 'a','b'..., current block label, used for generating layer names\n-    '''\n-    dim_ordering = K.image_dim_ordering()\n-    nb_filter1, nb_filter2, nb_filter3 = filters\n-    if dim_ordering == 'tf':\n-        bn_axis = 3\n-    else:\n-        bn_axis = 1\n-    conv_name_base = 'res' + str(stage) + block + '_branch'\n-    bn_name_base = 'bn' + str(stage) + block + '_branch'\n-\n-    out = Convolution2D(nb_filter1, 1, 1, dim_ordering=dim_ordering, name=conv_name_base + '2a')(input_tensor)\n-    out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(out)\n-    out = Activation('relu')(out)\n-\n-    out = Convolution2D(nb_filter2, kernel_size, kernel_size, border_mode='same',\n-                        dim_ordering=dim_ordering, name=conv_name_base + '2b')(out)\n-    out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(out)\n-    out = Activation('relu')(out)\n-\n-    out = Convolution2D(nb_filter3, 1, 1, dim_ordering=dim_ordering, name=conv_name_base + '2c')(out)\n-    out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(out)\n-\n-    out = merge([out, input_tensor], mode='sum')\n-    out = Activation('relu')(out)\n-    return out\n-\n-\n-def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n-    '''conv_block is the block that has a conv layer at shortcut\n-\n-    # Arguments\n-        input_tensor: input tensor\n-        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n-        filters: list of integers, the nb_filters of 3 conv layer at main path\n-        stage: integer, current stage label, used for generating layer names\n-        block: 'a','b'..., current block label, used for generating layer names\n-\n-    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n-    And the shortcut should has subsample=(2,2) as well\n-    '''\n-    nb_filter1, nb_filter2, nb_filter3 = filters\n-    dim_ordering = K.image_dim_ordering()\n-    if dim_ordering == 'tf':\n-        bn_axis = 3\n-    else:\n-        bn_axis = 1\n-    conv_name_base = 'res' + str(stage) + block + '_branch'\n-    bn_name_base = 'bn' + str(stage) + block + '_branch'\n-\n-    out = Convolution2D(nb_filter1, 1, 1, subsample=strides,\n-                        dim_ordering=dim_ordering, name=conv_name_base + '2a')(input_tensor)\n-    out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(out)\n-    out = Activation('relu')(out)\n-\n-    out = Convolution2D(nb_filter2, kernel_size, kernel_size, border_mode='same',\n-                        dim_ordering=dim_ordering, name=conv_name_base + '2b')(out)\n-    out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(out)\n-    out = Activation('relu')(out)\n-\n-    out = Convolution2D(nb_filter3, 1, 1, dim_ordering=dim_ordering, name=conv_name_base + '2c')(out)\n-    out = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(out)\n-\n-    shortcut = Convolution2D(nb_filter3, 1, 1, subsample=strides,\n-                             dim_ordering=dim_ordering, name=conv_name_base + '1')(input_tensor)\n-    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n-\n-    out = merge([out, shortcut], mode='sum')\n-    out = Activation('relu')(out)\n-    return out\n-\n-\n-def read_img(img_path):\n-    '''This function returns a preprocessed image\n-    '''\n-    dim_ordering = K.image_dim_ordering()\n-    mean = (103.939, 116.779, 123.68)\n-    img = load_img(img_path, target_size=(224, 224))\n-    img = img_to_array(img, dim_ordering=dim_ordering)\n-\n-    if dim_ordering == 'th':\n-        img[0, :, :] -= mean[0]\n-        img[1, :, :] -= mean[1]\n-        img[2, :, :] -= mean[2]\n-        # 'RGB'->'BGR'\n-        img = img[::-1, :, :]\n-    else:\n-        img[:, :, 0] -= mean[0]\n-        img[:, :, 1] -= mean[1]\n-        img[:, :, 2] -= mean[2]\n-        img = img[:, :, ::-1]\n-\n-    img = np.expand_dims(img, axis=0)\n-    return img\n-\n-\n-def get_resnet50():\n-    '''This function returns the 50-layer residual network model\n-    you should load pretrained weights if you want to use it directly.\n-    Note that since the pretrained weights is converted from caffemodel\n-    the order of channels for input image should be 'BGR' (the channel order of caffe)\n-    '''\n-    if K.image_dim_ordering() == 'tf':\n-        inp = Input(shape=(224, 224, 3))\n-        bn_axis = 3\n-    else:\n-        inp = Input(shape=(3, 224, 224))\n-        bn_axis = 1\n-\n-    dim_ordering = K.image_dim_ordering()\n-    out = ZeroPadding2D((3, 3), dim_ordering=dim_ordering)(inp)\n-    out = Convolution2D(64, 7, 7, subsample=(2, 2), dim_ordering=dim_ordering, name='conv1')(out)\n-    out = BatchNormalization(axis=bn_axis, name='bn_conv1')(out)\n-    out = Activation('relu')(out)\n-    out = MaxPooling2D((3, 3), strides=(2, 2), dim_ordering=dim_ordering)(out)\n-\n-    out = conv_block(out, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n-    out = identity_block(out, 3, [64, 64, 256], stage=2, block='b')\n-    out = identity_block(out, 3, [64, 64, 256], stage=2, block='c')\n-\n-    out = conv_block(out, 3, [128, 128, 512], stage=3, block='a')\n-    out = identity_block(out, 3, [128, 128, 512], stage=3, block='b')\n-    out = identity_block(out, 3, [128, 128, 512], stage=3, block='c')\n-    out = identity_block(out, 3, [128, 128, 512], stage=3, block='d')\n-\n-    out = conv_block(out, 3, [256, 256, 1024], stage=4, block='a')\n-    out = identity_block(out, 3, [256, 256, 1024], stage=4, block='b')\n-    out = identity_block(out, 3, [256, 256, 1024], stage=4, block='c')\n-    out = identity_block(out, 3, [256, 256, 1024], stage=4, block='d')\n-    out = identity_block(out, 3, [256, 256, 1024], stage=4, block='e')\n-    out = identity_block(out, 3, [256, 256, 1024], stage=4, block='f')\n-\n-    out = conv_block(out, 3, [512, 512, 2048], stage=5, block='a')\n-    out = identity_block(out, 3, [512, 512, 2048], stage=5, block='b')\n-    out = identity_block(out, 3, [512, 512, 2048], stage=5, block='c')\n-\n-    out = AveragePooling2D((7, 7), dim_ordering=dim_ordering)(out)\n-    out = Flatten()(out)\n-    out = Dense(1000, activation='softmax', name='fc1000')(out)\n-\n-    model = Model(inp, out)\n-\n-    return model\n-\n-\n-if __name__ == '__main__':\n-    weights_file = K.image_dim_ordering() + '_dim_ordering_resnet50.h5'\n-    resnet_model = get_resnet50()\n-    resnet_model.load_weights(weights_file)\n-\n-    # you may download synset_words from the address given at the begining of this file\n-    class_table = open('synset_words.txt', 'r')\n-    lines = class_table.readlines()\n-\n-    test_img1 = read_img('cat.jpg')\n-    print('Result for test 1 is:')\n-    print(lines[np.argmax(resnet_model.predict(test_img1)[0])])\n-\n-    test_img2 = read_img('elephant.jpg')\n-    print('Result for test 2 is:')\n-    print(lines[np.argmax(resnet_model.predict(test_img2)[0])])\n-    class_table.close()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
