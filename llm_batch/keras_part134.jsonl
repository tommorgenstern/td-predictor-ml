{"custom_id": "keras#0ba2626bd283bc481035f8f27077b8c8dfe8865e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 242 | Lines Deleted: 124 | Files Changed: 2 | Hunks: 88 | Methods Changed: 33 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 366 | Churn Cumulative: 7300 | Contributors (this commit): 49 | Commits (past 90d): 36 | Contributors (cumulative): 54 | DMM Complexity: 0.2542372881355932\n\nDIFF:\n@@ -76,9 +76,11 @@ class Node(object):\n             `node_indices[i]` is the origin node of `input_tensors[i]`\n             (necessary since each inbound layer might have several nodes,\n             e.g. if the layer is being shared with a different data stream).\n-        tensor_indices: a list of integers, the same length as `inbound_layers`.\n+        tensor_indices: a list of integers,\n+            the same length as `inbound_layers`.\n             `tensor_indices[i]` is the index of `input_tensors[i]` within the\n-            output of the inbound layer (necessary since each inbound layer might\n+            output of the inbound layer\n+            (necessary since each inbound layer might\n             have multiple tensor outputs, with each one being\n             independently manipulable).\n         input_tensors: list of input tensors.\n@@ -105,7 +107,8 @@ class Node(object):\n         # Layer instance (NOT a list).\n         # this is the layer that takes a list of input tensors\n         # and turns them into a list of output tensors.\n-        # the current node will be added to the inbound_nodes of outbound_layer.\n+        # the current node will be added to\n+        # the inbound_nodes of outbound_layer.\n         self.outbound_layer = outbound_layer\n \n         # The following 3 properties describe where\n@@ -160,7 +163,8 @@ class Node(object):\n         if len(input_tensors) == 1:\n             output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n             output_masks = to_list(outbound_layer.compute_mask(input_tensors[0], input_masks[0]))\n-            # TODO: try to auto-infer shape if exception is raised by get_output_shape_for.\n+            # TODO: try to auto-infer shape\n+            # if exception is raised by get_output_shape_for.\n             output_shapes = to_list(outbound_layer.get_output_shape_for(input_shapes[0]))\n         else:\n             output_tensors = to_list(outbound_layer.call(input_tensors, mask=input_masks))\n@@ -315,8 +319,8 @@ class Layer(object):\n                           'name',\n                           'trainable'}\n         for kwarg in kwargs.keys():\n-            assert kwarg in allowed_kwargs, 'Keyword argument not understood: ' + kwarg\n-\n+            if kwarg not in allowed_kwargs:\n+                raise TypeError('Keyword argument not understood:', kwarg)\n         name = kwargs.get('name')\n         if not name:\n             prefix = self.__class__.__name__.lower()\n@@ -361,14 +365,16 @@ class Layer(object):\n \n     @property\n     def regularizers(self):\n-        warnings.warn('The `regularizers` property of layers/models is deprecated. '\n+        warnings.warn('The `regularizers` property of '\n+                      'layers/models is deprecated. '\n                       'Regularization losses are now managed via the `losses` '\n                       'layer/model property.')\n         return []\n \n     @regularizers.setter\n     def regularizers(self, _):\n-        warnings.warn('The `regularizers` property of layers/models is deprecated. '\n+        warnings.warn('The `regularizers` property of layers/models '\n+                      'is deprecated. '\n                       'Regularization losses are now managed via the `losses` '\n                       'layer/model property.')\n \n@@ -592,9 +598,12 @@ class Layer(object):\n                 where to connect the current layer.\n             tensor_indices: Integer or list of integers.\n                 The output of the inbound node might be a list/tuple\n-                of tensor, and we might only be interested in one specific entry.\n-                This index allows you to specify the index of the entry in the output list\n-                (if applicable). \"None\" means that we take all outputs (as a list).\n+                of tensor, and we might only be interested in\n+                one specific entry.\n+                This index allows you to specify the index of\n+                the entry in the output list\n+                (if applicable). \"None\" means that we take all outputs\n+                (as a list).\n         '''\n         inbound_layers = to_list(inbound_layers)\n         if not node_indices:\n@@ -804,7 +813,8 @@ class Layer(object):\n                                  ' has multiple inbound nodes, '\n                                  'hence the notion of \"layer output mask\" '\n                                  'is ill-defined. '\n-                                 'Use `get_output_mask_at(node_index)` instead.')\n+                                 'Use `get_output_mask_at(node_index)` '\n+                                 'instead.')\n         return self._get_node_attribute_at_index(0, 'output_masks',\n                                                  'output mask')\n \n@@ -830,7 +840,8 @@ class Layer(object):\n                                  'with different input shapes. Hence '\n                                  'the notion of \"input shape\" is '\n                                  'ill-defined for the layer. '\n-                                 'Use `get_input_shape_at(node_index)` instead.')\n+                                 'Use `get_input_shape_at(node_index)` '\n+                                 'instead.')\n \n     @property\n     def output_shape(self):\n@@ -854,7 +865,8 @@ class Layer(object):\n                                  'with different output shapes. Hence '\n                                  'the notion of \"output shape\" is '\n                                  'ill-defined for the layer. '\n-                                 'Use `get_output_shape_at(node_index)` instead.')\n+                                 'Use `get_output_shape_at(node_index)` '\n+                                 'instead.')\n \n     def add_loss(self, losses, inputs=None):\n         if losses is None:\n@@ -944,10 +956,14 @@ class Layer(object):\n         '''\n         params = self.weights\n         if len(params) != len(weights):\n-            raise ValueError('You called `set_weights(weights)` on layer \"' + self.name +\n-                             '\" with a  weight list of length ' + str(len(weights)) +\n-                             ', but the layer was expecting ' + str(len(params)) +\n-                             ' weights. Provided weights: ' + str(weights)[:50] + '...')\n+            raise ValueError('You called `set_weights(weights)` on layer \"' +\n+                             self.name +\n+                             '\" with a  weight list of length ' +\n+                             str(len(weights)) +\n+                             ', but the layer was expecting ' +\n+                             str(len(params)) +\n+                             ' weights. Provided weights: ' +\n+                             str(weights)[:50] + '...')\n         if not params:\n             return\n         weight_value_tuples = []\n@@ -1064,10 +1080,12 @@ class InputLayer(Layer):\n                 batch_input_shape = K.int_shape(input_tensor)\n             except:\n                 if not input_shape and not batch_input_shape:\n-                    raise ValueError('InputLayer was provided an input_tensor argument, '\n-                                     'but its input shape cannot be automatically inferred. '\n-                                     'You should pass an input_shape or batch_input_shape '\n-                                     'argument.')\n+                    raise ValueError('InputLayer was provided '\n+                                     'an input_tensor argument, '\n+                                     'but its input shape cannot be '\n+                                     'automatically inferred. '\n+                                     'You should pass an input_shape or '\n+                                     'batch_input_shape argument.')\n         if not batch_input_shape:\n             if not input_shape:\n                 raise ValueError('An Input layer should be passed either '\n@@ -1163,8 +1181,8 @@ def Input(shape=None, batch_shape=None,\n         ```\n     '''\n     if not batch_shape and tensor is None:\n-        assert shape, ('Please provide to Input either a `shape`' +\n-                       ' or a `batch_shape` argument. Note that ' +\n+        assert shape, ('Please provide to Input either a `shape`'\n+                       ' or a `batch_shape` argument. Note that '\n                        '`shape` does not include the batch '\n                        'dimension.')\n     if shape and not batch_shape:\n@@ -1208,15 +1226,21 @@ class Merge(Layer):\n             If lambda/function, it should take as input a list of tensors\n             and return a single tensor.\n         concat_axis: Integer, axis to use in mode `concat`.\n-        dot_axes: Integer or tuple of integers, axes to use in mode `dot` or `cos`.\n-        output_shape: Either a shape tuple (tuple of integers), or a lambda/function\n-            to compute `output_shape` (only if merge mode is a lambda/function).\n+        dot_axes: Integer or tuple of integers,\n+            axes to use in mode `dot` or `cos`.\n+        output_shape: Either a shape tuple (tuple of integers),\n+            or a lambda/function\n+            to compute `output_shape`\n+            (only if merge mode is a lambda/function).\n             If the argument is a tuple,\n             it should be expected output shape, *not* including the batch size\n             (same convention as the `input_shape` argument in layers).\n-            If the argument is callable, it should take as input a list of shape tuples\n-            (1:1 mapping to input tensors) and return a single shape tuple, including the\n-            batch size (same convention as the `get_output_shape_for` method of layers).\n+            If the argument is callable,\n+            it should take as input a list of shape tuples\n+            (1:1 mapping to input tensors)\n+            and return a single shape tuple, including the\n+            batch size (same convention as the\n+            `get_output_shape_for` method of layers).\n         node_indices: Optional list of integers containing\n             the output node index for each input layer\n             (in case some input layers have multiple output nodes).\n@@ -1486,12 +1510,14 @@ class Merge(Layer):\n             masks = [K.expand_dims(m, 0) for m in mask if m is not None]\n             return K.all(K.concatenate(masks, axis=0), axis=0, keepdims=False)\n         elif self.mode == 'concat':\n-            # Make a list of masks while making sure the dimensionality of each mask\n+            # Make a list of masks while making sure\n+            # the dimensionality of each mask\n             # is the same as the corresponding input.\n             masks = []\n             for input_i, mask_i in zip(inputs, mask):\n                 if mask_i is None:\n-                    # Input is unmasked. Append all 1s to masks, but cast it to uint8 first\n+                    # Input is unmasked. Append all 1s to masks,\n+                    # but cast it to uint8 first\n                     masks.append(K.cast(K.ones_like(input_i), 'uint8'))\n                 elif K.ndim(mask_i) < K.ndim(input_i):\n                     # Mask is smaller than the input, expand it\n@@ -1607,12 +1633,14 @@ def merge(inputs, mode='sum', concat_axis=-1,\n             If lambda/function, it should take as input a list of tensors\n             and return a single tensor.\n         concat_axis: Integer, axis to use in mode `concat`.\n-        dot_axes: Integer or tuple of integers, axes to use in mode `dot` or `cos`.\n+        dot_axes: Integer or tuple of integers,\n+            axes to use in mode `dot` or `cos`.\n         output_shape: Shape tuple (tuple of integers), or lambda/function\n             to compute output_shape (only if merge mode is a lambda/function).\n             If the latter case, it should take as input a list of shape tuples\n-            (1:1 mapping to input tensors) and return a single shape tuple, including the\n-            batch size (same convention as the `get_output_shape_for` method of layers).\n+            (1:1 mapping to input tensors) and return a single shape tuple,\n+            including the batch size\n+            (same convention as the `get_output_shape_for` method of layers).\n         node_indices: Optional list of integers containing\n             the output node index for each input layer\n             (in case some input layers have multiple output nodes).\n@@ -1717,13 +1745,15 @@ class Container(Layer):\n         inputs_set = set(self.inputs)\n         if len(inputs_set) != len(self.inputs):\n             raise ValueError('The list of inputs passed to the model '\n-                             'is redundant. All inputs should only appear once.'\n+                             'is redundant. '\n+                             'All inputs should only appear once.'\n                              ' Found: ' + str(self.inputs))\n \n         # List of initial layers (1 to 1 mapping with self.inputs,\n         # hence the same layer might appear twice)\n         self.input_layers = []\n-        # TODO: probably useless because input layers must be Input layers (node_indices = [0], tensor_indices = [0])\n+        # TODO: probably useless because input layers must be Input layers\n+        # (node_indices = [0], tensor_indices = [0])\n         self.input_layers_node_indices = []\n         self.input_layers_tensor_indices = []\n         # list of layers (1 to 1 mapping with self.inputs,\n@@ -1828,7 +1858,8 @@ class Container(Layer):\n         self.internal_output_shapes = [x._keras_shape for x in self.outputs]\n \n         # Container_nodes: set of nodes included in the graph\n-        # (not all nodes included in the layers are relevant to the current graph).\n+        # (not all nodes included in the layers\n+        # are relevant to the current graph).\n         container_nodes = set()  # ids of all nodes relevant to the Container\n         nodes_depths = {}  # dict {node: depth value}\n         layers_depths = {}  # dict {layer: depth value}\n@@ -2318,9 +2349,11 @@ class Container(Layer):\n         if masks is None:\n             masks = [None for _ in range(len(inputs))]\n \n-        # Dictionary mapping reference tensors to tuples (computed tensor, compute mask)\n+        # Dictionary mapping reference tensors to tuples\n+        # (computed tensor, compute mask)\n         # we assume a 1:1 mapping from tensor to mask\n-        # TODO: raise exception when a .compute_mask does not return a list the same size as call\n+        # TODO: raise exception when a `.compute_mask()` call\n+        # does not return a list the same size as `call`\n         tensor_map = {}\n         for x, y, mask in zip(self.inputs, inputs, masks):\n             tensor_map[str(id(x))] = (y, mask)\n@@ -2346,25 +2379,32 @@ class Container(Layer):\n                     # call layer\n                     if len(computed_data) == 1:\n                         computed_tensor, computed_mask = computed_data[0]\n-                        output_tensors = to_list(layer.call(computed_tensor, computed_mask))\n-                        output_masks = to_list(layer.compute_mask(computed_tensor, computed_mask))\n+                        output_tensors = to_list(layer.call(computed_tensor,\n+                                                            computed_mask))\n+                        output_masks = to_list(layer.compute_mask(computed_tensor,\n+                                                                  computed_mask))\n                         computed_tensors = [computed_tensor]\n                         computed_masks = [computed_mask]\n                     else:\n                         computed_tensors = [x[0] for x in computed_data]\n                         computed_masks = [x[1] for x in computed_data]\n-                        output_tensors = to_list(layer.call(computed_tensors, computed_masks))\n-                        output_masks = to_list(layer.compute_mask(computed_tensors, computed_masks))\n+                        output_tensors = to_list(layer.call(computed_tensors,\n+                                                            computed_masks))\n+                        output_masks = to_list(layer.compute_mask(computed_tensors,\n+                                                                  computed_masks))\n \n                     # Update model updates and losses:\n                     layer_inputs = [x[0] for x in computed_data]\n-                    # Keep track of updates that depend on the inputs (e.g. BN updates).\n+                    # Keep track of updates that depend on the inputs\n+                    # (e.g. BN updates).\n                     self.add_update(layer.get_updates_for(layer_inputs), inputs)\n                     # Keep track of unconditional updates (e.g. a counter).\n                     self.add_update(layer.get_updates_for(None), None)\n-                    # Keep track of losses that depend on the inputs (e.g. activity regularizers).\n+                    # Keep track of losses that depend on the inputs\n+                    # (e.g. activity regularizers).\n                     self.add_loss(layer.get_losses_for(layer_inputs), inputs)\n-                    # Keep track of unconditional losses (e.g. weight regularizers).\n+                    # Keep track of unconditional losses\n+                    # (e.g. weight regularizers).\n                     self.add_loss(layer.get_losses_for(None), None)\n \n                     # Update _keras_shape.\n@@ -2398,7 +2438,8 @@ class Container(Layer):\n             output_tensors.append(tensor)\n             output_masks.append(mask)\n \n-        # Update cache; keys are based on ids on input tensors and inputs masks.\n+        # Update cache;\n+        # keys are based on ids on input tensors and inputs masks.\n         cache_key = ','.join([str(id(x)) for x in inputs])\n         cache_key += '_' + ','.join([str(id(x)) for x in masks])\n \n@@ -2589,7 +2630,8 @@ class Container(Layer):\n                 (ordered names of model layers).\n             - For every layer, a `group` named `layer.name`\n                 - For every such layer group, a group attribute `weight_names`,\n-                    a list of strings (ordered names of weights tensor of the layer).\n+                    a list of strings\n+                    (ordered names of weights tensor of the layer).\n                 - For every weight in the layer, a dataset\n                     storing the weight value, named after the weight tensor.\n         '''\n@@ -2736,7 +2778,8 @@ class Container(Layer):\n                     w = weight_values[0]\n                     shape = w.shape\n                     if shape[:2] != (layer.filter_length, 1) or shape[3] != layer.nb_filter:\n-                        # Legacy shape: (self.nb_filter, input_dim, self.filter_length, 1)\n+                        # Legacy shape:\n+                        # (self.nb_filter, input_dim, self.filter_length, 1)\n                         assert shape[0] == layer.nb_filter and shape[2:] == (layer.filter_length, 1)\n                         w = np.transpose(w, (2, 3, 1, 0))\n                         weight_values[0] = w\n@@ -2788,7 +2831,8 @@ class Container(Layer):\n                                          ' element(s).')\n                     # Set values.\n                     for i in range(len(weight_values)):\n-                        weight_value_tuples.append((symbolic_weights[i], weight_values[i]))\n+                        weight_value_tuples.append((symbolic_weights[i],\n+                                                    weight_values[i]))\n             K.batch_set_value(weight_value_tuples)\n \n     def _updated_config(self):\n@@ -2846,8 +2890,10 @@ class Container(Layer):\n             flattened_layers = self.flattened_layers\n         else:\n             flattened_layers = self.layers\n-\n-        print_summary(flattened_layers, getattr(self, 'container_nodes', None), line_length=line_length, positions=positions)\n+        print_summary(flattened_layers,\n+                      getattr(self, 'container_nodes', None),\n+                      line_length=line_length,\n+                      positions=positions)\n \n \n def get_source_inputs(tensor, layer=None, node_index=None):\n\n@@ -56,7 +56,8 @@ def standardize_input_data(data, names, shapes=None,\n                 if len(names) == 1:\n                     data = [np.asarray(data)]\n                 else:\n-                    raise ValueError('Error when checking ' + exception_prefix +\n+                    raise ValueError(\n+                        'Error when checking ' + exception_prefix +\n                         ': you are passing a list as '\n                         'input to your model, '\n                         'but the model expects '\n@@ -104,7 +105,8 @@ def standardize_input_data(data, names, shapes=None,\n                     continue\n                 if ref_dim:\n                     if ref_dim != dim:\n-                        raise ValueError('Error when checking ' + exception_prefix +\n+                        raise ValueError(\n+                            'Error when checking ' + exception_prefix +\n                             ': expected ' + names[i] +\n                             ' to have shape ' + str(shapes[i]) +\n                             ' but got array with shape ' +\n@@ -175,9 +177,9 @@ def check_array_lengths(X, Y, W):\n                          'the same number of samples.')\n     if list(set_x)[0] != list(set_y)[0]:\n         raise ValueError('Input arrays should have '\n-                         'the same number of samples as target arrays. Found ' +\n-                         str(list(set_x)[0]) + ' input samples and ' +\n-                         str(list(set_y)[0]) + ' target samples.')\n+                         'the same number of samples as target arrays. '\n+                         'Found ' + str(list(set_x)[0]) + ' input samples '\n+                         'and ' + str(list(set_y)[0]) + ' target samples.')\n     if list(set_x)[0] != list(set_w)[0]:\n         raise ValueError('Sample_weight arrays should have '\n                          'the same number of samples as input arrays. Found ' +\n@@ -192,7 +194,8 @@ def check_loss_and_target_compatibility(targets, losses, output_shapes):\n     for y, loss, shape in zip(targets, losses, output_shapes):\n         if loss.__name__ == 'categorical_crossentropy':\n             if y.shape[-1] == 1:\n-                raise ValueError('You are passing a target array of shape ' + str(y.shape) +\n+                raise ValueError(\n+                    'You are passing a target array of shape ' + str(y.shape) +\n                     ' while using as loss `categorical_crossentropy`. '\n                     '`categorical_crossentropy` expects '\n                     'targets to be binary matrices (1s and 0s) '\n@@ -210,7 +213,8 @@ def check_loss_and_target_compatibility(targets, losses, output_shapes):\n         if loss.__name__ in key_losses:\n             for target_dim, out_dim in zip(y.shape[1:], shape[1:]):\n                 if out_dim is not None and target_dim != out_dim:\n-                    raise ValueError('A target array with shape ' + str(y.shape) +\n+                    raise ValueError(\n+                        'A target array with shape ' + str(y.shape) +\n                         ' was passed for an output of shape ' + str(shape) +\n                         ' while using as loss `' + loss.__name__ + '`. '\n                         'This loss expects '\n@@ -351,7 +355,8 @@ def standardize_weights(y, sample_weight=None, class_weight=None,\n             raise ValueError('Found a sample_weight array with shape ' +\n                              str(sample_weight.shape) + '. '\n                              'In order to use timestep-wise sample weights, '\n-                             'you should specify sample_weight_mode=\"temporal\" '\n+                             'you should specify '\n+                             'sample_weight_mode=\"temporal\" '\n                              'in compile(). If you just mean to use '\n                              'sample-wise weights, make sure your '\n                              'sample_weight array is 1D.')\n@@ -411,7 +416,8 @@ def generator_queue(generator, max_q_size=10,\n \n         for i in range(nb_worker):\n             if pickle_safe:\n-                # Reset random seed else all children processes share the same seed\n+                # Reset random seed else all children processes\n+                # share the same seed\n                 np.random.seed()\n                 thread = multiprocessing.Process(target=data_generator_task)\n             else:\n@@ -543,10 +549,12 @@ class Model(Container):\n                                      '\" missing from sample_weight_modes '\n                                      'dictionary')\n                 if sample_weight_mode.get(name) == 'temporal':\n-                    weight = K.placeholder(ndim=2, name=name + '_sample_weights')\n+                    weight = K.placeholder(ndim=2,\n+                                           name=name + '_sample_weights')\n                     sample_weight_modes.append('temporal')\n                 else:\n-                    weight = K.placeholder(ndim=1, name=name + '_sample_weights')\n+                    weight = K.placeholder(ndim=1,\n+                                           name=name + '_sample_weights')\n                     sample_weight_modes.append(None)\n                 sample_weights.append(weight)\n         elif isinstance(sample_weight_mode, list):\n@@ -554,25 +562,31 @@ class Model(Container):\n                 raise ValueError('When passing a list as sample_weight_mode, '\n                                  'it should have one entry per model outputs. '\n                                  'The model has ' + str(len(self.outputs)) +\n-                                 ' outputs, but you passed sample_weight_mode=' +\n+                                 ' outputs, but you passed '\n+                                 'sample_weight_mode=' +\n                                  str(sample_weight_mode))\n             sample_weights = []\n             sample_weight_modes = []\n             for mode, name in zip(sample_weight_mode, self.output_names):\n                 if mode == 'temporal':\n-                    weight = K.placeholder(ndim=2, name=name + '_sample_weights')\n+                    weight = K.placeholder(ndim=2,\n+                                           name=name + '_sample_weights')\n                     sample_weight_modes.append('temporal')\n                 else:\n-                    weight = K.placeholder(ndim=1, name=name + '_sample_weights')\n+                    weight = K.placeholder(ndim=1,\n+                                           name=name + '_sample_weights')\n                     sample_weight_modes.append(None)\n                 sample_weights.append(weight)\n         else:\n             if sample_weight_mode == 'temporal':\n-                sample_weights = [K.placeholder(ndim=2, name=name + '_sample_weights')\n+                sample_weights = [K.placeholder(ndim=2,\n+                                                name=name + '_sample_weights')\n+                                  for name in self.output_names]\n+                sample_weight_modes = ['temporal'\n                                        for name in self.output_names]\n-                sample_weight_modes = ['temporal' for name in self.output_names]\n             else:\n-                sample_weights = [K.placeholder(ndim=1, name=name + '_sample_weights')\n+                sample_weights = [K.placeholder(ndim=1,\n+                                                name=name + '_sample_weights')\n                                   for name in self.output_names]\n                 sample_weight_modes = [None for name in self.output_names]\n         self.sample_weight_modes = sample_weight_modes\n@@ -635,7 +649,8 @@ class Model(Container):\n \n             for metric in output_metrics:\n                 if metric == 'accuracy' or metric == 'acc':\n-                    # custom handling of accuracy (because of class mode duality)\n+                    # custom handling of accuracy\n+                    # (because of class mode duality)\n                     output_shape = self.internal_output_shapes[i]\n                     acc_fn = None\n                     if output_shape[-1] == 1 or self.loss_functions[i] == objectives.binary_crossentropy:\n@@ -948,7 +963,8 @@ class Model(Container):\n                                sample_weight=None, class_weight=None,\n                                check_batch_dim=True, batch_size=None):\n         if not hasattr(self, 'optimizer'):\n-            raise RuntimeError('You must compile a model before training/testing.'\n+            raise RuntimeError('You must compile a model before '\n+                               'training/testing. '\n                                'Use `model.compile(optimizer, loss)`.')\n \n         output_shapes = []\n@@ -993,27 +1009,37 @@ class Model(Container):\n         # Arguments\n             x: Numpy array of training data,\n                 or list of Numpy arrays if the model has multiple inputs.\n-                If all inputs in the model are named, you can also pass a dictionary\n+                If all inputs in the model are named,\n+                you can also pass a dictionary\n                 mapping input names to Numpy arrays.\n             y: Numpy array of target data,\n                 or list of Numpy arrays if the model has multiple outputs.\n-                If all outputs in the model are named, you can also pass a dictionary\n+                If all outputs in the model are named,\n+                you can also pass a dictionary\n                 mapping output names to Numpy arrays.\n             batch_size: integer. Number of samples per gradient update.\n-            nb_epoch: integer, the number of times to iterate over the training data arrays.\n-            verbose: 0, 1, or 2. Verbosity mode. 0 = silent, 1 = verbose, 2 = one log line per epoch.\n+            nb_epoch: integer, the number of times to iterate\n+                over the training data arrays.\n+                verbose: 0, 1, or 2. Verbosity mode.\n+                0 = silent, 1 = verbose, 2 = one log line per epoch.\n             callbacks: list of callbacks to be called during training.\n                 See [callbacks](/callbacks).\n             validation_split: float between 0 and 1:\n                 fraction of the training data to be used as validation data.\n                 The model will set apart this fraction of the training data,\n-                will not train on it, and will evaluate the loss and any model metrics\n+                will not train on it, and will evaluate\n+                the loss and any model metrics\n                 on this data at the end of each epoch.\n-            validation_data: data on which to evaluate the loss and any model metrics\n-                at the end of each epoch. The model will not be trained on this data.\n-                This could be a tuple (x_val, y_val) or a tuple (x_val, y_val, val_sample_weights).\n-            shuffle: boolean, whether to shuffle the training data before each epoch.\n-            class_weight: optional dictionary mapping class indices (integers) to\n+            validation_data: data on which to evaluate\n+                the loss and any model metrics\n+                at the end of each epoch. The model will not\n+                be trained on this data.\n+                This could be a tuple (x_val, y_val)\n+                or a tuple (x_val, y_val, val_sample_weights).\n+            shuffle: boolean, whether to shuffle the training data\n+                before each epoch.\n+            class_weight: optional dictionary mapping\n+                class indices (integers) to\n                 a weight (float) to apply to the model's loss for the samples\n                 from this class during training.\n                 This can be useful to tell the model to \"pay more attention\" to\n@@ -1023,7 +1049,8 @@ class Model(Container):\n                 In the case of temporal data, you can pass a 2D array\n                 with shape (samples, sequence_length),\n                 to apply a different weight to every timestep of every sample.\n-                In this case you should make sure to specify sample_weight_mode=\"temporal\" in compile().\n+                In this case you should make sure to specify\n+                sample_weight_mode=\"temporal\" in compile().\n             initial_epoch: epoch at which to start training\n                 (useful for resuming a previous training run)\n \n@@ -1033,7 +1060,8 @@ class Model(Container):\n             all information collected during training.\n         '''\n         # validate user data\n-        x, y, sample_weights = self._standardize_user_data(x, y,\n+        x, y, sample_weights = self._standardize_user_data(\n+            x, y,\n             sample_weight=sample_weight,\n             class_weight=class_weight,\n             check_batch_dim=False,\n@@ -1048,7 +1076,8 @@ class Model(Container):\n                 val_x, val_y, val_sample_weight = validation_data\n             else:\n                 raise\n-            val_x, val_y, val_sample_weights = self._standardize_user_data(val_x, val_y,\n+            val_x, val_y, val_sample_weights = self._standardize_user_data(\n+                val_x, val_y,\n                 sample_weight=val_sample_weight,\n                 check_batch_dim=False,\n                 batch_size=batch_size)\n@@ -1120,11 +1149,13 @@ class Model(Container):\n         # Arguments\n             x: Numpy array of test data,\n                 or list of Numpy arrays if the model has multiple inputs.\n-                If all inputs in the model are named, you can also pass a dictionary\n+                If all inputs in the model are named,\n+                you can also pass a dictionary\n                 mapping input names to Numpy arrays.\n             y: Numpy array of target data,\n                 or list of Numpy arrays if the model has multiple outputs.\n-                If all outputs in the model are named, you can also pass a dictionary\n+                If all outputs in the model are named,\n+                you can also pass a dictionary\n                 mapping output names to Numpy arrays.\n             batch_size: integer. Number of samples per gradient update.\n \n@@ -1135,7 +1166,8 @@ class Model(Container):\n             the display labels for the scalar outputs.\n         '''\n         # validate user data\n-        x, y, sample_weights = self._standardize_user_data(x, y,\n+        x, y, sample_weights = self._standardize_user_data(\n+            x, y,\n             sample_weight=sample_weight,\n             check_batch_dim=False,\n             batch_size=batch_size)\n@@ -1193,31 +1225,37 @@ class Model(Container):\n         # Arguments\n             x: Numpy array of training data,\n                 or list of Numpy arrays if the model has multiple inputs.\n-                If all inputs in the model are named, you can also pass a dictionary\n+                If all inputs in the model are named,\n+                you can also pass a dictionary\n                 mapping input names to Numpy arrays.\n             y: Numpy array of target data,\n                 or list of Numpy arrays if the model has multiple outputs.\n-                If all outputs in the model are named, you can also pass a dictionary\n+                If all outputs in the model are named,\n+                you can also pass a dictionary\n                 mapping output names to Numpy arrays.\n             sample_weight: optional array of the same length as x, containing\n                 weights to apply to the model's loss for each sample.\n                 In the case of temporal data, you can pass a 2D array\n                 with shape (samples, sequence_length),\n                 to apply a different weight to every timestep of every sample.\n-                In this case you should make sure to specify sample_weight_mode=\"temporal\" in compile().\n-            class_weight: optional dictionary mapping class indices (integers) to\n+                In this case you should make sure to specify\n+                sample_weight_mode=\"temporal\" in compile().\n+            class_weight: optional dictionary mapping\n+                lass indices (integers) to\n                 a weight (float) to apply to the model's loss for the samples\n                 from this class during training.\n                 This can be useful to tell the model to \"pay more attention\" to\n                 samples from an under-represented class.\n \n         # Returns\n-            Scalar training loss (if the model has a single output and no metrics)\n+            Scalar training loss\n+            (if the model has a single output and no metrics)\n             or list of scalars (if the model has multiple outputs\n             and/or metrics). The attribute `model.metrics_names` will give you\n             the display labels for the scalar outputs.\n         '''\n-        x, y, sample_weights = self._standardize_user_data(x, y,\n+        x, y, sample_weights = self._standardize_user_data(\n+            x, y,\n             sample_weight=sample_weight,\n             class_weight=class_weight,\n             check_batch_dim=True)\n@@ -1237,18 +1275,21 @@ class Model(Container):\n         # Arguments\n             x: Numpy array of test data,\n                 or list of Numpy arrays if the model has multiple inputs.\n-                If all inputs in the model are named, you can also pass a dictionary\n+                If all inputs in the model are named,\n+                you can also pass a dictionary\n                 mapping input names to Numpy arrays.\n             y: Numpy array of target data,\n                 or list of Numpy arrays if the model has multiple outputs.\n-                If all outputs in the model are named, you can also pass a dictionary\n+                If all outputs in the model are named,\n+                you can also pass a dictionary\n                 mapping output names to Numpy arrays.\n             sample_weight: optional array of the same length as x, containing\n                 weights to apply to the model's loss for each sample.\n                 In the case of temporal data, you can pass a 2D array\n                 with shape (samples, sequence_length),\n                 to apply a different weight to every timestep of every sample.\n-                In this case you should make sure to specify sample_weight_mode=\"temporal\" in compile().\n+                In this case you should make sure to specify\n+                sample_weight_mode=\"temporal\" in compile().\n \n         # Returns\n             Scalar test loss (if the model has a single output and no metrics)\n@@ -1256,7 +1297,8 @@ class Model(Container):\n             and/or metrics). The attribute `model.metrics_names` will give you\n             the display labels for the scalar outputs.\n         '''\n-        x, y, sample_weights = self._standardize_user_data(x, y,\n+        x, y, sample_weights = self._standardize_user_data(\n+            x, y,\n             sample_weight=sample_weight,\n             check_batch_dim=True)\n         if self.uses_learning_phase and not isinstance(K.learning_phase, int):\n@@ -1287,7 +1329,8 @@ class Model(Container):\n     def fit_generator(self, generator, samples_per_epoch, nb_epoch,\n                       verbose=1, callbacks=[],\n                       validation_data=None, nb_val_samples=None,\n-                      class_weight={}, max_q_size=10, nb_worker=1, pickle_safe=False,\n+                      class_weight={},\n+                      max_q_size=10, nb_worker=1, pickle_safe=False,\n                       initial_epoch=0):\n         '''Fits the model on data generated batch-by-batch by\n         a Python generator.\n@@ -1319,10 +1362,14 @@ class Model(Container):\n             class_weight: dictionary mapping class indices to a weight\n                 for the class.\n             max_q_size: maximum size for the generator queue\n-            nb_worker: maximum number of processes to spin up when using process based threading\n-            pickle_safe: if True, use process based threading. Note that because\n-                this implementation relies on multiprocessing, you should not pass\n-                non picklable arguments to the generator as they can't be passed\n+            nb_worker: maximum number of processes to spin up\n+                when using process based threading\n+            pickle_safe: if True, use process based threading.\n+                Note that because\n+                this implementation relies on multiprocessing,\n+                you should not pass\n+                non picklable arguments to the generator\n+                as they can't be passed\n                 easily to children processes.\n             initial_epoch: epoch at which to start training\n                 (useful for resuming a previous training run)\n@@ -1397,14 +1444,19 @@ class Model(Container):\n             else:\n                 raise ValueError('validation_data should be a tuple '\n                                  '(val_x, val_y, val_sample_weight) '\n-                                 'or (val_x, val_y). Found: ' + str(validation_data))\n-            val_x, val_y, val_sample_weights = self._standardize_user_data(val_x, val_y, val_sample_weight)\n+                                 'or (val_x, val_y). Found: ' +\n+                                 str(validation_data))\n+            val_x, val_y, val_sample_weights = self._standardize_user_data(\n+                val_x, val_y, val_sample_weight)\n             self.validation_data = val_x + [val_y, val_sample_weights]\n         else:\n             self.validation_data = None\n \n         # start generator thread storing batches into a queue\n-        data_gen_queue, _stop, generator_threads = generator_queue(generator, max_q_size=max_q_size, nb_worker=nb_worker,\n+        data_gen_queue, _stop, generator_threads = generator_queue(\n+            generator,\n+            max_q_size=max_q_size,\n+            nb_worker=nb_worker,\n             pickle_safe=pickle_safe)\n \n         callback_model.stop_training = False\n@@ -1425,7 +1477,8 @@ class Model(Container):\n                     _stop.set()\n                     raise ValueError('output of generator should be a tuple '\n                                      '(x, y, sample_weight) '\n-                                     'or (x, y). Found: ' + str(generator_output))\n+                                     'or (x, y). Found: ' +\n+                                     str(generator_output))\n                 if len(generator_output) == 2:\n                     x, y = generator_output\n                     sample_weight = None\n@@ -1435,7 +1488,8 @@ class Model(Container):\n                     _stop.set()\n                     raise ValueError('output of generator should be a tuple '\n                                      '(x, y, sample_weight) '\n-                                     'or (x, y). Found: ' + str(generator_output))\n+                                     'or (x, y). Found: ' +\n+                                     str(generator_output))\n                 # build batch logs\n                 batch_logs = {}\n                 if isinstance(x, list):\n@@ -1477,7 +1531,8 @@ class Model(Container):\n                                   'to avoid this warning.')\n                 if samples_seen >= samples_per_epoch and do_validation:\n                     if val_gen:\n-                        val_outs = self.evaluate_generator(validation_data,\n+                        val_outs = self.evaluate_generator(\n+                            validation_data,\n                             nb_val_samples,\n                             max_q_size=max_q_size,\n                             nb_worker=nb_worker,\n@@ -1485,7 +1540,8 @@ class Model(Container):\n                     else:\n                         # no need for try/except because\n                         # data has already been validated\n-                        val_outs = self.evaluate(val_x, val_y,\n+                        val_outs = self.evaluate(\n+                            val_x, val_y,\n                             batch_size=batch_size,\n                             sample_weight=val_sample_weights,\n                             verbose=0)\n@@ -1510,7 +1566,8 @@ class Model(Container):\n         callbacks.on_train_end()\n         return self.history\n \n-    def evaluate_generator(self, generator, val_samples, max_q_size=10, nb_worker=1, pickle_safe=False):\n+    def evaluate_generator(self, generator, val_samples,\n+                           max_q_size=10, nb_worker=1, pickle_safe=False):\n         '''Evaluates the model on a data generator. The generator should\n         return the same kind of data as accepted by `test_on_batch`.\n \n@@ -1522,10 +1579,14 @@ class Model(Container):\n                 total number of samples to generate from `generator`\n                 before returning.\n             max_q_size: maximum size for the generator queue\n-            nb_worker: maximum number of processes to spin up when using process based threading\n-            pickle_safe: if True, use process based threading. Note that because\n-                this implementation relies on multiprocessing, you should not pass\n-                non picklable arguments to the generator as they can't be passed\n+            nb_worker: maximum number of processes to spin up\n+                when using process based threading\n+            pickle_safe: if True, use process based threading.\n+                Note that because\n+                this implementation relies on multiprocessing,\n+                you should not pass\n+                non picklable arguments to the generator\n+                as they can't be passed\n                 easily to children processes.\n \n         # Returns\n@@ -1540,7 +1601,10 @@ class Model(Container):\n         wait_time = 0.01\n         all_outs = []\n         weights = []\n-        data_gen_queue, _stop, generator_threads = generator_queue(generator, max_q_size=max_q_size, nb_worker=nb_worker,\n+        data_gen_queue, _stop, generator_threads = generator_queue(\n+            generator,\n+            max_q_size=max_q_size,\n+            nb_worker=nb_worker,\n             pickle_safe=pickle_safe)\n \n         while processed_samples < val_samples:\n@@ -1601,7 +1665,8 @@ class Model(Container):\n                                            weights=weights))\n             return averages\n \n-    def predict_generator(self, generator, val_samples, max_q_size=10, nb_worker=1, pickle_safe=False):\n+    def predict_generator(self, generator, val_samples,\n+                          max_q_size=10, nb_worker=1, pickle_safe=False):\n         '''Generates predictions for the input samples from a data generator.\n         The generator should return the same kind of data as accepted by\n         `predict_on_batch`.\n@@ -1611,10 +1676,14 @@ class Model(Container):\n             val_samples: total number of samples to generate from `generator`\n                 before returning.\n             max_q_size: maximum size for the generator queue\n-            nb_worker: maximum number of processes to spin up when using process based threading\n-            pickle_safe: if True, use process based threading. Note that because\n-                this implementation relies on multiprocessing, you should not pass\n-                non picklable arguments to the generator as they can't be passed\n+            nb_worker: maximum number of processes to spin up\n+                when using process based threading\n+            pickle_safe: if True, use process based threading.\n+                Note that because\n+                this implementation relies on multiprocessing,\n+                you should not pass\n+                non picklable arguments to the generator\n+                as they can't be passed\n                 easily to children processes.\n \n         # Returns\n@@ -1625,7 +1694,10 @@ class Model(Container):\n         processed_samples = 0\n         wait_time = 0.01\n         all_outs = []\n-        data_gen_queue, _stop, generator_threads = generator_queue(generator, max_q_size=max_q_size, nb_worker=nb_worker,\n+        data_gen_queue, _stop, generator_threads = generator_queue(\n+            generator,\n+            max_q_size=max_q_size,\n+            nb_worker=nb_worker,\n             pickle_safe=pickle_safe)\n \n         while processed_samples < val_samples:\n@@ -1647,7 +1719,8 @@ class Model(Container):\n                     _stop.set()\n                     raise ValueError('output of generator should be a tuple '\n                                      '(x, y, sample_weight) '\n-                                     'or (x, y). Found: ' + str(generator_output))\n+                                     'or (x, y). Found: ' +\n+                                     str(generator_output))\n             else:\n                 x = generator_output\n \n@@ -1674,7 +1747,6 @@ class Model(Container):\n \n             for i, out in enumerate(outs):\n                 all_outs[i][processed_samples:(processed_samples + nb_samples)] = out\n-\n             processed_samples += nb_samples\n \n         _stop.set()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
