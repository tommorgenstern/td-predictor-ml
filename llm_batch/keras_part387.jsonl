{"custom_id": "keras#07db2d75d2b598a879309b45243f6cbafd3984e5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 4435 | Contributors (this commit): 18 | Commits (past 90d): 3 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -372,7 +372,9 @@ class MeanAbsoluteError(LossFunctionWrapper):\n class MeanAbsolutePercentageError(LossFunctionWrapper):\n   \"\"\"Computes the mean absolute percentage error between `y_true` and `y_pred`.\n \n-  `loss = 100 * abs(y_true - y_pred) / y_true`\n+  `loss = 100 * abs((y_true - y_pred) / y_true)`\n+  \n+  Note that to avoid division by zero error, a small value epsilon is added to the denominator.\n \n   Standalone usage:\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f823c5c7d6063151b7c57e7071fc7d88ac526264", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/1 | Churn Δ: 38 | Churn Cumulative: 4236 | Contributors (this commit): 9 | Commits (past 90d): 18 | Contributors (cumulative): 15 | DMM Complexity: 1.0\n\nDIFF:\n@@ -453,14 +453,6 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n   def _preprocess(self, inputs):\n     inputs = utils.ensure_tensor(inputs, dtype=tf.string)\n     if self._standardize in (LOWER, LOWER_AND_STRIP_PUNCTUATION):\n-      if tf_utils.is_ragged(inputs):\n-        inputs = tf.ragged.map_flat_values(tf.strings.lower, inputs)\n-        # Depending on configuration, we may never touch the non-data tensor\n-        # in the ragged inputs tensor. If that is the case, and this is the\n-        # only layer in the keras model, running it will throw an error.\n-        # To get around this, we wrap the result in an identity.\n-        inputs = tf.identity(inputs)\n-      else:\n       inputs = tf.strings.lower(inputs)\n     if self._standardize in (STRIP_PUNCTUATION, LOWER_AND_STRIP_PUNCTUATION):\n       inputs = tf.strings.regex_replace(inputs, DEFAULT_STRIP_REGEX, \"\")\n\n@@ -331,14 +331,40 @@ class TextVectorizationLayerTest(keras_parameterized.TestCase,\n     layer = text_vectorization.TextVectorization(\n         vocabulary=[\"earth\", \"wind\", \"and\", \"fire\"])\n     output_data = layer(input_data)\n-    self.assertAllEqual(expected_output, output_data)\n+    self.assertAllEqual(output_data, expected_output)\n \n     # Again in a keras.Model\n     inputs = keras.Input(shape=input_shape, dtype=tf.string)\n     outputs = layer(inputs)\n     model = keras.Model(inputs=inputs, outputs=outputs)\n     output_data = model(tf.constant(input_data))\n-    self.assertAllEqual(expected_output, output_data)\n+    self.assertAllEqual(output_data, expected_output)\n+\n+  @parameterized.named_parameters([\n+      {\n+          \"testcase_name\": \"ragged_tensor1\",\n+          \"input_data\": [[[\"0 a b\"], [\"c d\"]], [[\"e a\"], [\"b c d\"]], [[\"f\"]]],\n+          \"expected_output\": [[[1, 2, 3], [4, 5]], [[6, 2], [3, 4, 5]], [[7]]],\n+      },\n+      {\n+          \"testcase_name\": \"ragged_tensor2\",\n+          \"input_data\": [[[\"0 a b\"], [\"\"]], [], [[\"e a\"], [\"b c d\"]], [[\"f\"]]],\n+          \"expected_output\": [[[1, 2, 3], []], [], [[6, 2], [3, 4, 5]], [[7]]],\n+      },\n+  ])\n+  def test_ragged_input_and_ragged_output(self, input_data, expected_output):\n+    input_data = tf.ragged.constant(input_data, inner_shape=(1,))\n+    layer = text_vectorization.TextVectorization(\n+        vocabulary=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"], ragged=True)\n+    output_data = layer(input_data)\n+    self.assertAllEqual(output_data, expected_output)\n+\n+    # Again in a keras.Model\n+    inputs = keras.Input(shape=(1,), dtype=tf.string)\n+    outputs = layer(inputs)\n+    model = keras.Model(inputs=inputs, outputs=outputs)\n+    output_data = model.predict(input_data)\n+    self.assertAllEqual(output_data, expected_output)\n \n   def test_scalar_input_int_mode_no_len_limit(self):\n     vocab_data = [\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#31dbf01916b915a94f92f9de7a25e906b2d6d6f7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 226 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 4 | Methods Changed: 9 | Complexity Δ (Sum/Max): 9/6 | Churn Δ: 229 | Churn Cumulative: 12583 | Contributors (this commit): 27 | Commits (past 90d): 10 | Contributors (cumulative): 32 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3202,6 +3202,122 @@ class IoU(_IoUBase):\n     return dict(list(base_config.items()) + list(config.items()))\n \n \n+@keras_export('keras.metrics.BinaryIoU')\n+class BinaryIoU(IoU):\n+  \"\"\"Computes the Intersection-Over-Union metric for class 0 and/or 1.\n+\n+  General definition and computation:\n+\n+  Intersection-Over-Union is a common evaluation metric for semantic image\n+  segmentation.\n+\n+  For an individual class, the IoU metric is defined as follows:\n+\n+  ```\n+  iou = true_positives / (true_positives + false_positives + false_negatives)\n+  ```\n+\n+  To compute IoUs, the predictions are accumulated in a confusion matrix,\n+  weighted by `sample_weight` and the metric is then calculated from it.\n+\n+  If `sample_weight` is `None`, weights default to 1.\n+  Use `sample_weight` of 0 to mask values.\n+\n+  This class can be used to compute IoUs for a binary classification task where\n+  the predictions are provided as logits. First a `threshold` is applied to the\n+  predicted values such that those that are below the `threshold` are converted\n+  to class 0 and those that are above the `threshold` are converted to class 1.\n+\n+  IoUs for classes 0 and 1 are then computed, the mean of IoUs for the classes\n+  that are specified by `target_class_ids` is returned.\n+\n+  Note: with `threshold=0`, this metric has the same behavior as `IoU`.\n+\n+  Args:\n+    target_class_ids: A tuple or list of target class ids for which the metric\n+      is returned. Options are `[0]`, `[1]`, or `[0, 1]`. With `[0]` (or `[1]`),\n+      the IoU metric for class 0 (or class 1, respectively) is returned. With\n+      `[0, 1]`, the mean of IoUs for the two classes is returned.\n+    threshold: A threshold that applies to the prediction logits to convert them\n+      to either predicted class 0 if the logit is below `threshold` or predicted\n+      class 1 if the logit is above `threshold`.\n+    name: (Optional) string name of the metric instance.\n+    dtype: (Optional) data type of the metric result.\n+\n+  Standalone usage:\n+\n+  >>> m = tf.keras.metrics.BinaryIoU(target_class_id=[0, 1], threshold=0.3)\n+  >>> m.update_state([0, 1, 0, 1], [0.1, 0.2, 0.4, 0.7])\n+  >>> m.result().numpy()\n+  0.33333334\n+\n+  >>> m.reset_state()\n+  >>> m.update_state([0, 1, 0, 1], [0.1, 0.2, 0.4, 0.7],\n+  ...                sample_weight=[0.2, 0.3, 0.4, 0.1])\n+  >>> # cm = [[0.2, 0.4],\n+  >>> #        [0.3, 0.1]]\n+  >>> # sum_row = [0.6, 0.4], sum_col = [0.5, 0.5], true_positives = [0.2, 0.1]\n+  >>> # iou = [0.222, 0.125]\n+  >>> m.result().numpy()\n+  0.17\n+\n+  Usage with `compile()` API:\n+\n+  ```python\n+  model.compile(\n+    optimizer='sgd',\n+    loss='mse',\n+    metrics=[tf.keras.metrics.BinaryIoU(target_class_id=[0], threshold=0.5)])\n+  ```\n+  \"\"\"\n+\n+  def __init__(\n+      self,\n+      target_class_ids: Union[List[int], Tuple[int, ...]] = (0, 1),\n+      threshold=0.5,\n+      name=None,\n+      dtype=None,\n+  ):\n+\n+    super(BinaryIoU, self).__init__(\n+        num_classes=2,\n+        target_class_ids=target_class_ids,\n+        name=name,\n+        dtype=dtype,\n+    )\n+    self.threshold = threshold\n+\n+  def update_state(self, y_true, y_pred, sample_weight=None):\n+    \"\"\"Accumulates the confusion matrix statistics.\n+\n+    Before the confusion matrix is updated, the predicted values are thresholded\n+    to be:\n+      0 for values that are smaller than the `threshold`\n+      1 for values that are larger or equal to the `threshold`\n+\n+    Args:\n+      y_true: The ground truth values.\n+      y_pred: The predicted values.\n+      sample_weight: Optional weighting of each example. Defaults to 1. Can be a\n+        `Tensor` whose rank is either 0, or the same rank as `y_true`, and must\n+        be broadcastable to `y_true`.\n+\n+    Returns:\n+      Update op.\n+    \"\"\"\n+    y_pred = tf.cast(y_pred, self._dtype)\n+    y_pred = tf.cast(y_pred >= self.threshold, self._dtype)\n+    return super().update_state(y_true, y_pred, sample_weight)\n+\n+  def get_config(self):\n+    return {\n+        'target_class_ids': self.target_class_ids,\n+        'threshold': self.threshold,\n+        'name': self.name,\n+        'dtype': self._dtype,\n+    }\n+\n+\n @keras_export('keras.metrics.MeanIoU')\n class MeanIoU(IoU):\n   \"\"\"Computes the mean Intersection-Over-Union metric.\n\n@@ -1288,13 +1288,13 @@ class IoUTest(tf.test.TestCase):\n \n   def test_config(self):\n     obj = metrics.IoU(\n-        num_classes=2, target_class_ids=[1, 0], name='iou_class_1')\n-    self.assertEqual(obj.name, 'iou_class_1')\n+        num_classes=2, target_class_ids=[1, 0], name='iou_class_1_0')\n+    self.assertEqual(obj.name, 'iou_class_1_0')\n     self.assertEqual(obj.num_classes, 2)\n     self.assertEqual(obj.target_class_ids, [1, 0])\n \n     obj2 = metrics.IoU.from_config(obj.get_config())\n-    self.assertEqual(obj2.name, 'iou_class_1')\n+    self.assertEqual(obj2.name, 'iou_class_1_0')\n     self.assertEqual(obj2.num_classes, 2)\n     self.assertEqual(obj2.target_class_ids, [1, 0])\n \n@@ -1370,6 +1370,113 @@ class IoUTest(tf.test.TestCase):\n     self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n \n \n+@combinations.generate(combinations.combine(mode=['graph', 'eager']))\n+class BinaryIoUTest(tf.test.TestCase):\n+\n+  def test_config(self):\n+    obj = metrics.BinaryIoU(\n+        target_class_ids=[1, 0], threshold=0.1, name='iou_class_1_0')\n+    self.assertEqual(obj.name, 'iou_class_1_0')\n+    self.assertAlmostEqual(obj.threshold, 0.1)\n+    self.assertEqual(obj.target_class_ids, [1, 0])\n+\n+    obj2 = metrics.BinaryIoU.from_config(obj.get_config())\n+    self.assertEqual(obj.name, 'iou_class_1_0')\n+    self.assertAlmostEqual(obj2.threshold, 0.1)\n+    self.assertEqual(obj.target_class_ids, [1, 0])\n+\n+  def test_different_thresholds_weighted(self):\n+    y_true = [0, 1, 0, 1]\n+    y_pred = [0.1, 0.2, 0.4, 0.7]\n+\n+    sample_weight = tf.constant([0.2, 0.3, 0.4, 0.1])\n+    # with threshold = 0.3, y_pred will be converted to [0, 0, 1, 1]\n+    # cm = [[0.2, 0.4],\n+    #       [0.3, 0.1]]\n+    # sum_row = [0.6, 0.4], sum_col = [0.5, 0.5], true_positives = [0.2, 0.1]\n+    # iou = true_positives / (sum_row + sum_col - true_positives))\n+    expected_result = (0.2 / (0.6 + 0.5 - 0.2) + 0.1 / (0.4 + 0.5 - 0.1)) / 2\n+    obj = metrics.BinaryIoU(target_class_ids=[0, 1], threshold=0.3)\n+    self.evaluate(tf.compat.v1.variables_initializer(obj.variables))\n+    result = obj(y_true, y_pred, sample_weight=sample_weight)\n+    self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n+\n+    sample_weight = tf.constant([0.1, 0.2, 0.4, 0.3])\n+    # with threshold = 0.5, y_pred will be converted to [0, 0, 0, 1]\n+    # cm = [[0.1+0.4, 0],\n+    #       [0.2, 0.3]]\n+    # sum_row = [0.5, 0.5], sum_col = [0.7, 0.3], true_positives = [0.5, 0.3]\n+    # iou = true_positives / (sum_row + sum_col - true_positives))\n+    expected_result = (0.5 / (0.5 + 0.7 - 0.5) + 0.3 / (0.5 + 0.3 - 0.3)) / 2\n+    obj = metrics.BinaryIoU(target_class_ids=[0, 1], threshold=0.5)\n+    self.evaluate(tf.compat.v1.variables_initializer(obj.variables))\n+    result = obj(y_true, y_pred, sample_weight=sample_weight)\n+    self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n+\n+  def test_different_thresholds_unweighted(self):\n+    y_true = [0, 1, 0, 1]\n+    y_pred = [0.1, 0.2, 0.4, 0.7]\n+\n+    # with threshold = 0.3, y_pred will be converted to [0, 0, 1, 1]\n+    # cm = [[1, 1],\n+    #       [1, 1]]\n+    # sum_row = [2, 2], sum_col = [2, 2], true_positives = [1, 1]\n+    # iou = true_positives / (sum_row + sum_col - true_positives))\n+    expected_result = (1 / (2 + 2 - 1) + 1 / (2 + 2 - 1)) / 2\n+    obj = metrics.BinaryIoU(target_class_ids=[0, 1], threshold=0.3)\n+    self.evaluate(tf.compat.v1.variables_initializer(obj.variables))\n+    result = obj(y_true, y_pred)\n+    self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n+\n+    # with threshold = 0.5, y_pred will be converted to [0, 0, 0, 1]\n+    # cm = [[2, 0],\n+    #       [1, 1]]\n+    # sum_row = [2, 2], sum_col = [3, 1], true_positives = [2, 1]\n+    # iou = true_positives / (sum_row + sum_col - true_positives))\n+    expected_result = (2 / (2 + 3 - 2) + 1 / (2 + 1 - 1)) / 2\n+    obj = metrics.BinaryIoU(target_class_ids=[0, 1], threshold=0.5)\n+    self.evaluate(tf.compat.v1.variables_initializer(obj.variables))\n+    result = obj(y_true, y_pred)\n+    self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n+\n+  def test_multi_dim_input(self):\n+    y_true = tf.constant([[0, 1], [0, 1]], dtype=tf.float32)\n+    y_pred = tf.constant([[0.1, 0.7], [0.9, 0.3]])\n+    threshold = 0.4  # y_pred will become [[0, 1], [1, 0]]\n+    sample_weight = tf.constant([[0.2, 0.3], [0.4, 0.1]])\n+    # cm = [[0.2, 0.4],\n+    #       [0.1, 0.3]]\n+    # sum_row = [0.6, 0.4], sum_col = [0.3, 0.7], true_positives = [0.2, 0.3]\n+    # iou = true_positives / (sum_row + sum_col - true_positives))\n+    expected_result = (0.2 / (0.6 + 0.3 - 0.2) + 0.3 / (0.4 + 0.7 - 0.3)) / 2\n+    obj = metrics.BinaryIoU(target_class_ids=[0, 1], threshold=threshold)\n+    self.evaluate(tf.compat.v1.variables_initializer(obj.variables))\n+    result = obj(y_true, y_pred, sample_weight=sample_weight)\n+    self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n+\n+  def test_zero_valid_entries(self):\n+    obj = metrics.BinaryIoU(target_class_ids=[0, 1])\n+    self.evaluate(tf.compat.v1.variables_initializer(obj.variables))\n+    self.assertAllClose(\n+        self.evaluate(obj.result()), 0, atol=1e-3)\n+\n+  def test_zero_and_non_zero_entries(self):\n+    y_pred = tf.constant([0.6], dtype=tf.float32)\n+    threshold = 0.5\n+    y_true = tf.constant([1])\n+\n+    obj = metrics.BinaryIoU(target_class_ids=[0, 1], threshold=threshold)\n+    self.evaluate(tf.compat.v1.variables_initializer(obj.variables))\n+    result = obj(y_true, y_pred)\n+\n+    # cm = [[0, 0],\n+    #       [0, 1]]\n+    # sum_row = [0, 1], sum_col = [0, 1], true_positives = [0, 1]\n+    # iou = true_positives / (sum_row + sum_col - true_positives))\n+    expected_result = 1 / (1 + 1 - 1)\n+    self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n+\n+\n @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n class MeanIoUTest(tf.test.TestCase):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2b763b752c7394af2505121ef3ab92999d73b333", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 562 | Contributors (this commit): 3 | Commits (past 90d): 8 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -162,7 +162,9 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n \n   def _build_learning_rate(self, learning_rate):\n     if isinstance(learning_rate, learning_rate_schedule.LearningRateSchedule):\n-      self._current_learning_rate = learning_rate(self.iterations)\n+      # Create a variable to hold the current learning rate.\n+      self._current_learning_rate = tf.Variable(\n+          learning_rate(self.iterations), dtype=tf.float32)\n       return learning_rate\n     return tf.Variable(learning_rate, dtype=backend.floatx())\n \n@@ -293,7 +295,7 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n     if isinstance(self._learning_rate,\n                   learning_rate_schedule.LearningRateSchedule):\n       # Compute the current learning rate at the beginning of variable update.\n-      self._current_learning_rate = self._learning_rate(self.iterations)\n+      self._current_learning_rate.assign(self._learning_rate(self.iterations))\n     grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n     grads, trainable_variables = zip(*grads_and_vars)\n     scope_name = self._name or \"optimizer\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a3c53fc0988d61c6cb9f6663fd6a326e884dca13", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 33 | Lines Deleted: 1 | Files Changed: 3 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 34 | Churn Cumulative: 2036 | Contributors (this commit): 24 | Commits (past 90d): 3 | Contributors (cumulative): 30 | DMM Complexity: 1.0\n\nDIFF:\n@@ -26,6 +26,7 @@ from keras.distribute import distributed_training_utils_v1\n from keras.engine import training_utils_v1\n from keras.utils.generic_utils import make_batches\n from keras.utils.generic_utils import slice_arrays\n+from keras.utils import io_utils\n from keras.utils.mode_keys import ModeKeys\n from tensorflow.python.platform import tf_logging as logging\n \n@@ -464,7 +465,7 @@ def _print_train_info(num_samples_or_steps, val_samples_or_steps, is_dataset):\n   if val_samples_or_steps:\n     msg += ', validate on {0} {increment}'.format(\n         val_samples_or_steps, increment=increment)\n-  print(msg)\n+  io_utils.print_msg(msg)\n \n \n def _get_num_samples_or_steps(ins, batch_size, steps_per_epoch):\n\n@@ -16,6 +16,21 @@\n \"\"\"Utilities related to disk I/O.\"\"\"\n \n import os\n+import sys\n+import threading\n+\n+import absl\n+\n+ABSL_LOGGING = threading.local()\n+ABSL_LOGGING.enable = False\n+\n+\n+def print_msg(message):\n+  if ABSL_LOGGING.enable:\n+    absl.logging.info(message)\n+  else:\n+    sys.stdout.write(message)\n+    sys.stdout.flush()\n \n \n def path_to_string(path):\n\n@@ -14,6 +14,8 @@\n # ==============================================================================\n \"\"\"Tests for io_utils.\"\"\"\n \n+import sys\n+\n import tensorflow.compat.v2 as tf\n \n import builtins\n@@ -57,6 +59,20 @@ class TestIOUtils(keras_parameterized.TestCase):\n     self.assertEqual(io_utils.path_to_string('path'), 'path')\n     self.assertIs(io_utils.path_to_string(dummy), dummy)\n \n+  def test_print_msg(self):\n+    enabled = io_utils.ABSL_LOGGING.enable\n+\n+    io_utils.ABSL_LOGGING.enable = True\n+    with self.assertLogs(level='INFO') as logged:\n+      io_utils.print_msg('Testing Message')\n+    self.assertIn('Testing Message', logged.output[0])\n+\n+    io_utils.ABSL_LOGGING.enable = False\n+    with self.captureWritesToStream(sys.stdout) as printed:\n+      io_utils.print_msg('Testing Message')\n+    self.assertIn('Testing Message', printed.contents())\n+\n+    io_utils.ABSL_LOGGING.enable = enabled\n \n if __name__ == '__main__':\n   tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e0a232af3e0ebb5456239daedbaba02e1d328477", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 2750 | Contributors (this commit): 19 | Commits (past 90d): 1 | Contributors (cumulative): 19 | DMM Complexity: 1.0\n\nDIFF:\n@@ -219,6 +219,9 @@ class _Merge(Layer):\n     return backend.all(\n         backend.concatenate(masks, axis=0), axis=0, keepdims=False)\n \n+  def get_config(self):\n+    return super(_Merge, self).get_config()\n+\n \n @keras_export('keras.layers.Add')\n class Add(_Merge):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#747f187e40b7f5a4e4b3368eae50c786364d5d7d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 324 | Lines Deleted: 3 | Files Changed: 6 | Hunks: 8 | Methods Changed: 11 | Complexity Δ (Sum/Max): 15/8 | Churn Δ: 327 | Churn Cumulative: 4142 | Contributors (this commit): 5 | Commits (past 90d): 20 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,3 @@\n+\"\"\"Init file.\"\"\"\n+\n+from keras.legacy_tf_layers import migration_utils  # pylint: disable=unused-import\n\n@@ -0,0 +1,103 @@\n+\"\"\"The DetermisticRandomTestTool.\n+\n+(from www.tensorflow.org/guide/migrate/validate_correctness) is a tool used to\n+make random number generation semantics match between TF1.x graphs/sessions and\n+eager execution.\n+\"\"\"\n+\n+import sys\n+\n+import tensorflow.compat.v2 as tf\n+\n+from tensorflow.python.util.tf_export import keras_export  # pylint: disable=g-direct-tensorflow-import\n+\n+\n+@keras_export(v1=[\"keras.utils.DeterministicRandomTestTool\"])\n+class DeterministicRandomTestTool(object):\n+  \"\"\"DeterministicRandomTestTool is a testing tool.\n+\n+  This tool is used to validate random number generation semantics match between\n+  TF1.x graphs/sessions and eager execution.\n+\n+  This is useful when you are migrating from TF 1.x to TF2 and need to make sure\n+  your computation is still happening correctly along the way. See the\n+  validating correctness migration guide for more info :\n+  https://www.tensorflow.org/guide/migrate/validate_correctness\n+\n+  The following DeterministicRandomTestTool object provides a context manager\n+  scope() that can make stateful random operations use the same seed across both\n+  TF1 graphs/sessions and eager execution,The tool provides two testing modes:\n+  - constant which uses the same seed for every single operation no matter how\n+  many times it has been called and,\n+  - num_random_ops which uses the number of previously-observed stateful random\n+  operations as the operation seed.\n+  The num_random_ops mode serves as a more sensitive validation check than the\n+  constant mode. It ensures that the random numbers initialization does not get\n+  accidentaly reused.(for example if several weights take on the same\n+  initializations), you can use the num_random_ops mode to avoid this. In the\n+  num_random_ops mode, the generated random numbers will depend on the ordering\n+  of random ops in the program.\n+\n+  This applies both to the stateful random operations used for creating and\n+  initializing variables, and to the stateful random operations used in\n+  computation (such as for dropout layers).\n+  \"\"\"\n+\n+  def __init__(self, seed: int = 42, mode=\"constant\"):\n+    \"\"\"Set mode to 'constant' or 'num_random_ops'. Defaults to 'constant'.\"\"\"\n+    if mode not in {\"constant\", \"num_random_ops\"}:\n+      raise ValueError(\"Mode arg must be 'constant' or 'num_random_ops'. \" +\n+                       \"Got: {}\".format(mode))\n+    self.seed_implementation = sys.modules[tf.compat.v1.get_seed.__module__]\n+    self._mode = mode\n+    self._seed = seed\n+    self.operation_seed = 0\n+    self._observed_seeds = set()\n+\n+  @property\n+  def operation_seed(self):\n+    return self._operation_seed\n+\n+  @operation_seed.setter\n+  def operation_seed(self, value):\n+    self._operation_seed = value\n+\n+  def scope(self):\n+    \"\"\"set random seed.\"\"\"\n+\n+    tf.random.set_seed(self._seed)\n+    def _get_seed(_):\n+      \"\"\"Wraps TF get_seed to make deterministic random generation easier.\n+\n+      This makes a variable's initialization (and calls that involve random\n+      number generation) depend only on how many random number generations\n+      were used in the scope so far, rather than on how many unrelated\n+      operations the graph contains.\n+\n+      Returns:\n+        Random seed tuple.\n+      \"\"\"\n+      op_seed = self._operation_seed\n+      if self._mode == \"constant\":\n+        tf.random.set_seed(op_seed)\n+      else:\n+        if op_seed in self._observed_seeds:\n+          raise ValueError(\n+              \"This `DeterministicTestTool` object is trying to re-use the \" +\n+              \"already-used operation seed {}. \".format(op_seed) +\n+              \"It cannot guarantee random numbers will match between eager \" +\n+              \"and sessions when an operation seed is reused. \" +\n+              \"You most likely set \" +\n+              \"`operation_seed` explicitly but used a value that caused the \" +\n+              \"naturally-incrementing operation seed sequences to overlap \" +\n+              \"with an already-used seed.\")\n+\n+        self._observed_seeds.add(op_seed)\n+        self._operation_seed += 1\n+\n+      return (self._seed, op_seed)\n+    # mock.patch internal symbols to modify the behavior of TF APIs relying on\n+    # them\n+\n+    return tf.compat.v1.test.mock.patch.object(\n+        self.seed_implementation, \"get_seed\", wraps=_get_seed)\n\n@@ -0,0 +1,215 @@\n+\"\"\"Tests for migration_utils.\"\"\"\n+\n+from keras.initializers import GlorotUniform as V2GlorotUniform\n+from keras.legacy_tf_layers import migration_utils\n+import tensorflow as tf\n+\n+\n+class DeterministicRandomTestToolTest(tf.test.TestCase):\n+\n+  def test_constant_mode_no_seed(self):\n+    \"\"\"Test random tensor generation consistancy in constant mode.\n+\n+    Verify that the random tensor generated without using the seed is\n+    consistant between graph and eager mode\n+    \"\"\"\n+\n+    # Generate three random tensors to show how the stateful random number\n+    # generation and glorot_uniform_initializer match between sessions and\n+    # eager execution.\n+    random_tool = migration_utils.DeterministicRandomTestTool()\n+    with random_tool.scope():\n+      graph = tf.Graph()\n+      with graph.as_default(), tf.compat.v1.Session(graph=graph) as sess:\n+        a = tf.compat.v1.random.uniform(shape=(3, 1))\n+        # adding additional computation/ops to the graph and ensuring consistant\n+        # random number generation\n+        a = a * 3\n+        b = tf.compat.v1.random.uniform(shape=(3, 3))\n+        b = b * 3\n+        c = tf.compat.v1.random.uniform(shape=(3, 3))\n+        c = c * 3\n+        d = tf.compat.v1.glorot_uniform_initializer()(\n+            shape=(6, 6), dtype=tf.float32)\n+        graph_a, graph_b, graph_c, graph_d = sess.run([a, b, c, d])\n+\n+      a = tf.compat.v2.random.uniform(shape=(3, 1))\n+      a = a * 3\n+      b = tf.compat.v2.random.uniform(shape=(3, 3))\n+      b = b * 3\n+      c = tf.compat.v2.random.uniform(shape=(3, 3))\n+      c = c * 3\n+      d = V2GlorotUniform()(shape=(6, 6), dtype=tf.float32)\n+    # validate that the generated random tensors match\n+    self.assertAllClose(graph_a, a)\n+    self.assertAllClose(graph_b, b)\n+    self.assertAllClose(graph_c, c)\n+    self.assertAllClose(graph_d, d)\n+    # In constant mode, because b and c were generated with the same seed within\n+    # the same scope and have the same shape, they will have exactly the same\n+    # values.\n+    # validate that b and c are the same, also graph_b and graph_c\n+    self.assertAllClose(b, c)\n+    self.assertAllClose(graph_b, graph_c)\n+\n+  def test_constant_mode_seed_argument(self):\n+    \"\"\"Test random tensor generation consistancy in constant mode.\n+\n+    Verify that the random tensor generated by setting the global seeed\n+    in the args is consistant between graph and eager mode.\n+    \"\"\"\n+    random_tool = migration_utils.DeterministicRandomTestTool()\n+    with random_tool.scope():\n+      graph = tf.Graph()\n+      with graph.as_default(), tf.compat.v1.Session(graph=graph) as sess:\n+        # adding additional computation/ops to the graph and ensuring consistant\n+        # random number generation\n+        a = tf.compat.v1.random.uniform(shape=(3, 1), seed=1234)\n+        a = a * 3\n+        b = tf.compat.v1.random.uniform(shape=(3, 3), seed=1234)\n+        b = b * 3\n+        c = tf.compat.v1.glorot_uniform_initializer(seed=1234)(\n+            shape=(6, 6), dtype=tf.float32)\n+        graph_a, graph_b, graph_c = sess.run([a, b, c])\n+      a = tf.compat.v2.random.uniform(shape=(3, 1), seed=1234)\n+      a = a * 3\n+      b = tf.compat.v2.random.uniform(shape=(3, 3), seed=1234)\n+      b = b * 3\n+      c = V2GlorotUniform(seed=1234)(shape=(6, 6), dtype=tf.float32)\n+\n+    # validate that the generated random tensors match\n+    self.assertAllClose(graph_a, a)\n+    self.assertAllClose(graph_b, b)\n+    self.assertAllClose(graph_c, c)\n+\n+  def test_num_rand_ops(self):\n+    \"\"\"Test random tensor generation consistancy in num_random_ops mode.\n+\n+    Verify that the random tensor generated without using the seed is\n+    consistant between graph and eager mode.\n+    Random tensor generated should be different based on random ops ordering\n+    \"\"\"\n+    random_tool = migration_utils.DeterministicRandomTestTool(\n+        mode=\"num_random_ops\")\n+    with random_tool.scope():\n+      graph = tf.Graph()\n+      with graph.as_default(), tf.compat.v1.Session(graph=graph) as sess:\n+        # adding additional computation/ops to the graph and ensuring consistant\n+        # random number generation\n+        a = tf.compat.v1.random.uniform(shape=(3, 1))\n+        a = a * 3\n+        b = tf.compat.v1.random.uniform(shape=(3, 3))\n+        b = b * 3\n+        c = tf.compat.v1.random.uniform(shape=(3, 3))\n+        c = c * 3\n+        d = tf.compat.v1.glorot_uniform_initializer()(\n+            shape=(6, 6), dtype=tf.float32)\n+        graph_a, graph_b, graph_c, graph_d = sess.run([a, b, c, d])\n+\n+    random_tool = migration_utils.DeterministicRandomTestTool(\n+        mode=\"num_random_ops\")\n+    with random_tool.scope():\n+      a = tf.compat.v2.random.uniform(shape=(3, 1))\n+      a = a * 3\n+      b = tf.compat.v2.random.uniform(shape=(3, 3))\n+      b = b * 3\n+      c = tf.compat.v2.random.uniform(shape=(3, 3))\n+      c = c * 3\n+      d = V2GlorotUniform()(shape=(6, 6), dtype=tf.float32)\n+    # validate that the generated random tensors match\n+    self.assertAllClose(graph_a, a)\n+    self.assertAllClose(graph_b, b)\n+    self.assertAllClose(graph_c, c)\n+    self.assertAllClose(graph_d, d)\n+    # validate that the tensors differ based on ops ordering\n+    self.assertNotAllClose(b, c)\n+    self.assertNotAllClose(graph_b, graph_c)\n+\n+  def test_num_rand_ops_program_order(self):\n+    \"\"\"Test random tensor generation consistancy in num_random_ops mode.\n+\n+    validate that in this mode random number generation is sensitive to program\n+    order, so the generated random tesnors should not match.\n+    \"\"\"\n+    random_tool = migration_utils.DeterministicRandomTestTool(\n+        mode=\"num_random_ops\")\n+    with random_tool.scope():\n+      a = tf.random.uniform(shape=(3, 1))\n+      # adding additional computation/ops to the graph and ensuring consistant\n+      # random number generation\n+      a = a * 3\n+      b = tf.random.uniform(shape=(3, 3))\n+      b = b * 3\n+\n+    random_tool = migration_utils.DeterministicRandomTestTool(\n+        mode=\"num_random_ops\")\n+    with random_tool.scope():\n+      b_prime = tf.random.uniform(shape=(3, 3))\n+      # adding additional computation/ops to the graph and ensuring consistant\n+      # random number generation\n+      b_prime = b_prime * 3\n+      a_prime = tf.random.uniform(shape=(3, 1))\n+      a_prime = a_prime * 3\n+    # validate that the tensors are different\n+    self.assertNotAllClose(a, a_prime)\n+    self.assertNotAllClose(b, b_prime)\n+\n+  def test_num_rand_ops_operation_seed(self):\n+    \"\"\"Test random tensor generation consistancy in num_random_ops mode.\n+\n+    validate if  random number generation match across two different program\n+    orders.\n+    \"\"\"\n+    random_tool = migration_utils.DeterministicRandomTestTool(\n+        mode=\"num_random_ops\")\n+    with random_tool.scope():\n+      # operation seed = 0\n+      a = tf.random.uniform(shape=(3, 1))\n+      a = a * 3\n+      # operation seed = 1\n+      b = tf.random.uniform(shape=(3, 3))\n+      b = b * 3\n+\n+    random_tool = migration_utils.DeterministicRandomTestTool(\n+        mode=\"num_random_ops\")\n+    with random_tool.scope():\n+      random_tool.operation_seed = 1\n+      b_prime = tf.random.uniform(shape=(3, 3))\n+      b_prime = b_prime * 3\n+      random_tool.operation_seed = 0\n+      a_prime = tf.random.uniform(shape=(3, 1))\n+      a_prime = a_prime * 3\n+\n+    self.assertAllClose(a, a_prime)\n+    self.assertAllClose(b, b_prime)\n+\n+  def test_num_rand_ops_disallow_repeated_ops_seed(self):\n+    \"\"\"Test random tensor generation consistancy in num_random_ops mode.\n+\n+    validate if  DeterministicRandomTestTool disallows reusing already-used\n+    operation seeds.\n+    \"\"\"\n+    random_tool = migration_utils.DeterministicRandomTestTool(\n+        mode=\"num_random_ops\")\n+    with random_tool.scope():\n+      random_tool.operation_seed = 1\n+      b_prime = tf.random.uniform(shape=(3, 3))\n+      b_prime = b_prime * 3\n+      random_tool.operation_seed = 0\n+      a_prime = tf.random.uniform(shape=(3, 1))\n+      a_prime = a_prime * 3\n+      error_string = \"An exception should have been raised before this\"\n+      error_raised = \"An exception should have been raised before this\"\n+      try:\n+        c = tf.random.uniform(shape=(3, 1))\n+        raise RuntimeError(error_string)\n+\n+      except ValueError as err:\n+        err_raised = err\n+\n+      self.assertNotEqual(err_raised, error_string)\n+\n+\n+if __name__ == \"__main__\":\n+  tf.test.main()\n+\n\n@@ -20,10 +20,10 @@ from __future__ import print_function\n \n import contextlib\n import functools\n+\n from keras.engine import base_layer\n from keras.utils import layer_utils\n from keras.utils import tf_inspect\n-\n import tensorflow.compat.v2 as tf\n \n from tensorflow.python.ops import variable_scope as vs  # pylint: disable=g-direct-tensorflow-import\n\n@@ -30,7 +30,7 @@ from keras.layers import core\n from keras.legacy_tf_layers import core as core_layers\n from keras.legacy_tf_layers import variable_scope_shim\n import numpy\n-import tensorflow.compat.v2 as tf\n+import tensorflow as tf\n \n from tensorflow.python.framework import test_util   # pylint: disable=g-direct-tensorflow-import\n from tensorflow.python.ops import variable_scope   # pylint: disable=g-direct-tensorflow-import\n@@ -1425,5 +1425,6 @@ class TF1VariableScopeLayerTest(tf.test.TestCase, parameterized.TestCase):\n     with self.assertRaisesRegex(ValueError, \"does not extend\"):\n       foo(tf.ones(shape=(4, 4)))\n \n+\n if __name__ == \"__main__\":\n   tf.test.main()\n\n@@ -177,6 +177,5 @@ class SplitUtilsTest(keras_parameterized.TestCase):\n           ValueError, 'instance was constructed with eager mode enabled'):\n         model.fit(x, y, batch_size=2)\n \n-\n if __name__ == '__main__':\n   tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dc7f1f1dd016ee82ad9bb0d0e24925e3e5d4a0bd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 1307 | Contributors (this commit): 24 | Commits (past 90d): 4 | Contributors (cumulative): 27 | DMM Complexity: None\n\nDIFF:\n@@ -26,10 +26,13 @@ ABSL_LOGGING.enable = False\n \n \n def print_msg(message):\n+  \"\"\"Print the message to absl logging or stdout.\"\"\"\n   if ABSL_LOGGING.enable:\n     absl.logging.info(message)\n   else:\n-    sys.stdout.write(message)\n+    # Simulate the print function,\n+    # which has a new line at the end.\n+    sys.stdout.write(message + '\\n')\n     sys.stdout.flush()\n \n \n\n@@ -70,7 +70,7 @@ class TestIOUtils(keras_parameterized.TestCase):\n     io_utils.ABSL_LOGGING.enable = False\n     with self.captureWritesToStream(sys.stdout) as printed:\n       io_utils.print_msg('Testing Message')\n-    self.assertIn('Testing Message', printed.contents())\n+    self.assertEqual('Testing Message\\n', printed.contents())\n \n     io_utils.ABSL_LOGGING.enable = enabled\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5fe94eff8b28080b7b38ddd8e97ca5b2965cde86", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 564 | Contributors (this commit): 3 | Commits (past 90d): 9 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -98,7 +98,7 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n         tape.watch(var_list)\n         loss = loss()\n     grads = tape.gradient(loss, var_list)\n-    return zip(grads, var_list)\n+    return list(zip(grads, var_list))\n \n   def _clip_gradients(self, grads):\n     clipped_grads = []\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8328312e157a5bd67f2753f6c7a24baf6d6cedf0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 6 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 402 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -36,10 +36,11 @@ python efficientnet_weight_update_util.py --model b3 --notop \\\n     --ckpt noisy_student_efficientnet-b3/model.ckpt --o efficientnetb3_new.h5\n \"\"\"\n \n-import tensorflow.compat.v2 as tf\n-\n import argparse\n import warnings\n+\n+from keras.utils import io_utils\n+import tensorflow.compat.v2 as tf\n from tensorflow.keras.applications import efficientnet\n \n \n@@ -65,11 +66,11 @@ def write_ckpt_to_h5(path_h5, path_ckpt, keras_model, use_ema=True):\n   keras_blocks = get_keras_blocks(keras_weight_names)\n   tf_blocks = get_tf_blocks(tf_weight_names)\n \n-  print('check variables match in each block')\n+  io_utils.print_msg('check variables match in each block')\n   for keras_block, tf_block in zip(keras_blocks, tf_blocks):\n     check_match(keras_block, tf_block, keras_weight_names, tf_weight_names,\n                 model_name_tf)\n-    print('{} and {} match.'.format(tf_block, keras_block))\n+    io_utils.print_msg('{} and {} match.'.format(tf_block, keras_block))\n \n   block_mapping = {x[0]: x[1] for x in zip(keras_blocks, tf_blocks)}\n \n@@ -89,9 +90,9 @@ def write_ckpt_to_h5(path_h5, path_ckpt, keras_model, use_ema=True):\n       tf_name = keras_name_to_tf_name_stem_top(\n           w.name, use_ema=use_ema, model_name_tf=model_name_tf)\n     elif 'normalization' in w.name:\n-      print('skipping variable {}: normalization is a layer'\n-            'in keras implementation, but preprocessing in '\n-            'TF implementation.'.format(w.name))\n+      io_utils.print_msg(\n+          f'Skipping variable {w.name}: normalization is a Keras '\n+          'preprocessing layer, which does not exist in the TF ckpt.')\n       continue\n     else:\n       raise ValueError('{} failed to parse.'.format(w.name))\n@@ -111,7 +112,7 @@ def write_ckpt_to_h5(path_h5, path_ckpt, keras_model, use_ema=True):\n         raise ValueError('Fail to load {} from {}'.format(w.name, tf_name))\n \n   total_weights = len(keras_model.weights)\n-  print('{}/{} weights updated'.format(changed_weights, total_weights))\n+  io_utils.print_msg(f'{changed_weights}/{total_weights} weights updated')\n   keras_model.save_weights(path_h5)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a2e72b4dd715d8b54f5e13221d982727dd696b19", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 147 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 4 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 147 | Churn Cumulative: 12730 | Contributors (this commit): 27 | Commits (past 90d): 12 | Contributors (cumulative): 32 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3394,6 +3394,113 @@ class MeanIoU(IoU):\n     }\n \n \n+@keras_export('keras.metrics.OneHotIoU')\n+class OneHotIoU(IoU):\n+  \"\"\"Computes the Intersection-Over-Union metric for one-hot encoded labels.\n+\n+  General definition and computation:\n+\n+  Intersection-Over-Union is a common evaluation metric for semantic image\n+  segmentation.\n+\n+  For an individual class, the IoU metric is defined as follows:\n+\n+  ```\n+  iou = true_positives / (true_positives + false_positives + false_negatives)\n+  ```\n+\n+  To compute IoUs, the predictions are accumulated in a confusion matrix,\n+  weighted by `sample_weight` and the metric is then calculated from it.\n+\n+  If `sample_weight` is `None`, weights default to 1.\n+  Use `sample_weight` of 0 to mask values.\n+\n+  This class can be used to compute IoU for multi-class classification tasks\n+  where the labels are one-hot encoded (the last axis should have one dimension\n+  per class). Note that the predictions should also have the same shape. To\n+  compute the IoU, first the labels and predictions are converted back into\n+  integer format by taking the argmax over the class axis. Then the same\n+  computation steps as for the base `IoU` class apply.\n+\n+  Note, if there is only one channel in the labels and predictions, this class\n+  is the same as class `IoU`. In this case, use `IoU` instead.\n+\n+  Also, make sure that `num_classes` is equal to the number of classes in the\n+  data, to avoid a \"labels out of bound\" error when the confusion matrix is\n+  computed.\n+\n+  Args:\n+    num_classes: The possible number of labels the prediction task can have.\n+      A confusion matrix of shape `(num_classes, num_classes)` will be\n+      allocated to accumulate predictions from which the metric is calculated.\n+    target_class_ids: A tuple or list of target class ids for which the metric\n+      is returned. To compute IoU for a specific class, a list (or tuple) of a\n+      single id value should be provided.\n+    name: (Optional) string name of the metric instance.\n+    dtype: (Optional) data type of the metric result.\n+\n+  Standalone usage:\n+\n+  >>> y_true = tf.constant([[0, 0, 1], [1, 0, 0], [0, 1, 0], [1, 0, 0]])\n+  >>> y_pred = tf.constant([[0.2, 0.3, 0.5], [0.1, 0.2, 0.7], [0.5, 0.3, 0.1],\n+  >>>                       [0.1, 0.4, 0.5]])\n+  >>> sample_weight = [0.1, 0.2, 0.3, 0.4]\n+  >>> m = metrics.OneHotIoU(num_classes=3, target_class_ids=[0, 2])\n+  >>> m.update_state(y_true=y_true, y_pred=y_pred, sample_weight=sample_weight)\n+  >>> # cm = [[0, 0, 0.2+0.4],\n+  >>> #       [0.3, 0, 0],\n+  >>> #       [0, 0, 0.1]]\n+  >>> # sum_row = [0.3, 0, 0.7], sum_col = [0.6, 0.3, 0.1]\n+  >>> # true_positives = [0, 0, 0.1]\n+  >>> # single_iou = true_positives / (sum_row + sum_col - true_positives))\n+  >>> # mean_iou = (0 / (0.3 + 0.6 - 0) + 0.1 / (0.7 + 0.1 - 0.1)) / 2\n+  >>> m.result().numpy()\n+  0.071\n+\n+  Usage with `compile()` API:\n+\n+  ```python\n+  model.compile(\n+    optimizer='sgd',\n+    loss='mse',\n+    metrics=[tf.keras.metrics.OneHotIoU(num_classes=3, target_class_id=[1])])\n+  ```\n+  \"\"\"\n+\n+  def __init__(\n+      self,\n+      num_classes: int,\n+      target_class_ids: Union[List[int], Tuple[int, ...]],\n+      name=None,\n+      dtype=None,\n+  ):\n+    super(OneHotIoU, self).__init__(\n+        num_classes=num_classes,\n+        target_class_ids=target_class_ids,\n+        name=name,\n+        dtype=dtype,\n+    )\n+\n+  def update_state(self, y_true, y_pred, sample_weight=None):\n+    \"\"\"Accumulates the confusion matrix statistics.\n+\n+    Args:\n+      y_true: The ground truth values.\n+      y_pred: The predicted values.\n+      sample_weight: Optional weighting of each example. Defaults to 1. Can be a\n+        `Tensor` whose rank is either 0, or the same rank as `y_true`, and must\n+        be broadcastable to `y_true`.\n+\n+    Returns:\n+      Update op.\n+    \"\"\"\n+    # Select max hot-encoding channels to convert into all-class format\n+    y_true = tf.argmax(y_true, axis=-1, output_type=tf.int32)\n+    y_pred = tf.argmax(y_pred, axis=-1, output_type=tf.int32)\n+\n+    return super().update_state(y_true, y_pred, sample_weight)\n+\n+\n @keras_export('keras.metrics.MeanTensor')\n class MeanTensor(Metric):\n   \"\"\"Computes the element-wise (weighted) mean of the given tensors.\n\n@@ -1560,6 +1560,46 @@ class MeanIoUTest(tf.test.TestCase):\n     self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n \n \n+@combinations.generate(combinations.combine(mode=['graph', 'eager']))\n+class OneHotIoUTest(tf.test.TestCase):\n+\n+  def test_unweighted(self):\n+    y_true = tf.constant([[0, 0, 1], [1, 0, 0], [0, 1, 0], [1, 0, 0]])\n+    # y_true will be converted to [2, 0, 1, 0]\n+    y_pred = tf.constant([[0.2, 0.3, 0.5], [0.1, 0.2, 0.7], [0.5, 0.3, 0.1],\n+                          [0.1, 0.4, 0.5]])\n+    # y_pred will be converted to [2, 2, 0, 2]\n+    # cm = [[0, 0, 2],\n+    #       [1, 0, 0],\n+    #       [0, 0, 1]\n+    # sum_row = [1, 0, 3], sum_col = [2, 1, 1], true_positives = [0, 0, 1]\n+    # iou = true_positives / (sum_row + sum_col - true_positives))\n+    expected_result = (0 / (1 + 2 - 0) + 1 / (3 + 1 - 1)) / 2\n+    obj = metrics.OneHotIoU(num_classes=3, target_class_ids=[0, 2])\n+    self.evaluate(tf.compat.v1.variables_initializer(obj.variables))\n+    result = obj(y_true, y_pred)\n+    self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n+\n+  def test_weighted(self):\n+    y_true = tf.constant([[0, 0, 1], [1, 0, 0], [0, 1, 0], [1, 0, 0]])\n+    # y_true will be converted to [2, 0, 1, 0]\n+    y_pred = tf.constant([[0.2, 0.3, 0.5], [0.1, 0.2, 0.7], [0.5, 0.3, 0.1],\n+                          [0.1, 0.4, 0.5]])\n+    # y_pred will be converted to [2, 2, 0, 2]\n+    sample_weight = [0.1, 0.2, 0.3, 0.4]\n+    # cm = [[0, 0, 0.2+0.4],\n+    #       [0.3, 0, 0],\n+    #       [0, 0, 0.1]]\n+    # sum_row = [0.3, 0, 0.7], sum_col = [0.6, 0.3, 0.1]\n+    # true_positives = [0, 0, 0.1]\n+    # iou = true_positives / (sum_row + sum_col - true_positives))\n+    expected_result = (0 / (0.3 + 0.6 - 0) + 0.1 / (0.7 + 0.1 - 0.1)) / 2\n+    obj = metrics.OneHotIoU(num_classes=3, target_class_ids=[0, 2])\n+    self.evaluate(tf.compat.v1.variables_initializer(obj.variables))\n+    result = obj(y_true, y_pred, sample_weight=sample_weight)\n+    self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n+\n+\n class MeanTensorTest(tf.test.TestCase, parameterized.TestCase):\n \n   @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#42ddcec45e6021d0f0a441df42fe8ce063e8896b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 12 | Files Changed: 3 | Hunks: 9 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 25 | Churn Cumulative: 6189 | Contributors (this commit): 65 | Commits (past 90d): 14 | Contributors (cumulative): 80 | DMM Complexity: 0.0\n\nDIFF:\n@@ -41,7 +41,7 @@ import numpy as np\n from six.moves.urllib.request import urlopen\n from keras.utils import tf_inspect\n from keras.utils.generic_utils import Progbar\n-from keras.utils.io_utils import path_to_string\n+from keras.utils import io_utils\n from tensorflow.python.util.tf_export import keras_export\n \n # Required to support google internal urlretrieve\n@@ -120,8 +120,8 @@ def _extract_archive(file_path, path='.', archive_format='auto'):\n   if isinstance(archive_format, str):\n     archive_format = [archive_format]\n \n-  file_path = path_to_string(file_path)\n-  path = path_to_string(path)\n+  file_path = io_utils.path_to_string(file_path)\n+  path = io_utils.path_to_string(path)\n \n   for archive_type in archive_format:\n     if archive_type == 'tar':\n@@ -221,7 +221,7 @@ def get_file(fname=None,\n   datadir = os.path.join(datadir_base, cache_subdir)\n   _makedirs_exist_ok(datadir)\n \n-  fname = path_to_string(fname)\n+  fname = io_utils.path_to_string(fname)\n   if not fname:\n     fname = os.path.basename(urlsplit(origin).path)\n     if not fname:\n@@ -246,16 +246,17 @@ def get_file(fname=None,\n     # File found; verify integrity if a hash was provided.\n     if file_hash is not None:\n       if not validate_file(fpath, file_hash, algorithm=hash_algorithm):\n-        print('A local file was found, but it seems to be '\n-              'incomplete or outdated because the ' + hash_algorithm +\n-              ' file hash does not match the original value of ' + file_hash +\n+        io_utils.print_msg(\n+            'A local file was found, but it seems to be '\n+            f'incomplete or outdated because the {hash_algorithm} '\n+            f'file hash does not match the original value of {file_hash} '\n             'so we will re-download the data.')\n         download = True\n   else:\n     download = True\n \n   if download:\n-    print('Downloading data from', origin)\n+    io_utils.print_msg(f'Downloading data from {origin}')\n \n     class ProgressTracker:\n       # Maintain progbar for the lifetime of download.\n\n@@ -73,5 +73,5 @@ def ask_to_proceed_with_overwrite(filepath):\n                       '(cancel).').strip().lower()\n   if overwrite == 'n':\n     return False\n-  print('[TIP] Next time specify overwrite=True!')\n+  print_msg('[TIP] Next time specify overwrite=True!')\n   return True\n\n@@ -22,7 +22,7 @@ import os\n import sys\n import re\n from keras import activations\n-from keras.utils.io_utils import path_to_string\n+from keras.utils import io_utils\n from tensorflow.python.util.tf_export import keras_export\n \n \n@@ -157,7 +157,7 @@ def model_to_dot(model,\n     if 'IPython.core.magics.namespace' in sys.modules:\n       # We don't raise an exception here in order to avoid crashing notebook\n       # tests where graphviz is not available.\n-      print(message)\n+      io_utils.print_msg(message)\n       return\n     else:\n       raise ImportError(message)\n@@ -422,7 +422,7 @@ def plot_model(model,\n       dpi=dpi,\n       layer_range=layer_range,\n       show_layer_activations=show_layer_activations)\n-  to_file = path_to_string(to_file)\n+  to_file = io_utils.path_to_string(to_file)\n   if dot is None:\n     return\n   _, extension = os.path.splitext(to_file)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
