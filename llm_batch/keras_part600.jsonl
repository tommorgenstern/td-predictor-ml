{"custom_id": "keras#e15cc826945bbc8f5a6330e19d7d647b33bde0f5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 7 | Files Changed: 3 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 2436 | Contributors (this commit): 9 | Commits (past 90d): 48 | Contributors (cumulative): 14 | DMM Complexity: 0.0\n\nDIFF:\n@@ -31,12 +31,11 @@ epochs = 15\n model = keras_core.Sequential(\n     [\n         layers.Input(shape=input_shape, batch_size=batch_size),\n-        # layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n-        # layers.MaxPooling2D(pool_size=(2, 2)),\n-        # layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n-        # layers.MaxPooling2D(pool_size=(2, 2)),\n+        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n+        layers.MaxPooling2D(pool_size=(2, 2)),\n+        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n+        layers.MaxPooling2D(pool_size=(2, 2)),\n         layers.Flatten(),\n-        layers.Dense(32, activation=\"relu\"),\n         layers.Dropout(0.5),\n         layers.Dense(num_classes, activation=\"softmax\"),\n     ]\n\n@@ -5,6 +5,7 @@ from jax import lax\n from jax import nn as jnn\n \n from keras_core.backend.config import epsilon\n+from keras_core.backend.jax.core import convert_to_tensor\n \n \n def relu(x):\n@@ -247,8 +248,8 @@ def conv(\n         )\n     feature_group_count = channels // kernel_in_channels\n     return jax.lax.conv_general_dilated(\n-        inputs,\n-        kernel,\n+        convert_to_tensor(inputs),\n+        convert_to_tensor(kernel),\n         strides,\n         padding,\n         rhs_dilation=dilation_rate,\n\n@@ -92,6 +92,7 @@ class TensorFlowTrainer(base_trainer.Trainer):\n         if self.train_function is not None and not force:\n             return self.train_function\n \n+        @tf.autograph.experimental.do_not_convert\n         def one_step_on_data(data):\n             \"\"\"Runs a single training step on a batch of data.\"\"\"\n             return self.train_step(data)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e1e9ec5b91eac8dc59426ad8524eac71546af3d0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 249 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 5 | Complexity Δ (Sum/Max): 25/18 | Churn Δ: 249 | Churn Cumulative: 694 | Contributors (this commit): 9 | Commits (past 90d): 30 | Contributors (cumulative): 11 | DMM Complexity: 0.5833333333333334\n\nDIFF:\n@@ -41,6 +41,14 @@ class TestCase(unittest.TestCase):\n     def assertAlmostEqual(self, x1, x2, decimal=3, msg=None):\n         np.testing.assert_almost_equal(x1, x2, decimal=decimal)\n \n+    def assertAllEqual(self, x1, x2, msg=None):\n+        self.assertEqual(len(x1), len(x2), msg=msg)\n+        for e1, e2 in zip(x1, x2):\n+            if isinstance(e1, (list, tuple)) or isinstance(e2, (list, tuple)):\n+                self.assertAllEqual(e1, e2, msg=msg)\n+            else:\n+                self.assertEqual(e1, e2, msg=msg)\n+\n     def assertLen(self, iterable, expected_len, msg=None):\n         self.assertEqual(len(iterable), expected_len, msg=msg)\n \n\n@@ -0,0 +1,139 @@\n+import numpy as np\n+\n+from keras_core.api_export import keras_core_export\n+\n+\n+@keras_core_export(\n+    [\n+        \"keras_core.utils.pad_sequences\",\n+        \"keras_core.preprocessing.sequence.pad_sequences\",\n+    ]\n+)\n+def pad_sequences(\n+    sequences,\n+    maxlen=None,\n+    dtype=\"int32\",\n+    padding=\"pre\",\n+    truncating=\"pre\",\n+    value=0.0,\n+):\n+    \"\"\"Pads sequences to the same length.\n+\n+    This function transforms a list (of length `num_samples`)\n+    of sequences (lists of integers)\n+    into a 2D NumPy array of shape `(num_samples, num_timesteps)`.\n+    `num_timesteps` is either the `maxlen` argument if provided,\n+    or the length of the longest sequence in the list.\n+\n+    Sequences that are shorter than `num_timesteps`\n+    are padded with `value` until they are `num_timesteps` long.\n+\n+    Sequences longer than `num_timesteps` are truncated\n+    so that they fit the desired length.\n+\n+    The position where padding or truncation happens is determined by\n+    the arguments `padding` and `truncating`, respectively.\n+    Pre-padding or removing values from the beginning of the sequence is the\n+    default.\n+\n+    >>> sequence = [[1], [2, 3], [4, 5, 6]]\n+    >>> keras_core.utils.pad_sequences(sequence)\n+    array([[0, 0, 1],\n+           [0, 2, 3],\n+           [4, 5, 6]], dtype=int32)\n+\n+    >>> keras_core.utils.pad_sequences(sequence, value=-1)\n+    array([[-1, -1,  1],\n+           [-1,  2,  3],\n+           [ 4,  5,  6]], dtype=int32)\n+\n+    >>> keras_core.utils.pad_sequences(sequence, padding='post')\n+    array([[1, 0, 0],\n+           [2, 3, 0],\n+           [4, 5, 6]], dtype=int32)\n+\n+    >>> keras_core.utils.pad_sequences(sequence, maxlen=2)\n+    array([[0, 1],\n+           [2, 3],\n+           [5, 6]], dtype=int32)\n+\n+    Args:\n+        sequences: List of sequences (each sequence is a list of integers).\n+        maxlen: Optional Int, maximum length of all sequences. If not provided,\n+            sequences will be padded to the length of the longest individual\n+            sequence.\n+        dtype: (Optional, defaults to `\"int32\"`). Type of the output sequences.\n+            To pad sequences with variable length strings, you can use `object`.\n+        padding: String, \"pre\" or \"post\" (optional, defaults to `\"pre\"`):\n+            pad either before or after each sequence.\n+        truncating: String, \"pre\" or \"post\" (optional, defaults to `\"pre\"`):\n+            remove values from sequences larger than\n+            `maxlen`, either at the beginning or at the end of the sequences.\n+        value: Float or String, padding value. (Optional, defaults to 0.)\n+\n+    Returns:\n+        NumPy array with shape `(len(sequences), maxlen)`\n+    \"\"\"\n+    if not hasattr(sequences, \"__len__\"):\n+        raise ValueError(\"`sequences` must be iterable.\")\n+    num_samples = len(sequences)\n+\n+    lengths = []\n+    sample_shape = ()\n+    flag = True\n+\n+    # take the sample shape from the first non empty sequence\n+    # checking for consistency in the main loop below.\n+\n+    for x in sequences:\n+        try:\n+            lengths.append(len(x))\n+            if flag and len(x):\n+                sample_shape = np.asarray(x).shape[1:]\n+                flag = False\n+        except TypeError as e:\n+            raise ValueError(\n+                \"`sequences` must be a list of iterables. \"\n+                f\"Found non-iterable: {str(x)}\"\n+            ) from e\n+\n+    if maxlen is None:\n+        maxlen = np.max(lengths)\n+\n+    is_dtype_str = np.issubdtype(dtype, np.str_) or np.issubdtype(\n+        dtype, np.unicode_\n+    )\n+    if isinstance(value, str) and dtype != object and not is_dtype_str:\n+        raise ValueError(\n+            f\"`dtype` {dtype} is not compatible with `value`'s type: \"\n+            f\"{type(value)}\\nYou should set `dtype=object` for variable length \"\n+            \"strings.\"\n+        )\n+\n+    x = np.full((num_samples, maxlen) + sample_shape, value, dtype=dtype)\n+    for idx, s in enumerate(sequences):\n+        if not len(s):\n+            continue  # empty list/array was found\n+        if truncating == \"pre\":\n+            trunc = s[-maxlen:]\n+        elif truncating == \"post\":\n+            trunc = s[:maxlen]\n+        else:\n+            raise ValueError(f'Truncating type \"{truncating}\" not understood')\n+\n+        # check `trunc` has expected shape\n+        trunc = np.asarray(trunc, dtype=dtype)\n+        if trunc.shape[1:] != sample_shape:\n+            raise ValueError(\n+                f\"Shape of sample {trunc.shape[1:]} of sequence at \"\n+                f\"position {idx} is different from expected shape \"\n+                f\"{sample_shape}\"\n+            )\n+\n+        if padding == \"post\":\n+            x[idx, : len(trunc)] = trunc\n+        elif padding == \"pre\":\n+            x[idx, -len(trunc) :] = trunc\n+        else:\n+            raise ValueError(f'Padding type \"{padding}\" not understood')\n+    return x\n\n@@ -0,0 +1,102 @@\n+from keras_core import testing\n+from keras_core.utils import sequence_utils\n+\n+\n+class PadSequencesTest(testing.TestCase):\n+    def test_pad_sequences(self):\n+        a = [[1], [1, 2], [1, 2, 3]]\n+\n+        # test padding\n+        b = sequence_utils.pad_sequences(a, maxlen=3, padding=\"pre\")\n+        self.assertAllClose(b, [[0, 0, 1], [0, 1, 2], [1, 2, 3]])\n+        b = sequence_utils.pad_sequences(a, maxlen=3, padding=\"post\")\n+        self.assertAllClose(b, [[1, 0, 0], [1, 2, 0], [1, 2, 3]])\n+\n+        # test truncating\n+        b = sequence_utils.pad_sequences(a, maxlen=2, truncating=\"pre\")\n+        self.assertAllClose(b, [[0, 1], [1, 2], [2, 3]])\n+        b = sequence_utils.pad_sequences(a, maxlen=2, truncating=\"post\")\n+        self.assertAllClose(b, [[0, 1], [1, 2], [1, 2]])\n+\n+        # test value\n+        b = sequence_utils.pad_sequences(a, maxlen=3, value=1)\n+        self.assertAllClose(b, [[1, 1, 1], [1, 1, 2], [1, 2, 3]])\n+\n+    def test_pad_sequences_str(self):\n+        a = [[\"1\"], [\"1\", \"2\"], [\"1\", \"2\", \"3\"]]\n+\n+        # test padding\n+        b = sequence_utils.pad_sequences(\n+            a, maxlen=3, padding=\"pre\", value=\"pad\", dtype=object\n+        )\n+        self.assertAllEqual(\n+            b, [[\"pad\", \"pad\", \"1\"], [\"pad\", \"1\", \"2\"], [\"1\", \"2\", \"3\"]]\n+        )\n+        b = sequence_utils.pad_sequences(\n+            a, maxlen=3, padding=\"post\", value=\"pad\", dtype=\"<U3\"\n+        )\n+        self.assertAllEqual(\n+            b, [[\"1\", \"pad\", \"pad\"], [\"1\", \"2\", \"pad\"], [\"1\", \"2\", \"3\"]]\n+        )\n+\n+        # test truncating\n+        b = sequence_utils.pad_sequences(\n+            a, maxlen=2, truncating=\"pre\", value=\"pad\", dtype=object\n+        )\n+        self.assertAllEqual(b, [[\"pad\", \"1\"], [\"1\", \"2\"], [\"2\", \"3\"]])\n+        b = sequence_utils.pad_sequences(\n+            a, maxlen=2, truncating=\"post\", value=\"pad\", dtype=\"<U3\"\n+        )\n+        self.assertAllEqual(b, [[\"pad\", \"1\"], [\"1\", \"2\"], [\"1\", \"2\"]])\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \"`dtype` int32 is not compatible with \"\n+        ):\n+            sequence_utils.pad_sequences(\n+                a, maxlen=2, truncating=\"post\", value=\"pad\"\n+            )\n+\n+    def test_pad_sequences_vector(self):\n+        a = [[[1, 1]], [[2, 1], [2, 2]], [[3, 1], [3, 2], [3, 3]]]\n+\n+        # test padding\n+        b = sequence_utils.pad_sequences(a, maxlen=3, padding=\"pre\")\n+        self.assertAllClose(\n+            b,\n+            [\n+                [[0, 0], [0, 0], [1, 1]],\n+                [[0, 0], [2, 1], [2, 2]],\n+                [[3, 1], [3, 2], [3, 3]],\n+            ],\n+        )\n+        b = sequence_utils.pad_sequences(a, maxlen=3, padding=\"post\")\n+        self.assertAllClose(\n+            b,\n+            [\n+                [[1, 1], [0, 0], [0, 0]],\n+                [[2, 1], [2, 2], [0, 0]],\n+                [[3, 1], [3, 2], [3, 3]],\n+            ],\n+        )\n+\n+        # test truncating\n+        b = sequence_utils.pad_sequences(a, maxlen=2, truncating=\"pre\")\n+        self.assertAllClose(\n+            b, [[[0, 0], [1, 1]], [[2, 1], [2, 2]], [[3, 2], [3, 3]]]\n+        )\n+\n+        b = sequence_utils.pad_sequences(a, maxlen=2, truncating=\"post\")\n+        self.assertAllClose(\n+            b, [[[0, 0], [1, 1]], [[2, 1], [2, 2]], [[3, 1], [3, 2]]]\n+        )\n+\n+        # test value\n+        b = sequence_utils.pad_sequences(a, maxlen=3, value=1)\n+        self.assertAllClose(\n+            b,\n+            [\n+                [[1, 1], [1, 1], [1, 1]],\n+                [[1, 1], [2, 1], [2, 2]],\n+                [[3, 1], [3, 2], [3, 3]],\n+            ],\n+        )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#eed2e7af65b8fbb0575c3080ce57569531bc9838", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 7 | Files Changed: 3 | Hunks: 6 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 20 | Churn Cumulative: 2587 | Contributors (this commit): 11 | Commits (past 90d): 91 | Contributors (cumulative): 18 | DMM Complexity: 0.0\n\nDIFF:\n@@ -472,7 +472,8 @@ class Layer(Operation):\n \n         Args:\n             trainable_variables: List of trainable variables of the model.\n-            non_trainable_variables: List of non-trainable variables of the model.\n+            non_trainable_variables: List of non-trainable variables of the\n+                model.\n             *args: Positional argumets to be passed to `call()`.\n             return_losses: If `True`, `stateless_call()` will return the list of\n                 losses created during `call()` as part of its return values.\n@@ -504,7 +505,9 @@ class Layer(Operation):\n         )\n         # Attach the updated state to the model\n         # (until you do this, the model is still in its pre-call state).\n-        for ref_var, value in zip(model.non_trainable_variables, non_trainable_variables):\n+        for ref_var, value in zip(\n+            model.non_trainable_variables, non_trainable_variables\n+        ):\n             ref_var.assign(value)\n         ```\n         \"\"\"\n@@ -597,7 +600,8 @@ class Layer(Operation):\n                 and isinstance(output_shape[0], (int, type(None)))\n             ):\n                 return KerasTensor(output_shape, dtype=self.compute_dtype)\n-            # Case: nested. Could be a tuple/list of shapes, or a dict of shapes.\n+            # Case: nested. Could be a tuple/list of shapes, or a dict of\n+            # shapes.\n             if isinstance(output_shape, list):\n                 return [\n                     KerasTensor(s, dtype=self.compute_dtype)\n@@ -770,7 +774,8 @@ class Layer(Operation):\n                                 \"In a layer with multiple tensor arguments \"\n                                 \"in call(), the build() method should accept \"\n                                 \"corresponding `*_shape` arguments, e.g. \"\n-                                \"if the call signature is `def call(self, x1, x2)` \"\n+                                \"if the call signature is \"\n+                                \"`def call(self, x1, x2)` \"\n                                 \"then the build signature should be \"\n                                 \"`def build(self, x1_shape, x2_shape)`. \"\n                                 \"Keras will not build this layer automatically \"\n\n@@ -115,8 +115,8 @@ class EpochIterator:\n                 )\n             if class_weight is not None:\n                 raise ValueError(\n-                    \"Argument `class_weight` is not supported for Python generator \"\n-                    f\"inputs. Received: class_weight={class_weight}\"\n+                    \"Argument `class_weight` is not supported for Python \"\n+                    f\"generator inputs. Received: class_weight={class_weight}\"\n                 )\n             if shuffle:\n                 raise ValueError(\n\n@@ -40,7 +40,8 @@ def build():\n \n     whl_path = None\n     try:\n-        # Copy sources (`keras_core/` directory and setup files) to build directory\n+        # Copy sources (`keras_core/` directory and setup files) to build\n+        # directory\n         root_path = pathlib.Path(__file__).parent.resolve()\n         os.chdir(root_path)\n         os.mkdir(build_directory)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c56cafb2187528d49a756d7dab756e27a2a9844b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 21 | Churn Cumulative: 1699 | Contributors (this commit): 23 | Commits (past 90d): 14 | Contributors (cumulative): 25 | DMM Complexity: 1.0\n\nDIFF:\n@@ -27,6 +27,7 @@ build_directory = \"tmp_build_dir\"\n dist_directory = \"dist\"\n to_copy = [\n     \"setup.py\",\n+    \"README.md\"\n ]\n \n \n\n@@ -1,17 +1,35 @@\n \"\"\"Setup script.\"\"\"\n \n+import os\n import pathlib\n \n from setuptools import find_packages\n from setuptools import setup\n \n+\n+def read(rel_path):\n+    here = os.path.abspath(os.path.dirname(__file__))\n+    with open(os.path.join(here, rel_path)) as fp:\n+        return fp.read()\n+\n+\n+def get_version(rel_path):\n+    for line in read(rel_path).splitlines():\n+        if line.startswith(\"__version__\"):\n+            delim = '\"' if '\"' in line else \"'\"\n+            return line.split(delim)[1]\n+    raise RuntimeError(\"Unable to find version string.\")\n+\n+\n HERE = pathlib.Path(__file__).parent\n+README = (HERE / \"README.md\").read_text()\n+VERSION = get_version(\"keras_core/__init__.py\")\n \n setup(\n     name=\"keras-core\",\n     description=\"Multi-backend Keras.\",\n     long_description_content_type=\"text/markdown\",\n-    version=\"0.1.0\",\n+    version=VERSION,\n     url=\"https://github.com/keras-team/keras-core\",\n     author=\"Keras team\",\n     author_email=\"keras@google.com\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8cc8ed3cd523b15b2efbacbaca262fe0103c8c1c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 40 | Files Changed: 3 | Hunks: 9 | Methods Changed: 4 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 49 | Churn Cumulative: 1744 | Contributors (this commit): 6 | Commits (past 90d): 18 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,6 +1,7 @@\n from keras_core import operations as ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers.merging.base_merge import Merge\n+from keras_core.utils.numerical_utils import normalize\n \n \n def batch_dot(x, y, axes=None):\n@@ -195,32 +196,6 @@ def batch_dot(x, y, axes=None):\n     return result\n \n \n-def l2_normalize(x, axis=None, epsilon=1e-9):\n-    \"\"\"Normalizes along dimension `axis` using an L2 norm.\n-\n-    For a 1-D tensor with `axis = 0`, computes\n-\n-    `output = x / sqrt(max(sum(x**2), epsilon))`\n-\n-    For `x` with more dimensions, independently normalizes each\n-    1-D slice along dimension `axis`.\n-\n-    Args:\n-        x: Input tensor.\n-        axis: Dimension along which to normalize. A scalar or a\n-            vector of integers.\n-        epsilon: A lower bound value for the norm. Will use `sqrt(epsilon)`\n-            as the divisor if `norm < sqrt(epsilon)`.\n-\n-    Returns:\n-        A normalized tensor with the same shape as input.\n-    \"\"\"\n-\n-    square_sum = ops.sum(ops.square(x), axis=axis, keepdims=True)\n-    x_inv_norm = 1.0 / ops.sqrt(ops.maximum(square_sum, epsilon))\n-    return ops.multiply(x, x_inv_norm)\n-\n-\n @keras_core_export(\"keras_core.layers.Dot\")\n class Dot(Merge):\n     \"\"\"Computes element-wise dot product of two tensors.\n@@ -340,8 +315,8 @@ class Dot(Merge):\n                     axes.append(self.axes[i])\n \n         if self.normalize:\n-            x1 = l2_normalize(x1, axis=axes[0])\n-            x2 = l2_normalize(x2, axis=axes[1])\n+            x1 = normalize(x1, axis=axes[0])\n+            x2 = normalize(x2, axis=axes[1])\n         output = batch_dot(x1, x2, axes)\n         return output\n \n\n@@ -1,8 +1,10 @@\n+from keras_core import backend\n from keras_core import initializers\n from keras_core import operations as ops\n from keras_core.api_export import keras_core_export\n from keras_core.layers import Wrapper\n from keras_core.layers.input_spec import InputSpec\n+from keras_core.utils.numerical_utils import normalize\n \n \n @keras_core_export(\"keras_core.layers.SpectralNormalization\")\n@@ -96,10 +98,10 @@ class SpectralNormalization(Wrapper):\n         # check for zeroes weights\n         if not all([w == 0.0 for w in weights]):\n             for _ in range(self.power_iterations):\n-                vector_v = self._l2_normalize(\n-                    ops.matmul(vector_u, ops.transpose(weights))\n+                vector_v = normalize(\n+                    ops.matmul(vector_u, ops.transpose(weights)), axis=None\n                 )\n-                vector_u = self._l2_normalize(ops.matmul(vector_v, weights))\n+                vector_u = normalize(ops.matmul(vector_v, weights), axis=None)\n             # vector_u = tf.stop_gradient(vector_u)\n             # vector_v = tf.stop_gradient(vector_v)\n             sigma = ops.matmul(\n@@ -113,11 +115,6 @@ class SpectralNormalization(Wrapper):\n                 )\n             )\n \n-    def _l2_normalize(self, x):\n-        square_sum = ops.sum(ops.square(x), keepdims=True)\n-        x_inv_norm = 1 / ops.sqrt(ops.maximum(square_sum, 1e-12))\n-        return ops.multiply(x, x_inv_norm)\n-\n     def get_config(self):\n         config = {\"power_iterations\": self.power_iterations}\n         base_config = super().get_config()\n\n@@ -25,10 +25,7 @@ import namex\n package = \"keras_core\"\n build_directory = \"tmp_build_dir\"\n dist_directory = \"dist\"\n-to_copy = [\n-    \"setup.py\",\n-    \"README.md\"\n-]\n+to_copy = [\"setup.py\", \"README.md\"]\n \n \n def ignore_files(_, filenames):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9a4a063158836dd0df8faec959f5c311c80ebe7f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 113 | Lines Deleted: 16 | Files Changed: 3 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 7/13 | Churn Δ: 129 | Churn Cumulative: 1959 | Contributors (this commit): 8 | Commits (past 90d): 94 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -34,6 +34,7 @@ from keras_core.metrics.metric import Metric\n from keras_core.operations.operation import Operation\n from keras_core.utils import summary_utils\n from keras_core.utils import traceback_utils\n+from keras_core.utils.shape_utils import map_shape_structure\n from keras_core.utils.tracking import Tracker\n \n \n@@ -601,22 +602,10 @@ class Layer(Operation):\n             ):\n                 return KerasTensor(output_shape, dtype=self.compute_dtype)\n             # Case: nested. Could be a tuple/list of shapes, or a dict of\n-            # shapes.\n-            if isinstance(output_shape, list):\n-                return [\n-                    KerasTensor(s, dtype=self.compute_dtype)\n-                    for s in output_shape\n-                ]\n-            if isinstance(output_shape, tuple):\n-                return tuple(\n-                    KerasTensor(s, dtype=self.compute_dtype)\n-                    for s in output_shape\n+            # shapes. Could be deeply nested.\n+            return map_shape_structure(\n+                lambda s: KerasTensor(s, dtype=self.compute_dtype), output_shape\n             )\n-            if isinstance(output_shape, dict):\n-                return {\n-                    name: KerasTensor(s, dtype=self.compute_dtype)\n-                    for name, s in output_shape.items()\n-                }\n \n     @utils.default\n     def compute_output_shape(self, *args, **kwargs):\n\n@@ -8,6 +8,115 @@ from keras_core import testing\n \n \n class LayerTest(testing.TestCase):\n+    def test_compute_output_spec(self):\n+        # Test that implementing compute_output_shape\n+        # is enough to make compute_output_spec work.\n+\n+        # Case: single output\n+        class TestLayer(layers.Layer):\n+            def call(self, x):\n+                assert False  # Should never be called.\n+\n+            def compute_output_shape(self, input_shape):\n+                return input_shape\n+\n+        layer = TestLayer()\n+        self.assertEqual(\n+            layer.compute_output_spec(backend.KerasTensor((2, 3))).shape, (2, 3)\n+        )\n+\n+        # Case: tuple output\n+        class TestLayer(layers.Layer):\n+            def call(self, x):\n+                assert False  # Should never be called.\n+\n+            def compute_output_shape(self, input_shape):\n+                return (input_shape, input_shape)\n+\n+        layer = TestLayer()\n+        out = layer.compute_output_spec(backend.KerasTensor((2, 3)))\n+        self.assertTrue(isinstance(out, tuple))\n+        self.assertEqual(len(out), 2)\n+        self.assertEqual(out[0].shape, (2, 3))\n+        self.assertEqual(out[1].shape, (2, 3))\n+\n+        # Case: list output\n+        class TestLayer(layers.Layer):\n+            def call(self, x):\n+                assert False  # Should never be called.\n+\n+            def compute_output_shape(self, input_shape):\n+                return [input_shape, input_shape]\n+\n+        layer = TestLayer()\n+        out = layer.compute_output_spec(backend.KerasTensor((2, 3)))\n+        self.assertTrue(isinstance(out, list))\n+        self.assertEqual(len(out), 2)\n+        self.assertEqual(out[0].shape, (2, 3))\n+        self.assertEqual(out[1].shape, (2, 3))\n+\n+        # Case: dict output\n+        class TestLayer(layers.Layer):\n+            def call(self, x):\n+                assert False  # Should never be called.\n+\n+            def compute_output_shape(self, input_shape):\n+                return {\"1\": input_shape, \"2\": input_shape}\n+\n+        layer = TestLayer()\n+        out = layer.compute_output_spec(backend.KerasTensor((2, 3)))\n+        self.assertTrue(isinstance(out, dict))\n+        self.assertEqual(len(out), 2)\n+        self.assertEqual(out[\"1\"].shape, (2, 3))\n+        self.assertEqual(out[\"2\"].shape, (2, 3))\n+\n+        # Case: nested tuple output\n+        class TestLayer(layers.Layer):\n+            def call(self, x):\n+                assert False  # Should never be called.\n+\n+            def compute_output_shape(self, input_shape):\n+                return (\n+                    input_shape,\n+                    (input_shape, input_shape),\n+                    (input_shape, input_shape),\n+                )\n+\n+        layer = TestLayer()\n+        out = layer.compute_output_spec(backend.KerasTensor((2, 3)))\n+        self.assertTrue(isinstance(out, tuple))\n+        self.assertEqual(len(out), 3)\n+        self.assertEqual(out[0].shape, (2, 3))\n+        self.assertTrue(isinstance(out[1], tuple))\n+        self.assertEqual(len(out[1]), 2)\n+        self.assertEqual(out[1][0].shape, (2, 3))\n+        self.assertEqual(out[1][1].shape, (2, 3))\n+        self.assertTrue(isinstance(out[2], tuple))\n+        self.assertEqual(len(out[2]), 2)\n+        self.assertEqual(out[2][0].shape, (2, 3))\n+        self.assertEqual(out[2][1].shape, (2, 3))\n+\n+        # Case: nested dict output\n+        class TestLayer(layers.Layer):\n+            def call(self, x):\n+                assert False  # Should never be called.\n+\n+            def compute_output_shape(self, input_shape):\n+                return {\n+                    \"1\": input_shape,\n+                    \"2\": {\"11\": input_shape, \"22\": input_shape},\n+                }\n+\n+        layer = TestLayer()\n+        out = layer.compute_output_spec(backend.KerasTensor((2, 3)))\n+        self.assertTrue(isinstance(out, dict))\n+        self.assertEqual(len(out), 2)\n+        self.assertEqual(out[\"1\"].shape, (2, 3))\n+        self.assertTrue(isinstance(out[\"2\"], dict))\n+        self.assertEqual(len(out[\"2\"]), 2)\n+        self.assertEqual(out[\"2\"][\"11\"].shape, (2, 3))\n+        self.assertEqual(out[\"2\"][\"22\"].shape, (2, 3))\n+\n     def test_positional_arg_error(self):\n         class SomeLayer(layers.Layer):\n             def call(self, x, bool_arg):\n\n@@ -1,4 +1,3 @@\n-from keras_core import backend\n from keras_core import initializers\n from keras_core import operations as ops\n from keras_core.api_export import keras_core_export\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0ed50561d7af7efe9e043a27c7d89f904d228426", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 36 | Files Changed: 10 | Hunks: 28 | Methods Changed: 20 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 72 | Churn Cumulative: 2636 | Contributors (this commit): 4 | Commits (past 90d): 85 | Contributors (cumulative): 40 | DMM Complexity: None\n\nDIFF:\n@@ -98,7 +98,7 @@ class Conv1D(BaseConv):\n         kernel_size,\n         strides=1,\n         padding=\"valid\",\n-        data_format=\"channels_last\",\n+        data_format=None,\n         dilation_rate=1,\n         groups=1,\n         activation=None,\n\n@@ -97,7 +97,7 @@ class Conv1DTranspose(BaseConvTranspose):\n         kernel_size,\n         strides=1,\n         padding=\"valid\",\n-        data_format=\"channels_last\",\n+        data_format=None,\n         dilation_rate=1,\n         activation=None,\n         use_bias=True,\n\n@@ -90,10 +90,10 @@ class Conv2D(BaseConv):\n         self,\n         filters,\n         kernel_size,\n-        strides=1,\n+        strides=(1, 1),\n         padding=\"valid\",\n-        data_format=\"channels_last\",\n-        dilation_rate=1,\n+        data_format=None,\n+        dilation_rate=(1, 1),\n         groups=1,\n         activation=None,\n         use_bias=True,\n\n@@ -97,10 +97,10 @@ class Conv2DTranspose(BaseConvTranspose):\n         self,\n         filters,\n         kernel_size,\n-        strides=1,\n+        strides=(1, 1),\n         padding=\"valid\",\n-        data_format=\"channels_last\",\n-        dilation_rate=1,\n+        data_format=None,\n+        dilation_rate=(1, 1),\n         activation=None,\n         use_bias=True,\n         kernel_initializer=\"glorot_uniform\",\n\n@@ -96,10 +96,10 @@ class Conv3D(BaseConv):\n         self,\n         filters,\n         kernel_size,\n-        strides=1,\n+        strides=(1, 1, 1),\n         padding=\"valid\",\n-        data_format=\"channels_last\",\n-        dilation_rate=1,\n+        data_format=None,\n+        dilation_rate=(1, 1, 1),\n         groups=1,\n         activation=None,\n         use_bias=True,\n\n@@ -102,10 +102,10 @@ class Conv3DTranspose(BaseConvTranspose):\n         self,\n         filters,\n         kernel_size,\n-        strides=1,\n+        strides=(1, 1, 1),\n         padding=\"valid\",\n-        data_format=\"channels_last\",\n-        dilation_rate=1,\n+        data_format=None,\n+        dilation_rate=(1, 1, 1),\n         activation=None,\n         use_bias=True,\n         kernel_initializer=\"glorot_uniform\",\n\n@@ -28,9 +28,6 @@ class DepthwiseConv1D(BaseDepthwiseConv):\n     are generated per input channel in the depthwise step.\n \n     Args:\n-        depth_multiplier: The number of depthwise convolution output channels\n-            for each input channel. The total number of depthwise convolution\n-            output channels will be equal to `input_channel * depth_multiplier`.\n         kernel_size: int or tuple/list of 1 integer, specifying the size of the\n             depthwise convolution window.\n         strides: int or tuple/list of 1 integer, specifying the stride length\n@@ -40,6 +37,9 @@ class DepthwiseConv1D(BaseDepthwiseConv):\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n             height/width dimension as the input.\n+        depth_multiplier: The number of depthwise convolution output channels\n+            for each input channel. The total number of depthwise convolution\n+            output channels will be equal to `input_channel * depth_multiplier`.\n         data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs. `\"channels_last\"`\n             corresponds to inputs with shape `(batch, steps, features)`\n@@ -98,11 +98,11 @@ class DepthwiseConv1D(BaseDepthwiseConv):\n \n     def __init__(\n         self,\n-        depth_multiplier,\n         kernel_size,\n         strides=1,\n         padding=\"valid\",\n-        data_format=\"channels_last\",\n+        depth_multiplier=1,\n+        data_format=None,\n         dilation_rate=1,\n         activation=None,\n         use_bias=True,\n\n@@ -28,9 +28,6 @@ class DepthwiseConv2D(BaseDepthwiseConv):\n     are generated per input channel in the depthwise step.\n \n     Args:\n-        depth_multiplier: The number of depthwise convolution output channels\n-            for each input channel. The total number of depthwise convolution\n-            output channels will be equal to `input_channel * depth_multiplier`.\n         kernel_size: int or tuple/list of 2 integer, specifying the size of the\n             depthwise convolution window.\n         strides: int or tuple/list of 2 integer, specifying the stride length\n@@ -40,6 +37,9 @@ class DepthwiseConv2D(BaseDepthwiseConv):\n             `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n             the left/right or up/down of the input such that output has the same\n             height/width dimension as the input.\n+        depth_multiplier: The number of depthwise convolution output channels\n+            for each input channel. The total number of depthwise convolution\n+            output channels will be equal to `input_channel * depth_multiplier`.\n         data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs. `\"channels_last\"`\n             corresponds to inputs with shape `(batch, steps, features)`\n@@ -98,12 +98,12 @@ class DepthwiseConv2D(BaseDepthwiseConv):\n \n     def __init__(\n         self,\n-        depth_multiplier,\n         kernel_size,\n-        strides=1,\n+        strides=(1, 1),\n         padding=\"valid\",\n-        data_format=\"channels_last\",\n-        dilation_rate=1,\n+        depth_multiplier=1,\n+        data_format=None,\n+        dilation_rate=(1, 1),\n         activation=None,\n         use_bias=True,\n         kernel_initializer=\"glorot_uniform\",\n\n@@ -20,9 +20,6 @@ class SeparableConv1D(BaseSeparableConv):\n     activation function to produce the final output.\n \n     Args:\n-        depth_multiplier: The number of depthwise convolution output channels\n-            for each input channel. The total number of depthwise convolution\n-            output channels will be equal to `input_channel * depth_multiplier`.\n         filters: int, the dimensionality of the output space (i.e. the number\n             of filters in the pointwise convolution).\n         kernel_size: int or tuple/list of 1 integers, specifying the size of the\n@@ -45,6 +42,9 @@ class SeparableConv1D(BaseSeparableConv):\n         dilation_rate: int or tuple/list of 1 integers, specifying the dilation\n             rate to use for dilated convolution. If only one int is specified,\n             the same dilation rate will be used for all dimensions.\n+         depth_multiplier: The number of depthwise convolution output channels\n+            for each input channel. The total number of depthwise convolution\n+            output channels will be equal to `input_channel * depth_multiplier`.\n         activation: Activation function. If `None`, no activation is applied.\n         use_bias: bool, if `True`, bias will be added to the output.\n         depthwise_initializer: An initializer for the depthwise convolution\n@@ -97,13 +97,13 @@ class SeparableConv1D(BaseSeparableConv):\n \n     def __init__(\n         self,\n-        depth_multiplier,\n         filters,\n         kernel_size,\n         strides=1,\n         padding=\"valid\",\n         data_format=None,\n         dilation_rate=1,\n+        depth_multiplier=1,\n         activation=None,\n         use_bias=True,\n         depthwise_initializer=\"glorot_uniform\",\n\n@@ -20,9 +20,6 @@ class SeparableConv2D(BaseSeparableConv):\n     activation function to produce the final output.\n \n     Args:\n-        depth_multiplier: The number of depthwise convolution output channels\n-            for each input channel. The total number of depthwise convolution\n-            output channels will be equal to `input_channel * depth_multiplier`.\n         filters: int, the dimensionality of the output space (i.e. the number\n             of filters in the pointwise convolution).\n         kernel_size: int or tuple/list of 2 integers, specifying the size of the\n@@ -45,6 +42,9 @@ class SeparableConv2D(BaseSeparableConv):\n         dilation_rate: int or tuple/list of 2 integers, specifying the dilation\n             rate to use for dilated convolution. If only one int is specified,\n             the same dilation rate will be used for all dimensions.\n+        depth_multiplier: The number of depthwise convolution output channels\n+            for each input channel. The total number of depthwise convolution\n+            output channels will be equal to `input_channel * depth_multiplier`.\n         activation: Activation function. If `None`, no activation is applied.\n         use_bias: bool, if `True`, bias will be added to the output.\n         depthwise_initializer: An initializer for the depthwise convolution\n@@ -97,13 +97,13 @@ class SeparableConv2D(BaseSeparableConv):\n \n     def __init__(\n         self,\n-        depth_multiplier,\n         filters,\n         kernel_size,\n-        strides=1,\n+        strides=(1, 1),\n         padding=\"valid\",\n         data_format=None,\n-        dilation_rate=1,\n+        dilation_rate=(1, 1),\n+        depth_multiplier=1,\n         activation=None,\n         use_bias=True,\n         depthwise_initializer=\"glorot_uniform\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bf2ab2d6d0436d1e4b84652e119189bb5ff33abe", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 350 | Lines Deleted: 5 | Files Changed: 8 | Hunks: 11 | Methods Changed: 20 | Complexity Δ (Sum/Max): 52/35 | Churn Δ: 355 | Churn Cumulative: 2734 | Contributors (this commit): 14 | Commits (past 90d): 163 | Contributors (cumulative): 31 | DMM Complexity: 0.75\n\nDIFF:\n@@ -117,10 +117,10 @@ def compute_output_spec(fn, *args, **kwargs):\n                     return KerasTensor(x.shape, x.dtype)\n                 return x\n \n-            output_shape = tf.nest.map_structure(\n+            output_spec = tf.nest.map_structure(\n                 convert_tf_to_keras_tensor, tf_out\n             )\n-    return output_shape\n+    return output_spec\n \n \n def cond(pred, true_fn, false_fn):\n\n@@ -17,6 +17,7 @@ from keras_core.layers.core.embedding import Embedding\n from keras_core.layers.core.identity import Identity\n from keras_core.layers.core.input_layer import Input\n from keras_core.layers.core.input_layer import InputLayer\n+from keras_core.layers.core.lambda_layer import Lambda\n from keras_core.layers.core.masking import Masking\n from keras_core.layers.core.wrapper import Wrapper\n from keras_core.layers.layer import Layer\n\n@@ -0,0 +1,229 @@\n+import inspect\n+import types\n+\n+from tensorflow import nest\n+\n+from keras_core import backend\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.layer import Layer\n+from keras_core.saving import serialization_lib\n+from keras_core.utils import python_utils\n+from keras_core.utils import shape_utils\n+\n+\n+@keras_core_export(\"keras_core.layers.Lambda\")\n+class Lambda(Layer):\n+    \"\"\"Wraps arbitrary expressions as a `Layer` object.\n+\n+    The `Lambda` layer exists so that arbitrary expressions can be used\n+    as a `Layer` when constructing Sequential\n+    and Functional API models. `Lambda` layers are best suited for simple\n+    operations or quick experimentation. For more advanced use cases,\n+    prefer writing new subclasses of `Layer`.\n+\n+    WARNING: `Lambda` layers have (de)serialization limitations!\n+\n+    The main reason to subclass `Layer` instead of using a\n+    `Lambda` layer is saving and inspecting a model. `Lambda` layers\n+    are saved by serializing the Python bytecode, which is fundamentally\n+    non-portable and potentially unsafe.\n+    They should only be loaded in the same environment where\n+    they were saved. Subclassed layers can be saved in a more portable way\n+    by overriding their `get_config()` method. Models that rely on\n+    subclassed Layers are also often easier to visualize and reason about.\n+\n+    Example:\n+\n+    ```python\n+    # add a x -> x^2 layer\n+    model.add(Lambda(lambda x: x ** 2))\n+    ```\n+\n+    Args:\n+        function: The function to be evaluated. Takes input tensor as first\n+            argument.\n+        output_shape: Expected output shape from function. This argument\n+            can usually be inferred if not explicitly provided.\n+            Can be a tuple or function. If a tuple, it only specifies\n+            the first dimension onward; sample dimension is assumed\n+            either the same as the input:\n+            `output_shape = (input_shape[0], ) + output_shape` or,\n+            the input is `None` and the sample dimension is also `None`:\n+            `output_shape = (None, ) + output_shape`.\n+            If a function, it specifies the\n+            entire shape as a function of the input shape:\n+            `output_shape = f(input_shape)`.\n+        mask: Either None (indicating no masking) or a callable with the same\n+            signature as the `compute_mask` layer method, or a tensor\n+            that will be returned as output mask regardless\n+            of what the input is.\n+        arguments: Optional dictionary of keyword arguments to be passed to the\n+            function.\n+    \"\"\"\n+\n+    def __init__(\n+        self, function, output_shape=None, mask=None, arguments=None, **kwargs\n+    ):\n+        super().__init__(**kwargs)\n+\n+        self.arguments = arguments or {}\n+        self.function = function\n+\n+        if mask is not None:\n+            self.supports_masking = True\n+        else:\n+            self.supports_masking = False\n+        self.mask = mask\n+        self._output_shape = output_shape\n+\n+        # Warning on every invocation will be quite irksome in Eager mode.\n+        self._already_warned = False\n+\n+        function_args = inspect.getfullargspec(function).args\n+        self._fn_expects_training_arg = \"training\" in function_args\n+        self._fn_expects_mask_arg = \"mask\" in function_args\n+\n+    def compute_output_shape(self, input_shape):\n+        if self._output_shape is None:\n+            # Leverage backend shape inference\n+            try:\n+                inputs = shape_utils.map_shape_structure(\n+                    lambda x: backend.KerasTensor(x, dtype=self.compute_dtype),\n+                    input_shape,\n+                )\n+                output_spec = backend.compute_output_spec(self.call, inputs)\n+                return nest.map_structure(lambda x: x.shape, output_spec)\n+            except:\n+                raise NotImplementedError(\n+                    \"We could not automatically infer the shape of \"\n+                    \"the Lambda's output. Please specify the `output_shape` \"\n+                    \"argument for this Lambda layer.\"\n+                )\n+\n+        if callable(self._output_shape):\n+            return self._output_shape(input_shape)\n+\n+        # Output shapes are passed directly and don't include batch dimension.\n+        batch_size = nest.flatten(input_shape)[0]\n+\n+        def _add_batch(shape):\n+            return (batch_size,) + shape\n+\n+        return shape_utils.map_shape_structure(_add_batch, self._output_shape)\n+\n+    def call(self, inputs, mask=None, training=None):\n+        # We must copy for thread safety,\n+        # but it only needs to be a shallow copy.\n+        kwargs = {k: v for k, v in self.arguments.items()}\n+        if self._fn_expects_mask_arg:\n+            kwargs[\"mask\"] = mask\n+        if self._fn_expects_training_arg:\n+            kwargs[\"training\"] = training\n+        return self.function(inputs, **kwargs)\n+\n+    def compute_mask(self, inputs, mask=None):\n+        if callable(self.mask):\n+            return self.mask(inputs, mask)\n+        return self.mask\n+\n+    def get_config(self):\n+        config = {\n+            \"function\": self._serialize_function_to_config(self.function),\n+        }\n+        if self._output_shape is not None:\n+            if callable(self._output_shape):\n+                output_shape = self._serialize_function_to_config(\n+                    self._output_shape\n+                )\n+            else:\n+                output_shape = self._output_shape\n+            config[\"output_shape\"] = output_shape\n+        if self.mask is not None:\n+            if callable(self.mask):\n+                mask = self._serialize_function_to_config(self.mask)\n+            else:\n+                mask = serialization_lib.serialize_keras_object(self.mask)\n+            config[\"mask\"] = mask\n+        config[\"arguments\"] = serialization_lib.serialize_keras_object(\n+            self.arguments\n+        )\n+        base_config = super().get_config()\n+        return {**base_config, **config}\n+\n+    def _serialize_function_to_config(self, fn):\n+        if isinstance(fn, types.LambdaType) and fn.__name__ == \"<lambda>\":\n+            code, defaults, closure = python_utils.func_dump(fn)\n+            return {\n+                \"class_name\": \"__lambda__\",\n+                \"config\": {\n+                    \"code\": code,\n+                    \"defaults\": defaults,\n+                    \"closure\": closure,\n+                },\n+            }\n+        elif callable(fn):\n+            return serialization_lib.serialize_keras_object(fn)\n+        raise ValueError(\n+            \"Invalid input type for serialization. \"\n+            f\"Received: {fn} of type {type(fn)}.\"\n+        )\n+\n+    @staticmethod\n+    def _raise_for_lambda_deserialization(arg_name, safe_mode):\n+        if safe_mode:\n+            raise ValueError(\n+                \"The `{arg_name}` of this `Lambda` layer is a Python lambda. \"\n+                \"Deserializing it is unsafe. If you trust the source of the \"\n+                \"config artifact, you can override this error \"\n+                \"by passing `safe_mode=False` \"\n+                \"to `from_config()`, or calling \"\n+                \"`keras_core.config.enable_unsafe_deserialization().\"\n+            )\n+\n+    @classmethod\n+    def from_config(cls, config, custom_objects=None, safe_mode=None):\n+        safe_mode = safe_mode or serialization_lib.in_safe_mode()\n+        fn_config = config[\"function\"]\n+        if (\n+            isinstance(fn_config, dict)\n+            and \"class_name\" in fn_config\n+            and fn_config[\"class_name\"] == \"__lambda__\"\n+        ):\n+            cls._raise_for_lambda_deserialization(\"function\", safe_mode)\n+            inner_config = fn_config[\"config\"]\n+            fn = python_utils.func_load(\n+                inner_config[\"code\"],\n+                defaults=inner_config[\"defaults\"],\n+                closure=inner_config[\"closure\"],\n+            )\n+            config[\"function\"] = fn\n+        else:\n+            config[\"function\"] = serialization_lib.deserialize_keras_object(\n+                fn_config, custom_objects=custom_objects\n+            )\n+        if \"output_shape\" in config:\n+            fn_config = config[\"output_shape\"]\n+            if (\n+                isinstance(fn_config, dict)\n+                and \"class_name\" in fn_config\n+                and fn_config[\"class_name\"] == \"__lambda__\"\n+            ):\n+                cls._raise_for_lambda_deserialization(\"function\", safe_mode)\n+                inner_config = fn_config[\"config\"]\n+                fn = python_utils.func_load(\n+                    inner_config[\"code\"],\n+                    defaults=inner_config[\"defaults\"],\n+                    closure=inner_config[\"closure\"],\n+                )\n+                config[\"output_shape\"] = fn\n+            else:\n+                config[\n+                    \"output_shape\"\n+                ] = serialization_lib.deserialize_keras_object(\n+                    fn_config, custom_objects=custom_objects\n+                )\n+        if \"arguments\" in config:\n+            config[\"arguments\"] = serialization_lib.deserialize_keras_object(\n+                config[\"arguments\"], custom_objects=custom_objects\n+            )\n+        return cls(**config)\n\n@@ -0,0 +1,92 @@\n+import numpy as np\n+\n+from keras_core import layers\n+from keras_core import operations as ops\n+from keras_core import testing\n+\n+\n+class LambdaTest(testing.TestCase):\n+    def test_lambda_basics(self):\n+        self.run_layer_test(\n+            layers.Lambda,\n+            init_kwargs={\n+                \"function\": ops.square,\n+            },\n+            input_shape=(2, 3),\n+            expected_output_shape=(2, 3),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+            custom_objects={\"square\": ops.square},\n+        )\n+        self.run_layer_test(\n+            layers.Lambda,\n+            init_kwargs={\"function\": ops.square, \"mask\": ops.ones((2, 3))},\n+            input_shape=(2, 3),\n+            expected_output_shape=(2, 3),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=True,\n+            custom_objects={\"square\": ops.square},\n+        )\n+\n+        def stacker(x):\n+            return ops.concatenate([x, x], axis=1)\n+\n+        self.run_layer_test(\n+            layers.Lambda,\n+            init_kwargs={\"function\": stacker, \"output_shape\": (6,)},\n+            input_shape=(2, 3),\n+            expected_output_shape=(2, 6),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+            custom_objects={\"stacker\": stacker},\n+        )\n+\n+        def stacker_shape(s):\n+            return (s[0], s[1] * 2)\n+\n+        self.run_layer_test(\n+            layers.Lambda,\n+            init_kwargs={\n+                \"function\": stacker,\n+                \"output_shape\": stacker_shape,\n+            },\n+            input_shape=(2, 3),\n+            expected_output_shape=(2, 6),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=False,\n+            custom_objects={\"stacker\": stacker, \"stacker_shape\": stacker_shape},\n+        )\n+\n+    def test_correctness(self):\n+        layer = layers.Lambda(lambda x: x**2)\n+        output = layer(2 * np.ones((2, 3)))\n+        self.assertAllClose(4 * np.ones((2, 3)), output)\n+\n+        # Test serialization roundtrip\n+        config = layer.get_config()\n+        layer = layers.Lambda.from_config(config, safe_mode=False)\n+        output = layer(2 * np.ones((2, 3)))\n+        self.assertAllClose(4 * np.ones((2, 3)), output)\n+\n+    def test_correctness_lambda_shape(self):\n+        layer = layers.Lambda(lambda x: x**2, output_shape=lambda x: x)\n+        output = layer(2 * np.ones((2, 3)))\n+        self.assertAllClose(4 * np.ones((2, 3)), output)\n+\n+        # Test serialization roundtrip\n+        config = layer.get_config()\n+        layer = layers.Lambda.from_config(config, safe_mode=False)\n+        output = layer(2 * np.ones((2, 3)))\n+        self.assertAllClose(4 * np.ones((2, 3)), output)\n\n@@ -324,8 +324,6 @@ class Layer(Operation):\n         #####################################\n         # 1. Convert any array arguments to tensors of correct dtype.\n         def maybe_convert(x):\n-            if isinstance(x, np.ndarray):\n-                return backend.convert_to_tensor(x, dtype=self.compute_dtype)\n             if backend.is_tensor(x):\n                 if (\n                     self.autocast\n@@ -333,6 +331,7 @@ class Layer(Operation):\n                     and x.dtype != self.compute_dtype\n                 ):\n                     return backend.cast(x, dtype=self.compute_dtype)\n+                return x\n             elif isinstance(x, backend.KerasTensor):\n                 if (\n                     self.autocast\n@@ -341,6 +340,9 @@ class Layer(Operation):\n                 ):\n                     x.dtype = self.compute_dtype\n                 return x\n+            elif hasattr(x, \"__array__\"):\n+                return backend.convert_to_tensor(x, dtype=self.compute_dtype)\n+            return x\n \n         args = nest.map_structure(maybe_convert, args)\n         kwargs = nest.map_structure(maybe_convert, kwargs)\n\n\n@@ -52,6 +52,7 @@ class SafeModeScope:\n         global_state.set_global_setting(\"safe_mode_saving\", self.original_value)\n \n \n+@keras_core_export(\"keras_core.config.enable_unsafe_deserialization\")\n def enable_unsafe_deserialization():\n     \"\"\"Disables safe mode globally, allowing deserialization of lambdas.\"\"\"\n     global_state.set_global_setting(\"safe_mode_saving\", False)\n@@ -600,7 +601,8 @@ def deserialize_keras_object(\n                 \"This carries a potential risk of arbitrary code execution \"\n                 \"and thus it is disallowed by default. If you trust the \"\n                 \"source of the saved model, you can pass `safe_mode=False` to \"\n-                \"the loading function in order to allow `lambda` loading.\"\n+                \"the loading function in order to allow `lambda` loading, \"\n+                \"or call `keras_core.config.enable_unsafe_deserialization()`.\"\n             )\n         return python_utils.func_load(inner_config[\"value\"])\n     if config[\"class_name\"] == \"__typespec__\":\n\n@@ -0,0 +1,19 @@\n+def is_shape_tuple(x):\n+    if isinstance(x, (list, tuple)):\n+        if all(isinstance(e, (int, type(None))) for e in x):\n+            return True\n+    return False\n+\n+\n+def map_shape_structure(fn, struct):\n+    \"\"\"Variant of nest.map_structure that operates on shape tuples.\"\"\"\n+    if is_shape_tuple(struct):\n+        return fn(tuple(struct))\n+    if isinstance(struct, list):\n+        return [map_shape_structure(fn, e) for e in struct]\n+    if isinstance(struct, tuple):\n+        return tuple(map_shape_structure(fn, e) for e in struct)\n+    if isinstance(struct, dict):\n+        return {k: map_shape_structure(fn, v) for k, v in struct.items()}\n+    else:\n+        raise ValueError(f\"Cannot map function to unknown object {struct}\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
