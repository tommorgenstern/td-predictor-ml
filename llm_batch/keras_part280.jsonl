{"custom_id": "keras#ae30f36fbde83beb122a1eb1c3bf3cea2d490d5a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 25 | Churn Cumulative: 17282 | Contributors (this commit): 134 | Commits (past 90d): 44 | Contributors (cumulative): 163 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4512,7 +4512,7 @@ def ctc_decode(y_pred, input_length, greedy=True, beam_width=100,\n         (decoded, log_prob) = ctc.ctc_beam_search_decoder(\n             inputs=y_pred,\n             sequence_length=input_length, beam_width=beam_width,\n-            top_paths=top_paths)\n+            top_paths=top_paths, merge_repeated=False)\n \n     decoded_dense = []\n     for st in decoded:\n\n@@ -1769,22 +1769,31 @@ class TestBackend(object):\n              [0.155251, 0.164444, 0.173517, 0.176138, 0.169979, 0.160671]],\n             dtype=np.float32)\n \n+        # Add arbitrary offset - this is fine\n+        input_prob_matrix_0 = input_prob_matrix_0 + 2.0\n+\n         # len max_time_steps array of batch_size x depth matrices\n         inputs = ([input_prob_matrix_0[t, :][np.newaxis, :]\n                    for t in range(seq_len_0)] +  # Pad to max_time_steps = 8\n                   2 * [np.zeros((1, depth), dtype=np.float32)])\n \n-        inputs = K.variable(np.asarray(inputs).transpose((1, 0, 2)))\n+        # Take exponential as we directly apply ctc_decode_beam_search\n+        inputs = np.exp(inputs)\n+\n+        # change tensorflow order to keras backend order\n+        inputs = K.variable(inputs.transpose((1, 0, 2)))\n \n         # batch_size length vector of sequence_lengths\n         input_length = K.variable(np.array([seq_len_0], dtype=np.int32))\n-        # batch_size length vector of negative log probabilities\n-        log_prob_truth = np.array([\n-            0.584855,  # output beam 0\n-            0.389139  # output beam 1\n-        ], np.float32)[np.newaxis, :]\n+        # batch_size length vector of log probabilities\n+        log_prob_truth = np.array(\n+            [\n+                -5.811451,  # output beam 0\n+                -6.63339  # output beam 1\n+            ],\n+            np.float32)[np.newaxis, :]\n \n-        decode_truth = [np.array([1, 0]), np.array([0, 1, 0])]\n+        decode_truth = [np.array([1, 0]), np.array([[1]])]\n \n         beam_width = 2\n         top_paths = 2\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5c934bd646b0781eaf03e5b533ad2b6bfda401d5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 15 | Methods Changed: 9 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 50 | Churn Cumulative: 2362 | Contributors (this commit): 34 | Commits (past 90d): 3 | Contributors (cumulative): 34 | DMM Complexity: 1.0\n\nDIFF:\n@@ -859,10 +859,12 @@ def test_TensorBoard(tmpdir, update_freq):\n                   metrics=['accuracy', DummyStatefulMetric()])\n \n     # we must generate new callbacks for each test, as they aren't stateless\n-    def callbacks_factory(histogram_freq, embeddings_freq=1):\n+    def callbacks_factory(histogram_freq, embeddings_freq=1, write_images=True,\n+                          write_grads=True):\n         return [callbacks.TensorBoard(log_dir=filepath,\n                                       histogram_freq=histogram_freq,\n-                                      write_images=True, write_grads=True,\n+                                      write_images=write_images,\n+                                      write_grads=write_grads,\n                                       embeddings_freq=embeddings_freq,\n                                       embeddings_layer_names=['dense_1'],\n                                       embeddings_data=X_test,\n@@ -872,24 +874,30 @@ def test_TensorBoard(tmpdir, update_freq):\n     # fit without validation data\n     model.fit(X_train, y_train, batch_size=batch_size,\n               callbacks=callbacks_factory(histogram_freq=0, embeddings_freq=0),\n-              epochs=3)\n+              epochs=2)\n \n     # fit with validation data and accuracy\n     model.fit(X_train, y_train, batch_size=batch_size,\n               validation_data=(X_test, y_test),\n-              callbacks=callbacks_factory(histogram_freq=0), epochs=2)\n+              callbacks=callbacks_factory(histogram_freq=0, write_images=False,\n+                                          write_grads=False),\n+              epochs=2)\n \n     # fit generator without validation data\n     train_generator = data_generator(X_train, y_train, batch_size)\n     model.fit_generator(train_generator, len(X_train), epochs=2,\n                         callbacks=callbacks_factory(histogram_freq=0,\n+                                                    write_images=False,\n+                                                    write_grads=False,\n                                                     embeddings_freq=0))\n \n     # fit generator with validation data and accuracy\n     train_generator = data_generator(X_train, y_train, batch_size)\n     model.fit_generator(train_generator, len(X_train), epochs=2,\n                         validation_data=(X_test, y_test),\n-                        callbacks=callbacks_factory(histogram_freq=1))\n+                        callbacks=callbacks_factory(histogram_freq=1,\n+                                                    write_images=False,\n+                                                    write_grads=False))\n \n     assert os.path.isdir(filepath)\n     shutil.rmtree(filepath)\n@@ -916,10 +924,12 @@ def test_TensorBoard_histogram_freq_must_have_validation_data(tmpdir):\n                   metrics=['accuracy'])\n \n     # we must generate new callbacks for each test, as they aren't stateless\n-    def callbacks_factory(histogram_freq, embeddings_freq=1):\n+    def callbacks_factory(histogram_freq, embeddings_freq=1, write_images=True,\n+                          write_grads=True):\n         return [callbacks.TensorBoard(log_dir=filepath,\n                                       histogram_freq=histogram_freq,\n-                                      write_images=True, write_grads=True,\n+                                      write_images=write_images,\n+                                      write_grads=write_grads,\n                                       embeddings_freq=embeddings_freq,\n                                       embeddings_layer_names=['dense_1'],\n                                       embeddings_data=X_test,\n@@ -939,7 +949,9 @@ def test_TensorBoard_histogram_freq_must_have_validation_data(tmpdir):\n     with pytest.raises(ValueError) as raised_exception:\n         model.fit_generator(train_generator,\n                             len(X_train), epochs=2,\n-                            callbacks=callbacks_factory(histogram_freq=1))\n+                            callbacks=callbacks_factory(histogram_freq=1,\n+                                                        write_images=False,\n+                                                        write_grads=False))\n     assert 'validation_data must be provided' in str(raised_exception.value)\n \n     # fit generator with validation data generator should raise ValueError if\n@@ -948,7 +960,9 @@ def test_TensorBoard_histogram_freq_must_have_validation_data(tmpdir):\n         model.fit_generator(train_generator, len(X_train), epochs=2,\n                             validation_data=validation_generator,\n                             validation_steps=1,\n-                            callbacks=callbacks_factory(histogram_freq=1))\n+                            callbacks=callbacks_factory(histogram_freq=1,\n+                                                        write_images=False,\n+                                                        write_grads=False))\n     assert 'validation_data must be provided' in str(raised_exception.value)\n \n \n@@ -979,10 +993,12 @@ def test_TensorBoard_multi_input_output(tmpdir):\n                   metrics=['accuracy'])\n \n     # we must generate new callbacks for each test, as they aren't stateless\n-    def callbacks_factory(histogram_freq, embeddings_freq=1):\n+    def callbacks_factory(histogram_freq, embeddings_freq=1, write_images=True,\n+                          write_grads=True):\n         return [callbacks.TensorBoard(log_dir=filepath,\n                                       histogram_freq=histogram_freq,\n-                                      write_images=True, write_grads=True,\n+                                      write_images=write_images,\n+                                      write_grads=write_grads,\n                                       embeddings_freq=embeddings_freq,\n                                       embeddings_layer_names=['dense_1'],\n                                       embeddings_data=[X_test] * 2,\n@@ -996,19 +1012,25 @@ def test_TensorBoard_multi_input_output(tmpdir):\n     # fit with validation data and accuracy\n     model.fit([X_train] * 2, [y_train] * 2, batch_size=batch_size,\n               validation_data=([X_test] * 2, [y_test] * 2),\n-              callbacks=callbacks_factory(histogram_freq=1), epochs=2)\n+              callbacks=callbacks_factory(histogram_freq=1, write_images=False,\n+                                          write_grads=False),\n+              epochs=2)\n \n     train_generator = data_generator([X_train] * 2, [y_train] * 2, batch_size)\n \n     # fit generator without validation data\n     model.fit_generator(train_generator, len(X_train), epochs=2,\n                         callbacks=callbacks_factory(histogram_freq=0,\n-                                                    embeddings_freq=0))\n+                                                    embeddings_freq=0,\n+                                                    write_images=False,\n+                                                    write_grads=False))\n \n     # fit generator with validation data and accuracy\n     model.fit_generator(train_generator, len(X_train), epochs=2,\n                         validation_data=([X_test] * 2, [y_test] * 2),\n-                        callbacks=callbacks_factory(histogram_freq=1))\n+                        callbacks=callbacks_factory(histogram_freq=1,\n+                                                    write_images=False,\n+                                                    write_grads=False))\n \n     assert os.path.isdir(filepath)\n     shutil.rmtree(filepath)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fd537c7962edf563a3bb14526de9ce57dd26c341", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 44 | Files Changed: 4 | Hunks: 15 | Methods Changed: 17 | Complexity Δ (Sum/Max): -8/0 | Churn Δ: 78 | Churn Cumulative: 2623 | Contributors (this commit): 23 | Commits (past 90d): 4 | Contributors (cumulative): 38 | DMM Complexity: 0.16666666666666666\n\nDIFF:\n@@ -4,9 +4,13 @@ from keras import layers\n from keras import backend as K\n \n \n-def test_leaky_relu():\n-    for alpha in [0., .5, -1.]:\n-        layer_test(layers.LeakyReLU, kwargs={'alpha': alpha},\n+@pytest.mark.parametrize('activation_layer',\n+                         [layers.LeakyReLU,\n+                          layers.ELU])\n+@pytest.mark.parametrize('alpha', [0., .5, -1.])\n+def test_linear_unit_activations(activation_layer,\n+                                 alpha):\n+    layer_test(activation_layer, kwargs={'alpha': alpha},\n                input_shape=(2, 3, 4))\n \n \n@@ -20,19 +24,13 @@ def test_prelu_share():\n                input_shape=(2, 3, 4))\n \n \n-def test_elu():\n-    for alpha in [0., .5, -1.]:\n-        layer_test(layers.ELU, kwargs={'alpha': alpha},\n-                   input_shape=(2, 3, 4))\n-\n-\n def test_thresholded_relu():\n     layer_test(layers.ThresholdedReLU, kwargs={'theta': 0.5},\n                input_shape=(2, 3, 4))\n \n \n-def test_softmax():\n-    for axis in [1, -1]:\n+@pytest.mark.parametrize('axis', [1, -1])\n+def test_softmax(axis):\n     layer_test(layers.Softmax, kwargs={'axis': axis},\n                input_shape=(2, 3, 4))\n \n\n@@ -693,14 +693,15 @@ def test_zero_padding_2d(data_format, padding):\n                input_shape=inputs.shape)\n \n \n-def test_zero_padding_2d_correctness():\n+@pytest.mark.parametrize('data_format',\n+                         ['channels_first', 'channels_last'])\n+def test_zero_padding_2d_correctness(data_format):\n     num_samples = 2\n     stack_size = 2\n     input_num_row = 4\n     input_num_col = 5\n     inputs = np.ones((num_samples, stack_size, input_num_row, input_num_col))\n \n-    for data_format in ['channels_first', 'channels_last']:\n     layer = convolutional.ZeroPadding2D(padding=(2, 2),\n                                         data_format=data_format)\n     layer.build(inputs.shape)\n@@ -765,7 +766,9 @@ def test_zero_padding_3d(data_format, padding):\n                input_shape=inputs.shape)\n \n \n-def test_zero_padding_3d_correctness():\n+@pytest.mark.parametrize('data_format',\n+                         ['channels_first', 'channels_last'])\n+def test_zero_padding_3d_correctness(data_format):\n     num_samples = 2\n     stack_size = 2\n     input_len_dim1 = 4\n@@ -775,7 +778,6 @@ def test_zero_padding_3d_correctness():\n                       input_len_dim1, input_len_dim2, input_len_dim3,\n                       stack_size))\n \n-    for data_format in ['channels_first', 'channels_last']:\n     layer = convolutional.ZeroPadding3D(padding=(2, 2, 2),\n                                         data_format=data_format)\n     layer.build(inputs.shape)\n@@ -823,13 +825,14 @@ def test_upsampling_1d():\n                input_shape=(3, 5, 4))\n \n \n-def test_upsampling_2d():\n+@pytest.mark.parametrize('data_format',\n+                         ['channels_first', 'channels_last'])\n+def test_upsampling_2d(data_format):\n     num_samples = 2\n     stack_size = 2\n     input_num_row = 11\n     input_num_col = 12\n \n-    for data_format in ['channels_first', 'channels_last']:\n     if data_format == 'channels_first':\n         inputs = np.random.rand(num_samples, stack_size, input_num_row,\n                                 input_num_col)\n@@ -910,14 +913,15 @@ def test_upsampling_2d_bilinear(data_format):\n \n @pytest.mark.skipif((K.backend() == 'cntk'),\n                     reason=\"cntk does not support it yet\")\n-def test_upsampling_3d():\n+@pytest.mark.parametrize('data_format',\n+                         ['channels_first', 'channels_last'])\n+def test_upsampling_3d(data_format):\n     num_samples = 2\n     stack_size = 2\n     input_len_dim1 = 10\n     input_len_dim2 = 11\n     input_len_dim3 = 12\n \n-    for data_format in ['channels_first', 'channels_last']:\n     if data_format == 'channels_first':\n         inputs = np.random.rand(num_samples,\n                                 stack_size,\n\n@@ -70,22 +70,15 @@ def test_activation():\n                input_shape=(3, 2))\n \n \n-def test_reshape():\n+@pytest.mark.parametrize('target_shape,input_shape',\n+                         [((8, 1), (3, 2, 4)),\n+                          ((-1, 1), (3, 2, 4)),\n+                          ((1, -1), (3, 2, 4)),\n+                          ((-1, 1), (None, None, 4))])\n+def test_reshape(target_shape, input_shape):\n     layer_test(layers.Reshape,\n-               kwargs={'target_shape': (8, 1)},\n-               input_shape=(3, 2, 4))\n-\n-    layer_test(layers.Reshape,\n-               kwargs={'target_shape': (-1, 1)},\n-               input_shape=(3, 2, 4))\n-\n-    layer_test(layers.Reshape,\n-               kwargs={'target_shape': (1, -1)},\n-               input_shape=(3, 2, 4))\n-\n-    layer_test(layers.Reshape,\n-               kwargs={'target_shape': (-1, 1)},\n-               input_shape=(None, None, 4))\n+               kwargs={'target_shape': target_shape},\n+               input_shape=input_shape)\n \n \n def test_permute():\n\n@@ -29,7 +29,10 @@ def test_embedding():\n                expected_output_dtype=K.floatx())\n \n \n-def test_embedding_invalid():\n+@pytest.mark.parametrize('input_shape',\n+                         [(3, 4, 5),\n+                          (3, 5)])\n+def test_embedding_invalid(input_shape):\n \n     # len(input_length) should be equal to len(input_shape) - 1\n     with pytest.raises(ValueError):\n@@ -37,15 +40,7 @@ def test_embedding_invalid():\n             input_dim=10,\n             output_dim=4,\n             input_length=2,\n-            input_shape=(3, 4, 5))])\n-\n-    # input_length should be equal to input_shape[1:]\n-    with pytest.raises(ValueError):\n-        model = Sequential([Embedding(\n-            input_dim=10,\n-            output_dim=4,\n-            input_length=2,\n-            input_shape=(3, 5))])\n+            input_shape=input_shape)])\n \n \n if __name__ == '__main__':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#041814193dc9f0490fc2d93db830d64eb2b2d28b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 3896 | Contributors (this commit): 88 | Commits (past 90d): 6 | Contributors (cumulative): 90 | DMM Complexity: None\n\nDIFF:\n@@ -17,7 +17,7 @@ models are more common in this domain.\n - A decoder LSTM is trained to turn the target sequences into\n     the same sequence but offset by one timestep in the future,\n     a training process called \"teacher forcing\" in this context.\n-    Is uses as initial state the state vectors from the encoder.\n+    It uses as initial state the state vectors from the encoder.\n     Effectively, the decoder learns to generate `targets[t+1...]`\n     given `targets[...t]`, conditioned on the input sequence.\n - In inference mode, when we want to decode unknown input sequences, we:\n\n@@ -633,7 +633,7 @@ class ModelCheckpoint(Callback):\n     \"\"\"Save the model after every epoch.\n \n     `filepath` can contain named formatting options,\n-    which will be filled the value of `epoch` and\n+    which will be filled with the values of `epoch` and\n     keys in `logs` (passed in `on_epoch_end`).\n \n     For example: if `filepath` is `weights.{epoch:02d}-{val_loss:.2f}.hdf5`,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a96d8709fba51b70a08daeea12529948fa800830", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 10913 | Contributors (this commit): 127 | Commits (past 90d): 29 | Contributors (cumulative): 131 | DMM Complexity: None\n\nDIFF:\n@@ -277,7 +277,7 @@ def relu(x, alpha=0., max_value=None, threshold=0.):\n def switch(condition, then_expression, else_expression):\n     cond_float = condition.astype(floatx())\n     while cond_float.ndim < then_expression.ndim:\n-        cond_float = cond_float[..., None]\n+        cond_float = cond_float[..., np.newaxis]\n     return cond_float * then_expression + (1 - cond_float) * else_expression\n \n \n\n@@ -3227,6 +3227,8 @@ def switch(condition, then_expression, else_expression):\n \n     # Raises\n         ValueError: If rank of `condition` is greater than rank of expressions.\n+\n+    {{np_implementation}}\n     \"\"\"\n     if condition.dtype != tf.bool:\n         condition = tf.cast(condition, 'bool')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#34bce5bac9f434dc501f4cbff37b44680271a337", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 12458 | Contributors (this commit): 82 | Commits (past 90d): 2 | Contributors (cumulative): 82 | DMM Complexity: None\n\nDIFF:\n@@ -29,10 +29,9 @@ from ..legacy import interfaces\n class Masking(Layer):\n     \"\"\"Masks a sequence by using a mask value to skip timesteps.\n \n-    For each timestep in the input tensor (dimension #1 in the tensor),\n-    if all values in the input tensor at that timestep\n-    are equal to `mask_value`, then the timestep will be masked (skipped)\n-    in all downstream layers (as long as they support masking).\n+    If all features for a given sample timestep are equal to `mask_value`,\n+    then the sample timestep will be masked (skipped) in all downstream layers\n+    (as long as they support masking).\n \n     If any downstream layer does not support masking yet receives such\n     an input mask, an exception will be raised.\n@@ -41,10 +40,10 @@ class Masking(Layer):\n \n     Consider a Numpy data array `x` of shape `(samples, timesteps, features)`,\n     to be fed to an LSTM layer.\n-    You want to mask timestep #3 and #5 because you lack data for\n-    these timesteps. You can:\n+    You want to mask sample #0 at timestep #3, and sample #2 at timestep #5,\n+    because you lack features for these sample timesteps. You can do:\n \n-        - set `x[:, 3, :] = 0.` and `x[:, 5, :] = 0.`\n+        - set `x[0, 3, :] = 0.` and `x[2, 5, :] = 0.`\n         - insert a `Masking` layer with `mask_value=0.` before the LSTM layer:\n \n     ```python\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#49c8a35dfaa22b5ca29f9aa05bbe4b89f34e6da0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 27 | Methods Changed: 27 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 28 | Churn Cumulative: 10829 | Contributors (this commit): 127 | Commits (past 90d): 20 | Contributors (cumulative): 127 | DMM Complexity: None\n\nDIFF:\n@@ -659,6 +659,7 @@ def dtype(x):\n         >>> K.dtype(kvar)\n         'float32_ref'\n     ```\n+    {{np_implementation}}\n     \"\"\"\n     return x.dtype.base_dtype.name\n \n@@ -680,6 +681,7 @@ def eval(x):\n         array([[ 1.,  2.],\n                [ 3.,  4.]], dtype=float32)\n     ```\n+    {{np_implementation}}\n     \"\"\"\n     return to_dense(x).eval(session=get_session())\n \n@@ -706,6 +708,7 @@ def zeros(shape, dtype=None, name=None):\n                [ 0.,  0.,  0.,  0.],\n                [ 0.,  0.,  0.,  0.]], dtype=float32)\n     ```\n+    {{np_implementation}}\n     \"\"\"\n     if dtype is None:\n         dtype = floatx()\n@@ -738,6 +741,7 @@ def ones(shape, dtype=None, name=None):\n                [ 1.,  1.,  1.,  1.],\n                [ 1.,  1.,  1.,  1.]], dtype=float32)\n     ```\n+    {{np_implementation}}\n     \"\"\"\n     if dtype is None:\n         dtype = floatx()\n@@ -768,7 +772,7 @@ def eye(size, dtype=None, name=None):\n                [ 0.,  1.,  0.],\n                [ 0.,  0.,  1.]], dtype=float32)\n     ```\n-\n+    {{np_implementation}}\n     \"\"\"\n     if dtype is None:\n         dtype = floatx()\n@@ -797,6 +801,7 @@ def zeros_like(x, dtype=None, name=None):\n         array([[ 0.,  0.,  0.],\n                [ 0.,  0.,  0.]], dtype=float32)\n     ```\n+    {{np_implementation}}\n     \"\"\"\n     return tf.zeros_like(x, dtype=dtype, name=name)\n \n@@ -822,6 +827,7 @@ def ones_like(x, dtype=None, name=None):\n         array([[ 1.,  1.,  1.],\n                [ 1.,  1.,  1.]], dtype=float32)\n     ```\n+    {{np_implementation}}\n     \"\"\"\n     return tf.ones_like(x, dtype=dtype, name=name)\n \n@@ -864,6 +870,7 @@ def random_uniform_variable(shape, low, high, dtype=None,\n         array([[ 0.10940075,  0.10047495,  0.476143  ],\n                [ 0.66137183,  0.00869417,  0.89220798]], dtype=float32)\n     ```\n+    {{np_implementation}}\n     \"\"\"\n     if dtype is None:\n         dtype = floatx()\n@@ -901,6 +908,7 @@ def random_normal_variable(shape, mean, scale, dtype=None,\n         array([[ 1.19591331,  0.68685907, -0.63814116],\n                [ 0.92629528,  0.28055015,  1.70484698]], dtype=float32)\n     ```\n+    {{np_implementation}}\n     \"\"\"\n     if dtype is None:\n         dtype = floatx()\n@@ -932,6 +940,7 @@ def count_params(x):\n         array([[ 0.,  0.,  0.],\n                [ 0.,  0.,  0.]], dtype=float32)\n     ```\n+    {{np_implementation}}\n     \"\"\"\n     return np.prod(int_shape(x))\n \n@@ -1070,6 +1079,7 @@ def dot(x, y):\n         >>> K.int_shape(xy)\n         (2, 4, 5)\n     ```\n+    {{np_implementation}}\n     \"\"\"\n     if ndim(x) is not None and (ndim(x) > 2 or ndim(y) > 2):\n         x_shape = []\n@@ -1334,6 +1344,7 @@ def transpose(x):\n         <tf.Tensor 'transpose_4:0' shape=(3, 2) dtype=float32>\n \n     ```\n+    {{np_implementation}}\n     \"\"\"\n     return tf.transpose(x)\n \n@@ -1449,6 +1460,7 @@ def cumsum(x, axis=0):\n \n     # Returns\n         A tensor of the cumulative sum of values of `x` along `axis`.\n+    {{np_implementation}}\n     \"\"\"\n     return tf.cumsum(x, axis=axis)\n \n@@ -1462,6 +1474,7 @@ def cumprod(x, axis=0):\n \n     # Returns\n         A tensor of the cumulative product of values of `x` along `axis`.\n+    {{np_implementation}}\n     \"\"\"\n     return tf.cumprod(x, axis=axis)\n \n@@ -1481,6 +1494,7 @@ def var(x, axis=None, keepdims=False):\n \n     # Returns\n         A tensor with the variance of elements of `x`.\n+    {{np_implementation}}\n     \"\"\"\n     if x.dtype.base_dtype == tf.bool:\n         x = tf.cast(x, floatx())\n@@ -1506,6 +1520,7 @@ def std(x, axis=None, keepdims=False):\n \n     # Returns\n         A tensor with the standard deviation of elements of `x`.\n+    {{np_implementation}}\n     \"\"\"\n     return tf.sqrt(var(x, axis=axis, keepdims=keepdims))\n \n@@ -1525,6 +1540,7 @@ def mean(x, axis=None, keepdims=False):\n \n     # Returns\n         A tensor with the mean of elements of `x`.\n+    {{np_implementation}}\n     \"\"\"\n     if x.dtype.base_dtype == tf.bool:\n         x = tf.cast(x, floatx())\n@@ -1543,6 +1559,7 @@ def any(x, axis=None, keepdims=False):\n \n     # Returns\n         A uint8 tensor (0s and 1s).\n+    {{np_implementation}}\n     \"\"\"\n     x = tf.cast(x, tf.bool)\n     return tf.reduce_any(x, axis, keepdims)\n@@ -1560,6 +1577,7 @@ def all(x, axis=None, keepdims=False):\n \n     # Returns\n         A uint8 tensor (0s and 1s).\n+    {{np_implementation}}\n     \"\"\"\n     x = tf.cast(x, tf.bool)\n     return tf.reduce_all(x, axis, keepdims)\n@@ -1574,6 +1592,7 @@ def argmax(x, axis=-1):\n \n     # Returns\n         A tensor.\n+    {{np_implementation}}\n     \"\"\"\n     return tf.argmax(x, axis)\n \n@@ -1587,6 +1606,7 @@ def argmin(x, axis=-1):\n \n     # Returns\n         A tensor.\n+    {{np_implementation}}\n     \"\"\"\n     return tf.argmin(x, axis)\n \n@@ -1623,6 +1643,7 @@ def sqrt(x):\n \n     # Returns\n         A tensor.\n+    {{np_implementation}}\n     \"\"\"\n     zero = _to_tensor(0., x.dtype.base_dtype)\n     inf = _to_tensor(np.inf, x.dtype.base_dtype)\n@@ -1673,6 +1694,7 @@ def logsumexp(x, axis=None, keepdims=False):\n \n     # Returns\n         The reduced tensor.\n+    {{np_implementation}}\n     \"\"\"\n     return tf.reduce_logsumexp(x, axis, keepdims)\n \n@@ -1712,6 +1734,7 @@ def pow(x, a):\n \n     # Returns\n         A tensor.\n+    {{np_implementation}}\n     \"\"\"\n     return tf.pow(x, a)\n \n@@ -1726,6 +1749,7 @@ def clip(x, min_value, max_value):\n \n     # Returns\n         A tensor.\n+    {{np_implementation}}\n     \"\"\"\n     if (isinstance(min_value, (int, float)) and\n             isinstance(max_value, (int, float))):\n@@ -3644,6 +3668,7 @@ def dropout(x, level, noise_shape=None, seed=None):\n \n     # Returns\n         A tensor.\n+    {{np_implementation}}\n     \"\"\"\n     retain_prob = 1. - level\n     if seed is None:\n@@ -4263,6 +4288,7 @@ def bias_add(x, bias, data_format=None):\n                     2. invalid bias shape.\n                        the bias should be either a vector or\n                        a tensor with ndim(x) - 1 dimension\n+    {{np_implementation}}\n     \"\"\"\n     data_format = normalize_data_format(data_format)\n     bias_shape = int_shape(bias)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3fa96cf36f049efd6cf077f2812ba67ef8736d56", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 6377 | Contributors (this commit): 59 | Commits (past 90d): 4 | Contributors (cumulative): 59 | DMM Complexity: None\n\nDIFF:\n@@ -102,6 +102,7 @@ class DirectoryIterator(image.DirectoryIterator, Iterator):\n             `None`: no targets get yielded (only input images are yielded).\n         batch_size: Integer, size of a batch.\n         shuffle: Boolean, whether to shuffle the data between epochs.\n+            If set to False, sorts the data in alphanumeric order.\n         seed: Random seed for data shuffling.\n         data_format: String, one of `channels_first`, `channels_last`.\n         save_to_dir: Optional directory where to save the pictures\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#57a4fd619649acf8043071eda5bb8b849116980b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 275 | Contributors (this commit): 11 | Commits (past 90d): 1 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -79,7 +79,7 @@ def convert_kernel(kernel):\n     slices = [slice(None, None, -1) for _ in range(kernel.ndim)]\n     no_flip = (slice(None, None), slice(None, None))\n     slices[-2:] = no_flip\n-    return np.copy(kernel[slices])\n+    return np.copy(kernel[tuple(slices)])\n \n \n def conv_output_length(input_length, filter_size,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#48a8fa0e0dcb7b06af113c8f5dd47fa5190407ca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 8470 | Contributors (this commit): 42 | Commits (past 90d): 17 | Contributors (cumulative): 51 | DMM Complexity: None\n\nDIFF:\n@@ -37,7 +37,7 @@ else:\n \n \n def check_dtype(var, dtype):\n-    if K._BACKEND == 'theano':\n+    if K.backend() == 'theano':\n         assert var.dtype == dtype\n     else:\n         assert var.dtype.name == '%s_ref' % dtype\n\n@@ -470,7 +470,7 @@ def test_recursion():\n     ####################################################\n     # test calling layers/models on TF tensors\n \n-    if K._BACKEND == 'tensorflow':\n+    if K.backend() == 'tensorflow':\n         import tensorflow as tf\n         j = Input(shape=(32,), name='input_j')\n         k = Input(shape=(32,), name='input_k')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#844c1b44b75bc5345c26d19a8fa4161f5b00e99a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 4 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 31 | Churn Cumulative: 3086 | Contributors (this commit): 33 | Commits (past 90d): 11 | Contributors (cumulative): 38 | DMM Complexity: 0.7222222222222222\n\nDIFF:\n@@ -322,6 +322,11 @@ def collect_metrics(metrics, output_names):\n         return [copy.copy(metrics) for _ in output_names]\n     elif isinstance(metrics, dict):\n         nested_metrics = []\n+        if not set(metrics.keys()).issubset(set(output_names)):\n+            unknown_output_names = list(set(metrics.keys()) - set(output_names))\n+            warnings.warn('Invalid layer name for metric computations: '\n+                          '{}. Available names are {}.'\n+                          .format(unknown_output_names, output_names))\n         for name in output_names:\n             output_metrics = metrics.get(name, [])\n             output_metrics = to_list(output_metrics)\n\n@@ -734,6 +734,32 @@ def test_check_bad_shape():\n     assert 'targets to have the same shape' in str(exc)\n \n \n+@pytest.mark.parametrize('input_metrics,expected_output', [\n+    (None, [[], []]),\n+    (['mse', 'mae'], [['mse', 'mae'], ['mse', 'mae']]),\n+    ({'layer_1': 'mae', 'layer_2': 'mse'}, [['mae'], ['mse']]),\n+])\n+def test_collect_metrics(input_metrics, expected_output):\n+    output_names = ['layer_1', 'layer_2']\n+\n+    output_metrics = training_utils.collect_metrics(input_metrics,\n+                                                    output_names)\n+    assert output_metrics == expected_output\n+\n+\n+def test_collect_metrics_with_invalid_metrics_format():\n+    with pytest.raises(TypeError):\n+        training_utils.collect_metrics({'a', 'set', 'type'}, [])\n+\n+\n+def test_collect_metrics_with_invalid_layer_name():\n+    with pytest.warns(Warning) as w:\n+        training_utils.collect_metrics({'unknown_layer': 'mse'}, ['layer_1'])\n+\n+    warning_raised = all(['unknown_layer' in str(w_.message) for w_ in w])\n+    assert warning_raised, 'Warning was raised for unknown_layer'\n+\n+\n @pytest.mark.skipif(K.backend() != 'tensorflow',\n                     reason='Requires TensorFlow backend')\n def test_model_with_input_feed_tensor():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8c9de8349ff4498c83f72fdcf5e432a6975d9722", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 11 | Files Changed: 5 | Hunks: 11 | Methods Changed: 8 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 22 | Churn Cumulative: 7195 | Contributors (this commit): 54 | Commits (past 90d): 9 | Contributors (cumulative): 72 | DMM Complexity: None\n\nDIFF:\n@@ -36,10 +36,10 @@ import os\n def sampling(args):\n     \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n \n-    # Arguments:\n+    # Arguments\n         args (tensor): mean and log of variance of Q(z|X)\n \n-    # Returns:\n+    # Returns\n         z (tensor): sampled latent vector\n     \"\"\"\n \n@@ -57,7 +57,7 @@ def plot_results(models,\n                  model_name=\"vae_mnist\"):\n     \"\"\"Plots labels and MNIST digits as function of 2-dim latent vector\n \n-    # Arguments:\n+    # Arguments\n         models (tuple): encoder and decoder models\n         data (tuple): test data and label\n         batch_size (int): prediction batch size\n\n@@ -38,10 +38,10 @@ import os\n def sampling(args):\n     \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n \n-    # Arguments:\n+    # Arguments\n         args (tensor): mean and log of variance of Q(z|X)\n \n-    # Returns:\n+    # Returns\n         z (tensor): sampled latent vector\n     \"\"\"\n \n@@ -59,7 +59,7 @@ def plot_results(models,\n                  model_name=\"vae_mnist\"):\n     \"\"\"Plots labels and MNIST digits as function of 2-dim latent vector\n \n-    # Arguments:\n+    # Arguments\n         models (tuple): encoder and decoder models\n         data (tuple): test data and label\n         batch_size (int): prediction batch size\n\n@@ -1307,7 +1307,7 @@ def _map_graph_network(inputs, outputs):\n         This recursively updates the map `layer_indices`,\n         the list `nodes_in_decreasing_depth` and the set `network_nodes`.\n \n-        # Arguments:\n+        # Arguments\n             tensor: Some tensor in a graph.\n             finished_nodes: Set of nodes whose subgraphs have been traversed\n                 completely. Useful to prevent duplicated work.\n@@ -1318,7 +1318,7 @@ def _map_graph_network(inputs, outputs):\n             node_index: Node index from which `tensor` comes from.\n             tensor_index: Tensor_index from which `tensor` comes from.\n \n-        # Raises:\n+        # Raises\n             ValueError: if a cycle is detected.\n         \"\"\"\n         node = layer._inbound_nodes[node_index]\n\n@@ -261,7 +261,7 @@ class Sequential(Model):\n             batch_size: integer.\n             verbose: verbosity mode, 0 or 1.\n \n-        # Returns:\n+        # Returns\n             A numpy array of class predictions.\n         \"\"\"\n         proba = self.predict(x, batch_size=batch_size, verbose=verbose)\n\n@@ -501,10 +501,10 @@ def unpack_singleton(x):\n \n     Otherwise return the iterable.\n \n-    # Argument:\n+    # Argument\n         x: A list or tuple.\n \n-    # Returns:\n+    # Returns\n         The same iterable or the first element.\n     \"\"\"\n     if len(x) == 1:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1400e7b355366a35eb35250c1e6191d4deb21a85", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 3625 | Contributors (this commit): 85 | Commits (past 90d): 5 | Contributors (cumulative): 85 | DMM Complexity: None\n\nDIFF:\n@@ -91,8 +91,9 @@ class CallbackList(object):\n            delta_t_median > 0.1):\n             warnings.warn(\n                 'Method (%s) is slow compared '\n-                'to the batch update (%f). Check your callbacks.', hook_name,\n-                delta_t_median)\n+                'to the batch update (%f). Check your callbacks.'\n+                % (hook_name, delta_t_median), RuntimeWarning)\n+\n         if hook == 'begin':\n             self._t_enter_batch = time.time()\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a6c8042121371b5873773ca767f28cdf5689d5e4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 111 | Lines Deleted: 6 | Files Changed: 5 | Hunks: 19 | Methods Changed: 12 | Complexity Δ (Sum/Max): 12/5 | Churn Δ: 117 | Churn Cumulative: 13137 | Contributors (this commit): 105 | Commits (past 90d): 19 | Contributors (cumulative): 147 | DMM Complexity: 0.8846153846153846\n\nDIFF:\n@@ -844,6 +844,7 @@ class Model(Network):\n             initial_epoch=0,\n             steps_per_epoch=None,\n             validation_steps=None,\n+            validation_freq=1,\n             **kwargs):\n         \"\"\"Trains the model for a given number of epochs (iterations on a dataset).\n \n@@ -926,6 +927,13 @@ class Model(Network):\n             validation_steps: Only relevant if `steps_per_epoch`\n                 is specified. Total number of steps (batches of samples)\n                 to validate before stopping.\n+            validation_freq: Only relevant if validation data is provided. Integer\n+                or list/tuple/set. If an integer, specifies how many training\n+                epochs to run before a new validation run is performed, e.g.\n+                `validation_freq=2` runs validation every 2 epochs. If a list,\n+                tuple, or set, specifies the epochs on which to run validation,\n+                e.g. `validation_freq=[1, 2, 10]` runs validation at the end\n+                of the 1st, 2nd, and 10th epochs.\n \n         # Returns\n             A `History` object. Its `History.history` attribute is\n@@ -1044,7 +1052,8 @@ class Model(Network):\n                                         callback_metrics=callback_metrics,\n                                         initial_epoch=initial_epoch,\n                                         steps_per_epoch=steps_per_epoch,\n-                                        validation_steps=validation_steps)\n+                                        validation_steps=validation_steps,\n+                                        validation_freq=validation_freq)\n \n     def evaluate(self, x=None, y=None,\n                  batch_size=None,\n@@ -1300,6 +1309,7 @@ class Model(Network):\n                       callbacks=None,\n                       validation_data=None,\n                       validation_steps=None,\n+                      validation_freq=1,\n                       class_weight=None,\n                       max_queue_size=10,\n                       workers=1,\n@@ -1369,6 +1379,13 @@ class Model(Network):\n                 validation dataset divided by the batch size.\n                 Optional for `Sequence`: if unspecified, will use\n                 the `len(validation_data)` as a number of steps.\n+            validation_freq: Only relevant if validation data is provided. Integer\n+                or `collections.Container` instance (e.g. list, tuple, etc.). If an\n+                integer, specifies how many training epochs to run before a new\n+                validation run is performed, e.g. `validation_freq=2` runs\n+                validation every 2 epochs. If a Container, specifies the epochs on\n+                which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n+                validation at the end of the 1st, 2nd, and 10th epochs.\n             class_weight: Optional dictionary mapping class indices (integers)\n                 to a weight (float) value, used for weighting the loss function\n                 (during training only). This can be useful to tell the model to\n@@ -1428,6 +1445,7 @@ class Model(Network):\n             callbacks=callbacks,\n             validation_data=validation_data,\n             validation_steps=validation_steps,\n+            validation_freq=validation_freq,\n             class_weight=class_weight,\n             max_queue_size=max_queue_size,\n             workers=workers,\n\n@@ -8,8 +8,9 @@ import numpy as np\n from scipy.sparse import issparse\n \n from .training_utils import batch_shuffle\n-from .training_utils import make_batches\n from .training_utils import check_num_samples\n+from .training_utils import make_batches\n+from .training_utils import should_run_validation\n from .. import backend as K\n from .. import callbacks as cbks\n from ..utils.generic_utils import Progbar\n@@ -30,7 +31,8 @@ def fit_loop(model, fit_function, fit_inputs,\n              callback_metrics=None,\n              initial_epoch=0,\n              steps_per_epoch=None,\n-             validation_steps=None):\n+             validation_steps=None,\n+             validation_freq=1):\n     \"\"\"Abstract fit function for `fit_function(fit_inputs)`.\n \n     Assumes that fit_function returns a list, labeled by out_labels.\n@@ -62,6 +64,13 @@ def fit_loop(model, fit_function, fit_inputs,\n         validation_steps: Number of steps to run validation for\n             (only if doing validation from data tensors).\n             Ignored with the default value of `None`.\n+        validation_freq: Only relevant if validation data is provided. Integer\n+            or list/tuple/set. If an integer, specifies how many training\n+            epochs to run before a new validation run is performed, e.g.\n+            validation_freq=2` runs validation every 2 epochs. If a list,\n+            tuple, or set, specifies the epochs on which to run validation,\n+            e.g. `validation_freq=[1, 2, 10]` runs validation at the end\n+            of the 1st, 2nd, and 10th epochs.\n \n     # Returns\n         `History` object.\n@@ -158,7 +167,7 @@ def fit_loop(model, fit_function, fit_inputs,\n                 if callback_model.stop_training:\n                     break\n \n-            if do_validation:\n+            if do_validation and should_run_validation(validation_freq, epoch):\n                 val_outs = test_loop(model, val_function, val_inputs,\n                                      steps=validation_steps,\n                                      callbacks=callbacks,\n@@ -202,7 +211,7 @@ def fit_loop(model, fit_function, fit_inputs,\n                     break\n \n             if batch_index == len(batches) - 1:  # Last batch.\n-                    if do_validation:\n+                if do_validation and should_run_validation(validation_freq, epoch):\n                     val_outs = test_loop(model, val_function, val_inputs,\n                                          batch_size=batch_size,\n                                          callbacks=callbacks,\n@@ -211,6 +220,7 @@ def fit_loop(model, fit_function, fit_inputs,\n                     # Same labels assumed.\n                     for l, o in zip(out_labels, val_outs):\n                         epoch_logs['val_' + l] = o\n+\n         callbacks.on_epoch_end(epoch, epoch_logs)\n         if callbacks.model.stop_training:\n             break\n\n@@ -9,6 +9,7 @@ import numpy as np\n \n from .training_utils import is_sequence\n from .training_utils import iter_sequence_infinite\n+from .training_utils import should_run_validation\n from .. import backend as K\n from ..utils.data_utils import Sequence\n from ..utils.data_utils import GeneratorEnqueuer\n@@ -27,6 +28,7 @@ def fit_generator(model,\n                   callbacks=None,\n                   validation_data=None,\n                   validation_steps=None,\n+                  validation_freq=1,\n                   class_weight=None,\n                   max_queue_size=10,\n                   workers=1,\n@@ -222,7 +224,9 @@ def fit_generator(model,\n                 steps_done += 1\n \n                 # Epoch finished.\n-                if steps_done >= steps_per_epoch and do_validation:\n+                if (steps_done >= steps_per_epoch and\n+                        do_validation and\n+                        should_run_validation(validation_freq, epoch)):\n                     # Note that `callbacks` here is an instance of\n                     # `keras.callbacks.CallbackList`\n                     if val_gen:\n\n@@ -4,6 +4,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n+import collections\n import copy\n import numpy as np\n import warnings\n@@ -615,3 +616,33 @@ def is_sequence(seq):\n     # TODO Dref360: Decide which pattern to follow. First needs a new TF Version.\n     return (getattr(seq, 'use_sequence_api', False)\n             or set(dir(Sequence())).issubset(set(dir(seq) + ['use_sequence_api'])))\n+\n+\n+def should_run_validation(validation_freq, epoch):\n+    \"\"\"Checks if validation should be run this epoch.\n+\n+    Arguments:\n+    validation_freq: Integer or list. If an integer, specifies how many training\n+      epochs to run before a new validation run is performed. If a list,\n+      specifies the epochs on which to run validation.\n+    epoch: Integer, the number of the training epoch just completed.\n+\n+    Returns:\n+    Bool, True if validation should be run.\n+\n+    Raises:\n+    ValueError: if `validation_freq` is an Integer and less than 1, or if\n+    it is neither an Integer nor a Sequence.\n+    \"\"\"\n+    # `epoch` is 0-indexed internally but 1-indexed in the public API.\n+    one_indexed_epoch = epoch + 1\n+\n+    if isinstance(validation_freq, int):\n+        if validation_freq < 1:\n+            raise ValueError('`validation_freq` can not be less than 1.')\n+        return one_indexed_epoch % validation_freq == 0\n+\n+    if not isinstance(validation_freq, collections.Container):\n+        raise ValueError('`validation_freq` must be an Integer or '\n+                         '`collections.Container` (e.g. list, tuple, etc.)')\n+    return one_indexed_epoch in validation_freq\n\n@@ -1621,5 +1621,47 @@ def test_sample_weights():\n     assert np.allclose(weights, expected)\n \n \n+def test_validation_freq():\n+    model = Sequential([Dense(1)])\n+    model.compile('sgd', 'mse')\n+\n+    def _gen():\n+        while True:\n+            yield np.ones((2, 10)), np.ones((2, 1))\n+\n+    x, y = np.ones((10, 10)), np.ones((10, 1))\n+\n+    class ValCounter(Callback):\n+\n+        def __init__(self):\n+            self.val_runs = 0\n+\n+        def on_test_begin(self, logs=None):\n+            self.val_runs += 1\n+\n+    # Test in training_arrays.py\n+    val_counter = ValCounter()\n+    model.fit(\n+        x,\n+        y,\n+        batch_size=2,\n+        epochs=4,\n+        validation_data=(x, y),\n+        validation_freq=2,\n+        callbacks=[val_counter])\n+    assert val_counter.val_runs == 2\n+\n+    # Test in training_generator.py\n+    val_counter = ValCounter()\n+    model.fit_generator(\n+        _gen(),\n+        epochs=4,\n+        steps_per_epoch=5,\n+        validation_data=(x, y),\n+        validation_freq=[4, 2, 2, 1],\n+        callbacks=[val_counter])\n+    assert val_counter.val_runs == 3\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
