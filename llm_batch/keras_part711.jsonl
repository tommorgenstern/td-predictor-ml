{"custom_id": "keras#7e69d03947c6cc0e51bfc86a1966861edd91cd4f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 12 | Files Changed: 1 | Hunks: 14 | Methods Changed: 14 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 24 | Churn Cumulative: 3156 | Contributors (this commit): 10 | Commits (past 90d): 26 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -165,7 +165,6 @@ def broadcast_shapes(shape1, shape2):\n         output_shape (list of integers or `None`): The broadcasted shape.\n \n     Example:\n-\n     >>> broadcast_shapes((5, 3), (1, 3))\n     [5, 3]\n     \"\"\"\n@@ -247,7 +246,6 @@ def absolute(x):\n         An array containing the absolute value of each element in `x`.\n \n     Example:\n-\n     >>> x = keras_core.ops.convert_to_tensor([-1.2, 1.2])\n     >>> keras_core.ops.absolute(x)\n     array([1.2 1.2], shape=(2,), dtype=float32)\n@@ -290,7 +288,6 @@ def add(x1, x2):\n         The tensor containing the element-wise sum of `x1` and `x2`.\n \n     Examples:\n-\n     >>> x1 = keras_core.ops.convert_to_tensor([1, 4])\n     >>> x2 = keras_core.ops.convert_to_tensor([5, 6])\n     >>> keras_core.ops.add(x1, x2)\n@@ -357,7 +354,6 @@ def all(x, axis=None, keepdims=False):\n         The tensor containing the logical AND reduction over the `axis`.\n \n     Examples:\n-\n     >>> x = keras_core.ops.convert_to_tensor([True, False])\n     >>> keras_core.ops.all(x)\n     array(False, shape=(), dtype=bool)\n@@ -422,7 +418,6 @@ def any(x, axis=None, keepdims=False):\n         The tensor containing the logical OR reduction over the `axis`.\n \n     Examples:\n-\n     >>> x = keras_core.ops.convert_to_tensor([True, False])\n     >>> keras_core.ops.any(x)\n     array(True, shape=(), dtype=bool)\n@@ -483,7 +478,6 @@ def amax(x, axis=None, keepdims=False):\n         the specified axis.\n \n     Examples:\n-\n     >>> x = keras_core.ops.convert_to_tensor([[1, 3, 5], [2, 3, 6]])\n     >>> keras_core.ops.amax(x)\n     array(6, dtype=int32)\n@@ -539,7 +533,6 @@ def amin(x, axis=None, keepdims=False):\n         the specified axis.\n \n     Examples:\n-\n     >>> x = keras_core.ops.convert_to_tensor([1, 3, 5, 2, 3, 6])\n     >>> keras_core.ops.amin(x)\n     array(1, dtype=int32)\n@@ -605,7 +598,6 @@ def append(\n         A tensor with the values of `x2` appended to `x1`.\n \n     Examples:\n-\n     >>> x1 = keras_core.ops.convert_to_tensor([1, 2, 3])\n     >>> x2 = keras_core.ops.convert_to_tensor([[4, 5, 6], [7, 8, 9]])\n     >>> keras_core.ops.append(x1, x2)\n@@ -675,7 +667,6 @@ def arange(start, stop=None, step=1, dtype=None):\n         rule may result in the last element of out being greater than stop.\n \n     Examples:\n-\n     >>> keras_core.ops.arange(3)\n     array([0, 1, 2], dtype=int32)\n \n@@ -714,7 +705,8 @@ def arccos(x):\n \n     Example:\n     >>> x = keras_core.ops.convert_to_tensor([1, -1])\n-    array([0., 3.1415927], dtype=float32)\n+    >>> keras_core.ops.arccos(x)\n+    array([0.0, 3.1415927], dtype=float32)\n     \"\"\"\n     if any_symbolic_tensors((x,)):\n         return Arccos().symbolic_call(x)\n@@ -737,6 +729,11 @@ def arccosh(x):\n \n     Returns:\n         Output tensor of same shape as x.\n+\n+    Example:\n+    >>> x = keras_core.ops.convert_to_tensor([10, 100])\n+    >>> keras_core.ops.arccosh(x)\n+    array([2.993223, 5.298292], dtype=float32)\n     \"\"\"\n     if any_symbolic_tensors((x,)):\n         return Arccosh().symbolic_call(x)\n@@ -789,6 +786,11 @@ def arcsinh(x):\n \n     Returns:\n         Output tensor of same shape as `x`.\n+\n+    Example:\n+    >>> x = keras_core.ops.convert_to_tensor([1, -1, 0])\n+    >>> keras_core.ops.arcsinh(x)\n+    array([0.88137364, -0.88137364, 0.0], dtype=float32)\n     \"\"\"\n     if any_symbolic_tensors((x,)):\n         return Arcsinh().symbolic_call(x)\n@@ -1332,7 +1334,6 @@ def clip(x, x_min, x_max):\n         x: Input tensor.\n         x_min: Minimum value.\n         x_max: Maximum value.\n-\n     Returns:\n         The clipped tensor.\n     \"\"\"\n@@ -1927,7 +1928,6 @@ def digitize(x, bins):\n         Output array of indices, of same shape as `x`.\n \n     Example:\n-\n     >>> x = np.array([0.0, 1.0, 3.0, 1.6])\n     >>> bins = np.array([0.0, 3.0, 4.5, 7.0])\n     >>> keras_core.ops.digitize(x, bins)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4483893ca9431b7a0fd0c03560e014b69f5dcf67", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 90 | Lines Deleted: 346 | Files Changed: 11 | Hunks: 47 | Methods Changed: 32 | Complexity Δ (Sum/Max): -21/2 | Churn Δ: 436 | Churn Cumulative: 13499 | Contributors (this commit): 32 | Commits (past 90d): 199 | Contributors (cumulative): 77 | DMM Complexity: 1.0\n\nDIFF:\n@@ -109,9 +109,6 @@ class Variable(KerasVariable):\n \n def convert_to_tensor(x, dtype=None):\n     if is_tensor(x):\n-        device = get_device()\n-        if x.device != device:\n-            x = x.to(device)\n         if dtype is None:\n             return x\n         return x.to(to_torch_dtype(dtype))\n\n@@ -1,5 +1,8 @@\n+import math\n+\n import numpy as np\n import pytest\n+import tensorflow as tf\n from absl.testing import parameterized\n from numpy.lib.stride_tricks import as_strided\n \n@@ -246,11 +249,11 @@ class ConvBasicTest(testing.TestCase, parameterized.TestCase):\n \n class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n     def _same_padding(self, input_size, kernel_size, stride):\n-        if input_size % stride == 0:\n-            padding = max(kernel_size - stride, 0)\n-        else:\n-            padding = max(kernel_size - (input_size % stride), 0)\n-        return padding // 2, padding - padding // 2\n+        # P = ((S-1)*W-S+K)/2, with K = kernel size, S = stride, W = input size\n+        padding = int(\n+            math.ceil(((stride - 1) * input_size - stride + kernel_size) / 2)\n+        )\n+        return padding\n \n     def _np_conv1d(\n         self,\n@@ -289,9 +292,9 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             h_pad = self._same_padding(h_x, kernel_size, h_stride)\n             npad = [(0, 0)] * x.ndim\n             if padding == \"causal\":\n-                npad[1] = (h_pad[0] + h_pad[1], 0)\n+                npad[1] = (h_pad * 2, 0)\n             else:\n-                npad[1] = h_pad\n+                npad[1] = (h_pad, h_pad)\n             x = np.pad(x, pad_width=npad, mode=\"constant\", constant_values=0)\n \n         n_batch, h_x, _ = x.shape\n@@ -322,192 +325,7 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n                 ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n             ]\n             out_grps.append(x_strided @ kernel_weights_grp + bias_weights_grp)\n-        out = np.concatenate(out_grps, axis=-1)\n-        if data_format == \"channels_first\":\n-            out = out.swapaxes(1, 2)\n-        return out\n-\n-    def _np_conv2d(\n-        self,\n-        x,\n-        kernel_weights,\n-        bias_weights,\n-        strides,\n-        padding,\n-        data_format,\n-        dilation_rate,\n-        groups,\n-    ):\n-        if data_format == \"channels_first\":\n-            x = x.transpose((0, 2, 3, 1))\n-        if isinstance(strides, (tuple, list)):\n-            h_stride, w_stride = strides\n-        else:\n-            h_stride = strides\n-            w_stride = strides\n-        if isinstance(dilation_rate, (tuple, list)):\n-            h_dilation, w_dilation = dilation_rate\n-        else:\n-            h_dilation = dilation_rate\n-            w_dilation = dilation_rate\n-        h_kernel, w_kernel, ch_in, ch_out = kernel_weights.shape\n-\n-        if h_dilation > 1 or w_dilation > 1:\n-            new_h_kernel = h_kernel + (h_dilation - 1) * (h_kernel - 1)\n-            new_w_kernel = w_kernel + (w_dilation - 1) * (w_kernel - 1)\n-            new_kenel_size_tuple = (new_h_kernel, new_w_kernel)\n-            new_kernel_weights = np.zeros(\n-                (*new_kenel_size_tuple, ch_in, ch_out),\n-                dtype=kernel_weights.dtype,\n-            )\n-            new_kernel_weights[::h_dilation, ::w_dilation] = kernel_weights\n-            kernel_weights = new_kernel_weights\n-            h_kernel, w_kernel = kernel_weights.shape[:2]\n-\n-        if padding == \"same\":\n-            n_batch, h_x, w_x, _ = x.shape\n-            h_pad = self._same_padding(h_x, h_kernel, h_stride)\n-            w_pad = self._same_padding(w_x, w_kernel, w_stride)\n-            npad = [(0, 0)] * x.ndim\n-            npad[1] = h_pad\n-            npad[2] = w_pad\n-            x = np.pad(x, pad_width=npad, mode=\"constant\", constant_values=0)\n-\n-        n_batch, h_x, w_x, _ = x.shape\n-        h_out = int((h_x - h_kernel) / h_stride) + 1\n-        w_out = int((w_x - w_kernel) / w_stride) + 1\n-\n-        out_grps = []\n-        for grp in range(1, groups + 1):\n-            x_in = x[..., (grp - 1) * ch_in : grp * ch_in]\n-            stride_shape = (n_batch, h_out, w_out, h_kernel, w_kernel, ch_in)\n-            strides = (\n-                x_in.strides[0],\n-                h_stride * x_in.strides[1],\n-                w_stride * x_in.strides[2],\n-                x_in.strides[1],\n-                x_in.strides[2],\n-                x_in.strides[3],\n-            )\n-            inner_dim = h_kernel * w_kernel * ch_in\n-            x_strided = as_strided(\n-                x_in, shape=stride_shape, strides=strides\n-            ).reshape(-1, inner_dim)\n-            ch_out_groups = ch_out // groups\n-            kernel_weights_grp = kernel_weights[\n-                ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n-            ].reshape(-1, ch_out_groups)\n-            bias_weights_grp = bias_weights[\n-                ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n-            ]\n-            out_grps.append(x_strided @ kernel_weights_grp + bias_weights_grp)\n-        out = np.concatenate(out_grps, axis=-1).reshape(\n-            n_batch, h_out, w_out, ch_out\n-        )\n-        if data_format == \"channels_first\":\n-            out = out.transpose((0, 3, 1, 2))\n-        return out\n-\n-    def _np_conv3d(\n-        self,\n-        x,\n-        kernel_weights,\n-        bias_weights,\n-        strides,\n-        padding,\n-        data_format,\n-        dilation_rate,\n-        groups,\n-    ):\n-        if data_format == \"channels_first\":\n-            x = x.transpose((0, 2, 3, 4, 1))\n-        if isinstance(strides, (tuple, list)):\n-            h_stride, w_stride, d_stride = strides\n-        else:\n-            h_stride = strides\n-            w_stride = strides\n-            d_stride = strides\n-        if isinstance(dilation_rate, (tuple, list)):\n-            h_dilation, w_dilation, d_dilation = dilation_rate\n-        else:\n-            h_dilation = dilation_rate\n-            w_dilation = dilation_rate\n-            d_dilation = dilation_rate\n-\n-        h_kernel, w_kernel, d_kernel, ch_in, ch_out = kernel_weights.shape\n-\n-        if h_dilation > 1 or w_dilation > 1 or d_dilation > 1:\n-            new_h_kernel = h_kernel + (h_dilation - 1) * (h_kernel - 1)\n-            new_w_kernel = w_kernel + (w_dilation - 1) * (w_kernel - 1)\n-            new_d_kernel = d_kernel + (d_dilation - 1) * (d_kernel - 1)\n-            new_kenel_size_tuple = (new_h_kernel, new_w_kernel, new_d_kernel)\n-            new_kernel_weights = np.zeros(\n-                (*new_kenel_size_tuple, ch_in, ch_out),\n-                dtype=kernel_weights.dtype,\n-            )\n-            new_kernel_weights[\n-                ::h_dilation, ::w_dilation, ::d_dilation\n-            ] = kernel_weights\n-            kernel_weights = new_kernel_weights\n-            h_kernel, w_kernel, d_kernel = kernel_weights.shape[:3]\n-\n-        if padding == \"same\":\n-            n_batch, h_x, w_x, d_x, _ = x.shape\n-            h_pad = self._same_padding(h_x, h_kernel, h_stride)\n-            w_pad = self._same_padding(w_x, w_kernel, w_stride)\n-            d_pad = self._same_padding(d_x, d_kernel, d_stride)\n-            npad = [(0, 0)] * x.ndim\n-            npad[1] = h_pad\n-            npad[2] = w_pad\n-            npad[3] = d_pad\n-            x = np.pad(x, pad_width=npad, mode=\"constant\", constant_values=0)\n-\n-        n_batch, h_x, w_x, d_x, _ = x.shape\n-        h_out = int((h_x - h_kernel) / h_stride) + 1\n-        w_out = int((w_x - w_kernel) / w_stride) + 1\n-        d_out = int((d_x - d_kernel) / d_stride) + 1\n-\n-        out_grps = []\n-        for grp in range(1, groups + 1):\n-            x_in = x[..., (grp - 1) * ch_in : grp * ch_in]\n-            stride_shape = (\n-                n_batch,\n-                h_out,\n-                w_out,\n-                d_out,\n-                h_kernel,\n-                w_kernel,\n-                d_kernel,\n-                ch_in,\n-            )\n-            strides = (\n-                x_in.strides[0],\n-                h_stride * x_in.strides[1],\n-                w_stride * x_in.strides[2],\n-                d_stride * x_in.strides[3],\n-                x_in.strides[1],\n-                x_in.strides[2],\n-                x_in.strides[3],\n-                x_in.strides[4],\n-            )\n-            inner_dim = h_kernel * w_kernel * d_kernel * ch_in\n-            x_strided = as_strided(\n-                x_in, shape=stride_shape, strides=strides\n-            ).reshape(-1, inner_dim)\n-            ch_out_groups = ch_out // groups\n-            kernel_weights_grp = kernel_weights[\n-                ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n-            ].reshape(-1, ch_out_groups)\n-            bias_weights_grp = bias_weights[\n-                ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n-            ]\n-            out_grps.append(x_strided @ kernel_weights_grp + bias_weights_grp)\n-        out = np.concatenate(out_grps, axis=-1).reshape(\n-            n_batch, h_out, w_out, d_out, ch_out\n-        )\n-        if data_format == \"channels_first\":\n-            out = out.transpose((0, 4, 1, 2, 3))\n-        return out\n+        return np.concatenate(out_grps, axis=-1)\n \n     @parameterized.parameters(\n         {\n@@ -546,15 +364,6 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             \"dilation_rate\": 1,\n             \"groups\": 2,\n         },\n-        {\n-            \"filters\": 6,\n-            \"kernel_size\": (2,),\n-            \"strides\": (2,),\n-            \"padding\": \"valid\",\n-            \"data_format\": \"channels_first\",\n-            \"dilation_rate\": 1,\n-            \"groups\": 2,\n-        },\n     )\n     def test_conv1d(\n         self,\n@@ -626,15 +435,6 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             \"dilation_rate\": (2, 2),\n             \"groups\": 2,\n         },\n-        {\n-            \"filters\": 6,\n-            \"kernel_size\": 2,\n-            \"strides\": 1,\n-            \"padding\": \"same\",\n-            \"data_format\": \"channels_last\",\n-            \"dilation_rate\": (2, 3),\n-            \"groups\": 2,\n-        },\n         {\n             \"filters\": 6,\n             \"kernel_size\": (4, 3),\n@@ -644,15 +444,6 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             \"dilation_rate\": (1, 1),\n             \"groups\": 2,\n         },\n-        {\n-            \"filters\": 6,\n-            \"kernel_size\": (4, 3),\n-            \"strides\": (2, 1),\n-            \"padding\": \"valid\",\n-            \"data_format\": \"channels_first\",\n-            \"dilation_rate\": (1, 1),\n-            \"groups\": 2,\n-        },\n     )\n     def test_conv2d(\n         self,\n@@ -673,27 +464,31 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             dilation_rate=dilation_rate,\n             groups=groups,\n         )\n-\n-        inputs = np.random.normal(size=[2, 8, 8, 4])\n-        layer.build(input_shape=inputs.shape)\n-\n-        kernel_shape = layer.kernel.shape\n-        kernel_weights = np.random.normal(size=kernel_shape)\n-        bias_weights = np.random.normal(size=(filters,))\n-        layer.kernel.assign(kernel_weights)\n-        layer.bias.assign(bias_weights)\n-\n-        outputs = layer(inputs)\n-        expected = self._np_conv2d(\n-            inputs,\n-            kernel_weights,\n-            bias_weights,\n+        tf_keras_layer = tf.keras.layers.Conv2D(\n+            filters=filters,\n+            kernel_size=kernel_size,\n             strides=strides,\n             padding=padding,\n             data_format=data_format,\n             dilation_rate=dilation_rate,\n             groups=groups,\n         )\n+\n+        inputs = np.random.normal(size=[2, 8, 8, 4])\n+        layer.build(input_shape=inputs.shape)\n+        tf_keras_layer.build(input_shape=inputs.shape)\n+\n+        kernel_shape = layer.kernel.shape\n+        kernel_weights = np.random.normal(size=kernel_shape)\n+        bias_weights = np.random.normal(size=(filters,))\n+        layer.kernel.assign(kernel_weights)\n+        tf_keras_layer.kernel.assign(kernel_weights)\n+\n+        layer.bias.assign(bias_weights)\n+        tf_keras_layer.bias.assign(bias_weights)\n+\n+        outputs = layer(inputs)\n+        expected = tf_keras_layer(inputs)\n         self.assertAllClose(outputs, expected, rtol=5e-4)\n \n     @parameterized.parameters(\n@@ -715,15 +510,6 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             \"dilation_rate\": (2, 2, 2),\n             \"groups\": 2,\n         },\n-        {\n-            \"filters\": 6,\n-            \"kernel_size\": 2,\n-            \"strides\": 1,\n-            \"padding\": \"same\",\n-            \"data_format\": \"channels_last\",\n-            \"dilation_rate\": (2, 3, 4),\n-            \"groups\": 2,\n-        },\n         {\n             \"filters\": 6,\n             \"kernel_size\": (2, 2, 3),\n@@ -733,15 +519,6 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             \"dilation_rate\": (1, 1, 1),\n             \"groups\": 2,\n         },\n-        {\n-            \"filters\": 6,\n-            \"kernel_size\": (2, 2, 3),\n-            \"strides\": (2, 1, 2),\n-            \"padding\": \"valid\",\n-            \"data_format\": \"channels_first\",\n-            \"dilation_rate\": (1, 1, 1),\n-            \"groups\": 2,\n-        },\n     )\n     def test_conv3d(\n         self,\n@@ -762,25 +539,29 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             dilation_rate=dilation_rate,\n             groups=groups,\n         )\n-\n-        inputs = np.random.normal(size=[2, 8, 8, 8, 4])\n-        layer.build(input_shape=inputs.shape)\n-\n-        kernel_shape = layer.kernel.shape\n-        kernel_weights = np.random.normal(size=kernel_shape)\n-        bias_weights = np.random.normal(size=(filters,))\n-        layer.kernel.assign(kernel_weights)\n-        layer.bias.assign(bias_weights)\n-\n-        outputs = layer(inputs)\n-        expected = self._np_conv3d(\n-            inputs,\n-            kernel_weights,\n-            bias_weights,\n+        tf_keras_layer = tf.keras.layers.Conv3D(\n+            filters=filters,\n+            kernel_size=kernel_size,\n             strides=strides,\n             padding=padding,\n             data_format=data_format,\n             dilation_rate=dilation_rate,\n             groups=groups,\n         )\n+\n+        inputs = np.random.normal(size=[2, 8, 8, 8, 4])\n+        layer.build(input_shape=inputs.shape)\n+        tf_keras_layer.build(input_shape=inputs.shape)\n+\n+        kernel_shape = layer.kernel.shape\n+        kernel_weights = np.random.normal(size=kernel_shape)\n+        bias_weights = np.random.normal(size=(filters,))\n+        layer.kernel.assign(kernel_weights)\n+        tf_keras_layer.kernel.assign(kernel_weights)\n+\n+        layer.bias.assign(bias_weights)\n+        tf_keras_layer.bias.assign(bias_weights)\n+        outputs = layer(inputs)\n+\n+        expected = tf_keras_layer(inputs)\n         self.assertAllClose(outputs, expected, rtol=5e-4)\n\n@@ -323,7 +323,7 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n \n         outputs = layer(inputs)\n         expected = tf_keras_layer(inputs)\n-        self.assertAllClose(outputs, expected, atol=1e-5)\n+        self.assertAllClose(outputs, expected)\n \n     @parameterized.parameters(\n         {\n@@ -407,7 +407,7 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n \n         outputs = layer(inputs)\n         expected = tf_keras_layer(inputs)\n-        self.assertAllClose(outputs, expected, atol=1e-5)\n+        self.assertAllClose(outputs, expected)\n \n     @parameterized.parameters(\n         {\n\n@@ -326,6 +326,7 @@ class Layer(BackendLayer, Operation):\n \n     @utils.default\n     def build(self, input_shape):\n+        self._check_super_called()\n         if utils.is_default(self.build) and might_have_unbuilt_state(self):\n             warnings.warn(\n                 f\"`build()` was called on layer '{self.name}', however \"\n@@ -1267,6 +1268,7 @@ class Layer(BackendLayer, Operation):\n \n     @python_utils.default\n     def get_config(self):\n+        self._check_super_called()\n         base_config = super().get_config()\n         config = {\n             \"trainable\": self.trainable,\n\n@@ -94,16 +94,3 @@ class NormalizationTest(testing.TestCase, parameterized.TestCase):\n     def test_normalization_errors(self):\n         # TODO\n         pass\n-\n-    @pytest.mark.skipif(\n-        backend.backend() != \"torch\",\n-        reason=\"Test symbolic call for torch meta device.\",\n-    )\n-    def test_call_on_meta_device_after_built(self):\n-        from keras_core.backend.torch import core\n-\n-        layer = layers.Normalization()\n-        data = np.random.random((32, 4))\n-        layer.adapt(data)\n-        with core.device_scope(\"meta\"):\n-            layer(data)\n\n@@ -180,7 +180,7 @@ def map_graph(inputs, outputs):\n \n     Returns:\n         A tuple `(nodes, nodes_by_depth, operations, operations_by_depth)`.\n-        - network_nodes: dict mapping unique node keys to the Node instances\n+        - nodes: list of Node instances.\n         - nodes_by_depth: dict mapping ints (depth) to lists of node instances.\n         - operations: list of Operation instances.\n         - operations_by_depth: dict mapping ints (depth) to lists of Operation\n\n@@ -48,11 +48,10 @@ def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n \n     Example:\n \n-    >>> data = keras_core.ops.convert_to_tensor([1, 2, 10, 20, 100, 200])\n-    >>> segment_ids = keras_core.ops.convert_to_tensor([0, 0, 1, 1, 2, 2])\n-    >>> num_segments = 3\n-    >>> keras_core.ops.segment_sum(data, segment_ids,num_segments)\n-    array([3, 30, 300], dtype=int32)\n+    >>> data = keras_core.ops.convert_to_tensor([1, 2, 3, 4, 5, 6])\n+    >>> segment_ids = keras_core.ops.convert_to_tensor([0, 1, 0, 1, 0, 1])\n+    >>> segment_sum(data, segment_ids)\n+    array([9 12], shape=(2,), dtype=int32)\n     \"\"\"\n     if any_symbolic_tensors((data,)):\n         return SegmentSum(num_segments, sorted).symbolic_call(data, segment_ids)\n@@ -101,11 +100,10 @@ def segment_max(data, segment_ids, num_segments=None, sorted=False):\n \n     Example:\n \n-    >>> data = keras_core.ops.convert_to_tensor([1, 2, 10, 20, 100, 200])\n-    >>> segment_ids = keras_core.ops.convert_to_tensor([0, 0, 1, 1, 2, 2])\n-    >>> num_segments = 3\n-    >>> keras_core.ops.segment_max(data, segment_ids, num_segments)\n-    array([2, 20, 200], dtype=int32)\n+    >>> data = keras_core.ops.convert_to_tensor([1, 2, 3, 4, 5, 6])\n+    >>> segment_ids = keras_core.ops.convert_to_tensor([0, 1, 0, 1, 0, 1])\n+    >>> segment_max(data, segment_ids)\n+    array([9 12], shape=(2,), dtype=int32)\n     \"\"\"\n     if any_symbolic_tensors((data,)):\n         return SegmentMax(num_segments, sorted).symbolic_call(data, segment_ids)\n@@ -698,9 +696,8 @@ class Rsqrt(Operation):\n \n     Example:\n \n-    >>> data = keras_core.ops.convert_to_tensor([1.0, 10.0, 100.0])\n-    >>> keras_core.ops.rsqrt(data)\n-    array([1.0, 0.31622776, 0.1], dtype=float32)\n+    >>> x = keras_core.ops.convert_to_tensor([2., 3., -2.])\n+    >>> rsqrt(x)\n     \"\"\"\n \n     def call(self, x):\n\n@@ -1501,30 +1501,6 @@ class MultiHot(Operation):\n     ]\n )\n def multi_hot(inputs, num_tokens, axis=-1, dtype=None):\n-    \"\"\"Encodes integer labels as multi-hot vectors.\n-\n-    This function encodes integer labels as multi-hot vectors, where each label\n-    is mapped to a binary value in the resulting vector.\n-\n-    Args:\n-        inputs: Tensor of integer labels to be converted to multi-hot vectors.\n-        num_tokens: Integer, the total number of unique tokens or classes.\n-        axis: (optional) Axis along which the multi-hot encoding should be\n-            added. Default is -1, which corresponds to the last dimension.\n-        dtype: (optional) The data type of the resulting tensor. Default\n-            is backend's float type.\n-\n-    Returns:\n-        Tensor: The multi-hot encoded tensor.\n-\n-\n-    Example:\n-\n-    >>> data = keras_core.ops.convert_to_tensor([0, 4])\n-    >>> keras_core.ops.multi_hot(data, num_tokens=5)\n-    array([1.0, 0.0, 0.0, 0.0, 1.0], dtype=float32)\n-\n-    \"\"\"\n     if any_symbolic_tensors((inputs,)):\n         return MultiHot(num_tokens, axis, dtype).symbolic_call(inputs)\n \n\n@@ -165,6 +165,7 @@ def broadcast_shapes(shape1, shape2):\n         output_shape (list of integers or `None`): The broadcasted shape.\n \n     Example:\n+\n     >>> broadcast_shapes((5, 3), (1, 3))\n     [5, 3]\n     \"\"\"\n@@ -246,6 +247,7 @@ def absolute(x):\n         An array containing the absolute value of each element in `x`.\n \n     Example:\n+\n     >>> x = keras_core.ops.convert_to_tensor([-1.2, 1.2])\n     >>> keras_core.ops.absolute(x)\n     array([1.2 1.2], shape=(2,), dtype=float32)\n@@ -288,6 +290,7 @@ def add(x1, x2):\n         The tensor containing the element-wise sum of `x1` and `x2`.\n \n     Examples:\n+\n     >>> x1 = keras_core.ops.convert_to_tensor([1, 4])\n     >>> x2 = keras_core.ops.convert_to_tensor([5, 6])\n     >>> keras_core.ops.add(x1, x2)\n@@ -354,6 +357,7 @@ def all(x, axis=None, keepdims=False):\n         The tensor containing the logical AND reduction over the `axis`.\n \n     Examples:\n+\n     >>> x = keras_core.ops.convert_to_tensor([True, False])\n     >>> keras_core.ops.all(x)\n     array(False, shape=(), dtype=bool)\n@@ -418,6 +422,7 @@ def any(x, axis=None, keepdims=False):\n         The tensor containing the logical OR reduction over the `axis`.\n \n     Examples:\n+\n     >>> x = keras_core.ops.convert_to_tensor([True, False])\n     >>> keras_core.ops.any(x)\n     array(True, shape=(), dtype=bool)\n@@ -478,6 +483,7 @@ def amax(x, axis=None, keepdims=False):\n         the specified axis.\n \n     Examples:\n+\n     >>> x = keras_core.ops.convert_to_tensor([[1, 3, 5], [2, 3, 6]])\n     >>> keras_core.ops.amax(x)\n     array(6, dtype=int32)\n@@ -533,6 +539,7 @@ def amin(x, axis=None, keepdims=False):\n         the specified axis.\n \n     Examples:\n+\n     >>> x = keras_core.ops.convert_to_tensor([1, 3, 5, 2, 3, 6])\n     >>> keras_core.ops.amin(x)\n     array(1, dtype=int32)\n@@ -598,6 +605,7 @@ def append(\n         A tensor with the values of `x2` appended to `x1`.\n \n     Examples:\n+\n     >>> x1 = keras_core.ops.convert_to_tensor([1, 2, 3])\n     >>> x2 = keras_core.ops.convert_to_tensor([[4, 5, 6], [7, 8, 9]])\n     >>> keras_core.ops.append(x1, x2)\n@@ -667,6 +675,7 @@ def arange(start, stop=None, step=1, dtype=None):\n         rule may result in the last element of out being greater than stop.\n \n     Examples:\n+\n     >>> keras_core.ops.arange(3)\n     array([0, 1, 2], dtype=int32)\n \n@@ -705,8 +714,7 @@ def arccos(x):\n \n     Example:\n     >>> x = keras_core.ops.convert_to_tensor([1, -1])\n-    >>> keras_core.ops.arccos(x)\n-    array([0.0, 3.1415927], dtype=float32)\n+    array([0., 3.1415927], dtype=float32)\n     \"\"\"\n     if any_symbolic_tensors((x,)):\n         return Arccos().symbolic_call(x)\n@@ -729,11 +737,6 @@ def arccosh(x):\n \n     Returns:\n         Output tensor of same shape as x.\n-\n-    Example:\n-    >>> x = keras_core.ops.convert_to_tensor([10, 100])\n-    >>> keras_core.ops.arccosh(x)\n-    array([2.993223, 5.298292], dtype=float32)\n     \"\"\"\n     if any_symbolic_tensors((x,)):\n         return Arccosh().symbolic_call(x)\n@@ -786,11 +789,6 @@ def arcsinh(x):\n \n     Returns:\n         Output tensor of same shape as `x`.\n-\n-    Example:\n-    >>> x = keras_core.ops.convert_to_tensor([1, -1, 0])\n-    >>> keras_core.ops.arcsinh(x)\n-    array([0.88137364, -0.88137364, 0.0], dtype=float32)\n     \"\"\"\n     if any_symbolic_tensors((x,)):\n         return Arcsinh().symbolic_call(x)\n@@ -1334,6 +1332,7 @@ def clip(x, x_min, x_max):\n         x: Input tensor.\n         x_min: Minimum value.\n         x_max: Maximum value.\n+\n     Returns:\n         The clipped tensor.\n     \"\"\"\n@@ -1928,6 +1927,7 @@ def digitize(x, bins):\n         Output array of indices, of same shape as `x`.\n \n     Example:\n+\n     >>> x = np.array([0.0, 1.0, 3.0, 1.6])\n     >>> bins = np.array([0.0, 3.0, 4.5, 7.0])\n     >>> keras_core.ops.digitize(x, bins)\n\n@@ -1,4 +1,5 @@\n import numpy as np\n+import tensorflow as tf\n from absl.testing import parameterized\n \n from keras_core import backend\n@@ -55,20 +56,22 @@ class TestNumericalUtils(testing.TestCase, parameterized.TestCase):\n \n     @parameterized.parameters([1, 2, 3])\n     def test_normalize(self, order):\n+        xnp = np.random.random((3, 3))\n         xb = backend.random.uniform((3, 3), seed=1337)\n-        xnp = backend.convert_to_numpy(xb)\n-\n-        # Expected result\n-        l2 = np.atleast_1d(np.linalg.norm(xnp, order, axis=-1))\n-        l2[l2 == 0] = 1\n-        expected = xnp / np.expand_dims(l2, axis=-1)\n \n         # Test NumPy\n         out = numerical_utils.normalize(xnp, axis=-1, order=order)\n         self.assertTrue(isinstance(out, np.ndarray))\n-        self.assertAllClose(out, expected)\n+        self.assertAllClose(\n+            tf.keras.utils.normalize(xnp, axis=-1, order=order), out\n+        )\n \n         # Test backend\n         out = numerical_utils.normalize(xb, axis=-1, order=order)\n         self.assertTrue(backend.is_tensor(out))\n-        self.assertAllClose(backend.convert_to_numpy(out), expected)\n+        self.assertAllClose(\n+            tf.keras.utils.normalize(\n+                backend.convert_to_numpy(xb), axis=-1, order=order\n+            ),\n+            backend.convert_to_numpy(out),\n+        )\n\n@@ -30,14 +30,15 @@ def weight_memory_size(weights):\n     Returns:\n         The total memory size (in Bytes) of the weights.\n     \"\"\"\n-    unique_weights = {id(w): w for w in weights}.values()\n+    unique_weights_ids = set(id(w) for w in weights)\n+    unique_weights = [w for w in weights if id(w) in unique_weights_ids]\n     total_memory_size = 0\n     for w in unique_weights:\n         weight_shape = math.prod(w.shape)\n         dtype = backend.standardize_dtype(w.dtype)\n         per_param_size = dtype_utils.dtype_size(dtype)\n         total_memory_size += weight_shape * per_param_size\n-    return total_memory_size / 8\n+    return total_memory_size\n \n \n def readable_memory_size(weight_memory_size):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9c66631e4c953f1d9bc2ca895666a4d405377a0b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 346 | Lines Deleted: 88 | Files Changed: 10 | Hunks: 45 | Methods Changed: 30 | Complexity Δ (Sum/Max): 21/21 | Churn Δ: 434 | Churn Cumulative: 11308 | Contributors (this commit): 27 | Commits (past 90d): 161 | Contributors (cumulative): 60 | DMM Complexity: 0.0\n\nDIFF:\n@@ -109,6 +109,9 @@ class Variable(KerasVariable):\n \n def convert_to_tensor(x, dtype=None):\n     if is_tensor(x):\n+        device = get_device()\n+        if x.device != device:\n+            x = x.to(device)\n         if dtype is None:\n             return x\n         return x.to(to_torch_dtype(dtype))\n\n@@ -1,8 +1,5 @@\n-import math\n-\n import numpy as np\n import pytest\n-import tensorflow as tf\n from absl.testing import parameterized\n from numpy.lib.stride_tricks import as_strided\n \n@@ -249,11 +246,11 @@ class ConvBasicTest(testing.TestCase, parameterized.TestCase):\n \n class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n     def _same_padding(self, input_size, kernel_size, stride):\n-        # P = ((S-1)*W-S+K)/2, with K = kernel size, S = stride, W = input size\n-        padding = int(\n-            math.ceil(((stride - 1) * input_size - stride + kernel_size) / 2)\n-        )\n-        return padding\n+        if input_size % stride == 0:\n+            padding = max(kernel_size - stride, 0)\n+        else:\n+            padding = max(kernel_size - (input_size % stride), 0)\n+        return padding // 2, padding - padding // 2\n \n     def _np_conv1d(\n         self,\n@@ -292,9 +289,9 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             h_pad = self._same_padding(h_x, kernel_size, h_stride)\n             npad = [(0, 0)] * x.ndim\n             if padding == \"causal\":\n-                npad[1] = (h_pad * 2, 0)\n+                npad[1] = (h_pad[0] + h_pad[1], 0)\n             else:\n-                npad[1] = (h_pad, h_pad)\n+                npad[1] = h_pad\n             x = np.pad(x, pad_width=npad, mode=\"constant\", constant_values=0)\n \n         n_batch, h_x, _ = x.shape\n@@ -325,7 +322,192 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n                 ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n             ]\n             out_grps.append(x_strided @ kernel_weights_grp + bias_weights_grp)\n-        return np.concatenate(out_grps, axis=-1)\n+        out = np.concatenate(out_grps, axis=-1)\n+        if data_format == \"channels_first\":\n+            out = out.swapaxes(1, 2)\n+        return out\n+\n+    def _np_conv2d(\n+        self,\n+        x,\n+        kernel_weights,\n+        bias_weights,\n+        strides,\n+        padding,\n+        data_format,\n+        dilation_rate,\n+        groups,\n+    ):\n+        if data_format == \"channels_first\":\n+            x = x.transpose((0, 2, 3, 1))\n+        if isinstance(strides, (tuple, list)):\n+            h_stride, w_stride = strides\n+        else:\n+            h_stride = strides\n+            w_stride = strides\n+        if isinstance(dilation_rate, (tuple, list)):\n+            h_dilation, w_dilation = dilation_rate\n+        else:\n+            h_dilation = dilation_rate\n+            w_dilation = dilation_rate\n+        h_kernel, w_kernel, ch_in, ch_out = kernel_weights.shape\n+\n+        if h_dilation > 1 or w_dilation > 1:\n+            new_h_kernel = h_kernel + (h_dilation - 1) * (h_kernel - 1)\n+            new_w_kernel = w_kernel + (w_dilation - 1) * (w_kernel - 1)\n+            new_kenel_size_tuple = (new_h_kernel, new_w_kernel)\n+            new_kernel_weights = np.zeros(\n+                (*new_kenel_size_tuple, ch_in, ch_out),\n+                dtype=kernel_weights.dtype,\n+            )\n+            new_kernel_weights[::h_dilation, ::w_dilation] = kernel_weights\n+            kernel_weights = new_kernel_weights\n+            h_kernel, w_kernel = kernel_weights.shape[:2]\n+\n+        if padding == \"same\":\n+            n_batch, h_x, w_x, _ = x.shape\n+            h_pad = self._same_padding(h_x, h_kernel, h_stride)\n+            w_pad = self._same_padding(w_x, w_kernel, w_stride)\n+            npad = [(0, 0)] * x.ndim\n+            npad[1] = h_pad\n+            npad[2] = w_pad\n+            x = np.pad(x, pad_width=npad, mode=\"constant\", constant_values=0)\n+\n+        n_batch, h_x, w_x, _ = x.shape\n+        h_out = int((h_x - h_kernel) / h_stride) + 1\n+        w_out = int((w_x - w_kernel) / w_stride) + 1\n+\n+        out_grps = []\n+        for grp in range(1, groups + 1):\n+            x_in = x[..., (grp - 1) * ch_in : grp * ch_in]\n+            stride_shape = (n_batch, h_out, w_out, h_kernel, w_kernel, ch_in)\n+            strides = (\n+                x_in.strides[0],\n+                h_stride * x_in.strides[1],\n+                w_stride * x_in.strides[2],\n+                x_in.strides[1],\n+                x_in.strides[2],\n+                x_in.strides[3],\n+            )\n+            inner_dim = h_kernel * w_kernel * ch_in\n+            x_strided = as_strided(\n+                x_in, shape=stride_shape, strides=strides\n+            ).reshape(-1, inner_dim)\n+            ch_out_groups = ch_out // groups\n+            kernel_weights_grp = kernel_weights[\n+                ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n+            ].reshape(-1, ch_out_groups)\n+            bias_weights_grp = bias_weights[\n+                ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n+            ]\n+            out_grps.append(x_strided @ kernel_weights_grp + bias_weights_grp)\n+        out = np.concatenate(out_grps, axis=-1).reshape(\n+            n_batch, h_out, w_out, ch_out\n+        )\n+        if data_format == \"channels_first\":\n+            out = out.transpose((0, 3, 1, 2))\n+        return out\n+\n+    def _np_conv3d(\n+        self,\n+        x,\n+        kernel_weights,\n+        bias_weights,\n+        strides,\n+        padding,\n+        data_format,\n+        dilation_rate,\n+        groups,\n+    ):\n+        if data_format == \"channels_first\":\n+            x = x.transpose((0, 2, 3, 4, 1))\n+        if isinstance(strides, (tuple, list)):\n+            h_stride, w_stride, d_stride = strides\n+        else:\n+            h_stride = strides\n+            w_stride = strides\n+            d_stride = strides\n+        if isinstance(dilation_rate, (tuple, list)):\n+            h_dilation, w_dilation, d_dilation = dilation_rate\n+        else:\n+            h_dilation = dilation_rate\n+            w_dilation = dilation_rate\n+            d_dilation = dilation_rate\n+\n+        h_kernel, w_kernel, d_kernel, ch_in, ch_out = kernel_weights.shape\n+\n+        if h_dilation > 1 or w_dilation > 1 or d_dilation > 1:\n+            new_h_kernel = h_kernel + (h_dilation - 1) * (h_kernel - 1)\n+            new_w_kernel = w_kernel + (w_dilation - 1) * (w_kernel - 1)\n+            new_d_kernel = d_kernel + (d_dilation - 1) * (d_kernel - 1)\n+            new_kenel_size_tuple = (new_h_kernel, new_w_kernel, new_d_kernel)\n+            new_kernel_weights = np.zeros(\n+                (*new_kenel_size_tuple, ch_in, ch_out),\n+                dtype=kernel_weights.dtype,\n+            )\n+            new_kernel_weights[\n+                ::h_dilation, ::w_dilation, ::d_dilation\n+            ] = kernel_weights\n+            kernel_weights = new_kernel_weights\n+            h_kernel, w_kernel, d_kernel = kernel_weights.shape[:3]\n+\n+        if padding == \"same\":\n+            n_batch, h_x, w_x, d_x, _ = x.shape\n+            h_pad = self._same_padding(h_x, h_kernel, h_stride)\n+            w_pad = self._same_padding(w_x, w_kernel, w_stride)\n+            d_pad = self._same_padding(d_x, d_kernel, d_stride)\n+            npad = [(0, 0)] * x.ndim\n+            npad[1] = h_pad\n+            npad[2] = w_pad\n+            npad[3] = d_pad\n+            x = np.pad(x, pad_width=npad, mode=\"constant\", constant_values=0)\n+\n+        n_batch, h_x, w_x, d_x, _ = x.shape\n+        h_out = int((h_x - h_kernel) / h_stride) + 1\n+        w_out = int((w_x - w_kernel) / w_stride) + 1\n+        d_out = int((d_x - d_kernel) / d_stride) + 1\n+\n+        out_grps = []\n+        for grp in range(1, groups + 1):\n+            x_in = x[..., (grp - 1) * ch_in : grp * ch_in]\n+            stride_shape = (\n+                n_batch,\n+                h_out,\n+                w_out,\n+                d_out,\n+                h_kernel,\n+                w_kernel,\n+                d_kernel,\n+                ch_in,\n+            )\n+            strides = (\n+                x_in.strides[0],\n+                h_stride * x_in.strides[1],\n+                w_stride * x_in.strides[2],\n+                d_stride * x_in.strides[3],\n+                x_in.strides[1],\n+                x_in.strides[2],\n+                x_in.strides[3],\n+                x_in.strides[4],\n+            )\n+            inner_dim = h_kernel * w_kernel * d_kernel * ch_in\n+            x_strided = as_strided(\n+                x_in, shape=stride_shape, strides=strides\n+            ).reshape(-1, inner_dim)\n+            ch_out_groups = ch_out // groups\n+            kernel_weights_grp = kernel_weights[\n+                ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n+            ].reshape(-1, ch_out_groups)\n+            bias_weights_grp = bias_weights[\n+                ..., (grp - 1) * ch_out_groups : grp * ch_out_groups\n+            ]\n+            out_grps.append(x_strided @ kernel_weights_grp + bias_weights_grp)\n+        out = np.concatenate(out_grps, axis=-1).reshape(\n+            n_batch, h_out, w_out, d_out, ch_out\n+        )\n+        if data_format == \"channels_first\":\n+            out = out.transpose((0, 4, 1, 2, 3))\n+        return out\n \n     @parameterized.parameters(\n         {\n@@ -364,6 +546,15 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             \"dilation_rate\": 1,\n             \"groups\": 2,\n         },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": (2,),\n+            \"strides\": (2,),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_first\",\n+            \"dilation_rate\": 1,\n+            \"groups\": 2,\n+        },\n     )\n     def test_conv1d(\n         self,\n@@ -435,6 +626,15 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             \"dilation_rate\": (2, 2),\n             \"groups\": 2,\n         },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": 1,\n+            \"padding\": \"same\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (2, 3),\n+            \"groups\": 2,\n+        },\n         {\n             \"filters\": 6,\n             \"kernel_size\": (4, 3),\n@@ -444,6 +644,15 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             \"dilation_rate\": (1, 1),\n             \"groups\": 2,\n         },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": (4, 3),\n+            \"strides\": (2, 1),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_first\",\n+            \"dilation_rate\": (1, 1),\n+            \"groups\": 2,\n+        },\n     )\n     def test_conv2d(\n         self,\n@@ -464,31 +673,27 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             dilation_rate=dilation_rate,\n             groups=groups,\n         )\n-        tf_keras_layer = tf.keras.layers.Conv2D(\n-            filters=filters,\n-            kernel_size=kernel_size,\n+\n+        inputs = np.random.normal(size=[2, 8, 8, 4])\n+        layer.build(input_shape=inputs.shape)\n+\n+        kernel_shape = layer.kernel.shape\n+        kernel_weights = np.random.normal(size=kernel_shape)\n+        bias_weights = np.random.normal(size=(filters,))\n+        layer.kernel.assign(kernel_weights)\n+        layer.bias.assign(bias_weights)\n+\n+        outputs = layer(inputs)\n+        expected = self._np_conv2d(\n+            inputs,\n+            kernel_weights,\n+            bias_weights,\n             strides=strides,\n             padding=padding,\n             data_format=data_format,\n             dilation_rate=dilation_rate,\n             groups=groups,\n         )\n-\n-        inputs = np.random.normal(size=[2, 8, 8, 4])\n-        layer.build(input_shape=inputs.shape)\n-        tf_keras_layer.build(input_shape=inputs.shape)\n-\n-        kernel_shape = layer.kernel.shape\n-        kernel_weights = np.random.normal(size=kernel_shape)\n-        bias_weights = np.random.normal(size=(filters,))\n-        layer.kernel.assign(kernel_weights)\n-        tf_keras_layer.kernel.assign(kernel_weights)\n-\n-        layer.bias.assign(bias_weights)\n-        tf_keras_layer.bias.assign(bias_weights)\n-\n-        outputs = layer(inputs)\n-        expected = tf_keras_layer(inputs)\n         self.assertAllClose(outputs, expected, rtol=5e-4)\n \n     @parameterized.parameters(\n@@ -510,6 +715,15 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             \"dilation_rate\": (2, 2, 2),\n             \"groups\": 2,\n         },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": 2,\n+            \"strides\": 1,\n+            \"padding\": \"same\",\n+            \"data_format\": \"channels_last\",\n+            \"dilation_rate\": (2, 3, 4),\n+            \"groups\": 2,\n+        },\n         {\n             \"filters\": 6,\n             \"kernel_size\": (2, 2, 3),\n@@ -519,6 +733,15 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             \"dilation_rate\": (1, 1, 1),\n             \"groups\": 2,\n         },\n+        {\n+            \"filters\": 6,\n+            \"kernel_size\": (2, 2, 3),\n+            \"strides\": (2, 1, 2),\n+            \"padding\": \"valid\",\n+            \"data_format\": \"channels_first\",\n+            \"dilation_rate\": (1, 1, 1),\n+            \"groups\": 2,\n+        },\n     )\n     def test_conv3d(\n         self,\n@@ -539,29 +762,25 @@ class ConvCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             dilation_rate=dilation_rate,\n             groups=groups,\n         )\n-        tf_keras_layer = tf.keras.layers.Conv3D(\n-            filters=filters,\n-            kernel_size=kernel_size,\n+\n+        inputs = np.random.normal(size=[2, 8, 8, 8, 4])\n+        layer.build(input_shape=inputs.shape)\n+\n+        kernel_shape = layer.kernel.shape\n+        kernel_weights = np.random.normal(size=kernel_shape)\n+        bias_weights = np.random.normal(size=(filters,))\n+        layer.kernel.assign(kernel_weights)\n+        layer.bias.assign(bias_weights)\n+\n+        outputs = layer(inputs)\n+        expected = self._np_conv3d(\n+            inputs,\n+            kernel_weights,\n+            bias_weights,\n             strides=strides,\n             padding=padding,\n             data_format=data_format,\n             dilation_rate=dilation_rate,\n             groups=groups,\n         )\n-\n-        inputs = np.random.normal(size=[2, 8, 8, 8, 4])\n-        layer.build(input_shape=inputs.shape)\n-        tf_keras_layer.build(input_shape=inputs.shape)\n-\n-        kernel_shape = layer.kernel.shape\n-        kernel_weights = np.random.normal(size=kernel_shape)\n-        bias_weights = np.random.normal(size=(filters,))\n-        layer.kernel.assign(kernel_weights)\n-        tf_keras_layer.kernel.assign(kernel_weights)\n-\n-        layer.bias.assign(bias_weights)\n-        tf_keras_layer.bias.assign(bias_weights)\n-        outputs = layer(inputs)\n-\n-        expected = tf_keras_layer(inputs)\n         self.assertAllClose(outputs, expected, rtol=5e-4)\n\n@@ -323,7 +323,7 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n \n         outputs = layer(inputs)\n         expected = tf_keras_layer(inputs)\n-        self.assertAllClose(outputs, expected)\n+        self.assertAllClose(outputs, expected, atol=1e-5)\n \n     @parameterized.parameters(\n         {\n@@ -407,7 +407,7 @@ class ConvTransposeCorrectnessTest(testing.TestCase, parameterized.TestCase):\n \n         outputs = layer(inputs)\n         expected = tf_keras_layer(inputs)\n-        self.assertAllClose(outputs, expected)\n+        self.assertAllClose(outputs, expected, atol=1e-5)\n \n     @parameterized.parameters(\n         {\n\n@@ -94,3 +94,16 @@ class NormalizationTest(testing.TestCase, parameterized.TestCase):\n     def test_normalization_errors(self):\n         # TODO\n         pass\n+\n+    @pytest.mark.skipif(\n+        backend.backend() != \"torch\",\n+        reason=\"Test symbolic call for torch meta device.\",\n+    )\n+    def test_call_on_meta_device_after_built(self):\n+        from keras_core.backend.torch import core\n+\n+        layer = layers.Normalization()\n+        data = np.random.random((32, 4))\n+        layer.adapt(data)\n+        with core.device_scope(\"meta\"):\n+            layer(data)\n\n@@ -180,7 +180,7 @@ def map_graph(inputs, outputs):\n \n     Returns:\n         A tuple `(nodes, nodes_by_depth, operations, operations_by_depth)`.\n-        - nodes: list of Node instances.\n+        - network_nodes: dict mapping unique node keys to the Node instances\n         - nodes_by_depth: dict mapping ints (depth) to lists of node instances.\n         - operations: list of Operation instances.\n         - operations_by_depth: dict mapping ints (depth) to lists of Operation\n\n@@ -48,10 +48,11 @@ def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n \n     Example:\n \n-    >>> data = keras_core.ops.convert_to_tensor([1, 2, 3, 4, 5, 6])\n-    >>> segment_ids = keras_core.ops.convert_to_tensor([0, 1, 0, 1, 0, 1])\n-    >>> segment_sum(data, segment_ids)\n-    array([9 12], shape=(2,), dtype=int32)\n+    >>> data = keras_core.ops.convert_to_tensor([1, 2, 10, 20, 100, 200])\n+    >>> segment_ids = keras_core.ops.convert_to_tensor([0, 0, 1, 1, 2, 2])\n+    >>> num_segments = 3\n+    >>> keras_core.ops.segment_sum(data, segment_ids,num_segments)\n+    array([3, 30, 300], dtype=int32)\n     \"\"\"\n     if any_symbolic_tensors((data,)):\n         return SegmentSum(num_segments, sorted).symbolic_call(data, segment_ids)\n@@ -100,10 +101,11 @@ def segment_max(data, segment_ids, num_segments=None, sorted=False):\n \n     Example:\n \n-    >>> data = keras_core.ops.convert_to_tensor([1, 2, 3, 4, 5, 6])\n-    >>> segment_ids = keras_core.ops.convert_to_tensor([0, 1, 0, 1, 0, 1])\n-    >>> segment_max(data, segment_ids)\n-    array([9 12], shape=(2,), dtype=int32)\n+    >>> data = keras_core.ops.convert_to_tensor([1, 2, 10, 20, 100, 200])\n+    >>> segment_ids = keras_core.ops.convert_to_tensor([0, 0, 1, 1, 2, 2])\n+    >>> num_segments = 3\n+    >>> keras_core.ops.segment_max(data, segment_ids, num_segments)\n+    array([2, 20, 200], dtype=int32)\n     \"\"\"\n     if any_symbolic_tensors((data,)):\n         return SegmentMax(num_segments, sorted).symbolic_call(data, segment_ids)\n@@ -696,8 +698,9 @@ class Rsqrt(Operation):\n \n     Example:\n \n-    >>> x = keras_core.ops.convert_to_tensor([2., 3., -2.])\n-    >>> rsqrt(x)\n+    >>> data = keras_core.ops.convert_to_tensor([1.0, 10.0, 100.0])\n+    >>> keras_core.ops.rsqrt(data)\n+    array([1.0, 0.31622776, 0.1], dtype=float32)\n     \"\"\"\n \n     def call(self, x):\n\n@@ -1501,6 +1501,30 @@ class MultiHot(Operation):\n     ]\n )\n def multi_hot(inputs, num_tokens, axis=-1, dtype=None):\n+    \"\"\"Encodes integer labels as multi-hot vectors.\n+\n+    This function encodes integer labels as multi-hot vectors, where each label\n+    is mapped to a binary value in the resulting vector.\n+\n+    Args:\n+        inputs: Tensor of integer labels to be converted to multi-hot vectors.\n+        num_tokens: Integer, the total number of unique tokens or classes.\n+        axis: (optional) Axis along which the multi-hot encoding should be\n+            added. Default is -1, which corresponds to the last dimension.\n+        dtype: (optional) The data type of the resulting tensor. Default\n+            is backend's float type.\n+\n+    Returns:\n+        Tensor: The multi-hot encoded tensor.\n+\n+\n+    Example:\n+\n+    >>> data = keras_core.ops.convert_to_tensor([0, 4])\n+    >>> keras_core.ops.multi_hot(data, num_tokens=5)\n+    array([1.0, 0.0, 0.0, 0.0, 1.0], dtype=float32)\n+\n+    \"\"\"\n     if any_symbolic_tensors((inputs,)):\n         return MultiHot(num_tokens, axis, dtype).symbolic_call(inputs)\n \n\n@@ -165,7 +165,6 @@ def broadcast_shapes(shape1, shape2):\n         output_shape (list of integers or `None`): The broadcasted shape.\n \n     Example:\n-\n     >>> broadcast_shapes((5, 3), (1, 3))\n     [5, 3]\n     \"\"\"\n@@ -247,7 +246,6 @@ def absolute(x):\n         An array containing the absolute value of each element in `x`.\n \n     Example:\n-\n     >>> x = keras_core.ops.convert_to_tensor([-1.2, 1.2])\n     >>> keras_core.ops.absolute(x)\n     array([1.2 1.2], shape=(2,), dtype=float32)\n@@ -290,7 +288,6 @@ def add(x1, x2):\n         The tensor containing the element-wise sum of `x1` and `x2`.\n \n     Examples:\n-\n     >>> x1 = keras_core.ops.convert_to_tensor([1, 4])\n     >>> x2 = keras_core.ops.convert_to_tensor([5, 6])\n     >>> keras_core.ops.add(x1, x2)\n@@ -357,7 +354,6 @@ def all(x, axis=None, keepdims=False):\n         The tensor containing the logical AND reduction over the `axis`.\n \n     Examples:\n-\n     >>> x = keras_core.ops.convert_to_tensor([True, False])\n     >>> keras_core.ops.all(x)\n     array(False, shape=(), dtype=bool)\n@@ -422,7 +418,6 @@ def any(x, axis=None, keepdims=False):\n         The tensor containing the logical OR reduction over the `axis`.\n \n     Examples:\n-\n     >>> x = keras_core.ops.convert_to_tensor([True, False])\n     >>> keras_core.ops.any(x)\n     array(True, shape=(), dtype=bool)\n@@ -483,7 +478,6 @@ def amax(x, axis=None, keepdims=False):\n         the specified axis.\n \n     Examples:\n-\n     >>> x = keras_core.ops.convert_to_tensor([[1, 3, 5], [2, 3, 6]])\n     >>> keras_core.ops.amax(x)\n     array(6, dtype=int32)\n@@ -539,7 +533,6 @@ def amin(x, axis=None, keepdims=False):\n         the specified axis.\n \n     Examples:\n-\n     >>> x = keras_core.ops.convert_to_tensor([1, 3, 5, 2, 3, 6])\n     >>> keras_core.ops.amin(x)\n     array(1, dtype=int32)\n@@ -605,7 +598,6 @@ def append(\n         A tensor with the values of `x2` appended to `x1`.\n \n     Examples:\n-\n     >>> x1 = keras_core.ops.convert_to_tensor([1, 2, 3])\n     >>> x2 = keras_core.ops.convert_to_tensor([[4, 5, 6], [7, 8, 9]])\n     >>> keras_core.ops.append(x1, x2)\n@@ -675,7 +667,6 @@ def arange(start, stop=None, step=1, dtype=None):\n         rule may result in the last element of out being greater than stop.\n \n     Examples:\n-\n     >>> keras_core.ops.arange(3)\n     array([0, 1, 2], dtype=int32)\n \n@@ -714,7 +705,8 @@ def arccos(x):\n \n     Example:\n     >>> x = keras_core.ops.convert_to_tensor([1, -1])\n-    array([0., 3.1415927], dtype=float32)\n+    >>> keras_core.ops.arccos(x)\n+    array([0.0, 3.1415927], dtype=float32)\n     \"\"\"\n     if any_symbolic_tensors((x,)):\n         return Arccos().symbolic_call(x)\n@@ -737,6 +729,11 @@ def arccosh(x):\n \n     Returns:\n         Output tensor of same shape as x.\n+\n+    Example:\n+    >>> x = keras_core.ops.convert_to_tensor([10, 100])\n+    >>> keras_core.ops.arccosh(x)\n+    array([2.993223, 5.298292], dtype=float32)\n     \"\"\"\n     if any_symbolic_tensors((x,)):\n         return Arccosh().symbolic_call(x)\n@@ -789,6 +786,11 @@ def arcsinh(x):\n \n     Returns:\n         Output tensor of same shape as `x`.\n+\n+    Example:\n+    >>> x = keras_core.ops.convert_to_tensor([1, -1, 0])\n+    >>> keras_core.ops.arcsinh(x)\n+    array([0.88137364, -0.88137364, 0.0], dtype=float32)\n     \"\"\"\n     if any_symbolic_tensors((x,)):\n         return Arcsinh().symbolic_call(x)\n@@ -1332,7 +1334,6 @@ def clip(x, x_min, x_max):\n         x: Input tensor.\n         x_min: Minimum value.\n         x_max: Maximum value.\n-\n     Returns:\n         The clipped tensor.\n     \"\"\"\n@@ -1927,7 +1928,6 @@ def digitize(x, bins):\n         Output array of indices, of same shape as `x`.\n \n     Example:\n-\n     >>> x = np.array([0.0, 1.0, 3.0, 1.6])\n     >>> bins = np.array([0.0, 3.0, 4.5, 7.0])\n     >>> keras_core.ops.digitize(x, bins)\n\n@@ -1,5 +1,4 @@\n import numpy as np\n-import tensorflow as tf\n from absl.testing import parameterized\n \n from keras_core import backend\n@@ -56,22 +55,20 @@ class TestNumericalUtils(testing.TestCase, parameterized.TestCase):\n \n     @parameterized.parameters([1, 2, 3])\n     def test_normalize(self, order):\n-        xnp = np.random.random((3, 3))\n         xb = backend.random.uniform((3, 3), seed=1337)\n+        xnp = backend.convert_to_numpy(xb)\n+\n+        # Expected result\n+        l2 = np.atleast_1d(np.linalg.norm(xnp, order, axis=-1))\n+        l2[l2 == 0] = 1\n+        expected = xnp / np.expand_dims(l2, axis=-1)\n \n         # Test NumPy\n         out = numerical_utils.normalize(xnp, axis=-1, order=order)\n         self.assertTrue(isinstance(out, np.ndarray))\n-        self.assertAllClose(\n-            tf.keras.utils.normalize(xnp, axis=-1, order=order), out\n-        )\n+        self.assertAllClose(out, expected)\n \n         # Test backend\n         out = numerical_utils.normalize(xb, axis=-1, order=order)\n         self.assertTrue(backend.is_tensor(out))\n-        self.assertAllClose(\n-            tf.keras.utils.normalize(\n-                backend.convert_to_numpy(xb), axis=-1, order=order\n-            ),\n-            backend.convert_to_numpy(out),\n-        )\n+        self.assertAllClose(backend.convert_to_numpy(out), expected)\n\n@@ -30,15 +30,14 @@ def weight_memory_size(weights):\n     Returns:\n         The total memory size (in Bytes) of the weights.\n     \"\"\"\n-    unique_weights_ids = set(id(w) for w in weights)\n-    unique_weights = [w for w in weights if id(w) in unique_weights_ids]\n+    unique_weights = {id(w): w for w in weights}.values()\n     total_memory_size = 0\n     for w in unique_weights:\n         weight_shape = math.prod(w.shape)\n         dtype = backend.standardize_dtype(w.dtype)\n         per_param_size = dtype_utils.dtype_size(dtype)\n         total_memory_size += weight_shape * per_param_size\n-    return total_memory_size\n+    return total_memory_size / 8\n \n \n def readable_memory_size(weight_memory_size):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
