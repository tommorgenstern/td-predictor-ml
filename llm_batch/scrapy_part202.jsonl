{"custom_id": "scrapy#937277e8598bd3f62642d4d8267cec2defcead7c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 6 | Churn Cumulative: 719 | Contributors (this commit): 16 | Commits (past 90d): 6 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -159,7 +159,7 @@ def _get_clickable(clickdata, form):\n     # If we don't have clickdata, we just use the first clickable element\n     if clickdata is None:\n         el = clickables[0]\n-        return (el.get('name'), el.get('value'))\n+        return (el.get('name'), el.get('value') or '')\n \n     # If clickdata is given, we compare it to the clickable elements to find a\n     # match. We first look to see if the number is specified in clickdata,\n@@ -171,7 +171,7 @@ def _get_clickable(clickdata, form):\n         except IndexError:\n             pass\n         else:\n-            return (el.get('name'), el.get('value'))\n+            return (el.get('name'), el.get('value') or '')\n \n     # We didn't find it, so now we build an XPath expression out of the other\n     # arguments, because they can be used as such\n@@ -179,7 +179,7 @@ def _get_clickable(clickdata, form):\n             u''.join(u'[@%s=\"%s\"]' % c for c in six.iteritems(clickdata))\n     el = form.xpath(xpath)\n     if len(el) == 1:\n-        return (el[0].get('name'), el[0].get('value'))\n+        return (el[0].get('name'), el[0].get('value') or '')\n     elif len(el) > 1:\n         raise ValueError(\"Multiple elements found (%r) matching the criteria \"\n                          \"in clickdata: %r\" % (el, clickdata))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#ca83a0b02880aad8c34f48ac81c7005880f5140e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 12 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 29 | Churn Cumulative: 158 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4,11 +4,15 @@ Downloader Middleware manager\n See documentation in docs/topics/downloader-middleware.rst\n \"\"\"\n import six\n+\n+from twisted.internet import defer\n+\n from scrapy.http import Request, Response\n from scrapy.middleware import MiddlewareManager\n from scrapy.utils.defer import mustbe_deferred\n from scrapy.utils.conf import build_component_list\n \n+\n class DownloaderMiddlewareManager(MiddlewareManager):\n \n     component_name = 'downloader middleware'\n@@ -27,40 +31,45 @@ class DownloaderMiddlewareManager(MiddlewareManager):\n             self.methods['process_exception'].insert(0, mw.process_exception)\n \n     def download(self, download_func, request, spider):\n+        @defer.inlineCallbacks\n         def process_request(request):\n             for method in self.methods['process_request']:\n-                response = method(request=request, spider=spider)\n+                response = yield method(request=request, spider=spider)\n                 assert response is None or isinstance(response, (Response, Request)), \\\n                         'Middleware %s.process_request must return None, Response or Request, got %s' % \\\n                         (six.get_method_self(method).__class__.__name__, response.__class__.__name__)\n                 if response:\n-                    return response\n-            return download_func(request=request, spider=spider)\n+                    defer.returnValue(response)\n+            defer.returnValue((yield download_func(request=request,spider=spider)))\n \n+        @defer.inlineCallbacks\n         def process_response(response):\n             assert response is not None, 'Received None in process_response'\n             if isinstance(response, Request):\n-                return response\n+                defer.returnValue(response)\n \n             for method in self.methods['process_response']:\n-                response = method(request=request, response=response, spider=spider)\n+                response = yield method(request=request, response=response,\n+                                        spider=spider)\n                 assert isinstance(response, (Response, Request)), \\\n                     'Middleware %s.process_response must return Response or Request, got %s' % \\\n                     (six.get_method_self(method).__class__.__name__, type(response))\n                 if isinstance(response, Request):\n-                    return response\n-            return response\n+                    defer.returnValue(response)\n+            defer.returnValue(response)\n \n+        @defer.inlineCallbacks\n         def process_exception(_failure):\n             exception = _failure.value\n             for method in self.methods['process_exception']:\n-                response = method(request=request, exception=exception, spider=spider)\n+                response = yield method(request=request, exception=exception,\n+                                        spider=spider)\n                 assert response is None or isinstance(response, (Response, Request)), \\\n                     'Middleware %s.process_exception must return None, Response or Request, got %s' % \\\n                     (six.get_method_self(method).__class__.__name__, type(response))\n                 if response:\n-                    return response\n-            return _failure\n+                    defer.returnValue(response)\n+            defer.returnValue(_failure)\n \n         deferred = mustbe_deferred(process_request, request)\n         deferred.addErrback(process_exception)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#9ce9a293a6e0eefcb43f61d38d5f7ccc655d7889", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 56 | Lines Deleted: 53 | Files Changed: 2 | Hunks: 22 | Methods Changed: 19 | Complexity Δ (Sum/Max): 0/4 | Churn Δ: 109 | Churn Cumulative: 333 | Contributors (this commit): 7 | Commits (past 90d): 4 | Contributors (cumulative): 10 | DMM Complexity: 0.0\n\nDIFF:\n@@ -8,6 +8,7 @@ import logging\n \n from six.moves.urllib import robotparser\n \n+from twisted.internet.defer import Deferred, maybeDeferred\n from scrapy.exceptions import NotConfigured, IgnoreRequest\n from scrapy.http import Request\n from scrapy.utils.httpobj import urlparse_cached\n@@ -34,17 +35,22 @@ class RobotsTxtMiddleware(object):\n     def process_request(self, request, spider):\n         if request.meta.get('dont_obey_robotstxt'):\n             return\n-        rp = self.robot_parser(request, spider)\n-        if rp and not rp.can_fetch(self._useragent, request.url):\n+        d = maybeDeferred(self.robot_parser, request, spider)\n+        d.addCallback(self.process_request_2, request, spider)\n+        return d\n+\n+    def process_request_2(self, rp, request, spider):\n+        if rp is not None and not rp.can_fetch(self._useragent, request.url):\n             logger.debug(\"Forbidden by robots.txt: %(request)s\",\n                          {'request': request}, extra={'spider': spider})\n-            raise IgnoreRequest\n+            raise IgnoreRequest()\n \n     def robot_parser(self, request, spider):\n         url = urlparse_cached(request)\n         netloc = url.netloc\n+\n         if netloc not in self._parsers:\n-            self._parsers[netloc] = None\n+            self._parsers[netloc] = Deferred()\n             robotsurl = \"%s://%s/robots.txt\" % (url.scheme, url.netloc)\n             robotsreq = Request(\n                 robotsurl,\n@@ -52,8 +58,18 @@ class RobotsTxtMiddleware(object):\n                 meta={'dont_obey_robotstxt': True}\n             )\n             dfd = self.crawler.engine.download(robotsreq, spider)\n-            dfd.addCallback(self._parse_robots)\n+            dfd.addCallback(self._parse_robots, netloc)\n             dfd.addErrback(self._logerror, robotsreq, spider)\n+            dfd.addErrback(self._robots_error, netloc)\n+\n+        if isinstance(self._parsers[netloc], Deferred):\n+            d = Deferred()\n+            def cb(result):\n+                d.callback(result)\n+                return result\n+            self._parsers[netloc].addCallback(cb)\n+            return d\n+        else:\n             return self._parsers[netloc]\n \n     def _logerror(self, failure, request, spider):\n@@ -62,8 +78,9 @@ class RobotsTxtMiddleware(object):\n                          {'request': request, 'f_exception': failure.value},\n                          exc_info=failure_to_exc_info(failure),\n                          extra={'spider': spider})\n+        return failure\n \n-    def _parse_robots(self, response):\n+    def _parse_robots(self, response, netloc):\n         rp = robotparser.RobotFileParser(response.url)\n         body = ''\n         if hasattr(response, 'body_as_unicode'):\n@@ -78,4 +95,10 @@ class RobotsTxtMiddleware(object):\n                 # 'disallow all' to 'allow any'.\n                 pass\n         rp.parse(body.splitlines())\n-        self._parsers[urlparse_cached(response).netloc] = rp\n+\n+        rp_dfd = self._parsers[netloc]\n+        self._parsers[netloc] = rp\n+        rp_dfd.callback(rp)\n+\n+    def _robots_error(self, failure, netloc):\n+        self._parsers.pop(netloc).callback(None)\n\n@@ -1,7 +1,7 @@\n from __future__ import absolute_import\n import re\n from twisted.internet import reactor, error\n-from twisted.internet.defer import Deferred\n+from twisted.internet.defer import Deferred, DeferredList, maybeDeferred\n from twisted.python import failure\n from twisted.trial import unittest\n from scrapy.downloadermiddlewares.robotstxt import RobotsTxtMiddleware\n@@ -44,32 +44,20 @@ class RobotsTxtMiddlewareTest(unittest.TestCase):\n \n     def test_robotstxt(self):\n         middleware = RobotsTxtMiddleware(self._get_successful_crawler())\n-        # There is a bit of neglect in robotstxt.py: robots.txt is fetched asynchronously,\n-        # and it is actually fetched only *after* first process_request completes.\n-        # So, first process_request will always succeed.\n-        # We defer test() because otherwise robots.txt download mock will be called after assertRaises failure.\n-        self.assertNotIgnored(Request('http://site.local'), middleware)\n-        def test(r):\n-            self.assertNotIgnored(Request('http://site.local/allowed'), middleware)\n-            self.assertIgnored(Request('http://site.local/admin/main'), middleware)\n+        return DeferredList([\n+            self.assertNotIgnored(Request('http://site.local/allowed'), middleware),\n+            self.assertIgnored(Request('http://site.local/admin/main'), middleware),\n             self.assertIgnored(Request('http://site.local/static/'), middleware)\n-        deferred = Deferred()\n-        deferred.addCallback(test)\n-        reactor.callFromThread(deferred.callback, None)\n-        return deferred\n+        ], fireOnOneErrback=True)\n \n     def test_robotstxt_meta(self):\n         middleware = RobotsTxtMiddleware(self._get_successful_crawler())\n         meta = {'dont_obey_robotstxt': True}\n-        self.assertNotIgnored(Request('http://site.local', meta=meta), middleware)\n-        def test(r):\n-            self.assertNotIgnored(Request('http://site.local/allowed', meta=meta), middleware)\n-            self.assertNotIgnored(Request('http://site.local/admin/main', meta=meta), middleware)\n+        return DeferredList([\n+            self.assertNotIgnored(Request('http://site.local/allowed', meta=meta), middleware),\n+            self.assertNotIgnored(Request('http://site.local/admin/main', meta=meta), middleware),\n             self.assertNotIgnored(Request('http://site.local/static/', meta=meta), middleware)\n-        deferred = Deferred()\n-        deferred.addCallback(test)\n-        reactor.callFromThread(deferred.callback, None)\n-        return deferred\n+        ], fireOnOneErrback=True)\n \n     def _get_garbage_crawler(self):\n         crawler = self.crawler\n@@ -85,17 +73,12 @@ class RobotsTxtMiddlewareTest(unittest.TestCase):\n     def test_robotstxt_garbage(self):\n         # garbage response should be discarded, equal 'allow all'\n         middleware = RobotsTxtMiddleware(self._get_garbage_crawler())\n-        middleware._logerror = mock.MagicMock()\n-        middleware.process_request(Request('http://site.local'), None)\n-        self.assertNotIgnored(Request('http://site.local'), middleware)\n-        def test(r):\n-            self.assertNotIgnored(Request('http://site.local/allowed'), middleware)\n-            self.assertNotIgnored(Request('http://site.local/admin/main'), middleware)\n+        deferred = DeferredList([\n+            self.assertNotIgnored(Request('http://site.local'), middleware),\n+            self.assertNotIgnored(Request('http://site.local/allowed'), middleware),\n+            self.assertNotIgnored(Request('http://site.local/admin/main'), middleware),\n             self.assertNotIgnored(Request('http://site.local/static/'), middleware)\n-        deferred = Deferred()\n-        deferred.addCallback(test)\n-        deferred.addErrback(lambda _: self.assertIsNone(middleware._logerror.assert_any_call()))\n-        reactor.callFromThread(deferred.callback, None)\n+        ], fireOnOneErrback=True)\n         return deferred\n \n     def _get_emptybody_crawler(self):\n@@ -112,15 +95,11 @@ class RobotsTxtMiddlewareTest(unittest.TestCase):\n     def test_robotstxt_empty_response(self):\n         # empty response should equal 'allow all'\n         middleware = RobotsTxtMiddleware(self._get_emptybody_crawler())\n-        self.assertNotIgnored(Request('http://site.local'), middleware)\n-        def test(r):\n-            self.assertNotIgnored(Request('http://site.local/allowed'), middleware)\n-            self.assertNotIgnored(Request('http://site.local/admin/main'), middleware)\n+        return DeferredList([\n+            self.assertNotIgnored(Request('http://site.local/allowed'), middleware),\n+            self.assertNotIgnored(Request('http://site.local/admin/main'), middleware),\n             self.assertNotIgnored(Request('http://site.local/static/'), middleware)\n-        deferred = Deferred()\n-        deferred.addCallback(test)\n-        reactor.callFromThread(deferred.callback, None)\n-        return deferred\n+        ], fireOnOneErrback=True)\n \n     def test_robotstxt_error(self):\n         self.crawler.settings.set('ROBOTSTXT_OBEY', True)\n@@ -132,17 +111,18 @@ class RobotsTxtMiddlewareTest(unittest.TestCase):\n         self.crawler.engine.download.side_effect = return_failure\n \n         middleware = RobotsTxtMiddleware(self.crawler)\n-        middleware._logerror = mock.MagicMock()\n-        middleware.process_request(Request('http://site.local'), None)\n-        deferred = Deferred()\n-        deferred.addErrback(lambda _: self.assertIsNone(middleware._logerror.assert_any_call()))\n-        reactor.callFromThread(deferred.callback, None)\n+        middleware._logerror = mock.MagicMock(side_effect=lambda fail, req, spider: fail)\n+        deferred = middleware.process_request(Request('http://site.local'), None)\n+        deferred.addCallback(lambda _: self.assertTrue(middleware._logerror.called))\n         return deferred\n \n     def assertNotIgnored(self, request, middleware):\n         spider = None  # not actually used\n-        self.assertIsNone(middleware.process_request(request, spider))\n+        dfd = maybeDeferred(middleware.process_request, request, spider)\n+        dfd.addCallback(self.assertIsNone)\n+        return dfd\n \n     def assertIgnored(self, request, middleware):\n         spider = None  # not actually used\n-        self.assertRaises(IgnoreRequest, middleware.process_request, request, spider)\n+        return self.assertFailure(maybeDeferred(middleware.process_request, request, spider),\n+                                  IgnoreRequest)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#a6a629e707c5bdaa0601fad6edf9074fe3b2533b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 280 | Contributors (this commit): 7 | Commits (past 90d): 3 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -111,7 +111,7 @@ class RobotsTxtMiddlewareTest(unittest.TestCase):\n         self.crawler.engine.download.side_effect = return_failure\n \n         middleware = RobotsTxtMiddleware(self.crawler)\n-        middleware._logerror = mock.MagicMock(side_effect=lambda fail, req, spider: fail)\n+        middleware._logerror = mock.MagicMock(side_effect=middleware._logerror)\n         deferred = middleware.process_request(Request('http://site.local'), None)\n         deferred.addCallback(lambda _: self.assertTrue(middleware._logerror.called))\n         return deferred\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#668e5fd25706171fe227f2f161aa331435560849", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 6 | Churn Cumulative: 286 | Contributors (this commit): 7 | Commits (past 90d): 4 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -50,6 +50,12 @@ class RobotsTxtMiddlewareTest(unittest.TestCase):\n             self.assertIgnored(Request('http://site.local/static/'), middleware)\n         ], fireOnOneErrback=True)\n \n+    def test_robotstxt_ready_parser(self):\n+        middleware = RobotsTxtMiddleware(self._get_successful_crawler())\n+        d = self.assertNotIgnored(Request('http://site.local/allowed'), middleware)\n+        d.addCallback(lambda _: self.assertNotIgnored(Request('http://site.local/allowed'), middleware))\n+        return d\n+\n     def test_robotstxt_meta(self):\n         middleware = RobotsTxtMiddleware(self._get_successful_crawler())\n         meta = {'dont_obey_robotstxt': True}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#1f4af9d81eeb1c54288f647b6dfb6de8bccffa3f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 18 | Churn Cumulative: 304 | Contributors (this commit): 7 | Commits (past 90d): 5 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4,7 +4,8 @@ from twisted.internet import reactor, error\n from twisted.internet.defer import Deferred, DeferredList, maybeDeferred\n from twisted.python import failure\n from twisted.trial import unittest\n-from scrapy.downloadermiddlewares.robotstxt import RobotsTxtMiddleware\n+from scrapy.downloadermiddlewares.robotstxt import (RobotsTxtMiddleware,\n+                                                    logger as mw_module_logger)\n from scrapy.exceptions import IgnoreRequest, NotConfigured\n from scrapy.http import Request, Response, TextResponse\n from scrapy.settings import Settings\n@@ -122,6 +123,21 @@ class RobotsTxtMiddlewareTest(unittest.TestCase):\n         deferred.addCallback(lambda _: self.assertTrue(middleware._logerror.called))\n         return deferred\n \n+    def test_ignore_robotstxt_request(self):\n+        self.crawler.settings.set('ROBOTSTXT_OBEY', True)\n+        def ignore_request(request, spider):\n+            deferred = Deferred()\n+            reactor.callFromThread(deferred.errback, failure.Failure(IgnoreRequest()))\n+            return deferred\n+        self.crawler.engine.download.side_effect = ignore_request\n+\n+        middleware = RobotsTxtMiddleware(self.crawler)\n+        mw_module_logger.error = mock.MagicMock()\n+\n+        d = self.assertNotIgnored(Request('http://site.local/allowed'), middleware)\n+        d.addCallback(lambda _: self.assertFalse(mw_module_logger.error.called))\n+        return d\n+\n     def assertNotIgnored(self, request, middleware):\n         spider = None  # not actually used\n         dfd = maybeDeferred(middleware.process_request, request, spider)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#2748b38592b7f66634b47a782ba571769de8b048", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 22 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 22 | Churn Cumulative: 29 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -5,6 +5,7 @@ from scrapy.http import Request, Response\n from scrapy.spiders import Spider\n from scrapy.core.downloader.middleware import DownloaderMiddlewareManager\n from scrapy.utils.test import get_crawler\n+from tests import mock\n \n \n class ManagerTestCase(TestCase):\n@@ -90,3 +91,24 @@ class DefaultsTest(ManagerTestCase):\n             'Location': 'http://example.com/login',\n         })\n         self.assertRaises(IOError, self._download, request=req, response=resp)\n+\n+\n+class ResponseFromProcessRequestTest(ManagerTestCase):\n+    \"\"\"Tests middleware returning a response from process_request.\"\"\"\n+\n+    def test_download_func_not_called(self):\n+        class ResponseMiddleware(object):\n+            def process_request(self, request, spider):\n+                return Response(request.url)\n+\n+        self.mwman._add_middleware(ResponseMiddleware())\n+\n+        req = Request('http://example.com/index.html')\n+        download_func = mock.MagicMock()\n+        dfd = self.mwman.download(download_func, req, self.spider)\n+        results = []\n+        dfd.addBoth(results.append)\n+        self._wait(dfd)\n+\n+        self.assertIsInstance(results[0], Response)\n+        self.assertFalse(download_func.called)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#dd83f6123d54493661ae00ef668a5c2ee7d4e199", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 35 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -97,9 +97,11 @@ class ResponseFromProcessRequestTest(ManagerTestCase):\n     \"\"\"Tests middleware returning a response from process_request.\"\"\"\n \n     def test_download_func_not_called(self):\n+        resp = Response('http://example.com/index.html')\n+\n         class ResponseMiddleware(object):\n             def process_request(self, request, spider):\n-                return Response(request.url)\n+                return resp\n \n         self.mwman._add_middleware(ResponseMiddleware())\n \n@@ -110,5 +112,5 @@ class ResponseFromProcessRequestTest(ManagerTestCase):\n         dfd.addBoth(results.append)\n         self._wait(dfd)\n \n-        self.assertIsInstance(results[0], Response)\n+        self.assertIs(results[0], resp)\n         self.assertFalse(download_func.called)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#d9fddabe959ae93e4f4a50c04f6306a4e79a2af8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 514 | Contributors (this commit): 11 | Commits (past 90d): 5 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -38,7 +38,7 @@ def iflatten(x):\n     Similar to ``.flatten()``, but returns iterator instead\"\"\"\n     for el in x:\n         if is_listlike(el):\n-            for el_ in flatten(el):\n+            for el_ in iflatten(el):\n                 yield el_\n         else:\n             yield el\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#d022d3cb9e05ce66d602e0ee0120f2c25f1533ae", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 12 | Churn Cumulative: 526 | Contributors (this commit): 11 | Commits (past 90d): 6 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -257,19 +257,13 @@ def equal_attributes(obj1, obj2, attributes):\n     if not attributes:\n         return False\n \n+    temp1, temp2 = object(), object()\n     for attr in attributes:\n         # support callables like itemgetter\n         if callable(attr):\n-            if not attr(obj1) == attr(obj2):\n+            if attr(obj1) != attr(obj2):\n                 return False\n-        else:\n-            # check that objects has attribute\n-            if not hasattr(obj1, attr):\n-                return False\n-            if not hasattr(obj2, attr):\n-                return False\n-            # compare object attributes\n-            if not getattr(obj1, attr) == getattr(obj2, attr):\n+        elif getattr(obj1, attr, temp1) != getattr(obj2, attr, temp2):\n             return False\n     # all attributes equal\n     return True\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#faf9265c91e35c2e14c4fb78731ec694cce63d56", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 286 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -9,8 +9,7 @@ import webbrowser\n import tempfile\n \n from twisted.web import http\n-from twisted.web.http import RESPONSES\n-from scrapy.utils.python import to_bytes\n+from scrapy.utils.python import to_bytes, to_native_str\n from w3lib import html\n \n from scrapy.utils.decorators import deprecated\n@@ -55,7 +54,7 @@ def response_status_message(status):\n     >>> response_status_message(404)\n     '404 Not Found'\n     \"\"\"\n-    return '%s %s' % (status, http.responses.get(int(status)))\n+    return '%s %s' % (status, to_native_str(http.RESPONSES.get(int(status))))\n \n \n def response_httprepr(response):\n@@ -64,7 +63,7 @@ def response_httprepr(response):\n     that was received (that's not exposed by Twisted).\n     \"\"\"\n     s = b\"HTTP/1.1 \" + to_bytes(str(response.status)) + b\" \" + \\\n-        to_bytes(RESPONSES.get(response.status, b'')) + b\"\\r\\n\"\n+        to_bytes(http.RESPONSES.get(response.status, b'')) + b\"\\r\\n\"\n     if response.headers:\n         s += response.headers.to_string() + b\"\\r\\n\"\n     s += b\"\\r\\n\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#1f95af3c07da64621a86de643ffd993423baacd3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 145 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 8 | Methods Changed: 11 | Complexity Δ (Sum/Max): 14/9 | Churn Δ: 149 | Churn Cumulative: 172 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -24,16 +24,46 @@ class ItemLoader(object):\n     default_output_processor = Identity()\n     default_selector_class = Selector\n \n-    def __init__(self, item=None, selector=None, response=None, **context):\n+    def __init__(self, item=None, selector=None, response=None, parent=None, **context):\n         if selector is None and response is not None:\n             selector = self.default_selector_class(response)\n         self.selector = selector\n         context.update(selector=selector, response=response)\n         if item is None:\n             item = self.default_item_class()\n-        self.item = context['item'] = item\n         self.context = context\n-        self._values = defaultdict(list)\n+        self.parent = parent\n+        self._local_item = context['item'] = item\n+        self._local_values = defaultdict(list)\n+\n+    @property\n+    def _values(self):\n+        if self.parent is not None:\n+            return self.parent._values\n+        else:\n+            return self._local_values\n+\n+    @property\n+    def item(self):\n+        if self.parent is not None:\n+            return self.parent.item\n+        else:\n+            return self._local_item\n+\n+    def nested_loader(self, xpath=None, css=None):\n+        if xpath is not None and css is not None:\n+            raise ValueError(\"Cannot nest a loader with both a xpath selector and a css selector\")\n+\n+        if xpath is not None:\n+            selector = self.selector.xpath(xpath)\n+\n+        if css is not None:\n+            selector = self.selector.css(css)\n+\n+        subloader = self.__class__(\n+            item=self.item, selector=selector, parent=self\n+        )\n+        return subloader\n \n     def add_value(self, field_name, value, *processors, **kw):\n         value = self.get_value(value, *processors, **kw)\n@@ -84,6 +114,10 @@ class ItemLoader(object):\n             value = self.get_output_value(field_name)\n             if value is not None:\n                 item[field_name] = value\n+\n+        # for loader in self._subloaders:\n+        #     loader.load_item()\n+\n         return item\n \n     def get_output_value(self, field_name):\n@@ -168,5 +202,4 @@ class ItemLoader(object):\n         csss = arg_to_iter(csss)\n         return flatten([self.selector.css(css).extract() for css in csss])\n \n-\n XPathItemLoader = create_deprecated_class('XPathItemLoader', ItemLoader)\n\n@@ -19,11 +19,24 @@ class TestItem(NameItem):\n     summary = Field()\n \n \n+class TestNestedItem(Item):\n+    name = Field()\n+    name_div = Field()\n+    name_value = Field()\n+\n+    url = Field()\n+    image = Field()\n+\n+\n # test item loaders\n class NameItemLoader(ItemLoader):\n     default_item_class = TestItem\n \n \n+class NestedItemLoader(ItemLoader):\n+    default_item_class = TestNestedItem\n+\n+\n class TestItemLoader(NameItemLoader):\n     name_in = MapCompose(lambda v: v.title())\n \n@@ -600,6 +613,101 @@ class SelectortemLoaderTest(unittest.TestCase):\n         self.assertEqual(l.get_output_value('url'), [u'scrapy.org'])\n \n \n+class SubselectorLoaderTest(unittest.TestCase):\n+    response = HtmlResponse(url=\"\", encoding='utf-8', body=b\"\"\"\n+    <html>\n+    <body>\n+    <header>\n+      <div id=\"id\">marta</div>\n+      <p>paragraph</p>\n+    </header>\n+    <footer class=\"footer\">\n+      <a href=\"http://www.scrapy.org\">homepage</a>\n+      <img src=\"/images/logo.png\" width=\"244\" height=\"65\" alt=\"Scrapy\">\n+    </footer>\n+    </body>\n+    </html>\n+    \"\"\")\n+\n+    def test_nested_xpath(self):\n+        l = NestedItemLoader(response=self.response)\n+        nl = l.nested_loader(xpath=\"//header\")\n+        nl.add_xpath('name', 'div/text()')\n+        nl.add_css('name_div', '#id')\n+        nl.add_value('name_value', nl.selector.xpath('div[@id = \"id\"]/text()').extract())\n+\n+        self.assertEqual(l.get_output_value('name'), [u'marta'])\n+        self.assertEqual(l.get_output_value('name_div'), [u'<div id=\"id\">marta</div>'])\n+        self.assertEqual(l.get_output_value('name_value'),  [u'marta'])\n+\n+        self.assertEqual(l.get_output_value('name'), nl.get_output_value('name'))\n+        self.assertEqual(l.get_output_value('name_div'), nl.get_output_value('name_div'))\n+        self.assertEqual(l.get_output_value('name_value'), nl.get_output_value('name_value'))\n+\n+    def test_nested_css(self):\n+        l = NestedItemLoader(response=self.response)\n+        nl = l.nested_loader(css=\"header\")\n+        nl.add_xpath('name', 'div/text()')\n+        nl.add_css('name_div', '#id')\n+        nl.add_value('name_value', nl.selector.xpath('div[@id = \"id\"]/text()').extract())\n+\n+        self.assertEqual(l.get_output_value('name'), [u'marta'])\n+        self.assertEqual(l.get_output_value('name_div'), [u'<div id=\"id\">marta</div>'])\n+        self.assertEqual(l.get_output_value('name_value'),  [u'marta'])\n+\n+        self.assertEqual(l.get_output_value('name'), nl.get_output_value('name'))\n+        self.assertEqual(l.get_output_value('name_div'), nl.get_output_value('name_div'))\n+        self.assertEqual(l.get_output_value('name_value'), nl.get_output_value('name_value'))\n+\n+    def test_nested_replace(self):\n+        l = NestedItemLoader(response=self.response)\n+        nl1 = l.nested_loader(xpath='//footer')\n+        nl2 = nl1.nested_loader(xpath='a')\n+\n+        l.add_xpath('url', '//footer/a/@href')\n+        self.assertEqual(l.get_output_value('url'), [u'http://www.scrapy.org'])\n+        nl1.replace_xpath('url', 'img/@src')\n+        self.assertEqual(l.get_output_value('url'), [u'/images/logo.png'])\n+        nl2.replace_xpath('url', '@href')\n+        self.assertEqual(l.get_output_value('url'), [u'http://www.scrapy.org'])\n+\n+    def test_nested_ordering(self):\n+        l = NestedItemLoader(response=self.response)\n+        nl1 = l.nested_loader(xpath='//footer')\n+        nl2 = nl1.nested_loader(xpath='a')\n+\n+        nl1.add_xpath('url', 'img/@src')\n+        l.add_xpath('url', '//footer/a/@href')\n+        nl2.add_xpath('url', 'text()')\n+        l.add_xpath('url', '//footer/a/@href')\n+\n+        self.assertEqual(l.get_output_value('url'), [\n+            u'/images/logo.png',\n+            u'http://www.scrapy.org',\n+            u'homepage',\n+            u'http://www.scrapy.org',\n+        ])\n+\n+    def test_nested_load_item(self):\n+        l = NestedItemLoader(response=self.response)\n+        nl1 = l.nested_loader(xpath='//footer')\n+        nl2 = nl1.nested_loader(xpath='img')\n+\n+        l.add_xpath('name', '//header/div/text()')\n+        nl1.add_xpath('url', 'a/@href')\n+        nl2.add_xpath('image', '@src')\n+\n+        item = l.load_item()\n+\n+        assert item is l.item\n+        assert item is nl1.item\n+        assert item is nl2.item\n+\n+        self.assertEqual(item['name'], [u'marta'])\n+        self.assertEqual(item['url'], [u'http://www.scrapy.org'])\n+        self.assertEqual(item['image'], [u'/images/logo.png'])\n+\n+\n class SelectJmesTestCase(unittest.TestCase):\n         test_list_equals = {\n             'simple': ('foo.bar', {\"foo\": {\"bar\": \"baz\"}}, \"baz\"),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#425e35ee9023f5a973869d7e0d926297d9f75c35", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 8 | Churn Cumulative: 180 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -115,9 +115,6 @@ class ItemLoader(object):\n             if value is not None:\n                 item[field_name] = value\n \n-        # for loader in self._subloaders:\n-        #     loader.load_item()\n-\n         return item\n \n     def get_output_value(self, field_name):\n\n@@ -707,6 +707,11 @@ class SubselectorLoaderTest(unittest.TestCase):\n         self.assertEqual(item['url'], [u'http://www.scrapy.org'])\n         self.assertEqual(item['image'], [u'/images/logo.png'])\n \n+    def test_nested_bad_arguments(self):\n+        l = NestedItemLoader(response=self.response)\n+        with self.assertRaises(ValueError):\n+            l.nested_loader(css=\"#id\", xpath=\"//footer\")\n+\n \n class SelectJmesTestCase(unittest.TestCase):\n         test_list_equals = {\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#311d5cd495c7bb82c39a85dd85438871518ea165", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 23 | Files Changed: 2 | Hunks: 9 | Methods Changed: 9 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 42 | Churn Cumulative: 222 | Contributors (this commit): 4 | Commits (past 90d): 7 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -50,18 +50,19 @@ class ItemLoader(object):\n         else:\n             return self._local_item\n \n-    def nested_loader(self, xpath=None, css=None):\n-        if xpath is not None and css is not None:\n-            raise ValueError(\"Cannot nest a loader with both a xpath selector and a css selector\")\n-\n-        if xpath is not None:\n+    def nested_xpath(self, xpath, **context):\n         selector = self.selector.xpath(xpath)\n-\n-        if css is not None:\n-            selector = self.selector.css(css)\n-\n+        context.update(selector=selector)\n         subloader = self.__class__(\n-            item=self.item, selector=selector, parent=self\n+            item=self.item, parent=self, **context\n+        )\n+        return subloader\n+\n+    def nested_css(self, css, **context):\n+        selector = self.selector.css(css)\n+        context.update(selector=selector)\n+        subloader = self.__class__(\n+            item=self.item, parent=self, **context\n         )\n         return subloader\n \n\n@@ -631,7 +631,7 @@ class SubselectorLoaderTest(unittest.TestCase):\n \n     def test_nested_xpath(self):\n         l = NestedItemLoader(response=self.response)\n-        nl = l.nested_loader(xpath=\"//header\")\n+        nl = l.nested_xpath(\"//header\")\n         nl.add_xpath('name', 'div/text()')\n         nl.add_css('name_div', '#id')\n         nl.add_value('name_value', nl.selector.xpath('div[@id = \"id\"]/text()').extract())\n@@ -646,7 +646,7 @@ class SubselectorLoaderTest(unittest.TestCase):\n \n     def test_nested_css(self):\n         l = NestedItemLoader(response=self.response)\n-        nl = l.nested_loader(css=\"header\")\n+        nl = l.nested_css(\"header\")\n         nl.add_xpath('name', 'div/text()')\n         nl.add_css('name_div', '#id')\n         nl.add_value('name_value', nl.selector.xpath('div[@id = \"id\"]/text()').extract())\n@@ -661,8 +661,8 @@ class SubselectorLoaderTest(unittest.TestCase):\n \n     def test_nested_replace(self):\n         l = NestedItemLoader(response=self.response)\n-        nl1 = l.nested_loader(xpath='//footer')\n-        nl2 = nl1.nested_loader(xpath='a')\n+        nl1 = l.nested_xpath('//footer')\n+        nl2 = nl1.nested_xpath('a')\n \n         l.add_xpath('url', '//footer/a/@href')\n         self.assertEqual(l.get_output_value('url'), [u'http://www.scrapy.org'])\n@@ -673,8 +673,8 @@ class SubselectorLoaderTest(unittest.TestCase):\n \n     def test_nested_ordering(self):\n         l = NestedItemLoader(response=self.response)\n-        nl1 = l.nested_loader(xpath='//footer')\n-        nl2 = nl1.nested_loader(xpath='a')\n+        nl1 = l.nested_xpath('//footer')\n+        nl2 = nl1.nested_xpath('a')\n \n         nl1.add_xpath('url', 'img/@src')\n         l.add_xpath('url', '//footer/a/@href')\n@@ -690,8 +690,8 @@ class SubselectorLoaderTest(unittest.TestCase):\n \n     def test_nested_load_item(self):\n         l = NestedItemLoader(response=self.response)\n-        nl1 = l.nested_loader(xpath='//footer')\n-        nl2 = nl1.nested_loader(xpath='img')\n+        nl1 = l.nested_xpath('//footer')\n+        nl2 = nl1.nested_xpath('img')\n \n         l.add_xpath('name', '//header/div/text()')\n         nl1.add_xpath('url', 'a/@href')\n@@ -707,11 +707,6 @@ class SubselectorLoaderTest(unittest.TestCase):\n         self.assertEqual(item['url'], [u'http://www.scrapy.org'])\n         self.assertEqual(item['image'], [u'/images/logo.png'])\n \n-    def test_nested_bad_arguments(self):\n-        l = NestedItemLoader(response=self.response)\n-        with self.assertRaises(ValueError):\n-            l.nested_loader(css=\"#id\", xpath=\"//footer\")\n-\n \n class SelectJmesTestCase(unittest.TestCase):\n         test_list_equals = {\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#be7821a48200e784e26f7b6160d44a854953b12e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 11 | Files Changed: 7 | Hunks: 9 | Methods Changed: 9 | Complexity Δ (Sum/Max): -4/2 | Churn Δ: 22 | Churn Cumulative: 2954 | Contributors (this commit): 22 | Commits (past 90d): 18 | Contributors (cumulative): 56 | DMM Complexity: None\n\nDIFF:\n@@ -62,7 +62,7 @@ class Command(ScrapyCommand):\n             self.settings['SPIDER_CONTRACTS_BASE'],\n             self.settings['SPIDER_CONTRACTS'],\n         )\n-        conman = ContractsManager([load_object(c) for c in contracts])\n+        conman = ContractsManager(load_object(c) for c in contracts)\n         runner = TextTestRunner(verbosity=2 if opts.verbose else 1)\n         result = TextTestResult(runner.stream, runner.descriptions, runner.verbosity)\n \n\n@@ -88,8 +88,8 @@ class Command(ScrapyCommand):\n             'module': module,\n             'name': name,\n             'domain': domain,\n-            'classname': '%sSpider' % ''.join([s.capitalize() \\\n-                for s in module.split('_')])\n+            'classname': '%sSpider' % ''.join(s.capitalize() \\\n+                for s in module.split('_'))\n         }\n         spiders_module = import_module(self.settings['NEWSPIDER_MODULE'])\n         spiders_dir = abspath(dirname(spiders_module.__file__))\n\n@@ -173,7 +173,7 @@ class CrawlerRunner(object):\n \n         Returns a deferred that is fired when they all have ended.\n         \"\"\"\n-        return defer.DeferredList([c.stop() for c in list(self.crawlers)])\n+        return defer.DeferredList([c.stop() for c in self.crawlers])\n \n     @defer.inlineCallbacks\n     def join(self):\n\n@@ -69,7 +69,7 @@ class ItemLoader(object):\n         regex = kw.get('re', None)\n         if regex:\n             value = arg_to_iter(value)\n-            value = flatten([extract_regex(regex, x) for x in value])\n+            value = flatten(extract_regex(regex, x) for x in value)\n \n         for proc in processors:\n             if value is None:\n@@ -149,7 +149,7 @@ class ItemLoader(object):\n     def _get_xpathvalues(self, xpaths, **kw):\n         self._check_selector_method()\n         xpaths = arg_to_iter(xpaths)\n-        return flatten([self.selector.xpath(xpath).extract() for xpath in xpaths])\n+        return flatten(self.selector.xpath(xpath).extract() for xpath in xpaths)\n \n     def add_css(self, field_name, css, *processors, **kw):\n         values = self._get_cssvalues(css, **kw)\n@@ -166,7 +166,7 @@ class ItemLoader(object):\n     def _get_cssvalues(self, csss, **kw):\n         self._check_selector_method()\n         csss = arg_to_iter(csss)\n-        return flatten([self.selector.css(css).extract() for css in csss])\n+        return flatten(self.selector.css(css).extract() for css in csss)\n \n \n XPathItemLoader = create_deprecated_class('XPathItemLoader', ItemLoader)\n\n@@ -146,7 +146,7 @@ class Shell(object):\n                      \"update local objects\")\n         b.append(\"  view(response)    View response in a browser\")\n \n-        return \"\\n\".join([\"[s] %s\" % l for l in b])\n+        return \"\\n\".join(\"[s] %s\" % l for l in b)\n \n     def _is_relevant(self, value):\n         return isinstance(value, self.relevant_classes)\n\n@@ -61,7 +61,7 @@ def parallel(iterable, count, callable, *args, **named):\n     \"\"\"\n     coop = task.Cooperator()\n     work = (callable(elem, *args, **named) for elem in iterable)\n-    return defer.DeferredList([coop.coiterate(work) for i in range(count)])\n+    return defer.DeferredList([coop.coiterate(work) for _ in range(count)])\n \n def process_chain(callbacks, input, *a, **kw):\n     \"\"\"Return a Deferred built by chaining the given callbacks\"\"\"\n\n@@ -44,8 +44,8 @@ def request_fingerprint(request, include_headers=None):\n \n     \"\"\"\n     if include_headers:\n-        include_headers = tuple([to_bytes(h.lower())\n-                                 for h in sorted(include_headers)])\n+        include_headers = tuple(to_bytes(h.lower())\n+                                 for h in sorted(include_headers))\n     cache = _fingerprint_cache.setdefault(request, {})\n     if include_headers not in cache:\n         fp = hashlib.sha1()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#9a64d8ff97f2b188d2be8a1d7944a47790adda2c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 14 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -19,7 +19,7 @@ class MarshalFifoDiskQueueTest(t.FifoDiskQueueTest):\n     chunksize = 100000\n \n     def queue(self):\n-        return MarshalFifoDiskQueue(self.qdir, chunksize=self.chunksize)\n+        return MarshalFifoDiskQueue(self.qpath, chunksize=self.chunksize)\n \n     def test_serialize(self):\n         q = self.queue()\n@@ -54,7 +54,7 @@ class PickleFifoDiskQueueTest(MarshalFifoDiskQueueTest):\n     chunksize = 100000\n \n     def queue(self):\n-        return PickleFifoDiskQueue(self.qdir, chunksize=self.chunksize)\n+        return PickleFifoDiskQueue(self.qpath, chunksize=self.chunksize)\n \n     def test_serialize_item(self):\n         q = self.queue()\n@@ -99,7 +99,7 @@ class ChunkSize4PickleFifoDiskQueueTest(PickleFifoDiskQueueTest):\n class MarshalLifoDiskQueueTest(t.LifoDiskQueueTest):\n \n     def queue(self):\n-        return MarshalLifoDiskQueue(self.path)\n+        return MarshalLifoDiskQueue(self.qpath)\n \n     def test_serialize(self):\n         q = self.queue()\n@@ -120,7 +120,7 @@ class MarshalLifoDiskQueueTest(t.LifoDiskQueueTest):\n class PickleLifoDiskQueueTest(MarshalLifoDiskQueueTest):\n \n     def queue(self):\n-        return PickleLifoDiskQueue(self.path)\n+        return PickleLifoDiskQueue(self.qpath)\n \n     def test_serialize_item(self):\n         q = self.queue()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#563b1500bf384e104169ee214bed328833658843", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 9 | Churn Cumulative: 119 | Contributors (this commit): 6 | Commits (past 90d): 2 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,5 +1,6 @@\n-import logging\n from collections import defaultdict\n+import logging\n+import pprint\n \n from scrapy.exceptions import NotConfigured\n from scrapy.utils.misc import load_object\n@@ -43,11 +44,9 @@ class MiddlewareManager(object):\n                     logger.warning(\"Disabled %(clsname)s: %(eargs)s\",\n                                    {'clsname': clsname, 'eargs': e.args[0]},\n                                    extra={'crawler': crawler})\n-\n-        enabled = [x.__class__.__name__ for x in middlewares]\n-        logger.info(\"Enabled %(componentname)ss: %(enabledlist)s\",\n+        logger.info(\"Enabled %(componentname)ss:\\n%(enabledlist)s\",\n                     {'componentname': cls.component_name,\n-                     'enabledlist': ', '.join(enabled)},\n+                     'enabledlist': pprint.pformat(mwlist)},\n                     extra={'crawler': crawler})\n         return cls(*middlewares)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
