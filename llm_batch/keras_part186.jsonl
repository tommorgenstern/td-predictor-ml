{"custom_id": "keras#0c237ebea2633afbb92809da07734b9bac82a9c5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 9744 | Contributors (this commit): 42 | Commits (past 90d): 37 | Contributors (cumulative): 42 | DMM Complexity: None\n\nDIFF:\n@@ -1571,7 +1571,7 @@ class Cropping2D(Layer):\n         model.add(Cropping2D(cropping=((2, 2), (4, 4)),\n                              input_shape=(28, 28, 3)))\n         # now model.output_shape == (None, 24, 20, 3)\n-        model.add(Conv2D(64, (3, 3), padding='same))\n+        model.add(Conv2D(64, (3, 3), padding='same'))\n         model.add(Cropping2D(cropping=((2, 2), (2, 2))))\n         # now model.output_shape == (None, 20, 16. 64)\n     ```\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0ddc3360b74d86c5bcf09578998899685e49eaa8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 13 | Files Changed: 1 | Hunks: 8 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 34 | Churn Cumulative: 1131 | Contributors (this commit): 14 | Commits (past 90d): 6 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -8,9 +8,7 @@ Index\n - Getting started\n     Getting started with the sequential model\n     Getting started with the functional api\n-    Examples\n     FAQ\n-    Installation guide\n \n - Models\n     About Keras models\n@@ -26,18 +24,23 @@ Index\n         explain common layer functions: get_weights, set_weights, get_config\n         explain input_shape\n         explain usage on non-Keras tensors\n-    Core layers\n-    Convolutional\n-    Recurrent\n-    Embeddings\n-    Normalization\n-    Advanced activations\n-    Noise\n+    Core Layers\n+    Convolutional Layers\n+    Pooling Layers\n+    Locally-connected Layers\n+    Recurrent Layers\n+    Embedding Layers\n+    Merge Layers\n+    Advanced Activations Layers\n+    Normalization Layers\n+    Noise Layers\n+    Layer Wrappers\n+    Writing your own Keras layers\n \n - Preprocessing\n-    Image preprocessing\n-    Text preprocessing\n-    Sequence preprocessing\n+    Sequence Preprocessing\n+    Text Preprocessing\n+    Image Preprocessing\n \n Losses\n Metrics\n@@ -45,12 +48,15 @@ Optimizers\n Activations\n Callbacks\n Datasets\n+Applications\n Backend\n-Initializations\n+Initializers\n Regularizers\n Constraints\n Visualization\n Scikit-learn API\n+Utils\n+Contributing\n \n '''\n from __future__ import print_function\n@@ -509,3 +515,5 @@ for page_data in PAGES:\n     if not os.path.exists(subdir):\n         os.makedirs(subdir)\n     open(path, 'w').write(mkdown)\n+\n+shutil.copyfile('../CONTRIBUTING.md', 'sources/contributing.md')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f1df88737c107668df54d4f521758b6da7e844ec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 8 | Churn Cumulative: 2551 | Contributors (this commit): 44 | Commits (past 90d): 12 | Contributors (cumulative): 44 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3,6 +3,7 @@ from __future__ import print_function\n \n import os\n import csv\n+import six\n \n import numpy as np\n import time\n@@ -861,16 +862,17 @@ class CSVLogger(Callback):\n         self.writer = None\n         self.keys = None\n         self.append_header = True\n+        self.file_flags = 'b' if six.PY2 and os.name == 'nt' else ''\n         super(CSVLogger, self).__init__()\n \n     def on_train_begin(self, logs=None):\n         if self.append:\n             if os.path.exists(self.filename):\n-                with open(self.filename) as f:\n+                with open(self.filename, 'r' + self.file_flags) as f:\n                     self.append_header = not bool(len(f.readline()))\n-            self.csv_file = open(self.filename, 'a')\n+            self.csv_file = open(self.filename, 'a' + self.file_flags)\n         else:\n-            self.csv_file = open(self.filename, 'w')\n+            self.csv_file = open(self.filename, 'w' + self.file_flags)\n \n     def on_epoch_end(self, epoch, logs=None):\n         logs = logs or {}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c627fa5bbdb37d9f196486b27b5cec7445ab7704", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 321 | Contributors (this commit): 11 | Commits (past 90d): 20 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -20,4 +20,4 @@ from . import regularizers\n # Importable from root because it's technically not a layer\r\n from .layers import Input\r\n \r\n-__version__ = '2.0.3'\r\n+__version__ = '2.0.4'\r\n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='2.0.3',\n+      version='2.0.4',\n       description='Deep Learning for Python',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/fchollet/keras',\n-      download_url='https://github.com/fchollet/keras/tarball/2.0.3',\n+      download_url='https://github.com/fchollet/keras/tarball/2.0.4',\n       license='MIT',\n       install_requires=['theano', 'pyyaml', 'six'],\n       extras_require={\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c430b6c49222166d7a2c425705a80ac5a4ac2b65", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 13 | Churn Cumulative: 9126 | Contributors (this commit): 65 | Commits (past 90d): 35 | Contributors (cumulative): 65 | DMM Complexity: 0.0\n\nDIFF:\n@@ -167,7 +167,7 @@ def save_model(model, filepath, overwrite=True, include_optimizer=True):\n     f.close()\n \n \n-def load_model(filepath, custom_objects=None):\n+def load_model(filepath, custom_objects=None, compile=True):\n     \"\"\"Loads a model saved via `save_model`.\n \n     # Arguments\n@@ -175,12 +175,16 @@ def load_model(filepath, custom_objects=None):\n         custom_objects: Optional dictionary mapping names\n             (strings) to custom classes or functions to be\n             considered during deserialization.\n+        compile: Boolean, whether to compile the model\n+            after loading.\n \n     # Returns\n         A Keras model instance. If an optimizer was found\n         as part of the saved model, the model is already\n         compiled. Otherwise, the model is uncompiled and\n-        a warning will be displayed.\n+        a warning will be displayed. When `compile` is set\n+        to False, the compilation is omitted without any\n+        warning.\n \n     # Raises\n         ImportError: if h5py is not available.\n@@ -242,6 +246,11 @@ def load_model(filepath, custom_objects=None):\n     # set weights\n     topology.load_weights_from_hdf5_group(f['model_weights'], model.layers)\n \n+    # Early return if compilation is not required.\n+    if not compile:\n+        f.close()\n+        return model\n+\n     # instantiate optimizer\n     training_config = f.attrs.get('training_config')\n     if training_config is None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1a707ea11e9a71e5cdf8095c70cc9cb8574d10c0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 2555 | Contributors (this commit): 45 | Commits (past 90d): 13 | Contributors (cumulative): 45 | DMM Complexity: 1.0\n\nDIFF:\n@@ -879,7 +879,9 @@ class CSVLogger(Callback):\n \n         def handle_value(k):\n             is_zero_dim_ndarray = isinstance(k, np.ndarray) and k.ndim == 0\n-            if isinstance(k, Iterable) and not is_zero_dim_ndarray:\n+            if isinstance(k, six.string_types):\n+                return k\n+            elif isinstance(k, Iterable) and not is_zero_dim_ndarray:\n                 return '\"[%s]\"' % (', '.join(map(str, k)))\n             else:\n                 return k\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a736c2632b315d8c6ee54369df89c31695c70591", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 2 | Files Changed: 3 | Hunks: 9 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 16918 | Contributors (this commit): 122 | Commits (past 90d): 124 | Contributors (cumulative): 181 | DMM Complexity: 0.8333333333333334\n\nDIFF:\n@@ -2187,9 +2187,10 @@ class Function(object):\n         inputs: Feed placeholders to the computation graph.\n         outputs: Output tensors to fetch.\n         updates: Additional update ops to be run at function call.\n+        name: a name to help users identify what this function does.\n     \"\"\"\n \n-    def __init__(self, inputs, outputs, updates=None):\n+    def __init__(self, inputs, outputs, updates=None, name=None):\n         updates = updates or []\n         if not isinstance(inputs, (list, tuple)):\n             raise TypeError('`inputs` to a TensorFlow backend function '\n@@ -2212,6 +2213,7 @@ class Function(object):\n                     # assumed already an op\n                     updates_ops.append(update)\n             self.updates_op = tf.group(*updates_ops)\n+        self.name = name\n \n     def __call__(self, inputs):\n         if not isinstance(inputs, (list, tuple)):\n\n@@ -1142,7 +1142,7 @@ def print_tensor(x, message=''):\n \n class Function(object):\n \n-    def __init__(self, inputs, outputs, updates=[], **kwargs):\n+    def __init__(self, inputs, outputs, updates=[], name=None, **kwargs):\n         unique_variables_to_update = {}\n         for v, nv in updates:\n             if v not in unique_variables_to_update:\n@@ -1151,7 +1151,9 @@ class Function(object):\n         self.function = theano.function(inputs, outputs, updates=updates,\n                                         allow_input_downcast=True,\n                                         on_unused_input='ignore',\n+                                        name=name,\n                                         **kwargs)\n+        self.name = name\n \n     def __call__(self, inputs):\n         assert isinstance(inputs, (list, tuple))\n\n@@ -1016,6 +1016,7 @@ class Model(Container):\n             self.train_function = K.function(inputs,\n                                              [self.total_loss] + self.metrics_tensors,\n                                              updates=updates,\n+                                             name='train_function',\n                                              **self._function_kwargs)\n \n     def _make_test_function(self):\n@@ -1030,6 +1031,7 @@ class Model(Container):\n             self.test_function = K.function(inputs,\n                                             [self.total_loss] + self.metrics_tensors,\n                                             updates=self.state_updates,\n+                                            name='test_function',\n                                             **self._function_kwargs)\n \n     def _make_predict_function(self):\n@@ -1046,6 +1048,7 @@ class Model(Container):\n             self.predict_function = K.function(inputs,\n                                                self.outputs,\n                                                updates=self.state_updates,\n+                                               name='predict_function',\n                                                **kwargs)\n \n     def _fit_loop(self, f, ins, out_labels=None, batch_size=32,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fdd822c03ed8eeb03e18de931d1694e10cc01ea1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 72 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 77 | Churn Cumulative: 3444 | Contributors (this commit): 46 | Commits (past 90d): 19 | Contributors (cumulative): 56 | DMM Complexity: 0.6296296296296297\n\nDIFF:\n@@ -632,12 +632,36 @@ class TensorBoard(Callback):\n                     tf.summary.histogram(weight.name, weight)\n                     if self.write_images:\n                         w_img = tf.squeeze(weight)\n-                        shape = w_img.get_shape()\n-                        if len(shape) > 1 and shape[0] > shape[1]:\n+                        shape = K.int_shape(w_img)\n+                        if len(shape) == 2:  # dense layer kernel case\n+                            if shape[0] > shape[1]:\n                                 w_img = tf.transpose(w_img)\n-                        if len(shape) == 1:\n-                            w_img = tf.expand_dims(w_img, 0)\n-                        w_img = tf.expand_dims(tf.expand_dims(w_img, 0), -1)\n+                                shape = K.int_shape(w_img)\n+                            w_img = tf.reshape(w_img, [1,\n+                                                       shape[0],\n+                                                       shape[1],\n+                                                       1])\n+                        elif len(shape) == 3:  # convnet case\n+                            if K.image_data_format() == 'channels_last':\n+                                # switch to channels_first to display\n+                                # every kernel as a separate image\n+                                w_img = tf.transpose(w_img, perm=[2, 0, 1])\n+                                shape = K.int_shape(w_img)\n+                            w_img = tf.reshape(w_img, [shape[0],\n+                                                       shape[1],\n+                                                       shape[2],\n+                                                       1])\n+                        elif len(shape) == 1:  # bias case\n+                            w_img = tf.reshape(w_img, [1,\n+                                                       shape[0],\n+                                                       1,\n+                                                       1])\n+                        else:\n+                            # not possible to handle 3D convnets etc.\n+                            continue\n+\n+                        shape = K.int_shape(w_img)\n+                        assert len(shape) == 4 and shape[-1] in [1, 3, 4]\n                         tf.summary.image(weight.name, w_img)\n \n                 if hasattr(layer, 'output'):\n\n@@ -9,6 +9,8 @@ from keras import optimizers\n from keras import callbacks\n from keras.models import Sequential\n from keras.layers.core import Dense\n+from keras.layers.convolutional import Conv2D\n+from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D\n from keras.utils.test_utils import get_test_data\n from keras.utils.test_utils import keras_test\n from keras import backend as K\n@@ -348,6 +350,47 @@ def test_TensorBoard():\n     shutil.rmtree(filepath)\n \n \n+@keras_test\n+@pytest.mark.skipif((K.backend() != 'tensorflow'),\n+                    reason='Requires tensorflow backend')\n+def test_TensorBoard_convnet():\n+    np.random.seed(1337)\n+\n+    filepath = './logs'\n+    input_shape = (16, 16, 3)\n+    (x_train, y_train), (x_test, y_test) = get_test_data(num_train=500,\n+                                                         num_test=200,\n+                                                         input_shape=input_shape,\n+                                                         classification=True,\n+                                                         num_classes=4)\n+    y_train = np_utils.to_categorical(y_train)\n+    y_test = np_utils.to_categorical(y_test)\n+\n+    model = Sequential([\n+        Conv2D(filters=8, kernel_size=3,\n+               activation='relu',\n+               input_shape=input_shape),\n+        MaxPooling2D(pool_size=2),\n+        Conv2D(filters=4, kernel_size=(3, 3),\n+               activation='relu', padding='same'),\n+        GlobalAveragePooling2D(),\n+        Dense(y_test.shape[-1], activation='softmax')\n+    ])\n+    model.compile(loss='categorical_crossentropy',\n+                  optimizer='rmsprop',\n+                  metrics=['accuracy'])\n+    tsb = callbacks.TensorBoard(log_dir=filepath, histogram_freq=1,\n+                                write_images=True)\n+    cbks = [tsb]\n+    model.summary()\n+    history = model.fit(x_train, y_train, epochs=2, batch_size=16,\n+                        validation_data=(x_test, y_test),\n+                        callbacks=cbks,\n+                        verbose=0)\n+    assert os.path.exists(filepath)\n+    shutil.rmtree(filepath)\n+\n+\n @keras_test\n def test_LambdaCallback():\n     np.random.seed(1337)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#47dddaa7fd6947800f5f091336cf822b6db72a51", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 198 | Contributors (this commit): 5 | Commits (past 90d): 8 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -70,7 +70,7 @@ def convert_kernel(kernel):\n     Also works reciprocally, since the transformation is its own inverse.\n \n     # Arguments\n-        kernel: Numpy array (4D or 5D).\n+        kernel: Numpy array (3D, 4D or 5D).\n \n     # Returns\n         The converted kernel.\n@@ -79,7 +79,7 @@ def convert_kernel(kernel):\n         ValueError: in case of invalid kernel shape or invalid data_format.\n     \"\"\"\n     kernel = np.asarray(kernel)\n-    if not 4 <= kernel.ndim <= 5:\n+    if not 3 <= kernel.ndim <= 5:\n         raise ValueError('Invalid kernel shape:', kernel.shape)\n     slices = [slice(None, None, -1) for _ in range(kernel.ndim)]\n     no_flip = (slice(None, None), slice(None, None))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dc3d164c6b1079f647ac7ed416cb917a1cc72c18", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 433 | Contributors (this commit): 8 | Commits (past 90d): 3 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -68,7 +68,7 @@ class Tokenizer(object):\n             tabs and line breaks, minus the `'` character.\n         lower: boolean. Whether to convert the texts to lowercase.\n         split: character or string to use for token splitting.\n-        char_level: if True, every character will be treated as a word.\n+        char_level: if True, every character will be treated as a token.\n \n     By default, all punctuation is removed, turning the texts into\n     space-separated sequences of words\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b93d3b23f51ef282c90dcf924475eb1fcaa4151d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 237 | Contributors (this commit): 9 | Commits (past 90d): 5 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -62,8 +62,8 @@ class HDF5Matrix(object):\n         return self.end - self.start\n \n     def __getitem__(self, key):\n-        start, stop = key.start, key.stop\n         if isinstance(key, slice):\n+            start, stop = key.start, key.stop\n             if start is None:\n                 start = 0\n             if stop is None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#75519651bbfd0a31a382eee92a982d9338e0e6d5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 452 | Contributors (this commit): 5 | Commits (past 90d): 4 | Contributors (cumulative): 5 | DMM Complexity: 0.0\n\nDIFF:\n@@ -76,7 +76,7 @@ def test_sequential_model_saving_2():\n \n \n @keras_test\n-def test_fuctional_model_saving():\n+def test_functional_model_saving():\n     input = Input(shape=(3,))\n     x = Dense(2)(input)\n     output = Dense(3)(x)\n@@ -131,10 +131,11 @@ def test_saving_multiple_metrics_outputs():\n \n @keras_test\n def test_saving_without_compilation():\n+    \"\"\"Test saving model without compiling.\n+    \"\"\"\n     model = Sequential()\n     model.add(Dense(2, input_shape=(3,)))\n     model.add(Dense(3))\n-    model.compile(loss='mse', optimizer='sgd', metrics=['acc'])\n \n     _, fname = tempfile.mkstemp('.h5')\n     save_model(model, fname)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cf550db5a5a0b740a185edf8f38874558061345d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 83 | Lines Deleted: 15 | Files Changed: 4 | Hunks: 18 | Methods Changed: 9 | Complexity Δ (Sum/Max): 8/5 | Churn Δ: 98 | Churn Cumulative: 16975 | Contributors (this commit): 128 | Commits (past 90d): 100 | Contributors (cumulative): 166 | DMM Complexity: 0.8727272727272727\n\nDIFF:\n@@ -582,15 +582,18 @@ class TensorBoard(Callback):\n \n     # Arguments\n         log_dir: the path of the directory where to save the log\n-            files to be parsed by Tensorboard.\n+            files to be parsed by TensorBoard.\n         histogram_freq: frequency (in epochs) at which to compute activation\n-            histograms for the layers of the model. If set to 0,\n-            histograms won't be computed.\n-        write_graph: whether to visualize the graph in Tensorboard.\n+            and weight histograms for the layers of the model. If set to 0,\n+            histograms won't be computed. Validation data (or split) must be\n+            specified for histogram visualizations.\n+        write_graph: whether to visualize the graph in TensorBoard.\n             The log file can become quite large when\n             write_graph is set to True.\n+        write_grads: whether to visualize gradient histograms in TensorBoard.\n+            `histogram_freq` must be greater than 0.\n         write_images: whether to write model weights to visualize as\n-            image in Tensorboard.\n+            image in TensorBoard.\n         embeddings_freq: frequency (in epochs) at which selected embedding\n             layers will be saved.\n         embeddings_layer_names: a list of names of layers to keep eye on. If\n@@ -605,6 +608,7 @@ class TensorBoard(Callback):\n     def __init__(self, log_dir='./logs',\n                  histogram_freq=0,\n                  write_graph=True,\n+                 write_grads=False,\n                  write_images=False,\n                  embeddings_freq=0,\n                  embeddings_layer_names=None,\n@@ -617,6 +621,7 @@ class TensorBoard(Callback):\n         self.histogram_freq = histogram_freq\n         self.merged = None\n         self.write_graph = write_graph\n+        self.write_grads = write_grads\n         self.write_images = write_images\n         self.embeddings_freq = embeddings_freq\n         self.embeddings_layer_names = embeddings_layer_names\n@@ -630,6 +635,10 @@ class TensorBoard(Callback):\n \n                 for weight in layer.weights:\n                     tf.summary.histogram(weight.name, weight)\n+                    if self.write_grads:\n+                        grads = model.optimizer.get_gradients(model.total_loss,\n+                                                              weight)\n+                        tf.summary.histogram('{}_grad'.format(weight.name), grads)\n                     if self.write_images:\n                         w_img = tf.squeeze(weight)\n                         shape = K.int_shape(w_img)\n@@ -718,13 +727,16 @@ class TensorBoard(Callback):\n             if epoch % self.histogram_freq == 0:\n                 # TODO: implement batched calls to sess.run\n                 # (current call will likely go OOM on GPU)\n-                if self.model.uses_learning_phase:\n-                    cut_v_data = len(self.model.inputs)\n-                    val_data = self.validation_data[:cut_v_data] + [0]\n-                    tensors = self.model.inputs + [K.learning_phase()]\n-                else:\n+\n                 val_data = self.validation_data\n-                    tensors = self.model.inputs\n+                tensors = (self.model.inputs +\n+                           self.model.targets +\n+                           self.model.sample_weights)\n+\n+                if self.model.uses_learning_phase:\n+                    tensors += [K.learning_phase()]\n+\n+                assert len(val_data) == len(tensors)\n                 feed_dict = dict(zip(tensors, val_data))\n                 result = self.sess.run([self.merged], feed_dict=feed_dict)\n                 summary_str = result[0]\n\n@@ -1839,8 +1839,11 @@ class Model(Container):\n                                  str(validation_data))\n             val_x, val_y, val_sample_weights = self._standardize_user_data(\n                 val_x, val_y, val_sample_weight)\n+            val_data = val_x + val_y + val_sample_weights\n+            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n+                val_data += [0.]\n             for cbk in callbacks:\n-                cbk.validation_data = val_x + [val_y, val_sample_weights]\n+                cbk.validation_data = val_data\n         enqueuer = None\n \n         try:\n\n@@ -786,11 +786,14 @@ class Sequential(Model):\n                            **kwargs)\n         self.optimizer = self.model.optimizer\n         self.loss = self.model.loss\n+        self.total_loss = self.model.total_loss\n         self.loss_weights = self.model.loss_weights\n         self.metrics = self.model.metrics\n         self.metrics_tensors = self.model.metrics_tensors\n         self.metrics_names = self.model.metrics_names\n         self.sample_weight_mode = self.model.sample_weight_mode\n+        self.sample_weights = self.model.sample_weights\n+        self.targets = self.model.targets\n \n     def fit(self, x, y, batch_size=32, epochs=10, verbose=1, callbacks=None,\n             validation_split=0., validation_data=None, shuffle=True,\n\n@@ -8,7 +8,7 @@ import shutil\n from keras import optimizers\n from keras import callbacks\n from keras.models import Sequential\n-from keras.layers.core import Dense\n+from keras.layers.core import Dense, Dropout\n from keras.layers.convolutional import Conv2D\n from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D\n from keras.utils.test_utils import get_test_data\n@@ -311,13 +311,14 @@ def test_TensorBoard():\n     # case 1 Sequential\n     model = Sequential()\n     model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n+    model.add(Dropout(0.1))\n     model.add(Dense(num_class, activation='softmax'))\n     model.compile(loss='categorical_crossentropy',\n                   optimizer='sgd',\n                   metrics=['accuracy'])\n \n     tsb = callbacks.TensorBoard(log_dir=filepath, histogram_freq=1,\n-                                write_images=True)\n+                                write_images=True, write_grads=True)\n     cbks = [tsb]\n \n     # fit with validation data\n@@ -380,7 +381,7 @@ def test_TensorBoard_convnet():\n                   optimizer='rmsprop',\n                   metrics=['accuracy'])\n     tsb = callbacks.TensorBoard(log_dir=filepath, histogram_freq=1,\n-                                write_images=True)\n+                                write_images=True, write_grads=True)\n     cbks = [tsb]\n     model.summary()\n     history = model.fit(x_train, y_train, epochs=2, batch_size=16,\n@@ -391,6 +392,55 @@ def test_TensorBoard_convnet():\n     shutil.rmtree(filepath)\n \n \n+@keras_test\n+def test_CallbackValData():\n+    np.random.seed(1337)\n+    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n+                                                         num_test=test_samples,\n+                                                         input_shape=(input_dim,),\n+                                                         classification=True,\n+                                                         num_classes=num_class)\n+    y_test = np_utils.to_categorical(y_test)\n+    y_train = np_utils.to_categorical(y_train)\n+    model = Sequential()\n+    model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n+    model.add(Dense(num_class, activation='softmax'))\n+    model.compile(loss='categorical_crossentropy',\n+                  optimizer='sgd',\n+                  metrics=['accuracy'])\n+\n+    cbk = callbacks.LambdaCallback(on_train_end=lambda x: 1)\n+    model.fit(X_train, y_train, batch_size=batch_size,\n+              validation_data=(X_test, y_test), callbacks=[cbk], epochs=1)\n+\n+    def data_generator(train):\n+        if train:\n+            max_batch_index = len(X_train) // batch_size\n+        else:\n+            max_batch_index = len(X_test) // batch_size\n+        i = 0\n+        while 1:\n+            if train:\n+                yield (X_train[i * batch_size: (i + 1) * batch_size],\n+                       y_train[i * batch_size: (i + 1) * batch_size])\n+            else:\n+                yield (X_test[i * batch_size: (i + 1) * batch_size],\n+                       y_test[i * batch_size: (i + 1) * batch_size])\n+            i += 1\n+            i = i % max_batch_index\n+\n+    cbk2 = callbacks.LambdaCallback(on_train_end=lambda x: 1)\n+    model.fit_generator(data_generator(True), len(X_train), epochs=1,\n+                        validation_data=(X_test, y_test),\n+                        callbacks=[cbk2])\n+\n+    # callback validation data should always have x, y, and sample weights\n+    assert len(cbk.validation_data) == len(cbk2.validation_data) == 3\n+    assert cbk.validation_data[0] is cbk2.validation_data[0]\n+    assert cbk.validation_data[1] is cbk2.validation_data[1]\n+    assert cbk.validation_data[2].shape == cbk2.validation_data[2].shape\n+\n+\n @keras_test\n def test_LambdaCallback():\n     np.random.seed(1337)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#85221ccd13fc69a233b3f39311ba19382daabee4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 4935 | Contributors (this commit): 66 | Commits (past 90d): 40 | Contributors (cumulative): 66 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1526,8 +1526,9 @@ def dropout(x, level, noise_shape=None, seed=None):\n     return x\n \n \n-def l2_normalize(x, axis):\n-    norm = T.sqrt(T.sum(T.square(x), axis=axis, keepdims=True))\n+def l2_normalize(x, axis, epsilon=1e-12):\n+    square_sum = T.sum(T.square(x), axis=axis, keepdims=True)\n+    norm = T.sqrt(T.maximum(square_sum, epsilon))\n     return x / norm\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1c7e63e42c3d1e8989109f502c110dfd1e4e4656", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 1134 | Contributors (this commit): 14 | Commits (past 90d): 7 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -120,14 +120,13 @@ PAGES = [\n             models.Sequential.fit,\n             models.Sequential.evaluate,\n             models.Sequential.predict,\n-            models.Sequential.predict_classes,\n-            models.Sequential.predict_proba,\n             models.Sequential.train_on_batch,\n             models.Sequential.test_on_batch,\n             models.Sequential.predict_on_batch,\n             models.Sequential.fit_generator,\n             models.Sequential.evaluate_generator,\n             models.Sequential.predict_generator,\n+            models.Sequential.get_layer,\n         ],\n     },\n     {\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#61c9cdc53ca5725e43b3e9c159ea5b68966fabfe", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 7683 | Contributors (this commit): 73 | Commits (past 90d): 44 | Contributors (cumulative): 73 | DMM Complexity: None\n\nDIFF:\n@@ -1399,7 +1399,7 @@ def logsumexp(x, axis=None, keepdims=False):\n         The reduced tensor.\n     \"\"\"\n     axis = _normalize_axis(axis, ndim(x))\n-    return tf.reduce_logsumexp(x, reduction_indices=axis, keep_dims=keepdims)\n+    return tf.reduce_logsumexp(x, axis=axis, keep_dims=keepdims)\n \n \n def round(x):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#23833417cfe83723f088bea08e63844cae6f1121", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1003 | Contributors (this commit): 20 | Commits (past 90d): 15 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -167,7 +167,7 @@ def convert_dense_weights_data_format(dense,\n             came before the target `Dense` layer.\n         target_data_format: One of \"channels_last\", \"channels_first\".\n             Set it \"channels_last\"\n-            if converting a \"chnnels_first\" model to \"channels_last\",\n+            if converting a \"channels_first\" model to \"channels_last\",\n             or reciprocally.\n     \"\"\"\n     assert target_data_format in {'channels_last', 'channels_first'}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8ac1b1fdc90b51da0410a8d922d705a791dc1f0d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 35 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 19/18 | Churn Δ: 38 | Churn Cumulative: 2168 | Contributors (this commit): 25 | Commits (past 90d): 12 | Contributors (cumulative): 27 | DMM Complexity: 0.9\n\nDIFF:\n@@ -838,6 +838,8 @@ class DirectoryIterator(Iterator):\n             `\"binary\"`: binary targets (if there are only two classes),\n             `\"categorical\"`: categorical targets,\n             `\"sparse\"`: integer targets,\n+            `\"input\"`: targets are images identical to input images (mainly\n+                used to work with autoencoders),\n             `None`: no targets get yielded (only input images are yielded).\n         batch_size: Integer, size of a batch.\n         shuffle: Boolean, whether to shuffle the data between epochs.\n@@ -881,10 +883,12 @@ class DirectoryIterator(Iterator):\n             else:\n                 self.image_shape = (1,) + self.target_size\n         self.classes = classes\n-        if class_mode not in {'categorical', 'binary', 'sparse', None}:\n+        if class_mode not in {'categorical', 'binary', 'sparse',\n+                              'input', None}:\n             raise ValueError('Invalid class_mode:', class_mode,\n                              '; expected one of \"categorical\", '\n-                             '\"binary\", \"sparse\", or None.')\n+                             '\"binary\", \"sparse\", \"input\"'\n+                             ' or None.')\n         self.class_mode = class_mode\n         self.save_to_dir = save_to_dir\n         self.save_prefix = save_prefix\n@@ -972,7 +976,9 @@ class DirectoryIterator(Iterator):\n                                                                   format=self.save_format)\n                 img.save(os.path.join(self.save_to_dir, fname))\n         # build batch of labels\n-        if self.class_mode == 'sparse':\n+        if self.class_mode == 'input':\n+            batch_y = batch_x.copy()\n+        elif self.class_mode == 'sparse':\n             batch_y = self.classes[index_array]\n         elif self.class_mode == 'binary':\n             batch_y = self.classes[index_array].astype(K.floatx())\n\n@@ -160,6 +160,32 @@ class TestImage:\n         assert(sorted(dir_iterator.filenames) == sorted(filenames))\n         shutil.rmtree(tmp_folder)\n \n+    def test_directory_iterator_class_mode_input(self):\n+        tmp_folder = tempfile.mkdtemp(prefix='test_images')\n+        os.mkdir(os.path.join(tmp_folder, 'class-1'))\n+\n+        # save the images in the paths\n+        count = 0\n+        for test_images in self.all_test_images:\n+            for im in test_images:\n+                filename = os.path.join(tmp_folder, 'class-1', 'image-{}.jpg'.format(count))\n+                im.save(os.path.join(tmp_folder, filename))\n+                count += 1\n+\n+        # create iterator\n+        generator = image.ImageDataGenerator()\n+        dir_iterator = generator.flow_from_directory(tmp_folder, class_mode='input')\n+        batch = next(dir_iterator)\n+\n+        # check if input and output have the same shape\n+        assert(batch[0].shape == batch[1].shape)\n+        # check if the input and output images are not the same numpy array\n+        input_img = batch[0][0]\n+        output_img = batch[1][0]\n+        output_img[0][0][0] += 1\n+        assert(input_img[0][0][0] != output_img[0][0][0])\n+        shutil.rmtree(tmp_folder)\n+\n     def test_img_utils(self):\n         height, width = 10, 8\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d223cc0ff7fa13970c809bb2534728d2e1f2a247", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 33 | Churn Cumulative: 58 | Contributors (this commit): 4 | Commits (past 90d): 5 | Contributors (cumulative): 4 | DMM Complexity: 0.2\n\nDIFF:\n@@ -21,13 +21,20 @@ def _check_pydot():\n                           ' and graphviz for `pydotprint` to work.')\n \n \n-def model_to_dot(model, show_shapes=False, show_layer_names=True):\n-    \"\"\"Converts a Keras model to dot format.\n+def model_to_dot(model,\n+                 show_shapes=False,\n+                 show_layer_names=True,\n+                 rankdir='TB'):\n+    \"\"\"Convert a Keras model to dot format.\n \n     # Arguments\n         model: A Keras model instance.\n         show_shapes: whether to display shape information.\n         show_layer_names: whether to display layer names.\n+        rankdir: `rankdir` argument passed to PyDot,\n+            a string specifying the format of the plot:\n+            'TB' creates a vertical plot;\n+            'LR' creates a horizontal plot.\n \n     # Returns\n         A `pydot.Dot` instance representing the Keras model.\n@@ -37,7 +44,7 @@ def model_to_dot(model, show_shapes=False, show_layer_names=True):\n \n     _check_pydot()\n     dot = pydot.Dot()\n-    dot.set('rankdir', 'TB')\n+    dot.set('rankdir', rankdir)\n     dot.set('concentrate', True)\n     dot.set_node_defaults(shape='record')\n \n@@ -78,7 +85,8 @@ def model_to_dot(model, show_shapes=False, show_layer_names=True):\n                     [str(ishape) for ishape in layer.input_shapes])\n             else:\n                 inputlabels = 'multiple'\n-            label = '%s\\n|{input:|output:}|{{%s}|{%s}}' % (label, inputlabels, outputlabels)\n+            label = '%s\\n|{input:|output:}|{{%s}|{%s}}' \\\n+                    % (label, inputlabels, outputlabels)\n \n         node = pydot.Node(layer_id, label=label)\n         dot.add_node(node)\n@@ -99,8 +107,21 @@ def model_to_dot(model, show_shapes=False, show_layer_names=True):\n def plot_model(model,\n                to_file='model.png',\n                show_shapes=False,\n-               show_layer_names=True):\n-    dot = model_to_dot(model, show_shapes, show_layer_names)\n+               show_layer_names=True,\n+               rankdir='TB'):\n+    \"\"\"Converts a Keras model to dot format and save to a file.\n+\n+    # Arguments\n+        model: A Keras model instance\n+        to_file: File name of the\n+        show_shapes: whether to display shape information.\n+        show_layer_names: whether to display layer names.\n+        rankdir: `rankdir` argument passed to PyDot,\n+            a string specifying the format of the plot:\n+            'TB' creates a vertical plot;\n+            'LR' creates a horizontal plot.\n+    \"\"\"\n+    dot = model_to_dot(model, show_shapes, show_layer_names, rankdir)\n     _, extension = os.path.splitext(to_file)\n     if not extension:\n         extension = 'png'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ea8e2edf17fed647037109f712672a44f5a66ac9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 627 | Contributors (this commit): 17 | Commits (past 90d): 13 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -153,7 +153,7 @@ def deserialize_keras_object(identifier, module_objects=None,\n         else:\n             fn = module_objects.get(function_name)\n             if fn is None:\n-                raise ValueError('Unknown ' + printable_module_name,\n+                raise ValueError('Unknown ' + printable_module_name +\n                                  ':' + function_name)\n         return fn\n     else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a2a0f66276a6ecb8210ba8b9c5df0dbe556c6996", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 6 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 14 | Churn Cumulative: 191 | Contributors (this commit): 9 | Commits (past 90d): 5 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -44,19 +44,27 @@ if os.path.exists(_config_path):\n     _BACKEND = _backend\n \n # Save config file, if possible.\n-if os.access(_keras_base_dir, os.W_OK):\n if not os.path.exists(_keras_dir):\n     try:\n         os.makedirs(_keras_dir)\n     except OSError:\n+        # Except permission denied and potential race conditions\n+        # in multi-threaded environments.\n         pass\n+\n if not os.path.exists(_config_path):\n-        _config = {'floatx': floatx(),\n+    _config = {\n+        'floatx': floatx(),\n         'epsilon': epsilon(),\n         'backend': _BACKEND,\n-                   'image_data_format': image_data_format()}\n+        'image_data_format': image_data_format()\n+    }\n+    try:\n         with open(_config_path, 'w') as f:\n             f.write(json.dumps(_config, indent=4))\n+    except IOError:\n+        # Except permission denied.\n+        pass\n \n # Set backend based on KERAS_BACKEND flag, if applicable.\n if 'KERAS_BACKEND' in os.environ:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bfae0a61917f8cc7563db80051f89e178e8bfb1c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 5 | Files Changed: 3 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 236 | Contributors (this commit): 4 | Commits (past 90d): 9 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -2,7 +2,7 @@ import pytest\n import numpy as np\n from numpy.testing import assert_allclose\n \n-from keras.layers import Dense, Activation, Input\n+from keras.layers import Input\n from keras.utils.test_utils import layer_test, keras_test\n from keras.layers import normalization\n from keras.models import Sequential, Model\n\n@@ -9,8 +9,6 @@ from six.moves.urllib.parse import urljoin\n from keras.utils.data_utils import get_file\n from keras.utils.data_utils import validate_file\n from keras.utils.data_utils import _hash_file\n-from keras import activations\n-from keras import regularizers\n \n \n def test_data_utils():\n\n@@ -2,8 +2,6 @@ import pytest\n import numpy as np\n \n from keras.utils.test_utils import get_test_data\n-from keras.utils import np_utils\n-from keras import backend as K\n \n from keras.models import Sequential\n from keras.layers.core import Dense, Activation\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#268672df65941fcc2e1727b877aa457c05acfc45", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 629 | Contributors (this commit): 18 | Commits (past 90d): 13 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -246,7 +246,7 @@ class Progbar(object):\n \n         now = time.time()\n         if self.verbose == 1:\n-            if not force and (now - self.last_update) < self.interval:\n+            if not force and (now - self.last_update) < self.interval and current < self.target:\n                 return\n \n             prev_total_width = self.total_width\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1a89b13cb4ac52b7dad40e671b618e42921a4c48", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 2 | Churn Cumulative: 631 | Contributors (this commit): 18 | Commits (past 90d): 14 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -246,7 +246,7 @@ class Progbar(object):\n \n         now = time.time()\n         if self.verbose == 1:\n-            if not force and (now - self.last_update) < self.interval and current < self.target:\n+            if not force and (now - self.last_update) < self.interval:\n                 return\n \n             prev_total_width = self.total_width\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
