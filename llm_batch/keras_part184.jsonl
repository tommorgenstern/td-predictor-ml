{"custom_id": "keras#8830c53135dcad4825e2f8805c78523931c3bbed", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 58 | Lines Deleted: 35 | Files Changed: 10 | Hunks: 35 | Methods Changed: 11 | Complexity Δ (Sum/Max): 6/5 | Churn Δ: 93 | Churn Cumulative: 43147 | Contributors (this commit): 149 | Commits (past 90d): 234 | Contributors (cumulative): 253 | DMM Complexity: 1.0\n\nDIFF:\n@@ -360,10 +360,14 @@ class Layer(object):\n     def non_trainable_weights(self, weights):\n         self._non_trainable_weights = weights\n \n-    def add_weight(self, shape, initializer,\n-                   name=None,\n-                   trainable=True,\n+    @interfaces.legacy_add_weight_support\n+    def add_weight(self,\n+                   name,\n+                   shape,\n+                   dtype=None,\n+                   initializer=None,\n                    regularizer=None,\n+                   trainable=True,\n                    constraint=None):\n         \"\"\"Adds a weight variable to the layer.\n \n@@ -381,7 +385,9 @@ class Layer(object):\n             The created weight variable.\n         \"\"\"\n         initializer = initializers.get(initializer)\n-        weight = K.variable(initializer(shape), dtype=K.floatx(), name=name)\n+        if dtype is None:\n+            dtype = K.floatx()\n+        weight = K.variable(initializer(shape), dtype=dtype, name=name)\n         if regularizer is not None:\n             self.add_loss(regularizer(weight))\n         if constraint is not None:\n\n@@ -104,7 +104,7 @@ class PReLU(Layer):\n             for i in self.shared_axes:\n                 param_shape[i - 1] = 1\n                 self.param_broadcast[i - 1] = True\n-        self.alpha = self.add_weight(param_shape,\n+        self.alpha = self.add_weight(shape=param_shape,\n                                      name='alpha',\n                                      initializer=self.alpha_initializer,\n                                      regularizer=self.alpha_regularizer,\n\n@@ -127,13 +127,13 @@ class _Conv(Layer):\n         input_dim = input_shape[channel_axis]\n         kernel_shape = self.kernel_size + (input_dim, self.filters)\n \n-        self.kernel = self.add_weight(kernel_shape,\n+        self.kernel = self.add_weight(shape=kernel_shape,\n                                       initializer=self.kernel_initializer,\n                                       name='kernel',\n                                       regularizer=self.kernel_regularizer,\n                                       constraint=self.kernel_constraint)\n         if self.use_bias:\n-            self.bias = self.add_weight((self.filters,),\n+            self.bias = self.add_weight(shape=(self.filters,),\n                                         initializer=self.bias_initializer,\n                                         name='bias',\n                                         regularizer=self.bias_regularizer,\n@@ -721,13 +721,13 @@ class Conv2DTranspose(Conv2D):\n         input_dim = input_shape[channel_axis]\n         kernel_shape = self.kernel_size + (self.filters, input_dim)\n \n-        self.kernel = self.add_weight(kernel_shape,\n+        self.kernel = self.add_weight(shape=kernel_shape,\n                                       initializer=self.kernel_initializer,\n                                       name='kernel',\n                                       regularizer=self.kernel_regularizer,\n                                       constraint=self.kernel_constraint)\n         if self.use_bias:\n-            self.bias = self.add_weight((self.filters,),\n+            self.bias = self.add_weight(shape=(self.filters,),\n                                         initializer=self.bias_initializer,\n                                         name='bias',\n                                         regularizer=self.bias_regularizer,\n@@ -952,20 +952,20 @@ class SeparableConv2D(Conv2D):\n                                   self.filters)\n \n         self.depthwise_kernel = self.add_weight(\n-            depthwise_kernel_shape,\n+            shape=depthwise_kernel_shape,\n             initializer=self.depthwise_initializer,\n             name='depthwise_kernel',\n             regularizer=self.depthwise_regularizer,\n             constraint=self.depthwise_constraint)\n         self.pointwise_kernel = self.add_weight(\n-            pointwise_kernel_shape,\n+            shape=pointwise_kernel_shape,\n             initializer=self.pointwise_initializer,\n             name='pointwise_kernel',\n             regularizer=self.pointwise_regularizer,\n             constraint=self.pointwise_constraint)\n \n         if self.use_bias:\n-            self.bias = self.add_weight((self.filters,),\n+            self.bias = self.add_weight(shape=(self.filters,),\n                                         initializer=self.bias_initializer,\n                                         name='bias',\n                                         regularizer=self.bias_regularizer,\n\n@@ -351,19 +351,19 @@ class ConvLSTM2D(ConvRecurrent2D):\n         self.kernel_shape = kernel_shape\n         recurrent_kernel_shape = self.kernel_size + (self.filters, self.filters * 4)\n \n-        self.kernel = self.add_weight(kernel_shape,\n+        self.kernel = self.add_weight(shape=kernel_shape,\n                                       initializer=self.kernel_initializer,\n                                       name='kernel',\n                                       regularizer=self.kernel_regularizer,\n                                       constraint=self.kernel_constraint)\n         self.recurrent_kernel = self.add_weight(\n-            recurrent_kernel_shape,\n+            shape=recurrent_kernel_shape,\n             initializer=self.recurrent_initializer,\n             name='recurrent_kernel',\n             regularizer=self.recurrent_regularizer,\n             constraint=self.recurrent_constraint)\n         if self.use_bias:\n-            self.bias = self.add_weight((self.filters * 4,),\n+            self.bias = self.add_weight(shape=(self.filters * 4,),\n                                         initializer=self.bias_initializer,\n                                         name='bias',\n                                         regularizer=self.bias_regularizer,\n\n@@ -820,13 +820,13 @@ class Dense(Layer):\n         assert len(input_shape) >= 2\n         input_dim = input_shape[-1]\n \n-        self.kernel = self.add_weight((input_dim, self.units),\n+        self.kernel = self.add_weight(shape=(input_dim, self.units),\n                                       initializer=self.kernel_initializer,\n                                       name='kernel',\n                                       regularizer=self.kernel_regularizer,\n                                       constraint=self.kernel_constraint)\n         if self.use_bias:\n-            self.bias = self.add_weight((self.units,),\n+            self.bias = self.add_weight(shape=(self.units,),\n                                         initializer=self.bias_initializer,\n                                         name='bias',\n                                         regularizer=self.bias_regularizer,\n\n@@ -94,7 +94,7 @@ class Embedding(Layer):\n \n     def build(self, input_shape):\n         self.embeddings = self.add_weight(\n-            (self.input_dim, self.output_dim),\n+            shape=(self.input_dim, self.output_dim),\n             initializer=self.embeddings_initializer,\n             name='embeddings',\n             regularizer=self.embeddings_regularizer,\n\n@@ -122,14 +122,14 @@ class LocallyConnected1D(Layer):\n                              self.kernel_size[0] * input_dim,\n                              self.filters)\n         self.kernel = self.add_weight(\n-            self.kernel_shape,\n+            shape=self.kernel_shape,\n             initializer=self.kernel_initializer,\n             name='kernel',\n             regularizer=self.kernel_regularizer,\n             constraint=self.kernel_constraint)\n         if self.use_bias:\n             self.bias = self.add_weight(\n-                (output_length, self.filters),\n+                shape=(output_length, self.filters),\n                 initializer=self.bias_initializer,\n                 name='bias',\n                 regularizer=self.bias_regularizer,\n@@ -325,13 +325,13 @@ class LocallyConnected2D(Layer):\n         self.kernel_shape = (output_row * output_col,\n                              self.kernel_size[0] * self.kernel_size[1] * input_filter,\n                              self.filters)\n-        self.kernel = self.add_weight(self.kernel_shape,\n+        self.kernel = self.add_weight(shape=self.kernel_shape,\n                                       initializer=self.kernel_initializer,\n                                       name='kernel',\n                                       regularizer=self.kernel_regularizer,\n                                       constraint=self.kernel_constraint)\n         if self.use_bias:\n-            self.bias = self.add_weight((output_row, output_col, self.filters),\n+            self.bias = self.add_weight(shape=(output_row, output_col, self.filters),\n                                         initializer=self.bias_initializer,\n                                         name='bias',\n                                         regularizer=self.bias_regularizer,\n\n@@ -96,7 +96,7 @@ class BatchNormalization(Layer):\n         shape = (dim,)\n \n         if self.scale:\n-            self.gamma = self.add_weight(shape,\n+            self.gamma = self.add_weight(shape=shape,\n                                          name='gamma',\n                                          initializer=self.gamma_initializer,\n                                          regularizer=self.gamma_regularizer,\n@@ -104,7 +104,7 @@ class BatchNormalization(Layer):\n         else:\n             self.gamma = None\n         if self.center:\n-            self.beta = self.add_weight(shape,\n+            self.beta = self.add_weight(shape=shape,\n                                         name='beta',\n                                         initializer=self.beta_initializer,\n                                         regularizer=self.beta_regularizer,\n@@ -112,12 +112,12 @@ class BatchNormalization(Layer):\n         else:\n             self.beta = None\n         self.moving_mean = self.add_weight(\n-            shape,\n+            shape=shape,\n             name='moving_mean',\n             initializer=self.moving_mean_initializer,\n             trainable=False)\n         self.moving_variance = self.add_weight(\n-            shape,\n+            shape=shape,\n             name='moving_variance',\n             initializer=self.moving_variance_initializer,\n             trainable=False)\n\n@@ -471,19 +471,19 @@ class SimpleRNN(Recurrent):\n         if self.stateful:\n             self.reset_states()\n \n-        self.kernel = self.add_weight((self.input_dim, self.units),\n+        self.kernel = self.add_weight(shape=(self.input_dim, self.units),\n                                       name='kernel',\n                                       initializer=self.kernel_initializer,\n                                       regularizer=self.kernel_regularizer,\n                                       constraint=self.kernel_constraint)\n         self.recurrent_kernel = self.add_weight(\n-            (self.units, self.units),\n+            shape=(self.units, self.units),\n             name='recurrent_kernel',\n             initializer=self.recurrent_initializer,\n             regularizer=self.recurrent_regularizer,\n             constraint=self.recurrent_constraint)\n         if self.use_bias:\n-            self.bias = self.add_weight((self.units,),\n+            self.bias = self.add_weight(shape=(self.units,),\n                                         name='bias',\n                                         initializer=self.bias_initializer,\n                                         regularizer=self.bias_regularizer,\n@@ -690,20 +690,20 @@ class GRU(Recurrent):\n         if self.stateful:\n             self.reset_states()\n \n-        self.kernel = self.add_weight((self.input_dim, self.units * 3),\n+        self.kernel = self.add_weight(shape=(self.input_dim, self.units * 3),\n                                       name='kernel',\n                                       initializer=self.kernel_initializer,\n                                       regularizer=self.kernel_regularizer,\n                                       constraint=self.kernel_constraint)\n         self.recurrent_kernel = self.add_weight(\n-            (self.units, self.units * 3),\n+            shape=(self.units, self.units * 3),\n             name='recurrent_kernel',\n             initializer=self.recurrent_initializer,\n             regularizer=self.recurrent_regularizer,\n             constraint=self.recurrent_constraint)\n \n         if self.use_bias:\n-            self.bias = self.add_weight((self.units * 3,),\n+            self.bias = self.add_weight(shape=(self.units * 3,),\n                                         name='bias',\n                                         initializer=self.bias_initializer,\n                                         regularizer=self.bias_regularizer,\n@@ -970,20 +970,20 @@ class LSTM(Recurrent):\n         if self.stateful:\n             self.reset_states()\n \n-        self.kernel = self.add_weight((self.input_dim, self.units * 4),\n+        self.kernel = self.add_weight(shape=(self.input_dim, self.units * 4),\n                                       name='kernel',\n                                       initializer=self.kernel_initializer,\n                                       regularizer=self.kernel_regularizer,\n                                       constraint=self.kernel_constraint)\n         self.recurrent_kernel = self.add_weight(\n-            (self.units, self.units * 4),\n+            shape=(self.units, self.units * 4),\n             name='recurrent_kernel',\n             initializer=self.recurrent_initializer,\n             regularizer=self.recurrent_regularizer,\n             constraint=self.recurrent_constraint)\n \n         if self.use_bias:\n-            self.bias = self.add_weight((self.units * 4,),\n+            self.bias = self.add_weight(shape=(self.units * 4,),\n                                         name='bias',\n                                         initializer=self.bias_initializer,\n                                         regularizer=self.bias_regularizer,\n\n@@ -606,3 +606,20 @@ legacy_model_constructor_support = generate_legacy_interface(\n legacy_input_support = generate_legacy_interface(\n     allowed_positional_args=None,\n     conversions=[('input_dtype', 'dtype')])\n+\n+\n+def add_weight_args_preprocessing(args, kwargs):\n+    if len(args) > 1:\n+        if isinstance(args[1], (tuple, list)):\n+            kwargs['shape'] = args[1]\n+            args = (args[0],) + args[2:]\n+            if len(args) > 1:\n+                if isinstance(args[1], six.string_types):\n+                    kwargs['name'] = args[1]\n+                    args = (args[0],) + args[2:]\n+    return args, kwargs, []\n+\n+\n+legacy_add_weight_support = generate_legacy_interface(\n+    allowed_positional_args=['name', 'shape'],\n+    preprocessor=add_weight_args_preprocessing)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f71831790fe8c5e8735ff5847a97818a865e1e1e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 4 | Churn Cumulative: 1001 | Contributors (this commit): 19 | Commits (past 90d): 15 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -19,7 +19,9 @@ def print_summary(model, line_length=None, positions=None):\n     else:\n         sequential_like = True\n         for v in model.nodes_by_depth.values():\n-            if len(v) > 1:\n+            if (len(v) > 1) or (len(v) == 1 and len(v[0].inbound_layers) > 1):\n+                # if the model has multiple nodes or if the nodes have multiple inbound_layers\n+                # the model is no longer sequential\n                 sequential_like = False\n                 break\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0976afb46d175f9bffd99ead3df06f7befb5ce1c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 7814 | Contributors (this commit): 34 | Commits (past 90d): 56 | Contributors (cumulative): 34 | DMM Complexity: None\n\nDIFF:\n@@ -372,13 +372,14 @@ class Layer(object):\n         \"\"\"Adds a weight variable to the layer.\n \n         # Arguments\n-            shape: The shape tuple of the weight.\n-            initializer: An Initializer instance (callable).\n             name: String, the name for the weight variable.\n+            shape: The shape tuple of the weight.\n+            dtype: The dtype of the weight.\n+            initializer: An Initializer instance (callable).\n+            regularizer: An optional Regularizer instance.\n             trainable: A boolean, whether the weight should\n                 be trained via backprop or not (assuming\n                 that the layer itself is also trainable).\n-            regularizer: An optional Regularizer instance.\n             constraint: An optional Constraint instance.\n \n         # Returns\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d498a9846567e4986ba2a2541b2b4e4719c2c83f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 107 | Contributors (this commit): 3 | Commits (past 90d): 9 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -17,5 +17,7 @@ from . import models\n from . import losses\r\n from . import optimizers\r\n from . import regularizers\r\n+# Importable from root because it's technically not a layer\r\n+from .layers import Input\r\n \r\n __version__ = '2.0.3'\r\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#47350dc6078053403c59e8da3fd63ac3ae12b5ec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 15 | Churn Cumulative: 6559 | Contributors (this commit): 39 | Commits (past 90d): 29 | Contributors (cumulative): 39 | DMM Complexity: 1.0\n\nDIFF:\n@@ -983,15 +983,20 @@ class LSTM(Recurrent):\n             constraint=self.recurrent_constraint)\n \n         if self.use_bias:\n+            if self.unit_forget_bias:\n+                def bias_initializer(shape, *args, **kwargs):\n+                    return K.concatenate([\n+                        self.bias_initializer((self.units,), *args, **kwargs),\n+                        initializers.Ones()((self.units,), *args, **kwargs),\n+                        self.bias_initializer((self.units * 2,), *args, **kwargs),\n+                    ])\n+            else:\n+                bias_initializer = self.bias_initializer\n             self.bias = self.add_weight(shape=(self.units * 4,),\n                                         name='bias',\n-                                        initializer=self.bias_initializer,\n+                                        initializer=bias_initializer,\n                                         regularizer=self.bias_regularizer,\n                                         constraint=self.bias_constraint)\n-            if self.unit_forget_bias:\n-                bias_value = np.zeros((self.units * 4,))\n-                bias_value[self.units: self.units * 2] = 1.\n-                K.set_value(self.bias, bias_value)\n         else:\n             self.bias = None\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e7f3317de617fe20cf1cd483927acdfcb1c9b497", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 2543 | Contributors (this commit): 43 | Commits (past 90d): 13 | Contributors (cumulative): 43 | DMM Complexity: None\n\nDIFF:\n@@ -503,8 +503,7 @@ class RemoteMonitor(Callback):\n         field: String; JSON field under which the data will be stored.\n         headers: Dictionary; optional custom HTTP headers.\n             Defaults to:\n-            `{'Accept': 'application/json',\n-              'Content-Type': 'application/json'}`\n+            `{'Accept': 'application/json', 'Content-Type': 'application/json'}`\n     \"\"\"\n \n     def __init__(self,\n@@ -910,6 +909,7 @@ class LambdaCallback(Callback):\n     This callback is constructed with anonymous functions that will be called\n     at the appropriate time. Note that the callbacks expects positional\n     arguments, as:\n+\n      - `on_epoch_begin` and `on_epoch_end` expect two positional arguments:\n         `epoch`, `logs`\n      - `on_batch_begin` and `on_batch_end` expect two positional arguments:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7d52af64c03e71bcd23112a7086dc8aab1b37ed2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 80 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 4 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 80 | Churn Cumulative: 12637 | Contributors (this commit): 91 | Commits (past 90d): 96 | Contributors (cumulative): 143 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1304,6 +1304,28 @@ def log(x):\n     return tf.log(x)\n \n \n+def logsumexp(x, axis=None, keepdims=False):\n+    \"\"\"Computes log(sum(exp(elements across dimensions of a tensor))).\n+\n+    This function is more numerically stable than log(sum(exp(x))).\n+    It avoids overflows caused by taking the exp of large inputs and\n+    underflows caused by taking the log of small inputs.\n+\n+    # Arguments\n+        x: A tensor or variable.\n+        axis: An integer, the axis to reduce over.\n+        keepdims: A boolean, whether to keep the dimensions or not.\n+            If `keepdims` is `False`, the rank of the tensor is reduced\n+            by 1. If `keepdims` is `True`, the reduced dimension is\n+            retained with length 1.\n+\n+    # Returns\n+        The reduced tensor.\n+    \"\"\"\n+    axis = _normalize_axis(axis, ndim(x))\n+    return tf.reduce_logsumexp(x, reduction_indices=axis, keep_dims=keepdims)\n+\n+\n def round(x):\n     \"\"\"Element-wise rounding to the closest integer.\n \n\n@@ -528,6 +528,29 @@ def log(x):\n     return T.log(x)\n \n \n+def logsumexp(x, axis=None, keepdims=False):\n+    \"\"\"Computes log(sum(exp(elements across dimensions of a tensor))).\n+\n+    This function is more numerically stable than log(sum(exp(x))).\n+    It avoids overflows caused by taking the exp of large inputs and\n+    underflows caused by taking the log of small inputs.\n+\n+    # Arguments\n+        x: A tensor or variable.\n+        axis: An integer, the axis to reduce over.\n+        keepdims: A boolean, whether to keep the dimensions or not.\n+            If `keepdims` is `False`, the rank of the tensor is reduced\n+            by 1. If `keepdims` is `True`, the reduced dimension is\n+            retained with length 1.\n+\n+    # Returns\n+        The reduced tensor.\n+    \"\"\"\n+    # Theano has a built-in optimization for logsumexp (see https://github.com/Theano/Theano/pull/4736)\n+    # so we can just write the expression directly:\n+    return T.log(T.sum(T.exp(x), axis=axis, keepdims=keepdims))\n+\n+\n def round(x):\n     return T.round(x, mode='half_to_even')\n \n\n@@ -580,6 +580,41 @@ class TestBackend(object):\n         assert_allclose(tf_last_output, th_last_output, atol=1e-04)\n         assert_allclose(tf_outputs, th_outputs, atol=1e-04)\n \n+    @pytest.mark.parametrize('x_np,axis,keepdims', [\n+        (np.array([1.1, 0.8, 0.9]), 0, False),\n+        (np.array([[1.1, 0.8, 0.9]]), 0, False),\n+        (np.array([[1.1, 0.8, 0.9]]), 1, False),\n+        (np.array([[1.1, 0.8, 0.9]]), -1, False),\n+        (np.array([[1.1, 0.8, 0.9]]), 1, True),\n+        (np.array([[1.1], [1.2]]), 0, False),\n+        (np.array([[1.1], [1.2]]), 1, False),\n+        (np.array([[1.1], [1.2]]), -1, False),\n+        (np.array([[1.1], [1.2]]), -1, True),\n+        (np.array([[1.1, 1.2, 1.3], [0.9, 0.7, 1.4]]), None, False),\n+        (np.array([[1.1, 1.2, 1.3], [0.9, 0.7, 1.4]]), 0, False),\n+        (np.array([[1.1, 1.2, 1.3], [0.9, 0.7, 1.4]]), 1, False),\n+        (np.array([[1.1, 1.2, 1.3], [0.9, 0.7, 1.4]]), -1, False),\n+    ])\n+    @pytest.mark.parametrize('K', [KTH, KTF], ids=[\"KTH\", \"KTF\"])\n+    def test_logsumexp(self, x_np, axis, keepdims, K):\n+        '''\n+        Check if K.logsumexp works properly for values close to one.\n+        '''\n+        x = K.variable(x_np)\n+        assert_allclose(K.eval(K.logsumexp(x, axis=axis, keepdims=keepdims)),\n+                        np.log(np.sum(np.exp(x_np), axis=axis, keepdims=keepdims)),\n+                        rtol=1e-5)\n+\n+    @pytest.mark.parametrize('K', [KTH, KTF], ids=[\"KTH\", \"KTF\"])\n+    def test_logsumexp_optim(self, K):\n+        '''\n+        Check if optimization works.\n+        '''\n+        x_np = np.array([1e+4, 1e-4])\n+        assert_allclose(K.eval(K.logsumexp(K.variable(x_np), axis=0)),\n+                        1e4,\n+                        rtol=1e-5)\n+\n     def test_switch(self):\n         val = np.random.random()\n         xth = KTH.variable(val)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#04bf5ac57a6071e32ffd340da0acb059912d922c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 21 | Churn Cumulative: 915 | Contributors (this commit): 12 | Commits (past 90d): 21 | Contributors (cumulative): 15 | DMM Complexity: 0.0\n\nDIFF:\n@@ -152,12 +152,17 @@ class TimeDistributed(Wrapper):\n         timesteps = input_shape[1]\n         return (child_output_shape[0], timesteps) + child_output_shape[1:]\n \n-    def call(self, inputs, mask=None):\n+    def call(self, inputs, training=None, mask=None):\n+        kwargs = {}\n+        func_args = inspect.getargspec(self.layer.call).args\n+        if 'training' in func_args:\n+            kwargs['training'] = training\n+\n         input_shape = K.int_shape(inputs)\n         if input_shape[0]:\n             # batch size matters, use rnn-based implementation\n             def step(x, _):\n-                output = self.layer.call(x)\n+                output = self.layer.call(x, **kwargs)\n                 return output, []\n \n             _, outputs, _ = K.rnn(step, inputs,\n@@ -174,7 +179,7 @@ class TimeDistributed(Wrapper):\n                 input_length = K.shape(inputs)[1]\n             # Shape: (num_samples * timesteps, ...)\n             inputs = K.reshape(inputs, (-1,) + input_shape[2:])\n-            y = self.layer.call(inputs)  # (num_samples * timesteps, ...)\n+            y = self.layer.call(inputs, **kwargs)  # (num_samples * timesteps, ...)\n             # Shape: (num_samples, timesteps, ...)\n             output_shape = self.compute_output_shape(input_shape)\n             y = K.reshape(y, (-1, input_length) + output_shape[2:])\n@@ -184,6 +189,10 @@ class TimeDistributed(Wrapper):\n            self.layer.activity_regularizer is not None):\n             regularization_loss = self.layer.activity_regularizer(y)\n             self.add_loss(regularization_loss, inputs)\n+\n+        if 'training' in kwargs:\n+            y._uses_learning_phase = True\n+            pass\n         return y\n \n \n\n@@ -86,6 +86,12 @@ def test_TimeDistributed():\n     outer_model.compile(optimizer='rmsprop', loss='mse')\n     outer_model.fit(np.random.random((10, 3, 2)), np.random.random((10, 3, 3)), epochs=1, batch_size=10)\n \n+    # test layers that need learning_phase to be set\n+    model = Sequential()\n+    model.add(wrappers.TimeDistributed(core.Dropout(.5), input_shape=(3, 2)))\n+    model.compile(optimizer='rmsprop', loss='mse')\n+    model.predict(np.random.random((10, 3, 2)))\n+\n \n @keras_test\n def test_regularizers():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5be73f1ab39a4bc2dfe278a199972e0a14ffa014", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 43 | Lines Deleted: 16 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 59 | Churn Cumulative: 1329 | Contributors (this commit): 20 | Commits (past 90d): 12 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -135,21 +135,6 @@ class BatchNormalization(Layer):\n         # Determines whether broadcasting is needed.\n         needs_broadcasting = (sorted(reduction_axes) != list(range(ndim))[:-1])\n \n-        normed, mean, variance = K.normalize_batch_in_training(\n-            inputs, self.gamma, self.beta, reduction_axes,\n-            epsilon=self.epsilon)\n-\n-        if training in {0, False}:\n-            return normed\n-        else:\n-            self.add_update([K.moving_average_update(self.moving_mean,\n-                                                     mean,\n-                                                     self.momentum),\n-                             K.moving_average_update(self.moving_variance,\n-                                                     variance,\n-                                                     self.momentum)],\n-                            inputs)\n-\n         def normalize_inference():\n             if needs_broadcasting:\n                 # In this case we must explictly broadcast all parameters.\n@@ -182,8 +167,25 @@ class BatchNormalization(Layer):\n                     self.gamma,\n                     epsilon=self.epsilon)\n \n+        # If the learning phase is *static* and set to inference:\n+        if training in {0, False}:\n+            return normalize_inference()\n+\n+        # If the learning is either dynamic, or set to training:\n+        normed_training, mean, variance = K.normalize_batch_in_training(\n+            inputs, self.gamma, self.beta, reduction_axes,\n+            epsilon=self.epsilon)\n+\n+        self.add_update([K.moving_average_update(self.moving_mean,\n+                                                 mean,\n+                                                 self.momentum),\n+                         K.moving_average_update(self.moving_variance,\n+                                                 variance,\n+                                                 self.momentum)],\n+                        inputs)\n+\n         # Pick the normalized form corresponding to the training phase.\n-        return K.in_train_phase(normed,\n+        return K.in_train_phase(normed_training,\n                                 normalize_inference,\n                                 training=training)\n \n\n@@ -52,6 +52,31 @@ def test_batchnorm_correctness():\n     assert_allclose(out.std(), 1.0, atol=1e-1)\n \n \n+@keras_test\n+def test_batchnorm_training_argument():\n+    bn1 = normalization.BatchNormalization(input_shape=(10,))\n+    x1 = Input(shape=(10,))\n+    y1 = bn1(x1, training=True)\n+    assert bn1.updates\n+\n+    model1 = Model(x1, y1)\n+    np.random.seed(123)\n+    x = np.random.normal(loc=5.0, scale=10.0, size=(20, 10))\n+    output_a = model1.predict(x)\n+\n+    model1.compile(loss='mse', optimizer='rmsprop')\n+    model1.fit(x, x, epochs=1, verbose=0)\n+    output_b = model1.predict(x)\n+    assert np.abs(np.sum(output_a - output_b)) > 0.1\n+    assert_allclose(output_b.mean(), 0.0, atol=1e-1)\n+    assert_allclose(output_b.std(), 1.0, atol=1e-1)\n+\n+    bn2 = normalization.BatchNormalization(input_shape=(10,))\n+    x2 = Input(shape=(10,))\n+    bn2(x2, training=False)\n+    assert not bn2.updates\n+\n+\n @keras_test\n def test_batchnorm_mode_twice():\n     # This is a regression test for issue #4881 with the old\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2bb9014c9100a5b0344ba81af7eca8698228883a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 4926 | Contributors (this commit): 65 | Commits (past 90d): 39 | Contributors (cumulative): 65 | DMM Complexity: None\n\nDIFF:\n@@ -1934,10 +1934,14 @@ def pool2d(x, pool_size, strides=(1, 1), padding='valid',\n                                 pad=pad,\n                                 mode='max')\n     elif pool_mode == 'avg':\n+        if padding == 'same':\n+            th_avg_pool_mode = 'average_inc_pad'\n+        elif padding == 'valid':\n+            th_avg_pool_mode = 'average_exc_pad'\n         pool_out = pool.pool_2d(x, ws=pool_size, stride=strides,\n                                 ignore_border=True,\n                                 pad=pad,\n-                                mode='average_exc_pad')\n+                                mode=th_avg_pool_mode)\n     else:\n         raise ValueError('Invalid pooling mode:', pool_mode)\n     if padding == 'same':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#791cba094c757b04280fd8bffdfcd67c93ea7de4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 194 | Contributors (this commit): 4 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -78,6 +78,7 @@ def convert_kernel(kernel):\n     # Raises\n         ValueError: in case of invalid kernel shape or invalid data_format.\n     \"\"\"\n+    kernel = np.asarray(kernel)\n     if not 4 <= kernel.ndim <= 5:\n         raise ValueError('Invalid kernel shape:', kernel.shape)\n     slices = [slice(None, None, -1) for _ in range(kernel.ndim)]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0d4fb04c7f460f7548c916e022310c0048051613", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 2130 | Contributors (this commit): 24 | Commits (past 90d): 9 | Contributors (cumulative): 24 | DMM Complexity: None\n\nDIFF:\n@@ -325,9 +325,9 @@ def load_img(path, grayscale=False, target_size=None):\n         if img.mode != 'RGB':\n             img = img.convert('RGB')\n     if target_size:\n-        wh_tuple = (target_size[1], target_size[0])\n-        if img.size != wh_tuple:\n-            img = img.resize(wh_tuple)\n+        hw_tuple = (target_size[1], target_size[0])\n+        if img.size != hw_tuple:\n+            img = img.resize(hw_tuple)\n     return img\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9295efb21686b4ea5a55dfa1944c4e30bd27794e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 113 | Lines Deleted: 144 | Files Changed: 1 | Hunks: 32 | Methods Changed: 10 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 257 | Churn Cumulative: 766 | Contributors (this commit): 8 | Commits (past 90d): 2 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -8,24 +8,16 @@ e.g.:\n ```\n python deep_dream.py img/mypic.jpg results/dream\n ```\n-\n-It is preferable to run this script on GPU, for speed.\n-If running on CPU, prefer the TensorFlow backend (much faster).\n-\n-Example results: http://i.imgur.com/FX6ROg9.jpg\n '''\n from __future__ import print_function\n \n from keras.preprocessing.image import load_img, img_to_array\n import numpy as np\n-from scipy.misc import imsave\n-from scipy.optimize import fmin_l_bfgs_b\n-import time\n+import scipy\n import argparse\n \n-from keras.applications import vgg16\n+from keras.applications import inception_v3\n from keras import backend as K\n-from keras.layers import Input\n \n parser = argparse.ArgumentParser(description='Deep Dreams with Keras.')\n parser.add_argument('base_image_path', metavar='base', type=str,\n@@ -37,183 +29,160 @@ args = parser.parse_args()\n base_image_path = args.base_image_path\n result_prefix = args.result_prefix\n \n-# dimensions of the generated picture.\n-img_height = 600\n-img_width = 600\n-\n-# some settings we found interesting\n-saved_settings = {\n-    'bad_trip': {'features': {'block4_conv1': 0.05,\n-                              'block4_conv2': 0.01,\n-                              'block4_conv3': 0.01},\n-                 'continuity': 0.1,\n-                 'dream_l2': 0.8,\n-                 'jitter': 5},\n-    'dreamy': {'features': {'block5_conv1': 0.05,\n-                            'block5_conv2': 0.02},\n-               'continuity': 0.1,\n-               'dream_l2': 0.02,\n-               'jitter': 0},\n+# These are the names of the layers\n+# for which we try to maximize activation,\n+# as well as their weight in the final loss\n+# we try to maximize.\n+# You can tweak these setting to obtain new visual effects.\n+settings = {\n+    'features': {\n+        'mixed2': 0.5,\n+        'mixed3': 1.,\n+        'mixed4': 1.,\n+    },\n }\n-# the settings we will use in this experiment\n-settings = saved_settings['dreamy']\n \n \n def preprocess_image(image_path):\n-    # util function to open, resize and format pictures\n-    # into appropriate tensors\n-    img = load_img(image_path, target_size=(img_height, img_width))\n+    # Util function to open, resize and format pictures\n+    # into appropriate tensors.\n+    img = load_img(image_path)\n     img = img_to_array(img)\n     img = np.expand_dims(img, axis=0)\n-    img = vgg16.preprocess_input(img)\n+    img = inception_v3.preprocess_input(img)\n     return img\n \n \n def deprocess_image(x):\n-    # util function to convert a tensor into a valid image\n+    # Util function to convert a tensor into a valid image.\n     if K.image_data_format() == 'channels_first':\n-        x = x.reshape((3, img_height, img_width))\n+        x = x.reshape((3, x.shape[2], x.shape[3]))\n         x = x.transpose((1, 2, 0))\n     else:\n-        x = x.reshape((img_height, img_width, 3))\n-    # Remove zero-center by mean pixel\n-    x[:, :, 0] += 103.939\n-    x[:, :, 1] += 116.779\n-    x[:, :, 2] += 123.68\n-    # 'BGR'->'RGB'\n-    x = x[:, :, ::-1]\n+        x = x.reshape((x.shape[1], x.shape[2], 3))\n+    x /= 2.\n+    x += 0.5\n+    x *= 255.\n     x = np.clip(x, 0, 255).astype('uint8')\n     return x\n \n-if K.image_data_format() == 'channels_first':\n-    img_size = (3, img_height, img_width)\n-else:\n-    img_size = (img_height, img_width, 3)\n-# this will contain our generated image\n-dream = Input(batch_shape=(1,) + img_size)\n+K.set_learning_phase(0)\n \n-# build the VGG16 network with our placeholder\n-# the model will be loaded with pre-trained ImageNet weights\n-model = vgg16.VGG16(input_tensor=dream,\n-                    weights='imagenet', include_top=False)\n+# Build the InceptionV3 network with our placeholder.\n+# The model will be loaded with pre-trained ImageNet weights.\n+model = inception_v3.InceptionV3(weights='imagenet',\n+                                 include_top=False)\n+dream = model.input\n print('Model loaded.')\n \n-# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n+# Get the symbolic outputs of each \"key\" layer (we gave them unique names).\n layer_dict = dict([(layer.name, layer) for layer in model.layers])\n \n-\n-def continuity_loss(x):\n-    # continuity loss util function\n-    assert K.ndim(x) == 4\n-    if K.image_data_format() == 'channels_first':\n-        a = K.square(x[:, :, :img_height - 1, :img_width - 1] -\n-                     x[:, :, 1:, :img_width - 1])\n-        b = K.square(x[:, :, :img_height - 1, :img_width - 1] -\n-                     x[:, :, :img_height - 1, 1:])\n-    else:\n-        a = K.square(x[:, :img_height - 1, :img_width - 1, :] -\n-                     x[:, 1:, :img_width - 1, :])\n-        b = K.square(x[:, :img_height - 1, :img_width - 1, :] -\n-                     x[:, :img_height - 1, 1:, :])\n-    return K.sum(K.pow(a + b, 1.25))\n-\n-# define the loss\n+# Define the loss.\n loss = K.variable(0.)\n for layer_name in settings['features']:\n-    # add the L2 norm of the features of a layer to the loss\n+    # Add the L2 norm of the features of a layer to the loss.\n     assert layer_name in layer_dict.keys(), 'Layer ' + layer_name + ' not found in model.'\n     coeff = settings['features'][layer_name]\n     x = layer_dict[layer_name].output\n-    shape = layer_dict[layer_name].output_shape\n-    # we avoid border artifacts by only involving non-border pixels in the loss\n+    # We avoid border artifacts by only involving non-border pixels in the loss.\n+    scaling = K.prod(K.cast(K.shape(x), 'float32'))\n     if K.image_data_format() == 'channels_first':\n-        loss -= coeff * K.sum(K.square(x[:, :, 2: shape[2] - 2, 2: shape[3] - 2])) / np.prod(shape[1:])\n+        loss += coeff * K.sum(K.square(x[:, :, 2: -2, 2: -2])) / scaling\n     else:\n-        loss -= coeff * K.sum(K.square(x[:, 2: shape[1] - 2, 2: shape[2] - 2, :])) / np.prod(shape[1:])\n+        loss += coeff * K.sum(K.square(x[:, 2: -2, 2: -2, :])) / scaling\n \n-# add continuity loss (gives image local coherence, can result in an artful blur)\n-loss += settings['continuity'] * continuity_loss(dream) / np.prod(img_size)\n-# add image L2 norm to loss (prevents pixels from taking very high values, makes image darker)\n-loss += settings['dream_l2'] * K.sum(K.square(dream)) / np.prod(img_size)\n+# Compute the gradients of the dream wrt the loss.\n+grads = K.gradients(loss, dream)[0]\n+# Normalize gradients.\n+grads /= K.maximum(K.mean(K.abs(grads)), 1e-7)\n \n-# feel free to further modify the loss as you see fit, to achieve new effects...\n-\n-# compute the gradients of the dream wrt the loss\n-grads = K.gradients(loss, dream)\n-\n-outputs = [loss]\n-if isinstance(grads, (list, tuple)):\n-    outputs += grads\n-else:\n-    outputs.append(grads)\n-\n-f_outputs = K.function([dream], outputs)\n+# Set up function to retrieve the value\n+# of the loss and gradients given an input image.\n+outputs = [loss, grads]\n+fetch_loss_and_grads = K.function([dream], outputs)\n \n \n def eval_loss_and_grads(x):\n-    x = x.reshape((1,) + img_size)\n-    outs = f_outputs([x])\n+    outs = fetch_loss_and_grads([x])\n     loss_value = outs[0]\n-    if len(outs[1:]) == 1:\n-        grad_values = outs[1].flatten().astype('float64')\n-    else:\n-        grad_values = np.array(outs[1:]).flatten().astype('float64')\n+    grad_values = outs[1]\n     return loss_value, grad_values\n \n \n-class Evaluator(object):\n-    \"\"\"Loss and gradients evaluator.\n+def resize_img(img, size):\n+    img = np.copy(img)\n+    if K.image_data_format() == 'channels_first':\n+        factors = (1, 1,\n+                   float(size[0]) / img.shape[2],\n+                   float(size[1]) / img.shape[3])\n+    else:\n+        factors = (1,\n+                   float(size[0]) / img.shape[1],\n+                   float(size[1]) / img.shape[2],\n+                   1)\n+    return scipy.ndimage.zoom(img, factors, order=1)\n \n-    This Evaluator class makes it possible\n-    to compute loss and gradients in one pass\n-    while retrieving them via two separate functions,\n-    \"loss\" and \"grads\". This is done because scipy.optimize\n-    requires separate functions for loss and gradients,\n-    but computing them separately would be inefficient.\n+\n+def gradient_ascent(x, iterations, step):\n+    for i in range(iterations):\n+        loss_value, grad_values = eval_loss_and_grads(x)\n+        print('..Loss value at', i, ':', loss_value)\n+        x += step * grad_values\n+    return x\n+\n+\n+def save_img(img, fname):\n+    pil_img = deprocess_image(np.copy(img))\n+    scipy.misc.imsave(fname, pil_img)\n+\n+\n+\"\"\"Process:\n+\n+- Load the original image.\n+- Define a number of processing scales (i.e. image shapes),\n+    from smallest to largest.\n+- Resize the original image to the smallest scale.\n+- For every scale, starting with the smallest (i.e. current one):\n+    - Run gradient ascent\n+    - Upscale image to the next scale\n+    - Reinject the detail that was lost at upscaling time\n+- Stop when we are back to the original size.\n+\n+To obtain the detail lost during upscaling, we simply\n+take the original image, shrink it down, upscale it,\n+and compare the result to the (resized) original image.\n \"\"\"\n \n-    def __init__(self):\n-        self.loss_value = None\n-        self.grad_values = None\n \n-    def loss(self, x):\n-        assert self.loss_value is None\n-        loss_value, grad_values = eval_loss_and_grads(x)\n-        self.loss_value = loss_value\n-        self.grad_values = grad_values\n-        return self.loss_value\n+step = 0.003  # Gradient ascent step size\n+num_octave = 4  # Number of scales at which to run gradient ascent\n+octave_scale = 1.3  # Size ratio between scales\n+iterations = 20  # Number of ascent steps per scale\n \n-    def grads(self, x):\n-        assert self.loss_value is not None\n-        grad_values = np.copy(self.grad_values)\n-        self.loss_value = None\n-        self.grad_values = None\n-        return grad_values\n+img = preprocess_image(base_image_path)\n+if K.image_data_format() == 'channels_first':\n+    original_shape = img.shape[2:]\n+else:\n+    original_shape = img.shape[1:3]\n+successive_shapes = [original_shape]\n+for i in range(1, num_octave):\n+    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n+    successive_shapes.append(shape)\n+successive_shapes = successive_shapes[::-1]\n+original_img = np.copy(img)\n+shrunk_original_img = resize_img(img, successive_shapes[0])\n \n-evaluator = Evaluator()\n+for shape in successive_shapes:\n+    print('Processing image shape', shape)\n+    img = resize_img(img, shape)\n+    img = gradient_ascent(img, iterations=iterations, step=step)\n \n-# Run scipy-based optimization (L-BFGS) over the pixels of the generated image\n-# so as to minimize the loss\n-x = preprocess_image(base_image_path)\n-for i in range(5):\n-    print('Start of iteration', i)\n-    start_time = time.time()\n+    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n+    same_size_original = resize_img(original_img, shape)\n+    lost_detail = same_size_original - upscaled_shrunk_original_img\n \n-    # Add a random jitter to the initial image.\n-    # This will be reverted at decoding time\n-    random_jitter = (settings['jitter'] * 2) * (np.random.random(img_size) - 0.5)\n-    x += random_jitter\n+    img += lost_detail\n+    shrunk_original_img = resize_img(original_img, shape)\n \n-    # Run L-BFGS for 7 steps\n-    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n-                                     fprime=evaluator.grads, maxfun=7)\n-    print('Current loss value:', min_val)\n-    # Decode the dream and save it\n-    x = x.reshape(img_size)\n-    x -= random_jitter\n-    img = deprocess_image(np.copy(x))\n-    fname = result_prefix + '_at_iteration_%d.png' % i\n-    imsave(fname, img)\n-    end_time = time.time()\n-    print('Image saved as', fname)\n-    print('Iteration %d completed in %ds' % (i, end_time - start_time))\n+save_img(img, fname=result_prefix + '.png')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
