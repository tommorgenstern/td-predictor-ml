{"custom_id": "keras#2d167255d5cd595d2890f761e35ba4aeb3935237", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 920 | Contributors (this commit): 6 | Commits (past 90d): 6 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -320,7 +320,8 @@ class ExportArchive:\n \n                 def stateful_fn(*args, **kwargs):\n                     return jax2tf_stateless_fn(\n-                        self._tf_trackable.variables, *args, **kwargs\n+                        # Change the trackable `ListWrapper` to a plain `list`\n+                        list(self._tf_trackable.variables), *args, **kwargs\n                     )\n \n                 # Note: we truncate the number of parameters to what is\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#104fe8e252c32ada20843c9f757ff5008d241794", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 924 | Contributors (this commit): 6 | Commits (past 90d): 7 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -321,7 +321,9 @@ class ExportArchive:\n                 def stateful_fn(*args, **kwargs):\n                     return jax2tf_stateless_fn(\n                         # Change the trackable `ListWrapper` to a plain `list`\n-                        list(self._tf_trackable.variables), *args, **kwargs\n+                        list(self._tf_trackable.variables),\n+                        *args,\n+                        **kwargs,\n                     )\n \n                 # Note: we truncate the number of parameters to what is\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b57bfcd46a9d30d1354651f7488fb31c2928def3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 15 | Churn Cumulative: 2494 | Contributors (this commit): 12 | Commits (past 90d): 13 | Contributors (cumulative): 14 | DMM Complexity: 0.8461538461538461\n\nDIFF:\n@@ -2707,6 +2707,8 @@ class GetItem(Operation):\n             remaining_key = [key]\n         elif isinstance(key, tuple):\n             remaining_key = list(key)\n+        elif isinstance(key, list):\n+            remaining_key = key.copy()\n         else:\n             raise ValueError(\n                 f\"Unsupported key type for array slice. Recieved: `{key}`\"\n\n@@ -94,6 +94,19 @@ class SerializationLibTest(testing.TestCase):\n         self.assertEqual(layer.trainable, restored.trainable)\n         self.assertEqual(layer.compute_dtype, restored.compute_dtype)\n \n+    def test_numpy_get_item_layer(self):\n+        def tuples_to_lists_str(x):\n+            return str(x).replace(\"(\", \"[\").replace(\")\", \"]\")\n+\n+        input = keras.layers.Input(shape=(2,))\n+        layer = input[:, 1]\n+        model = keras.Model(input, layer)\n+        serialized, _, reserialized = self.roundtrip(model)\n+        # Anticipate JSON roundtrip mapping tuples to lists:\n+        serialized_str = tuples_to_lists_str(serialized)\n+        reserialized_str = tuples_to_lists_str(reserialized)\n+        self.assertEqual(serialized_str, reserialized_str)\n+\n     def test_tensors_and_shapes(self):\n         x = ops.random.normal((2, 2), dtype=\"float64\")\n         obj = {\"x\": x}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6c591d7d34c3ffaa50e805fd75c83d9c2a23414f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 93 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 6 | Methods Changed: 6 | Complexity Δ (Sum/Max): 6/3 | Churn Δ: 93 | Churn Cumulative: 584 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4,6 +4,7 @@ from keras.losses.losses import BinaryCrossentropy\n from keras.losses.losses import CategoricalCrossentropy\n from keras.losses.losses import CategoricalHinge\n from keras.losses.losses import CosineSimilarity\n+from keras.losses.losses import Dice\n from keras.losses.losses import Hinge\n from keras.losses.losses import Huber\n from keras.losses.losses import KLDivergence\n@@ -21,6 +22,7 @@ from keras.losses.losses import categorical_crossentropy\n from keras.losses.losses import categorical_hinge\n from keras.losses.losses import cosine_similarity\n from keras.losses.losses import ctc\n+from keras.losses.losses import dice\n from keras.losses.losses import hinge\n from keras.losses.losses import huber\n from keras.losses.losses import kl_divergence\n@@ -56,6 +58,8 @@ ALL_OBJECTS = {\n     Hinge,\n     SquaredHinge,\n     CategoricalHinge,\n+    # Image segmentation\n+    Dice,\n     # Probabilistic\n     kl_divergence,\n     poisson,\n@@ -74,6 +78,8 @@ ALL_OBJECTS = {\n     hinge,\n     squared_hinge,\n     categorical_hinge,\n+    # Image segmentation\n+    dice,\n }\n \n ALL_OBJECTS_DICT = {cls.__name__: cls for cls in ALL_OBJECTS}\n\n@@ -1934,3 +1934,69 @@ def ctc(y_true, y_pred):\n     return ops.ctc_loss(\n         y_true, y_pred, label_length, input_length, mask_index=0\n     )\n+\n+\n+@keras_export(\"keras.losses.Dice\")\n+class Dice(LossFunctionWrapper):\n+    \"\"\"Computes the Dice loss value between `y_true` and `y_pred`.\n+\n+    Formula:\n+    ```python\n+    loss = 1 - (2 * sum(y_true * y_pred)) / (sum(y_true) + sum(y_pred))\n+    ```\n+\n+    Args:\n+        y_true: tensor of true targets.\n+        y_pred: tensor of predicted targets.\n+\n+    Returns:\n+        Dice loss value.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        reduction=\"sum_over_batch_size\",\n+        name=\"dice\",\n+    ):\n+        super().__init__(\n+            dice,\n+            name=name,\n+            reduction=reduction,\n+        )\n+\n+    def get_config(self):\n+        return {\n+            \"name\": self.name,\n+            \"reduction\": self.reduction,\n+        }\n+\n+\n+@keras_export(\"keras.losses.dice\")\n+def dice(y_true, y_pred):\n+    \"\"\"Computes the Dice loss value between `y_true` and `y_pred`.\n+\n+    Formula:\n+    ```python\n+    loss = 1 - (2 * sum(y_true * y_pred)) / (sum(y_true) + sum(y_pred))\n+    ```\n+\n+    Args:\n+        y_true: tensor of true targets.\n+        y_pred: tensor of predicted targets.\n+\n+    Returns:\n+        Dice loss value.\n+    \"\"\"\n+    y_pred = ops.convert_to_tensor(y_pred)\n+    y_true = ops.cast(y_true, y_pred.dtype)\n+\n+    inputs = ops.reshape(y_true, [-1])\n+    targets = ops.reshape(y_pred, [-1])\n+\n+    intersection = ops.sum(inputs * targets)\n+    dice = ops.divide(\n+        2.0 * intersection,\n+        ops.sum(y_true) + ops.sum(y_pred) + backend.epsilon(),\n+    )\n+\n+    return 1 - dice\n\n@@ -1388,3 +1388,24 @@ class CTCTest(testing.TestCase):\n         y_true = np.array(([[1, 2, 1, 0], [1, 2, 0, 2]]))\n         output = losses.CTC()(y_true, logits)\n         self.assertAllClose(output, 4.389582)\n+\n+\n+class DiceTest(testing.TestCase):\n+    def test_config(self):\n+        self.run_class_serialization_test(losses.Dice(name=\"mydice\"))\n+\n+    def test_correctness(self):\n+        y_true = np.array(([[1, 2], [1, 2]]))\n+        y_pred = np.array(([[4, 1], [6, 1]]))\n+        output = losses.Dice()(y_true, y_pred)\n+        self.assertAllClose(output, -0.55555546)\n+\n+    def test_binary_segmentation(self):\n+        y_true = np.array(\n+            ([[1, 0, 1, 0], [0, 1, 0, 1], [1, 0, 1, 0], [0, 1, 0, 1]])\n+        )\n+        y_pred = np.array(\n+            ([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 1], [1, 0, 1, 1]])\n+        )\n+        output = losses.Dice()(y_true, y_pred)\n+        self.assertAllClose(output, 0.77777773)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b2eb9649e66762dacab6d3cb1b8b4ffd3360e96e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 7 | Methods Changed: 6 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 39 | Churn Cumulative: 1106 | Contributors (this commit): 8 | Commits (past 90d): 8 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -15,6 +15,7 @@ from keras.models.model import Model\n from keras.ops.function import Function\n from keras.ops.function import _build_map\n from keras.ops.function import make_node_key\n+from keras.ops.node import KerasHistory\n from keras.ops.node import Node\n from keras.saving import serialization_lib\n from keras.utils import tracking\n@@ -391,7 +392,7 @@ class Functional(Function, Model):\n                 if node_key in self._nodes:\n                     # The node is relevant to the model:\n                     # add to filtered_inbound_nodes.\n-                    node_data = serialize_node(node, node_reindexing_map)\n+                    node_data = serialize_node(node, own_nodes=self._nodes)\n                     if node_data is not None:\n                         filtered_inbound_nodes.append(node_data)\n \n@@ -594,13 +595,33 @@ def unpack_singleton(x):\n     return x\n \n \n-def serialize_node(node, node_reindexing_map):\n+def serialize_node(node, own_nodes=()):\n     if not node.input_tensors:\n         # Does not need to be serialized.\n         return\n \n+    def serialize_keras_tensor(x):\n+        # Serialize KerasTensor while converting\n+        # node indices to only include nodes relevant to `own_nodes`.\n+        if isinstance(x, backend.KerasTensor):\n+            operation, node_index, tensor_index = x._keras_history\n+            irrelevant_node_count = 0\n+            for node in operation._inbound_nodes[:node_index]:\n+                if node not in own_nodes:\n+                    irrelevant_node_count += 1\n+            x._keras_history = KerasHistory(\n+                operation, node_index - irrelevant_node_count, tensor_index\n+            )\n+            serialized = serialization_lib.serialize_keras_object(x)\n+            x._keras_history = KerasHistory(operation, node_index, tensor_index)\n+            return serialized\n+        return x\n+\n     args = node.arguments.args\n     kwargs = node.arguments.kwargs\n+\n+    args = tree.map_structure(serialize_keras_tensor, args)\n+    kwargs = tree.map_structure(serialize_keras_tensor, kwargs)\n     return {\n         \"args\": serialization_lib.serialize_keras_object(args),\n         \"kwargs\": serialization_lib.serialize_keras_object(kwargs),\n\n@@ -203,7 +203,7 @@ def map_graph(inputs, outputs):\n \n     Returns:\n         A tuple `(nodes, nodes_by_depth, operations, operations_by_depth)`.\n-        - network_nodes: dict mapping unique node keys to the Node instances\n+        - nodes: set of Node instances\n         - nodes_by_depth: dict mapping ints (depth) to lists of node instances.\n         - operations: list of Operation instances.\n         - operations_by_depth: dict mapping ints (depth) to lists of Operation\n\n@@ -327,6 +327,18 @@ class SerializationLibTest(testing.TestCase):\n         self.assertIs(layers[0].activation, layers[1].activation)\n         self.assertIs(new_layers[0].activation, new_layers[1].activation)\n \n+    def test_layer_sharing(self):\n+        seq = keras.Sequential(\n+            [\n+                keras.Input(shape=(3,)),\n+                keras.layers.Dense(5),\n+                keras.layers.Softmax(),\n+            ],\n+        )\n+        func = keras.Model(inputs=seq.inputs, outputs=seq.outputs)\n+        serialized, deserialized, reserialized = self.roundtrip(func)\n+        self.assertLen(deserialized.layers, 3)\n+\n \n @keras.saving.register_keras_serializable()\n class MyDense(keras.layers.Layer):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f61a5337a07459a821a333feb95327f1021f8df0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 3 | Churn Cumulative: 1141 | Contributors (this commit): 6 | Commits (past 90d): 3 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -237,7 +237,6 @@ def load_weights_only(model, filepath, skip_mismatch=False):\n \n     Note: only supports h5 for now.\n     \"\"\"\n-    temp_dir = None\n     archive = None\n     filepath = str(filepath)\n     if filepath.endswith(\".weights.h5\"):\n@@ -262,8 +261,6 @@ def load_weights_only(model, filepath, skip_mismatch=False):\n         error_msgs=error_msgs,\n     )\n     weights_store.close()\n-    if temp_dir and file_utils.exists(temp_dir):\n-        file_utils.rmtree(temp_dir)\n     if archive:\n         archive.close()\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6c0d75f1c46522b3dff578e2a502b3ff57938456", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 3 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 587 | Contributors (this commit): 8 | Commits (past 90d): 10 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -40,8 +40,8 @@ def softsign(x):\n     return tf.nn.softsign(x)\n \n \n-def silu(x, beta=1.0):\n-    return tf.nn.silu(x, beta=beta)\n+def silu(x):\n+    return tf.nn.silu(x)\n \n \n def log_sigmoid(x):\n\n@@ -47,9 +47,9 @@ def softsign(x):\n     return tnn.softsign(x)\n \n \n-def silu(x, beta=1.0):\n+def silu(x):\n     x = convert_to_tensor(x)\n-    return x * sigmoid(beta * x)\n+    return tnn.silu(x)\n \n \n def log_sigmoid(x):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d7f4605935614150863e1aa8508702599b28601a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 23 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -360,7 +360,10 @@ def print_summary(\n \n     # Output captured summary for non-interactive logging.\n     if print_fn:\n+        if print_fn is io_utils.print_msg:\n             print_fn(console.end_capture(), line_break=False)\n+        else:\n+            print_fn(console.end_capture())\n \n \n def get_layer_index_bound_by_layer_name(layers, layer_range=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7e5a6089d386a7a04364c5e1b83a352b55e1a1e0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 34 | Churn Cumulative: 3746 | Contributors (this commit): 11 | Commits (past 90d): 2 | Contributors (cumulative): 20 | DMM Complexity: 1.0\n\nDIFF:\n@@ -182,13 +182,13 @@ class Bidirectional(Wrapper):\n             output_shape[-1] *= 2\n             output_shape = tuple(output_shape)\n         elif self.merge_mode is None:\n-            output_shape = [output_shape, copy.copy(output_shape)]\n+            output_shape = [output_shape, output_shape]\n \n         if self.return_state:\n             if self.merge_mode is None:\n-                return output_shape + state_shape + copy.copy(state_shape)\n-            return [output_shape] + state_shape + copy.copy(state_shape)\n-        return output_shape\n+                return tuple(output_shape) + state_shape + state_shape\n+            return tuple([output_shape]) + (state_shape) + (state_shape)\n+        return tuple(output_shape)\n \n     def call(\n         self,\n\n@@ -234,3 +234,29 @@ class SimpleRNNTest(testing.TestCase):\n             np.array([[0.2501858, 0.2501858], [0.941473, 0.941473]]),\n             c2,\n         )\n+\n+    @pytest.mark.requires_trainable_backend\n+    def test_output_shape(self):\n+        x = np.array([[[101, 202], [303, 404]]])\n+        for merge_mode in [\"ave\", \"concat\", \"mul\", \"sum\", None]:\n+            sub_layer = layers.LSTM(2, return_state=True)\n+            layer = layers.Bidirectional(sub_layer, merge_mode=merge_mode)\n+            output = layer(x)\n+            output_shape = layer.compute_output_shape(x.shape)\n+            for out, shape in zip(output, output_shape):\n+                self.assertEqual(out.shape, shape)\n+\n+        for merge_mode in [\"concat\", \"ave\", \"mul\", \"sum\"]:\n+            sub_layer = layers.LSTM(2, return_state=False)\n+            layer = layers.Bidirectional(sub_layer, merge_mode=merge_mode)\n+            output = layer(x)\n+            output_shape = layer.compute_output_shape(x.shape)\n+            self.assertEqual(output.shape, output_shape)\n+\n+        # return_state=False & merge_mode=None\n+        sub_layer = layers.LSTM(2, return_state=False)\n+        layer = layers.Bidirectional(sub_layer, merge_mode=None)\n+        output = layer(x)\n+        output_shape = layer.compute_output_shape(x.shape)\n+        for out, shape in zip(output, output_shape):\n+            self.assertEqual(out.shape, shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b53b4d635713e055586cf237cd22717566d79f79", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 62 | Lines Deleted: 6 | Files Changed: 4 | Hunks: 12 | Methods Changed: 14 | Complexity Δ (Sum/Max): 13/6 | Churn Δ: 68 | Churn Cumulative: 830 | Contributors (this commit): 9 | Commits (past 90d): 29 | Contributors (cumulative): 15 | DMM Complexity: 0.375\n\nDIFF:\n@@ -11,9 +11,13 @@ class name_scope:\n             and the previous caller matches the current caller,\n             and the previous name matches the current name,\n             do not reenter a new namespace.\n+        override_parent: Can be used to provide an absolute path\n+            which would override any previously opened name scopes.\n     \"\"\"\n \n-    def __init__(self, name, caller=None, deduplicate=True):\n+    def __init__(\n+        self, name, caller=None, deduplicate=True, override_parent=None\n+    ):\n         if not isinstance(name, str) or \"/\" in name:\n             raise ValueError(\n                 \"Argument `name` must be a string and \"\n@@ -23,6 +27,13 @@ class name_scope:\n         self.name = name\n         self.caller = caller\n         self.deduplicate = deduplicate\n+        self.override_parent = override_parent\n+        if (\n+            override_parent is None\n+            and deduplicate\n+            and getattr(caller, \"_parent_path\", None) is not None\n+        ):\n+            self.override_parent = caller._parent_path\n         self._pop_on_exit = False\n \n     def __enter__(self):\n@@ -54,4 +65,9 @@ def current_path():\n     name_scope_stack = global_state.get_global_attribute(\"name_scope_stack\")\n     if name_scope_stack is None:\n         return \"\"\n-    return \"/\".join(x.name for x in name_scope_stack)\n+    parts = []\n+    for entry in name_scope_stack:\n+        if entry.override_parent is not None:\n+            parts = [p for p in entry.override_parent.split(\"/\") if p]\n+        parts.append(entry.name)\n+    return \"/\".join(parts)\n\n@@ -34,3 +34,15 @@ class NameScopeTest(testing.TestCase):\n             name_scope(\"foo/bar\")\n         with self.assertRaisesRegex(ValueError, \"must be a string\"):\n             name_scope(4)\n+\n+    def test_override_parent(self):\n+        self.assertEqual(current_path(), \"\")\n+        with name_scope(\"outer\"):\n+            self.assertEqual(current_path(), \"outer\")\n+            with name_scope(\"middle\", override_parent=\"/absolute/path\"):\n+                self.assertEqual(current_path(), \"absolute/path/middle\")\n+                with name_scope(\"inner\"):\n+                    self.assertEqual(\n+                        current_path(), \"absolute/path/middle/inner\"\n+                    )\n+            self.assertEqual(current_path(), \"outer\")\n\n@@ -266,6 +266,27 @@ class DenseTest(testing.TestCase):\n         model.load_weights(temp_filepath)\n         self.assertAllClose(model.predict(x), new_model.predict(x))\n \n+    @pytest.mark.requires_trainable_backend\n+    def test_lora_weight_name(self):\n+\n+        class MyModel(models.Model):\n+            def __init__(self):\n+                super().__init__(name=\"mymodel\")\n+                self.dense = layers.Dense(16, name=\"dense\")\n+\n+            def build(self, input_shape):\n+                self.dense.build(input_shape)\n+\n+            def call(self, x):\n+                return self.dense(x)\n+\n+        model = MyModel()\n+        model.build((None, 8))\n+        model.dense.enable_lora(4)\n+        self.assertEqual(\n+            model.dense.lora_kernel_a.path, \"mymodel/dense/lora_kernel_a\"\n+        )\n+\n     @pytest.mark.requires_trainable_backend\n     def test_lora_rank_argument(self):\n         self.run_layer_test(\n\n@@ -218,7 +218,7 @@ class Layer(BackendLayer, Operation):\n \n         @wraps(original_build_method)\n         def build_wrapper(*args, **kwargs):\n-            with backend.name_scope(obj.name, caller=obj):\n+            with obj._open_name_scope():\n                 original_build_method(*args, **kwargs)\n             # Record build config.\n             signature = inspect.signature(original_build_method)\n@@ -289,6 +289,8 @@ class Layer(BackendLayer, Operation):\n         self._allow_non_tensor_positional_args = False\n         # Dict of shapes that were used to call `build()`.\n         self._build_shapes_dict = None\n+        # Parent path\n+        self._parent_path = None\n         self._initializer_tracker()\n \n     @tracking.no_automatic_dependency_tracking\n@@ -494,7 +496,7 @@ class Layer(BackendLayer, Operation):\n             else:\n                 initializer = \"zeros\"\n         initializer = initializers.get(initializer)\n-        with backend.name_scope(self.name, caller=self):\n+        with self._open_name_scope():\n             variable = backend.Variable(\n                 initializer=initializer,\n                 shape=shape,\n@@ -737,7 +739,7 @@ class Layer(BackendLayer, Operation):\n \n         ################\n         # 4. Call build\n-        with backend.name_scope(self.name, caller=self):\n+        with self._open_name_scope():\n             self._maybe_build(call_spec)\n \n         ##########################\n@@ -792,7 +794,7 @@ class Layer(BackendLayer, Operation):\n         ####################\n         # 7. Call the layer.\n         try:\n-            with backend.name_scope(self.name, caller=self):\n+            with self._open_name_scope():\n                 current_scope = backend.get_autocast_scope()\n                 new_scope = None\n                 if current_scope is not None:\n@@ -1401,6 +1403,11 @@ class Layer(BackendLayer, Operation):\n         }\n         return {**base_config, **config}\n \n+    def _open_name_scope(self):\n+        if self._parent_path is None:\n+            self._parent_path = current_path()\n+        return backend.name_scope(self.name, caller=self)\n+\n \n def is_backend_tensor_or_symbolic(x):\n     return backend.is_tensor(x) or isinstance(x, backend.KerasTensor)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ab2611985997d3a6e8117e7437b862aab7b9a163", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 270 | Lines Deleted: 0 | Files Changed: 6 | Hunks: 9 | Methods Changed: 14 | Complexity Δ (Sum/Max): 33/12 | Churn Δ: 270 | Churn Cumulative: 12869 | Contributors (this commit): 14 | Commits (past 90d): 72 | Contributors (cumulative): 48 | DMM Complexity: 0.6485148514851485\n\nDIFF:\n@@ -1126,3 +1126,9 @@ def logical_xor(x1, x2):\n     x1 = convert_to_tensor(x1)\n     x2 = convert_to_tensor(x2)\n     return jnp.logical_xor(x1, x2)\n+\n+\n+def correlate(x1, x2, mode=\"valid\"):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n+    return jnp.correlate(x1, x2, mode)\n\n@@ -1075,3 +1075,18 @@ def floor_divide(x1, x2):\n \n def logical_xor(x1, x2):\n     return np.logical_xor(x1, x2)\n+\n+\n+def correlate(x1, x2, mode=\"valid\"):\n+    dtype = dtypes.result_type(\n+        getattr(x1, \"dtype\", type(x1)),\n+        getattr(x2, \"dtype\", type(x2)),\n+    )\n+    if dtype == \"int64\":\n+        dtype = \"float64\"\n+    elif dtype not in [\"bfloat16\", \"float16\", \"float64\"]:\n+        dtype = \"float32\"\n+\n+    x1 = convert_to_tensor(x1, dtype)\n+    x2 = convert_to_tensor(x2, dtype)\n+    return np.correlate(x1, x2, mode)\n\n@@ -2069,3 +2069,45 @@ def logical_xor(x1, x2):\n     x1 = tf.cast(x1, \"bool\")\n     x2 = tf.cast(x2, \"bool\")\n     return tf.math.logical_xor(x1, x2)\n+\n+\n+def correlate(x1, x2, mode=\"valid\"):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n+\n+    dtype = dtypes.result_type(\n+        getattr(x1, \"dtype\", type(x1)),\n+        getattr(x2, \"dtype\", type(x2)),\n+    )\n+    if dtype == tf.int64:\n+        dtype = tf.float64\n+    elif dtype not in [tf.bfloat16, tf.float16, tf.float64]:\n+        dtype = tf.float32\n+\n+    x1 = tf.cast(x1, dtype)\n+    x2 = tf.cast(x2, dtype)\n+\n+    x1_len, x2_len = int(x1.shape[0]), int(x2.shape[0])\n+\n+    if mode == \"full\":\n+        full_len = x1_len + x2_len - 1\n+\n+        x1_pad = (full_len - x1_len) / 2\n+        x2_pad = (full_len - x2_len) / 2\n+\n+        x1 = tf.pad(\n+            x1, paddings=[[tf.math.floor(x1_pad), tf.math.ceil(x1_pad)]]\n+        )\n+        x2 = tf.pad(\n+            x2, paddings=[[tf.math.floor(x2_pad), tf.math.ceil(x2_pad)]]\n+        )\n+\n+        x1 = tf.reshape(x1, (1, full_len, 1))\n+        x2 = tf.reshape(x2, (full_len, 1, 1))\n+\n+        return tf.squeeze(tf.nn.conv1d(x1, x2, stride=1, padding=\"SAME\"))\n+\n+    x1 = tf.reshape(x1, (1, x1_len, 1))\n+    x2 = tf.reshape(x2, (x2_len, 1, 1))\n+\n+    return tf.squeeze(tf.nn.conv1d(x1, x2, stride=1, padding=mode.upper()))\n\n@@ -1520,3 +1520,50 @@ def floor_divide(x1, x2):\n def logical_xor(x1, x2):\n     x1, x2 = convert_to_tensor(x1), convert_to_tensor(x2)\n     return torch.logical_xor(x1, x2)\n+\n+\n+def correlate(x1, x2, mode=\"valid\"):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n+\n+    dtype = dtypes.result_type(\n+        getattr(x1, \"dtype\", type(x1)),\n+        getattr(x2, \"dtype\", type(x2)),\n+    )\n+    if dtype == \"int64\":\n+        dtype = \"float64\"\n+    elif dtype not in [\"bfloat16\", \"float16\", \"float64\"]:\n+        dtype = \"float32\"\n+\n+    x1 = cast(x1, dtype)\n+    x2 = cast(x2, dtype)\n+\n+    x1_len, x2_len = x1.size(0), x2.size(0)\n+\n+    if x1.shape[:-1] != x2.shape[:-1]:\n+        new_shape = [max(i, j) for i, j in zip(x1.shape[:-1], x2.shape[:-1])]\n+        x1 = torch.broadcast_to(x1, new_shape + [x1.shape[-1]])\n+        x2 = torch.broadcast_to(x2, new_shape + [x2.shape[-1]])\n+\n+    num_signals = torch.tensor(x1.shape[:-1]).prod()\n+    x1 = torch.reshape(x1, (int(num_signals), x1.size(-1)))\n+    x2 = torch.reshape(x2, (int(num_signals), x2.size(-1)))\n+\n+    output = torch.nn.functional.conv1d(\n+        x1, x2.unsqueeze(1), groups=x1.size(0), padding=x2.size(-1) - 1\n+    )\n+    output_shape = x1.shape[:-1] + (-1,)\n+    result = output.reshape(output_shape)\n+\n+    if mode == \"valid\":\n+        target_length = (\n+            builtins.max(x1_len, x2_len) - builtins.min(x1_len, x2_len) + 1\n+        )\n+        start_idx = (result.size(-1) - target_length) // 2\n+        result = result[..., start_idx : start_idx + target_length]\n+\n+    if mode == \"same\":\n+        start_idx = (result.size(-1) - x1_len) // 2\n+        result = result[..., start_idx : start_idx + x1_len]\n+\n+    return torch.squeeze(result)\n\n@@ -29,6 +29,7 @@ concatenate\n conj\n conjugate\n copy\n+correlate\n cos\n cosh\n count_nonzero\n@@ -6085,3 +6086,70 @@ def logical_xor(x1, x2):\n     if any_symbolic_tensors((x1, x2)):\n         return LogicalXor().symbolic_call(x1, x2)\n     return backend.numpy.logical_xor(x1, x2)\n+\n+\n+class Correlate(Operation):\n+    def __init__(self, mode=\"valid\"):\n+        super().__init__()\n+        self.mode = mode\n+\n+    def call(self, x1, x2):\n+        return backend.numpy.correlate(x1, x2, mode=self.mode)\n+\n+    def compute_output_spec(self, x1, x2):\n+        x1_shape = getattr(x1, \"shape\", [])\n+        x2_shape = getattr(x2, \"shape\", [])\n+        if len(x1_shape) != 1:\n+            raise ValueError(\n+                \"`x1` must be a 1-dimensional tensor, but received\"\n+                + f\"shape {x1_shape}\"\n+            )\n+        if len(x2_shape) != 1:\n+            raise ValueError(\n+                \"`x2` must be a 1-dimensional tensor, but received\"\n+                + f\"shape {x2_shape}\"\n+            )\n+        x1_len, x2_len = x1_shape[0], x2_shape[0]\n+        output_shape = (\n+            np.maximum(x1_len, x2_len) - np.minimum(x1_len, x2_len) + 1,\n+        )\n+        if self.mode == \"same\":\n+            output_shape = (np.maximum(x1_len, x2_len),)\n+        elif self.mode == \"full\":\n+            output_shape = (x1_len + x2_len - 1,)\n+        if self.mode not in (\"valid\", \"same\", \"full\"):\n+            raise ValueError(\n+                \"`mode` must be either `valid`, `same`, or `full`, but\"\n+                f\"received: {self.mode}\"\n+            )\n+        output_dtype = dtypes.result_type(\n+            getattr(x1, \"dtype\", type(x1)),\n+            getattr(x2, \"dtype\", type(x2)),\n+        )\n+        if output_dtype == \"int64\":\n+            output_dtype = \"float64\"\n+        elif output_dtype not in [\"bfloat16\", \"float16\", \"float64\"]:\n+            output_dtype = \"float32\"\n+        return KerasTensor(output_shape, dtype=output_dtype)\n+\n+\n+@keras_export([\"keras.ops.correlate\", \"keras.ops.numpy.correlate\"])\n+def correlate(x1, x2, mode=\"valid\"):\n+    \"\"\"Compute the cross-correlation of two 1-dimensional tensors.\n+\n+    Args:\n+        x1: First 1-dimensional input tensor of length M.\n+        x2: Second 1-dimensional input tensor of length N.\n+        mode: Either `valid`, `same` or `full`.\n+            By default the mode is set to `valid`, which returns\n+            an output of length max(M, N) - min(M, N) + 1.\n+            `same` returns an output of length max(M, N).\n+            `full` mode returns the convolution at each point of\n+            overlap, with an output length of N+M-1\n+\n+    Returns:\n+        Output tensor, cross-correlation of `x1` and `x2`.\n+    \"\"\"\n+    if any_symbolic_tensors((x1, x2)):\n+        return Correlate(mode=mode).symbolic_call(x1, x2)\n+    return backend.numpy.correlate(x1, x2, mode=mode)\n\n@@ -847,6 +847,39 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n             bins = KerasTensor((2, 3, 4))\n             knp.digitize(x, bins)\n \n+    def test_correlate_mode_valid(self):\n+        x = KerasTensor((3,))\n+        y = KerasTensor((3,))\n+        self.assertEqual(knp.correlate(x, y).shape, (1,))\n+        self.assertTrue(knp.correlate(x, y).dtype == \"float32\")\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor((3,))\n+            y = KerasTensor((3, 4))\n+            knp.correlate(x, y)\n+\n+    def test_correlate_mode_same(self):\n+        x = KerasTensor((3,))\n+        y = KerasTensor((3,))\n+        self.assertEqual(knp.correlate(x, y, mode=\"same\").shape, (3,))\n+        self.assertTrue(knp.correlate(x, y, mode=\"same\").dtype == \"float32\")\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor((3,))\n+            y = KerasTensor((3, 4))\n+            knp.correlate(x, y, mode=\"same\")\n+\n+    def test_correlate_mode_full(self):\n+        x = KerasTensor((3,))\n+        y = KerasTensor((3,))\n+        self.assertEqual(knp.correlate(x, y, mode=\"full\").shape, (5,))\n+        self.assertTrue(knp.correlate(x, y, mode=\"full\").dtype == \"float32\")\n+\n+        with self.assertRaises(ValueError):\n+            x = KerasTensor((3))\n+            y = KerasTensor((3, 4))\n+            knp.correlate(x, y, mode=\"full\")\n+\n \n class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n     def test_mean(self):\n@@ -4065,6 +4098,44 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(knp.LogicalXor()(x, True), np.logical_xor(x, True))\n         self.assertAllClose(knp.LogicalXor()(True, x), np.logical_xor(True, x))\n \n+    def test_correlate(self):\n+        x = np.array([1, 2, 3])\n+        y = np.array([0, 1, 0.5])\n+        self.assertAllClose(knp.correlate(x, y), np.correlate(x, y))\n+        self.assertAllClose(\n+            knp.correlate(x, y, mode=\"same\"), np.correlate(x, y, mode=\"same\")\n+        )\n+        self.assertAllClose(\n+            knp.correlate(x, y, mode=\"full\"), np.correlate(x, y, mode=\"full\")\n+        )\n+\n+        self.assertAllClose(knp.Correlate()(x, y), np.correlate(x, y))\n+        self.assertAllClose(\n+            knp.Correlate(mode=\"same\")(x, y), np.correlate(x, y, mode=\"same\")\n+        )\n+        self.assertAllClose(\n+            knp.Correlate(mode=\"full\")(x, y), np.correlate(x, y, mode=\"full\")\n+        )\n+\n+    def test_correlate_different_size(self):\n+        x = np.array([1, 2, 3, 4, 5, 6])\n+        y = np.array([0, 1, 0.5])\n+        self.assertAllClose(knp.correlate(x, y), np.correlate(x, y))\n+        self.assertAllClose(\n+            knp.correlate(x, y, mode=\"same\"), np.correlate(x, y, mode=\"same\")\n+        )\n+        self.assertAllClose(\n+            knp.correlate(x, y, mode=\"full\"), np.correlate(x, y, mode=\"full\")\n+        )\n+\n+        self.assertAllClose(knp.Correlate()(x, y), np.correlate(x, y))\n+        self.assertAllClose(\n+            knp.Correlate(mode=\"same\")(x, y), np.correlate(x, y, mode=\"same\")\n+        )\n+        self.assertAllClose(\n+            knp.Correlate(mode=\"full\")(x, y), np.correlate(x, y, mode=\"full\")\n+        )\n+\n \n class NumpyArrayCreateOpsCorrectnessTest(testing.TestCase):\n     def test_ones(self):\n@@ -5472,6 +5543,27 @@ class NumpyDtypeTest(testing.TestCase, parameterized.TestCase):\n             expected_dtype,\n         )\n \n+    @parameterized.named_parameters(\n+        named_product(dtypes=itertools.combinations(ALL_DTYPES, 2))\n+    )\n+    def test_correlate(self, dtypes):\n+        import jax.numpy as jnp\n+\n+        dtype1, dtype2 = dtypes\n+        x1 = knp.ones((3,), dtype=dtype1)\n+        x2 = knp.ones((3,), dtype=dtype2)\n+        x1_jax = jnp.ones((3,), dtype=dtype1)\n+        x2_jax = jnp.ones((3,), dtype=dtype2)\n+        expected_dtype = standardize_dtype(jnp.correlate(x1_jax, x2_jax).dtype)\n+\n+        self.assertEqual(\n+            standardize_dtype(knp.correlate(x1, x2).dtype), expected_dtype\n+        )\n+        self.assertEqual(\n+            standardize_dtype(knp.Correlate().symbolic_call(x1, x2).dtype),\n+            expected_dtype,\n+        )\n+\n     @parameterized.named_parameters(named_product(dtype=ALL_DTYPES))\n     def test_count_nonzero(self, dtype):\n         x = knp.ones((1,), dtype=dtype)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5f31cac6166014f0ba6fdcde61ef1f757360a4fc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 29 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 31 | Churn Cumulative: 39 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,7 +1,12 @@\n+import json\n+\n import numpy as np\n \n from keras import testing\n from keras.backend.common import keras_tensor\n+from keras.layers import Dense\n+from keras.layers import Input\n+from keras.models import Model\n from keras.ops import function\n from keras.ops import numpy as knp\n \n@@ -108,5 +113,27 @@ class FunctionTest(testing.TestCase):\n         pass\n \n     def test_serialization(self):\n-        # TODO\n-        pass\n+        inputs = Input(shape=(10,))\n+        outputs = Dense(1)(inputs)\n+        model = Model(inputs=inputs, outputs=outputs)\n+\n+        config = model.get_config()\n+        new_model = Model.from_config(config)\n+\n+        self.assertEqual(\n+            json.dumps(model.get_config()), json.dumps(new_model.get_config())\n+        )\n+\n+    def test_function_with_empty_outputs(self):\n+        x = keras_tensor.KerasTensor((None, 3))\n+        with self.assertRaisesRegex(\n+            ValueError, \"`outputs` argument cannot be empty\"\n+        ):\n+            _ = function.Function(inputs=x, outputs=[])\n+\n+    def test_function_with_empty_inputs(self):\n+        x = keras_tensor.KerasTensor((None, 3))\n+        with self.assertRaisesRegex(\n+            ValueError, \"`inputs` argument cannot be empty\"\n+        ):\n+            _ = function.Function(inputs=[], outputs=x)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4b612a351efa0a613c27ee0b2541ee312dedf4a0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 91 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 7 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 91 | Churn Cumulative: 1016 | Contributors (this commit): 5 | Commits (past 90d): 1 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -218,6 +218,97 @@ class SparseCategoricalAccuracyTest(testing.TestCase):\n         result = sp_cat_acc_obj.result()\n         self.assertAllClose(result, 0.3, atol=1e-3)\n \n+    def test_squeeze_y_true(self):\n+        sp_cat_acc_obj = accuracy_metrics.SparseCategoricalAccuracy(\n+            name=\"sparse_categorical_accuracy\", dtype=\"float32\"\n+        )\n+        # Scenario with 100% accuracy for simplicity.\n+        # y_true is a 2D tensor with shape (3, 1) to test squeeze.\n+        y_true = np.array([[0], [1], [2]])\n+        y_pred = np.array(\n+            [[0.9, 0.05, 0.05], [0.05, 0.9, 0.05], [0.05, 0.05, 0.9]]\n+        )\n+        sp_cat_acc_obj.update_state(y_true, y_pred)\n+        result = sp_cat_acc_obj.result()\n+        self.assertAllClose(result, 1.0, atol=1e-4)\n+\n+    def test_cast_y_pred_dtype(self):\n+        sp_cat_acc_obj = accuracy_metrics.SparseCategoricalAccuracy(\n+            name=\"sparse_categorical_accuracy\", dtype=\"float32\"\n+        )\n+        # Scenario with 100% accuracy for simplicity.\n+        # y_true is a 1D tensor with shape (2,) to test cast.\n+        y_true = np.array([0, 1], dtype=np.int64)\n+        y_pred = np.array([[0.9, 0.1], [0.1, 0.9]], dtype=np.float32)\n+        sp_cat_acc_obj.update_state(y_true, y_pred)\n+        result = sp_cat_acc_obj.result()\n+        self.assertAllClose(result, 1.0, atol=1e-4)\n+\n+    def test_reshape_matches(self):\n+        sp_cat_acc_obj = accuracy_metrics.SparseCategoricalAccuracy(\n+            name=\"sparse_categorical_accuracy\", dtype=\"float32\"\n+        )\n+        # Scenario with 100% accuracy for simplicity.\n+        # y_true is a 2D tensor with shape (2, 1) to test reshape.\n+        y_true = np.array([[0], [0]], dtype=np.int64)\n+        y_pred = np.array(\n+            [[[0.9, 0.1, 0.0], [0.8, 0.15, 0.05]]], dtype=np.float32\n+        )\n+        sp_cat_acc_obj.update_state(y_true, y_pred)\n+        result = sp_cat_acc_obj.result()\n+        self.assertAllClose(result, np.array([1.0, 1.0]))\n+\n+    def test_squeeze_y_true_shape(self):\n+        sp_cat_acc_obj = accuracy_metrics.SparseCategoricalAccuracy(\n+            name=\"sparse_categorical_accuracy\", dtype=\"float32\"\n+        )\n+        # True labels are in the shape (num_samples, 1) should be squeezed.\n+        y_true = np.array([[0], [1], [2]])\n+        y_pred = np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])\n+        sp_cat_acc_obj.update_state(y_true, y_pred)\n+        result = sp_cat_acc_obj.result()\n+        self.assertAllClose(result, 1.0, atol=1e-4)\n+\n+    def test_cast_y_pred_to_match_y_true_dtype(self):\n+        sp_cat_acc_obj = accuracy_metrics.SparseCategoricalAccuracy(\n+            name=\"sparse_categorical_accuracy\", dtype=\"float32\"\n+        )\n+        # True labels are integers, while predictions are floats.\n+        y_true = np.array([0, 1, 2], dtype=np.int32)\n+        y_pred = np.array(\n+            [[0.9, 0.1, 0.0], [0.0, 0.9, 0.1], [0.1, 0.0, 0.9]],\n+            dtype=np.float64,\n+        )\n+        sp_cat_acc_obj.update_state(y_true, y_pred)\n+        result = sp_cat_acc_obj.result()\n+        self.assertAllClose(result, 1.0, atol=1e-4)\n+\n+    def test_reshape_matches_to_original_y_true_shape(self):\n+        sp_cat_acc_obj = accuracy_metrics.SparseCategoricalAccuracy(\n+            name=\"sparse_categorical_accuracy\", dtype=\"float32\"\n+        )\n+        # True labels have an additional dimension that needs to be squeezed.\n+        y_true = np.array([[0], [1]])\n+        # Predictions must trigger a reshape of matches.\n+        y_pred = np.array([[0.9, 0.1], [0.1, 0.9]])\n+        sp_cat_acc_obj.update_state(y_true, y_pred)\n+        result = sp_cat_acc_obj.result()\n+        self.assertAllClose(result, 1.0, atol=1e-4)\n+\n+    def test_matching_shapes_without_squeeze(self):\n+        sp_cat_acc_obj = accuracy_metrics.SparseCategoricalAccuracy(\n+            name=\"sparse_categorical_accuracy\", dtype=\"float32\"\n+        )\n+        y_true = np.array([2, 1, 0], dtype=np.int32)\n+        y_pred = np.array(\n+            [[0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0]],\n+            dtype=np.float32,\n+        )\n+        # No need to squeeze or reshape.\n+        sp_cat_acc_obj.update_state(y_true, y_pred)\n+        result = sp_cat_acc_obj.result()\n+        self.assertAllClose(result, 1.0, atol=1e-4)\n+\n \n class TopKCategoricalAccuracyTest(testing.TestCase):\n     def test_config(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d4a4ae4c6500e198d590036ced8b6d9faaad6da5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 153 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 14 | Complexity Δ (Sum/Max): 14/14 | Churn Δ: 153 | Churn Cumulative: 711 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -227,6 +227,159 @@ class FBetaScoreTest(parameterized.TestCase, testing.TestCase):\n             reference_result=result,\n         )\n \n+    def test_invalid_average_raises_value_error(self):\n+        expected_message = (\n+            \"Invalid `average` argument value. Expected one of: \"\n+            r\"\\{None, 'micro', 'macro', 'weighted'\\}. \"\n+            \"Received: average=invalid_average\"\n+        )\n+        with self.assertRaisesRegex(ValueError, expected_message):\n+            f_score_metrics.FBetaScore(\n+                average=\"invalid_average\",\n+                beta=1.0,\n+                threshold=None,\n+                dtype=\"float32\",\n+            )\n+\n+    def test_beta_integer_type_raises_value_error(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"Invalid `beta` argument value. It should be a Python float.\",\n+        ):\n+            f_score_metrics.FBetaScore(\n+                average=\"macro\", beta=1, threshold=None, dtype=\"float32\"\n+            )\n+\n+    def test_beta_string_type_raises_value_error(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"Invalid `beta` argument value. It should be a Python float.\",\n+        ):\n+            f_score_metrics.FBetaScore(\n+                average=\"macro\", beta=\"1.0\", threshold=None, dtype=\"float32\"\n+            )\n+\n+    def test_beta_none_type_raises_value_error(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"Invalid `beta` argument value. It should be a Python float.\",\n+        ):\n+            f_score_metrics.FBetaScore(\n+                average=\"macro\", beta=None, threshold=None, dtype=\"float32\"\n+            )\n+\n+    def test_beta_zero_raises_value_error(self):\n+        expected_message = (\n+            \"Invalid `beta` argument value. It should be > 0. \"\n+            \"Received: beta=0.0\"\n+        )\n+        with self.assertRaisesRegex(ValueError, expected_message):\n+            f_score_metrics.FBetaScore(\n+                average=\"macro\", beta=0.0, threshold=None, dtype=\"float32\"\n+            )\n+\n+    def test_beta_negative_one_raises_value_error(self):\n+        expected_message = (\n+            \"Invalid `beta` argument value. It should be > 0. \"\n+            \"Received: beta=-1.0\"\n+        )\n+        with self.assertRaisesRegex(ValueError, expected_message):\n+            f_score_metrics.FBetaScore(\n+                average=\"macro\", beta=-1.0, threshold=None, dtype=\"float32\"\n+            )\n+\n+    def test_beta_negative_half_raises_value_error(self):\n+        expected_message = (\n+            \"Invalid `beta` argument value. It should be > 0. \"\n+            \"Received: beta=-0.5\"\n+        )\n+        with self.assertRaisesRegex(ValueError, expected_message):\n+            f_score_metrics.FBetaScore(\n+                average=\"macro\", beta=-0.5, threshold=None, dtype=\"float32\"\n+            )\n+\n+    def test_threshold_not_float_raises_value_error(self):\n+        expected_message_pattern = (\n+            \"Invalid `threshold` argument value. \"\n+            \"It should be a Python float. \"\n+            \"Received: threshold=1 of type '<class 'int'>'\"\n+        )\n+        with self.assertRaisesRegex(ValueError, expected_message_pattern):\n+            f_score_metrics.FBetaScore(\n+                average=\"macro\", beta=1.0, threshold=1, dtype=\"float32\"\n+            )\n+\n+    def test_threshold_string_raises_value_error(self):\n+        expected_message_pattern = (\n+            \"Invalid `threshold` argument value. \"\n+            \"It should be a Python float. \"\n+            \"Received: threshold=0.5 of type '<class 'str'>'\"\n+        )\n+        with self.assertRaisesRegex(ValueError, expected_message_pattern):\n+            f_score_metrics.FBetaScore(\n+                average=\"macro\", beta=1.0, threshold=\"0.5\", dtype=\"float32\"\n+            )\n+\n+    def test_threshold_above_one_raises_value_error(self):\n+        expected_message = (\n+            \"Invalid `threshold` argument value. \"\n+            \"It should verify 0 < threshold <= 1. \"\n+            \"Received: threshold=1.1\"\n+        )\n+        with self.assertRaisesRegex(ValueError, expected_message):\n+            f_score_metrics.FBetaScore(\n+                average=\"macro\", beta=1.0, threshold=1.1, dtype=\"float32\"\n+            )\n+\n+    def test_threshold_zero_raises_value_error(self):\n+        expected_message = (\n+            \"Invalid `threshold` argument value. \"\n+            \"It should verify 0 < threshold <= 1. \"\n+            \"Received: threshold=0.0\"\n+        )\n+        with self.assertRaisesRegex(ValueError, expected_message):\n+            f_score_metrics.FBetaScore(\n+                average=\"macro\", beta=1.0, threshold=0.0, dtype=\"float32\"\n+            )\n+\n+    def test_threshold_negative_raises_value_error(self):\n+        expected_message = (\n+            \"Invalid `threshold` argument value. \"\n+            \"It should verify 0 < threshold <= 1. \"\n+            \"Received: threshold=-0.5\"\n+        )\n+        with self.assertRaisesRegex(ValueError, expected_message):\n+            f_score_metrics.FBetaScore(\n+                average=\"macro\", beta=1.0, threshold=-0.5, dtype=\"float32\"\n+            )\n+\n+    def test_non_2d_input_shapes_raises_value_error(self):\n+        fbeta = f_score_metrics.FBetaScore(beta=1.0, dtype=\"float32\")\n+        y_true_shape = (2, 3, 4)\n+        y_pred_shape = (2, 3, 4)\n+        expected_error_message = (\n+            \"FBetaScore expects 2D inputs with shape \"\n+            r\"\\(batch_size, output_dim\\)\\. Received input \"\n+            r\"shapes: y_pred\\.shape=\\(2, 3, 4\\) and \"\n+            r\"y_true\\.shape=\\(2, 3, 4\\)\\.\"\n+        )\n+        with self.assertRaisesRegex(ValueError, expected_error_message):\n+            fbeta._build(y_true_shape, y_pred_shape)\n+\n+    def test_undefined_output_dim_raises_value_error(self):\n+        fbeta = f_score_metrics.FBetaScore(beta=1.0, dtype=\"float32\")\n+        y_true_shape = (2, None)\n+        y_pred_shape = (2, None)\n+        expected_error_message = (\n+            \"FBetaScore expects 2D inputs with shape \"\n+            r\"\\(batch_size, output_dim\\), with output_dim fully \"\n+            r\"defined \\(not None\\)\\. Received input \"\n+            r\"shapes: y_pred\\.shape=\\(2, None\\) and \"\n+            r\"y_true\\.shape=\\(2, None\\)\\.\"\n+        )\n+        with self.assertRaisesRegex(ValueError, expected_error_message):\n+            fbeta._build(y_true_shape, y_pred_shape)\n+\n \n class F1ScoreTest(testing.TestCase):\n     def test_config(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
