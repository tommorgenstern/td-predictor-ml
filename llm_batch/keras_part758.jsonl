{"custom_id": "keras#a1296d7485e05a8e863d6334d5615b75eee049dc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 544 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -189,7 +189,8 @@ for subdir in os.listdir(DATASET_NOISE_PATH):\n             for filepath in os.listdir(subdir_path)\n             if filepath.endswith(\".wav\")\n         ]\n-\n+if not noise_paths:\n+    raise RuntimeError(f\"Could not find any files at {DATASET_NOISE_PATH}\")\n print(\n     \"Found {} files belonging to {} directories\".format(\n         len(noise_paths), len(os.listdir(DATASET_NOISE_PATH))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3e5424772e52d54db7c32d0b2fb3b66ebedff6f6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 552 | Contributors (this commit): 3 | Commits (past 90d): 6 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -141,14 +141,6 @@ main_directory/\n ```\n \"\"\"\n \n-# If folder `audio`, does not exist, create it, otherwise do nothing\n-if os.path.exists(DATASET_AUDIO_PATH) is False:\n-    os.makedirs(DATASET_AUDIO_PATH)\n-\n-# If folder `noise`, does not exist, create it, otherwise do nothing\n-if os.path.exists(DATASET_NOISE_PATH) is False:\n-    os.makedirs(DATASET_NOISE_PATH)\n-\n for folder in os.listdir(DATASET_ROOT):\n     if os.path.isdir(os.path.join(DATASET_ROOT, folder)):\n         if folder in [AUDIO_SUBFOLDER, NOISE_SUBFOLDER]:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ff709ef3ebfc1e2e17c3bc43f69b5d9685b4c080", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 562 | Contributors (this commit): 3 | Commits (past 90d): 7 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -53,16 +53,14 @@ from pathlib import Path\n from IPython.display import display, Audio\n \n # Get the data from https://www.kaggle.com/kongaevans/speaker-recognition-dataset/\n-# and save it to ~/speaker-recognition-dataset.zip\n-# then unzip it to ~/16000_pcm_speeches\n+# and save it to ./speaker-recognition-dataset.zip\n+# then unzip it to ./16000_pcm_speeches\n \"\"\"shell\n kaggle datasets download -d kongaevans/speaker-recognition-dataset\n-unzip ~/speaker-recognition-dataset.zip -qq\n+unzip speaker-recognition-dataset.zip -qq\n \"\"\"\n \n-DATASET_ROOT = os.path.join(\n-    os.path.expanduser(\"~\"), \"16000_pcm_speeches\"\n-)\n+DATASET_ROOT = \"16000_pcm_speeches\"\n \n # The folders in which we will put the audio samples and the noise samples\n AUDIO_SUBFOLDER = \"audio\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f3ef538c6aea51eade531715f339f0e80e132ac5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 564 | Contributors (this commit): 3 | Commits (past 90d): 8 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -57,7 +57,7 @@ from IPython.display import display, Audio\n # then unzip it to ./16000_pcm_speeches\n \"\"\"shell\n kaggle datasets download -d kongaevans/speaker-recognition-dataset\n-unzip speaker-recognition-dataset.zip -qq\n+unzip -qq speaker-recognition-dataset.zip\n \"\"\"\n \n DATASET_ROOT = \"16000_pcm_speeches\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#55a6f4af8f7eb1316bdbb521133e1bb8bd9b6380", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 6 | Methods Changed: 6 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 32 | Churn Cumulative: 2592 | Contributors (this commit): 11 | Commits (past 90d): 4 | Contributors (cumulative): 17 | DMM Complexity: 1.0\n\nDIFF:\n@@ -153,6 +153,12 @@ class ExponentialDecay(LearningRateSchedule):\n         self.staircase = staircase\n         self.name = name\n \n+        if self.decay_steps <= 0:\n+            raise ValueError(\n+                \"Argument `decay_steps` must be > 0. \"\n+                f\"Received : decay_steps = {self.decay_steps}. \"\n+            )\n+\n     def __call__(self, step):\n         with ops.name_scope(self.name):\n             initial_learning_rate = ops.convert_to_tensor(\n@@ -396,6 +402,12 @@ class PolynomialDecay(LearningRateSchedule):\n         self.cycle = cycle\n         self.name = name\n \n+        if self.decay_steps <= 0:\n+            raise ValueError(\n+                \"Argument `decay_steps` must be > 0. \"\n+                f\"Received : decay_steps = {self.decay_steps}. \"\n+            )\n+\n     def __call__(self, step):\n         with ops.name_scope(self.name):\n             initial_learning_rate = ops.convert_to_tensor(\n@@ -524,6 +536,12 @@ class InverseTimeDecay(LearningRateSchedule):\n         self.staircase = staircase\n         self.name = name\n \n+        if self.decay_steps <= 0:\n+            raise ValueError(\n+                \"Argument `decay_steps` must be > 0. \"\n+                f\"Received : decay_steps = {self.decay_steps}. \"\n+            )\n+\n     def __call__(self, step):\n         with ops.name_scope(self.name):\n             initial_learning_rate = ops.convert_to_tensor(\n@@ -666,6 +684,12 @@ class CosineDecay(LearningRateSchedule):\n         self.warmup_steps = warmup_steps\n         self.warmup_target = warmup_target\n \n+        if self.decay_steps <= 0:\n+            raise ValueError(\n+                \"Argument `decay_steps` must be > 0. \"\n+                f\"Received : decay_steps = {self.decay_steps}. \"\n+            )\n+\n     def _decay_function(self, step, decay_steps, decay_from_lr, dtype):\n         with ops.name_scope(self.name):\n             completed_fraction = step / decay_steps\n@@ -808,6 +832,12 @@ class CosineDecayRestarts(LearningRateSchedule):\n         self.alpha = alpha\n         self.name = name\n \n+        if self.first_decay_steps <= 0:\n+            raise ValueError(\n+                \"Argument `first_decay_steps` must be > 0. \"\n+                f\"Received : first_decay_steps = {self.first_decay_steps}. \"\n+            )\n+\n     def __call__(self, step):\n         with ops.name_scope(self.name):\n             initial_learning_rate = ops.convert_to_tensor(\n\n@@ -325,7 +325,7 @@ class CosineDecayTest(testing.TestCase):\n         for step in range(0, 1500, 250):\n             lr = schedules.CosineDecay(\n                 initial_lr,\n-                0,\n+                10,\n                 warmup_target=target_lr,\n                 warmup_steps=warmup_steps,\n             )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#148d18c9f6fd2b0ce25313c9d0c26146a09ecf18", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 1858 | Contributors (this commit): 10 | Commits (past 90d): 3 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -156,7 +156,7 @@ class ExponentialDecay(LearningRateSchedule):\n         if self.decay_steps <= 0:\n             raise ValueError(\n                 \"Argument `decay_steps` must be > 0. \"\n-                f\"Received : decay_steps = {self.decay_steps}. \"\n+                f\"Received: decay_steps={self.decay_steps}\"\n             )\n \n     def __call__(self, step):\n@@ -405,7 +405,7 @@ class PolynomialDecay(LearningRateSchedule):\n         if self.decay_steps <= 0:\n             raise ValueError(\n                 \"Argument `decay_steps` must be > 0. \"\n-                f\"Received : decay_steps = {self.decay_steps}. \"\n+                f\"Received: decay_steps={self.decay_steps}\"\n             )\n \n     def __call__(self, step):\n@@ -539,7 +539,7 @@ class InverseTimeDecay(LearningRateSchedule):\n         if self.decay_steps <= 0:\n             raise ValueError(\n                 \"Argument `decay_steps` must be > 0. \"\n-                f\"Received : decay_steps = {self.decay_steps}. \"\n+                f\"Received: decay_steps={self.decay_steps}\"\n             )\n \n     def __call__(self, step):\n@@ -687,7 +687,7 @@ class CosineDecay(LearningRateSchedule):\n         if self.decay_steps <= 0:\n             raise ValueError(\n                 \"Argument `decay_steps` must be > 0. \"\n-                f\"Received : decay_steps = {self.decay_steps}. \"\n+                f\"Received: decay_steps={self.decay_steps}\"\n             )\n \n     def _decay_function(self, step, decay_steps, decay_from_lr, dtype):\n@@ -835,7 +835,7 @@ class CosineDecayRestarts(LearningRateSchedule):\n         if self.first_decay_steps <= 0:\n             raise ValueError(\n                 \"Argument `first_decay_steps` must be > 0. \"\n-                f\"Received : first_decay_steps = {self.first_decay_steps}. \"\n+                f\"Received: first_decay_steps={self.first_decay_steps}\"\n             )\n \n     def __call__(self, step):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#418fcd90aa0b9532c0f6212c7a39e43458a7cc89", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 1138 | Contributors (this commit): 3 | Commits (past 90d): 12 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -32,7 +32,7 @@ Note:\n - This example should be run with TensorFlow 2.3 or higher, or `tf-nightly`.\n - The noise samples in the dataset need to be resampled to a sampling rate of 16000 Hz\n before using the code in this example. In order to do this, you will need to have\n-installed `ffmpg`.\n+installed `ffmpeg`.\n \"\"\"\n \n \"\"\"\n@@ -188,7 +188,8 @@ print(\n )\n \n \"\"\"\n-Resample all noise samples to 16000 Hz\n+Resample all noise samples to 16000 Hz.\n+Note that this requires `ffmpeg`.\n \"\"\"\n \n command = (\n\n@@ -4,7 +4,7 @@ Author: [Dimitre Oliveira](https://www.linkedin.com/in/dimitre-oliveira-7a1a0113\n Date created: 2023/01/02\n Last modified: 2023/01/02\n Description: How to serve TensorFlow models with TensorFlow Serving.\n-Accelerator: NONE\n+Accelerator: None\n \"\"\"\n \n \"\"\"\n@@ -55,6 +55,9 @@ TensorFlow.\n \"\"\"\n \n import os\n+\n+os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n+\n import json\n import shutil\n import requests\n@@ -540,6 +543,7 @@ print(f\"Predicted class: {grpc_outputs}\")\n ```\n \n outputs:\n+\n ```\n gRPC output shape: (1, 1)\n Predicted class: [[b'banana']]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4daefc71016cd24ed9887a014dd5040331258135", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 128 | Lines Deleted: 7 | Files Changed: 3 | Hunks: 8 | Methods Changed: 9 | Complexity Δ (Sum/Max): 10/12 | Churn Δ: 135 | Churn Cumulative: 1160 | Contributors (this commit): 4 | Commits (past 90d): 11 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -109,7 +109,7 @@ def indexed_slices_union_indices_and_values(x1, x2_indices, x2_values=None):\n         )\n         to_union_indices = tf.gather(indices_indices, union_indices)\n         values_with_leading_zeros = tf.concat(\n-            [tf.zeros((1,) + x1.dense_shape[1:], values.dtype), values], axis=0\n+            [tf.zeros((1,) + values.shape[1:], values.dtype), values], axis=0\n         )\n         return tf.gather(values_with_leading_zeros, to_union_indices)\n \n\n@@ -247,13 +247,13 @@ class Functional(Function, Model):\n         return tree.flatten(inputs)\n \n     def _convert_inputs_to_tensors(self, flat_inputs):\n-        flat_dtypes = [x.dtype for x in self._inputs]\n         converted = []\n-        for x, dtype in zip(flat_inputs, flat_dtypes):\n-            if backend.is_tensor(x):\n-                converted.append(backend.cast(x, dtype=dtype))\n-            else:\n-                converted.append(backend.convert_to_tensor(x, dtype=dtype))\n+        for x, input in zip(flat_inputs, self._inputs):\n+            converted.append(\n+                backend.convert_to_tensor(\n+                    x, dtype=input.dtype, sparse=input.sparse\n+                )\n+            )\n         return converted\n \n     def _adjust_input_rank(self, flat_inputs):\n\n@@ -1,3 +1,5 @@\n+from unittest import mock\n+\n import numpy as np\n import pytest\n from absl.testing import parameterized\n@@ -91,6 +93,25 @@ class TrainingTestingLayer(Trainer, layers.Layer):\n         return x * 0\n \n \n+def tf_sparse_generator():\n+    import tensorflow as tf\n+\n+    for i in range(4):\n+        x = tf.random.uniform((2, 4), dtype=\"float32\")\n+        x = tf.sparse.from_dense(tf.nn.dropout(x, 0.25))\n+        y = tf.random.uniform((2, 3), dtype=\"float32\")\n+        yield x, y\n+\n+\n+def scipy_sparse_generator():\n+    import scipy\n+\n+    for i in range(4):\n+        x = scipy.sparse.random(2, 4, density=0.25, dtype=\"float32\")\n+        y = np.random.rand(2, 3).astype(\"float32\")\n+        yield x, y\n+\n+\n class TestTrainer(testing.TestCase, parameterized.TestCase):\n     @pytest.mark.requires_trainable_backend\n     def test_metric_tracking(self):\n@@ -258,6 +279,50 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n         self.assertIn(\"loss\", history)\n         self.assertIn(\"val_loss\", history)\n \n+    @parameterized.named_parameters(\n+        [\n+            (\"eager_tf_sparse\", True, False),\n+            (\"graph_fn_tf_sparse\", False, False),\n+            (\"eager_scipy_sparse\", True, False),\n+            (\"graph_fn_scipy_sparse\", False, False),\n+        ]\n+    )\n+    @pytest.mark.skipif(\n+        not backend.SUPPORTS_SPARSE_TENSORS,\n+        reason=\"Backend does not support sparse tensors.\",\n+    )\n+    def test_fit_sparse(self, run_eagerly, use_scipy_sparse):\n+        model = ExampleModel(units=3)\n+        optimizer = optimizers.Adagrad()\n+        model.compile(\n+            optimizer=optimizer,\n+            loss=losses.MeanSquaredError(),\n+            metrics=[metrics.MeanSquaredError()],\n+            run_eagerly=run_eagerly,\n+            jit_compile=False,\n+        )\n+        dataset = (\n+            scipy_sparse_generator()\n+            if use_scipy_sparse\n+            else tf_sparse_generator()\n+        )\n+\n+        sparse_variable_updates = False\n+\n+        def mock_optimizer_assign(variable, value):\n+            nonlocal sparse_variable_updates\n+            if value.__class__.__name__ == \"IndexedSlices\":\n+                sparse_variable_updates = True\n+\n+        with mock.patch.object(\n+            optimizer, \"assign_sub\", autospec=True\n+        ) as optimizer_assign_sub:\n+            optimizer_assign_sub.side_effect = mock_optimizer_assign\n+            model.fit(dataset)\n+\n+        # Verify tensors did not get densified along the way.\n+        self.assertTrue(sparse_variable_updates)\n+\n     @parameterized.named_parameters(\n         [\n             (\"eager\", True, False),\n@@ -286,6 +351,34 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n         self.assertIn(\"mean_squared_error\", output)\n         self.assertAllClose(output[\"mean_squared_error\"], 16.0)\n \n+    @parameterized.named_parameters(\n+        [\n+            (\"eager_tf_sparse\", True, False),\n+            (\"graph_fn_tf_sparse\", False, False),\n+            (\"eager_scipy_sparse\", True, False),\n+            (\"graph_fn_scipy_sparse\", False, False),\n+        ]\n+    )\n+    @pytest.mark.skipif(\n+        not backend.SUPPORTS_SPARSE_TENSORS,\n+        reason=\"Backend does not support sparse tensors.\",\n+    )\n+    def test_evaluate_sparse(self, run_eagerly, use_scipy_sparse):\n+        model = ExampleModel(units=3)\n+        model.compile(\n+            optimizer=optimizers.Adagrad(),\n+            loss=losses.MeanSquaredError(),\n+            metrics=[metrics.MeanSquaredError()],\n+            run_eagerly=run_eagerly,\n+            jit_compile=False,\n+        )\n+        dataset = (\n+            scipy_sparse_generator()\n+            if use_scipy_sparse\n+            else tf_sparse_generator()\n+        )\n+        model.evaluate(dataset)\n+\n     @parameterized.named_parameters(\n         [\n             (\"eager\", True, False),\n@@ -328,6 +421,34 @@ class TestTrainer(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(outputs[\"y_one\"], 4 * np.ones((100, 3)))\n         self.assertAllClose(outputs[\"y_two\"], 4 * np.ones((100, 3)))\n \n+    @parameterized.named_parameters(\n+        [\n+            (\"eager_tf_sparse\", True, False),\n+            (\"graph_fn_tf_sparse\", False, False),\n+            (\"eager_scipy_sparse\", True, False),\n+            (\"graph_fn_scipy_sparse\", False, False),\n+        ]\n+    )\n+    @pytest.mark.skipif(\n+        not backend.SUPPORTS_SPARSE_TENSORS,\n+        reason=\"Backend does not support sparse tensors.\",\n+    )\n+    def test_predict_sparse(self, run_eagerly, use_scipy_sparse):\n+        model = ExampleModel(units=3)\n+        model.compile(\n+            optimizer=optimizers.Adagrad(),\n+            loss=losses.MeanSquaredError(),\n+            metrics=[metrics.MeanSquaredError()],\n+            run_eagerly=run_eagerly,\n+            jit_compile=False,\n+        )\n+        dataset = (\n+            scipy_sparse_generator()\n+            if use_scipy_sparse\n+            else tf_sparse_generator()\n+        )\n+        model.predict(dataset)\n+\n     @pytest.mark.skipif(\n         backend.backend() != \"jax\",\n         reason=\"Memory optimization is only implemented in JAX\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2c285b848a626ec79bc24d5dc88a49f3bbe2b856", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 11 | Churn Cumulative: 43 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -70,10 +70,21 @@ class Variable(\n         return self.value._shared_name\n \n     def _serialize_to_tensors(self):\n+        try:\n             return self.value._serialize_to_tensors()\n+        except NotImplementedError:\n+            return {\"VARIABLE_VALUE\": self.value}\n \n     def _restore_from_tensors(self, restored_tensors):\n+        try:\n             return self.value._restore_from_tensors(restored_tensors)\n+        except NotImplementedError:\n+            self.assign(restored_tensors[\"VARIABLE_VALUE\"])\n+            return self.value\n+\n+    def _copy_trackable_to_cpu(self, object_map):\n+        self.value._copy_trackable_to_cpu(object_map)\n+        object_map[self] = tf.Variable(object_map[self.value])\n \n     def _export_to_saved_model_graph(\n         self, object_map, tensor_map, options, **kwargs\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d24f51573bcdab098af7ac8e7d06fa8408481565", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 72 | Lines Deleted: 0 | Files Changed: 6 | Hunks: 7 | Methods Changed: 8 | Complexity Δ (Sum/Max): 10/4 | Churn Δ: 72 | Churn Cumulative: 380 | Contributors (this commit): 4 | Commits (past 90d): 23 | Contributors (cumulative): 19 | DMM Complexity: 1.0\n\nDIFF:\n@@ -252,3 +252,9 @@ def rsqrt(x):\n \n def erf(x):\n     return jax.lax.erf(x)\n+\n+\n+def solve(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n+    return jnp.linalg.solve(x1, x2)\n\n@@ -306,3 +306,9 @@ def rsqrt(x):\n \n def erf(x):\n     return np.array(scipy.special.erf(x))\n+\n+\n+def solve(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n+    return np.linalg.solve(x1, x2)\n\n@@ -243,3 +243,9 @@ def rsqrt(x):\n \n def erf(x):\n     return tf.math.erf(x)\n+\n+\n+def solve(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n+    return tf.linalg.solve(x1, x2)\n\n@@ -413,3 +413,9 @@ def rsqrt(x):\n def erf(x):\n     x = convert_to_tensor(x)\n     return torch.erf(x)\n+\n+\n+def solve(x1, x2):\n+    x1 = convert_to_tensor(x1)\n+    x2 = convert_to_tensor(x2)\n+    return torch.linalg.solve(x1, x2)\n\n@@ -958,3 +958,38 @@ def erf(x):\n         return Erf().symbolic_call(x)\n     x = backend.convert_to_tensor(x)\n     return backend.math.erf(x)\n+\n+\n+class Solve(Operation):\n+    def call(self, x1, x2):\n+        x1 = backend.convert_to_tensor(x1)\n+        x2 = backend.convert_to_tensor(x2)\n+        return backend.math.solve(x1, x2)\n+\n+    def compute_output_spec(self, x1, x2):\n+        return KerasTensor(shape=x1.shape, dtype=x1.dtype)\n+\n+\n+@keras_export(\"keras.ops.solve\")\n+def solve(x1, x2):\n+    \"\"\"Solves for X in AX=B equation.\n+\n+    Args:\n+        x1: Input tensor.\n+        x2: Input tensor.\n+\n+    Returns:\n+        A tensor with the same shape and dtype as x1 and x2.\n+\n+    Example:\n+\n+    >>> x1 = np.array([[1, 2], [4, 5]], dtype=\"float32\")\n+    >>> x2 = np.array([[2, 4], [8, 10]], dtype=\"float32\")\n+    >>> keras.ops.solve(x1, x2)\n+    array([[2, 0], [0, 2]], dtype=\"float32\")\n+    \"\"\"\n+    if any_symbolic_tensors((x1, x2)):\n+        return Solve().symbolic_call(x1, x2)\n+    x1 = backend.convert_to_tensor(x1)\n+    x2 = backend.convert_to_tensor(x2)\n+    return backend.math.solve(x1, x2)\n\n@@ -419,6 +419,12 @@ class MathOpsStaticShapeTest(testing.TestCase):\n         )\n         self.assertEqual(output.shape, ref.shape)\n \n+    def test_solve(self):\n+        x1 = KerasTensor((2, 2), dtype=\"float32\")\n+        x2 = KerasTensor((2, 2), dtype=\"float32\")\n+        outputs = kmath.solve(x1, x2)\n+        self.assertEqual(outputs.shape, (2, 2))\n+\n \n class MathOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n     @pytest.mark.skipif(\n@@ -865,3 +871,10 @@ class MathOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         expected_output = scipy.special.erf(edge_values)\n         output_from_edge_erf_op = kmath.erf(edge_values)\n         self.assertAllClose(expected_output, output_from_edge_erf_op, atol=1e-4)\n+\n+    def test_solve(self):\n+        x1 = np.array([[1, 2], [4, 5]], dtype=\"float32\")\n+        x2 = np.array([[2, 4], [8, 10]], dtype=\"float32\")\n+        output = kmath.solve(x1, x2)\n+        expected_result = np.array([[2, 0], [0, 2]], dtype=\"float32\")\n+        self.assertAllClose(output, expected_result)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#958bb03d6eb8486c63cff29a926ccc8a006c7960", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 34 | Files Changed: 5 | Hunks: 11 | Methods Changed: 14 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 68 | Churn Cumulative: 355 | Contributors (this commit): 4 | Commits (past 90d): 23 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -254,7 +254,7 @@ def erf(x):\n     return jax.lax.erf(x)\n \n \n-def solve(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n-    return jnp.linalg.solve(x1, x2)\n+def solve(a, b):\n+    a = convert_to_tensor(a)\n+    b = convert_to_tensor(b)\n+    return jnp.linalg.solve(a, b)\n\n@@ -308,7 +308,7 @@ def erf(x):\n     return np.array(scipy.special.erf(x))\n \n \n-def solve(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n-    return np.linalg.solve(x1, x2)\n+def solve(a, b):\n+    a = convert_to_tensor(a)\n+    b = convert_to_tensor(b)\n+    return np.linalg.solve(a, b)\n\n@@ -245,7 +245,7 @@ def erf(x):\n     return tf.math.erf(x)\n \n \n-def solve(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n-    return tf.linalg.solve(x1, x2)\n+def solve(a, b):\n+    a = convert_to_tensor(a)\n+    b = convert_to_tensor(b)\n+    return tf.linalg.solve(a, b)\n\n@@ -415,7 +415,7 @@ def erf(x):\n     return torch.erf(x)\n \n \n-def solve(x1, x2):\n-    x1 = convert_to_tensor(x1)\n-    x2 = convert_to_tensor(x2)\n-    return torch.linalg.solve(x1, x2)\n+def solve(a, b):\n+    a = convert_to_tensor(a)\n+    b = convert_to_tensor(b)\n+    return torch.linalg.solve(a, b)\n\n@@ -961,35 +961,35 @@ def erf(x):\n \n \n class Solve(Operation):\n-    def call(self, x1, x2):\n-        x1 = backend.convert_to_tensor(x1)\n-        x2 = backend.convert_to_tensor(x2)\n-        return backend.math.solve(x1, x2)\n+    def call(self, a, b):\n+        a = backend.convert_to_tensor(a)\n+        b = backend.convert_to_tensor(b)\n+        return backend.math.solve(a, b)\n \n-    def compute_output_spec(self, x1, x2):\n-        return KerasTensor(shape=x1.shape, dtype=x1.dtype)\n+    def compute_output_spec(self, a, b):\n+        return KerasTensor(shape=a.shape, dtype=a.dtype)\n \n \n @keras_export(\"keras.ops.solve\")\n-def solve(x1, x2):\n-    \"\"\"Solves for X in AX=B equation.\n+def solve(a, b):\n+    \"\"\"Solves for `x` in the equation `a * x = b`.\n \n     Args:\n-        x1: Input tensor.\n-        x2: Input tensor.\n+        a: Input tensor.\n+        b: Input tensor.\n \n     Returns:\n-        A tensor with the same shape and dtype as x1 and x2.\n+        A tensor with the same shape and dtype as `a`.\n \n     Example:\n \n-    >>> x1 = np.array([[1, 2], [4, 5]], dtype=\"float32\")\n-    >>> x2 = np.array([[2, 4], [8, 10]], dtype=\"float32\")\n+    >>> a = np.array([[1, 2], [4, 5]], dtype=\"float32\")\n+    >>> b = np.array([[2, 4], [8, 10]], dtype=\"float32\")\n     >>> keras.ops.solve(x1, x2)\n     array([[2, 0], [0, 2]], dtype=\"float32\")\n     \"\"\"\n-    if any_symbolic_tensors((x1, x2)):\n-        return Solve().symbolic_call(x1, x2)\n-    x1 = backend.convert_to_tensor(x1)\n-    x2 = backend.convert_to_tensor(x2)\n-    return backend.math.solve(x1, x2)\n+    if any_symbolic_tensors((a, b)):\n+        return Solve().symbolic_call(a, b)\n+    a = backend.convert_to_tensor(a)\n+    b = backend.convert_to_tensor(b)\n+    return backend.math.solve(a, b)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#508dfe261d85489a0b2a736bc3d676a140781a16", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 147 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -24,6 +24,10 @@ by putting the custom training step in the Trainer class definition.\n ## Setup\n \"\"\"\n \n+import os\n+\n+os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n+\n import tensorflow as tf\n import keras\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fc351c1f676ed0c5cf2846558e52895feee23bf1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 372 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -24,21 +24,17 @@ Let's run through a few examples.\n \n \"\"\"\n ## Setup\n-TensorFlow NumPy requires TensorFlow 2.5 or later.\n \"\"\"\n \n+import os\n+\n+os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n+\n import tensorflow as tf\n import tensorflow.experimental.numpy as tnp\n import keras\n from keras import layers\n \n-\"\"\"\n-Optionally, you can call `tnp.experimental_enable_numpy_behavior()` to enable type promotion in TensorFlow.\n-This allows TNP to more closely follow the NumPy standard.\n-\"\"\"\n-\n-tnp.experimental_enable_numpy_behavior()\n-\n \"\"\"\n To test our models we will use the Boston housing prices regression dataset.\n \"\"\"\n@@ -50,10 +46,10 @@ input_dim = x_train.shape[1]\n \n \n def evaluate_model(model: keras.Model):\n-    [loss, percent_error] = model.evaluate(x_test, y_test, verbose=0)\n+    loss, percent_error = model.evaluate(x_test, y_test, verbose=0)\n     print(\"Mean absolute percent error before training: \", percent_error)\n     model.fit(x_train, y_train, epochs=200, verbose=0)\n-    [loss, percent_error] = model.evaluate(x_test, y_test, verbose=0)\n+    loss, percent_error = model.evaluate(x_test, y_test, verbose=0)\n     print(\"Mean absolute percent error after training:\", percent_error)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#36195fb3a2e0b0bdb29704fa6652bc648eb8604f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 2803 | Contributors (this commit): 22 | Commits (past 90d): 3 | Contributors (cumulative): 22 | DMM Complexity: 1.0\n\nDIFF:\n@@ -597,7 +597,6 @@ class TextVectorization(Layer):\n             # dimension to the bounding shape of the ragged dimension.\n             shape[-1] = self._output_sequence_length\n             outputs = lookup_data.to_tensor(default_value=0, shape=shape)\n-            print(\"outputs (after conversion from ragged):\", outputs)\n \n         # If we have a dense tensor, we need to pad/trim directly.\n         if self._output_sequence_length is not None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e82f46989aceec1fd5d09b70c6558ac8ef6a67b2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1812 | Contributors (this commit): 6 | Commits (past 90d): 8 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -37,9 +37,6 @@ This example requires KerasNLP. You can install it via the following command:\n \"\"\"\n \n import os\n-\n-os.environ[\"KERAS_BACKEND\"] = \"jax\"\n-\n import keras_nlp\n import keras\n \n\n@@ -314,7 +314,6 @@ class SavingTest(testing.TestCase):\n             config_dict[\"compile_config\"][\"optimizer\"],\n             \"adam\",\n         )\n-        print(config_dict[\"compile_config\"])\n         self.assertEqual(\n             config_dict[\"compile_config\"][\"loss\"][\"config\"],\n             \"my_mean_squared_error\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9892ee0020a9f5b5f488fe728c08681e0206947f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 19 | Files Changed: 7 | Hunks: 10 | Methods Changed: 12 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 32 | Churn Cumulative: 411 | Contributors (this commit): 7 | Commits (past 90d): 29 | Contributors (cumulative): 19 | DMM Complexity: 0.0\n\nDIFF:\n@@ -46,7 +46,7 @@ class Variable(KerasVariable):\n         return self.value\n \n \n-def convert_to_tensor(x, dtype=None, sparse=False):\n+def convert_to_tensor(x, dtype=None, sparse=None):\n     if sparse:\n         raise ValueError(\"`sparse=True` is not supported with jax backend\")\n     if dtype is not None:\n\n@@ -25,7 +25,7 @@ class Variable(KerasVariable):\n         return self.value\n \n \n-def convert_to_tensor(x, dtype=None, sparse=False):\n+def convert_to_tensor(x, dtype=None, sparse=None):\n     if sparse:\n         raise ValueError(\"`sparse=True` is not supported with numpy backend\")\n     if dtype is not None:\n\n@@ -99,14 +99,8 @@ class Variable(\n         return self.value._write_object_proto(proto, options)\n \n \n-def convert_to_tensor(x, dtype=None, sparse=True):\n-    \"\"\"Convert to a TensorFlow tensor.\n-\n-    `sparse=True` means that `tf.SparseTensor`s are returned as-is, which is the\n-    default with the TensorFlow backend. An explicit `sparse=False` densifies\n-    `tf.SparseTensor`s.\n-    \"\"\"\n-    if isinstance(x, tf.SparseTensor) and not sparse:\n+def convert_to_tensor(x, dtype=None, sparse=None):\n+    if isinstance(x, tf.SparseTensor) and sparse is not None and not sparse:\n         x = tf.sparse.to_dense(x)\n     if dtype is not None:\n         dtype = standardize_dtype(dtype)\n\n@@ -130,7 +130,7 @@ class Variable(KerasVariable):\n             return False\n \n \n-def convert_to_tensor(x, dtype=None, sparse=False):\n+def convert_to_tensor(x, dtype=None, sparse=None):\n     if sparse:\n         raise ValueError(\"`sparse=True` is not supported with torch backend\")\n     if is_tensor(x):\n\n@@ -250,9 +250,7 @@ class Functional(Function, Model):\n         converted = []\n         for x, input in zip(flat_inputs, self._inputs):\n             converted.append(\n-                backend.convert_to_tensor(\n-                    x, dtype=input.dtype, sparse=input.sparse\n-                )\n+                ops.convert_to_tensor(x, dtype=input.dtype, sparse=input.sparse)\n             )\n         return converted\n \n\n@@ -461,12 +461,15 @@ def cast(x, dtype):\n \n \n @keras_export(\"keras.ops.convert_to_tensor\")\n-def convert_to_tensor(x, dtype=None):\n+def convert_to_tensor(x, dtype=None, sparse=None):\n     \"\"\"Convert a NumPy array to a tensor.\n \n     Args:\n         x: A NumPy array.\n         dtype: The target type.\n+        sparse: Whether to keep sparse tensors. `False` will cause sparse\n+            tensors to be densified. The default value of `None` means that\n+            sparse tensors are kept only if the backend supports them.\n \n     Returns:\n         A tensor of the specified `dtype`.\n@@ -476,7 +479,7 @@ def convert_to_tensor(x, dtype=None):\n     >>> x = np.array([1, 2, 3])\n     >>> y = keras.ops.convert_to_tensor(x)\n     \"\"\"\n-    return backend.convert_to_tensor(x, dtype=dtype)\n+    return backend.convert_to_tensor(x, dtype=dtype, sparse=sparse)\n \n \n @keras_export(\"keras.ops.convert_to_numpy\")\n\n@@ -316,11 +316,10 @@ class CoreOpsCorrectnessTest(testing.TestCase):\n         x_default = ops.convert_to_tensor(x)\n         self.assertIsInstance(x_default, tf.SparseTensor)\n         self.assertAllClose(x, x_default)\n-        # Note that ops.convert_to_tensor does not expose the 'sparse' arg\n-        x_sparse = backend.convert_to_tensor(x, sparse=True)\n+        x_sparse = ops.convert_to_tensor(x, sparse=True)\n         self.assertIsInstance(x_sparse, tf.SparseTensor)\n         self.assertAllClose(x, x_sparse)\n-        x_dense = backend.convert_to_tensor(x, sparse=False)\n+        x_dense = ops.convert_to_tensor(x, sparse=False)\n         self.assertNotIsInstance(x_dense, tf.SparseTensor)\n         self.assertAllClose(x, x_dense)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e20b53267f491a7088c985766d1f72b718049557", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 393 | Contributors (this commit): 3 | Commits (past 90d): 10 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -776,10 +776,6 @@ LayoutMap.get.__doc__ = LayoutMap.__getitem__.__doc__\n def distribute_tensor(tensor, layout):\n     \"\"\"Change the layout of a Tensor value in the jit function execution.\n \n-    Note that this might not work outside of the jitted function for certain\n-    backend. To change the layout of a value eagerly, please use\n-    `backend.distribution_lib.distribute_value`.\n-\n     Args:\n         tensor: a Tensor to change the layout.\n         layout: `TensorLayout` to be applied on the value.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#adde3684874cb08e2caf401db1e93ba1a7a95f6c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 294 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 294 | Churn Cumulative: 294 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,294 @@\n+\"\"\"\n+Title: Image classification from scratch\n+Author: [fchollet](https://twitter.com/fchollet)\n+Date created: 2020/04/27\n+Last modified: 2023/11/09\n+Description: Training an image classifier from scratch on the Kaggle Cats vs Dogs dataset.\n+Accelerator: GPU\n+\"\"\"\n+\"\"\"\n+## Introduction\n+\n+This example shows how to do image classification from scratch, starting from JPEG\n+image files on disk, without leveraging pre-trained weights or a pre-made Keras\n+Application model. We demonstrate the workflow on the Kaggle Cats vs Dogs binary\n+classification dataset.\n+\n+We use the `image_dataset_from_directory` utility to generate the datasets, and\n+we use Keras image preprocessing layers for image standardization and data augmentation.\n+\"\"\"\n+\n+\"\"\"\n+## Setup\n+\"\"\"\n+\n+import os\n+import keras\n+from keras import layers\n+from tensorflow import data as tf_data\n+import matplotlib.pyplot as plt\n+\n+\"\"\"\n+## Load the data: the Cats vs Dogs dataset\n+\n+### Raw data download\n+\n+First, let's download the 786M ZIP archive of the raw data:\n+\"\"\"\n+\n+\"\"\"shell\n+curl -O https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n+\"\"\"\n+\n+\"\"\"shell\n+unzip -q kagglecatsanddogs_5340.zip\n+ls\n+\"\"\"\n+\n+\"\"\"\n+Now we have a `PetImages` folder which contain two subfolders, `Cat` and `Dog`. Each\n+subfolder contains image files for each category.\n+\"\"\"\n+\n+\"\"\"shell\n+ls PetImages\n+\"\"\"\n+\n+\"\"\"\n+## Generate a `Dataset`\n+\"\"\"\n+\n+image_size = (180, 180)\n+batch_size = 128\n+\n+train_ds, val_ds = keras.utils.image_dataset_from_directory(\n+    \"PetImages\",\n+    validation_split=0.2,\n+    subset=\"both\",\n+    seed=1337,\n+    image_size=image_size,\n+    batch_size=batch_size,\n+)\n+\n+\"\"\"\n+## Visualize the data\n+\n+Here are the first 9 images in the training dataset.\n+\"\"\"\n+\n+\n+plt.figure(figsize=(10, 10))\n+for images, labels in train_ds.take(1):\n+    for i in range(9):\n+        ax = plt.subplot(3, 3, i + 1)\n+        plt.imshow(images[i].numpy().astype(\"uint8\"))\n+        plt.title(int(labels[i]))\n+        plt.axis(\"off\")\n+\n+\"\"\"\n+## Using image data augmentation\n+\n+When you don't have a large image dataset, it's a good practice to artificially\n+introduce sample diversity by applying random yet realistic transformations to the\n+training images, such as random horizontal flipping or small random rotations. This\n+helps expose the model to different aspects of the training data while slowing down\n+overfitting.\n+\"\"\"\n+\n+data_augmentation = keras.Sequential(\n+    [\n+        layers.RandomFlip(),\n+        layers.RandomRotation(0.15),\n+        layers.RandomZoom(0.15),\n+    ]\n+)\n+\n+\"\"\"\n+Let's visualize what the augmented samples look like, by applying `data_augmentation`\n+repeatedly to the first few images in the dataset:\n+\"\"\"\n+\n+plt.figure(figsize=(10, 10))\n+for images, _ in train_ds.take(1):\n+    for i in range(9):\n+        augmented_images = data_augmentation(images)\n+        ax = plt.subplot(3, 3, i + 1)\n+        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n+        plt.axis(\"off\")\n+\n+\n+\"\"\"\n+## Standardizing the data\n+\n+Our image are already in a standard size (180x180), as they are being yielded as\n+contiguous `float32` batches by our dataset. However, their RGB channel values are in\n+the `[0, 255]` range. This is not ideal for a neural network;\n+in general you should seek to make your input values small. Here, we will\n+standardize values to be in the `[0, 1]` by using a `Rescaling` layer at the start of\n+our model.\n+\"\"\"\n+\n+\"\"\"\n+## Two options to preprocess the data\n+\n+There are two ways you could be using the `data_augmentation` preprocessor:\n+\n+**Option 1: Make it part of the model**, like this:\n+\n+```python\n+inputs = keras.Input(shape=input_shape)\n+x = data_augmentation(inputs)\n+x = layers.Rescaling(1./255)(x)\n+...  # Rest of the model\n+```\n+\n+With this option, your data augmentation will happen *on device*, synchronously\n+with the rest of the model execution, meaning that it will benefit from GPU\n+acceleration.\n+\n+Note that data augmentation is inactive at test time, so the input samples will only be\n+augmented during `fit()`, not when calling `evaluate()` or `predict()`.\n+\n+If you're training on GPU, this may be a good option.\n+\n+**Option 2: apply it to the dataset**, so as to obtain a dataset that yields batches of\n+augmented images, like this:\n+\n+```python\n+augmented_train_ds = train_ds.map(\n+    lambda x, y: (data_augmentation(x, training=True), y))\n+```\n+\n+With this option, your data augmentation will happen **on CPU**, asynchronously, and will\n+be buffered before going into the model.\n+\n+If you're training on CPU, this is the better option, since it makes data augmentation\n+asynchronous and non-blocking.\n+\n+In our case, we'll go with the second option. If you're not sure\n+which one to pick, this second option (asynchronous preprocessing) is always a solid choice.\n+\"\"\"\n+\n+\"\"\"\n+## Configure the dataset for performance\n+\n+Let's apply data augmentation to our training dataset,\n+and let's make sure to use buffered prefetching so we can yield data from disk without\n+having I/O becoming blocking:\n+\"\"\"\n+\n+# Apply `data_augmentation` to the training images.\n+train_ds = train_ds.map(\n+    lambda img, label: (data_augmentation(img), label),\n+    num_parallel_calls=tf_data.AUTOTUNE,\n+)\n+# Prefetching samples in GPU memory helps maximize GPU utilization.\n+train_ds = train_ds.prefetch(tf_data.AUTOTUNE)\n+val_ds = val_ds.prefetch(tf_data.AUTOTUNE)\n+\n+\"\"\"\n+## Build a model\n+\n+We'll build a small version of the Xception network. We haven't particularly tried to\n+optimize the architecture; if you want to do a systematic search for the best model\n+configuration, consider using\n+[KerasTuner](https://github.com/keras-team/keras-tuner).\n+\n+Note that:\n+\n+- We start the model with the `data_augmentation` preprocessor, followed by a\n+ `Rescaling` layer.\n+- We include a `Dropout` layer before the final classification layer.\n+\"\"\"\n+\n+\n+def make_model(input_shape, num_classes):\n+    inputs = keras.Input(shape=input_shape)\n+\n+    # Entry block\n+    x = layers.Rescaling(1.0 / 255)(inputs)\n+    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n+    x = layers.BatchNormalization()(x)\n+    x = layers.Activation(\"relu\")(x)\n+\n+    previous_block_activation = x  # Set aside residual\n+\n+    for size in [256, 512, 728]:\n+        x = layers.Activation(\"relu\")(x)\n+        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n+        x = layers.BatchNormalization()(x)\n+\n+        x = layers.Activation(\"relu\")(x)\n+        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n+        x = layers.BatchNormalization()(x)\n+\n+        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n+\n+        # Project residual\n+        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n+            previous_block_activation\n+        )\n+        x = layers.add([x, residual])  # Add back residual\n+        previous_block_activation = x  # Set aside next residual\n+\n+    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n+    x = layers.BatchNormalization()(x)\n+    x = layers.Activation(\"relu\")(x)\n+\n+    x = layers.GlobalAveragePooling2D()(x)\n+    if num_classes == 2:\n+        activation = \"sigmoid\"\n+        units = 1\n+    else:\n+        activation = \"softmax\"\n+        units = num_classes\n+\n+    x = layers.Dropout(0.5)(x)\n+    outputs = layers.Dense(units, activation=activation)(x)\n+    return keras.Model(inputs, outputs)\n+\n+\n+model = make_model(input_shape=image_size + (3,), num_classes=2)\n+keras.utils.plot_model(model, show_shapes=True)\n+\n+\"\"\"\n+## Train the model\n+\"\"\"\n+\n+epochs = 25\n+\n+callbacks = [\n+    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),\n+]\n+model.compile(\n+    optimizer=keras.optimizers.Adam(1e-3),\n+    loss=\"binary_crossentropy\",\n+    metrics=[\"accuracy\"],\n+)\n+model.fit(\n+    train_ds,\n+    epochs=epochs,\n+    callbacks=callbacks,\n+    validation_data=val_ds,\n+)\n+\n+\"\"\"\n+We get to >90% validation accuracy after training for 25 epochs on the full dataset\n+(in practice, you can train for 50+ epochs before validation performance starts degrading).\n+\"\"\"\n+\n+\"\"\"\n+## Run inference on new data\n+\n+Note that data augmentation and dropout are inactive at inference time.\n+\"\"\"\n+\n+img = keras.utils.load_img(\"PetImages/Cat/6779.jpg\", target_size=image_size)\n+plt.imshow(img)\n+\n+img_array = keras.utils.img_to_array(img)\n+img_array = keras.ops.expand_dims(img_array, 0)  # Create batch axis\n+\n+predictions = model.predict(img_array)\n+score = float(predictions[0])\n+print(f\"This image is {100 * (1 - score):.2f}% cat and {100 * score:.2f}% dog.\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#00eccfb21f399dca3541960689c5877068951b94", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 26 | Churn Cumulative: 320 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -54,6 +54,32 @@ subfolder contains image files for each category.\n ls PetImages\n \"\"\"\n \n+\"\"\"\n+### Filter out corrupted images\n+\n+When working with lots of real-world image data, corrupted images are a common\n+occurence. Let's filter out badly-encoded images that do not feature the string \"JFIF\"\n+in their header.\n+\"\"\"\n+\n+num_skipped = 0\n+for folder_name in (\"Cat\", \"Dog\"):\n+    folder_path = os.path.join(\"PetImages\", folder_name)\n+    for fname in os.listdir(folder_path):\n+        fpath = os.path.join(folder_path, fname)\n+        try:\n+            fobj = open(fpath, \"rb\")\n+            is_jfif = b\"JFIF\" in fobj.peek(10)\n+        finally:\n+            fobj.close()\n+\n+        if not is_jfif:\n+            num_skipped += 1\n+            # Delete corrupted image\n+            os.remove(fpath)\n+\n+print(f\"Deleted {num_skipped} images.\")\n+\n \"\"\"\n ## Generate a `Dataset`\n \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
