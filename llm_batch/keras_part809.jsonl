{"custom_id": "keras#2c59ea8afa2b6af1e4136980cc5ff0655b2883ab", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 97 | Lines Deleted: 0 | Files Changed: 6 | Hunks: 6 | Methods Changed: 9 | Complexity Δ (Sum/Max): -49/7 | Churn Δ: 97 | Churn Cumulative: 1002 | Contributors (this commit): 3 | Commits (past 90d): 23 | Contributors (cumulative): 17 | DMM Complexity: 0.6595744680851063\n\nDIFF:\n@@ -1143,3 +1143,7 @@ def correlate(x1, x2, mode=\"valid\"):\n     x1 = convert_to_tensor(x1)\n     x2 = convert_to_tensor(x2)\n     return jnp.correlate(x1, x2, mode)\n+\n+\n+def select(condlist, choicelist, default=0):\n+    return jnp.select(condlist, choicelist, default=default)\n\n@@ -1090,3 +1090,7 @@ def correlate(x1, x2, mode=\"valid\"):\n     x1 = convert_to_tensor(x1, dtype)\n     x2 = convert_to_tensor(x2, dtype)\n     return np.correlate(x1, x2, mode)\n+\n+\n+def select(condlist, choicelist, default=0):\n+    return np.select(condlist, choicelist, default=default)\n\n@@ -2132,3 +2132,7 @@ def correlate(x1, x2, mode=\"valid\"):\n     x2 = tf.reshape(x2, (x2_len, 1, 1))\n \n     return tf.squeeze(tf.nn.conv1d(x1, x2, stride=1, padding=mode.upper()))\n+\n+\n+def select(condlist, choicelist, default=0):\n+    return tfnp.select(condlist, choicelist, default=default)\n\n@@ -1567,3 +1567,12 @@ def correlate(x1, x2, mode=\"valid\"):\n         result = result[..., start_idx : start_idx + x1_len]\n \n     return torch.squeeze(result)\n+\n+\n+def select(condlist, choicelist, default=0):\n+    condlist = [convert_to_tensor(c) for c in condlist]\n+    choicelist = [convert_to_tensor(c) for c in choicelist]\n+    out = convert_to_tensor(default)\n+    for c, v in reversed(list(zip(condlist, choicelist))):\n+        out = torch.where(c, v, out)\n+    return out\n\n@@ -6172,3 +6172,66 @@ def correlate(x1, x2, mode=\"valid\"):\n     if any_symbolic_tensors((x1, x2)):\n         return Correlate(mode=mode).symbolic_call(x1, x2)\n     return backend.numpy.correlate(x1, x2, mode=mode)\n+\n+\n+class Select(Operation):\n+    def __init__(self):\n+        super().__init__()\n+\n+    def call(self, condlist, choicelist, default=0):\n+        return backend.numpy.correlate(condlist, choicelist, default)\n+\n+    def compute_output_spec(self, condlist, choicelist, default=0):\n+        first_element = choicelist[0]\n+        return KerasTensor(first_element.shape, dtype=first_element.dtype)\n+\n+\n+@keras_export([\"keras.ops.select\", \"keras.ops.numpy.select\"])\n+def select(condlist, choicelist, default=0):\n+    \"\"\"Return elements from `choicelist`, based on conditions in `condlist`.\n+\n+    Args:\n+        condlist: List of boolean tensors.\n+            The list of conditions which determine from which array\n+            in choicelist the output elements are taken.\n+            When multiple conditions are satisfied,\n+            the first one encountered in condlist is used.\n+        choicelist: List of tensors.\n+            The list of tensors from which the output elements are taken.\n+            This list has to be of the same length as `condlist`.\n+        defaults: Optional scalar value.\n+            The element inserted in the output\n+            when all conditions evaluate to `False`.\n+\n+    Returns:\n+        Tensor where the output at position `m` is the `m`-th element\n+        of the tensor in `choicelist` where the `m`-th element of the\n+        corresponding tensor in `condlist` is `True`.\n+\n+    Example:\n+\n+    ```python\n+    from keras import ops\n+\n+    x = ops.arange(6)\n+    condlist = [x<3, x>3]\n+    choicelist = [x, x**2]\n+    ops.select(condlist, choicelist, 42)\n+    # Returns: tensor([0,  1,  2, 42, 16, 25])\n+    ```\n+    \"\"\"\n+    if not isinstance(condlist, list) or not isinstance(choicelist, list):\n+        raise ValueError(\n+            \"condlist and choicelist must be lists. Received: \"\n+            f\"type(condlist) = {type(condlist)}, \"\n+            f\"type(choicelist) = {type(choicelist)}\"\n+        )\n+    if not condlist or not choicelist:\n+        raise ValueError(\n+            \"condlist and choicelist must not be empty. Received: \"\n+            f\"condlist = {condlist}, \"\n+            f\"choicelist = {choicelist}\"\n+        )\n+    if any_symbolic_tensors(condlist + choicelist + [default]):\n+        return Select().symbolic_call(condlist, choicelist, default)\n+    return backend.numpy.select(condlist, choicelist, default)\n\n@@ -4169,6 +4169,19 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             knp.Correlate(mode=\"full\")(x, y), np.correlate(x, y, mode=\"full\")\n         )\n \n+    def test_select(self):\n+        x = np.arange(6)\n+        condlist = [x < 3, x > 3]\n+        choicelist = [x, x**2]\n+        y = knp.select(condlist, choicelist, 42)\n+        self.assertAllClose(y, [0, 1, 2, 42, 16, 25])\n+\n+        x = backend.KerasTensor((6,))\n+        condlist = [x < 3, x > 3]\n+        choicelist = [x, x**2]\n+        y = knp.select(condlist, choicelist, 42)\n+        self.assertEqual(y.shape, (6,))\n+\n \n class NumpyArrayCreateOpsCorrectnessTest(testing.TestCase):\n     def test_ones(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a4315076922ad265cfe95b48681b4ced11f542fd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 4 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 744 | Contributors (this commit): 2 | Commits (past 90d): 10 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -190,6 +190,7 @@ from keras.src.ops.numpy import repeat\n from keras.src.ops.numpy import reshape\n from keras.src.ops.numpy import roll\n from keras.src.ops.numpy import round\n+from keras.src.ops.numpy import select\n from keras.src.ops.numpy import sign\n from keras.src.ops.numpy import sin\n from keras.src.ops.numpy import sinh\n\n@@ -112,6 +112,7 @@ from keras.src.ops.numpy import repeat\n from keras.src.ops.numpy import reshape\n from keras.src.ops.numpy import roll\n from keras.src.ops.numpy import round\n+from keras.src.ops.numpy import select\n from keras.src.ops.numpy import sign\n from keras.src.ops.numpy import sin\n from keras.src.ops.numpy import sinh\n\n@@ -190,6 +190,7 @@ from keras.src.ops.numpy import repeat\n from keras.src.ops.numpy import reshape\n from keras.src.ops.numpy import roll\n from keras.src.ops.numpy import round\n+from keras.src.ops.numpy import select\n from keras.src.ops.numpy import sign\n from keras.src.ops.numpy import sin\n from keras.src.ops.numpy import sinh\n\n@@ -112,6 +112,7 @@ from keras.src.ops.numpy import repeat\n from keras.src.ops.numpy import reshape\n from keras.src.ops.numpy import roll\n from keras.src.ops.numpy import round\n+from keras.src.ops.numpy import select\n from keras.src.ops.numpy import sign\n from keras.src.ops.numpy import sin\n from keras.src.ops.numpy import sinh\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#29d10d1a6c58d02a4f9629ececddac6280c340cd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 9 | Files Changed: 3 | Hunks: 7 | Methods Changed: 5 | Complexity Δ (Sum/Max): 64/57 | Churn Δ: 16 | Churn Cumulative: 652 | Contributors (this commit): 4 | Commits (past 90d): 15 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -223,10 +223,8 @@ def absolute(x):\n     return jnp.absolute(x)\n \n \n-@sparse.elementwise_unary(linear=False)\n def abs(x):\n-    x = convert_to_tensor(x)\n-    return jnp.absolute(x)\n+    return absolute(x)\n \n \n def all(x, axis=None, keepdims=False):\n\n@@ -615,6 +615,7 @@ def zeros(shape, dtype=None):\n \n @sparse.elementwise_unary\n def absolute(x):\n+    x = convert_to_tensor(x)\n     # uintx and bool are always non-negative\n     dtype = standardize_dtype(x.dtype)\n     if \"uint\" in dtype or dtype == \"bool\":\n@@ -622,7 +623,6 @@ def absolute(x):\n     return tf.abs(x)\n \n \n-@sparse.elementwise_unary\n def abs(x):\n     return absolute(x)\n \n@@ -2405,4 +2405,4 @@ def correlate(x1, x2, mode=\"valid\"):\n \n \n def select(condlist, choicelist, default=0):\n-    return tfnp.select(condlist, choicelist, default=default)\n+    return tf.experimental.numpy.select(condlist, choicelist, default=default)\n\n@@ -201,10 +201,6 @@ def zeros_like(x, dtype=None):\n \n \n def absolute(x):\n-    return abs(x)\n-\n-\n-def abs(x):\n     x = convert_to_tensor(x)\n     # bool are always non-negative\n     if standardize_dtype(x.dtype) == \"bool\":\n@@ -212,6 +208,10 @@ def abs(x):\n     return torch.abs(x)\n \n \n+def abs(x):\n+    return absolute(x)\n+\n+\n def all(x, axis=None, keepdims=False):\n     x = convert_to_tensor(x)\n     if axis is None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ee8b2f87c52c9991f06b71b3a91a1f4350807f25", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 11 | Churn Cumulative: 31 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: 0.42857142857142855\n\nDIFF:\n@@ -162,6 +162,11 @@ def serialize_keras_object(obj):\n                 \"step\": serialize_keras_object(obj.step),\n             },\n         }\n+    # Ellipsis is an instance, and ellipsis class is not in global scope.\n+    # checking equality also fails elsewhere in the library, so we have\n+    # to dynamically get the type.\n+    if isinstance(obj, type(Ellipsis)):\n+        return {\"class_name\": \"__ellipsis__\", \"config\": {}}\n     if isinstance(obj, backend.KerasTensor):\n         history = getattr(obj, \"_keras_history\", None)\n         if history:\n@@ -613,6 +618,8 @@ def deserialize_keras_object(\n         return np.array(inner_config[\"value\"], dtype=inner_config[\"dtype\"])\n     if config[\"class_name\"] == \"__bytes__\":\n         return inner_config[\"value\"].encode(\"utf-8\")\n+    if config[\"class_name\"] == \"__ellipsis__\":\n+        return Ellipsis\n     if config[\"class_name\"] == \"__slice__\":\n         return slice(\n             deserialize_keras_object(\n\n@@ -107,6 +107,10 @@ class SerializationLibTest(testing.TestCase):\n         reserialized_str = tuples_to_lists_str(reserialized)\n         self.assertEqual(serialized_str, reserialized_str)\n \n+    def test_serialize_ellipsis(self):\n+        _, deserialized, _ = self.roundtrip(Ellipsis)\n+        self.assertEqual(..., deserialized)\n+\n     def test_tensors_and_shapes(self):\n         x = ops.random.normal((2, 2), dtype=\"float64\")\n         obj = {\"x\": x}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#86b08c81354fe6b32847cce2aaecf8a0f8bcce7a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 14 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -446,7 +446,7 @@ def conv_transpose(\n \n \n def one_hot(x, num_classes, axis=-1, dtype=\"float32\", sparse=False):\n-    x = convert_to_tensor(x)\n+    x = convert_to_tensor(x, dtype=\"int64\")\n     if dtype is None:\n         dtype = \"float32\"\n     if sparse:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#261fa4e5d76f825c6f3fd70414306d63e09e0474", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 26 | Churn Cumulative: 102 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -408,7 +408,9 @@ class EinsumDense(Layer):\n             self._custom_gradient_equation,\n             self._kernel_reverse_transpose_axes,\n         ) = _analyze_quantization_info(self.equation, self.input_spec.ndim)\n-        self.inputs_quantizer = quantizers.AbsMaxQuantizer(axis=-1)\n+        self.inputs_quantizer = quantizers.AbsMaxQuantizer(\n+            axis=self._input_reduced_axes\n+        )\n         self._kernel = self.add_weight(\n             name=\"kernel\",\n             shape=kernel_shape,\n\n@@ -469,6 +469,28 @@ class EinsumDenseTest(testing.TestCase, parameterized.TestCase):\n             backend.standardize_dtype(layer.kernel_scale.dtype), \"float32\"\n         )\n \n+    @parameterized.named_parameters(\n+        (\"btnh,nhd->btd\", \"btnh,nhd->btd\", (None, 8), (1, 2, 2, 4)),\n+        (\"btd,ndh->btnh\", \"btd,ndh->btnh\", (None, 2, 8), (1, 2, 4)),\n+        (\"btd,df->btf\", \"btd,df->btf\", (None, 4), (1, 2, 4)),\n+    )\n+    @pytest.mark.skipif(\n+        backend.backend() == \"numpy\",\n+        reason=f\"{backend.backend()} does not support ops.custom_gradient.\",\n+    )\n+    def test_quantize_int8_with_specific_equations(\n+        self, equation, output_shape, input_shape\n+    ):\n+        layer = layers.EinsumDense(equation=equation, output_shape=output_shape)\n+        layer.build(input_shape)\n+        x = ops.random.uniform(input_shape)\n+        y_float = layer(x)\n+\n+        layer.quantize(\"int8\")\n+        y_quantized = layer(x)\n+        mse = ops.mean(ops.square(y_float - y_quantized))\n+        self.assertLess(mse, 1e-3)  # A weak correctness test\n+\n     @parameterized.named_parameters(\n         (\"int8\", \"int8\"),\n         (\"float8\", \"float8\"),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6f45089e9c8211a9b587798247ccf6bfa8c7c029", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 48 | Files Changed: 2 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 53 | Churn Cumulative: 203 | Contributors (this commit): 3 | Commits (past 90d): 7 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -797,25 +797,6 @@ def ctc_loss(\n     output_length,\n     mask_index=0,\n ):\n-    \"\"\"Runs CTC (Connectionist Temporal Classification) loss on each\n-    batch element.\n-\n-    Arguments:\n-        target: Tensor `(batch_size, max_length)` containing the\n-            target sequences in integer format.\n-        output: Tensor `(batch_size, max_length, num_classes)`\n-            containing the output of the softmax.\n-        target_length: Tensor `(batch_size,)` containing the sequence length\n-            for each target sequence in the batch.\n-        output_length: Tensor `(batch_size,)` containing the sequence length\n-            for each output sequence in the batch.\n-        mask_index: The value in `target` and `output` that represents the\n-            blank label.\n-\n-    Returns:\n-        A tensor of shape `(batch_size,)` containing the CTC loss for each\n-        sample in the batch.\n-    \"\"\"\n     target = tf.convert_to_tensor(target)\n     target = tf.cast(target, dtype=\"int32\")\n     output = tf.convert_to_tensor(output)\n@@ -839,30 +820,6 @@ def ctc_decode(\n     merge_repeated=True,\n     mask_index=None,\n ):\n-    \"\"\"Decodes the output of a softmax using CTC (Connectionist Temporal\n-    Classification).\n-\n-    Arguments:\n-        inputs: Tensor `(batch_size, max_length, num_classes)` containing the\n-            output of the softmax.\n-        sequence_length: Tensor `(batch_size,)` containing the sequence length\n-            for each output sequence in the batch.\n-        strategy: String for decoding strategy to use. Supported values\n-            are \"greedy\" and \"beam_search\".\n-        beam_width: Integer specifying the beam width to use for beam\n-            search strategies. Ignored if `strategy` is \"greedy\".\n-        top_paths: Integer specifying the number of top paths to return.\n-            Ignored if `strategy` is \"greedy\".\n-        merge_repeated: Boolean specifying whether to merge repeated labels\n-            during decoding.\n-        mask_index: Integer specifying the index of the blank label.\n-\n-    Returns:\n-        A tuple of a list of `SparseTensor` containing the decoded sequences\n-        and a `Tensor` containing the negative of the sum of probability\n-        logits (if strategy is `\"greedy\"`) or the log probability (if strategy\n-        is `\"beam_search\"`) for each sequence.\n-    \"\"\"\n     inputs = tf.convert_to_tensor(inputs)\n     inputs = tf.transpose(inputs, (1, 0, 2))\n \n\n@@ -1888,7 +1888,7 @@ def ctc_decode(\n     merge_repeated=True,\n     mask_index=None,\n ):\n-    \"\"\"Decodes the output of a CTC network.\n+    \"\"\"Decodes the output of a CTC model.\n \n     Args:\n         inputs: A tensor of shape `(batch_size, max_length, num_classes)`\n@@ -1898,9 +1898,9 @@ def ctc_decode(\n         strategy: A string for the decoding strategy. Supported values are\n             `\"greedy\"` and `\"beam_search\"`.\n         beam_width: An integer scalar beam width used in beam search.\n-            Defaults to `100`.\n+            Defaults to 100.\n         top_paths: An integer scalar, the number of top paths to return.\n-            Defaults to `1`.\n+            Defaults to 1.\n         merge_repeated: A boolean scalar, whether to merge repeated\n             labels in the output. Defaults to `True`.\n         mask_index: An integer scalar, the index of the mask character in\n@@ -1909,8 +1909,8 @@ def ctc_decode(\n     Returns:\n         A tuple containing:\n \n-        - a list of decoded sequences.\n-        - a list of the negative of the sum of the probability logits\n+        - A list of decoded sequences.\n+        - A list of the negative of the sum of the probability logits\n         (if strategy is `\"greedy\"`) or the log probability (if strategy is\n         `\"beam_search\"`) for each sequence.\n     \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b44d810bf4c7fd9596467f03e6cd538340515d8f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 58 | Lines Deleted: 16 | Files Changed: 6 | Hunks: 15 | Methods Changed: 14 | Complexity Δ (Sum/Max): 8/5 | Churn Δ: 74 | Churn Cumulative: 1092 | Contributors (this commit): 4 | Commits (past 90d): 32 | Contributors (cumulative): 20 | DMM Complexity: 1.0\n\nDIFF:\n@@ -768,9 +768,9 @@ def moveaxis(x, source, destination):\n     return jnp.moveaxis(x, source=source, destination=destination)\n \n \n-def nan_to_num(x):\n+def nan_to_num(x, nan=0.0, posinf=None, neginf=None):\n     x = convert_to_tensor(x)\n-    return jnp.nan_to_num(x)\n+    return jnp.nan_to_num(x, nan=nan, posinf=posinf, neginf=neginf)\n \n \n def ndim(x):\n\n@@ -688,8 +688,8 @@ def moveaxis(x, source, destination):\n     return np.moveaxis(x, source=source, destination=destination)\n \n \n-def nan_to_num(x):\n-    return np.nan_to_num(x)\n+def nan_to_num(x, nan=0.0, posinf=None, neginf=None):\n+    return np.nan_to_num(x, nan=nan, posinf=posinf, neginf=neginf)\n \n \n def ndim(x):\n\n@@ -1531,7 +1531,7 @@ def moveaxis(x, source, destination):\n     return tf.transpose(x, perm)\n \n \n-def nan_to_num(x):\n+def nan_to_num(x, nan=0.0, posinf=None, neginf=None):\n     x = convert_to_tensor(x)\n \n     dtype = x.dtype\n@@ -1539,14 +1539,18 @@ def nan_to_num(x):\n     if dtype_as_dtype.is_integer or not dtype_as_dtype.is_numeric:\n         return x\n \n-    # Replace NaN with 0\n-    x = tf.where(tf.math.is_nan(x), tf.constant(0, dtype), x)\n+    # Replace NaN with `nan`\n+    x = tf.where(tf.math.is_nan(x), tf.constant(nan, dtype), x)\n \n-    # Replace positive infinity with dtype.max\n-    x = tf.where(tf.math.is_inf(x) & (x > 0), tf.constant(dtype.max, dtype), x)\n+    # Replace positive infinity with `posinf` or `dtype.max`\n+    if posinf is None:\n+        posinf = dtype.max\n+    x = tf.where(tf.math.is_inf(x) & (x > 0), tf.constant(posinf, dtype), x)\n \n-    # Replace negative infinity with dtype.min\n-    x = tf.where(tf.math.is_inf(x) & (x < 0), tf.constant(dtype.min, dtype), x)\n+    # Replace negative infinity with `neginf` or `dtype.min`\n+    if neginf is None:\n+        neginf = dtype.min\n+    x = tf.where(tf.math.is_inf(x) & (x < 0), tf.constant(neginf, dtype), x)\n \n     return x\n \n\n@@ -994,9 +994,9 @@ def moveaxis(x, source, destination):\n     return torch.moveaxis(x, source=source, destination=destination)\n \n \n-def nan_to_num(x):\n+def nan_to_num(x, nan=0.0, posinf=None, neginf=None):\n     x = convert_to_tensor(x)\n-    return torch.nan_to_num(x)\n+    return torch.nan_to_num(x, nan=nan, posinf=posinf, neginf=neginf)\n \n \n def ndim(x):\n\n@@ -3955,8 +3955,19 @@ def moveaxis(x, source, destination):\n \n \n class NanToNum(Operation):\n+    def __init__(self, nan=0.0, posinf=None, neginf=None):\n+        super().__init__()\n+        self.nan = nan\n+        self.posinf = posinf\n+        self.neginf = neginf\n+\n     def call(self, x):\n-        return backend.numpy.nan_to_num(x)\n+        return backend.numpy.nan_to_num(\n+            x, nan=self.nan, posinf=self.posinf, neginf=self.neginf\n+        )\n+\n+    def compute_output_spec(self, x):\n+        return KerasTensor(x.shape, dtype=x.dtype)\n \n \n @keras_export(\n@@ -3965,16 +3976,23 @@ class NanToNum(Operation):\n         \"keras.ops.numpy.nan_to_num\",\n     ]\n )\n-def nan_to_num(x):\n+def nan_to_num(x, nan=0.0, posinf=None, neginf=None):\n     \"\"\"Replace NaN with zero and infinity with large finite numbers.\n \n     Args:\n         x: Input data.\n+        nan: Optional float or int. Value to replace `NaN` entries with.\n+        posinf: Optional float or int.\n+            Value to replace positive infinity with.\n+        neginf: Optional float or int.\n+            Value to replace negative infinity with.\n \n     Returns:\n         `x`, with non-finite values replaced.\n     \"\"\"\n-    return backend.numpy.nan_to_num(x)\n+    if any_symbolic_tensors((x,)):\n+        return NanToNum(nan=nan, posinf=posinf, neginf=neginf).symbolic_call(x)\n+    return backend.numpy.nan_to_num(x, nan=nan, posinf=posinf, neginf=neginf)\n \n \n class Ndim(Operation):\n\n@@ -4335,6 +4335,26 @@ class NumpyArrayCreateOpsCorrectnessTest(testing.TestCase):\n         # Test k > M\n         self.assertAllClose(knp.Tri(k=4)(3), np.tri(3, k=4))\n \n+    def test_nan_to_num(self):\n+        x = knp.array([1.0, np.nan, np.inf, -np.inf])\n+        self.assertAllClose(\n+            knp.nan_to_num(x), [1.0, 0.0, 3.402823e38, -3.402823e38]\n+        )\n+        self.assertAllClose(\n+            knp.NanToNum()(x), [1.0, 0.0, 3.402823e38, -3.402823e38]\n+        )\n+        self.assertAllClose(\n+            knp.nan_to_num(x, nan=2, posinf=3, neginf=4), [1.0, 2.0, 3.0, 4.0]\n+        )\n+        self.assertAllClose(\n+            knp.NanToNum(nan=2, posinf=3, neginf=4)(x), [1.0, 2.0, 3.0, 4.0]\n+        )\n+\n+        x = backend.KerasTensor((3, 4))\n+        self.assertEqual(\n+            knp.NanToNum(nan=2, posinf=3, neginf=4)(x).shape, (3, 4)\n+        )\n+\n \n def create_sparse_tensor(x, indices_from=None, start=0, delta=2):\n     if indices_from is not None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#36d24c9d36e6d6c1dfa1647c96755bd7577df329", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 86 | Lines Deleted: 20 | Files Changed: 10 | Hunks: 12 | Methods Changed: 10 | Complexity Δ (Sum/Max): 10/2 | Churn Δ: 106 | Churn Cumulative: 1944 | Contributors (this commit): 5 | Commits (past 90d): 54 | Contributors (cumulative): 30 | DMM Complexity: 1.0\n\nDIFF:\n@@ -220,6 +220,7 @@ from keras.src.ops.numpy import triu\n from keras.src.ops.numpy import true_divide\n from keras.src.ops.numpy import var\n from keras.src.ops.numpy import vdot\n+from keras.src.ops.numpy import vectorize\n from keras.src.ops.numpy import vstack\n from keras.src.ops.numpy import where\n from keras.src.ops.numpy import zeros\n\n@@ -141,6 +141,7 @@ from keras.src.ops.numpy import triu\n from keras.src.ops.numpy import true_divide\n from keras.src.ops.numpy import var\n from keras.src.ops.numpy import vdot\n+from keras.src.ops.numpy import vectorize\n from keras.src.ops.numpy import vstack\n from keras.src.ops.numpy import where\n from keras.src.ops.numpy import zeros\n\n@@ -220,6 +220,7 @@ from keras.src.ops.numpy import triu\n from keras.src.ops.numpy import true_divide\n from keras.src.ops.numpy import var\n from keras.src.ops.numpy import vdot\n+from keras.src.ops.numpy import vectorize\n from keras.src.ops.numpy import vstack\n from keras.src.ops.numpy import where\n from keras.src.ops.numpy import zeros\n\n@@ -141,6 +141,7 @@ from keras.src.ops.numpy import triu\n from keras.src.ops.numpy import true_divide\n from keras.src.ops.numpy import var\n from keras.src.ops.numpy import vdot\n+from keras.src.ops.numpy import vectorize\n from keras.src.ops.numpy import vstack\n from keras.src.ops.numpy import where\n from keras.src.ops.numpy import zeros\n\n@@ -1023,6 +1023,10 @@ def vstack(xs):\n     return jnp.vstack(xs)\n \n \n+def vectorize(pyfunc):\n+    return jnp.vectorize(pyfunc)\n+\n+\n def where(condition, x1, x2):\n     return jnp.where(condition, x1, x2)\n \n\n@@ -937,6 +937,10 @@ def vstack(xs):\n     return np.vstack(xs)\n \n \n+def vectorize(pyfunc):\n+    return np.vectorize(pyfunc)\n+\n+\n def where(condition, x1, x2):\n     if x1 is not None and x2 is not None:\n         if not isinstance(x1, (int, float)):\n\n@@ -2156,6 +2156,14 @@ def vstack(xs):\n     return tf.concat(xs, axis=0)\n \n \n+def vectorize(pyfunc):\n+    @functools.wraps(pyfunc)\n+    def wrapped(x):\n+        return tf.vectorized_map(pyfunc, x)\n+\n+    return wrapped\n+\n+\n def where(condition, x1, x2):\n     condition = tf.cast(condition, \"bool\")\n     if x1 is not None and x2 is not None:\n\n@@ -1,4 +1,5 @@\n import builtins\n+import functools\n import math\n \n import torch\n@@ -1412,6 +1413,14 @@ def vstack(xs):\n     return torch.vstack(xs)\n \n \n+def vectorize(pyfunc):\n+    @functools.wraps(pyfunc)\n+    def wrapped(x):\n+        return torch.vmap(pyfunc, x)\n+\n+    return wrapped\n+\n+\n def where(condition, x1, x2):\n     condition = convert_to_tensor(condition, dtype=bool)\n     if x1 is not None and x2 is not None:\n\n@@ -5415,6 +5415,35 @@ def vdot(x1, x2):\n     return backend.numpy.vdot(x1, x2)\n \n \n+@keras_export([\"keras.ops.vectorize\", \"keras.ops.numpy.vectorize\"])\n+def vectorize(pyfunc):\n+    \"\"\"Turn a function into a vectorized function.\n+\n+    Example:\n+\n+    ```python\n+    def myfunc(a, b):\n+        return a + b\n+\n+    vfunc = np.vectorize(myfunc)\n+    y = vfunc([1, 2, 3, 4], 2)  # Returns Tensor([3, 4, 5, 6])\n+    ```\n+\n+    Args:\n+        pyfunc: Callable of a single tensor argument.\n+\n+    Returns:\n+        A new function that applies `pyfunc` to every element\n+        of its input along axis 0 (the batch axis).\n+    \"\"\"\n+    if not callable(pyfunc):\n+        raise ValueError(\n+            \"Expected argument `pyfunc` to be a callable. \"\n+            f\"Received: pyfunc={pyfunc}\"\n+        )\n+    return backend.numpy.vectorize(pyfunc)\n+\n+\n class Vstack(Operation):\n     def call(self, xs):\n         return backend.numpy.vstack(xs)\n\n@@ -4250,6 +4250,34 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         y = knp.select(condlist, choicelist, 42)\n         self.assertEqual(y.shape, (6,))\n \n+    def test_nan_to_num(self):\n+        x = knp.array([1.0, np.nan, np.inf, -np.inf])\n+        self.assertAllClose(\n+            knp.nan_to_num(x), [1.0, 0.0, 3.402823e38, -3.402823e38]\n+        )\n+        self.assertAllClose(\n+            knp.NanToNum()(x), [1.0, 0.0, 3.402823e38, -3.402823e38]\n+        )\n+        self.assertAllClose(\n+            knp.nan_to_num(x, nan=2, posinf=3, neginf=4), [1.0, 2.0, 3.0, 4.0]\n+        )\n+        self.assertAllClose(\n+            knp.NanToNum(nan=2, posinf=3, neginf=4)(x), [1.0, 2.0, 3.0, 4.0]\n+        )\n+\n+        x = backend.KerasTensor((3, 4))\n+        self.assertEqual(\n+            knp.NanToNum(nan=2, posinf=3, neginf=4)(x).shape, (3, 4)\n+        )\n+\n+    def test_vectorize(self):\n+        def myfunc(a, b):\n+            return a + b\n+\n+        vfunc = np.vectorize(myfunc)\n+        y = vfunc([1, 2, 3, 4], 2)\n+        self.assertAllClose(y, [3, 4, 5, 6])\n+\n \n class NumpyArrayCreateOpsCorrectnessTest(testing.TestCase):\n     def test_ones(self):\n@@ -4335,26 +4363,6 @@ class NumpyArrayCreateOpsCorrectnessTest(testing.TestCase):\n         # Test k > M\n         self.assertAllClose(knp.Tri(k=4)(3), np.tri(3, k=4))\n \n-    def test_nan_to_num(self):\n-        x = knp.array([1.0, np.nan, np.inf, -np.inf])\n-        self.assertAllClose(\n-            knp.nan_to_num(x), [1.0, 0.0, 3.402823e38, -3.402823e38]\n-        )\n-        self.assertAllClose(\n-            knp.NanToNum()(x), [1.0, 0.0, 3.402823e38, -3.402823e38]\n-        )\n-        self.assertAllClose(\n-            knp.nan_to_num(x, nan=2, posinf=3, neginf=4), [1.0, 2.0, 3.0, 4.0]\n-        )\n-        self.assertAllClose(\n-            knp.NanToNum(nan=2, posinf=3, neginf=4)(x), [1.0, 2.0, 3.0, 4.0]\n-        )\n-\n-        x = backend.KerasTensor((3, 4))\n-        self.assertEqual(\n-            knp.NanToNum(nan=2, posinf=3, neginf=4)(x).shape, (3, 4)\n-        )\n-\n \n def create_sparse_tensor(x, indices_from=None, start=0, delta=2):\n     if indices_from is not None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5021ab79ac2ac30dfa85d9484ab8edab9cab9a88", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 16 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -146,10 +146,10 @@ class TrackedList(list):\n             self.tracker.track(value)\n         super().append(value)\n \n-    def insert(self, value):\n+    def insert(self, index, value):\n         if self.tracker:\n             self.tracker.track(value)\n-        super().insert(value)\n+        super().insert(index, value)\n \n     def extend(self, values):\n         if self.tracker:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a6dfcbc0b329150e5c14e3b1ad01b695a797320c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 276 | Lines Deleted: 16 | Files Changed: 7 | Hunks: 17 | Methods Changed: 24 | Complexity Δ (Sum/Max): 107/106 | Churn Δ: 292 | Churn Cumulative: 1486 | Contributors (this commit): 4 | Commits (past 90d): 46 | Contributors (cumulative): 22 | DMM Complexity: 0.36548223350253806\n\nDIFF:\n@@ -1,4 +1,6 @@\n+import functools\n import operator\n+import re\n import warnings\n \n \n@@ -288,3 +290,224 @@ def to_tuple_or_list(value):\n     if isinstance(value, int):\n         return (value,)\n     return value\n+\n+\n+### Code for ops.vectorize() used for TF and torch backends.\n+\n+# See http://docs.scipy.org/doc/numpy/reference/c-api.generalized-ufuncs.html\n+_DIMENSION_NAME = r\"\\w+\"\n+_CORE_DIMENSION_LIST = \"(?:{0:}(?:,{0:})*)?\".format(_DIMENSION_NAME)\n+_ARGUMENT = rf\"\\({_CORE_DIMENSION_LIST}\\)\"\n+_ARGUMENT_LIST = \"{0:}(?:,{0:})*\".format(_ARGUMENT)\n+_SIGNATURE = \"^{0:}->{0:}$\".format(_ARGUMENT_LIST)\n+\n+\n+def _vectorize_parse_gufunc_signature(\n+    signature,\n+):\n+    if not re.match(_SIGNATURE, signature):\n+        raise ValueError(f\"not a valid gufunc signature: {signature}\")\n+    args, retvals = (\n+        [\n+            tuple(re.findall(_DIMENSION_NAME, arg))\n+            for arg in re.findall(_ARGUMENT, arg_list)\n+        ]\n+        for arg_list in signature.split(\"->\")\n+    )\n+    return args, retvals\n+\n+\n+def _vectorize_update_dim_sizes(dim_sizes, shape, core_dims, is_input=True):\n+    num_core_dims = len(core_dims)\n+    if is_input:\n+        if len(shape) < num_core_dims:\n+            raise ValueError(\n+                f\"input with shape {shape} does not \"\n+                \"have enough dimensions for all core \"\n+                f\"dimensions {core_dims}\"\n+            )\n+    else:\n+        if len(shape) != num_core_dims:\n+            raise ValueError(\n+                f\"output shape {shape} does not \"\n+                f\"match core dimensions {core_dims}\"\n+            )\n+\n+    core_shape = shape[-num_core_dims:] if core_dims else ()\n+    for dim, size in zip(core_dims, core_shape):\n+        if dim not in dim_sizes:\n+            dim_sizes[dim] = size\n+        elif size != dim_sizes[dim]:\n+            raise ValueError(\n+                f\"inconsistent size for core dimension {dim}: \"\n+                f\"{size} vs {dim_sizes[dim]}\"\n+            )\n+\n+\n+def _vectorize_parse_input_dimensions(\n+    args,\n+    input_core_dims,\n+):\n+    from keras.src import ops\n+\n+    if len(args) != len(input_core_dims):\n+        raise TypeError(\n+            \"wrong number of positional arguments: \"\n+            f\"expected {len(input_core_dims)}, got {len(args)}\"\n+        )\n+    shapes = []\n+    dim_sizes: dict[str, int] = {}\n+    for arg, core_dims in zip(args, input_core_dims):\n+        _vectorize_update_dim_sizes(\n+            dim_sizes, arg.shape, core_dims, is_input=True\n+        )\n+        ndim = arg.ndim - len(core_dims)\n+        shapes.append(arg.shape[:ndim])\n+    broadcast_shape = shapes[0]\n+    for s in shapes:\n+        broadcast_shape = ops.broadcast_shapes(broadcast_shape, s)\n+    return broadcast_shape, dim_sizes\n+\n+\n+def _vectorize_check_output_dims(\n+    func,\n+    dim_sizes,\n+    expected_output_core_dims,\n+):\n+    from keras.src import ops\n+\n+    def wrapped(*args):\n+        out = func(*args)\n+        if isinstance(out, (list, tuple)):\n+            out_shapes = [ops.shape(x) for x in out]\n+        else:\n+            out_shapes = [out.shape]\n+\n+        if expected_output_core_dims is None:\n+            output_core_dims = [()] * len(out_shapes)\n+        else:\n+            output_core_dims = expected_output_core_dims\n+            if len(output_core_dims) > 1 and not isinstance(out, tuple):\n+                raise TypeError(\n+                    \"output must be a tuple when multiple outputs \"\n+                    f\"are expected, got: {out}\"\n+                )\n+            if len(out_shapes) != len(output_core_dims):\n+                raise TypeError(\n+                    \"wrong number of output arguments: \"\n+                    f\"expected {len(output_core_dims)}, got {len(out_shapes)}\"\n+                )\n+\n+        sizes = dict(dim_sizes)\n+        for shape, core_dims in zip(out_shapes, output_core_dims):\n+            _vectorize_update_dim_sizes(sizes, shape, core_dims, is_input=False)\n+\n+        return out\n+\n+    return wrapped\n+\n+\n+def _vectorize_apply_excluded(func, excluded, args, kwargs):\n+    if not excluded:\n+        return func, args, kwargs\n+\n+    dynamic_args = [arg for i, arg in enumerate(args) if i not in excluded]\n+    dynamic_kwargs = {\n+        key: val for key, val in kwargs.items() if key not in excluded\n+    }\n+    static_args = [\n+        (i, args[i])\n+        for i in sorted(e for e in excluded if isinstance(e, int))\n+        if i < len(args)\n+    ]\n+    static_kwargs = {key: val for key, val in kwargs.items() if key in excluded}\n+\n+    def new_func(*args, **kwargs):\n+        args = list(args)\n+        for i, arg in static_args:\n+            args.insert(i, arg)\n+        return func(*args, **kwargs, **static_kwargs)\n+\n+    return new_func, dynamic_args, dynamic_kwargs\n+\n+\n+def vectorize_impl(pyfunc, vmap_fn, *, excluded=None, signature=None):\n+    \"\"\"Implementation adapted from JAX and NumPy.\"\"\"\n+\n+    from keras.src import ops\n+\n+    excluded = None or set()\n+\n+    @functools.wraps(pyfunc)\n+    def wrapped(*args, **kwargs):\n+        excluded_func, args, kwargs = _vectorize_apply_excluded(\n+            pyfunc, excluded, args, kwargs\n+        )\n+\n+        if signature is not None:\n+            input_core_dims, output_core_dims = (\n+                _vectorize_parse_gufunc_signature(signature)\n+            )\n+        else:\n+            input_core_dims = [()] * len(args)\n+            output_core_dims = None\n+\n+        none_args = {i for i, arg in enumerate(args) if arg is None}\n+        if any(none_args):\n+            if any(input_core_dims[i] != () for i in none_args):\n+                raise ValueError(\n+                    f\"Cannot pass None at locations {none_args} \"\n+                    f\"with signature={signature}\"\n+                )\n+            excluded_func, args, _ = _vectorize_apply_excluded(\n+                excluded_func, none_args, args, {}\n+            )\n+            input_core_dims = [\n+                dim\n+                for i, dim in enumerate(input_core_dims)\n+                if i not in none_args\n+            ]\n+\n+        args = tuple(map(ops.convert_to_tensor, args))\n+\n+        broadcast_shape, dim_sizes = _vectorize_parse_input_dimensions(\n+            args, input_core_dims\n+        )\n+        checked_func = _vectorize_check_output_dims(\n+            excluded_func, dim_sizes, output_core_dims\n+        )\n+        squeezed_args = []\n+        rev_filled_shapes = []\n+        for arg, core_dims in zip(args, input_core_dims):\n+            noncore_shape = arg.shape[: arg.ndim - len(core_dims)]\n+\n+            pad_ndim = len(broadcast_shape) - len(noncore_shape)\n+            filled_shape = pad_ndim * (1,) + noncore_shape\n+            rev_filled_shapes.append(filled_shape[::-1])\n+\n+            squeeze_indices = tuple(\n+                i for i, size in enumerate(noncore_shape) if size == 1\n+            )\n+            squeezed_arg = ops.squeeze(arg, axis=squeeze_indices)\n+            squeezed_args.append(squeezed_arg)\n+\n+        vectorized_func = checked_func\n+        dims_to_expand = []\n+        for negdim, axis_sizes in enumerate(zip(*rev_filled_shapes)):\n+            in_axes = tuple(None if size == 1 else 0 for size in axis_sizes)\n+            if all(axis is None for axis in in_axes):\n+                dims_to_expand.append(len(broadcast_shape) - 1 - negdim)\n+            else:\n+                vectorized_func = vmap_fn(vectorized_func, in_axes)\n+        result = vectorized_func(*squeezed_args)\n+\n+        if not dims_to_expand:\n+            return result\n+        elif isinstance(result, tuple):\n+            return tuple(\n+                ops.expand_dims(r, axis=dims_to_expand) for r in result\n+            )\n+        else:\n+            return ops.expand_dims(result, axis=dims_to_expand)\n+\n+    return wrapped\n\n@@ -1023,8 +1023,8 @@ def vstack(xs):\n     return jnp.vstack(xs)\n \n \n-def vectorize(pyfunc):\n-    return jnp.vectorize(pyfunc)\n+def vectorize(pyfunc, *, excluded=None, signature=None):\n+    return jnp.vectorize(pyfunc, excluded=excluded, signature=signature)\n \n \n def where(condition, x1, x2):\n\n@@ -937,8 +937,8 @@ def vstack(xs):\n     return np.vstack(xs)\n \n \n-def vectorize(pyfunc):\n-    return np.vectorize(pyfunc)\n+def vectorize(pyfunc, *, excluded=None, signature=None):\n+    return np.vectorize(pyfunc, excluded=excluded, signature=signature)\n \n \n def where(condition, x1, x2):\n\n@@ -15,6 +15,7 @@ from keras.src.backend import standardize_dtype\n from keras.src.backend.common import dtypes\n from keras.src.backend.common.backend_utils import canonicalize_axis\n from keras.src.backend.common.backend_utils import to_tuple_or_list\n+from keras.src.backend.common.backend_utils import vectorize_impl\n from keras.src.backend.tensorflow import sparse\n from keras.src.backend.tensorflow.core import cast\n from keras.src.backend.tensorflow.core import convert_to_tensor\n@@ -2156,14 +2157,25 @@ def vstack(xs):\n     return tf.concat(xs, axis=0)\n \n \n-def vectorize(pyfunc):\n-    @functools.wraps(pyfunc)\n+def _vmap_fn(fn, in_axes=0):\n+    if in_axes != 0:\n+        raise ValueError(\n+            \"Not supported with `vectorize()` with the TensorFlow backend.\"\n+        )\n+\n+    @functools.wraps(fn)\n     def wrapped(x):\n-        return tf.vectorized_map(pyfunc, x)\n+        return tf.vectorized_map(fn, x)\n \n     return wrapped\n \n \n+def vectorize(pyfunc, *, excluded=None, signature=None):\n+    return vectorize_impl(\n+        pyfunc, _vmap_fn, excluded=excluded, signature=signature\n+    )\n+\n+\n def where(condition, x1, x2):\n     condition = tf.cast(condition, \"bool\")\n     if x1 is not None and x2 is not None:\n\n@@ -1,5 +1,4 @@\n import builtins\n-import functools\n import math\n \n import torch\n@@ -9,6 +8,7 @@ from keras.src.backend import config\n from keras.src.backend.common import dtypes\n from keras.src.backend.common.backend_utils import canonicalize_axis\n from keras.src.backend.common.backend_utils import to_tuple_or_list\n+from keras.src.backend.common.backend_utils import vectorize_impl\n from keras.src.backend.common.variables import standardize_dtype\n from keras.src.backend.torch.core import cast\n from keras.src.backend.torch.core import convert_to_tensor\n@@ -1413,12 +1413,10 @@ def vstack(xs):\n     return torch.vstack(xs)\n \n \n-def vectorize(pyfunc):\n-    @functools.wraps(pyfunc)\n-    def wrapped(x):\n-        return torch.vmap(pyfunc, x)\n-\n-    return wrapped\n+def vectorize(pyfunc, *, excluded=None, signature=None):\n+    return vectorize_impl(\n+        pyfunc, torch.vmap, excluded=excluded, signature=signature\n+    )\n \n \n def where(condition, x1, x2):\n\n@@ -5416,7 +5416,7 @@ def vdot(x1, x2):\n \n \n @keras_export([\"keras.ops.vectorize\", \"keras.ops.numpy.vectorize\"])\n-def vectorize(pyfunc):\n+def vectorize(pyfunc, *, excluded=None, signature=None):\n     \"\"\"Turn a function into a vectorized function.\n \n     Example:\n@@ -5431,6 +5431,17 @@ def vectorize(pyfunc):\n \n     Args:\n         pyfunc: Callable of a single tensor argument.\n+        excluded: Optional set of integers representing\n+            positional arguments for which the function\n+            will not be vectorized.\n+            These will be passed directly to `pyfunc` unmodified.\n+        signature: Optional generalized universal function signature,\n+            e.g., `\"(m,n),(n)->(m)\"` for vectorized\n+            matrix-vector multiplication. If provided,\n+            `pyfunc` will be called with (and expected to return)\n+            arrays with shapes given by the size of corresponding\n+            core dimensions. By default, `pyfunc` is assumed\n+            to take scalars tensors as input and output.\n \n     Returns:\n         A new function that applies `pyfunc` to every element\n@@ -5441,7 +5452,9 @@ def vectorize(pyfunc):\n             \"Expected argument `pyfunc` to be a callable. \"\n             f\"Received: pyfunc={pyfunc}\"\n         )\n-    return backend.numpy.vectorize(pyfunc)\n+    return backend.numpy.vectorize(\n+        pyfunc, excluded=excluded, signature=signature\n+    )\n \n \n class Vstack(Operation):\n\n@@ -4271,6 +4271,7 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         )\n \n     def test_vectorize(self):\n+        # Basic functionality\n         def myfunc(a, b):\n             return a + b\n \n@@ -4278,6 +4279,19 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         y = vfunc([1, 2, 3, 4], 2)\n         self.assertAllClose(y, [3, 4, 5, 6])\n \n+        # Test signature arg\n+        vfunc = knp.vectorize(knp.trace, signature=\"(d,d)->()\")\n+        out = vfunc(np.eye(4))\n+        self.assertAllClose(\n+            out, np.vectorize(np.trace, signature=\"(d,d)->()\")(np.eye(4))\n+        )\n+\n+        vfunc = knp.vectorize(knp.diag, signature=\"(d,d)->(d)\")\n+        out = vfunc(np.eye(4))\n+        self.assertAllClose(\n+            out, np.vectorize(np.diag, signature=\"(d,d)->(d)\")(np.eye(4))\n+        )\n+\n \n class NumpyArrayCreateOpsCorrectnessTest(testing.TestCase):\n     def test_ones(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3afc089aa90687bd9fb5b74139ee72aa32286902", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 138 | Lines Deleted: 5 | Files Changed: 5 | Hunks: 18 | Methods Changed: 10 | Complexity Δ (Sum/Max): 7/4 | Churn Δ: 143 | Churn Cumulative: 216 | Contributors (this commit): 3 | Commits (past 90d): 11 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4,6 +4,9 @@ This file was autogenerated. Do not edit it by hand,\n since your modifications would be overwritten.\n \"\"\"\n \n+from keras.src.dtype_policies import deserialize\n+from keras.src.dtype_policies import get\n+from keras.src.dtype_policies import serialize\n from keras.src.dtype_policies.dtype_policy import DTypePolicy\n from keras.src.dtype_policies.dtype_policy import FloatDTypePolicy\n from keras.src.dtype_policies.dtype_policy import QuantizedDTypePolicy\n\n@@ -4,6 +4,9 @@ This file was autogenerated. Do not edit it by hand,\n since your modifications would be overwritten.\n \"\"\"\n \n+from keras.src.dtype_policies import deserialize\n+from keras.src.dtype_policies import get\n+from keras.src.dtype_policies import serialize\n from keras.src.dtype_policies.dtype_policy import DTypePolicy\n from keras.src.dtype_policies.dtype_policy import FloatDTypePolicy\n from keras.src.dtype_policies.dtype_policy import QuantizedDTypePolicy\n\n@@ -1,23 +1,96 @@\n from keras.src import backend\n+from keras.src.api_export import keras_export\n from keras.src.dtype_policies import dtype_policy\n from keras.src.dtype_policies.dtype_policy import QUANTIZATION_MODES\n+from keras.src.dtype_policies.dtype_policy import DTypePolicy\n from keras.src.dtype_policies.dtype_policy import FloatDTypePolicy\n from keras.src.dtype_policies.dtype_policy import QuantizedDTypePolicy\n from keras.src.dtype_policies.dtype_policy import QuantizedFloat8DTypePolicy\n \n+ALL_OBJECTS = {\n+    DTypePolicy,\n+    FloatDTypePolicy,\n+    QuantizedDTypePolicy,\n+    QuantizedFloat8DTypePolicy,\n+}\n+ALL_OBJECTS_DICT = {cls.__name__: cls for cls in ALL_OBJECTS}\n \n+\n+@keras_export(\"keras.dtype_policies.serialize\")\n+def serialize(dtype_policy):\n+    \"\"\"Serializes `DTypePolicy` instance.\n+\n+    Args:\n+        dtype_policy: A Keras `DTypePolicy` instance.\n+\n+    Returns:\n+        `DTypePolicy` configuration dictionary.\n+    \"\"\"\n+    from keras.src.saving import serialization_lib\n+\n+    return serialization_lib.serialize_keras_object(dtype_policy)\n+\n+\n+@keras_export(\"keras.dtype_policies.deserialize\")\n+def deserialize(config, custom_objects=None):\n+    \"\"\"Deserializes a serialized `DTypePolicy` instance.\n+\n+    Args:\n+        config: `DTypePolicy` configuration.\n+        custom_objects: Optional dictionary mapping names (strings) to custom\n+            objects (classes and functions) to be considered during\n+            deserialization.\n+\n+    Returns:\n+        A Keras `DTypePolicy` instance.\n+    \"\"\"\n+    from keras.src.saving import serialization_lib\n+\n+    return serialization_lib.deserialize_keras_object(\n+        config,\n+        module_objects=ALL_OBJECTS_DICT,\n+        custom_objects=custom_objects,\n+    )\n+\n+\n+@keras_export(\"keras.dtype_policies.get\")\n def get(identifier):\n+    \"\"\"Retrieves a Keras `DTypePolicy` instance.\n+\n+    The `identifier` may be the string name of a `DTypePolicy` class.\n+\n+    >>> policy = dtype_policies.get(\"mixed_bfloat16\")\n+    >>> type(loss)\n+    <class '...FloatDTypePolicy'>\n+\n+    You can also specify `config` of the dtype policy to this function by\n+    passing dict containing `class_name` and `config` as an identifier. Also\n+    note that the `class_name` must map to a `DTypePolicy` class\n+\n+    >>> identifier = {\"class_name\": \"FloatDTypePolicy\",\n+    ...               \"config\": {\"name\": \"float32\"}}\n+    >>> policy = dtype_policies.get(identifier)\n+    >>> type(loss)\n+    <class '...FloatDTypePolicy'>\n+\n+    Args:\n+        identifier: A dtype policy identifier. One of `None` or string name of a\n+            `DTypePolicy` or `DTypePolicy` configuration dictionary or a\n+            `DTypePolicy` instance.\n+\n+    Returns:\n+        A Keras `DTypePolicy` instance.\n+    \"\"\"\n     from keras.src.dtype_policies.dtype_policy import (\n         _get_quantized_dtype_policy_by_str,\n     )\n-    from keras.src.saving import serialization_lib\n \n     if identifier is None:\n         return dtype_policy.dtype_policy()\n     if isinstance(identifier, (FloatDTypePolicy, QuantizedDTypePolicy)):\n         return identifier\n     if isinstance(identifier, dict):\n-        return serialization_lib.deserialize_keras_object(identifier)\n+        return deserialize(identifier)\n     if isinstance(identifier, str):\n         if identifier.startswith(QUANTIZATION_MODES):\n             return _get_quantized_dtype_policy_by_str(identifier)\n\n@@ -293,6 +293,11 @@ class QuantizedFloat8DTypePolicy(QuantizedDTypePolicy):\n         ]\n         return valid_policies\n \n+    def get_config(self):\n+        config = super().get_config()\n+        config.update({\"amax_history_length\": self.amax_history_length})\n+        return config\n+\n \n @keras_export(\n     [\n\n@@ -1,5 +1,8 @@\n from absl.testing import parameterized\n \n+from keras.src.dtype_policies import deserialize\n+from keras.src.dtype_policies import get\n+from keras.src.dtype_policies import serialize\n from keras.src.dtype_policies.dtype_policy import DTypePolicy\n from keras.src.dtype_policies.dtype_policy import FloatDTypePolicy\n from keras.src.dtype_policies.dtype_policy import QuantizedDTypePolicy\n@@ -64,7 +67,7 @@ class DTypePolicyTest(test_case.TestCase):\n         new_policy = DTypePolicy.from_config(config)\n         self.assertEqual(new_policy.name, \"mixed_float16\")\n \n-    def test_serialization(self):\n+    def test_python_serialization(self):\n         \"\"\"Test builtin serialization methods.\"\"\"\n         import copy\n         import pickle\n@@ -91,6 +94,16 @@ class DTypePolicyTest(test_case.TestCase):\n             repr(copied_policy), '<FloatDTypePolicy \"mixed_float16\">'\n         )\n \n+    def test_serialization(self):\n+        policy = DTypePolicy(\"mixed_float16\")\n+        config = serialize(policy)\n+        reloaded_policy = deserialize(config)\n+        self.assertEqual(policy.name, reloaded_policy.name)\n+\n+        # Test `dtype_policies.get`\n+        reloaded_policy = get(config)\n+        self.assertEqual(policy.name, reloaded_policy.name)\n+\n \n class FloatDTypePolicyTest(test_case.TestCase):\n     def test_initialization_valid_name(self):\n@@ -154,6 +167,16 @@ class FloatDTypePolicyTest(test_case.TestCase):\n         new_policy = FloatDTypePolicy.from_config(config)\n         self.assertEqual(new_policy.name, \"mixed_float16\")\n \n+    def test_serialization(self):\n+        policy = FloatDTypePolicy(\"mixed_float16\")\n+        config = serialize(policy)\n+        reloaded_policy = deserialize(config)\n+        self.assertEqual(policy.name, reloaded_policy.name)\n+\n+        # Test `dtype_policies.get`\n+        reloaded_policy = get(config)\n+        self.assertEqual(policy.name, reloaded_policy.name)\n+\n \n class QuantizedDTypePolicyTest(test_case.TestCase, parameterized.TestCase):\n     @parameterized.named_parameters(\n@@ -224,7 +247,7 @@ class QuantizedDTypePolicyTest(test_case.TestCase, parameterized.TestCase):\n             '<QuantizedFloat8DTypePolicy \"float8_from_mixed_bfloat16\">',\n         ),\n     )\n-    def test_serialization(self, name, repr_str):\n+    def test_python_serialization(self, name, repr_str):\n         import copy\n         import pickle\n \n@@ -244,6 +267,16 @@ class QuantizedDTypePolicyTest(test_case.TestCase, parameterized.TestCase):\n             copied_policy = pickle.load(f)\n         self.assertEqual(repr(copied_policy), repr_str)\n \n+    def test_serialization(self):\n+        policy = QuantizedDTypePolicy(\"int8_from_float32\")\n+        config = serialize(policy)\n+        reloaded_policy = deserialize(config)\n+        self.assertEqual(policy.name, reloaded_policy.name)\n+\n+        # Test `dtype_policies.get`\n+        reloaded_policy = get(config)\n+        self.assertEqual(policy.name, reloaded_policy.name)\n+\n     def test_properties_for_float8(self):\n         policy = QuantizedFloat8DTypePolicy(\"float8_from_mixed_bfloat16\")\n         self.assertEqual(policy.amax_history_length, 1024)\n@@ -256,7 +289,7 @@ class QuantizedDTypePolicyTest(test_case.TestCase, parameterized.TestCase):\n         with self.assertRaisesRegex(TypeError, \"must be an integer.\"):\n             QuantizedFloat8DTypePolicy(\"float8_from_float32\", 512.0)\n \n-    def test_serialization_for_float8(self):\n+    def test_python_serialization_for_float8(self):\n         import copy\n         import pickle\n \n@@ -288,6 +321,22 @@ class QuantizedDTypePolicyTest(test_case.TestCase, parameterized.TestCase):\n         )\n         self.assertEqual(copied_policy.amax_history_length, 123)\n \n+    def test_serialization_for_float8(self):\n+        policy = QuantizedFloat8DTypePolicy(\"float8_from_mixed_float16\")\n+        config = serialize(policy)\n+        reloaded_policy = deserialize(config)\n+        self.assertEqual(policy.name, reloaded_policy.name)\n+        self.assertEqual(\n+            policy.amax_history_length, reloaded_policy.amax_history_length\n+        )\n+\n+        # Test `dtype_policies.get`\n+        reloaded_policy = get(config)\n+        self.assertEqual(policy.name, reloaded_policy.name)\n+        self.assertEqual(\n+            policy.amax_history_length, reloaded_policy.amax_history_length\n+        )\n+\n     @parameterized.named_parameters(\n         (\"int8_from_mixed_bfloat16\", \"int8_from_mixed_bfloat16\"),\n         (\"float8_from_mixed_bfloat16\", \"float8_from_mixed_bfloat16\"),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
