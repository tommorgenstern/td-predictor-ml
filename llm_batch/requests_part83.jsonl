{"custom_id": "requests#e8d02ea0bbc05042e618a7ca115f4fca7b2deeb9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 10 | Churn Cumulative: 7094 | Contributors (this commit): 124 | Commits (past 90d): 16 | Contributors (cumulative): 143 | DMM Complexity: 1.0\n\nDIFF:\n@@ -115,7 +115,7 @@ def get_netrc_auth(url):\n def guess_filename(obj):\n     \"\"\"Tries to guess the filename of the given object.\"\"\"\n     name = getattr(obj, 'name', None)\n-    if name and name[0] != '<' and name[-1] != '>':\n+    if name and isinstance(name, builtin_str) and name[0] != '<' and name[-1] != '>':\n         return os.path.basename(name)\n \n \n\n@@ -928,6 +928,14 @@ class RequestsTestCase(unittest.TestCase):\n \n         assert 'multipart/form-data' in p.headers['Content-Type']\n \n+    def test_can_send_file_object_with_non_string_filename(self):\n+        f = io.BytesIO()\n+        f.name = 2\n+        r = requests.Request('POST', httpbin('post'), files={'f': f})\n+        p = r.prepare()\n+\n+        assert 'multipart/form-data' in p.headers['Content-Type']\n+\n     def test_autoset_header_values_are_native(self):\n         data = 'this is a string'\n         length = '16'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#da82fb4b1d287caff3a2a99692be111eccbd1347", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 25 | Churn Cumulative: 113 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -1,9 +1,24 @@\n \"\"\"\n-pip._vendor is for vendoring dependencies of pip to prevent needing pip to\n-depend on something external.\n+Copyright (c) Donald Stufft, pip, and individual contributors\n \n-Files inside of pip._vendor should be considered immutable and should only be\n-updated to versions from upstream.\n+Permission is hereby granted, free of charge, to any person obtaining\n+a copy of this software and associated documentation files (the\n+\"Software\"), to deal in the Software without restriction, including\n+without limitation the rights to use, copy, modify, merge, publish,\n+distribute, sublicense, and/or sell copies of the Software, and to\n+permit persons to whom the Software is furnished to do so, subject to\n+the following conditions:\n+\n+The above copyright notice and this permission notice shall be\n+included in all copies or substantial portions of the Software.\n+\n+THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n+EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n+MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n+NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n+LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n+OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n+WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n \"\"\"\n from __future__ import absolute_import\n \n@@ -50,7 +65,7 @@ class VendorAlias(object):\n             finally:\n                 # Re-add any additions to sys.meta_path that were made while\n                 # during the import we just did, otherwise things like\n-                # pip._vendor.six.moves will fail.\n+                # requests.packages.urllib3.poolmanager will fail.\n                 for m in sys.meta_path:\n                     if m not in real_meta_path:\n                         real_meta_path.append(m)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#01b58ba04e694384119e33b05726b81757022b2e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 169 | Contributors (this commit): 16 | Commits (past 90d): 1 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -76,7 +76,7 @@ is_solaris = ('solar==' in str(sys.platform).lower())   # Complete guess.\n try:\n     import simplejson as json\n except (ImportError, SyntaxError):\n-    # simplejson does not support Python 3.2, it thows a SyntaxError\n+    # simplejson does not support Python 3.2, it throws a SyntaxError\n     # because of u'...' Unicode literals.\n     import json\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#4c61fef13f53db220f95032b72e6e374970bf272", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 18 | Churn Cumulative: 4901 | Contributors (this commit): 89 | Commits (past 90d): 11 | Contributors (cumulative): 89 | DMM Complexity: 1.0\n\nDIFF:\n@@ -825,15 +825,15 @@ class RequestsTestCase(unittest.TestCase):\n         assert str(error) == 'message'\n         assert error.response == response\n \n-##    def test_session_pickling(self):\n-##        r = requests.Request('GET', httpbin('get'))\n-##        s = requests.Session()\n-##\n-##        s = pickle.loads(pickle.dumps(s))\n-##        s.proxies = getproxies()\n-##\n-##        r = s.send(r.prepare())\n-##        assert r.status_code == 200\n+    def test_session_pickling(self):\n+        r = requests.Request('GET', httpbin('get'))\n+        s = requests.Session()\n+\n+        s = pickle.loads(pickle.dumps(s))\n+        s.proxies = getproxies()\n+\n+        r = s.send(r.prepare())\n+        assert r.status_code == 200\n \n     def test_fixes_1329(self):\n         \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#925e975295e2fe772268e748c6c074af7b0ae47d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 7 | Churn Cumulative: 9248 | Contributors (this commit): 140 | Commits (past 90d): 17 | Contributors (cumulative): 140 | DMM Complexity: None\n\nDIFF:\n@@ -22,9 +22,8 @@ from .packages.urllib3.util import parse_url\n from .packages.urllib3.exceptions import (\n     DecodeError, ReadTimeoutError, ProtocolError)\n from .exceptions import (\n-    HTTPError, RequestException, MissingSchema, InvalidURL, \n-    ChunkedEncodingError, ContentDecodingError, ConnectionError, \n-    StreamConsumedError)\n+    HTTPError, MissingSchema, InvalidURL, ChunkedEncodingError,\n+    ContentDecodingError, ConnectionError, StreamConsumedError)\n from .utils import (\n     guess_filename, get_auth_from_url, requote_uri,\n     stream_decode_response_unicode, to_key_val_list, parse_header_links,\n@@ -615,7 +614,7 @@ class Response(object):\n     def ok(self):\n         try:\n             self.raise_for_status()\n-        except RequestException:\n+        except HTTPError:\n             return False\n         return True\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#bd3cf95e34aa49c8d764c899672048df107e0d70", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 9250 | Contributors (this commit): 140 | Commits (past 90d): 18 | Contributors (cumulative): 140 | DMM Complexity: None\n\nDIFF:\n@@ -353,7 +353,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         try:\n             scheme, auth, host, port, path, query, fragment = parse_url(url)\n         except LocationParseError as e:\n-            raise InvalidURL(e.message)\n+            raise InvalidURL(*e.args)\n \n         if not scheme:\n             raise MissingSchema(\"Invalid URL {0!r}: No schema supplied. \"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#86c3ecfd341e4e86977317f03ae344d363c63e3a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 1267 | Contributors (this commit): 32 | Commits (past 90d): 5 | Contributors (cumulative): 32 | DMM Complexity: 1.0\n\nDIFF:\n@@ -67,6 +67,7 @@ class HTTPDigestAuth(AuthBase):\n         self.nonce_count = 0\n         self.chal = {}\n         self.pos = None\n+        self.num_401_calls = 1\n \n     def build_digest_header(self, method, url):\n \n@@ -154,7 +155,7 @@ class HTTPDigestAuth(AuthBase):\n     def handle_redirect(self, r, **kwargs):\n         \"\"\"Reset num_401_calls counter on redirects.\"\"\"\n         if r.is_redirect:\n-            setattr(self, 'num_401_calls', 1)\n+            self.num_401_calls = 1\n \n     def handle_401(self, r, **kwargs):\n         \"\"\"Takes the given response and tries digest-auth, if needed.\"\"\"\n@@ -168,7 +169,7 @@ class HTTPDigestAuth(AuthBase):\n \n         if 'digest' in s_auth.lower() and num_401_calls < 2:\n \n-            setattr(self, 'num_401_calls', num_401_calls + 1)\n+            self.num_401_calls += 1\n             pat = re.compile(r'digest ', flags=re.IGNORECASE)\n             self.chal = parse_dict_header(pat.sub('', s_auth, count=1))\n \n@@ -188,7 +189,7 @@ class HTTPDigestAuth(AuthBase):\n \n             return _r\n \n-        setattr(self, 'num_401_calls', num_401_calls + 1)\n+        self.num_401_calls = 1\n         return r\n \n     def __call__(self, r):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#b83131779c701720a9ae9efae78996277d416269", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 569 | Contributors (this commit): 11 | Commits (past 90d): 4 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -42,8 +42,8 @@ is at <http://python-requests.org>.\n \"\"\"\n \n __title__ = 'requests'\n-__version__ = '2.5.0'\n-__build__ = 0x020500\n+__version__ = '2.5.1'\n+__build__ = 0x020501\n __author__ = 'Kenneth Reitz'\n __license__ = 'Apache 2.0'\n __copyright__ = 'Copyright 2014 Kenneth Reitz'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#f4ec3d2309c681777211c5aba8c9fe3144f21ae2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 47 | Lines Deleted: 39 | Files Changed: 1 | Hunks: 17 | Methods Changed: 13 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 86 | Churn Cumulative: 907 | Contributors (this commit): 18 | Commits (past 90d): 1 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -157,26 +157,28 @@ class CookieConflictError(RuntimeError):\n \n \n class RequestsCookieJar(cookielib.CookieJar, collections.MutableMapping):\n-    \"\"\"Compatibility class; is a cookielib.CookieJar, but exposes a dict interface.\n+    \"\"\"Compatibility class; is a cookielib.CookieJar, but exposes a dict\n+    interface.\n \n     This is the CookieJar we create by default for requests and sessions that\n     don't specify one, since some clients may expect response.cookies and\n     session.cookies to support dict operations.\n \n-    Don't use the dict interface internally; it's just for compatibility with\n-    with external client code. All `requests` code should work out of the box\n-    with externally provided instances of CookieJar, e.g., LWPCookieJar and\n-    FileCookieJar.\n-\n-    Caution: dictionary operations that are normally O(1) may be O(n).\n+    Requests does not use the dict interface internally; it's just for\n+    compatibility with external client code. All `requests` code should work\n+    out of the box with externally provided instances of ``CookieJar``, e.g.\n+    ``LWPCookieJar`` and ``FileCookieJar``.\n \n     Unlike a regular CookieJar, this class is pickleable.\n-    \"\"\"\n \n+    .. warning:: dictionary operations that are normally O(1) may be O(n).\n+    \"\"\"\n     def get(self, name, default=None, domain=None, path=None):\n         \"\"\"Dict-like get() that also supports optional domain and path args in\n         order to resolve naming collisions from using one cookie jar over\n-        multiple domains. Caution: operation is O(n), not O(1).\"\"\"\n+        multiple domains.\n+\n+        .. warning:: operation is O(n), not O(1).\"\"\"\n         try:\n             return self._find_no_duplicates(name, domain, path)\n         except KeyError:\n@@ -199,37 +201,38 @@ class RequestsCookieJar(cookielib.CookieJar, collections.MutableMapping):\n         return c\n \n     def iterkeys(self):\n-        \"\"\"Dict-like iterkeys() that returns an iterator of names of cookies from the jar.\n-        See itervalues() and iteritems().\"\"\"\n+        \"\"\"Dict-like iterkeys() that returns an iterator of names of cookies\n+        from the jar. See itervalues() and iteritems().\"\"\"\n         for cookie in iter(self):\n             yield cookie.name\n \n     def keys(self):\n-        \"\"\"Dict-like keys() that returns a list of names of cookies from the jar.\n-        See values() and items().\"\"\"\n+        \"\"\"Dict-like keys() that returns a list of names of cookies from the\n+        jar. See values() and items().\"\"\"\n         return list(self.iterkeys())\n \n     def itervalues(self):\n-        \"\"\"Dict-like itervalues() that returns an iterator of values of cookies from the jar.\n-        See iterkeys() and iteritems().\"\"\"\n+        \"\"\"Dict-like itervalues() that returns an iterator of values of cookies\n+        from the jar. See iterkeys() and iteritems().\"\"\"\n         for cookie in iter(self):\n             yield cookie.value\n \n     def values(self):\n-        \"\"\"Dict-like values() that returns a list of values of cookies from the jar.\n-        See keys() and items().\"\"\"\n+        \"\"\"Dict-like values() that returns a list of values of cookies from the\n+        jar. See keys() and items().\"\"\"\n         return list(self.itervalues())\n \n     def iteritems(self):\n-        \"\"\"Dict-like iteritems() that returns an iterator of name-value tuples from the jar.\n-        See iterkeys() and itervalues().\"\"\"\n+        \"\"\"Dict-like iteritems() that returns an iterator of name-value tuples\n+        from the jar. See iterkeys() and itervalues().\"\"\"\n         for cookie in iter(self):\n             yield cookie.name, cookie.value\n \n     def items(self):\n-        \"\"\"Dict-like items() that returns a list of name-value tuples from the jar.\n-        See keys() and values(). Allows client-code to call \"dict(RequestsCookieJar)\n-        and get a vanilla python dict of key value pairs.\"\"\"\n+        \"\"\"Dict-like items() that returns a list of name-value tuples from the\n+        jar. See keys() and values(). Allows client-code to call\n+        ``dict(RequestsCookieJar)`` and get a vanilla python dict of key value\n+        pairs.\"\"\"\n         return list(self.iteritems())\n \n     def list_domains(self):\n@@ -259,8 +262,9 @@ class RequestsCookieJar(cookielib.CookieJar, collections.MutableMapping):\n         return False  # there is only one domain in jar\n \n     def get_dict(self, domain=None, path=None):\n-        \"\"\"Takes as an argument an optional domain and path and returns a plain old\n-        Python dict of name-value pairs of cookies that meet the requirements.\"\"\"\n+        \"\"\"Takes as an argument an optional domain and path and returns a plain\n+        old Python dict of name-value pairs of cookies that meet the\n+        requirements.\"\"\"\n         dictionary = {}\n         for cookie in iter(self):\n             if (domain is None or cookie.domain == domain) and (path is None\n@@ -269,21 +273,23 @@ class RequestsCookieJar(cookielib.CookieJar, collections.MutableMapping):\n         return dictionary\n \n     def __getitem__(self, name):\n-        \"\"\"Dict-like __getitem__() for compatibility with client code. Throws exception\n-        if there are more than one cookie with name. In that case, use the more\n-        explicit get() method instead. Caution: operation is O(n), not O(1).\"\"\"\n+        \"\"\"Dict-like __getitem__() for compatibility with client code. Throws\n+        exception if there are more than one cookie with name. In that case,\n+        use the more explicit get() method instead. Caution: operation is O(n),\n+        not O(1).\"\"\"\n \n         return self._find_no_duplicates(name)\n \n     def __setitem__(self, name, value):\n-        \"\"\"Dict-like __setitem__ for compatibility with client code. Throws exception\n-        if there is already a cookie of that name in the jar. In that case, use the more\n-        explicit set() method instead.\"\"\"\n+        \"\"\"Dict-like __setitem__ for compatibility with client code. Throws\n+        exception if there is already a cookie of that name in the jar. In that\n+        case, use the more explicit set() method instead.\"\"\"\n \n         self.set(name, value)\n \n     def __delitem__(self, name):\n-        \"\"\"Deletes a cookie given a name. Wraps cookielib.CookieJar's remove_cookie_by_name().\"\"\"\n+        \"\"\"Deletes a cookie given a name. Wraps ``cookielib.CookieJar``'s\n+        ``remove_cookie_by_name()``.\"\"\"\n         remove_cookie_by_name(self, name)\n \n     def set_cookie(self, cookie, *args, **kwargs):\n@@ -300,10 +306,11 @@ class RequestsCookieJar(cookielib.CookieJar, collections.MutableMapping):\n             super(RequestsCookieJar, self).update(other)\n \n     def _find(self, name, domain=None, path=None):\n-        \"\"\"Requests uses this method internally to get cookie values. Takes as args name\n-        and optional domain and path. Returns a cookie.value. If there are conflicting cookies,\n-        _find arbitrarily chooses one. See _find_no_duplicates if you want an exception thrown\n-        if there are conflicting cookies.\"\"\"\n+        \"\"\"Requests uses this method internally to get cookie values. Takes as\n+        args name and optional domain and path. Returns a cookie.value. If\n+        there are conflicting cookies, _find arbitrarily chooses one. See\n+        _find_no_duplicates if you want an exception thrown if there are\n+        conflicting cookies.\"\"\"\n         for cookie in iter(self):\n             if cookie.name == name:\n                 if domain is None or cookie.domain == domain:\n@@ -313,10 +320,11 @@ class RequestsCookieJar(cookielib.CookieJar, collections.MutableMapping):\n         raise KeyError('name=%r, domain=%r, path=%r' % (name, domain, path))\n \n     def _find_no_duplicates(self, name, domain=None, path=None):\n-        \"\"\"__get_item__ and get call _find_no_duplicates -- never used in Requests internally.\n-        Takes as args name and optional domain and path. Returns a cookie.value.\n-        Throws KeyError if cookie is not found and CookieConflictError if there are\n-        multiple cookies that match name and optionally domain and path.\"\"\"\n+        \"\"\"__get_item__ and get call _find_no_duplicates -- never used in\n+        Requests internally. Takes as args name and optional domain and path.\n+        Returns a cookie.value. Throws KeyError if cookie is not found and\n+        CookieConflictError if there are multiple cookies that match name and\n+        optionally domain and path.\"\"\"\n         toReturn = None\n         for cookie in iter(self):\n             if cookie.name == name:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#101425ebfc747d4c0173fc42e64654c6bcb45fe1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 924 | Contributors (this commit): 18 | Commits (past 90d): 2 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -165,7 +165,7 @@ class RequestsCookieJar(cookielib.CookieJar, collections.MutableMapping):\n     session.cookies to support dict operations.\n \n     Requests does not use the dict interface internally; it's just for\n-    compatibility with external client code. All `requests` code should work\n+    compatibility with external client code. All requests code should work\n     out of the box with externally provided instances of ``CookieJar``, e.g.\n     ``LWPCookieJar`` and ``FileCookieJar``.\n \n@@ -275,8 +275,9 @@ class RequestsCookieJar(cookielib.CookieJar, collections.MutableMapping):\n     def __getitem__(self, name):\n         \"\"\"Dict-like __getitem__() for compatibility with client code. Throws\n         exception if there are more than one cookie with name. In that case,\n-        use the more explicit get() method instead. Caution: operation is O(n),\n-        not O(1).\"\"\"\n+        use the more explicit get() method instead.\n+\n+        .. warning:: operation is O(n), not O(1).\"\"\"\n \n         return self._find_no_duplicates(name)\n \n@@ -320,11 +321,11 @@ class RequestsCookieJar(cookielib.CookieJar, collections.MutableMapping):\n         raise KeyError('name=%r, domain=%r, path=%r' % (name, domain, path))\n \n     def _find_no_duplicates(self, name, domain=None, path=None):\n-        \"\"\"__get_item__ and get call _find_no_duplicates -- never used in\n-        Requests internally. Takes as args name and optional domain and path.\n-        Returns a cookie.value. Throws KeyError if cookie is not found and\n-        CookieConflictError if there are multiple cookies that match name and\n-        optionally domain and path.\"\"\"\n+        \"\"\"Both ``__get_item__`` and ``get`` call this function: it's never\n+        used elsewhere in Requests. Takes as args name and optional domain and\n+        path. Returns a cookie.value. Throws KeyError if cookie is not found\n+        and CookieConflictError if there are multiple cookies that match name\n+        and optionally domain and path.\"\"\"\n         toReturn = None\n         for cookie in iter(self):\n             if cookie.name == name:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#892f2560c1fc99260a8cb073478c0c6e7245bd93", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 861 | Contributors (this commit): 14 | Commits (past 90d): 6 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -46,7 +46,7 @@ master_doc = 'index'\n \n # General information about the project.\n project = u'Requests'\n-copyright = u'2014. A <a href=\"http://kennethreitz.com/pages/open-projects.html\">Kenneth Reitz</a> Project'\n+copyright = u'2015. A <a href=\"http://kennethreitz.com/pages/open-projects.html\">Kenneth Reitz</a> Project'\n \n # The version info for the project you're documenting, acts as replacement for\n # |version| and |release|, also used in various other places throughout the\n\n@@ -36,7 +36,7 @@ usage:\n The other HTTP methods are supported - see `requests.api`. Full documentation\n is at <http://python-requests.org>.\n \n-:copyright: (c) 2014 by Kenneth Reitz.\n+:copyright: (c) 2015 by Kenneth Reitz.\n :license: Apache 2.0, see LICENSE for more details.\n \n \"\"\"\n@@ -46,7 +46,7 @@ __version__ = '2.5.1'\n __build__ = 0x020501\n __author__ = 'Kenneth Reitz'\n __license__ = 'Apache 2.0'\n-__copyright__ = 'Copyright 2014 Kenneth Reitz'\n+__copyright__ = 'Copyright 2015 Kenneth Reitz'\n \n # Attempt to enable urllib3's SNI support, if possible\n try:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#d2d576b6b1101e2871c82f63adf2c2b534c2dabc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 8 | Files Changed: 4 | Hunks: 10 | Methods Changed: 5 | Complexity Δ (Sum/Max): 5/3 | Churn Δ: 34 | Churn Cumulative: 4495 | Contributors (this commit): 15 | Commits (past 90d): 11 | Contributors (cumulative): 31 | DMM Complexity: 1.0\n\nDIFF:\n@@ -55,7 +55,7 @@ def add_stderr_logger(level=logging.DEBUG):\n del NullHandler\n \n \n-# Set security warning to only go off once by default.\n+# Set security warning to always go off by default.\n import warnings\n warnings.simplefilter('always', exceptions.SecurityWarning)\n \n\n@@ -266,6 +266,10 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n         \"\"\"\n         pass\n \n+    def _prepare_proxy(self, conn):\n+        # Nothing to do for HTTP connections.\n+        pass\n+\n     def _get_timeout(self, timeout):\n         \"\"\" Helper that always returns a :class:`urllib3.util.Timeout` \"\"\"\n         if timeout is _Default:\n@@ -510,11 +514,18 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n \n         try:\n             # Request a connection from the queue.\n+            timeout_obj = self._get_timeout(timeout)\n             conn = self._get_conn(timeout=pool_timeout)\n \n+            conn.timeout = timeout_obj.connect_timeout\n+\n+            is_new_proxy_conn = self.proxy is not None and not getattr(conn, 'sock', None)\n+            if is_new_proxy_conn:\n+                self._prepare_proxy(conn)\n+\n             # Make the request on the httplib connection object.\n             httplib_response = self._make_request(conn, method, url,\n-                                                  timeout=timeout,\n+                                                  timeout=timeout_obj,\n                                                   body=body, headers=headers)\n \n             # If we're going to release the connection in ``finally:``, then\n@@ -673,7 +684,13 @@ class HTTPSConnectionPool(HTTPConnectionPool):\n                           assert_fingerprint=self.assert_fingerprint)\n             conn.ssl_version = self.ssl_version\n \n-        if self.proxy is not None:\n+        return conn\n+\n+    def _prepare_proxy(self, conn):\n+        \"\"\"\n+        Establish tunnel connection early, because otherwise httplib\n+        would improperly set Host: header to proxy's IP:port.\n+        \"\"\"\n         # Python 2.7+\n         try:\n             set_tunnel = conn.set_tunnel\n@@ -685,12 +702,8 @@ class HTTPSConnectionPool(HTTPConnectionPool):\n         else:\n             set_tunnel(self.host, self.port, self.proxy_headers)\n \n-            # Establish tunnel connection early, because otherwise httplib\n-            # would improperly set Host: header to proxy's IP:port.\n         conn.connect()\n \n-        return conn\n-\n     def _new_conn(self):\n         \"\"\"\n         Return a fresh :class:`httplib.HTTPSConnection`.\n\n@@ -191,6 +191,11 @@ class WrappedSocket(object):\n                 return b''\n             else:\n                 raise\n+        except OpenSSL.SSL.ZeroReturnError as e:\n+            if self.connection.get_shutdown() == OpenSSL.SSL.RECEIVED_SHUTDOWN:\n+                return b''\n+            else:\n+                raise\n         except OpenSSL.SSL.WantReadError:\n             rd, wd, ed = select.select(\n                 [self.socket], [], [], self.socket.gettimeout())\n\n@@ -190,7 +190,7 @@ class Retry(object):\n         return isinstance(err, (ReadTimeoutError, ProtocolError))\n \n     def is_forced_retry(self, method, status_code):\n-        \"\"\" Is this method/response retryable? (Based on method/codes whitelists)\n+        \"\"\" Is this method/status code retryable? (Based on method/codes whitelists)\n         \"\"\"\n         if self.method_whitelist and method.upper() not in self.method_whitelist:\n             return False\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#751b35c346e1cf373fcf4b2f19683ebfbd9dae3d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 30 | Churn Cumulative: 7142 | Contributors (this commit): 124 | Commits (past 90d): 18 | Contributors (cumulative): 143 | DMM Complexity: 1.0\n\nDIFF:\n@@ -418,10 +418,18 @@ def requote_uri(uri):\n     This function passes the given URI through an unquote/quote cycle to\n     ensure that it is fully and consistently quoted.\n     \"\"\"\n+    safe_with_percent = \"!#$%&'()*+,/:;=?@[]~\"\n+    safe_without_percent = \"!#$&'()*+,/:;=?@[]~\"\n+    try:\n         # Unquote only the unreserved characters\n-    # Then quote only illegal characters (do not quote reserved, unreserved,\n-    # or '%')\n-    return quote(unquote_unreserved(uri), safe=\"!#$%&'()*+,/:;=?@[]~\")\n+        # Then quote only illegal characters (do not quote reserved,\n+        # unreserved, or '%')\n+        return quote(unquote_unreserved(uri), safe=safe_with_percent)\n+    except InvalidURL:\n+        # We couldn't unquote the given URI, so let's try quoting it, but\n+        # there may be unquoted '%'s in the URI. We need to make sure they're\n+        # properly quoted so they do not cause issues elsewhere.\n+        return quote(uri, safe=safe_without_percent)\n \n \n def address_in_network(ip, net):\n\n@@ -1301,6 +1301,22 @@ class UtilsTestCase(unittest.TestCase):\n         assert username == percent_encoding_test_chars\n         assert password == percent_encoding_test_chars\n \n+    def test_requote_uri_with_unquoted_percents(self):\n+        \"\"\"Ensure we handle unquoted percent signs in redirects.\n+\n+        See: https://github.com/kennethreitz/requests/issues/2356\n+        \"\"\"\n+        from requests.utils import requote_uri\n+        bad_uri = 'http://example.com/fiz?buz=%ppicture'\n+        quoted = 'http://example.com/fiz?buz=%25ppicture'\n+        assert quoted == requote_uri(bad_uri)\n+\n+    def test_requote_uri_properly_requotes(self):\n+        \"\"\"Ensure requoting doesn't break expectations.\"\"\"\n+        from requests.utils import requote_uri\n+        quoted = 'http://example.com/fiz?buz=%25ppicture'\n+        assert quoted == requote_uri(quoted)\n+\n \n class TestMorselToCookieExpires(unittest.TestCase):\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#f37fe551bbbf6ac8d07c35c64888b4ab289c967d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 52 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 52 | Churn Cumulative: 221 | Contributors (this commit): 16 | Commits (past 90d): 2 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -21,58 +21,6 @@ is_py2 = (_ver[0] == 2)\n #: Python 3.x?\n is_py3 = (_ver[0] == 3)\n \n-#: Python 3.0.x\n-is_py30 = (is_py3 and _ver[1] == 0)\n-\n-#: Python 3.1.x\n-is_py31 = (is_py3 and _ver[1] == 1)\n-\n-#: Python 3.2.x\n-is_py32 = (is_py3 and _ver[1] == 2)\n-\n-#: Python 3.3.x\n-is_py33 = (is_py3 and _ver[1] == 3)\n-\n-#: Python 3.4.x\n-is_py34 = (is_py3 and _ver[1] == 4)\n-\n-#: Python 2.7.x\n-is_py27 = (is_py2 and _ver[1] == 7)\n-\n-#: Python 2.6.x\n-is_py26 = (is_py2 and _ver[1] == 6)\n-\n-#: Python 2.5.x\n-is_py25 = (is_py2 and _ver[1] == 5)\n-\n-#: Python 2.4.x\n-is_py24 = (is_py2 and _ver[1] == 4)   # I'm assuming this is not by choice.\n-\n-\n-# ---------\n-# Platforms\n-# ---------\n-\n-\n-# Syntax sugar.\n-_ver = sys.version.lower()\n-\n-is_pypy = ('pypy' in _ver)\n-is_jython = ('jython' in _ver)\n-is_ironpython = ('iron' in _ver)\n-\n-# Assume CPython, if nothing else.\n-is_cpython = not any((is_pypy, is_jython, is_ironpython))\n-\n-# Windows-based system.\n-is_windows = 'win32' in str(sys.platform).lower()\n-\n-# Standard Linux 2+ system.\n-is_linux = ('linux' in str(sys.platform).lower())\n-is_osx = ('darwin' in str(sys.platform).lower())\n-is_hpux = ('hpux' in str(sys.platform).lower())   # Complete guess.\n-is_solaris = ('solar==' in str(sys.platform).lower())   # Complete guess.\n-\n try:\n     import simplejson as json\n except (ImportError, SyntaxError):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#677bbe30d7b26b006d8b38107e1db9cbd429ac2f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1271 | Contributors (this commit): 32 | Commits (past 90d): 4 | Contributors (cumulative): 32 | DMM Complexity: 0.0\n\nDIFF:\n@@ -124,13 +124,15 @@ class HTTPDigestAuth(AuthBase):\n         s += os.urandom(8)\n \n         cnonce = (hashlib.sha1(s).hexdigest()[:16])\n-        noncebit = \"%s:%s:%s:%s:%s\" % (nonce, ncvalue, cnonce, qop, HA2)\n         if _algorithm == 'MD5-SESS':\n             HA1 = hash_utf8('%s:%s:%s' % (HA1, nonce, cnonce))\n \n         if qop is None:\n             respdig = KD(HA1, \"%s:%s\" % (nonce, HA2))\n         elif qop == 'auth' or 'auth' in qop.split(','):\n+            noncebit = \"%s:%s:%s:%s:%s\" % (\n+                nonce, ncvalue, cnonce, 'auth', HA2\n+                )\n             respdig = KD(HA1, noncebit)\n         else:\n             # XXX handle auth-int.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#eec44dbbb1a0ce0427bf5151aa32ad5fcd1898e5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 4 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/2 | Churn Δ: 33 | Churn Cumulative: 7396 | Contributors (this commit): 129 | Commits (past 90d): 18 | Contributors (cumulative): 159 | DMM Complexity: 1.0\n\nDIFF:\n@@ -99,7 +99,6 @@ if is_py2:\n     basestring = basestring\n     numeric_types = (int, long, float)\n \n-\n elif is_py3:\n     from urllib.parse import urlparse, urlunparse, urljoin, urlsplit, urlencode, quote, unquote, quote_plus, unquote_plus, urldefrag\n     from urllib.request import parse_http_list, getproxies, proxy_bypass\n\n@@ -25,7 +25,8 @@ from . import __version__\n from . import certs\n from .compat import parse_http_list as _parse_list_header\n from .compat import (quote, urlparse, bytes, str, OrderedDict, unquote, is_py2,\n-                     builtin_str, getproxies, proxy_bypass, urlunparse)\n+                     builtin_str, getproxies, proxy_bypass, urlunparse,\n+                     basestring)\n from .cookies import RequestsCookieJar, cookiejar_from_dict\n from .structures import CaseInsensitiveDict\n from .exceptions import InvalidURL\n@@ -115,7 +116,8 @@ def get_netrc_auth(url):\n def guess_filename(obj):\n     \"\"\"Tries to guess the filename of the given object.\"\"\"\n     name = getattr(obj, 'name', None)\n-    if name and isinstance(name, builtin_str) and name[0] != '<' and name[-1] != '>':\n+    if (name and isinstance(name, basestring) and name[0] != '<' and\n+            name[-1] != '>'):\n         return os.path.basename(name)\n \n \n\n@@ -1265,6 +1265,32 @@ class UtilsTestCase(unittest.TestCase):\n             'http://localhost.localdomain:5000/v1.0/') == {}\n         assert get_environ_proxies('http://www.requests.com/') != {}\n \n+    def test_guess_filename_when_int(self):\n+        from requests.utils import guess_filename\n+        assert None is guess_filename(1)\n+\n+    def test_guess_filename_when_filename_is_an_int(self):\n+        from requests.utils import guess_filename\n+        fake = type('Fake', (object,), {'name': 1})()\n+        assert None is guess_filename(fake)\n+\n+    def test_guess_filename_with_file_like_obj(self):\n+        from requests.utils import guess_filename\n+        from requests import compat\n+        fake = type('Fake', (object,), {'name': b'value'})()\n+        guessed_name = guess_filename(fake)\n+        assert b'value' == guessed_name\n+        assert isinstance(guessed_name, compat.bytes)\n+\n+    def test_guess_filename_with_unicode_name(self):\n+        from requests.utils import guess_filename\n+        from requests import compat\n+        filename = b'value'.decode('utf-8')\n+        fake = type('Fake', (object,), {'name': filename})()\n+        guessed_name = guess_filename(fake)\n+        assert filename == guessed_name\n+        assert isinstance(guessed_name, compat.str)\n+\n     def test_is_ipv4_address(self):\n         from requests.utils import is_ipv4_address\n         assert is_ipv4_address('8.8.8.8')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#fb1971778f0a199e65193af4bbd0a040fd3808f8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 1274 | Contributors (this commit): 33 | Commits (past 90d): 4 | Contributors (cumulative): 33 | DMM Complexity: None\n\nDIFF:\n@@ -103,7 +103,8 @@ class HTTPDigestAuth(AuthBase):\n         # XXX not implemented yet\n         entdig = None\n         p_parsed = urlparse(url)\n-        path = p_parsed.path\n+        #: path is request-uri defined in RFC 2616 which should not be empty\n+        path = p_parsed.path or \"/\"\n         if p_parsed.query:\n             path += '?' + p_parsed.query\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#ced6550a2555002f6c081d75547f30fd3fc5e29c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 6 | Churn Cumulative: 4949 | Contributors (this commit): 90 | Commits (past 90d): 9 | Contributors (cumulative): 90 | DMM Complexity: 1.0\n\nDIFF:\n@@ -301,11 +301,13 @@ class RequestsTestCase(unittest.TestCase):\n         r = s.get(url)\n         assert r.status_code == 200\n \n-    def test_connection_error(self):\n+    def test_connection_error_invalid_domain(self):\n         \"\"\"Connecting to an unknown domain should raise a ConnectionError\"\"\"\n         with pytest.raises(ConnectionError):\n-            requests.get(\"http://fooobarbangbazbing.httpbin.org\")\n+            requests.get(\"http://doesnotexist.google.com\")\n \n+    def test_connection_error_invalid_port(self):\n+        \"\"\"Connecting to an invalid port should raise a ConnectionError\"\"\"\n         with pytest.raises(ConnectionError):\n             requests.get(\"http://httpbin.org:1\")\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#80aee7a2252f15d6790f15e1d98d59885e9c7e7b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 4951 | Contributors (this commit): 90 | Commits (past 90d): 10 | Contributors (cumulative): 90 | DMM Complexity: None\n\nDIFF:\n@@ -309,7 +309,7 @@ class RequestsTestCase(unittest.TestCase):\n     def test_connection_error_invalid_port(self):\n         \"\"\"Connecting to an invalid port should raise a ConnectionError\"\"\"\n         with pytest.raises(ConnectionError):\n-            requests.get(\"http://httpbin.org:1\")\n+            requests.get(\"http://httpbin.org:1\", timeout=1)\n \n     def test_LocationParseError(self):\n         \"\"\"Inputing a URL that cannot be parsed should raise an InvalidURL error\"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#62df872871049f1911bbcfee194d603e9704613e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 76 | Lines Deleted: 8 | Files Changed: 5 | Hunks: 17 | Methods Changed: 17 | Complexity Δ (Sum/Max): 19/9 | Churn Δ: 84 | Churn Cumulative: 5666 | Contributors (this commit): 18 | Commits (past 90d): 9 | Contributors (cumulative): 47 | DMM Complexity: 0.40476190476190477\n\nDIFF:\n@@ -161,7 +161,7 @@ class HTTPHeaderDict(MutableMapping):\n     def getlist(self, key):\n         \"\"\"Returns a list of all the values for the named field. Returns an\n         empty list if the key doesn't exist.\"\"\"\n-        return self[key].split(', ') if key in self else []\n+        return [v for k, v in self._data.get(key.lower(), [])]\n \n     def copy(self):\n         h = HTTPHeaderDict()\n@@ -196,3 +196,11 @@ class HTTPHeaderDict(MutableMapping):\n \n     def __repr__(self):\n         return '%s(%r)' % (self.__class__.__name__, dict(self.items()))\n+\n+    def update(self, *args, **kwds):\n+        headers = args[0]\n+        if isinstance(headers, HTTPHeaderDict):\n+            for key in iterkeys(headers._data):\n+                self._data.setdefault(key.lower(), []).extend(headers._data[key])\n+        else:\n+            super(HTTPHeaderDict, self).update(*args, **kwds)\n\n@@ -72,6 +72,21 @@ class ConnectionPool(object):\n         return '%s(host=%r, port=%r)' % (type(self).__name__,\n                                          self.host, self.port)\n \n+    def __enter__(self):\n+        return self\n+\n+    def __exit__(self, exc_type, exc_val, exc_tb):\n+        self.close()\n+        # Return False to re-raise any potential exceptions\n+        return False\n+\n+    def close():\n+        \"\"\"\n+        Close all pooled connections and disable the pool.\n+        \"\"\"\n+        pass\n+\n+\n # This is taken from http://hg.python.org/cpython/file/7aaba721ebc0/Lib/socket.py#l252\n _blocking_errnos = set([errno.EAGAIN, errno.EWOULDBLOCK])\n \n@@ -353,7 +368,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n \n         # Receive the response from the server\n         try:\n-            try:  # Python 2.7+, use buffering of HTTP responses\n+            try:  # Python 2.7, use buffering of HTTP responses\n                 httplib_response = conn.getresponse(buffering=True)\n             except TypeError:  # Python 2.6 and older\n                 httplib_response = conn.getresponse()\n@@ -558,6 +573,14 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n                 conn = None\n             raise SSLError(e)\n \n+        except SSLError:\n+            # Treat SSLError separately from BaseSSLError to preserve\n+            # traceback.\n+            if conn:\n+                conn.close()\n+                conn = None\n+            raise\n+\n         except (TimeoutError, HTTPException, SocketError, ConnectionError) as e:\n             if conn:\n                 # Discard the connection for these exceptions. It will be\n\n@@ -64,6 +64,14 @@ class PoolManager(RequestMethods):\n         self.pools = RecentlyUsedContainer(num_pools,\n                                            dispose_func=lambda p: p.close())\n \n+    def __enter__(self):\n+        return self\n+\n+    def __exit__(self, exc_type, exc_val, exc_tb):\n+        self.clear()\n+        # Return False to re-raise any potential exceptions\n+        return False\n+\n     def _new_pool(self, scheme, host, port):\n         \"\"\"\n         Create a new :class:`ConnectionPool` based on host, port and scheme.\n\n@@ -2,6 +2,7 @@ import zlib\n import io\n from socket import timeout as SocketTimeout\n \n+from .packages import six\n from ._collections import HTTPHeaderDict\n from .exceptions import ProtocolError, DecodeError, ReadTimeoutError\n from .packages.six import string_types as basestring, binary_type\n@@ -9,7 +10,6 @@ from .connection import HTTPException, BaseSSLError\n from .util.response import is_fp_closed\n \n \n-\n class DeflateDecoder(object):\n \n     def __init__(self):\n@@ -21,6 +21,9 @@ class DeflateDecoder(object):\n         return getattr(self._obj, name)\n \n     def decompress(self, data):\n+        if not data:\n+            return data\n+\n         if not self._first_try:\n             return self._obj.decompress(data)\n \n@@ -36,9 +39,23 @@ class DeflateDecoder(object):\n                 self._data = None\n \n \n+class GzipDecoder(object):\n+\n+    def __init__(self):\n+        self._obj = zlib.decompressobj(16 + zlib.MAX_WBITS)\n+\n+    def __getattr__(self, name):\n+        return getattr(self._obj, name)\n+\n+    def decompress(self, data):\n+        if not data:\n+            return data\n+        return self._obj.decompress(data)\n+\n+\n def _get_decoder(mode):\n     if mode == 'gzip':\n-        return zlib.decompressobj(16 + zlib.MAX_WBITS)\n+        return GzipDecoder()\n \n     return DeflateDecoder()\n \n@@ -202,7 +219,7 @@ class HTTPResponse(io.IOBase):\n \n             except BaseSSLError as e:\n                 # FIXME: Is there a better way to differentiate between SSLErrors?\n-                if not 'read operation timed out' in str(e):  # Defensive:\n+                if 'read operation timed out' not in str(e):  # Defensive:\n                     # This shouldn't happen but just in case we're missing an edge\n                     # case, let's avoid swallowing SSL errors.\n                     raise\n@@ -270,8 +287,17 @@ class HTTPResponse(io.IOBase):\n \n         headers = HTTPHeaderDict()\n         for k, v in r.getheaders():\n+            if k.lower() != 'set-cookie':\n                 headers.add(k, v)\n \n+        if six.PY3:  # Python 3:\n+            cookies = r.msg.get_all('set-cookie') or tuple()\n+        else:  # Python 2:\n+            cookies = r.msg.getheaders('set-cookie')\n+\n+        for cookie in cookies:\n+            headers.add('set-cookie', cookie)\n+\n         # HTTPResponse objects in Python 3 don't have a .strict attribute\n         strict = getattr(r, 'strict', 0)\n         return ResponseCls(body=r,\n\n@@ -1,5 +1,5 @@\n from binascii import hexlify, unhexlify\n-from hashlib import md5, sha1\n+from hashlib import md5, sha1, sha256\n \n from ..exceptions import SSLError\n \n@@ -96,7 +96,8 @@ def assert_fingerprint(cert, fingerprint):\n     # this digest.\n     hashfunc_map = {\n         16: md5,\n-        20: sha1\n+        20: sha1,\n+        32: sha256,\n     }\n \n     fingerprint = fingerprint.replace(':', '').lower()\n@@ -211,7 +212,9 @@ def create_urllib3_context(ssl_version=None, cert_reqs=ssl.CERT_REQUIRED,\n \n     context.verify_mode = cert_reqs\n     if getattr(context, 'check_hostname', None) is not None:  # Platform-specific: Python 3.2\n-        context.check_hostname = (context.verify_mode == ssl.CERT_REQUIRED)\n+        # We do our own verification, including fingerprints and alternative\n+        # hostnames. So disable it here\n+        context.check_hostname = False\n     return context\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#58e513579a0934dbd737077f3069c04d68cf1a52", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 197 | Lines Deleted: 83 | Files Changed: 6 | Hunks: 23 | Methods Changed: 28 | Complexity Δ (Sum/Max): 25/26 | Churn Δ: 280 | Churn Cumulative: 6049 | Contributors (this commit): 18 | Commits (past 90d): 15 | Contributors (cumulative): 49 | DMM Complexity: 0.8285714285714286\n\nDIFF:\n@@ -14,12 +14,14 @@ try:  # Python 2.7+\n     from collections import OrderedDict\n except ImportError:\n     from .packages.ordered_dict import OrderedDict\n-from .packages.six import iterkeys, itervalues\n+from .packages.six import iterkeys, itervalues, PY3\n \n \n __all__ = ['RecentlyUsedContainer', 'HTTPHeaderDict']\n \n \n+MULTIPLE_HEADERS_ALLOWED = frozenset(['cookie', 'set-cookie', 'set-cookie2'])\n+\n _Null = object()\n \n \n@@ -97,7 +99,14 @@ class RecentlyUsedContainer(MutableMapping):\n             return list(iterkeys(self._container))\n \n \n-class HTTPHeaderDict(MutableMapping):\n+_dict_setitem = dict.__setitem__\n+_dict_getitem = dict.__getitem__\n+_dict_delitem = dict.__delitem__\n+_dict_contains = dict.__contains__\n+_dict_setdefault = dict.setdefault\n+\n+\n+class HTTPHeaderDict(dict):\n     \"\"\"\n     :param headers:\n         An iterable of field-value pairs. Must not contain multiple field names\n@@ -129,25 +138,72 @@ class HTTPHeaderDict(MutableMapping):\n     'foo=bar, baz=quxx'\n     >>> headers['Content-Length']\n     '7'\n-\n-    If you want to access the raw headers with their original casing\n-    for debugging purposes you can access the private ``._data`` attribute\n-    which is a normal python ``dict`` that maps the case-insensitive key to a\n-    list of tuples stored as (case-sensitive-original-name, value). Using the\n-    structure from above as our example:\n-\n-    >>> headers._data\n-    {'set-cookie': [('Set-Cookie', 'foo=bar'), ('set-cookie', 'baz=quxx')],\n-    'content-length': [('content-length', '7')]}\n     \"\"\"\n \n     def __init__(self, headers=None, **kwargs):\n-        self._data = {}\n-        if headers is None:\n-            headers = {}\n-        self.update(headers, **kwargs)\n+        dict.__init__(self)\n+        if headers is not None:\n+            self.extend(headers)\n+        if kwargs:\n+            self.extend(kwargs)\n \n-    def add(self, key, value):\n+    def __setitem__(self, key, val):\n+        return _dict_setitem(self, key.lower(), (key, val))\n+\n+    def __getitem__(self, key):\n+        val = _dict_getitem(self, key.lower())\n+        return ', '.join(val[1:])\n+\n+    def __delitem__(self, key):\n+        return _dict_delitem(self, key.lower())\n+\n+    def __contains__(self, key):\n+        return _dict_contains(self, key.lower())\n+\n+    def __eq__(self, other):\n+        if not isinstance(other, Mapping) and not hasattr(other, 'keys'):\n+            return False\n+        if not isinstance(other, type(self)):\n+            other = type(self)(other)\n+        return dict((k1, self[k1]) for k1 in self) == dict((k2, other[k2]) for k2 in other)\n+\n+    def __ne__(self, other):\n+        return not self.__eq__(other)\n+\n+    values = MutableMapping.values\n+    get = MutableMapping.get\n+    update = MutableMapping.update\n+    \n+    if not PY3: # Python 2\n+        iterkeys = MutableMapping.iterkeys\n+        itervalues = MutableMapping.itervalues\n+\n+    __marker = object()\n+\n+    def pop(self, key, default=__marker):\n+        '''D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n+          If key is not found, d is returned if given, otherwise KeyError is raised.\n+        '''\n+        # Using the MutableMapping function directly fails due to the private marker.\n+        # Using ordinary dict.pop would expose the internal structures.\n+        # So let's reinvent the wheel.\n+        try:\n+            value = self[key]\n+        except KeyError:\n+            if default is self.__marker:\n+                raise\n+            return default\n+        else:\n+            del self[key]\n+            return value\n+\n+    def discard(self, key):\n+        try:\n+            del self[key]\n+        except KeyError:\n+            pass\n+\n+    def add(self, key, val):\n         \"\"\"Adds a (name, value) pair, doesn't overwrite the value if it already\n         exists.\n \n@@ -156,51 +212,108 @@ class HTTPHeaderDict(MutableMapping):\n         >>> headers['foo']\n         'bar, baz'\n         \"\"\"\n-        self._data.setdefault(key.lower(), []).append((key, value))\n+        key_lower = key.lower()\n+        new_vals = key, val\n+        # Keep the common case aka no item present as fast as possible\n+        vals = _dict_setdefault(self, key_lower, new_vals)\n+        if new_vals is not vals:\n+            # new_vals was not inserted, as there was a previous one\n+            if isinstance(vals, list):\n+                # If already several items got inserted, we have a list\n+                vals.append(val)\n+            else:\n+                # vals should be a tuple then, i.e. only one item so far\n+                if key_lower in MULTIPLE_HEADERS_ALLOWED:\n+                    # Need to convert the tuple to list for further extension\n+                    _dict_setitem(self, key_lower, [vals[0], vals[1], val])\n+                else:\n+                    _dict_setitem(self, key_lower, new_vals)\n+\n+    def extend(*args, **kwargs):\n+        \"\"\"Generic import function for any type of header-like object.\n+        Adapted version of MutableMapping.update in order to insert items\n+        with self.add instead of self.__setitem__\n+        \"\"\"\n+        if len(args) > 2:\n+            raise TypeError(\"update() takes at most 2 positional \"\n+                            \"arguments ({} given)\".format(len(args)))\n+        elif not args:\n+            raise TypeError(\"update() takes at least 1 argument (0 given)\")\n+        self = args[0]\n+        other = args[1] if len(args) >= 2 else ()\n+        \n+        if isinstance(other, Mapping):\n+            for key in other:\n+                self.add(key, other[key])\n+        elif hasattr(other, \"keys\"):\n+            for key in other.keys():\n+                self.add(key, other[key])\n+        else:\n+            for key, value in other:\n+                self.add(key, value)\n+\n+        for key, value in kwargs.items():\n+            self.add(key, value)\n \n     def getlist(self, key):\n         \"\"\"Returns a list of all the values for the named field. Returns an\n         empty list if the key doesn't exist.\"\"\"\n-        return [v for k, v in self._data.get(key.lower(), [])]\n+        try:\n+            vals = _dict_getitem(self, key.lower())\n+        except KeyError:\n+            return []\n+        else:\n+            if isinstance(vals, tuple):\n+                return [vals[1]]\n+            else:\n+                return vals[1:]\n \n-    def copy(self):\n-        h = HTTPHeaderDict()\n-        for key in self._data:\n-            for rawkey, value in self._data[key]:\n-                h.add(rawkey, value)\n-        return h\n-\n-    def __eq__(self, other):\n-        if not isinstance(other, Mapping):\n-            return False\n-        other = HTTPHeaderDict(other)\n-        return dict((k1, self[k1]) for k1 in self._data) == \\\n-                dict((k2, other[k2]) for k2 in other._data)\n-\n-    def __getitem__(self, key):\n-        values = self._data[key.lower()]\n-        return ', '.join(value[1] for value in values)\n-\n-    def __setitem__(self, key, value):\n-        self._data[key.lower()] = [(key, value)]\n-\n-    def __delitem__(self, key):\n-        del self._data[key.lower()]\n-\n-    def __len__(self):\n-        return len(self._data)\n-\n-    def __iter__(self):\n-        for headers in itervalues(self._data):\n-            yield headers[0][0]\n+    # Backwards compatibility for httplib\n+    getheaders = getlist\n+    getallmatchingheaders = getlist\n+    iget = getlist\n \n     def __repr__(self):\n-        return '%s(%r)' % (self.__class__.__name__, dict(self.items()))\n+        return \"%s(%s)\" % (type(self).__name__, dict(self.itermerged()))\n \n-    def update(self, *args, **kwds):\n-        headers = args[0]\n-        if isinstance(headers, HTTPHeaderDict):\n-            for key in iterkeys(headers._data):\n-                self._data.setdefault(key.lower(), []).extend(headers._data[key])\n-        else:\n-            super(HTTPHeaderDict, self).update(*args, **kwds)\n+    def copy(self):\n+        clone = type(self)()\n+        for key in self:\n+            val = _dict_getitem(self, key)\n+            if isinstance(val, list):\n+                # Don't need to convert tuples\n+                val = list(val)\n+            _dict_setitem(clone, key, val)\n+        return clone\n+\n+    def iteritems(self):\n+        \"\"\"Iterate over all header lines, including duplicate ones.\"\"\"\n+        for key in self:\n+            vals = _dict_getitem(self, key)\n+            for val in vals[1:]:\n+                yield vals[0], val\n+\n+    def itermerged(self):\n+        \"\"\"Iterate over all headers, merging duplicate ones together.\"\"\"\n+        for key in self:\n+            val = _dict_getitem(self, key)\n+            yield val[0], ', '.join(val[1:])\n+\n+    def items(self):\n+        return list(self.iteritems())\n+\n+    @classmethod\n+    def from_httplib(cls, message, duplicates=('set-cookie',)): # Python 2\n+        \"\"\"Read headers from a Python 2 httplib message object.\"\"\"\n+        ret = cls(message.items())\n+        # ret now contains only the last header line for each duplicate.\n+        # Importing with all duplicates would be nice, but this would\n+        # mean to repeat most of the raw parsing already done, when the\n+        # message object was created. Extracting only the headers of interest \n+        # separately, the cookies, should be faster and requires less\n+        # extra code.\n+        for key in duplicates:\n+            ret.discard(key)\n+            for val in message.getheaders(key):\n+                ret.add(key, val)\n+            return ret\n\n@@ -588,14 +588,13 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n                 conn.close()\n                 conn = None\n \n-            stacktrace = sys.exc_info()[2]\n             if isinstance(e, SocketError) and self.proxy:\n                 e = ProxyError('Cannot connect to proxy.', e)\n             elif isinstance(e, (SocketError, HTTPException)):\n                 e = ProtocolError('Connection aborted.', e)\n \n-            retries = retries.increment(method, url, error=e,\n-                                        _pool=self, _stacktrace=stacktrace)\n+            retries = retries.increment(method, url, error=e, _pool=self,\n+                                        _stacktrace=sys.exc_info()[2])\n             retries.sleep()\n \n             # Keep track of the error for the retry warning.\n\n@@ -8,7 +8,7 @@ except ImportError:\n from ._collections import RecentlyUsedContainer\n from .connectionpool import HTTPConnectionPool, HTTPSConnectionPool\n from .connectionpool import port_by_scheme\n-from .exceptions import LocationValueError\n+from .exceptions import LocationValueError, MaxRetryError\n from .request import RequestMethods\n from .util.url import parse_url\n from .util.retry import Retry\n@@ -175,7 +175,14 @@ class PoolManager(RequestMethods):\n         if not isinstance(retries, Retry):\n             retries = Retry.from_int(retries, redirect=redirect)\n \n-        kw['retries'] = retries.increment(method, redirect_location)\n+        try:\n+            retries = retries.increment(method, url, response=response, _pool=conn)\n+        except MaxRetryError:\n+            if retries.raise_on_redirect:\n+                raise\n+            return response\n+\n+        kw['retries'] = retries\n         kw['redirect'] = redirect\n \n         log.info(\"Redirecting %s -> %s\" % (url, redirect_location))\n\n@@ -2,10 +2,9 @@ import zlib\n import io\n from socket import timeout as SocketTimeout\n \n-from .packages import six\n from ._collections import HTTPHeaderDict\n from .exceptions import ProtocolError, DecodeError, ReadTimeoutError\n-from .packages.six import string_types as basestring, binary_type\n+from .packages.six import string_types as basestring, binary_type, PY3\n from .connection import HTTPException, BaseSSLError\n from .util.response import is_fp_closed\n \n@@ -93,9 +92,10 @@ class HTTPResponse(io.IOBase):\n                  strict=0, preload_content=True, decode_content=True,\n                  original_response=None, pool=None, connection=None):\n \n-        self.headers = HTTPHeaderDict()\n-        if headers:\n-            self.headers.update(headers)\n+        if isinstance(headers, HTTPHeaderDict):\n+            self.headers = headers\n+        else:\n+            self.headers = HTTPHeaderDict(headers)\n         self.status = status\n         self.version = version\n         self.reason = reason\n@@ -284,23 +284,16 @@ class HTTPResponse(io.IOBase):\n         Remaining parameters are passed to the HTTPResponse constructor, along\n         with ``original_response=r``.\n         \"\"\"\n-\n-        headers = HTTPHeaderDict()\n-        for k, v in r.getheaders():\n-            if k.lower() != 'set-cookie':\n-                headers.add(k, v)\n-\n-        if six.PY3:  # Python 3:\n-            cookies = r.msg.get_all('set-cookie') or tuple()\n-        else:  # Python 2:\n-            cookies = r.msg.getheaders('set-cookie')\n-\n-        for cookie in cookies:\n-            headers.add('set-cookie', cookie)\n+        headers = r.msg\n+        if not isinstance(headers, HTTPHeaderDict):\n+            if PY3: # Python 3\n+                headers = HTTPHeaderDict(headers.items())\n+            else: # Python 2\n+                headers = HTTPHeaderDict.from_httplib(headers)\n \n         # HTTPResponse objects in Python 3 don't have a .strict attribute\n         strict = getattr(r, 'strict', 0)\n-        return ResponseCls(body=r,\n+        resp = ResponseCls(body=r,\n                            headers=headers,\n                            status=r.status,\n                            version=r.version,\n@@ -308,6 +301,7 @@ class HTTPResponse(io.IOBase):\n                            strict=strict,\n                            original_response=r,\n                            **response_kw)\n+        return resp\n \n     # Backwards-compatibility methods for httplib.HTTPResponse\n     def getheaders(self):\n\n@@ -82,6 +82,7 @@ def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,\n             err = _\n             if sock is not None:\n                 sock.close()\n+                sock = None\n \n     if err is not None:\n         raise err\n\n@@ -29,8 +29,8 @@ try:\n except ImportError:\n     _DEFAULT_CIPHERS = (\n         'ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+HIGH:'\n-        'DH+HIGH:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+HIGH:RSA+3DES:ECDH+RC4:'\n-        'DH+RC4:RSA+RC4:!aNULL:!eNULL:!MD5'\n+        'DH+HIGH:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+HIGH:RSA+3DES:!aNULL:'\n+        '!eNULL:!MD5'\n     )\n \n try:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
