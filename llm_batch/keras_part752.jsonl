{"custom_id": "keras#e1872a29ab231cc7f11fe3b6b943ec4766adcf7f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 261 | Contributors (this commit): 5 | Commits (past 90d): 2 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -22,7 +22,7 @@ class Adafactor(optimizer.Optimizer):\n             a callable that takes no arguments and returns the actual value to\n             use. The learning rate. Defaults to `0.001`.\n         beta_2_decay: float, defaults to -0.8. The decay rate of `beta_2`.\n-        epsilon_1: float, defaults to 1e-30. A small offset to keep demoninator\n+        epsilon_1: float, defaults to 1e-30. A small offset to keep denominator\n             away from 0.\n         epsilon_2: float, defaults to 1e-3. A small offset to avoid learning\n             rate becoming too small by time.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2cade16d825311da310873bc47f89c85a9c4a71b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 187 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 5 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 187 | Churn Cumulative: 187 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,187 @@\n+\"\"\"\n+Title: PixelCNN\n+Author: [ADMoreau](https://github.com/ADMoreau)\n+Date created: 2020/05/17\n+Last modified: 2020/05/23\n+Description: PixelCNN implemented in Keras.\n+Accelerator: GPU\n+\"\"\"\n+\n+\"\"\"\n+## Introduction\n+\n+PixelCNN is a generative model proposed in 2016 by van den Oord et al.\n+(reference: [Conditional Image Generation with PixelCNN Decoders](https://arxiv.org/abs/1606.05328)).\n+It is designed to generate images (or other data types) iteratively\n+from an input vector where the probability distribution of prior elements dictates the\n+probability distribution of later elements. In the following example, images are generated\n+in this fashion, pixel-by-pixel, via a masked convolution kernel that only looks at data\n+from previously generated pixels (origin at the top left) to generate later pixels.\n+During inference, the output of the network is used as a probability ditribution\n+from which new pixel values are sampled to generate a new image\n+(here, with MNIST, the pixels values are either black or white).\n+\"\"\"\n+\n+import numpy as np\n+import keras\n+from keras import layers\n+from keras import ops\n+from tqdm import tqdm\n+\n+\"\"\"\n+## Getting the Data\n+\"\"\"\n+\n+# Model / data parameters\n+num_classes = 10\n+input_shape = (28, 28, 1)\n+n_residual_blocks = 5\n+# The data, split between train and test sets\n+(x, _), (y, _) = keras.datasets.mnist.load_data()\n+# Concatenate all the images together\n+data = np.concatenate((x, y), axis=0)\n+# Round all pixel values less than 33% of the max 256 value to 0\n+# anything above this value gets rounded up to 1 so that all values are either\n+# 0 or 1\n+data = np.where(data < (0.33 * 256), 0, 1)\n+data = data.astype(np.float32)\n+\n+\"\"\"\n+## Create two classes for the requisite Layers for the model\n+\"\"\"\n+\n+\n+# The first layer is the PixelCNN layer. This layer simply\n+# builds on the 2D convolutional layer, but includes masking.\n+class PixelConvLayer(layers.Layer):\n+    def __init__(self, mask_type, **kwargs):\n+        super().__init__()\n+        self.mask_type = mask_type\n+        self.conv = layers.Conv2D(**kwargs)\n+\n+    def build(self, input_shape):\n+        # Build the conv2d layer to initialize kernel variables\n+        self.conv.build(input_shape)\n+        # Use the initialized kernel to create the mask\n+        kernel_shape = ops.shape(self.conv.kernel)\n+        self.mask = np.zeros(shape=kernel_shape)\n+        self.mask[: kernel_shape[0] // 2, ...] = 1.0\n+        self.mask[kernel_shape[0] // 2, : kernel_shape[1] // 2, ...] = 1.0\n+        if self.mask_type == \"B\":\n+            self.mask[kernel_shape[0] // 2, kernel_shape[1] // 2, ...] = 1.0\n+\n+    def call(self, inputs):\n+        self.conv.kernel.assign(self.conv.kernel * self.mask)\n+        return self.conv(inputs)\n+\n+\n+# Next, we build our residual block layer.\n+# This is just a normal residual block, but based on the PixelConvLayer.\n+class ResidualBlock(keras.layers.Layer):\n+    def __init__(self, filters, **kwargs):\n+        super().__init__(**kwargs)\n+        self.conv1 = keras.layers.Conv2D(\n+            filters=filters, kernel_size=1, activation=\"relu\"\n+        )\n+        self.pixel_conv = PixelConvLayer(\n+            mask_type=\"B\",\n+            filters=filters // 2,\n+            kernel_size=3,\n+            activation=\"relu\",\n+            padding=\"same\",\n+        )\n+        self.conv2 = keras.layers.Conv2D(\n+            filters=filters, kernel_size=1, activation=\"relu\"\n+        )\n+\n+    def call(self, inputs):\n+        x = self.conv1(inputs)\n+        x = self.pixel_conv(x)\n+        x = self.conv2(x)\n+        return keras.layers.add([inputs, x])\n+\n+\n+\"\"\"\n+## Build the model based on the original paper\n+\"\"\"\n+\n+inputs = keras.Input(shape=input_shape)\n+x = PixelConvLayer(\n+    mask_type=\"A\", filters=128, kernel_size=7, activation=\"relu\", padding=\"same\"\n+)(inputs)\n+\n+for _ in range(n_residual_blocks):\n+    x = ResidualBlock(filters=128)(x)\n+\n+for _ in range(2):\n+    x = PixelConvLayer(\n+        mask_type=\"B\",\n+        filters=128,\n+        kernel_size=1,\n+        strides=1,\n+        activation=\"relu\",\n+        padding=\"valid\",\n+    )(x)\n+\n+out = keras.layers.Conv2D(\n+    filters=1, kernel_size=1, strides=1, activation=\"sigmoid\", padding=\"valid\"\n+)(x)\n+\n+pixel_cnn = keras.Model(inputs, out)\n+adam = keras.optimizers.Adam(learning_rate=0.0005)\n+pixel_cnn.compile(optimizer=adam, loss=\"binary_crossentropy\")\n+\n+pixel_cnn.summary()\n+pixel_cnn.fit(\n+    x=data, y=data, batch_size=128, epochs=50, validation_split=0.1, verbose=2\n+)\n+\n+\"\"\"\n+## Demonstration\n+\n+The PixelCNN cannot generate the full image at once. Instead, it must generate each pixel in\n+order, append the last generated pixel to the current image, and feed the image back into the\n+model to repeat the process.\n+\"\"\"\n+\n+from IPython.display import Image, display\n+\n+# Create an empty array of pixels.\n+batch = 4\n+pixels = np.zeros(shape=(batch,) + (pixel_cnn.input_shape)[1:])\n+batch, rows, cols, channels = pixels.shape\n+\n+# Iterate over the pixels because generation has to be done sequentially pixel by pixel.\n+for row in tqdm(range(rows)):\n+    for col in range(cols):\n+        for channel in range(channels):\n+            # Feed the whole array and retrieving the pixel value probabilities for the next\n+            # pixel.\n+            probs = pixel_cnn.predict(pixels)[:, row, col, channel]\n+            # Use the probabilities to pick pixel values and append the values to the image\n+            # frame.\n+            pixels[:, row, col, channel] = ops.ceil(\n+                probs - keras.random.uniform(probs.shape)\n+            )\n+\n+\n+def deprocess_image(x):\n+    # Stack the single channeled black and white image to rgb values.\n+    x = np.stack((x, x, x), 2)\n+    # Undo preprocessing\n+    x *= 255.0\n+    # Convert to uint8 and clip to the valid range [0, 255]\n+    x = np.clip(x, 0, 255).astype(\"uint8\")\n+    return x\n+\n+\n+# Iterate over the generated images and plot them with matplotlib.\n+for i, pic in enumerate(pixels):\n+    keras.utils.save_img(\n+        \"generated_image_{}.png\".format(i), deprocess_image(np.squeeze(pic, -1))\n+    )\n+\n+display(Image(\"generated_image_0.png\"))\n+display(Image(\"generated_image_1.png\"))\n+display(Image(\"generated_image_2.png\"))\n+display(Image(\"generated_image_3.png\"))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3525ec7146592865508de29b3ceada5d4599896b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 768 | Contributors (this commit): 3 | Commits (past 90d): 8 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3583,6 +3583,7 @@ def meshgrid(*x, indexing=\"xy\"):\n \n class Min(Operation):\n     def __init__(self, axis=None, keepdims=False, initial=None):\n+        super().__init__()\n         if isinstance(axis, int):\n             self.axis = [axis]\n         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ea3f7e8e8d1c12d3725b2d53a75151c4428e2d54", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 759 | Contributors (this commit): 18 | Commits (past 90d): 4 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -27,26 +27,17 @@ from keras.backend.config import set_epsilon\n from keras.backend.config import set_floatx\n from keras.backend.config import set_image_data_format\n from keras.backend.config import standardize_data_format\n-from keras.utils.io_utils import print_msg\n \n # Import backend functions.\n if backend() == \"tensorflow\":\n-    print_msg(\"Using TensorFlow backend\")\n     from keras.backend.tensorflow import *  # noqa: F403\n elif backend() == \"jax\":\n-    print_msg(\"Using JAX backend.\")\n     from keras.backend.jax import *  # noqa: F403\n elif backend() == \"torch\":\n-    print_msg(\"Using PyTorch backend.\")\n     from keras.backend.torch import *  # noqa: F403\n \n     distribution_lib = None\n elif backend() == \"numpy\":\n-    print_msg(\n-        \"Using NumPy backend.\\nThe NumPy backend does not support \"\n-        \"training. It should only be used for inference, evaluation, \"\n-        \"and debugging.\"\n-    )\n     from keras.backend.numpy import *  # noqa: F403\n \n     distribution_lib = None\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6d66a12733e0af89436b0eba7dead5195fe225cd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 2004 | Contributors (this commit): 5 | Commits (past 90d): 17 | Contributors (cumulative): 8 | DMM Complexity: 1.0\n\nDIFF:\n@@ -851,6 +851,8 @@ def repeat(x, repeats, axis=None):\n \n \n def reshape(x, new_shape):\n+    if not isinstance(new_shape, (list, tuple)):\n+        new_shape = (new_shape,)\n     x = convert_to_tensor(x)\n     return torch.reshape(x, new_shape)\n \n\n@@ -3631,6 +3631,7 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n         x = np.array([[1, 2, 3], [3, 2, 1]])\n         self.assertAllClose(knp.reshape(x, [3, 2]), np.reshape(x, [3, 2]))\n         self.assertAllClose(knp.Reshape([3, 2])(x), np.reshape(x, [3, 2]))\n+        self.assertAllClose(knp.Reshape(-1)(x), np.reshape(x, -1))\n \n     @pytest.mark.skipif(\n         not backend.SUPPORTS_SPARSE_TENSORS,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#68a61352e421ca75d85f369ff6d9f49b4ff0698e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 370 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 370 | Churn Cumulative: 370 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -0,0 +1,370 @@\n+\"\"\"\n+Title: GPT2 Text Generation with KerasNLP\n+Author: Chen Qian\n+Date created: 04/17/2023\n+Last modified: 04/17/2023\n+Description: Use KerasNLP GPT2 model and `samplers` to do text generation.\n+Accelerator: GPU\n+\"\"\"\n+\n+\"\"\"\n+In this tutorial, you will learn to use [KerasNLP](https://keras.io/keras_nlp/) to load a\n+pre-trained Large Language Model (LLM) - [GPT-2 model](https://openai.com/research/better-language-models)\n+(originally invented by OpenAI), finetune it to a specific text style, and\n+generate text based on users' input (also known as prompt). You will also learn\n+how GPT2 adapts quickly to non-English languages, such as Chinese.\n+\"\"\"\n+\n+\"\"\"\n+##  Before we begin\n+\n+Colab offers different kinds of runtimes. Make sure to go to **Runtime ->\n+Change runtime type** and choose the GPU Hardware Accelerator runtime\n+(which should have >12G host RAM and ~15G GPU RAM) since you will finetune the\n+GPT-2 model. Running this tutorial on CPU runtime will take hours.\n+\"\"\"\n+\n+\"\"\"\n+## Install KerasNLP, Choose Backend and Import Dependencies\n+\n+This examples uses [Keras 3.0](https://keras.io/keras_core/) to work in any of\n+`\"tensorflow\"`, `\"jax\"` or `\"torch\"`. Support for Keras Core is baked into\n+KerasNLP, simply change the `\"KERAS_BACKEND\"` environment variable to select\n+the backend of your choice. We select the JAX backend below.\n+\"\"\"\n+\n+\"\"\"shell\n+pip install git+https://github.com/keras-team/keras-nlp.git -q\n+\"\"\"\n+\n+import keras_nlp\n+import tensorflow as tf\n+import json\n+import keras\n+import os\n+import tensorflow_datasets as tfds\n+import time\n+\n+\n+\"\"\"\n+## Introduction to Generative Large Language Models (LLMs)\n+\n+Large language models (LLMs) are a type of machine learning models that are\n+trained on a large corpus of text data to generate outputs for various natural\n+language processing (NLP) tasks, such as text generation, question answering,\n+and machine translation.\n+\n+Generative LLMs are typically based on deep learning neural networks, such as\n+the [Transformer architecture](https://arxiv.org/abs/1706.03762) invented by\n+Google researchers in 2017, and are trained on massive amounts of text data,\n+often involving billions of words. These models, such as Google [LaMDA](https://blog.google/technology/ai/lamda/)\n+and [PaLM](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html),\n+are trained with a large dataset from various data sources which allows them to\n+generate output for many tasks. The core of Generative LLMs is predicting the\n+next word in a sentence, often referred as **Causal LM Pretraining**. In this\n+way LLMs can generate coherent text based on user prompts. For a more\n+pedagogical discussion on language models, you can refer to the\n+[Stanford CS324 LLM class](https://stanford-cs324.github.io/winter2022/lectures/introduction/).\n+\"\"\"\n+\n+\"\"\"\n+## Introduction to KerasNLP\n+\n+Large Language Models are complex to build and expensive to train from scratch.\n+Luckily there are pretrained LLMs available for use right away. [KerasNLP](https://keras.io/keras_nlp/)\n+provides a large number of pre-trained checkpoints that allow you to experiment\n+with SOTA models without needing to train them yourself.\n+\n+KerasNLP is a natural language processing library that supports users through\n+their entire development cycle. KerasNLP offers both pretrained models and\n+modularized building blocks, so developers could easily reuse pretrained models\n+or stack their own LLM.\n+\n+In a nutshell, for generative LLM, KerasNLP offers:\n+\n+- Pretrained models with `generate()` method, e.g.,\n+    `keras_nlp.models.GPT2CausalLM` and `keras_nlp.models.OPTCausalLM`.\n+- Sampler class that implements generation algorithms such as Top-K, Beam and\n+    contrastive search. These samplers can be used to generate text with\n+    custom models.\n+\"\"\"\n+\n+\"\"\"\n+## Load a pre-trained GPT-2 model and generate some text\n+\n+KerasNLP provides a number of pre-trained models, such as [Google\n+Bert](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html)\n+and [GPT-2](https://openai.com/research/better-language-models). You can see\n+the list of models available in the [KerasNLP repository](https://github.com/keras-team/keras-nlp/tree/master/keras_nlp/models).\n+\n+It's very easy to load the GPT-2 model as you can see below:\n+\"\"\"\n+\n+# To speed up training and generation, we use preprocessor of length 128\n+# instead of full length 1024.\n+preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n+    \"gpt2_base_en\",\n+    sequence_length=128,\n+)\n+gpt2_lm = keras_nlp.models.GPT2CausalLM.from_preset(\n+    \"gpt2_base_en\", preprocessor=preprocessor\n+)\n+\n+\"\"\"\n+Once the model is loaded, you can use it to generate some text right away. Run\n+the cells below to give it a try. It's as simple as calling a single function\n+*generate()*:\n+\"\"\"\n+\n+start = time.time()\n+\n+output = gpt2_lm.generate(\"My trip to Yosemite was\", max_length=200)\n+print(\"\\nGPT-2 output:\")\n+print(output)\n+\n+end = time.time()\n+print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")\n+\n+\"\"\"\n+Try another one:\n+\"\"\"\n+\n+start = time.time()\n+\n+output = gpt2_lm.generate(\"That Italian restaurant is\", max_length=200)\n+print(\"\\nGPT-2 output:\")\n+print(output)\n+\n+end = time.time()\n+print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")\n+\n+\"\"\"\n+Notice how much faster the second call is. This is because the computational\n+graph is [XLA compiled](https://www.tensorflow.org/xla) in the 1st run and\n+re-used in the 2nd behind the scenes.\n+\n+The quality of the generated text looks OK, but we can improve it via\n+fine-tuning.\n+\"\"\"\n+\n+\"\"\"\n+## More on the GPT-2 model from KerasNLP\n+\n+Next up, we will actually fine-tune the model to update its parameters, but\n+before we do, let's take a look at the full set of tools we have to for working\n+with for GPT2.\n+\n+The code of GPT2 can be found\n+[here](https://github.com/keras-team/keras-nlp/blob/master/keras_nlp/models/gpt2/).\n+Conceptually the `GPT2CausalLM` can be hierarchically broken down into several\n+modules in KerasNLP, all of which have a *from_preset()* function that loads a\n+pretrained model:\n+\n+- `keras_nlp.models.GPT2Tokenizer`: The tokenizer used by GPT2 model, which is a\n+    [byte-pair encoder](https://huggingface.co/course/chapter6/5?fw=pt).\n+- `keras_nlp.models.GPT2CausalLMPreprocessor`: the preprocessor used by GPT2\n+    causal LM training. It does the tokenization along with other preprocessing\n+    works such as creating the label and appending the end token.\n+- `keras_nlp.models.GPT2Backbone`: the GPT2 model, which is a stack of\n+    `keras_nlp.layers.TransformerDecoder`. This is usually just referred as\n+    `GPT2`.\n+- `keras_nlp.models.GPT2CausalLM`: wraps `GPT2Backbone`, it multiplies the\n+    output of `GPT2Backbone` by embedding matrix to generate logits over\n+    vocab tokens.\n+\"\"\"\n+\n+\"\"\"\n+## Finetune on Reddit dataset\n+\n+Now you have the knowledge of the GPT-2 model from KerasNLP, you can take one\n+step further to finetune the model so that it generates text in a specific\n+style, short or long, strict or casual. In this tutorial, we will use reddit\n+dataset for example.\n+\"\"\"\n+\n+reddit_ds = tfds.load(\"reddit_tifu\", split=\"train\", as_supervised=True)\n+\n+\"\"\"\n+Let's take a look inside sample data from the reddit TensorFlow Dataset. There\n+are two features:\n+\n+- **__document__**: text of the post.\n+- **__title__**: the title.\n+\n+\"\"\"\n+\n+for document, title in reddit_ds:\n+    print(document.numpy())\n+    print(title.numpy())\n+    break\n+\n+\"\"\"\n+In our case, we are performing next word prediction in a language model, so we\n+only need the 'document' feature.\n+\"\"\"\n+\n+train_ds = (\n+    reddit_ds.map(lambda document, _: document)\n+    .batch(32)\n+    .cache()\n+    .prefetch(tf.data.AUTOTUNE)\n+)\n+\n+\"\"\"\n+Now you can finetune the model using the familiar *fit()* function. Note that\n+`preprocessor` will be automatically called inside `fit` method since\n+`GPT2CausalLM` is a `keras_nlp.models.Task` instance.\n+\n+This step takes quite a bit of GPU memory and a long time if we were to train\n+it all the way to a fully trained state. Here we just use part of the dataset\n+for demo purposes.\n+\"\"\"\n+\n+train_ds = train_ds.take(500)\n+num_epochs = 1\n+\n+# Linearly decaying learning rate.\n+learning_rate = keras.optimizers.schedules.PolynomialDecay(\n+    5e-5,\n+    decay_steps=train_ds.cardinality() * num_epochs,\n+    end_learning_rate=0.0,\n+)\n+loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n+gpt2_lm.compile(\n+    optimizer=keras.optimizers.Adam(learning_rate),\n+    loss=loss,\n+    weighted_metrics=[\"accuracy\"],\n+)\n+\n+gpt2_lm.fit(train_ds, epochs=num_epochs)\n+\n+\"\"\"\n+After fine-tuning is finished, you can again generate text using the same\n+*generate()* function. This time, the text will be closer to Reddit writing\n+style, and the generated length will be close to our preset length in the\n+training set.\n+\"\"\"\n+\n+start = time.time()\n+\n+output = gpt2_lm.generate(\"I like basketball\", max_length=200)\n+print(\"\\nGPT-2 output:\")\n+print(output)\n+\n+end = time.time()\n+print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")\n+\n+\"\"\"\n+## Into the Sampling Method\n+\n+In KerasNLP, we offer a few sampling methods, e.g., contrastive search,\n+Top-K and beam sampling. By default, our `GPT2CausalLM` uses Top-k search, but\n+you can choose your own sampling method.\n+\n+Much like optimizer and activations, there are two ways to specify your custom\n+sampler:\n+\n+- Use a string identifier, such as \"greedy\", you are using the default\n+configuration via this way.\n+- Pass a `keras_nlp.samplers.Sampler` instance, you can use custom configuration\n+via this way.\n+\"\"\"\n+\n+# Use a string identifier.\n+gpt2_lm.compile(sampler=\"top_k\")\n+output = gpt2_lm.generate(\"I like basketball\", max_length=200)\n+print(\"\\nGPT-2 output:\")\n+print(output)\n+\n+# Use a `Sampler` instance. `GreedySampler` tends to repeat itself,\n+greedy_sampler = keras_nlp.samplers.GreedySampler()\n+gpt2_lm.compile(sampler=greedy_sampler)\n+\n+output = gpt2_lm.generate(\"I like basketball\", max_length=200)\n+print(\"\\nGPT-2 output:\")\n+print(output)\n+\n+\"\"\"\n+For more details on KerasNLP `Sampler` class, you can check the code\n+[here](https://github.com/keras-team/keras-nlp/tree/master/keras_nlp/samplers).\n+\"\"\"\n+\n+\"\"\"\n+## Finetune on Chinese Poem Dataset\n+\n+We can also finetune GPT2 on non-English datasets. For readers knowing Chinese,\n+this part illustrates how to fine-tune GPT2 on Chinese poem dataset to teach our\n+model to become a poet!\n+\n+Because GPT2 uses byte-pair encoder, and the original pretraining dataset\n+contains some Chinese characters, we can use the original vocab to finetune on\n+Chinese dataset.\n+\"\"\"\n+\n+\"\"\"shell\n+# Load chinese poetry dataset.\n+git clone https://github.com/chinese-poetry/chinese-poetry.git\n+\"\"\"\n+\n+\"\"\"\n+Load text from the json file. We only use《全唐诗》for demo purposes.\n+\"\"\"\n+\n+poem_collection = []\n+for file in os.listdir(\"chinese-poetry/全唐诗\"):\n+    if \".json\" not in file or \"poet\" not in file:\n+        continue\n+    full_filename = f\"{'chinese-poetry/全唐诗'}/{file}\"\n+    with open(full_filename, \"r\") as f:\n+        content = json.load(f)\n+        poem_collection.extend(content)\n+\n+paragraphs = [\"\".join(data[\"paragraphs\"]) for data in poem_collection]\n+\n+\"\"\"\n+Let's take a look at sample data.\n+\"\"\"\n+\n+print(paragraphs[0])\n+\n+\"\"\"\n+Similar as Reddit example, we convert to TF dataset, and only use partial data\n+to train.\n+\"\"\"\n+\n+train_ds = (\n+    tf.data.Dataset.from_tensor_slices(paragraphs)\n+    .batch(16)\n+    .cache()\n+    .prefetch(tf.data.AUTOTUNE)\n+)\n+\n+# Running through the whole dataset takes long, only take `500` and run 1\n+# epochs for demo purposes.\n+train_ds = train_ds.take(500)\n+num_epochs = 1\n+\n+learning_rate = keras.optimizers.schedules.PolynomialDecay(\n+    5e-4,\n+    decay_steps=train_ds.cardinality() * num_epochs,\n+    end_learning_rate=0.0,\n+)\n+loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n+gpt2_lm.compile(\n+    optimizer=keras.optimizers.Adam(learning_rate),\n+    loss=loss,\n+    weighted_metrics=[\"accuracy\"],\n+)\n+\n+gpt2_lm.fit(train_ds, epochs=num_epochs)\n+\n+\"\"\"\n+Let's check the result!\n+\"\"\"\n+\n+output = gpt2_lm.generate(\"昨夜雨疏风骤\", max_length=200)\n+print(output)\n+\n+\"\"\"\n+Not bad 😀\n+\"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8647a3c351965e845f15656bd63f8048aca4696b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 12 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -540,7 +540,7 @@ def update_confusion_matrix_variables(\n \n     if sample_weight is not None:\n         sample_weight = ops.broadcast_to(\n-            ops.cast(sample_weight, dtype=y_pred.dtype), y_pred.shape\n+            ops.cast(sample_weight, dtype=y_pred.dtype), ops.shape(y_pred)\n         )\n         weights_tiled = ops.tile(\n             ops.reshape(sample_weight, thresh_tiles), data_tiles\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d3fa4a0a79ae0f2b1e6d440403623a4ce6662bc6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 9 | Churn Cumulative: 957 | Contributors (this commit): 3 | Commits (past 90d): 12 | Contributors (cumulative): 6 | DMM Complexity: 0.5\n\nDIFF:\n@@ -31,6 +31,10 @@ class KerasVariable:\n         self._shape = None\n         self._initializer = None\n         self._trainable = trainable\n+        if isinstance(initializer, str):\n+            from keras import initializers\n+\n+            initializer = initializers.get(initializer)\n         if callable(initializer):\n             if shape is None:\n                 raise ValueError(\n\n@@ -36,6 +36,11 @@ class VariableInitializationTest(test_case.TestCase):\n         v = backend.Variable(initializer=np.ones((2, 2)))\n         self.assertAllClose(v.value, np.ones((2, 2)))\n \n+    def test_variable_initialization_with_strings(self):\n+        \"\"\"Test variable init with non-callable initializer.\"\"\"\n+        v = backend.Variable(initializer=\"ones\", shape=(2, 2))\n+        self.assertAllClose(v.value, np.ones((2, 2)))\n+\n     def test_variable_initialization_with_non_trainable(self):\n         \"\"\"Test variable initialization with non-trainable flag.\"\"\"\n         v = backend.Variable(initializer=np.ones((2, 2)), trainable=False)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9e30f7ff43f51a3a94c4ff2f3b08f2f65b422237", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 263 | Contributors (this commit): 5 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -104,7 +104,7 @@ class Adafactor(optimizer.Optimizer):\n                         backend.Variable(0, name=var.name, trainable=False)\n                     )\n             else:\n-                # Always factor the last 2 dimenstions.\n+                # Always factor the last 2 dimensions.\n                 r_shape = var.shape[:-1]\n                 c_shape = var.shape[:-2] + var.shape[-1]\n                 self._r.append(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6e54f7f302c637d7b0af2e935a2db32642a19928", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 54 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 8 | Complexity Δ (Sum/Max): 8/6 | Churn Δ: 54 | Churn Cumulative: 72 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -167,3 +167,15 @@ class BackupAndRestoreCallbackTest(testing.TestCase):\n             verbose=0,\n         )\n         self.assertFalse(file_utils.exists(backup_dir))\n+\n+    def test_backup_dir_empty_error(self):\n+        with self.assertRaisesRegex(\n+            ValueError, expected_regex=\"Empty `backup_dir` argument passed\"\n+        ):\n+            callbacks.BackupAndRestore(backup_dir=\"\", save_freq=\"epoch\")\n+\n+    def test_backup_dir_none_error(self):\n+        with self.assertRaisesRegex(\n+            ValueError, expected_regex=\"Empty `backup_dir` argument passed\"\n+        ):\n+            callbacks.BackupAndRestore(backup_dir=None, save_freq=\"epoch\")\n\n@@ -57,3 +57,45 @@ class ConstraintsTest(testing.TestCase):\n \n         with self.assertRaises(ValueError):\n             constraints.get(\"typo\")\n+\n+    def test_default_constraint_call(self):\n+        constraint_fn = constraints.Constraint()\n+        x = np.array([1.0, 2.0, 3.0])\n+        output = constraint_fn(x)\n+        self.assertAllClose(x, output)\n+\n+    def test_constraint_get_config(self):\n+        constraint_fn = constraints.Constraint()\n+        config = constraint_fn.get_config()\n+        self.assertEqual(config, {})\n+\n+    def test_constraint_from_config(self):\n+        constraint_fn = constraints.Constraint()\n+        config = constraint_fn.get_config()\n+        recreated_constraint_fn = constraints.Constraint.from_config(config)\n+        self.assertIsInstance(recreated_constraint_fn, constraints.Constraint)\n+\n+    def test_max_norm_get_config(self):\n+        constraint_fn = constraints.MaxNorm(max_value=3.0, axis=1)\n+        config = constraint_fn.get_config()\n+        expected_config = {\"max_value\": 3.0, \"axis\": 1}\n+        self.assertEqual(config, expected_config)\n+\n+    def test_unit_norm_get_config(self):\n+        constraint_fn = constraints.UnitNorm(axis=1)\n+        config = constraint_fn.get_config()\n+        expected_config = {\"axis\": 1}\n+        self.assertEqual(config, expected_config)\n+\n+    def test_min_max_norm_get_config(self):\n+        constraint_fn = constraints.MinMaxNorm(\n+            min_value=0.5, max_value=2.0, rate=0.7, axis=1\n+        )\n+        config = constraint_fn.get_config()\n+        expected_config = {\n+            \"min_value\": 0.5,\n+            \"max_value\": 2.0,\n+            \"rate\": 0.7,\n+            \"axis\": 1,\n+        }\n+        self.assertEqual(config, expected_config)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9d08fe2675a903e9a06f954c74a7aeaebddf3290", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 14 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -185,14 +185,14 @@ class RandomTranslation(TFDataLayer):\n             shape=[batch_size, 1],\n             seed=seed_generator,\n         )\n-        height_translate = height_translate * height\n+        height_translate = self.backend.numpy.multiply(height_translate, height)\n         width_translate = self.backend.random.uniform(\n             minval=self.width_lower,\n             maxval=self.width_upper,\n             shape=[batch_size, 1],\n             seed=seed_generator,\n         )\n-        width_translate = width_translate * width\n+        width_translate = self.backend.numpy.multiply(width_translate, width)\n         translations = self.backend.cast(\n             self.backend.numpy.concatenate(\n                 [width_translate, height_translate], axis=1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#689cd70bac06563551e3deab04d6ae6cd04f76d1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 6 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 9 | Churn Cumulative: 31 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,6 +1,7 @@\n import numpy as np\n import torch\n import torch.nn.functional as tnn\n+import tree\n \n from keras.backend import standardize_data_format\n from keras.backend import standardize_dtype\n@@ -337,7 +338,9 @@ def conv(\n         inputs = _transpose_spatial_inputs(inputs)\n     # Transpose kernel from keras format to torch format.\n     kernel = _transpose_conv_kernel(kernel)\n-    if padding == \"same\":\n+    if padding == \"same\" and any(d != 1 for d in tree.flatten(strides)):\n+        # Torch does not support this case in conv2d().\n+        # Manually pad the tensor.\n         inputs = _apply_same_padding(\n             inputs,\n             kernel.shape[2:],\n@@ -345,6 +348,7 @@ def conv(\n             operation_type=\"conv\",\n             dilation_rate=dilation_rate,\n         )\n+        padding = 0\n     channels = inputs.shape[1]\n     kernel_in_channels = kernel.shape[1]\n     if channels % kernel_in_channels > 0:\n@@ -361,6 +365,7 @@ def conv(\n             stride=strides,\n             dilation=dilation_rate,\n             groups=groups,\n+            padding=padding,\n         )\n     elif num_spatial_dims == 2:\n         outputs = tnn.conv2d(\n@@ -369,6 +374,7 @@ def conv(\n             stride=strides,\n             dilation=dilation_rate,\n             groups=groups,\n+            padding=padding,\n         )\n     elif num_spatial_dims == 3:\n         outputs = tnn.conv3d(\n@@ -377,6 +383,7 @@ def conv(\n             stride=strides,\n             dilation=dilation_rate,\n             groups=groups,\n+            padding=padding,\n         )\n     else:\n         raise ValueError(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0185654e756bd3d13d78b132e3d757f1ab8d6dc6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 267 | Contributors (this commit): 3 | Commits (past 90d): 7 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -14,9 +14,6 @@ import warnings\n \n import numpy as np\n \n-# TF is used for dataset sharding.\n-import tensorflow as tf\n-\n from keras.api_export import keras_export\n from keras.backend import KerasTensor\n from keras.backend import distribution_lib\n@@ -426,6 +423,8 @@ class DataParallel(Distribution):\n         return None\n \n     def distribute_dataset(self, dataset):\n+        from keras.utils.module_utils import tensorflow as tf\n+\n         if not isinstance(dataset, tf.data.Dataset):\n             raise ValueError(\n                 \"Only `tf.data.Dataset` is supported for \"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e3c68cd1d4e3c6dce42260b835041ea0a4111c57", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 55 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 7 | Methods Changed: 4 | Complexity Δ (Sum/Max): 5/3 | Churn Δ: 60 | Churn Cumulative: 142 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -445,8 +445,8 @@ class Layer(BackendLayer, Operation):\n \n     def add_weight(\n         self,\n-        shape,\n-        initializer,\n+        shape=None,\n+        initializer=None,\n         dtype=None,\n         trainable=True,\n         regularizer=None,\n@@ -458,12 +458,19 @@ class Layer(BackendLayer, Operation):\n         Args:\n             shape: Shape tuple for the variable.\n                 Must be fully-defined (no `None` entries).\n+                Defaults to `()` (scalar) if unspecified.\n             initializer: Initializer object to use to\n                 populate the initial variable value,\n                 or string name of a built-in initializer\n-                (e.g. `\"random_normal\"`).\n+                (e.g. `\"random_normal\"`). If unspecified,\n+                defaults to `\"glorot_uniform\"`\n+                for floating-point variables and to `\"zeros\"`\n+                for all other types (e.g. int, bool).\n             dtype: Dtype of the variable to create,\n-                e.g. `\"float32\"`.\n+                e.g. `\"float32\"`. If unspecified,\n+                defaults to the layer's\n+                variable dtype (which itself defaults to\n+                `\"float32\"` if unspecified).\n             trainable: Boolean, whether the variable should\n                 be trainable via backprop or whether its\n                 updates are managed manually.\n@@ -474,12 +481,23 @@ class Layer(BackendLayer, Operation):\n                 for debugging purposes.\n         \"\"\"\n         self._check_super_called()\n+        if shape is None:\n+            shape = ()\n+        if dtype is not None:\n+            dtype = backend.standardize_dtype(dtype)\n+        else:\n+            dtype = self.variable_dtype\n+        if initializer is None:\n+            if \"float\" in dtype:\n+                initializer = \"glorot_uniform\"\n+            else:\n+                initializer = \"zeros\"\n         initializer = initializers.get(initializer)\n         with backend.name_scope(self.name, caller=self):\n             variable = backend.Variable(\n                 initializer=initializer,\n                 shape=shape,\n-                dtype=dtype or self.variable_dtype,\n+                dtype=dtype,\n                 trainable=trainable,\n                 name=name,\n             )\n\n@@ -813,3 +813,35 @@ class LayerTest(testing.TestCase):\n \n         layer = MyLayer()\n         self.assertEqual(len(layer.weights), 1)\n+\n+    def test_add_weight_defaults(self):\n+        class MyLayer(layers.Layer):\n+            def __init__(self):\n+                super().__init__()\n+                self.w1 = self.add_weight()\n+                self.w2 = self.add_weight(dtype=\"int32\")\n+                self.w3 = self.add_weight(dtype=\"bool\")\n+                self.w4 = self.add_weight(dtype=\"int32\", shape=(2, 2))\n+                self.w5 = self.add_weight(initializer=\"ones\", shape=(2, 2))\n+\n+        layer = MyLayer()\n+        self.assertEqual(layer.w1.shape, ())\n+        self.assertEqual(layer.w1.dtype, \"float32\")\n+\n+        self.assertEqual(layer.w2.shape, ())\n+        self.assertEqual(layer.w2.dtype, \"int32\")\n+        self.assertAllClose(backend.convert_to_numpy(layer.w2), 0)\n+\n+        self.assertEqual(layer.w3.shape, ())\n+        self.assertEqual(layer.w3.dtype, \"bool\")\n+        self.assertAllClose(backend.convert_to_numpy(layer.w3), False)\n+\n+        self.assertEqual(layer.w4.shape, (2, 2))\n+        self.assertEqual(layer.w4.dtype, \"int32\")\n+        self.assertAllClose(\n+            backend.convert_to_numpy(layer.w4), np.zeros((2, 2))\n+        )\n+\n+        self.assertEqual(layer.w5.shape, (2, 2))\n+        self.assertEqual(layer.w5.dtype, \"float32\")\n+        self.assertAllClose(backend.convert_to_numpy(layer.w5), np.ones((2, 2)))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#353aaff0347f5fd4b43ac5a4145aac6f2166a156", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 8 | Methods Changed: 4 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 17 | Churn Cumulative: 34 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -20,14 +20,13 @@ def setup_package():\n         shell=True,\n     )\n     print(build_process.stdout)\n-    match = re.search(\n-        r\"\\s[^\\s]*\\.whl\",\n+    whl_path = re.findall(\n+        r\"[^\\s]*\\.whl\",\n         build_process.stdout,\n-    )\n-    if not match:\n-        raise ValueError(\"Installing Keras package unsuccessful. \")\n+    )[-1]\n+    if not whl_path:\n         print(build_process.stderr)\n-    whl_path = match.group()\n+        raise ValueError(\"Installing Keras package unsuccessful. \")\n     return whl_path\n \n \n@@ -82,18 +81,21 @@ def cleanup():\n \n def run_commands_local(commands):\n     for command in commands:\n+        print(f\"Running command: {command}\")\n         subprocess.run(command, shell=True)\n \n \n def run_commands_venv(commands):\n     for command in commands:\n+        print(f\"Running command: {command}\")\n         cmd_with_args = command.split(\" \")\n         cmd_with_args[0] = \"test_env/bin/\" + cmd_with_args[0]\n         p = subprocess.Popen(cmd_with_args)\n-        p.wait()\n+        assert p.wait() == 0\n \n \n def test_keras_imports():\n+    try:\n         # Ensures packages from all backends are installed.\n         # Builds Keras core package and returns package file path.\n         whl_path = setup_package()\n@@ -110,6 +112,7 @@ def test_keras_imports():\n         run_keras_flow()\n \n         # Removes virtual environment and associated files\n+    finally:\n         cleanup()\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b00065c7878ade450286ad2c298148f50e098f0c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 55 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -22,14 +22,14 @@ class TestCase(unittest.TestCase):\n \n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n-        if traceback_utils.is_traceback_filtering_enabled():\n-            traceback_utils.disable_traceback_filtering()\n \n     def setUp(self):\n         # clear global state so that test cases are independent\n         # required for the jit enabled torch tests since dynamo has\n         # a global cache for guards, compiled fn, etc\n         clear_session()\n+        if traceback_utils.is_traceback_filtering_enabled():\n+            traceback_utils.disable_traceback_filtering()\n \n     def get_temp_dir(self):\n         temp_dir = tempfile.mkdtemp()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b640ef34ad972e98f56a1d9c4f97044a604da76f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 52 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -819,9 +819,11 @@ class LayerTest(testing.TestCase):\n             def __init__(self):\n                 super().__init__()\n                 self.w1 = self.add_weight()\n-                self.w2 = self.add_weight(dtype=\"int32\")\n-                self.w3 = self.add_weight(dtype=\"bool\")\n-                self.w4 = self.add_weight(dtype=\"int32\", shape=(2, 2))\n+                self.w2 = self.add_weight(dtype=\"int32\", trainable=False)\n+                self.w3 = self.add_weight(dtype=\"bool\", trainable=False)\n+                self.w4 = self.add_weight(\n+                    dtype=\"int32\", shape=(2, 2), trainable=False\n+                )\n                 self.w5 = self.add_weight(initializer=\"ones\", shape=(2, 2))\n \n         layer = MyLayer()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#93e81f69ed6000dcf6d271efa998a281fcb3a104", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 1389 | Contributors (this commit): 7 | Commits (past 90d): 10 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -179,7 +179,10 @@ def build_and_save_output(root_path, __version__):\n     for fname in os.listdir(dist_directory):\n         if __version__ in fname and fname.endswith(\".whl\"):\n             whl_path = os.path.abspath(os.path.join(dist_directory, fname))\n+    if whl_path:\n         print(f\"Build successful. Wheel file available at {whl_path}\")\n+    else:\n+        print(f\"Build failed.\")\n     return whl_path\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4b36becd3da98538356e6adbb63a9995b62dece0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1391 | Contributors (this commit): 7 | Commits (past 90d): 11 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -182,7 +182,7 @@ def build_and_save_output(root_path, __version__):\n     if whl_path:\n         print(f\"Build successful. Wheel file available at {whl_path}\")\n     else:\n-        print(f\"Build failed.\")\n+        print(\"Build failed.\")\n     return whl_path\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#15926e1f8136380a4ce92fd3f8a6942505e93cc0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 101 | Lines Deleted: 1 | Files Changed: 5 | Hunks: 6 | Methods Changed: 7 | Complexity Δ (Sum/Max): 7/2 | Churn Δ: 102 | Churn Cumulative: 601 | Contributors (this commit): 9 | Commits (past 90d): 10 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -42,3 +42,19 @@ class DropoutTest(testing.TestCase):\n         layer = layers.Dropout(0.5, noise_shape=(20, 1, 10))\n         outputs = layer(inputs, training=True)\n         self.assertAllClose(outputs[:, 0, :], outputs[:, 1, :])\n+\n+    def test_dropout_negative_rate(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"Invalid value received for argument `rate`. \"\n+            \"Expected a float value between 0 and 1.\",\n+        ):\n+            _ = layers.Dropout(rate=-0.5)\n+\n+    def test_dropout_rate_greater_than_one(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"Invalid value received for argument `rate`. \"\n+            \"Expected a float value between 0 and 1.\",\n+        ):\n+            _ = layers.Dropout(rate=1.5)\n\n@@ -62,6 +62,19 @@ class Cropping1DTest(testing.TestCase):\n             layers.Cropping1D(cropping=\"1\")\n \n     def test_cropping_1d_errors_if_cropping_more_than_available(self):\n-        with self.assertRaises(ValueError):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"`cropping` parameter of `Cropping1D` layer must be greater than\",\n+        ):\n             input_layer = layers.Input(batch_shape=(3, 5, 7))\n             layers.Cropping1D(cropping=(2, 3))(input_layer)\n+\n+    def test_cropping_1d_error_on_excessive_cropping(self):\n+        inputs = np.random.rand(3, 5, 7)\n+\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"`cropping` parameter of `Cropping1D` layer must be greater than\",\n+        ):\n+            layer = layers.Cropping1D(cropping=(3, 3))\n+            _ = layer(inputs)\n\n@@ -99,3 +99,30 @@ class Cropping2DTest(testing.TestCase, parameterized.TestCase):\n             layers.Cropping2D(cropping=((1, 2), (3, -4)))\n         with self.assertRaises(ValueError):\n             layers.Cropping2D(cropping=((1, 2), \"3\"))\n+\n+    @parameterized.product(\n+        (\n+            {\"cropping\": ((4, 5), (0, 0)), \"input_shape\": (3, 8, 9, 5)},\n+            {\"cropping\": ((0, 0), (5, 5)), \"input_shape\": (3, 8, 9, 5)},\n+            {\"cropping\": ((6, 3), (0, 0)), \"input_shape\": (3, 8, 9, 5)},\n+            {\"cropping\": ((0, 0), (7, 3)), \"input_shape\": (3, 8, 9, 5)},\n+        ),\n+        (\n+            {\"data_format\": \"channels_first\"},\n+            {\"data_format\": \"channels_last\"},\n+        ),\n+    )\n+    def test_cropping_2d_error_on_excessive_cropping(\n+        self, cropping, input_shape, data_format\n+    ):\n+        inputs = np.random.rand(*input_shape)\n+\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"Values in `cropping` argument should be greater than the \"\n+            \"corresponding spatial dimension of the input.\",\n+        ):\n+            layer = layers.Cropping2D(\n+                cropping=cropping, data_format=data_format\n+            )\n+            _ = layer(inputs)\n\n@@ -162,3 +162,31 @@ class Cropping3DTest(testing.TestCase, parameterized.TestCase):\n             layers.Cropping3D(cropping=((1, 2), (3, 4), (5, -6)))\n         with self.assertRaises(ValueError):\n             layers.Cropping3D(cropping=((1, 2), (3, 4), \"5\"))\n+\n+    @parameterized.product(\n+        (\n+            {\"cropping\": ((8, 1), (1, 1), (1, 1))},\n+            {\"cropping\": ((1, 1), (10, 1), (1, 1))},\n+            {\"cropping\": ((1, 1), (1, 1), (14, 1))},\n+        ),\n+        (\n+            {\"data_format\": \"channels_first\"},\n+            {\"data_format\": \"channels_last\"},\n+        ),\n+    )\n+    def test_cropping_3d_with_excessive_cropping(self, cropping, data_format):\n+        if data_format == \"channels_first\":\n+            shape = (3, 5, 7, 9, 13)\n+            input_layer = layers.Input(batch_shape=shape)\n+        else:\n+            shape = (3, 7, 9, 13, 5)\n+            input_layer = layers.Input(batch_shape=shape)\n+\n+        expected_error_msg = (\n+            \"Values in `cropping` argument should be greater than the\"\n+        )\n+\n+        with self.assertRaisesRegex(ValueError, expected_error_msg):\n+            layers.Cropping3D(cropping=cropping, data_format=data_format)(\n+                input_layer\n+            )\n\n@@ -29,3 +29,19 @@ class FlattenTest(testing.TestCase):\n         input_layer = layers.Input(batch_shape=(2, None))\n         repeated = layers.RepeatVector(n=3)(input_layer)\n         self.assertEqual(repeated.shape, (2, 3, None))\n+\n+    def test_repeat_vector_with_invalid_n(self):\n+        with self.assertRaisesRegex(\n+            TypeError, \"Expected an integer value for `n`\"\n+        ):\n+            layers.RepeatVector(n=\"3\")\n+\n+        with self.assertRaisesRegex(\n+            TypeError, \"Expected an integer value for `n`\"\n+        ):\n+            layers.RepeatVector(n=3.5)\n+\n+        with self.assertRaisesRegex(\n+            TypeError, \"Expected an integer value for `n`\"\n+        ):\n+            layers.RepeatVector(n=[3])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
