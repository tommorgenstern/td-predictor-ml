{"custom_id": "keras#54dc47d0510a80793891ad519b9175afaa414301", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 93 | Contributors (this commit): 1 | Commits (past 90d): 4 | Contributors (cumulative): 1 | DMM Complexity: 0.0\n\nDIFF:\n@@ -34,7 +34,6 @@ class SavingTest(testing.TestCase):\n \n         editor = KerasFileEditor(temp_filepath)\n         editor.summary()\n-        editor._weights_summary_interactive()\n \n         target_model = get_target_model()\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#10a50afd59c9c55ebad19e5aaaa9309e81d49775", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 12 | Churn Cumulative: 24 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -33,6 +33,10 @@ class DeviceTest(testing.TestCase):\n         import jax\n         from jax.lib import xla_bridge\n \n+        def get_device(t):\n+            # After updating to Jax 0.4.33, Directly access via t.device attr.\n+            return list(t.devices())[0]\n+\n         platform = xla_bridge.get_backend().platform\n \n         if platform != \"gpu\":\n@@ -40,19 +44,19 @@ class DeviceTest(testing.TestCase):\n \n         with backend.device_scope(\"cpu:0\"):\n             t = backend.numpy.ones((2, 1))\n-            self.assertEqual(t.device, jax.devices(\"cpu\")[0])\n+            self.assertEqual(get_device(t), jax.devices(\"cpu\")[0])\n         with backend.device_scope(\"CPU:0\"):\n             t = backend.numpy.ones((2, 1))\n-            self.assertEqual(t.device, jax.devices(\"cpu\")[0])\n+            self.assertEqual(get_device(t), jax.devices(\"cpu\")[0])\n \n         # When leaving the scope, the device should be back with gpu:0\n         t = backend.numpy.ones((2, 1))\n-        self.assertEqual(t.device, jax.devices(\"gpu\")[0])\n+        self.assertEqual(get_device(t), jax.devices(\"gpu\")[0])\n \n         # Also verify the explicit gpu device\n         with backend.device_scope(\"gpu:0\"):\n             t = backend.numpy.ones((2, 1))\n-            self.assertEqual(t.device, jax.devices(\"gpu\")[0])\n+            self.assertEqual(get_device(t), jax.devices(\"gpu\")[0])\n \n     @pytest.mark.skipif(backend.backend() != \"jax\", reason=\"jax only\")\n     def test_invalid_jax_device(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f6df47d5896cbca5362f6142a4894e7e9efe6b98", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 570 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -314,11 +314,10 @@ the case for other layers in general, as\n [weight trainability & inference/training modes are two orthogonal concepts](\n   https://keras.io/getting_started/faq/#whats-the-difference-between-the-training-argument-in-call-and-the-trainable-attribute).\n But the two are tied in the case of the `BatchNormalization` layer.\n-- When you unfreeze a model that contains `BatchNormalization` layers in order to do\n-fine-tuning, you should keep the `BatchNormalization` layers in inference mode by\n- passing `training=False` when calling the base model.\n-Otherwise the updates applied to the non-trainable weights will suddenly destroy\n-what the model has learned.\n+- When you unfreeze a model for finetuning by setting `base_model.trainable=True` that \n+contains `BatchNormalization` layers, then all layers of pretrained(based) model become\n+trainable along with BatchNormalization layers.BatchNormalization layer normalize(update)\n+its output using a moving average of mean and standard deviation.  \n \n You'll see this pattern in action in the end-to-end example at the end of this guide.\n \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#09c133c56542f3cada5f492b20b7ff01c8a5e667", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 579 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -315,9 +315,12 @@ the case for other layers in general, as\n   https://keras.io/getting_started/faq/#whats-the-difference-between-the-training-argument-in-call-and-the-trainable-attribute).\n But the two are tied in the case of the `BatchNormalization` layer.\n - When you unfreeze a model for finetuning by setting `base_model.trainable=True` that \n-contains `BatchNormalization` layers, then all layers of pretrained(based) model become\n-trainable along with BatchNormalization layers.BatchNormalization layer normalize(update)\n-its output using a moving average of mean and standard deviation.  \n+contains `BatchNormalization` layers, then all layers of the base model become\n+trainable along with `BatchNormalization` layers. It's a good idea to keep\n+`BatchNormalization` either frozen during fine-tuning, or running in inference mode,\n+so remember to set `layer.trainable = False`\n+on those layers specifically after unfreezing the outer model, or otherwise\n+call the model with `training=False` to keep it inference mode.\n \n You'll see this pattern in action in the end-to-end example at the end of this guide.\n \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#79adef4527b072c602ad0d1f87af30ec70197007", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 18 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -28,7 +28,7 @@ class AdditiveAttention(Attention):\n         dropout: Float between 0 and 1. Fraction of the units to drop for the\n             attention scores. Defaults to `0.0`.\n \n-    Call Args:\n+    Call arguments:\n         inputs: List of the following tensors:\n             - `query`: Query tensor of shape `(batch_size, Tq, dim)`.\n             - `value`: Value tensor of shape `(batch_size, Tv, dim)`.\n\n@@ -33,7 +33,7 @@ class Attention(Layer):\n             query and key vectors. `\"concat\"` refers to the hyperbolic tangent\n             of the concatenation of the `query` and `key` vectors.\n \n-    Call Args:\n+    Call arguments:\n         inputs: List of the following tensors:\n             - `query`: Query tensor of shape `(batch_size, Tq, dim)`.\n             - `value`: Value tensor of shape `(batch_size, Tv, dim)`.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4f7f85285acbb15b41f5ddf99722f5504879a1eb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 3 | Hunks: 3 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 6 | Churn Cumulative: 823 | Contributors (this commit): 12 | Commits (past 90d): 20 | Contributors (cumulative): 23 | DMM Complexity: 1.0\n\nDIFF:\n@@ -341,6 +341,8 @@ def fori_loop(lower, upper, body_fun, init_val):\n \n \n def stop_gradient(variable):\n+    if isinstance(variable, KerasVariable):\n+        variable = variable.value\n     return jax.lax.stop_gradient(variable)\n \n \n\n@@ -645,6 +645,8 @@ def fori_loop(lower, upper, body_fun, init_val):\n \n \n def stop_gradient(variable):\n+    if isinstance(variable, KerasVariable):\n+        variable = variable.value\n     # We can't use `.requires_grad_(False)` here since it only\n     # works when the tensor is a leaf node in the graph.\n     return variable.detach()\n\n@@ -565,7 +565,7 @@ class CoreOpsCorrectnessTest(testing.TestCase):\n                 self.b = self.add_weight(shape=(1,), initializer=\"zeros\")\n \n             def call(self, x, training=False):\n-                return x * ops.stop_gradient(self.w.value) + self.b\n+                return x * ops.stop_gradient(self.w) + self.b\n \n         model = models.Sequential([ExampleLayer()])\n         model.compile(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e80fe5bc1d18f0c8e566224880ca378b808866df", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 8 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -169,7 +169,7 @@ def softmax(x, axis=-1):\n def elu(x, alpha=1.0):\n     \"\"\"Exponential Linear Unit.\n \n-    The exponential linear unit (ELU) with `alpha > 0` is define as:\n+    The exponential linear unit (ELU) with `alpha > 0` is defined as:\n \n     - `x` if `x > 0`\n     - alpha * `exp(x) - 1` if `x < 0`\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d3671cf276d838599dd8acec9616845ac262d52a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 182 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -128,6 +128,9 @@ class Config:\n         self._raise_if_frozen()\n         return self._config.update(*args, **kwargs)\n     \n+    def get(self, keyname, value=None):\n+        return self._config.get(keyname, value)\n+\n     def __setattr__(self, name, value):\n         attrs = object.__getattribute__(self, \"__attrs__\")\n         if attrs is None or name in attrs:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#443284f57b1a105561f9774825784e835cc51048", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1748 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -351,7 +351,7 @@ def _compute_affine_transform_coordinates(image, transform):\n     # transform the indices\n     coordinates = np.einsum(\"Bhwij, Bjk -> Bhwik\", indices, transform)\n     coordinates = np.moveaxis(coordinates, source=-1, destination=1)\n-    coordinates += np.reshape(a=offset, newshape=(*offset.shape, 1, 1, 1))\n+    coordinates += np.reshape(offset, newshape=(*offset.shape, 1, 1, 1))\n     if need_squeeze:\n         coordinates = np.squeeze(coordinates, axis=0)\n     return coordinates\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a71ba9681b4091c5024ded666442add493513b37", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 18 | Files Changed: 2 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/7 | Churn Δ: 46 | Churn Cumulative: 70 | Contributors (this commit): 1 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,24 +1,10 @@\n-import weakref\n-\n-from keras.src.backend.common import global_state\n+from keras.src.backend.common.tensor_attributes import get_tensor_attr\n+from keras.src.backend.common.tensor_attributes import set_tensor_attr\n \n \n def set_keras_mask(x, mask):\n-    try:\n-        x._keras_mask = mask\n-    except AttributeError:\n-        if mask is None:\n-            return\n-        mask_dict = global_state.get_global_attribute(\"keras_mask_dict\")\n-        if mask_dict is None:\n-            mask_dict = weakref.WeakValueDictionary()\n-            global_state.set_global_attribute(\"keras_mask_dict\", mask_dict)\n-        mask_dict[id(x)] = mask\n+    return set_tensor_attr(x, \"_keras_mask\", mask)\n \n \n def get_keras_mask(x):\n-    if not hasattr(x, \"_keras_mask\"):\n-        mask_dict = global_state.get_global_attribute(\"keras_mask_dict\")\n-        if mask_dict is not None:\n-            return mask_dict.get(id(x), None)\n-    return getattr(x, \"_keras_mask\", None)\n+    return get_tensor_attr(x, \"_keras_mask\")\n\n@@ -0,0 +1,24 @@\n+import weakref\n+\n+from keras.src.backend.common import global_state\n+\n+\n+def set_tensor_attr(tensor, attr, value):\n+    try:\n+        setattr(tensor, \"_keras_mask\", value)\n+    except AttributeError:\n+        if value is None:\n+            return\n+        attr_dict = global_state.get_global_attribute(f\"{attr}_dict\")\n+        if attr_dict is None:\n+            attr_dict = weakref.WeakValueDictionary()\n+            global_state.set_global_attribute(f\"{attr}_dict\", attr_dict)\n+        attr_dict[id(tensor)] = value\n+\n+\n+def get_tensor_attr(tensor, attr):\n+    if not hasattr(tensor, attr):\n+        attr_dict = global_state.get_global_attribute(f\"{attr}_dict\")\n+        if attr_dict is not None:\n+            return attr_dict.get(id(tensor), None)\n+    return getattr(tensor, attr, None)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#623641a32697a3c1c9f40abee8de9c769a953d92", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 5 | Churn Cumulative: 1285 | Contributors (this commit): 2 | Commits (past 90d): 14 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -109,9 +109,6 @@ class KerasFileEditor:\n \n     def summary(self):\n         \"\"\"Prints the weight structure of the opened file.\"\"\"\n-        if is_ipython_notebook():\n-            self._weights_summary_interactive()\n-        else:\n         self._weights_summary_cli()\n \n     def compare_to(self, reference_model):\n@@ -561,7 +558,7 @@ class KerasFileEditor:\n                         f'<details style=\"margin-left: {margin_left}px;\">'\n                         + '<summary style=\"'\n                         + f\"font-size: {font_size}em; \"\n-                        + \"font-weight: 'bold';\"\n+                        + \"font-weight: bold;\"\n                         + f'\">{key}</summary>'\n                         + _generate_html_weights(\n                             value, margin_left + 20, font_size - 1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#084b7e113d0aa9984af5318e29a19d235c19de6f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 26 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -5,7 +5,7 @@ from keras.src.backend.common import global_state\n \n def set_tensor_attr(tensor, attr, value):\n     try:\n-        setattr(tensor, \"_keras_mask\", value)\n+        setattr(tensor, attr, value)\n     except AttributeError:\n         if value is None:\n             return\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#08910e26bf1e3973e22ca29fbc8f2b700bbddd0c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 241 | Lines Deleted: 0 | Files Changed: 8 | Hunks: 8 | Methods Changed: 17 | Complexity Δ (Sum/Max): 33/19 | Churn Δ: 241 | Churn Cumulative: 1606 | Contributors (this commit): 13 | Commits (past 90d): 36 | Contributors (cumulative): 51 | DMM Complexity: 0.7676056338028169\n\nDIFF:\n@@ -47,6 +47,7 @@ from keras.src.ops.math import erfinv\n from keras.src.ops.math import extract_sequences\n from keras.src.ops.math import fft\n from keras.src.ops.math import fft2\n+from keras.src.ops.math import histogram\n from keras.src.ops.math import in_top_k\n from keras.src.ops.math import irfft\n from keras.src.ops.math import istft\n\n@@ -47,6 +47,7 @@ from keras.src.ops.math import erfinv\n from keras.src.ops.math import extract_sequences\n from keras.src.ops.math import fft\n from keras.src.ops.math import fft2\n+from keras.src.ops.math import histogram\n from keras.src.ops.math import in_top_k\n from keras.src.ops.math import irfft\n from keras.src.ops.math import istft\n\n@@ -294,3 +294,7 @@ def logdet(x):\n     # `np.log(np.linalg.det(x))`. See\n     # https://numpy.org/doc/stable/reference/generated/numpy.linalg.slogdet.html\n     return slogdet(x)[1]\n+\n+\n+def histogram(x, bins, range):\n+    return jnp.histogram(x, bins=bins, range=range)\n\n@@ -316,3 +316,7 @@ def logdet(x):\n     # In NumPy slogdet is more stable than `np.log(np.linalg.det(x))`. See\n     # https://numpy.org/doc/stable/reference/generated/numpy.linalg.slogdet.html\n     return slogdet(x)[1]\n+\n+\n+def histogram(x, bins, range):\n+    return np.histogram(x, bins=bins, range=range)\n\n@@ -370,3 +370,31 @@ def norm(x, ord=None, axis=None, keepdims=False):\n def logdet(x):\n     x = convert_to_tensor(x)\n     return tf.linalg.logdet(x)\n+\n+\n+def histogram(x, bins, range):\n+    \"\"\"\n+    Computes a histogram of the data tensor `x` using TensorFlow.\n+    The `tf.histogram_fixed_width()` and `tf.histogram_fixed_width_bins()`\n+    methods yielded slight numerical differences on some edge cases.\n+    \"\"\"\n+\n+    x = tf.convert_to_tensor(x, dtype=x.dtype)\n+\n+    # Handle the range argument\n+    if range is None:\n+        min_val = tf.reduce_min(x)\n+        max_val = tf.reduce_max(x)\n+    else:\n+        min_val, max_val = range\n+\n+    x = tf.boolean_mask(x, (x >= min_val) & (x <= max_val))\n+    bin_edges = tf.linspace(min_val, max_val, bins + 1)\n+    bin_edges_list = bin_edges.numpy().tolist()\n+    bin_indices = tf.raw_ops.Bucketize(input=x, boundaries=bin_edges_list[1:-1])\n+\n+    bin_counts = tf.math.bincount(\n+        bin_indices, minlength=bins, maxlength=bins, dtype=x.dtype\n+    )\n+\n+    return bin_counts, bin_edges\n\n@@ -419,3 +419,8 @@ def norm(x, ord=None, axis=None, keepdims=False):\n def logdet(x):\n     x = convert_to_tensor(x)\n     return torch.logdet(x)\n+\n+\n+def histogram(x, bins, range):\n+    hist_result = torch.histogram(x, bins=bins, range=range)\n+    return hist_result.hist, hist_result.bin_edges\n\n@@ -971,3 +971,89 @@ def logdet(x):\n     if any_symbolic_tensors((x,)):\n         return Logdet().symbolic_call(x)\n     return backend.math.logdet(x)\n+\n+\n+class Histogram(Operation):\n+    def __init__(self, bins=10, range=None):\n+        super().__init__()\n+\n+        if not isinstance(bins, int):\n+            raise TypeError(\"bins must be of type `int`\")\n+        if bins < 0:\n+            raise ValueError(\"`bins` should be a non-negative integer\")\n+\n+        if range:\n+            if len(range) < 2 or not isinstance(range, tuple):\n+                raise ValueError(\"range must be a tuple of two elements\")\n+\n+            if range[1] < range[0]:\n+                raise ValueError(\n+                    \"The second element of range must be greater than the first\"\n+                )\n+\n+        self.bins = bins\n+        self.range = range\n+\n+    def call(self, x):\n+        x = backend.convert_to_tensor(x)\n+        if len(x.shape) > 1:\n+            raise ValueError(\"Input tensor must be 1-dimensional\")\n+        return backend.math.histogram(x, bins=self.bins, range=self.range)\n+\n+    def compute_output_spec(self, x):\n+        return (\n+            KerasTensor(shape=(self.bins,), dtype=x.dtype),\n+            KerasTensor(shape=(self.bins + 1,), dtype=x.dtype),\n+        )\n+\n+\n+@keras_export(\"keras.ops.histogram\")\n+def histogram(x, bins=10, range=None):\n+    \"\"\"Computes a histogram of the data tensor `x`.\n+\n+    Args:\n+        x: Input tensor.\n+        bins: An integer representing the number of histogram bins.\n+            Defaults to 10.\n+        range: A tuple representing the lower and upper range of the bins.\n+            If not specified, it will use the min and max of `x`.\n+\n+    Returns:\n+        A tuple containing:\n+        - A tensor representing the counts of elements in each bin.\n+        - A tensor representing the bin edges.\n+\n+    Example:\n+\n+    ```\n+    >>> nput_tensor = np.random.rand(8)\n+    >>> keras.ops.histogram(input_tensor)\n+    (array([1, 1, 1, 0, 0, 1, 2, 1, 0, 1], dtype=int32),\n+    array([0.0189519 , 0.10294958, 0.18694726, 0.27094494, 0.35494262,\n+        0.43894029, 0.52293797, 0.60693565, 0.69093333, 0.77493101,\n+        0.85892869]))\n+    ```\n+\n+    \"\"\"\n+\n+    if not isinstance(bins, int):\n+        raise TypeError(\"bins must be of type `int`\")\n+    if bins < 0:\n+        raise ValueError(\"`bins` should be a non-negative integer\")\n+\n+    if range:\n+        if len(range) < 2 or not isinstance(range, tuple):\n+            raise ValueError(\"range must be a tuple of two elements\")\n+\n+        if range[1] < range[0]:\n+            raise ValueError(\n+                \"The second element of range must be greater than the first\"\n+            )\n+\n+    if any_symbolic_tensors((x,)):\n+        return Histogram(bins=bins, range=range).symbolic_call(x)\n+\n+    x = backend.convert_to_tensor(x)\n+    if len(x.shape) > 1:\n+        raise ValueError(\"Input tensor must be 1-dimensional\")\n+    return backend.math.histogram(x, bins=bins, range=range)\n\n@@ -1468,3 +1468,115 @@ class TestMathErrors(testing.TestCase):\n                 fft_length,\n                 window=incorrect_window,\n             )\n+\n+\n+class HistogramTest(testing.TestCase):\n+    def test_histogram_default_args(self):\n+        hist_op = kmath.histogram\n+        input_tensor = np.random.rand(8)\n+\n+        # Expected output\n+        expected_counts, expected_edges = np.histogram(input_tensor)\n+\n+        counts, edges = hist_op(input_tensor)\n+\n+        self.assertEqual(counts.shape, expected_counts.shape)\n+        self.assertAllClose(counts, expected_counts)\n+        self.assertEqual(edges.shape, expected_edges.shape)\n+        self.assertAllClose(edges, expected_edges)\n+\n+    def test_histogram_custom_bins(self):\n+        hist_op = kmath.histogram\n+        input_tensor = np.random.rand(8)\n+        bins = 5\n+\n+        # Expected output\n+        expected_counts, expected_edges = np.histogram(input_tensor, bins=bins)\n+\n+        counts, edges = hist_op(input_tensor, bins=bins)\n+\n+        self.assertEqual(counts.shape, expected_counts.shape)\n+        self.assertAllClose(counts, expected_counts)\n+        self.assertEqual(edges.shape, expected_edges.shape)\n+        self.assertAllClose(edges, expected_edges)\n+\n+    def test_histogram_custom_range(self):\n+        hist_op = kmath.histogram\n+        input_tensor = np.random.rand(10)\n+        range_specified = (2, 8)\n+\n+        # Expected output\n+        expected_counts, expected_edges = np.histogram(\n+            input_tensor, range=range_specified\n+        )\n+\n+        counts, edges = hist_op(input_tensor, range=range_specified)\n+\n+        self.assertEqual(counts.shape, expected_counts.shape)\n+        self.assertAllClose(counts, expected_counts)\n+        self.assertEqual(edges.shape, expected_edges.shape)\n+        self.assertAllClose(edges, expected_edges)\n+\n+    def test_histogram_symbolic_input(self):\n+        hist_op = kmath.histogram\n+        input_tensor = KerasTensor(shape=(None,), dtype=\"float32\")\n+\n+        counts, edges = hist_op(input_tensor)\n+\n+        self.assertEqual(counts.shape, (10,))\n+        self.assertEqual(edges.shape, (11,))\n+\n+    def test_histogram_non_integer_bins_raises_error(self):\n+        hist_op = kmath.histogram\n+        input_tensor = np.random.rand(8)\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \"`bins` should be a non-negative integer\"\n+        ):\n+            hist_op(input_tensor, bins=-5)\n+\n+    def test_histogram_range_validation(self):\n+        hist_op = kmath.histogram\n+        input_tensor = np.random.rand(8)\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \"range must be a tuple of two elements\"\n+        ):\n+            hist_op(input_tensor, range=(1,))\n+\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"The second element of range must be greater than the first\",\n+        ):\n+            hist_op(input_tensor, range=(5, 1))\n+\n+    def test_histogram_large_values(self):\n+        hist_op = kmath.histogram\n+        input_tensor = np.array([1e10, 2e10, 3e10, 4e10, 5e10])\n+\n+        counts, edges = hist_op(input_tensor, bins=5)\n+\n+        expected_counts, expected_edges = np.histogram(input_tensor, bins=5)\n+\n+        self.assertAllClose(counts, expected_counts)\n+        self.assertAllClose(edges, expected_edges)\n+\n+    def test_histogram_float_input(self):\n+        hist_op = kmath.histogram\n+        input_tensor = np.random.rand(8)\n+\n+        counts, edges = hist_op(input_tensor, bins=5)\n+\n+        expected_counts, expected_edges = np.histogram(input_tensor, bins=5)\n+\n+        self.assertAllClose(counts, expected_counts)\n+        self.assertAllClose(edges, expected_edges)\n+\n+    def test_histogram_high_dimensional_input(self):\n+        hist_op = kmath.histogram\n+        input_tensor = np.random.rand(3, 4, 5)\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \"Input tensor must be 1-dimensional\"\n+        ):\n+            hist_op(input_tensor)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#10710283d5a6d2c70b4d8b6cb0f146d7ed349033", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 259 | Lines Deleted: 241 | Files Changed: 18 | Hunks: 20 | Methods Changed: 34 | Complexity Δ (Sum/Max): 0/19 | Churn Δ: 500 | Churn Cumulative: 5999 | Contributors (this commit): 19 | Commits (past 90d): 98 | Contributors (cumulative): 116 | DMM Complexity: 0.0\n\nDIFF:\n@@ -160,6 +160,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_flip import (\n from keras.src.layers.preprocessing.image_preprocessing.random_rotation import (\n     RandomRotation,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_shear import (\n+    RandomShear,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_translation import (\n     RandomTranslation,\n )\n\n@@ -47,7 +47,6 @@ from keras.src.ops.math import erfinv\n from keras.src.ops.math import extract_sequences\n from keras.src.ops.math import fft\n from keras.src.ops.math import fft2\n-from keras.src.ops.math import histogram\n from keras.src.ops.math import in_top_k\n from keras.src.ops.math import irfft\n from keras.src.ops.math import istft\n@@ -160,6 +159,7 @@ from keras.src.ops.numpy import full_like\n from keras.src.ops.numpy import get_item\n from keras.src.ops.numpy import greater\n from keras.src.ops.numpy import greater_equal\n+from keras.src.ops.numpy import histogram\n from keras.src.ops.numpy import hstack\n from keras.src.ops.numpy import identity\n from keras.src.ops.numpy import imag\n\n@@ -70,6 +70,7 @@ from keras.src.ops.numpy import full_like\n from keras.src.ops.numpy import get_item\n from keras.src.ops.numpy import greater\n from keras.src.ops.numpy import greater_equal\n+from keras.src.ops.numpy import histogram\n from keras.src.ops.numpy import hstack\n from keras.src.ops.numpy import identity\n from keras.src.ops.numpy import imag\n\n@@ -160,6 +160,9 @@ from keras.src.layers.preprocessing.image_preprocessing.random_flip import (\n from keras.src.layers.preprocessing.image_preprocessing.random_rotation import (\n     RandomRotation,\n )\n+from keras.src.layers.preprocessing.image_preprocessing.random_shear import (\n+    RandomShear,\n+)\n from keras.src.layers.preprocessing.image_preprocessing.random_translation import (\n     RandomTranslation,\n )\n\n@@ -47,7 +47,6 @@ from keras.src.ops.math import erfinv\n from keras.src.ops.math import extract_sequences\n from keras.src.ops.math import fft\n from keras.src.ops.math import fft2\n-from keras.src.ops.math import histogram\n from keras.src.ops.math import in_top_k\n from keras.src.ops.math import irfft\n from keras.src.ops.math import istft\n@@ -160,6 +159,7 @@ from keras.src.ops.numpy import full_like\n from keras.src.ops.numpy import get_item\n from keras.src.ops.numpy import greater\n from keras.src.ops.numpy import greater_equal\n+from keras.src.ops.numpy import histogram\n from keras.src.ops.numpy import hstack\n from keras.src.ops.numpy import identity\n from keras.src.ops.numpy import imag\n\n@@ -70,6 +70,7 @@ from keras.src.ops.numpy import full_like\n from keras.src.ops.numpy import get_item\n from keras.src.ops.numpy import greater\n from keras.src.ops.numpy import greater_equal\n+from keras.src.ops.numpy import histogram\n from keras.src.ops.numpy import hstack\n from keras.src.ops.numpy import identity\n from keras.src.ops.numpy import imag\n\n@@ -294,7 +294,3 @@ def logdet(x):\n     # `np.log(np.linalg.det(x))`. See\n     # https://numpy.org/doc/stable/reference/generated/numpy.linalg.slogdet.html\n     return slogdet(x)[1]\n-\n-\n-def histogram(x, bins, range):\n-    return jnp.histogram(x, bins=bins, range=range)\n\n@@ -1246,3 +1246,7 @@ def slogdet(x):\n \n def argpartition(x, kth, axis=-1):\n     return jnp.argpartition(x, kth, axis)\n+\n+\n+def histogram(x, bins, range):\n+    return jnp.histogram(x, bins=bins, range=range)\n\n@@ -316,7 +316,3 @@ def logdet(x):\n     # In NumPy slogdet is more stable than `np.log(np.linalg.det(x))`. See\n     # https://numpy.org/doc/stable/reference/generated/numpy.linalg.slogdet.html\n     return slogdet(x)[1]\n-\n-\n-def histogram(x, bins, range):\n-    return np.histogram(x, bins=bins, range=range)\n\n@@ -1177,3 +1177,7 @@ def slogdet(x):\n \n def argpartition(x, kth, axis=-1):\n     return np.argpartition(x, kth, axis).astype(\"int32\")\n+\n+\n+def histogram(x, bins, range):\n+    return np.histogram(x, bins=bins, range=range)\n\n@@ -370,31 +370,3 @@ def norm(x, ord=None, axis=None, keepdims=False):\n def logdet(x):\n     x = convert_to_tensor(x)\n     return tf.linalg.logdet(x)\n-\n-\n-def histogram(x, bins, range):\n-    \"\"\"\n-    Computes a histogram of the data tensor `x` using TensorFlow.\n-    The `tf.histogram_fixed_width()` and `tf.histogram_fixed_width_bins()`\n-    methods yielded slight numerical differences on some edge cases.\n-    \"\"\"\n-\n-    x = tf.convert_to_tensor(x, dtype=x.dtype)\n-\n-    # Handle the range argument\n-    if range is None:\n-        min_val = tf.reduce_min(x)\n-        max_val = tf.reduce_max(x)\n-    else:\n-        min_val, max_val = range\n-\n-    x = tf.boolean_mask(x, (x >= min_val) & (x <= max_val))\n-    bin_edges = tf.linspace(min_val, max_val, bins + 1)\n-    bin_edges_list = bin_edges.numpy().tolist()\n-    bin_indices = tf.raw_ops.Bucketize(input=x, boundaries=bin_edges_list[1:-1])\n-\n-    bin_counts = tf.math.bincount(\n-        bin_indices, minlength=bins, maxlength=bins, dtype=x.dtype\n-    )\n-\n-    return bin_counts, bin_edges\n\n@@ -2546,3 +2546,31 @@ def argpartition(x, kth, axis=-1):\n \n     out = tf.concat([bottom_ind, top_ind], axis=x.ndim - 1)\n     return swapaxes(out, -1, axis)\n+\n+\n+def histogram(x, bins, range):\n+    \"\"\"Computes a histogram of the data tensor `x`.\n+\n+    Note: the `tf.histogram_fixed_width()` and\n+    `tf.histogram_fixed_width_bins()` functions\n+    yield slight numerical differences for some edge cases.\n+    \"\"\"\n+\n+    x = tf.convert_to_tensor(x, dtype=x.dtype)\n+\n+    # Handle the range argument\n+    if range is None:\n+        min_val = tf.reduce_min(x)\n+        max_val = tf.reduce_max(x)\n+    else:\n+        min_val, max_val = range\n+\n+    x = tf.boolean_mask(x, (x >= min_val) & (x <= max_val))\n+    bin_edges = tf.linspace(min_val, max_val, bins + 1)\n+    bin_edges_list = bin_edges.numpy().tolist()\n+    bin_indices = tf.raw_ops.Bucketize(input=x, boundaries=bin_edges_list[1:-1])\n+\n+    bin_counts = tf.math.bincount(\n+        bin_indices, minlength=bins, maxlength=bins, dtype=x.dtype\n+    )\n+    return bin_counts, bin_edges\n\n@@ -419,8 +419,3 @@ def norm(x, ord=None, axis=None, keepdims=False):\n def logdet(x):\n     x = convert_to_tensor(x)\n     return torch.logdet(x)\n-\n-\n-def histogram(x, bins, range):\n-    hist_result = torch.histogram(x, bins=bins, range=range)\n-    return hist_result.hist, hist_result.bin_edges\n\n@@ -1701,3 +1701,8 @@ def argpartition(x, kth, axis=-1):\n     top_ind = torch.topk(proxy, x.shape[-1] - kth - 1)[1]\n     out = torch.cat([bottom_ind, top_ind], dim=x.dim() - 1)\n     return cast(torch.transpose(out, -1, axis), \"int32\")\n+\n+\n+def histogram(x, bins, range):\n+    hist_result = torch.histogram(x, bins=bins, range=range)\n+    return hist_result.hist, hist_result.bin_edges\n\n@@ -971,89 +971,3 @@ def logdet(x):\n     if any_symbolic_tensors((x,)):\n         return Logdet().symbolic_call(x)\n     return backend.math.logdet(x)\n-\n-\n-class Histogram(Operation):\n-    def __init__(self, bins=10, range=None):\n-        super().__init__()\n-\n-        if not isinstance(bins, int):\n-            raise TypeError(\"bins must be of type `int`\")\n-        if bins < 0:\n-            raise ValueError(\"`bins` should be a non-negative integer\")\n-\n-        if range:\n-            if len(range) < 2 or not isinstance(range, tuple):\n-                raise ValueError(\"range must be a tuple of two elements\")\n-\n-            if range[1] < range[0]:\n-                raise ValueError(\n-                    \"The second element of range must be greater than the first\"\n-                )\n-\n-        self.bins = bins\n-        self.range = range\n-\n-    def call(self, x):\n-        x = backend.convert_to_tensor(x)\n-        if len(x.shape) > 1:\n-            raise ValueError(\"Input tensor must be 1-dimensional\")\n-        return backend.math.histogram(x, bins=self.bins, range=self.range)\n-\n-    def compute_output_spec(self, x):\n-        return (\n-            KerasTensor(shape=(self.bins,), dtype=x.dtype),\n-            KerasTensor(shape=(self.bins + 1,), dtype=x.dtype),\n-        )\n-\n-\n-@keras_export(\"keras.ops.histogram\")\n-def histogram(x, bins=10, range=None):\n-    \"\"\"Computes a histogram of the data tensor `x`.\n-\n-    Args:\n-        x: Input tensor.\n-        bins: An integer representing the number of histogram bins.\n-            Defaults to 10.\n-        range: A tuple representing the lower and upper range of the bins.\n-            If not specified, it will use the min and max of `x`.\n-\n-    Returns:\n-        A tuple containing:\n-        - A tensor representing the counts of elements in each bin.\n-        - A tensor representing the bin edges.\n-\n-    Example:\n-\n-    ```\n-    >>> nput_tensor = np.random.rand(8)\n-    >>> keras.ops.histogram(input_tensor)\n-    (array([1, 1, 1, 0, 0, 1, 2, 1, 0, 1], dtype=int32),\n-    array([0.0189519 , 0.10294958, 0.18694726, 0.27094494, 0.35494262,\n-        0.43894029, 0.52293797, 0.60693565, 0.69093333, 0.77493101,\n-        0.85892869]))\n-    ```\n-\n-    \"\"\"\n-\n-    if not isinstance(bins, int):\n-        raise TypeError(\"bins must be of type `int`\")\n-    if bins < 0:\n-        raise ValueError(\"`bins` should be a non-negative integer\")\n-\n-    if range:\n-        if len(range) < 2 or not isinstance(range, tuple):\n-            raise ValueError(\"range must be a tuple of two elements\")\n-\n-        if range[1] < range[0]:\n-            raise ValueError(\n-                \"The second element of range must be greater than the first\"\n-            )\n-\n-    if any_symbolic_tensors((x,)):\n-        return Histogram(bins=bins, range=range).symbolic_call(x)\n-\n-    x = backend.convert_to_tensor(x)\n-    if len(x.shape) > 1:\n-        raise ValueError(\"Input tensor must be 1-dimensional\")\n-    return backend.math.histogram(x, bins=bins, range=range)\n\n@@ -1468,115 +1468,3 @@ class TestMathErrors(testing.TestCase):\n                 fft_length,\n                 window=incorrect_window,\n             )\n-\n-\n-class HistogramTest(testing.TestCase):\n-    def test_histogram_default_args(self):\n-        hist_op = kmath.histogram\n-        input_tensor = np.random.rand(8)\n-\n-        # Expected output\n-        expected_counts, expected_edges = np.histogram(input_tensor)\n-\n-        counts, edges = hist_op(input_tensor)\n-\n-        self.assertEqual(counts.shape, expected_counts.shape)\n-        self.assertAllClose(counts, expected_counts)\n-        self.assertEqual(edges.shape, expected_edges.shape)\n-        self.assertAllClose(edges, expected_edges)\n-\n-    def test_histogram_custom_bins(self):\n-        hist_op = kmath.histogram\n-        input_tensor = np.random.rand(8)\n-        bins = 5\n-\n-        # Expected output\n-        expected_counts, expected_edges = np.histogram(input_tensor, bins=bins)\n-\n-        counts, edges = hist_op(input_tensor, bins=bins)\n-\n-        self.assertEqual(counts.shape, expected_counts.shape)\n-        self.assertAllClose(counts, expected_counts)\n-        self.assertEqual(edges.shape, expected_edges.shape)\n-        self.assertAllClose(edges, expected_edges)\n-\n-    def test_histogram_custom_range(self):\n-        hist_op = kmath.histogram\n-        input_tensor = np.random.rand(10)\n-        range_specified = (2, 8)\n-\n-        # Expected output\n-        expected_counts, expected_edges = np.histogram(\n-            input_tensor, range=range_specified\n-        )\n-\n-        counts, edges = hist_op(input_tensor, range=range_specified)\n-\n-        self.assertEqual(counts.shape, expected_counts.shape)\n-        self.assertAllClose(counts, expected_counts)\n-        self.assertEqual(edges.shape, expected_edges.shape)\n-        self.assertAllClose(edges, expected_edges)\n-\n-    def test_histogram_symbolic_input(self):\n-        hist_op = kmath.histogram\n-        input_tensor = KerasTensor(shape=(None,), dtype=\"float32\")\n-\n-        counts, edges = hist_op(input_tensor)\n-\n-        self.assertEqual(counts.shape, (10,))\n-        self.assertEqual(edges.shape, (11,))\n-\n-    def test_histogram_non_integer_bins_raises_error(self):\n-        hist_op = kmath.histogram\n-        input_tensor = np.random.rand(8)\n-\n-        with self.assertRaisesRegex(\n-            ValueError, \"`bins` should be a non-negative integer\"\n-        ):\n-            hist_op(input_tensor, bins=-5)\n-\n-    def test_histogram_range_validation(self):\n-        hist_op = kmath.histogram\n-        input_tensor = np.random.rand(8)\n-\n-        with self.assertRaisesRegex(\n-            ValueError, \"range must be a tuple of two elements\"\n-        ):\n-            hist_op(input_tensor, range=(1,))\n-\n-        with self.assertRaisesRegex(\n-            ValueError,\n-            \"The second element of range must be greater than the first\",\n-        ):\n-            hist_op(input_tensor, range=(5, 1))\n-\n-    def test_histogram_large_values(self):\n-        hist_op = kmath.histogram\n-        input_tensor = np.array([1e10, 2e10, 3e10, 4e10, 5e10])\n-\n-        counts, edges = hist_op(input_tensor, bins=5)\n-\n-        expected_counts, expected_edges = np.histogram(input_tensor, bins=5)\n-\n-        self.assertAllClose(counts, expected_counts)\n-        self.assertAllClose(edges, expected_edges)\n-\n-    def test_histogram_float_input(self):\n-        hist_op = kmath.histogram\n-        input_tensor = np.random.rand(8)\n-\n-        counts, edges = hist_op(input_tensor, bins=5)\n-\n-        expected_counts, expected_edges = np.histogram(input_tensor, bins=5)\n-\n-        self.assertAllClose(counts, expected_counts)\n-        self.assertAllClose(edges, expected_edges)\n-\n-    def test_histogram_high_dimensional_input(self):\n-        hist_op = kmath.histogram\n-        input_tensor = np.random.rand(3, 4, 5)\n-\n-        with self.assertRaisesRegex(\n-            ValueError, \"Input tensor must be 1-dimensional\"\n-        ):\n-            hist_op(input_tensor)\n\n@@ -6611,3 +6611,99 @@ def argpartition(x, kth, axis=-1):\n     if any_symbolic_tensors((x,)):\n         return Argpartition(kth, axis).symbolic_call(x)\n     return backend.numpy.argpartition(x, kth, axis)\n+\n+\n+class Histogram(Operation):\n+    def __init__(self, bins=10, range=None):\n+        super().__init__()\n+\n+        if not isinstance(bins, int):\n+            raise TypeError(\"bins must be of type `int`\")\n+        if bins < 0:\n+            raise ValueError(\"`bins` should be a non-negative integer\")\n+\n+        if range:\n+            if len(range) < 2 or not isinstance(range, tuple):\n+                raise ValueError(\"range must be a tuple of two elements\")\n+\n+            if range[1] < range[0]:\n+                raise ValueError(\n+                    \"The second element of range must be greater than the first\"\n+                )\n+\n+        self.bins = bins\n+        self.range = range\n+\n+    def call(self, x):\n+        x = backend.convert_to_tensor(x)\n+        if len(x.shape) > 1:\n+            raise ValueError(\"Input tensor must be 1-dimensional\")\n+        return backend.math.histogram(x, bins=self.bins, range=self.range)\n+\n+    def compute_output_spec(self, x):\n+        return (\n+            KerasTensor(shape=(self.bins,), dtype=x.dtype),\n+            KerasTensor(shape=(self.bins + 1,), dtype=x.dtype),\n+        )\n+\n+\n+@keras_export([\"keras.ops.histogram\", \"keras.ops.numpy.histogram\"])\n+def histogram(x, bins=10, range=None):\n+    \"\"\"Computes a histogram of the data tensor `x`.\n+\n+    Args:\n+        x: Input tensor.\n+        bins: An integer representing the number of histogram bins.\n+            Defaults to 10.\n+        range: A tuple representing the lower and upper range of the bins.\n+            If not specified, it will use the min and max of `x`.\n+\n+    Returns:\n+        A tuple containing:\n+        - A tensor representing the counts of elements in each bin.\n+        - A tensor representing the bin edges.\n+\n+    Example:\n+\n+    ```\n+    >>> input_tensor = np.random.rand(8)\n+    >>> keras.ops.histogram(input_tensor)\n+    (array([1, 1, 1, 0, 0, 1, 2, 1, 0, 1], dtype=int32),\n+    array([0.0189519 , 0.10294958, 0.18694726, 0.27094494, 0.35494262,\n+        0.43894029, 0.52293797, 0.60693565, 0.69093333, 0.77493101,\n+        0.85892869]))\n+    ```\n+    \"\"\"\n+    if not isinstance(bins, int):\n+        raise TypeError(\n+            f\"Argument `bins` must be of type `int`. Received: bins={bins}\"\n+        )\n+    if bins < 0:\n+        raise ValueError(\n+            \"Argument `bins` should be a non-negative integer. \"\n+            f\"Received: bins={bins}\"\n+        )\n+\n+    if range:\n+        if len(range) < 2 or not isinstance(range, tuple):\n+            raise ValueError(\n+                \"Argument `range` must be a tuple of two elements. \"\n+                f\"Received: range={range}\"\n+            )\n+\n+        if range[1] < range[0]:\n+            raise ValueError(\n+                \"The second element of `range` must be greater than the first. \"\n+                f\"Received: range={range}\"\n+            )\n+\n+    if any_symbolic_tensors((x,)):\n+        return Histogram(bins=bins, range=range).symbolic_call(x)\n+\n+    x = backend.convert_to_tensor(x)\n+    if len(x.shape) > 1:\n+        raise ValueError(\n+            \"Input tensor must be 1-dimensional. \"\n+            f\"Received: input.shape={x.shape}\"\n+        )\n+    return backend.numpy.histogram(x, bins=bins, range=range)\n\n@@ -8332,3 +8332,115 @@ class NumpyDtypeTest(testing.TestCase):\n             standardize_dtype(knp.ZerosLike().symbolic_call(x).dtype),\n             expected_dtype,\n         )\n+\n+\n+class HistogramTest(testing.TestCase):\n+    def test_histogram_default_args(self):\n+        hist_op = knp.histogram\n+        input_tensor = np.random.rand(8)\n+\n+        # Expected output\n+        expected_counts, expected_edges = np.histogram(input_tensor)\n+\n+        counts, edges = hist_op(input_tensor)\n+\n+        self.assertEqual(counts.shape, expected_counts.shape)\n+        self.assertAllClose(counts, expected_counts)\n+        self.assertEqual(edges.shape, expected_edges.shape)\n+        self.assertAllClose(edges, expected_edges)\n+\n+    def test_histogram_custom_bins(self):\n+        hist_op = knp.histogram\n+        input_tensor = np.random.rand(8)\n+        bins = 5\n+\n+        # Expected output\n+        expected_counts, expected_edges = np.histogram(input_tensor, bins=bins)\n+\n+        counts, edges = hist_op(input_tensor, bins=bins)\n+\n+        self.assertEqual(counts.shape, expected_counts.shape)\n+        self.assertAllClose(counts, expected_counts)\n+        self.assertEqual(edges.shape, expected_edges.shape)\n+        self.assertAllClose(edges, expected_edges)\n+\n+    def test_histogram_custom_range(self):\n+        hist_op = knp.histogram\n+        input_tensor = np.random.rand(10)\n+        range_specified = (2, 8)\n+\n+        # Expected output\n+        expected_counts, expected_edges = np.histogram(\n+            input_tensor, range=range_specified\n+        )\n+\n+        counts, edges = hist_op(input_tensor, range=range_specified)\n+\n+        self.assertEqual(counts.shape, expected_counts.shape)\n+        self.assertAllClose(counts, expected_counts)\n+        self.assertEqual(edges.shape, expected_edges.shape)\n+        self.assertAllClose(edges, expected_edges)\n+\n+    def test_histogram_symbolic_input(self):\n+        hist_op = knp.histogram\n+        input_tensor = KerasTensor(shape=(None,), dtype=\"float32\")\n+\n+        counts, edges = hist_op(input_tensor)\n+\n+        self.assertEqual(counts.shape, (10,))\n+        self.assertEqual(edges.shape, (11,))\n+\n+    def test_histogram_non_integer_bins_raises_error(self):\n+        hist_op = knp.histogram\n+        input_tensor = np.random.rand(8)\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \"Argument `bins` should be a non-negative integer\"\n+        ):\n+            hist_op(input_tensor, bins=-5)\n+\n+    def test_histogram_range_validation(self):\n+        hist_op = knp.histogram\n+        input_tensor = np.random.rand(8)\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \"Argument `range` must be a tuple of two elements\"\n+        ):\n+            hist_op(input_tensor, range=(1,))\n+\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"The second element of `range` must be greater than the first\",\n+        ):\n+            hist_op(input_tensor, range=(5, 1))\n+\n+    def test_histogram_large_values(self):\n+        hist_op = knp.histogram\n+        input_tensor = np.array([1e10, 2e10, 3e10, 4e10, 5e10])\n+\n+        counts, edges = hist_op(input_tensor, bins=5)\n+\n+        expected_counts, expected_edges = np.histogram(input_tensor, bins=5)\n+\n+        self.assertAllClose(counts, expected_counts)\n+        self.assertAllClose(edges, expected_edges)\n+\n+    def test_histogram_float_input(self):\n+        hist_op = knp.histogram\n+        input_tensor = np.random.rand(8)\n+\n+        counts, edges = hist_op(input_tensor, bins=5)\n+\n+        expected_counts, expected_edges = np.histogram(input_tensor, bins=5)\n+\n+        self.assertAllClose(counts, expected_counts)\n+        self.assertAllClose(edges, expected_edges)\n+\n+    def test_histogram_high_dimensional_input(self):\n+        hist_op = knp.histogram\n+        input_tensor = np.random.rand(3, 4, 5)\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \"Input tensor must be 1-dimensional\"\n+        ):\n+            hist_op(input_tensor)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
