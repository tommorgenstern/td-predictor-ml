{"custom_id": "keras#281bc587b38b91abd3a2af41fb43848dd38b042c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 11 | Churn Cumulative: 2649 | Contributors (this commit): 11 | Commits (past 90d): 20 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1629,7 +1629,7 @@ def categorical_crossentropy(target, output, from_logits=False):\n def sparse_categorical_crossentropy(target, output, from_logits=False):\n     target = C.one_hot(target, output.shape[-1])\n     target = C.reshape(target, output.shape)\n-    return categorical_crossentropy(output, target, from_logits)\n+    return categorical_crossentropy(target, output, from_logits)\n \n \n class Function(object):\n\n@@ -57,5 +57,14 @@ def test_categorical_hinge():\n     assert np.isclose(expected_loss, np.mean(loss))\n \n \n+def test_sparse_categorical_crossentropy():\n+    y_pred = K.variable(np.array([[0.3, 0.6, 0.1],\n+                                  [0.1, 0.2, 0.7]]))\n+    y_true = K.variable(np.array([1, 2]))\n+    expected_loss = - (np.log(0.6) + np.log(0.7)) / 2\n+    loss = K.eval(losses.sparse_categorical_crossentropy(y_true, y_pred))\n+    assert np.isclose(expected_loss, np.mean(loss))\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#eeee45877cea31ce83427b08565e35238ed4edb3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 30 | Churn Cumulative: 242 | Contributors (this commit): 5 | Commits (past 90d): 1 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -29,6 +29,18 @@ def test_merge_add():\n     assert out.shape == (2, 4, 5)\n     assert_allclose(out, x1 + x2 + x3, atol=1e-4)\n \n+    assert add_layer.compute_mask([i1, i2, i3], [None, None, None]) is None\n+    assert np.all(K.eval(add_layer.compute_mask(\n+        [i1, i2, i3], [K.variable(x1), K.variable(x2), K.variable(x3)])))\n+\n+    # Test invalid use case\n+    with pytest.raises(ValueError):\n+        add_layer.compute_mask([i1, i2, i3], x1)\n+    with pytest.raises(ValueError):\n+        add_layer.compute_mask(i1, [None, None, None])\n+    with pytest.raises(ValueError):\n+        add_layer.compute_mask([i1, i2, i3], [None, None])\n+\n \n @keras_test\n def test_merge_multiply():\n@@ -91,6 +103,12 @@ def test_merge_maximum():\n \n @keras_test\n def test_merge_concatenate():\n+    i1 = layers.Input(shape=(None, 5))\n+    i2 = layers.Input(shape=(None, 5))\n+    o = layers.concatenate([i1, i2], axis=1)\n+    assert o._keras_shape == (None, None, 5)\n+    model = models.Model([i1, i2], o)\n+\n     i1 = layers.Input(shape=(4, 5))\n     i2 = layers.Input(shape=(4, 5))\n     o = layers.concatenate([i1, i2], axis=1)\n@@ -121,6 +139,18 @@ def test_merge_concatenate():\n     assert concat_out.shape == (1, 16, 1)\n     assert_allclose(concat_out, x3)\n \n+    assert concat_layer.compute_mask([i1, i2], [None, None]) is None\n+    assert np.all(K.eval(concat_layer.compute_mask(\n+        [i1, i2], [K.variable(x1), K.variable(x2)])).reshape(-1))\n+\n+    # Test invalid use case\n+    with pytest.raises(ValueError):\n+        concat_layer.compute_mask([i1, i2], x1)\n+    with pytest.raises(ValueError):\n+        concat_layer.compute_mask(i1, [None, None])\n+    with pytest.raises(ValueError):\n+        concat_layer.compute_mask([i1, i2], [None])\n+\n \n @keras_test\n def test_merge_dot():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#39d019917c3919120ee6073ed945b83f87e226c4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 47 | Lines Deleted: 114 | Files Changed: 1 | Hunks: 19 | Methods Changed: 4 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 161 | Churn Cumulative: 2855 | Contributors (this commit): 13 | Commits (past 90d): 18 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -463,162 +463,95 @@ class TestBackend(object):\n \n     def test_rnn(self):\n         # implement a simple RNN\n-        input_dim = 8\n-        output_dim = 4\n-        timesteps = 5\n+        num_samples = 4\n+        input_dim = 5\n+        output_dim = 3\n+        timesteps = 6\n \n-        input_val = np.random.random((32, timesteps, input_dim))\n-        init_state_val = np.random.random((32, output_dim))\n-        W_i_val = np.random.random((input_dim, output_dim))\n-        W_o_val = np.random.random((output_dim, output_dim))\n+        input_val = np.random.random((num_samples, timesteps, input_dim)).astype(np.float32)\n+        init_state_val = np.random.random((num_samples, output_dim)).astype(np.float32)\n+        W_i_val = np.random.random((input_dim, output_dim)).astype(np.float32)\n+        W_o_val = np.random.random((output_dim, output_dim)).astype(np.float32)\n+        np_mask = np.random.randint(2, size=(num_samples, timesteps))\n \n-        def rnn_step_fn(input_dim, output_dim, K):\n-            W_i = K.variable(W_i_val)\n-            W_o = K.variable(W_o_val)\n+        def rnn_step_fn(input_dim, output_dim, k):\n+            W_i = k.variable(W_i_val)\n+            W_o = k.variable(W_o_val)\n \n             def step_function(x, states):\n                 assert len(states) == 1\n                 prev_output = states[0]\n-                output = K.dot(x, W_i) + K.dot(prev_output, W_o)\n+                output = k.dot(x, W_i) + k.dot(prev_output, W_o)\n                 return output, [output]\n \n             return step_function\n \n         # test default setup\n-        last_output_list = []\n-        outputs_list = []\n-        state_list = []\n-\n-        unrolled_last_output_list = []\n-        unrolled_outputs_list = []\n-        unrolled_states_list = []\n-\n-        backwards_last_output_list = []\n-        backwards_outputs_list = []\n-        backwards_states_list = []\n-\n-        bwd_unrolled_last_output_list = []\n-        bwd_unrolled_outputs_list = []\n-        bwd_unrolled_states_list = []\n-\n-        masked_last_output_list = []\n-        masked_outputs_list = []\n-        masked_states_list = []\n-\n-        unrolled_masked_last_output_list = []\n-        unrolled_masked_outputs_list = []\n-        unrolled_masked_states_list = []\n+        last_output_list = [[], [], [], [], [], []]\n+        outputs_list = [[], [], [], [], [], []]\n+        state_list = [[], [], [], [], [], []]\n \n         for k in BACKENDS:\n             rnn_fn = rnn_step_fn(input_dim, output_dim, k)\n             inputs = k.variable(input_val)\n             initial_states = [k.variable(init_state_val)]\n-            last_output, outputs, new_states = k.rnn(rnn_fn, inputs,\n-                                                     initial_states,\n-                                                     go_backwards=False,\n-                                                     mask=None)\n-\n-            last_output_list.append(k.eval(last_output))\n-            outputs_list.append(k.eval(outputs))\n-            assert len(new_states) == 1\n-            state_list.append(k.eval(new_states[0]))\n-            # test unroll\n-            unrolled_last_output, unrolled_outputs, unrolled_new_states = k.rnn(\n-                rnn_fn, inputs,\n-                initial_states,\n-                go_backwards=False,\n-                mask=None,\n-                unroll=True,\n-                input_length=timesteps)\n-\n-            unrolled_last_output_list.append(k.eval(unrolled_last_output))\n-            unrolled_outputs_list.append(k.eval(unrolled_outputs))\n-            assert len(unrolled_new_states) == 1\n-            unrolled_states_list.append(k.eval(unrolled_new_states[0]))\n-\n-            backwards_last_output, backwards_outputs, backwards_new_states = k.rnn(rnn_fn, inputs,\n-                                                                                   initial_states,\n-                                                                                   go_backwards=True,\n-                                                                                   mask=None)\n-            backwards_last_output_list.append(k.eval(backwards_last_output))\n-            backwards_outputs_list.append(k.eval(backwards_outputs))\n-            assert len(backwards_new_states) == 1\n-            backwards_states_list.append(k.eval(backwards_new_states[0]))\n-\n-            bwd_unrolled_last_output, bwd_unrolled_outputs, bwd_unrolled_new_states = k.rnn(\n-                rnn_fn, inputs,\n-                initial_states,\n-                go_backwards=True,\n-                mask=None,\n-                unroll=True,\n-                input_length=timesteps)\n-\n-            bwd_unrolled_last_output_list.append(k.eval(bwd_unrolled_last_output))\n-            bwd_unrolled_outputs_list.append(k.eval(bwd_unrolled_outputs))\n-            assert len(bwd_unrolled_new_states) == 1\n-            bwd_unrolled_states_list.append(k.eval(bwd_unrolled_new_states[0]))\n-\n-            np_mask = np.random.randint(2, size=(32, timesteps))\n             mask = k.variable(np_mask)\n \n-            masked_last_output, masked_outputs, masked_new_states = k.rnn(\n-                rnn_fn, inputs,\n+            kwargs_list = [\n+                {'go_backwards': False, 'mask': None},\n+                {'go_backwards': False, 'mask': None, 'unroll': True, 'input_length': timesteps},\n+                {'go_backwards': True, 'mask': None},\n+                {'go_backwards': True, 'mask': None, 'unroll': True, 'input_length': timesteps},\n+                {'go_backwards': False, 'mask': mask},\n+                {'go_backwards': False, 'mask': mask, 'unroll': True, 'input_length': timesteps},\n+            ]\n+\n+            for (i, kwargs) in enumerate(kwargs_list):\n+                last_output, outputs, new_states = k.rnn(rnn_fn, inputs,\n                                                          initial_states,\n-                go_backwards=False,\n-                mask=mask)\n-            masked_last_output_list.append(k.eval(masked_last_output))\n-            masked_outputs_list.append(k.eval(masked_outputs))\n-            assert len(masked_new_states) == 1\n-            masked_states_list.append(k.eval(masked_new_states[0]))\n+                                                         **kwargs)\n \n-            unrolled_masked_last_output, unrolled_masked_outputs, unrolled_masked_new_states = k.rnn(\n-                rnn_fn, inputs,\n-                initial_states,\n-                go_backwards=False,\n-                mask=mask,\n-                unroll=True,\n-                input_length=timesteps)\n-            unrolled_masked_last_output_list.append(k.eval(unrolled_masked_last_output))\n-            unrolled_masked_outputs_list.append(k.eval(unrolled_masked_outputs))\n-            assert len(unrolled_masked_new_states) == 1\n-            unrolled_masked_states_list.append(k.eval(unrolled_masked_new_states[0]))\n+                last_output_list[i].append(k.eval(last_output))\n+                outputs_list[i].append(k.eval(outputs))\n+                assert len(new_states) == 1\n+                state_list[i].append(k.eval(new_states[0]))\n \n-        assert_list_pairwise(last_output_list, shape=False, atol=1e-04)\n-        assert_list_pairwise(outputs_list, shape=False, atol=1e-04)\n-        assert_list_pairwise(state_list, shape=False, atol=1e-04)\n-        assert_list_pairwise(backwards_states_list, shape=False, atol=1e-04)\n-        assert_list_pairwise(backwards_last_output_list, shape=False, atol=1e-04)\n-        assert_list_pairwise(backwards_outputs_list, shape=False, atol=1e-04)\n+        assert_list_pairwise(last_output_list[0], shape=False, atol=1e-04)\n+        assert_list_pairwise(outputs_list[0], shape=False, atol=1e-04)\n+        assert_list_pairwise(state_list[0], shape=False, atol=1e-04)\n+        assert_list_pairwise(last_output_list[2], shape=False, atol=1e-04)\n+        assert_list_pairwise(outputs_list[2], shape=False, atol=1e-04)\n+        assert_list_pairwise(state_list[2], shape=False, atol=1e-04)\n \n-        for l, u_l in zip(last_output_list, unrolled_last_output_list):\n+        for l, u_l in zip(last_output_list[0], last_output_list[1]):\n             assert_allclose(l, u_l, atol=1e-04)\n \n-        for o, u_o in zip(outputs_list, unrolled_outputs_list):\n+        for o, u_o in zip(outputs_list[0], outputs_list[1]):\n             assert_allclose(o, u_o, atol=1e-04)\n \n-        for s, u_s in zip(state_list, unrolled_states_list):\n+        for s, u_s in zip(state_list[0], state_list[1]):\n             assert_allclose(s, u_s, atol=1e-04)\n \n-        for b_l, b_u_l in zip(backwards_last_output_list, bwd_unrolled_last_output_list):\n+        for b_l, b_u_l in zip(last_output_list[2], last_output_list[3]):\n             assert_allclose(b_l, b_u_l, atol=1e-04)\n \n-        for b_o, b_u_o, in zip(backwards_outputs_list, bwd_unrolled_outputs_list):\n+        for b_o, b_u_o in zip(outputs_list[2], outputs_list[3]):\n             assert_allclose(b_o, b_u_o, atol=1e-04)\n \n-        for b_s, b_u_s in zip(backwards_states_list, bwd_unrolled_states_list):\n+        for b_s, b_u_s in zip(state_list[2], state_list[3]):\n             assert_allclose(b_s, b_u_s, atol=1e-04)\n \n-        for m_l, u_m_l, k in zip(masked_last_output_list, unrolled_masked_last_output_list, BACKENDS):\n+        for m_l, u_m_l, k in zip(last_output_list[4], last_output_list[5], BACKENDS):\n             # skip this compare on tensorflow\n             if k != KTF:\n                 assert_allclose(m_l, u_m_l, atol=1e-04)\n \n-        for m_o, u_m_o, k in zip(masked_outputs_list, unrolled_masked_outputs_list, BACKENDS):\n+        for m_o, u_m_o, k in zip(outputs_list[4], outputs_list[5], BACKENDS):\n             # skip this compare on tensorflow\n             if k != KTF:\n                 assert_allclose(m_o, u_m_o, atol=1e-04)\n \n-        for m_s, u_m_s, k in zip(masked_states_list, unrolled_masked_states_list, BACKENDS):\n+        for m_s, u_m_s, k in zip(state_list[4], state_list[5], BACKENDS):\n             if k != KTF:\n                 assert_allclose(m_s, u_m_s, atol=1e-04)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#81ab7573565e3f3d09a077945f4ab2659c9c48d9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 13 | Churn Cumulative: 5455 | Contributors (this commit): 17 | Commits (past 90d): 37 | Contributors (cumulative): 22 | DMM Complexity: 0.6666666666666666\n\nDIFF:\n@@ -953,6 +953,9 @@ def normalize_batch_in_training(x, gamma, beta,\n         for axis in range(1, ndim(x)):\n             if axis in reduction_axes:\n                 target_shape.append(1)\n+                if ndim(gamma) > axis:\n+                    gamma = C.reduce_mean(gamma, axis - 1)\n+                    beta = C.reduce_mean(beta, axis - 1)\n             else:\n                 target_shape.append(x_shape[axis])\n \n\n@@ -1022,15 +1022,21 @@ class TestBackend(object):\n                 x_shape = (1, 4) + shape\n             else:\n                 x_shape = (1,) + shape + (4,)\n-            xth = KTH.variable(np.random.random(x_shape))\n-            xtf = KTF.variable(np.random.random(x_shape))\n+            x_val = np.random.random(x_shape).astype(np.float32)\n+            xth = KTH.variable(x_val)\n+            xtf = KTF.variable(x_val)\n+            xc = KC.placeholder(x_shape)\n             zth, _, _ = KTH.normalize_batch_in_training(xth, None, None,\n                                                         reduction_axes='per-activation')\n             ztf, _, _ = KTF.normalize_batch_in_training(xtf, None, None,\n                                                         reduction_axes=[0, 1, 2, 3])\n+            zc, _, _ = KC.normalize_batch_in_training(xc, None, None,\n+                                                      reduction_axes=[0, 1, 2, 3])\n             zth = KTH.eval(zth)\n             ztf = KTF.eval(ztf)\n+            zc = KC.function([xc], [zc])([x_val])[0]\n             assert zth.shape == ztf.shape\n+            assert zth.shape == zc.shape\n \n     def test_ctc(self):\n         # simplified version of TensorFlow's test\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e0fefdae0cae9c97f318fca9717467f7faf071d9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 17 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): -7/0 | Churn Δ: 28 | Churn Cumulative: 8411 | Contributors (this commit): 87 | Commits (past 90d): 32 | Contributors (cumulative): 87 | DMM Complexity: 1.0\n\nDIFF:\n@@ -192,24 +192,18 @@ def _convert_string_dtype(dtype):\n     # Raises\n         ValueError: if `dtype` is not supported.\n     \"\"\"\n-    if dtype == 'float16':\n-        return tf.float16\n-    if dtype == 'float32':\n-        return tf.float32\n-    elif dtype == 'float64':\n-        return tf.float64\n-    elif dtype == 'int16':\n-        return tf.int16\n-    elif dtype == 'int32':\n-        return tf.int32\n-    elif dtype == 'int64':\n-        return tf.int64\n-    elif dtype == 'uint8':\n-        return tf.int8\n-    elif dtype == 'uint16':\n-        return tf.uint16\n-    else:\n+    mapping = {'float16': tf.float16,\n+               'float32': tf.float32,\n+               'float64': tf.float64,\n+               'int16': tf.int16,\n+               'int32': tf.int32,\n+               'int64': tf.int64,\n+               'uint8': tf.int8,\n+               'uint16': tf.uint16}\n+\n+    if dtype not in mapping:\n         raise ValueError('Unsupported dtype:', dtype)\n+    return mapping[dtype]\n \n \n def _to_tensor(x, dtype):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a6679b7077ff102a83d2706fea671eaa3a0bf349", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 3 | Churn Cumulative: 2303 | Contributors (this commit): 33 | Commits (past 90d): 10 | Contributors (cumulative): 33 | DMM Complexity: 0.0\n\nDIFF:\n@@ -984,9 +984,6 @@ class DirectoryIterator(Iterator):\n         self.num_class = len(classes)\n         self.class_indices = dict(zip(classes, range(len(classes))))\n \n-        def _recursive_list(subpath):\n-            return sorted(os.walk(subpath, followlinks=follow_links), key=lambda tpl: tpl[0])\n-\n         pool = multiprocessing.pool.ThreadPool()\n         function_partial = partial(_count_valid_files_in_directory,\n                                    white_list_formats=white_list_formats,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1d176e261469651067221448ee27c9b83abd1cc7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 12263 | Contributors (this commit): 70 | Commits (past 90d): 12 | Contributors (cumulative): 70 | DMM Complexity: None\n\nDIFF:\n@@ -61,7 +61,7 @@ class Masking(Layer):\n     def call(self, inputs):\n         boolean_mask = K.any(K.not_equal(inputs, self.mask_value),\n                              axis=-1, keepdims=True)\n-        return inputs * K.cast(boolean_mask, K.floatx())\n+        return inputs * K.cast(boolean_mask, inputs.dtype)\n \n     def get_config(self):\n         config = {'mask_value': self.mask_value}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b200b7d19c6b00a99bd890b925c1c0d887c1b303", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 582 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -18,6 +18,10 @@ class Initializer(object):\n \n     @classmethod\n     def from_config(cls, config):\n+        if 'dtype' in config:\n+            # Initializers saved from `tf.keras`\n+            # may contain an unused `dtype` argument.\n+            config.pop('dtype')\n         return cls(**config)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#552727ed8d9eb898a27afbba7c9fd292ca149474", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 99 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 99 | Churn Cumulative: 1046 | Contributors (this commit): 11 | Commits (past 90d): 4 | Contributors (cumulative): 15 | DMM Complexity: 1.0\n\nDIFF:\n@@ -211,6 +211,40 @@ class Add(_Merge):\n         return output\n \n \n+class Subtract(_Merge):\n+    \"\"\"Layer that subtracts two inputs.\n+\n+    It takes as input a list of tensors of size 2,\n+    both of the same shape, and returns a single tensor, (inputs[0] - inputs[1]),\n+    also of the same shape.\n+\n+    # Examples\n+\n+    ```python\n+        import keras\n+\n+        input1 = keras.layers.Input(shape=(16,))\n+        x1 = keras.layers.Dense(8, activation='relu')(input1)\n+        input2 = keras.layers.Input(shape=(32,))\n+        x2 = keras.layers.Dense(8, activation='relu')(input2)\n+        # Equivalent to subtracted = keras.layers.subtract([x1, x2])\n+        subtracted = keras.layers.Subtract()([x1, x2])\n+\n+        out = keras.layers.Dense(4)(subtracted)\n+        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n+    ```\n+    \"\"\"\n+\n+    def _merge_function(self, inputs):\n+        if len(inputs) != 2:\n+            raise ValueError('`Subtract` layer should be called '\n+                             'on exactly 2 inputs')\n+        if inputs[0]._keras_shape != inputs[1]._keras_shape:\n+            raise ValueError('`Subtract` layer should be called '\n+                             'on inputs of the same shape')\n+        return inputs[0] - inputs[1]\n+\n+\n class Multiply(_Merge):\n     \"\"\"Layer that multiplies (element-wise) a list of inputs.\n \n@@ -485,6 +519,34 @@ def add(inputs, **kwargs):\n     return Add(**kwargs)(inputs)\n \n \n+def subtract(inputs, **kwargs):\n+    \"\"\"Functional interface to the `Subtract` layer.\n+\n+    # Arguments\n+        inputs: A list of input tensors (exactly 2).\n+        **kwargs: Standard layer keyword arguments.\n+\n+    # Returns\n+        A tensor, the difference of the inputs.\n+\n+    # Examples\n+\n+    ```python\n+        import keras\n+\n+        input1 = keras.layers.Input(shape=(16,))\n+        x1 = keras.layers.Dense(8, activation='relu')(input1)\n+        input2 = keras.layers.Input(shape=(32,))\n+        x2 = keras.layers.Dense(8, activation='relu')(input2)\n+        subtracted = keras.layers.subtract([x1, x2])\n+\n+        out = keras.layers.Dense(4)(subtracted)\n+        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n+    ```\n+    \"\"\"\n+    return Subtract(**kwargs)(inputs)\n+\n+\n def multiply(inputs, **kwargs):\n     \"\"\"Functional interface to the `Multiply` layer.\n \n\n@@ -42,6 +42,43 @@ def test_merge_add():\n         add_layer.compute_mask([i1, i2, i3], [None, None])\n \n \n+@keras_test\n+def test_merge_subtract():\n+    i1 = layers.Input(shape=(4, 5))\n+    i2 = layers.Input(shape=(4, 5))\n+    i3 = layers.Input(shape=(4, 5))\n+    i4 = layers.Input(shape=(3, 5))\n+    o = layers.subtract([i1, i2])\n+    assert o._keras_shape == (None, 4, 5)\n+    model = models.Model([i1, i2], o)\n+\n+    subtract_layer = layers.Subtract()\n+    o2 = subtract_layer([i1, i2])\n+    assert subtract_layer.output_shape == (None, 4, 5)\n+\n+    x1 = np.random.random((2, 4, 5))\n+    x2 = np.random.random((2, 4, 5))\n+    out = model.predict([x1, x2])\n+    assert out.shape == (2, 4, 5)\n+    assert_allclose(out, x1 - x2, atol=1e-4)\n+\n+    assert subtract_layer.compute_mask([i1, i2], [None, None]) is None\n+    assert np.all(K.eval(subtract_layer.compute_mask(\n+        [i1, i2], [K.variable(x1), K.variable(x2)])))\n+\n+    # Test invalid use case\n+    with pytest.raises(ValueError):\n+        subtract_layer.compute_mask([i1, i2], x1)\n+    with pytest.raises(ValueError):\n+        subtract_layer.compute_mask(i1, [None, None])\n+    with pytest.raises(ValueError):\n+        subtract_layer([i1, i2, i3])\n+    with pytest.raises(ValueError):\n+        subtract_layer([i1])\n+    with pytest.raises(ValueError):\n+        subtract_layer([i1, i4])\n+\n+\n @keras_test\n def test_merge_multiply():\n     i1 = layers.Input(shape=(4, 5))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c2b844ba2fe8d0d597da9ef6a9af3b20d18d0bec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 5 | Complexity Δ (Sum/Max): 8/6 | Churn Δ: 35 | Churn Cumulative: 9619 | Contributors (this commit): 46 | Commits (past 90d): 26 | Contributors (cumulative): 54 | DMM Complexity: 0.9259259259259259\n\nDIFF:\n@@ -610,6 +610,10 @@ class Layer(object):\n                 else:\n                     output_shape = None\n \n+            if not isinstance(output_mask, (list, tuple)) and len(output_ls) > 1:\n+                # Augment the mask to match the length of the output.\n+                output_mask = [output_mask] * len(output_ls)\n+\n             # Add an inbound node to the layer, so that it keeps track\n             # of the call and of all new variables created during the call.\n             # This also updates the layer history of the output tensor(s).\n\n@@ -4,7 +4,7 @@ import numpy as np\n \n from keras.layers import Dense, Dropout, InputLayer\n from keras import layers\n-from keras.engine import Input, get_source_inputs\n+from keras.engine import Input, Layer, get_source_inputs\n from keras.models import Model, Sequential\n from keras import backend as K\n from keras.models import model_from_json, model_from_yaml\n@@ -626,5 +626,34 @@ def test_layer_sharing_at_heterogenous_depth():\n     np.testing.assert_allclose(output_val, output_val_2, atol=1e-6)\n \n \n+@keras_test\n+def test_multi_output_mask():\n+    \"\"\"Fixes #7589\"\"\"\n+    class ArbitraryMultiOutputLayer(Layer):\n+        def __init__(self, **kwargs):\n+            super(ArbitraryMultiOutputLayer, self).__init__(**kwargs)\n+\n+        def call(self, inputs, **kwargs):\n+            return [K.abs(inputs), K.abs(inputs)]\n+\n+        def compute_output_shape(self, input_shape):\n+            out_shape = super(ArbitraryMultiOutputLayer, self).compute_output_shape(input_shape)\n+            return [out_shape, out_shape]\n+\n+    class ArbitraryMultiInputLayer(Layer):\n+        def __init__(self, **kwargs):\n+            super(ArbitraryMultiInputLayer, self).__init__(**kwargs)\n+\n+        def call(self, inputs, **kwargs):\n+            negative, positive = inputs\n+            return negative + positive\n+\n+    input_layer = Input(shape=(16, 16, 3))\n+    x, y = ArbitraryMultiOutputLayer()(input_layer)\n+    z = ArbitraryMultiInputLayer()([x, y])\n+    _ = Model(inputs=input_layer, outputs=z)\n+    assert K.int_shape(z)[1:] == (16, 16, 3)\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3537381fa9487559b47f4cf3711265b2d5b049db", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 15 | Churn Cumulative: 2620 | Contributors (this commit): 9 | Commits (past 90d): 20 | Contributors (cumulative): 9 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1310,7 +1310,15 @@ def rnn(step_function, inputs, initial_states,\n             initial.append(s)\n \n     need_convert = not has_seq_axis(inputs)\n+    if go_backwards and need_convert is False:\n+        raise NotImplementedError('CNTK Backend: `go_backwards` is not supported with '\n+                                  'variable-length sequences. Please specify a '\n+                                  'static length for your sequences.')\n+\n     if need_convert:\n+        if go_backwards:\n+            inputs = reverse(inputs, 1)\n+\n         inputs = C.to_sequence(inputs)\n \n         j = 0\n@@ -1327,6 +1335,8 @@ def rnn(step_function, inputs, initial_states,\n             j += 1\n \n     if mask is not None and not has_seq_axis(mask):\n+        if go_backwards:\n+            mask = reverse(mask, 1)\n         if len(int_shape(mask)) == 2:\n             mask = expand_dims(mask)\n         mask = C.to_sequence_like(mask, inputs)\n@@ -1339,10 +1349,7 @@ def rnn(step_function, inputs, initial_states,\n             place_holders = [C.placeholder(dynamic_axes=x.dynamic_axes) for _ in states]\n             past_values = []\n             for s, p in zip(states, place_holders):\n-                past_values.append(\n-                    C.sequence.past_value(\n-                        p, s) if go_backwards is False else C.sequence.future_value(\n-                        p, s))\n+                past_values.append(C.sequence.past_value(p, s))\n             new_output, new_states = step_function(\n                 x, tuple(past_values) + tuple(constants))\n             if m is not None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1e9ee7e1651f201c3b2f86e534c551e9688949e5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 32 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 8/4 | Churn Δ: 34 | Churn Cumulative: 1136 | Contributors (this commit): 4 | Commits (past 90d): 14 | Contributors (cumulative): 7 | DMM Complexity: 0.4090909090909091\n\nDIFF:\n@@ -377,9 +377,24 @@ def MobileNet(input_shape=None,\n         raise ValueError('If using `weights` as ImageNet with `include_top` '\n                          'as true, `classes` should be 1000')\n \n-    # Determine proper input shape.\n+    # Determine proper input shape and default size.\n+    if input_shape is None:\n+        default_size = 224\n+    else:\n+        if K.image_data_format() == 'channels_first':\n+            rows = input_shape[1]\n+            cols = input_shape[2]\n+        else:\n+            rows = input_shape[0]\n+            cols = input_shape[1]\n+\n+        if rows == cols and rows in [128, 160, 192, 224]:\n+            default_size = rows\n+        else:\n+            default_size = 224\n+\n     input_shape = _obtain_input_shape(input_shape,\n-                                      default_size=224,\n+                                      default_size=default_size,\n                                       min_size=32,\n                                       data_format=K.image_data_format(),\n                                       include_top=include_top or weights)\n\n@@ -193,6 +193,21 @@ def test_mobilenet_pooling():\n     assert model.output_shape == (None, 1024)\n \n \n+@keras_test\n+@pytest.mark.skipif((K.backend() != 'tensorflow'),\n+                    reason=\"MobileNets are supported only on TensorFlow\")\n+def test_mobilenet_image_size():\n+    valid_image_sizes = [128, 160, 192, 224]\n+    for size in valid_image_sizes:\n+        input_shape = (size, size, 3) if K.image_data_format() == 'channels_last' else (3, size, size)\n+        model = applications.MobileNet(input_shape=input_shape, weights='imagenet', include_top=True)\n+        assert model.input_shape == (None,) + input_shape\n+\n+    invalid_image_shape = (112, 112, 3) if K.image_data_format() == 'channels_last' else (3, 112, 112)\n+    with pytest.raises(ValueError):\n+        model = applications.MobileNet(input_shape=invalid_image_shape, weights='imagenet', include_top=True)\n+\n+\n @pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TF backend')\n @keras_test\n def test_depthwise_conv_2d():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d687c6eda4d9cb58756822fd77402274db309da8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 322 | Lines Deleted: 31 | Files Changed: 5 | Hunks: 34 | Methods Changed: 14 | Complexity Δ (Sum/Max): 28/25 | Churn Δ: 353 | Churn Cumulative: 6931 | Contributors (this commit): 76 | Commits (past 90d): 44 | Contributors (cumulative): 95 | DMM Complexity: 0.4186046511627907\n\nDIFF:\n@@ -0,0 +1,158 @@\n+'''MNIST dataset with TFRecords, the standard TensorFlow data format.\n+\n+TFRecord is a data format supported throughout TensorFlow.\n+This example demonstrates how to load TFRecord data using\n+Input Tensors. Input Tensors differ from the normal Keras\n+workflow because instead of fitting to data loaded into a\n+a numpy array, data is supplied via a special tensor that\n+reads data from nodes that are wired directly into model\n+graph with the `Input(tensor=input_tensor)` parameter.\n+\n+There are several advantages to using Input Tensors.\n+First, if a dataset is already in TFRecord format you\n+can load and train on that data directly in Keras.\n+Second, extended backend API capabilities such as TensorFlow\n+data augmentation is easy to integrate directly into your\n+Keras training scripts via input tensors.\n+Third, TensorFlow implements several data APIs for\n+TFRecords, some of which provide significantly faster\n+training performance than numpy arrays can provide because\n+they run via the C++ backend. Please note that this\n+example is tailored for brevity and clarity and not\n+to demonstrate performance or augmentation capabilities.\n+\n+Input Tensors also have important disadvantages. In\n+particular, Input Tensors are fixed at model construction\n+because rewiring networks is not yet supported.\n+For this reason, changing the data input source means\n+model weights must be saved and the model rebuilt\n+from scratch to connect the new input data.\n+validation cannot currently be performed as training\n+progresses, and must be performed after training completes.\n+This example demonstrates how to train with input\n+tensors, save the model weights, and then evaluate the\n+model using the numpy based Keras API.\n+\n+Gets to 99.1% test accuracy after 78 epochs\n+(there is still a lot of margin for parameter tuning).\n+'''\n+import os\n+import copy\n+import time\n+\n+import numpy as np\n+\n+import tensorflow as tf\n+from keras import backend as K\n+from keras.models import Model\n+from keras import layers\n+from keras import objectives\n+from keras.utils import np_utils\n+from keras import objectives\n+\n+from tensorflow.contrib.learn.python.learn.datasets import mnist\n+\n+if K.backend() != 'tensorflow':\n+    raise RuntimeError('This example can only run with the '\n+                       'TensorFlow backend for the time being, '\n+                       'because it requires TFRecords, which '\n+                       'are not supported on other platforms.')\n+\n+\n+def cnn_layers(x_train_input):\n+    x = layers.Conv2D(32, (3, 3),\n+                      activation='relu', padding='valid')(x_train_input)\n+    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n+    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n+    x = layers.Dropout(0.25)(x)\n+    x = layers.Flatten()(x)\n+    x = layers.Dense(128, activation='relu')(x)\n+    x = layers.Dropout(0.5)(x)\n+    x_train_out = layers.Dense(classes,\n+                               activation='softmax',\n+                               name='x_train_out')(x)\n+    return x_train_out\n+\n+sess = K.get_session()\n+\n+batch_size = 128\n+batch_shape = (batch_size, 28, 28, 1)\n+steps_per_epoch = 469\n+epochs = 78\n+classes = 10\n+\n+# The capacity variable controls the maximum queue size\n+# allowed when prefetching data for training.\n+capacity = 10000\n+\n+# min_after_dequeue is the minimum number elements in the queue\n+# after a dequeue, which ensures sufficient mixing of elements.\n+min_after_dequeue = 3000\n+\n+# If `enqueue_many` is `False`, `tensors` is assumed to represent a\n+# single example.  An input tensor with shape `[x, y, z]` will be output\n+# as a tensor with shape `[batch_size, x, y, z]`.\n+#\n+# If `enqueue_many` is `True`, `tensors` is assumed to represent a\n+# batch of examples, where the first dimension is indexed by example,\n+# and all members of `tensors` should have the same size in the\n+# first dimension.  If an input tensor has shape `[*, x, y, z]`, the\n+# output will have shape `[batch_size, x, y, z]`.\n+enqueue_many = True\n+\n+data = mnist.load_mnist()\n+x_train_batch, y_train_batch = tf.train.shuffle_batch(\n+    tensors=[data.train.images, data.train.labels.astype(np.int32)],\n+    batch_size=batch_size,\n+    capacity=capacity,\n+    min_after_dequeue=min_after_dequeue,\n+    enqueue_many=enqueue_many,\n+    num_threads=8)\n+\n+x_train_batch = tf.cast(x_train_batch, tf.float32)\n+x_train_batch = tf.reshape(x_train_batch, shape=batch_shape)\n+\n+y_train_batch = tf.cast(y_train_batch, tf.int32)\n+y_train_batch = tf.one_hot(y_train_batch, classes)\n+\n+x_batch_shape = x_train_batch.get_shape().as_list()\n+y_batch_shape = y_train_batch.get_shape().as_list()\n+\n+x_train_input = layers.Input(tensor=x_train_batch, batch_shape=x_batch_shape)\n+x_train_out = cnn_layers(x_train_input)\n+train_model = Model(inputs=x_train_input, outputs=x_train_out)\n+\n+cce = objectives.categorical_crossentropy(y_train_batch, x_train_out)\n+train_model.add_loss(cce)\n+\n+# Do not pass the loss directly to model.compile()\n+# because it is not yet supported for Input Tensors.\n+train_model.compile(optimizer='rmsprop',\n+                    loss=None,\n+                    metrics=['accuracy'])\n+train_model.summary()\n+\n+coord = tf.train.Coordinator()\n+threads = tf.train.start_queue_runners(sess, coord)\n+train_model.fit(epochs=epochs,\n+                steps_per_epoch=steps_per_epoch)\n+\n+train_model.save_weights('saved_wt.h5')\n+\n+coord.request_stop()\n+coord.join(threads)\n+K.clear_session()\n+\n+# Second Session to test loading trained model without tensors\n+x_test = np.reshape(data.validation.images, (data.validation.images.shape[0], 28, 28, 1))\n+y_test = data.validation.labels\n+x_test_inp = layers.Input(batch_shape=(None,) + (x_test.shape[1:]))\n+test_out = cnn_layers(x_test_inp)\n+test_model = Model(inputs=x_test_inp, outputs=test_out)\n+\n+test_model.load_weights('saved_wt.h5')\n+test_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n+test_model.summary()\n+\n+loss, acc = test_model.evaluate(x_test, np_utils.to_categorical(y_test), classes)\n+print('\\nTest accuracy: {0}'.format(acc))\n\n@@ -974,10 +974,49 @@ class Model(Container):\n                                                name='predict_function',\n                                                **kwargs)\n \n-    def _fit_loop(self, f, ins, out_labels=None, batch_size=32,\n+    def _check_num_samples(self, ins, batch_size=None, steps=None, steps_name='steps'):\n+        \"\"\"Determine the number of samples provided for training and evaluation.\n+\n+        The number of samples is not defined when running with `steps`,\n+        in which case the number of samples is set to `None`.\n+\n+        # Arguments\n+            ins: list of tensors to be fed to the Keras function.\n+            batch_size: integer batch size or `None` if not defined.\n+            steps: Total number of steps (batches of samples)\n+                before declaring `_predict_loop` finished.\n+                Ignored with the default value of `None`.\n+            steps_name: The public API's parameter name for `steps`.\n+\n+        # Raises\n+            ValueError when `steps` is `None` and the attribute `ins.shape`\n+            does not exist. Also raises ValueError when `steps` is not `None`\n+            and `batch_size` is not `None` because they are mutually\n+            exclusive.\n+\n+        # Returns\n+            When steps is `None`, returns the number of samples to be\n+            processed based on the size of the first dimension of the\n+            first input numpy array. When steps is not `None` and\n+            `batch_size` is `None`, returns `None`.\n+        \"\"\"\n+        if steps is not None:\n+            num_samples = None\n+            if batch_size is not None:\n+                raise ValueError('If ' + steps_name +\n+                                 ' is set the batch_size must be None.')\n+        elif ins and hasattr(ins[0], 'shape'):\n+            num_samples = ins[0].shape[0]\n+        else:\n+            raise ValueError('The input data should have shape, or '\n+                             'please specify ' + steps_name + '.')\n+        return num_samples\n+\n+    def _fit_loop(self, f, ins, out_labels=None, batch_size=None,\n                   epochs=100, verbose=1, callbacks=None,\n                   val_f=None, val_ins=None, shuffle=True,\n-                  callback_metrics=None, initial_epoch=0):\n+                  callback_metrics=None, initial_epoch=0,\n+                  steps_per_epoch=None, validation_steps=None):\n         \"\"\"Abstract fit function for `f(ins)`.\n \n         Assume that f returns a list, labeled by out_labels.\n@@ -987,7 +1026,7 @@ class Model(Container):\n             ins: list of tensors to be fed to `f`\n             out_labels: list of strings, display names of\n                 the outputs of `f`\n-            batch_size: integer batch size\n+            batch_size: integer batch size or None if unknown.\n             epochs: number of times to iterate over the data\n             verbose: verbosity mode, 0, 1 or 2\n             callbacks: list of callbacks to be called during training\n@@ -1000,6 +1039,9 @@ class Model(Container):\n                  `f` and the list of display names of the outputs of `f_val`.\n             initial_epoch: epoch at which to start training\n                 (useful for resuming a previous training run)\n+            steps_per_epoch: Total number of steps (batches of samples)\n+                before declaring one epoch finished and starting the\n+                next epoch. Ignored with the default value of `None`.\n \n         # Returns\n             `History` object.\n@@ -1007,25 +1049,33 @@ class Model(Container):\n         do_validation = False\n         if val_f and val_ins:\n             do_validation = True\n-            if verbose:\n+            if steps_per_epoch and not validation_steps:\n+                if hasattr(ins[0], 'shape'):\n+                    validation_steps = steps_per_epoch\n+                else:\n+                    raise ValueError('You must specify a value for '\n+                                     '`validation_steps` when using '\n+                                     '`steps_per_epoch` validation '\n+                                     'without a `shape` attribute.')\n+\n+            if verbose and ins and hasattr(ins[0], 'shape'):\n                 print('Train on %d samples, validate on %d samples' %\n                       (ins[0].shape[0], val_ins[0].shape[0]))\n \n-        if ins and hasattr(ins[0], 'shape'):\n-            num_train_samples = ins[0].shape[0]\n-        else:\n-            # May happen if we are running `fit` without Numpy input data,\n-            # i.e. if all inputs to the models are data tensors\n-            # instead of placeholders.\n-            # In that case we will run `fit` over a single batch.\n-            num_train_samples = batch_size\n-            verbose = 2\n+        num_train_samples = self._check_num_samples(ins, batch_size,\n+                                                    steps_per_epoch, 'steps_per_epoch')\n+\n+        if num_train_samples is not None:\n             index_array = np.arange(num_train_samples)\n \n         self.history = cbks.History()\n         callbacks = [cbks.BaseLogger()] + (callbacks or []) + [self.history]\n         if verbose:\n-            callbacks += [cbks.ProgbarLogger()]\n+            if steps_per_epoch is not None:\n+                count_mode = 'steps'\n+            else:\n+                count_mode = 'samples'\n+            callbacks += [cbks.ProgbarLogger(count_mode)]\n         callbacks = cbks.CallbackList(callbacks)\n         out_labels = out_labels or []\n \n@@ -1040,6 +1090,7 @@ class Model(Container):\n         callbacks.set_params({\n             'batch_size': batch_size,\n             'epochs': epochs,\n+            'steps': steps_per_epoch,\n             'samples': num_train_samples,\n             'verbose': verbose,\n             'do_validation': do_validation,\n@@ -1052,13 +1103,41 @@ class Model(Container):\n \n         for epoch in range(initial_epoch, epochs):\n             callbacks.on_epoch_begin(epoch)\n+            epoch_logs = {}\n+            if steps_per_epoch is not None:\n+                for step_num in range(steps_per_epoch):\n+                    batch_logs = {}\n+                    batch_logs['batch'] = step_num\n+                    batch_logs['size'] = 1\n+                    callbacks.on_batch_begin(step_num, batch_logs)\n+                    outs = f(ins)\n+\n+                    if not isinstance(outs, list):\n+                        outs = [outs]\n+                    for l, o in zip(out_labels, outs):\n+                        batch_logs[l] = o\n+\n+                    callbacks.on_batch_end(step_num, batch_logs)\n+                    if callback_model.stop_training:\n+                        break\n+\n+                if do_validation:\n+                    val_outs = self._test_loop(val_f, val_ins,\n+                                               batch_size=batch_size,\n+                                               steps=validation_steps,\n+                                               verbose=0)\n+                    if not isinstance(val_outs, list):\n+                        val_outs = [val_outs]\n+                    # Same labels assumed.\n+                    for l, o in zip(out_labels, val_outs):\n+                        epoch_logs['val_' + l] = o\n+            else:\n                 if shuffle == 'batch':\n                     index_array = _batch_shuffle(index_array, batch_size)\n                 elif shuffle:\n                     np.random.shuffle(index_array)\n \n                 batches = _make_batches(num_train_samples, batch_size)\n-            epoch_logs = {}\n                 for batch_index, (batch_start, batch_end) in enumerate(batches):\n                     batch_ids = index_array[batch_start:batch_end]\n                     try:\n@@ -1109,6 +1188,9 @@ class Model(Container):\n             ins: list of tensors to be fed to `f`.\n             batch_size: integer batch size.\n             verbose: verbosity mode.\n+            steps: Total number of steps (batches of samples)\n+                before declaring `_predict_loop` finished.\n+                Ignored with the default value of `None`.\n \n         # Returns\n             Array of predictions (if the model has a single output)\n@@ -1124,6 +1206,7 @@ class Model(Container):\n             # In that case we will run `predict` over a single batch.\n             samples = batch_size\n             verbose = 2\n+\n         outs = []\n         if verbose == 1:\n             progbar = Progbar(target=samples)\n@@ -1153,14 +1236,17 @@ class Model(Container):\n             return outs[0]\n         return outs\n \n-    def _test_loop(self, f, ins, batch_size=32, verbose=0):\n+    def _test_loop(self, f, ins, batch_size=None, verbose=0, steps=None):\n         \"\"\"Abstract method to loop over some data in batches.\n \n         # Arguments\n             f: Keras function returning a list of tensors.\n             ins: list of tensors to be fed to `f`.\n-            batch_size: integer batch size.\n+            batch_size: integer batch size or `None`.\n             verbose: verbosity mode.\n+            steps: Total number of steps (batches of samples)\n+                before declaring predictions finished.\n+                Ignored with the default value of `None`.\n \n         # Returns\n             Scalar loss (if the model has a single output and no metrics)\n@@ -1168,17 +1254,26 @@ class Model(Container):\n             and/or metrics). The attribute `model.metrics_names` will give you\n             the display labels for the scalar outputs.\n         \"\"\"\n+        outs = []\n+        if batch_size is None and steps is not None:\n+            if verbose == 1:\n+                progbar = Progbar(target=steps)\n+            for step_num in range(steps):\n+                f(ins)\n+                if verbose == 1:\n+                    progbar.update(step_num)\n+\n+        else:\n             if ins and hasattr(ins[0], 'shape'):\n                 samples = ins[0].shape[0]\n             else:\n-            # May happen if we are running `evaluate` without Numpy input data,\n+                # May happen if we are running `predict` without Numpy input data,\n                 # i.e. if all inputs to the models are data tensors\n                 # instead of placeholders.\n-            # In that case we will run `evaluate` over a single batch.\n+                # In that case we will run `predict` over a single batch.\n                 samples = batch_size\n                 verbose = 2\n \n-        outs = []\n             if verbose == 1:\n                 progbar = Progbar(target=samples)\n             batches = _make_batches(samples, batch_size)\n@@ -1271,7 +1366,7 @@ class Model(Container):\n \n     def fit(self, x=None,\n             y=None,\n-            batch_size=32,\n+            batch_size=None,\n             epochs=1,\n             verbose=1,\n             callbacks=None,\n@@ -1281,6 +1376,8 @@ class Model(Container):\n             class_weight=None,\n             sample_weight=None,\n             initial_epoch=0,\n+            steps_per_epoch=None,\n+            validation_steps=None,\n             **kwargs):\n         \"\"\"Trains the model for a fixed number of epochs (iterations on a dataset).\n \n@@ -1295,7 +1392,9 @@ class Model(Container):\n                 If all outputs in the model are named,\n                 you can also pass a dictionary\n                 mapping output names to Numpy arrays.\n-            batch_size: integer. Number of samples per gradient update.\n+            batch_size: integer or `None`. Number of samples per gradient update.\n+                Defaults to 32 if training numpy arrays and no batch\n+                size is specified. Defaults to `None` when `steps_per_epoch` is set.\n             epochs: integer, the number of times to iterate\n                 over the training data arrays.\n             verbose: 0, 1, or 2. Verbosity mode.\n@@ -1315,7 +1414,8 @@ class Model(Container):\n                 This could be a tuple (x_val, y_val)\n                 or a tuple (x_val, y_val, val_sample_weights).\n             shuffle: boolean, whether to shuffle the training data\n-                before each epoch.\n+                before each epoch. Has no effect when `steps_per_epoch`\n+                is not `None`.\n             class_weight: optional dictionary mapping\n                 class indices (integers) to\n                 a weight (float) to apply to the model's loss for the samples\n@@ -1331,6 +1431,15 @@ class Model(Container):\n                 sample_weight_mode=\"temporal\" in compile().\n             initial_epoch: epoch at which to start training\n                 (useful for resuming a previous training run)\n+            steps_per_epoch: Total number of steps (batches of samples)\n+                before declaring one epoch finished and starting the\n+                next epoch. When training with Input Tensors such as\n+                TensorFlow data tensors, the default `None` is equal to\n+                the number of unique samples in your dataset divided by\n+                the batch size, or 1 if that cannot be determined.\n+            validation_steps: Only relevant if `steps_per_epoch`\n+                is specified. Total number of steps (batches of samples)\n+                to validate before stopping.\n \n         # Returns\n             A `History` instance. Its `history` attribute contains\n@@ -1340,6 +1449,9 @@ class Model(Container):\n             ValueError: In case of mismatch between the provided input data\n                 and what the model expects.\n         \"\"\"\n+        # backwards compatibility\n+        if batch_size is None and steps_per_epoch is None:\n+            batch_size = 32\n         # Legacy support\n         if 'nb_epoch' in kwargs:\n             warnings.warn('The `nb_epoch` argument in `fit` '\n@@ -1426,7 +1538,9 @@ class Model(Container):\n                               verbose=verbose, callbacks=callbacks,\n                               val_f=val_f, val_ins=val_ins, shuffle=shuffle,\n                               callback_metrics=callback_metrics,\n-                              initial_epoch=initial_epoch)\n+                              initial_epoch=initial_epoch,\n+                              steps_per_epoch=steps_per_epoch,\n+                              validation_steps=validation_steps)\n \n     def evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None):\n         \"\"\"Returns the loss value & metrics values for the model in test mode.\n@@ -1512,8 +1626,8 @@ class Model(Container):\n             ins = x\n         self._make_predict_function()\n         f = self.predict_function\n-        return self._predict_loop(f, ins,\n-                                  batch_size=batch_size, verbose=verbose)\n+        return self._predict_loop(f, ins, batch_size=batch_size,\n+                                  verbose=verbose)\n \n     def train_on_batch(self, x, y,\n                        sample_weight=None, class_weight=None):\n\n@@ -329,7 +329,7 @@ class Progbar(object):\n             for k in self.unique_values:\n                 info += ' - %s:' % k\n                 if isinstance(self.sum_values[k], list):\n-                    avg = self.sum_values[k][0] / max(1, self.sum_values[k][1])\n+                    avg = np.mean(self.sum_values[k][0] / max(1, self.sum_values[k][1]))\n                     if abs(avg) > 1e-3:\n                         info += ' %.4f' % avg\n                     else:\n@@ -352,7 +352,7 @@ class Progbar(object):\n                 info = '%ds' % (now - self.start)\n                 for k in self.unique_values:\n                     info += ' - %s:' % k\n-                    avg = self.sum_values[k][0] / max(1, self.sum_values[k][1])\n+                    avg = np.mean(self.sum_values[k][0] / max(1, self.sum_values[k][1]))\n                     if avg > 1e-3:\n                         info += ' %.4f' % avg\n                     else:\n\n@@ -143,7 +143,12 @@ def test_model_methods():\n                     epochs=1, batch_size=4, validation_split=0.5)\n     out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n                     {'dense_1': output_a_np, 'dropout': output_b_np},\n-                    epochs=1, batch_size=4, validation_split=0.5)\n+                    epochs=1, batch_size=None, validation_split=0.5,\n+                    steps_per_epoch=1)\n+    out = model.fit({'input_a': input_a_np, 'input_b': input_b_np},\n+                    {'dense_1': output_a_np, 'dropout': output_b_np},\n+                    epochs=1, batch_size=None, validation_split=0.5,\n+                    steps_per_epoch=1, validation_steps=1)\n \n     # test validation data\n     out = model.fit([input_a_np, input_b_np],\n@@ -734,7 +739,7 @@ def test_model_with_external_loss():\n         out = model.predict_on_batch(None)\n \n         # test fit\n-        out = model.fit(None, None, epochs=1, batch_size=10)\n+        out = model.fit(None, None, epochs=1, batch_size=None, steps_per_epoch=1)\n \n         # test evaluate\n         out = model.evaluate(None, None, batch_size=10)\n\n@@ -1,10 +1,24 @@\n import sys\n import pytest\n-from keras.utils.generic_utils import custom_object_scope, has_arg\n+import numpy as np\n+from keras.utils.generic_utils import custom_object_scope\n+from keras.utils.generic_utils import has_arg\n+from keras.utils.generic_utils import Progbar\n+from keras.utils.test_utils import keras_test\n from keras import activations\n from keras import regularizers\n \n \n+@keras_test\n+def test_progbar():\n+    n = 2\n+    input_arr = np.random.random((n, n, n))\n+    bar = Progbar(n)\n+\n+    for i, arr in enumerate(input_arr):\n+        bar.update(i, list(arr))\n+\n+\n def test_custom_objects_scope():\n \n     def custom_fn():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
