{"custom_id": "keras#458ede12641a2089f7d1a233ff0753e7d676a45d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 46 | Lines Deleted: 17 | Files Changed: 2 | Hunks: 10 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 63 | Churn Cumulative: 2099 | Contributors (this commit): 36 | Commits (past 90d): 9 | Contributors (cumulative): 38 | DMM Complexity: None\n\nDIFF:\n@@ -80,6 +80,7 @@ from keras import losses\n from keras import metrics\n from keras import backend\n from keras import activations\n+from keras import preprocessing\n \n import sys\n if sys.version[0] == '2':\n@@ -248,6 +249,17 @@ PAGES = [\n             layers.dot,\n         ]\n     },\n+    {\n+        'page': 'preprocessing/sequence.md',\n+        'functions': [\n+            preprocessing.sequence.pad_sequences,\n+            preprocessing.sequence.skipgrams,\n+            preprocessing.sequence.make_sampling_table,\n+        ],\n+        'classes': [\n+            preprocessing.sequence.TimeseriesGenerator,\n+        ]\n+    },\n     {\n         'page': 'layers/wrappers.md',\n         'all_module_classes': [wrappers],\n\n@@ -14,14 +14,23 @@ from ..utils.data_utils import Sequence\n \n def pad_sequences(sequences, maxlen=None, dtype='int32',\n                   padding='pre', truncating='pre', value=0.):\n-    \"\"\"Pads each sequence to the same length (length of the longest sequence).\n+    \"\"\"Pads sequences to the same length.\n \n-    If maxlen is provided, any sequence longer\n-    than maxlen is truncated to maxlen.\n-    Truncation happens off either the beginning (default) or\n-    the end of the sequence.\n+    This function transforms a list of\n+    `num_samples` sequences (lists of integers)\n+    into a 2D Numpy array of shape `(num_samples, num_timesteps)`.\n+    `num_timesteps` is either the `maxlen` argument if provided,\n+    or the length of the longest sequence otherwise.\n \n-    Supports post-padding and pre-padding (default).\n+    Sequences that are shorter than `num_timesteps`\n+    are padded with `value` at the end.\n+\n+    Sequences longer than `num_timesteps` are truncated\n+    so that they fit the desired length.\n+    The position where padding or truncation happens is determined by\n+    the arguments `padding` and `truncating`, respectively.\n+\n+    Pre-padding is the default.\n \n     # Arguments\n         sequences: List of lists, where each element is a sequence.\n@@ -93,15 +102,19 @@ def pad_sequences(sequences, maxlen=None, dtype='int32',\n def make_sampling_table(size, sampling_factor=1e-5):\n     \"\"\"Generates a word rank-based probabilistic sampling table.\n \n-    This generates an array where the ith element\n-    is the probability that a word of rank i would be sampled,\n-    according to the sampling distribution used in word2vec.\n+    Used for generating the `sampling_table` argument for `skipgrams`.\n+    `sampling_table[i]` is the probability of sampling\n+    the word i-th most common word in a dataset\n+    (more common words should be sampled less frequently, for balance).\n \n-    The word2vec formula is:\n-        `p(word) = min(1, sqrt(word.frequency/sampling_factor) / (word.frequency/sampling_factor))`\n+    The sampling probabilities are generated according\n+    to the sampling distribution used in word2vec:\n+\n+    `p(word) = min(1, sqrt(word_frequency / sampling_factor) / (word_frequency / sampling_factor))`\n \n     We assume that the word frequencies follow Zipf's law (s=1) to derive\n     a numerical approximation of frequency(rank):\n+\n     `frequency(rank) ~ 1/(rank * (log(rank) + gamma) + 1/2 - 1/(12*rank))`\n     where `gamma` is the Euler-Mascheroni constant.\n \n@@ -127,11 +140,15 @@ def skipgrams(sequence, vocabulary_size,\n               categorical=False, sampling_table=None, seed=None):\n     \"\"\"Generates skipgram word pairs.\n \n-    Takes a sequence (list of indexes of words),\n-    returns couples of samples `[word_index, other_word index]`\n-    and labels (1s or 0s),\n-    where `label == 1` if 'other_word' belongs to the context of 'word',\n-    and `label == 0` if 'other_word' is randomly sampled.\n+    This function transforms a sequence of word indexes (list of integers)\n+    into tuples of words of the form:\n+\n+    - (word, word in the same window), with label 1 (positive samples).\n+    - (word, random word from the vocabulary), with label 0 (negative samples).\n+\n+    Read more about Skipgram in this gnomic paper by Mikolov et al.:\n+    [Efficient Estimation of Word Representations in\n+    Vector Space](http://arxiv.org/pdf/1301.3781v3.pdf)\n \n     # Arguments\n         sequence: A word sequence (sentence), encoded as a list\n@@ -262,7 +279,7 @@ class TimeseriesGenerator(Sequence):\n             (except maybe the last one).\n \n     # Returns\n-        A `Sequence` instance.\n+        A [Sequence](/utils/#sequence) instance.\n \n     # Examples\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ae72ea0bfe7f7041d6f7580427fa1f69158bab7e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 137 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 3 | Methods Changed: 7 | Complexity Δ (Sum/Max): 16/16 | Churn Δ: 138 | Churn Cumulative: 3682 | Contributors (this commit): 21 | Commits (past 90d): 15 | Contributors (cumulative): 21 | DMM Complexity: 0.7314814814814815\n\nDIFF:\n@@ -230,6 +230,44 @@ def ref_conv(x, w, padding, data_format):\n     return y\n \n \n+def ref_rnn(x, w, init, go_backwards=False, mask=None, unroll=False, input_length=None):\n+    w_i, w_h, w_o = w\n+    h = []\n+    o = []\n+\n+    if go_backwards:\n+        t_list = range(x.shape[1] - 1, -1, -1)\n+    else:\n+        t_list = range(x.shape[1])\n+\n+    if mask is not None:\n+        np_mask = K.eval(mask)\n+    else:\n+        np_mask = None\n+\n+    for (i, t) in enumerate(t_list):\n+        h_t = np.dot(x[:, t], w_i)\n+\n+        if w_h is not None:\n+            prev = h[i - 1] if i > 0 else init\n+            h_t1 = np.dot(prev, w_h)\n+            if np_mask is not None:\n+                h_t1[np_mask[:, t] == 0] = prev[np_mask[:, t] == 0]\n+        else:\n+            h_t1 = 0\n+\n+        o_t = h_t + h_t1\n+        if w_o is not None:\n+            o_t = np.dot(o_t, w_o)\n+        o.append(o_t)\n+\n+        if np_mask is not None:\n+            h_t = h_t * np_mask[:, t].reshape(-1, 1)\n+        h.append(h_t + h_t1)\n+\n+    return o[-1], np.stack(o, axis=1), np.stack(h, axis=1)\n+\n+\n class TestBackend(object):\n \n     def test_is_keras_tensor(self):\n@@ -574,6 +612,104 @@ class TestBackend(object):\n         output_dim = 3\n         timesteps = 6\n \n+        _, x = parse_shape_or_val((num_samples, timesteps, input_dim))\n+        _, h0 = parse_shape_or_val((num_samples, output_dim))\n+        _, wi = parse_shape_or_val((input_dim, output_dim))\n+        _, wh = parse_shape_or_val((output_dim, output_dim))\n+        mask = np.random.randint(2, size=(num_samples, timesteps))\n+\n+        x_k = K.variable(x)\n+        h0_k = [K.variable(h0)]\n+        wi_k = K.variable(wi)\n+        wh_k = K.variable(wh)\n+        mask_k = K.variable(mask)\n+\n+        def rnn_fn(x_k, h_k):\n+            assert len(h_k) == 1\n+            y_k = K.dot(x_k, wi_k) + K.dot(h_k[0], wh_k)\n+            return y_k, [y_k]\n+\n+        # test default setup\n+        last_output_list = []\n+        outputs_list = []\n+        state_list = []\n+\n+        kwargs_list = [\n+            {'go_backwards': False, 'mask': None},\n+            {'go_backwards': False, 'mask': None, 'unroll': True, 'input_length': timesteps},\n+            {'go_backwards': True, 'mask': None},\n+            {'go_backwards': True, 'mask': None, 'unroll': True, 'input_length': timesteps},\n+            {'go_backwards': False, 'mask': mask_k},\n+            {'go_backwards': False, 'mask': mask_k, 'unroll': True, 'input_length': timesteps},\n+        ]\n+\n+        for (i, kwargs) in enumerate(kwargs_list):\n+            last_y1, y1, h1 = ref_rnn(x, [wi, wh, None], h0, **kwargs)\n+            last_y2, y2, h2 = K.rnn(rnn_fn, x_k, h0_k, **kwargs)\n+\n+            assert len(h2) == 1\n+            last_y2 = K.eval(last_y2)\n+            y2 = K.eval(y2)\n+            h1 = h1[:, -1]\n+            h2 = K.eval(h2[0])\n+\n+            if kwargs['mask'] is not None:\n+                last_y1 = last_y1 * np.expand_dims(mask[:, -1], -1)\n+                last_y2 = last_y2 * np.expand_dims(mask[:, -1], -1)\n+                y1 = y1 * np.expand_dims(mask, -1)\n+                y2 = y2 * np.expand_dims(mask, -1)\n+                h1 = h1 * np.expand_dims(mask[:, -1], -1)\n+                h2 = h2 * np.expand_dims(mask[:, -1], -1)\n+\n+            last_output_list.append(last_y2)\n+            outputs_list.append(y2)\n+            state_list.append(h2)\n+\n+            if i % 2 == 0:\n+                assert_allclose(last_y1, last_y2, atol=1e-05)\n+                assert_allclose(y1, y2, atol=1e-05)\n+                assert_allclose(h1, h2, atol=1e-05)\n+            else:\n+                assert_allclose(last_output_list[i - 1], last_output_list[i], atol=1e-05)\n+                assert_allclose(outputs_list[i - 1], outputs_list[i], atol=1e-05)\n+                assert_allclose(state_list[i - 1], state_list[i], atol=1e-05)\n+\n+    def test_rnn_no_states(self):\n+        # implement a simple RNN without states\n+        input_dim = 8\n+        output_dim = 4\n+        timesteps = 5\n+\n+        _, x = parse_shape_or_val((32, timesteps, input_dim))\n+        _, wi = parse_shape_or_val((input_dim, output_dim))\n+\n+        x_k = K.variable(x)\n+        wi_k = K.variable(wi)\n+\n+        def rnn_fn(x_k, h_k):\n+            assert len(h_k) == 0\n+            y_k = K.dot(x_k, wi_k)\n+            return y_k, []\n+\n+        last_y1, y1, h1 = ref_rnn(x, [wi, None, None], None,\n+                                  go_backwards=False, mask=None)\n+        last_y2, y2, h2 = K.rnn(rnn_fn, x_k, [],\n+                                go_backwards=False, mask=None)\n+\n+        assert len(h2) == 0\n+        last_y2 = K.eval(last_y2)\n+        y2 = K.eval(y2)\n+\n+        assert_allclose(last_y1, last_y2, atol=1e-05)\n+        assert_allclose(y1, y2, atol=1e-05)\n+\n+    def legacy_test_rnn(self):\n+        # implement a simple RNN\n+        num_samples = 4\n+        input_dim = 5\n+        output_dim = 3\n+        timesteps = 6\n+\n         input_val = np.random.random((num_samples, timesteps, input_dim)).astype(np.float32)\n         init_state_val = np.random.random((num_samples, output_dim)).astype(np.float32)\n         W_i_val = np.random.random((input_dim, output_dim)).astype(np.float32)\n@@ -662,7 +798,7 @@ class TestBackend(object):\n         for m_s, u_m_s, k in zip(state_list[4], state_list[5], BACKENDS):\n             assert_allclose(m_s, u_m_s, atol=1e-04)\n \n-    def test_rnn_no_states(self):\n+    def legacy_test_rnn_no_states(self):\n         # implement a simple RNN without states\n         input_dim = 8\n         output_dim = 4\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#16fba547a15958225077303635b816c68263e73d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 56 | Lines Deleted: 30 | Files Changed: 1 | Hunks: 10 | Methods Changed: 8 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 86 | Churn Cumulative: 3768 | Contributors (this commit): 21 | Commits (past 90d): 16 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -192,23 +192,43 @@ def check_composed_tensor_operations(first_function_name, first_function_args,\n     assert_list_pairwise(z_list)\n \n \n-def ref_conv(x, w, padding, data_format):\n+def normalize_ref_conv(func):\n+    def wrapper(*args):\n+        x = args[0]\n+        w = args[1]\n         if x.ndim == 3:\n             w = np.flipud(w)\n             w = np.transpose(w, (1, 2, 0))\n-        if data_format == 'channels_last':\n+            if args[3] == 'channels_last':\n                 x = np.transpose(x, (0, 2, 1))\n         elif x.ndim == 4:\n             w = np.fliplr(np.flipud(w))\n             w = np.transpose(w, (2, 3, 0, 1))\n-        if data_format == 'channels_last':\n+            if args[3] == 'channels_last':\n                 x = np.transpose(x, (0, 3, 1, 2))\n         else:\n             w = np.flip(np.fliplr(np.flipud(w)), axis=2)\n             w = np.transpose(w, (3, 4, 0, 1, 2))\n-        if data_format == 'channels_last':\n+            if args[3] == 'channels_last':\n                 x = np.transpose(x, (0, 4, 1, 2, 3))\n \n+        y = func(x, w, args[2], args[3])\n+\n+        if args[3] == 'channels_last':\n+            if y.ndim == 3:\n+                y = np.transpose(y, (0, 2, 1))\n+            elif y.ndim == 4:\n+                y = np.transpose(y, (0, 2, 3, 1))\n+            else:\n+                y = np.transpose(y, (0, 2, 3, 4, 1))\n+\n+        return y\n+\n+    return wrapper\n+\n+\n+@normalize_ref_conv\n+def ref_conv(x, w, padding, data_format):\n     y = []\n     for i in range(x.shape[0]):\n         _y = []\n@@ -219,14 +239,21 @@ def ref_conv(x, w, padding, data_format):\n             _y.append(np.sum(np.stack(__y, axis=-1), axis=-1))\n         y.append(_y)\n     y = np.array(y)\n+    return y\n \n-    if data_format == 'channels_last':\n-        if y.ndim == 3:\n-            y = np.transpose(y, (0, 2, 1))\n-        elif y.ndim == 4:\n-            y = np.transpose(y, (0, 2, 3, 1))\n-        else:\n-            y = np.transpose(y, (0, 2, 3, 4, 1))\n+\n+@normalize_ref_conv\n+def ref_depthwise_conv(x, w, padding, data_format):\n+    y = []\n+    for i in range(x.shape[0]):\n+        _y = []\n+        for j in range(w.shape[0]):\n+            __y = []\n+            for k in range(w.shape[1]):\n+                __y.append(signal.convolve(x[i, j], w[j, k], mode=padding))\n+            _y.append(np.stack(__y, axis=0))\n+        y.append(np.concatenate(_y, axis=0))\n+    y = np.array(y)\n     return y\n \n \n@@ -996,6 +1023,23 @@ class TestBackend(object):\n             cntk_dynamicity=True, return_results=True)\n         assert_allclose(y1, y2, atol=1e-05)\n \n+    @pytest.mark.parametrize('op,input_shape,kernel_shape,padding,data_format', [\n+        ('depthwise_conv2d', (2, 3, 4, 5), (3, 3, 3, 2), 'same', 'channels_first'),\n+        ('depthwise_conv2d', (2, 3, 5, 6), (4, 3, 3, 4), 'valid', 'channels_first'),\n+        ('depthwise_conv2d', (1, 6, 5, 3), (3, 4, 3, 2), 'valid', 'channels_last'),\n+        ('depthwise_conv2d', (1, 7, 6, 3), (3, 3, 3, 4), 'same', 'channels_last'),\n+    ])\n+    def test_depthwise_conv(self, op, input_shape, kernel_shape, padding, data_format):\n+        k = K.backend()\n+        _, x = parse_shape_or_val(input_shape)\n+        _, w = parse_shape_or_val(kernel_shape)\n+        y1 = ref_depthwise_conv(x, w, padding, data_format)\n+        y2 = check_two_tensor_operation(\n+            op, x, w, [KTH if k == 'theano' else KC if k == 'cntk' else KTF],\n+            padding=padding, data_format=data_format,\n+            cntk_dynamicity=True, return_results=True)\n+        assert_allclose(y1, y2, atol=1e-05)\n+\n     def legacy_test_conv1d(self):\n         # channels_last input shape: (n, length, input_depth)\n         input_shape = (4, 8, 2)\n@@ -1017,7 +1061,7 @@ class TestBackend(object):\n                                        BACKENDS, cntk_dynamicity=True,\n                                        data_format=data_format)\n \n-    def test_depthwise_conv_2d(self):\n+    def legacy_test_depthwise_conv_2d(self):\n         # TF kernel shape: (rows, cols, input_depth, depth_multiplier)\n         # channels_first input shape: (n, input_depth, rows, cols)\n         for (input_shape, kernel_shape, data_format) in [\n@@ -1064,24 +1108,6 @@ class TestBackend(object):\n                                                  data_format=data_format)([x_val])[0]\n                     assert_allclose(z_tf, z_c, 1e-3)\n \n-    @pytest.mark.parametrize('k', [KTF], ids=['TensorFlow'])\n-    def test_depthwise_conv_2d(self, k):\n-        for data_format in ['channels_first', 'channels_last']:\n-            x_shape = (4, 4)\n-            if data_format == 'channels_first':\n-                input_shape = (2, 3) + x_shape\n-            elif data_format == 'channels_last':\n-                input_shape = (2,) + x_shape + (3,)\n-            kernel_shape = (3, 3, 3, 2)\n-\n-            x_val = np.ones(input_shape)\n-            kernel_val = np.arange(np.prod(kernel_shape)).reshape(kernel_shape)\n-            z = k.eval(k.depthwise_conv2d(k.variable(x_val), k.variable(kernel_val),\n-                                          data_format=data_format))\n-\n-            for z_i in np.split(z, 6, axis=1 if data_format == 'channels_first' else -1):\n-                assert_allclose(z_i, z_i[0] * np.ones_like(z_i))\n-\n     def test_pool2d(self):\n         check_single_tensor_operation('pool2d', (5, 10, 12, 3),\n                                       BACKENDS, cntk_dynamicity=True,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#614a8b4f0a7efa2a99d5c1af0e42993288f25e96", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 9364 | Contributors (this commit): 53 | Commits (past 90d): 22 | Contributors (cumulative): 53 | DMM Complexity: None\n\nDIFF:\n@@ -229,7 +229,7 @@ class RNN(Layer):\n             It is also possible for `cell` to be a list of RNN cell instances,\n             in which cases the cells get stacked on after the other in the RNN,\n             implementing an efficient stacked RNN.\n-        return_sequences: Boolean. Whether to return the last output.\n+        return_sequences: Boolean. Whether to return the last output\n             in the output sequence, or the full sequence.\n         return_state: Boolean. Whether to return the last state\n             in addition to the output.\n@@ -983,7 +983,7 @@ class SimpleRNN(RNN):\n         recurrent_dropout: Float between 0 and 1.\n             Fraction of the units to drop for\n             the linear transformation of the recurrent state.\n-        return_sequences: Boolean. Whether to return the last output.\n+        return_sequences: Boolean. Whether to return the last output\n             in the output sequence, or the full sequence.\n         return_state: Boolean. Whether to return the last state\n             in addition to the output.\n@@ -1528,7 +1528,7 @@ class GRU(RNN):\n             batch them into fewer, larger operations. These modes will\n             have different performance profiles on different hardware and\n             for different applications.\n-        return_sequences: Boolean. Whether to return the last output.\n+        return_sequences: Boolean. Whether to return the last output\n             in the output sequence, or the full sequence.\n         return_state: Boolean. Whether to return the last state\n             in addition to the output.\n@@ -2054,7 +2054,7 @@ class LSTM(RNN):\n             batch them into fewer, larger operations. These modes will\n             have different performance profiles on different hardware and\n             for different applications.\n-        return_sequences: Boolean. Whether to return the last output.\n+        return_sequences: Boolean. Whether to return the last output\n             in the output sequence, or the full sequence.\n         return_state: Boolean. Whether to return the last state\n             in addition to the output.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#62c395e7b6c7eb405614969035407560c82f5096", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 20 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 48 | Churn Cumulative: 3816 | Contributors (this commit): 21 | Commits (past 90d): 17 | Contributors (cumulative): 21 | DMM Complexity: None\n\nDIFF:\n@@ -257,6 +257,11 @@ def ref_depthwise_conv(x, w, padding, data_format):\n     return y\n \n \n+def ref_separable_conv(x, w1, w2, padding, data_format):\n+    x2 = ref_depthwise_conv(x, w1, padding, data_format)\n+    return ref_conv(x2, w2, padding, data_format)\n+\n+\n def ref_rnn(x, w, init, go_backwards=False, mask=None, unroll=False, input_length=None):\n     w_i, w_h, w_o = w\n     h = []\n@@ -1086,27 +1091,30 @@ class TestBackend(object):\n                                        BACKENDS, cntk_dynamicity=True,\n                                        data_format=data_format)\n \n-    def test_separable_conv2d(self):\n-        for (input_shape, data_format) in [\n-                ((2, 3, 4, 5), 'channels_first'),\n-                ((2, 3, 5, 6), 'channels_first'),\n-                ((1, 6, 5, 3), 'channels_last')]:\n+    @pytest.mark.skipif(K.backend() == 'theano', reason='Not supported.')\n+    @pytest.mark.parametrize('op,input_shape,kernel_shape,depth_multiplier,padding,data_format', [\n+        ('separable_conv2d', (2, 3, 4, 5), (3, 3), 1, 'same', 'channels_first'),\n+        ('separable_conv2d', (2, 3, 5, 6), (4, 3), 2, 'valid', 'channels_first'),\n+        ('separable_conv2d', (1, 6, 5, 3), (3, 4), 1, 'valid', 'channels_last'),\n+        ('separable_conv2d', (1, 7, 6, 3), (3, 3), 2, 'same', 'channels_last'),\n+    ])\n+    def test_separable_conv2d(self, op, input_shape, kernel_shape, depth_multiplier, padding, data_format):\n         input_depth = input_shape[1] if data_format == 'channels_first' else input_shape[-1]\n-            _, x_val = parse_shape_or_val(input_shape)\n-            x_tf = KTF.variable(x_val)\n-            for kernel_shape in [(2, 2), (4, 3)]:\n-                for depth_multiplier in [1, 2]:\n-                    _, depthwise_val = parse_shape_or_val(kernel_shape + (input_depth, depth_multiplier))\n-                    _, pointwise_val = parse_shape_or_val((1, 1) + (input_depth * depth_multiplier, 7))\n-\n-                    z_tf = KTF.eval(KTF.separable_conv2d(x_tf, KTF.variable(depthwise_val),\n-                                                         KTF.variable(pointwise_val),\n-                                                         data_format=data_format))\n-                    z_c = cntk_func_three_tensor('separable_conv2d', input_shape,\n-                                                 depthwise_val,\n-                                                 pointwise_val,\n-                                                 data_format=data_format)([x_val])[0]\n-                    assert_allclose(z_tf, z_c, 1e-3)\n+        _, x = parse_shape_or_val(input_shape)\n+        _, depthwise = parse_shape_or_val(kernel_shape + (input_depth, depth_multiplier))\n+        _, pointwise = parse_shape_or_val((1, 1) + (input_depth * depth_multiplier, 7))\n+        y1 = ref_separable_conv(x, depthwise, pointwise, padding, data_format)\n+        if K.backend() == 'cntk':\n+            y2 = cntk_func_three_tensor(\n+                op, input_shape,\n+                depthwise, pointwise,\n+                padding=padding, data_format=data_format)([x])[0]\n+        else:\n+            y2 = K.eval(getattr(K, op)(\n+                K.variable(x),\n+                K.variable(depthwise), K.variable(pointwise),\n+                padding=padding, data_format=data_format))\n+        assert_allclose(y1, y2, atol=1e-05)\n \n     def test_pool2d(self):\n         check_single_tensor_operation('pool2d', (5, 10, 12, 3),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2fae46169239287796d44523deb5e2ac38712ba3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 432 | Contributors (this commit): 18 | Commits (past 90d): 9 | Contributors (cumulative): 19 | DMM Complexity: None\n\nDIFF:\n@@ -23,4 +23,4 @@ from .layers import Input\n from .models import Model\r\n from .models import Sequential\r\n \r\n-__version__ = '2.1.4'\r\n+__version__ = '2.1.5'\r\n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='2.1.4',\n+      version='2.1.5',\n       description='Deep Learning for humans',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/keras-team/keras',\n-      download_url='https://github.com/keras-team/keras/tarball/2.1.4',\n+      download_url='https://github.com/keras-team/keras/tarball/2.1.5',\n       license='MIT',\n       install_requires=['numpy>=1.9.1',\n                         'scipy>=0.14',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1c9a49781da2101507db23e2014e4e5d16bd2e52", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 5480 | Contributors (this commit): 80 | Commits (past 90d): 6 | Contributors (cumulative): 80 | DMM Complexity: None\n\nDIFF:\n@@ -2200,9 +2200,9 @@ def pool3d(x, pool_size, strides=(1, 1, 1), padding='valid',\n         w_pad = pool_size[0] - 2 if pool_size[0] % 2 == 1 else pool_size[0] - 1\n         h_pad = pool_size[1] - 2 if pool_size[1] % 2 == 1 else pool_size[1] - 1\n         d_pad = pool_size[2] - 2 if pool_size[2] % 2 == 1 else pool_size[2] - 1\n-        padding = (w_pad, h_pad, d_pad)\n+        pad = (w_pad, h_pad, d_pad)\n     elif padding == 'valid':\n-        padding = (0, 0, 0)\n+        pad = (0, 0, 0)\n     else:\n         raise ValueError('Invalid padding:', padding)\n \n@@ -2212,12 +2212,12 @@ def pool3d(x, pool_size, strides=(1, 1, 1), padding='valid',\n     if pool_mode == 'max':\n         pool_out = pool.pool_3d(x, ws=pool_size, stride=strides,\n                                 ignore_border=True,\n-                                pad=padding,\n+                                pad=pad,\n                                 mode='max')\n     elif pool_mode == 'avg':\n         pool_out = pool.pool_3d(x, ws=pool_size, stride=strides,\n                                 ignore_border=True,\n-                                pad=padding,\n+                                pad=pad,\n                                 mode='average_exc_pad')\n     else:\n         raise ValueError('Invalid pooling mode:', pool_mode)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#70ad0d6e4a569701ef106058397ad0540ec08340", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 5/3 | Churn Δ: 27 | Churn Cumulative: 667 | Contributors (this commit): 16 | Commits (past 90d): 9 | Contributors (cumulative): 22 | DMM Complexity: 0.4\n\nDIFF:\n@@ -38,12 +38,21 @@ def text_to_word_sequence(text,\n     if lower:\n         text = text.lower()\n \n-    if sys.version_info < (3,) and isinstance(text, unicode):\n+    if sys.version_info < (3,):\n+        if isinstance(text, unicode):\n             translate_map = dict((ord(c), unicode(split)) for c in filters)\n-    else:\n-        translate_map = maketrans(filters, split * len(filters))\n-\n             text = text.translate(translate_map)\n+        elif len(split) == 1:\n+            translate_map = maketrans(filters, split * len(filters))\n+            text = text.translate(translate_map)\n+        else:\n+            for c in filters:\n+                text = text.replace(c, split)\n+    else:\n+        translate_dict = dict((c, split) for c in filters)\n+        translate_map = maketrans(translate_dict)\n+        text = text.translate(translate_map)\n+\n     seq = text.split(split)\n     return [i for i in seq if i]\n \n\n@@ -73,11 +73,21 @@ def test_text_to_word_sequence():\n     assert text_to_word_sequence(text) == ['hello', 'world']\n \n \n+def test_text_to_word_sequence_multichar_split():\n+    text = 'hello!stop?world!'\n+    assert text_to_word_sequence(text, split='stop') == ['hello', 'world']\n+\n+\n def test_text_to_word_sequence_unicode():\n     text = u'ali! veli? kırk dokuz elli'\n     assert text_to_word_sequence(text) == [u'ali', u'veli', u'kırk', u'dokuz', u'elli']\n \n \n+def test_text_to_word_sequence_unicode_multichar_split():\n+    text = u'ali!stopveli?stopkırkstopdokuzstopelli'\n+    assert text_to_word_sequence(text, split='stop') == [u'ali', u'veli', u'kırk', u'dokuz', u'elli']\n+\n+\n def test_tokenizer_unicode():\n     texts = [u'ali veli kırk dokuz elli', u'ali veli kırk dokuz elli veli kırk dokuz']\n     tokenizer = Tokenizer(num_words=5)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0121ba067e19c023b725f9bee581633a276db890", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 71 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 4 | Methods Changed: 6 | Complexity Δ (Sum/Max): 22/22 | Churn Δ: 73 | Churn Cumulative: 3889 | Contributors (this commit): 21 | Commits (past 90d): 18 | Contributors (cumulative): 21 | DMM Complexity: 0.2\n\nDIFF:\n@@ -262,6 +262,54 @@ def ref_separable_conv(x, w1, w2, padding, data_format):\n     return ref_conv(x2, w2, padding, data_format)\n \n \n+def ref_pool(x, pool_size, strides, padding, data_format, pool_mode):\n+    if data_format == 'channels_last':\n+        if x.ndim == 3:\n+            x = np.transpose(x, (0, 2, 1))\n+        elif x.ndim == 4:\n+            x = np.transpose(x, (0, 3, 1, 2))\n+        else:\n+            x = np.transpose(x, (0, 4, 1, 2, 3))\n+\n+    if padding == 'same':\n+        pad = [(0, 0), (0, 0)] + [(s // 2, s // 2) for s in pool_size]\n+        x = np.pad(x, pad, 'constant', constant_values=-np.inf)\n+\n+    # indexing trick\n+    x = np.pad(x, [(0, 0), (0, 0)] + [(0, 1) for _ in pool_size],\n+               'constant', constant_values=0)\n+\n+    if x.ndim == 3:\n+        y = [x[:, :, k:k1:strides[0]]\n+             for (k, k1) in zip(range(pool_size[0]), range(-pool_size[0], 0))]\n+    elif x.ndim == 4:\n+        y = []\n+        for (k, k1) in zip(range(pool_size[0]), range(-pool_size[0], 0)):\n+            for (l, l1) in zip(range(pool_size[1]), range(-pool_size[1], 0)):\n+                y.append(x[:, :, k:k1:strides[0], l:l1:strides[1]])\n+    else:\n+        y = []\n+        for (k, k1) in zip(range(pool_size[0]), range(-pool_size[0], 0)):\n+            for (l, l1) in zip(range(pool_size[1]), range(-pool_size[1], 0)):\n+                for (m, m1) in zip(range(pool_size[2]), range(-pool_size[2], 0)):\n+                    y.append(x[:, :, k:k1:strides[0], l:l1:strides[1], m:m1:strides[2]])\n+    y = np.stack(y, axis=-1)\n+    if pool_mode == 'avg':\n+        y = np.mean(np.ma.masked_invalid(y), axis=-1).data\n+    elif pool_mode == 'max':\n+        y = np.max(y, axis=-1)\n+\n+    if data_format == 'channels_last':\n+        if y.ndim == 3:\n+            y = np.transpose(y, (0, 2, 1))\n+        elif y.ndim == 4:\n+            y = np.transpose(y, (0, 2, 3, 1))\n+        else:\n+            y = np.transpose(y, (0, 2, 3, 4, 1))\n+\n+    return y\n+\n+\n def ref_rnn(x, w, init, go_backwards=False, mask=None, unroll=False, input_length=None):\n     w_i, w_h, w_o = w\n     h = []\n@@ -1045,6 +1093,27 @@ class TestBackend(object):\n             cntk_dynamicity=True, return_results=True)\n         assert_allclose(y1, y2, atol=1e-05)\n \n+    @pytest.mark.parametrize('op,input_shape,pool_size,strides,padding,data_format,pool_mode', [\n+        ('pool2d', (2, 3, 7, 7), (3, 3), (1, 1), 'same', 'channels_first', 'avg'),\n+        ('pool2d', (3, 3, 8, 5), (2, 3), (1, 1), 'valid', 'channels_first', 'max'),\n+        ('pool2d', (2, 9, 5, 3), (3, 2), (1, 1), 'valid', 'channels_last', 'avg'),\n+        ('pool2d', (3, 6, 7, 3), (3, 3), (1, 1), 'same', 'channels_last', 'max'),\n+        ('pool3d', (2, 3, 7, 7, 7), (3, 3, 3), (1, 1, 1), 'same', 'channels_first', 'avg'),\n+        ('pool3d', (3, 3, 8, 5, 9), (2, 3, 2), (1, 1, 1), 'valid', 'channels_first', 'max'),\n+        ('pool3d', (2, 8, 9, 5, 3), (3, 2, 3), (1, 1, 1), 'valid', 'channels_last', 'avg'),\n+        ('pool3d', (3, 5, 6, 7, 3), (3, 3, 3), (1, 1, 1), 'same', 'channels_last', 'max'),\n+    ])\n+    def test_pool(self, op, input_shape, pool_size, strides, padding, data_format, pool_mode):\n+        k = K.backend()\n+        _, x = parse_shape_or_val(input_shape)\n+        y1 = ref_pool(x, pool_size, strides, padding, data_format, pool_mode)\n+        y2 = check_single_tensor_operation(\n+            op, x, [KTH if k == 'theano' else KC if k == 'cntk' else KTF],\n+            pool_size=pool_size, strides=strides,\n+            padding=padding, data_format=data_format, pool_mode=pool_mode,\n+            cntk_dynamicity=True, return_results=True)\n+        assert_allclose(y1, y2, atol=1e-05)\n+\n     def legacy_test_conv1d(self):\n         # channels_last input shape: (n, length, input_depth)\n         input_shape = (4, 8, 2)\n@@ -1116,7 +1185,7 @@ class TestBackend(object):\n                 padding=padding, data_format=data_format))\n         assert_allclose(y1, y2, atol=1e-05)\n \n-    def test_pool2d(self):\n+    def legacy_test_pool2d(self):\n         check_single_tensor_operation('pool2d', (5, 10, 12, 3),\n                                       BACKENDS, cntk_dynamicity=True,\n                                       pool_size=(2, 2), strides=(1, 1), padding='valid')\n@@ -1138,7 +1207,7 @@ class TestBackend(object):\n                                       pool_size=(3, 3), strides=(1, 1),\n                                       padding='same', pool_mode='avg')\n \n-    def test_pool3d(self):\n+    def legacy_test_pool3d(self):\n         check_single_tensor_operation('pool3d', (5, 10, 12, 5, 3),\n                                       BACKENDS, cntk_dynamicity=True,\n                                       pool_size=(2, 2, 2), strides=(1, 1, 1), padding='valid')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#839d3dd0b598ecf6f2e93b9f9068c2e21fa1c97b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 47 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): 8/5 | Churn Δ: 53 | Churn Cumulative: 9139 | Contributors (this commit): 59 | Commits (past 90d): 20 | Contributors (cumulative): 63 | DMM Complexity: 0.6388888888888888\n\nDIFF:\n@@ -2210,7 +2210,6 @@ class Container(Layer):\n             for node in nodes:\n                 # This is always a single layer, never a list.\n                 layer = node.outbound_layer\n-\n                 reference_input_tensors = node.input_tensors\n                 reference_output_tensors = node.output_tensors\n \n@@ -2234,8 +2233,12 @@ class Container(Layer):\n                                 if 'mask' not in kwargs:\n                                     kwargs['mask'] = computed_mask\n                             output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n-                            output_masks = _to_list(layer.compute_mask(computed_tensor,\n-                                                                       computed_mask))\n+                            output_masks = layer.compute_mask(computed_tensor,\n+                                                              computed_mask)\n+                            if output_masks is None:\n+                                output_masks = [None for _ in output_tensors]\n+                            else:\n+                                output_masks = _to_list(output_masks)\n                             computed_tensors = [computed_tensor]\n                             computed_masks = [computed_mask]\n                         else:\n@@ -2245,14 +2248,22 @@ class Container(Layer):\n                                 if 'mask' not in kwargs:\n                                     kwargs['mask'] = computed_masks\n                             output_tensors = _to_list(layer.call(computed_tensors, **kwargs))\n-                            output_masks = _to_list(layer.compute_mask(computed_tensors,\n-                                                                       computed_masks))\n-\n+                            output_masks = layer.compute_mask(computed_tensors,\n+                                                              computed_masks)\n+                            if output_masks is None:\n+                                output_masks = [None for _ in output_tensors]\n+                            else:\n+                                output_masks = _to_list(output_masks)\n                         # Apply activity regularizer if any:\n                         if hasattr(layer, 'activity_regularizer') and layer.activity_regularizer is not None:\n                             regularization_losses = [layer.activity_regularizer(x) for x in output_tensors]\n                             layer.add_loss(regularization_losses, computed_tensors)\n \n+                        if len(output_masks) != len(output_tensors):\n+                            raise Exception('Layers should have equal number of output tensors '\n+                                            'and output masks. Layer ' + str(layer.name) + ' has'\n+                                            ' ' + str(len(output_tensors)) + ' output tensors and'\n+                                            ' ' + str(len(output_masks)) + ' output masks.')\n                     # Update model updates and losses:\n                     # Keep track of updates that depend on the inputs\n                     # (e.g. BN updates).\n\n@@ -169,6 +169,36 @@ def test_lambda():\n \n     test_multiple_outputs()\n \n+    # test layer with multiple outputs and no\n+    # explicit mask\n+    def test_multiple_outputs_no_mask():\n+        def func(x):\n+            return [x * 0.2, x * 0.3]\n+\n+        def output_shape(input_shape):\n+            return [input_shape, input_shape]\n+\n+        i = layers.Input(shape=(64, 64, 3))\n+        o = layers.Lambda(function=func,\n+                          output_shape=output_shape)(i)\n+\n+        assert o[0]._keras_shape == (None, 64, 64, 3)\n+        assert o[1]._keras_shape == (None, 64, 64, 3)\n+\n+        o = layers.add(o)\n+        model = Model(i, o)\n+\n+        i2 = layers.Input(shape=(64, 64, 3))\n+        o2 = model(i2)\n+        model2 = Model(i2, o2)\n+\n+        x = np.random.random((4, 64, 64, 3))\n+        out = model2.predict(x)\n+        assert out.shape == (4, 64, 64, 3)\n+        assert_allclose(out, x * 0.2 + x * 0.3, atol=1e-4)\n+\n+    test_multiple_outputs_no_mask()\n+\n     # test serialization with function\n     def f(x):\n         return x + 1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6249bd5e0fbd1968d9d57eea1bd4547dec8c19c9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 6 | Files Changed: 4 | Hunks: 8 | Methods Changed: 7 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 18 | Churn Cumulative: 21641 | Contributors (this commit): 137 | Commits (past 90d): 59 | Contributors (cumulative): 229 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1727,8 +1727,8 @@ def batch_flatten(x):\n     return x\n \n \n-def softmax(x):\n-    return C.softmax(x)\n+def softmax(x, axis=-1):\n+    return C.softmax(x, axis=axis)\n \n \n def softplus(x):\n\n@@ -2945,16 +2945,18 @@ def elu(x, alpha=1.):\n         return tf.where(x > 0, res, alpha * res)\n \n \n-def softmax(x):\n+def softmax(x, axis=-1):\n     \"\"\"Softmax of a tensor.\n \n     # Arguments\n         x: A tensor or variable.\n+        axis: The dimension softmax would be performed on.\n+            The default is -1 which indicates the last dimension.\n \n     # Returns\n         A tensor.\n     \"\"\"\n-    return tf.nn.softmax(x)\n+    return tf.nn.softmax(x, axis=axis)\n \n \n def softplus(x):\n\n@@ -1551,8 +1551,10 @@ def relu(x, alpha=0., max_value=None):\n     return x\n \n \n-def softmax(x):\n+def softmax(x, axis=-1):\n+    if axis == -1 or axis == x.ndim - 1:\n         return T.nnet.softmax(x)\n+    return T.exp(x) / T.exp(x).sum(axis=axis, keepdims=True)\n \n \n def softplus(x):\n\n@@ -998,7 +998,6 @@ class TestBackend(object):\n \n     def test_nn_operations(self):\n         check_single_tensor_operation('relu', (4, 2), BACKENDS, alpha=0.1, max_value=0.5)\n-        check_single_tensor_operation('softmax', (4, 10), BACKENDS)\n         check_single_tensor_operation('softplus', (4, 10), BACKENDS)\n         check_single_tensor_operation('elu', (4, 10), BACKENDS, alpha=0.5)\n \n@@ -1006,6 +1005,9 @@ class TestBackend(object):\n         check_single_tensor_operation('hard_sigmoid', (4, 2), BACKENDS)\n         check_single_tensor_operation('tanh', (4, 2), BACKENDS)\n \n+        check_single_tensor_operation('softmax', (4, 10), BACKENDS)\n+        check_single_tensor_operation('softmax', (4, 5, 3, 10), BACKENDS, axis=2)\n+\n         check_two_tensor_operation('binary_crossentropy', (4, 2), (4, 2), BACKENDS, from_logits=True)\n         # cross_entropy call require the label is a valid probability distribution,\n         # otherwise it is garbage in garbage out...\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#853774ada4aa191ec8ad2f5a3484fae46920bf7c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 12 | Files Changed: 1 | Hunks: 9 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 24 | Churn Cumulative: 319 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -149,21 +149,21 @@ def test_lambda():\n         def mask(inputs, mask=None):\n             return [None, None]\n \n-        i = layers.Input(shape=(64, 64, 3))\n+        i = layers.Input(shape=(3, 2, 1))\n         o = layers.Lambda(function=func,\n                           output_shape=output_shape,\n                           mask=mask)(i)\n \n         o1, o2 = o\n-        assert o1._keras_shape == (None, 64, 64, 3)\n-        assert o2._keras_shape == (None, 64, 64, 3)\n+        assert o1._keras_shape == (None, 3, 2, 1)\n+        assert o2._keras_shape == (None, 3, 2, 1)\n \n         model = Model(i, o)\n \n-        x = np.random.random((4, 64, 64, 3))\n+        x = np.random.random((4, 3, 2, 1))\n         out1, out2 = model.predict(x)\n-        assert out1.shape == (4, 64, 64, 3)\n-        assert out2.shape == (4, 64, 64, 3)\n+        assert out1.shape == (4, 3, 2, 1)\n+        assert out2.shape == (4, 3, 2, 1)\n         assert_allclose(out1, x * 0.2, atol=1e-4)\n         assert_allclose(out2, x * 0.3, atol=1e-4)\n \n@@ -178,23 +178,23 @@ def test_lambda():\n         def output_shape(input_shape):\n             return [input_shape, input_shape]\n \n-        i = layers.Input(shape=(64, 64, 3))\n+        i = layers.Input(shape=(3, 2, 1))\n         o = layers.Lambda(function=func,\n                           output_shape=output_shape)(i)\n \n-        assert o[0]._keras_shape == (None, 64, 64, 3)\n-        assert o[1]._keras_shape == (None, 64, 64, 3)\n+        assert o[0]._keras_shape == (None, 3, 2, 1)\n+        assert o[1]._keras_shape == (None, 3, 2, 1)\n \n         o = layers.add(o)\n         model = Model(i, o)\n \n-        i2 = layers.Input(shape=(64, 64, 3))\n+        i2 = layers.Input(shape=(3, 2, 1))\n         o2 = model(i2)\n         model2 = Model(i2, o2)\n \n-        x = np.random.random((4, 64, 64, 3))\n+        x = np.random.random((4, 3, 2, 1))\n         out = model2.predict(x)\n-        assert out.shape == (4, 64, 64, 3)\n+        assert out.shape == (4, 3, 2, 1)\n         assert_allclose(out, x * 0.2 + x * 0.3, atol=1e-4)\n \n     test_multiple_outputs_no_mask()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#be87868aa27b262b61b20cd74bcacd6728545c52", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 5487 | Contributors (this commit): 81 | Commits (past 90d): 8 | Contributors (cumulative): 81 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1554,7 +1554,8 @@ def relu(x, alpha=0., max_value=None):\n def softmax(x, axis=-1):\n     if axis == -1 or axis == x.ndim - 1:\n         return T.nnet.softmax(x)\n-    return T.exp(x) / T.exp(x).sum(axis=axis, keepdims=True)\n+    return T.exp(x - x.max()) / T.exp(\n+        x - x.max()).sum(axis=axis, keepdims=True)\n \n \n def softplus(x):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#96f71e70dc54282df4a693c54efdbfd7d52429af", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 10691 | Contributors (this commit): 53 | Commits (past 90d): 6 | Contributors (cumulative): 53 | DMM Complexity: None\n\nDIFF:\n@@ -2042,14 +2042,14 @@ class ZeroPadding3D(Layer):\n     \"\"\"Zero-padding layer for 3D data (spatial or spatio-temporal).\n \n     # Arguments\n-        padding: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n+        padding: int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n             - If int: the same symmetric padding\n                 is applied to width and height.\n-            - If tuple of 2 ints:\n+            - If tuple of 3 ints:\n                 interpreted as two different\n                 symmetric padding values for height and width:\n                 `(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad)`.\n-            - If tuple of 2 tuples of 2 ints:\n+            - If tuple of 3 tuples of 2 ints:\n                 interpreted as\n                 `((left_dim1_pad, right_dim1_pad), (left_dim2_pad, right_dim2_pad), (left_dim3_pad, right_dim3_pad))`\n         data_format: A string,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5d8063359d5d4223a8b892d186118c500890c932", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 39 | Files Changed: 2 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): -5/0 | Churn Δ: 42 | Churn Cumulative: 3424 | Contributors (this commit): 53 | Commits (past 90d): 23 | Contributors (cumulative): 63 | DMM Complexity: 1.0\n\nDIFF:\n@@ -580,6 +580,8 @@ class ImageDataGenerator(object):\n         # Returns\n             The inputs, normalized.\n         \"\"\"\n+        if self.preprocessing_function:\n+            x = self.image_data_generator.preprocessing_function(x)\n         if self.rescale:\n             x *= self.rescale\n         if self.samplewise_center:\n@@ -949,8 +951,6 @@ class NumpyArrayIterator(Iterator):\n                            dtype=K.floatx())\n         for i, j in enumerate(index_array):\n             x = self.x[j]\n-            if self.image_data_generator.preprocessing_function:\n-                x = self.image_data_generator.preprocessing_function(x)\n             x = self.image_data_generator.random_transform(x.astype(K.floatx()))\n             x = self.image_data_generator.standardize(x)\n             batch_x[i] = x\n@@ -1227,21 +1227,8 @@ class DirectoryIterator(Iterator):\n             fname = self.filenames[j]\n             img = load_img(os.path.join(self.directory, fname),\n                            grayscale=grayscale,\n-                           target_size=None,\n+                           target_size=self.target_size,\n                            interpolation=self.interpolation)\n-            if self.image_data_generator.preprocessing_function:\n-                img = self.image_data_generator.preprocessing_function(img)\n-            if self.target_size is not None:\n-                width_height_tuple = (self.target_size[1], self.target_size[0])\n-                if img.size != width_height_tuple:\n-                    if self.interpolation not in _PIL_INTERPOLATION_METHODS:\n-                        raise ValueError(\n-                            'Invalid interpolation method {} specified. Supported '\n-                            'methods are {}'.format(\n-                                self.interpolation,\n-                                \", \".join(_PIL_INTERPOLATION_METHODS.keys())))\n-                    resample = _PIL_INTERPOLATION_METHODS[self.interpolation]\n-                    img = img.resize(width_height_tuple, resample)\n             x = img_to_array(img, data_format=self.data_format)\n             x = self.image_data_generator.random_transform(x)\n             x = self.image_data_generator.standardize(x)\n\n@@ -235,29 +235,6 @@ class TestImage(object):\n         with pytest.raises(ValueError):\n             x1, y1 = dir_seq[9]\n \n-        # Test Preprocessing before resize\n-        def preprocess_test(img):\n-            return img.resize((1, 1))\n-\n-        generator = image.ImageDataGenerator(preprocessing_function=preprocess_test)\n-        dir_seq = generator.flow_from_directory(str(tmpdir),\n-                                                target_size=(26, 26),\n-                                                color_mode='rgb',\n-                                                batch_size=1,\n-                                                class_mode='categorical')\n-\n-        gen_x1, gen_y1 = dir_seq[1]\n-\n-        test_x1 = image.load_img(os.path.join(dir_seq.directory, dir_seq.filenames[1]),\n-                                 grayscale=False)\n-        test_x1 = preprocess_test(test_x1)\n-        test_x1 = test_x1.resize((26, 26))\n-        test_x1 = image.img_to_array(test_x1)\n-        test_x1 = dir_seq.image_data_generator.random_transform(test_x1)\n-        test_x1 = dir_seq.image_data_generator.standardize(test_x1)\n-\n-        assert gen_x1.shape[1:] == test_x1.shape\n-\n     def test_directory_iterator_class_mode_input(self, tmpdir):\n         tmpdir.join('class-1').mkdir()\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
