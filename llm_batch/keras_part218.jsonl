{"custom_id": "keras#925ca148de9f5367c6fa148554ba552435df6ab5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 211 | Contributors (this commit): 6 | Commits (past 90d): 8 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -171,7 +171,7 @@ def multi_gpu_model(model, gpus):\n     # Merge outputs on CPU.\n     with tf.device('/cpu:0'):\n         merged = []\n-        for outputs in all_outputs:\n+        for name, outputs in zip(model.output_names, all_outputs):\n             merged.append(concatenate(outputs,\n-                                      axis=0))\n+                                      axis=0, name=name))\n         return Model(model.inputs, merged)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#236c3ebed52f9eb224657206d7aebfc1c1478f72", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 637 | Contributors (this commit): 4 | Commits (past 90d): 6 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -61,11 +61,6 @@ model_type = 'ResNet%d v%d' % (depth, version)\n (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n \n # Input image dimensions.\n-# We assume data format \"channels_last\".\n-img_rows = x_train.shape[1]\n-img_cols = x_train.shape[2]\n-channels = x_train.shape[3]\n-\n if K.image_data_format() == 'channels_first':\n     img_rows = x_train.shape[2]\n     img_cols = x_train.shape[3]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bc53ef938a0e3d142ec596f75b87b642c19f10b9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 5 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 1286 | Contributors (this commit): 17 | Commits (past 90d): 2 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -20,18 +20,18 @@ class BaseWrapper(object):\n         build_fn: callable function or class instance\n         **sk_params: model parameters & fitting parameters\n \n-    The build_fn should construct, compile and return a Keras model, which\n+    The `build_fn` should construct, compile and return a Keras model, which\n     will then be used to fit/predict. One of the following\n-    three values could be passed to build_fn:\n+    three values could be passed to `build_fn`:\n     1. A function\n-    2. An instance of a class that implements the __call__ method\n+    2. An instance of a class that implements the `__call__` method\n     3. None. This means you implement a class that inherits from either\n-    `KerasClassifier` or `KerasRegressor`. The __call__ method of the\n-    present class will then be treated as the default build_fn.\n+    `KerasClassifier` or `KerasRegressor`. The `__call__` method of the\n+    present class will then be treated as the default `build_fn`.\n \n     `sk_params` takes both model parameters and fitting parameters. Legal model\n     parameters are the arguments of `build_fn`. Note that like all other\n-    estimators in scikit-learn, 'build_fn' should provide default values for\n+    estimators in scikit-learn, `build_fn` should provide default values for\n     its arguments, so that you could create the estimator without passing any\n     values to `sk_params`.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8fe4af613260c872e9429b7e76bba43eb76eabec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 5806 | Contributors (this commit): 72 | Commits (past 90d): 28 | Contributors (cumulative): 72 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1399,6 +1399,8 @@ class Model(Container):\n         for output_shape, loss_fn in zip(self._feed_output_shapes, self._feed_loss_fns):\n             if loss_fn is losses.sparse_categorical_crossentropy:\n                 output_shapes.append(output_shape[:-1] + (1,))\n+            elif getattr(losses, loss_fn.__name__, None) is None:\n+                output_shapes.append(None)\n             else:\n                 output_shapes.append(output_shape)\n         x = _standardize_input_data(x, self._feed_input_names,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2c64566855b39060484f07269303dfd115d5e5fa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 22 | Churn Cumulative: 2662 | Contributors (this commit): 45 | Commits (past 90d): 15 | Contributors (cumulative): 45 | DMM Complexity: 0.5\n\nDIFF:\n@@ -499,7 +499,8 @@ class ImageDataGenerator(object):\n                             save_to_dir=None,\n                             save_prefix='',\n                             save_format='png',\n-                            follow_links=False):\n+                            follow_links=False,\n+                            interpolation='nearest'):\n         return DirectoryIterator(\n             directory, self,\n             target_size=target_size, color_mode=color_mode,\n@@ -509,7 +510,8 @@ class ImageDataGenerator(object):\n             save_to_dir=save_to_dir,\n             save_prefix=save_prefix,\n             save_format=save_format,\n-            follow_links=follow_links)\n+            follow_links=follow_links,\n+            interpolation=interpolation)\n \n     def standardize(self, x):\n         \"\"\"Apply the normalization configuration to a batch of inputs.\n@@ -1002,15 +1004,21 @@ class DirectoryIterator(Iterator):\n             images (if `save_to_dir` is set).\n         save_format: Format to use for saving sample images\n             (if `save_to_dir` is set).\n+        interpolation: Interpolation method used to resample the image if the\n+            target size is different from that of the loaded image.\n+            Supported methods are \"nearest\", \"bilinear\", and \"bicubic\".\n+            If PIL version 1.1.3 or newer is installed, \"lanczos\" is also\n+            supported. If PIL version 3.4.0 or newer is installed, \"box\" and\n+            \"hamming\" are also supported. By default, \"nearest\" is used.\n     \"\"\"\n \n     def __init__(self, directory, image_data_generator,\n                  target_size=(256, 256), color_mode='rgb',\n                  classes=None, class_mode='categorical',\n                  batch_size=32, shuffle=True, seed=None,\n-                 data_format=None,\n-                 save_to_dir=None, save_prefix='', save_format='png',\n-                 follow_links=False):\n+                 data_format=None, save_to_dir=None,\n+                 save_prefix='', save_format='png',\n+                 follow_links=False, interpolation='nearest'):\n         if data_format is None:\n             data_format = K.image_data_format()\n         self.directory = directory\n@@ -1042,6 +1050,7 @@ class DirectoryIterator(Iterator):\n         self.save_to_dir = save_to_dir\n         self.save_prefix = save_prefix\n         self.save_format = save_format\n+        self.interpolation = interpolation\n \n         white_list_formats = {'png', 'jpg', 'jpeg', 'bmp', 'ppm'}\n \n@@ -1093,7 +1102,8 @@ class DirectoryIterator(Iterator):\n             fname = self.filenames[j]\n             img = load_img(os.path.join(self.directory, fname),\n                            grayscale=grayscale,\n-                           target_size=self.target_size)\n+                           target_size=self.target_size,\n+                           interpolation=self.interpolation)\n             x = img_to_array(img, data_format=self.data_format)\n             x = self.image_data_generator.random_transform(x)\n             x = self.image_data_generator.standardize(x)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e0d9fcb91ad4cd8d993c3225cda508a30b3095b9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 5401 | Contributors (this commit): 79 | Commits (past 90d): 6 | Contributors (cumulative): 79 | DMM Complexity: None\n\nDIFF:\n@@ -5,6 +5,7 @@ from theano import tensor as T\n from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n from theano.tensor.signal import pool\n from theano.printing import Print\n+from theano.ifelse import ifelse\n try:\n     import theano.sparse as th_sparse_module\n except ImportError:\n@@ -1500,7 +1501,7 @@ def in_train_phase(x, alt, training=None):\n         alt = alt()\n \n     # else: assume learning phase is a placeholder tensor.\n-    x = theano.ifelse.ifelse(training, x, alt)\n+    x = ifelse(training, x, alt)\n     if uses_learning_phase:\n         x._uses_learning_phase = True\n     return x\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5665b4d41ee1cf2cda0e422e6dabe741a0e0a4ce", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 7 | Churn Cumulative: 5813 | Contributors (this commit): 72 | Commits (past 90d): 29 | Contributors (cumulative): 72 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1399,7 +1399,12 @@ class Model(Container):\n         for output_shape, loss_fn in zip(self._feed_output_shapes, self._feed_loss_fns):\n             if loss_fn is losses.sparse_categorical_crossentropy:\n                 output_shapes.append(output_shape[:-1] + (1,))\n-            elif getattr(losses, loss_fn.__name__, None) is None:\n+            elif (not hasattr(loss_fn, '__name__') or\n+                  getattr(losses, loss_fn.__name__, None) is None):\n+                # If `loss_fn` is not a function (e.g. callable class)\n+                # or if it not in the `losses` module, then\n+                # it is a user-defined loss and we make no assumptions\n+                # about it.\n                 output_shapes.append(None)\n             else:\n                 output_shapes.append(output_shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#69f231cbfd5c90092d37567bd2049ef6f4597b43", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 639 | Contributors (this commit): 4 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -325,7 +325,7 @@ print(model_type)\n \n # Prepare model model saving directory.\n save_dir = os.path.join(os.getcwd(), 'saved_models')\n-model_name = 'cifar10_resnet_model.{epoch:02d}.h5'\n+model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n if not os.path.isdir(save_dir):\n     os.makedirs(save_dir)\n filepath = os.path.join(save_dir, model_name)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f2c010b4c4b4e1b18e04d24fd5568b6c8a698836", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 476 | Contributors (this commit): 11 | Commits (past 90d): 2 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -193,11 +193,10 @@ for iteration in range(1, 200):\n         q = ctable.decode(rowx[0])\n         correct = ctable.decode(rowy[0])\n         guess = ctable.decode(preds[0], calc_argmax=False)\n-        print('Q', q[::-1] if INVERT else q)\n-        print('T', correct)\n+        print('Q', q[::-1] if INVERT else q, end=' ')\n+        print('T', correct, end=' ')\n         if correct == guess:\n-            print(colors.ok + '☑' + colors.close, end=\" \")\n+            print(colors.ok + '☑' + colors.close, end=' ')\n         else:\n-            print(colors.fail + '☒' + colors.close, end=\" \")\n+            print(colors.fail + '☒' + colors.close, end=' ')\n         print(guess)\n-        print('---')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#42ccc34b337f9eb05de7f864a88844352740133a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 125 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -19,8 +19,6 @@ and tf.data is preferred. See the release notes for details.\n This example is intended to closely follow the\n mnist_tfrecord.py example.\n '''\n-from __future__ import division\n-\n import numpy as np\n import os\n import tempfile\n@@ -57,7 +55,7 @@ def cnn_layers(inputs):\n \n batch_size = 128\n buffer_size = 10000\n-steps_per_epoch = np.ceil(60000 / 128).astype('int')  # = 469\n+steps_per_epoch = int(np.ceil(60000 / float(batch_size)))  # = 469\n epochs = 5\n num_classes = 10\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#716e138c08fb5907652429df969e0be9babd6a22", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 75 | Contributors (this commit): 7 | Commits (past 90d): 4 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -47,13 +47,11 @@ def logcosh(y_true, y_pred):\n     `log(cosh(x))` is approximately equal to `(x ** 2) / 2` for small `x` and\n     to `abs(x) - log(2)` for large `x`. This means that 'logcosh' works mostly\n     like the mean squared error, but will not be so strongly affected by the\n-    occasional wildly incorrect prediction. However, it may return NaNs if the\n-    intermediate value `cosh(y_pred - y_true)` is too large to be represented\n-    in the chosen precision.\n+    occasional wildly incorrect prediction.\n     \"\"\"\n-    def cosh(x):\n-        return (K.exp(x) + K.exp(-x)) / 2\n-    return K.mean(K.log(cosh(y_pred - y_true)), axis=-1)\n+    def _logcosh(x):\n+        return x + K.softplus(-2. * x) - K.log(2.)\n+    return K.mean(_logcosh(y_pred - y_true), axis=-1)\n \n \n def categorical_crossentropy(y_true, y_pred):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ce80cd1c85eee49de8e647124b5a87b6ea55ffe6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 12 | Methods Changed: 6 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 39 | Churn Cumulative: 6257 | Contributors (this commit): 74 | Commits (past 90d): 30 | Contributors (cumulative): 80 | DMM Complexity: 0.6086956521739131\n\nDIFF:\n@@ -1969,7 +1969,8 @@ class Model(Container):\n                 If unspecified, `max_queue_size` will default to 10.\n             workers: Integer. Maximum number of processes to spin up\n                 when using process based threading.\n-                If unspecified, `workers` will default to 1.\n+                If unspecified, `workers` will default to 1. If 0, will\n+                execute the generator on the main thread.\n             use_multiprocessing: Boolean. If True, use process based threading.\n                 If unspecified, `workers` will default to False.\n                 Note that because\n@@ -2091,6 +2092,7 @@ class Model(Container):\n         enqueuer = None\n \n         try:\n+            if workers > 0:\n                 if is_sequence:\n                     enqueuer = OrderedEnqueuer(generator,\n                                                use_multiprocessing=use_multiprocessing,\n@@ -2101,6 +2103,8 @@ class Model(Container):\n                                                  wait_time=wait_time)\n                 enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n                 output_generator = enqueuer.get()\n+            else:\n+                output_generator = generator\n \n             callback_model.stop_training = False\n             while epoch < epochs:\n@@ -2213,8 +2217,10 @@ class Model(Container):\n                 Optional for `Sequence`: if unspecified, will use\n                 the `len(generator)` as a number of steps.\n             max_queue_size: maximum size for the generator queue\n-            workers: maximum number of processes to spin up\n-                when using process based threading\n+            workers: Integer. Maximum number of processes to spin up\n+                when using process based threading.\n+                If unspecified, `workers` will default to 1. If 0, will\n+                execute the generator on the main thread.\n             use_multiprocessing: if True, use process based threading.\n                 Note that because\n                 this implementation relies on multiprocessing,\n@@ -2257,6 +2263,7 @@ class Model(Container):\n         enqueuer = None\n \n         try:\n+            if workers > 0:\n                 if is_sequence:\n                     enqueuer = OrderedEnqueuer(generator,\n                                                use_multiprocessing=use_multiprocessing)\n@@ -2266,6 +2273,8 @@ class Model(Container):\n                                                  wait_time=wait_time)\n                 enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n                 output_generator = enqueuer.get()\n+            else:\n+                output_generator = generator\n \n             while steps_done < steps:\n                 generator_output = next(output_generator)\n@@ -2335,8 +2344,10 @@ class Model(Container):\n                 Optional for `Sequence`: if unspecified, will use\n                 the `len(generator)` as a number of steps.\n             max_queue_size: Maximum size for the generator queue.\n-            workers: Maximum number of processes to spin up\n-                when using process based threading\n+            workers: Integer. Maximum number of processes to spin up\n+                when using process based threading.\n+                If unspecified, `workers` will default to 1. If 0, will\n+                execute the generator on the main thread.\n             use_multiprocessing: If `True`, use process based threading.\n                 Note that because\n                 this implementation relies on multiprocessing,\n@@ -2376,6 +2387,7 @@ class Model(Container):\n         enqueuer = None\n \n         try:\n+            if workers > 0:\n                 if is_sequence:\n                     enqueuer = OrderedEnqueuer(generator,\n                                                use_multiprocessing=use_multiprocessing)\n@@ -2385,6 +2397,8 @@ class Model(Container):\n                                                  wait_time=wait_time)\n                 enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n                 output_generator = enqueuer.get()\n+            else:\n+                output_generator = generator\n \n             if verbose == 1:\n                 progbar = Progbar(target=steps)\n\n@@ -72,6 +72,12 @@ def test_multiprocessing_training():\n                         validation_data=custom_generator(True),\n                         validation_steps=1)\n \n+    model.fit_generator(custom_generator(True),\n+                        steps_per_epoch=5,\n+                        validation_data=custom_generator(True),\n+                        validation_steps=1,\n+                        workers=0)\n+\n     # Test invalid use cases\n     def invalid_generator():\n         while True:\n@@ -173,6 +179,10 @@ def test_multiprocessing_predicting():\n                             steps=5,\n                             max_queue_size=10,\n                             use_multiprocessing=False)\n+    model.predict_generator(custom_generator(),\n+                            steps=5,\n+                            max_queue_size=10,\n+                            workers=0)\n \n \n @keras_test\n@@ -206,6 +216,11 @@ def test_multiprocessing_evaluating():\n                              steps=5,\n                              max_queue_size=10,\n                              use_multiprocessing=False)\n+    model.evaluate_generator(custom_generator(),\n+                             steps=5,\n+                             max_queue_size=10,\n+                             use_multiprocessing=False,\n+                             workers=0)\n \n \n @keras_test\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4e37b0cc8d5775d2745a58b438eefe64b7e5cfd9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 8282 | Contributors (this commit): 53 | Commits (past 90d): 6 | Contributors (cumulative): 53 | DMM Complexity: None\n\nDIFF:\n@@ -1425,11 +1425,11 @@ def Input(shape=None, batch_shape=None,\n         ```\n     \"\"\"\n     if not batch_shape and tensor is None:\n-        assert shape, ('Please provide to Input either a `shape`'\n+        assert shape is not None, ('Please provide to Input either a `shape`'\n                                    ' or a `batch_shape` argument. Note that '\n                                    '`shape` does not include the batch '\n                                    'dimension.')\n-    if shape and not batch_shape:\n+    if shape is not None and not batch_shape:\n         batch_shape = (None,) + tuple(shape)\n     if not dtype:\n         dtype = K.floatx()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dea301923dfce820701818214965f0acb82907a3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 20 | Churn Cumulative: 8864 | Contributors (this commit): 58 | Commits (past 90d): 9 | Contributors (cumulative): 64 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3029,9 +3029,10 @@ def preprocess_weights_for_loading(layer, weights,\n                 weights[1] = np.transpose(weights[1], (3, 2, 0, 1))\n \n     # convert the weights of CuDNNLSTM so that they could be loaded into LSTM\n-    if layer.__class__.__name__ == 'LSTM':\n+    if layer.__class__.__name__ == 'LSTM' and len(weights) == 3:\n         # determine if we're loading a CuDNNLSTM layer from the number of bias weights:\n         # CuDNNLSTM has (units * 8) weights; while LSTM has (units * 4)\n+        # if there's no bias weight in the file, skip this conversion\n         units = weights[1].shape[0]\n         bias = weights[2]\n         if len(bias) == units * 8:\n\n@@ -370,5 +370,22 @@ def test_saving_recurrent_layer_with_init_state():\n     loaded_model = load_model(fname)\n     os.remove(fname)\n \n+\n+@keras_test\n+def test_saving_recurrent_layer_without_bias():\n+    vector_size = 8\n+    input_length = 20\n+\n+    input_x = Input(shape=(input_length, vector_size))\n+    lstm = LSTM(vector_size, use_bias=False)(input_x)\n+    model = Model(inputs=[input_x], outputs=[lstm])\n+\n+    _, fname = tempfile.mkstemp('.h5')\n+    model.save(fname)\n+\n+    loaded_model = load_model(fname)\n+    os.remove(fname)\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c24406fc9ff05edb2ab261a65e7e07ced9094a0d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 654 | Contributors (this commit): 4 | Commits (past 90d): 8 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -61,20 +61,7 @@ model_type = 'ResNet%dv%d' % (depth, version)\n (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n \n # Input image dimensions.\n-if K.image_data_format() == 'channels_first':\n-    img_rows = x_train.shape[2]\n-    img_cols = x_train.shape[3]\n-    channels = x_train.shape[1]\n-    x_train = x_train.reshape(x_train.shape[0], channels, img_rows, img_cols)\n-    x_test = x_test.reshape(x_test.shape[0], channels, img_rows, img_cols)\n-    input_shape = (channels, img_rows, img_cols)\n-else:\n-    img_rows = x_train.shape[1]\n-    img_cols = x_train.shape[2]\n-    channels = x_train.shape[3]\n-    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, channels)\n-    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, channels)\n-    input_shape = (img_rows, img_cols, channels)\n+input_shape = x_train.shape[1:]\n \n # Normalize data.\n x_train = x_train.astype('float32') / 255\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c3842edd8ea5da4626ffe6cb7f6c1965fa956757", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 5845 | Contributors (this commit): 74 | Commits (past 90d): 27 | Contributors (cumulative): 74 | DMM Complexity: None\n\nDIFF:\n@@ -195,7 +195,7 @@ def _standardize_sample_or_class_weights(x_weight, output_names, weight_type):\n     else:\n         raise TypeError('The model has multiple outputs, so `' +\n                         weight_type + '` '\n-                        'should be either a list of a dict. '\n+                        'should be either a list or a dict. '\n                         'Provided `' + weight_type +\n                         '` type not understood: ' +\n                         str(x_weight))\n@@ -701,7 +701,7 @@ class Model(Container):\n         elif isinstance(loss_weights, list):\n             if len(loss_weights) != len(self.outputs):\n                 raise ValueError('When passing a list as loss_weights, '\n-                                 'it should have one entry per model outputs. '\n+                                 'it should have one entry per model output. '\n                                  'The model has ' + str(len(self.outputs)) +\n                                  ' outputs, but you passed loss_weights=' +\n                                  str(loss_weights))\n@@ -719,7 +719,7 @@ class Model(Container):\n                 if len(target_tensors) != len(self.outputs):\n                     raise ValueError(\n                         'When passing a list as `target_tensors`, '\n-                        'it should have one entry per model outputs. '\n+                        'it should have one entry per model output. '\n                         'The model has ' + str(len(self.outputs)) +\n                         ' outputs, but you passed target_tensors=' +\n                         str(target_tensors))\n@@ -794,7 +794,7 @@ class Model(Container):\n         elif isinstance(sample_weight_mode, list):\n             if len(sample_weight_mode) != len(self.outputs):\n                 raise ValueError('When passing a list as sample_weight_mode, '\n-                                 'it should have one entry per model outputs. '\n+                                 'it should have one entry per model output. '\n                                  'The model has ' + str(len(self.outputs)) +\n                                  ' outputs, but you passed '\n                                  'sample_weight_mode=' +\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#98851dfac355c0be518351c962b0f847afa09cf9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 8291 | Contributors (this commit): 54 | Commits (past 90d): 8 | Contributors (cumulative): 54 | DMM Complexity: None\n\nDIFF:\n@@ -1378,7 +1378,7 @@ def Input(shape=None, batch_shape=None,\n     \"\"\"`Input()` is used to instantiate a Keras tensor.\n \n     A Keras tensor is a tensor object from the underlying backend\n-    (Theano or TensorFlow), which we augment with certain\n+    (Theano, TensorFlow or CNTK), which we augment with certain\n     attributes that allow us to build a Keras model\n     just by knowing the inputs and outputs of the model.\n \n@@ -1387,9 +1387,9 @@ def Input(shape=None, batch_shape=None,\n     `model = Model(input=[a, b], output=c)`\n \n     The added Keras attributes are:\n-        ._keras_shape: Integer shape tuple propagated\n+        `_keras_shape`: Integer shape tuple propagated\n             via Keras-side shape inference.\n-        ._keras_history: Last layer applied to the tensor.\n+        `_keras_history`: Last layer applied to the tensor.\n             the entire layer graph is retrievable from that layer,\n             recursively.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cdd95c08bafe4d70b3c1163c9b9387e0efd2325b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 5851 | Contributors (this commit): 75 | Commits (past 90d): 28 | Contributors (cumulative): 75 | DMM Complexity: None\n\nDIFF:\n@@ -2296,11 +2296,11 @@ class Model(Container):\n                 outs = self.test_on_batch(x, y, sample_weight=sample_weight)\n \n                 if isinstance(x, list):\n-                    batch_size = len(x[0])\n+                    batch_size = x[0].shape[0]\n                 elif isinstance(x, dict):\n-                    batch_size = len(list(x.values())[0])\n+                    batch_size = list(x.values())[0].shape[0]\n                 else:\n-                    batch_size = len(x)\n+                    batch_size = x.shape[0]\n                 if batch_size == 0:\n                     raise ValueError('Received an empty batch. '\n                                      'Batches should at least contain one item.')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bc285462ad8ec9b8bc00bd6e09f9bcd9ae3d84a2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1275 | Contributors (this commit): 15 | Commits (past 90d): 15 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -11,7 +11,6 @@ from keras.preprocessing.image import ImageDataGenerator\n from keras.models import Sequential\n from keras.layers import Dense, Dropout, Activation, Flatten\n from keras.layers import Conv2D, MaxPooling2D\n-import numpy as np\n import os\n \n batch_size = 32\n@@ -97,7 +96,6 @@ else:\n     # Fit the model on the batches generated by datagen.flow().\n     model.fit_generator(datagen.flow(x_train, y_train,\n                                      batch_size=batch_size),\n-                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),\n                         epochs=epochs,\n                         validation_data=(x_test, y_test),\n                         workers=4)\n\n@@ -371,9 +371,7 @@ else:\n     datagen.fit(x_train)\n \n     # Fit the model on the batches generated by datagen.flow().\n-    steps_per_epoch = int(np.ceil(x_train.shape[0] / float(batch_size)))\n     model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n-                        steps_per_epoch=steps_per_epoch,\n                         validation_data=(x_test, y_test),\n                         epochs=epochs, verbose=1, workers=4,\n                         callbacks=callbacks)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#45e781c305edc0ee23af8a60bfa73a6e2e19839a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 19 | Churn Cumulative: 1066 | Contributors (this commit): 25 | Commits (past 90d): 14 | Contributors (cumulative): 29 | DMM Complexity: 1.0\n\nDIFF:\n@@ -9,6 +9,7 @@ import six\n import marshal\n import types as python_types\n import inspect\n+import codecs\n \n _GLOBAL_CUSTOM_OBJECTS = {}\n \n@@ -172,7 +173,8 @@ def func_dump(func):\n     # Returns\n         A tuple `(code, defaults, closure)`.\n     \"\"\"\n-    code = marshal.dumps(func.__code__).decode('raw_unicode_escape')\n+    raw_code = marshal.dumps(func.__code__)\n+    code = codecs.encode(raw_code, 'base64').decode('ascii')\n     defaults = func.__defaults__\n     if func.__closure__:\n         closure = tuple(c.cell_contents for c in func.__closure__)\n@@ -197,7 +199,8 @@ def func_load(code, defaults=None, closure=None, globs=None):\n         code, defaults, closure = code\n         if isinstance(defaults, list):\n             defaults = tuple(defaults)\n-    code = marshal.loads(code.encode('raw_unicode_escape'))\n+    raw_code = codecs.decode(code.encode('ascii'), 'base64')\n+    code = marshal.loads(raw_code)\n     if globs is None:\n         globs = globals()\n     return python_types.FunctionType(code, globs,\n\n@@ -4,6 +4,8 @@ import numpy as np\n from keras.utils.generic_utils import custom_object_scope\n from keras.utils.generic_utils import has_arg\n from keras.utils.generic_utils import Progbar\n+from keras.utils.generic_utils import func_dump\n+from keras.utils.generic_utils import func_load\n from keras.utils.test_utils import keras_test\n from keras import activations\n from keras import regularizers\n@@ -76,5 +78,15 @@ def test_has_arg_positional_only():\n     assert has_arg(pow, 'x') is False\n \n \n+def test_func_dump_and_load():\n+    def test_func():\n+        return r'\\u'\n+    serialized = func_dump(test_func)\n+    deserialized = func_load(serialized)\n+    assert deserialized.__code__ == test_func.__code__\n+    assert deserialized.__defaults__ == test_func.__defaults__\n+    assert deserialized.__closure__ == test_func.__closure__\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#785384016277ae624fe1f5ff0876ed95c2936ef7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 104 | Lines Deleted: 20 | Files Changed: 2 | Hunks: 7 | Methods Changed: 4 | Complexity Δ (Sum/Max): 10/9 | Churn Δ: 124 | Churn Cumulative: 610 | Contributors (this commit): 7 | Commits (past 90d): 4 | Contributors (cumulative): 9 | DMM Complexity: 0.6557377049180327\n\nDIFF:\n@@ -1,5 +1,6 @@\n import json\n import warnings\n+import numpy as np\n \n from ..utils.data_utils import get_file\n from .. import backend as K\n@@ -7,28 +8,11 @@ from .. import backend as K\n CLASS_INDEX = None\n CLASS_INDEX_PATH = 'https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json'\n \n+# Global Numpy arrays of imagenet mean for preprocessing symbolic inputs\n+_IMAGENET_MEAN = None\n \n-def preprocess_input(x, data_format=None, mode='caffe'):\n-    \"\"\"Preprocesses a tensor encoding a batch of images.\n-\n-    # Arguments\n-        x: input Numpy tensor, 4D.\n-        data_format: data format of the image tensor.\n-        mode: One of \"caffe\", \"tf\".\n-            - caffe: will convert the images from RGB to BGR,\n-                then will zero-center each color channel with\n-                respect to the ImageNet dataset,\n-                without scaling.\n-            - tf: will scale pixels between -1 and 1,\n-                sample-wise.\n-\n-    # Returns\n-        Preprocessed tensor.\n-    \"\"\"\n-    if data_format is None:\n-        data_format = K.image_data_format()\n-    assert data_format in {'channels_last', 'channels_first'}\n \n+def _preprocess_numpy_input(x, data_format, mode):\n     if mode == 'tf':\n         x /= 255.\n         x -= 0.5\n@@ -58,6 +42,64 @@ def preprocess_input(x, data_format=None, mode='caffe'):\n     return x\n \n \n+def _preprocess_symbolic_input(x, data_format, mode):\n+    global _IMAGENET_MEAN\n+\n+    if mode == 'tf':\n+        x /= 255.\n+        x -= 0.5\n+        x *= 2.\n+        return x\n+\n+    if data_format == 'channels_first':\n+        # 'RGB'->'BGR'\n+        if K.ndim(x) == 3:\n+            x = x[::-1, ...]\n+        else:\n+            x = x[:, ::-1, ...]\n+    else:\n+        # 'RGB'->'BGR'\n+        x = x[..., ::-1]\n+\n+    if _IMAGENET_MEAN is None:\n+        _IMAGENET_MEAN = K.constant(-np.array([103.939, 116.779, 123.68]))\n+    # Zero-center by mean pixel\n+    if K.dtype(x) != K.dtype(_IMAGENET_MEAN):\n+        x = K.bias_add(x, K.cast(_IMAGENET_MEAN, K.dtype(x)), data_format)\n+    else:\n+        x = K.bias_add(x, _IMAGENET_MEAN, data_format)\n+    return x\n+\n+\n+def preprocess_input(x, data_format=None, mode='caffe'):\n+    \"\"\"Preprocesses a tensor encoding a batch of images.\n+\n+    # Arguments\n+        x: input Numpy or symoblic tensor, 3D or 4D.\n+        data_format: data format of the image tensor.\n+        mode: One of \"caffe\", \"tf\".\n+            - caffe: will convert the images from RGB to BGR,\n+                then will zero-center each color channel with\n+                respect to the ImageNet dataset,\n+                without scaling.\n+            - tf: will scale pixels between -1 and 1,\n+                sample-wise.\n+\n+    # Returns\n+        Preprocessed tensor.\n+    \"\"\"\n+    if data_format is None:\n+        data_format = K.image_data_format()\n+    if data_format not in {'channels_first', 'channels_last'}:\n+        raise ValueError('Unknown data_format ' + str(data_format))\n+\n+    if isinstance(x, np.ndarray):\n+        return _preprocess_numpy_input(x, data_format=data_format, mode=mode)\n+    else:\n+        return _preprocess_symbolic_input(x, data_format=data_format,\n+                                          mode=mode)\n+\n+\n def decode_predictions(preds, top=5):\n     \"\"\"Decodes the prediction of an ImageNet model.\n \n\n@@ -3,6 +3,8 @@ import numpy as np\n from numpy.testing import assert_allclose\n \n from keras.applications import imagenet_utils as utils\n+from keras.models import Model\n+from keras.layers import Input, Lambda\n \n \n def test_preprocess_input():\n@@ -25,6 +27,46 @@ def test_preprocess_input():\n     assert_allclose(out1, out2.transpose(1, 2, 0))\n \n \n+def test_preprocess_input_symbolic():\n+    # Test image batch\n+    x = np.random.uniform(0, 255, (2, 10, 10, 3))\n+    inputs = Input(shape=x.shape[1:])\n+    outputs = Lambda(utils.preprocess_input, output_shape=x.shape[1:])(inputs)\n+    model = Model(inputs, outputs)\n+    assert model.predict(x).shape == x.shape\n+\n+    outputs1 = Lambda(lambda x: utils.preprocess_input(x, 'channels_last'),\n+                      output_shape=x.shape[1:])(inputs)\n+    model1 = Model(inputs, outputs1)\n+    out1 = model1.predict(x)\n+    x2 = np.transpose(x, (0, 3, 1, 2))\n+    inputs2 = Input(shape=x2.shape[1:])\n+    outputs2 = Lambda(lambda x: utils.preprocess_input(x, 'channels_first'),\n+                      output_shape=x2.shape[1:])(inputs2)\n+    model2 = Model(inputs2, outputs2)\n+    out2 = model2.predict(x2)\n+    assert_allclose(out1, out2.transpose(0, 2, 3, 1))\n+\n+    # Test single image\n+    x = np.random.uniform(0, 255, (10, 10, 3))\n+    inputs = Input(shape=x.shape)\n+    outputs = Lambda(utils.preprocess_input, output_shape=x.shape)(inputs)\n+    model = Model(inputs, outputs)\n+    assert model.predict(x[np.newaxis])[0].shape == x.shape\n+\n+    outputs1 = Lambda(lambda x: utils.preprocess_input(x, 'channels_last'),\n+                      output_shape=x.shape)(inputs)\n+    model1 = Model(inputs, outputs1)\n+    out1 = model1.predict(x[np.newaxis])[0]\n+    x2 = np.transpose(x, (2, 0, 1))\n+    inputs2 = Input(shape=x2.shape)\n+    outputs2 = Lambda(lambda x: utils.preprocess_input(x, 'channels_first'),\n+                      output_shape=x2.shape)(inputs2)\n+    model2 = Model(inputs2, outputs2)\n+    out2 = model2.predict(x2[np.newaxis])[0]\n+    assert_allclose(out1, out2.transpose(1, 2, 0))\n+\n+\n def test_decode_predictions():\n     x = np.zeros((2, 1000))\n     x[0, 372] = 1.0\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#017fe07d01751011a054a081d9646d78081c9b3e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 21 | Files Changed: 1 | Hunks: 12 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 51 | Churn Cumulative: 608 | Contributors (this commit): 8 | Commits (past 90d): 12 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -34,7 +34,7 @@ from keras.datasets import mnist\n from keras import layers\n from keras.layers import Input, Dense, Reshape, Flatten, Embedding, Dropout\n from keras.layers.advanced_activations import LeakyReLU\n-from keras.layers.convolutional import UpSampling2D, Conv2D\n+from keras.layers.convolutional import Conv2DTranspose, Conv2D\n from keras.models import Sequential, Model\n from keras.optimizers import Adam\n from keras.utils.generic_utils import Progbar\n@@ -49,24 +49,21 @@ def build_generator(latent_size):\n     # label drawn from P_c, to image space (..., 28, 28, 1)\n     cnn = Sequential()\n \n-    cnn.add(Dense(1024, input_dim=latent_size, activation='relu'))\n-    cnn.add(Dense(128 * 7 * 7, activation='relu'))\n-    cnn.add(Reshape((7, 7, 128)))\n+    cnn.add(Dense(3 * 3 * 384, input_dim=latent_size, activation='relu'))\n+    cnn.add(Reshape((3, 3, 384)))\n+\n+    # upsample to (7, 7, ...)\n+    cnn.add(Conv2DTranspose(192, 5, strides=1, padding='valid',\n+                            activation='relu',\n+                            kernel_initializer='glorot_normal'))\n \n     # upsample to (14, 14, ...)\n-    cnn.add(UpSampling2D(size=(2, 2)))\n-    cnn.add(Conv2D(256, 5, padding='same',\n+    cnn.add(Conv2DTranspose(96, 5, strides=2, padding='same',\n                             activation='relu',\n                             kernel_initializer='glorot_normal'))\n \n     # upsample to (28, 28, ...)\n-    cnn.add(UpSampling2D(size=(2, 2)))\n-    cnn.add(Conv2D(128, 5, padding='same',\n-                   activation='relu',\n-                   kernel_initializer='glorot_normal'))\n-\n-    # take a channel axis reduction\n-    cnn.add(Conv2D(1, 2, padding='same',\n+    cnn.add(Conv2DTranspose(1, 5, strides=2, padding='same',\n                             activation='tanh',\n                             kernel_initializer='glorot_normal'))\n \n@@ -94,19 +91,19 @@ def build_discriminator():\n \n     cnn.add(Conv2D(32, 3, padding='same', strides=2,\n                    input_shape=(28, 28, 1)))\n-    cnn.add(LeakyReLU())\n+    cnn.add(LeakyReLU(0.2))\n     cnn.add(Dropout(0.3))\n \n     cnn.add(Conv2D(64, 3, padding='same', strides=1))\n-    cnn.add(LeakyReLU())\n+    cnn.add(LeakyReLU(0.2))\n     cnn.add(Dropout(0.3))\n \n     cnn.add(Conv2D(128, 3, padding='same', strides=2))\n-    cnn.add(LeakyReLU())\n+    cnn.add(LeakyReLU(0.2))\n     cnn.add(Dropout(0.3))\n \n     cnn.add(Conv2D(256, 3, padding='same', strides=1))\n-    cnn.add(LeakyReLU())\n+    cnn.add(LeakyReLU(0.2))\n     cnn.add(Dropout(0.3))\n \n     cnn.add(Flatten())\n@@ -185,6 +182,16 @@ if __name__ == '__main__':\n         num_batches = int(x_train.shape[0] / batch_size)\n         progress_bar = Progbar(target=num_batches)\n \n+        # we don't want the discriminator to also maximize the classification\n+        # accuracy of the auxilary classifier on generated images, so we\n+        # don't train discriminator to produce class labels for generated\n+        # images (see https://openreview.net/forum?id=rJXTf9Bxg).\n+        # To preserve sum of sample weights for the auxilary classifier,\n+        # we assign sample weight of 2 to the real images.\n+        disc_sample_weight = [np.ones(2 * batch_size),\n+                              np.concatenate((np.ones(batch_size) * 2,\n+                                              np.zeros(batch_size)))]\n+\n         epoch_gen_loss = []\n         epoch_disc_loss = []\n \n@@ -209,12 +216,13 @@ if __name__ == '__main__':\n             x = np.concatenate((image_batch, generated_images))\n \n             # use soft real/fake labels\n-            soft_zero, soft_one = 0.25, 0.75\n+            soft_zero, soft_one = 0.1, 0.9\n             y = np.array([soft_one] * batch_size + [soft_zero] * batch_size)\n             aux_y = np.concatenate((label_batch, sampled_labels), axis=0)\n \n             # see if the discriminator can figure itself out...\n-            epoch_disc_loss.append(discriminator.train_on_batch(x, [y, aux_y]))\n+            epoch_disc_loss.append(discriminator.train_on_batch(\n+                x, [y, aux_y], sample_weight=disc_sample_weight))\n \n             # make new noise. we generate 2 * batch size here such that we have\n             # the generator optimize over an identical number of images as the\n@@ -295,8 +303,9 @@ if __name__ == '__main__':\n             'params_discriminator_epoch_{0:03d}.hdf5'.format(epoch), True)\n \n         # generate some digits to display\n-        num_rows = 10\n-        noise = np.random.uniform(-1, 1, (num_rows * num_classes, latent_size))\n+        num_rows = 40\n+        noise = np.tile(np.random.uniform(-1, 1, (num_rows, latent_size)),\n+                        (num_classes, 1))\n \n         sampled_labels = np.array([\n             [i] * num_rows for i in range(num_classes)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cac44b56baec55b73f655f41f878380962140337", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 9025 | Contributors (this commit): 96 | Commits (past 90d): 23 | Contributors (cumulative): 96 | DMM Complexity: None\n\nDIFF:\n@@ -365,7 +365,7 @@ def variable(value, dtype=None, name=None, constraint=None):\n         'float64'\n         >>> print(kvar)\n         example_var\n-        >>> kvar.eval()\n+        >>> K.eval(kvar)\n         array([[ 1.,  2.],\n                [ 3.,  4.]])\n     ```\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
