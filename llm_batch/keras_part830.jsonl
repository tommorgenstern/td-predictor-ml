{"custom_id": "keras#e09414a658a6a294d9a0b65fd3f9a9f6ab77da8f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 17 | Churn Cumulative: 19 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -221,15 +221,16 @@ def process_id():\n     return jax.process_index()\n \n \n-def _to_jax_device(device_id):\n-    if isinstance(device_id, jax.Device):\n-        return device_id\n-    device_type, index = device_id.split(\":\")\n-    index = int(index)\n+def _to_jax_device(device_name):\n+    if isinstance(device_name, jax.Device):\n+        return device_name\n+    device_type, device_id = device_name.split(\":\")\n+\n     devices = jax.devices(backend=device_type)\n-    if index >= len(devices):\n-        raise ValueError(f\"Unknown device: {device_id}\")\n-    return devices[index]\n+    for device in devices:\n+        if device.platform == device_type and device.id == int(device_id):\n+            return device\n+    raise ValueError(f\"Device not found: {device_name}\")\n \n \n def _to_jax_mesh(device_mesh):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#297df87c14eb3e5cd97611c27aed7bee65be28cb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 28 | Churn Cumulative: 72 | Contributors (this commit): 4 | Commits (past 90d): 6 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -29,6 +29,8 @@ def uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n \n def categorical(logits, num_samples, dtype=\"int64\", seed=None):\n     seed = draw_seed(seed)\n+    # Only int32 seeds are supported in stateless_categorical.\n+    seed = tf.cast(tf.math.floormod(seed, tf.int32.max - 1), dtype=\"int32\")\n     output = tf.random.stateless_categorical(logits, num_samples, seed=seed)\n     return tf.cast(output, dtype)\n \n\n@@ -0,0 +1,26 @@\n+import pytest\n+import tensorflow as tf\n+\n+from keras.src import backend\n+from keras.src.backend.tensorflow import random\n+from keras.src.testing import TestCase\n+\n+\n+@pytest.mark.skipif(\n+    backend.backend() != \"tensorflow\",\n+    reason=\"Only applies to TensorFlow random ops.\",\n+)\n+class TFRandomTest(TestCase):\n+\n+    def test_categorical(self):\n+        inputs = tf.ones([2, 3], dtype=\"float32\")\n+        outputs = random.categorical(inputs, 2, seed=42)\n+        expected = tf.constant([[0, 2], [1, 0]])\n+        self.assertAllClose(outputs, expected)\n+\n+    def test_categorical_seed_cast(self):\n+        inputs = tf.ones([2, 3], dtype=\"float32\")\n+        seed = tf.int32.max + 1000\n+        outputs_mod = random.categorical(inputs, 2, seed=seed)\n+        outputs_nomod = random.categorical(inputs, 2, seed=1001)\n+        self.assertAllClose(outputs_mod, outputs_nomod)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5c8363b4d4f8465c0197c06bed84de61282a5f97", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 328 | Lines Deleted: 239 | Files Changed: 5 | Hunks: 50 | Methods Changed: 32 | Complexity Δ (Sum/Max): 12/6 | Churn Δ: 567 | Churn Cumulative: 718 | Contributors (this commit): 4 | Commits (past 90d): 12 | Contributors (cumulative): 12 | DMM Complexity: 0.38095238095238093\n\nDIFF:\n@@ -8,7 +8,9 @@ from keras.src.backend.numpy.core import convert_to_tensor\n from keras.src.utils.module_utils import scipy\n \n \n-def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n+def _segment_reduction_fn(\n+    data, segment_ids, reduction_method, num_segments, sorted\n+):\n     if num_segments is None:\n         num_segments = np.amax(segment_ids) + 1\n \n@@ -21,46 +23,34 @@ def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n         num_segments  # Replace first dimension (which corresponds to segments)\n     )\n \n-    if sorted:\n+    if reduction_method == np.maximum:\n+        result = np.ones(data_shape, dtype=valid_data.dtype) * -np.inf\n+    else:\n         result = np.zeros(data_shape, dtype=valid_data.dtype)\n-        np.add.at(result, valid_segment_ids, valid_data)\n+\n+    if sorted:\n+        reduction_method.at(result, valid_segment_ids, valid_data)\n     else:\n         sort_indices = np.argsort(valid_segment_ids)\n         sorted_segment_ids = valid_segment_ids[sort_indices]\n         sorted_data = valid_data[sort_indices]\n \n-        result = np.zeros(data_shape, dtype=valid_data.dtype)\n-        np.add.at(result, sorted_segment_ids, sorted_data)\n+        reduction_method.at(result, sorted_segment_ids, sorted_data)\n \n     return result\n \n \n+def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n+    return _segment_reduction_fn(\n+        data, segment_ids, np.add, num_segments, sorted\n+    )\n+\n+\n def segment_max(data, segment_ids, num_segments=None, sorted=False):\n-    if num_segments is None:\n-        num_segments = np.amax(segment_ids) + 1\n-\n-    valid_indices = segment_ids >= 0  # Ignore segment_ids that are -1\n-    valid_data = data[valid_indices]\n-    valid_segment_ids = segment_ids[valid_indices]\n-\n-    data_shape = list(valid_data.shape)\n-    data_shape[0] = (\n-        num_segments  # Replace first dimension (which corresponds to segments)\n+    return _segment_reduction_fn(\n+        data, segment_ids, np.maximum, num_segments, sorted\n     )\n \n-    if sorted:\n-        result = np.zeros(data_shape, dtype=valid_data.dtype)\n-        np.maximum.at(result, valid_segment_ids, valid_data)\n-    else:\n-        sort_indices = np.argsort(valid_segment_ids)\n-        sorted_segment_ids = valid_segment_ids[sort_indices]\n-        sorted_data = valid_data[sort_indices]\n-\n-        result = np.zeros(data_shape, dtype=valid_data.dtype)\n-        np.maximum.at(result, sorted_segment_ids, sorted_data)\n-\n-    return result\n-\n \n def top_k(x, k, sorted=False):\n     sorted_indices = np.argsort(x, axis=-1)[..., ::-1]\n\n@@ -9,6 +9,12 @@ from keras.src.backend.tensorflow.core import convert_to_tensor\n \n def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n     if sorted:\n+        if num_segments is not None:\n+            raise ValueError(\n+                \"Argument `num_segments` cannot be set when sorted is True \"\n+                \"when using the tensorflow backend.\"\n+                f\"Received: num_segments={num_segments}, sorted={sorted}.\"\n+            )\n         return tf.math.segment_sum(data, segment_ids)\n     else:\n         if num_segments is None:\n@@ -19,6 +25,12 @@ def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n \n def segment_max(data, segment_ids, num_segments=None, sorted=False):\n     if sorted:\n+        if num_segments is not None:\n+            raise ValueError(\n+                \"Argument `num_segments` cannot be set when sorted is True \"\n+                \"when using the tensorflow backend.\"\n+                f\"Received: num_segments={num_segments}, sorted={sorted}.\"\n+            )\n         return tf.math.segment_max(data, segment_ids)\n     else:\n         if num_segments is None:\n\n@@ -11,9 +11,7 @@ from keras.src.backend.torch.core import get_device\n from keras.src.backend.torch.numpy import pad\n \n \n-def segment_sum(data, segment_ids, num_segments=None, **kwargs):\n-    data = convert_to_tensor(data)\n-    segment_ids = convert_to_tensor(segment_ids)\n+def _segment_reduction_fn(data, segment_ids, reduction_method, num_segments):\n     num_repeats = torch.prod(\n         torch.tensor(data.shape[1:], device=get_device())\n     ).long()\n@@ -39,8 +37,13 @@ def segment_sum(data, segment_ids, num_segments=None, **kwargs):\n     # Add one more dimension to the result shape with the \"+1\".\n     shape = (num_segments + 1,) + tuple(data.shape[1:])\n \n-    result = torch.zeros(*shape, device=get_device()).scatter_add(\n-        0, segment_ids, data.float()\n+    if reduction_method == \"amax\":\n+        result = torch.ones(*shape, device=get_device()) * -float(\"Inf\")\n+    else:\n+        result = torch.zeros(*shape, device=get_device())\n+\n+    result = result.scatter_reduce(\n+        0, segment_ids, data.float(), reduction_method\n     )\n \n     # Removing the extra dimension.\n@@ -49,42 +52,16 @@ def segment_sum(data, segment_ids, num_segments=None, **kwargs):\n     return result.type(data.dtype)\n \n \n+def segment_sum(data, segment_ids, num_segments=None, **kwargs):\n+    data = convert_to_tensor(data)\n+    segment_ids = convert_to_tensor(segment_ids)\n+    return _segment_reduction_fn(data, segment_ids, \"sum\", num_segments)\n+\n+\n def segment_max(data, segment_ids, num_segments=None, **kwargs):\n     data = convert_to_tensor(data)\n     segment_ids = convert_to_tensor(segment_ids)\n-    num_repeats = torch.prod(\n-        torch.tensor(data.shape[1:], device=get_device())\n-    ).long()\n-    # To use `scatter_reduce` in torch, we need to replicate `segment_ids` into\n-    # the shape of `data`.\n-    segment_ids = (\n-        segment_ids.repeat_interleave(num_repeats)\n-        .view(*data.shape)\n-        .type(torch.int64)\n-    )\n-    num_segments = num_segments or len(torch.unique(segment_ids))\n-\n-    # .scatter_reduce does not support -1 in the indices.\n-    # Add all out-of-bound indices value to an extra dimension after\n-    # num_segments, which is removed before returning the result.\n-\n-    # Replacing the out-of-bound indices.\n-    segment_ids = torch.where(segment_ids >= 0, segment_ids, num_segments)\n-    segment_ids = torch.where(\n-        segment_ids < num_segments, segment_ids, num_segments\n-    )\n-\n-    # Add one more dimension to the result shape with the \"+1\".\n-    shape = (num_segments + 1,) + tuple(data.shape[1:])\n-\n-    result = torch.zeros(*shape, device=get_device()).scatter_reduce(\n-        0, segment_ids, data.float(), \"amax\"\n-    )\n-\n-    # Removing the extra dimension.\n-    result = result[:-1, ...]\n-\n-    return result.type(data.dtype)\n+    return _segment_reduction_fn(data, segment_ids, \"amax\", num_segments)\n \n \n def top_k(x, k, sorted=True):\n\n@@ -8,18 +8,44 @@ from keras.src.ops.operation import Operation\n from keras.src.ops.operation_utils import reduce_shape\n \n \n-class SegmentSum(Operation):\n+def _segment_reduce_validation(data, segment_ids):\n+    data_shape = data.shape\n+    segment_ids_shape = segment_ids.shape\n+    if len(segment_ids_shape) > 1:\n+        raise ValueError(\n+            \"Argument `segment_ids` should be an 1-D vector, got shape: \"\n+            f\"{len(segment_ids_shape)}. Consider either flatten input with \"\n+            \"segment_ids.reshape((-1)) and \"\n+            \"data.reshape((-1, ) + data.shape[len(segment_ids.shape):]) or \"\n+            \"vectorize with vmap.\"\n+        )\n+    if (\n+        segment_ids_shape[0] is not None\n+        and data_shape[0] is not None\n+        and segment_ids_shape[0] != data_shape[0]\n+    ):\n+        raise ValueError(\n+            \"Argument `segment_ids` and `data` should have same leading \"\n+            f\"dimension. Got {segment_ids_shape} v.s. \"\n+            f\"{data_shape}.\"\n+        )\n+\n+\n+class SegmentReduction(Operation):\n     def __init__(self, num_segments=None, sorted=False):\n         super().__init__()\n         self.num_segments = num_segments\n         self.sorted = sorted\n \n-    def compute_output_spec(self, data, segment_ids):\n-        num_segments = self.num_segments\n-        output_shape = (num_segments,) + tuple(data.shape[1:])\n+    def compute_output_spec(self, data, _):\n+        output_shape = (self.num_segments,) + tuple(data.shape[1:])\n         return KerasTensor(shape=output_shape, dtype=data.dtype)\n \n+\n+class SegmentSum(SegmentReduction):\n+\n     def call(self, data, segment_ids):\n+        _segment_reduce_validation(data, segment_ids)\n         return backend.math.segment_sum(\n             data,\n             segment_ids,\n@@ -34,8 +60,9 @@ def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n \n     Args:\n         data: Input tensor.\n-        segment_ids: A 1-D tensor containing segment indices for each\n-            element in `data`.\n+        segment_ids: A N-D tensor containing segment indices for each\n+            element in `data`. Num dims for segment ids should be strictly\n+            smaller or equal to number of dims in data.\n         num_segments: An integer representing the total number of\n             segments. If not specified, it is inferred from the maximum\n             value in `segment_ids`.\n@@ -54,6 +81,7 @@ def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n     >>> keras.ops.segment_sum(data, segment_ids,num_segments)\n     array([3, 30, 300], dtype=int32)\n     \"\"\"\n+    _segment_reduce_validation(data, segment_ids)\n     if any_symbolic_tensors((data,)):\n         return SegmentSum(num_segments, sorted).symbolic_call(data, segment_ids)\n     return backend.math.segment_sum(\n@@ -61,18 +89,10 @@ def segment_sum(data, segment_ids, num_segments=None, sorted=False):\n     )\n \n \n-class SegmentMax(Operation):\n-    def __init__(self, num_segments=None, sorted=False):\n-        super().__init__()\n-        self.num_segments = num_segments\n-        self.sorted = sorted\n-\n-    def compute_output_spec(self, data, segment_ids):\n-        num_segments = self.num_segments\n-        output_shape = (num_segments,) + tuple(data.shape[1:])\n-        return KerasTensor(shape=output_shape, dtype=data.dtype)\n+class SegmentMax(SegmentReduction):\n \n     def call(self, data, segment_ids):\n+        _segment_reduce_validation(data, segment_ids)\n         return backend.math.segment_max(\n             data,\n             segment_ids,\n@@ -87,8 +107,8 @@ def segment_max(data, segment_ids, num_segments=None, sorted=False):\n \n     Args:\n         data: Input tensor.\n-        segment_ids: A 1-D tensor containing segment indices for each\n-            element in `data`.\n+        segment_ids: A N-D tensor containing segment indices for each\n+            element in `data`. data.shape[:len(segment_ids.shape)] should match.\n         num_segments: An integer representing the total number of\n             segments. If not specified, it is inferred from the maximum\n             value in `segment_ids`.\n@@ -107,6 +127,7 @@ def segment_max(data, segment_ids, num_segments=None, sorted=False):\n     >>> keras.ops.segment_max(data, segment_ids, num_segments)\n     array([2, 20, 200], dtype=int32)\n     \"\"\"\n+    _segment_reduce_validation(data, segment_ids)\n     if any_symbolic_tensors((data,)):\n         return SegmentMax(num_segments, sorted).symbolic_call(data, segment_ids)\n     return backend.math.segment_max(\n\n@@ -136,28 +136,36 @@ def _istft(\n     return x[..., start:end]\n \n \n+def _sum_reduce(left, right):\n+    return left + right\n+\n+\n+def _max_reduce(left, right):\n+    return np.max(np.stack([left, right]), axis=0)\n+\n+\n class MathOpsDynamicShapeTest(testing.TestCase, parameterized.TestCase):\n-    def test_segment_sum(self):\n+\n+    @parameterized.parameters([(kmath.segment_sum,), (kmath.segment_max,)])\n+    def test_segment_reduce(self, segment_reduce_op):\n+        # 1D case\n         data = KerasTensor((None, 4), dtype=\"float32\")\n         segment_ids = KerasTensor((10,), dtype=\"int32\")\n-        outputs = kmath.segment_sum(data, segment_ids)\n+        outputs = segment_reduce_op(data, segment_ids)\n         self.assertEqual(outputs.shape, (None, 4))\n \n         data = KerasTensor((None, 4), dtype=\"float32\")\n         segment_ids = KerasTensor((10,), dtype=\"int32\")\n-        outputs = kmath.segment_sum(data, segment_ids, num_segments=5)\n+        outputs = segment_reduce_op(data, segment_ids, num_segments=5)\n         self.assertEqual(outputs.shape, (5, 4))\n \n-    def test_segment_max(self):\n-        data = KerasTensor((None, 4), dtype=\"float32\")\n-        segment_ids = KerasTensor((10,), dtype=\"int32\")\n-        outputs = kmath.segment_max(data, segment_ids)\n-        self.assertEqual(outputs.shape, (None, 4))\n-\n-        data = KerasTensor((None, 4), dtype=\"float32\")\n-        segment_ids = KerasTensor((10,), dtype=\"int32\")\n-        outputs = kmath.segment_max(data, segment_ids, num_segments=5)\n-        self.assertEqual(outputs.shape, (5, 4))\n+        data = KerasTensor((10,), dtype=\"float32\")\n+        segment_ids = KerasTensor(\n+            (10,),\n+            dtype=\"int32\",\n+        )\n+        outputs = segment_reduce_op(data, segment_ids)\n+        self.assertEqual(outputs.shape, (None,))\n \n     def test_top_k(self):\n         x = KerasTensor((None, 2, 3))\n@@ -268,38 +276,39 @@ class MathOpsDynamicShapeTest(testing.TestCase, parameterized.TestCase):\n         self.assertEqual(kmath.rsqrt(x).shape, (None, 3))\n \n \n-class MathOpsStaticShapeTest(testing.TestCase):\n+class MathOpsStaticShapeTest(testing.TestCase, parameterized.TestCase):\n+    @parameterized.parameters([(kmath.segment_sum,), (kmath.segment_max,)])\n     @pytest.mark.skipif(\n         backend.backend() == \"jax\",\n         reason=\"JAX does not support `num_segments=None`.\",\n     )\n-    def test_segment_sum(self):\n+    def test_segment_reduce(self, segment_reduce_op):\n+        # 1D case\n         data = KerasTensor((10, 4), dtype=\"float32\")\n         segment_ids = KerasTensor((10,), dtype=\"int32\")\n-        outputs = kmath.segment_sum(data, segment_ids)\n+        outputs = segment_reduce_op(data, segment_ids)\n         self.assertEqual(outputs.shape, (None, 4))\n \n-    def test_segment_sum_explicit_num_segments(self):\n+        data = KerasTensor((10,), dtype=\"float32\")\n+        segment_ids = KerasTensor((10,), dtype=\"int32\")\n+        outputs = segment_reduce_op(data, segment_ids)\n+        self.assertEqual(outputs.shape, (None,))\n+\n+    @parameterized.parameters([(kmath.segment_sum,), (kmath.segment_max,)])\n+    def test_segment_reduce_explicit_num_segments(self, segment_reduce_op):\n+        # 1D case\n         data = KerasTensor((10, 4), dtype=\"float32\")\n         segment_ids = KerasTensor((10,), dtype=\"int32\")\n-        outputs = kmath.segment_sum(data, segment_ids, num_segments=5)\n+        outputs = segment_reduce_op(data, segment_ids, num_segments=5)\n         self.assertEqual(outputs.shape, (5, 4))\n \n-    @pytest.mark.skipif(\n-        backend.backend() == \"jax\",\n-        reason=\"JAX does not support `num_segments=None`.\",\n+        data = KerasTensor((6,), dtype=\"float32\")\n+        segment_ids = KerasTensor(\n+            (6,),\n+            dtype=\"int32\",\n         )\n-    def test_segment_max(self):\n-        data = KerasTensor((10, 4), dtype=\"float32\")\n-        segment_ids = KerasTensor((10,), dtype=\"int32\")\n-        outputs = kmath.segment_max(data, segment_ids)\n-        self.assertEqual(outputs.shape, (None, 4))\n-\n-    def test_segment_max_explicit_num_segments(self):\n-        data = KerasTensor((10, 4), dtype=\"float32\")\n-        segment_ids = KerasTensor((10,), dtype=\"int32\")\n-        outputs = kmath.segment_max(data, segment_ids, num_segments=5)\n-        self.assertEqual(outputs.shape, (5, 4))\n+        outputs = segment_reduce_op(data, segment_ids, num_segments=5)\n+        self.assertEqual(outputs.shape, (5,))\n \n     def test_topk(self):\n         x = KerasTensor((1, 2, 3))\n@@ -395,128 +404,169 @@ class MathOpsStaticShapeTest(testing.TestCase):\n \n \n class MathOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n+\n+    def run_segment_reduce_test(\n+        self,\n+        segment_reduce_op,\n+        element_wise_reduce_method,\n+        num_indices,\n+        indices_high,\n+        data_dims=tuple(),\n+        num_segments=None,\n+        add_neg1_to_indices=False,\n+        sorted_indices=False,\n+    ):\n+        if num_segments is not None and indices_high >= num_segments:\n+            raise ValueError(\"Indices high cannot be more than num segments\")\n+        indices_dims = (num_indices,)\n+        full_data_dims = indices_dims + data_dims\n+        data = np.random.rand(*full_data_dims).astype(np.float32)\n+        segment_ids = np.concatenate(\n+            [\n+                np.arange(indices_high),\n+                np.random.randint(\n+                    low=0,\n+                    high=indices_high,\n+                    size=(indices_dims[0] - indices_high),\n+                ),\n+            ]\n+        ).astype(np.int32)\n+        if sorted_indices:\n+            segment_ids = np.sort(segment_ids, axis=-1)\n+        if add_neg1_to_indices:\n+            segment_ids[0] = -1\n+        outputs = segment_reduce_op(\n+            data, segment_ids, num_segments, sorted=sorted_indices\n+        )\n+        if num_segments is None:\n+            num_segments = np.max(segment_ids).item() + 1\n+        expected_shape = (num_segments,) + data_dims\n+        if segment_reduce_op == kmath.segment_max:\n+            if backend.backend() == \"tensorflow\":\n+                empty_fill_value = -np.finfo(np.float32).max\n+            else:\n+                empty_fill_value = -np.inf\n+            expected = np.full(expected_shape, empty_fill_value)\n+        else:\n+            expected = np.zeros(expected_shape)\n+\n+        for idx in range(num_indices):\n+            segment_id = segment_ids[idx]\n+            if segment_id == -1:\n+                continue\n+            expected[segment_id] = element_wise_reduce_method(\n+                expected[segment_id], data[idx]\n+            )\n+        self.assertAllClose(outputs, expected)\n+\n+    @parameterized.product(\n+        (\n+            dict(\n+                segment_reduce_op=kmath.segment_sum,\n+                element_wise_reduce_method=_sum_reduce,\n+            ),\n+            dict(\n+                segment_reduce_op=kmath.segment_max,\n+                element_wise_reduce_method=_max_reduce,\n+            ),\n+        ),\n+        sorted_indices=(True, False),\n+    )\n     @pytest.mark.skipif(\n         backend.backend() == \"jax\",\n         reason=\"JAX does not support `num_segments=None`.\",\n     )\n-    def test_segment_sum(self):\n+    def test_segment_reduce(\n+        self,\n+        segment_reduce_op,\n+        element_wise_reduce_method,\n+        sorted_indices,\n+    ):\n         # Test 1D case.\n-        data = np.array([1, 2, 3, 4, 5, 6, 7, 8], dtype=np.float32)\n-        segment_ids = np.array([0, 0, 1, 1, 1, 2, 2, 2], dtype=np.int32)\n-        outputs = kmath.segment_sum(data, segment_ids)\n-\n-        # Segment 0: 1 + 2 = 3\n-        # Segment 1: 3 + 4 + 5 = 12\n-        # Segment 2: 6 + 7 + 8 = 21\n-        expected = np.array([3, 12, 21], dtype=np.float32)\n-        self.assertAllClose(outputs, expected)\n-\n-        # Test N-D case.\n-        data = np.random.rand(9, 3, 3)\n-        segment_ids = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2], dtype=np.int32)\n-        outputs = kmath.segment_sum(data, segment_ids)\n-\n-        expected = np.zeros((3, 3, 3))\n-        for i in range(data.shape[0]):\n-            segment_id = segment_ids[i]\n-            expected[segment_id] += data[i]\n-\n-        self.assertAllClose(outputs, expected)\n-\n-    def test_segment_sum_explicit_num_segments(self):\n-        # Test 1D case.\n-        data = np.array([1, 2, 3, 4, 5, 6, 7, 8], dtype=np.float32)\n-        segment_ids = np.array([0, 0, 1, 1, 1, 2, 2, 2], dtype=np.int32)\n-        outputs = kmath.segment_sum(data, segment_ids, num_segments=4)\n-        expected = np.array([3, 12, 21, 0], dtype=np.float32)\n-        self.assertAllClose(outputs, expected)\n-\n-        # Test 1D with -1 case.\n-        data = np.array([1, 2, 3, 4, 5, 6, 7, 8], dtype=np.float32)\n-        segment_ids = np.array([0, 0, 1, 1, -1, 2, 2, -1], dtype=np.int32)\n-        outputs = kmath.segment_sum(data, segment_ids, num_segments=4)\n-\n-        # Segment ID 0: First two elements (1 + 2) = 3\n-        # Segment ID 1: Next two elements (3 + 4) = 7\n-        # Segment ID -1: Ignore the next two elements, because segment ID is -1.\n-        # Segment ID 2: Next two elements (6 + 7) = 13\n-        # Segment ID 3: No elements, so output is 0.\n-        expected = np.array([3, 7, 13, 0], dtype=np.float32)\n-        self.assertAllClose(outputs, expected)\n-\n-        # Test N-D case.\n-        data = np.random.rand(9, 3, 3)\n-        segment_ids = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2], dtype=np.int32)\n-        outputs = kmath.segment_sum(data, segment_ids, num_segments=4)\n-\n-        expected = np.zeros((4, 3, 3))\n-        for i in range(data.shape[0]):\n-            segment_id = segment_ids[i]\n-            if segment_id != -1:\n-                expected[segment_id] += data[i]\n-\n-        self.assertAllClose(outputs, expected)\n-\n-    @pytest.mark.skipif(\n-        backend.backend() == \"jax\",\n-        reason=\"JAX does not support `num_segments=None`.\",\n+        self.run_segment_reduce_test(\n+            segment_reduce_op,\n+            element_wise_reduce_method,\n+            num_indices=9,\n+            indices_high=3,\n+            sorted_indices=sorted_indices,\n+        )\n+\n+        # Test ND data case.\n+        self.run_segment_reduce_test(\n+            segment_reduce_op,\n+            element_wise_reduce_method,\n+            num_indices=9,\n+            indices_high=3,\n+            data_dims=(\n+                3,\n+                3,\n+            ),\n+            sorted_indices=sorted_indices,\n+        )\n+\n+    @parameterized.product(\n+        (\n+            dict(\n+                segment_reduce_op=kmath.segment_sum,\n+                element_wise_reduce_method=_sum_reduce,\n+            ),\n+            dict(\n+                segment_reduce_op=kmath.segment_max,\n+                element_wise_reduce_method=_max_reduce,\n+            ),\n+        ),\n+        (\n+            dict(\n+                contains_neg1_in_indices=True,\n+                sorted_indices=False,\n+            ),\n+            dict(\n+                contains_neg1_in_indices=False,\n+                sorted_indices=False,\n+            ),\n+            dict(\n+                contains_neg1_in_indices=False,\n+                sorted_indices=True,\n+            ),\n+        ),\n+    )\n+    def test_segment_reduce_explicit_num_segments(\n+        self,\n+        segment_reduce_op,\n+        element_wise_reduce_method,\n+        contains_neg1_in_indices,\n+        sorted_indices,\n+    ):\n+        if backend.backend() == \"tensorflow\" and sorted_indices:\n+            pytest.skip(\n+                \"Num segments and sorted_indices=True doesn't work for \"\n+                \"tensorflow.\"\n             )\n-    def test_segment_max(self):\n         # Test 1D case.\n-        data = np.array([1, 2, 3, 4, 5, 6, 7, 8], dtype=np.float32)\n-        segment_ids = np.array([0, 0, 1, 1, 1, 2, 2, 2], dtype=np.int32)\n-        outputs = kmath.segment_max(data, segment_ids)\n+        self.run_segment_reduce_test(\n+            segment_reduce_op,\n+            element_wise_reduce_method,\n+            num_indices=9,\n+            indices_high=3,\n+            num_segments=4,\n+            add_neg1_to_indices=contains_neg1_in_indices,\n+            sorted_indices=sorted_indices,\n+        )\n \n-        # Segment ID 0: Max of the first two elements = 2\n-        # Segment ID 1: Max of the next three elements = 5\n-        # Segment ID 2: Max of the next three elements = 8\n-        expected = np.array([2, 5, 8], dtype=np.float32)\n-\n-        self.assertAllClose(outputs, expected)\n-\n-        # Test N-D case.\n-        data = np.random.rand(9, 3, 3)\n-        segment_ids = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2], dtype=np.int32)\n-        outputs = kmath.segment_max(data, segment_ids)\n-        expected = np.zeros((3, 3, 3))\n-        for i in range(data.shape[0]):\n-            segment_id = segment_ids[i]\n-            expected[segment_id] = np.maximum(expected[segment_id], data[i])\n-\n-        self.assertAllClose(outputs, expected)\n-\n-    def test_segment_max_explicit_num_segments(self):\n-        # Test 1D case.\n-        data = np.array([1, 2, 3, 4, 5, 6, 7, 8], dtype=np.float32)\n-        segment_ids = np.array([0, 0, 1, 1, 1, 2, 2, 2], dtype=np.int32)\n-        outputs = kmath.segment_max(data, segment_ids, num_segments=3)\n-\n-        # Segment ID 0: Max of the first two elements = 2\n-        # Segment ID 1: Max of the next three elements = 5\n-        # Segment ID 2: Max of the next three elements = 8\n-        expected = np.array([2, 5, 8], dtype=np.float32)\n-\n-        self.assertAllClose(outputs, expected)\n-\n-        # Test 1D with -1 case.\n-        data = np.array([1, 2, 3, 4, 5, 6, 7, 8], dtype=np.float32)\n-        segment_ids = np.array([0, 0, 1, 1, -1, 2, 2, -1], dtype=np.int32)\n-        outputs = kmath.segment_max(data, segment_ids, num_segments=3)\n-        expected = np.array([2, 4, 7], dtype=np.float32)\n-\n-        self.assertAllClose(outputs, expected)\n-\n-        # Test N-D case.\n-        data = np.random.rand(9, 3, 3)\n-        segment_ids = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2], dtype=np.int32)\n-        outputs = kmath.segment_max(data, segment_ids, num_segments=3)\n-\n-        expected = np.full((3, 3, 3), -np.inf)\n-        for i in range(data.shape[0]):\n-            segment_id = segment_ids[i]\n-            expected[segment_id] = np.maximum(expected[segment_id], data[i])\n-\n-        self.assertAllClose(outputs, expected)\n+        # Test ND data case.\n+        self.run_segment_reduce_test(\n+            segment_reduce_op,\n+            element_wise_reduce_method,\n+            num_indices=9,\n+            indices_high=3,\n+            data_dims=(\n+                3,\n+                3,\n+            ),\n+            num_segments=4,\n+            add_neg1_to_indices=contains_neg1_in_indices,\n+            sorted_indices=sorted_indices,\n+        )\n \n     def test_top_k(self):\n         x = np.array([0, 4, 2, 1, 3, -1], dtype=np.float32)\n@@ -1259,31 +1309,70 @@ class ISTFTTest(testing.TestCase):\n         self.assertEqual(output_spec.shape, expected_shape)\n \n \n-class TestMathErrors(testing.TestCase):\n+class TestMathErrors(testing.TestCase, parameterized.TestCase):\n \n+    @parameterized.parameters([(kmath.segment_sum,), (kmath.segment_max,)])\n     @pytest.mark.skipif(\n         backend.backend() != \"jax\", reason=\"Testing Jax errors only\"\n     )\n-    def test_segment_sum_no_num_segments(self):\n+    def test_segment_reduce_no_num_segments(self, segment_reduce_op):\n         data = jnp.array([1, 2, 3, 4])\n         segment_ids = jnp.array([0, 0, 1, 1])\n         with self.assertRaisesRegex(\n             ValueError,\n             \"Argument `num_segments` must be set when using the JAX backend.\",\n         ):\n-            kmath.segment_sum(data, segment_ids)\n+            segment_reduce_op(data, segment_ids)\n \n+    @parameterized.parameters([(kmath.segment_sum,), (kmath.segment_max,)])\n     @pytest.mark.skipif(\n-        backend.backend() != \"jax\", reason=\"Testing Jax errors only\"\n+        backend.backend() != \"tensorflow\", reason=\"Tensorflow error only\"\n     )\n-    def test_segment_max_no_num_segments(self):\n-        data = jnp.array([1, 2, 3, 4])\n-        segment_ids = jnp.array([0, 0, 1, 1])\n+    def test_segment_reduce_sort_and_num_segments(self, segment_reduce_op):\n+        data = np.array([1, 2, 3, 4])\n+        segment_ids = np.array([0, 0, 1, 1])\n         with self.assertRaisesRegex(\n             ValueError,\n-            \"Argument `num_segments` must be set when using the JAX backend.\",\n+            \"Argument `num_segments` cannot be set when sorted is True when \"\n+            \"using the tensorflow backend.\",\n         ):\n-            kmath.segment_max(data, segment_ids)\n+            segment_reduce_op(data, segment_ids, num_segments=2, sorted=True)\n+\n+    @parameterized.parameters([(kmath.segment_sum,), (kmath.segment_max,)])\n+    def test_segment_reduce_multi_dim_segment_ids(self, segment_reduce_op):\n+        data = np.array([1, 2, 3, 4])\n+        segment_ids = np.array([0, 0, 1, 1]).reshape((2, 2))\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"Argument `segment_ids` should be an 1-D vector,\",\n+        ):\n+            segment_reduce_op(data, segment_ids)\n+\n+    @parameterized.parameters([(kmath.segment_sum,), (kmath.segment_max,)])\n+    def test_segment_reduce_leading_not_match(self, segment_reduce_op):\n+        data = np.array([])\n+        segment_ids = np.array([0, 0, 1, 1])\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"Argument `segment_ids` and `data` should have same leading \"\n+            \"dimension.\",\n+        ):\n+            segment_reduce_op(data, segment_ids)\n+\n+        output_tensor = segment_reduce_op(\n+            KerasTensor(shape=(None, 4)), KerasTensor(shape=(5,))\n+        )\n+        self.assertEqual(output_tensor.shape, (None, 4))\n+\n+        output_tensor = segment_reduce_op(\n+            KerasTensor(shape=(5, 4)), KerasTensor(shape=(None,))\n+        )\n+        self.assertEqual(output_tensor.shape, (None, 4))\n+\n+        output_tensor = segment_reduce_op(\n+            KerasTensor(shape=(None, 4)), KerasTensor(shape=(None,))\n+        )\n+        self.assertEqual(output_tensor.shape, (None, 4))\n \n     def test_stft_invalid_input_type(self):\n         # backend agnostic error message\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#10a008fac10e2eb7dd343c128cbf2e0f971fa993", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 57 | Lines Deleted: 18 | Files Changed: 2 | Hunks: 12 | Methods Changed: 6 | Complexity Δ (Sum/Max): 7/4 | Churn Δ: 75 | Churn Cumulative: 733 | Contributors (this commit): 8 | Commits (past 90d): 18 | Contributors (cumulative): 14 | DMM Complexity: 0.696969696969697\n\nDIFF:\n@@ -430,6 +430,8 @@ def one_hot(x, num_classes, axis=-1, dtype=\"float32\", sparse=False):\n     x = convert_to_tensor(x, dtype=\"int64\")\n     if dtype is None:\n         dtype = \"float32\"\n+    else:\n+        dtype = backend.standardize_dtype(dtype)\n     if sparse:\n         # We don't use `tf.sparse.bincount`, it doesn't handle negative indices\n         # and only support rank 1 and 2 tensors (`one_hot` adds a dimension).\n@@ -449,22 +451,49 @@ def one_hot(x, num_classes, axis=-1, dtype=\"float32\", sparse=False):\n         shape = list(x.shape)\n         shape.insert(axis, num_classes)\n         return tf.SparseTensor(indices, values, shape)\n-    return tf.one_hot(x, num_classes, axis=axis, dtype=dtype)\n+    on_value, off_value = (True, False) if dtype == \"bool\" else (None, None)\n+    return tf.one_hot(\n+        x,\n+        num_classes,\n+        on_value=on_value,\n+        off_value=off_value,\n+        axis=axis,\n+        dtype=dtype,\n+    )\n \n \n def multi_hot(x, num_classes, axis=-1, dtype=\"float32\", sparse=False):\n-    x = convert_to_tensor(x)\n     reduction_axis = 1 if len(x.shape) > 1 else 0\n-    one_hot_outputs = one_hot(\n-        cast(x, \"int32\"), num_classes, axis=axis, dtype=dtype, sparse=sparse\n-    )\n+    if backend.standardize_dtype(dtype) == \"bool\":\n         if sparse:\n-        # We don't use `tf.sparse.bincount`, it doesn't handle negative indices\n-        # and has a rank limitation.\n-        return tf.sparse.reduce_max(\n-            one_hot_outputs, axis=reduction_axis, output_is_sparse=True\n+            # `tf.sparse.reduce_max` doesn't work on bool and there is no\n+            # `tf.sparse.reduce_any`.\n+            outputs = one_hot(\n+                x, num_classes, axis=axis, dtype=\"int8\", sparse=True\n             )\n-    return tf.reduce_max(one_hot_outputs, axis=reduction_axis)\n+            outputs = tf.sparse.reduce_max(\n+                outputs, axis=reduction_axis, output_is_sparse=True\n+            )\n+            outputs_shape = outputs.shape\n+            outputs = tf.cast(outputs, dtype)\n+            outputs.set_shape(outputs_shape)\n+            return outputs\n+        else:\n+            outputs = one_hot(x, num_classes, axis=axis, dtype=dtype)\n+            return tf.reduce_any(outputs, axis=reduction_axis)\n+    else:\n+        if sparse:\n+            # We don't use `tf.sparse.bincount`, it doesn't handle negative\n+            # indices and has a rank limitation.\n+            outputs = one_hot(\n+                x, num_classes, axis=axis, dtype=dtype, sparse=True\n+            )\n+            return tf.sparse.reduce_max(\n+                outputs, axis=reduction_axis, output_is_sparse=True\n+            )\n+        else:\n+            outputs = one_hot(x, num_classes, axis=axis, dtype=dtype)\n+            return tf.reduce_max(outputs, axis=reduction_axis)\n \n \n def _get_logits(output, from_logits, op_type, fn_name):\n\n@@ -210,12 +210,17 @@ class NNOpsDynamicShapeTest(testing.TestCase, parameterized.TestCase):\n         self.assertEqual(knn.multi_hot(x, 5, 2).shape, (None, 5, 1))\n         self.assertSparse(knn.multi_hot(x, 5, sparse=True))\n \n-    @parameterized.product(dtype=[\"float32\", \"int32\"])\n-    def test_multi_hot_dtype(self, dtype):\n-        # dtype tests\n+    @parameterized.named_parameters(\n+        named_product(dtype=[\"float32\", \"int32\", \"bool\"], sparse=[False, True])\n+    )\n+    def test_multi_hot_dtype(self, dtype, sparse):\n+        if sparse and not backend.SUPPORTS_SPARSE_TENSORS:\n+            pytest.skip(\"Backend does not support sparse tensors\")\n+\n         x = np.arange(5)\n-        out = knn.multi_hot(x, 5, axis=0, dtype=dtype)\n+        out = knn.multi_hot(x, 5, axis=0, dtype=dtype, sparse=sparse)\n         self.assertEqual(backend.standardize_dtype(out.dtype), dtype)\n+        self.assertSparse(out, sparse)\n \n     def test_conv(self):\n         data_format = backend.config.image_data_format()\n@@ -564,12 +569,17 @@ class NNOpsDynamicShapeTest(testing.TestCase, parameterized.TestCase):\n         self.assertEqual(knn.one_hot(x, 5, 2).shape, (None, 3, 5, 1))\n         self.assertSparse(knn.one_hot(x, 5, sparse=True))\n \n-    @parameterized.product(dtype=[\"float32\", \"int32\"])\n-    def test_one_hot_dtype(self, dtype):\n-        # dtype tests\n+    @parameterized.named_parameters(\n+        named_product(dtype=[\"float32\", \"int32\", \"bool\"], sparse=[False, True])\n+    )\n+    def test_one_hot_dtype(self, dtype, sparse):\n+        if sparse and not backend.SUPPORTS_SPARSE_TENSORS:\n+            pytest.skip(\"Backend does not support sparse tensors\")\n+\n         x = np.arange(5)\n-        out = knn.one_hot(x, 5, axis=0, dtype=dtype)\n+        out = knn.one_hot(x, 5, axis=0, dtype=dtype, sparse=sparse)\n         self.assertEqual(backend.standardize_dtype(out.dtype), dtype)\n+        self.assertSparse(out, sparse)\n \n     def test_moments(self):\n         x = KerasTensor([None, 3, 4])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ed1b3fe43a43dde68a60f27283ea749d0c19abda", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 29 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -15,6 +15,9 @@ class TFRandomTest(TestCase):\n     def test_categorical(self):\n         inputs = tf.ones([2, 3], dtype=\"float32\")\n         outputs = random.categorical(inputs, 2, seed=42)\n+        if tf.config.list_physical_devices(\"GPU\"):\n+            expected = tf.constant([[2, 2], [0, 1]])\n+        else:\n             expected = tf.constant([[0, 2], [1, 0]])\n         self.assertAllClose(outputs, expected)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#61ea9c61f08f2a7b06091c63f032fc5e7839fb4f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 19 | Churn Cumulative: 83 | Contributors (this commit): 4 | Commits (past 90d): 6 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -210,6 +210,21 @@ class MultiHeadAttention(Layer):\n             key: Optional shape of the `key` tensor.\n         \"\"\"\n         key_shape = value_shape if key_shape is None else key_shape\n+\n+        if query_shape[-1] != value_shape[-1]:\n+            raise ValueError(\n+                \"The last dimension of `query_shape` and `value_shape` \"\n+                f\"must be equal, but are {query_shape[-1]}, {value_shape[-1]}. \"\n+                \"Received: query_shape={query_shape}, value_shape={value_shape}\"\n+            )\n+\n+        if value_shape[1:-1] != key_shape[1:-1]:\n+            raise ValueError(\n+                \"All dimensions of `value` and `key`, except the last one, \"\n+                f\"must be equal. Received: value_shape={value_shape} and \"\n+                f\"key_shape={key_shape}\"\n+            )\n+\n         query_rank = len(query_shape)\n         value_rank = len(value_shape)\n         key_rank = len(key_shape)\n\n@@ -148,6 +148,10 @@ class MultiHeadAttentionTest(testing.TestCase, parameterized.TestCase):\n         )\n         with self.assertRaisesRegex(ValueError, r\"must be equal\"):\n             layer.compute_output_shape(query_shape, value_shape, key_shape)\n+        with self.assertRaisesRegex(ValueError, r\"must be equal\"):\n+            layer(\n+                np.ones(query_shape), np.ones(value_shape), np.ones(key_shape)\n+            )\n \n     def test_initializer(self):\n         # Test with a specified initializer.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#de066e599a7985e5a008cd2d7b796f9b39efe574", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 106 | Lines Deleted: 111 | Files Changed: 3 | Hunks: 18 | Methods Changed: 22 | Complexity Δ (Sum/Max): 0/2 | Churn Δ: 217 | Churn Cumulative: 359 | Contributors (this commit): 5 | Commits (past 90d): 15 | Contributors (cumulative): 9 | DMM Complexity: 0.0\n\nDIFF:\n@@ -7,9 +7,22 @@ from keras.src.random.seed_generator import draw_seed\n from keras.src.random.seed_generator import make_default_seed\n \n \n+def _cast_seed(seed):\n+    # TensorFlow has a device placement issue that `Variable` must be int64\n+    # in `SeedGenerator`. However, all `tf.random.stateless_*` expect the seed\n+    # to be int32 to run with XLA.\n+    # This function addresses the inconsistency using `floormod`.\n+    # Ref: https://www.tensorflow.org/api_docs/python/tf/random\n+    if standardize_dtype(seed.dtype) == \"int32\":\n+        return seed\n+    else:\n+        seed = tf.cast(tf.math.floormod(seed, tf.int32.max - 1), dtype=\"int32\")\n+        return seed\n+\n+\n def normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n     dtype = dtype or floatx()\n-    seed = draw_seed(seed)\n+    seed = _cast_seed(draw_seed(seed))\n     return tf.random.stateless_normal(\n         shape=shape, mean=mean, stddev=stddev, dtype=dtype, seed=seed\n     )\n@@ -17,7 +30,7 @@ def normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n \n def uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n     dtype = dtype or floatx()\n-    seed = draw_seed(seed)\n+    seed = _cast_seed(draw_seed(seed))\n     return tf.random.stateless_uniform(\n         shape=shape,\n         minval=tf.cast(minval, dtype),\n@@ -28,9 +41,7 @@ def uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n \n \n def categorical(logits, num_samples, dtype=\"int64\", seed=None):\n-    seed = draw_seed(seed)\n-    # Only int32 seeds are supported in stateless_categorical.\n-    seed = tf.cast(tf.math.floormod(seed, tf.int32.max - 1), dtype=\"int32\")\n+    seed = _cast_seed(draw_seed(seed))\n     output = tf.random.stateless_categorical(logits, num_samples, seed=seed)\n     return tf.cast(output, dtype)\n \n@@ -39,7 +50,7 @@ def randint(shape, minval, maxval, dtype=\"int32\", seed=None):\n     intemediate_dtype = dtype\n     if standardize_dtype(dtype) not in [\"int32\", \"int64\"]:\n         intemediate_dtype = \"int64\"\n-    seed = draw_seed(seed)\n+    seed = _cast_seed(draw_seed(seed))\n     output = tf.random.stateless_uniform(\n         shape=shape,\n         minval=minval,\n@@ -52,7 +63,7 @@ def randint(shape, minval, maxval, dtype=\"int32\", seed=None):\n \n def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n     dtype = dtype or floatx()\n-    seed = draw_seed(seed)\n+    seed = _cast_seed(draw_seed(seed))\n     return tf.random.stateless_truncated_normal(\n         shape=shape, mean=mean, stddev=stddev, dtype=dtype, seed=seed\n     )\n@@ -72,7 +83,7 @@ def _get_concrete_noise_shape(inputs, noise_shape):\n \n \n def dropout(inputs, rate, noise_shape=None, seed=None):\n-    seed = draw_seed(seed)\n+    seed = _cast_seed(draw_seed(seed))\n     noise_shape = _get_concrete_noise_shape(inputs, noise_shape)\n     return tf.nn.experimental.stateless_dropout(\n         inputs,\n@@ -85,7 +96,7 @@ def dropout(inputs, rate, noise_shape=None, seed=None):\n def shuffle(x, axis=0, seed=None):\n     from keras.src.backend.tensorflow.numpy import swapaxes\n \n-    seed = draw_seed(seed)\n+    seed = _cast_seed(draw_seed(seed))\n     if axis == 0:\n         return tf.random.experimental.stateless_shuffle(x, seed=seed)\n     x = swapaxes(x, axis1=0, axis2=axis)\n@@ -96,7 +107,7 @@ def shuffle(x, axis=0, seed=None):\n \n def gamma(shape, alpha, dtype=None, seed=None):\n     dtype = dtype or floatx()\n-    seed = draw_seed(seed)\n+    seed = _cast_seed(draw_seed(seed))\n     # TODO: `tf.random.stateless_gamma` doesn't support bfloat16\n     intemediate_dtype = dtype\n     if standardize_dtype(dtype) == \"bfloat16\":\n@@ -114,7 +125,7 @@ def gamma(shape, alpha, dtype=None, seed=None):\n \n def binomial(shape, counts, probabilities, dtype=None, seed=None):\n     dtype = dtype or floatx()\n-    seed = draw_seed(seed)\n+    seed = _cast_seed(draw_seed(seed))\n     # TODO: `tf.random.stateless_binomial` doesn't support bfloat16\n     intemediate_dtype = dtype\n     if standardize_dtype(dtype) == \"bfloat16\":\n@@ -143,7 +154,7 @@ def beta(shape, alpha, beta, dtype=None, seed=None):\n     # gamma random variables to prevent any unintended\n     # dependencies and correlations between the generated values\n     # due to the usage of same seed.\n-    seed_1 = draw_seed(seed)\n+    seed_1 = _cast_seed(draw_seed(seed))\n     # The choice of 12 is totally arbitrary, as we're\n     # incrementing the first drawn seed by a CONSTANT to\n     # ensure deterministic results.\n\n@@ -1,29 +0,0 @@\n-import pytest\n-import tensorflow as tf\n-\n-from keras.src import backend\n-from keras.src.backend.tensorflow import random\n-from keras.src.testing import TestCase\n-\n-\n-@pytest.mark.skipif(\n-    backend.backend() != \"tensorflow\",\n-    reason=\"Only applies to TensorFlow random ops.\",\n-)\n-class TFRandomTest(TestCase):\n-\n-    def test_categorical(self):\n-        inputs = tf.ones([2, 3], dtype=\"float32\")\n-        outputs = random.categorical(inputs, 2, seed=42)\n-        if tf.config.list_physical_devices(\"GPU\"):\n-            expected = tf.constant([[2, 2], [0, 1]])\n-        else:\n-            expected = tf.constant([[0, 2], [1, 0]])\n-        self.assertAllClose(outputs, expected)\n-\n-    def test_categorical_seed_cast(self):\n-        inputs = tf.ones([2, 3], dtype=\"float32\")\n-        seed = tf.int32.max + 1000\n-        outputs_mod = random.categorical(inputs, 2, seed=seed)\n-        outputs_nomod = random.categorical(inputs, 2, seed=1001)\n-        self.assertAllClose(outputs_mod, outputs_nomod)\n\n@@ -14,7 +14,7 @@ from keras.src.testing.test_utils import named_product\n from keras.src.utils.rng_utils import set_random_seed\n \n \n-class RandomTest(testing.TestCase, parameterized.TestCase):\n+class RandomCorrectnessTest(testing.TestCase, parameterized.TestCase):\n     @parameterized.parameters(\n         {\"seed\": 10, \"shape\": (5,), \"mean\": 0, \"stddev\": 1},\n         {\"seed\": 10, \"shape\": (2, 3), \"mean\": 0, \"stddev\": 1},\n@@ -63,12 +63,6 @@ class RandomTest(testing.TestCase, parameterized.TestCase):\n         expected = np.tile(np.arange(batch_size)[:, None], (1, num_samples))\n         self.assertAllClose(res, expected)\n \n-    def test_categorical_errors(self):\n-        with self.assertRaises(ValueError):\n-            random.categorical(np.ones((5,)), 5)\n-        with self.assertRaises(ValueError):\n-            random.categorical(np.ones((5, 5, 5)), 5)\n-\n     @parameterized.parameters(\n         {\"seed\": 10, \"shape\": (5,), \"min\": 0, \"max\": 10, \"dtype\": \"uint16\"},\n         {\"seed\": 10, \"shape\": (2, 3), \"min\": 0, \"max\": 10, \"dtype\": \"uint32\"},\n@@ -117,25 +111,6 @@ class RandomTest(testing.TestCase, parameterized.TestCase):\n         self.assertGreater(ops.max(x_res), ops.max(x))\n         self.assertGreater(ops.sum(x_res == 0), 2)\n \n-    @pytest.mark.skipif(\n-        keras.backend.backend() != \"jax\",\n-        reason=\"This test requires `jax` as the backend.\",\n-    )\n-    def test_dropout_jax_jit_stateless(self):\n-        import jax\n-        import jax.numpy as jnp\n-\n-        x = ops.ones(3)\n-\n-        @jax.jit\n-        def train_step(x):\n-            with keras.src.backend.StatelessScope():\n-                x = keras.layers.Dropout(rate=0.1)(x, training=True)\n-            return x\n-\n-        x = train_step(x)\n-        self.assertIsInstance(x, jnp.ndarray)\n-\n     def test_dropout_noise_shape(self):\n         inputs = ops.ones((2, 3, 5, 7))\n         x = random.dropout(\n@@ -143,37 +118,6 @@ class RandomTest(testing.TestCase, parameterized.TestCase):\n         )\n         self.assertEqual(x.shape, (2, 3, 5, 7))\n \n-    @pytest.mark.skipif(\n-        keras.backend.backend() != \"jax\",\n-        reason=\"This test requires `jax` as the backend.\",\n-    )\n-    def test_jax_rngkey_seed(self):\n-        import jax\n-        import jax.numpy as jnp\n-\n-        seed = 1234\n-        rng = jax.random.PRNGKey(seed)\n-        self.assertEqual(rng.shape, (2,))\n-        self.assertEqual(rng.dtype, jnp.uint32)\n-        x = random.randint((3, 5), 0, 10, seed=rng)\n-        self.assertIsInstance(x, jnp.ndarray)\n-\n-    @pytest.mark.skipif(\n-        keras.backend.backend() != \"jax\",\n-        reason=\"This test requires `jax` as the backend.\",\n-    )\n-    def test_jax_unseed_disallowed_during_tracing(self):\n-        import jax\n-\n-        @jax.jit\n-        def jit_fn():\n-            return random.randint((2, 2), 0, 10, seed=None)\n-\n-        with self.assertRaisesRegex(\n-            ValueError, \"you should only use seeded random ops\"\n-        ):\n-            jit_fn()\n-\n     def test_global_seed_generator(self):\n         # Check that unseeded RNG calls use and update global_rng_state()\n \n@@ -238,19 +182,6 @@ class RandomTest(testing.TestCase, parameterized.TestCase):\n         self.assertAllClose(np.sum(x, axis=1), ops.sum(y, axis=1))\n         self.assertNotAllClose(np.sum(x, axis=0), ops.sum(y, axis=0))\n \n-    def test_randint_dtype_validation(self):\n-        with self.assertRaisesRegex(\n-            ValueError, \"`keras.random.randint` requires an integer `dtype`.\"\n-        ):\n-            random.randint((3, 4), minval=0, maxval=10, dtype=\"float64\")\n-\n-    def test_uniform_dtype_validation(self):\n-        with self.assertRaisesRegex(\n-            ValueError,\n-            \"`keras.random.uniform` requires a floating point `dtype`.\",\n-        ):\n-            random.uniform((3, 4), minval=0, maxval=10, dtype=\"int64\")\n-\n     @parameterized.parameters(\n         {\"seed\": 10, \"shape\": (5, 2), \"alpha\": 2.0, \"dtype\": \"float16\"},\n         {\"seed\": 10, \"shape\": (2,), \"alpha\": 1.5, \"dtype\": \"float32\"},\n@@ -425,6 +356,88 @@ class RandomBehaviorTest(testing.TestCase, parameterized.TestCase):\n             output = ops.convert_to_numpy(output)\n         self.assertEqual(output.shape, (2, 4, 4, 3))\n \n+    def test_categorical_errors(self):\n+        with self.assertRaises(ValueError):\n+            random.categorical(np.ones((5,)), 5)\n+        with self.assertRaises(ValueError):\n+            random.categorical(np.ones((5, 5, 5)), 5)\n+\n+    def test_randint_dtype_validation(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"`keras.random.randint` requires an integer `dtype`.\"\n+        ):\n+            random.randint((3, 4), minval=0, maxval=10, dtype=\"float64\")\n+\n+    def test_uniform_dtype_validation(self):\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"`keras.random.uniform` requires a floating point `dtype`.\",\n+        ):\n+            random.uniform((3, 4), minval=0, maxval=10, dtype=\"int64\")\n+\n+    @pytest.mark.skipif(\n+        keras.backend.backend() != \"jax\",\n+        reason=\"This test requires `jax` as the backend.\",\n+    )\n+    def test_dropout_jax_jit_stateless(self):\n+        import jax\n+        import jax.numpy as jnp\n+\n+        x = ops.ones(3)\n+\n+        @jax.jit\n+        def train_step(x):\n+            with keras.src.backend.StatelessScope():\n+                x = keras.layers.Dropout(rate=0.1)(x, training=True)\n+            return x\n+\n+        x = train_step(x)\n+        self.assertIsInstance(x, jnp.ndarray)\n+\n+    @pytest.mark.skipif(\n+        keras.backend.backend() != \"jax\",\n+        reason=\"This test requires `jax` as the backend.\",\n+    )\n+    def test_jax_rngkey_seed(self):\n+        import jax\n+        import jax.numpy as jnp\n+\n+        seed = 1234\n+        rng = jax.random.PRNGKey(seed)\n+        self.assertEqual(rng.shape, (2,))\n+        self.assertEqual(rng.dtype, jnp.uint32)\n+        x = random.randint((3, 5), 0, 10, seed=rng)\n+        self.assertIsInstance(x, jnp.ndarray)\n+\n+    @pytest.mark.skipif(\n+        keras.backend.backend() != \"jax\",\n+        reason=\"This test requires `jax` as the backend.\",\n+    )\n+    def test_jax_unseed_disallowed_during_tracing(self):\n+        import jax\n+\n+        @jax.jit\n+        def jit_fn():\n+            return random.randint((2, 2), 0, 10, seed=None)\n+\n+        with self.assertRaisesRegex(\n+            ValueError, \"you should only use seeded random ops\"\n+        ):\n+            jit_fn()\n+\n+    @pytest.mark.skipif(\n+        backend.backend() != \"tensorflow\",\n+        reason=\"This test requires `tensorflow` as the backend.\",\n+    )\n+    def test_tf_cast_seed(self):\n+        import tensorflow as tf\n+\n+        inputs = tf.ones([2, 3], dtype=\"float32\")\n+        seed = tf.int32.max + 1000  # Test floormod operation\n+        outputs_mod = random.categorical(inputs, 2, seed=seed)\n+        outputs_nomod = random.categorical(inputs, 2, seed=1001)\n+        self.assertAllClose(outputs_mod, outputs_nomod)\n+\n \n class RandomDTypeTest(testing.TestCase, parameterized.TestCase):\n     INT_DTYPES = [x for x in dtypes.INT_TYPES if x != \"uint64\"]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
