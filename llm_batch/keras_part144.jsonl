{"custom_id": "keras#2c432ffeb381d5d604ac51a1fbd2422bdc76dfa9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 122 | Lines Deleted: 16 | Files Changed: 3 | Hunks: 37 | Methods Changed: 27 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 138 | Churn Cumulative: 6932 | Contributors (this commit): 62 | Commits (past 90d): 44 | Contributors (cumulative): 68 | DMM Complexity: None\n\nDIFF:\n@@ -1080,6 +1080,11 @@ def mean(x, axis=None, keepdims=False):\n def any(x, axis=None, keepdims=False):\n     \"\"\"Bitwise reduction (logical OR).\n \n+    # Arguments\n+        x: input tensor.\n+        axis: axis along which to perform the reduction.\n+        keepdims: whether the drop or broadcast the reduction axes.\n+\n     # Returns\n         A uint8 tensor (0s and 1s).\n     \"\"\"\n@@ -1092,6 +1097,11 @@ def any(x, axis=None, keepdims=False):\n def all(x, axis=None, keepdims=False):\n     \"\"\"Bitwise reduction (logical AND).\n \n+    # Arguments\n+        x: input tensor.\n+        axis: axis along which to perform the reduction.\n+        keepdims: whether the drop or broadcast the reduction axes.\n+\n     # Returns\n         A uint8 tensor (0s and 1s).\n     \"\"\"\n@@ -1102,8 +1112,12 @@ def all(x, axis=None, keepdims=False):\n \n \n def argmax(x, axis=-1):\n-    \"\"\"Returns the index of the maximum value\n-    along a tensor axis.\n+    \"\"\"Returns the index of the maximum value along an axis.\n+\n+    # Arguments\n+        x: input tensor.\n+        axis: axis along which to perform the reduction.\n+        keepdims: whether the drop or broadcast the reduction axes.\n \n     # Returns\n         A tensor.\n@@ -1114,8 +1128,12 @@ def argmax(x, axis=-1):\n \n \n def argmin(x, axis=-1):\n-    \"\"\"Returns the index of the minimum value\n-    along a tensor axis.\n+    \"\"\"Returns the index of the minimum value along an axis.\n+\n+    # Arguments\n+        x: input tensor.\n+        axis: axis along which to perform the reduction.\n+        keepdims: whether the drop or broadcast the reduction axes.\n \n     # Returns\n         A tensor.\n@@ -1128,6 +1146,9 @@ def argmin(x, axis=-1):\n def square(x):\n     \"\"\"Element-wise square.\n \n+    # Arguments\n+        x: input tensor.\n+\n     # Returns\n         A tensor.\n     \"\"\"\n@@ -1137,6 +1158,9 @@ def square(x):\n def abs(x):\n     \"\"\"Element-wise absolute value.\n \n+    # Arguments\n+        x: input tensor.\n+\n     # Returns\n         A tensor.\n     \"\"\"\n@@ -1146,6 +1170,9 @@ def abs(x):\n def sqrt(x):\n     \"\"\"Element-wise square root.\n \n+    # Arguments\n+        x: input tensor.\n+\n     # Returns\n         A tensor.\n     \"\"\"\n@@ -1158,6 +1185,9 @@ def sqrt(x):\n def exp(x):\n     \"\"\"Element-wise exponential.\n \n+    # Arguments\n+        x: input tensor.\n+\n     # Returns\n         A tensor.\n     \"\"\"\n@@ -1167,6 +1197,9 @@ def exp(x):\n def log(x):\n     \"\"\"Element-wise log.\n \n+    # Arguments\n+        x: input tensor.\n+\n     # Returns\n         A tensor.\n     \"\"\"\n@@ -1176,6 +1209,9 @@ def log(x):\n def round(x):\n     \"\"\"Element-wise rounding to the closest integer.\n \n+    # Arguments\n+        x: input tensor.\n+\n     # Returns\n         A tensor.\n     \"\"\"\n@@ -1185,6 +1221,9 @@ def round(x):\n def sign(x):\n     \"\"\"Element-wise sign.\n \n+    # Arguments\n+        x: input tensor.\n+\n     # Returns\n         A tensor.\n     \"\"\"\n@@ -1194,6 +1233,9 @@ def sign(x):\n def pow(x, a):\n     \"\"\"Element-wise exponentiation.\n \n+    # Arguments\n+        x: input tensor.\n+\n     # Returns\n         A tensor.\n     \"\"\"\n@@ -1297,6 +1339,9 @@ def sin(x):\n def cos(x):\n     \"\"\"Computes cos of x element-wise.\n \n+    # Arguments\n+        x: input tensor.\n+\n     # Returns\n         A tensor.\n     \"\"\"\n@@ -1668,6 +1713,9 @@ def spatial_3d_padding(x, padding=(1, 1, 1), dim_ordering='default'):\n def stack(x):\n     \"\"\"Stacks a list of rank `R` tensors into a rank `R+1` tensor.\n \n+    # Arguments\n+        x: input tensor.\n+\n     # Returns\n         A tensor.\n     \"\"\"\n@@ -1708,7 +1756,10 @@ def reverse(x, axes):\n \n \n def get_value(x):\n-    \"\"\"Returns the value of a variable/\n+    \"\"\"Returns the value of a variable.\n+\n+    # Arguments\n+        x: input variable.\n \n     # Returns\n         A Numpy array.\n@@ -1719,6 +1770,9 @@ def get_value(x):\n def batch_get_value(xs):\n     \"\"\"Returns the value of more than one tensor variable.\n \n+    # Arguments\n+        x: list of variables.\n+\n     # Returns\n         A list of Numpy arrays.\n     \"\"\"\n@@ -1731,7 +1785,6 @@ def batch_get_value(xs):\n def set_value(x, value):\n     \"\"\"Sets the value of a variable,\n     from a Numpy array. It returns `None`.\n-\n     \"\"\"\n     value = np.asarray(value)\n     tf_dtype = _convert_string_dtype(x.dtype.name.split('_')[0])\n@@ -2094,8 +2147,11 @@ def switch(condition, then_expression, else_expression):\n \n     # Arguments\n         condition: scalar tensor.\n-        then_expression: TensorFlow operation.\n-        else_expression: TensorFlow operation.\n+        then_expression: either a tensor, or a callable that returns a tensor.\n+        else_expression: either a tensor, or a callable that returns a tensor.\n+\n+    # Returns\n+        The selected tensor.\n     \"\"\"\n     if condition.dtype != tf.bool:\n         condition = tf.cast(condition, 'bool')\n@@ -2161,7 +2217,7 @@ def relu(x, alpha=0., max_value=None):\n         max_value: Saturation threshold.\n \n     # Returns\n-        A tensor\n+        A tensor.\n     \"\"\"\n     if alpha != 0.:\n         negative_part = tf.nn.relu(-x)\n@@ -2182,6 +2238,9 @@ def elu(x, alpha=1.):\n     # Arguments\n         x: A tenor or variable to compute the activation function for.\n         alpha: A scalar, slope of positive section.\n+\n+    # Returns\n+        A tensor.\n     \"\"\"\n     res = tf.nn.elu(x)\n     if alpha == 1:\n@@ -2281,6 +2340,16 @@ def sparse_categorical_crossentropy(output, target, from_logits=False):\n \n def binary_crossentropy(output, target, from_logits=False):\n     \"\"\"Binary crossentropy between an output tensor and a target tensor.\n+\n+    # Arguments\n+        output: A tensor.\n+        target: A tensor with the same shape as `output`.\n+        from_logits: Whether `output` is expected to be a logits tensor.\n+            By default, we consider that `output`\n+            encodes a probability distribution.\n+\n+    # Returns\n+        A tensor.\n     \"\"\"\n     # Note: tf.nn.softmax_cross_entropy_with_logits\n     # expects logits, Keras expects probabilities.\n@@ -2340,8 +2409,7 @@ def tanh(x):\n \n \n def dropout(x, level, noise_shape=None, seed=None):\n-    \"\"\"Sets entries in `x` to zero at random,\n-    while scaling the entire tensor.\n+    \"\"\"Sets entries in `x` to zero at random, while scaling the entire tensor.\n \n     # Arguments\n         x: tensor\n@@ -2350,6 +2418,9 @@ def dropout(x, level, noise_shape=None, seed=None):\n         noise_shape: shape for randomly generated keep/drop flags,\n             must be broadcastable to the shape of `x`\n         seed: random seed to ensure determinism.\n+\n+    # Returns\n+        A tensor.\n     \"\"\"\n     retain_prob = 1. - level\n     if seed is None:\n@@ -2361,6 +2432,13 @@ def dropout(x, level, noise_shape=None, seed=None):\n \n def l2_normalize(x, axis):\n     \"\"\"Normalizes a tensor wrt the L2 norm alongside the specified axis.\n+\n+    # Arguments\n+        x: input tensor.\n+        axis: axis along which to perform normalization.\n+\n+    # Returns\n+        A tensor.\n     \"\"\"\n     if axis < 0:\n         axis = axis % len(x.get_shape())\n@@ -2543,6 +2621,9 @@ def deconv2d(x, kernel, output_shape, strides=(1, 1),\n         dim_ordering: `\"tf\"` or `\"th\"`.\n             Whether to use Theano or TensorFlow dimension ordering\n             for inputs/kernels/ouputs.\n+\n+    # Returns\n+        A tensor, result of transposed 2D convolution.\n     \"\"\"\n     if dim_ordering == 'default':\n         dim_ordering = image_dim_ordering()\n@@ -2577,6 +2658,9 @@ def atrous_conv2d(x, kernel, rate=1,\n         dim_ordering: `\"tf\"` or `\"th\"`.\n             Whether to use Theano or TensorFlow dimension ordering\n             for inputs/kernels/ouputs.\n+\n+    # Returns\n+        A tensor, result of atrous transposed 2D convolution.\n     \"\"\"\n     if dim_ordering == 'default':\n         dim_ordering = image_dim_ordering()\n@@ -2628,6 +2712,9 @@ def conv3d(x, kernel, strides=(1, 1, 1),\n         dim_ordering: `\"tf\"` or `\"th\"`.\n             Whether to use Theano or TensorFlow dimension ordering\n             for inputs/kernels/ouputs.\n+\n+    # Returns\n+        A tensor, result of 3D convolution.\n     \"\"\"\n     if dim_ordering == 'default':\n         dim_ordering = image_dim_ordering()\n@@ -2654,6 +2741,9 @@ def pool2d(x, pool_size, strides=(1, 1),\n         border_mode: one of `\"valid\"`, `\"same\"`.\n         dim_ordering: one of `\"th\"`, `\"tf\"`.\n         pool_mode: one of `\"max\"`, `\"avg\"`.\n+\n+    # Returns\n+        A tensor, result of 2D pooling.\n     \"\"\"\n     if dim_ordering == 'default':\n         dim_ordering = image_dim_ordering()\n@@ -2686,6 +2776,9 @@ def pool3d(x, pool_size, strides=(1, 1, 1), border_mode='valid',\n         border_mode: one of `\"valid\"`, `\"same\"`.\n         dim_ordering: one of `\"th\"`, `\"tf\"`.\n         pool_mode: one of `\"max\"`, `\"avg\"`.\n+\n+    # Returns\n+        A tensor, result of 3D pooling.\n     \"\"\"\n     if dim_ordering == 'default':\n         dim_ordering = image_dim_ordering()\n@@ -2720,6 +2813,9 @@ def random_normal(shape, mean=0.0, std=1.0, dtype=None, seed=None):\n             to draw samples.\n         dtype: String, dtype of returned tensor.\n         seed: Integer, random seed.\n+\n+    # Returns\n+        A tensor.\n     \"\"\"\n     if dtype is None:\n         dtype = floatx()\n@@ -2740,6 +2836,9 @@ def random_uniform(shape, low=0.0, high=1.0, dtype=None, seed=None):\n             to draw samples.\n         dtype: String, dtype of returned tensor.\n         seed: Integer, random seed.\n+\n+    # Returns\n+        A tensor.\n     \"\"\"\n     if dtype is None:\n         dtype = floatx()\n@@ -2757,6 +2856,9 @@ def random_binomial(shape, p=0.0, dtype=None, seed=None):\n         p: A float, `0. <= p <= 1`, probability of binomlai distribution.\n         dtype: String, dtype of returned tensor.\n         seed: Integer, random seed.\n+\n+    # Returns\n+        A tensor.\n     \"\"\"\n     if dtype is None:\n         dtype = floatx()\n\n@@ -5,9 +5,10 @@ import numpy as np\n \n \n class GaussianNoise(Layer):\n-    \"\"\"Apply to the input an additive zero-centered Gaussian noise with\n-    standard deviation `sigma`. This is useful to mitigate overfitting\n-    (you could see it as a kind of random data augmentation).\n+    \"\"\"Apply additive zero-centered Gaussian noise.\n+\n+    This is useful to mitigate overfitting\n+    (you could see it as a form of random data augmentation).\n     Gaussian Noise (GS) is a natural choice as corruption process\n     for real valued inputs.\n \n@@ -44,13 +45,14 @@ class GaussianNoise(Layer):\n \n \n class GaussianDropout(Layer):\n-    \"\"\"Apply to the input an multiplicative one-centered Gaussian noise\n-    with standard deviation `sqrt(p/(1-p))`.\n+    \"\"\"Apply multiplicative 1-centered Gaussian noise.\n \n     As it is a regularization layer, it is only active at training time.\n \n     # Arguments\n         p: float, drop probability (as with `Dropout`).\n+            The multiplicative noise will have\n+            standard deviation `sqrt(p / (1 - p))`.\n \n     # Input shape\n         Arbitrary. Use the keyword argument `input_shape`\n\n@@ -1,7 +1,9 @@\n from __future__ import absolute_import\n+\n import copy\n import inspect\n import types\n+\n import numpy as np\n \n from ..utils.np_utils import to_categorical\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a5ec992b1fb7e52b12c9cfa220defaa9a5b0628e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 831 | Contributors (this commit): 17 | Commits (past 90d): 11 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -1,4 +1,3 @@\n-import numpy as np\n from . import backend as K\n from .utils.generic_utils import get_from_module\n \n@@ -67,7 +66,7 @@ def mean_absolute_percentage_error(y_true, y_pred):\n     \"\"\"\n     diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true),\n                                             K.epsilon(),\n-                                            np.inf))\n+                                            None))\n     return 100. * K.mean(diff)\n \n \n@@ -77,8 +76,8 @@ def mean_squared_logarithmic_error(y_true, y_pred):\n     Computes the mean squared logarithmic error (msle) rate\n     between predicted and target values.\n     \"\"\"\n-    first_log = K.log(K.clip(y_pred, K.epsilon(), np.inf) + 1.)\n-    second_log = K.log(K.clip(y_true, K.epsilon(), np.inf) + 1.)\n+    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n+    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n     return K.mean(K.square(first_log - second_log))\n \n \n\n@@ -1,5 +1,5 @@\n from __future__ import absolute_import\n-import numpy as np\n+\n from . import backend as K\n from .utils.generic_utils import get_from_module\n \n@@ -15,13 +15,13 @@ def mean_absolute_error(y_true, y_pred):\n def mean_absolute_percentage_error(y_true, y_pred):\n     diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true),\n                                             K.epsilon(),\n-                                            np.inf))\n+                                            None))\n     return 100. * K.mean(diff, axis=-1)\n \n \n def mean_squared_logarithmic_error(y_true, y_pred):\n-    first_log = K.log(K.clip(y_pred, K.epsilon(), np.inf) + 1.)\n-    second_log = K.log(K.clip(y_true, K.epsilon(), np.inf) + 1.)\n+    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n+    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n     return K.mean(K.square(first_log - second_log), axis=-1)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fdb9561adee7cb63853c0cb7d9ca01197bcd618e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 6 | Churn Cumulative: 3445 | Contributors (this commit): 49 | Commits (past 90d): 29 | Contributors (cumulative): 49 | DMM Complexity: 0.0\n\nDIFF:\n@@ -486,7 +486,8 @@ def _old_normalize_batch_in_training(x, gamma, beta,\n     \"\"\"Computes mean and std for batch then apply batch_normalization on batch.\n     \"\"\"\n     dev = theano.config.device\n-    use_cudnn = ndim(x) < 5 and reduction_axes == [0, 2, 3] and (dev.startswith('cuda') or dev.startswith('gpu'))\n+    use_cudnn = ndim(x) < 5 and reduction_axes == [0, 2, 3] and (dev.startswith('cuda') or dev.startswith('gpu')) and \\\n+        theano.sandbox.cuda.dnn_available()\n     if use_cudnn:\n         broadcast_beta = beta.dimshuffle('x', 0, 'x', 'x')\n         broadcast_gamma = gamma.dimshuffle('x', 0, 'x', 'x')\n@@ -539,7 +540,8 @@ def _old_batch_normalization(x, mean, var, beta, gamma, epsilon=1e-3):\n \n     ndim = x.ndim\n     dev = theano.config.device\n-    use_cudnn = ndim < 5 and (dev.startswith('cuda') or dev.startswith('gpu'))\n+    use_cudnn = ndim < 5 and (dev.startswith('cuda') or dev.startswith('gpu')) and \\\n+        theano.sandbox.cuda.dnn_available()\n     if use_cudnn:\n         try:\n             axis = mean.broadcastable.index(False)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9120a7251d3ac13048d212b424cb92841ffd7cd4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 47 | Lines Deleted: 32 | Files Changed: 2 | Hunks: 33 | Methods Changed: 13 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 79 | Churn Cumulative: 1954 | Contributors (this commit): 27 | Commits (past 90d): 13 | Contributors (cumulative): 29 | DMM Complexity: 0.3333333333333333\n\nDIFF:\n@@ -4,7 +4,9 @@ from .. import backend as K\n \n \n class BatchNormalization(Layer):\n-    \"\"\"Normalize the activations of the previous layer at each batch,\n+    \"\"\"Batch normalization layer (Ioffe and Szegedy, 2014).\n+\n+    Normalize the activations of the previous layer at each batch,\n     i.e. applies a transformation that maintains the mean activation\n     close to 0 and the activation standard deviation close to 1.\n \n\n@@ -18,7 +18,7 @@ class BaseWrapper(object):\n \n     # Arguments\n         build_fn: callable function or class instance\n-        sk_params: model parameters & fitting parameters\n+        **sk_params: model parameters & fitting parameters\n \n     The build_fn should construct, compile and return a Keras model, which\n     will then be used to fit/predict. One of the following\n@@ -57,18 +57,23 @@ class BaseWrapper(object):\n         self.check_params(sk_params)\n \n     def check_params(self, params):\n-        \"\"\"Check for user typos in \"params\" keys to avoid\n+        \"\"\"Checks for user typos in \"params\" keys to avoid\n         unwanted usage of default values\n \n         # Arguments\n             params: dictionary\n                 The parameters to be checked\n+\n+        # Raises\n+            ValueError: if any member of `params` is not a valid\n+                argument.\n         \"\"\"\n         legal_params_fns = [Sequential.fit, Sequential.predict,\n                             Sequential.predict_classes, Sequential.evaluate]\n         if self.build_fn is None:\n             legal_params_fns.append(self.__call__)\n-        elif not isinstance(self.build_fn, types.FunctionType) and not isinstance(self.build_fn, types.MethodType):\n+        elif (not isinstance(self.build_fn, types.FunctionType) and\n+              not isinstance(self.build_fn, types.MethodType)):\n             legal_params_fns.append(self.build_fn.__call__)\n         else:\n             legal_params_fns.append(self.build_fn)\n@@ -83,7 +88,7 @@ class BaseWrapper(object):\n                 raise ValueError('{} is not a legal parameter'.format(params_name))\n \n     def get_params(self, deep=True):\n-        \"\"\"Get parameters for this estimator.\n+        \"\"\"Gets parameters for this estimator.\n \n         # Arguments\n             deep: boolean, optional\n@@ -99,7 +104,7 @@ class BaseWrapper(object):\n         return res\n \n     def set_params(self, **params):\n-        \"\"\"Set the parameters of this estimator.\n+        \"\"\"Sets the parameters of this estimator.\n \n         # Arguments\n         params: dict\n@@ -112,12 +117,12 @@ class BaseWrapper(object):\n         self.sk_params.update(params)\n         return self\n \n-    def fit(self, X, y, **kwargs):\n-        \"\"\"Construct a new model with build_fn and fit the model according\n+    def fit(self, x, y, **kwargs):\n+        \"\"\"Constructs a new model with build_fn and fit the model according\n         to the given training data.\n \n         # Arguments\n-            X : array-like, shape `(n_samples, n_features)`\n+            x : array-like, shape `(n_samples, n_features)`\n                 Training samples where n_samples in the number of samples\n                 and n_features is the number of features.\n             y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n@@ -129,10 +134,10 @@ class BaseWrapper(object):\n             history : object\n                 details about the training history at each epoch.\n         \"\"\"\n-\n         if self.build_fn is None:\n             self.model = self.__call__(**self.filter_sk_params(self.__call__))\n-        elif not isinstance(self.build_fn, types.FunctionType) and not isinstance(self.build_fn, types.MethodType):\n+        elif (not isinstance(self.build_fn, types.FunctionType) and\n+              not isinstance(self.build_fn, types.MethodType)):\n             self.model = self.build_fn(\n                 **self.filter_sk_params(self.build_fn.__call__))\n         else:\n@@ -147,12 +152,12 @@ class BaseWrapper(object):\n         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n         fit_args.update(kwargs)\n \n-        history = self.model.fit(X, y, **fit_args)\n+        history = self.model.fit(x, y, **fit_args)\n \n         return history\n \n-    def filter_sk_params(self, fn, override={}):\n-        \"\"\"Filter sk_params and return those in fn's arguments\n+    def filter_sk_params(self, fn, override=None):\n+        \"\"\"Filters sk_params and return those in fn's arguments\n \n         # Arguments\n             fn : arbitrary function\n@@ -162,6 +167,7 @@ class BaseWrapper(object):\n             res : dictionary dictionary containing variables\n                 in both sk_params and fn's arguments.\n         \"\"\"\n+        override = override or {}\n         res = {}\n         fn_args = inspect.getargspec(fn)[0]\n         for name, value in self.sk_params.items():\n@@ -175,32 +181,34 @@ class KerasClassifier(BaseWrapper):\n     \"\"\"Implementation of the scikit-learn classifier API for Keras.\n     \"\"\"\n \n-    def predict(self, X, **kwargs):\n+    def predict(self, x, **kwargs):\n         \"\"\"Returns the class predictions for the given test data.\n \n         # Arguments\n-            X: array-like, shape `(n_samples, n_features)`\n+            x: array-like, shape `(n_samples, n_features)`\n                 Test samples where n_samples in the number of samples\n                 and n_features is the number of features.\n             kwargs: dictionary arguments\n-                Legal arguments are the arguments of `Sequential.predict_classes`.\n+                Legal arguments are the arguments\n+                of `Sequential.predict_classes`.\n \n         # Returns\n             preds: array-like, shape `(n_samples,)`\n                 Class predictions.\n         \"\"\"\n         kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n-        return self.model.predict_classes(X, **kwargs)\n+        return self.model.predict_classes(x, **kwargs)\n \n-    def predict_proba(self, X, **kwargs):\n+    def predict_proba(self, x, **kwargs):\n         \"\"\"Returns class probability estimates for the given test data.\n \n         # Arguments\n-            X: array-like, shape `(n_samples, n_features)`\n+            x: array-like, shape `(n_samples, n_features)`\n                 Test samples where n_samples in the number of samples\n                 and n_features is the number of features.\n             kwargs: dictionary arguments\n-                Legal arguments are the arguments of `Sequential.predict_classes`.\n+                Legal arguments are the arguments\n+                of `Sequential.predict_classes`.\n \n         # Returns\n             proba: array-like, shape `(n_samples, n_outputs)`\n@@ -211,7 +219,7 @@ class KerasClassifier(BaseWrapper):\n                 (instead of `(n_sample, 1)` as in Keras).\n         \"\"\"\n         kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n-        probs = self.model.predict_proba(X, **kwargs)\n+        probs = self.model.predict_proba(x, **kwargs)\n \n         # check if binary classification\n         if probs.shape[1] == 1:\n@@ -219,21 +227,26 @@ class KerasClassifier(BaseWrapper):\n             probs = np.hstack([1 - probs, probs])\n         return probs\n \n-    def score(self, X, y, **kwargs):\n+    def score(self, x, y, **kwargs):\n         \"\"\"Returns the mean accuracy on the given test data and labels.\n \n         # Arguments\n-            X: array-like, shape `(n_samples, n_features)`\n+            x: array-like, shape `(n_samples, n_features)`\n                 Test samples where n_samples in the number of samples\n                 and n_features is the number of features.\n             y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n-                True labels for X.\n+                True labels for x.\n             kwargs: dictionary arguments\n                 Legal arguments are the arguments of `Sequential.evaluate`.\n \n         # Returns\n             score: float\n                 Mean accuracy of predictions on X wrt. y.\n+\n+        # Raises\n+            ValueError: If the underlying model isn't configured to\n+                compute accuracy. You should pass `metrics=[\"accuracy\"]` to\n+                the `.compile()` method of the model.\n         \"\"\"\n         kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n \n@@ -243,7 +256,7 @@ class KerasClassifier(BaseWrapper):\n         if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n             y = to_categorical(y)\n \n-        outputs = self.model.evaluate(X, y, **kwargs)\n+        outputs = self.model.evaluate(x, y, **kwargs)\n         if not isinstance(outputs, list):\n             outputs = [outputs]\n         for name, output in zip(self.model.metrics_names, outputs):\n@@ -258,27 +271,27 @@ class KerasRegressor(BaseWrapper):\n     \"\"\"Implementation of the scikit-learn regressor API for Keras.\n     \"\"\"\n \n-    def predict(self, X, **kwargs):\n+    def predict(self, x, **kwargs):\n         \"\"\"Returns predictions for the given test data.\n \n         # Arguments\n             X: array-like, shape `(n_samples, n_features)`\n                 Test samples where n_samples in the number of samples\n                 and n_features is the number of features.\n-            kwargs: dictionary arguments\n+            **kwargs: dictionary arguments\n                 Legal arguments are the arguments of `Sequential.predict`.\n         # Returns\n             preds: array-like, shape `(n_samples,)`\n                 Predictions.\n         \"\"\"\n         kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n-        return np.squeeze(self.model.predict(X, **kwargs))\n+        return np.squeeze(self.model.predict(x, **kwargs))\n \n-    def score(self, X, y, **kwargs):\n+    def score(self, x, y, **kwargs):\n         \"\"\"Returns the mean loss on the given test data and labels.\n \n         # Arguments\n-            X: array-like, shape `(n_samples, n_features)`\n+            x: array-like, shape `(n_samples, n_features)`\n                 Test samples where n_samples in the number of samples\n                 and n_features is the number of features.\n             y: array-like, shape `(n_samples,)`\n@@ -291,7 +304,7 @@ class KerasRegressor(BaseWrapper):\n                 Mean accuracy of predictions on X wrt. y.\n         \"\"\"\n         kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n-        loss = self.model.evaluate(X, y, **kwargs)\n+        loss = self.model.evaluate(x, y, **kwargs)\n         if isinstance(loss, list):\n             return loss[0]\n         return loss\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7aa3114d9ff1cfbeb4128934fec05878fb7cf633", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 74 | Lines Deleted: 33 | Files Changed: 4 | Hunks: 36 | Methods Changed: 21 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 107 | Churn Cumulative: 1930 | Contributors (this commit): 31 | Commits (past 90d): 21 | Contributors (cumulative): 37 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,13 +1,16 @@\n+\"\"\"Utilities for file download and caching.\"\"\"\n from __future__ import absolute_import\n from __future__ import print_function\n \n+import functools\n import tarfile\n import os\n import sys\n import shutil\n import hashlib\n from six.moves.urllib.request import urlopen\n-from six.moves.urllib.error import URLError, HTTPError\n+from six.moves.urllib.error import URLError\n+from six.moves.urllib.error import HTTPError\n \n from ..utils.generic_utils import Progbar\n \n@@ -42,7 +45,8 @@ def get_file(fname, origin, untar=False,\n              md5_hash=None, cache_subdir='datasets'):\n     \"\"\"Downloads a file from a URL if it not already in the cache.\n \n-    Passing the MD5 hash will verify the file after download as well as if it is already present in the cache.\n+    Passing the MD5 hash will verify the file after download\n+    as well as if it is already present in the cache.\n \n     # Arguments\n         fname: name of the file\n@@ -69,7 +73,7 @@ def get_file(fname, origin, untar=False,\n \n     download = False\n     if os.path.exists(fpath):\n-        # file found; verify integrity if a hash was provided\n+        # File found; verify integrity if a hash was provided.\n         if md5_hash is not None:\n             if not validate_file(fpath, md5_hash):\n                 print('A local file was found, but it seems to be '\n@@ -80,11 +84,9 @@ def get_file(fname, origin, untar=False,\n \n     if download:\n         print('Downloading data from', origin)\n-        global progbar\n         progbar = None\n \n-        def dl_progress(count, block_size, total_size):\n-            global progbar\n+        def dl_progress(count, block_size, total_size, progbar=None):\n             if progbar is None:\n                 progbar = Progbar(total_size)\n             else:\n@@ -93,7 +95,8 @@ def get_file(fname, origin, untar=False,\n         error_msg = 'URL fetch failure on {}: {} -- {}'\n         try:\n             try:\n-                urlretrieve(origin, fpath, dl_progress)\n+                urlretrieve(origin, fpath,\n+                            functools.partial(dl_progress, progbar=progbar))\n             except URLError as e:\n                 raise Exception(error_msg.format(origin, e.errno, e.reason))\n             except HTTPError as e:\n@@ -124,7 +127,7 @@ def get_file(fname, origin, untar=False,\n \n \n def validate_file(fpath, md5_hash):\n-    \"\"\"Validates a file against a MD5 hash\n+    \"\"\"Validates a file against a MD5 hash.\n \n     # Arguments\n         fpath: path to the file being validated\n\n@@ -1,5 +1,8 @@\n+\"\"\"Python utilities required by Keras.\"\"\"\n from __future__ import absolute_import\n+\n import numpy as np\n+\n import time\n import sys\n import six\n@@ -9,6 +12,27 @@ import types as python_types\n \n def get_from_module(identifier, module_params, module_name,\n                     instantiate=False, kwargs=None):\n+    \"\"\"Retrieves a class of function member of a module.\n+\n+    # Arguments\n+        identifier: the object to retrieve. It could be specified\n+            by name (as a string), or by dict. In any other case,\n+            `identifier` itself will be returned without any changes.\n+        module_params: the members of a module\n+            (e.g. the output of `globals()`).\n+        module_name: string; the name of the target module. Only used\n+            to format error messages.\n+        instantiate: whether to instantiate the returned object\n+            (if it's a class).\n+        kwargs: a dictionary of keyword arguments to pass to the\n+            class constructor if `instantiate` is `True`.\n+\n+    # Returns\n+        The target object.\n+\n+    # Raises\n+        ValueError: if the identifier cannot be found.\n+    \"\"\"\n     if isinstance(identifier, six.string_types):\n         res = module_params.get(identifier)\n         if not res:\n@@ -36,7 +60,13 @@ def make_tuple(*args):\n \n \n def func_dump(func):\n-    \"\"\"Serializes user defined function.\n+    \"\"\"Serializes a user defined function.\n+\n+    # Arguments\n+        func: the function to serialize.\n+\n+    # Returns\n+        A tuple `(code, defaults, closure)`.\n     \"\"\"\n     code = marshal.dumps(func.__code__).decode('raw_unicode_escape')\n     defaults = func.__defaults__\n@@ -48,7 +78,16 @@ def func_dump(func):\n \n \n def func_load(code, defaults=None, closure=None, globs=None):\n-    \"\"\"Deserializes user defined function.\n+    \"\"\"Deserializes a user defined function.\n+\n+    # Arguments\n+        code: bytecode of the function.\n+        defaults: defaults of the function.\n+        closure: closure of the function.\n+        globs: dictionary of global objects.\n+\n+    # Returns\n+        A function object.\n     \"\"\"\n     if isinstance(code, (tuple, list)):  # unpack previous dump\n         code, defaults, closure = code\n@@ -81,7 +120,7 @@ class Progbar(object):\n         self.seen_so_far = 0\n         self.verbose = verbose\n \n-    def update(self, current, values=[], force=False):\n+    def update(self, current, values=None, force=False):\n         \"\"\"Updates the progress bar.\n \n         # Arguments\n@@ -90,6 +129,7 @@ class Progbar(object):\n                 The progress bar will display averages for these values.\n             force: Whether to force visual progress update.\n         \"\"\"\n+        values = values or []\n         for k, v in values:\n             if k not in self.sum_values:\n                 self.sum_values[k] = [v * (current - self.seen_so_far),\n@@ -170,7 +210,7 @@ class Progbar(object):\n \n         self.last_update = now\n \n-    def add(self, n, values=[]):\n+    def add(self, n, values=None):\n         self.update(self.seen_so_far + n, values)\n \n \n\n@@ -1,4 +1,6 @@\n+\"\"\"Numpy-related utilities.\"\"\"\n from __future__ import absolute_import\n+\n import numpy as np\n import scipy as sp\n from six.moves import range\n@@ -7,12 +9,12 @@ from .. import backend as K\n \n \n def to_categorical(y, nb_classes=None):\n-    \"\"\"Converts class vector (integers from 0 to nb_classes)\n+    \"\"\"Converts a class vector (integers from 0 to nb_classes)\n     to binary class matrix, for use with categorical_crossentropy.\n \n     # Arguments\n-        y: class vector to be converted into a matrix\n-        nb_classes: total number of classes\n+        y: class vector to be converted into a matrix.\n+        nb_classes: total number of classes.\n \n     # Returns\n         A binary matrix representation of the input.\n@@ -61,13 +63,13 @@ def categorical_probas_to_classes(p):\n     return np.argmax(p, axis=1)\n \n \n-def convert_kernel(kernel, dim_ordering='default'):\n+def convert_kernel(kernel, dim_ordering=None):\n     \"\"\"Converts a kernel matrix (Numpy array)\n     from Theano format to TensorFlow format\n     (or reciprocally, since the transformation\n     is its own inverse).\n     \"\"\"\n-    if dim_ordering == 'default':\n+    if dim_ordering is None:\n         dim_ordering = K.image_dim_ordering()\n     if not 4 <= kernel.ndim <= 5:\n         raise ValueError('Invalid kernel shape:', kernel.shape)\n\n@@ -57,16 +57,13 @@ class BaseWrapper(object):\n         self.check_params(sk_params)\n \n     def check_params(self, params):\n-        \"\"\"Checks for user typos in \"params\" keys to avoid\n-        unwanted usage of default values\n+        \"\"\"Checks for user typos in \"params\".\n \n         # Arguments\n-            params: dictionary\n-                The parameters to be checked\n+            params: dictionary; the parameters to be checked\n \n         # Raises\n-            ValueError: if any member of `params` is not a valid\n-                argument.\n+            ValueError: if any member of `params` is not a valid argument.\n         \"\"\"\n         legal_params_fns = [Sequential.fit, Sequential.predict,\n                             Sequential.predict_classes, Sequential.evaluate]\n@@ -107,8 +104,7 @@ class BaseWrapper(object):\n         \"\"\"Sets the parameters of this estimator.\n \n         # Arguments\n-        params: dict\n-            Dictionary of parameter names mapped to their values.\n+            **params: Dictionary of parameter names mapped to their values.\n \n         # Returns\n             self\n@@ -118,8 +114,7 @@ class BaseWrapper(object):\n         return self\n \n     def fit(self, x, y, **kwargs):\n-        \"\"\"Constructs a new model with build_fn and fit the model according\n-        to the given training data.\n+        \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n \n         # Arguments\n             x : array-like, shape `(n_samples, n_features)`\n@@ -157,7 +152,7 @@ class BaseWrapper(object):\n         return history\n \n     def filter_sk_params(self, fn, override=None):\n-        \"\"\"Filters sk_params and return those in fn's arguments\n+        \"\"\"Filters `sk_params` and return those in `fn`'s arguments.\n \n         # Arguments\n             fn : arbitrary function\n@@ -188,7 +183,7 @@ class KerasClassifier(BaseWrapper):\n             x: array-like, shape `(n_samples, n_features)`\n                 Test samples where n_samples in the number of samples\n                 and n_features is the number of features.\n-            kwargs: dictionary arguments\n+            **kwargs: dictionary arguments\n                 Legal arguments are the arguments\n                 of `Sequential.predict_classes`.\n \n@@ -206,7 +201,7 @@ class KerasClassifier(BaseWrapper):\n             x: array-like, shape `(n_samples, n_features)`\n                 Test samples where n_samples in the number of samples\n                 and n_features is the number of features.\n-            kwargs: dictionary arguments\n+            **kwargs: dictionary arguments\n                 Legal arguments are the arguments\n                 of `Sequential.predict_classes`.\n \n@@ -236,7 +231,7 @@ class KerasClassifier(BaseWrapper):\n                 and n_features is the number of features.\n             y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                 True labels for x.\n-            kwargs: dictionary arguments\n+            **kwargs: dictionary arguments\n                 Legal arguments are the arguments of `Sequential.evaluate`.\n \n         # Returns\n@@ -275,11 +270,12 @@ class KerasRegressor(BaseWrapper):\n         \"\"\"Returns predictions for the given test data.\n \n         # Arguments\n-            X: array-like, shape `(n_samples, n_features)`\n+            x: array-like, shape `(n_samples, n_features)`\n                 Test samples where n_samples in the number of samples\n                 and n_features is the number of features.\n             **kwargs: dictionary arguments\n                 Legal arguments are the arguments of `Sequential.predict`.\n+\n         # Returns\n             preds: array-like, shape `(n_samples,)`\n                 Predictions.\n@@ -296,7 +292,7 @@ class KerasRegressor(BaseWrapper):\n                 and n_features is the number of features.\n             y: array-like, shape `(n_samples,)`\n                 True labels for X.\n-            kwargs: dictionary arguments\n+            **kwargs: dictionary arguments\n                 Legal arguments are the arguments of `Sequential.evaluate`.\n \n         # Returns\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6fb7ba721cf215e88176c665d2d7f90027f4e26f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 4 | Churn Cumulative: 9093 | Contributors (this commit): 71 | Commits (past 90d): 69 | Contributors (cumulative): 102 | DMM Complexity: None\n\nDIFF:\n@@ -1248,7 +1248,7 @@ def clip(x, min_value, max_value):\n     # Returns\n         A tensor.\n     \"\"\"\n-    if max_value < min_value:\n+    if max_value is not None and max_value < min_value:\n         max_value = min_value\n     min_value = _to_tensor(min_value, x.dtype.base_dtype)\n     max_value = _to_tensor(max_value, x.dtype.base_dtype)\n\n@@ -401,7 +401,7 @@ def pow(x, a):\n \n \n def clip(x, min_value, max_value):\n-    if max_value < min_value:\n+    if max_value is not None and max_value < min_value:\n         max_value = min_value\n     return T.clip(x, min_value, max_value)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#088dbe6866fd51f4e0e64866e442968c17abfa10", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 14 | Churn Cumulative: 355 | Contributors (this commit): 12 | Commits (past 90d): 5 | Contributors (cumulative): 12 | DMM Complexity: 0.0\n\nDIFF:\n@@ -212,17 +212,3 @@ class Progbar(object):\n \n     def add(self, n, values=None):\n         self.update(self.seen_so_far + n, values)\n-\n-\n-def display_table(rows, positions):\n-\n-    def display_row(objects, positions):\n-        line = ''\n-        for i in range(len(objects)):\n-            line += str(objects[i])\n-            line = line[:positions[i]]\n-            line += ' ' * (positions[i] - len(line))\n-        print(line)\n-\n-    for objects in rows:\n-        display_row(objects, positions)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7ae2f8478317cd80a2adc0d5c98e00f978d1cc99", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 6 | Churn Cumulative: 3453 | Contributors (this commit): 49 | Commits (past 90d): 31 | Contributors (cumulative): 49 | DMM Complexity: 1.0\n\nDIFF:\n@@ -486,8 +486,7 @@ def _old_normalize_batch_in_training(x, gamma, beta,\n     \"\"\"Computes mean and std for batch then apply batch_normalization on batch.\n     \"\"\"\n     dev = theano.config.device\n-    use_cudnn = ndim(x) < 5 and reduction_axes == [0, 2, 3] and (dev.startswith('cuda') or dev.startswith('gpu')) and \\\n-        theano.sandbox.cuda.dnn_available()\n+    use_cudnn = ndim(x) < 5 and reduction_axes == [0, 2, 3] and (dev.startswith('cuda') or dev.startswith('gpu'))\n     if use_cudnn:\n         broadcast_beta = beta.dimshuffle('x', 0, 'x', 'x')\n         broadcast_gamma = gamma.dimshuffle('x', 0, 'x', 'x')\n@@ -540,8 +539,7 @@ def _old_batch_normalization(x, mean, var, beta, gamma, epsilon=1e-3):\n \n     ndim = x.ndim\n     dev = theano.config.device\n-    use_cudnn = ndim < 5 and (dev.startswith('cuda') or dev.startswith('gpu')) and \\\n-        theano.sandbox.cuda.dnn_available()\n+    use_cudnn = ndim < 5 and (dev.startswith('cuda') or dev.startswith('gpu'))\n     if use_cudnn:\n         try:\n             axis = mean.broadcastable.index(False)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fa585c5151ccf926ae94945ed8b9f274ee747391", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 135 | Lines Deleted: 38 | Files Changed: 6 | Hunks: 36 | Methods Changed: 21 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 173 | Churn Cumulative: 3150 | Contributors (this commit): 45 | Commits (past 90d): 37 | Contributors (cumulative): 57 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,22 +1,33 @@\n+\"\"\"Utilities related to disk I/O.\"\"\"\n from __future__ import absolute_import\n from __future__ import print_function\n+\n import numpy as np\n import sys\n from collections import defaultdict\n \n+try:\n+    import h5py\n+except ImportError:\n+    h5py = None\n+\n+try:\n+    import tables\n+except ImportError:\n+    tables = None\n+\n \n class HDF5Matrix():\n-    \"\"\"Representation of HDF5 dataset which can be used instead of a\n-    Numpy array.\n+    \"\"\"Representation of HDF5 dataset to be used instead of a Numpy array.\n \n     # Example\n \n     ```python\n-        X_data = HDF5Matrix('input/file.hdf5', 'data')\n-        model.predict(X_data)\n+        x_data = HDF5Matrix('input/file.hdf5', 'data')\n+        model.predict(x_data)\n     ```\n \n-    Providing start and end allows use of a slice of the dataset.\n+    Providing `start` and `end` allows use of a slice of the dataset.\n \n     Optionally, a normalizer function (or lambda) can be given. This will\n     be called on every slice of data retrieved.\n@@ -29,11 +40,15 @@ class HDF5Matrix():\n         end: int, end of desired slice of the specified dataset\n         normalizer: function to be called on data when retrieved\n \n+    # Returns\n+        An array-like HDF5 dataset.\n     \"\"\"\n     refs = defaultdict(int)\n \n     def __init__(self, datapath, dataset, start=0, end=None, normalizer=None):\n-        import h5py\n+        if h5py is None:\n+            raise ImportError('The use of HDF5Matrix requires '\n+                              'HDF5 and h5py installed.')\n \n         if datapath not in list(self.refs.keys()):\n             f = h5py.File(datapath)\n@@ -83,7 +98,9 @@ class HDF5Matrix():\n \n \n def save_array(array, name):\n-    import tables\n+    if tables is None:\n+        raise ImportError('The use of `save_array` requires '\n+                          'the tables module.')\n     f = tables.open_file(name, 'w')\n     atom = tables.Atom.from_dtype(array.dtype)\n     ds = f.create_carray(f.root, 'data', atom, array.shape)\n@@ -92,7 +109,9 @@ def save_array(array, name):\n \n \n def load_array(name):\n-    import tables\n+    if tables is None:\n+        raise ImportError('The use of `save_array` requires '\n+                          'the tables module.')\n     f = tables.open_file(name)\n     array = f.root.data\n     a = np.empty(shape=array.shape, dtype=array.dtype)\n@@ -102,6 +121,14 @@ def load_array(name):\n \n \n def ask_to_proceed_with_overwrite(filepath):\n+    \"\"\"Produces a prompt asking about overwriting a file.\n+\n+    # Arguments\n+        filepath: the path to the file to be overwritten.\n+\n+    # Returns\n+        True if we can proceed with overwrite, False otherwise.\n+    \"\"\"\n     get_input = input\n     if sys.version_info[:2] <= (2, 7):\n         get_input = raw_input\n\n@@ -73,9 +73,14 @@ def print_summary(layers, relevant_nodes=None,\n     print('=' * line_length)\n \n     def print_layer_summary(layer):\n+        \"\"\"Prints a summary for a single layer.\n+\n+        # Arguments\n+            layer: target layer.\n+        \"\"\"\n         try:\n             output_shape = layer.output_shape\n-        except:\n+        except AttributeError:\n             output_shape = 'multiple'\n         connections = []\n         for node_index, node in enumerate(layer.inbound_nodes):\n@@ -119,6 +124,16 @@ def print_summary(layers, relevant_nodes=None,\n \n \n def count_total_params(layers, layer_set=None):\n+    \"\"\"Counts the number of parameters in a list of layers.\n+\n+    # Arguments\n+        layers: list of layers.\n+        layer_set: set of layers already seen\n+            (so that we don't count their weights twice).\n+\n+    # Returns\n+        A tuple (count of trainable weights, count of non-trainable weights.)\n+    \"\"\"\n     if layer_set is None:\n         layer_set = set()\n     trainable_count = 0\n@@ -138,6 +153,13 @@ def count_total_params(layers, layer_set=None):\n \n \n def convert_all_kernels_in_model(model):\n+    \"\"\"Converts all convolution kernels in a model from Theano to TensorFlow.\n+\n+    Also works from TensorFlow to Theano.\n+\n+    # Arguments\n+        model: target model for the conversion.\n+    \"\"\"\n     # Note: SeparableConvolution not included\n     # since only supported by TF.\n     conv_classes = {\n\n@@ -9,11 +9,13 @@ from .. import backend as K\n \n \n def to_categorical(y, nb_classes=None):\n-    \"\"\"Converts a class vector (integers from 0 to nb_classes)\n-    to binary class matrix, for use with categorical_crossentropy.\n+    \"\"\"Converts a class vector (integers) to binary class matrix.\n+\n+    E.g. for use with categorical_crossentropy.\n \n     # Arguments\n-        y: class vector to be converted into a matrix.\n+        y: class vector to be converted into a matrix\n+            (integers from 0 to nb_classes).\n         nb_classes: total number of classes.\n \n     # Returns\n@@ -43,9 +45,9 @@ def binary_logloss(p, y):\n     return res\n \n \n-def multiclass_logloss(P, Y):\n-    npreds = [P[i][Y[i] - 1] for i in range(len(Y))]\n-    score = -(1. / len(Y)) * np.sum(np.log(npreds))\n+def multiclass_logloss(p, y):\n+    npreds = [p[i][y[i] - 1] for i in range(len(y))]\n+    score = -(1. / len(y)) * np.sum(np.log(npreds))\n     return score\n \n \n@@ -64,10 +66,19 @@ def categorical_probas_to_classes(p):\n \n \n def convert_kernel(kernel, dim_ordering=None):\n-    \"\"\"Converts a kernel matrix (Numpy array)\n-    from Theano format to TensorFlow format\n-    (or reciprocally, since the transformation\n-    is its own inverse).\n+    \"\"\"Converts a Numpy kernel matrix from Theano format to TensorFlow format.\n+\n+    Also works reciprocally, since the transformation is its own inverse.\n+\n+    # Arguments\n+        kerne: Numpy array (4D or 5D).\n+        dim_ordering: the data format.\n+\n+    # Returns\n+        The converted kernel.\n+\n+    # Raises\n+        ValueError: in case of invalid kernel shape or invalid dim_ordering.\n     \"\"\"\n     if dim_ordering is None:\n         dim_ordering = K.image_dim_ordering()\n@@ -88,6 +99,18 @@ def convert_kernel(kernel, dim_ordering=None):\n \n def conv_output_length(input_length, filter_size,\n                        border_mode, stride, dilation=1):\n+    \"\"\"Determines output length of a convolution given input length.\n+\n+    # Arguments\n+        input_length: integer.\n+        filter_size: integer.\n+        border_mode: one of \"same\", \"valid\", \"full\".\n+        stride: integer.\n+        dilation: dilation rate, integer.\n+\n+    # Returns\n+        The output length (integer).\n+    \"\"\"\n     if input_length is None:\n         return None\n     assert border_mode in {'same', 'valid', 'full'}\n@@ -102,6 +125,17 @@ def conv_output_length(input_length, filter_size,\n \n \n def conv_input_length(output_length, filter_size, border_mode, stride):\n+    \"\"\"Determines input length of a convolution given output length.\n+\n+    # Arguments\n+        output_length: integer.\n+        filter_size: integer.\n+        border_mode: one of \"same\", \"valid\", \"full\".\n+        stride: integer.\n+\n+    # Returns\n+        The input length (integer).\n+    \"\"\"\n     if output_length is None:\n         return None\n     assert border_mode in {'same', 'valid', 'full'}\n\n@@ -1,3 +1,4 @@\n+\"\"\"Utilities related to Keras unit tests.\"\"\"\n import numpy as np\n from numpy.testing import assert_allclose\n import inspect\n@@ -11,7 +12,8 @@ from .. import backend as K\n def get_test_data(nb_train=1000, nb_test=500, input_shape=(10,),\n                   output_shape=(2,),\n                   classification=True, nb_class=2):\n-    \"\"\"\n+    \"\"\"Generates test data to train a model on.\n+\n     classification=True overrides output_shape\n     (i.e. output_shape is set to (1,)) and the output\n     consists in integers in [0, nb_class-1].\n@@ -121,12 +123,18 @@ def layer_test(layer_cls, kwargs={}, input_shape=None, input_dtype=None,\n \n \n def keras_test(func):\n-    \"\"\"Clean up after tensorflow tests.\n+    \"\"\"Function wrapper to clean up after TensorFlow tests.\n+\n+    # Arguments\n+        func: test function to clean up after.\n+\n+    # Returns\n+        A function wrapping the input function.\n     \"\"\"\n     @six.wraps(func)\n     def wrapper(*args, **kwargs):\n         output = func(*args, **kwargs)\n-        if K._BACKEND == 'tensorflow':\n+        if K.backend() == 'tensorflow':\n             K.clear_session()\n         return output\n     return wrapper\n\n@@ -1,20 +1,31 @@\n+\"\"\"Utilities related to model visualization.\"\"\"\n import os\n \n from ..layers.wrappers import Wrapper\n from ..models import Sequential\n \n try:\n-    # pydot-ng is a fork of pydot that is better maintained\n+    # pydot-ng is a fork of pydot that is better maintained.\n     import pydot_ng as pydot\n except ImportError:\n-    # fall back on pydot if necessary\n+    # Fall back on pydot if necessary.\n     import pydot\n if not pydot.find_graphviz():\n-    raise RuntimeError('Failed to import pydot. You must install pydot'\n+    raise ImportError('Failed to import pydot. You must install pydot'\n                       ' and graphviz for `pydotprint` to work.')\n \n \n def model_to_dot(model, show_shapes=False, show_layer_names=True):\n+    \"\"\"Converts a Keras model to dot format.\n+\n+    # Arguments\n+        model: A Keras model instance.\n+        show_shapes: whether to display shape information.\n+        show_layer_names: whether to display layer names.\n+\n+    # Returns\n+        A `pydot.Dot` instance representing the Keras model.\n+    \"\"\"\n     dot = pydot.Dot()\n     dot.set('rankdir', 'TB')\n     dot.set('concentrate', True)\n@@ -48,7 +59,7 @@ def model_to_dot(model, show_shapes=False, show_layer_names=True):\n         if show_shapes:\n             try:\n                 outputlabels = str(layer.output_shape)\n-            except:\n+            except AttributeError:\n                 outputlabels = 'multiple'\n             if hasattr(layer, 'input_shape'):\n                 inputlabels = str(layer.input_shape)\n@@ -77,9 +88,9 @@ def model_to_dot(model, show_shapes=False, show_layer_names=True):\n \n def plot(model, to_file='model.png', show_shapes=False, show_layer_names=True):\n     dot = model_to_dot(model, show_shapes, show_layer_names)\n-    _, format = os.path.splitext(to_file)\n-    if not format:\n-        format = 'png'\n+    _, extension = os.path.splitext(to_file)\n+    if not extension:\n+        extension = 'png'\n     else:\n-        format = format[1:]\n-    dot.write(to_file, format=format)\n+        extension = extension[1:]\n+    dot.write(to_file, format=extension)\n\n@@ -84,14 +84,9 @@ class BaseWrapper(object):\n             if params_name not in legal_params:\n                 raise ValueError('{} is not a legal parameter'.format(params_name))\n \n-    def get_params(self, deep=True):\n+    def get_params(self, _):\n         \"\"\"Gets parameters for this estimator.\n \n-        # Arguments\n-            deep: boolean, optional\n-                If True, will return the parameters for this estimator and\n-                contained sub-objects that are estimators.\n-\n         # Returns\n             params : dict\n                 Dictionary of parameter names mapped to their values.\n@@ -122,7 +117,7 @@ class BaseWrapper(object):\n                 and n_features is the number of features.\n             y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n                 True labels for X.\n-            kwargs: dictionary arguments\n+            **kwargs: dictionary arguments\n                 Legal arguments are the arguments of `Sequential.fit`\n \n         # Returns\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
