{"custom_id": "keras#ce2f736bac8e58fc3df27290a589fb8f762e6939", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1151 | Contributors (this commit): 5 | Commits (past 90d): 5 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -255,7 +255,9 @@ class PiecewiseConstantDecay(LearningRateSchedule):\n \n     if len(boundaries) != len(values) - 1:\n       raise ValueError(\n-          \"The length of boundaries should be 1 less than the length of values\")\n+          \"The length of boundaries should be 1 less than the length of \"\n+          f\"values. Received: boundaries={boundaries} of length \"\n+          f\"{len(boundaries)}, and values={values} of length {len(values)}.\")\n \n     self.boundaries = boundaries\n     self.values = values\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e08753b3ebbcca2c76da02edd65cf3258d1accdb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 95 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -20,10 +20,10 @@ but sets are not. This class implements a set on top of a dict so that we get\n deterministic iteration order across runs.\n \"\"\"\n \n-import collections\n+import collections.abc\n \n \n-class OrderPreservingSet(collections.MutableSet):\n+class OrderPreservingSet(collections.abc.MutableSet):\n   \"\"\"A set based on dict so that it preserves key insertion order.\"\"\"\n \n   def __init__(self, iterable=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7bc34b968bde1e4a9543f94b0b453af1b2055b59", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 4399 | Contributors (this commit): 33 | Commits (past 90d): 13 | Contributors (cumulative): 36 | DMM Complexity: None\n\nDIFF:\n@@ -1496,16 +1496,16 @@ class TextVectorizationErrorTest(keras_parameterized.TestCase,\n \n   def test_unknown_standardize_arg_fails(self):\n     with self.assertRaisesRegex(ValueError,\n-                                \"standardize arg.*unsupported_value\"):\n+                                \"`standardize` arg.*unsupported_value\"):\n       _ = text_vectorization.TextVectorization(standardize=\"unsupported_value\")\n \n   def test_unknown_split_arg_fails(self):\n-    with self.assertRaisesRegex(ValueError, \"split arg.*unsupported_value\"):\n+    with self.assertRaisesRegex(ValueError, \"`split` arg.*unsupported_value\"):\n       _ = text_vectorization.TextVectorization(split=\"unsupported_value\")\n \n   def test_unknown_output_mode_arg_fails(self):\n     with self.assertRaisesRegex(ValueError,\n-                                \"output_mode arg.*unsupported_value\"):\n+                                \"`output_mode` arg.*unsupported_value\"):\n       _ = text_vectorization.TextVectorization(output_mode=\"unsupported_value\")\n \n   def test_unknown_ngrams_arg_fails(self):\n\n@@ -80,9 +80,9 @@ def validate_string_arg(input_data,\n     allowed_args = '`None`, ' if allow_none else ''\n     allowed_args += 'a `Callable`, ' if allow_callables else ''\n     allowed_args += 'or one of the following values: %s' % (allowable_strings,)\n-    raise ValueError(('The %s argument of layer %s received an invalid '\n-                      'value %s. Allowed values are: %s.') %\n-                     (arg_name, layer_name, input_data, allowed_args))\n+    raise ValueError(\n+        f'The `{arg_name}` argument of layer {layer_name} received an invalid '\n+        f'value `{input_data}`. Allowed values are: {allowed_args}.')\n \n \n def count_params(weights):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9dac3d633deb7e9b870175460fe38722d9e3a0bf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 4 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 14 | Churn Cumulative: 196 | Contributors (this commit): 5 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: 0.75\n\nDIFF:\n@@ -69,8 +69,9 @@ def filter_empty_gradients(grads_and_vars):\n   filtered = tuple(filtered)\n \n   if not filtered:\n-    raise ValueError(\"No gradients provided for any variable: %s.\" %\n-                     ([v.name for _, v in grads_and_vars],))\n+    variable = ([v.name for _, v in grads_and_vars],)\n+    raise ValueError(f\"No gradients provided for any variable: {variable}. \"\n+                     f\"Provided `grads_and_vars` is {grads_and_vars}.\")\n   if vars_with_empty_grads:\n     logging.warning(\n         (\"Gradients do not exist for variables %s when minimizing the loss. \"\n@@ -91,7 +92,8 @@ def make_gradient_clipnorm_fn(clipnorm):\n                   (tf.distribute.experimental.CentralStorageStrategy,\n                    tf.compat.v1.distribute.experimental.CentralStorageStrategy)):\n       raise ValueError(\n-          \"`clipnorm` is not supported with `CenteralStorageStrategy`\")\n+          \"`clipnorm` is not supported with `CenteralStorageStrategy`. \"\n+          f\"The strategy used is {tf.distribute.get_strategy()}.\")\n \n     clipped_grads_and_vars = [\n         (tf.clip_by_norm(g, clipnorm), v) for g, v in grads_and_vars\n@@ -112,7 +114,8 @@ def make_global_gradient_clipnorm_fn(clipnorm):\n                   (tf.distribute.experimental.CentralStorageStrategy,\n                    tf.compat.v1.distribute.experimental.CentralStorageStrategy)):\n       raise ValueError(\n-          \"`global_clipnorm` is not supported with `CenteralStorageStrategy`\")\n+          \"`global_clipnorm` is not supported with `CenteralStorageStrategy`. \"\n+          f\"The strategy used is {tf.distribute.get_strategy()}.\")\n \n     grads, variables = zip(*grads_and_vars)\n     clipped_grads, _ = tf.clip_by_global_norm(grads, clipnorm)\n@@ -133,7 +136,8 @@ def make_gradient_clipvalue_fn(clipvalue):\n                   (tf.distribute.experimental.CentralStorageStrategy,\n                    tf.compat.v1.distribute.experimental.CentralStorageStrategy)):\n       raise ValueError(\n-          \"`clipvalue` is not supported with `CenteralStorageStrategy`\")\n+          \"`clipvalue` is not supported with `CenteralStorageStrategy`. \"\n+          f\"The strategy used is {tf.distribute.get_strategy()}.\")\n \n     clipped_grads_and_vars = [(tf.clip_by_value(g, -clipvalue,\n                                                       clipvalue), v)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6f8d70723625a9be23b11ec6b25251dcc4e4f5db", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 23 | Churn Cumulative: 802 | Contributors (this commit): 6 | Commits (past 90d): 7 | Contributors (cumulative): 6 | DMM Complexity: 0.2\n\nDIFF:\n@@ -274,7 +274,8 @@ class LossesContainer(Container):\n     if not isinstance(loss, losses_mod.Loss):\n       loss_name = get_custom_object_name(loss)\n       if loss_name is None:\n-        raise ValueError('Loss should be a callable, found: {}'.format(loss))\n+        raise ValueError(\n+            f'Loss should be a callable, received: {loss}')\n       loss = losses_mod.LossFunctionWrapper(loss, name=loss_name)\n     loss._allow_sum_over_batch_size = True  # pylint: disable=protected-access\n     return loss\n@@ -394,8 +395,9 @@ class MetricsContainer(Container):\n         if is_multi_output:\n           m._name = output_name + '_' + m._name\n         if m._name in metric_names:\n-          raise ValueError('Found two metrics with the same name: {}'.format(\n-              m._name))\n+          raise ValueError(\n+              f'Found two metrics with the same name: {m._name}.'\n+              'All the metrics added to the model need to have unique names.')\n         metric_names.add(m._name)\n \n       for wm in weighted_output_metrics:\n@@ -410,8 +412,9 @@ class MetricsContainer(Container):\n           wm._name = 'weighted_' + wm._name\n \n         if wm._name in metric_names:\n-          raise ValueError('Found two metrics with the same name: {}'.format(\n-              wm._name))\n+          raise ValueError(\n+              f'Found two weighted metrics with the same name: {wm._name}.'\n+              'All the metrics added to the model need to have unique names.')\n         metric_names.add(wm._name)\n     # pylint: enable=protected-access\n \n@@ -534,7 +537,7 @@ class MetricsContainer(Container):\n         metric_name = get_custom_object_name(metric)\n         if metric_name is None:\n           raise ValueError(\n-              'Metric should be a callable, found: {}'.format(metric))\n+              f'Metric should be a callable, received: {metric}')\n \n       metric_obj = metrics_mod.MeanMetricWrapper(metric_obj, name=metric_name)\n \n@@ -646,9 +649,11 @@ def map_to_output_names(y_pred, output_names, struct):\n     struct = copy.copy(struct)\n     new_struct = [struct.pop(name, None) for name in output_names]\n     if struct:\n-      raise ValueError('Found unexpected keys that do not correspond '\n-                       'to any Model output: {}. Expected: {}'.format(\n-                           struct.keys(), output_names))\n+      raise ValueError(\n+          'Found unexpected losses or metrics that do not correspond '\n+          f'to any Model output: {struct.keys()}. '\n+          f'Valid mode output names: {output_names}. '\n+          f'Received struct is: {struct}.')\n     if len(new_struct) == 1:\n       return new_struct[0]\n     return new_struct\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0718c967e801309bc33b8174f6657063a0114d9f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 15 | Files Changed: 1 | Hunks: 9 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 34 | Churn Cumulative: 1394 | Contributors (this commit): 15 | Commits (past 90d): 2 | Contributors (cumulative): 15 | DMM Complexity: 0.75\n\nDIFF:\n@@ -101,12 +101,14 @@ PREPROCESS_INPUT_RET_DOC_CAFFE = \"\"\"\n def preprocess_input(x, data_format=None, mode='caffe'):\n   \"\"\"Preprocesses a tensor or Numpy array encoding a batch of images.\"\"\"\n   if mode not in {'caffe', 'tf', 'torch'}:\n-    raise ValueError('Unknown mode ' + str(mode))\n+    raise ValueError('Expected mode to be one of `caffe`, `tf` or `torch`. '\n+                     f'Received: mode={mode}')\n \n   if data_format is None:\n     data_format = backend.image_data_format()\n   elif data_format not in {'channels_first', 'channels_last'}:\n-    raise ValueError('Unknown data_format ' + str(data_format))\n+    raise ValueError('Expected data_format to be one of `channels_first` or '\n+                     f'`channels_last`. Received: data_format={data_format}')\n \n   if isinstance(x, np.ndarray):\n     return _preprocess_numpy_input(\n@@ -342,7 +344,8 @@ def obtain_input_shape(input_shape,\n       if input_shape != default_shape:\n         raise ValueError('When setting `include_top=True` '\n                          'and loading `imagenet` weights, '\n-                         '`input_shape` should be ' + str(default_shape) + '.')\n+                         f'`input_shape` should be {default_shape}.  '\n+                         f'Received: input_shape={input_shape}')\n     return default_shape\n   if input_shape:\n     if data_format == 'channels_first':\n@@ -350,25 +353,25 @@ def obtain_input_shape(input_shape,\n         if len(input_shape) != 3:\n           raise ValueError('`input_shape` must be a tuple of three integers.')\n         if input_shape[0] != 3 and weights == 'imagenet':\n-          raise ValueError('The input must have 3 channels; got '\n-                           '`input_shape=' + str(input_shape) + '`')\n+          raise ValueError('The input must have 3 channels; Received '\n+                           f'`input_shape={input_shape}`')\n         if ((input_shape[1] is not None and input_shape[1] < min_size) or\n             (input_shape[2] is not None and input_shape[2] < min_size)):\n-          raise ValueError('Input size must be at least ' + str(min_size) +\n-                           'x' + str(min_size) + '; got `input_shape=' +\n-                           str(input_shape) + '`')\n+          raise ValueError(f'Input size must be at least {min_size}'\n+                           f'x{min_size}; Received: '\n+                           f'input_shape={input_shape}')\n     else:\n       if input_shape is not None:\n         if len(input_shape) != 3:\n           raise ValueError('`input_shape` must be a tuple of three integers.')\n         if input_shape[-1] != 3 and weights == 'imagenet':\n-          raise ValueError('The input must have 3 channels; got '\n-                           '`input_shape=' + str(input_shape) + '`')\n+          raise ValueError('The input must have 3 channels; Received '\n+                           f'`input_shape={input_shape}`')\n         if ((input_shape[0] is not None and input_shape[0] < min_size) or\n             (input_shape[1] is not None and input_shape[1] < min_size)):\n-          raise ValueError('Input size must be at least ' + str(min_size) +\n-                           'x' + str(min_size) + '; got `input_shape=' +\n-                           str(input_shape) + '`')\n+          raise ValueError('Input size must be at least '\n+                           f'{min_size}x{min_size}; Received: '\n+                           f'input_shape={input_shape}')\n   else:\n     if require_flatten:\n       input_shape = default_shape\n@@ -381,7 +384,7 @@ def obtain_input_shape(input_shape,\n     if None in input_shape:\n       raise ValueError('If `include_top` is True, '\n                        'you should specify a static `input_shape`. '\n-                       'Got `input_shape=' + str(input_shape) + '`')\n+                       f'Received: input_shape={input_shape}')\n   return input_shape\n \n \n@@ -429,4 +432,5 @@ def validate_activation(classifier_activation, weights):\n   }:\n     raise ValueError('Only `None` and `softmax` activations are allowed '\n                      'for the `classifier_activation` argument when using '\n-                     'pretrained weights, with `include_top=True`')\n+                     'pretrained weights, with `include_top=True`; Received: '\n+                     f'classifier_activation={classifier_activation}')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d9680f61c81d70de0687e38dd52a0338c2a75931", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 6 | Churn Cumulative: 20467 | Contributors (this commit): 78 | Commits (past 90d): 17 | Contributors (cumulative): 82 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3400,7 +3400,7 @@ class Cropping1D(Layer):\n     return tf.TensorShape([input_shape[0], length, input_shape[2]])\n \n   def call(self, inputs):\n-    if sum(self.cropping) >= inputs.shape[1]:\n+    if tf.not_equal(tf.size(inputs), 0) and sum(self.cropping) >= inputs.shape[1]:\n       raise ValueError(\n         'cropping parameter of Cropping layer is too high,' +\n         'the result of crop' + str(inputs.shape) + ' with cropping ' +\n\n@@ -23,6 +23,7 @@ import keras\n from tensorflow.python.framework import test_util\n from keras import keras_parameterized\n from keras import testing_utils\n+from tensorflow.python.types.core import Value\n \n \n @keras_parameterized.run_all_keras_modes\n@@ -1012,6 +1013,9 @@ class CroppingTest(keras_parameterized.TestCase):\n       keras.layers.Cropping1D(cropping=(1, 1, 1))\n     with self.assertRaises(ValueError):\n       keras.layers.Cropping1D(cropping=None)\n+    with self.assertRaises(ValueError):\n+      input_layer = keras.layers.Input(shape=(num_samples, time_length, input_len_dim1))\n+      crop = keras.layers.Cropping1D(cropping=(2,3))(input_layer)\n \n   def test_cropping_2d(self):\n     num_samples = 2\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f54ee7bdc9d67e7060ee1c36b3a3387e387bf3c3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 15 | Files Changed: 1 | Hunks: 9 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 32 | Churn Cumulative: 413 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: 0.5\n\nDIFF:\n@@ -15,8 +15,6 @@\n # LINT.IfChange\n \"\"\"Utilities for creating SavedModels.\"\"\"\n \n-import tensorflow.compat.v2 as tf\n-\n import collections\n import os\n import time\n@@ -25,6 +23,8 @@ from keras.saving.utils_v1 import export_output as export_output_lib\n from keras.saving.utils_v1 import mode_keys\n from keras.saving.utils_v1 import unexported_constants\n from keras.saving.utils_v1.mode_keys import KerasModeKeys as ModeKeys\n+import tensorflow.compat.v2 as tf\n+\n from tensorflow.python.platform import tf_logging as logging\n \n \n@@ -86,8 +86,9 @@ def build_all_signature_defs(receiver_tensors,\n   if not isinstance(receiver_tensors, dict):\n     receiver_tensors = {SINGLE_RECEIVER_DEFAULT_NAME: receiver_tensors}\n   if export_outputs is None or not isinstance(export_outputs, dict):\n-    raise ValueError('export_outputs must be a dict and not'\n-                     '{}'.format(type(export_outputs)))\n+    raise ValueError('`export_outputs` must be a dict. Received '\n+                     f'{export_outputs} with type '\n+                     f'{type(export_outputs).__name__}.')\n \n   signature_def_map = {}\n   excluded_signatures = {}\n@@ -219,7 +220,7 @@ def get_timestamped_export_dir(export_dir_base):\n             tf.compat.as_str(result_dir), attempts,\n             MAX_DIRECTORY_CREATION_ATTEMPTS))\n   raise RuntimeError('Failed to obtain a unique export directory name after '\n-                     '{} attempts.'.format(MAX_DIRECTORY_CREATION_ATTEMPTS))\n+                     f'{MAX_DIRECTORY_CREATION_ATTEMPTS} attempts.')\n \n \n def get_temp_export_dir(timestamped_export_dir):\n@@ -275,10 +276,10 @@ def export_outputs_for_mode(\n   \"\"\"\n   if mode not in SIGNATURE_KEY_MAP:\n     raise ValueError(\n-        'Export output type not found for mode: {}. Expected one of: {}.\\n'\n+        f'Export output type not found for `mode`: {mode}. Expected one of: '\n+        f'{list(SIGNATURE_KEY_MAP.keys())}.\\n'\n         'One likely error is that V1 Estimator Modekeys were somehow passed to '\n-        'this function. Please ensure that you are using the new ModeKeys.'\n-        .format(mode, SIGNATURE_KEY_MAP.keys()))\n+        'this function. Please ensure that you are using the new ModeKeys.')\n   signature_key = SIGNATURE_KEY_MAP[mode]\n   if mode_keys.is_predict(mode):\n     return get_export_outputs(serving_export_outputs, predictions)\n@@ -311,13 +312,13 @@ def get_export_outputs(export_outputs, predictions):\n         tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY: default_output}\n \n   if not isinstance(export_outputs, dict):\n-    raise TypeError('export_outputs must be dict, given: {}'.format(\n-        export_outputs))\n+    raise TypeError(\n+        f'`export_outputs` must be dict, received: {export_outputs}.')\n   for v in export_outputs.values():\n     if not isinstance(v, export_output_lib.ExportOutput):\n       raise TypeError(\n-          'Values in export_outputs must be ExportOutput objects. '\n-          'Given: {}'.format(export_outputs))\n+          'Values in `export_outputs` must be ExportOutput objects, '\n+          f'received: {export_outputs}.')\n \n   _maybe_add_default_serving_output(export_outputs)\n \n@@ -347,9 +348,10 @@ def _maybe_add_default_serving_output(export_outputs):\n     if (tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n         not in export_outputs):\n       raise ValueError(\n-          'Multiple export_outputs were provided, but none of them is '\n-          'specified as the default.  Do this by naming one of them with '\n-          'signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY.')\n+          'Multiple `export_outputs` were provided, but none of them are '\n+          'specified as the default. Use'\n+          '`tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY` to '\n+          'specify a default.')\n \n   return export_outputs\n # LINT.ThenChange(//tensorflow/python/saved_model/model_utils/export_utils.py)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#02ec19c88ba756b470c80fae7db74160fca25de5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 89 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -58,7 +58,7 @@ def _supervised_signature_def(\n     ValueError: If inputs or outputs is `None`.\n   \"\"\"\n   if inputs is None or not inputs:\n-    raise ValueError('{} inputs cannot be None or empty.'.format(method_name))\n+    raise ValueError('f{method_name} `inputs` cannot be None or empty.')\n \n   signature_inputs = {key: tf.compat.v1.saved_model.build_tensor_info(tensor)\n                       for key, tensor in inputs.items()}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bdd766a93ca5131c88057cbe3189cbcc3c6bec92", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 18 | Files Changed: 1 | Hunks: 9 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 46 | Churn Cumulative: 701 | Contributors (this commit): 5 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: 0.0\n\nDIFF:\n@@ -187,16 +187,18 @@ def MobileNetV2(input_shape=None,\n   else:\n     layers = VersionAwareLayers()\n   if kwargs:\n-    raise ValueError('Unknown argument(s): %s' % (kwargs,))\n+    raise ValueError(f'Unknown argument(s): {kwargs}')\n   if not (weights in {'imagenet', None} or tf.io.gfile.exists(weights)):\n     raise ValueError('The `weights` argument should be either '\n                      '`None` (random initialization), `imagenet` '\n                      '(pre-training on ImageNet), '\n-                     'or the path to the weights file to be loaded.')\n+                     'or the path to the weights file to be loaded.  '\n+                     f'Received `weights={weights}`')\n \n   if weights == 'imagenet' and include_top and classes != 1000:\n-    raise ValueError('If using `weights` as `\"imagenet\"` with `include_top` '\n-                     'as true, `classes` should be 1000')\n+    raise ValueError(\n+        'If using `weights` as `\"imagenet\"` with `include_top` '\n+        f'as true, `classes` should be 1000. Received `classes={classes}`')\n \n   # Determine proper input shape and default size.\n   # If both input_shape and input_tensor are used, they should match\n@@ -208,22 +210,29 @@ def MobileNetV2(input_shape=None,\n         is_input_t_tensor = backend.is_keras_tensor(\n             layer_utils.get_source_inputs(input_tensor))\n       except ValueError:\n-        raise ValueError('input_tensor: ', input_tensor,\n-                         'is not type input_tensor')\n+        raise ValueError(\n+            f'input_tensor: {input_tensor}'\n+            'is not type input_tensor. '\n+            f'Received `type(input_tensor)={type(input_tensor)}`'\n+        )\n     if is_input_t_tensor:\n       if backend.image_data_format() == 'channels_first':\n         if backend.int_shape(input_tensor)[1] != input_shape[1]:\n-          raise ValueError('input_shape: ', input_shape, 'and input_tensor: ',\n-                           input_tensor,\n-                           'do not meet the same shape requirements')\n+          raise ValueError('input_shape[1] must equal shape(input_tensor)[1] '\n+                           'when `image_data_format` is `channels_first`; '\n+                           'Received `input_tensor.shape='\n+                           f'{input_tensor.shape}`'\n+                           f', `input_shape={input_shape}`')\n       else:\n         if backend.int_shape(input_tensor)[2] != input_shape[1]:\n-          raise ValueError('input_shape: ', input_shape, 'and input_tensor: ',\n-                           input_tensor,\n-                           'do not meet the same shape requirements')\n+          raise ValueError(\n+              'input_tensor.shape[2] must equal input_shape[1]; '\n+              'Received `input_tensor.shape='\n+              f'{input_tensor.shape}`, '\n+              f'`input_shape={input_shape}`')\n     else:\n-      raise ValueError('input_tensor specified: ', input_tensor,\n-                       'is not a keras tensor')\n+      raise ValueError('input_tensor is not a Keras tensor; '\n+                       f'Received `input_tensor={input_tensor}`')\n \n   # If input_shape is None, infer shape from input_tensor.\n   if input_shape is None and input_tensor is not None:\n@@ -231,8 +240,8 @@ def MobileNetV2(input_shape=None,\n     try:\n       backend.is_keras_tensor(input_tensor)\n     except ValueError:\n-      raise ValueError('input_tensor: ', input_tensor, 'is type: ',\n-                       type(input_tensor), 'which is not a valid type')\n+      raise ValueError('input_tensor must be a valid Keras tensor type; '\n+                       f'Received {input_tensor} of type {type(input_tensor)}')\n \n     if input_shape is None and not backend.is_keras_tensor(input_tensor):\n       default_size = 224\n@@ -285,8 +294,9 @@ def MobileNetV2(input_shape=None,\n   if weights == 'imagenet':\n     if alpha not in [0.35, 0.50, 0.75, 1.0, 1.3, 1.4]:\n       raise ValueError('If imagenet weights are being loaded, '\n-                       'alpha can be one of `0.35`, `0.50`, `0.75`, '\n-                       '`1.0`, `1.3` or `1.4` only.')\n+                       'alpha must be one of `0.35`, `0.50`, `0.75`, '\n+                       '`1.0`, `1.3` or `1.4` only;'\n+                       f' Received `alpha={alpha}`')\n \n     if rows != cols or rows not in [96, 128, 160, 192, 224]:\n       rows = 224\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#04c3de0a4e47a6be3b1a2a21dd0485daf0573ede", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 21 | Files Changed: 7 | Hunks: 13 | Methods Changed: 9 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 57 | Churn Cumulative: 5277 | Contributors (this commit): 7 | Commits (past 90d): 52 | Contributors (cumulative): 35 | DMM Complexity: 0.4666666666666667\n\nDIFF:\n@@ -121,8 +121,9 @@ class CategoryCrossing(base_layer.Layer):\n     if ragged_out:\n       # TODO(momernick): Support separator with ragged_cross.\n       if self.separator != '_X_':\n-        raise ValueError('Non-default separator with ragged input is not '\n-                         'supported yet, given {}'.format(self.separator))\n+        raise ValueError(\n+            f'Non-default separator with ragged input is not implemented. '\n+            f'Received separator: {self.separator}.')\n       return tf.ragged.cross(partial_inputs)\n     elif sparse_out:\n       return tf.sparse.cross(partial_inputs, separator=self.separator)\n@@ -150,8 +151,8 @@ class CategoryCrossing(base_layer.Layer):\n     for depth in depth_tuple:\n       if len(inputs) < depth:\n         raise ValueError(\n-            'Number of inputs cannot be less than depth, got {} input tensors, '\n-            'and depth {}'.format(len(inputs), depth))\n+            f'Number of inputs cannot be less than depth. Received '\n+            f'{len(inputs)} input tensors, and depth {depth}.')\n       for partial_inps in itertools.combinations(inputs, depth):\n         partial_out = self.partial_crossing(\n             partial_inps, ragged_out, sparse_out)\n@@ -162,14 +163,16 @@ class CategoryCrossing(base_layer.Layer):\n \n   def compute_output_shape(self, input_shape):\n     if not isinstance(input_shape, (tuple, list)):\n-      raise ValueError('A `CategoryCrossing` layer should be called '\n-                       'on a list of inputs.')\n+      raise ValueError(\n+          f'A `CategoryCrossing` layer should be called on a list of inputs. '\n+          f'Received: input_shape={input_shape}.')\n     input_shapes = input_shape\n     batch_size = None\n     for inp_shape in input_shapes:\n       inp_tensor_shape = tf.TensorShape(inp_shape).as_list()\n       if len(inp_tensor_shape) != 2:\n-        raise ValueError('Inputs must be rank 2, get {}'.format(input_shapes))\n+        raise ValueError(\n+            f'Inputs must be rank 2. Received: input_shape={input_shape}.')\n       if batch_size is None:\n         batch_size = inp_tensor_shape[0]\n     # The second dimension is dynamic based on inputs.\n\n@@ -141,7 +141,8 @@ class CategoryEncoding(base_layer.Layer):\n                        \"number of tokens is not known beforehand, use the \"\n                        \"IntegerLookup layer instead.\")\n     if num_tokens < 1:\n-      raise ValueError(\"num_tokens must be >= 1.\")\n+      raise ValueError(\n+          f\"`num_tokens` must be >= 1. Received: num_tokens={num_tokens}.\")\n \n     self.num_tokens = num_tokens\n     self.output_mode = output_mode\n\n@@ -124,7 +124,9 @@ class Hashing(base_layer.Layer):\n \n   def __init__(self, num_bins, mask_value=None, salt=None, **kwargs):\n     if num_bins is None or num_bins <= 0:\n-      raise ValueError('`num_bins` cannot be `None` or non-positive values.')\n+      raise ValueError(\n+          f'The `num_bins` for `Hashing` cannot be `None` or non-positive '\n+          f'values. Received: num_bins={num_bins}.')\n     super().__init__(**kwargs)\n     base_preprocessing_layer.keras_kpl_gauge.get_cell('Hashing').set(True)\n     self.num_bins = num_bins\n@@ -137,8 +139,9 @@ class Hashing(base_layer.Layer):\n       elif isinstance(salt, int):\n         self.salt = [salt, salt]\n       else:\n-        raise ValueError('`salt can only be a tuple of size 2 integers, or a '\n-                         'single integer, given {}'.format(salt))\n+        raise ValueError(\n+            f'The `salt` argument for `Hashing` can only be a tuple of size 2 '\n+            f'integers, or a single integer. Received: salt={salt}.')\n \n   def call(self, inputs):\n     if isinstance(inputs, (list, tuple, np.ndarray)):\n\n@@ -336,13 +336,15 @@ class IntegerLookup(index_lookup.IndexLookup):\n     # If max_tokens is set, the token must be greater than 1 - otherwise we\n     # are creating a 0-element vocab, which doesn't make sense.\n     if max_tokens is not None and max_tokens <= 1:\n-      raise ValueError(\"If set, max_tokens must be greater than 1. \"\n-                       \"You passed %s\" % (max_tokens,))\n+      raise ValueError(\n+          f\"If `max_tokens` is set for `IntegerLookup`, it must be \"\n+          f\"greater than 1. Received: max_tokens={max_tokens}.\")\n \n     if num_oov_indices < 0:\n       raise ValueError(\n-          \"num_oov_indices must be greater than or equal to 0. You passed %s\" %\n-          (num_oov_indices,))\n+          f\"The value of `num_oov_indices` argument for `IntegerLookup` \"\n+          f\"must >= 0. Received num_oov_indices=\"\n+          f\"{num_oov_indices}.\")\n \n     # Make sure mask and oov are of the dtype we want.\n     mask_token = None if mask_token is None else np.int64(mask_token)\n\n@@ -57,7 +57,9 @@ class PreprocessingLayerTest(tf.test.TestCase):\n   def validate_accumulator_computation(self, combiner, data, expected):\n     \"\"\"Validate that various combinations of compute and merge are identical.\"\"\"\n     if len(data) < 4:\n-      raise AssertionError(\"Data must have at least 4 elements.\")\n+      raise AssertionError(\n+          f\"Data must have at least 4 elements. Received \"\n+          f\"len(data)={len(data)}.\")\n     data_0 = np.array([data[0]])\n     data_1 = np.array([data[1]])\n     data_2 = np.array(data[2:])\n\n@@ -303,8 +303,9 @@ class StringLookup(index_lookup.IndexLookup):\n     allowed_dtypes = [tf.string]\n \n     if \"dtype\" in kwargs and kwargs[\"dtype\"] not in allowed_dtypes:\n-      raise ValueError(\"The value of the dtype argument for StringLookup may \"\n-                       \"only be one of %s.\" % (allowed_dtypes,))\n+      raise ValueError(\n+          f\"The value of the `dtype` for `StringLookup` may \"\n+          f\"only be one of {allowed_dtypes}, but received {kwargs['dtype']}.\")\n \n     if \"dtype\" not in kwargs:\n       kwargs[\"dtype\"] = tf.string\n\n@@ -238,7 +238,9 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n     # This layer only applies to string processing, and so should only have\n     # a dtype of 'string'.\n     if \"dtype\" in kwargs and kwargs[\"dtype\"] != tf.string:\n-      raise ValueError(\"TextVectorization may only have a dtype of string.\")\n+      raise ValueError(\n+          f\"`TextVectorization` may only have a dtype of string. \"\n+          f\"Received dtype: {kwargs['dtype']}.\")\n     elif \"dtype\" not in kwargs:\n       kwargs[\"dtype\"] = tf.string\n \n@@ -290,8 +292,9 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n                        \"Got %s\" % output_sequence_length)\n \n     if output_mode != INT and output_sequence_length is not None:\n-      raise ValueError(\"`output_sequence_length` must not be set if \"\n-                       \"`output_mode` is not 'int'.\")\n+      raise ValueError(\n+          f\"`output_sequence_length` must not be set if `output_mode` is not \"\n+          f\"'int'. Received output_sequence_length={output_sequence_length}.\")\n \n     self._max_tokens = max_tokens\n     self._standardize = standardize\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d8f79581504e793660a053acb2e3246efe24d3ee", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 20 | Files Changed: 8 | Hunks: 13 | Methods Changed: 9 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 56 | Churn Cumulative: 4571 | Contributors (this commit): 10 | Commits (past 90d): 30 | Contributors (cumulative): 28 | DMM Complexity: 0.25\n\nDIFF:\n@@ -351,5 +351,8 @@ class Lambda(Layer):\n     elif function_type == 'raw':\n       function = config[func_attr_name]\n     else:\n-      raise TypeError('Unknown function type:', function_type)\n+      supported_types = ['function', 'lambda', 'raw']\n+      raise TypeError(\n+          f'Unsupported value for `function_type` argument. Received: '\n+          f'function_type={function_type}. Expected one of {supported_types}')\n     return function\n\n@@ -95,7 +95,9 @@ class Reshape(Layer):\n         if unknown is None:\n           unknown = index\n         else:\n-          raise ValueError('Can only specify one unknown dimension.')\n+          raise ValueError(\n+              f'There must be at most one unknown dimension in output_shape. '\n+              f'Received: output_shape={output_shape}.')\n       else:\n         known *= dim\n \n\n@@ -98,8 +98,9 @@ class SpatialDropout2D(Dropout):\n     if data_format is None:\n       data_format = K.image_data_format()\n     if data_format not in {'channels_last', 'channels_first'}:\n-      raise ValueError('data_format must be in '\n-                       '{\"channels_last\", \"channels_first\"}')\n+      raise ValueError(\n+          f'`data_format` must be \"channels_last\" or \"channels_first\". '\n+          f'Received: data_format={data_format}.')\n     self.data_format = data_format\n     self.input_spec = InputSpec(ndim=4)\n \n@@ -149,8 +150,9 @@ class SpatialDropout3D(Dropout):\n     if data_format is None:\n       data_format = K.image_data_format()\n     if data_format not in {'channels_last', 'channels_first'}:\n-      raise ValueError('data_format must be in '\n-                       '{\"channels_last\", \"channels_first\"}')\n+      raise ValueError(\n+          f'`data_format` must be \"channels_last\" or \"channels_first\". '\n+          f'Received: data_format={data_format}.')\n     self.data_format = data_format\n     self.input_spec = InputSpec(ndim=5)\n \n\n@@ -213,8 +213,9 @@ class BatchNormalizationBase(Layer):\n       renorm_clipping = renorm_clipping or {}\n       keys = ['rmax', 'rmin', 'dmax']\n       if set(renorm_clipping) - set(keys):\n-        raise ValueError('renorm_clipping %s contains keys not in %s' %\n-                         (renorm_clipping, keys))\n+        raise ValueError(\n+            f'Received invalid keys for `renorm_clipping` argument: '\n+            f'{renorm_clipping}. Supported values: {keys}.')\n       self.renorm_clipping = renorm_clipping\n       self.renorm_momentum = renorm_momentum\n \n@@ -293,7 +294,8 @@ class BatchNormalizationBase(Layer):\n   def build(self, input_shape):\n     input_shape = tf.TensorShape(input_shape)\n     if not input_shape.ndims:\n-      raise ValueError('Input has undefined rank.')\n+      raise ValueError(\n+          f'Input has undefined rank. Received: input_shape={input_shape}.')\n     ndims = len(input_shape)\n \n     # Convert axis to list and resolve negatives\n@@ -307,14 +309,18 @@ class BatchNormalizationBase(Layer):\n     # Validate axes\n     for x in self.axis:\n       if x < 0 or x >= ndims:\n-        raise ValueError('Invalid axis: %s' % (self.axis,))\n+        raise ValueError(\n+            f'Invalid axis. Expected 0 <= axis < inputs.rank (with '\n+            f'inputs.rank={ndims}). Received: layer.axis={self.axis}')\n     if len(self.axis) != len(set(self.axis)):\n       raise ValueError('Duplicate axis: %s' % (self.axis,))\n \n     if self.virtual_batch_size is not None:\n       if self.virtual_batch_size <= 0:\n-        raise ValueError('virtual_batch_size must be a positive integer that '\n-                         'divides the true batch size of the input tensor')\n+        raise ValueError(\n+            f'virtual_batch_size must be a positive integer that divides the '\n+            f'true batch size of the input tensor. Received: '\n+            f'virtual_batch_size={self.virtual_batch_size}')\n       # If using virtual batches, the first dimension must be the batch\n       # dimension and cannot be the batch norm axis\n       if 0 in self.axis:\n\n@@ -223,7 +223,9 @@ class LayerNormalization(Layer):\n     # Validate axes\n     for x in self.axis:\n       if x < 0 or x >= ndims:\n-        raise ValueError('Invalid axis: %d' % x)\n+        raise ValueError(\n+            f'Invalid axis. Expected 0 <= axis < inputs.rank (with '\n+            f'inputs.rank={ndims}). Received: layer.axis={self.axis}')\n     if len(self.axis) != len(set(self.axis)):\n       raise ValueError('Duplicate axis: {}'.format(tuple(self.axis)))\n \n\n@@ -156,7 +156,9 @@ class LayerNormalizationTest(keras_parameterized.TestCase):\n \n   @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n   def testInvalidAxis(self):\n-    with self.assertRaisesRegex(ValueError, r'Invalid axis: 3'):\n+    with self.assertRaisesRegex(\n+        ValueError,\n+        r'Invalid axis. Expected 0 <= axis < inputs.rank'):\n       layer_norm = layer_normalization.LayerNormalization(axis=3)\n       layer_norm.build(input_shape=(2, 2, 2))\n \n\n@@ -184,7 +184,7 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n     base_preprocessing_layer.keras_kpl_gauge.get_cell(\"Discretization\").set(\n         True)\n     if num_bins is not None and num_bins < 0:\n-      raise ValueError(\"`num_bins` must be must be greater than or equal to 0. \"\n+      raise ValueError(\"`num_bins` must be greater than or equal to 0. \"\n                        \"You passed `num_bins={}`\".format(num_bins))\n     if num_bins is not None and bin_boundaries is not None:\n       raise ValueError(\"Both `num_bins` and `bin_boundaries` should not be \"\n\n@@ -48,12 +48,11 @@ class PreprocessingStage(sequential.Sequential,\n       reset_state: Whether this call to `adapt` should reset the state of\n         the layers in this preprocessing stage.\n     \"\"\"\n-    if not isinstance(data,\n-                      (tf.data.Dataset, np.ndarray, tf.__internal__.EagerTensor)):\n+    if not isinstance(\n+        data, (tf.data.Dataset, np.ndarray, tf.__internal__.EagerTensor)):\n       raise ValueError(\n-          '`adapt()` requires a batched Dataset, an EagerTensor, '\n-          'or a Numpy array as input, '\n-          'got {}'.format(type(data)))\n+          f'`adapt()` requires a batched Dataset, an EagerTensor, or a Numpy '\n+          f'array as input. Received data={data}')\n     if isinstance(data, tf.data.Dataset):\n       # Validate the datasets to try and ensure we haven't been passed one with\n       # infinite size. That would cause an infinite loop here.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e6ba8373f8918f05e2454c8a2bd13221900cad70", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 15 | Files Changed: 1 | Hunks: 13 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 27 | Churn Cumulative: 2000 | Contributors (this commit): 8 | Commits (past 90d): 15 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1144,11 +1144,9 @@ class DataHandler:\n     # `steps_per_execution` is mutable and may be changed by the DataAdapter\n     # to handle partial executions.\n     if steps_per_execution is None:\n-      self._steps_per_execution = 1\n-      self._steps_per_execution_value = 1\n+      self._steps_per_execution = tf.Variable(1)\n     else:\n       self._steps_per_execution = steps_per_execution\n-      self._steps_per_execution_value = steps_per_execution.numpy().item()\n \n     adapter_cls = select_data_adapter(x, y)\n     self._adapter = adapter_cls(\n@@ -1168,7 +1166,7 @@ class DataHandler:\n     strategy = tf.distribute.get_strategy()\n \n     self._current_step = 0\n-    self._step_increment = self._steps_per_execution_value - 1\n+    self._step_increment = self._steps_per_execution.numpy().item() - 1\n     self._insufficient_data = False\n \n     self._configure_dataset_and_inferred_steps(strategy, x, steps_per_epoch,\n@@ -1207,17 +1205,15 @@ class DataHandler:\n     \"\"\"Truncates steps per execution to at most one epoch.\"\"\"\n     should_truncate = (\n         self._inferred_steps is not None and\n-        self._steps_per_execution_value > self._inferred_steps)\n-    original_value = self._steps_per_execution_value\n+        self._steps_per_execution.numpy().item() > self._inferred_steps)\n+    original_value = self._steps_per_execution.numpy().item()\n     try:\n       if should_truncate:\n         self._steps_per_execution.assign(self._inferred_steps)\n-        self._steps_per_execution_value = self._inferred_steps\n       yield\n     finally:\n       if should_truncate:\n         self._steps_per_execution.assign(original_value)\n-        self._steps_per_execution_value = original_value\n \n   def sync(self):\n     context.async_wait()\n@@ -1250,17 +1246,17 @@ class DataHandler:\n            self._current_step < self._inferred_steps):\n       if self._insufficient_data:  # Set by `catch_stop_iteration`.\n         break\n-\n+      original_spe = self._steps_per_execution.numpy().item()\n       can_run_full_execution = (\n-          self._steps_per_execution_value == 1 or\n+          original_spe == 1 or\n           self._inferred_steps is None or\n           self._inferred_steps - self._current_step >=\n-          self._steps_per_execution_value)\n+          original_spe)\n \n       if can_run_full_execution:\n-        self._step_increment = self._steps_per_execution_value - 1\n+        self._step_increment = original_spe - 1\n         yield self._current_step\n-        self._current_step += self._steps_per_execution_value\n+        self._current_step += original_spe\n       else:\n         # Last partial execution.\n         steps_remaining = self._inferred_steps - self._current_step\n@@ -1268,7 +1264,7 @@ class DataHandler:\n         self._step_increment = steps_remaining - 1\n         yield self._current_step\n         self._current_step += steps_remaining\n-        self._steps_per_execution.assign(self._steps_per_execution_value)\n+        self._steps_per_execution.assign(original_spe)\n \n   @property\n   def step_increment(self):\n@@ -1334,7 +1330,8 @@ class DataHandler:\n \n   def _validate_data_handler(self):\n     # TODO(b/152094471): Support this with DistIter.get_next_as_optional.\n-    if self._steps_per_execution_value > 1 and self._inferred_steps is None:\n+    if self._steps_per_execution.numpy().item(\n+    ) > 1 and self._inferred_steps is None:\n       raise ValueError(\n           \"Could not infer the size of the data. With \"\n           \"`steps_per_execution > 1`, you must specify the number of steps \"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#67d3fb98bfa82c20e816a4d156e677d4f27553bc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 19145 | Contributors (this commit): 78 | Commits (past 90d): 16 | Contributors (cumulative): 78 | DMM Complexity: 0.0\n\nDIFF:\n@@ -3410,11 +3410,9 @@ class Cropping1D(Layer):\n \n   def call(self, inputs):\n     if tf.not_equal(tf.size(inputs), 0) and sum(self.cropping) >= inputs.shape[1]:\n-      raise ValueError(\n-        'cropping parameter of Cropping layer is too high,' +\n-        'the result of crop' + str(inputs.shape) + ' with cropping ' +\n-        str(self.cropping) + ' is an empty tensor'\n-      )\n+      raise ValueError('cropping parameter of Cropping layer must be '\n+                       'greater than the input shape. Recieved: inputs.shape='\n+                       f'{inputs.shape}, and cropping={self.cropping}')\n     if self.cropping[1] == 0:\n       return inputs[:, self.cropping[0]:, :]\n     else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#36e0a33d85e0ab30ca2f7220a437e80e66e87f18", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 19147 | Contributors (this commit): 78 | Commits (past 90d): 17 | Contributors (cumulative): 78 | DMM Complexity: None\n\nDIFF:\n@@ -3409,7 +3409,7 @@ class Cropping1D(Layer):\n     return tf.TensorShape([input_shape[0], length, input_shape[2]])\n \n   def call(self, inputs):\n-    if tf.not_equal(tf.size(inputs), 0) and sum(self.cropping) >= inputs.shape[1]:\n+    if inputs.shape[1] is not None and sum(self.cropping) >= inputs.shape[1]:\n       raise ValueError('cropping parameter of Cropping layer must be '\n                        'greater than the input shape. Recieved: inputs.shape='\n                        f'{inputs.shape}, and cropping={self.cropping}')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
