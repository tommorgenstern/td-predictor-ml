{"custom_id": "keras#4f735c4b0d57e88dd9a6745173063e672bffa04d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 51 | Lines Deleted: 23 | Files Changed: 1 | Hunks: 19 | Methods Changed: 17 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 74 | Churn Cumulative: 8905 | Contributors (this commit): 54 | Commits (past 90d): 23 | Contributors (cumulative): 54 | DMM Complexity: None\n\nDIFF:\n@@ -11,7 +11,7 @@ import numpy as np\n \n from . import backend as K\n from . import optimizers\n-from . import layers\n+from . import layers as layer_module\n from .utils.io_utils import ask_to_proceed_with_overwrite\n from .engine.training import Model\n from .engine import topology\n@@ -174,6 +174,7 @@ def load_model(filepath, custom_objects=None):\n \n     # Raises\n         ImportError: if h5py is not available.\n+        ValueError: In case of an invalid savefile.\n     \"\"\"\n     if h5py is None:\n         raise ImportError('`save_model` requires h5py.')\n@@ -270,7 +271,7 @@ def model_from_config(config, custom_objects=None):\n         raise TypeError('`model_fom_config` expects a dictionary, not a list. '\n                         'Maybe you meant to use '\n                         '`Sequential.from_config(config)`?')\n-    return layers.deserialize(config, custom_objects=custom_objects)\n+    return layer_module.deserialize(config, custom_objects=custom_objects)\n \n \n def model_from_yaml(yaml_string, custom_objects=None):\n@@ -286,7 +287,7 @@ def model_from_yaml(yaml_string, custom_objects=None):\n         A Keras model instance (uncompiled).\n     \"\"\"\n     config = yaml.load(yaml_string)\n-    return layers.deserialize(config, custom_objects=custom_objects)\n+    return layer_module.deserialize(config, custom_objects=custom_objects)\n \n \n def model_from_json(json_string, custom_objects=None):\n@@ -302,7 +303,7 @@ def model_from_json(json_string, custom_objects=None):\n         A Keras model instance (uncompiled).\n     \"\"\"\n     config = json.loads(json_string)\n-    return layers.deserialize(config, custom_objects=custom_objects)\n+    return layer_module.deserialize(config, custom_objects=custom_objects)\n \n \n class Sequential(Model):\n@@ -371,6 +372,14 @@ class Sequential(Model):\n \n         # Arguments\n             layer: layer instance.\n+\n+        # Raises\n+            TypeError: If `layer` is not a layer instance.\n+            ValueError: In case the `layer` argument does not\n+                know its input shape.\n+            ValueError: In case the `layer` argument has\n+                multiple output tensors, or is already connected\n+                somewhere else (forbidden in `Sequential` models).\n         \"\"\"\n         if not isinstance(layer, Layer):\n             raise TypeError('The added layer must be '\n@@ -378,7 +387,7 @@ class Sequential(Model):\n                             'Found: ' + str(layer))\n         if not self.outputs:\n             # first layer in model: check that it is an input layer\n-            if len(layer.inbound_nodes) == 0:\n+            if layer.inbound_nodes:\n                 # create an input layer\n                 if not hasattr(layer, 'batch_input_shape'):\n                     raise ValueError('The first layer in a '\n@@ -461,7 +470,9 @@ class Sequential(Model):\n         self.built = False\n \n     def get_layer(self, name=None, index=None):\n-        \"\"\"Returns a layer based on either its name (unique)\n+        \"\"\"Retrieve a layer that is part of the model.\n+\n+        Returns a layer based on either its name (unique)\n         or its index in the graph. Indices are based on\n         order of horizontal graph traversal (bottom-up).\n \n@@ -708,7 +719,7 @@ class Sequential(Model):\n             sample_weight_mode: if you need to do timestep-wise\n                 sample weighting (2D weights), set this to \"temporal\".\n                 \"None\" defaults to sample-wise weights (1D).\n-            kwargs: for Theano backend, these are passed into K.function.\n+            **kwargs: for Theano backend, these are passed into K.function.\n                 Ignored for Tensorflow backend.\n \n         # Example\n@@ -830,7 +841,9 @@ class Sequential(Model):\n                                    sample_weight=sample_weight)\n \n     def predict(self, x, batch_size=32, verbose=0):\n-        \"\"\"Generates output predictions for the input samples, processing the samples in a batched way.\n+        \"\"\"Generates output predictions for the input samples.\n+\n+        The input samples are processed batch by batch.\n \n         # Arguments\n             x: the input data, as a Numpy array.\n@@ -846,6 +859,13 @@ class Sequential(Model):\n \n     def predict_on_batch(self, x):\n         \"\"\"Returns predictions for a single batch of samples.\n+\n+        # Arguments\n+            x: input data, as a Numpy array or list of Numpy arrays\n+                (if the model has multiple inputs).\n+\n+        # Returns\n+            A Numpy array of predictions.\n         \"\"\"\n         if self.model is None:\n             self.build()\n@@ -905,7 +925,9 @@ class Sequential(Model):\n                                         sample_weight=sample_weight)\n \n     def predict_proba(self, x, batch_size=32, verbose=1):\n-        \"\"\"Generates class probability predictions for the input samples batch by batch.\n+        \"\"\"Generates class probability predictions for the input samples.\n+\n+        The input samples are processed batch by batch.\n \n         # Arguments\n             x: input data, as a Numpy array or list of Numpy arrays\n@@ -925,8 +947,9 @@ class Sequential(Model):\n         return preds\n \n     def predict_classes(self, x, batch_size=32, verbose=1):\n-        \"\"\"Generate class predictions for the input samples\n-        batch by batch.\n+        \"\"\"Generate class predictions for the input samples.\n+\n+        The input samples are processed batch by batch.\n \n         # Arguments\n             x: input data, as a Numpy array or list of Numpy arrays\n@@ -1042,10 +1065,11 @@ class Sequential(Model):\n                 before returning.\n             max_q_size: maximum size for the generator queue\n             workers: maximum number of processes to spin up\n-            pickle_safe: if True, use process based threading. Note that because\n-                this implementation relies on multiprocessing, you should not pass non\n-                non picklable arguments to the generator as they can't be passed\n-                easily to children processes.\n+            pickle_safe: if True, use process based threading.\n+                Note that because this implementation\n+                relies on multiprocessing, you should not pass\n+                non picklable arguments to the generator\n+                as they can't be passed easily to children processes.\n \n         # Raises\n             RuntimeError: if the model was never compiled.\n@@ -1072,10 +1096,11 @@ class Sequential(Model):\n                 before returning.\n             max_q_size: maximum size for the generator queue\n             workers: maximum number of processes to spin up\n-            pickle_safe: if True, use process based threading. Note that because\n-                this implementation relies on multiprocessing, you should not pass non\n-                non picklable arguments to the generator as they can't be passed\n-                easily to children processes.\n+            pickle_safe: if True, use process based threading.\n+                Note that because this implementation\n+                relies on multiprocessing, you should not pass\n+                non picklable arguments to the generator\n+                as they can't be passed easily to children processes.\n \n         # Returns\n             A Numpy array of predictions.\n@@ -1106,12 +1131,15 @@ class Sequential(Model):\n \n         model = cls()\n         for conf in config:\n-            layer = layers.deserialize(conf)\n+            layer = layer_module.deserialize(conf)\n             model.add(layer)\n         return model\n \n     def legacy_get_config(self):\n-        \"\"\"Returns the model configuration as a Python list.\n+        \"\"\"Retrieves the model configuration as a Python list.\n+\n+        # Returns\n+            A list of dicts (each dict is a layer config).\n         \"\"\"\n         config = []\n         if isinstance(self.layers[0], legacy_layers.Merge):\n@@ -1156,7 +1184,7 @@ class Sequential(Model):\n             name = layer_data['config'].get('name')\n             if name in layer_cache:\n                 return layer_cache[name]\n-            layer = layers.deserialize(layer_data)\n+            layer = layer_module.deserialize(layer_data)\n             layer_cache[name] = layer\n             return layer\n \n@@ -1166,7 +1194,7 @@ class Sequential(Model):\n             merge_inputs = []\n             first_layer_config = first_layer['config']\n             for merge_input_config in first_layer_config.pop('layers'):\n-                merge_input = layers.deserialize(merge_input_config)\n+                merge_input = layer_module.deserialize(merge_input_config)\n                 merge_inputs.append(merge_input)\n             first_layer_config['layers'] = merge_inputs\n             merge = legacy_layers.Merge.from_config(first_layer_config)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5ef7ce3f077abdb35ad74f720717a6721601cc72", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 70 | Files Changed: 4 | Hunks: 11 | Methods Changed: 20 | Complexity Δ (Sum/Max): -11/1 | Churn Δ: 104 | Churn Cumulative: 12149 | Contributors (this commit): 88 | Commits (past 90d): 59 | Contributors (cumulative): 105 | DMM Complexity: 0.0\n\nDIFF:\n@@ -12,9 +12,9 @@ import warnings\n from collections import deque\n from collections import OrderedDict\n from collections import Iterable\n-from .utils.generic_utils import Progbar\n-from keras import backend as K\n from pkg_resources import parse_version\n+from .utils.generic_utils import Progbar\n+from . import backend as K\n \n try:\n     import requests\n\n@@ -20,6 +20,11 @@ from .convolutional_recurrent import *\n from ..legacy.layers import *\n \n \n+def serialize(layer):\n+    return {'class_name': layer.__class__.__name__,\n+            'config': layer.get_config()}\n+\n+\n def deserialize(config, custom_objects=None):\n     \"\"\"Instantiate a layer from a config dictionary.\n \n\n@@ -1,6 +1,18 @@\n from __future__ import absolute_import\n import six\n from . import backend as K\n+from .losses import mean_squared_error\n+from .losses import mean_absolute_error\n+from .losses import mean_absolute_percentage_error\n+from .losses import mean_squared_logarithmic_error\n+from .losses import hinge\n+from .losses import squared_hinge\n+from .losses import categorical_crossentropy\n+from .losses import sparse_categorical_crossentropy\n+from .losses import binary_crossentropy\n+from .losses import kullback_leibler_divergence\n+from .losses import poisson\n+from .losses import cosine_proximity\n from .utils.generic_utils import deserialize_keras_object\n \n \n@@ -21,64 +33,6 @@ def sparse_categorical_accuracy(y_true, y_pred):\n def top_k_categorical_accuracy(y_true, y_pred, k=5):\n     return K.mean(K.in_top_k(y_pred, K.argmax(y_true, axis=-1), k), axis=-1)\n \n-\n-def mean_squared_error(y_true, y_pred):\n-    return K.mean(K.square(y_pred - y_true), axis=-1)\n-\n-\n-def mean_absolute_error(y_true, y_pred):\n-    return K.mean(K.abs(y_pred - y_true), axis=-1)\n-\n-\n-def mean_absolute_percentage_error(y_true, y_pred):\n-    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true),\n-                                            K.epsilon(),\n-                                            None))\n-    return 100. * K.mean(diff, axis=-1)\n-\n-\n-def mean_squared_logarithmic_error(y_true, y_pred):\n-    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n-    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n-    return K.mean(K.square(first_log - second_log), axis=-1)\n-\n-\n-def hinge(y_true, y_pred):\n-    return K.mean(K.maximum(1. - y_true * y_pred, 0.), axis=-1)\n-\n-\n-def squared_hinge(y_true, y_pred):\n-    return K.mean(K.square(K.maximum(1. - y_true * y_pred, 0.)), axis=-1)\n-\n-\n-def categorical_crossentropy(y_true, y_pred):\n-    return K.categorical_crossentropy(y_pred, y_true)\n-\n-\n-def sparse_categorical_crossentropy(y_true, y_pred):\n-    return K.sparse_categorical_crossentropy(y_pred, y_true)\n-\n-\n-def binary_crossentropy(y_true, y_pred):\n-    return K.mean(K.binary_crossentropy(y_pred, y_true), axis=-1)\n-\n-\n-def kullback_leibler_divergence(y_true, y_pred):\n-    y_true = K.clip(y_true, K.epsilon(), 1)\n-    y_pred = K.clip(y_pred, K.epsilon(), 1)\n-    return K.mean(K.sum(y_true * K.log(y_true / y_pred), axis=-1), axis=-1)\n-\n-\n-def poisson(y_true, y_pred):\n-    return K.mean(y_pred - y_true * K.log(y_pred + K.epsilon()), axis=-1)\n-\n-\n-def cosine_proximity(y_true, y_pred):\n-    y_true = K.l2_normalize(y_true, axis=-1)\n-    y_pred = K.l2_normalize(y_pred, axis=-1)\n-    return - K.mean(y_true * y_pred, axis=-1)\n-\n-\n # Aliases\n \n mse = MSE = mean_squared_error\n\n@@ -84,7 +84,7 @@ def save_model(model, filepath, overwrite=True):\n \n         raise TypeError('Not JSON Serializable:', obj)\n \n-    from keras import __version__ as keras_version\n+    from . import __version__ as keras_version\n \n     # If file exists and should not be overwritten.\n     if not overwrite and os.path.isfile(filepath):\n@@ -387,7 +387,7 @@ class Sequential(Model):\n                             'Found: ' + str(layer))\n         if not self.outputs:\n             # first layer in model: check that it is an input layer\n-            if layer.inbound_nodes:\n+            if not layer.inbound_nodes:\n                 # create an input layer\n                 if not hasattr(layer, 'batch_input_shape'):\n                     raise ValueError('The first layer in a '\n@@ -629,7 +629,11 @@ class Sequential(Model):\n         return self.model.constraints\n \n     def get_weights(self):\n-        \"\"\"Returns the weights of the model, as a flat list of Numpy arrays.\n+        \"\"\"Retrieves the weights of the model.\n+\n+        # Returns\n+            A flat list of Numpy arrays\n+            (one array per model weight).\n         \"\"\"\n         # Legacy support\n         if legacy_models.needs_legacy_support(self):\n@@ -1071,6 +1075,12 @@ class Sequential(Model):\n                 non picklable arguments to the generator\n                 as they can't be passed easily to children processes.\n \n+        # Returns\n+            Scalar test loss (if the model has no metrics)\n+            or list of scalars (if the model computes other metrics).\n+            The attribute `model.metrics_names` will give you\n+            the display labels for the scalar outputs.\n+\n         # Raises\n             RuntimeError: if the model was never compiled.\n         \"\"\"\n@@ -1113,8 +1123,6 @@ class Sequential(Model):\n                                             pickle_safe=pickle_safe)\n \n     def get_config(self):\n-        \"\"\"Returns the model configuration as a Python list.\n-        \"\"\"\n         if isinstance(self.layers[0], legacy_layers.Merge):\n             return self.legacy_get_config()\n \n@@ -1170,11 +1178,8 @@ class Sequential(Model):\n                 class_name = conf['name']\n                 name = conf.get('custom_name')\n                 conf['name'] = name\n-                new_config = {\n-                    'class_name': class_name,\n-                    'config': conf,\n-                }\n-                return new_config\n+                return {'class_name': class_name,\n+                        'config': conf}\n             return conf\n \n         # the model we will return\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cb3e82051fb1591e33887347758549f9191d8fd5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 90 | Lines Deleted: 12 | Files Changed: 2 | Hunks: 20 | Methods Changed: 18 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 102 | Churn Cumulative: 16116 | Contributors (this commit): 75 | Commits (past 90d): 61 | Contributors (cumulative): 81 | DMM Complexity: 0.875\n\nDIFF:\n@@ -705,6 +705,10 @@ class Layer(object):\n \n         # Returns\n             The layer's attribute `attr` at the node of index `node_index`.\n+\n+        # Raises\n+            RuntimeError: If the layer has no inbound nodes.\n+            ValueError: If the index is does not match any node.\n         \"\"\"\n         if not self.inbound_nodes:\n             raise RuntimeError('The layer has never been called '\n@@ -722,6 +726,16 @@ class Layer(object):\n \n     def get_input_shape_at(self, node_index):\n         \"\"\"Retrieves the input shape(s) of a layer at a given node.\n+\n+        # Arguments\n+            node_index: Integer, index of the node\n+                from which to retrieve the attribute.\n+                E.g. `node_index=0` will correspond to the\n+                first time the layer was called.\n+\n+        # Returns\n+            A shape tuple\n+            (or list of shape tuples if the layer has multiple inputs).\n         \"\"\"\n         return self._get_node_attribute_at_index(node_index,\n                                                  'input_shapes',\n@@ -729,6 +743,16 @@ class Layer(object):\n \n     def get_output_shape_at(self, node_index):\n         \"\"\"Retrieves the output shape(s) of a layer at a given node.\n+\n+        # Arguments\n+            node_index: Integer, index of the node\n+                from which to retrieve the attribute.\n+                E.g. `node_index=0` will correspond to the\n+                first time the layer was called.\n+\n+        # Returns\n+            A shape tuple\n+            (or list of shape tuples if the layer has multiple outputs).\n         \"\"\"\n         return self._get_node_attribute_at_index(node_index,\n                                                  'output_shapes',\n@@ -736,6 +760,15 @@ class Layer(object):\n \n     def get_input_at(self, node_index):\n         \"\"\"Retrieves the input tensor(s) of a layer at a given node.\n+\n+        # Arguments\n+            node_index: Integer, index of the node\n+                from which to retrieve the attribute.\n+                E.g. `node_index=0` will correspond to the\n+                first time the layer was called.\n+\n+        # Returns\n+            A tensor (or list of tensors if the layer has multiple inputs).\n         \"\"\"\n         return self._get_node_attribute_at_index(node_index,\n                                                  'input_tensors',\n@@ -743,6 +776,15 @@ class Layer(object):\n \n     def get_output_at(self, node_index):\n         \"\"\"Retrieves the output tensor(s) of a layer at a given node.\n+\n+        # Arguments\n+            node_index: Integer, index of the node\n+                from which to retrieve the attribute.\n+                E.g. `node_index=0` will correspond to the\n+                first time the layer was called.\n+\n+        # Returns\n+            A tensor (or list of tensors if the layer has multiple outputs).\n         \"\"\"\n         return self._get_node_attribute_at_index(node_index,\n                                                  'output_tensors',\n@@ -750,6 +792,16 @@ class Layer(object):\n \n     def get_input_mask_at(self, node_index):\n         \"\"\"Retrieves the input mask tensor(s) of a layer at a given node.\n+\n+        # Arguments\n+            node_index: Integer, index of the node\n+                from which to retrieve the attribute.\n+                E.g. `node_index=0` will correspond to the\n+                first time the layer was called.\n+\n+        # Returns\n+            A mask tensor\n+            (or list of tensors if the layer has multiple inputs).\n         \"\"\"\n         return self._get_node_attribute_at_index(node_index,\n                                                  'input_masks',\n@@ -757,6 +809,16 @@ class Layer(object):\n \n     def get_output_mask_at(self, node_index):\n         \"\"\"Retrieves the output mask tensor(s) of a layer at a given node.\n+\n+        # Arguments\n+            node_index: Integer, index of the node\n+                from which to retrieve the attribute.\n+                E.g. `node_index=0` will correspond to the\n+                first time the layer was called.\n+\n+        # Returns\n+            A mask tensor\n+            (or list of tensors if the layer has multiple outputs).\n         \"\"\"\n         return self._get_node_attribute_at_index(node_index,\n                                                  'output_masks',\n@@ -802,7 +864,7 @@ class Layer(object):\n             AttributeError: if the layer is connected to\n             more than one incoming layers.\n         \"\"\"\n-        if len(self.inbound_nodes) == 0:\n+        if not self.inbound_nodes:\n             raise AttributeError('Layer ' + self.name +\n                                  ' has no inbound nodes.')\n         if len(self.inbound_nodes) > 1:\n@@ -900,8 +962,9 @@ class Layer(object):\n \n     @property\n     def output_shape(self):\n-        \"\"\"Retrieves the output shape tuple(s) of a layer. Only applicable\n-        if the layer has one inbound node,\n+        \"\"\"Retrieves the output shape tuple(s) of a layer.\n+\n+        Only applicable if the layer has one inbound node,\n         or if all inbound nodes have the same output shape.\n \n         # Returns\n@@ -1048,6 +1111,10 @@ class Layer(object):\n                 number of the dimensions of the weights\n                 of the layer (i.e. it should match the\n                 output of `get_weights`).\n+\n+        # Raises\n+            ValueError: If the provided weights list does not match the\n+                layer's specifications.\n         \"\"\"\n         params = self.weights\n         if len(params) != len(weights):\n@@ -1127,6 +1194,10 @@ class Layer(object):\n \n         # Returns\n             An integer count.\n+\n+        # Raises\n+            RuntimeError: if the layer isn't yet built\n+                (in which case its weights aren't yet defined).\n         \"\"\"\n         if not self.built:\n             if self.__class__.__name__ == 'Sequential':\n@@ -1184,7 +1255,7 @@ class InputLayer(Layer):\n             # Attempt automatic input shape inference.\n             try:\n                 batch_input_shape = K.int_shape(input_tensor)\n-            except:\n+            except TypeError:\n                 if not input_shape and not batch_input_shape:\n                     raise ValueError('InputLayer was provided '\n                                      'an input_tensor argument, '\n@@ -1244,6 +1315,7 @@ def Input(shape=None, batch_shape=None,\n           name=None, dtype=K.floatx(), sparse=False,\n           tensor=None):\n     \"\"\"`Input()` is used to instantiate a Keras tensor.\n+\n     A Keras tensor is a tensor object from the underlying backend\n     (Theano or TensorFlow), which we augment with certain\n     attributes that allow us to build a Keras model\n@@ -1276,14 +1348,16 @@ def Input(shape=None, batch_shape=None,\n             (`float32`, `float64`, `int32`...)\n         sparse: A boolean specifying whether the placeholder\n             to be created is sparse.\n+        tensor: Optional existing tensor to wrap into the `Input` layer.\n+            If set, the layer will not create a placeholder tensor.\n \n     # Example\n \n         ```python\n         # this is a logistic regression in Keras\n-        a = Input(shape=(32,))\n-        b = Dense(16, activation='softmax')(a)\n-        model = Model(input=a, output=b)\n+        x = Input(shape=(32,))\n+        y = Dense(16, activation='softmax')(x)\n+        model = Model(x, y)\n         ```\n     \"\"\"\n     if not batch_shape and tensor is None:\n@@ -1490,7 +1564,7 @@ class Container(Layer):\n         def make_node_marker(node, depth):\n             return str(id(node)) + '-' + str(depth)\n \n-        def build_map_of_graph(tensor, seen_nodes=set(), depth=0,\n+        def build_map_of_graph(tensor, seen_nodes=None, depth=0,\n                                layer=None, node_index=None, tensor_index=None):\n             \"\"\"Builds a map of the graph of layers.\n \n@@ -1509,6 +1583,7 @@ class Container(Layer):\n                 node_index: Node index from which `tensor` comes from.\n                 tensor_index: Tensor_index from which `tensor` comes from.\n             \"\"\"\n+            seen_nodes = seen_nodes or set()\n             if not layer or node_index is None or tensor_index is None:\n                 layer, node_index, tensor_index = tensor._keras_history\n             node = layer.inbound_nodes[node_index]\n\n@@ -183,6 +183,11 @@ def load_model(filepath, custom_objects=None):\n         custom_objects = {}\n \n     def convert_custom_objects(obj):\n+        \"\"\"Handles custom object lookup.\n+\n+        # Arguments\n+            obj: object, dict, or list.\n+        \"\"\"\n         if isinstance(obj, list):\n             deserialized = []\n             for value in obj:\n@@ -1061,11 +1066,9 @@ class Sequential(Model):\n         as accepted by `test_on_batch`.\n \n         # Arguments\n-            generator:\n-                generator yielding tuples (inputs, targets)\n+            generator: Generator yielding tuples (inputs, targets)\n                 or (inputs, targets, sample_weights)\n-            val_samples:\n-                total number of samples to generate from `generator`\n+            val_samples: Total number of samples to generate from `generator`\n                 before returning.\n             max_q_size: maximum size for the generator queue\n             workers: maximum number of processes to spin up\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2ab5295ceebb1acc455f43ee5a8b185983620655", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 86 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 21 | Methods Changed: 15 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 100 | Churn Cumulative: 7275 | Contributors (this commit): 27 | Commits (past 90d): 37 | Contributors (cumulative): 27 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1739,6 +1739,9 @@ class Container(Layer):\n \n         # Returns\n             A layer instance.\n+\n+        # Raises\n+            ValueError: In case of invalid layer name or index.\n         \"\"\"\n         # It would be unreliable to build a dictionary\n         # based on layer names, because names can potentially\n@@ -1815,10 +1818,14 @@ class Container(Layer):\n \n     @property\n     def state_updates(self):\n-        \"\"\"Returns the `updates` from all layers that are\n-        stateful.  This is useful for separating training updates and\n+        \"\"\"Returns the `updates` from all layers that are stateful.\n+\n+        This is useful for separating training updates and\n         state updates, e.g. when we need to update a layer's internal state\n         during prediction.\n+\n+        # Returns\n+            A list of update ops.\n         \"\"\"\n         state_updates = []\n         for layer in self.layers:\n@@ -1860,8 +1867,10 @@ class Container(Layer):\n         return weights\n \n     def get_weights(self):\n-        \"\"\"Returns the weights of the model,\n-        as a flat list of Numpy arrays.\n+        \"\"\"Retrieves the weights of the model.\n+\n+        # Returns\n+            A flat list of Numpy arrays.\n         \"\"\"\n         weights = []\n         for layer in self.layers:\n@@ -1870,8 +1879,9 @@ class Container(Layer):\n \n     def set_weights(self, weights):\n         \"\"\"Sets the weights of the model.\n-        The `weights` argument should be a list\n-        of Numpy arrays with shapes and types matching\n+\n+        # Arguments\n+            weights: A list of Numpy arrays with shapes and types matching\n                 the output of `model.get_weights()`.\n         \"\"\"\n         tuples = []\n@@ -1900,10 +1910,13 @@ class Container(Layer):\n         return specs\n \n     def call(self, input, mask=None):\n-        \"\"\"`call` just reapplies all ops in the graph to the new inputs\n+        \"\"\"Call the model on new inputs.\n+\n+        In this case `call` just reapplies\n+        all ops in the graph to the new inputs\n         (e.g. build a new computational graph from the provided inputs).\n \n-        It is callable on non-Keras tensors.\n+        A model is callable on non-Keras tensors.\n \n         # Arguments\n             input: A tensor or list of tensors.\n@@ -1924,7 +1937,7 @@ class Container(Layer):\n         if cache_key in self._output_tensor_cache:\n             return self._output_tensor_cache[cache_key]\n         else:\n-            output_tensors, output_masks, output_shapes = self.run_internal_graph(inputs, masks)\n+            output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n             return output_tensors\n \n     def compute_mask(self, inputs, mask):\n@@ -2246,6 +2259,15 @@ class Container(Layer):\n     @classmethod\n     def from_config(cls, config, custom_objects=None):\n         \"\"\"Instantiates a Model from its config (output of `get_config()`).\n+\n+        # Arguments\n+            config: Model config dictionary.\n+            custom_objects: Optional dictionary mapping names\n+                (strings) to custom classes or functions to be\n+                considered during deserialization.\n+\n+        # Returns\n+            A model instance.\n         \"\"\"\n         # layer instances created during\n         # the graph reconstruction process\n@@ -2267,14 +2289,17 @@ class Container(Layer):\n             for node_data in inbound_nodes_data:\n                 input_tensors = []\n                 for input_data in node_data:\n+                    inbound_layer_name = input_data[0]\n+                    inbound_node_index = input_data[1]\n+                    inbound_tensor_index = input_data[2]\n                     if len(input_data) == 3:\n-                        inbound_layer_name, inbound_node_index, inbound_tensor_index = input_data\n                         kwargs = {}\n                     elif len(input_data) == 4:\n-                        inbound_layer_name, inbound_node_index, inbound_tensor_index, kwargs = input_data\n+                        kwargs = input_data[3]\n                     else:\n                         raise ValueError('Improperly formatted model config.')\n-                    assert inbound_layer_name in created_layers, 'Missing layer: %s' % inbound_layer_name\n+                    if inbound_layer_name not in created_layers:\n+                        raise ValueError('Missing layer: ' + inbound_layer_name)\n                     inbound_layer = created_layers[inbound_layer_name]\n                     inbound_node = inbound_layer.inbound_nodes[inbound_node_index]\n                     input_tensors.append(inbound_node.output_tensors[inbound_tensor_index])\n@@ -2349,6 +2374,11 @@ class Container(Layer):\n                     (ordered names of weights tensor of the layer).\n                 - For every weight in the layer, a dataset\n                     storing the weight value, named after the weight tensor.\n+\n+        # Arguments\n+            filepath: String, path to the file to save the weights to.\n+            overwrite: Whether to silently overwrite any existing file at the\n+                target location, or provide the user with a manual prompt.\n         \"\"\"\n         if h5py is None:\n             raise ImportError('`save_weights` requires h5py.')\n@@ -2381,6 +2411,9 @@ class Container(Layer):\n             filepath: String, path to the weights file to load.\n             by_name: Boolean, whether to load weights by name\n                 or by topological order.\n+\n+        # Raises\n+            ImportError: If h5py is not available.\n         \"\"\"\n         if h5py is None:\n             raise ImportError('`load_weights` requires h5py.')\n@@ -2396,7 +2429,11 @@ class Container(Layer):\n             f.close()\n \n     def _updated_config(self):\n-        \"\"\"Shared between different serialization methods.\"\"\"\n+        \"\"\"Util hared between different serialization methods.\n+\n+        # Returns\n+            Model config with Keras version information added.\n+        \"\"\"\n         from .. import __version__ as keras_version\n \n         config = self.get_config()\n@@ -2412,6 +2449,13 @@ class Container(Layer):\n \n         To load a network from a JSON save file, use\n         `keras.models.model_from_json(json_string, custom_objects={})`.\n+\n+        # Arguments\n+            **kwargs: Additional keyword arguments\n+                to be passed to `json.dumps()`.\n+\n+        # Returns\n+            A JSON string.\n         \"\"\"\n         def get_json_type(obj):\n             # If obj is any numpy type\n@@ -2436,6 +2480,13 @@ class Container(Layer):\n         `custom_objects` should be a dictionary mapping\n         the names of custom losses / layers / etc to the corresponding\n         functions / classes.\n+\n+        # Arguments\n+            **kwargs: Additional keyword arguments\n+                to be passed to `yaml.dump()`.\n+\n+        # Returns\n+            A YAML string.\n         \"\"\"\n         return yaml.dump(self._updated_config(), **kwargs)\n \n@@ -2523,7 +2574,14 @@ def _is_all_none(iterable_or_element):\n \n \n def _collect_previous_mask(input_tensors):\n-    # Return the output mask(s) of the previous node.\n+    \"\"\"Retrieves the output mask(s) of the previous node.\n+\n+    # Arguments\n+        input_tensors: A tensor or list of tensors.\n+\n+    # Returns\n+        A mask tensor or list of mask tensors.\n+    \"\"\"\n     input_tensors = _to_list(input_tensors)\n     masks = []\n     for x in input_tensors:\n@@ -2596,6 +2654,16 @@ def save_weights_to_hdf5_group(f, layers):\n \n \n def load_weights_from_hdf5_group(f, layers):\n+    \"\"\"Implements topological (order-based) weight loading.\n+\n+    # Arguments\n+        f: A pointer to a HDF5 group.\n+        layers: a list of target layers.\n+\n+    # Raises\n+        ValueError: in case of mismatch between provided layers\n+            and weights file.\n+    \"\"\"\n     filtered_layers = []\n     for layer in layers:\n         weights = layer.weights\n@@ -2650,6 +2718,10 @@ def load_weights_from_hdf5_group_by_name(f, layers):\n     # Arguments\n         f: A pointer to a HDF5 group.\n         layers: a list of target layers.\n+\n+    # Raises\n+        ValueError: in case of mismatch between provided layers\n+            and weights file.\n     \"\"\"\n     # New file format.\n     layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b361e30146ed82fbd4e5b8c301bfb5196997a307", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 21 | Files Changed: 1 | Hunks: 10 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 37 | Churn Cumulative: 7312 | Contributors (this commit): 27 | Commits (past 90d): 38 | Contributors (cumulative): 27 | DMM Complexity: 1.0\n\nDIFF:\n@@ -267,7 +267,7 @@ class Layer(object):\n                           'name',\n                           'trainable',\n                           'weights'}\n-        for kwarg in kwargs.keys():\n+        for kwarg in kwargs:\n             if kwarg not in allowed_kwargs:\n                 raise TypeError('Keyword argument not understood:', kwarg)\n         name = kwargs.get('name')\n@@ -1219,6 +1219,7 @@ class InputLayer(Layer):\n \n     # Arguments\n         input_shape: Shape tuple, not including the batch axis.\n+        batch_size: Optional input batch size (integer or None).\n         batch_input_shape: Shape tuple, including the batch axis.\n         dtype: Datatype of the input.\n         input_tensor: Optional tensor to use as layer input\n@@ -1228,24 +1229,17 @@ class InputLayer(Layer):\n         name: Name of the layer (string).\n     \"\"\"\n \n-    def __init__(self, input_shape=None, batch_input_shape=None,\n+    def __init__(self, input_shape=None, batch_size=None,\n+                 batch_input_shape=None,\n                  dtype=None, input_tensor=None, sparse=False, name=None):\n-        # TODO: call parent's __init__ instead.\n-        self.input_spec = None\n-        self.trainable = False\n-        self.built = True\n-        self._trainable_weights = []\n-        self._non_trainable_weights = []\n-        self.inbound_nodes = []\n-        self.outbound_nodes = []\n-        self._constraints = {}\n-        self.sparse = sparse\n-        self.supports_masking = False\n-\n         if not name:\n             prefix = 'input'\n             name = prefix + '_' + str(K.get_uid(prefix))\n-        self.name = name\n+        super(InputLayer, self).__init__(dtype=dtype, name=name)\n+\n+        self.trainable = False\n+        self.built = True\n+        self.sparse = sparse\n \n         if input_shape and batch_input_shape:\n             raise ValueError('Only provide the input_shape OR '\n@@ -1268,7 +1262,7 @@ class InputLayer(Layer):\n                 raise ValueError('An Input layer should be passed either '\n                                  'a `batch_input_shape` or an `input_shape`.')\n             else:\n-                batch_input_shape = (None,) + tuple(input_shape)\n+                batch_input_shape = (batch_size,) + tuple(input_shape)\n         else:\n             batch_input_shape = tuple(batch_input_shape)\n \n@@ -1351,6 +1345,9 @@ def Input(shape=None, batch_shape=None,\n         tensor: Optional existing tensor to wrap into the `Input` layer.\n             If set, the layer will not create a placeholder tensor.\n \n+    # Returns\n+        A tensor.\n+\n     # Example\n \n         ```python\n@@ -1418,16 +1415,13 @@ class Container(Layer):\n     \"\"\"\n \n     def __init__(self, inputs, outputs, name=None):\n-        # TODO: call parent's __init__ instead.\n-        # Handle name argument.\n+        # Handle `name` argument.\n         if not name:\n             prefix = self.__class__.__name__.lower()\n             name = prefix + '_' + str(K.get_uid(prefix))\n         self.name = name\n \n         self.supports_masking = False\n-\n-        # Whether container weights are trainable.\n         self.trainable = True\n \n         # Container-specific properties.\n@@ -1755,7 +1749,8 @@ class Container(Layer):\n             else:\n                 return self.layers[index]\n         else:\n-            assert name, 'Provide either a layer name or layer index.'\n+            if not name:\n+                raise ValueError('Provide either a layer name or layer index.')\n         layer = None\n         for layer in self.layers:\n             if layer.name == name:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a277dabc1410a36430fa63365876b504e1aa835d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 46 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 12 | Methods Changed: 11 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 56 | Churn Cumulative: 7368 | Contributors (this commit): 27 | Commits (past 90d): 39 | Contributors (cumulative): 27 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1723,9 +1723,9 @@ class Container(Layer):\n         # self.input_spec\n \n     def get_layer(self, name=None, index=None):\n-        \"\"\"Returns a layer based on either its name (unique)\n-        or its index in the graph. Indices are based on\n-        order of horizontal graph traversal (bottom-up).\n+        \"\"\"Retrieves a layer based on either its name (unique) or index.\n+\n+        Indices are based on order of horizontal graph traversal (bottom-up).\n \n         # Arguments\n             name: String, name of layer.\n@@ -1760,6 +1760,16 @@ class Container(Layer):\n \n     @property\n     def updates(self):\n+        \"\"\"Retrieve the model's updates.\n+\n+        Will only include updates that are either\n+        inconditional, or conditional on inputs to this model\n+        (e.g. will not include updates that depend on tensors\n+        that aren't inputs to this model).\n+\n+        # Returns\n+            A list of update ops.\n+        \"\"\"\n         updates = []\n         for layer in self.layers:\n             if hasattr(layer, 'updates'):\n@@ -1780,6 +1790,16 @@ class Container(Layer):\n \n     @property\n     def losses(self):\n+        \"\"\"Retrieve the model's losses.\n+\n+        Will only include losses that are either\n+        inconditional, or conditional on inputs to this model\n+        (e.g. will not include losses that depend on tensors\n+        that aren't inputs to this model).\n+\n+        # Returns\n+            A list of loss tensors.\n+        \"\"\"\n         losses = []\n         for layer in self.layers:\n             if hasattr(layer, 'losses'):\n@@ -1890,6 +1910,12 @@ class Container(Layer):\n \n     @property\n     def input_spec(self):\n+        \"\"\"Gets the model's input specs.\n+\n+        # Returns\n+            A list of `InputSpec` instances (one per input to the model)\n+                or a single instance if the model has only one input.\n+        \"\"\"\n         specs = []\n         for layer in getattr(self, 'input_layers', []):\n             if layer.input_spec is None:\n@@ -1902,9 +1928,11 @@ class Container(Layer):\n                                     'Found input_spec = ' +\n                                     str(layer.input_spec))\n                 specs += layer.input_spec\n+        if len(specs) == 1:\n+            return specs[0]\n         return specs\n \n-    def call(self, input, mask=None):\n+    def call(self, inputs, mask=None):\n         \"\"\"Call the model on new inputs.\n \n         In this case `call` just reapplies\n@@ -1914,7 +1942,7 @@ class Container(Layer):\n         A model is callable on non-Keras tensors.\n \n         # Arguments\n-            input: A tensor or list of tensors.\n+            inputs: A tensor or list of tensors.\n             mask: A mask or list of masks. A mask can be\n                 either a tensor or None (no mask).\n \n@@ -1922,7 +1950,7 @@ class Container(Layer):\n             A tensor if there is a single output, or\n             a list of tensors if there are more than one outputs.\n         \"\"\"\n-        inputs = _to_list(input)\n+        inputs = _to_list(inputs)\n         if mask is None:\n             masks = [None for _ in range(len(inputs))]\n         else:\n@@ -1946,7 +1974,7 @@ class Container(Layer):\n         if cache_key in self._output_mask_cache:\n             return self._output_mask_cache[cache_key]\n         else:\n-            output_tensors, output_masks, output_shapes = self.run_internal_graph(inputs, masks)\n+            _, output_masks, _ = self.run_internal_graph(inputs, masks)\n             return output_masks\n \n     def compute_output_shape(self, input_shape):\n@@ -2269,8 +2297,11 @@ class Container(Layer):\n         created_layers = {}\n \n         def process_layer(layer_data):\n-            # Iterate over saved layers, instantiate them,\n-            # then call them on appropriate inputs to create graph nodes\n+            \"\"\"Deserialize a layer, then call it on appropriate inputs.\n+\n+            # Arguments\n+                layer_data: layer config dict.\n+            \"\"\"\n             layer_name = layer_data['name']\n \n             # Instantiate layer.\n@@ -2327,7 +2358,9 @@ class Container(Layer):\n         return cls(inputs=input_tensors, outputs=output_tensors, name=name)\n \n     def save(self, filepath, overwrite=True):\n-        \"\"\"Save into a single HDF5 file:\n+        \"\"\"Save the model to a single HDF5 file.\n+\n+        The savefile includes:\n             - The model architecture, allowing to re-instantiate the model.\n             - The model weights.\n             - The state of the optimizer, allowing to resume training\n@@ -2374,6 +2407,9 @@ class Container(Layer):\n             filepath: String, path to the file to save the weights to.\n             overwrite: Whether to silently overwrite any existing file at the\n                 target location, or provide the user with a manual prompt.\n+\n+        # Raises\n+            ImportError: If h5py is not available.\n         \"\"\"\n         if h5py is None:\n             raise ImportError('`save_weights` requires h5py.')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#309f13ad8cfe5c5e711837cc8efa5bd00b01368e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 47 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 11 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 52 | Churn Cumulative: 10845 | Contributors (this commit): 56 | Commits (past 90d): 62 | Contributors (cumulative): 61 | DMM Complexity: None\n\nDIFF:\n@@ -2291,6 +2291,9 @@ class Container(Layer):\n \n         # Returns\n             A model instance.\n+\n+        # Raises\n+            ValueError: In case of improperly formatted config dict.\n         \"\"\"\n         # layer instances created during\n         # the graph reconstruction process\n@@ -2374,6 +2377,11 @@ class Container(Layer):\n         is a compiled model ready to be used (unless the saved model\n         was never compiled in the first place).\n \n+        # Arguments\n+            filepath: String, path to the file to save the weights to.\n+            overwrite: Whether to silently overwrite any existing file at the\n+                target location, or provide the user with a manual prompt.\n+\n         # Example\n \n         ```python\n\n@@ -59,7 +59,7 @@ def _standardize_input_data(data, names, shapes=None,\n             arrays.append(data[name])\n     elif isinstance(data, list):\n         if len(data) != len(names):\n-            if len(data) > 0 and hasattr(data[0], 'shape'):\n+            if data and hasattr(data[0], 'shape'):\n                 raise ValueError('Error when checking ' + exception_prefix +\n                                  ': the list of Numpy arrays '\n                                  'that you are passing to your model '\n@@ -90,8 +90,8 @@ def _standardize_input_data(data, names, shapes=None,\n                             'or list/dict of Numpy arrays. '\n                             'Found: ' + str(data)[:200] + '...')\n         if len(names) != 1:\n-            # case: model expects multiple inputs but only received\n-            # a single Numpy array\n+            # Case: model expects multiple inputs but only received\n+            # a single Numpy array.\n             raise ValueError('The model expects ' + str(len(names)) +\n                              ' input arrays, but only received one array. '\n                              'Found: array with shape ' + str(data.shape))\n@@ -133,6 +133,18 @@ def _standardize_input_data(data, names, shapes=None,\n \n def _standardize_sample_or_class_weights(x_weight, output_names, weight_type):\n     \"\"\"Maps `sample_weight` or `class_weight` to model outputs.\n+\n+    # Arguments\n+        x_weight: User-provided `sample_weight` or `class_weight` argument.\n+        output_names: List of output names (strings) in the model.\n+        weight_type: A string used purely for exception printing.\n+\n+    # Returns\n+        A list of `sample_weight` or `class_weight` where there are exactly\n+            one element per model output.\n+\n+    # ValueError\n+        ValueError: In case of invalid user-provided argument.\n     \"\"\"\n     if x_weight is None or len(x_weight) == 0:\n         return [None for _ in output_names]\n@@ -327,6 +339,13 @@ def _batch_shuffle(index_array, batch_size):\n \n def _make_batches(size, batch_size):\n     \"\"\"Returns a list of batch indices (tuples of indices).\n+\n+    # Arguments\n+        size: Integer, total size of the data to slice into batches.\n+        batch_size: Integer, batch size.\n+\n+    # Returns\n+        A list of tuples of array indices.\n     \"\"\"\n     num_batches = int(np.ceil(size / float(batch_size)))\n     return [(i * batch_size, min(size, (i + 1) * batch_size))\n@@ -334,7 +353,9 @@ def _make_batches(size, batch_size):\n \n \n def _slice_arrays(arrays, start=None, stop=None):\n-    \"\"\"This takes an array-like, or a list of\n+    \"\"\"Slice an array or list of arrays.\n+\n+    This takes an array-like, or a list of\n     array-likes, and outputs:\n         - arrays[start:stop] if `arrays` is an array-like\n         - [x[start:stop] for x in arrays] if `arrays` is a list\n@@ -342,10 +363,14 @@ def _slice_arrays(arrays, start=None, stop=None):\n     Can also work on list/array of indices: `_slice_arrays(x, indices)`\n \n     # Arguments\n+        arrays: Single array or list of arrays.\n         start: can be an integer index (start index)\n             or a list/array of indices\n         stop: integer (stop index); should be None if\n             `start` was a list.\n+\n+    # Returns\n+        A slice of the array(s).\n     \"\"\"\n     if isinstance(arrays, list):\n         if hasattr(start, '__len__'):\n@@ -365,9 +390,18 @@ def _slice_arrays(arrays, start=None, stop=None):\n \n \n def _weighted_masked_objective(fn):\n-    \"\"\"Transforms an objective function `fn(y_true, y_pred)`\n+    \"\"\"Adds support for masking and sample-weighting to an objective function.\n+\n+    It transforms an objective function `fn(y_true, y_pred)`\n     into a sample-weighted, cost-masked objective function\n     `fn(y_true, y_pred, weights, mask)`.\n+\n+    # Arguments\n+        fn: The objective function to wrap,\n+            with signature `fn(y_true, y_pred)`.\n+\n+    # Returns\n+        A function with signature `fn(y_true, y_pred, weights, mask)`.\n     \"\"\"\n     def weighted(y_true, y_pred, weights, mask=None):\n         # score_array has ndim >= 2\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
